[
{"item_id": "explain", "code": "explain(x, ...)  show_query(x, ...)", "description": "     This is a generic function which gives more details about an object than print(), and is more focused on human readable output than str().     ", "parameters": ["x: An object to explain", "...: Other parameters possibly used by generic"]},
{"item_id": "ident", "code": "ident(...)", "description": "     ident() takes unquoted strings and flags them as identifiers. ident_q() assumes its input has already been quoted, and ensures it does not get quoted again. This is currently used only for for schema.table.     ", "parameters": ["...: A character vector, or name-value pairs"]},
{"item_id": "copy_to", "code": "copy_to(dest, df, name = deparse(substitute(df)), overwrite = FALSE, ...)", "description": "     This function uploads a local data frame into a remote data source, creating the table definition as needed. Wherever possible, the new object will be temporary, limited to the current connection to the source.     ", "parameters": ["dest: remote data source", "df: local data frame", "name: name for new remote table.", "overwrite: If TRUE, will overwrite an existing table with name name. If FALSE, will throw an error if name already exists.", "...: other parameters passed to methods."]},
{"item_id": "with_groups", "code": "with_groups(.data, .groups, .f, ...)", "description": "      This is an experimental new function that allows you to modify the grouping variables for a single operation.     ", "parameters": [".data: A data frame", ".groups: &lt;tidy-select&gt; One or more variables to group by. Unlike group_by(), you can only group by existing variables, and you can use tidy-select syntax like c(x, y, z) to select multiple variables. Use NULL to temporarily ungroup.", ".f: Function to apply to regrouped data. Supports purrr-style ~ syntax", "...: Additional arguments passed on to ...."]},
{"item_id": "group_trim", "code": "group_trim(.tbl, .drop = group_by_drop_default(.tbl))", "description": "       Drop unused levels of all factors that are used as grouping variables, then recalculates the grouping structure. group_trim() is particularly useful after a filter() that is intended to select a subset of groups.     ", "parameters": [".tbl: A grouped data frame", ".drop: See group_by()"]},
{"item_id": "group_split", "code": "group_split(.tbl, ..., .keep = TRUE)", "description": "       group_split() works like base::split() but it uses the grouping structure from group_by() and therefore is subject to the data mask it does not name the elements of the list based on the grouping as this typically loses information and is confusing.   group_keys() explains the grouping structure, by returning a data frame that has one row per group and one column per grouping variable.     ", "parameters": [".tbl: A tbl", "...: Grouping specification, forwarded to group_by()", ".keep: Should the grouping columns be kept"]},
{"item_id": "sql", "code": "sql(...)", "description": "     These functions are critical when writing functions that translate R functions to sql functions. Typically a conversion function should escape all its inputs and return an sql object.     ", "parameters": ["...: Character vectors that will be combined into a single SQL expression."]},
{"item_id": "group_map", "code": "group_map(.data, .f, ..., .keep = FALSE)  group_modify(.data, .f, ..., .keep = FALSE)  group_walk(.data, .f, ...)", "description": "      group_map(), group_modify() and group_walk() are purrr-style functions that can be used to iterate on grouped tibbles.     ", "parameters": [".data: A grouped tibble", ".f: A function or formula to apply to each group. It must return a data frame. If a function, it is used as is. It should have at least 2 formal arguments. If a formula, e.g. ~ head(.x), it is converted to a function. In the formula, you can use . or .x to refer to the subset of rows of .tbl for the given group .y to refer to the key, a one row tibble with one column per grouping variable that identifies the group ", "...: Additional arguments passed on to .f", ".keep: are the grouping variables kept in .x"]},
{"item_id": "all_equal", "code": "all_equal(   target,   current,   ignore_col_order = TRUE,   ignore_row_order = TRUE,   convert = FALSE,   ... )", "description": "       all_equal() allows you to compare data frames, optionally ignoring row and column names. It is questioning as of dplyr 1.0.0, because it seems to solve a problem that no longer seems that important.     ", "parameters": ["target, current: Two data frames to compare.", "ignore_col_order: Should order of columns be ignored?", "ignore_row_order: Should order of rows be ignored?", "convert: Should similar classes be converted? Currently this will convert factor to character and integer to double.", "...: Ignored. Needed for compatibility with all.equal()."]},
{"item_id": "tbl", "code": "tbl(src, ...)  is.tbl(x)", "description": "     This is a generic method that dispatches based on the first argument.     ", "parameters": ["src: A data source", "...: Other arguments passed on to the individual methods", "x: Any object"]},
{"item_id": "compute", "code": "compute(x, name = random_table_name(), ...)  collect(x, ...)  collapse(x, ...)", "description": "     compute() stores results in a remote temporary table. collect() retrieves data into a local tibble. collapse() is slightly different: it doesn't force computation, but instead forces generation of the SQL query. This is sometimes needed to work around bugs in dplyr's SQL generation. All functions preserve grouping and ordering.     ", "parameters": ["x: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "name: Name of temporary table on database.", "...: Other arguments passed on to methods"]},
{"item_id": "auto_copy", "code": "auto_copy(x, y, copy = FALSE, ...)", "description": "     Copy tables to same source, if necessary     ", "parameters": ["x, y: y will be copied to x, if necessary.", "copy: If x and y are not from the same data source, and copy is TRUE, then y will be copied into the same src as x.  This allows you to join tables across srcs, but it is a potentially expensive operation so you must opt into it.", "...: Other arguments passed on to methods."]},
{"item_id": "storms", "code": "storms", "description": "     This data is a subset of the NOAA Atlantic hurricane database best track data, http://www.nhc.noaa.gov/data/#hurdat. The data includes the positions and attributes of 198 tropical storms, measured every six hours during the lifetime of a storm.     ", "parameters": []},
{"item_id": "starwars", "code": "starwars", "description": "     This data comes from SWAPI, the Star Wars API, http://swapi.dev/     ", "parameters": []},
{"item_id": "band_members", "code": "band_members  band_instruments  band_instruments2", "description": "     These data sets describe band members of the Beatles and Rolling Stones. They are toy data sets that can be displayed in their entirety on a slide (e.g. to demonstrate a join).     ", "parameters": []},
{"item_id": "vars", "code": "vars(...)", "description": "     vars() was only needed for the scoped verbs, which have been superseded by the use of across() in an existing verb. See vignette(\"colwise\") for details. This helper is intended to provide equivalent semantics to select(). It is used for instance in scoped summarising and mutating verbs (mutate_at() and summarise_at()). Note that verbs accepting a vars() specification also accept a numeric vector of positions or a character vector of column names.     ", "parameters": ["...: &lt;tidy-select&gt; Variables to include/exclude in mutate/summarise. You can use same specifications as in select(). If missing, defaults to all non-grouping variables."]},
{"item_id": "all_vars", "code": "all_vars(expr)  any_vars(expr)", "description": "      all_vars() and any_vars() were only needed for the scoped verbs, which have been superseded by the use of across() in an existing verb. See vignette(\"colwise\") for details. These quoting functions signal to scoped filtering verbs (e.g. filter_if() or filter_all()) that a predicate expression should be applied to all relevant variables. The all_vars() variant takes the intersection of the predicate expressions with &amp; while the any_vars() variant takes the union with |.     ", "parameters": ["expr: &lt;data-masking&gt; An expression that returns a logical vector, using . to refer to the \"current\" variable."]},
{"item_id": "summarise_all", "code": "summarise_all(.tbl, .funs, ...)  summarise_if(.tbl, .predicate, .funs, ...)  summarise_at(.tbl, .vars, .funs, ..., .cols = NULL)  summarize_all(.tbl, .funs, ...)  summarize_if(.tbl, .predicate, .funs, ...)  summarize_at(.tbl, .vars, .funs, ..., .cols = NULL)", "description": "      Scoped verbs (_if, _at, _all) have been superseded by the use of across() in an existing verb. See vignette(\"colwise\") for details. The scoped variants of summarise() make it easy to apply the same transformation to multiple variables. There are three variants. summarise_all() affects every variable summarise_at() affects variables selected with a character vector or vars() summarise_if() affects variables selected with a predicate function       ", "parameters": [".tbl: A tbl object.", ".funs: A function fun, a quosure style lambda ~ fun(.) or a list of either form.", "...: Additional arguments for the function calls in .funs. These are evaluated only once, with tidy dots support.", ".predicate: A predicate function to be applied to the columns or a logical vector. The variables for which .predicate is or returns TRUE are selected. This argument is passed to rlang::as_function() and thus supports quosure-style lambda functions and strings representing function names.", ".vars: A list of columns generated by vars(), a character vector of column names, a numeric vector of column positions, or NULL.", ".cols: This argument has been renamed to .vars to fit dplyr's terminology and is deprecated."]},
{"item_id": "mutate_all", "code": "mutate_all(.tbl, .funs, ...)  mutate_if(.tbl, .predicate, .funs, ...)  mutate_at(.tbl, .vars, .funs, ..., .cols = NULL)  transmute_all(.tbl, .funs, ...)  transmute_if(.tbl, .predicate, .funs, ...)  transmute_at(.tbl, .vars, .funs, ..., .cols = NULL)", "description": "      Scoped verbs (_if, _at, _all) have been superseded by the use of across() in an existing verb. See vignette(\"colwise\") for details. The scoped variants of mutate() and transmute() make it easy to apply the same transformation to multiple variables. There are three variants: _all affects every variable _at affects variables selected with a character vector or vars() _if affects variables selected with a predicate function:       ", "parameters": [".tbl: A tbl object.", ".funs: A function fun, a quosure style lambda ~ fun(.) or a list of either form.", "...: Additional arguments for the function calls in .funs. These are evaluated only once, with tidy dots support.", ".predicate: A predicate function to be applied to the columns or a logical vector. The variables for which .predicate is or returns TRUE are selected. This argument is passed to rlang::as_function() and thus supports quosure-style lambda functions and strings representing function names.", ".vars: A list of columns generated by vars(), a character vector of column names, a numeric vector of column positions, or NULL.", ".cols: This argument has been renamed to .vars to fit dplyr's terminology and is deprecated."]},
{"item_id": "group_by_all", "code": "group_by_all(   .tbl,   .funs = list(),   ...,   .add = FALSE,   .drop = group_by_drop_default(.tbl) )  group_by_at(   .tbl,   .vars,   .funs = list(),   ...,   .add = FALSE,   .drop = group_by_drop_default(.tbl) )  group_by_if(   .tbl,   .predicate,   .funs = list(),   ...,   .add = FALSE,   .drop = group_by_drop_default(.tbl) )", "description": "      Scoped verbs (_if, _at, _all) have been superseded by the use of across() in an existing verb. See vignette(\"colwise\") for details. These scoped variants of group_by() group a data frame by a selection of variables. Like group_by(), they have optional mutate semantics.     ", "parameters": [".tbl: A tbl object.", ".funs: A function fun, a quosure style lambda ~ fun(.) or a list of either form.", "...: Additional arguments for the function calls in .funs. These are evaluated only once, with tidy dots support.", ".add: See group_by()", ".drop: When .drop = TRUE, empty groups are dropped. See group_by_drop_default() for what the default value is for this argument.", ".vars: A list of columns generated by vars(), a character vector of column names, a numeric vector of column positions, or NULL.", ".predicate: A predicate function to be applied to the columns or a logical vector. The variables for which .predicate is or returns TRUE are selected. This argument is passed to rlang::as_function() and thus supports quosure-style lambda functions and strings representing function names."]},
{"item_id": "top_n", "code": "top_n(x, n, wt)  top_frac(x, n, wt)", "description": "       top_n() has been superseded in favour of slice_min()/slice_max(). While it will not be deprecated in the near future, retirement means that we will only perform critical bug fixes, so we recommend moving to the newer alternatives. top_n() was superseded because the name was fundamentally confusing as it returned what you might reasonably consider to be the bottom rows. Additionally, the wt variable had a confusing name, and strange default (the last column in the data frame). Unfortunately we could not see an easy way to fix the existing top_n() function without breaking existing code, so we created a new alternative.     ", "parameters": ["x: A data frame.", "n: Number of rows to return for top_n(), fraction of rows to return for top_frac(). If n is positive, selects the top rows. If negative, selects the bottom rows. If x is grouped, this is the number (or fraction) of rows per group. Will include more rows if there are ties.", "wt: (Optional). The variable to use for ordering. If not specified, defaults to the last variable in the tbl."]},
{"item_id": "filter_all", "code": "filter_all(.tbl, .vars_predicate, .preserve = FALSE)  filter_if(.tbl, .predicate, .vars_predicate, .preserve = FALSE)  filter_at(.tbl, .vars, .vars_predicate, .preserve = FALSE)", "description": "      Scoped verbs (_if, _at, _all) have been superseded by the use of across() in an existing verb. See vignette(\"colwise\") for details. These scoped filtering verbs apply a predicate expression to a selection of variables. The predicate expression should be quoted with all_vars() or any_vars() and should mention the pronoun . to refer to variables.     ", "parameters": [".tbl: A tbl object.", ".vars_predicate: A quoted predicate expression as returned by all_vars() or any_vars(). Can also be a function or purrr-like formula. In this case, the intersection of the results is taken by default and there's currently no way to request the union.", ".preserve: when FALSE (the default), the grouping structure is recalculated based on the resulting data, otherwise it is kept as is.", ".predicate: A predicate function to be applied to the columns or a logical vector. The variables for which .predicate is or returns TRUE are selected. This argument is passed to rlang::as_function() and thus supports quosure-style lambda functions and strings representing function names.", ".vars: A list of columns generated by vars(), a character vector of column names, a numeric vector of column positions, or NULL."]},
{"item_id": "distinct_all", "code": "distinct_all(.tbl, .funs = list(), ..., .keep_all = FALSE)  distinct_at(.tbl, .vars, .funs = list(), ..., .keep_all = FALSE)  distinct_if(.tbl, .predicate, .funs = list(), ..., .keep_all = FALSE)", "description": "      Scoped verbs (_if, _at, _all) have been superseded by the use of across() in an existing verb. See vignette(\"colwise\") for details. These scoped variants of distinct() extract distinct rows by a selection of variables. Like distinct(), you can modify the variables before ordering with the .funs argument.     ", "parameters": [".tbl: A tbl object.", ".funs: A function fun, a quosure style lambda ~ fun(.) or a list of either form.", "...: Additional arguments for the function calls in .funs. These are evaluated only once, with tidy dots support.", ".keep_all: If TRUE, keep all variables in .data. If a combination of ... is not distinct, this keeps the first row of values.", ".vars: A list of columns generated by vars(), a character vector of column names, a numeric vector of column positions, or NULL.", ".predicate: A predicate function to be applied to the columns or a logical vector. The variables for which .predicate is or returns TRUE are selected. This argument is passed to rlang::as_function() and thus supports quosure-style lambda functions and strings representing function names."]},
{"item_id": "arrange_all", "code": "arrange_all(.tbl, .funs = list(), ..., .by_group = FALSE)  arrange_at(.tbl, .vars, .funs = list(), ..., .by_group = FALSE)  arrange_if(.tbl, .predicate, .funs = list(), ..., .by_group = FALSE)", "description": "      Scoped verbs (_if, _at, _all) have been superseded by the use of across() in an existing verb. See vignette(\"colwise\") for details. These scoped variants of arrange() sort a data frame by a selection of variables. Like arrange(), you can modify the variables before ordering with the .funs argument.     ", "parameters": [".tbl: A tbl object.", ".funs: A function fun, a quosure style lambda ~ fun(.) or a list of either form.", "...: Additional arguments for the function calls in .funs. These are evaluated only once, with tidy dots support.", ".by_group: If TRUE, will sort first by grouping variable. Applies to grouped data frames only.", ".vars: A list of columns generated by vars(), a character vector of column names, a numeric vector of column positions, or NULL.", ".predicate: A predicate function to be applied to the columns or a logical vector. The variables for which .predicate is or returns TRUE are selected. This argument is passed to rlang::as_function() and thus supports quosure-style lambda functions and strings representing function names."]},
{"item_id": "recode", "code": "recode(.x, ..., .default = NULL, .missing = NULL)  recode_factor(.x, ..., .default = NULL, .missing = NULL, .ordered = FALSE)", "description": "     This is a vectorised version of switch(): you can replace numeric values based on their position or their name, and character or factor values only by their name. This is an S3 generic: dplyr provides methods for numeric, character, and factors. For logical vectors, use if_else(). For more complicated criteria, use case_when(). You can use recode() directly with factors; it will preserve the existing order of levels while changing the values. Alternatively, you can use recode_factor(), which will change the order of levels to match the order of replacements. See the forcats package for more tools for working with factors and their levels.   recode() is questioning because the arguments are in the wrong order. We have new &lt;- old, mutate(df, new = old), and rename(df, new = old) but recode(x, old = new). We don't yet know how to fix this problem, but it's likely to involve creating a new function then retiring or deprecating recode().     ", "parameters": [".x: A vector to modify", "...: &lt;dynamic-dots&gt; Replacements. For character and factor .x, these should be named and replacement is based only on their name. For numeric .x, these can be named or not. If not named, the replacement is done based on position i.e. .x represents positions to look for in replacements. See examples. When named, the argument names should be the current values to be replaced, and the argument values should be the new (replacement) values. All replacements must be the same type, and must have either length one or the same length as .x.", ".default: If supplied, all values not otherwise matched will be given this value. If not supplied and if the replacements are the same type as the original values in .x, unmatched values are not changed. If not supplied and if the replacements are not compatible, unmatched values are replaced with NA. .default must be either length 1 or the same length as .x.", ".missing: If supplied, any missing values in .x will be replaced by this value. Must be either length 1 or the same length as .x.", ".ordered: If TRUE, recode_factor() creates an ordered factor."]},
{"item_id": "ranking", "code": "row_number(x)  ntile(x = row_number(), n)  min_rank(x)  dense_rank(x)  percent_rank(x)  cume_dist(x)", "description": "     Six variations on ranking functions, mimicking the ranking functions described in SQL2003. They are currently implemented using the built in rank function, and are provided mainly as a convenience when converting between R and SQL. All ranking functions map smallest inputs to smallest outputs. Use desc() to reverse the direction.     ", "parameters": ["x: a vector of values to rank. Missing values are left as is. If you want to treat them as the smallest or largest values, replace with Inf or -Inf before ranking.", "n: number of groups to split up into."]},
{"item_id": "sample_n", "code": "sample_n(tbl, size, replace = FALSE, weight = NULL, .env = NULL, ...)  sample_frac(tbl, size = 1, replace = FALSE, weight = NULL, .env = NULL, ...)", "description": "       sample_n() and sample_frac() have been superseded in favour of slice_sample(). While they will not be deprecated in the near future, retirement means that we will only perform critical bug fixes, so we recommend moving to the newer alternative. These functions were superseded because we realised it was more convenient to have two mutually exclusive arguments to one function, rather than two separate functions. This also made it to clean up a few other smaller design issues with sample_n()/sample_frac: The connection to slice() was not obvious. The name of the first argument, tbl, is inconsistent with other single table verbs which use .data. The size argument uses tidy evaluation, which is surprising and undocumented. It was easier to remove the deprecated .env argument. ... was in a suboptimal position.       ", "parameters": ["tbl: A data.frame.", "size: &lt;tidy-select&gt; For sample_n(), the number of rows to select. For sample_frac(), the fraction of rows to select. If tbl is grouped, size applies to each group.", "replace: Sample with or without replacement?", "weight: &lt;tidy-select&gt; Sampling weights. This must evaluate to a vector of non-negative numbers the same length as the input. Weights are automatically standardised to sum to 1.", ".env: DEPRECATED.", "...: ignored"]},
{"item_id": "nth", "code": "nth(x, n, order_by = NULL, default = default_missing(x))  first(x, order_by = NULL, default = default_missing(x))  last(x, order_by = NULL, default = default_missing(x))", "description": "     These are straightforward wrappers around [[. The main advantage is that you can provide an optional secondary vector that defines the ordering, and provide a default value to use when the input is shorter than expected.     ", "parameters": ["x: A vector", "n: For nth_value(), a single integer specifying the position. Negative integers index from the end (i.e. -1L will return the last value in the vector). If a double is supplied, it will be silently truncated.", "order_by: An optional vector used to determine the order", "default: A default value to use if the position does not exist in the input. This is guessed by default for base vectors, where a missing value of the appropriate type is returned, and for lists, where a NULL is return. For more complicated objects, you'll need to supply this value. Make sure it is the same type as x."]},
{"item_id": "near", "code": "near(x, y, tol = .Machine$double.eps^0.5)", "description": "     This is a safe way of comparing if two vectors of floating point numbers are (pairwise) equal.  This is safer than using ==, because it has a built in tolerance     ", "parameters": ["x, y: Numeric vectors to compare", "tol: Tolerance of comparison."]},
{"item_id": "na_if", "code": "na_if(x, y)", "description": "     This is a translation of the SQL command NULLIF. It is useful if you want to convert an annoying value to NA.     ", "parameters": ["x: Vector to modify", "y: Value to replace with NA"]},
{"item_id": "n_distinct", "code": "n_distinct(..., na.rm = FALSE)", "description": "     This is a faster and more concise equivalent of length(unique(x))     ", "parameters": ["...: vectors of values", "na.rm: if TRUE missing values don't count"]},
{"item_id": "context", "code": "n()  cur_data()  cur_group()  cur_group_id()  cur_group_rows()  cur_column()", "description": "     These functions return information about the \"current\" group or \"current\" variable, so only work inside specific contexts like summarise() and mutate() n() gives the current group size. cur_data() gives the current data for the current group (exclusing grouping variables) cur_group() gives the group keys, a tibble with one row and one column for each grouping variable. cur_group_id() gives a unique numeric identifier for the current group. cur_column() gives the name of the current column (in across() only).   See group_data() for equivalent functions that return values for all groups.     ", "parameters": []},
{"item_id": "order_by", "code": "order_by(order_by, call)", "description": "     This function makes it possible to control the ordering of window functions in R that don't have a specific ordering parameter. When translated to SQL it will modify the order clause of the OVER function.     ", "parameters": ["order_by: a vector to order_by", "call: a function call to a window function, where the first argument is the vector being operated on"]},
{"item_id": "lead-lag", "code": "lag(x, n = 1L, default = NA, order_by = NULL, ...)  lead(x, n = 1L, default = NA, order_by = NULL, ...)", "description": "     Find the \"previous\" (lag()) or \"next\" (lead()) values in a vector. Useful for comparing values behind of or ahead of the current values.     ", "parameters": ["x: Vector of values", "n: Positive integer of length 1, giving the number of positions to lead or lag by", "default: Value used for non-existent rows. Defaults to NA.", "order_by: Override the default ordering to use another vector or column", "...: Needed for compatibility with lag generic."]},
{"item_id": "if_else", "code": "if_else(condition, true, false, missing = NULL)", "description": "     Compared to the base ifelse(), this function is more strict. It checks that true and false are the same type. This strictness makes the output type more predictable, and makes it somewhat faster.     ", "parameters": ["condition: Logical vector", "true, false: Values to use for TRUE and FALSE values of condition. They must be either the same length as condition, or length 1. They must also be the same type: if_else() checks that they have the same type and same class. All other attributes are taken from true.", "missing: If not NULL, will be used to replace missing values."]},
{"item_id": "desc", "code": "desc(x)", "description": "     Transform a vector into a format that will be sorted in descending order. This is useful within arrange().     ", "parameters": ["x: vector to transform"]},
{"item_id": "cumall", "code": "cumall(x)  cumany(x)  cummean(x)", "description": "     dplyr provides cumall(), cumany(), and cummean() to complete R's set of cumulative functions.     ", "parameters": ["x: For cumall() and cumany(), a logical vector; for cummean() an integer or numeric vector."]},
{"item_id": "case_when", "code": "case_when(...)", "description": "     This function allows you to vectorise multiple if_else() statements. It is an R equivalent of the SQL CASE WHEN statement. If no cases match, NA is returned.     ", "parameters": ["...: &lt;dynamic-dots&gt; A sequence of two-sided formulas. The left hand side (LHS) determines which values match this case. The right hand side (RHS) provides the replacement value. The LHS must evaluate to a logical vector. The RHS does not need to be logical, but all RHSs must evaluate to the same type of vector. Both LHS and RHS may have the same length of either 1 or n. The value of n must be consistent across all cases. The case of n == 0 is treated as a variant of n != 1. NULL inputs are ignored."]},
{"item_id": "between", "code": "between(x, left, right)", "description": "     This is a shortcut for x &gt;= left &amp; x &lt;= right, implemented efficiently in C++ for local values, and translated to the appropriate SQL for remote tables.     ", "parameters": ["x: A numeric vector of values", "left, right: Boundary values"]},
{"item_id": "across", "code": "across(.cols = everything(), .fns = NULL, ..., .names = NULL)  c_across(cols = everything())", "description": "     across() makes it easy to apply the same transformation to multiple columns, allowing you to use select() semantics inside in summarise() and mutate(). across() supersedes the family of \"scoped variants\" like summarise_at(), summarise_if(), and summarise_all(). See vignette(\"colwise\") for more details. c_across() is designed to work with rowwise() to make it easy to perform row-wise aggregations. It has two differences from c(): It uses tidy select semantics so you can easily select multiple variables. See vignette(\"rowwise\") for more details. It uses vctrs::vec_c() in order to give safer outputs.       ", "parameters": [".fns: Functions to apply to each of the selected columns. Possible values are: NULL, to returns the columns untransformed. A function, e.g. mean. A purrr-style lambda, e.g. ~ mean(.x, na.rm = TRUE) A list of functions/lambdas, e.g. list(mean = mean, n_miss = ~ sum(is.na(.x))   Within these functions you can use cur_column() and cur_group() to access the current column and grouping keys respectively.", "...: Additional arguments for the function calls in .fns.", ".names: A glue specification that describes how to name the output columns. This can use {col} to stand for the selected column name, and {fn} to stand for the name of the function being applied. The default (NULL) is equivalent to \"{col}\" for the single function case and \"{col}_{fn}\" for the case where a list is used for .fns.", "cols, .cols: &lt;tidy-select&gt; Columns to transform. Because across() is used within functions like summarise() and mutate(), you can't select or compute upon grouping variables."]},
{"item_id": "rowwise", "code": "rowwise(data, ...)", "description": "     rowwise() allows you to compute on a data frame a row-at-a-time. This is most useful when a vectorised function doesn't exist. Most dplyr verbs preserve row-wise grouping. The exception is summarise(), which return a grouped_df. You can explicitly ungroup with ungroup() or as_tibble(), or convert to a grouped_df with group_by().     ", "parameters": ["data: Input data frame.", "...: &lt;tidy-select&gt; Variables to be preserved when calling summarise(). This is typically a set of variables whose combination uniquely identify each row. NB: unlike group_by() you can not create new variables here but instead you can select multiple variables with (e.g.) everything()."]},
{"item_id": "coalesce", "code": "coalesce(...)", "description": "     Given a set of vectors, coalesce() finds the first non-missing value at each position. This is inspired by the SQL COALESCE function which does the same thing for NULLs.     ", "parameters": ["...: &lt;dynamic-dots&gt; Vectors. Inputs should be recyclable (either be length 1 or same length as the longest vector) and coercible to a common type."]},
{"item_id": "group_cols", "code": "group_cols(vars = NULL, data = NULL)", "description": "     This selection helpers matches grouping variables. It can be used in select() or vars() selections.     ", "parameters": ["vars: Deprecated; please use data instead.", "data: For advanced use only. The default NULL automatically finds the \"current\" data frames."]},
{"item_id": "group_by", "code": "group_by(.data, ..., .add = FALSE, .drop = group_by_drop_default(.data))  ungroup(x, ...)", "description": "     Most data operations are done on groups defined by variables. group_by() takes an existing tbl and converts it into a grouped tbl where operations are performed \"by group\". ungroup() removes grouping.     ", "parameters": [".data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "...: In group_by(), variables or computations to group by. In ungroup(), variables to remove from the grouping.", ".add: When FALSE, the default, group_by() will override existing groups. To add to the existing groups, use .add = TRUE. This argument was previously called add, but that prevented creating a new grouping variable called add, and conflicts with our naming conventions.", ".drop: When .drop = TRUE, empty groups are dropped. See group_by_drop_default() for what the default value is for this argument.", "x: A tbl()"]},
{"item_id": "filter-joins", "code": "semi_join(x, y, by = NULL, copy = FALSE, ...)  # S3 method for data.frame semi_join(x, y, by = NULL, copy = FALSE, ..., na_matches = c(\"na\", \"never\"))  anti_join(x, y, by = NULL, copy = FALSE, ...)  # S3 method for data.frame anti_join(x, y, by = NULL, copy = FALSE, ..., na_matches = c(\"na\", \"never\"))", "description": "     Filtering joins filter rows from x based on the presence or absence of matches in y: semi_join() return all rows from x with a match in y. anti_join() return all rows from x without a match in y.       ", "parameters": ["x, y: A pair of data frames, data frame extensions (e.g. a tibble), or lazy data frames (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "by: A character vector of variables to join by. If NULL, the default, *_join() will perform a natural join, using all variables in common across x and y. A message lists the variables so that you can check they're correct; suppress the message by supplying by explicitly. To join by different variables on x and y, use a named vector. For example, by = c(\"a\" = \"b\") will match x$a to y$b. To join by multiple variables, use a vector with length &gt; 1. For example, by = c(\"a\", \"b\") will match x$a to y$a and x$b to y$b. Use a named vector to match different variables in x and y. For example, by = c(\"a\" = \"b\", \"c\" = \"d\") will match x$a to y$b and x$c to y$d. To perform a cross-join, generating all combinations of x and y, use by = character().", "copy: If x and y are not from the same data source, and copy is TRUE, then y will be copied into the same src as x.  This allows you to join tables across srcs, but it is a potentially expensive operation so you must opt into it.", "...: Other parameters passed onto methods.", "na_matches: Should NA and NaN values match one another? The default, \"na\", treats two NA or NaN values as equal, like %in%, match(), merge(). Use \"never\" to always treat two NA or NaN values as different, like joins for database sources, similarly to merge(incomparables = FALSE)."]},
{"item_id": "nest_join", "code": "nest_join(x, y, by = NULL, copy = FALSE, keep = FALSE, name = NULL, ...)  # S3 method for data.frame nest_join(x, y, by = NULL, copy = FALSE, keep = FALSE, name = NULL, ...)", "description": "     nest_join() returns all rows and columns in x with a new nested-df column that contains all matches from y. When there is no match, the list column is a 0-row tibble.     ", "parameters": ["x, y: A pair of data frames, data frame extensions (e.g. a tibble), or lazy data frames (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "by: A character vector of variables to join by. If NULL, the default, *_join() will perform a natural join, using all variables in common across x and y. A message lists the variables so that you can check they're correct; suppress the message by supplying by explicitly. To join by different variables on x and y, use a named vector. For example, by = c(\"a\" = \"b\") will match x$a to y$b. To join by multiple variables, use a vector with length &gt; 1. For example, by = c(\"a\", \"b\") will match x$a to y$a and x$b to y$b. Use a named vector to match different variables in x and y. For example, by = c(\"a\" = \"b\", \"c\" = \"d\") will match x$a to y$b and x$c to y$d. To perform a cross-join, generating all combinations of x and y, use by = character().", "copy: If x and y are not from the same data source, and copy is TRUE, then y will be copied into the same src as x.  This allows you to join tables across srcs, but it is a potentially expensive operation so you must opt into it.", "keep: Should the join keys from both x and y be preserved in the output? Only applies to nest_join(), left_join(), right_join(), and full_join().", "name: The name of the list column nesting joins create. If NULL the name of y is used.", "...: Other parameters passed onto methods."]},
{"item_id": "mutate-joins", "code": "inner_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ...)  # S3 method for data.frame inner_join(   x,   y,   by = NULL,   copy = FALSE,   suffix = c(\".x\", \".y\"),   ...,   na_matches = c(\"na\", \"never\") )  left_join(   x,   y,   by = NULL,   copy = FALSE,   suffix = c(\".x\", \".y\"),   ...,   keep = FALSE )  # S3 method for data.frame left_join(   x,   y,   by = NULL,   copy = FALSE,   suffix = c(\".x\", \".y\"),   ...,   keep = FALSE,   na_matches = c(\"na\", \"never\") )  right_join(   x,   y,   by = NULL,   copy = FALSE,   suffix = c(\".x\", \".y\"),   ...,   keep = FALSE )  # S3 method for data.frame right_join(   x,   y,   by = NULL,   copy = FALSE,   suffix = c(\".x\", \".y\"),   ...,   keep = FALSE,   na_matches = c(\"na\", \"never\") )  full_join(   x,   y,   by = NULL,   copy = FALSE,   suffix = c(\".x\", \".y\"),   ...,   keep = FALSE )  # S3 method for data.frame full_join(   x,   y,   by = NULL,   copy = FALSE,   suffix = c(\".x\", \".y\"),   ...,   keep = FALSE,   na_matches = c(\"na\", \"never\") )", "description": "     The mutating joins add columns from y to x, matching rows based on the keys: inner_join(): includes all rows in x and y. left_join(): includes all rows in x. right_join(): includes all rows in y. full_join(): includes all rows in x or y.   If a row in x matches multiple rows in y, all the rows in y will be returned once for each matching row in x.     ", "parameters": ["x, y: A pair of data frames, data frame extensions (e.g. a tibble), or lazy data frames (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "by: A character vector of variables to join by. If NULL, the default, *_join() will perform a natural join, using all variables in common across x and y. A message lists the variables so that you can check they're correct; suppress the message by supplying by explicitly. To join by different variables on x and y, use a named vector. For example, by = c(\"a\" = \"b\") will match x$a to y$b. To join by multiple variables, use a vector with length &gt; 1. For example, by = c(\"a\", \"b\") will match x$a to y$a and x$b to y$b. Use a named vector to match different variables in x and y. For example, by = c(\"a\" = \"b\", \"c\" = \"d\") will match x$a to y$b and x$c to y$d. To perform a cross-join, generating all combinations of x and y, use by = character().", "copy: If x and y are not from the same data source, and copy is TRUE, then y will be copied into the same src as x.  This allows you to join tables across srcs, but it is a potentially expensive operation so you must opt into it.", "suffix: If there are non-joined duplicate variables in x and y, these suffixes will be added to the output to disambiguate them. Should be a character vector of length 2.", "...: Other parameters passed onto methods.", "na_matches: Should NA and NaN values match one another? The default, \"na\", treats two NA or NaN values as equal, like %in%, match(), merge(). Use \"never\" to always treat two NA or NaN values as different, like joins for database sources, similarly to merge(incomparables = FALSE).", "keep: Should the join keys from both x and y be preserved in the output? Only applies to nest_join(), left_join(), right_join(), and full_join()."]},
{"item_id": "bind", "code": "bind_rows(..., .id = NULL)  bind_cols(...)", "description": "     This is an efficient implementation of the common pattern of do.call(rbind, dfs) or do.call(cbind, dfs) for binding many data frames into one.     ", "parameters": ["...: Data frames to combine. Each argument can either be a data frame, a list that could be a data frame, or a list of data frames. When row-binding, columns are matched by name, and any missing columns will be filled with NA. When column-binding, rows are matched by position, so all data frames must have the same number of rows. To match by value, not position, see mutate-joins.", ".id: Data frame identifier. When .id is supplied, a new column of identifiers is created to link each row to its original data frame. The labels are taken from the named arguments to bind_rows(). When a list of data frames is supplied, the labels are taken from the names of the list. If no names are found a numeric sequence is used instead."]},
{"item_id": "slice", "code": "slice(.data, ..., .preserve = FALSE)  slice_head(.data, ..., n, prop)  slice_tail(.data, ..., n, prop)  slice_min(.data, order_by, ..., n, prop, with_ties = TRUE)  slice_max(.data, order_by, ..., n, prop, with_ties = TRUE)  slice_sample(.data, ..., n, prop, weight_by = NULL, replace = FALSE)", "description": "     slice() lets you index rows by their (integer) locations. It allows you to select, remove, and duplicate rows. It is accompanied by a number of helpers for common use cases: slice_head() and slice_tail() select the first or last rows. slice_sample() randomly selects rows. slice_min() and slice_max() select rows with highest or lowest values of a variable.   If .data is a grouped_df, the operation will be performed on each group, so that (e.g.) slice_head(df, n = 5) will select the first five rows in each group.     ", "parameters": [".data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "...: For slice(): &lt;data-masking&gt; Integer row values. Provide either positive values to keep, or negative values to drop. The values provided must be either all positive or all negative. Indices beyond the number of rows in the input are silently ignored. For slice_helpers(), these arguments are passed on to methods.", ".preserve: Relevant when the .data input is grouped. If .preserve = FALSE (the default), the grouping structure is recalculated based on the resulting data, otherwise the grouping is kept as is.", "n, prop: Provide either n, the number of rows, or prop, the proportion of rows to select. If neither are supplied, n = 1 will be used. If n is greater than the number of rows in the group (or prop &gt; 1), the result will be silently truncated to the group size. If the proportion of a group size is not an integer, it is rounded down.", "order_by: Variable or function of variables to order by.", "with_ties: Should ties be kept together? The default, TRUE, may return more rows than you request. Use FALSE to ignore ties, and return the first n rows.", "weight_by: Sampling weights. This must evaluate to a vector of non-negative numbers the same length as the input. Weights are automatically standardised to sum to 1.", "replace: Should sampling be performed with (TRUE) or without (FALSE, the default) replacement."]},
{"item_id": "select", "code": "select(.data, ...)", "description": "     Select (and optionally rename) variables in a data frame, using a concise mini-language that makes it easy to refer to variables based on their name (e.g. a:f selects all columns from a on the left to f on the right). You can also use predicate functions like is.numeric to select variables based on their properties.Overview of selection features   Tidyverse selections implement a dialect of R where operators make it easy to select variables: : for selecting a range of consecutive variables. ! for taking the complement of a set of variables. &amp; and | for selecting the intersection or the union of two sets of variables. c() for combining selections.   In addition, you can use selection helpers. Some helpers select specific columns: everything(): Matches all variables. last_col(): Select last variable, possibly with an offset.   These helpers select variables by matching patterns in their names: starts_with(): Starts with a prefix. ends_with(): Ends with a suffix. contains(): Contains a literal string. matches(): Matches a regular expression. num_range(): Matches a numerical range like x01, x02, x03.   These helpers select variables from a character vector: all_of(): Matches variable names in a character vector. All names must be present, otherwise an out-of-bounds error is thrown. any_of(): Same as all_of(), except that no error is thrown for names that don't exist.   This helper selects variables with a function: where(): Applies a function to all variables and selects those for which the function returns TRUE.        ", "parameters": [".data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "...: &lt;tidy-select&gt; One or more unquoted expressions separated by commas. Variable names can be used as if they were positions in the data frame, so expressions like x:y can be used to select a range of variables."]},
{"item_id": "summarise", "code": "summarise(.data, ..., .groups = NULL)  summarize(.data, ..., .groups = NULL)", "description": "     summarise() creates a new data frame. It will have one (or more) rows for each combination of grouping variables; if there are no grouping variables, the output will have a single row summarising all observations in the input. It will contain one column for each grouping variable and one column for each of the summary statistics that you have specified. summarise() and summarize() are synonyms.     ", "parameters": [".data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "...: &lt;data-masking&gt; Name-value pairs of summary functions. The name will be the name of the variable in the result. The value can be: A vector of length 1, e.g. min(x), n(), or sum(is.na(y)). A vector of length n, e.g. quantile(). A data frame, to add multiple columns from a single expression. ", ".groups:   Grouping structure of the result. \"drop_last\": dropping the last level of grouping. This was the only supported option before version 1.0.0. \"drop\": All levels of grouping are dropped. \"keep\": Same grouping structure as .data. \"rowwise\": Each row is it's own group.   When .groups is not specified, you either get \"drop_last\" when all the results are size 1, or \"keep\" if the size varies. In addition, a message informs you of that choice, unless the option \"dplyr.summarise.inform\" is set to FALSE."]},
{"item_id": "rename", "code": "rename(.data, ...)  rename_with(.data, .fn, .cols = everything(), ...)", "description": "     rename() changes the names of individual variables using new_name = old_name syntax; rename_with() renames columns using a function.     ", "parameters": [".data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "...: For rename(): &lt;tidy-select&gt; Use new_name = old_name to rename selected variables. For rename_with(): additional arguments passed onto .fn.", ".fn: A function used to transform the selected .cols. Should return a character vector the same length as the input.", ".cols: &lt;tidy-select&gt; Columns to rename; defaults to all columns."]},
{"item_id": "relocate", "code": "relocate(.data, ..., .before = NULL, .after = NULL)", "description": "     Use relocate() to change column positions, using the same syntax as select() to make it easy to move blocks of columns at once.     ", "parameters": [".data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "...: &lt;tidy-select&gt; Columns to move.", ".before, .after: &lt;tidy-select&gt; Destination of columns selected by .... Supplying neither will move columns to the left-hand side; specifying both is an error."]},
{"item_id": "pull", "code": "pull(.data, var = -1, name = NULL, ...)", "description": "     pull() is similar to $. It's mostly useful because it looks a little nicer in pipes, it also works with remote data frames, and it can optionally name the output.     ", "parameters": [".data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "var: A variable specified as: a literal variable name a positive integer, giving the position counting from the left a negative integer, giving the position counting from the right.   The default returns the last column (on the assumption that's the column you've created most recently). This argument is taken by expression and supports quasiquotation (you can unquote column names and column locations).", "name: An optional parameter that specifies the column to be used as names for a named vector. Specified in a similar manner as var.", "...: For use by methods."]},
{"item_id": "mutate", "code": "mutate(.data, ...)  # S3 method for data.frame mutate(   .data,   ...,   .keep = c(\"all\", \"used\", \"unused\", \"none\"),   .before = NULL,   .after = NULL )  transmute(.data, ...)", "description": "     mutate() adds new variables and preserves existing ones; transmute() adds new variables and drops existing ones. New variables overwrite existing variables of the same name. Variables can be removed by setting their value to NULL.     ", "parameters": [".data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "...: &lt;data-masking&gt; Name-value pairs. The name gives the name of the column in the output. The value can be: A vector of length 1, which will be recycled to the correct length. A vector the same length as the current group (or the whole data frame if ungrouped). NULL, to remove the column. A data frame or tibble, to create multiple columns in the output. ", ".keep:   This is an experimental argument that allows you to control which columns from .data are retained in the output: \"all\", the default, retains all variables. \"used\" keeps any variables used to make new variables; it's useful for checking your work as it displays inputs and outputs side-by-side. \"unused\" keeps only existing variables not used to make new variables. \"none\", only keeps grouping keys (like transmute()). ", ".before, .after:   &lt;tidy-select&gt; Optionally, control where new columns should appear (the default is to add to the right hand side). See relocate() for more details."]},
{"item_id": "filter", "code": "filter(.data, ..., .preserve = FALSE)", "description": "     The filter() function is used to subset a data frame, retaining all rows that satisfy your conditions. To be retained, the row must produce a value of TRUE for all conditions. Note that when a condition evaluates to NA the row will be dropped, unlike base subsetting with [.     ", "parameters": [".data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "...: &lt;data-masking&gt; Expressions that return a logical value, and are defined in terms of the variables in .data. If multiple expressions are included, they are combined with the &amp; operator. Only rows for which all conditions evaluate to TRUE are kept.", ".preserve: Relevant when the .data input is grouped. If .preserve = FALSE (the default), the grouping structure is recalculated based on the resulting data, otherwise the grouping is kept as is."]},
{"item_id": "distinct", "code": "distinct(.data, ..., .keep_all = FALSE)", "description": "     Select only unique/distinct rows from a data frame. This is similar to unique.data.frame() but considerably faster.     ", "parameters": [".data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "...: &lt;data-masking&gt; Optional variables to use when determining uniqueness. If there are multiple rows for a given combination of inputs, only the first row will be preserved. If omitted, will use all variables.", ".keep_all: If TRUE, keep all variables in .data. If a combination of ... is not distinct, this keeps the first row of values."]},
{"item_id": "arrange", "code": "arrange(.data, ..., .by_group = FALSE)  # S3 method for data.frame arrange(.data, ..., .by_group = FALSE)", "description": "     arrange() order the rows of a data frame rows by the values of selected columns. Unlike other dplyr verbs, arrange() largely ignores grouping; you need to explicit mention grouping variables (or use  by_group = TRUE) in order to group by them, and functions of variables are evaluated once per data frame, not once per group.     ", "parameters": [".data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See Methods, below, for more details.", "...: &lt;data-masking&gt; Variables, or functions or variables. Use desc() to sort a variable in descending order.", ".by_group: If TRUE, will sort first by grouping variable. Applies to grouped data frames only."]},
{"item_id": "count", "code": "count(   x,   ...,   wt = NULL,   sort = FALSE,   name = NULL,   .drop = group_by_drop_default(x) )  tally(x, wt = NULL, sort = FALSE, name = NULL)  add_count(x, ..., wt = NULL, sort = FALSE, name = NULL, .drop = deprecated())  add_tally(x, wt = NULL, sort = FALSE, name = NULL)", "description": "     count() lets you quickly count the unique values of one or more variables: df %&gt;% count(a, b) is roughly equivalent to df %&gt;% group_by(a, b) %&gt;% summarise(n = n()). count() is paired with tally(), a lower-level helper that is equivalent to df %&gt;% summarise(n = n()). Supply wt to perform weighted counts, switching the summary from from n = n() to n = sum(wt). add_count() are add_tally() are equivalents to count() and tally() but use mutate() instead of summarise() so that they add a new column with group-wise counts.     ", "parameters": ["x: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr).", "...: &lt;data-masking&gt; Variables to group by.", "wt: &lt;data-masking&gt; Frequency weights. Can be a variable (or combination of variables) or NULL. wt is computed once for each unique combination of the counted variables. If a variable, count() will compute sum(wt) for each unique combination. If NULL, the default, the computation depends on whether a column of frequency counts n exists in the data frame. If it exists, the counts are computed with sum(n) for each unique combination. Otherwise, n() is used to compute the counts. Supply wt = n() to force this behaviour even if you have an n column in the data frame. ", "sort: If TRUE, will show the largest groups at the top.", "name: The name of the new column in the output. If omitted, it will default to n. If there's already a column called n, it will error, and require you to specify the name.", ".drop: For count(): if FALSE will include counts for empty groups (i.e. for levels of factors that don't exist in the data). Deprecated in add_count() since it didn't actually affect the output."]}
]