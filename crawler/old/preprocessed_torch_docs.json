[{"code": "torchvision.utils.make_grid(tensor,nrow=8,padding=2,normalize=False,range=None,scale_each=False,pad_value=0)", "id": "torchvision.utils.make_grid", "summary": "Make a grid of images.\n\nParameters\n\ntensor (Tensor or list) \u2013 4D mini-batch Tensor of shape (B x C x H x W)\nor a list of images all of the same size.\nnrow (python:int, optional) \u2013 Number of images displayed in each row of the grid.\nThe final grid size is (B / nrow, nrow)", "description": "", "code-info": {"name": "torchvision.utils.make_grid", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor or list) \u2013 4D mini-batch Tensor of shape (B x C x H x W)\nor a list of images all of the same size."}, {"name": "nrow", "is_optional": true, "type": "int", "default_value": "8", "description": "(python:int, optional) \u2013 Number of images displayed in each row of the grid.\nThe final grid size is (B / nrow, nrow). Default: 8."}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "2", "description": "(python:int, optional) \u2013 amount of padding. Default: 2."}, {"name": "normalize", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If True, shift the image to the range (0, 1),\nby the min and max values specified by range. Default: False."}, {"name": "range", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 tuple (min, max) where min and max are numbers,\nthen these numbers are used to normalize the image. By default, min and max\nare computed from the tensor."}, {"name": "scale_each", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If True, scale each image in the batch of\nimages separately rather than the (min, max) over all images. Default: False."}, {"name": "pad_value", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float, optional) \u2013 Value for the padded pixels. Default: 0."}]}},
{"code": "torchvision.utils.save_image(tensor,fp,nrow=8,padding=2,normalize=False,range=None,scale_each=False,pad_value=0,format=None)", "id": "torchvision.utils.save_image", "summary": "Save a given Tensor into an image file.\n\nParameters\n\ntensor (Tensor or list) \u2013 Image to be saved", "description": "", "code-info": {"name": "torchvision.utils.save_image", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "fp", "is_optional": false, "type": "others", "description": ""}, {"name": "nrow", "is_optional": true, "type": "int", "default_value": "8", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "2", "description": ""}, {"name": "normalize", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "range", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "scale_each", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "pad_value", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "format", "is_optional": true, "type": "others", "default_value": "None", "description": "(Optional) \u2013 If omitted, the format to use is determined from the filename extension.\nIf a file object was used instead of a filename, this parameter should always be used.\n**kwargs \u2013 Other arguments are documented in make_grid."}]}},
{"code": "torchvision.get_image_backend()", "id": "torchvision.get_image_backend", "summary": "Gets the name of the package used to load images\n", "description": "", "code-info": {"name": "torchvision.get_image_backend", "parameters": []}},
{"code": "torchvision.set_image_backend(backend)", "id": "torchvision.set_image_backend", "summary": "Specifies the package used to load images.\n\nParameters\nbackend (string) \u2013 Name of the image backend", "description": "", "code-info": {"name": "torchvision.set_image_backend", "parameters": [{"name": "backend", "is_optional": false, "type": "string", "description": "(string) \u2013 Name of the image backend. one of {\u2018PIL\u2019, \u2018accimage\u2019}.\nThe accimage package uses the Intel IPP library. It is\ngenerally faster than PIL, but does not support as many operations."}]}},
{"code": "torchvision.set_video_backend(backend)", "id": "torchvision.set_video_backend", "summary": "Specifies the package used to decode videos.\n\nParameters\nbackend (string) \u2013 Name of the video backend", "description": "", "code-info": {"name": "torchvision.set_video_backend", "parameters": [{"name": "backend", "is_optional": false, "type": "string", "description": "(string) \u2013 Name of the video backend. one of {\u2018pyav\u2019, \u2018video_reader\u2019}.\nThe pyav package uses the 3rd party PyAv library. It is a Pythonic"}]}},
{"code": "torchvision.io.read_video(filename,start_pts=0,end_pts=None,pts_unit='pts')", "id": "torchvision.io.read_video", "summary": "Reads a video from a file, returning both the video frames as well as\nthe audio frames\n\nParameters\n\nfilename (str) \u2013 path to the video file\nstart_pts (python:int if pts_unit = 'pts', optional) \u2013 float / Fraction if pts_unit = \u2018sec\u2019, optional\nthe start presentation time of the video\nend_pts (python:int if pts_unit = 'pts', optional) \u2013 float / Fraction if pts_unit = \u2018sec\u2019, optional\nthe end presentation time\npts_unit (str, optional) \u2013 unit in which start_pts and end_pts values will be interpreted, either \u2018pts\u2019 or \u2018sec\u2019", "description": "", "code-info": {"name": "torchvision.io.read_video", "parameters": [{"name": "filename", "is_optional": false, "type": "others", "description": "(str) \u2013 path to the video file"}, {"name": "start_pts", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int if pts_unit = 'pts', optional) \u2013 float / Fraction if pts_unit = \u2018sec\u2019, optional\nthe start presentation time of the video"}, {"name": "end_pts", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int if pts_unit = 'pts', optional) \u2013 float / Fraction if pts_unit = \u2018sec\u2019, optional\nthe end presentation time"}, {"name": "pts_unit", "is_optional": true, "type": "string", "default_value": "'pts'", "description": "(str, optional) \u2013 unit in which start_pts and end_pts values will be interpreted, either \u2018pts\u2019 or \u2018sec\u2019. Defaults to \u2018pts\u2019."}]}},
{"code": "torchvision.io.read_video_timestamps(filename,pts_unit='pts')", "id": "torchvision.io.read_video_timestamps", "summary": "List the video frames timestamps.\nNote that the function decodes the whole video frame-by-frame.\n\nParameters\n\nfilename (str) \u2013 path to the video file\npts_unit (str, optional) \u2013 unit in which timestamp values will be returned either \u2018pts\u2019 or \u2018sec\u2019", "description": "", "code-info": {"name": "torchvision.io.read_video_timestamps", "parameters": [{"name": "filename", "is_optional": false, "type": "others", "description": "(str) \u2013 path to the video file"}, {"name": "pts_unit", "is_optional": true, "type": "string", "default_value": "'pts'", "description": "(str, optional) \u2013 unit in which timestamp values will be returned either \u2018pts\u2019 or \u2018sec\u2019. Defaults to \u2018pts\u2019."}]}},
{"code": "torchvision.io.write_video(filename,video_array,fps,video_codec='libx264',options=None)", "id": "torchvision.io.write_video", "summary": "Writes a 4d tensor in [T, H, W, C] format in a video file\n\nParameters\n\nfilename (str) \u2013 path where the video will be saved\nvideo_array (Tensor[T, H, W, C]) \u2013 tensor containing the individual frames, as a uint8 tensor in [T, H, W, C] format\nfps (Number) \u2013 frames per second\n\n\n\n", "description": "", "code-info": {"name": "torchvision.io.write_video", "parameters": [{"name": "filename", "is_optional": false, "type": "others", "description": "(str) \u2013 path where the video will be saved"}, {"name": "video_array", "is_optional": false, "type": "tensor", "description": "(Tensor[T, H, W, C]) \u2013 tensor containing the individual frames, as a uint8 tensor in [T, H, W, C] format"}, {"name": "fps", "is_optional": false, "type": "others", "description": ""}, {"name": "video_codec", "is_optional": true, "type": "string", "default_value": "'libx264'", "description": ""}, {"name": "options", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.rename(*names,**rename_map)", "id": "torch.Tensor.rename", "summary": "Renames dimension names of self.\nThere are two main usages:\nself.rename(**rename_map) returns a view on tensor that has dims\nrenamed as specified in the mapping rename_map.\nself.rename(*names) returns a view on tensor, renaming all\ndimensions positionally using names.\nUse self.rename(None) to drop names on a tensor.\nOne cannot specify both positional args names and keyword args\nrename_map.\nExamples:\n&gt;&gt;&gt; imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n&gt;&gt;&gt; renamed_imgs = imgs.rename(N='batch', C='channels')\n&gt;&gt;&gt; renamed_imgs.names\n('batch', 'channels', 'H', 'W')\n\n&gt;&gt;&gt; renamed_imgs = imgs.rename(None)\n&gt;&gt;&gt; renamed_imgs.names\n(None,)\n\n&gt;&gt;&gt; renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n&gt;&gt;&gt; renamed_imgs.names\n('batch', 'channel', 'height', 'width')\n\n\n\nWarning\nThe named tensor API is experimental and subject to change.\n\n", "description": "", "code-info": {"name": "torch.Tensor.rename", "parameters": [{"name": "*names", "is_optional": false, "type": "others", "description": ""}, {"name": "**rename_map", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.transforms.functional.adjust_brightness(img,brightness_factor)", "id": "torchvision.transforms.functional.adjust_brightness", "summary": "Adjust brightness of an Image.\n\nParameters\n\nimg (PIL Image) \u2013 PIL Image to be adjusted.\nbrightness_factor (python:float) \u2013 How much to adjust the brightness", "description": "", "code-info": {"name": "torchvision.transforms.functional.adjust_brightness", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 PIL Image to be adjusted."}, {"name": "brightness_factor", "is_optional": false, "type": "float", "description": "(python:float) \u2013 How much to adjust the brightness. Can be\nany non negative number. 0 gives a black image, 1 gives the\noriginal image while 2 increases the brightness by a factor of 2."}]}},
{"code": "torch.Tensor.rename_(*names,**rename_map)", "id": "torch.Tensor.rename_", "summary": "In-place version of rename().\n", "description": "", "code-info": {"name": "torch.Tensor.rename_", "parameters": [{"name": "*names", "is_optional": false, "type": "others", "description": ""}, {"name": "**rename_map", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.refine_names(*names)", "id": "torch.Tensor.refine_names", "summary": "Refines the dimension names of self according to names.\nRefining is a special case of renaming that \u201clifts\u201d unnamed dimensions.\nA None dim can be refined to have any name; a named dim can only be\nrefined to have the same name.\nBecause named tensors can coexist with unnamed tensors, refining names\ngives a nice way to write named-tensor-aware code that works with both\nnamed and unnamed tensors.\nnames may contain up to one Ellipsis (...).\nThe Ellipsis is expanded greedily; it is expanded in-place to fill\nnames to the same length as self.dim() using names from the\ncorresponding indices of self.names.\nPython 2 does not support Ellipsis but one may use a string literal\ninstead ('...').\n\nParameters\nnames (iterable of str) \u2013 The desired names of the output tensor", "description": "", "code-info": {"name": "torch.Tensor.refine_names", "parameters": [{"name": "*names", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.align_as(other)", "id": "torch.Tensor.align_as", "summary": "Permutes the dimensions of the self tensor to match the dimension order\nin the other tensor, adding size-one dims for any new names.\nThis operation is useful for explicit broadcasting by names (see examples).\nAll of the dims of self must be named in order to use this method.\nThe resulting tensor is a view on the original tensor.\nAll dimension names of self must be present in other.names.\nother may contain named dimensions that are not in self.names;\nthe output tensor has a size-one dimension for each of those new names.\nTo align a tensor to a specific order, use align_to().\nExamples:\n# Example 1: Applying a mask\n&gt;&gt;&gt; mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n&gt;&gt;&gt; imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n&gt;&gt;&gt; imgs.masked_fill_(mask.align_as(imgs), 0)\n\n\n# Example 2: Applying a per-channel-scale\ndef scale_channels(input, scale):\n    scale = scale.refine_names('C')\n    return input * scale.align_as(input)\n\n&gt;&gt;&gt; num_channels = 3\n&gt;&gt;&gt; scale = torch.randn(num_channels, names=('C',))\n&gt;&gt;&gt; imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n&gt;&gt;&gt; more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n&gt;&gt;&gt; videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n\n# scale_channels is agnostic to the dimension order of the input\n&gt;&gt;&gt; scale_channels(imgs, scale)\n&gt;&gt;&gt; scale_channels(more_imgs, scale)\n&gt;&gt;&gt; scale_channels(videos, scale)\n\n\n\nWarning\nThe named tensor API is experimental and subject to change.\n\n", "description": "", "code-info": {"name": "torch.Tensor.align_as", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.align_to(*names)", "id": "torch.Tensor.align_to", "summary": "Permutes the dimensions of the self tensor to match the order\nspecified in names, adding size-one dims for any new names.\nAll of the dims of self must be named in order to use this method.\nThe resulting tensor is a view on the original tensor.\nAll dimension names of self must be present in names.\nnames may contain additional names that are not in self.names;\nthe output tensor has a size-one dimension for each of those new names.\nnames may contain up to one Ellipsis (...).\nThe Ellipsis is expanded to be equal to all dimension names of self\nthat are not mentioned in names, in the order that they appear\nin self.\nPython 2 does not support Ellipsis but one may use a string literal\ninstead ('...').\n\nParameters\nnames (iterable of str) \u2013 The desired dimension ordering of the\noutput tensor", "description": "", "code-info": {"name": "torch.Tensor.align_to", "parameters": [{"name": "*names", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.unflatten(dim,namedshape)", "id": "torch.Tensor.unflatten", "summary": "Unflattens the named dimension dim, viewing it in the shape\nspecified by namedshape.\n\nParameters\nnamedshape \u2013 (iterable of (name, size) tuples).\n\n\nExamples:\n&gt;&gt;&gt; flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features'))\n&gt;&gt;&gt; imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128)))\n&gt;&gt;&gt; imgs.names, images.shape\n(('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128]))\n\n\n\nWarning\nThe named tensor API is experimental and subject to change.\n\n", "description": "", "code-info": {"name": "torch.Tensor.unflatten", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "namedshape", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-name descname(dims,out_dim)", "id": "sig-name descname", "summary": "Flattens dims into a single dimension with name out_dim.\nAll of dims must be consecutive in order in the self tensor,\nbut not necessary contiguous in memory.\nExamples:\n&gt;&gt;&gt; imgs = torch.randn(32, 3, 128, 128, names=('N', 'C', 'H', 'W'))\n&gt;&gt;&gt; flat_imgs = imgs.flatten(['C', 'H', 'W'], 'features')\n&gt;&gt;&gt; flat_imgs.names, flat_imgs.shape\n(('N', 'features'), torch.Size([32, 49152]))\n\n\n\nWarning\nThe named tensor API is experimental and subject to change.\n\n", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "dims", "is_optional": false, "type": "others", "description": ""}, {"name": "out_dim", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.ops.nms(boxes,scores,iou_threshold)", "id": "torchvision.ops.nms", "summary": "Performs non-maximum suppression (NMS) on the boxes according\nto their intersection-over-union (IoU).\nNMS iteratively removes lower scoring boxes which have an\nIoU greater than iou_threshold with another (higher scoring)\nbox.\n\nParameters\n\nboxes (Tensor[N, 4])) \u2013 boxes to perform NMS on", "description": "", "code-info": {"name": "torchvision.ops.nms", "parameters": [{"name": "boxes", "is_optional": false, "type": "tensor", "description": "(Tensor[N, 4])) \u2013 boxes to perform NMS on. They\nare expected to be in (x1, y1, x2, y2) format"}, {"name": "scores", "is_optional": false, "type": "tensor", "description": "(Tensor[N]) \u2013 scores for each one of the boxes"}, {"name": "iou_threshold", "is_optional": false, "type": "float", "description": "(python:float) \u2013 discards all overlapping\nboxes with IoU &gt; iou_threshold"}]}},
{"code": "torchvision.ops.roi_align(input,boxes,output_size,spatial_scale=1.0,sampling_ratio=-1)", "id": "torchvision.ops.roi_align", "summary": "Performs Region of Interest (RoI) Align operator described in Mask R-CNN\n\nParameters\n\ninput (Tensor[N, C, H, W]) \u2013 input tensor\nboxes (Tensor[K, 5] or List[Tensor[L, 4]]) \u2013 the box coordinates in (x1, y1, x2, y2)\nformat where the regions will be taken from", "description": "", "code-info": {"name": "torchvision.ops.roi_align", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor[N, C, H, W]) \u2013 input tensor"}, {"name": "boxes", "is_optional": false, "type": "tensor", "description": "(Tensor[K, 5] or List[Tensor[L, 4]]) \u2013 the box coordinates in (x1, y1, x2, y2)\nformat where the regions will be taken from. If a single Tensor is passed,\nthen the first column should contain the batch index. If a list of Tensors\nis passed, then each Tensor will correspond to the boxes for an element i\nin a batch"}, {"name": "output_size", "is_optional": false, "type": "int", "description": "(python:int or Tuple[python:int, python:int]) \u2013 the size of the output after the cropping\nis performed, as (height, width)"}, {"name": "spatial_scale", "is_optional": true, "type": "float", "default_value": "1.0", "description": "(python:float) \u2013 a scaling factor that maps the input coordinates to\nthe box coordinates. Default: 1.0"}, {"name": "sampling_ratio", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 number of sampling points in the interpolation grid\nused to compute the output value of each pooled output bin. If &gt; 0,\nthen exactly sampling_ratio x sampling_ratio grid points are used. If\n&lt;= 0, then an adaptive number of grid points are used (computed as\nceil(roi_width / pooled_w), and likewise for height). Default: -1"}]}},
{"code": "torchvision.ops.roi_pool(input,boxes,output_size,spatial_scale=1.0)", "id": "torchvision.ops.roi_pool", "summary": "Performs Region of Interest (RoI) Pool operator described in Fast R-CNN\n\nParameters\n\ninput (Tensor[N, C, H, W]) \u2013 input tensor\nboxes (Tensor[K, 5] or List[Tensor[L, 4]]) \u2013 the box coordinates in (x1, y1, x2, y2)\nformat where the regions will be taken from", "description": "", "code-info": {"name": "torchvision.ops.roi_pool", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor[N, C, H, W]) \u2013 input tensor"}, {"name": "boxes", "is_optional": false, "type": "tensor", "description": "(Tensor[K, 5] or List[Tensor[L, 4]]) \u2013 the box coordinates in (x1, y1, x2, y2)\nformat where the regions will be taken from. If a single Tensor is passed,\nthen the first column should contain the batch index. If a list of Tensors\nis passed, then each Tensor will correspond to the boxes for an element i\nin a batch"}, {"name": "output_size", "is_optional": false, "type": "int", "description": "(python:int or Tuple[python:int, python:int]) \u2013 the size of the output after the cropping\nis performed, as (height, width)"}, {"name": "spatial_scale", "is_optional": true, "type": "float", "default_value": "1.0", "description": "(python:float) \u2013 a scaling factor that maps the input coordinates to\nthe box coordinates. Default: 1.0"}]}},
{"code": "torchvision.ops.RoIAlign(output_size,spatial_scale,sampling_ratio)", "id": "torchvision.ops.RoIAlign", "summary": "See roi_align\n", "description": "", "code-info": {"name": "torchvision.ops.RoIAlign", "parameters": [{"name": "output_size", "is_optional": false, "type": "others", "description": ""}, {"name": "spatial_scale", "is_optional": false, "type": "others", "description": ""}, {"name": "sampling_ratio", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.ops.RoIPool(output_size,spatial_scale)", "id": "torchvision.ops.RoIPool", "summary": "See roi_pool\n", "description": "", "code-info": {"name": "torchvision.ops.RoIPool", "parameters": [{"name": "output_size", "is_optional": false, "type": "others", "description": ""}, {"name": "spatial_scale", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.transforms.functional.adjust_contrast(img,contrast_factor)", "id": "torchvision.transforms.functional.adjust_contrast", "summary": "Adjust contrast of an Image.\n\nParameters\n\nimg (PIL Image) \u2013 PIL Image to be adjusted.\ncontrast_factor (python:float) \u2013 How much to adjust the contrast", "description": "", "code-info": {"name": "torchvision.transforms.functional.adjust_contrast", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 PIL Image to be adjusted."}, {"name": "contrast_factor", "is_optional": false, "type": "float", "description": "(python:float) \u2013 How much to adjust the contrast. Can be any\nnon negative number. 0 gives a solid gray image, 1 gives the\noriginal image while 2 increases the contrast by a factor of 2."}]}},
{"code": "torchvision.transforms.functional.adjust_gamma(img,gamma,gain=1)", "id": "torchvision.transforms.functional.adjust_gamma", "summary": "Perform gamma correction on an image.\nAlso known as Power Law Transform", "description": "", "code-info": {"name": "torchvision.transforms.functional.adjust_gamma", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 PIL Image to be adjusted."}, {"name": "gamma", "is_optional": false, "type": "float", "description": "(python:float) \u2013 Non negative real number, same as \u03b3\\gamma\u03b3\n\n in the equation.\ngamma larger than 1 make the shadows darker,\nwhile gamma smaller than 1 make dark regions lighter."}, {"name": "gain", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:float) \u2013 The constant multiplier."}]}},
{"code": "torchvision.transforms.functional.adjust_hue(img,hue_factor)", "id": "torchvision.transforms.functional.adjust_hue", "summary": "Adjust hue of an image.\nThe image hue is adjusted by converting the image to HSV and\ncyclically shifting the intensities in the hue channel (H).\nThe image is then converted back to original image mode.\nhue_factor is the amount of shift in H channel and must be in the\ninterval [-0.5, 0.5].\nSee Hue for more details.\n\nParameters\n\nimg (PIL Image) \u2013 PIL Image to be adjusted.\nhue_factor (python:float) \u2013 How much to shift the hue channel", "description": "", "code-info": {"name": "torchvision.transforms.functional.adjust_hue", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 PIL Image to be adjusted."}, {"name": "hue_factor", "is_optional": false, "type": "float", "description": "(python:float) \u2013 How much to shift the hue channel. Should be in\n[-0.5, 0.5]. 0.5 and -0.5 give complete reversal of hue channel in\nHSV space in positive and negative direction respectively.\n0 means no shift. Therefore, both -0.5 and 0.5 will give an image\nwith complementary colors while 0 gives the original image."}]}},
{"code": "torchvision.transforms.functional.adjust_saturation(img,saturation_factor)", "id": "torchvision.transforms.functional.adjust_saturation", "summary": "Adjust color saturation of an image.\n\nParameters\n\nimg (PIL Image) \u2013 PIL Image to be adjusted.\nsaturation_factor (python:float) \u2013 How much to adjust the saturation", "description": "", "code-info": {"name": "torchvision.transforms.functional.adjust_saturation", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 PIL Image to be adjusted."}, {"name": "saturation_factor", "is_optional": false, "type": "float", "description": "(python:float) \u2013 How much to adjust the saturation. 0 will\ngive a black and white image, 1 will give the original image while\n2 will enhance the saturation by a factor of 2."}]}},
{"code": "torchvision.transforms.functional.affine(img,angle,translate,scale,shear,resample=0,fillcolor=None)", "id": "torchvision.transforms.functional.affine", "summary": "Apply affine transformation on the image keeping image center invariant\n\nParameters\n\nimg (PIL Image) \u2013 PIL Image to be rotated.\nangle (python:float or python:int) \u2013 rotation angle in degrees between -180 and 180, clockwise direction.\ntranslate (list or tuple of python:integers) \u2013 horizontal and vertical translations (post-rotation translation)\nscale (python:float) \u2013 overall scale\nshear (python:float or tuple or list) \u2013 shear angle value in degrees between -180 to 180, clockwise direction.\na tuple of list is specified, the first value corresponds to a shear parallel to the x axis, while (If) \u2013 \nsecond value corresponds to a shear parallel to the y axis", "description": "", "code-info": {"name": "torchvision.transforms.functional.affine", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 PIL Image to be rotated."}, {"name": "angle", "is_optional": false, "type": "int", "description": "(python:float or python:int) \u2013 rotation angle in degrees between -180 and 180, clockwise direction."}, {"name": "translate", "is_optional": false, "type": "int", "description": "(list or tuple of python:integers) \u2013 horizontal and vertical translations (post-rotation translation)"}, {"name": "scale", "is_optional": false, "type": "float", "description": "(python:float) \u2013 overall scale"}, {"name": "shear", "is_optional": false, "type": "float", "description": "(python:float or tuple or list) \u2013 shear angle value in degrees between -180 to 180, clockwise direction.\na tuple of list is specified, the first value corresponds to a shear parallel to the x axis, while (If) \u2013 \nsecond value corresponds to a shear parallel to the y axis. (the) \u2013 "}, {"name": "resample", "is_optional": true, "type": "int", "default_value": "0", "description": "(PIL.Image.NEAREST or PIL.Image.BILINEAR or PIL.Image.BICUBIC, optional) \u2013 An optional resampling filter.\nSee filters for more information.\nIf omitted, or if the image has mode \u201c1\u201d or \u201cP\u201d, it is set to PIL.Image.NEAREST."}, {"name": "fillcolor", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Optional fill color for the area outside the transform in the output image. (Pillow&gt;=5.0.0)"}]}},
{"code": "torchvision.transforms.functional.center_crop(img,output_size)", "id": "torchvision.transforms.functional.center_crop", "summary": "Crop the given PIL Image and resize it to desired size.\n\nParameters\n\nimg (PIL Image) \u2013 Image to be cropped", "description": "", "code-info": {"name": "torchvision.transforms.functional.center_crop", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 Image to be cropped. (0,0) denotes the top left corner of the image."}, {"name": "output_size", "is_optional": false, "type": "int", "description": "(sequence or python:int) \u2013 (height, width) of the crop box. If int,\nit is used for both directions"}]}},
{"code": "torchvision.transforms.functional.crop(img,top,left,height,width)", "id": "torchvision.transforms.functional.crop", "summary": "Crop the given PIL Image.\n:param img: Image to be cropped", "description": "", "code-info": {"name": "torchvision.transforms.functional.crop", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": ""}, {"name": "top", "is_optional": false, "type": "others", "description": ""}, {"name": "left", "is_optional": false, "type": "others", "description": ""}, {"name": "height", "is_optional": false, "type": "others", "description": ""}, {"name": "width", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.transforms.functional.erase(img,i,j,h,w,v,inplace=False)", "id": "torchvision.transforms.functional.erase", "summary": "Erase the input Tensor Image with given value.\n\nParameters\n\nimg (Tensor Image) \u2013 Tensor image of size (C, H, W) to be erased\ni (python:int) \u2013 i in (i,j) i.e coordinates of the upper left corner.\nj (python:int) \u2013 j in (i,j) i.e coordinates of the upper left corner.\nh (python:int) \u2013 Height of the erased region.\nw (python:int) \u2013 Width of the erased region.\nv \u2013 Erasing value.\ninplace (bool, optional) \u2013 For in-place operations", "description": "", "code-info": {"name": "torchvision.transforms.functional.erase", "parameters": [{"name": "img", "is_optional": false, "type": "tensor", "description": "(Tensor Image) \u2013 Tensor image of size (C, H, W) to be erased"}, {"name": "i", "is_optional": false, "type": "int", "description": "(python:int) \u2013 i in (i,j) i.e coordinates of the upper left corner."}, {"name": "j", "is_optional": false, "type": "int", "description": "(python:int) \u2013 j in (i,j) i.e coordinates of the upper left corner."}, {"name": "h", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Height of the erased region."}, {"name": "w", "is_optional": false, "type": "others", "description": ""}, {"name": "v", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 For in-place operations. By default is set False."}]}},
{"code": "torchvision.transforms.functional.five_crop(img,size)", "id": "torchvision.transforms.functional.five_crop", "summary": "Crop the given PIL Image into four corners and the central crop.\n\nNote\nThis transform returns a tuple of images and there may be a\nmismatch in the number of inputs and targets your Dataset returns.\n\n\nParameters\nsize (sequence or python:int) \u2013 Desired output size of the crop", "description": "", "code-info": {"name": "torchvision.transforms.functional.five_crop", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": ""}, {"name": "size", "is_optional": false, "type": "int", "description": "(sequence or python:int) \u2013 Desired output size of the crop. If size is an\nint instead of sequence like (h, w), a square crop (size, size) is\nmade."}]}},
{"code": "torchvision.transforms.functional.hflip(img)", "id": "torchvision.transforms.functional.hflip", "summary": "Horizontally flip the given PIL Image.\n\nParameters\nimg (PIL Image) \u2013 Image to be flipped.\n\nReturns\nHorizontall flipped image.\n\nReturn type\nPIL Image\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.functional.hflip", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 Image to be flipped."}]}},
{"code": "torchvision.transforms.functional.normalize(tensor,mean,std,inplace=False)", "id": "torchvision.transforms.functional.normalize", "summary": "Normalize a tensor image with mean and standard deviation.\n\nNote\nThis transform acts out of place by default, i.e., it does not mutates the input tensor.\n\nSee Normalize for more details.\n\nParameters\n\ntensor (Tensor) \u2013 Tensor image of size (C, H, W) to be normalized.\nmean (sequence) \u2013 Sequence of means for each channel.\nstd (sequence) \u2013 Sequence of standard deviations for each channel.\ninplace (bool,optional) \u2013 Bool to make this operation inplace.\n\n\nReturns\nNormalized Tensor image.\n\nReturn type\nTensor\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.functional.normalize", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Tensor image of size (C, H, W) to be normalized."}, {"name": "mean", "is_optional": false, "type": "others", "description": "(sequence) \u2013 Sequence of means for each channel."}, {"name": "std", "is_optional": false, "type": "others", "description": "(sequence) \u2013 Sequence of standard deviations for each channel."}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool,optional) \u2013 Bool to make this operation inplace."}]}},
{"code": "torchvision.transforms.functional.pad(img,padding,fill=0,padding_mode='constant')", "id": "torchvision.transforms.functional.pad", "summary": "Pad the given PIL Image on all sides with specified padding mode and fill value.\n\nParameters\n\nimg (PIL Image) \u2013 Image to be padded.\npadding (python:int or tuple) \u2013 Padding on each border", "description": "", "code-info": {"name": "torchvision.transforms.functional.pad", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 Image to be padded."}, {"name": "padding", "is_optional": false, "type": "others", "description": ""}, {"name": "fill", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'constant'", "description": ""}]}},
{"code": "torchvision.models.alexnet(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.alexnet", "summary": "AlexNet model architecture from the\n\u201cOne weird trick\u2026\u201d paper.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.alexnet", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.datasets.CocoCaptions.__getitem__(index)", "id": "torchvision.datasets.CocoCaptions.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\nTuple (image, target)", "description": "", "code-info": {"name": "torchvision.datasets.CocoCaptions.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.transforms.functional.perspective(img,startpoints,endpoints,interpolation=3)", "id": "torchvision.transforms.functional.perspective", "summary": "Perform perspective transform of the given PIL Image.\n\nParameters\n\nimg (PIL Image) \u2013 Image to be transformed.\nstartpoints \u2013 List containing [top-left, top-right, bottom-right, bottom-left] of the orignal image\nendpoints \u2013 List containing [top-left, top-right, bottom-right, bottom-left] of the transformed image\ninterpolation \u2013 Default- Image.BICUBIC\n\n\nReturns\nPerspectively transformed Image.\n\nReturn type\nPIL Image\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.functional.perspective", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": ""}, {"name": "startpoints", "is_optional": false, "type": "others", "description": ""}, {"name": "endpoints", "is_optional": false, "type": "others", "description": ""}, {"name": "interpolation", "is_optional": true, "type": "int", "default_value": "3", "description": ""}]}},
{"code": "torchvision.transforms.functional.resize(img,size,interpolation=2)", "id": "torchvision.transforms.functional.resize", "summary": "Resize the input PIL Image to the given size.\n\nParameters\n\nimg (PIL Image) \u2013 Image to be resized.\nsize (sequence or python:int) \u2013 Desired output size", "description": "", "code-info": {"name": "torchvision.transforms.functional.resize", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 Image to be resized."}, {"name": "size", "is_optional": false, "type": "int", "description": "(sequence or python:int) \u2013 Desired output size. If size is a sequence like\n(h, w), the output size will be matched to this. If size is an int,\nthe smaller edge of the image will be matched to this number maintaing\nthe aspect ratio. i.e, if height &gt; width, then image will be rescaled to\n(size\u00d7heightwidth,size)\\left(\\text{size} \\times \\frac{\\text{height}}{\\text{width}}, \\text{size}\\right)(size\u00d7widthheight\u200b,size)\n\n"}, {"name": "interpolation", "is_optional": true, "type": "int", "default_value": "2", "description": "(python:int, optional) \u2013 Desired interpolation. Default is\nPIL.Image.BILINEAR"}]}},
{"code": "torchvision.transforms.functional.resized_crop(img,top,left,height,width,size,interpolation=2)", "id": "torchvision.transforms.functional.resized_crop", "summary": "Crop the given PIL Image and resize it to desired size.\nNotably used in RandomResizedCrop.\n\nParameters\n\nimg (PIL Image) \u2013 Image to be cropped", "description": "", "code-info": {"name": "torchvision.transforms.functional.resized_crop", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 Image to be cropped. (0,0) denotes the top left corner of the image."}, {"name": "top", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Vertical component of the top left corner of the crop box."}, {"name": "left", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Horizontal component of the top left corner of the crop box."}, {"name": "height", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Height of the crop box."}, {"name": "width", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Width of the crop box."}, {"name": "size", "is_optional": false, "type": "int", "description": "(sequence or python:int) \u2013 Desired output size. Same semantics as resize."}, {"name": "interpolation", "is_optional": true, "type": "int", "default_value": "2", "description": "(python:int, optional) \u2013 Desired interpolation. Default is\nPIL.Image.BILINEAR."}]}},
{"code": "torchvision.transforms.functional.rotate(img,angle,resample=False,expand=False,center=None,fill=0)", "id": "torchvision.transforms.functional.rotate", "summary": "Rotate the image by angle.\n\nParameters\n\nimg (PIL Image) \u2013 PIL Image to be rotated.\nangle (python:float or python:int) \u2013 In degrees degrees counter clockwise order.\nresample (PIL.Image.NEAREST or PIL.Image.BILINEAR or PIL.Image.BICUBIC, optional) \u2013 An optional resampling filter", "description": "", "code-info": {"name": "torchvision.transforms.functional.rotate", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 PIL Image to be rotated."}, {"name": "angle", "is_optional": false, "type": "int", "description": "(python:float or python:int) \u2013 In degrees degrees counter clockwise order."}, {"name": "resample", "is_optional": true, "type": "bool", "default_value": "False", "description": "(PIL.Image.NEAREST or PIL.Image.BILINEAR or PIL.Image.BICUBIC, optional) \u2013 An optional resampling filter. See filters for more information.\nIf omitted, or if the image has mode \u201c1\u201d or \u201cP\u201d, it is set to PIL.Image.NEAREST."}, {"name": "expand", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Optional expansion flag.\nIf true, expands the output image to make it large enough to hold the entire rotated image.\nIf false or omitted, make the output image the same size as the input image.\nNote that the expand flag assumes rotation around the center and no translation."}, {"name": "center", "is_optional": true, "type": "others", "default_value": "None", "description": "(2-tuple, optional) \u2013 Optional center of rotation.\nOrigin is the upper left corner.\nDefault is the center of the image."}, {"name": "fill", "is_optional": true, "type": "int", "default_value": "0", "description": "(3-tuple or python:int) \u2013 RGB pixel fill value for area outside the rotated image.\nIf int, it is used for all channels respectively."}]}},
{"code": "torchvision.transforms.functional.ten_crop(img,size,vertical_flip=False)", "id": "torchvision.transforms.functional.ten_crop", "summary": "\nCrop the given PIL Image into four corners and the central crop plus theflipped version of these (horizontal flipping is used by default).\n\n\n\nNote\nThis transform returns a tuple of images and there may be a\nmismatch in the number of inputs and targets your Dataset returns.\n\n\nParameters\n\nsize (sequence or python:int) \u2013 Desired output size of the crop", "description": "", "code-info": {"name": "torchvision.transforms.functional.ten_crop", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": ""}, {"name": "size", "is_optional": false, "type": "int", "description": "(sequence or python:int) \u2013 Desired output size of the crop. If size is an\nint instead of sequence like (h, w), a square crop (size, size) is\nmade."}, {"name": "vertical_flip", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 Use vertical flipping instead of horizontal"}]}},
{"code": "torchvision.transforms.functional.to_grayscale(img,num_output_channels=1)", "id": "torchvision.transforms.functional.to_grayscale", "summary": "Convert image to grayscale version of image.\n\nParameters\nimg (PIL Image) \u2013 Image to be converted to grayscale.\n\nReturns\n\nGrayscale version of the image.if num_output_channels = 1 : returned image is single channel\nif num_output_channels = 3 : returned image is 3 channel with r = g = b\n\n\n\n\nReturn type\nPIL Image\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.functional.to_grayscale", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": ""}, {"name": "num_output_channels", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torchvision.transforms.functional.to_pil_image(pic,mode=None)", "id": "torchvision.transforms.functional.to_pil_image", "summary": "Convert a tensor or an ndarray to PIL Image.\nSee ToPILImage for more details.\n\nParameters\n\npic (Tensor or numpy.ndarray) \u2013 Image to be converted to PIL Image.\nmode (PIL.Image mode) \u2013 color space and pixel depth of input data (optional).\n\n\n\n\nReturns\nImage converted to PIL Image.\n\nReturn type\nPIL Image\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.functional.to_pil_image", "parameters": [{"name": "pic", "is_optional": false, "type": "tensor", "description": "(Tensor or numpy.ndarray) \u2013 Image to be converted to PIL Image."}, {"name": "mode", "is_optional": true, "type": "others", "default_value": "None", "description": "(PIL.Image mode) \u2013 color space and pixel depth of input data (optional)."}]}},
{"code": "torchvision.transforms.functional.to_tensor(pic)", "id": "torchvision.transforms.functional.to_tensor", "summary": "Convert a PIL Image or numpy.ndarray to tensor.\nSee ToTensor for more details.\n\nParameters\npic (PIL Image or numpy.ndarray) \u2013 Image to be converted to tensor.\n\nReturns\nConverted image.\n\nReturn type\nTensor\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.functional.to_tensor", "parameters": [{"name": "pic", "is_optional": false, "type": "others", "description": "(PIL Image or numpy.ndarray) \u2013 Image to be converted to tensor."}]}},
{"code": "torchvision.transforms.functional.vflip(img)", "id": "torchvision.transforms.functional.vflip", "summary": "Vertically flip the given PIL Image.\n\nParameters\nimg (PIL Image) \u2013 Image to be flipped.\n\nReturns\nVertically flipped image.\n\nReturn type\nPIL Image\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.functional.vflip", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": "(PIL Image) \u2013 Image to be flipped."}]}},
{"code": "torchvision.transforms.Normalize.__call__(tensor)", "id": "torchvision.transforms.Normalize.__call__", "summary": "\nParameters\ntensor (Tensor) \u2013 Tensor image of size (C, H, W) to be normalized.\n\nReturns\nNormalized Tensor image.\n\nReturn type\nTensor\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.Normalize.__call__", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Tensor image of size (C, H, W) to be normalized."}]}},
{"code": "torchvision.transforms.ToPILImage.__call__(pic)", "id": "torchvision.transforms.ToPILImage.__call__", "summary": "\nParameters\npic (Tensor or numpy.ndarray) \u2013 Image to be converted to PIL Image.\n\nReturns\nImage converted to PIL Image.\n\nReturn type\nPIL Image\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.ToPILImage.__call__", "parameters": [{"name": "pic", "is_optional": false, "type": "tensor", "description": "(Tensor or numpy.ndarray) \u2013 Image to be converted to PIL Image."}]}},
{"code": "torchvision.transforms.ToTensor.__call__(pic)", "id": "torchvision.transforms.ToTensor.__call__", "summary": "\nParameters\npic (PIL Image or numpy.ndarray) \u2013 Image to be converted to tensor.\n\nReturns\nConverted image.\n\nReturn type\nTensor\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.ToTensor.__call__", "parameters": [{"name": "pic", "is_optional": false, "type": "others", "description": "(PIL Image or numpy.ndarray) \u2013 Image to be converted to tensor."}]}},
{"code": "torchvision.transforms.Compose(transforms)", "id": "torchvision.transforms.Compose", "summary": "Composes several transforms together.\n\nParameters\ntransforms (list of Transform objects) \u2013 list of transforms to compose.\n\n\nExample\n&gt;&gt;&gt; transforms.Compose([\n&gt;&gt;&gt;     transforms.CenterCrop(10),\n&gt;&gt;&gt;     transforms.ToTensor(),\n&gt;&gt;&gt; ])\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.Compose", "parameters": [{"name": "transforms", "is_optional": false, "type": "others", "description": "(list of Transform objects) \u2013 list of transforms to compose."}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.__init__(log_dir=None,comment='',purge_step=None,max_queue=10,flush_secs=120,filename_suffix='')", "id": "torch.utils.tensorboard.writer.SummaryWriter.__init__", "summary": "Creates a SummaryWriter that will write out events and summaries\nto the event file.\n\nParameters\n\nlog_dir (string) \u2013 Save directory location", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.__init__", "parameters": [{"name": "log_dir", "is_optional": true, "type": "string", "default_value": "None", "description": "(string) \u2013 Save directory location. Default is\nruns/CURRENT_DATETIME_HOSTNAME, which changes after each run.\nUse hierarchical folder structure to compare\nbetween runs easily. e.g. pass in \u2018runs/exp1\u2019, \u2018runs/exp2\u2019, etc.\nfor each new experiment to compare across them."}, {"name": "comment", "is_optional": true, "type": "string", "default_value": "''", "description": "(string) \u2013 Comment log_dir suffix appended to the default\nlog_dir. If log_dir is assigned, this argument has no effect."}, {"name": "purge_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 When logging crashes at step T+XT+XT+X\n\n and restarts at step TTT\n\n,\nany events whose global_step larger or equal to TTT\n\n will be\npurged and hidden from TensorBoard.\nNote that crashed and resumed experiments should have the same log_dir."}, {"name": "max_queue", "is_optional": true, "type": "int", "default_value": "10", "description": "(python:int) \u2013 Size of the queue for pending events and\nsummaries before one of the \u2018add\u2019 calls forces a flush to disk.\nDefault is ten items."}, {"name": "flush_secs", "is_optional": true, "type": "int", "default_value": "120", "description": "(python:int) \u2013 How often, in seconds, to flush the\npending events and summaries to disk. Default is every two minutes."}, {"name": "filename_suffix", "is_optional": true, "type": "string", "default_value": "''", "description": "(string) \u2013 Suffix added to all event filenames in\nthe log_dir directory. More details on filename construction in\ntensorboard.summary.writer.event_file_writer.EventFileWriter."}]}},
{"code": "torch.utils.model_zoo.load_url(url,model_dir=None,map_location=None,progress=True,check_hash=False)", "id": "torch.utils.model_zoo.load_url", "summary": "Loads the Torch serialized object at the given URL.\nIf downloaded file is a zip file, it will be automatically\ndecompressed.\nIf the object is already present in model_dir, it\u2019s deserialized and\nreturned.\nThe default value of model_dir is $TORCH_HOME/checkpoints where\nenvironment variable $TORCH_HOME defaults to $XDG_CACHE_HOME/torch.\n$XDG_CACHE_HOME follows the X Design Group specification of the Linux\nfilesytem layout, with a default value ~/.cache if not set.\n\nParameters\n\nurl (string) \u2013 URL of the object to download\nmodel_dir (string, optional) \u2013 directory in which to save the object\nmap_location (optional) \u2013 a function or a dict specifying how to remap storage locations (see torch.load)\nprogress (bool, optional) \u2013 whether or not to display a progress bar to stderr.\nDefault: True\ncheck_hash (bool, optional) \u2013 If True, the filename part of the URL should follow the naming convention\nfilename-&lt;sha256&gt;.ext where &lt;sha256&gt; is the first eight or more\ndigits of the SHA256 hash of the contents of the file", "description": "", "code-info": {"name": "torch.utils.model_zoo.load_url", "parameters": [{"name": "url", "is_optional": false, "type": "string", "description": "(string) \u2013 URL of the object to download"}, {"name": "model_dir", "is_optional": true, "type": "string", "default_value": "None", "description": "(string, optional) \u2013 directory in which to save the object"}, {"name": "map_location", "is_optional": true, "type": "others", "default_value": "None", "description": "(optional) \u2013 a function or a dict specifying how to remap storage locations (see torch.load)"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 whether or not to display a progress bar to stderr.\nDefault: True"}, {"name": "check_hash", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If True, the filename part of the URL should follow the naming convention\nfilename-&lt;sha256&gt;.ext where &lt;sha256&gt; is the first eight or more\ndigits of the SHA256 hash of the contents of the file. The hash is used to\nensure unique names and to verify the contents of the file.\nDefault: False"}]}},
{"code": "torch.utils.dlpack.from_dlpack(dlpack)", "id": "torch.utils.dlpack.from_dlpack", "summary": "Decodes a DLPack to a tensor.\n\nParameters\ndlpack \u2013 a PyCapsule object with the dltensor\n\n\nThe tensor will share the memory with the object represented\nin the dlpack.\nNote that each dlpack can only be consumed once.\n", "description": "", "code-info": {"name": "torch.utils.dlpack.from_dlpack", "parameters": [{"name": "dlpack", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.utils.dlpack.to_dlpack(tensor)", "id": "torch.utils.dlpack.to_dlpack", "summary": "Returns a DLPack representing the tensor.\n\nParameters\ntensor \u2013 a tensor to be exported\n\n\nThe dlpack shares the tensors memory.\nNote that each dlpack can only be consumed once.\n", "description": "", "code-info": {"name": "torch.utils.dlpack.to_dlpack", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.utils.data.get_worker_info()", "id": "torch.utils.data.get_worker_info", "summary": "Returns the information about the current\nDataLoader iterator worker process.\nWhen called in a worker, this returns an object guaranteed to have the\nfollowing attributes:\n\nid: the current worker id.\nnum_workers: the total number of workers.\nseed: the random seed set for the current worker", "description": "", "code-info": {"name": "torch.utils.data.get_worker_info", "parameters": []}},
{"code": "torchvision.models.vgg11(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.vgg11", "summary": "VGG 11-layer model (configuration \u201cA\u201d) from\n\u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.vgg11", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.vgg11_bn(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.vgg11_bn", "summary": "VGG 11-layer model (configuration \u201cA\u201d) with batch normalization\n\u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.vgg11_bn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.vgg13(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.vgg13", "summary": "VGG 13-layer model (configuration \u201cB\u201d)\n\u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.vgg13", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.vgg13_bn(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.vgg13_bn", "summary": "VGG 13-layer model (configuration \u201cB\u201d) with batch normalization\n\u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.vgg13_bn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.vgg16(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.vgg16", "summary": "VGG 16-layer model (configuration \u201cD\u201d)\n\u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.vgg16", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.vgg16_bn(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.vgg16_bn", "summary": "VGG 16-layer model (configuration \u201cD\u201d) with batch normalization\n\u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.vgg16_bn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.vgg19(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.vgg19", "summary": "VGG 19-layer model (configuration \u201cE\u201d)\n\u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.vgg19", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.vgg19_bn(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.vgg19_bn", "summary": "VGG 19-layer model (configuration \u2018E\u2019) with batch normalization\n\u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.vgg19_bn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.resnet18(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.resnet18", "summary": "ResNet-18 model from\n\u201cDeep Residual Learning for Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.resnet18", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.resnet34(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.resnet34", "summary": "ResNet-34 model from\n\u201cDeep Residual Learning for Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.resnet34", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.resnet50(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.resnet50", "summary": "ResNet-50 model from\n\u201cDeep Residual Learning for Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.resnet50", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.resnet101(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.resnet101", "summary": "ResNet-101 model from\n\u201cDeep Residual Learning for Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.resnet101", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.resnet152(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.resnet152", "summary": "ResNet-152 model from\n\u201cDeep Residual Learning for Image Recognition\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.resnet152", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.squeezenet1_0(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.squeezenet1_0", "summary": "SqueezeNet model architecture from the \u201cSqueezeNet: AlexNet-level\naccuracy with 50x fewer parameters and &lt;0.5MB model size\u201d paper.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.squeezenet1_0", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.utils.cpp_extension.CppExtension(name,sources,*args,**kwargs)", "id": "torch.utils.cpp_extension.CppExtension", "summary": "Creates a setuptools.Extension for C++.\nConvenience method that creates a setuptools.Extension with the\nbare minimum (but often sufficient) arguments to build a C++ extension.\nAll arguments are forwarded to the setuptools.Extension\nconstructor.\nExample\n&gt;&gt;&gt; from setuptools import setup\n&gt;&gt;&gt; from torch.utils.cpp_extension import BuildExtension, CppExtension\n&gt;&gt;&gt; setup(\n        name='extension',\n        ext_modules=[\n            CppExtension(\n                name='extension',\n                sources=['extension.cpp'],\n                extra_compile_args=['-g']),\n        ],\n        cmdclass={\n            'build_ext': BuildExtension\n        })\n\n\n", "description": "", "code-info": {"name": "torch.utils.cpp_extension.CppExtension", "parameters": [{"name": "name", "is_optional": false, "type": "others", "description": ""}, {"name": "sources", "is_optional": false, "type": "others", "description": ""}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.utils.cpp_extension.CUDAExtension(name,sources,*args,**kwargs)", "id": "torch.utils.cpp_extension.CUDAExtension", "summary": "Creates a setuptools.Extension for CUDA/C++.\nConvenience method that creates a setuptools.Extension with the\nbare minimum (but often sufficient) arguments to build a CUDA/C++\nextension", "description": "", "code-info": {"name": "torch.utils.cpp_extension.CUDAExtension", "parameters": [{"name": "name", "is_optional": false, "type": "others", "description": ""}, {"name": "sources", "is_optional": false, "type": "others", "description": ""}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.utils.cpp_extension.BuildExtension(*args,**kwargs)", "id": "torch.utils.cpp_extension.BuildExtension", "summary": "A custom setuptools build extension .\nThis setuptools.build_ext subclass takes care of passing the\nminimum required compiler flags (e.g", "description": "", "code-info": {"name": "torch.utils.cpp_extension.BuildExtension", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.utils.cpp_extension.load(name,sources,extra_cflags=None,extra_cuda_cflags=None,extra_ldflags=None,extra_include_paths=None,build_directory=None,verbose=False,with_cuda=None,is_python_module=True)", "id": "torch.utils.cpp_extension.load", "summary": "Loads a PyTorch C++ extension just-in-time (JIT).\nTo load an extension, a Ninja build file is emitted, which is used to\ncompile the given sources into a dynamic library", "description": "", "code-info": {"name": "torch.utils.cpp_extension.load", "parameters": [{"name": "name", "is_optional": false, "type": "others", "description": ""}, {"name": "sources", "is_optional": false, "type": "others", "description": ""}, {"name": "extra_cflags", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extra_cuda_cflags", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extra_ldflags", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extra_include_paths", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "build_directory", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "verbose", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "with_cuda", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "is_python_module", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torchvision.datasets.CocoDetection.__getitem__(index)", "id": "torchvision.datasets.CocoDetection.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\nTuple (image, target)", "description": "", "code-info": {"name": "torchvision.datasets.CocoDetection.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.LSUN.__getitem__(index)", "id": "torchvision.datasets.LSUN.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\nTuple (image, target) where target is the index of the target category.\n\nReturn type\ntuple\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.LSUN.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.ImageFolder.__getitem__(index)", "id": "torchvision.datasets.ImageFolder.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(sample, target) where target is class_index of the target class.\n\nReturn type\ntuple\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.ImageFolder.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.DatasetFolder.__getitem__(index)", "id": "torchvision.datasets.DatasetFolder.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(sample, target) where target is class_index of the target class.\n\nReturn type\ntuple\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.DatasetFolder.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.CIFAR10.__getitem__(index)", "id": "torchvision.datasets.CIFAR10.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(image, target) where target is index of the target class.\n\nReturn type\ntuple\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.CIFAR10.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.STL10.__getitem__(index)", "id": "torchvision.datasets.STL10.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(image, target) where target is index of the target class.\n\nReturn type\ntuple\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.STL10.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.SVHN.__getitem__(index)", "id": "torchvision.datasets.SVHN.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(image, target) where target is index of the target class.\n\nReturn type\ntuple\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.SVHN.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.PhotoTour.__getitem__(index)", "id": "torchvision.datasets.PhotoTour.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(data1, data2, matches)\n\nReturn type\ntuple\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.PhotoTour.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.SBU.__getitem__(index)", "id": "torchvision.datasets.SBU.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(image, target) where target is a caption for the photo.\n\nReturn type\ntuple\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.SBU.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.Flickr8k.__getitem__(index)", "id": "torchvision.datasets.Flickr8k.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\nTuple (image, target)", "description": "", "code-info": {"name": "torchvision.datasets.Flickr8k.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.Flickr30k.__getitem__(index)", "id": "torchvision.datasets.Flickr30k.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\nTuple (image, target)", "description": "", "code-info": {"name": "torchvision.datasets.Flickr30k.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.VOCSegmentation.__getitem__(index)", "id": "torchvision.datasets.VOCSegmentation.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(image, target) where target is the image segmentation.\n\nReturn type\ntuple\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.VOCSegmentation.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.VOCDetection.__getitem__(index)", "id": "torchvision.datasets.VOCDetection.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(image, target) where target is a dictionary of the XML tree.\n\nReturn type\ntuple\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.VOCDetection.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.Cityscapes.__getitem__(index)", "id": "torchvision.datasets.Cityscapes.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(image, target) where target is a tuple of all target types if target_type is a list with more\nthan one item", "description": "", "code-info": {"name": "torchvision.datasets.Cityscapes.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.transforms.CenterCrop(size)", "id": "torchvision.transforms.CenterCrop", "summary": "Crops the given PIL Image at the center.\n\nParameters\nsize (sequence or python:int) \u2013 Desired output size of the crop", "description": "", "code-info": {"name": "torchvision.transforms.CenterCrop", "parameters": [{"name": "size", "is_optional": false, "type": "int", "description": "(sequence or python:int) \u2013 Desired output size of the crop. If size is an\nint instead of sequence like (h, w), a square crop (size, size) is\nmade."}]}},
{"code": "torchvision.transforms.ColorJitter(brightness=0,contrast=0,saturation=0,hue=0)", "id": "torchvision.transforms.ColorJitter", "summary": "Randomly change the brightness, contrast and saturation of an image.\n\nParameters\n\nbrightness (python:float or tuple of python:float (min, max)) \u2013 How much to jitter brightness.\nbrightness_factor is chosen uniformly from [max(0, 1 - brightness), 1 + brightness]\nor the given [min, max]", "description": "", "code-info": {"name": "torchvision.transforms.ColorJitter", "parameters": [{"name": "brightness", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float or tuple of python:float (min, max)) \u2013 How much to jitter brightness.\nbrightness_factor is chosen uniformly from [max(0, 1 - brightness), 1 + brightness]\nor the given [min, max]. Should be non negative numbers."}, {"name": "contrast", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float or tuple of python:float (min, max)) \u2013 How much to jitter contrast.\ncontrast_factor is chosen uniformly from [max(0, 1 - contrast), 1 + contrast]\nor the given [min, max]. Should be non negative numbers."}, {"name": "saturation", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float or tuple of python:float (min, max)) \u2013 How much to jitter saturation.\nsaturation_factor is chosen uniformly from [max(0, 1 - saturation), 1 + saturation]\nor the given [min, max]. Should be non negative numbers."}, {"name": "hue", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float or tuple of python:float (min, max)) \u2013 How much to jitter hue.\nhue_factor is chosen uniformly from [-hue, hue] or the given [min, max].\nShould have 0&lt;= hue &lt;= 0.5 or -0.5 &lt;= min &lt;= max &lt;= 0.5."}]}},
{"code": "torchvision.transforms.FiveCrop(size)", "id": "torchvision.transforms.FiveCrop", "summary": "Crop the given PIL Image into four corners and the central crop\n\nNote\nThis transform returns a tuple of images and there may be a mismatch in the number of\ninputs and targets your Dataset returns", "description": "", "code-info": {"name": "torchvision.transforms.FiveCrop", "parameters": [{"name": "size", "is_optional": false, "type": "int", "description": "(sequence or python:int) \u2013 Desired output size of the crop. If size is an int\ninstead of sequence like (h, w), a square crop of size (size, size) is made."}]}},
{"code": "torchvision.transforms.Grayscale(num_output_channels=1)", "id": "torchvision.transforms.Grayscale", "summary": "Convert image to grayscale.\n\nParameters\nnum_output_channels (python:int) \u2013 (1 or 3) number of channels desired for output image\n\nReturns\nGrayscale version of the input.\n- If num_output_channels == 1 : returned image is single channel\n- If num_output_channels == 3 : returned image is 3 channel with r == g == b\n\nReturn type\nPIL Image\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.Grayscale", "parameters": [{"name": "num_output_channels", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int) \u2013 (1 or 3) number of channels desired for output image"}]}},
{"code": "torchvision.transforms.Pad(padding,fill=0,padding_mode='constant')", "id": "torchvision.transforms.Pad", "summary": "Pad the given PIL Image on all sides with the given \u201cpad\u201d value.\n\nParameters\n\npadding (python:int or tuple) \u2013 Padding on each border", "description": "", "code-info": {"name": "torchvision.transforms.Pad", "parameters": [{"name": "padding", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 Padding on each border. If a single int is provided this\nis used to pad all borders. If tuple of length 2 is provided this is the padding\non left/right and top/bottom respectively. If a tuple of length 4 is provided\nthis is the padding for the left, top, right and bottom borders\nrespectively."}, {"name": "fill", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple) \u2013 Pixel fill value for constant fill. Default is 0. If a tuple of\nlength 3, it is used to fill R, G, B channels respectively.\nThis value is only used when the padding_mode is constant"}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'constant'", "description": "(str) \u2013 Type of padding. Should be: constant, edge, reflect or symmetric.\nDefault is constant."}]}},
{"code": "torchvision.transforms.RandomAffine(degrees,translate=None,scale=None,shear=None,resample=False,fillcolor=0)", "id": "torchvision.transforms.RandomAffine", "summary": "Random affine transformation of the image keeping center invariant\n\nParameters\n\ndegrees (sequence or python:float or python:int) \u2013 Range of degrees to select from.\nIf degrees is a number instead of sequence like (min, max), the range of degrees\nwill be (-degrees, +degrees)", "description": "", "code-info": {"name": "torchvision.transforms.RandomAffine", "parameters": [{"name": "degrees", "is_optional": false, "type": "int", "description": "(sequence or python:float or python:int) \u2013 Range of degrees to select from.\nIf degrees is a number instead of sequence like (min, max), the range of degrees\nwill be (-degrees, +degrees). Set to 0 to deactivate rotations."}, {"name": "translate", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 tuple of maximum absolute fraction for horizontal\nand vertical translations. For example translate=(a, b), then horizontal shift\nis randomly sampled in the range -img_width * a &lt; dx &lt; img_width * a and vertical shift is\nrandomly sampled in the range -img_height * b &lt; dy &lt; img_height * b. Will not translate by default."}, {"name": "scale", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 scaling factor interval, e.g (a, b), then scale is\nrandomly sampled from the range a &lt;= scale &lt;= b. Will keep original scale by default."}, {"name": "shear", "is_optional": true, "type": "int", "default_value": "None", "description": "(sequence or python:float or python:int, optional) \u2013 Range of degrees to select from.\nIf shear is a number, a shear parallel to the x axis in the range (-shear, +shear)\nwill be apllied. Else if shear is a tuple or list of 2 values a shear parallel to the x axis in the\nrange (shear[0], shear[1]) will be applied. Else if shear is a tuple or list of 4 values,\na x-axis shear in (shear[0], shear[1]) and y-axis shear in (shear[2], shear[3]) will be applied.\nWill not apply shear by default"}, {"name": "resample", "is_optional": true, "type": "bool", "default_value": "False", "description": "({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional) \u2013 An optional resampling filter. See filters for more information.\nIf omitted, or if the image has mode \u201c1\u201d or \u201cP\u201d, it is set to PIL.Image.NEAREST."}, {"name": "fillcolor", "is_optional": true, "type": "int", "default_value": "0", "description": "(tuple or python:int) \u2013 Optional fill color (Tuple for RGB Image And int for grayscale) for the area\noutside the transform in the output image.(Pillow&gt;=5.0.0)"}]}},
{"code": "torchvision.transforms.RandomApply(transforms,p=0.5)", "id": "torchvision.transforms.RandomApply", "summary": "Apply randomly a list of transformations with a given probability\n\nParameters\n\ntransforms (list or tuple) \u2013 list of transformations\np (python:float) \u2013 probability\n\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.RandomApply", "parameters": [{"name": "transforms", "is_optional": false, "type": "others", "description": "(list or tuple) \u2013 list of transformations"}, {"name": "p", "is_optional": true, "type": "float", "default_value": "0.5", "description": "(python:float) \u2013 probability"}]}},
{"code": "torchvision.transforms.RandomChoice(transforms)", "id": "torchvision.transforms.RandomChoice", "summary": "Apply single transformation randomly picked from a list\n", "description": "", "code-info": {"name": "torchvision.transforms.RandomChoice", "parameters": [{"name": "transforms", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.transforms.RandomCrop(size,padding=None,pad_if_needed=False,fill=0,padding_mode='constant')", "id": "torchvision.transforms.RandomCrop", "summary": "Crop the given PIL Image at a random location.\n\nParameters\n\nsize (sequence or python:int) \u2013 Desired output size of the crop", "description": "", "code-info": {"name": "torchvision.transforms.RandomCrop", "parameters": [{"name": "size", "is_optional": false, "type": "int", "description": "(sequence or python:int) \u2013 Desired output size of the crop. If size is an\nint instead of sequence like (h, w), a square crop (size, size) is\nmade."}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or sequence, optional) \u2013 Optional padding on each border\nof the image. Default is None, i.e no padding. If a sequence of length\n4 is provided, it is used to pad left, top, right, bottom borders\nrespectively. If a sequence of length 2 is provided, it is used to\npad left/right, top/bottom borders, respectively."}, {"name": "pad_if_needed", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "fill", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'constant'", "description": ""}]}},
{"code": "torchvision.transforms.RandomGrayscale(p=0.1)", "id": "torchvision.transforms.RandomGrayscale", "summary": "Randomly convert image to grayscale with a probability of p (default 0.1).\n\nParameters\np (python:float) \u2013 probability that image should be converted to grayscale.\n\nReturns\nGrayscale version of the input image with probability p and unchanged\nwith probability (1-p).\n- If input image is 1 channel: grayscale version is 1 channel\n- If input image is 3 channel: grayscale version is 3 channel with r == g == b\n\nReturn type\nPIL Image\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.RandomGrayscale", "parameters": [{"name": "p", "is_optional": true, "type": "float", "default_value": "0.1", "description": "(python:float) \u2013 probability that image should be converted to grayscale."}]}},
{"code": "torchvision.transforms.RandomHorizontalFlip(p=0.5)", "id": "torchvision.transforms.RandomHorizontalFlip", "summary": "Horizontally flip the given PIL Image randomly with a given probability.\n\nParameters\np (python:float) \u2013 probability of the image being flipped", "description": "", "code-info": {"name": "torchvision.transforms.RandomHorizontalFlip", "parameters": [{"name": "p", "is_optional": true, "type": "float", "default_value": "0.5", "description": "(python:float) \u2013 probability of the image being flipped. Default value is 0.5"}]}},
{"code": "torchvision.transforms.RandomOrder(transforms)", "id": "torchvision.transforms.RandomOrder", "summary": "Apply a list of transformations in a random order\n", "description": "", "code-info": {"name": "torchvision.transforms.RandomOrder", "parameters": [{"name": "transforms", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_scalar(tag,scalar_value,global_step=None,walltime=None)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_scalar", "summary": "Add scalar data to summary.\n\nParameters\n\ntag (string) \u2013 Data identifier\nscalar_value (python:float or string/blobname) \u2013 Value to save\nglobal_step (python:int) \u2013 Global step value to record\nwalltime (python:float) \u2013 Optional override default walltime (time.time())\nwith seconds after epoch of event\n\n\n\nExamples:\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\nx = range(100)\nfor i in x:\n    writer.add_scalar('y=2x', i * 2, i)\nwriter.close()\n\n\nExpected result:\n\n", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_scalar", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": "(string) \u2013 Data identifier"}, {"name": "scalar_value", "is_optional": false, "type": "float", "description": "(python:float or string/blobname) \u2013 Value to save"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float) \u2013 Optional override default walltime (time.time())\nwith seconds after epoch of event"}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_scalars(main_tag,tag_scalar_dict,global_step=None,walltime=None)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_scalars", "summary": "Adds many scalar data to summary.\nNote that this function also keeps logged scalars in memory", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_scalars", "parameters": [{"name": "main_tag", "is_optional": false, "type": "string", "description": "(string) \u2013 The parent name for the tags"}, {"name": "tag_scalar_dict", "is_optional": false, "type": "others", "description": "(dict) \u2013 Key-value pair storing the tag and corresponding values"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event"}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_histogram(tag,values,global_step=None,bins='tensorflow',walltime=None,max_bins=None)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_histogram", "summary": "Add histogram to summary.\n\nParameters\n\ntag (string) \u2013 Data identifier\nvalues (torch.Tensor, numpy.array, or string/blobname) \u2013 Values to build histogram\nglobal_step (python:int) \u2013 Global step value to record\nbins (string) \u2013 One of {\u2018tensorflow\u2019,\u2019auto\u2019, \u2018fd\u2019, \u2026}", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_histogram", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": "(string) \u2013 Data identifier"}, {"name": "values", "is_optional": false, "type": "tensor", "description": "(torch.Tensor, numpy.array, or string/blobname) \u2013 Values to build histogram"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "bins", "is_optional": true, "type": "string", "default_value": "'tensorflow'", "description": "(string) \u2013 One of {\u2018tensorflow\u2019,\u2019auto\u2019, \u2018fd\u2019, \u2026}. This determines how the bins are made. You can find\nother options in: https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html"}, {"name": "walltime", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "max_bins", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_image(tag,img_tensor,global_step=None,walltime=None,dataformats='CHW')", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_image", "summary": "Add image data to summary.\nNote that this requires the pillow package.\n\nParameters\n\ntag (string) \u2013 Data identifier\nimg_tensor (torch.Tensor, numpy.array, or string/blobname) \u2013 Image data\nglobal_step (python:int) \u2013 Global step value to record\nwalltime (python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\n\n\n\n\nShape:img_tensor: Default is (3,H,W)(3, H, W)(3,H,W)\n\n", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_image", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": "(string) \u2013 Data identifier"}, {"name": "img_tensor", "is_optional": false, "type": "tensor", "description": "(torch.Tensor, numpy.array, or string/blobname) \u2013 Image data"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "dataformats", "is_optional": true, "type": "string", "default_value": "'CHW'", "description": ""}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_images(tag,img_tensor,global_step=None,walltime=None,dataformats='NCHW')", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_images", "summary": "Add batched image data to summary.\nNote that this requires the pillow package.\n\nParameters\n\ntag (string) \u2013 Data identifier\nimg_tensor (torch.Tensor, numpy.array, or string/blobname) \u2013 Image data\nglobal_step (python:int) \u2013 Global step value to record\nwalltime (python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\ndataformats (string) \u2013 Image data format specification of the form\nNCHW, NHWC, CHW, HWC, HW, WH, etc.\n\n\n\n\nShape:img_tensor: Default is (N,3,H,W)(N, 3, H, W)(N,3,H,W)\n\n", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_images", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": "(string) \u2013 Data identifier"}, {"name": "img_tensor", "is_optional": false, "type": "tensor", "description": "(torch.Tensor, numpy.array, or string/blobname) \u2013 Image data"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event"}, {"name": "dataformats", "is_optional": true, "type": "string", "default_value": "'NCHW'", "description": "(string) \u2013 Image data format specification of the form\nNCHW, NHWC, CHW, HWC, HW, WH, etc."}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_figure(tag,figure,global_step=None,close=True,walltime=None)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_figure", "summary": "Render matplotlib figure into an image and add it to summary.\nNote that this requires the matplotlib package.\n\nParameters\n\ntag (string) \u2013 Data identifier\nfigure (matplotlib.pyplot.figure) \u2013 Figure or a list of figures\nglobal_step (python:int) \u2013 Global step value to record\nclose (bool) \u2013 Flag to automatically close the figure\nwalltime (python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\n\n\n\n", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_figure", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": "(string) \u2013 Data identifier"}, {"name": "figure", "is_optional": false, "type": "others", "description": "(matplotlib.pyplot.figure) \u2013 Figure or a list of figures"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "close", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 Flag to automatically close the figure"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event"}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_video(tag,vid_tensor,global_step=None,fps=4,walltime=None)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_video", "summary": "Add video data to summary.\nNote that this requires the moviepy package.\n\nParameters\n\ntag (string) \u2013 Data identifier\nvid_tensor (torch.Tensor) \u2013 Video data\nglobal_step (python:int) \u2013 Global step value to record\nfps (python:float or python:int) \u2013 Frames per second\nwalltime (python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\n\n\n\n\nShape:vid_tensor: (N,T,C,H,W)(N, T, C, H, W)(N,T,C,H,W)\n\n", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_video", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": "(string) \u2013 Data identifier"}, {"name": "vid_tensor", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 Video data"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "fps", "is_optional": true, "type": "int", "default_value": "4", "description": "(python:float or python:int) \u2013 Frames per second"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event"}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_audio(tag,snd_tensor,global_step=None,sample_rate=44100,walltime=None)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_audio", "summary": "Add audio data to summary.\n\nParameters\n\ntag (string) \u2013 Data identifier\nsnd_tensor (torch.Tensor) \u2013 Sound data\nglobal_step (python:int) \u2013 Global step value to record\nsample_rate (python:int) \u2013 sample rate in Hz\nwalltime (python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\n\n\n\n\nShape:snd_tensor: (1,L)(1, L)(1,L)\n\n", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_audio", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": "(string) \u2013 Data identifier"}, {"name": "snd_tensor", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 Sound data"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "sample_rate", "is_optional": true, "type": "int", "default_value": "44100", "description": "(python:int) \u2013 sample rate in Hz"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event"}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_text(tag,text_string,global_step=None,walltime=None)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_text", "summary": "Add text data to summary.\n\nParameters\n\ntag (string) \u2013 Data identifier\ntext_string (string) \u2013 String to save\nglobal_step (python:int) \u2013 Global step value to record\nwalltime (python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\n\n\n\nExamples:\nwriter.add_text('lstm', 'This is an lstm', 0)\nwriter.add_text('rnn', 'This is an rnn', 10)\n\n\n", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_text", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": "(string) \u2013 Data identifier"}, {"name": "text_string", "is_optional": false, "type": "string", "description": "(string) \u2013 String to save"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event"}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_graph(model,input_to_model=None,verbose=False)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_graph", "summary": "", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_graph", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "input_to_model", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "verbose", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_embedding(mat,metadata=None,label_img=None,global_step=None,tag='default',metadata_header=None)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_embedding", "summary": "Add embedding projector data to summary.\n\nParameters\n\nmat (torch.Tensor or numpy.array) \u2013 A matrix which each row is the feature vector of the data point\nmetadata (list) \u2013 A list of labels, each element will be convert to string\nlabel_img (torch.Tensor) \u2013 Images correspond to each data point\nglobal_step (python:int) \u2013 Global step value to record\ntag (string) \u2013 Name for the embedding\n\n\n\n\nShape:mat: (N,D)(N, D)(N,D)\n\n, where N is number of data and D is feature dimension\nlabel_img: (N,C,H,W)(N, C, H, W)(N,C,H,W)\n\n\n\n\nExamples:\nimport keyword\nimport torch\nmeta = []\nwhile len(meta)&lt;100:\n    meta = meta+keyword.kwlist # get some strings\nmeta = meta[:100]\n\nfor i, v in enumerate(meta):\n    meta[i] = v+str(i)\n\nlabel_img = torch.rand(100, 3, 10, 32)\nfor i in range(100):\n    label_img[i]*=i/100.0\n\nwriter.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)\nwriter.add_embedding(torch.randn(100, 5), label_img=label_img)\nwriter.add_embedding(torch.randn(100, 5), metadata=meta)\n\n\n", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_embedding", "parameters": [{"name": "mat", "is_optional": false, "type": "tensor", "description": "(torch.Tensor or numpy.array) \u2013 A matrix which each row is the feature vector of the data point"}, {"name": "metadata", "is_optional": true, "type": "others", "default_value": "None", "description": "(list) \u2013 A list of labels, each element will be convert to string"}, {"name": "label_img", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(torch.Tensor) \u2013 Images correspond to each data point"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "tag", "is_optional": true, "type": "string", "default_value": "'default'", "description": ""}, {"name": "metadata_header", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.utils.checkpoint.checkpoint(function,*args,**kwargs)", "id": "torch.utils.checkpoint.checkpoint", "summary": "Checkpoint a model or part of the model\nCheckpointing works by trading compute for memory", "description": "", "code-info": {"name": "torch.utils.checkpoint.checkpoint", "parameters": [{"name": "function", "is_optional": false, "type": "others", "description": ""}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.utils.checkpoint.checkpoint_sequential(functions,segments,*inputs,**kwargs)", "id": "torch.utils.checkpoint.checkpoint_sequential", "summary": "A helper function for checkpointing sequential models.\nSequential models execute a list of modules/functions in order\n(sequentially)", "description": "", "code-info": {"name": "torch.utils.checkpoint.checkpoint_sequential", "parameters": [{"name": "functions", "is_optional": false, "type": "others", "description": ""}, {"name": "segments", "is_optional": false, "type": "others", "description": ""}, {"name": "*inputs", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.FloatStorage.bfloat16()", "id": "torch.FloatStorage.bfloat16", "summary": "Casts this storage to bfloat16 type\n", "description": "", "code-info": {"name": "torch.FloatStorage.bfloat16", "parameters": []}},
{"code": "torch.FloatStorage.bool()", "id": "torch.FloatStorage.bool", "summary": "Casts this storage to bool type\n", "description": "", "code-info": {"name": "torch.FloatStorage.bool", "parameters": []}},
{"code": "torch.FloatStorage.byte()", "id": "torch.FloatStorage.byte", "summary": "Casts this storage to byte type\n", "description": "", "code-info": {"name": "torch.FloatStorage.byte", "parameters": []}},
{"code": "torch.FloatStorage.char()", "id": "torch.FloatStorage.char", "summary": "Casts this storage to char type\n", "description": "", "code-info": {"name": "torch.FloatStorage.char", "parameters": []}},
{"code": "torch.FloatStorage.clone()", "id": "torch.FloatStorage.clone", "summary": "Returns a copy of this storage\n", "description": "", "code-info": {"name": "torch.FloatStorage.clone", "parameters": []}},
{"code": "torch.FloatStorage.copy_()", "id": "torch.FloatStorage.copy_", "summary": "", "description": "", "code-info": {"name": "torch.FloatStorage.copy_", "parameters": []}},
{"code": "torch.FloatStorage.cpu()", "id": "torch.FloatStorage.cpu", "summary": "Returns a CPU copy of this storage if it\u2019s not already on the CPU\n", "description": "", "code-info": {"name": "torch.FloatStorage.cpu", "parameters": []}},
{"code": "torch.FloatStorage.cuda(device=None,non_blocking=False,**kwargs)", "id": "torch.FloatStorage.cuda", "summary": "Returns a copy of this object in CUDA memory.\nIf this object is already in CUDA memory and on the correct device, then\nno copy is performed and the original object is returned.\n\nParameters\n\ndevice (python:int) \u2013 The destination GPU id", "description": "", "code-info": {"name": "torch.FloatStorage.cuda", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 The destination GPU id. Defaults to the current device."}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.FloatStorage.data_ptr()", "id": "torch.FloatStorage.data_ptr", "summary": "", "description": "", "code-info": {"name": "torch.FloatStorage.data_ptr", "parameters": []}},
{"code": "torch.FloatStorage.double()", "id": "torch.FloatStorage.double", "summary": "Casts this storage to double type\n", "description": "", "code-info": {"name": "torch.FloatStorage.double", "parameters": []}},
{"code": "torch.FloatStorage.element_size()", "id": "torch.FloatStorage.element_size", "summary": "", "description": "", "code-info": {"name": "torch.FloatStorage.element_size", "parameters": []}},
{"code": "torch.FloatStorage.fill_()", "id": "torch.FloatStorage.fill_", "summary": "", "description": "", "code-info": {"name": "torch.FloatStorage.fill_", "parameters": []}},
{"code": "torch.FloatStorage.float()", "id": "torch.FloatStorage.float", "summary": "Casts this storage to float type\n", "description": "", "code-info": {"name": "torch.FloatStorage.float", "parameters": []}},
{"code": "torch.FloatStorage.from_buffer()", "id": "torch.FloatStorage.from_buffer", "summary": "", "description": "", "code-info": {"name": "torch.FloatStorage.from_buffer", "parameters": []}},
{"code": "torch.FloatStorage.from_file(filename,shared=False,size=0)", "id": "torch.FloatStorage.from_file", "summary": "If shared is True, then memory is shared between all processes.\nAll changes are written to the file", "description": "", "code-info": {"name": "torch.FloatStorage.from_file", "parameters": [{"name": "filename", "is_optional": false, "type": "others", "description": "(str) \u2013 file name to map"}, {"name": "shared", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 whether to share memory"}, {"name": "size", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 number of elements in the storage"}]}},
{"code": "torch.sparse.addmm(mat,mat1,mat2,beta=1,alpha=1)", "id": "torch.sparse.addmm", "summary": "This function does exact same thing as torch.addmm() in the forward,\nexcept that it supports backward for sparse matrix mat1", "description": "", "code-info": {"name": "torch.sparse.addmm", "parameters": [{"name": "mat", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 a dense matrix to be added"}, {"name": "mat1", "is_optional": false, "type": "tensor", "description": "(SparseTensor) \u2013 a sparse matrix to be multiplied"}, {"name": "mat2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 a dense matrix be multiplied"}, {"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for mat (\u03b2\\beta\u03b2\n\n)"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for mat1@mat2mat1 @ mat2mat1@mat2"}]}},
{"code": "torch.sparse.mm(mat1,mat2)", "id": "torch.sparse.mm", "summary": "Performs a matrix multiplication of the sparse matrix mat1\nand dense matrix mat2", "description": "", "code-info": {"name": "torch.sparse.mm", "parameters": [{"name": "mat1", "is_optional": false, "type": "tensor", "description": "(SparseTensor) \u2013 the first sparse matrix to be multiplied"}, {"name": "mat2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the second dense matrix to be multiplied"}]}},
{"code": "torch.sparse.sum(input,dim=None,dtype=None)", "id": "torch.sparse.sum", "summary": "Returns the sum of each row of SparseTensor input in the given\ndimensions dim", "description": "", "code-info": {"name": "torch.sparse.sum", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input SparseTensor"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or tuple of python:ints) \u2013 a dimension or a list of dimensions to reduce. Default: reduce\nover all dims."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: dtype of input."}]}},
{"code": "torch.sparse.FloatTensor.add()", "id": "torch.sparse.FloatTensor.add", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.add", "parameters": []}},
{"code": "torch.random.fork_rng(devices=None,enabled=True,_caller='fork_rng',_devices_kw='devices')", "id": "torch.random.fork_rng", "summary": "Forks the RNG, so that when you return, the RNG is reset\nto the state that it was previously in.\n\nParameters\n\ndevices (iterable of CUDA IDs) \u2013 CUDA devices for which to fork\nthe RNG", "description": "", "code-info": {"name": "torch.random.fork_rng", "parameters": [{"name": "devices", "is_optional": true, "type": "others", "default_value": "None", "description": "(iterable of CUDA IDs) \u2013 CUDA devices for which to fork\nthe RNG.  CPU RNG state is always forked.  By default, fork_rng() operates\non all devices, but will emit a warning if your machine has a lot\nof devices, since this function will run very slowly in that case.\nIf you explicitly specify devices, this warning will be suppressed"}, {"name": "enabled", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "_caller", "is_optional": true, "type": "string", "default_value": "'fork_rng'", "description": ""}, {"name": "_devices_kw", "is_optional": true, "type": "string", "default_value": "'devices'", "description": ""}]}},
{"code": "torch.random.get_rng_state()", "id": "torch.random.get_rng_state", "summary": "Returns the random number generator state as a torch.ByteTensor.\n", "description": "", "code-info": {"name": "torch.random.get_rng_state", "parameters": []}},
{"code": "torch.random.initial_seed()", "id": "torch.random.initial_seed", "summary": "Returns the initial seed for generating random numbers as a\nPython long.\n", "description": "", "code-info": {"name": "torch.random.initial_seed", "parameters": []}},
{"code": "torch.random.manual_seed(seed)", "id": "torch.random.manual_seed", "summary": "Sets the seed for generating random numbers", "description": "", "code-info": {"name": "torch.random.manual_seed", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": "(python:int) \u2013 The desired seed."}]}},
{"code": "torch.random.seed()", "id": "torch.random.seed", "summary": "Sets the seed for generating random numbers to a non-deterministic\nrandom number", "description": "", "code-info": {"name": "torch.random.seed", "parameters": []}},
{"code": "torch.random.set_rng_state(new_state)", "id": "torch.random.set_rng_state", "summary": "Sets the random number generator state.\n\nParameters\nnew_state (torch.ByteTensor) \u2013 The desired state\n\n\n", "description": "", "code-info": {"name": "torch.random.set_rng_state", "parameters": [{"name": "new_state", "is_optional": false, "type": "tensor", "description": "(torch.ByteTensor) \u2013 The desired state"}]}},
{"code": "sig-prename descclassname()", "id": "sig-prename descclassname", "summary": "Returns the random number generator state as a torch.ByteTensor.\n", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": []}},
{"code": "sig-prename descclassname(new_state)", "id": "sig-prename descclassname", "summary": "Sets the random number generator state.\n\nParameters\nnew_state (torch.ByteTensor) \u2013 The desired state\n\n\n", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "new_state", "is_optional": false, "type": "tensor", "description": "(torch.ByteTensor) \u2013 The desired state"}]}},
{"code": "sig-prename descclassname(seed)", "id": "sig-prename descclassname", "summary": "Sets the seed for generating random numbers", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": "(python:int) \u2013 The desired seed."}]}},
{"code": "sig-prename descclassname()", "id": "sig-prename descclassname", "summary": "Sets the seed for generating random numbers to a non-deterministic\nrandom number", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": []}},
{"code": "sig-prename descclassname()", "id": "sig-prename descclassname", "summary": "Returns the initial seed for generating random numbers as a\nPython long.\n", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": []}},
{"code": "sig-prename descclassname(devices=None,enabled=True,_caller='fork_rng',_devices_kw='devices')", "id": "sig-prename descclassname", "summary": "Forks the RNG, so that when you return, the RNG is reset\nto the state that it was previously in.\n\nParameters\n\ndevices (iterable of CUDA IDs) \u2013 CUDA devices for which to fork\nthe RNG", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "devices", "is_optional": true, "type": "others", "default_value": "None", "description": "(iterable of CUDA IDs) \u2013 CUDA devices for which to fork\nthe RNG.  CPU RNG state is always forked.  By default, fork_rng() operates\non all devices, but will emit a warning if your machine has a lot\nof devices, since this function will run very slowly in that case.\nIf you explicitly specify devices, this warning will be suppressed"}, {"name": "enabled", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "_caller", "is_optional": true, "type": "string", "default_value": "'fork_rng'", "description": ""}, {"name": "_devices_kw", "is_optional": true, "type": "string", "default_value": "'devices'", "description": ""}]}},
{"code": "torch.utils.data.random_split(dataset,lengths)", "id": "torch.utils.data.random_split", "summary": "Randomly split a dataset into non-overlapping new datasets of given lengths.\n\nParameters\n\ndataset (Dataset) \u2013 Dataset to be split\nlengths (sequence) \u2013 lengths of splits to be produced\n\n\n\n", "description": "", "code-info": {"name": "torch.utils.data.random_split", "parameters": [{"name": "dataset", "is_optional": false, "type": "others", "description": "(Dataset) \u2013 Dataset to be split"}, {"name": "lengths", "is_optional": false, "type": "others", "description": "(sequence) \u2013 lengths of splits to be produced"}]}},
{"code": "torch.utils.data.DataLoader(dataset,batch_size=1,shuffle=False,sampler=None,batch_sampler=None,num_workers=0,collate_fn=None,pin_memory=False,drop_last=False,timeout=0,worker_init_fn=None,multiprocessing_context=None)", "id": "torch.utils.data.DataLoader", "summary": "Data loader", "description": "", "code-info": {"name": "torch.utils.data.DataLoader", "parameters": [{"name": "dataset", "is_optional": false, "type": "others", "description": "(Dataset) \u2013 dataset from which to load the data."}, {"name": "batch_size", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 how many samples per batch to load\n(default: 1)."}, {"name": "shuffle", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 set to True to have the data reshuffled\nat every epoch (default: False)."}, {"name": "sampler", "is_optional": true, "type": "others", "default_value": "None", "description": "(Sampler, optional) \u2013 defines the strategy to draw samples from\nthe dataset. If specified, shuffle must be False."}, {"name": "batch_sampler", "is_optional": true, "type": "others", "default_value": "None", "description": "(Sampler, optional) \u2013 like sampler, but returns a batch of\nindices at a time. Mutually exclusive with batch_size,\nshuffle, sampler, and drop_last."}, {"name": "num_workers", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 how many subprocesses to use for data\nloading. 0 means that the data will be loaded in the main process.\n(default: 0)"}, {"name": "collate_fn", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 merges a list of samples to form a\nmini-batch of Tensor(s).  Used when using batched loading from a\nmap-style dataset."}, {"name": "pin_memory", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If True, the data loader will copy Tensors\ninto CUDA pinned memory before returning them.  If your data elements\nare a custom type, or your collate_fn returns a batch that is a custom type,\nsee the example below."}, {"name": "drop_last", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 set to True to drop the last incomplete batch,\nif the dataset size is not divisible by the batch size. If False and\nthe size of dataset is not divisible by the batch size, then the last batch\nwill be smaller. (default: False)"}, {"name": "timeout", "is_optional": true, "type": "int", "default_value": "0", "description": "(numeric, optional) \u2013 if positive, the timeout value for collecting a batch\nfrom workers. Should always be non-negative. (default: 0)"}, {"name": "worker_init_fn", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "multiprocessing_context", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.utils.data.TensorDataset(*tensors)", "id": "torch.utils.data.TensorDataset", "summary": "Dataset wrapping tensors.\nEach sample will be retrieved by indexing tensors along the first dimension.\n\nParameters\n*tensors (Tensor) \u2013 tensors that have the same size of the first dimension.\n\n\n", "description": "", "code-info": {"name": "torch.utils.data.TensorDataset", "parameters": [{"name": "*tensors", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 tensors that have the same size of the first dimension."}]}},
{"code": "torch.utils.data.ConcatDataset(datasets)", "id": "torch.utils.data.ConcatDataset", "summary": "Dataset as a concatenation of multiple datasets.\nThis class is useful to assemble different existing datasets.\n\nParameters\ndatasets (sequence) \u2013 List of datasets to be concatenated\n\n\n", "description": "", "code-info": {"name": "torch.utils.data.ConcatDataset", "parameters": [{"name": "datasets", "is_optional": false, "type": "others", "description": "(sequence) \u2013 List of datasets to be concatenated"}]}},
{"code": "torch.utils.data.ChainDataset(datasets)", "id": "torch.utils.data.ChainDataset", "summary": "Dataset for chainning multiple IterableDataset s.\nThis class is useful to assemble different existing dataset streams", "description": "", "code-info": {"name": "torch.utils.data.ChainDataset", "parameters": [{"name": "datasets", "is_optional": false, "type": "others", "description": "(iterable of IterableDataset) \u2013 datasets to be chained together"}]}},
{"code": "torch.quantization.quantize(model,run_fn,run_args,mapping=None,inplace=False)", "id": "torch.quantization.quantize", "summary": "Converts a float model to quantized model.\nFirst it will prepare the model for calibration or training, then it calls\nrun_fn which will run the calibration step or training step,\nafter that we will call convert which will convert the model to a\nquantized model.\n\nParameters\n\nmodel \u2013 input model\nrun_fn \u2013 a function for evaluating the prepared model, can be a\nfunction that simply runs the prepared model or a training loop\nrun_args \u2013 positional arguments for run_fn\ninplace \u2013 carry out model transformations in-place, the original module is mutated\nmapping \u2013 correspondence between original module types and quantized counterparts\n\n\nReturns\nQuantized model.\n\n\n", "description": "", "code-info": {"name": "torch.quantization.quantize", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "run_fn", "is_optional": false, "type": "others", "description": ""}, {"name": "run_args", "is_optional": false, "type": "others", "description": ""}, {"name": "mapping", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torchvision.models.squeezenet1_1(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.squeezenet1_1", "summary": "SqueezeNet 1.1 model from the official SqueezeNet repo.\nSqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\nthan SqueezeNet 1.0, without sacrificing accuracy.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.squeezenet1_1", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.densenet121(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.densenet121", "summary": "Densenet-121 model from\n\u201cDensely Connected Convolutional Networks\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\nmemory_efficient (bool) \u2013 but slower", "description": "", "code-info": {"name": "torchvision.models.densenet121", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.densenet169(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.densenet169", "summary": "Densenet-169 model from\n\u201cDensely Connected Convolutional Networks\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\nmemory_efficient (bool) \u2013 but slower", "description": "", "code-info": {"name": "torchvision.models.densenet169", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.densenet161(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.densenet161", "summary": "Densenet-161 model from\n\u201cDensely Connected Convolutional Networks\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\nmemory_efficient (bool) \u2013 but slower", "description": "", "code-info": {"name": "torchvision.models.densenet161", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.densenet201(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.densenet201", "summary": "Densenet-201 model from\n\u201cDensely Connected Convolutional Networks\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\nmemory_efficient (bool) \u2013 but slower", "description": "", "code-info": {"name": "torchvision.models.densenet201", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.inception_v3(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.inception_v3", "summary": "Inception v3 model architecture from\n\u201cRethinking the Inception Architecture for Computer Vision\u201d.\n\nNote\nImportant: In contrast to the other models the inception_v3 expects tensors with a size of\nN x 3 x 299 x 299, so ensure your images are sized accordingly.\n\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\naux_logits (bool) \u2013 If True, add an auxiliary branch that can improve training.\nDefault: True\ntransform_input (bool) \u2013 If True, preprocesses the input according to the method with which it\nwas trained on ImageNet", "description": "", "code-info": {"name": "torchvision.models.inception_v3", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.googlenet(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.googlenet", "summary": "GoogLeNet (Inception v1) model architecture from\n\u201cGoing Deeper with Convolutions\u201d.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\naux_logits (bool) \u2013 If True, adds two auxiliary branches that can improve training.\nDefault: False when pretrained is True otherwise True\ntransform_input (bool) \u2013 If True, preprocesses the input according to the method with which it\nwas trained on ImageNet", "description": "", "code-info": {"name": "torchvision.models.googlenet", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.shufflenet_v2_x0_5(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.shufflenet_v2_x0_5", "summary": "Constructs a ShuffleNetV2 with 0.5x output channels, as described in\n\u201cShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\u201d.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.shufflenet_v2_x0_5", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.shufflenet_v2_x1_0(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.shufflenet_v2_x1_0", "summary": "Constructs a ShuffleNetV2 with 1.0x output channels, as described in\n\u201cShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\u201d.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.shufflenet_v2_x1_0", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.shufflenet_v2_x1_5(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.shufflenet_v2_x1_5", "summary": "Constructs a ShuffleNetV2 with 1.5x output channels, as described in\n\u201cShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\u201d.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.shufflenet_v2_x1_5", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.shufflenet_v2_x2_0(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.shufflenet_v2_x2_0", "summary": "Constructs a ShuffleNetV2 with 2.0x output channels, as described in\n\u201cShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\u201d.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.shufflenet_v2_x2_0", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.mobilenet_v2(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.mobilenet_v2", "summary": "Constructs a MobileNetV2 architecture from\n\u201cMobileNetV2: Inverted Residuals and Linear Bottlenecks\u201d.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.mobilenet_v2", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.resnext50_32x4d(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.resnext50_32x4d", "summary": "ResNeXt-50 32x4d model from\n\u201cAggregated Residual Transformation for Deep Neural Networks\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.resnext50_32x4d", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.resnext101_32x8d(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.resnext101_32x8d", "summary": "ResNeXt-101 32x8d model from\n\u201cAggregated Residual Transformation for Deep Neural Networks\u201d\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.resnext101_32x8d", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.wide_resnet50_2(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.wide_resnet50_2", "summary": "Wide ResNet-50-2 model from\n\u201cWide Residual Networks\u201d\nThe model is the same as ResNet except for the bottleneck number of channels\nwhich is twice larger in every block", "description": "", "code-info": {"name": "torchvision.models.wide_resnet50_2", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.wide_resnet101_2(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.wide_resnet101_2", "summary": "Wide ResNet-101-2 model from\n\u201cWide Residual Networks\u201d\nThe model is the same as ResNet except for the bottleneck number of channels\nwhich is twice larger in every block", "description": "", "code-info": {"name": "torchvision.models.wide_resnet101_2", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.mnasnet0_5(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.mnasnet0_5", "summary": "MNASNet with depth multiplier of 0.5 from\n\u201cMnasNet: Platform-Aware Neural Architecture Search for Mobile\u201d.\n:param pretrained: If True, returns a model pre-trained on ImageNet\n:type pretrained: bool\n:param progress: If True, displays a progress bar of the download to stderr\n:type progress: bool\n", "description": "", "code-info": {"name": "torchvision.models.mnasnet0_5", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.utils.cpp_extension.load_inline(name,cpp_sources,cuda_sources=None,functions=None,extra_cflags=None,extra_cuda_cflags=None,extra_ldflags=None,extra_include_paths=None,build_directory=None,verbose=False,with_cuda=None,is_python_module=True,with_pytorch_error_handling=True)", "id": "torch.utils.cpp_extension.load_inline", "summary": "Loads a PyTorch C++ extension just-in-time (JIT) from string sources.\nThis function behaves exactly like load(), but takes its sources as\nstrings rather than filenames", "description": "", "code-info": {"name": "torch.utils.cpp_extension.load_inline", "parameters": [{"name": "name", "is_optional": false, "type": "others", "description": ""}, {"name": "cpp_sources", "is_optional": false, "type": "others", "description": ""}, {"name": "cuda_sources", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "functions", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extra_cflags", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extra_cuda_cflags", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extra_ldflags", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extra_include_paths", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "build_directory", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "verbose", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "with_cuda", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "is_python_module", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "with_pytorch_error_handling", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.utils.cpp_extension.include_paths(cuda=False)", "id": "torch.utils.cpp_extension.include_paths", "summary": "Get the include paths required to build a C++ or CUDA extension.\n\nParameters\ncuda \u2013 If True, includes CUDA-specific include paths.\n\nReturns\nA list of include path strings.\n\n\n", "description": "", "code-info": {"name": "torch.utils.cpp_extension.include_paths", "parameters": [{"name": "cuda", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.utils.cpp_extension.check_compiler_abi_compatibility(compiler)", "id": "torch.utils.cpp_extension.check_compiler_abi_compatibility", "summary": "Verifies that the given compiler is ABI-compatible with PyTorch.\n\nParameters\ncompiler (str) \u2013 The compiler executable name to check (e.g", "description": "", "code-info": {"name": "torch.utils.cpp_extension.check_compiler_abi_compatibility", "parameters": [{"name": "compiler", "is_optional": false, "type": "others", "description": "(str) \u2013 The compiler executable name to check (e.g. g++).\nMust be executable in a shell process."}]}},
{"code": "torch.utils.cpp_extension.verify_ninja_availability()", "id": "torch.utils.cpp_extension.verify_ninja_availability", "summary": "Returns True if the ninja build system is\navailable on the system.\n", "description": "", "code-info": {"name": "torch.utils.cpp_extension.verify_ninja_availability", "parameters": []}},
{"code": "torchvision.datasets.USPS.__getitem__(index)", "id": "torchvision.datasets.USPS.__getitem__", "summary": "\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(image, target) where target is index of the target class.\n\nReturn type\ntuple\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.USPS.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Index"}]}},
{"code": "torchvision.datasets.MNIST(root,train=True,transform=None,target_transform=None,download=False)", "id": "torchvision.datasets.MNIST", "summary": "MNIST Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of dataset where MNIST/processed/training.pt\nand  MNIST/processed/test.pt exist.\ntrain (bool, optional) \u2013 If True, creates dataset from training.pt,\notherwise from test.pt.\ndownload (bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory", "description": "", "code-info": {"name": "torchvision.datasets.MNIST", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of dataset where MNIST/processed/training.pt\nand  MNIST/processed/test.pt exist."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, creates dataset from training.pt,\notherwise from test.pt.\ndownload (bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it.\n\n\n\n"}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again.\ntransform (callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop\ntarget_transform (callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}]}},
{"code": "torchvision.datasets.FashionMNIST(root,train=True,transform=None,target_transform=None,download=False)", "id": "torchvision.datasets.FashionMNIST", "summary": "Fashion-MNIST Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of dataset where Fashion-MNIST/processed/training.pt\nand  Fashion-MNIST/processed/test.pt exist.\ntrain (bool, optional) \u2013 If True, creates dataset from training.pt,\notherwise from test.pt.\ndownload (bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory", "description": "", "code-info": {"name": "torchvision.datasets.FashionMNIST", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of dataset where Fashion-MNIST/processed/training.pt\nand  Fashion-MNIST/processed/test.pt exist."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, creates dataset from training.pt,\notherwise from test.pt.\ndownload (bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it.\n\n\n\n"}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again.\ntransform (callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop\ntarget_transform (callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}]}},
{"code": "torchvision.datasets.KMNIST(root,train=True,transform=None,target_transform=None,download=False)", "id": "torchvision.datasets.KMNIST", "summary": "Kuzushiji-MNIST Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of dataset where KMNIST/processed/training.pt\nand  KMNIST/processed/test.pt exist.\ntrain (bool, optional) \u2013 If True, creates dataset from training.pt,\notherwise from test.pt.\ndownload (bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory", "description": "", "code-info": {"name": "torchvision.datasets.KMNIST", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of dataset where KMNIST/processed/training.pt\nand  KMNIST/processed/test.pt exist."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, creates dataset from training.pt,\notherwise from test.pt.\ndownload (bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it.\n\n\n\n"}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again.\ntransform (callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop\ntarget_transform (callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}]}},
{"code": "torchvision.datasets.EMNIST(root,split,**kwargs)", "id": "torchvision.datasets.EMNIST", "summary": "EMNIST Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of dataset where EMNIST/processed/training.pt\nand  EMNIST/processed/test.pt exist.\nsplit (string) \u2013 The dataset has 6 different splits: byclass, bymerge,\nbalanced, letters, digits and mnist", "description": "", "code-info": {"name": "torchvision.datasets.EMNIST", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of dataset where EMNIST/processed/training.pt\nand  EMNIST/processed/test.pt exist."}, {"name": "split", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.datasets.QMNIST(root,what=None,compat=True,train=True,**kwargs)", "id": "torchvision.datasets.QMNIST", "summary": "QMNIST Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of dataset whose ``processed\u2019\u2019\nsubdir contains torch binary files with the datasets.\nwhat (string,optional) \u2013 Can be \u2018train\u2019, \u2018test\u2019, \u2018test10k\u2019,\n\u2018test50k\u2019, or \u2018nist\u2019 for respectively the mnist compatible\ntraining set, the 60k qmnist testing set, the 10k qmnist\nexamples that match the mnist testing set, the 50k\nremaining qmnist testing examples, or all the nist\ndigits", "description": "", "code-info": {"name": "torchvision.datasets.QMNIST", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of dataset whose ``processed\u2019\u2019\nsubdir contains torch binary files with the datasets."}, {"name": "what", "is_optional": true, "type": "string", "default_value": "None", "description": "(string,optional) \u2013 Can be \u2018train\u2019, \u2018test\u2019, \u2018test10k\u2019,\n\u2018test50k\u2019, or \u2018nist\u2019 for respectively the mnist compatible\ntraining set, the 60k qmnist testing set, the 10k qmnist\nexamples that match the mnist testing set, the 50k\nremaining qmnist testing examples, or all the nist\ndigits. The default is to select \u2018train\u2019 or \u2018test\u2019\naccording to the compatibility argument \u2018train\u2019."}, {"name": "compat", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool,optional) \u2013 A boolean that says whether the target\nfor each example is class number (for compatibility with\nthe MNIST dataloader) or a torch vector containing the\nfull qmnist information. Default=True.\ndownload (bool, optional) \u2013 If true, downloads the dataset from\nthe internet and puts it in root directory. If dataset is\nalready downloaded, it is not downloaded again.\ntransform (callable, optional) \u2013 A function/transform that\ntakes in an PIL image and returns a transformed\nversion. E.g, transforms.RandomCrop\ntarget_transform (callable, optional) \u2013 A function/transform\nthat takes in the target and transforms it."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.datasets.FakeData(size=1000,image_size=(3,224,224)", "id": "torchvision.datasets.FakeData", "summary": "A fake dataset that returns randomly generated images and returns them as PIL images\n\nParameters\n\nsize (python:int, optional) \u2013 Size of the dataset", "description": "", "code-info": {"name": "torchvision.datasets.FakeData", "parameters": [{"name": "size", "is_optional": true, "type": "int", "default_value": "1000", "description": "(python:int, optional) \u2013 Size of the dataset. Default: 1000 images"}, {"name": "image_size", "is_optional": false, "type": "others", "description": "(tuple, optional) \u2013 Size if the returned images. Default: (3, 224, 224)\nnum_classes (python:int, optional) \u2013 Number of classes in the datset. Default: 10\ntransform (callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop\ntarget_transform (callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it.\nrandom_offset (python:int) \u2013 Offsets the index-based random seed used to\ngenerate each image. Default: 0"}]}},
{"code": "torchvision.datasets.CocoCaptions(root,annFile,transform=None,target_transform=None,transforms=None)", "id": "torchvision.datasets.CocoCaptions", "summary": "MS Coco Captions Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory where images are downloaded to.\nannFile (string) \u2013 Path to json annotation file.\ntransform (callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version", "description": "", "code-info": {"name": "torchvision.datasets.CocoCaptions", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory where images are downloaded to."}, {"name": "annFile", "is_optional": false, "type": "string", "description": "(string) \u2013 Path to json annotation file."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.ToTensor"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}, {"name": "transforms", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes input sample and its target as entry\nand returns a transformed version."}]}},
{"code": "torchvision.datasets.CocoDetection(root,annFile,transform=None,target_transform=None,transforms=None)", "id": "torchvision.datasets.CocoDetection", "summary": "MS Coco Detection Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory where images are downloaded to.\nannFile (string) \u2013 Path to json annotation file.\ntransform (callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version", "description": "", "code-info": {"name": "torchvision.datasets.CocoDetection", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory where images are downloaded to."}, {"name": "annFile", "is_optional": false, "type": "string", "description": "(string) \u2013 Path to json annotation file."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.ToTensor"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}, {"name": "transforms", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes input sample and its target as entry\nand returns a transformed version."}]}},
{"code": "torchvision.datasets.LSUN(root,classes='train',transform=None,target_transform=None)", "id": "torchvision.datasets.LSUN", "summary": "LSUN dataset.\n\nParameters\n\nroot (string) \u2013 Root directory for the database files.\nclasses (string or list) \u2013 One of {\u2018train\u2019, \u2018val\u2019, \u2018test\u2019} or a list of\ncategories to load", "description": "", "code-info": {"name": "torchvision.datasets.LSUN", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory for the database files."}, {"name": "classes", "is_optional": true, "type": "string", "default_value": "'train'", "description": "(string or list) \u2013 One of {\u2018train\u2019, \u2018val\u2019, \u2018test\u2019} or a list of\ncategories to load. e,g. [\u2018bedroom_train\u2019, \u2018church_train\u2019]."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}]}},
{"code": "torchvision.datasets.ImageFolder(root,transform=None,target_transform=None,loader=&lt;functiondefault_loader&gt;,is_valid_file=None)", "id": "torchvision.datasets.ImageFolder", "summary": "A generic data loader where the images are arranged in this way:\nroot/dog/xxx.png\nroot/dog/xxy.png\nroot/dog/xxz.png\n\nroot/cat/123.png\nroot/cat/nsdf3.png\nroot/cat/asd932_.png\n\n\n\nParameters\n\nroot (string) \u2013 Root directory path.\ntransform (callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version", "description": "", "code-info": {"name": "torchvision.datasets.ImageFolder", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory path."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}, {"name": "loader", "is_optional": true, "type": "others", "default_value": "&lt;functiondefault_loader&gt;", "description": ""}, {"name": "is_valid_file", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torchvision.datasets.DatasetFolder(root,loader,extensions=None,transform=None,target_transform=None,is_valid_file=None)", "id": "torchvision.datasets.DatasetFolder", "summary": "A generic data loader where the samples are arranged in this way:\nroot/class_x/xxx.ext\nroot/class_x/xxy.ext\nroot/class_x/xxz.ext\n\nroot/class_y/123.ext\nroot/class_y/nsdf3.ext\nroot/class_y/asd932_.ext\n\n\n\nParameters\n\nroot (string) \u2013 Root directory path.\nloader (callable) \u2013 A function to load a sample given its path.\nextensions (tuple[string]) \u2013 A list of allowed extensions.\nboth extensions and is_valid_file should not be passed.\ntransform (callable, optional) \u2013 A function/transform that takes in\na sample and returns a transformed version.\nE.g, transforms.RandomCrop for images.\ntarget_transform (callable, optional) \u2013 A function/transform that takes\nin the target and transforms it.\nis_valid_file \u2013 A function that takes path of a file\nand check if the file is a valid file (used to check of corrupt files)\nboth extensions and is_valid_file should not be passed.\n\n\n\n\n\n__getitem__(index) \u00b6\n\nParameters\nindex (python:int) \u2013 Index\n\nReturns\n(sample, target) where target is class_index of the target class.\n\nReturn type\ntuple\n\n\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.DatasetFolder", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory path."}, {"name": "loader", "is_optional": false, "type": "others", "description": "(callable) \u2013 A function to load a sample given its path."}, {"name": "extensions", "is_optional": true, "type": "string", "default_value": "None", "description": "(tuple[string]) \u2013 A list of allowed extensions.\nboth extensions and is_valid_file should not be passed."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in\na sample and returns a transformed version.\nE.g, transforms.RandomCrop for images."}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "is_valid_file", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torchvision.transforms.RandomPerspective(distortion_scale=0.5,p=0.5,interpolation=3)", "id": "torchvision.transforms.RandomPerspective", "summary": "Performs Perspective transformation of the given PIL Image randomly with a given probability.\n\nParameters\n\ninterpolation \u2013 Default- Image.BICUBIC\np (python:float) \u2013 probability of the image being perspectively transformed", "description": "", "code-info": {"name": "torchvision.transforms.RandomPerspective", "parameters": [{"name": "distortion_scale", "is_optional": true, "type": "float", "default_value": "0.5", "description": "(python:float) \u2013 it controls the degree of distortion and ranges from 0 to 1. Default value is 0.5.\n\n\n\n"}, {"name": "p", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}, {"name": "interpolation", "is_optional": true, "type": "int", "default_value": "3", "description": ""}]}},
{"code": "torchvision.transforms.RandomResizedCrop(size,scale=(0.08,1.0)", "id": "torchvision.transforms.RandomResizedCrop", "summary": "Crop the given PIL Image to random size and aspect ratio.\nA crop of random size (default: of 0.08 to 1.0) of the original size and a random\naspect ratio (default: of 3/4 to 4/3) of the original aspect ratio is made", "description": "", "code-info": {"name": "torchvision.transforms.RandomResizedCrop", "parameters": [{"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "scale", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.transforms.RandomRotation(degrees,resample=False,expand=False,center=None,fill=0)", "id": "torchvision.transforms.RandomRotation", "summary": "Rotate the image by angle.\n\nParameters\n\ndegrees (sequence or python:float or python:int) \u2013 Range of degrees to select from.\nIf degrees is a number instead of sequence like (min, max), the range of degrees\nwill be (-degrees, +degrees).\nresample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional) \u2013 An optional resampling filter", "description": "", "code-info": {"name": "torchvision.transforms.RandomRotation", "parameters": [{"name": "degrees", "is_optional": false, "type": "int", "description": "(sequence or python:float or python:int) \u2013 Range of degrees to select from.\nIf degrees is a number instead of sequence like (min, max), the range of degrees\nwill be (-degrees, +degrees)."}, {"name": "resample", "is_optional": true, "type": "bool", "default_value": "False", "description": "({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional) \u2013 An optional resampling filter. See filters for more information.\nIf omitted, or if the image has mode \u201c1\u201d or \u201cP\u201d, it is set to PIL.Image.NEAREST."}, {"name": "expand", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Optional expansion flag.\nIf true, expands the output to make it large enough to hold the entire rotated image.\nIf false or omitted, make the output image the same size as the input image.\nNote that the expand flag assumes rotation around the center and no translation."}, {"name": "center", "is_optional": true, "type": "others", "default_value": "None", "description": "(2-tuple, optional) \u2013 Optional center of rotation.\nOrigin is the upper left corner.\nDefault is the center of the image."}, {"name": "fill", "is_optional": true, "type": "int", "default_value": "0", "description": "(3-tuple or python:int) \u2013 RGB pixel fill value for area outside the rotated image.\nIf int, it is used for all channels respectively."}]}},
{"code": "torchvision.transforms.RandomSizedCrop(*args,**kwargs)", "id": "torchvision.transforms.RandomSizedCrop", "summary": "Note: This transform is deprecated in favor of RandomResizedCrop.\n", "description": "", "code-info": {"name": "torchvision.transforms.RandomSizedCrop", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.transforms.RandomVerticalFlip(p=0.5)", "id": "torchvision.transforms.RandomVerticalFlip", "summary": "Vertically flip the given PIL Image randomly with a given probability.\n\nParameters\np (python:float) \u2013 probability of the image being flipped", "description": "", "code-info": {"name": "torchvision.transforms.RandomVerticalFlip", "parameters": [{"name": "p", "is_optional": true, "type": "float", "default_value": "0.5", "description": "(python:float) \u2013 probability of the image being flipped. Default value is 0.5"}]}},
{"code": "torchvision.transforms.Resize(size,interpolation=2)", "id": "torchvision.transforms.Resize", "summary": "Resize the input PIL Image to the given size.\n\nParameters\n\nsize (sequence or python:int) \u2013 Desired output size", "description": "", "code-info": {"name": "torchvision.transforms.Resize", "parameters": [{"name": "size", "is_optional": false, "type": "int", "description": "(sequence or python:int) \u2013 Desired output size. If size is a sequence like\n(h, w), output size will be matched to this. If size is an int,\nsmaller edge of the image will be matched to this number.\ni.e, if height &gt; width, then image will be rescaled to\n(size * height / width, size)"}, {"name": "interpolation", "is_optional": true, "type": "int", "default_value": "2", "description": "(python:int, optional) \u2013 Desired interpolation. Default is\nPIL.Image.BILINEAR"}]}},
{"code": "torchvision.transforms.Scale(*args,**kwargs)", "id": "torchvision.transforms.Scale", "summary": "Note: This transform is deprecated in favor of Resize.\n", "description": "", "code-info": {"name": "torchvision.transforms.Scale", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.transforms.TenCrop(size,vertical_flip=False)", "id": "torchvision.transforms.TenCrop", "summary": "Crop the given PIL Image into four corners and the central crop plus the flipped version of\nthese (horizontal flipping is used by default)\n\nNote\nThis transform returns a tuple of images and there may be a mismatch in the number of\ninputs and targets your Dataset returns", "description": "", "code-info": {"name": "torchvision.transforms.TenCrop", "parameters": [{"name": "size", "is_optional": false, "type": "int", "description": "(sequence or python:int) \u2013 Desired output size of the crop. If size is an\nint instead of sequence like (h, w), a square crop (size, size) is\nmade."}, {"name": "vertical_flip", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 Use vertical flipping instead of horizontal"}]}},
{"code": "torchvision.transforms.LinearTransformation(transformation_matrix,mean_vector)", "id": "torchvision.transforms.LinearTransformation", "summary": "Transform a tensor image with a square transformation matrix and a mean_vector computed\noffline.\nGiven transformation_matrix and mean_vector, will flatten the torch.*Tensor and\nsubtract mean_vector from it which is then followed by computing the dot\nproduct with the transformation matrix and then reshaping the tensor to its\noriginal shape.\n\nApplications:whitening transformation: Suppose X is a column vector zero-centered data.\nThen compute the data covariance matrix [D x D] with torch.mm(X.t(), X),\nperform SVD on this matrix and pass it as transformation_matrix.\n\n\n\nParameters\n\ntransformation_matrix (Tensor) \u2013 tensor [D x D], D = C x H x W\nmean_vector (Tensor) \u2013 tensor [D], D = C x H x W\n\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.LinearTransformation", "parameters": [{"name": "transformation_matrix", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 tensor [D x D], D = C x H x W"}, {"name": "mean_vector", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 tensor [D], D = C x H x W"}]}},
{"code": "torchvision.transforms.Normalize(mean,std,inplace=False)", "id": "torchvision.transforms.Normalize", "summary": "Normalize a tensor image with mean and standard deviation.\nGiven mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels, this transform\nwill normalize each channel of the input torch.*Tensor i.e.\ninput[channel] = (input[channel] - mean[channel]) / std[channel]\n\nNote\nThis transform acts out of place, i.e., it does not mutates the input tensor.\n\n\nParameters\n\nmean (sequence) \u2013 Sequence of means for each channel.\nstd (sequence) \u2013 Sequence of standard deviations for each channel.\ninplace (bool,optional) \u2013 Bool to make this operation in-place.\n\n\n\n\n\n__call__(tensor) \u00b6\n\nParameters\ntensor (Tensor) \u2013 Tensor image of size (C, H, W) to be normalized.\n\nReturns\nNormalized Tensor image.\n\nReturn type\nTensor\n\n\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.Normalize", "parameters": [{"name": "mean", "is_optional": false, "type": "others", "description": "(sequence) \u2013 Sequence of means for each channel."}, {"name": "std", "is_optional": false, "type": "others", "description": "(sequence) \u2013 Sequence of standard deviations for each channel."}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool,optional) \u2013 Bool to make this operation in-place."}]}},
{"code": "torchvision.transforms.RandomErasing(p=0.5,scale=(0.02,0.33)", "id": "torchvision.transforms.RandomErasing", "summary": "\nRandomly selects a rectangle region in an image and erases its pixels.\u2018Random Erasing Data Augmentation\u2019 by Zhong et al.\nSee https://arxiv.org/pdf/1708.04896.pdf\n\n\n\nParameters\n\np \u2013 probability that the random erasing operation will be performed.\nscale \u2013 range of proportion of erased area against input image.\nratio \u2013 range of aspect ratio of erased area.\nvalue \u2013 erasing value", "description": "", "code-info": {"name": "torchvision.transforms.RandomErasing", "parameters": [{"name": "p", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}, {"name": "scale", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.transforms.ToPILImage(mode=None)", "id": "torchvision.transforms.ToPILImage", "summary": "Convert a tensor or an ndarray to PIL Image.\nConverts a torch.*Tensor of shape C x H x W or a numpy ndarray of shape\nH x W x C to a PIL Image while preserving the value range.\n\nParameters\nmode (PIL.Image mode) \u2013 color space and pixel depth of input data (optional).\nIf mode is None (default) there are some assumptions made about the input data:\n\n\nIf the input has 4 channels, the mode is assumed to be RGBA.\nIf the input has 3 channels, the mode is assumed to be RGB.\nIf the input has 2 channels, the mode is assumed to be LA.\nIf the input has 1 channel, the mode is determined by the data type (i.e int, float,\nshort).\n\n\n\n\n\n\n\n__call__(pic) \u00b6\n\nParameters\npic (Tensor or numpy.ndarray) \u2013 Image to be converted to PIL Image.\n\nReturns\nImage converted to PIL Image.\n\nReturn type\nPIL Image\n\n\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.ToPILImage", "parameters": [{"name": "mode", "is_optional": true, "type": "others", "default_value": "None", "description": "(PIL.Image mode) \u2013 color space and pixel depth of input data (optional).\nIf mode is None (default) there are some assumptions made about the input data:"}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve(tag,labels,predictions,global_step=None,num_thresholds=127,weights=None,walltime=None)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve", "summary": "Adds precision recall curve.\nPlotting a precision-recall curve lets you understand your model\u2019s\nperformance under different threshold settings", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": "(string) \u2013 Data identifier"}, {"name": "labels", "is_optional": false, "type": "tensor", "description": "(torch.Tensor, numpy.array, or string/blobname) \u2013 Ground truth data. Binary label for each element."}, {"name": "predictions", "is_optional": false, "type": "tensor", "description": "(torch.Tensor, numpy.array, or string/blobname) \u2013 The probability that an element be classified as true.\nValue should in [0, 1]"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "num_thresholds", "is_optional": true, "type": "int", "default_value": "127", "description": ""}, {"name": "weights", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event"}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars(layout)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars", "summary": "Create special chart by collecting charts tags in \u2018scalars\u2019", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars", "parameters": [{"name": "layout", "is_optional": false, "type": "others", "description": "(dict) \u2013 {categoryName: charts}, where charts is also a dictionary\n{chartName: ListOfProperties}. The first element in ListOfProperties is the chart\u2019s type\n(one of Multiline or Margin) and the second element should be a list containing the tags\nyou have used in add_scalar function, which will be collected into the new chart."}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_mesh(tag,vertices,colors=None,faces=None,config_dict=None,global_step=None,walltime=None)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_mesh", "summary": "Add meshes or 3D point clouds to TensorBoard", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_mesh", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": "(string) \u2013 Data identifier"}, {"name": "vertices", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 List of the 3D coordinates of vertices."}, {"name": "colors", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(torch.Tensor) \u2013 Colors for each vertex"}, {"name": "faces", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "config_dict", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event"}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.add_hparams(hparam_dict=None,metric_dict=None)", "id": "torch.utils.tensorboard.writer.SummaryWriter.add_hparams", "summary": "Add a set of hyperparameters to be compared in TensorBoard.\n\nParameters\n\nhparam_dict (dict) \u2013 Each key-value pair in the dictionary is the\nname of the hyper parameter and it\u2019s corresponding value.\nmetric_dict (dict) \u2013 Each key-value pair in the dictionary is the\nname of the metric and it\u2019s corresponding value", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_hparams", "parameters": [{"name": "hparam_dict", "is_optional": true, "type": "others", "default_value": "None", "description": "(dict) \u2013 Each key-value pair in the dictionary is the\nname of the hyper parameter and it\u2019s corresponding value."}, {"name": "metric_dict", "is_optional": true, "type": "others", "default_value": "None", "description": "(dict) \u2013 Each key-value pair in the dictionary is the\nname of the metric and it\u2019s corresponding value. Note that the key used\nhere should be unique in the tensorboard record. Otherwise the value\nyou added by add_scalar will be displayed in hparam plugin. In most\ncases, this is unwanted."}]}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.flush()", "id": "torch.utils.tensorboard.writer.SummaryWriter.flush", "summary": "Flushes the event file to disk.\nCall this method to make sure that all pending events have been written to\ndisk.\n", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.flush", "parameters": []}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter.close()", "id": "torch.utils.tensorboard.writer.SummaryWriter.close", "summary": "", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.close", "parameters": []}},
{"code": "torch.utils.tensorboard.writer.SummaryWriter(log_dir=None,comment='',purge_step=None,max_queue=10,flush_secs=120,filename_suffix='')", "id": "torch.utils.tensorboard.writer.SummaryWriter", "summary": "Writes entries directly to event files in the log_dir to be\nconsumed by TensorBoard.\nThe SummaryWriter class provides a high-level API to create an event file\nin a given directory and add summaries and events to it", "description": "", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter", "parameters": [{"name": "log_dir", "is_optional": true, "type": "string", "default_value": "None", "description": "(string) \u2013 Save directory location. Default is\nruns/CURRENT_DATETIME_HOSTNAME, which changes after each run.\nUse hierarchical folder structure to compare\nbetween runs easily. e.g. pass in \u2018runs/exp1\u2019, \u2018runs/exp2\u2019, etc.\nfor each new experiment to compare across them."}, {"name": "comment", "is_optional": true, "type": "string", "default_value": "''", "description": "(string) \u2013 Comment log_dir suffix appended to the default\nlog_dir. If log_dir is assigned, this argument has no effect."}, {"name": "purge_step", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 When logging crashes at step T+XT+XT+X\n\n and restarts at step TTT\n\n,\nany events whose global_step larger or equal to TTT\n\n will be\npurged and hidden from TensorBoard.\nNote that crashed and resumed experiments should have the same log_dir."}, {"name": "max_queue", "is_optional": true, "type": "int", "default_value": "10", "description": "(python:int) \u2013 Size of the queue for pending events and\nsummaries before one of the \u2018add\u2019 calls forces a flush to disk.\nDefault is ten items."}, {"name": "flush_secs", "is_optional": true, "type": "int", "default_value": "120", "description": "(python:int) \u2013 How often, in seconds, to flush the\npending events and summaries to disk. Default is every two minutes."}, {"name": "filename_suffix", "is_optional": true, "type": "string", "default_value": "''", "description": "(string) \u2013 Suffix added to all event filenames in\nthe log_dir directory. More details on filename construction in\ntensorboard.summary.writer.event_file_writer.EventFileWriter."}]}},
{"code": "torch.FloatStorage.half()", "id": "torch.FloatStorage.half", "summary": "Casts this storage to half type\n", "description": "", "code-info": {"name": "torch.FloatStorage.half", "parameters": []}},
{"code": "torch.FloatStorage.int()", "id": "torch.FloatStorage.int", "summary": "Casts this storage to int type\n", "description": "", "code-info": {"name": "torch.FloatStorage.int", "parameters": []}},
{"code": "torch.FloatStorage.is_pinned()", "id": "torch.FloatStorage.is_pinned", "summary": "", "description": "", "code-info": {"name": "torch.FloatStorage.is_pinned", "parameters": []}},
{"code": "torch.FloatStorage.is_shared()", "id": "torch.FloatStorage.is_shared", "summary": "", "description": "", "code-info": {"name": "torch.FloatStorage.is_shared", "parameters": []}},
{"code": "torch.FloatStorage.long()", "id": "torch.FloatStorage.long", "summary": "Casts this storage to long type\n", "description": "", "code-info": {"name": "torch.FloatStorage.long", "parameters": []}},
{"code": "torch.FloatStorage.new()", "id": "torch.FloatStorage.new", "summary": "", "description": "", "code-info": {"name": "torch.FloatStorage.new", "parameters": []}},
{"code": "torch.FloatStorage.pin_memory()", "id": "torch.FloatStorage.pin_memory", "summary": "Copies the storage to pinned memory, if it\u2019s not already pinned.\n", "description": "", "code-info": {"name": "torch.FloatStorage.pin_memory", "parameters": []}},
{"code": "torch.FloatStorage.resize_()", "id": "torch.FloatStorage.resize_", "summary": "", "description": "", "code-info": {"name": "torch.FloatStorage.resize_", "parameters": []}},
{"code": "torch.FloatStorage.share_memory_()", "id": "torch.FloatStorage.share_memory_", "summary": "Moves the storage to shared memory.\nThis is a no-op for storages already in shared memory and for CUDA\nstorages, which do not need to be moved for sharing across processes.\nStorages in shared memory cannot be resized.\nReturns: self\n", "description": "", "code-info": {"name": "torch.FloatStorage.share_memory_", "parameters": []}},
{"code": "torch.FloatStorage.short()", "id": "torch.FloatStorage.short", "summary": "Casts this storage to short type\n", "description": "", "code-info": {"name": "torch.FloatStorage.short", "parameters": []}},
{"code": "torch.FloatStorage.size()", "id": "torch.FloatStorage.size", "summary": "", "description": "", "code-info": {"name": "torch.FloatStorage.size", "parameters": []}},
{"code": "torch.FloatStorage.tolist()", "id": "torch.FloatStorage.tolist", "summary": "Returns a list containing the elements of this storage\n", "description": "", "code-info": {"name": "torch.FloatStorage.tolist", "parameters": []}},
{"code": "torch.FloatStorage.type(dtype=None,non_blocking=False,**kwargs)", "id": "torch.FloatStorage.type", "summary": "Returns the type if dtype is not provided, else casts this object to\nthe specified type.\nIf this is already of the correct type, no copy is performed and the\noriginal object is returned.\n\nParameters\n\ndtype (python:type or string) \u2013 The desired type\nnon_blocking (bool) \u2013 If True, and the source is in pinned memory\nand destination is on the GPU or vice versa, the copy is performed\nasynchronously with respect to the host", "description": "", "code-info": {"name": "torch.FloatStorage.type", "parameters": [{"name": "dtype", "is_optional": true, "type": "string", "default_value": "None", "description": "(python:type or string) \u2013 The desired type"}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.sparse.FloatTensor.add_()", "id": "torch.sparse.FloatTensor.add_", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.add_", "parameters": []}},
{"code": "torch.sparse.FloatTensor.clone()", "id": "torch.sparse.FloatTensor.clone", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.clone", "parameters": []}},
{"code": "torch.sparse.FloatTensor.dim()", "id": "torch.sparse.FloatTensor.dim", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.dim", "parameters": []}},
{"code": "torch.sparse.FloatTensor.div()", "id": "torch.sparse.FloatTensor.div", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.div", "parameters": []}},
{"code": "torch.sparse.FloatTensor.div_()", "id": "torch.sparse.FloatTensor.div_", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.div_", "parameters": []}},
{"code": "torch.sparse.FloatTensor.get_device()", "id": "torch.sparse.FloatTensor.get_device", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.get_device", "parameters": []}},
{"code": "torch.sparse.FloatTensor.hspmm()", "id": "torch.sparse.FloatTensor.hspmm", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.hspmm", "parameters": []}},
{"code": "torch.sparse.FloatTensor.mm()", "id": "torch.sparse.FloatTensor.mm", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.mm", "parameters": []}},
{"code": "torch.sparse.FloatTensor.mul()", "id": "torch.sparse.FloatTensor.mul", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.mul", "parameters": []}},
{"code": "torch.sparse.FloatTensor.mul_()", "id": "torch.sparse.FloatTensor.mul_", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.mul_", "parameters": []}},
{"code": "torch.sparse.FloatTensor.narrow_copy()", "id": "torch.sparse.FloatTensor.narrow_copy", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.narrow_copy", "parameters": []}},
{"code": "torch.sparse.FloatTensor.resizeAs_()", "id": "torch.sparse.FloatTensor.resizeAs_", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.resizeAs_", "parameters": []}},
{"code": "torch.sparse.FloatTensor.size()", "id": "torch.sparse.FloatTensor.size", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.size", "parameters": []}},
{"code": "torch.sparse.FloatTensor.spadd()", "id": "torch.sparse.FloatTensor.spadd", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.spadd", "parameters": []}},
{"code": "torch.sparse.FloatTensor.spmm()", "id": "torch.sparse.FloatTensor.spmm", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.spmm", "parameters": []}},
{"code": "torch.sparse.FloatTensor.sspaddmm()", "id": "torch.sparse.FloatTensor.sspaddmm", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.sspaddmm", "parameters": []}},
{"code": "torch.sparse.FloatTensor.sspmm()", "id": "torch.sparse.FloatTensor.sspmm", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.sspmm", "parameters": []}},
{"code": "torch.sparse.FloatTensor.sub()", "id": "torch.sparse.FloatTensor.sub", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.sub", "parameters": []}},
{"code": "torch.sparse.FloatTensor.sub_()", "id": "torch.sparse.FloatTensor.sub_", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.sub_", "parameters": []}},
{"code": "torch.sparse.FloatTensor.t_()", "id": "torch.sparse.FloatTensor.t_", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.t_", "parameters": []}},
{"code": "torch.utils.data.Subset(dataset,indices)", "id": "torch.utils.data.Subset", "summary": "Subset of a dataset at specified indices.\n\nParameters\n\ndataset (Dataset) \u2013 The whole Dataset\nindices (sequence) \u2013 Indices in the whole set selected for subset\n\n\n\n", "description": "", "code-info": {"name": "torch.utils.data.Subset", "parameters": [{"name": "dataset", "is_optional": false, "type": "others", "description": "(Dataset) \u2013 The whole Dataset"}, {"name": "indices", "is_optional": false, "type": "others", "description": "(sequence) \u2013 Indices in the whole set selected for subset"}]}},
{"code": "torch.utils.data.Sampler(data_source)", "id": "torch.utils.data.Sampler", "summary": "Base class for all Samplers.\nEvery Sampler subclass has to provide an __iter__() method, providing a\nway to iterate over indices of dataset elements, and a __len__() method\nthat returns the length of the returned iterators.\n\nNote\nThe __len__() method isn\u2019t strictly required by\nDataLoader, but is expected in any\ncalculation involving the length of a DataLoader.\n\n", "description": "", "code-info": {"name": "torch.utils.data.Sampler", "parameters": [{"name": "data_source", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.utils.data.SequentialSampler(data_source)", "id": "torch.utils.data.SequentialSampler", "summary": "Samples elements sequentially, always in the same order.\n\nParameters\ndata_source (Dataset) \u2013 dataset to sample from\n\n\n", "description": "", "code-info": {"name": "torch.utils.data.SequentialSampler", "parameters": [{"name": "data_source", "is_optional": false, "type": "others", "description": "(Dataset) \u2013 dataset to sample from"}]}},
{"code": "torch.utils.data.RandomSampler(data_source,replacement=False,num_samples=None)", "id": "torch.utils.data.RandomSampler", "summary": "Samples elements randomly", "description": "", "code-info": {"name": "torch.utils.data.RandomSampler", "parameters": [{"name": "data_source", "is_optional": false, "type": "others", "description": "(Dataset) \u2013 dataset to sample from"}, {"name": "replacement", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 samples are drawn with replacement if True, default=``False``"}, {"name": "num_samples", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 number of samples to draw, default=`len(dataset)`. This argument\nis supposed to be specified only when replacement is True."}]}},
{"code": "torch.utils.data.SubsetRandomSampler(indices)", "id": "torch.utils.data.SubsetRandomSampler", "summary": "Samples elements randomly from a given list of indices, without replacement.\n\nParameters\nindices (sequence) \u2013 a sequence of indices\n\n\n", "description": "", "code-info": {"name": "torch.utils.data.SubsetRandomSampler", "parameters": [{"name": "indices", "is_optional": false, "type": "others", "description": "(sequence) \u2013 a sequence of indices"}]}},
{"code": "torch.utils.data.WeightedRandomSampler(weights,num_samples,replacement=True)", "id": "torch.utils.data.WeightedRandomSampler", "summary": "Samples elements from [0,..,len(weights)-1] with given probabilities (weights).\n\nParameters\n\nweights (sequence) \u2013 a sequence of weights, not necessary summing up to one\nnum_samples (python:int) \u2013 number of samples to draw\nreplacement (bool) \u2013 if True, samples are drawn with replacement.\nIf not, they are drawn without replacement, which means that when a\nsample index is drawn for a row, it cannot be drawn again for that row.\n\n\n\nExample\n&gt;&gt;&gt; list(WeightedRandomSampler([0.1, 0.9, 0.4, 0.7, 3.0, 0.6], 5, replacement=True))\n[0, 0, 0, 1, 0]\n&gt;&gt;&gt; list(WeightedRandomSampler([0.9, 0.4, 0.05, 0.2, 0.3, 0.1], 5, replacement=False))\n[0, 1, 4, 3, 2]\n\n\n", "description": "", "code-info": {"name": "torch.utils.data.WeightedRandomSampler", "parameters": [{"name": "weights", "is_optional": false, "type": "others", "description": "(sequence) \u2013 a sequence of weights, not necessary summing up to one"}, {"name": "num_samples", "is_optional": false, "type": "int", "description": "(python:int) \u2013 number of samples to draw"}, {"name": "replacement", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 if True, samples are drawn with replacement.\nIf not, they are drawn without replacement, which means that when a\nsample index is drawn for a row, it cannot be drawn again for that row."}]}},
{"code": "torch.utils.data.BatchSampler(sampler,batch_size,drop_last)", "id": "torch.utils.data.BatchSampler", "summary": "Wraps another sampler to yield a mini-batch of indices.\n\nParameters\n\nsampler (Sampler) \u2013 Base sampler.\nbatch_size (python:int) \u2013 Size of mini-batch.\ndrop_last (bool) \u2013 If True, the sampler will drop the last batch if\nits size would be less than batch_size\n\n\n\nExample\n&gt;&gt;&gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))\n[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n&gt;&gt;&gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))\n[[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n\n\n", "description": "", "code-info": {"name": "torch.utils.data.BatchSampler", "parameters": [{"name": "sampler", "is_optional": false, "type": "others", "description": "(Sampler) \u2013 Base sampler."}, {"name": "batch_size", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Size of mini-batch."}, {"name": "drop_last", "is_optional": false, "type": "bool", "description": "(bool) \u2013 If True, the sampler will drop the last batch if\nits size would be less than batch_size"}]}},
{"code": "torch.utils.data.distributed.DistributedSampler(dataset,num_replicas=None,rank=None,shuffle=True)", "id": "torch.utils.data.distributed.DistributedSampler", "summary": "Sampler that restricts data loading to a subset of the dataset.\nIt is especially useful in conjunction with\ntorch.nn.parallel.DistributedDataParallel", "description": "", "code-info": {"name": "torch.utils.data.distributed.DistributedSampler", "parameters": [{"name": "dataset", "is_optional": false, "type": "others", "description": ""}, {"name": "num_replicas", "is_optional": true, "type": "others", "default_value": "None", "description": "(optional) \u2013 Number of processes participating in\ndistributed training."}, {"name": "rank", "is_optional": true, "type": "others", "default_value": "None", "description": "(optional) \u2013 Rank of the current process within num_replicas."}, {"name": "shuffle", "is_optional": true, "type": "bool", "default_value": "True", "description": "(optional) \u2013 If true (default), sampler will shuffle the indices"}]}},
{"code": "torch.quantization.quantize_dynamic(model,qconfig_spec=None,dtype=torch.qint8,mapping=None,inplace=False)", "id": "torch.quantization.quantize_dynamic", "summary": "Converts a float model to dynamic (i.e", "description": "", "code-info": {"name": "torch.quantization.quantize_dynamic", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "qconfig_spec", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.qint8", "description": ""}, {"name": "mapping", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.quantization.quantize_qat(model,run_fn,run_args,inplace=False)", "id": "torch.quantization.quantize_qat", "summary": "Do quantization aware training and output a quantized model\n\nParameters\n\nmodel \u2013 input model\nrun_fn \u2013 a function for evaluating the prepared model, can be a\nfunction that simply runs the prepared model or a training\nloop\nrun_args \u2013 positional arguments for run_fn\n\n\nReturns\nQuantized model.\n\n\n", "description": "", "code-info": {"name": "torch.quantization.quantize_qat", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "run_fn", "is_optional": false, "type": "others", "description": ""}, {"name": "run_args", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.quantization.prepare(model,qconfig_dict=None,inplace=False)", "id": "torch.quantization.prepare", "summary": "Prepares a copy of the model for quantization calibration or quantization-aware training.\nQuantization configuration can be passed as an qconfig_dict or assigned preemptively\nto individual submodules in .qconfig attribute.\nThe model will be attached with observer or fake quant modules, and qconfig\nwill be propagated.\n\nParameters\n\nmodel \u2013 input model to be modified in-place\nqconfig_dict \u2013 dictionary that maps from name or type of submodule to quantization\nconfiguration, qconfig applies to all submodules of a given\nmodule unless qconfig for the submodules are specified (when the\nsubmodule already has qconfig attribute)\ninplace \u2013 carry out model transformations in-place, the original module is mutated\n\n\n\n", "description": "", "code-info": {"name": "torch.quantization.prepare", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "qconfig_dict", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.quantization.prepare_qat(model,mapping=None,inplace=False)", "id": "torch.quantization.prepare_qat", "summary": "Prepares a copy of the model for quantization calibration or\nquantization-aware training and convers it to quantized version.\nQuantization configuration can be passed as an qconfig_dict or assigned\npreemptively to individual submodules in .qconfig attribute.\n\nParameters\n\nmodel \u2013 input model to be modified in-place\nmapping \u2013 dictionary that maps float modules to quantized modules to be\nreplaced.\ninplace \u2013 carry out model transformations in-place, the original module\nis mutated\n\n\n\n", "description": "", "code-info": {"name": "torch.quantization.prepare_qat", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "mapping", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.quantization.convert(module,mapping=None,inplace=False)", "id": "torch.quantization.convert", "summary": "Converts the float module with observers (where we can get quantization\nparameters) to a quantized module.\n\nParameters\n\nmodule \u2013 calibrated module with observers\nmapping \u2013 a dictionary that maps from float module type to quantized\nmodule type, can be overwrritten to allow swapping user defined\nModules\ninplace \u2013 carry out model transformations in-place, the original module\nis mutated\n\n\n\n", "description": "", "code-info": {"name": "torch.quantization.convert", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}, {"name": "mapping", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.quantization.fuse_modules(model,modules_to_fuse,inplace=False,fuser_func=&lt;functionfuse_known_modules&gt;)", "id": "torch.quantization.fuse_modules", "summary": "Fuses a list of modules into a single module\nFuses only the following sequence of modules:\n\nconv, bn\nconv, bn, relu\nconv, relu\nlinear, relu\n\nAll other sequences are left unchanged.\nFor these sequences, replaces the first item in the list\nwith the fused module, replacing the rest of the modules\nwith identity.\n\nParameters\n\nmodel \u2013 Model containing the modules to be fused\nmodules_to_fuse \u2013 list of list of module names to fuse", "description": "", "code-info": {"name": "torch.quantization.fuse_modules", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "modules_to_fuse", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "fuser_func", "is_optional": true, "type": "others", "default_value": "&lt;functionfuse_known_modules&gt;", "description": ""}]}},
{"code": "torch.quantization.add_quant_dequant(module)", "id": "torch.quantization.add_quant_dequant", "summary": "Wrap the leaf child module in QuantWrapper if it has a valid qconfig\nNote that this function will modify the children of module inplace and it\ncan return a new module which wraps the input module as well.\n\nParameters\n\nmodule \u2013 input module with qconfig attributes for all the leaf modules\nwe want to quantize (that) \u2013 \n\n\nReturns\nEither the inplace modified module with submodules wrapped in\nQuantWrapper based on qconfig or a new QuantWrapper module which\nwraps the input module, the latter case only happens when the input\nmodule is a leaf module and we want to quantize it.\n\n\n", "description": "", "code-info": {"name": "torch.quantization.add_quant_dequant", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.quantization.add_observer_(module)", "id": "torch.quantization.add_observer_", "summary": "Add observer for the leaf child of the module.\nThis function insert observer module to all leaf child module that\nhas a valid qconfig attribute.\n\nParameters\nmodule \u2013 input module with qconfig attributes for all the leaf modules that we want to quantize\n\nReturns\nNone, module is modified inplace with added observer modules and forward_hooks\n\n\n", "description": "", "code-info": {"name": "torch.quantization.add_observer_", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.quantization.swap_module(mod,mapping)", "id": "torch.quantization.swap_module", "summary": "Swaps the module if it has a quantized counterpart and it has an\nobserver attached.\n\nParameters\n\nmod \u2013 input module\nmapping \u2013 a dictionary that maps from nn module to nnq module\n\n\nReturns\nThe corresponding quantized module of mod\n\n\n", "description": "", "code-info": {"name": "torch.quantization.swap_module", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": ""}, {"name": "mapping", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.quantization.propagate_qconfig_(module,qconfig_dict=None)", "id": "torch.quantization.propagate_qconfig_", "summary": "Propagate qconfig through the module hierarchy and assign qconfig\nattribute on each leaf module\n\nParameters\n\nmodule \u2013 input module\nqconfig_dict \u2013 dictionary that maps from name or type of submodule to\nquantization configuration, qconfig applies to all submodules of a\ngiven module unless qconfig for the submodules are specified (when\nthe submodule already has qconfig attribute)\n\n\nReturns\nNone, module is modified inplace with qconfig attached\n\n\n", "description": "", "code-info": {"name": "torch.quantization.propagate_qconfig_", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}, {"name": "qconfig_dict", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.quantization.default_eval_fn(model,calib_data)", "id": "torch.quantization.default_eval_fn", "summary": "Default evaluation function takes a torch.utils.data.Dataset or a list of\ninput Tensors and run the model on the dataset\n", "description": "", "code-info": {"name": "torch.quantization.default_eval_fn", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "calib_data", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.quantization.get_observer_dict(mod,target_dict,prefix='')", "id": "torch.quantization.get_observer_dict", "summary": "Traverse the modules and save all observers into dict.\nThis is mainly used for quantization accuracy debug\n:param mod: the top module we want to save all observers\n:param prefix: the prefix for the current module\n:param target_dict: the dictionary used to save all the observers\n", "description": "", "code-info": {"name": "torch.quantization.get_observer_dict", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": ""}, {"name": "target_dict", "is_optional": false, "type": "others", "description": ""}, {"name": "prefix", "is_optional": true, "type": "string", "default_value": "''", "description": ""}]}},
{"code": "torch.nn.quantized.functional.relu(input,inplace=False)", "id": "torch.nn.quantized.functional.relu", "summary": "Applies the rectified linear unit function element-wise.\nSee ReLU for more details.\n\nParameters\n\ninput \u2013 quantized input\ninplace \u2013 perform the computation inplace\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.functional.relu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.quantized.functional.linear(input,weight,bias=None,scale=None,zero_point=None)", "id": "torch.nn.quantized.functional.linear", "summary": "Applies a linear transformation to the incoming quantized data:\ny=xAT+by = xA^T + by=xAT+b\n\n.\nSee Linear\n\nNote\nCurrent implementation packs weights on every call, which has penalty on performance.\nIf you want to avoid the overhead, use Linear.\n\n\nParameters\n\ninput (Tensor) \u2013 Quantized input of type torch.quint8\nweight (Tensor) \u2013 Quantized weight of type torch.qint8\nbias (Tensor) \u2013 None or fp32 bias of type torch.float\nscale (double) \u2013 output scale", "description": "", "code-info": {"name": "torch.nn.quantized.functional.linear", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Quantized input of type torch.quint8"}, {"name": "weight", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Quantized weight of type torch.qint8"}, {"name": "bias", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor) \u2013 None or fp32 bias of type torch.float"}, {"name": "scale", "is_optional": true, "type": "others", "default_value": "None", "description": "(double) \u2013 output scale. If None, derived from the input scale"}, {"name": "zero_point", "is_optional": true, "type": "others", "default_value": "None", "description": "(python:long) \u2013 output zero point. If None, derived from the input zero_point"}]}},
{"code": "torch.optim.Optimizer.add_param_group(param_group)", "id": "torch.optim.Optimizer.add_param_group", "summary": "Add a param group to the Optimizer s param_groups.\nThis can be useful when fine tuning a pre-trained network as frozen layers can be made\ntrainable and added to the Optimizer as training progresses.\n\nParameters\n\nparam_group (dict) \u2013 Specifies what Tensors should be optimized along with group\noptimization options", "description": "", "code-info": {"name": "torch.optim.Optimizer.add_param_group", "parameters": [{"name": "param_group", "is_optional": false, "type": "others", "description": "(dict) \u2013 Specifies what Tensors should be optimized along with group\noptimization options. (specific) \u2013 "}]}},
{"code": "torch.distributed.rpc.init_rpc(name,backend=BackendType.PROCESS_GROUP,rank=-1,world_size=None,rpc_backend_options=None)", "id": "torch.distributed.rpc.init_rpc", "summary": "Initializes RPC primitives such as the local RPC agent\nand distributed autograd.\nInitializes the local RPC agent which immediately makes the current\nprocess ready to send and receive RPCs", "description": "", "code-info": {"name": "torch.distributed.rpc.init_rpc", "parameters": [{"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 a globally unique name of this node. (e.g.,\nTrainer3, ParameterServer2, Master,\nWorker1) Name can only contain number, alphabet,\nunderscore, and/or dash, and must be shorter than\n128 characters.\nrank (python:int) \u2013 a globally unique id/rank of this node.\nworld_size (python:int) \u2013 The number of workers in the group.\nrpc_backend_options (RpcBackendOptions) \u2013 The options passed to RpcAgent\nconsturctor.\n\n\n\n"}, {"name": "backend", "is_optional": true, "type": "others", "default_value": "BackendType.PROCESS_GROUP", "description": "(Enum) \u2013 type of RPC backend implementation.\nCurrently, process group backend is the only\navailable backend implementation. (default:\nRpcBackend.PROCESS_GROUP).\nname (str) \u2013 a globally unique name of this node. (e.g.,\nTrainer3, ParameterServer2, Master,\nWorker1) Name can only contain number, alphabet,\nunderscore, and/or dash, and must be shorter than\n128 characters."}, {"name": "rank", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 a globally unique id/rank of this node."}, {"name": "world_size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 The number of workers in the group."}, {"name": "rpc_backend_options", "is_optional": true, "type": "others", "default_value": "None", "description": "(RpcBackendOptions) \u2013 The options passed to RpcAgent\nconsturctor."}]}},
{"code": "torch.distributed.rpc.rpc_sync(to,func,args=None,kwargs=None)", "id": "torch.distributed.rpc.rpc_sync", "summary": "Make a blocking RPC call to run function func on worker to", "description": "", "code-info": {"name": "torch.distributed.rpc.rpc_sync", "parameters": [{"name": "to", "is_optional": false, "type": "others", "description": "(str or WorkerInfo) \u2013 id or name of the destination worker."}, {"name": "func", "is_optional": false, "type": "others", "description": "(callable) \u2013 any callable function. builtin functions (like\ntorch.add()) can be sent over RPC more efficiently."}, {"name": "args", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple) \u2013 the argument tuple for the func invocation."}, {"name": "kwargs", "is_optional": true, "type": "others", "default_value": "None", "description": "(dict) \u2013 is a dictionary of keyword arguments for the func\ninvocation."}]}},
{"code": "torch.distributed.rpc.rpc_async(to,func,args=None,kwargs=None)", "id": "torch.distributed.rpc.rpc_async", "summary": "Make a non-blocking RPC call to run function func on worker to", "description": "", "code-info": {"name": "torch.distributed.rpc.rpc_async", "parameters": [{"name": "to", "is_optional": false, "type": "others", "description": "(str or WorkerInfo) \u2013 id or name of the destination worker."}, {"name": "func", "is_optional": false, "type": "others", "description": "(callable) \u2013 any callable function. builtin functions (like\ntorch.add()) can be sent over RPC more efficiently."}, {"name": "args", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple) \u2013 the argument tuple for the func invocation."}, {"name": "kwargs", "is_optional": true, "type": "others", "default_value": "None", "description": "(dict) \u2013 is a dictionary of keyword arguments for the func\ninvocation."}]}},
{"code": "torchvision.models.mnasnet0_75(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.mnasnet0_75", "summary": "MNASNet with depth multiplier of 0.75 from\n\u201cMnasNet: Platform-Aware Neural Architecture Search for Mobile\u201d.\n:param pretrained: If True, returns a model pre-trained on ImageNet\n:type pretrained: bool\n:param progress: If True, displays a progress bar of the download to stderr\n:type progress: bool\n", "description": "", "code-info": {"name": "torchvision.models.mnasnet0_75", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.mnasnet1_0(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.mnasnet1_0", "summary": "MNASNet with depth multiplier of 1.0 from\n\u201cMnasNet: Platform-Aware Neural Architecture Search for Mobile\u201d.\n:param pretrained: If True, returns a model pre-trained on ImageNet\n:type pretrained: bool\n:param progress: If True, displays a progress bar of the download to stderr\n:type progress: bool\n", "description": "", "code-info": {"name": "torchvision.models.mnasnet1_0", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.mnasnet1_3(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.mnasnet1_3", "summary": "MNASNet with depth multiplier of 1.3 from\n\u201cMnasNet: Platform-Aware Neural Architecture Search for Mobile\u201d.\n:param pretrained: If True, returns a model pre-trained on ImageNet\n:type pretrained: bool\n:param progress: If True, displays a progress bar of the download to stderr\n:type progress: bool\n", "description": "", "code-info": {"name": "torchvision.models.mnasnet1_3", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.segmentation.fcn_resnet50(pretrained=False,progress=True,num_classes=21,aux_loss=None,**kwargs)", "id": "torchvision.models.segmentation.fcn_resnet50", "summary": "Constructs a Fully-Convolutional Network model with a ResNet-50 backbone.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on COCO train2017 which\ncontains the same classes as Pascal VOC\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.segmentation.fcn_resnet50", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on COCO train2017 which\ncontains the same classes as Pascal VOC"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "21", "description": ""}, {"name": "aux_loss", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.segmentation.fcn_resnet101(pretrained=False,progress=True,num_classes=21,aux_loss=None,**kwargs)", "id": "torchvision.models.segmentation.fcn_resnet101", "summary": "Constructs a Fully-Convolutional Network model with a ResNet-101 backbone.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on COCO train2017 which\ncontains the same classes as Pascal VOC\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.segmentation.fcn_resnet101", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on COCO train2017 which\ncontains the same classes as Pascal VOC"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "21", "description": ""}, {"name": "aux_loss", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.segmentation.deeplabv3_resnet50(pretrained=False,progress=True,num_classes=21,aux_loss=None,**kwargs)", "id": "torchvision.models.segmentation.deeplabv3_resnet50", "summary": "Constructs a DeepLabV3 model with a ResNet-50 backbone.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on COCO train2017 which\ncontains the same classes as Pascal VOC\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.segmentation.deeplabv3_resnet50", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on COCO train2017 which\ncontains the same classes as Pascal VOC"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "21", "description": ""}, {"name": "aux_loss", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False,progress=True,num_classes=21,aux_loss=None,**kwargs)", "id": "torchvision.models.segmentation.deeplabv3_resnet101", "summary": "Constructs a DeepLabV3 model with a ResNet-101 backbone.\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on COCO train2017 which\ncontains the same classes as Pascal VOC\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\n\n", "description": "", "code-info": {"name": "torchvision.models.segmentation.deeplabv3_resnet101", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on COCO train2017 which\ncontains the same classes as Pascal VOC"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "21", "description": ""}, {"name": "aux_loss", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False,progress=True,num_classes=91,pretrained_backbone=True,**kwargs)", "id": "torchvision.models.detection.fasterrcnn_resnet50_fpn", "summary": "Constructs a Faster R-CNN model with a ResNet-50-FPN backbone.\nThe input to the model is expected to be a list of tensors, each of shape [C, H, W], one for each\nimage, and should be in 0-1 range", "description": "", "code-info": {"name": "torchvision.models.detection.fasterrcnn_resnet50_fpn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on COCO train2017"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "91", "description": ""}, {"name": "pretrained_backbone", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=False,progress=True,num_classes=91,pretrained_backbone=True,**kwargs)", "id": "torchvision.models.detection.maskrcnn_resnet50_fpn", "summary": "Constructs a Mask R-CNN model with a ResNet-50-FPN backbone.\nThe input to the model is expected to be a list of tensors, each of shape [C, H, W], one for each\nimage, and should be in 0-1 range", "description": "", "code-info": {"name": "torchvision.models.detection.maskrcnn_resnet50_fpn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on COCO train2017"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "91", "description": ""}, {"name": "pretrained_backbone", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=False,progress=True,num_classes=2,num_keypoints=17,pretrained_backbone=True,**kwargs)", "id": "torchvision.models.detection.keypointrcnn_resnet50_fpn", "summary": "Constructs a Keypoint R-CNN model with a ResNet-50-FPN backbone.\nThe input to the model is expected to be a list of tensors, each of shape [C, H, W], one for each\nimage, and should be in 0-1 range", "description": "", "code-info": {"name": "torchvision.models.detection.keypointrcnn_resnet50_fpn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on COCO train2017"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "2", "description": ""}, {"name": "num_keypoints", "is_optional": true, "type": "int", "default_value": "17", "description": ""}, {"name": "pretrained_backbone", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.video.r3d_18(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.video.r3d_18", "summary": "Construct 18 layer Resnet3D model as in\nhttps://arxiv.org/abs/1711.11248\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on Kinetics-400\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\nReturns\nR3D-18 network\n\nReturn type\nnn.Module\n\n\n", "description": "", "code-info": {"name": "torchvision.models.video.r3d_18", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on Kinetics-400"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.video.mc3_18(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.video.mc3_18", "summary": "Constructor for 18 layer Mixed Convolution network as in\nhttps://arxiv.org/abs/1711.11248\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on Kinetics-400\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\nReturns\nMC3 Network definition\n\nReturn type\nnn.Module\n\n\n", "description": "", "code-info": {"name": "torchvision.models.video.mc3_18", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on Kinetics-400"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.models.video.r2plus1d_18(pretrained=False,progress=True,**kwargs)", "id": "torchvision.models.video.r2plus1d_18", "summary": "Constructor for the 18 layer deep R(2+1)D network as in\nhttps://arxiv.org/abs/1711.11248\n\nParameters\n\npretrained (bool) \u2013 If True, returns a model pre-trained on Kinetics-400\nprogress (bool) \u2013 If True, displays a progress bar of the download to stderr\n\n\nReturns\nR(2+1)D-18 network\n\nReturn type\nnn.Module\n\n\n", "description": "", "code-info": {"name": "torchvision.models.video.r2plus1d_18", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, returns a model pre-trained on Kinetics-400"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.datasets.ImageNet(root,split='train',download=None,**kwargs)", "id": "torchvision.datasets.ImageNet", "summary": "ImageNet 2012 Classification Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of the ImageNet Dataset.\nsplit (string, optional) \u2013 The dataset split, supports train, or val.\ntransform (callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version", "description": "", "code-info": {"name": "torchvision.datasets.ImageNet", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of the ImageNet Dataset."}, {"name": "split", "is_optional": true, "type": "string", "default_value": "'train'", "description": ""}, {"name": "download", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.datasets.CIFAR10(root,train=True,transform=None,target_transform=None,download=False)", "id": "torchvision.datasets.CIFAR10", "summary": "CIFAR10 Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of dataset where directory\ncifar-10-batches-py exists or will be saved to if download is set to True.\ntrain (bool, optional) \u2013 If True, creates dataset from training set, otherwise\ncreates from test set.\ntransform (callable, optional) \u2013 A function/transform that takes in an PIL image\nand returns a transformed version", "description": "", "code-info": {"name": "torchvision.datasets.CIFAR10", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of dataset where directory\ncifar-10-batches-py exists or will be saved to if download is set to True."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, creates dataset from training set, otherwise\ncreates from test set."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again."}]}},
{"code": "torchvision.datasets.CIFAR100(root,train=True,transform=None,target_transform=None,download=False)", "id": "torchvision.datasets.CIFAR100", "summary": "CIFAR100 Dataset.\nThis is a subclass of the CIFAR10 Dataset.\n", "description": "", "code-info": {"name": "torchvision.datasets.CIFAR100", "parameters": [{"name": "root", "is_optional": false, "type": "others", "description": ""}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torchvision.datasets.STL10(root,split='train',folds=None,transform=None,target_transform=None,download=False)", "id": "torchvision.datasets.STL10", "summary": "STL10 Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of dataset where directory\nstl10_binary exists.\nsplit (string) \u2013 One of {\u2018train\u2019, \u2018test\u2019, \u2018unlabeled\u2019, \u2018train+unlabeled\u2019}.\nAccordingly dataset is selected.\nfolds (python:int, optional) \u2013 One of {0-9} or None.\nFor training, loads one of the 10 pre-defined folds of 1k samples for the\n\nstandard evaluation procedure", "description": "", "code-info": {"name": "torchvision.datasets.STL10", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of dataset where directory\nstl10_binary exists."}, {"name": "split", "is_optional": true, "type": "string", "default_value": "'train'", "description": "(string) \u2013 One of {\u2018train\u2019, \u2018test\u2019, \u2018unlabeled\u2019, \u2018train+unlabeled\u2019}.\nAccordingly dataset is selected."}, {"name": "folds", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 One of {0-9} or None.\nFor training, loads one of the 10 pre-defined folds of 1k samples for the\n\nstandard evaluation procedure. If no value is passed, loads the 5k samples.\n\n"}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again."}]}},
{"code": "torchvision.datasets.SVHN(root,split='train',transform=None,target_transform=None,download=False)", "id": "torchvision.datasets.SVHN", "summary": "SVHN Dataset.\nNote: The SVHN dataset assigns the label 10 to the digit 0", "description": "", "code-info": {"name": "torchvision.datasets.SVHN", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of dataset where directory\nSVHN exists."}, {"name": "split", "is_optional": true, "type": "string", "default_value": "'train'", "description": "(string) \u2013 One of {\u2018train\u2019, \u2018test\u2019, \u2018extra\u2019}.\nAccordingly dataset is selected. \u2018extra\u2019 is Extra training set."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again."}]}},
{"code": "torchvision.datasets.PhotoTour(root,name,train=True,transform=None,download=False)", "id": "torchvision.datasets.PhotoTour", "summary": "Learning Local Image Descriptors Data Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory where images are.\nname (string) \u2013 Name of the dataset to load.\ntransform (callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version.\ndownload (bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory", "description": "", "code-info": {"name": "torchvision.datasets.PhotoTour", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory where images are."}, {"name": "name", "is_optional": false, "type": "others", "description": ""}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again."}]}},
{"code": "torchvision.datasets.SBU(root,transform=None,target_transform=None,download=True)", "id": "torchvision.datasets.SBU", "summary": "SBU Captioned Photo Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of dataset where tarball\nSBUCaptionedPhotoDataset.tar.gz exists.\ntransform (callable, optional) \u2013 A function/transform that takes in a PIL image\nand returns a transformed version", "description": "", "code-info": {"name": "torchvision.datasets.SBU", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of dataset where tarball\nSBUCaptionedPhotoDataset.tar.gz exists."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in a PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again."}]}},
{"code": "torchvision.datasets.Flickr8k(root,ann_file,transform=None,target_transform=None)", "id": "torchvision.datasets.Flickr8k", "summary": "Flickr8k Entities Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory where images are downloaded to.\nann_file (string) \u2013 Path to annotation file.\ntransform (callable, optional) \u2013 A function/transform that takes in a PIL image\nand returns a transformed version", "description": "", "code-info": {"name": "torchvision.datasets.Flickr8k", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory where images are downloaded to."}, {"name": "ann_file", "is_optional": false, "type": "string", "description": "(string) \u2013 Path to annotation file."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in a PIL image\nand returns a transformed version. E.g, transforms.ToTensor"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}]}},
{"code": "torchvision.datasets.Flickr30k(root,ann_file,transform=None,target_transform=None)", "id": "torchvision.datasets.Flickr30k", "summary": "Flickr30k Entities Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory where images are downloaded to.\nann_file (string) \u2013 Path to annotation file.\ntransform (callable, optional) \u2013 A function/transform that takes in a PIL image\nand returns a transformed version", "description": "", "code-info": {"name": "torchvision.datasets.Flickr30k", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory where images are downloaded to."}, {"name": "ann_file", "is_optional": false, "type": "string", "description": "(string) \u2013 Path to annotation file."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in a PIL image\nand returns a transformed version. E.g, transforms.ToTensor"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}]}},
{"code": "torchvision.datasets.VOCSegmentation(root,year='2012',image_set='train',download=False,transform=None,target_transform=None,transforms=None)", "id": "torchvision.datasets.VOCSegmentation", "summary": "Pascal VOC Segmentation Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of the VOC Dataset.\nyear (string, optional) \u2013 The dataset year, supports years 2007 to 2012.\nimage_set (string, optional) \u2013 Select the image_set to use, train, trainval or val\ndownload (bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory", "description": "", "code-info": {"name": "torchvision.datasets.VOCSegmentation", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of the VOC Dataset."}, {"name": "year", "is_optional": true, "type": "string", "default_value": "'2012'", "description": "(string, optional) \u2013 The dataset year, supports years 2007 to 2012."}, {"name": "image_set", "is_optional": true, "type": "string", "default_value": "'train'", "description": "(string, optional) \u2013 Select the image_set to use, train, trainval or val"}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}, {"name": "transforms", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes input sample and its target as entry\nand returns a transformed version."}]}},
{"code": "torchvision.datasets.VOCDetection(root,year='2012',image_set='train',download=False,transform=None,target_transform=None,transforms=None)", "id": "torchvision.datasets.VOCDetection", "summary": "Pascal VOC Detection Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of the VOC Dataset.\nyear (string, optional) \u2013 The dataset year, supports years 2007 to 2012.\nimage_set (string, optional) \u2013 Select the image_set to use, train, trainval or val\ndownload (bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory", "description": "", "code-info": {"name": "torchvision.datasets.VOCDetection", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of the VOC Dataset."}, {"name": "year", "is_optional": true, "type": "string", "default_value": "'2012'", "description": "(string, optional) \u2013 The dataset year, supports years 2007 to 2012."}, {"name": "image_set", "is_optional": true, "type": "string", "default_value": "'train'", "description": "(string, optional) \u2013 Select the image_set to use, train, trainval or val"}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again.\n(default: alphabetic indexing of VOC\u2019s 20 classes)."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, required) \u2013 A function/transform that takes in the\ntarget and transforms it."}, {"name": "transforms", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes input sample and its target as entry\nand returns a transformed version."}]}},
{"code": "torchvision.datasets.Cityscapes(root,split='train',mode='fine',target_type='instance',transform=None,target_transform=None,transforms=None)", "id": "torchvision.datasets.Cityscapes", "summary": "Cityscapes Dataset.\n\nParameters\n\nroot (string) \u2013 Root directory of dataset where directory leftImg8bit\nand gtFine or gtCoarse are located.\nsplit (string, optional) \u2013 The image split to use, train, test or val if mode=\u201dgtFine\u201d\notherwise train, train_extra or val\nmode (string, optional) \u2013 The quality mode to use, gtFine or gtCoarse\ntarget_type (string or list, optional) \u2013 Type of target to use, instance, semantic, polygon\nor color", "description": "", "code-info": {"name": "torchvision.datasets.Cityscapes", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of dataset where directory leftImg8bit\nand gtFine or gtCoarse are located."}, {"name": "split", "is_optional": true, "type": "string", "default_value": "'train'", "description": "(string, optional) \u2013 The image split to use, train, test or val if mode=\u201dgtFine\u201d\notherwise train, train_extra or val"}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'fine'", "description": "(string, optional) \u2013 The quality mode to use, gtFine or gtCoarse"}, {"name": "target_type", "is_optional": true, "type": "string", "default_value": "'instance'", "description": "(string or list, optional) \u2013 Type of target to use, instance, semantic, polygon\nor color. Can also be a list to output a tuple with all specified target types."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in a PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}, {"name": "transforms", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes input sample and its target as entry\nand returns a transformed version."}]}},
{"code": "torchvision.transforms.Lambda(lambd)", "id": "torchvision.transforms.Lambda", "summary": "Apply a user-defined lambda as a transform.\n\nParameters\nlambd (function) \u2013 Lambda/function to be used for transform.\n\n\n", "description": "", "code-info": {"name": "torchvision.transforms.Lambda", "parameters": [{"name": "lambd", "is_optional": false, "type": "others", "description": "(function) \u2013 Lambda/function to be used for transform."}]}},
{"code": "torch.onnx.export(model,args,f,export_params=True,verbose=False,training=False,input_names=None,output_names=None,aten=False,export_raw_ir=False,operator_export_type=None,opset_version=None,_retain_param_name=True,do_constant_folding=False,example_outputs=None,strip_doc_string=True,dynamic_axes=None,keep_initializers_as_inputs=None)", "id": "torch.onnx.export", "summary": "Export a model into ONNX format", "description": "", "code-info": {"name": "torch.onnx.export", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": "(torch.nn.Module) \u2013 the model to be exported."}, {"name": "args", "is_optional": false, "type": "others", "description": ""}, {"name": "f", "is_optional": false, "type": "others", "description": ""}, {"name": "export_params", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, default True) \u2013 if specified, all parameters will\nbe exported.  Set this to False if you want to export an untrained model.\nIn this case, the exported model will first take all of its parameters\nas arguments, the ordering as specified by model.state_dict().values()"}, {"name": "verbose", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, default False) \u2013 if specified, we will print out a debug\ndescription of the trace being exported."}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, default False) \u2013 export the model in training mode.  At\nthe moment, ONNX is oriented towards exporting models for inference\nonly, so you will generally not need to set this to True."}, {"name": "input_names", "is_optional": true, "type": "string", "default_value": "None", "description": "(list of strings, default empty list) \u2013 names to assign to the\ninput nodes of the graph, in order"}, {"name": "output_names", "is_optional": true, "type": "string", "default_value": "None", "description": "(list of strings, default empty list) \u2013 names to assign to the\noutput nodes of the graph, in order"}, {"name": "aten", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, default False) \u2013 [DEPRECATED. use operator_export_type] export the\nmodel in aten mode. If using aten mode, all the ops original exported\nby the functions in symbolic_opset&lt;version&gt;.py are exported as ATen ops."}, {"name": "export_raw_ir", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, default False) \u2013 [DEPRECATED. use operator_export_type]\nexport the internal IR directly instead of converting it to ONNX ops."}, {"name": "operator_export_type", "is_optional": true, "type": "others", "default_value": "None", "description": "(enum, default OperatorExportTypes.ONNX) \u2013 OperatorExportTypes.ONNX: all ops are exported as regular ONNX ops.\nOperatorExportTypes.ONNX_ATEN: all ops are exported as ATen ops.\nOperatorExportTypes.ONNX_ATEN_FALLBACK: if symbolic is missing, fall back on ATen op.\nOperatorExportTypes.RAW: export raw ir."}, {"name": "opset_version", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "_retain_param_name", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "do_constant_folding", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, default False) \u2013 If True, the constant-folding\noptimization is applied to the model during export. Constant-folding\noptimization will replace some of the ops that have all constant\ninputs, with pre-computed constant nodes."}, {"name": "example_outputs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(tuple of Tensors, default None) \u2013 example_outputs must be provided\nwhen exporting a ScriptModule or TorchScript Function."}, {"name": "strip_doc_string", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, default True) \u2013 if True, strips the field\n\u201cdoc_string\u201d from the exported model, which information about the stack\ntrace.\nexample_outputs \u2013 example outputs of the model that is being exported."}, {"name": "dynamic_axes", "is_optional": true, "type": "int", "default_value": "None", "description": "(dict&lt;string, dict&lt;python:int, string&gt;&gt; or dict&lt;string, list(python:int)&gt;, default empty dict) \u2013 a dictionary to specify dynamic axes of input/output, such that:\n- KEY:  input and/or output names\n- VALUE: index of dynamic axes for given key and potentially the name to be used for\nexported dynamic axes. In general the value is defined according to one of the following\nways or a combination of both:\n(1). A list of integers specifiying the dynamic axes of provided input. In this scenario\nautomated names will be generated and applied to dynamic axes of provided input/output\nduring export.\nOR (2). An inner dictionary that specifies a mapping FROM the index of dynamic axis in\ncorresponding input/output TO the name that is desired to be applied on such axis of\nsuch input/output during export.\nExample. if we have the following shape for inputs and outputs:\nshape(input_1) = ('b', 3, 'w', 'h')\nand shape(input_2) = ('b', 4)\nand shape(output)  = ('b', 'd', 5)\n\n\n\nThen dynamic axes can be defined either as:\n(a). ONLY INDICES:dynamic_axes = {\u2018input_1\u2019:[0, 2, 3], \u2018input_2\u2019:[0], \u2018output\u2019:[0, 1]}\nwhere automatic names will be generated for exported dynamic axes\n\n(b). INDICES WITH CORRESPONDING NAMES:dynamic_axes = {\u2018input_1\u2019:{0:\u2019batch\u2019, 1:\u2019width\u2019, 2:\u2019height\u2019},\n\u2018input_2\u2019:{0:\u2019batch\u2019},\n\u2018output\u2019:{0:\u2019batch\u2019, 1:\u2019detections\u2019}\nwhere provided names will be applied to exported dynamic axes\n\n(c). MIXED MODE OF (a) and (b)dynamic_axes = {\u2018input_1\u2019:[0, 2, 3], \u2018input_2\u2019:{0:\u2019batch\u2019}, \u2018output\u2019:[0,1]}\n\n\n\n\n"}, {"name": "keep_initializers_as_inputs", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, default None) \u2013 If True, all the initializers\n(typically corresponding to parameters) in the exported graph will also be\nadded as inputs to the graph. If False, then initializers are not added as\ninputs to the graph, and only the non-parameter inputs are added as inputs.\nThis may allow for better optimizations (such as constant folding etc.) by\nbackends/runtimes that execute these graphs. If unspecified (default None),\nthen the behavior is chosen automatically as follows. If operator_export_type\nis OperatorExportTypes.ONNX, the behavior is equivalent to setting this\nargument to False. For other values of operator_export_type, the behavior is\nequivalent to setting this argument to True. Note that for ONNX opset version &lt; 9,\ninitializers MUST be part of graph inputs. Therefore, if opset_version argument is\nset to a 8 or lower, this argument will be ignored."}]}},
{"code": "torch.nn.init.calculate_gain(nonlinearity,param=None)", "id": "torch.nn.init.calculate_gain", "summary": "Return the recommended gain value for the given nonlinearity function.\nThe values are as follows:\n\n\n\n\n\n\nnonlinearity\ngain\n\n\n\nLinear / Identity\n111\n\n\n\nConv{1,2,3}D\n111\n\n\n\nSigmoid\n111\n\n\n\nTanh\n53\\frac{5}{3}35\u200b\n\n\n\nReLU\n2\\sqrt{2}2\u200b\n\n\n\nLeaky Relu\n21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b\n\n\n\n\n\n\nParameters\n\nnonlinearity \u2013 the non-linear function (nn.functional name)\nparam \u2013 optional parameter for the non-linear function\n\n\n\nExamples\n&gt;&gt;&gt; gain = nn.init.calculate_gain('leaky_relu', 0.2)  # leaky_relu with negative_slope=0.2\n\n\n", "description": "", "code-info": {"name": "torch.nn.init.calculate_gain", "parameters": [{"name": "nonlinearity", "is_optional": false, "type": "others", "description": ""}, {"name": "param", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.init.uniform_(tensor,a=0.0,b=1.0)", "id": "torch.nn.init.uniform_", "summary": "Fills the input Tensor with values drawn from the uniform\ndistribution U(a,b)\\mathcal{U}(a, b)U(a,b)\n\n.\n\nParameters\n\ntensor \u2013 an n-dimensional torch.Tensor\na \u2013 the lower bound of the uniform distribution\nb \u2013 the upper bound of the uniform distribution\n\n\n\nExamples\n&gt;&gt;&gt; w = torch.empty(3, 5)\n&gt;&gt;&gt; nn.init.uniform_(w)\n\n\n", "description": "", "code-info": {"name": "torch.nn.init.uniform_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "a", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}, {"name": "b", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}]}},
{"code": "torch.jit.script(obj)", "id": "torch.jit.script", "summary": "Scripting a function or nn.Module will inspect the source code, compile\nit as TorchScript code using the TorchScript compiler, and return a ScriptModule or\nScriptFunction", "description": "", "code-info": {"name": "torch.jit.script", "parameters": [{"name": "obj", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.sparse.FloatTensor.to_dense()", "id": "torch.sparse.FloatTensor.to_dense", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.to_dense", "parameters": []}},
{"code": "torch.sparse.FloatTensor.transpose()", "id": "torch.sparse.FloatTensor.transpose", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.transpose", "parameters": []}},
{"code": "torch.sparse.FloatTensor.transpose_()", "id": "torch.sparse.FloatTensor.transpose_", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.transpose_", "parameters": []}},
{"code": "torch.sparse.FloatTensor.zero_()", "id": "torch.sparse.FloatTensor.zero_", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.zero_", "parameters": []}},
{"code": "torch.sparse.FloatTensor.coalesce()", "id": "torch.sparse.FloatTensor.coalesce", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.coalesce", "parameters": []}},
{"code": "torch.sparse.FloatTensor.is_coalesced()", "id": "torch.sparse.FloatTensor.is_coalesced", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor.is_coalesced", "parameters": []}},
{"code": "torch.sparse.FloatTensor._indices()", "id": "torch.sparse.FloatTensor._indices", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor._indices", "parameters": []}},
{"code": "torch.sparse.FloatTensor._values()", "id": "torch.sparse.FloatTensor._values", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor._values", "parameters": []}},
{"code": "torch.sparse.FloatTensor._nnz()", "id": "torch.sparse.FloatTensor._nnz", "summary": "", "description": "", "code-info": {"name": "torch.sparse.FloatTensor._nnz", "parameters": []}},
{"code": "torch.hub.list(github,force_reload=False)", "id": "torch.hub.list", "summary": "List all entrypoints available in github hubconf.\n\nParameters\n\ngithub (string) \u2013 a string with format \u201crepo_owner/repo_name[:tag_name]\u201d with an optional\ntag/branch", "description": "", "code-info": {"name": "torch.hub.list", "parameters": [{"name": "github", "is_optional": false, "type": "string", "description": "(string) \u2013 a string with format \u201crepo_owner/repo_name[:tag_name]\u201d with an optional\ntag/branch. The default branch is master if not specified.\nExample: \u2018pytorch/vision[:hub]\u2019"}, {"name": "force_reload", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 whether to discard the existing cache and force a fresh download.\nDefault is False."}]}},
{"code": "torch.hub.help(github,model,force_reload=False)", "id": "torch.hub.help", "summary": "Show the docstring of entrypoint model.\n\nParameters\n\ngithub (string) \u2013 a string with format &lt;repo_owner/repo_name[:tag_name]&gt; with an optional\ntag/branch", "description": "", "code-info": {"name": "torch.hub.help", "parameters": [{"name": "github", "is_optional": false, "type": "string", "description": "(string) \u2013 a string with format &lt;repo_owner/repo_name[:tag_name]&gt; with an optional\ntag/branch. The default branch is master if not specified.\nExample: \u2018pytorch/vision[:hub]\u2019"}, {"name": "model", "is_optional": false, "type": "string", "description": "(string) \u2013 a string of entrypoint name defined in repo\u2019s hubconf.py"}, {"name": "force_reload", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 whether to discard the existing cache and force a fresh download.\nDefault is False."}]}},
{"code": "torch.hub.load(github,model,*args,**kwargs)", "id": "torch.hub.load", "summary": "Load a model from a github repo, with pretrained weights.\n\nParameters\n\ngithub (string) \u2013 a string with format \u201crepo_owner/repo_name[:tag_name]\u201d with an optional\ntag/branch", "description": "", "code-info": {"name": "torch.hub.load", "parameters": [{"name": "github", "is_optional": false, "type": "string", "description": "(string) \u2013 a string with format \u201crepo_owner/repo_name[:tag_name]\u201d with an optional\ntag/branch. The default branch is master if not specified.\nExample: \u2018pytorch/vision[:hub]\u2019"}, {"name": "model", "is_optional": false, "type": "string", "description": "(string) \u2013 a string of entrypoint name defined in repo\u2019s hubconf.py"}, {"name": "*args", "is_optional": false, "type": "others", "description": "(optional) \u2013 the corresponding args for callable model.\nforce_reload (bool, optional) \u2013 whether to force a fresh download of github repo unconditionally.\nDefault is False.\nverbose (bool, optional) \u2013 If False, mute messages about hitting local caches. Note that the message\nabout first download is cannot be muted.\nDefault is True."}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": "(optional) \u2013 the corresponding kwargs for callable model."}]}},
{"code": "torch.distributions.kl.kl_divergence(p,q)", "id": "torch.distributions.kl.kl_divergence", "summary": "Compute Kullback-Leibler divergence KL(p\u2225q)KL(p \\| q)KL(p\u2225q)\n\n between two distributions.\n\nKL(p\u2225q)=\u222bp(x)log\u2061p(x)q(x)\u2009dxKL(p \\| q) = \\int p(x) \\log\\frac {p(x)} {q(x)} \\,dxKL(p\u2225q)=\u222bp(x)logq(x)p(x)\u200bdx\n\n\nParameters\n\np (Distribution) \u2013 A Distribution object.\nq (Distribution) \u2013 A Distribution object.\n\n\nReturns\nA batch of KL divergences of shape batch_shape.\n\nReturn type\nTensor\n\nRaises\nNotImplementedError \u2013 If the distribution types have not been registered via\n    register_kl().\n\n\n", "description": "", "code-info": {"name": "torch.distributions.kl.kl_divergence", "parameters": [{"name": "p", "is_optional": false, "type": "others", "description": "(Distribution) \u2013 A Distribution object."}, {"name": "q", "is_optional": false, "type": "others", "description": "(Distribution) \u2013 A Distribution object."}]}},
{"code": "torch.distributed.init_process_group(backend,init_method=None,timeout=datetime.timedelta(0,1800)", "id": "torch.distributed.init_process_group", "summary": "Initializes the default distributed process group, and this will also\ninitialize the distributed package.\n\nThere are 2 main ways to initialize a process group:\nSpecify store, rank, and world_size explicitly.\nSpecify init_method (a URL string) which indicates where/how\nto discover peers", "description": "", "code-info": {"name": "torch.distributed.init_process_group", "parameters": [{"name": "backend", "is_optional": false, "type": "others", "description": "(str or Backend) \u2013 The backend to use. Depending on\nbuild-time configurations, valid values include mpi, gloo,\nand nccl. This field should be given as a lowercase string\n(e.g., \"gloo\"), which can also be accessed via\nBackend attributes (e.g., Backend.GLOO). If using\nmultiple processes per machine with nccl backend, each process\nmust have exclusive access to every GPU it uses, as sharing GPUs\nbetween processes can result in deadlocks."}, {"name": "init_method", "is_optional": true, "type": "others", "default_value": "None", "description": "(str, optional) \u2013 URL specifying how to initialize the\nprocess group. Default is \u201cenv://\u201d if no\ninit_method or store is specified.\nMutually exclusive with store.\nworld_size (python:int, optional) \u2013 Number of processes participating in\nthe job. Required if store is specified.\nrank (python:int, optional) \u2013 Rank of the current process.\nRequired if store is specified.\nstore (Store, optional) \u2013 Key/value store accessible to all workers, used\nto exchange connection/address information.\nMutually exclusive with init_method."}, {"name": "timeout", "is_optional": true, "type": "others", "default_value": "datetime.timedelt", "description": "(timedelta, optional) \u2013 Timeout for operations executed against\nthe process group. Default value equals 30 minutes.\nThis is applicable for the gloo backend. For nccl, this is\napplicable only if the environment variable NCCL_BLOCKING_WAIT\nis set to 1.\ngroup_name (str, optional, deprecated) \u2013 Group name."}]}},
{"code": "torch.nn.quantized.functional.conv2d(input,weight,bias,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',scale=1.0,zero_point=0,dtype=torch.quint8)", "id": "torch.nn.quantized.functional.conv2d", "summary": "Applies a 2D convolution over a quantized 2D input composed of several input\nplanes.\nSee Conv2d for details and output shape.\n\nParameters\n\ninput \u2013 quantized input tensor of shape (minibatch,in_channels,iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iH , iW)(minibatch,in_channels,iH,iW)\n\n\nweight \u2013 quantized filters of shape (out_channels,in_channelsgroups,kH,kW)(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kH , kW)(out_channels,groupsin_channels\u200b,kH,kW)\n\n\nbias \u2013 non-quantized bias tensor of shape (out_channels)(\\text{out\\_channels})(out_channels)\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.functional.conv2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}, {"name": "scale", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "zero_point", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.quint8", "description": ""}]}},
{"code": "torch.nn.quantized.functional.conv3d(input,weight,bias,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',scale=1.0,zero_point=0,dtype=torch.quint8)", "id": "torch.nn.quantized.functional.conv3d", "summary": "Applies a 3D convolution over a quantized 3D input composed of several input\nplanes.\nSee Conv3d for details and output shape.\n\nParameters\n\ninput \u2013 quantized input tensor of shape\n(minibatch,in_channels,iD,iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iD , iH , iW)(minibatch,in_channels,iD,iH,iW)\n\n\nweight \u2013 quantized filters of shape\n(out_channels,in_channelsgroups,kD,kH,kW)(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kD , kH , kW)(out_channels,groupsin_channels\u200b,kD,kH,kW)\n\n\nbias \u2013 non-quantized bias tensor of shape\n(out_channels)(\\text{out\\_channels})(out_channels)\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.functional.conv3d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}, {"name": "scale", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "zero_point", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.quint8", "description": ""}]}},
{"code": "torch.nn.quantized.functional.max_pool2d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)", "id": "torch.nn.quantized.functional.max_pool2d", "summary": "Applies a 2D max pooling over a quantized input signal composed of\nseveral quantized input planes.\n\nNote\nThe input quantization parameters are propagated to the output.\n\nSee MaxPool2d for details.\n", "description": "", "code-info": {"name": "torch.nn.quantized.functional.max_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "return_indices", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.quantized.functional.adaptive_avg_pool2d(input,output_size)", "id": "torch.nn.quantized.functional.adaptive_avg_pool2d", "summary": "Applies a 2D adaptive average pooling over a quantized input signal composed\nof several quantized input planes.\n\nNote\nThe input quantization paramteres propagate to the output.\n\nSee AdaptiveAvgPool2d for details and output shape.\n\nParameters\noutput_size \u2013 the target output size (single integer or\ndouble-integer tuple)\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.functional.adaptive_avg_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "output_size", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.quantized.functional.avg_pool2d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)", "id": "torch.nn.quantized.functional.avg_pool2d", "summary": "Applies 2D average-pooling operation in kH\u00d7kWkH \\times kWkH\u00d7kW\n\n regions by step size\nsH\u00d7sWsH \\times sWsH\u00d7sW\n\n steps", "description": "", "code-info": {"name": "torch.nn.quantized.functional.avg_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "count_include_pad", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "divisor_override", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.quantized.functional.interpolate(input,size=None,scale_factor=None,mode='nearest',align_corners=None)", "id": "torch.nn.quantized.functional.interpolate", "summary": "Down/up samples the input to either the given size or the given\nscale_factor\nSee torch.nn.functional.interpolate() for implementation details.\nThe input dimensions are interpreted in the form:\nmini-batch x channels x [optional depth] x [optional height] x width.\n\nNote\nThe input quantization parameters propagate to the output.\n\n\nNote\nOnly 2D input is supported for quantized inputs\n\n\nNote\nOnly the following modes are supported for the quantized inputs:\n\nbilinear\nnearest\n\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor\nsize (python:int or Tuple[python:int] or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) \u2013 output spatial size.\nscale_factor (python:float or Tuple[python:float]) \u2013 multiplier for spatial size", "description": "", "code-info": {"name": "torch.nn.quantized.functional.interpolate", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor"}, {"name": "size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int] or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) \u2013 output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float or Tuple[python:float]) \u2013 multiplier for spatial size. Has to match input size if it is a tuple."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'nearest'", "description": "(str) \u2013 algorithm used for upsampling:\n'nearest' | 'bilinear'"}, {"name": "align_corners", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Geometrically, we consider the pixels of the\ninput and output as squares rather than points.\nIf set to True, the input and output tensors are aligned by the\ncenter points of their corner pixels, preserving the values at the corner pixels.\nIf set to False, the input and output tensors are aligned by the corner\npoints of their corner pixels, and the interpolation uses edge value padding\nfor out-of-boundary values, making this operation independent of input size\nwhen scale_factor is kept the same. This only has an effect when mode\nis 'bilinear'.\nDefault: False"}]}},
{"code": "torch.nn.quantized.functional.upsample(input,size=None,scale_factor=None,mode='nearest',align_corners=None)", "id": "torch.nn.quantized.functional.upsample", "summary": "Upsamples the input to either the given size or the given\nscale_factor\n\nWarning\nThis function is deprecated in favor of\ntorch.nn.quantized.functional.interpolate().\nThis is equivalent with nn.quantized.functional.interpolate(...).\n\nSee torch.nn.functional.interpolate() for implementation details.\nThe input dimensions are interpreted in the form:\nmini-batch x channels x [optional depth] x [optional height] x width.\n\nNote\nThe input quantization parameters propagate to the output.\n\n\nNote\nOnly 2D input is supported for quantized inputs\n\n\nNote\nOnly the following modes are supported for the quantized inputs:\n\nbilinear\nnearest\n\n\n\nParameters\n\ninput (Tensor) \u2013 quantized input tensor\nsize (python:int or Tuple[python:int] or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) \u2013 output spatial size.\nscale_factor (python:float or Tuple[python:float]) \u2013 multiplier for spatial size", "description": "", "code-info": {"name": "torch.nn.quantized.functional.upsample", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 quantized input tensor"}, {"name": "size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int] or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) \u2013 output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float or Tuple[python:float]) \u2013 multiplier for spatial size. Has to be an integer."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'nearest'", "description": "(string) \u2013 algorithm used for upsampling:\n'nearest' | 'bilinear'"}, {"name": "align_corners", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Geometrically, we consider the pixels of the\ninput and output as squares rather than points.\nIf set to True, the input and output tensors are aligned by the\ncenter points of their corner pixels, preserving the values at the corner pixels.\nIf set to False, the input and output tensors are aligned by the corner\npoints of their corner pixels, and the interpolation uses edge value padding\nfor out-of-boundary values, making this operation independent of input size\nwhen scale_factor is kept the same. This only has an effect when mode\nis 'bilinear'.\nDefault: False"}]}},
{"code": "torch.nn.quantized.functional.upsample_bilinear(input,size=None,scale_factor=None)", "id": "torch.nn.quantized.functional.upsample_bilinear", "summary": "Upsamples the input, using bilinear upsampling.\n\nWarning\nThis function is deprecated in favor of\ntorch.nn.quantized.functional.interpolate().\nThis is equivalent with\nnn.quantized.functional.interpolate(..., mode='bilinear', align_corners=True).\n\n\nNote\nThe input quantization parameters propagate to the output.\n\n\nNote\nOnly 2D inputs are supported\n\n\nParameters\n\ninput (Tensor) \u2013 quantized input\nsize (python:int or Tuple[python:int, python:int]) \u2013 output spatial size.\nscale_factor (python:int or Tuple[python:int, python:int]) \u2013 multiplier for spatial size\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.functional.upsample_bilinear", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 quantized input"}, {"name": "size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int, python:int]) \u2013 output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int, python:int]) \u2013 multiplier for spatial size"}]}},
{"code": "torch.nn.quantized.functional.upsample_nearest(input,size=None,scale_factor=None)", "id": "torch.nn.quantized.functional.upsample_nearest", "summary": "Upsamples the input, using nearest neighbours\u2019 pixel values.\n\nWarning\nThis function is deprecated in favor of\ntorch.nn.quantized.functional.interpolate().\nThis is equivalent with nn.quantized.functional.interpolate(..., mode='nearest').\n\n\nNote\nThe input quantization parameters propagate to the output.\n\n\nNote\nOnly 2D inputs are supported\n\n\nParameters\n\ninput (Tensor) \u2013 quantized input\nsize (python:int or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) \u2013 output spatial\nsize.\nscale_factor (python:int) \u2013 multiplier for spatial size", "description": "", "code-info": {"name": "torch.nn.quantized.functional.upsample_nearest", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 quantized input"}, {"name": "size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) \u2013 output spatial\nsize."}, {"name": "scale_factor", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 multiplier for spatial size. Has to be an integer."}]}},
{"code": "torch.nn.intrinsic.qat.ConvBn2d.from_float(mod,qconfig=None)", "id": "torch.nn.intrinsic.qat.ConvBn2d.from_float", "summary": "Create a qat module from a float module or qparams_dict\nArgs: mod a float module, either produced by torch.quantization utilities\nor directly from user\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.qat.ConvBn2d.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.optim.Optimizer.load_state_dict(state_dict)", "id": "torch.optim.Optimizer.load_state_dict", "summary": "Loads the optimizer state.\n\nParameters\nstate_dict (dict) \u2013 optimizer state", "description": "", "code-info": {"name": "torch.optim.Optimizer.load_state_dict", "parameters": [{"name": "state_dict", "is_optional": false, "type": "others", "description": "(dict) \u2013 optimizer state. Should be an object returned\nfrom a call to state_dict()."}]}},
{"code": "torch.optim.Optimizer.state_dict()", "id": "torch.optim.Optimizer.state_dict", "summary": "Returns the state of the optimizer as a dict.\nIt contains two entries:\n\n\nstate - a dict holding current optimization state", "description": "", "code-info": {"name": "torch.optim.Optimizer.state_dict", "parameters": []}},
{"code": "torch.optim.Optimizer.step(closure)", "id": "torch.optim.Optimizer.step", "summary": "Performs a single optimization step (parameter update).\n\nParameters\nclosure (callable) \u2013 A closure that reevaluates the model and\nreturns the loss", "description": "", "code-info": {"name": "torch.optim.Optimizer.step", "parameters": [{"name": "closure", "is_optional": false, "type": "others", "description": "(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers."}]}},
{"code": "torch.optim.Optimizer.zero_grad()", "id": "torch.optim.Optimizer.zero_grad", "summary": "Clears the gradients of all optimized torch.Tensor s.\n", "description": "", "code-info": {"name": "torch.optim.Optimizer.zero_grad", "parameters": []}},
{"code": "torch.optim.Adadelta.step(closure=None)", "id": "torch.optim.Adadelta.step", "summary": "Performs a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n", "description": "", "code-info": {"name": "torch.optim.Adadelta.step", "parameters": [{"name": "closure", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss."}]}},
{"code": "torch.optim.Adagrad.step(closure=None)", "id": "torch.optim.Adagrad.step", "summary": "Performs a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n", "description": "", "code-info": {"name": "torch.optim.Adagrad.step", "parameters": [{"name": "closure", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss."}]}},
{"code": "torch.optim.Adam.step(closure=None)", "id": "torch.optim.Adam.step", "summary": "Performs a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n", "description": "", "code-info": {"name": "torch.optim.Adam.step", "parameters": [{"name": "closure", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss."}]}},
{"code": "torch.optim.AdamW.step(closure=None)", "id": "torch.optim.AdamW.step", "summary": "Performs a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n", "description": "", "code-info": {"name": "torch.optim.AdamW.step", "parameters": [{"name": "closure", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss."}]}},
{"code": "torch.optim.SparseAdam.step(closure=None)", "id": "torch.optim.SparseAdam.step", "summary": "Performs a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n", "description": "", "code-info": {"name": "torch.optim.SparseAdam.step", "parameters": [{"name": "closure", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss."}]}},
{"code": "torch.optim.Adamax.step(closure=None)", "id": "torch.optim.Adamax.step", "summary": "Performs a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n", "description": "", "code-info": {"name": "torch.optim.Adamax.step", "parameters": [{"name": "closure", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss."}]}},
{"code": "torch.optim.ASGD.step(closure=None)", "id": "torch.optim.ASGD.step", "summary": "Performs a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n", "description": "", "code-info": {"name": "torch.optim.ASGD.step", "parameters": [{"name": "closure", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss."}]}},
{"code": "torch.optim.LBFGS.step(closure)", "id": "torch.optim.LBFGS.step", "summary": "Performs a single optimization step.\n\nParameters\nclosure (callable) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n", "description": "", "code-info": {"name": "torch.optim.LBFGS.step", "parameters": [{"name": "closure", "is_optional": false, "type": "others", "description": "(callable) \u2013 A closure that reevaluates the model\nand returns the loss."}]}},
{"code": "torch.optim.RMSprop.step(closure=None)", "id": "torch.optim.RMSprop.step", "summary": "Performs a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n", "description": "", "code-info": {"name": "torch.optim.RMSprop.step", "parameters": [{"name": "closure", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss."}]}},
{"code": "torch.optim.Rprop.step(closure=None)", "id": "torch.optim.Rprop.step", "summary": "Performs a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n", "description": "", "code-info": {"name": "torch.optim.Rprop.step", "parameters": [{"name": "closure", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss."}]}},
{"code": "torch.optim.SGD.step(closure=None)", "id": "torch.optim.SGD.step", "summary": "Performs a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n", "description": "", "code-info": {"name": "torch.optim.SGD.step", "parameters": [{"name": "closure", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss."}]}},
{"code": "torch.optim.lr_scheduler.LambdaLR.load_state_dict(state_dict)", "id": "torch.optim.lr_scheduler.LambdaLR.load_state_dict", "summary": "Loads the schedulers state.\n\nParameters\nstate_dict (dict) \u2013 scheduler state", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.LambdaLR.load_state_dict", "parameters": [{"name": "state_dict", "is_optional": false, "type": "others", "description": "(dict) \u2013 scheduler state. Should be an object returned\nfrom a call to state_dict()."}]}},
{"code": "torch.optim.lr_scheduler.LambdaLR.state_dict()", "id": "torch.optim.lr_scheduler.LambdaLR.state_dict", "summary": "Returns the state of the scheduler as a dict.\nIt contains an entry for every variable in self.__dict__ which\nis not the optimizer.\nThe learning rate lambda functions will only be saved if they are callable objects\nand not if they are functions or lambdas.\n", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.LambdaLR.state_dict", "parameters": []}},
{"code": "torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict(state_dict)", "id": "torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict", "summary": "Loads the schedulers state.\n\nParameters\nstate_dict (dict) \u2013 scheduler state", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict", "parameters": [{"name": "state_dict", "is_optional": false, "type": "others", "description": "(dict) \u2013 scheduler state. Should be an object returned\nfrom a call to state_dict()."}]}},
{"code": "torch.optim.lr_scheduler.MultiplicativeLR.state_dict()", "id": "torch.optim.lr_scheduler.MultiplicativeLR.state_dict", "summary": "Returns the state of the scheduler as a dict.\nIt contains an entry for every variable in self.__dict__ which\nis not the optimizer.\nThe learning rate lambda functions will only be saved if they are callable objects\nand not if they are functions or lambdas.\n", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.MultiplicativeLR.state_dict", "parameters": []}},
{"code": "torch.optim.lr_scheduler.CyclicLR.get_lr()", "id": "torch.optim.lr_scheduler.CyclicLR.get_lr", "summary": "Calculates the learning rate at batch index", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.CyclicLR.get_lr", "parameters": []}},
{"code": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.step(epoch=None)", "id": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.step", "summary": "Step could be called after every batch update\nExample\n&gt;&gt;&gt; scheduler = CosineAnnealingWarmRestarts(optimizer, T_0, T_mult)\n&gt;&gt;&gt; iters = len(dataloader)\n&gt;&gt;&gt; for epoch in range(20):\n&gt;&gt;&gt;     for i, sample in enumerate(dataloader):\n&gt;&gt;&gt;         inputs, labels = sample['inputs'], sample['labels']\n&gt;&gt;&gt;         scheduler.step(epoch + i / iters)\n&gt;&gt;&gt;         optimizer.zero_grad()\n&gt;&gt;&gt;         outputs = net(inputs)\n&gt;&gt;&gt;         loss = criterion(outputs, labels)\n&gt;&gt;&gt;         loss.backward()\n&gt;&gt;&gt;         optimizer.step()\n\n\nThis function can be called in an interleaved way.\nExample\n&gt;&gt;&gt; scheduler = CosineAnnealingWarmRestarts(optimizer, T_0, T_mult)\n&gt;&gt;&gt; for epoch in range(20):\n&gt;&gt;&gt;     scheduler.step()\n&gt;&gt;&gt; scheduler.step(26)\n&gt;&gt;&gt; scheduler.step() # scheduler.step(27), instead of scheduler(20)\n\n\n", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.step", "parameters": [{"name": "epoch", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributed.rpc.remote(to,func,args=None,kwargs=None)", "id": "torch.distributed.rpc.remote", "summary": "Make a remote call to run func on worker to and return an\nRRef to the result value immediately.\nWorker to will be the owner of the returned\nRRef, and the worker calling remote is\na user", "description": "", "code-info": {"name": "torch.distributed.rpc.remote", "parameters": [{"name": "to", "is_optional": false, "type": "others", "description": "(str or WorkerInfo) \u2013 id or name of the destination worker."}, {"name": "func", "is_optional": false, "type": "others", "description": "(callable) \u2013 builtin functions (like torch.add())."}, {"name": "args", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple) \u2013 the argument tuple for the func invocation."}, {"name": "kwargs", "is_optional": true, "type": "others", "default_value": "None", "description": "(dict) \u2013 is a dictionary of keyword arguments for the func\ninvocation."}]}},
{"code": "torch.distributed.rpc.get_worker_info(worker_name=None)", "id": "torch.distributed.rpc.get_worker_info", "summary": "Get WorkerInfo of a given worker name.\nUse this WorkerInfo to avoid passing an\nexpensive string on every invocation.\n\nParameters\nworker_name (str) \u2013 the string name of a worker", "description": "", "code-info": {"name": "torch.distributed.rpc.get_worker_info", "parameters": [{"name": "worker_name", "is_optional": true, "type": "others", "default_value": "None", "description": "(str) \u2013 the string name of a worker. If None, return the\nthe id of the current worker. (default None)"}]}},
{"code": "torch.distributed.rpc.shutdown(graceful=True)", "id": "torch.distributed.rpc.shutdown", "summary": "Perform a shutdown of the RPC agent, and then destroy the RPC agent", "description": "", "code-info": {"name": "torch.distributed.rpc.shutdown", "parameters": [{"name": "graceful", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 Whether to do a graceful shutdown or not. If True,\nthis will block until all local and remote RPC\nprocesses have reached this method and wait for all\noutstanding work to complete."}]}},
{"code": "torch.distributed.autograd.backward(roots:List[Tensor])", "id": "torch.distributed.autograd.backward", "summary": "Kicks off the distributed backward pass using the provided roots", "description": "", "code-info": {"name": "torch.distributed.autograd.backward", "parameters": [{"name": "roots:List[Tensor]", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributed.autograd.get_gradients(context_id:int)", "id": "torch.distributed.autograd.get_gradients", "summary": "Retrieves a map from Tensor to the appropriate gradient for that Tensor\naccumulated in the provided context_id as part of the distributed autograd\nbackward pass.\n\nParameters\ncontext_id (python:int) \u2013 The autograd context id for which we should retrieve the\ngradients.\n\nReturns\nA map where the key is the Tensor and the value is the associated gradient for that Tensor.\n\n\nExample:\n&gt;&gt; import torch.distributed.autograd as dist_autograd\n&gt;&gt; with dist_autograd.context() as context_id:\n&gt;&gt;      t1 = torch.rand((3, 3), requires_grad=True)\n&gt;&gt;      t2 = torch.rand((3, 3), requires_grad=True)\n&gt;&gt;      loss = t1 + t2\n&gt;&gt;      dist_autograd.backward([loss.sum()])\n&gt;&gt;      grads = dist_autograd.get_gradients(context_id)\n&gt;&gt;      print (grads[t1])\n&gt;&gt;      print (grads[t2])\n\n\n", "description": "", "code-info": {"name": "torch.distributed.autograd.get_gradients", "parameters": [{"name": "context_id:int", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributed.rpc.RRef.is_owner(self:torch.distributed.rpc.RRef)", "id": "torch.distributed.rpc.RRef.is_owner", "summary": "Returns whether or not the current node is the owner of this RRef.\n", "description": "", "code-info": {"name": "torch.distributed.rpc.RRef.is_owner", "parameters": [{"name": "self:torch.distributed.rpc.RRef", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributed.rpc.RRef.local_value(self:torch.distributed.rpc.RRef)", "id": "torch.distributed.rpc.RRef.local_value", "summary": "If the current node is the owner, returns a reference to the local value.\nOtherwise, throws an exception.\n", "description": "", "code-info": {"name": "torch.distributed.rpc.RRef.local_value", "parameters": [{"name": "self:torch.distributed.rpc.RRef", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributed.rpc.RRef.owner(self:torch.distributed.rpc.RRef)", "id": "torch.distributed.rpc.RRef.owner", "summary": "Returns worker information of the node that owns this RRef.\n", "description": "", "code-info": {"name": "torch.distributed.rpc.RRef.owner", "parameters": [{"name": "self:torch.distributed.rpc.RRef", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributed.rpc.RRef.to_here(self:torch.distributed.rpc.RRef)", "id": "torch.distributed.rpc.RRef.to_here", "summary": "Blocking call that copies the value of the RRef from the owner to the local node\nand returns it", "description": "", "code-info": {"name": "torch.distributed.rpc.RRef.to_here", "parameters": [{"name": "self:torch.distributed.rpc.RRef", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributed.optim.DistributedOptimizer.step()", "id": "torch.distributed.optim.DistributedOptimizer.step", "summary": "Performs a single optimization step.\nThis will call torch.optim.Optimizer.step() on each worker\ncontaining parameters to be optimized, and will block until all workers\nreturn", "description": "", "code-info": {"name": "torch.distributed.optim.DistributedOptimizer.step", "parameters": []}},
{"code": "torch.distributed.optim.DistributedOptimizer(optimizer_class,params_rref,*args,**kwargs)", "id": "torch.distributed.optim.DistributedOptimizer", "summary": "DistributedOptimizer takes remote references to parameters scattered\nacross workers and applies the given optimizer locally for each parameter.\nThis class uses get_gradients() in order\nto retrieve the gradients for specific parameters.\nConcurrent calls to\nstep(),\neither from the same or different clients, will\nbe serialized on each worker \u2013 as each worker\u2019s optimizer can only work\non one set of gradients at a time", "description": "", "code-info": {"name": "torch.distributed.optim.DistributedOptimizer", "parameters": [{"name": "optimizer_class", "is_optional": false, "type": "others", "description": "(optim.Optimizer) \u2013 the class of optimizer to\ninstantiate on each worker."}, {"name": "params_rref", "is_optional": false, "type": "others", "description": ""}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.datasets.SBDataset(root,image_set='train',mode='boundaries',download=False,transforms=None)", "id": "torchvision.datasets.SBDataset", "summary": "Semantic Boundaries Dataset\nThe SBD currently contains annotations from 11355 images taken from the PASCAL VOC 2011 dataset.\n\nNote\nPlease note that the train and val splits included with this dataset are different from\nthe splits in the PASCAL VOC dataset", "description": "", "code-info": {"name": "torchvision.datasets.SBDataset", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of the Semantic Boundaries Dataset"}, {"name": "image_set", "is_optional": true, "type": "string", "default_value": "'train'", "description": "(string, optional) \u2013 Select the image_set to use, train, val or train_noval.\nImage set train_noval excludes VOC 2012 val images."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'boundaries'", "description": "(string, optional) \u2013 Select target type. Possible values \u2018boundaries\u2019 or \u2018segmentation\u2019.\nIn case of \u2018boundaries\u2019, the target is an array of shape [num_classes, H, W],\nwhere num_classes=20."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again."}, {"name": "transforms", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes input sample and its target as entry\nand returns a transformed version. Input sample is PIL image and target is a numpy array\nif mode=\u2019boundaries\u2019 or PIL image if mode=\u2019segmentation\u2019."}]}},
{"code": "torchvision.datasets.USPS(root,train=True,transform=None,target_transform=None,download=False)", "id": "torchvision.datasets.USPS", "summary": "USPS Dataset.\nThe data-format is : [label [index:value ]*256 n] * num_lines, where label lies in [1, 10].\nThe value for each pixel lies in [-1, 1]", "description": "", "code-info": {"name": "torchvision.datasets.USPS", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of dataset to store``USPS`` data files."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, creates dataset from usps.bz2,\notherwise from usps.t.bz2."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that  takes in an PIL image\nand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable, optional) \u2013 A function/transform that takes in the\ntarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If true, downloads the dataset from the internet and\nputs it in root directory. If dataset is already downloaded, it is not\ndownloaded again."}]}},
{"code": "torchvision.datasets.Kinetics400(root,frames_per_clip,step_between_clips=1,frame_rate=None,extensions=('avi',)", "id": "torchvision.datasets.Kinetics400", "summary": "Kinetics-400\ndataset.\nKinetics-400 is an action recognition video dataset.\nThis dataset consider every video as a collection of video clips of fixed size, specified\nby frames_per_clip, where the step in frames between each clip is given by\nstep_between_clips.\nTo give an example, for 2 videos with 10 and 15 frames respectively, if frames_per_clip=5\nand step_between_clips=5, the dataset size will be (2 + 3) = 5, where the first two\nelements will come from video 1, and the next three elements from video 2.\nNote that we drop clips which do not have exactly frames_per_clip elements, so not all\nframes in a video might be present.\nInternally, it uses a VideoClips object to handle clip creation.\n\nParameters\n\nroot (string) \u2013 Root directory of the Kinetics-400 Dataset.\nframes_per_clip (python:int) \u2013 number of frames in a clip\nstep_between_clips (python:int) \u2013 number of frames between each clip\ntransform (callable, optional) \u2013 A function/transform that  takes in a TxHxWxC video\nand returns a transformed version.\n\n\nReturns\nthe T video frames\naudio(Tensor[K, L]): the audio frames, where K is the number of channels\n\nand L is the number of points\n\nlabel (int): class of the video clip\n\n\nReturn type\nvideo (Tensor[T, H, W, C])\n\n\n", "description": "", "code-info": {"name": "torchvision.datasets.Kinetics400", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of the Kinetics-400 Dataset."}, {"name": "frames_per_clip", "is_optional": false, "type": "int", "description": "(python:int) \u2013 number of frames in a clip"}, {"name": "step_between_clips", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "frame_rate", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extensions", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torchvision.datasets.HMDB51(root,annotation_path,frames_per_clip,step_between_clips=1,frame_rate=None,fold=1,train=True,transform=None,_precomputed_metadata=None,num_workers=1,_video_width=0,_video_height=0,_video_min_dimension=0,_audio_samples=0)", "id": "torchvision.datasets.HMDB51", "summary": "HMDB51\ndataset.\nHMDB51 is an action recognition video dataset.\nThis dataset consider every video as a collection of video clips of fixed size, specified\nby frames_per_clip, where the step in frames between each clip is given by\nstep_between_clips.\nTo give an example, for 2 videos with 10 and 15 frames respectively, if frames_per_clip=5\nand step_between_clips=5, the dataset size will be (2 + 3) = 5, where the first two\nelements will come from video 1, and the next three elements from video 2.\nNote that we drop clips which do not have exactly frames_per_clip elements, so not all\nframes in a video might be present.\nInternally, it uses a VideoClips object to handle clip creation.\n\nParameters\n\nroot (string) \u2013 Root directory of the HMDB51 Dataset.\nannotation_path (str) \u2013 path to the folder containing the split files\nframes_per_clip (python:int) \u2013 number of frames in a clip.\nstep_between_clips (python:int) \u2013 number of frames between each clip.\nfold (python:int, optional) \u2013 which fold to use", "description": "", "code-info": {"name": "torchvision.datasets.HMDB51", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of the HMDB51 Dataset."}, {"name": "annotation_path", "is_optional": false, "type": "others", "description": "(str) \u2013 path to the folder containing the split files"}, {"name": "frames_per_clip", "is_optional": false, "type": "int", "description": "(python:int) \u2013 number of frames in a clip."}, {"name": "step_between_clips", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "frame_rate", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "fold", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 which fold to use. Should be between 1 and 3."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 if True, creates a dataset from the train split,\notherwise from the test split."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "_precomputed_metadata", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "num_workers", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "_video_width", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_video_height", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_video_min_dimension", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_audio_samples", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torchvision.datasets.UCF101(root,annotation_path,frames_per_clip,step_between_clips=1,frame_rate=None,fold=1,train=True,transform=None,_precomputed_metadata=None,num_workers=1,_video_width=0,_video_height=0,_video_min_dimension=0,_audio_samples=0)", "id": "torchvision.datasets.UCF101", "summary": "UCF101 dataset.\nUCF101 is an action recognition video dataset.\nThis dataset consider every video as a collection of video clips of fixed size, specified\nby frames_per_clip, where the step in frames between each clip is given by\nstep_between_clips.\nTo give an example, for 2 videos with 10 and 15 frames respectively, if frames_per_clip=5\nand step_between_clips=5, the dataset size will be (2 + 3) = 5, where the first two\nelements will come from video 1, and the next three elements from video 2.\nNote that we drop clips which do not have exactly frames_per_clip elements, so not all\nframes in a video might be present.\nInternally, it uses a VideoClips object to handle clip creation.\n\nParameters\n\nroot (string) \u2013 Root directory of the UCF101 Dataset.\nannotation_path (str) \u2013 path to the folder containing the split files\nframes_per_clip (python:int) \u2013 number of frames in a clip.\nstep_between_clips (python:int, optional) \u2013 number of frames between each clip.\nfold (python:int, optional) \u2013 which fold to use", "description": "", "code-info": {"name": "torchvision.datasets.UCF101", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": "(string) \u2013 Root directory of the UCF101 Dataset."}, {"name": "annotation_path", "is_optional": false, "type": "others", "description": "(str) \u2013 path to the folder containing the split files"}, {"name": "frames_per_clip", "is_optional": false, "type": "int", "description": "(python:int) \u2013 number of frames in a clip."}, {"name": "step_between_clips", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "frame_rate", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "fold", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 which fold to use. Should be between 1 and 3."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 if True, creates a dataset from the train split,\notherwise from the test split."}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "_precomputed_metadata", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "num_workers", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "_video_width", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_video_height", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_video_min_dimension", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_audio_samples", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.onnx.register_custom_op_symbolic(symbolic_name,symbolic_fn,opset_version)", "id": "torch.onnx.register_custom_op_symbolic", "summary": "", "description": "", "code-info": {"name": "torch.onnx.register_custom_op_symbolic", "parameters": [{"name": "symbolic_name", "is_optional": false, "type": "others", "description": ""}, {"name": "symbolic_fn", "is_optional": false, "type": "others", "description": ""}, {"name": "opset_version", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.onnx.operators.shape_as_tensor(x)", "id": "torch.onnx.operators.shape_as_tensor", "summary": "", "description": "", "code-info": {"name": "torch.onnx.operators.shape_as_tensor", "parameters": [{"name": "x", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.onnx.set_training(model,mode)", "id": "torch.onnx.set_training", "summary": "A context manager to temporarily set the training mode of \u2018model\u2019\nto \u2018mode\u2019, resetting it when we exit the with-block", "description": "", "code-info": {"name": "torch.onnx.set_training", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "mode", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.onnx.is_in_onnx_export()", "id": "torch.onnx.is_in_onnx_export", "summary": "Check whether it\u2019s in the middle of the ONNX export.\nThis function returns True in the middle of torch.onnx.export().\ntorch.onnx.export should be executed with single thread.\n", "description": "", "code-info": {"name": "torch.onnx.is_in_onnx_export", "parameters": []}},
{"code": "torch.nn.init.normal_(tensor,mean=0.0,std=1.0)", "id": "torch.nn.init.normal_", "summary": "Fills the input Tensor with values drawn from the normal\ndistribution N(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2)\n\n.\n\nParameters\n\ntensor \u2013 an n-dimensional torch.Tensor\nmean \u2013 the mean of the normal distribution\nstd \u2013 the standard deviation of the normal distribution\n\n\n\nExamples\n&gt;&gt;&gt; w = torch.empty(3, 5)\n&gt;&gt;&gt; nn.init.normal_(w)\n\n\n", "description": "", "code-info": {"name": "torch.nn.init.normal_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "mean", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}, {"name": "std", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}]}},
{"code": "torch.nn.init.constant_(tensor,val)", "id": "torch.nn.init.constant_", "summary": "Fills the input Tensor with the value val\\text{val}val\n\n.\n\nParameters\n\ntensor \u2013 an n-dimensional torch.Tensor\nval \u2013 the value to fill the tensor with\n\n\n\nExamples\n&gt;&gt;&gt; w = torch.empty(3, 5)\n&gt;&gt;&gt; nn.init.constant_(w, 0.3)\n\n\n", "description": "", "code-info": {"name": "torch.nn.init.constant_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "val", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.init.ones_(tensor)", "id": "torch.nn.init.ones_", "summary": "Fills the input Tensor with the scalar value 1.\n\nParameters\ntensor \u2013 an n-dimensional torch.Tensor\n\n\nExamples\n&gt;&gt;&gt; w = torch.empty(3, 5)\n&gt;&gt;&gt; nn.init.ones_(w)\n\n\n", "description": "", "code-info": {"name": "torch.nn.init.ones_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.init.zeros_(tensor)", "id": "torch.nn.init.zeros_", "summary": "Fills the input Tensor with the scalar value 0.\n\nParameters\ntensor \u2013 an n-dimensional torch.Tensor\n\n\nExamples\n&gt;&gt;&gt; w = torch.empty(3, 5)\n&gt;&gt;&gt; nn.init.zeros_(w)\n\n\n", "description": "", "code-info": {"name": "torch.nn.init.zeros_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.init.eye_(tensor)", "id": "torch.nn.init.eye_", "summary": "Fills the 2-dimensional input Tensor with the identity\nmatrix", "description": "", "code-info": {"name": "torch.nn.init.eye_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.init.dirac_(tensor)", "id": "torch.nn.init.dirac_", "summary": "Fills the {3, 4, 5}-dimensional input Tensor with the Dirac\ndelta function", "description": "", "code-info": {"name": "torch.nn.init.dirac_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.init.xavier_uniform_(tensor,gain=1.0)", "id": "torch.nn.init.xavier_uniform_", "summary": "Fills the input Tensor with values according to the method\ndescribed in Understanding the difficulty of training deep feedforward\nneural networks - Glorot, X", "description": "", "code-info": {"name": "torch.nn.init.xavier_uniform_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "gain", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}]}},
{"code": "torch.nn.init.xavier_normal_(tensor,gain=1.0)", "id": "torch.nn.init.xavier_normal_", "summary": "Fills the input Tensor with values according to the method\ndescribed in Understanding the difficulty of training deep feedforward\nneural networks - Glorot, X", "description": "", "code-info": {"name": "torch.nn.init.xavier_normal_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "gain", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}]}},
{"code": "torch.nn.init.kaiming_uniform_(tensor,a=0,mode='fan_in',nonlinearity='leaky_relu')", "id": "torch.nn.init.kaiming_uniform_", "summary": "Fills the input Tensor with values according to the method\ndescribed in Delving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification - He, K", "description": "", "code-info": {"name": "torch.nn.init.kaiming_uniform_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "a", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'fan_in'", "description": ""}, {"name": "nonlinearity", "is_optional": true, "type": "string", "default_value": "'leaky_relu'", "description": ""}]}},
{"code": "torch.nn.init.kaiming_normal_(tensor,a=0,mode='fan_in',nonlinearity='leaky_relu')", "id": "torch.nn.init.kaiming_normal_", "summary": "Fills the input Tensor with values according to the method\ndescribed in Delving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification - He, K", "description": "", "code-info": {"name": "torch.nn.init.kaiming_normal_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "a", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'fan_in'", "description": ""}, {"name": "nonlinearity", "is_optional": true, "type": "string", "default_value": "'leaky_relu'", "description": ""}]}},
{"code": "torch.nn.init.orthogonal_(tensor,gain=1)", "id": "torch.nn.init.orthogonal_", "summary": "Fills the input Tensor with a (semi) orthogonal matrix, as\ndescribed in Exact solutions to the nonlinear dynamics of learning in deep\nlinear neural networks - Saxe, A", "description": "", "code-info": {"name": "torch.nn.init.orthogonal_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "gain", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torch.nn.init.sparse_(tensor,sparsity,std=0.01)", "id": "torch.nn.init.sparse_", "summary": "Fills the 2D input Tensor as a sparse matrix, where the\nnon-zero elements will be drawn from the normal distribution\nN(0,0.01)\\mathcal{N}(0, 0.01)N(0,0.01)\n\n, as described in Deep learning via\nHessian-free optimization - Martens, J", "description": "", "code-info": {"name": "torch.nn.init.sparse_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "sparsity", "is_optional": false, "type": "others", "description": ""}, {"name": "std", "is_optional": true, "type": "others", "default_value": "0.01", "description": ""}]}},
{"code": "torch.jit.trace(func,example_inputs,optimize=None,check_trace=True,check_inputs=None,check_tolerance=1e-5)", "id": "torch.jit.trace", "summary": "Trace a function and return an executable  or ScriptFunction\nthat will be optimized using just-in-time compilation", "description": "", "code-info": {"name": "torch.jit.trace", "parameters": [{"name": "func", "is_optional": false, "type": "others", "description": "(callable or torch.nn.Module) \u2013 A Python function or torch.nn.Module\nthat will be run with example_inputs.\narguments and returns to func must be tensors\nor (possibly nested) tuples that\ncontain tensors. When a module is passed to\ntorch.jit.trace, only the\nforward method is run and traced\n(see torch.jit.trace for details)."}, {"name": "example_inputs", "is_optional": false, "type": "others", "description": ""}, {"name": "optimize", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "check_trace", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 Check if the same inputs run through\ntraced code produce the same outputs. Default: True. You might want\nto disable this if, for example, your network contains non-\ndeterministic ops or if you are sure that the network is correct despite\na checker failure."}, {"name": "check_inputs", "is_optional": true, "type": "others", "default_value": "None", "description": "(list of tuples, optional) \u2013 A list of tuples of input arguments that should be used\nto check the trace against what is expected. Each tuple\nis equivalent to a set of input arguments that would\nbe specified in example_inputs. For best results, pass in a\nset of checking inputs representative of the space of\nshapes and types of inputs you expect the network to see.\nIf not specified, the original example_inputs are used for checking"}, {"name": "check_tolerance", "is_optional": true, "type": "float", "default_value": "1e-5", "description": "(python:float, optional) \u2013 Floating-point comparison tolerance to use in the checker procedure.\nThis can be used to relax the checker strictness in the event that\nresults diverge numerically for a known reason, such as operator fusion."}]}},
{"code": "torch.jit.trace_module(mod,inputs,optimize=None,check_trace=True,check_inputs=None,check_tolerance=1e-5)", "id": "torch.jit.trace_module", "summary": "Trace a module and return an executable ScriptModule that will be optimized\nusing just-in-time compilation", "description": "", "code-info": {"name": "torch.jit.trace_module", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": ""}, {"name": "inputs", "is_optional": false, "type": "others", "description": ""}, {"name": "optimize", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "check_trace", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 Check if the same inputs run through\ntraced code produce the same outputs. Default: True. You might want\nto disable this if, for example, your network contains non-\ndeterministic ops or if you are sure that the network is correct despite\na checker failure."}, {"name": "check_inputs", "is_optional": true, "type": "others", "default_value": "None", "description": "(list of dicts, optional) \u2013 A list of dicts of input arguments that should be used\nto check the trace against what is expected. Each tuple\nis equivalent to a set of input arguments that would\nbe specified in example_inputs. For best results, pass in a\nset of checking inputs representative of the space of\nshapes and types of inputs you expect the network to see.\nIf not specified, the original example_inputs are used for checking"}, {"name": "check_tolerance", "is_optional": true, "type": "float", "default_value": "1e-5", "description": "(python:float, optional) \u2013 Floating-point comparison tolerance to use in the checker procedure.\nThis can be used to relax the checker strictness in the event that\nresults diverge numerically for a known reason, such as operator fusion."}]}},
{"code": "torch.jit.save(m,f,_extra_files=ExtraFilesMap{})", "id": "torch.jit.save", "summary": "Save an offline version of this module for use in a separate process", "description": "", "code-info": {"name": "torch.jit.save", "parameters": [{"name": "m", "is_optional": false, "type": "others", "description": ""}, {"name": "f", "is_optional": false, "type": "others", "description": ""}, {"name": "_extra_files", "is_optional": true, "type": "others", "default_value": "ExtraFilesMap{}", "description": ""}]}},
{"code": "torch.jit.load(f,map_location=None,_extra_files=ExtraFilesMap{})", "id": "torch.jit.load", "summary": "Load a ScriptModule or ScriptFunction previously\nsaved with torch.jit.save\nAll previously saved modules, no matter their device, are first loaded onto CPU,\nand then are moved to the devices they were saved from", "description": "", "code-info": {"name": "torch.jit.load", "parameters": [{"name": "f", "is_optional": false, "type": "others", "description": ""}, {"name": "map_location", "is_optional": true, "type": "string", "default_value": "None", "description": "(string or torch.device) \u2013 A simplified version of map_location in\ntorch.save used to dynamically remap storages to an alternative set of devices."}, {"name": "_extra_files", "is_optional": true, "type": "others", "default_value": "ExtraFilesMap{}", "description": "(dictionary of filename to content) \u2013 The extra\nfilenames given in the map would be loaded and their content\nwould be stored in the provided map."}]}},
{"code": "torch.jit.export(fn)", "id": "torch.jit.export", "summary": "This decorator indicates that a method on an nn.Module is used as an entry point into a\nScriptModule and should be compiled.\nforward implicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called from forward are compiled as they are seen\nby the compiler, so they do not need this decorator either.\nExample (using @torch.jit.export on a method):\nimport torch\nimport torch.nn as nn\n\nclass MyModule(nn.Module):\n    def implicitly_compiled_method(self, x):\n        return x + 99\n\n    # `forward` is implicitly decorated with `@torch.jit.export`,\n    # so adding it here would have no effect\n    def forward(self, x):\n        return x + 10\n\n    @torch.jit.export\n    def another_forward(self, x):\n        # When the compiler sees this call, it will compile\n        # `implicitly_compiled_method`\n        return self.implicitly_compiled_method(x)\n\n    def unused_method(self, x):\n        return x - 20\n\n# `m` will contain compiled methods:\n#     `forward`\n#     `another_forward`\n#     `implicitly_compiled_method`\n# `unused_method` will not be compiled since it was not called from\n# any compiled methods and wasn't decorated with `@torch.jit.export`\nm = torch.jit.script(MyModule())\n\n\n", "description": "", "code-info": {"name": "torch.jit.export", "parameters": [{"name": "fn", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.jit.ignore(drop=False,**kwargs)", "id": "torch.jit.ignore", "summary": "This decorator indicates to the compiler that a function or method should\nbe ignored and left as a Python function", "description": "", "code-info": {"name": "torch.jit.ignore", "parameters": [{"name": "drop", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.jit.unused(fn)", "id": "torch.jit.unused", "summary": "This decorator indicates to the compiler that a function or method should\nbe ignored and replaced with the raising of an exception", "description": "", "code-info": {"name": "torch.jit.unused", "parameters": [{"name": "fn", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.jit.is_scripting()", "id": "torch.jit.is_scripting", "summary": "Function that returns True when in compilation and False otherwise", "description": "", "code-info": {"name": "torch.jit.is_scripting", "parameters": []}},
{"code": "torch.hub.download_url_to_file(url,dst,hash_prefix=None,progress=True)", "id": "torch.hub.download_url_to_file", "summary": "Download object at the given URL to a local path.\n\nParameters\n\nurl (string) \u2013 URL of the object to download\ndst (string) \u2013 Full path where object will be saved, e.g", "description": "", "code-info": {"name": "torch.hub.download_url_to_file", "parameters": [{"name": "url", "is_optional": false, "type": "string", "description": "(string) \u2013 URL of the object to download"}, {"name": "dst", "is_optional": false, "type": "string", "description": "(string) \u2013 Full path where object will be saved, e.g. /tmp/temporary_file"}, {"name": "hash_prefix", "is_optional": true, "type": "string", "default_value": "None", "description": "(string, optional) \u2013 If not None, the SHA256 downloaded file should start with hash_prefix.\nDefault: None"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 whether or not to display a progress bar to stderr\nDefault: True"}]}},
{"code": "torch.hub.load_state_dict_from_url(url,model_dir=None,map_location=None,progress=True,check_hash=False)", "id": "torch.hub.load_state_dict_from_url", "summary": "Loads the Torch serialized object at the given URL.\nIf downloaded file is a zip file, it will be automatically\ndecompressed.\nIf the object is already present in model_dir, it\u2019s deserialized and\nreturned.\nThe default value of model_dir is $TORCH_HOME/checkpoints where\nenvironment variable $TORCH_HOME defaults to $XDG_CACHE_HOME/torch.\n$XDG_CACHE_HOME follows the X Design Group specification of the Linux\nfilesytem layout, with a default value ~/.cache if not set.\n\nParameters\n\nurl (string) \u2013 URL of the object to download\nmodel_dir (string, optional) \u2013 directory in which to save the object\nmap_location (optional) \u2013 a function or a dict specifying how to remap storage locations (see torch.load)\nprogress (bool, optional) \u2013 whether or not to display a progress bar to stderr.\nDefault: True\ncheck_hash (bool, optional) \u2013 If True, the filename part of the URL should follow the naming convention\nfilename-&lt;sha256&gt;.ext where &lt;sha256&gt; is the first eight or more\ndigits of the SHA256 hash of the contents of the file", "description": "", "code-info": {"name": "torch.hub.load_state_dict_from_url", "parameters": [{"name": "url", "is_optional": false, "type": "string", "description": "(string) \u2013 URL of the object to download"}, {"name": "model_dir", "is_optional": true, "type": "string", "default_value": "None", "description": "(string, optional) \u2013 directory in which to save the object"}, {"name": "map_location", "is_optional": true, "type": "others", "default_value": "None", "description": "(optional) \u2013 a function or a dict specifying how to remap storage locations (see torch.load)"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 whether or not to display a progress bar to stderr.\nDefault: True"}, {"name": "check_hash", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If True, the filename part of the URL should follow the naming convention\nfilename-&lt;sha256&gt;.ext where &lt;sha256&gt; is the first eight or more\ndigits of the SHA256 hash of the contents of the file. The hash is used to\nensure unique names and to verify the contents of the file.\nDefault: False"}]}},
{"code": "torch.hub.set_dir(d)", "id": "torch.hub.set_dir", "summary": "Optionally set hub_dir to a local dir to save downloaded models &amp; weights.\nIf set_dir is not called, default path is $TORCH_HOME/hub where\nenvironment variable $TORCH_HOME defaults to $XDG_CACHE_HOME/torch.\n$XDG_CACHE_HOME follows the X Design Group specification of the Linux\nfilesytem layout, with a default value ~/.cache if the environment\nvariable is not set.\n\nParameters\nd (string) \u2013 path to a local folder to save downloaded models &amp; weights.\n\n\n", "description": "", "code-info": {"name": "torch.hub.set_dir", "parameters": [{"name": "d", "is_optional": false, "type": "string", "description": "(string) \u2013 path to a local folder to save downloaded models &amp; weights."}]}},
{"code": "torch.distributions.kl.register_kl(type_p,type_q)", "id": "torch.distributions.kl.register_kl", "summary": "Decorator to register a pairwise function with kl_divergence().\nUsage:\n@register_kl(Normal, Normal)\ndef kl_normal_normal(p, q):\n    # insert implementation here\n\n\nLookup returns the most specific (type,type) match ordered by subclass", "description": "", "code-info": {"name": "torch.distributions.kl.register_kl", "parameters": [{"name": "type_p", "is_optional": false, "type": "others", "description": "(python:type) \u2013 A subclass of Distribution."}, {"name": "type_q", "is_optional": false, "type": "others", "description": "(python:type) \u2013 A subclass of Distribution."}]}},
{"code": "torch.distributions.distribution.Distribution.cdf(value)", "id": "torch.distributions.distribution.Distribution.cdf", "summary": "Returns the cumulative density/mass function evaluated at\nvalue.\n\nParameters\nvalue (Tensor) \u2013 \n\n\n", "description": "", "code-info": {"name": "torch.distributions.distribution.Distribution.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 "}]}},
{"code": "torch.distributions.distribution.Distribution.entropy()", "id": "torch.distributions.distribution.Distribution.entropy", "summary": "Returns entropy of distribution, batched over batch_shape.\n\nReturns\nTensor of shape batch_shape.\n\n\n", "description": "", "code-info": {"name": "torch.distributions.distribution.Distribution.entropy", "parameters": []}},
{"code": "torch.distributions.distribution.Distribution.enumerate_support(expand=True)", "id": "torch.distributions.distribution.Distribution.enumerate_support", "summary": "Returns tensor containing all values supported by a discrete\ndistribution", "description": "", "code-info": {"name": "torch.distributions.distribution.Distribution.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 whether to expand the support over the\nbatch dims to match the distribution\u2019s batch_shape."}]}},
{"code": "torch.distributions.distribution.Distribution.expand(batch_shape,_instance=None)", "id": "torch.distributions.distribution.Distribution.expand", "summary": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\nbatch_shape", "description": "", "code-info": {"name": "torch.distributions.distribution.Distribution.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.distribution.Distribution.icdf(value)", "id": "torch.distributions.distribution.Distribution.icdf", "summary": "Returns the inverse cumulative density/mass function evaluated at\nvalue.\n\nParameters\nvalue (Tensor) \u2013 \n\n\n", "description": "", "code-info": {"name": "torch.distributions.distribution.Distribution.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 "}]}},
{"code": "torch.distributions.distribution.Distribution.log_prob(value)", "id": "torch.distributions.distribution.Distribution.log_prob", "summary": "Returns the log of the probability density/mass function evaluated at\nvalue.\n\nParameters\nvalue (Tensor) \u2013 \n\n\n", "description": "", "code-info": {"name": "torch.distributions.distribution.Distribution.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 "}]}},
{"code": "torch.distributions.distribution.Distribution.perplexity()", "id": "torch.distributions.distribution.Distribution.perplexity", "summary": "Returns perplexity of distribution, batched over batch_shape.\n\nReturns\nTensor of shape batch_shape.\n\n\n", "description": "", "code-info": {"name": "torch.distributions.distribution.Distribution.perplexity", "parameters": []}},
{"code": "torch.distributions.distribution.Distribution.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.distribution.Distribution.rsample", "summary": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.\n", "description": "", "code-info": {"name": "torch.distributions.distribution.Distribution.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.distribution.Distribution.sample(sample_shape=torch.Size([])", "id": "torch.distributions.distribution.Distribution.sample", "summary": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.\n", "description": "", "code-info": {"name": "torch.distributions.distribution.Distribution.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributed.get_backend(group=&lt;objectobject&gt;)", "id": "torch.distributed.get_backend", "summary": "Returns the backend of the given process group.\n\nParameters\ngroup (ProcessGroup, optional) \u2013 The process group to work on", "description": "", "code-info": {"name": "torch.distributed.get_backend", "parameters": [{"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on. The\ndefault is the general main process group. If another specific group\nis specified, the calling process must be part of group."}]}},
{"code": "torch.distributed.get_rank(group=&lt;objectobject&gt;)", "id": "torch.distributed.get_rank", "summary": "Returns the rank of current process group\nRank is a unique identifier assigned to each process within a distributed\nprocess group", "description": "", "code-info": {"name": "torch.distributed.get_rank", "parameters": [{"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}]}},
{"code": "torch.distributed.get_world_size(group=&lt;objectobject&gt;)", "id": "torch.distributed.get_world_size", "summary": "Returns the number of processes in the current process group\n\nParameters\ngroup (ProcessGroup, optional) \u2013 The process group to work on\n\nReturns\nThe world size of the process group\n-1, if not part of the group\n\n\n", "description": "", "code-info": {"name": "torch.distributed.get_world_size", "parameters": [{"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}]}},
{"code": "torch.distributed.is_initialized()", "id": "torch.distributed.is_initialized", "summary": "Checking if the default process group has been initialized\n", "description": "", "code-info": {"name": "torch.distributed.is_initialized", "parameters": []}},
{"code": "torch.distributed.is_mpi_available()", "id": "torch.distributed.is_mpi_available", "summary": "Checks if the MPI backend is available.\n", "description": "", "code-info": {"name": "torch.distributed.is_mpi_available", "parameters": []}},
{"code": "torch.distributed.is_nccl_available()", "id": "torch.distributed.is_nccl_available", "summary": "Checks if the NCCL backend is available.\n", "description": "", "code-info": {"name": "torch.distributed.is_nccl_available", "parameters": []}},
{"code": "torch.distributed.new_group(ranks=None,timeout=datetime.timedelta(0,1800)", "id": "torch.distributed.new_group", "summary": "Creates a new distributed group.\nThis function requires that all processes in the main group (i.e", "description": "", "code-info": {"name": "torch.distributed.new_group", "parameters": [{"name": "ranks", "is_optional": true, "type": "int", "default_value": "None", "description": "(list[python:int]) \u2013 List of ranks of group members."}, {"name": "timeout", "is_optional": true, "type": "others", "default_value": "datetime.timedelt", "description": "(timedelta, optional) \u2013 Timeout for operations executed against\nthe process group. Default value equals 30 minutes.\nThis is only applicable for the gloo backend.\nbackend (str or Backend, optional) \u2013 The backend to use. Depending on\nbuild-time configurations, valid values are gloo and nccl.\nBy default uses the same backend as the global group. This field\nshould be given as a lowercase string (e.g., \"gloo\"), which can\nalso be accessed via Backend attributes (e.g.,\nBackend.GLOO)."}]}},
{"code": "torch.distributed.send(tensor,dst,group=&lt;objectobject&gt;,tag=0)", "id": "torch.distributed.send", "summary": "Sends a tensor synchronously.\n\nParameters\n\ntensor (Tensor) \u2013 Tensor to send.\ndst (python:int) \u2013 Destination rank.\ngroup (ProcessGroup, optional) \u2013 The process group to work on\ntag (python:int, optional) \u2013 Tag to match send with remote recv\n\n\n\n", "description": "", "code-info": {"name": "torch.distributed.send", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Tensor to send."}, {"name": "dst", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Destination rank."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "tag", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 Tag to match send with remote recv"}]}},
{"code": "torch.distributed.recv(tensor,src=None,group=&lt;objectobject&gt;,tag=0)", "id": "torch.distributed.recv", "summary": "Receives a tensor synchronously.\n\nParameters\n\ntensor (Tensor) \u2013 Tensor to fill with received data.\nsrc (python:int, optional) \u2013 Source rank", "description": "", "code-info": {"name": "torch.distributed.recv", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Tensor to fill with received data."}, {"name": "src", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 Source rank. Will receive from any\nprocess if unspecified."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "tag", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 Tag to match recv with remote send"}]}},
{"code": "torch.distributed.isend(tensor,dst,group=&lt;objectobject&gt;,tag=0)", "id": "torch.distributed.isend", "summary": "Sends a tensor asynchronously.\n\nParameters\n\ntensor (Tensor) \u2013 Tensor to send.\ndst (python:int) \u2013 Destination rank.\ngroup (ProcessGroup, optional) \u2013 The process group to work on\ntag (python:int, optional) \u2013 Tag to match send with remote recv\n\n\nReturns\nA distributed request object.\nNone, if not part of the group\n\n\n", "description": "", "code-info": {"name": "torch.distributed.isend", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Tensor to send."}, {"name": "dst", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Destination rank."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "tag", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 Tag to match send with remote recv"}]}},
{"code": "torch.distributed.irecv(tensor,src,group=&lt;objectobject&gt;,tag=0)", "id": "torch.distributed.irecv", "summary": "Receives a tensor asynchronously.\n\nParameters\n\ntensor (Tensor) \u2013 Tensor to fill with received data.\nsrc (python:int) \u2013 Source rank.\ngroup (ProcessGroup, optional) \u2013 The process group to work on\ntag (python:int, optional) \u2013 Tag to match recv with remote send\n\n\nReturns\nA distributed request object.\nNone, if not part of the group\n\n\n", "description": "", "code-info": {"name": "torch.distributed.irecv", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Tensor to fill with received data."}, {"name": "src", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Source rank."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "tag", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 Tag to match recv with remote send"}]}},
{"code": "torch.distributed.broadcast(tensor,src,group=&lt;objectobject&gt;,async_op=False)", "id": "torch.distributed.broadcast", "summary": "Broadcasts the tensor to the whole group.\ntensor must have the same number of elements in all processes\nparticipating in the collective.\n\nParameters\n\ntensor (Tensor) \u2013 Data to be sent if src is the rank of current\nprocess, and tensor to be used to save received data otherwise.\nsrc (python:int) \u2013 Source rank.\ngroup (ProcessGroup, optional) \u2013 The process group to work on\nasync_op (bool, optional) \u2013 Whether this op should be an async op\n\n\nReturns\nAsync work handle, if async_op is set to True.\nNone, if not async_op or if not part of the group\n\n\n", "description": "", "code-info": {"name": "torch.distributed.broadcast", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Data to be sent if src is the rank of current\nprocess, and tensor to be used to save received data otherwise."}, {"name": "src", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Source rank."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether this op should be an async op"}]}},
{"code": "torch.distributed.all_reduce(tensor,op=ReduceOp.SUM,group=&lt;objectobject&gt;,async_op=False)", "id": "torch.distributed.all_reduce", "summary": "Reduces the tensor data across all machines in such a way that all get\nthe final result.\nAfter the call tensor is going to be bitwise identical in all processes.\n\nParameters\n\ntensor (Tensor) \u2013 Input and output of the collective", "description": "", "code-info": {"name": "torch.distributed.all_reduce", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Input and output of the collective. The function\noperates in-place."}, {"name": "op", "is_optional": true, "type": "others", "default_value": "ReduceOp.SUM", "description": "(optional) \u2013 One of the values from\ntorch.distributed.ReduceOp\nenum.  Specifies an operation used for element-wise reductions."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether this op should be an async op"}]}},
{"code": "torch.distributed.reduce(tensor,dst,op=ReduceOp.SUM,group=&lt;objectobject&gt;,async_op=False)", "id": "torch.distributed.reduce", "summary": "Reduces the tensor data across all machines.\nOnly the process with rank dst is going to receive the final result.\n\nParameters\n\ntensor (Tensor) \u2013 Input and output of the collective", "description": "", "code-info": {"name": "torch.distributed.reduce", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Input and output of the collective. The function\noperates in-place."}, {"name": "dst", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Destination rank"}, {"name": "op", "is_optional": true, "type": "others", "default_value": "ReduceOp.SUM", "description": "(optional) \u2013 One of the values from\ntorch.distributed.ReduceOp\nenum.  Specifies an operation used for element-wise reductions."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether this op should be an async op"}]}},
{"code": "torch.distributed.all_gather(tensor_list,tensor,group=&lt;objectobject&gt;,async_op=False)", "id": "torch.distributed.all_gather", "summary": "Gathers tensors from the whole group in a list.\n\nParameters\n\ntensor_list (list[Tensor]) \u2013 Output list", "description": "", "code-info": {"name": "torch.distributed.all_gather", "parameters": [{"name": "tensor_list", "is_optional": false, "type": "tensor", "description": "(list[Tensor]) \u2013 Output list. It should contain\ncorrectly-sized tensors to be used for output of the collective."}, {"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Tensor to be broadcast from current process."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether this op should be an async op"}]}},
{"code": "torch.distributed.gather(tensor,gather_list=None,dst=0,group=&lt;objectobject&gt;,async_op=False)", "id": "torch.distributed.gather", "summary": "Gathers a list of tensors in a single process.\n\nParameters\n\ntensor (Tensor) \u2013 Input tensor.\ngather_list (list[Tensor], optional) \u2013 List of appropriately-sized\ntensors to use for gathered data (default is None, must be specified\non the destination rank)\ndst (python:int, optional) \u2013 Destination rank (default is 0)\ngroup (ProcessGroup, optional) \u2013 The process group to work on\nasync_op (bool, optional) \u2013 Whether this op should be an async op\n\n\nReturns\nAsync work handle, if async_op is set to True.\nNone, if not async_op or if not part of the group\n\n\n", "description": "", "code-info": {"name": "torch.distributed.gather", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Input tensor."}, {"name": "gather_list", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(list[Tensor], optional) \u2013 List of appropriately-sized\ntensors to use for gathered data (default is None, must be specified\non the destination rank)"}, {"name": "dst", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 Destination rank (default is 0)"}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether this op should be an async op"}]}},
{"code": "torch.distributed.scatter(tensor,scatter_list=None,src=0,group=&lt;objectobject&gt;,async_op=False)", "id": "torch.distributed.scatter", "summary": "Scatters a list of tensors to all processes in a group.\nEach process will receive exactly one tensor and store its data in the\ntensor argument.\n\nParameters\n\ntensor (Tensor) \u2013 Output tensor.\nscatter_list (list[Tensor]) \u2013 List of tensors to scatter (default is\nNone, must be specified on the source rank)\nsrc (python:int) \u2013 Source rank (default is 0)\ngroup (ProcessGroup, optional) \u2013 The process group to work on\nasync_op (bool, optional) \u2013 Whether this op should be an async op\n\n\nReturns\nAsync work handle, if async_op is set to True.\nNone, if not async_op or if not part of the group\n\n\n", "description": "", "code-info": {"name": "torch.distributed.scatter", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Output tensor."}, {"name": "scatter_list", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(list[Tensor]) \u2013 List of tensors to scatter (default is\nNone, must be specified on the source rank)"}, {"name": "src", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 Source rank (default is 0)"}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether this op should be an async op"}]}},
{"code": "torch.nn.qat.Conv2d.from_float(mod,qconfig=None)", "id": "torch.nn.qat.Conv2d.from_float", "summary": "Create a qat module from a float module or qparams_dict\nArgs: mod a float module, either produced by torch.quantization utilities\nor directly from user\n", "description": "", "code-info": {"name": "torch.nn.qat.Conv2d.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.qat.Linear.from_float(mod,qconfig=None)", "id": "torch.nn.qat.Linear.from_float", "summary": "Create a qat module from a float module or qparams_dict\nArgs: mod a float module, either produced by torch.quantization utilities\nor directly from user\n", "description": "", "code-info": {"name": "torch.nn.qat.Linear.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.quantized.Conv2d.from_float(mod)", "id": "torch.nn.quantized.Conv2d.from_float", "summary": "Creates a quantized module from a float module or qparams_dict.\n\nParameters\nmod (Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.Conv2d.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": "(Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user"}]}},
{"code": "torch.nn.quantized.Conv3d.from_float(mod)", "id": "torch.nn.quantized.Conv3d.from_float", "summary": "Creates a quantized module from a float module or qparams_dict.\n\nParameters\nmod (Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.Conv3d.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": "(Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user"}]}},
{"code": "torch.nn.quantized.Linear.from_float(mod)", "id": "torch.nn.quantized.Linear.from_float", "summary": "Create a quantized module from a float module or qparams_dict\n\nParameters\nmod (Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.Linear.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": "(Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user"}]}},
{"code": "torch.nn.quantized.dynamic.Linear.from_float(mod)", "id": "torch.nn.quantized.dynamic.Linear.from_float", "summary": "Create a dynamic quantized module from a float module or qparams_dict\n\nParameters\nmod (Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.dynamic.Linear.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": "(Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user"}]}},
{"code": "torch.quantization.QuantStub(qconfig=None)", "id": "torch.quantization.QuantStub", "summary": "Quantize stub module, before calibration, this is same as an observer,\nit will be swapped as nnq.Quantize in convert.\n\nParameters\nqconfig \u2013 quantization configuration for the tensor,\nif qconfig is not provided, we will get qconfig from parent modules\n\n\n", "description": "", "code-info": {"name": "torch.quantization.QuantStub", "parameters": [{"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.quantization.QuantWrapper(module)", "id": "torch.quantization.QuantWrapper", "summary": "A wrapper class that wraps the input module, adds QuantStub and\nDeQuantStub and surround the call to module with call to quant and dequant\nmodules.\nThis is used by the quantization utility functions to add the quant and\ndequant modules, before convert function QuantStub will just be observer,\nit observes the input tensor, after convert, QuantStub\nwill be swapped to nnq.Quantize which does actual quantization", "description": "", "code-info": {"name": "torch.quantization.QuantWrapper", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.quantization.MinMaxObserver(dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False)", "id": "torch.quantization.MinMaxObserver", "summary": "Observer module for computing the quantization parameters based on the\nrunning min and max values.\nThis observer uses the tensor min/max statistics to compute the quantization\nparameters", "description": "", "code-info": {"name": "torch.quantization.MinMaxObserver", "parameters": [{"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.quint8", "description": ""}, {"name": "qscheme", "is_optional": true, "type": "others", "default_value": "torch.per_tensor_affine", "description": ""}, {"name": "reduce_range", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.cuda.current_blas_handle()", "id": "torch.cuda.current_blas_handle", "summary": "Returns cublasHandle_t pointer to current cuBLAS handle\n", "description": "", "code-info": {"name": "torch.cuda.current_blas_handle", "parameters": []}},
{"code": "torch.cuda.current_device()", "id": "torch.cuda.current_device", "summary": "Returns the index of a currently selected device.\n", "description": "", "code-info": {"name": "torch.cuda.current_device", "parameters": []}},
{"code": "torch.autograd.backward(tensors,grad_tensors=None,retain_graph=None,create_graph=False,grad_variables=None)", "id": "torch.autograd.backward", "summary": "Computes the sum of gradients of given tensors w.r.t", "description": "", "code-info": {"name": "torch.autograd.backward", "parameters": [{"name": "tensors", "is_optional": false, "type": "tensor", "description": "(sequence of Tensor) \u2013 Tensors of which the derivative will be\ncomputed."}, {"name": "grad_tensors", "is_optional": true, "type": "others", "default_value": "None", "description": "(sequence of (Tensor or None)) \u2013 The \u201cvector\u201d in the Jacobian-vector\nproduct, usually gradients w.r.t. each element of corresponding tensors.\nNone values can be specified for scalar Tensors or ones that don\u2019t require\ngrad. If a None value would be acceptable for all grad_tensors, then this\nargument is optional."}, {"name": "retain_graph", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 If False, the graph used to compute the grad\nwill be freed. Note that in nearly all cases setting this option to True\nis not needed and often can be worked around in a much more efficient\nway. Defaults to the value of create_graph."}, {"name": "create_graph", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "grad_variables", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.optim.Optimizer(params,defaults)", "id": "torch.optim.Optimizer", "summary": "Base class for all optimizers.\n\nWarning\nParameters need to be specified as collections that have a deterministic\nordering that is consistent between runs", "description": "", "code-info": {"name": "torch.optim.Optimizer", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": ""}, {"name": "defaults", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.optim.Adadelta(params,lr=1.0,rho=0.9,eps=1e-06,weight_decay=0)", "id": "torch.optim.Adadelta", "summary": "Implements Adadelta algorithm.\nIt has been proposed in ADADELTA: An Adaptive Learning Rate Method.\n\nParameters\n\nparams (iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups\nrho (python:float, optional) \u2013 coefficient used for computing a running average\nof squared gradients (default: 0.9)\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-6)\nlr (python:float, optional) \u2013 coefficient that scale delta before it is applied\nto the parameters (default: 1.0)\nweight_decay (python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)\n\n\n\n\n\nstep(closure=None) \u00b6\nPerforms a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n\n\n", "description": "", "code-info": {"name": "torch.optim.Adadelta", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups\nrho (python:float, optional) \u2013 coefficient used for computing a running average\nof squared gradients (default: 0.9)\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-6)"}, {"name": "lr", "is_optional": true, "type": "float", "default_value": "1.0", "description": "(python:float, optional) \u2013 coefficient that scale delta before it is applied\nto the parameters (default: 1.0)\nweight_decay (python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)\n\n\n\n\n\nstep(closure=None) \u00b6\nPerforms a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n\n\n"}, {"name": "rho", "is_optional": true, "type": "float", "default_value": "0.9", "description": "(python:float, optional) \u2013 coefficient used for computing a running average\nof squared gradients (default: 0.9)"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-06", "description": "(python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-6)\nlr (python:float, optional) \u2013 coefficient that scale delta before it is applied\nto the parameters (default: 1.0)"}, {"name": "weight_decay", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)"}]}},
{"code": "torch.optim.Adagrad(params,lr=0.01,lr_decay=0,weight_decay=0,initial_accumulator_value=0,eps=1e-10)", "id": "torch.optim.Adagrad", "summary": "Implements Adagrad algorithm.\nIt has been proposed in Adaptive Subgradient Methods for Online Learning\nand Stochastic Optimization.\n\nParameters\n\nparams (iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups\nlr (python:float, optional) \u2013 learning rate (default: 1e-2)\nlr_decay (python:float, optional) \u2013 learning rate decay (default: 0)\nweight_decay (python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-10)\n\n\n\n\n\nstep(closure=None) \u00b6\nPerforms a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n\n\n", "description": "", "code-info": {"name": "torch.optim.Adagrad", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups"}, {"name": "lr", "is_optional": true, "type": "float", "default_value": "0.01", "description": "(python:float, optional) \u2013 learning rate (default: 1e-2)"}, {"name": "lr_decay", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float, optional) \u2013 learning rate decay (default: 0)"}, {"name": "weight_decay", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "initial_accumulator_value", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-10", "description": "(python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-10)"}]}},
{"code": "torch.optim.Adam(params,lr=0.001,betas=(0.9,0.999)", "id": "torch.optim.Adam", "summary": "Implements Adam algorithm.\nIt has been proposed in Adam: A Method for Stochastic Optimization.\n\nParameters\n\nparams (iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups\nlr (python:float, optional) \u2013 learning rate (default: 1e-3)\nbetas (Tuple[python:float, python:float], optional) \u2013 coefficients used for computing\nrunning averages of gradient and its square (default: (0.9, 0.999))\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-8)\nweight_decay (python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)\namsgrad (boolean, optional) \u2013 whether to use the AMSGrad variant of this\nalgorithm from the paper On the Convergence of Adam and Beyond\n(default: False)\n\n\n\n\n\nstep(closure=None) \u00b6\nPerforms a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n\n\n", "description": "", "code-info": {"name": "torch.optim.Adam", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups"}, {"name": "lr", "is_optional": true, "type": "float", "default_value": "0.001", "description": "(python:float, optional) \u2013 learning rate (default: 1e-3)"}, {"name": "betas", "is_optional": false, "type": "float", "description": "(Tuple[python:float, python:float], optional) \u2013 coefficients used for computing\nrunning averages of gradient and its square (default: (0.9, 0.999))\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-8)\nweight_decay (python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)\namsgrad (boolean, optional) \u2013 whether to use the AMSGrad variant of this\nalgorithm from the paper On the Convergence of Adam and Beyond\n(default: False)"}]}},
{"code": "torch.optim.AdamW(params,lr=0.001,betas=(0.9,0.999)", "id": "torch.optim.AdamW", "summary": "Implements AdamW algorithm.\nThe original Adam algorithm was proposed in Adam: A Method for Stochastic Optimization.\nThe AdamW variant was proposed in Decoupled Weight Decay Regularization.\n\nParameters\n\nparams (iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups\nlr (python:float, optional) \u2013 learning rate (default: 1e-3)\nbetas (Tuple[python:float, python:float], optional) \u2013 coefficients used for computing\nrunning averages of gradient and its square (default: (0.9, 0.999))\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-8)\nweight_decay (python:float, optional) \u2013 weight decay coefficient (default: 1e-2)\namsgrad (boolean, optional) \u2013 whether to use the AMSGrad variant of this\nalgorithm from the paper On the Convergence of Adam and Beyond\n(default: False)\n\n\n\n\n\nstep(closure=None) \u00b6\nPerforms a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n\n\n", "description": "", "code-info": {"name": "torch.optim.AdamW", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups"}, {"name": "lr", "is_optional": true, "type": "float", "default_value": "0.001", "description": "(python:float, optional) \u2013 learning rate (default: 1e-3)"}, {"name": "betas", "is_optional": false, "type": "float", "description": "(Tuple[python:float, python:float], optional) \u2013 coefficients used for computing\nrunning averages of gradient and its square (default: (0.9, 0.999))\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-8)\nweight_decay (python:float, optional) \u2013 weight decay coefficient (default: 1e-2)\namsgrad (boolean, optional) \u2013 whether to use the AMSGrad variant of this\nalgorithm from the paper On the Convergence of Adam and Beyond\n(default: False)"}]}},
{"code": "torch.optim.SparseAdam(params,lr=0.001,betas=(0.9,0.999)", "id": "torch.optim.SparseAdam", "summary": "Implements lazy version of Adam algorithm suitable for sparse tensors.\nIn this variant, only moments that show up in the gradient get updated, and\nonly those portions of the gradient get applied to the parameters.\n\nParameters\n\nparams (iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups\nlr (python:float, optional) \u2013 learning rate (default: 1e-3)\nbetas (Tuple[python:float, python:float], optional) \u2013 coefficients used for computing\nrunning averages of gradient and its square (default: (0.9, 0.999))\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-8)\n\n\n\n\n\nstep(closure=None) \u00b6\nPerforms a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n\n\n", "description": "", "code-info": {"name": "torch.optim.SparseAdam", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups"}, {"name": "lr", "is_optional": true, "type": "float", "default_value": "0.001", "description": "(python:float, optional) \u2013 learning rate (default: 1e-3)"}, {"name": "betas", "is_optional": false, "type": "float", "description": "(Tuple[python:float, python:float], optional) \u2013 coefficients used for computing\nrunning averages of gradient and its square (default: (0.9, 0.999))\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-8)"}]}},
{"code": "sig-name descname(p=0.5,*,generator=None)", "id": "sig-name descname", "summary": "Fills each location of self with an independent sample from\nBernoulli(p)\\text{Bernoulli}(\\texttt{p})Bernoulli(p)\n\n", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "p", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.jit.ScriptModule.save(f,_extra_files=ExtraFilesMap{})", "id": "torch.jit.ScriptModule.save", "summary": "See torch.jit.save for details.\n", "description": "", "code-info": {"name": "torch.jit.ScriptModule.save", "parameters": [{"name": "f", "is_optional": false, "type": "others", "description": ""}, {"name": "_extra_files", "is_optional": true, "type": "others", "default_value": "ExtraFilesMap{}", "description": ""}]}},
{"code": "torch.nn.functional.conv1d(input,weight,bias=None,stride=1,padding=0,dilation=1,groups=1)", "id": "torch.nn.functional.conv1d", "summary": "Applies a 1D convolution over an input signal composed of several input\nplanes.\nSee Conv1d for details and output shape.\n\nNote\nIn some circumstances when using the CUDA backend with CuDNN, this operator\nmay select a nondeterministic algorithm to increase performance", "description": "", "code-info": {"name": "torch.nn.functional.conv1d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torch.distributions.distribution.Distribution.sample_n(n)", "id": "torch.distributions.distribution.Distribution.sample_n", "summary": "Generates n samples or n batches of samples if the distribution\nparameters are batched.\n", "description": "", "code-info": {"name": "torch.distributions.distribution.Distribution.sample_n", "parameters": [{"name": "n", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.exp_family.ExponentialFamily.entropy()", "id": "torch.distributions.exp_family.ExponentialFamily.entropy", "summary": "Method to compute the entropy using Bregman divergence of the log normalizer.\n", "description": "", "code-info": {"name": "torch.distributions.exp_family.ExponentialFamily.entropy", "parameters": []}},
{"code": "torch.distributions.bernoulli.Bernoulli.entropy()", "id": "torch.distributions.bernoulli.Bernoulli.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.entropy", "parameters": []}},
{"code": "torch.distributions.bernoulli.Bernoulli.enumerate_support(expand=True)", "id": "torch.distributions.bernoulli.Bernoulli.enumerate_support", "summary": "", "description": "", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.distributions.bernoulli.Bernoulli.expand(batch_shape,_instance=None)", "id": "torch.distributions.bernoulli.Bernoulli.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.bernoulli.Bernoulli.log_prob(value)", "id": "torch.distributions.bernoulli.Bernoulli.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.bernoulli.Bernoulli.sample(sample_shape=torch.Size([])", "id": "torch.distributions.bernoulli.Bernoulli.sample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.beta.Beta.entropy()", "id": "torch.distributions.beta.Beta.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.beta.Beta.entropy", "parameters": []}},
{"code": "torch.distributions.beta.Beta.expand(batch_shape,_instance=None)", "id": "torch.distributions.beta.Beta.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.beta.Beta.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.beta.Beta.log_prob(value)", "id": "torch.distributions.beta.Beta.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.beta.Beta.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.beta.Beta.rsample(sample_shape=()", "id": "torch.distributions.beta.Beta.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.beta.Beta.rsample", "parameters": [{"name": "sample_shape", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.binomial.Binomial.enumerate_support(expand=True)", "id": "torch.distributions.binomial.Binomial.enumerate_support", "summary": "", "description": "", "code-info": {"name": "torch.distributions.binomial.Binomial.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.distributed.barrier(group=&lt;objectobject&gt;,async_op=False)", "id": "torch.distributed.barrier", "summary": "Synchronizes all processes.\nThis collective blocks processes until the whole group enters this function,\nif async_op is False, or if async work handle is called on wait().\n\nParameters\n\ngroup (ProcessGroup, optional) \u2013 The process group to work on\nasync_op (bool, optional) \u2013 Whether this op should be an async op\n\n\nReturns\nAsync work handle, if async_op is set to True.\nNone, if not async_op or if not part of the group\n\n\n", "description": "", "code-info": {"name": "torch.distributed.barrier", "parameters": [{"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether this op should be an async op"}]}},
{"code": "torch.distributed.broadcast_multigpu(tensor_list,src,group=&lt;objectobject&gt;,async_op=False,src_tensor=0)", "id": "torch.distributed.broadcast_multigpu", "summary": "Broadcasts the tensor to the whole group with multiple GPU tensors\nper node.\ntensor must have the same number of elements in all the GPUs from\nall processes participating in the collective", "description": "", "code-info": {"name": "torch.distributed.broadcast_multigpu", "parameters": [{"name": "tensor_list", "is_optional": false, "type": "tensor", "description": "(List[Tensor]) \u2013 Tensors that participate in the collective\noperation. If src is the rank, then the specified src_tensor\nelement of tensor_list (tensor_list[src_tensor]) will be\nbroadcast to all other tensors (on different GPUs) in the src process\nand all tensors in tensor_list of other non-src processes.\nYou also need to make sure that len(tensor_list) is the same\nfor all the distributed processes calling this function."}, {"name": "src", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Source rank."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether this op should be an async op"}, {"name": "src_tensor", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 Source tensor rank within tensor_list"}]}},
{"code": "torch.distributed.all_reduce_multigpu(tensor_list,op=ReduceOp.SUM,group=&lt;objectobject&gt;,async_op=False)", "id": "torch.distributed.all_reduce_multigpu", "summary": "Reduces the tensor data across all machines in such a way that all get\nthe final result", "description": "", "code-info": {"name": "torch.distributed.all_reduce_multigpu", "parameters": [{"name": "tensor_list", "is_optional": false, "type": "others", "description": ""}, {"name": "op", "is_optional": true, "type": "others", "default_value": "ReduceOp.SUM", "description": "(optional) \u2013 One of the values from\ntorch.distributed.ReduceOp\nenum.  Specifies an operation used for element-wise reductions."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether this op should be an async op"}]}},
{"code": "torch.distributed.reduce_multigpu(tensor_list,dst,op=ReduceOp.SUM,group=&lt;objectobject&gt;,async_op=False,dst_tensor=0)", "id": "torch.distributed.reduce_multigpu", "summary": "Reduces the tensor data on multiple GPUs across all machines", "description": "", "code-info": {"name": "torch.distributed.reduce_multigpu", "parameters": [{"name": "tensor_list", "is_optional": false, "type": "tensor", "description": "(List[Tensor]) \u2013 Input and output GPU tensors of the\ncollective. The function operates in-place.\nYou also need to make sure that len(tensor_list) is the same for\nall the distributed processes calling this function."}, {"name": "dst", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Destination rank"}, {"name": "op", "is_optional": true, "type": "others", "default_value": "ReduceOp.SUM", "description": "(optional) \u2013 One of the values from\ntorch.distributed.ReduceOp\nenum.  Specifies an operation used for element-wise reductions."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether this op should be an async op"}, {"name": "dst_tensor", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 Destination tensor rank within\ntensor_list"}]}},
{"code": "torch.distributed.all_gather_multigpu(output_tensor_lists,input_tensor_list,group=&lt;objectobject&gt;,async_op=False)", "id": "torch.distributed.all_gather_multigpu", "summary": "Gathers tensors from the whole group in a list.\nEach tensor in tensor_list should reside on a separate GPU\nOnly nccl backend is currently supported\ntensors should only be GPU tensors\n\nParameters\n\noutput_tensor_lists (List[List[Tensor]]) \u2013 Output lists", "description": "", "code-info": {"name": "torch.distributed.all_gather_multigpu", "parameters": [{"name": "output_tensor_lists", "is_optional": false, "type": "tensor", "description": "(List[List[Tensor]]) \u2013 Output lists. It should\ncontain correctly-sized tensors on each GPU to be used for output\nof the collective, e.g. output_tensor_lists[i] contains the\nall_gather result that resides on the GPU of\ninput_tensor_list[i].\nNote that each element of output_tensor_lists has the size of\nworld_size * len(input_tensor_list), since the function all\ngathers the result from every single GPU in the group. To interpret\neach element of output_tensor_lists[i], note that\ninput_tensor_list[j] of rank k will be appear in\noutput_tensor_lists[i][k * world_size + j]\nAlso note that len(output_tensor_lists), and the size of each\nelement in output_tensor_lists (each element is a list,\ntherefore len(output_tensor_lists[i])) need to be the same\nfor all the distributed processes calling this function.\n"}, {"name": "input_tensor_list", "is_optional": false, "type": "tensor", "description": "(List[Tensor]) \u2013 List of tensors(on different GPUs) to\nbe broadcast from current process.\nNote that len(input_tensor_list) needs to be the same for\nall the distributed processes calling this function."}, {"name": "group", "is_optional": true, "type": "others", "default_value": "&lt;objectobject&gt;", "description": "(ProcessGroup, optional) \u2013 The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether this op should be an async op"}]}},
{"code": "torch.quantization.MovingAverageMinMaxObserver(averaging_constant=0.01,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False)", "id": "torch.quantization.MovingAverageMinMaxObserver", "summary": "Observer module for computing the quantization parameters based on the\nmoving average of the min and max values.\nThis observer computes the quantization parameters based on the moving\naverages of minimums and maximums of the incoming tensors", "description": "", "code-info": {"name": "torch.quantization.MovingAverageMinMaxObserver", "parameters": [{"name": "averaging_constant", "is_optional": true, "type": "others", "default_value": "0.01", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.quint8", "description": ""}, {"name": "qscheme", "is_optional": true, "type": "others", "default_value": "torch.per_tensor_affine", "description": ""}, {"name": "reduce_range", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.quantization.PerChannelMinMaxObserver(ch_axis=0,dtype=torch.quint8,qscheme=torch.per_channel_affine,reduce_range=False)", "id": "torch.quantization.PerChannelMinMaxObserver", "summary": "Observer module for computing the quantization parameters based on the\nrunning per channel min and max values.\nThis observer uses the tensor min/max statistics to compute the per channel\nquantization parameters", "description": "", "code-info": {"name": "torch.quantization.PerChannelMinMaxObserver", "parameters": [{"name": "ch_axis", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.quint8", "description": ""}, {"name": "qscheme", "is_optional": true, "type": "others", "default_value": "torch.per_channel_affine", "description": ""}, {"name": "reduce_range", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.quantization.MovingAveragePerChannelMinMaxObserver(averaging_constant=0.01,ch_axis=0,dtype=torch.quint8,qscheme=torch.per_channel_affine,reduce_range=False)", "id": "torch.quantization.MovingAveragePerChannelMinMaxObserver", "summary": "Observer module for computing the quantization parameters based on the\nrunning per channel min and max values.\nThis observer uses the tensor min/max statistics to compute the per channel\nquantization parameters", "description": "", "code-info": {"name": "torch.quantization.MovingAveragePerChannelMinMaxObserver", "parameters": [{"name": "averaging_constant", "is_optional": true, "type": "others", "default_value": "0.01", "description": ""}, {"name": "ch_axis", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.quint8", "description": ""}, {"name": "qscheme", "is_optional": true, "type": "others", "default_value": "torch.per_channel_affine", "description": ""}, {"name": "reduce_range", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.quantization.HistogramObserver(bins=2048,upsample_rate=128,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False)", "id": "torch.quantization.HistogramObserver", "summary": "The module records the running histogram of tensor values along with\nmin/max values", "description": "", "code-info": {"name": "torch.quantization.HistogramObserver", "parameters": [{"name": "bins", "is_optional": true, "type": "int", "default_value": "2048", "description": ""}, {"name": "upsample_rate", "is_optional": true, "type": "int", "default_value": "128", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.quint8", "description": ""}, {"name": "qscheme", "is_optional": true, "type": "others", "default_value": "torch.per_tensor_affine", "description": ""}, {"name": "reduce_range", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.quantization.FakeQuantize(observer=&lt;class'torch.quantization.observer.MovingAverageMinMaxObserver'&gt;,quant_min=0,quant_max=255,**observer_kwargs)", "id": "torch.quantization.FakeQuantize", "summary": "Simulate the quantize and dequantize operations in training time.\nThe output of this module is given by\nx_out = (clamp(round(x/scale + zero_point), quant_min, quant_max)-zero_point)*scale\n\nscale defines the scale factor used for quantization.\nzero_point specifies the quantized value to which 0 in floating point maps to\nquant_min specifies the minimum allowable quantized value.\nquant_max specifies the maximum allowable quantized value.\nfake_quant_enable controls the application of fake quantization on tensors, note that\nstatistics can still be updated.\nobserver_enable controls statistics collection on tensors\n\ndtype specifies the quantized dtype that is being emulated with fake-quantization,allowable values are torch.qint8 and torch.quint8", "description": "", "code-info": {"name": "torch.quantization.FakeQuantize", "parameters": [{"name": "observer", "is_optional": true, "type": "others", "default_value": "&lt;class'torch.quantization.observer.MovingAverageMinMaxObserver'&gt;", "description": "(module) \u2013 Module for observing statistics on input tensors and calculating scale\nand zero-point."}, {"name": "quant_min", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 The minimum allowable quantized value."}, {"name": "quant_max", "is_optional": true, "type": "int", "default_value": "255", "description": ""}, {"name": "**observer_kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.quantization.NoopObserver(dtype=torch.float16)", "id": "torch.quantization.NoopObserver", "summary": "Observer that doesn\u2019t do anything and just passes its configuration to the\nquantized module\u2019s .from_float().\nPrimarily used for quantization to float16 which doesn\u2019t require determining\nranges.\n\nParameters\ndtype \u2013 Quantized data type\n\n\n", "description": "", "code-info": {"name": "torch.quantization.NoopObserver", "parameters": [{"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.float16", "description": ""}]}},
{"code": "torch.quantization.RecordingObserver(**kwargs)", "id": "torch.quantization.RecordingObserver", "summary": "The module is mainly for debug and records the tensor values during runtime.\n\nParameters\n\ndtype \u2013 Quantized data type\nqscheme \u2013 Quantization scheme to be used\nreduce_range \u2013 Reduces the range of the quantized data type by 1 bit\n\n\n\n", "description": "", "code-info": {"name": "torch.quantization.RecordingObserver", "parameters": [{"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.intrinsic.ConvBn2d(conv,bn)", "id": "torch.nn.intrinsic.ConvBn2d", "summary": "This is a sequential container which calls the Conv 2d and Batch Norm 2d modules.\nDuring quantization this will be replaced with the corresponding fused module.\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.ConvBn2d", "parameters": [{"name": "conv", "is_optional": false, "type": "others", "description": ""}, {"name": "bn", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.intrinsic.ConvBnReLU2d(conv,bn,relu)", "id": "torch.nn.intrinsic.ConvBnReLU2d", "summary": "This is a sequential container which calls the Conv 2d, Batch Norm 2d, and ReLU modules.\nDuring quantization this will be replaced with the corresponding fused module.\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.ConvBnReLU2d", "parameters": [{"name": "conv", "is_optional": false, "type": "others", "description": ""}, {"name": "bn", "is_optional": false, "type": "others", "description": ""}, {"name": "relu", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.intrinsic.ConvReLU2d(conv,relu)", "id": "torch.nn.intrinsic.ConvReLU2d", "summary": "This is a sequential container which calls the Conv 2d and ReLU modules.\nDuring quantization this will be replaced with the corresponding fused module.\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.ConvReLU2d", "parameters": [{"name": "conv", "is_optional": false, "type": "others", "description": ""}, {"name": "relu", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.intrinsic.ConvReLU3d(conv,relu)", "id": "torch.nn.intrinsic.ConvReLU3d", "summary": "This is a sequential container which calls the Conv 3d and ReLU modules.\nDuring quantization this will be replaced with the corresponding fused module.\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.ConvReLU3d", "parameters": [{"name": "conv", "is_optional": false, "type": "others", "description": ""}, {"name": "relu", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.intrinsic.LinearReLU(linear,relu)", "id": "torch.nn.intrinsic.LinearReLU", "summary": "This is a sequential container which calls the Linear and ReLU modules.\nDuring quantization this will be replaced with the corresponding fused module.\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.LinearReLU", "parameters": [{"name": "linear", "is_optional": false, "type": "others", "description": ""}, {"name": "relu", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.intrinsic.qat.ConvBn2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)", "id": "torch.nn.intrinsic.qat.ConvBn2d", "summary": "A ConvBn2d module is a module fused from Conv2d and BatchNorm2d,\nattached with FakeQuantize modules for both output activation and weight,\nused in quantization aware training.\nWe combined the interface of torch.nn.Conv2d and\ntorch.nn.BatchNorm2d.\nImplementation details: https://arxiv.org/pdf/1806.08342.pdf section 3.2.2\nSimilar to torch.nn.Conv2d, with FakeQuantize modules initialized\nto default.\n\nVariables\n\n~ConvBn2d.freeze_bn \u2013 \n~ConvBn2d.activation_post_process \u2013 fake quant module for output activation\n~ConvBn2d.weight_fake_quant \u2013 fake quant module for weight\n\n\n\n\n\nclassmethod from_float(mod, qconfig=None) \u00b6\nCreate a qat module from a float module or qparams_dict\nArgs: mod a float module, either produced by torch.quantization utilities\nor directly from user\n\n\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.qat.ConvBn2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "freeze_bn", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.intrinsic.qat.ConvBnReLU2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)", "id": "torch.nn.intrinsic.qat.ConvBnReLU2d", "summary": "A ConvBnReLU2d module is a module fused from Conv2d, BatchNorm2d and ReLU,\nattached with FakeQuantize modules for both output activation and weight,\nused in quantization aware training.\nWe combined the interface of torch.nn.Conv2d and\ntorch.nn.BatchNorm2d and torch.nn.ReLU.\nImplementation details: https://arxiv.org/pdf/1806.08342.pdf\nSimilar to torch.nn.Conv2d, with FakeQuantize modules initialized to\ndefault.\n\nVariables\n\n~ConvBnReLU2d.observer \u2013 fake quant module for output activation, it\u2019s called observer\nto align with post training flow\n~ConvBnReLU2d.weight_fake_quant \u2013 fake quant module for weight\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.qat.ConvBnReLU2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "freeze_bn", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.cuda.current_stream(device=None)", "id": "torch.cuda.current_stream", "summary": "Returns the currently selected Stream for a given device.\n\nParameters\ndevice (torch.device or python:int, optional) \u2013 selected device", "description": "", "code-info": {"name": "torch.cuda.current_stream", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 selected device. Returns\nthe currently selected Stream for the current device, given\nby current_device(), if device is None\n(default)."}]}},
{"code": "torch.cuda.default_stream(device=None)", "id": "torch.cuda.default_stream", "summary": "Returns the default Stream for a given device.\n\nParameters\ndevice (torch.device or python:int, optional) \u2013 selected device", "description": "", "code-info": {"name": "torch.cuda.default_stream", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 selected device. Returns\nthe default Stream for the current device, given by\ncurrent_device(), if device is None\n(default)."}]}},
{"code": "torch.cuda.device_count()", "id": "torch.cuda.device_count", "summary": "Returns the number of GPUs available.\n", "description": "", "code-info": {"name": "torch.cuda.device_count", "parameters": []}},
{"code": "torch.cuda.get_device_capability(device=None)", "id": "torch.cuda.get_device_capability", "summary": "Gets the cuda capability of a device.\n\nParameters\ndevice (torch.device or python:int, optional) \u2013 device for which to return the\ndevice capability", "description": "", "code-info": {"name": "torch.cuda.get_device_capability", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 device for which to return the\ndevice capability. This function is a no-op if this argument is\na negative integer. It uses the current device, given by\ncurrent_device(), if device is None\n(default)."}]}},
{"code": "torch.cuda.get_device_name(device=None)", "id": "torch.cuda.get_device_name", "summary": "Gets the name of a device.\n\nParameters\ndevice (torch.device or python:int, optional) \u2013 device for which to return the\nname", "description": "", "code-info": {"name": "torch.cuda.get_device_name", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 device for which to return the\nname. This function is a no-op if this argument is a negative\ninteger. It uses the current device, given by current_device(),\nif device is None (default)."}]}},
{"code": "torch.cuda.init()", "id": "torch.cuda.init", "summary": "Initialize PyTorch\u2019s CUDA state", "description": "", "code-info": {"name": "torch.cuda.init", "parameters": []}},
{"code": "torch.cuda.ipc_collect()", "id": "torch.cuda.ipc_collect", "summary": "Force collects GPU memory after it has been released by CUDA IPC.\n\nNote\nChecks if any sent CUDA tensors could be cleaned from the memory", "description": "", "code-info": {"name": "torch.cuda.ipc_collect", "parameters": []}},
{"code": "torch.cuda.is_available()", "id": "torch.cuda.is_available", "summary": "Returns a bool indicating if CUDA is currently available.\n", "description": "", "code-info": {"name": "torch.cuda.is_available", "parameters": []}},
{"code": "torch.cuda.is_initialized()", "id": "torch.cuda.is_initialized", "summary": "Returns whether PyTorch\u2019s CUDA state has been initialized.\n", "description": "", "code-info": {"name": "torch.cuda.is_initialized", "parameters": []}},
{"code": "torch.cuda.set_device(device)", "id": "torch.cuda.set_device", "summary": "Sets the current device.\nUsage of this function is discouraged in favor of device", "description": "", "code-info": {"name": "torch.cuda.set_device", "parameters": [{"name": "device", "is_optional": false, "type": "int", "description": "(torch.device or python:int) \u2013 selected device. This function is a no-op\nif this argument is negative."}]}},
{"code": "torch.cuda.stream(stream)", "id": "torch.cuda.stream", "summary": "Context-manager that selects a given stream.\nAll CUDA kernels queued within its context will be enqueued on a selected\nstream.\n\nParameters\nstream (Stream) \u2013 selected stream", "description": "", "code-info": {"name": "torch.cuda.stream", "parameters": [{"name": "stream", "is_optional": false, "type": "others", "description": "(Stream) \u2013 selected stream. This manager is a no-op if it\u2019s\nNone."}]}},
{"code": "torch.cuda.synchronize(device=None)", "id": "torch.cuda.synchronize", "summary": "Waits for all kernels in all streams on a CUDA device to complete.\n\nParameters\ndevice (torch.device or python:int, optional) \u2013 device for which to synchronize.\nIt uses the current device, given by current_device(),\nif device is None (default).\n\n\n", "description": "", "code-info": {"name": "torch.cuda.synchronize", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 device for which to synchronize.\nIt uses the current device, given by current_device(),\nif device is None (default)."}]}},
{"code": "torch.cuda.get_rng_state(device='cuda')", "id": "torch.cuda.get_rng_state", "summary": "Returns the random number generator state of the specified GPU as a ByteTensor.\n\nParameters\ndevice (torch.device or python:int, optional) \u2013 The device to return the RNG state of.\nDefault: 'cuda' (i.e., torch.device('cuda'), the current CUDA device).\n\n\n\nWarning\nThis function eagerly initializes CUDA.\n\n", "description": "", "code-info": {"name": "torch.cuda.get_rng_state", "parameters": [{"name": "device", "is_optional": true, "type": "string", "default_value": "'cuda'", "description": "(torch.device or python:int, optional) \u2013 The device to return the RNG state of.\nDefault: 'cuda' (i.e., torch.device('cuda'), the current CUDA device)."}]}},
{"code": "torch.cuda.get_rng_state_all()", "id": "torch.cuda.get_rng_state_all", "summary": "Returns a tuple of ByteTensor representing the random number states of all devices.\n", "description": "", "code-info": {"name": "torch.cuda.get_rng_state_all", "parameters": []}},
{"code": "torch.cuda.set_rng_state(new_state,device='cuda')", "id": "torch.cuda.set_rng_state", "summary": "Sets the random number generator state of the specified GPU.\n\nParameters\n\nnew_state (torch.ByteTensor) \u2013 The desired state\ndevice (torch.device or python:int, optional) \u2013 The device to set the RNG state.\nDefault: 'cuda' (i.e., torch.device('cuda'), the current CUDA device).\n\n\n\n", "description": "", "code-info": {"name": "torch.cuda.set_rng_state", "parameters": [{"name": "new_state", "is_optional": false, "type": "tensor", "description": "(torch.ByteTensor) \u2013 The desired state"}, {"name": "device", "is_optional": true, "type": "string", "default_value": "'cuda'", "description": "(torch.device or python:int, optional) \u2013 The device to set the RNG state.\nDefault: 'cuda' (i.e., torch.device('cuda'), the current CUDA device)."}]}},
{"code": "torch.cuda.set_rng_state_all(new_states)", "id": "torch.cuda.set_rng_state_all", "summary": "Sets the random number generator state of all devices.\n\nParameters\nnew_state (tuple of torch.ByteTensor) \u2013 The desired state for each device\n\n\n", "description": "", "code-info": {"name": "torch.cuda.set_rng_state_all", "parameters": [{"name": "new_states", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.cuda.manual_seed(seed)", "id": "torch.cuda.manual_seed", "summary": "Sets the seed for generating random numbers for the current GPU.\nIt\u2019s safe to call this function if CUDA is not available; in that\ncase, it is silently ignored.\n\nParameters\nseed (python:int) \u2013 The desired seed.\n\n\n\nWarning\nIf you are working with a multi-GPU model, this function is insufficient\nto get determinism", "description": "", "code-info": {"name": "torch.cuda.manual_seed", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": "(python:int) \u2013 The desired seed."}]}},
{"code": "torch.cuda.manual_seed_all(seed)", "id": "torch.cuda.manual_seed_all", "summary": "Sets the seed for generating random numbers on all GPUs.\nIt\u2019s safe to call this function if CUDA is not available; in that\ncase, it is silently ignored.\n\nParameters\nseed (python:int) \u2013 The desired seed.\n\n\n", "description": "", "code-info": {"name": "torch.cuda.manual_seed_all", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": "(python:int) \u2013 The desired seed."}]}},
{"code": "torch.cuda.seed()", "id": "torch.cuda.seed", "summary": "Sets the seed for generating random numbers to a random number for the current GPU.\nIt\u2019s safe to call this function if CUDA is not available; in that\ncase, it is silently ignored.\n\nWarning\nIf you are working with a multi-GPU model, this function will only initialize\nthe seed on one GPU", "description": "", "code-info": {"name": "torch.cuda.seed", "parameters": []}},
{"code": "torch.autograd.grad(outputs,inputs,grad_outputs=None,retain_graph=None,create_graph=False,only_inputs=True,allow_unused=False)", "id": "torch.autograd.grad", "summary": "Computes and returns the sum of gradients of outputs w.r.t", "description": "", "code-info": {"name": "torch.autograd.grad", "parameters": [{"name": "outputs", "is_optional": false, "type": "tensor", "description": "(sequence of Tensor) \u2013 outputs of the differentiated function."}, {"name": "inputs", "is_optional": false, "type": "tensor", "description": "(sequence of Tensor) \u2013 Inputs w.r.t. which the gradient will be\nreturned (and not accumulated into .grad)."}, {"name": "grad_outputs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(sequence of Tensor) \u2013 The \u201cvector\u201d in the Jacobian-vector product.\nUsually gradients w.r.t. each output. None values can be specified for scalar\nTensors or ones that don\u2019t require grad. If a None value would be acceptable\nfor all grad_tensors, then this argument is optional. Default: None."}, {"name": "retain_graph", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 If False, the graph used to compute the grad\nwill be freed. Note that in nearly all cases setting this option to True\nis not needed and often can be worked around in a much more efficient\nway. Defaults to the value of create_graph."}, {"name": "create_graph", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "only_inputs", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "allow_unused", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If False, specifying inputs that were not\nused when computing outputs (and therefore their grad is always zero)\nis an error. Defaults to False."}]}},
{"code": "torch.autograd.gradcheck(func,inputs,eps=1e-06,atol=1e-05,rtol=0.001,raise_exception=True,check_sparse_nnz=False,nondet_tol=0.0)", "id": "torch.autograd.gradcheck", "summary": "Check gradients computed via small finite differences against analytical\ngradients w.r.t", "description": "", "code-info": {"name": "torch.autograd.gradcheck", "parameters": [{"name": "func", "is_optional": false, "type": "others", "description": "(function) \u2013 a Python function that takes Tensor inputs and returns\na Tensor or a tuple of Tensors"}, {"name": "inputs", "is_optional": false, "type": "tensor", "description": "(tuple of Tensor or Tensor) \u2013 inputs to the function"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-06", "description": "(python:float, optional) \u2013 perturbation for finite differences"}, {"name": "atol", "is_optional": true, "type": "float", "default_value": "1e-05", "description": "(python:float, optional) \u2013 absolute tolerance"}, {"name": "rtol", "is_optional": true, "type": "float", "default_value": "0.001", "description": "(python:float, optional) \u2013 relative tolerance"}, {"name": "raise_exception", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 indicating whether to raise an exception if\nthe check fails. The exception gives more information about the\nexact nature of the failure. This is helpful when debugging gradchecks."}, {"name": "check_sparse_nnz", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 if True, gradcheck allows for SparseTensor input,\nand for any SparseTensor at input, gradcheck will perform check at nnz positions only."}, {"name": "nondet_tol", "is_optional": true, "type": "float", "default_value": "0.0", "description": "(python:float, optional) \u2013 tolerance for non-determinism. When running\nidentical inputs through the differentiation, the results must either match\nexactly (default, 0.0) or be within this tolerance."}]}},
{"code": "torch.autograd.gradgradcheck(func,inputs,grad_outputs=None,eps=1e-06,atol=1e-05,rtol=0.001,gen_non_contig_grad_outputs=False,raise_exception=True,nondet_tol=0.0)", "id": "torch.autograd.gradgradcheck", "summary": "Check gradients of gradients computed via small finite differences\nagainst analytical gradients w.r.t", "description": "", "code-info": {"name": "torch.autograd.gradgradcheck", "parameters": [{"name": "func", "is_optional": false, "type": "others", "description": "(function) \u2013 a Python function that takes Tensor inputs and returns\na Tensor or a tuple of Tensors"}, {"name": "inputs", "is_optional": false, "type": "tensor", "description": "(tuple of Tensor or Tensor) \u2013 inputs to the function"}, {"name": "grad_outputs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(tuple of Tensor or Tensor, optional) \u2013 The gradients with\nrespect to the function\u2019s outputs."}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-06", "description": "(python:float, optional) \u2013 perturbation for finite differences"}, {"name": "atol", "is_optional": true, "type": "float", "default_value": "1e-05", "description": "(python:float, optional) \u2013 absolute tolerance"}, {"name": "rtol", "is_optional": true, "type": "float", "default_value": "0.001", "description": "(python:float, optional) \u2013 relative tolerance"}, {"name": "gen_non_contig_grad_outputs", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 if grad_outputs is\nNone and gen_non_contig_grad_outputs is True, the\nrandomly generated gradient outputs are made to be noncontiguous"}, {"name": "raise_exception", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 indicating whether to raise an exception if\nthe check fails. The exception gives more information about the\nexact nature of the failure. This is helpful when debugging gradchecks."}, {"name": "nondet_tol", "is_optional": true, "type": "float", "default_value": "0.0", "description": "(python:float, optional) \u2013 tolerance for non-determinism. When running\nidentical inputs through the differentiation, the results must either match\nexactly (default, 0.0) or be within this tolerance. Note that a small amount\nof nondeterminism in the gradient will lead to larger inaccuracies in\nthe second derivative."}]}},
{"code": "torch.autograd.profiler.load_nvprof(path)", "id": "torch.autograd.profiler.load_nvprof", "summary": "Opens an nvprof trace file and parses autograd annotations.\n\nParameters\npath (str) \u2013 path to nvprof trace\n\n\n", "description": "", "code-info": {"name": "torch.autograd.profiler.load_nvprof", "parameters": [{"name": "path", "is_optional": false, "type": "others", "description": "(str) \u2013 path to nvprof trace"}]}},
{"code": "torch.Tensor.backward(gradient=None,retain_graph=None,create_graph=False)", "id": "torch.Tensor.backward", "summary": "Computes the gradient of current tensor w.r.t", "description": "", "code-info": {"name": "torch.Tensor.backward", "parameters": [{"name": "gradient", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor or None) \u2013 Gradient w.r.t. the\ntensor. If it is a tensor, it will be automatically converted\nto a Tensor that does not require grad unless create_graph is True.\nNone values can be specified for scalar Tensors or ones that\ndon\u2019t require grad. If a None value would be acceptable then\nthis argument is optional."}, {"name": "retain_graph", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 If False, the graph used to compute\nthe grads will be freed. Note that in nearly all cases setting\nthis option to True is not needed and often can be worked around\nin a much more efficient way. Defaults to the value of\ncreate_graph."}, {"name": "create_graph", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If True, graph of the derivative will\nbe constructed, allowing to compute higher order derivative\nproducts. Defaults to False."}]}},
{"code": "torch.Tensor.detach()", "id": "torch.Tensor.detach", "summary": "Returns a new Tensor, detached from the current graph.\nThe result will never require gradient.\n\nNote\nReturned Tensor shares the same storage with the original one.\nIn-place modifications on either of them will be seen, and may trigger\nerrors in correctness checks.\nIMPORTANT NOTE: Previously, in-place size / stride / storage changes\n(such as resize_ / resize_as_ / set_ / transpose_) to the returned tensor\nalso update the original tensor", "description": "", "code-info": {"name": "torch.Tensor.detach", "parameters": []}},
{"code": "torch.Tensor.detach_()", "id": "torch.Tensor.detach_", "summary": "Detaches the Tensor from the graph that created it, making it a leaf.\nViews cannot be detached in-place.\n", "description": "", "code-info": {"name": "torch.Tensor.detach_", "parameters": []}},
{"code": "torch.Tensor.register_hook(hook)", "id": "torch.Tensor.register_hook", "summary": "Registers a backward hook.\nThe hook will be called every time a gradient with respect to the\nTensor is computed", "description": "", "code-info": {"name": "torch.Tensor.register_hook", "parameters": [{"name": "hook", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.retain_grad()", "id": "torch.Tensor.retain_grad", "summary": "Enables .grad attribute for non-leaf Tensors.\n", "description": "", "code-info": {"name": "torch.Tensor.retain_grad", "parameters": []}},
{"code": "torch.autograd.Function.backward(ctx,*grad_outputs)", "id": "torch.autograd.Function.backward", "summary": "Defines a formula for differentiating the operation.\nThis function is to be overridden by all subclasses.\nIt must accept a context ctx as the first argument, followed by\nas many outputs did forward() return, and it should return as many\ntensors, as there were inputs to forward()", "description": "", "code-info": {"name": "torch.autograd.Function.backward", "parameters": [{"name": "ctx", "is_optional": false, "type": "others", "description": ""}, {"name": "*grad_outputs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.autograd.Function.forward(ctx,*args,**kwargs)", "id": "torch.autograd.Function.forward", "summary": "Performs the operation.\nThis function is to be overridden by all subclasses.\nIt must accept a context ctx as the first argument, followed by any\nnumber of arguments (tensors or other types).\nThe context can be used to store tensors that can be then retrieved\nduring the backward pass.\n", "description": "", "code-info": {"name": "torch.autograd.Function.forward", "parameters": [{"name": "ctx", "is_optional": false, "type": "others", "description": ""}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.autograd.function._ContextMethodMixin.mark_dirty(*args)", "id": "torch.autograd.function._ContextMethodMixin.mark_dirty", "summary": "Marks given tensors as modified in an in-place operation.\nThis should be called at most once, only from inside the\nforward() method, and all arguments should be inputs.\nEvery tensor that\u2019s been modified in-place in a call to forward()\nshould be given to this function, to ensure correctness of our checks.\nIt doesn\u2019t matter whether the function is called before or after\nmodification.\n", "description": "", "code-info": {"name": "torch.autograd.function._ContextMethodMixin.mark_dirty", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.autograd.function._ContextMethodMixin.mark_non_differentiable(*args)", "id": "torch.autograd.function._ContextMethodMixin.mark_non_differentiable", "summary": "Marks outputs as non-differentiable.\nThis should be called at most once, only from inside the\nforward() method, and all arguments should be outputs.\nThis will mark outputs as not requiring gradients, increasing the\nefficiency of backward computation", "description": "", "code-info": {"name": "torch.autograd.function._ContextMethodMixin.mark_non_differentiable", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.autograd.function._ContextMethodMixin.save_for_backward(*tensors)", "id": "torch.autograd.function._ContextMethodMixin.save_for_backward", "summary": "Saves given tensors for a future call to backward().\nThis should be called at most once, and only from inside the\nforward() method.\nLater, saved tensors can be accessed through the saved_tensors\nattribute", "description": "", "code-info": {"name": "torch.autograd.function._ContextMethodMixin.save_for_backward", "parameters": [{"name": "*tensors", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.optim.Adamax(params,lr=0.002,betas=(0.9,0.999)", "id": "torch.optim.Adamax", "summary": "Implements Adamax algorithm (a variant of Adam based on infinity norm).\nIt has been proposed in Adam: A Method for Stochastic Optimization.\n\nParameters\n\nparams (iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups\nlr (python:float, optional) \u2013 learning rate (default: 2e-3)\nbetas (Tuple[python:float, python:float], optional) \u2013 coefficients used for computing\nrunning averages of gradient and its square\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-8)\nweight_decay (python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)\n\n\n\n\n\nstep(closure=None) \u00b6\nPerforms a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n\n\n", "description": "", "code-info": {"name": "torch.optim.Adamax", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups"}, {"name": "lr", "is_optional": true, "type": "float", "default_value": "0.002", "description": "(python:float, optional) \u2013 learning rate (default: 2e-3)"}, {"name": "betas", "is_optional": false, "type": "float", "description": "(Tuple[python:float, python:float], optional) \u2013 coefficients used for computing\nrunning averages of gradient and its square\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-8)\nweight_decay (python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)"}]}},
{"code": "torch.optim.ASGD(params,lr=0.01,lambd=0.0001,alpha=0.75,t0=1000000.0,weight_decay=0)", "id": "torch.optim.ASGD", "summary": "Implements Averaged Stochastic Gradient Descent.\nIt has been proposed in Acceleration of stochastic approximation by\naveraging.\n\nParameters\n\nparams (iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups\nlr (python:float, optional) \u2013 learning rate (default: 1e-2)\nlambd (python:float, optional) \u2013 decay term (default: 1e-4)\nalpha (python:float, optional) \u2013 power for eta update (default: 0.75)\nt0 (python:float, optional) \u2013 point at which to start averaging (default: 1e6)\nweight_decay (python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)\n\n\n\n\n\nstep(closure=None) \u00b6\nPerforms a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n\n\n", "description": "", "code-info": {"name": "torch.optim.ASGD", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups"}, {"name": "lr", "is_optional": true, "type": "float", "default_value": "0.01", "description": "(python:float, optional) \u2013 learning rate (default: 1e-2)"}, {"name": "lambd", "is_optional": true, "type": "float", "default_value": "0.0001", "description": "(python:float, optional) \u2013 decay term (default: 1e-4)"}, {"name": "alpha", "is_optional": true, "type": "float", "default_value": "0.75", "description": "(python:float, optional) \u2013 power for eta update (default: 0.75)"}, {"name": "t0", "is_optional": true, "type": "float", "default_value": "1000000.0", "description": "(python:float, optional) \u2013 point at which to start averaging (default: 1e6)"}, {"name": "weight_decay", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)"}]}},
{"code": "torch.optim.LBFGS(params,lr=1,max_iter=20,max_eval=None,tolerance_grad=1e-07,tolerance_change=1e-09,history_size=100,line_search_fn=None)", "id": "torch.optim.LBFGS", "summary": "Implements L-BFGS algorithm, heavily inspired by minFunc\n&lt;https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html&gt;.\n\nWarning\nThis optimizer doesn\u2019t support per-parameter options and parameter\ngroups (there can be only one).\n\n\nWarning\nRight now all parameters have to be on a single device", "description": "", "code-info": {"name": "torch.optim.LBFGS", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": ""}, {"name": "lr", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:float) \u2013 learning rate (default: 1)"}, {"name": "max_iter", "is_optional": true, "type": "int", "default_value": "20", "description": "(python:int) \u2013 maximal number of iterations per optimization step\n(default: 20)"}, {"name": "max_eval", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 maximal number of function evaluations per optimization\nstep (default: max_iter * 1.25)."}, {"name": "tolerance_grad", "is_optional": true, "type": "float", "default_value": "1e-07", "description": "(python:float) \u2013 termination tolerance on first order optimality\n(default: 1e-5)."}, {"name": "tolerance_change", "is_optional": true, "type": "float", "default_value": "1e-09", "description": "(python:float) \u2013 termination tolerance on function\nvalue/parameter changes (default: 1e-9)."}, {"name": "history_size", "is_optional": true, "type": "int", "default_value": "100", "description": "(python:int) \u2013 update history size (default: 100)."}, {"name": "line_search_fn", "is_optional": true, "type": "others", "default_value": "None", "description": "(str) \u2013 either \u2018strong_wolfe\u2019 or None (default: None)."}]}},
{"code": "torch.optim.RMSprop(params,lr=0.01,alpha=0.99,eps=1e-08,weight_decay=0,momentum=0,centered=False)", "id": "torch.optim.RMSprop", "summary": "Implements RMSprop algorithm.\nProposed by G", "description": "", "code-info": {"name": "torch.optim.RMSprop", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups"}, {"name": "lr", "is_optional": true, "type": "float", "default_value": "0.01", "description": "(python:float, optional) \u2013 learning rate (default: 1e-2)\nmomentum (python:float, optional) \u2013 momentum factor (default: 0)"}, {"name": "alpha", "is_optional": true, "type": "float", "default_value": "0.99", "description": "(python:float, optional) \u2013 smoothing constant (default: 0.99)"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-08", "description": "(python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-8)\ncentered (bool, optional) \u2013 if True, compute the centered RMSProp,\nthe gradient is normalized by an estimation of its variance"}, {"name": "weight_decay", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)\n\n\n\n\n\nstep(closure=None) \u00b6\nPerforms a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n\n\n"}, {"name": "momentum", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float, optional) \u2013 momentum factor (default: 0)\nalpha (python:float, optional) \u2013 smoothing constant (default: 0.99)\neps (python:float, optional) \u2013 term added to the denominator to improve\nnumerical stability (default: 1e-8)"}, {"name": "centered", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 if True, compute the centered RMSProp,\nthe gradient is normalized by an estimation of its variance\nweight_decay (python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)"}]}},
{"code": "torch.optim.Rprop(params,lr=0.01,etas=(0.5,1.2)", "id": "torch.optim.Rprop", "summary": "Implements the resilient backpropagation algorithm.\n\nParameters\n\nparams (iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups\nlr (python:float, optional) \u2013 learning rate (default: 1e-2)\netas (Tuple[python:float, python:float], optional) \u2013 pair of (etaminus, etaplis), that\nare multiplicative increase and decrease factors\n(default: (0.5, 1.2))\nstep_sizes (Tuple[python:float, python:float], optional) \u2013 a pair of minimal and\nmaximal allowed step sizes (default: (1e-6, 50))\n\n\n\n\n\nstep(closure=None) \u00b6\nPerforms a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n\n\n", "description": "", "code-info": {"name": "torch.optim.Rprop", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups"}, {"name": "lr", "is_optional": true, "type": "float", "default_value": "0.01", "description": "(python:float, optional) \u2013 learning rate (default: 1e-2)"}, {"name": "etas", "is_optional": false, "type": "float", "description": "(Tuple[python:float, python:float], optional) \u2013 pair of (etaminus, etaplis), that\nare multiplicative increase and decrease factors\n(default: (0.5, 1.2))\nstep_sizes (Tuple[python:float, python:float], optional) \u2013 a pair of minimal and\nmaximal allowed step sizes (default: (1e-6, 50))"}]}},
{"code": "torch.optim.SGD(params,lr=&lt;requiredparameter&gt;,momentum=0,dampening=0,weight_decay=0,nesterov=False)", "id": "torch.optim.SGD", "summary": "Implements stochastic gradient descent (optionally with momentum).\nNesterov momentum is based on the formula from\nOn the importance of initialization and momentum in deep learning.\n\nParameters\n\nparams (iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups\nlr (python:float) \u2013 learning rate\nmomentum (python:float, optional) \u2013 momentum factor (default: 0)\nweight_decay (python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)\ndampening (python:float, optional) \u2013 dampening for momentum (default: 0)\nnesterov (bool, optional) \u2013 enables Nesterov momentum (default: False)\n\n\n\nExample\n&gt;&gt;&gt; optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n&gt;&gt;&gt; optimizer.zero_grad()\n&gt;&gt;&gt; loss_fn(model(input), target).backward()\n&gt;&gt;&gt; optimizer.step()\n\n\n\nNote\nThe implementation of SGD with Momentum/Nesterov subtly differs from\nSutskever et", "description": "", "code-info": {"name": "torch.optim.SGD", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of parameters to optimize or dicts defining\nparameter groups"}, {"name": "lr", "is_optional": true, "type": "float", "default_value": "&lt;requiredparameter&gt;", "description": "(python:float) \u2013 learning rate"}, {"name": "momentum", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float, optional) \u2013 momentum factor (default: 0)\nweight_decay (python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)"}, {"name": "dampening", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float, optional) \u2013 dampening for momentum (default: 0)\nnesterov (bool, optional) \u2013 enables Nesterov momentum (default: False)\n\n\n\nExample\n&gt;&gt;&gt; optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n&gt;&gt;&gt; optimizer.zero_grad()\n&gt;&gt;&gt; loss_fn(model(input), target).backward()\n&gt;&gt;&gt; optimizer.step()\n\n\n\nNote\nThe implementation of SGD with Momentum/Nesterov subtly differs from\nSutskever et. al. and implementations in some other frameworks.\nConsidering the specific case of Momentum, the update can be written as\n\nvt+1=\u03bc\u2217vt+gt+1pt+1=pt\u2212lr\u2217vt+1v_{t+1} = \\mu * v_{t} + g_{t+1} \\\\\np_{t+1} = p_{t} - lr * v_{t+1}\n\nvt+1\u200b=\u03bc\u2217vt\u200b+gt+1\u200bpt+1\u200b=pt\u200b\u2212lr\u2217vt+1\u200b\n\nwhere p, g, v and \u03bc\\mu\u03bc\n\n denote the parameters, gradient,\nvelocity, and momentum respectively.\nThis is in contrast to Sutskever et. al. and\nother frameworks which employ an update of the form\n\nvt+1=\u03bc\u2217vt+lr\u2217gt+1pt+1=pt\u2212vt+1v_{t+1} = \\mu * v_{t} + lr * g_{t+1} \\\\\np_{t+1} = p_{t} - v_{t+1}\n\nvt+1\u200b=\u03bc\u2217vt\u200b+lr\u2217gt+1\u200bpt+1\u200b=pt\u200b\u2212vt+1\u200b\n\nThe Nesterov version is analogously modified.\n\n\n\nstep(closure=None) \u00b6\nPerforms a single optimization step.\n\nParameters\nclosure (callable, optional) \u2013 A closure that reevaluates the model\nand returns the loss.\n\n\n\n\n"}, {"name": "weight_decay", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float, optional) \u2013 weight decay (L2 penalty) (default: 0)\ndampening (python:float, optional) \u2013 dampening for momentum (default: 0)"}, {"name": "nesterov", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 enables Nesterov momentum (default: False)"}]}},
{"code": "torch.optim.lr_scheduler.LambdaLR(optimizer,lr_lambda,last_epoch=-1)", "id": "torch.optim.lr_scheduler.LambdaLR", "summary": "Sets the learning rate of each parameter group to the initial lr\ntimes a given function", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.LambdaLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "others", "description": "(Optimizer) \u2013 Wrapped optimizer."}, {"name": "lr_lambda", "is_optional": false, "type": "others", "description": "(function or list) \u2013 A function which computes a multiplicative\nfactor given an integer parameter epoch, or a list of such\nfunctions, one for each group in optimizer.param_groups."}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 The index of last epoch. Default: -1."}]}},
{"code": "torch.optim.lr_scheduler.MultiplicativeLR(optimizer,lr_lambda,last_epoch=-1)", "id": "torch.optim.lr_scheduler.MultiplicativeLR", "summary": "Multiply the learning rate of each parameter group by the factor given\nin the specified function", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.MultiplicativeLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "others", "description": "(Optimizer) \u2013 Wrapped optimizer."}, {"name": "lr_lambda", "is_optional": false, "type": "others", "description": "(function or list) \u2013 A function which computes a multiplicative\nfactor given an integer parameter epoch, or a list of such\nfunctions, one for each group in optimizer.param_groups."}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 The index of last epoch. Default: -1."}]}},
{"code": "torch.optim.lr_scheduler.StepLR(optimizer,step_size,gamma=0.1,last_epoch=-1)", "id": "torch.optim.lr_scheduler.StepLR", "summary": "Decays the learning rate of each parameter group by gamma every\nstep_size epochs", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.StepLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "others", "description": "(Optimizer) \u2013 Wrapped optimizer."}, {"name": "step_size", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Period of learning rate decay."}, {"name": "gamma", "is_optional": true, "type": "float", "default_value": "0.1", "description": "(python:float) \u2013 Multiplicative factor of learning rate decay.\nDefault: 0.1."}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 The index of last epoch. Default: -1."}]}},
{"code": "torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones,gamma=0.1,last_epoch=-1)", "id": "torch.optim.lr_scheduler.MultiStepLR", "summary": "Decays the learning rate of each parameter group by gamma once the\nnumber of epoch reaches one of the milestones", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.MultiStepLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "others", "description": "(Optimizer) \u2013 Wrapped optimizer."}, {"name": "milestones", "is_optional": false, "type": "others", "description": "(list) \u2013 List of epoch indices. Must be increasing."}, {"name": "gamma", "is_optional": true, "type": "float", "default_value": "0.1", "description": "(python:float) \u2013 Multiplicative factor of learning rate decay.\nDefault: 0.1."}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 The index of last epoch. Default: -1."}]}},
{"code": "sig-name descname(p_tensor,*,generator=None)", "id": "sig-name descname", "summary": "p_tensor should be a tensor containing probabilities to be used for\ndrawing the binary random number.\nThe ith\\text{i}^{th}ith\n\n element of self tensor will be set to a\nvalue sampled from Bernoulli(p_tensor[i])\\text{Bernoulli}(\\texttt{p\\_tensor[i]})Bernoulli(p_tensor[i])\n\n.\nself can have integral dtype, but p_tensor must have\nfloating point dtype.\n", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "p_tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-name descname(dtype,non_blocking=False,copy=False)", "id": "sig-name descname", "summary": "Returns a Tensor with the specified dtype\n", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "dtype", "is_optional": false, "type": "others", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "copy", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "sig-name descname(device=None,dtype=None,non_blocking=False,copy=False)", "id": "sig-name descname", "summary": "Returns a Tensor with the specified device and (optional)\ndtype", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "copy", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "sig-name descname(other,non_blocking=False,copy=False)", "id": "sig-name descname", "summary": "Returns a Tensor with same torch.dtype and torch.device as\nthe Tensor other", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "copy", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "sig-name descname()", "id": "sig-name descname", "summary": "", "description": "", "code-info": {"name": "sig-name descname", "parameters": []}},
{"code": "sig-name descname(dim,keepdim=False,out=None)", "id": "sig-name descname", "summary": "", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-name descname()", "id": "sig-name descname", "summary": "", "description": "", "code-info": {"name": "sig-name descname", "parameters": []}},
{"code": "sig-name descname(dim,keepdim=False,out=None)", "id": "sig-name descname", "summary": "", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.new_tensor(data,dtype=None,device=None,requires_grad=False)", "id": "torch.Tensor.new_tensor", "summary": "Returns a new Tensor with data as the tensor data.\nBy default, the returned Tensor has the same torch.dtype and\ntorch.device as this tensor.\n\nWarning\nnew_tensor() always copies data", "description": "", "code-info": {"name": "torch.Tensor.new_tensor", "parameters": [{"name": "data", "is_optional": false, "type": "others", "description": "(array_like) \u2013 The returned Tensor copies data."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.Tensor.new_full(size,fill_value,dtype=None,device=None,requires_grad=False)", "id": "torch.Tensor.new_full", "summary": "Returns a Tensor of size size filled with fill_value.\nBy default, the returned Tensor has the same torch.dtype and\ntorch.device as this tensor.\n\nParameters\n\nfill_value (scalar) \u2013 the number to fill the output tensor with.\ndtype (torch.dtype, optional) \u2013 the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor.\nrequires_grad (bool, optional) \u2013 If autograd should record operations on the\nreturned tensor", "description": "", "code-info": {"name": "torch.Tensor.new_full", "parameters": [{"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "fill_value", "is_optional": false, "type": "others", "description": "(scalar) \u2013 the number to fill the output tensor with."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.Tensor.new_empty(size,dtype=None,device=None,requires_grad=False)", "id": "torch.Tensor.new_empty", "summary": "Returns a Tensor of size size filled with uninitialized data.\nBy default, the returned Tensor has the same torch.dtype and\ntorch.device as this tensor.\n\nParameters\n\ndtype (torch.dtype, optional) \u2013 the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor.\nrequires_grad (bool, optional) \u2013 If autograd should record operations on the\nreturned tensor", "description": "", "code-info": {"name": "torch.Tensor.new_empty", "parameters": [{"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.Tensor.new_ones(size,dtype=None,device=None,requires_grad=False)", "id": "torch.Tensor.new_ones", "summary": "Returns a Tensor of size size filled with 1.\nBy default, the returned Tensor has the same torch.dtype and\ntorch.device as this tensor.\n\nParameters\n\nsize (python:int...) \u2013 a list, tuple, or torch.Size of integers defining the\nshape of the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor.\nrequires_grad (bool, optional) \u2013 If autograd should record operations on the\nreturned tensor", "description": "", "code-info": {"name": "torch.Tensor.new_ones", "parameters": [{"name": "size", "is_optional": false, "type": "int", "description": "(python:int...) \u2013 a list, tuple, or torch.Size of integers defining the\nshape of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.nn.functional.conv2d(input,weight,bias=None,stride=1,padding=0,dilation=1,groups=1)", "id": "torch.nn.functional.conv2d", "summary": "Applies a 2D convolution over an input image composed of several input\nplanes.\nSee Conv2d for details and output shape.\n\nNote\nIn some circumstances when using the CUDA backend with CuDNN, this operator\nmay select a nondeterministic algorithm to increase performance", "description": "", "code-info": {"name": "torch.nn.functional.conv2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torch.nn.functional.conv3d(input,weight,bias=None,stride=1,padding=0,dilation=1,groups=1)", "id": "torch.nn.functional.conv3d", "summary": "Applies a 3D convolution over an input image composed of several input\nplanes.\nSee Conv3d for details and output shape.\n\nNote\nIn some circumstances when using the CUDA backend with CuDNN, this operator\nmay select a nondeterministic algorithm to increase performance", "description": "", "code-info": {"name": "torch.nn.functional.conv3d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torch.nn.functional.conv_transpose1d(input,weight,bias=None,stride=1,padding=0,output_padding=0,groups=1,dilation=1)", "id": "torch.nn.functional.conv_transpose1d", "summary": "Applies a 1D transposed convolution operator over an input signal\ncomposed of several input planes, sometimes also called \u201cdeconvolution\u201d.\nSee ConvTranspose1d for details and output shape.\n\nNote\nIn some circumstances when using the CUDA backend with CuDNN, this operator\nmay select a nondeterministic algorithm to increase performance", "description": "", "code-info": {"name": "torch.nn.functional.conv_transpose1d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "output_padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torch.nn.functional.conv_transpose2d(input,weight,bias=None,stride=1,padding=0,output_padding=0,groups=1,dilation=1)", "id": "torch.nn.functional.conv_transpose2d", "summary": "Applies a 2D transposed convolution operator over an input image\ncomposed of several input planes, sometimes also called \u201cdeconvolution\u201d.\nSee ConvTranspose2d for details and output shape.\n\nNote\nIn some circumstances when using the CUDA backend with CuDNN, this operator\nmay select a nondeterministic algorithm to increase performance", "description": "", "code-info": {"name": "torch.nn.functional.conv_transpose2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "output_padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torch.nn.functional.conv_transpose3d(input,weight,bias=None,stride=1,padding=0,output_padding=0,groups=1,dilation=1)", "id": "torch.nn.functional.conv_transpose3d", "summary": "Applies a 3D transposed convolution operator over an input image\ncomposed of several input planes, sometimes also called \u201cdeconvolution\u201d\nSee ConvTranspose3d for details and output shape.\n\nNote\nIn some circumstances when using the CUDA backend with CuDNN, this operator\nmay select a nondeterministic algorithm to increase performance", "description": "", "code-info": {"name": "torch.nn.functional.conv_transpose3d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "output_padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torch.nn.functional.unfold(input,kernel_size,dilation=1,padding=0,stride=1)", "id": "torch.nn.functional.unfold", "summary": "Extracts sliding local blocks from an batched input tensor.\n\nWarning\nCurrently, only 4-D input tensors (batched image-like tensors) are\nsupported.\n\n\nWarning\nMore than one element of the unfolded tensor may refer to a single\nmemory location", "description": "", "code-info": {"name": "torch.nn.functional.unfold", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torch.nn.functional.fold(input,output_size,kernel_size,dilation=1,padding=0,stride=1)", "id": "torch.nn.functional.fold", "summary": "Combines an array of sliding local blocks into a large containing\ntensor.\n\nWarning\nCurrently, only 4-D output tensors (batched image-like tensors) are\nsupported.\n\nSee torch.nn.Fold for details\n", "description": "", "code-info": {"name": "torch.nn.functional.fold", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "output_size", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torch.nn.functional.avg_pool1d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True)", "id": "torch.nn.functional.avg_pool1d", "summary": "Applies a 1D average pooling over an input signal composed of several\ninput planes.\nSee AvgPool1d for details and output shape.\n\nParameters\n\ninput \u2013 input tensor of shape (minibatch,in_channels,iW)(\\text{minibatch} , \\text{in\\_channels} , iW)(minibatch,in_channels,iW)\n\n\nkernel_size \u2013 the size of the window", "description": "", "code-info": {"name": "torch.nn.functional.avg_pool1d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "count_include_pad", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.functional.avg_pool2d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)", "id": "torch.nn.functional.avg_pool2d", "summary": "Applies 2D average-pooling operation in kH\u00d7kWkH \\times kWkH\u00d7kW\n\n regions by step size\nsH\u00d7sWsH \\times sWsH\u00d7sW\n\n steps", "description": "", "code-info": {"name": "torch.nn.functional.avg_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "count_include_pad", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "divisor_override", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.binomial.Binomial.expand(batch_shape,_instance=None)", "id": "torch.distributions.binomial.Binomial.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.binomial.Binomial.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.binomial.Binomial.log_prob(value)", "id": "torch.distributions.binomial.Binomial.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.binomial.Binomial.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.binomial.Binomial.sample(sample_shape=torch.Size([])", "id": "torch.distributions.binomial.Binomial.sample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.binomial.Binomial.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.categorical.Categorical.entropy()", "id": "torch.distributions.categorical.Categorical.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.categorical.Categorical.entropy", "parameters": []}},
{"code": "torch.distributions.categorical.Categorical.enumerate_support(expand=True)", "id": "torch.distributions.categorical.Categorical.enumerate_support", "summary": "", "description": "", "code-info": {"name": "torch.distributions.categorical.Categorical.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.distributions.categorical.Categorical.expand(batch_shape,_instance=None)", "id": "torch.distributions.categorical.Categorical.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.categorical.Categorical.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.categorical.Categorical.log_prob(value)", "id": "torch.distributions.categorical.Categorical.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.categorical.Categorical.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.categorical.Categorical.sample(sample_shape=torch.Size([])", "id": "torch.distributions.categorical.Categorical.sample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.categorical.Categorical.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.cauchy.Cauchy.cdf(value)", "id": "torch.distributions.cauchy.Cauchy.cdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.cauchy.Cauchy.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.cauchy.Cauchy.entropy()", "id": "torch.distributions.cauchy.Cauchy.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.cauchy.Cauchy.entropy", "parameters": []}},
{"code": "torch.distributions.cauchy.Cauchy.expand(batch_shape,_instance=None)", "id": "torch.distributions.cauchy.Cauchy.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.cauchy.Cauchy.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.cauchy.Cauchy.icdf(value)", "id": "torch.distributions.cauchy.Cauchy.icdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.cauchy.Cauchy.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.cauchy.Cauchy.log_prob(value)", "id": "torch.distributions.cauchy.Cauchy.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.cauchy.Cauchy.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.cauchy.Cauchy.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.cauchy.Cauchy.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.cauchy.Cauchy.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.nn.intrinsic.qat.ConvReLU2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros',qconfig=None)", "id": "torch.nn.intrinsic.qat.ConvReLU2d", "summary": "A ConvReLU2d module is a fused module of Conv2d and ReLU, attached with\nFakeQuantize modules for both output activation and weight for\nquantization aware training.\nWe combined the interface of Conv2d and\nBatchNorm2d.\n\nVariables\n\n~ConvReLU2d.activation_post_process \u2013 fake quant module for output activation\n~ConvReLU2d.weight_fake_quant \u2013 fake quant module for weight\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.qat.ConvReLU2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.intrinsic.qat.LinearReLU(in_features,out_features,bias=True,qconfig=None)", "id": "torch.nn.intrinsic.qat.LinearReLU", "summary": "A LinearReLU module fused from Linear and ReLU modules, attached with\nFakeQuantize modules for output activation and weight, used in\nquantization aware training.\nWe adopt the same interface as torch.nn.Linear.\nSimilar to torch.nn.intrinsic.LinearReLU, with FakeQuantize modules initialized to\ndefault.\n\nVariables\n\n~LinearReLU.activation_post_process \u2013 fake quant module for output activation\n~LinearReLU.weight \u2013 fake quant module for weight\n\n\n\nExamples:\n&gt;&gt;&gt; m = nn.qat.LinearReLU(20, 30)\n&gt;&gt;&gt; input = torch.randn(128, 20)\n&gt;&gt;&gt; output = m(input)\n&gt;&gt;&gt; print(output.size())\ntorch.Size([128, 30])\n\n\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.qat.LinearReLU", "parameters": [{"name": "in_features", "is_optional": false, "type": "others", "description": ""}, {"name": "out_features", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.intrinsic.quantized.ConvReLU2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')", "id": "torch.nn.intrinsic.quantized.ConvReLU2d", "summary": "A ConvReLU2d module is a fused module of Conv2d and ReLU\nWe adopt the same interface as torch.nn.quantized.Conv2d.\n\nVariables\nas torch.nn.quantized.Conv2d (Same) \u2013 \n\n\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.quantized.ConvReLU2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}]}},
{"code": "torch.nn.intrinsic.quantized.ConvReLU3d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')", "id": "torch.nn.intrinsic.quantized.ConvReLU3d", "summary": "A ConvReLU3d module is a fused module of Conv3d and ReLU\nWe adopt the same interface as torch.nn.quantized.Conv3d.\nAttributes: Same as torch.nn.quantized.Conv3d\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.quantized.ConvReLU3d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}]}},
{"code": "torch.nn.intrinsic.quantized.LinearReLU(in_features,out_features,bias=True)", "id": "torch.nn.intrinsic.quantized.LinearReLU", "summary": "A LinearReLU module fused from Linear and ReLU modules\nWe adopt the same interface as torch.nn.quantized.Linear.\n\nVariables\nas torch.nn.quantized.Linear (Same) \u2013 \n\n\nExamples:\n&gt;&gt;&gt; m = nn.intrinsic.LinearReLU(20, 30)\n&gt;&gt;&gt; input = torch.randn(128, 20)\n&gt;&gt;&gt; output = m(input)\n&gt;&gt;&gt; print(output.size())\ntorch.Size([128, 30])\n\n\n", "description": "", "code-info": {"name": "torch.nn.intrinsic.quantized.LinearReLU", "parameters": [{"name": "in_features", "is_optional": false, "type": "others", "description": ""}, {"name": "out_features", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.qat.Conv2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros',qconfig=None)", "id": "torch.nn.qat.Conv2d", "summary": "A Conv2d module attached with FakeQuantize modules for both output\nactivation and weight, used for quantization aware training.\nWe adopt the same interface as torch.nn.Conv2d, please see\nhttps://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d\nfor documentation.\nSimilar to torch.nn.Conv2d, with FakeQuantize modules initialized to\ndefault.\n\nVariables\n\n~Conv2d.activation_post_process \u2013 fake quant module for output activation\n~Conv2d.weight_fake_quant \u2013 fake quant module for weight\n\n\n\n\n\nclassmethod from_float(mod, qconfig=None) \u00b6\nCreate a qat module from a float module or qparams_dict\nArgs: mod a float module, either produced by torch.quantization utilities\nor directly from user\n\n\n", "description": "", "code-info": {"name": "torch.nn.qat.Conv2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.qat.Linear(in_features,out_features,bias=True,qconfig=None)", "id": "torch.nn.qat.Linear", "summary": "A linear module attached with FakeQuantize modules for both output\nactivation and weight, used for quantization aware training.\nWe adopt the same interface as torch.nn.Linear, please see\nhttps://pytorch.org/docs/stable/nn.html#torch.nn.Linear\nfor documentation.\nSimilar to torch.nn.Linear, with FakeQuantize modules initialized to\ndefault.\n\nVariables\n\n~Linear.activation_post_process \u2013 fake quant module for output activation\n~Linear.weight \u2013 fake quant module for weight\n\n\n\n\n\nclassmethod from_float(mod, qconfig=None) \u00b6\nCreate a qat module from a float module or qparams_dict\nArgs: mod a float module, either produced by torch.quantization utilities\nor directly from user\n\n\n", "description": "", "code-info": {"name": "torch.nn.qat.Linear", "parameters": [{"name": "in_features", "is_optional": false, "type": "others", "description": ""}, {"name": "out_features", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.quantized.ReLU(inplace=False)", "id": "torch.nn.quantized.ReLU", "summary": "Applies quantized rectified linear unit function element-wise:\nReLU(x)=max\u2061(x0,x)\\text{ReLU}(x)= \\max(x_0, x)ReLU(x)=max(x0\u200b,x)\n\n, where x0x_0x0\u200b\n\n is the zero point.\nPlease see https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU\nfor more documentation on ReLU.\n\nParameters\ninplace \u2013 (Currently not supported) can optionally do the operation in-place.\n\n\n\nShape:\nInput: (N,\u2217)(N, *)(N,\u2217)\n\n where * means, any number of additional\ndimensions\nOutput: (N,\u2217)(N, *)(N,\u2217)\n\n, same shape as the input\n\n\n\nExamples:\n&gt;&gt;&gt; m = nn.quantized.ReLU()\n&gt;&gt;&gt; input = torch.randn(2)\n&gt;&gt;&gt; input = torch.quantize_per_tensor(input, 1.0, 0, dtype=torch.qint32)\n&gt;&gt;&gt; output = m(input)\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.ReLU", "parameters": [{"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.quantized.ReLU6(inplace=False)", "id": "torch.nn.quantized.ReLU6", "summary": "Applies the element-wise function:\nReLU6(x)=min\u2061(max\u2061(x0,x),q(6))\\text{ReLU6}(x) = \\min(\\max(x_0, x), q(6))ReLU6(x)=min(max(x0\u200b,x),q(6))\n\n, where x0x_0x0\u200b\n\n is the\nzero_point, and q(6)q(6)q(6)\n\n is the quantized representation of number 6.\n\nParameters\ninplace \u2013 can optionally do the operation in-place", "description": "", "code-info": {"name": "torch.nn.quantized.ReLU6", "parameters": [{"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.quantized.Conv2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')", "id": "torch.nn.quantized.Conv2d", "summary": "Applies a 2D convolution over a quantized input signal composed of\nseveral quantized input planes.\nFor details on input arguments, parameters, and implementation see\nConv2d.\n\nNote\nOnly zeros is supported for the padding_mode argument.\n\n\nNote\nOnly torch.quint8 is supported for the input data type.\n\n\nVariables\n\n~Conv2d.weight (Tensor) \u2013 packed tensor derived from the learnable weight\nparameter.\n~Conv2d.scale (Tensor) \u2013 scalar for the output scale\n~Conv2d.zero_point (Tensor) \u2013 scalar for the output zero point\n\n\n\nSee Conv2d for other attributes.\nExamples:\n&gt;&gt;&gt; # With square kernels and equal stride\n&gt;&gt;&gt; m = nn.quantized.Conv2d(16, 33, 3, stride=2)\n&gt;&gt;&gt; # non-square kernels and unequal stride and with padding\n&gt;&gt;&gt; m = nn.quantized.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n&gt;&gt;&gt; # non-square kernels and unequal stride and with padding and dilation\n&gt;&gt;&gt; m = nn.quantized.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n&gt;&gt;&gt; input = torch.randn(20, 16, 50, 100)\n&gt;&gt;&gt; # quantize input to qint8\n&gt;&gt;&gt; q_input = torch.quantize_per_tensor(input, scale=1.0, zero_point=0, dtype=torch.qint32)\n&gt;&gt;&gt; output = m(input)\n\n\n\n\nclassmethod from_float(mod) \u00b6\nCreates a quantized module from a float module or qparams_dict.\n\nParameters\nmod (Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.Conv2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}]}},
{"code": "torch.nn.quantized.Conv3d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')", "id": "torch.nn.quantized.Conv3d", "summary": "Applies a 3D convolution over a quantized input signal composed of\nseveral quantized input planes.\nFor details on input arguments, parameters, and implementation see\nConv3d.\n\nNote\nOnly zeros is supported for the padding_mode argument.\n\n\nNote\nOnly torch.quint8 is supported for the input data type.\n\n\nVariables\n\n~Conv3d.weight (Tensor) \u2013 packed tensor derived from the learnable weight\nparameter.\n~Conv3d.scale (Tensor) \u2013 scalar for the output scale\n~Conv3d.zero_point (Tensor) \u2013 scalar for the output zero point\n\n\n\nSee Conv3d for other attributes.\nExamples:\n&gt;&gt;&gt; # With square kernels and equal stride\n&gt;&gt;&gt; m = nn.quantized.Conv3d(16, 33, 3, stride=2)\n&gt;&gt;&gt; # non-square kernels and unequal stride and with padding\n&gt;&gt;&gt; m = nn.quantized.Conv3d(16, 33, (3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2))\n&gt;&gt;&gt; # non-square kernels and unequal stride and with padding and dilation\n&gt;&gt;&gt; m = nn.quantized.Conv3d(16, 33, (3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2), dilation=(1, 2, 2))\n&gt;&gt;&gt; input = torch.randn(20, 16, 56, 56, 56)\n&gt;&gt;&gt; # quantize input to qint8\n&gt;&gt;&gt; q_input = torch.quantize_per_tensor(input, scale=1.0, zero_point=0, dtype=torch.qint32)\n&gt;&gt;&gt; output = m(input)\n\n\n\n\nclassmethod from_float(mod) \u00b6\nCreates a quantized module from a float module or qparams_dict.\n\nParameters\nmod (Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.Conv3d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}]}},
{"code": "torch.cuda.seed_all()", "id": "torch.cuda.seed_all", "summary": "Sets the seed for generating random numbers to a random number on all GPUs.\nIt\u2019s safe to call this function if CUDA is not available; in that\ncase, it is silently ignored.\n", "description": "", "code-info": {"name": "torch.cuda.seed_all", "parameters": []}},
{"code": "torch.cuda.initial_seed()", "id": "torch.cuda.initial_seed", "summary": "Returns the current random seed of the current GPU.\n\nWarning\nThis function eagerly initializes CUDA.\n\n", "description": "", "code-info": {"name": "torch.cuda.initial_seed", "parameters": []}},
{"code": "torch.cuda.comm.broadcast(tensor,devices)", "id": "torch.cuda.comm.broadcast", "summary": "Broadcasts a tensor to a number of GPUs.\n\nParameters\n\ntensor (Tensor) \u2013 tensor to broadcast.\ndevices (Iterable) \u2013 an iterable of devices among which to broadcast.\nNote that it should be like (src, dst1, dst2, \u2026), the first element\nof which is the source device to broadcast from.\n\n\nReturns\nA tuple containing copies of the tensor, placed on devices\ncorresponding to indices from devices.\n\n\n", "description": "", "code-info": {"name": "torch.cuda.comm.broadcast", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 tensor to broadcast."}, {"name": "devices", "is_optional": false, "type": "others", "description": "(Iterable) \u2013 an iterable of devices among which to broadcast.\nNote that it should be like (src, dst1, dst2, \u2026), the first element\nof which is the source device to broadcast from."}]}},
{"code": "torch.cuda.comm.broadcast_coalesced(tensors,devices,buffer_size=10485760)", "id": "torch.cuda.comm.broadcast_coalesced", "summary": "Broadcasts a sequence tensors to the specified GPUs.\nSmall tensors are first coalesced into a buffer to reduce the number\nof synchronizations.\n\nParameters\n\ntensors (sequence) \u2013 tensors to broadcast.\ndevices (Iterable) \u2013 an iterable of devices among which to broadcast.\nNote that it should be like (src, dst1, dst2, \u2026), the first element\nof which is the source device to broadcast from.\nbuffer_size (python:int) \u2013 maximum size of the buffer used for coalescing\n\n\nReturns\nA tuple containing copies of the tensor, placed on devices\ncorresponding to indices from devices.\n\n\n", "description": "", "code-info": {"name": "torch.cuda.comm.broadcast_coalesced", "parameters": [{"name": "tensors", "is_optional": false, "type": "others", "description": "(sequence) \u2013 tensors to broadcast."}, {"name": "devices", "is_optional": false, "type": "others", "description": "(Iterable) \u2013 an iterable of devices among which to broadcast.\nNote that it should be like (src, dst1, dst2, \u2026), the first element\nof which is the source device to broadcast from."}, {"name": "buffer_size", "is_optional": true, "type": "int", "default_value": "10485760", "description": "(python:int) \u2013 maximum size of the buffer used for coalescing"}]}},
{"code": "torch.cuda.comm.reduce_add(inputs,destination=None)", "id": "torch.cuda.comm.reduce_add", "summary": "Sums tensors from multiple GPUs.\nAll inputs should have matching shapes.\n\nParameters\n\ninputs (Iterable[Tensor]) \u2013 an iterable of tensors to add.\ndestination (python:int, optional) \u2013 a device on which the output will be\nplaced (default: current device).\n\n\nReturns\nA tensor containing an elementwise sum of all inputs, placed on the\ndestination device.\n\n\n", "description": "", "code-info": {"name": "torch.cuda.comm.reduce_add", "parameters": [{"name": "inputs", "is_optional": false, "type": "tensor", "description": "(Iterable[Tensor]) \u2013 an iterable of tensors to add."}, {"name": "destination", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 a device on which the output will be\nplaced (default: current device)."}]}},
{"code": "torch.cuda.comm.scatter(tensor,devices,chunk_sizes=None,dim=0,streams=None)", "id": "torch.cuda.comm.scatter", "summary": "Scatters tensor across multiple GPUs.\n\nParameters\n\ntensor (Tensor) \u2013 tensor to scatter.\ndevices (Iterable[python:int]) \u2013 iterable of ints, specifying among which\ndevices the tensor should be scattered.\nchunk_sizes (Iterable[python:int], optional) \u2013 sizes of chunks to be placed on\neach device", "description": "", "code-info": {"name": "torch.cuda.comm.scatter", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 tensor to scatter."}, {"name": "devices", "is_optional": false, "type": "int", "description": "(Iterable[python:int]) \u2013 iterable of ints, specifying among which\ndevices the tensor should be scattered."}, {"name": "chunk_sizes", "is_optional": true, "type": "int", "default_value": "None", "description": "(Iterable[python:int], optional) \u2013 sizes of chunks to be placed on\neach device. It should match devices in length and sum to\ntensor.size(dim). If not specified, the tensor will be divided\ninto equal chunks."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "streams", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.cuda.comm.gather(tensors,dim=0,destination=None)", "id": "torch.cuda.comm.gather", "summary": "Gathers tensors from multiple GPUs.\nTensor sizes in all dimension different than dim have to match.\n\nParameters\n\ntensors (Iterable[Tensor]) \u2013 iterable of tensors to gather.\ndim (python:int) \u2013 a dimension along which the tensors will be concatenated.\ndestination (python:int, optional) \u2013 output device (-1 means CPU, default:\ncurrent device)\n\n\nReturns\nA tensor located on destination device, that is a result of\nconcatenating tensors along dim.\n\n\n", "description": "", "code-info": {"name": "torch.cuda.comm.gather", "parameters": [{"name": "tensors", "is_optional": false, "type": "tensor", "description": "(Iterable[Tensor]) \u2013 iterable of tensors to gather."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 a dimension along which the tensors will be concatenated."}, {"name": "destination", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 output device (-1 means CPU, default:\ncurrent device)"}]}},
{"code": "torch.cuda.empty_cache()", "id": "torch.cuda.empty_cache", "summary": "Releases all unoccupied cached memory currently held by the caching\nallocator so that those can be used in other GPU application and visible in\nnvidia-smi.\n\nNote\nempty_cache() doesn\u2019t increase the amount of GPU\nmemory available for PyTorch", "description": "", "code-info": {"name": "torch.cuda.empty_cache", "parameters": []}},
{"code": "torch.cuda.memory_stats(device=None)", "id": "torch.cuda.memory_stats", "summary": "Returns a dictionary of CUDA memory allocator statistics for a\ngiven device.\nThe return value of this function is a dictionary of statistics, each of\nwhich is a non-negative integer.\nCore statistics:\n\n\"allocated.{all,large_pool,small_pool}.{current,peak,allocated,freed}\":\nnumber of allocation requests received by the memory allocator.\n\"allocated_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}\":\namount of allocated memory.\n\"segment.{all,large_pool,small_pool}.{current,peak,allocated,freed}\":\nnumber of reserved segments from cudaMalloc().\n\"reserved_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}\":\namount of reserved memory.\n\"active.{all,large_pool,small_pool}.{current,peak,allocated,freed}\":\nnumber of active memory blocks.\n\"active_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}\":\namount of active memory.\n\"inactive_split.{all,large_pool,small_pool}.{current,peak,allocated,freed}\":\nnumber of inactive, non-releasable memory blocks.\n\"inactive_split_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}\":\namount of inactive, non-releasable memory.\n\nFor these core statistics, values are broken down as follows.\nPool type:\n\nall: combined statistics across all memory pools.\nlarge_pool: statistics for the large allocation pool\n(as of October 2019, for size &gt;= 1MB allocations).\nsmall_pool: statistics for the small allocation pool\n(as of October 2019, for size &lt; 1MB allocations).\n\nMetric type:\n\ncurrent: current value of this metric.\npeak: maximum value of this metric.\nallocated: historical total increase in this metric.\nfreed: historical total decrease in this metric.\n\nIn addition to the core statistics, we also provide some simple event\ncounters:\n\n\"num_alloc_retries\": number of failed cudaMalloc calls that\nresult in a cache flush and retry.\n\"num_ooms\": number of out-of-memory errors thrown.\n\n\nParameters\ndevice (torch.device or python:int, optional) \u2013 selected device", "description": "", "code-info": {"name": "torch.cuda.memory_stats", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 selected device. Returns\nstatistics for the current device, given by current_device(),\nif device is None (default)."}]}},
{"code": "torch.cuda.memory_summary(device=None,abbreviated=False)", "id": "torch.cuda.memory_summary", "summary": "Returns a human-readable printout of the current memory allocator\nstatistics for a given device.\nThis can be useful to display periodically during training, or when\nhandling out-of-memory exceptions.\n\nParameters\n\ndevice (torch.device or python:int, optional) \u2013 selected device", "description": "", "code-info": {"name": "torch.cuda.memory_summary", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 selected device. Returns\nprintout for the current device, given by current_device(),\nif device is None (default)."}, {"name": "abbreviated", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 whether to return an abbreviated summary\n(default: False)."}]}},
{"code": "torch.cuda.memory_snapshot()", "id": "torch.cuda.memory_snapshot", "summary": "Returns a snapshot of the CUDA memory allocator state across all devices.\nInterpreting the output of this function requires familiarity with the\nmemory allocator internals.\n\nNote\nSee Memory management for more details about GPU memory\nmanagement.\n\n", "description": "", "code-info": {"name": "torch.cuda.memory_snapshot", "parameters": []}},
{"code": "torch.cuda.memory_allocated(device=None)", "id": "torch.cuda.memory_allocated", "summary": "Returns the current GPU memory occupied by tensors in bytes for a given\ndevice.\n\nParameters\ndevice (torch.device or python:int, optional) \u2013 selected device", "description": "", "code-info": {"name": "torch.cuda.memory_allocated", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}]}},
{"code": "torch.cuda.max_memory_allocated(device=None)", "id": "torch.cuda.max_memory_allocated", "summary": "Returns the maximum GPU memory occupied by tensors in bytes for a given\ndevice.\nBy default, this returns the peak allocated memory since the beginning of\nthis program", "description": "", "code-info": {"name": "torch.cuda.max_memory_allocated", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}]}},
{"code": "torch.cuda.reset_max_memory_allocated(device=None)", "id": "torch.cuda.reset_max_memory_allocated", "summary": "Resets the starting point in tracking maximum GPU memory occupied by\ntensors for a given device.\nSee max_memory_allocated() for details.\n\nParameters\ndevice (torch.device or python:int, optional) \u2013 selected device", "description": "", "code-info": {"name": "torch.cuda.reset_max_memory_allocated", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}]}},
{"code": "torch.cuda.memory_reserved(device=None)", "id": "torch.cuda.memory_reserved", "summary": "Returns the current GPU memory managed by the caching allocator in bytes\nfor a given device.\n\nParameters\ndevice (torch.device or python:int, optional) \u2013 selected device", "description": "", "code-info": {"name": "torch.cuda.memory_reserved", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}]}},
{"code": "torch.cuda.max_memory_reserved(device=None)", "id": "torch.cuda.max_memory_reserved", "summary": "Returns the maximum GPU memory managed by the caching allocator in bytes\nfor a given device.\nBy default, this returns the peak cached memory since the beginning of this\nprogram", "description": "", "code-info": {"name": "torch.cuda.max_memory_reserved", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}]}},
{"code": "torch.cuda.memory_cached(device=None)", "id": "torch.cuda.memory_cached", "summary": "Deprecated; see memory_reserved().\n", "description": "", "code-info": {"name": "torch.cuda.memory_cached", "parameters": [{"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.autograd.profiler.profile.export_chrome_trace(path)", "id": "torch.autograd.profiler.profile.export_chrome_trace", "summary": "Exports an EventList as a Chrome tracing tools file.\nThe checkpoint can be later loaded and inspected under chrome://tracing URL.\n\nParameters\npath (str) \u2013 Path where the trace will be written.\n\n\n", "description": "", "code-info": {"name": "torch.autograd.profiler.profile.export_chrome_trace", "parameters": [{"name": "path", "is_optional": false, "type": "others", "description": "(str) \u2013 Path where the trace will be written."}]}},
{"code": "torch.autograd.profiler.profile.key_averages(group_by_input_shape=False)", "id": "torch.autograd.profiler.profile.key_averages", "summary": "Averages all function events over their keys.\n@param group_by_input_shapes The key would become\n(event name, input dimensions) rather than just event name.\nThis is useful to see which dimensionality contributes to the runtime\nthe most and may help with dimension specific optimizations or\nchoosing best candidates for quantization (aka fitting a roof line)\n\nReturns\nAn EventList containing FunctionEventAvg objects.\n\n\n", "description": "", "code-info": {"name": "torch.autograd.profiler.profile.key_averages", "parameters": [{"name": "group_by_input_shape", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.autograd.profiler.profile.table(sort_by=None,row_limit=100,header=None)", "id": "torch.autograd.profiler.profile.table", "summary": "Prints an EventList as a nicely formatted table.\n\nParameters\nsort_by (str, optional) \u2013 Attribute used to sort entries", "description": "", "code-info": {"name": "torch.autograd.profiler.profile.table", "parameters": [{"name": "sort_by", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "row_limit", "is_optional": true, "type": "int", "default_value": "100", "description": ""}, {"name": "header", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.autograd.profiler.profile.total_average()", "id": "torch.autograd.profiler.profile.total_average", "summary": "Averages all events.\n\nReturns\nA FunctionEventAvg object.\n\n\n", "description": "", "code-info": {"name": "torch.autograd.profiler.profile.total_average", "parameters": []}},
{"code": "torch.autograd.set_grad_enabled(mode)", "id": "torch.autograd.set_grad_enabled", "summary": "Context-manager that sets gradient calculation to on or off.\nset_grad_enabled will enable or disable grads based on its argument mode.\nIt can be used as a context-manager or as a function.\nWhen using enable_grad context manager, set_grad_enabled(False)\nhas no effect.\nThis context manager is thread local; it will not affect computation\nin other threads.\n\nParameters\nmode (bool) \u2013 Flag whether to enable grad (True), or disable\n(False)", "description": "", "code-info": {"name": "torch.autograd.set_grad_enabled", "parameters": [{"name": "mode", "is_optional": false, "type": "bool", "description": "(bool) \u2013 Flag whether to enable grad (True), or disable\n(False). This can be used to conditionally enable\ngradients."}]}},
{"code": "torch.autograd.profiler.profile(enabled=True,use_cuda=False,record_shapes=False)", "id": "torch.autograd.profiler.profile", "summary": "Context manager that manages autograd profiler state and holds a summary of results.\nUnder the hood it just records events of functions being executed in C++ and\nexposes those events to Python", "description": "", "code-info": {"name": "torch.autograd.profiler.profile", "parameters": [{"name": "enabled", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 Setting this to False makes this context manager a no-op.\nDefault: True."}, {"name": "use_cuda", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Enables timing of CUDA events as well using the cudaEvent API.\nAdds approximately 4us of overhead to each tensor operation.\nDefault: False"}, {"name": "record_shapes", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If shapes recording is set, information\nabout input dimensions will be collected. This allows one to see which\ndimensions have been used under the hood and further group by them\nusing prof.key_averages(group_by_input_shape=True). Please note that\nshape recording might skew your profiling data. It is recommended to\nuse separate runs with and without shape recording to validate the timing.\nMost likely the skew will be negligible for bottom most events (in a case\nof nested function calls). But for higher level functions the total\nself cpu time might be artificially increased because of the shape\ncollection."}]}},
{"code": "torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma,last_epoch=-1)", "id": "torch.optim.lr_scheduler.ExponentialLR", "summary": "Decays the learning rate of each parameter group by gamma every epoch.\nWhen last_epoch=-1, sets initial lr as lr.\n\nParameters\n\noptimizer (Optimizer) \u2013 Wrapped optimizer.\ngamma (python:float) \u2013 Multiplicative factor of learning rate decay.\nlast_epoch (python:int) \u2013 The index of last epoch", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.ExponentialLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "others", "description": "(Optimizer) \u2013 Wrapped optimizer."}, {"name": "gamma", "is_optional": false, "type": "float", "description": "(python:float) \u2013 Multiplicative factor of learning rate decay."}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 The index of last epoch. Default: -1."}]}},
{"code": "torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max,eta_min=0,last_epoch=-1)", "id": "torch.optim.lr_scheduler.CosineAnnealingLR", "summary": "Set the learning rate of each parameter group using a cosine annealing\nschedule, where \u03b7max\\eta_{max}\u03b7max\u200b\n\n is set to the initial lr and\nTcurT_{cur}Tcur\u200b\n\n is the number of epochs since the last restart in SGDR:\n\n\u03b7t=\u03b7min+12(\u03b7max\u2212\u03b7min)(1+cos\u2061(TcurTmax\u03c0))Tcur\u2260(2k+1)Tmax;\u03b7t+1=\u03b7t+(\u03b7max\u2212\u03b7min)1\u2212cos\u2061(1Tmax\u03c0)2,Tcur=(2k+1)Tmax.\\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})\\left(1 +\n\\cos\\left(\\frac{T_{cur}}{T_{max}}\\pi\\right)\\right)\nT_{cur} \\neq (2k+1)T_{max};\\\\\n\\eta_{t+1} = \\eta_{t} + (\\eta_{max} - \\eta_{min})\\frac{1 -\n\\cos(\\frac{1}{T_{max}}\\pi)}{2},\nT_{cur} = (2k+1)T_{max}.\\\\\n\n\u03b7t\u200b=\u03b7min\u200b+21\u200b(\u03b7max\u200b\u2212\u03b7min\u200b)(1+cos(Tmax\u200bTcur\u200b\u200b\u03c0))Tcur\u200b\ue020\u200b=(2k+1)Tmax\u200b;\u03b7t+1\u200b=\u03b7t\u200b+(\u03b7max\u200b\u2212\u03b7min\u200b)21\u2212cos(Tmax\u200b1\u200b\u03c0)\u200b,Tcur\u200b=(2k+1)Tmax\u200b.\n\nWhen last_epoch=-1, sets initial lr as lr", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.CosineAnnealingLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "others", "description": "(Optimizer) \u2013 Wrapped optimizer."}, {"name": "T_max", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Maximum number of iterations."}, {"name": "eta_min", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float) \u2013 Minimum learning rate. Default: 0."}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 The index of last epoch. Default: -1."}]}},
{"code": "torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.1,patience=10,verbose=False,threshold=0.0001,threshold_mode='rel',cooldown=0,min_lr=0,eps=1e-08)", "id": "torch.optim.lr_scheduler.ReduceLROnPlateau", "summary": "Reduce learning rate when a metric has stopped improving.\nModels often benefit from reducing the learning rate by a factor\nof 2-10 once learning stagnates", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.ReduceLROnPlateau", "parameters": [{"name": "optimizer", "is_optional": false, "type": "others", "description": "(Optimizer) \u2013 Wrapped optimizer."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'min'", "description": "(str) \u2013 One of min, max. In min mode, lr will\nbe reduced when the quantity monitored has stopped\ndecreasing; in max mode it will be reduced when the\nquantity monitored has stopped increasing. Default: \u2018min\u2019."}, {"name": "factor", "is_optional": true, "type": "float", "default_value": "0.1", "description": "(python:float) \u2013 Factor by which the learning rate will be\nreduced. new_lr = lr * factor. Default: 0.1."}, {"name": "patience", "is_optional": true, "type": "int", "default_value": "10", "description": "(python:int) \u2013 Number of epochs with no improvement after\nwhich learning rate will be reduced. For example, if\npatience = 2, then we will ignore the first 2 epochs\nwith no improvement, and will only decrease the LR after the\n3rd epoch if the loss still hasn\u2019t improved then.\nDefault: 10."}, {"name": "verbose", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True, prints a message to stdout for\neach update. Default: False."}, {"name": "threshold", "is_optional": true, "type": "float", "default_value": "0.0001", "description": "(python:float) \u2013 Threshold for measuring the new optimum,\nto only focus on significant changes. Default: 1e-4."}, {"name": "threshold_mode", "is_optional": true, "type": "string", "default_value": "'rel'", "description": "(str) \u2013 One of rel, abs. In rel mode,\ndynamic_threshold = best * ( 1 + threshold ) in \u2018max\u2019\nmode or best * ( 1 - threshold ) in min mode.\nIn abs mode, dynamic_threshold = best + threshold in\nmax mode or best - threshold in min mode. Default: \u2018rel\u2019."}, {"name": "cooldown", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 Number of epochs to wait before resuming\nnormal operation after lr has been reduced. Default: 0."}, {"name": "min_lr", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float or list) \u2013 A scalar or a list of scalars. A\nlower bound on the learning rate of all param groups\nor each group respectively. Default: 0."}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-08", "description": "(python:float) \u2013 Minimal decay applied to lr. If the difference\nbetween new and old lr is smaller than eps, the update is\nignored. Default: 1e-8."}]}},
{"code": "torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr,max_lr,step_size_up=2000,step_size_down=None,mode='triangular',gamma=1.0,scale_fn=None,scale_mode='cycle',cycle_momentum=True,base_momentum=0.8,max_momentum=0.9,last_epoch=-1)", "id": "torch.optim.lr_scheduler.CyclicLR", "summary": "Sets the learning rate of each parameter group according to\ncyclical learning rate policy (CLR)", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.CyclicLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "others", "description": "(Optimizer) \u2013 Wrapped optimizer."}, {"name": "base_lr", "is_optional": false, "type": "float", "description": "(python:float or list) \u2013 Initial learning rate which is the\nlower boundary in the cycle for each parameter group."}, {"name": "max_lr", "is_optional": false, "type": "float", "description": "(python:float or list) \u2013 Upper learning rate boundaries in the cycle\nfor each parameter group. Functionally,\nit defines the cycle amplitude (max_lr - base_lr).\nThe lr at any cycle is the sum of base_lr\nand some scaling of the amplitude; therefore\nmax_lr may not actually be reached depending on\nscaling function."}, {"name": "step_size_up", "is_optional": true, "type": "int", "default_value": "2000", "description": "(python:int) \u2013 Number of training iterations in the\nincreasing half of a cycle. Default: 2000"}, {"name": "step_size_down", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 Number of training iterations in the\ndecreasing half of a cycle. If step_size_down is None,\nit is set to step_size_up. Default: None"}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'triangular'", "description": "(str) \u2013 One of {triangular, triangular2, exp_range}.\nValues correspond to policies detailed above.\nIf scale_fn is not None, this argument is ignored.\nDefault: \u2018triangular\u2019"}, {"name": "gamma", "is_optional": true, "type": "float", "default_value": "1.0", "description": "(python:float) \u2013 Constant in \u2018exp_range\u2019 scaling function:\ngamma**(cycle iterations)\nDefault: 1.0"}, {"name": "scale_fn", "is_optional": true, "type": "others", "default_value": "None", "description": "(function) \u2013 Custom scaling policy defined by a single\nargument lambda function, where\n0 &lt;= scale_fn(x) &lt;= 1 for all x &gt;= 0.\nIf specified, then \u2018mode\u2019 is ignored.\nDefault: None"}, {"name": "scale_mode", "is_optional": true, "type": "string", "default_value": "'cycle'", "description": "(str) \u2013 {\u2018cycle\u2019, \u2018iterations\u2019}.\nDefines whether scale_fn is evaluated on\ncycle number or cycle iterations (training\niterations since start of cycle).\nDefault: \u2018cycle\u2019"}, {"name": "cycle_momentum", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 If True, momentum is cycled inversely\nto learning rate between \u2018base_momentum\u2019 and \u2018max_momentum\u2019.\nDefault: True"}, {"name": "base_momentum", "is_optional": true, "type": "float", "default_value": "0.8", "description": "(python:float or list) \u2013 Lower momentum boundaries in the cycle\nfor each parameter group. Note that momentum is cycled inversely\nto learning rate; at the peak of a cycle, momentum is\n\u2018base_momentum\u2019 and learning rate is \u2018max_lr\u2019.\nDefault: 0.8"}, {"name": "max_momentum", "is_optional": true, "type": "float", "default_value": "0.9", "description": "(python:float or list) \u2013 Upper momentum boundaries in the cycle\nfor each parameter group. Functionally,\nit defines the cycle amplitude (max_momentum - base_momentum).\nThe momentum at any cycle is the difference of max_momentum\nand some scaling of the amplitude; therefore\nbase_momentum may not actually be reached depending on\nscaling function. Note that momentum is cycled inversely\nto learning rate; at the start of a cycle, momentum is \u2018max_momentum\u2019\nand learning rate is \u2018base_lr\u2019\nDefault: 0.9"}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 The index of the last batch. This parameter is used when\nresuming a training job. Since step() should be invoked after each\nbatch instead of after each epoch, this number represents the total\nnumber of batches computed, not the total number of epochs computed.\nWhen last_epoch=-1, the schedule is started from the beginning.\nDefault: -1"}]}},
{"code": "torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr,total_steps=None,epochs=None,steps_per_epoch=None,pct_start=0.3,anneal_strategy='cos',cycle_momentum=True,base_momentum=0.85,max_momentum=0.95,div_factor=25.0,final_div_factor=10000.0,last_epoch=-1)", "id": "torch.optim.lr_scheduler.OneCycleLR", "summary": "Sets the learning rate of each parameter group according to the\n1cycle learning rate policy", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.OneCycleLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "others", "description": "(Optimizer) \u2013 Wrapped optimizer."}, {"name": "max_lr", "is_optional": false, "type": "float", "description": "(python:float or list) \u2013 Upper learning rate boundaries in the cycle\nfor each parameter group."}, {"name": "total_steps", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 The total number of steps in the cycle. Note that\nif a value is provided here, then it must be inferred by providing\na value for epochs and steps_per_epoch.\nDefault: None"}, {"name": "epochs", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 The number of epochs to train for. This is used along\nwith steps_per_epoch in order to infer the total number of steps in the cycle\nif a value for total_steps is not provided.\nDefault: None"}, {"name": "steps_per_epoch", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 The number of steps per epoch to train for. This is\nused along with epochs in order to infer the total number of steps in the\ncycle if a value for total_steps is not provided.\nDefault: None"}, {"name": "pct_start", "is_optional": true, "type": "float", "default_value": "0.3", "description": "(python:float) \u2013 The percentage of the cycle (in number of steps) spent\nincreasing the learning rate.\nDefault: 0.3"}, {"name": "anneal_strategy", "is_optional": true, "type": "string", "default_value": "'cos'", "description": "(str) \u2013 {\u2018cos\u2019, \u2018linear\u2019}\nSpecifies the annealing strategy: \u201ccos\u201d for cosine annealing, \u201clinear\u201d for\nlinear annealing.\nDefault: \u2018cos\u2019"}, {"name": "cycle_momentum", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 If True, momentum is cycled inversely\nto learning rate between \u2018base_momentum\u2019 and \u2018max_momentum\u2019.\nDefault: True"}, {"name": "base_momentum", "is_optional": true, "type": "float", "default_value": "0.85", "description": "(python:float or list) \u2013 Lower momentum boundaries in the cycle\nfor each parameter group. Note that momentum is cycled inversely\nto learning rate; at the peak of a cycle, momentum is\n\u2018base_momentum\u2019 and learning rate is \u2018max_lr\u2019.\nDefault: 0.85"}, {"name": "max_momentum", "is_optional": true, "type": "float", "default_value": "0.95", "description": "(python:float or list) \u2013 Upper momentum boundaries in the cycle\nfor each parameter group. Functionally,\nit defines the cycle amplitude (max_momentum - base_momentum).\nNote that momentum is cycled inversely\nto learning rate; at the start of a cycle, momentum is \u2018max_momentum\u2019\nand learning rate is \u2018base_lr\u2019\nDefault: 0.95"}, {"name": "div_factor", "is_optional": true, "type": "float", "default_value": "25.0", "description": "(python:float) \u2013 Determines the initial learning rate via\ninitial_lr = max_lr/div_factor\nDefault: 25"}, {"name": "final_div_factor", "is_optional": true, "type": "float", "default_value": "10000.0", "description": "(python:float) \u2013 Determines the minimum learning rate via\nmin_lr = initial_lr/final_div_factor\nDefault: 1e4"}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 The index of the last batch. This parameter is used when\nresuming a training job. Since step() should be invoked after each\nbatch instead of after each epoch, this number represents the total\nnumber of batches computed, not the total number of epochs computed.\nWhen last_epoch=-1, the schedule is started from the beginning.\nDefault: -1"}]}},
{"code": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0,T_mult=1,eta_min=0,last_epoch=-1)", "id": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts", "summary": "Set the learning rate of each parameter group using a cosine annealing\nschedule, where \u03b7max\\eta_{max}\u03b7max\u200b\n\n is set to the initial lr, TcurT_{cur}Tcur\u200b\n\n\nis the number of epochs since the last restart and TiT_{i}Ti\u200b\n\n is the number\nof epochs between two warm restarts in SGDR:\n\n\u03b7t=\u03b7min+12(\u03b7max\u2212\u03b7min)(1+cos\u2061(TcurTi\u03c0))\\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})\\left(1 +\n\\cos\\left(\\frac{T_{cur}}{T_{i}}\\pi\\right)\\right)\n\n\u03b7t\u200b=\u03b7min\u200b+21\u200b(\u03b7max\u200b\u2212\u03b7min\u200b)(1+cos(Ti\u200bTcur\u200b\u200b\u03c0))\n\nWhen Tcur=TiT_{cur}=T_{i}Tcur\u200b=Ti\u200b\n\n, set \u03b7t=\u03b7min\\eta_t = \\eta_{min}\u03b7t\u200b=\u03b7min\u200b\n\n.\nWhen Tcur=0T_{cur}=0Tcur\u200b=0\n\n after restart, set \u03b7t=\u03b7max\\eta_t=\\eta_{max}\u03b7t\u200b=\u03b7max\u200b\n\n.\nIt has been proposed in\nSGDR: Stochastic Gradient Descent with Warm Restarts.\n\nParameters\n\noptimizer (Optimizer) \u2013 Wrapped optimizer.\nT_0 (python:int) \u2013 Number of iterations for the first restart.\nT_mult (python:int, optional) \u2013 A factor increases TiT_{i}Ti\u200b\n\n after a restart", "description": "", "code-info": {"name": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts", "parameters": [{"name": "optimizer", "is_optional": false, "type": "others", "description": "(Optimizer) \u2013 Wrapped optimizer."}, {"name": "T_0", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of iterations for the first restart."}, {"name": "T_mult", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 A factor increases TiT_{i}Ti\u200b\n\n after a restart. Default: 1."}, {"name": "eta_min", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float, optional) \u2013 Minimum learning rate. Default: 0."}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int, optional) \u2013 The index of last epoch. Default: -1."}]}},
{"code": "torch.Tensor.new_zeros(size,dtype=None,device=None,requires_grad=False)", "id": "torch.Tensor.new_zeros", "summary": "Returns a Tensor of size size filled with 0.\nBy default, the returned Tensor has the same torch.dtype and\ntorch.device as this tensor.\n\nParameters\n\nsize (python:int...) \u2013 a list, tuple, or torch.Size of integers defining the\nshape of the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor.\nrequires_grad (bool, optional) \u2013 If autograd should record operations on the\nreturned tensor", "description": "", "code-info": {"name": "torch.Tensor.new_zeros", "parameters": [{"name": "size", "is_optional": false, "type": "int", "description": "(python:int...) \u2013 a list, tuple, or torch.Size of integers defining the\nshape of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.Tensor.abs()", "id": "torch.Tensor.abs", "summary": "See torch.abs()\n", "description": "", "code-info": {"name": "torch.Tensor.abs", "parameters": []}},
{"code": "torch.Tensor.abs_()", "id": "torch.Tensor.abs_", "summary": "In-place version of abs()\n", "description": "", "code-info": {"name": "torch.Tensor.abs_", "parameters": []}},
{"code": "torch.Tensor.acos()", "id": "torch.Tensor.acos", "summary": "See torch.acos()\n", "description": "", "code-info": {"name": "torch.Tensor.acos", "parameters": []}},
{"code": "torch.Tensor.acos_()", "id": "torch.Tensor.acos_", "summary": "In-place version of acos()\n", "description": "", "code-info": {"name": "torch.Tensor.acos_", "parameters": []}},
{"code": "torch.Tensor.add(value)", "id": "torch.Tensor.add", "summary": "add(value=1, other) -&gt; Tensor\nSee torch.add()\n", "description": "", "code-info": {"name": "torch.Tensor.add", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.add_(value)", "id": "torch.Tensor.add_", "summary": "add_(value=1, other) -&gt; Tensor\nIn-place version of add()\n", "description": "", "code-info": {"name": "torch.Tensor.add_", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addbmm(beta=1,alpha=1,batch1,batch2)", "id": "torch.Tensor.addbmm", "summary": "See torch.addbmm()\n", "description": "", "code-info": {"name": "torch.Tensor.addbmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "batch1", "is_optional": false, "type": "others", "description": ""}, {"name": "batch2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addbmm_(beta=1,alpha=1,batch1,batch2)", "id": "torch.Tensor.addbmm_", "summary": "In-place version of addbmm()\n", "description": "", "code-info": {"name": "torch.Tensor.addbmm_", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "batch1", "is_optional": false, "type": "others", "description": ""}, {"name": "batch2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addcdiv(value=1,tensor1,tensor2)", "id": "torch.Tensor.addcdiv", "summary": "See torch.addcdiv()\n", "description": "", "code-info": {"name": "torch.Tensor.addcdiv", "parameters": [{"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "tensor1", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addcdiv_(value=1,tensor1,tensor2)", "id": "torch.Tensor.addcdiv_", "summary": "In-place version of addcdiv()\n", "description": "", "code-info": {"name": "torch.Tensor.addcdiv_", "parameters": [{"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "tensor1", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addcmul(value=1,tensor1,tensor2)", "id": "torch.Tensor.addcmul", "summary": "See torch.addcmul()\n", "description": "", "code-info": {"name": "torch.Tensor.addcmul", "parameters": [{"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "tensor1", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addcmul_(value=1,tensor1,tensor2)", "id": "torch.Tensor.addcmul_", "summary": "In-place version of addcmul()\n", "description": "", "code-info": {"name": "torch.Tensor.addcmul_", "parameters": [{"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "tensor1", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addmm(beta=1,alpha=1,mat1,mat2)", "id": "torch.Tensor.addmm", "summary": "See torch.addmm()\n", "description": "", "code-info": {"name": "torch.Tensor.addmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "mat1", "is_optional": false, "type": "others", "description": ""}, {"name": "mat2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addmm_(beta=1,alpha=1,mat1,mat2)", "id": "torch.Tensor.addmm_", "summary": "In-place version of addmm()\n", "description": "", "code-info": {"name": "torch.Tensor.addmm_", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "mat1", "is_optional": false, "type": "others", "description": ""}, {"name": "mat2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addmv(beta=1,alpha=1,mat,vec)", "id": "torch.Tensor.addmv", "summary": "See torch.addmv()\n", "description": "", "code-info": {"name": "torch.Tensor.addmv", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "mat", "is_optional": false, "type": "others", "description": ""}, {"name": "vec", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addmv_(beta=1,alpha=1,mat,vec)", "id": "torch.Tensor.addmv_", "summary": "In-place version of addmv()\n", "description": "", "code-info": {"name": "torch.Tensor.addmv_", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "mat", "is_optional": false, "type": "others", "description": ""}, {"name": "vec", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addr(beta=1,alpha=1,vec1,vec2)", "id": "torch.Tensor.addr", "summary": "See torch.addr()\n", "description": "", "code-info": {"name": "torch.Tensor.addr", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "vec1", "is_optional": false, "type": "others", "description": ""}, {"name": "vec2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.addr_(beta=1,alpha=1,vec1,vec2)", "id": "torch.Tensor.addr_", "summary": "In-place version of addr()\n", "description": "", "code-info": {"name": "torch.Tensor.addr_", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "vec1", "is_optional": false, "type": "others", "description": ""}, {"name": "vec2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.allclose(other,rtol=1e-05,atol=1e-08,equal_nan=False)", "id": "torch.Tensor.allclose", "summary": "See torch.allclose()\n", "description": "", "code-info": {"name": "torch.Tensor.allclose", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "rtol", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "atol", "is_optional": true, "type": "others", "default_value": "1e-08", "description": ""}, {"name": "equal_nan", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.angle()", "id": "torch.Tensor.angle", "summary": "See torch.angle()\n", "description": "", "code-info": {"name": "torch.Tensor.angle", "parameters": []}},
{"code": "torch.Tensor.apply_(callable)", "id": "torch.Tensor.apply_", "summary": "Applies the function callable to each element in the tensor, replacing\neach element with the value returned by callable.\n\nNote\nThis function only works with CPU tensors and should not be used in code\nsections that require high performance.\n\n", "description": "", "code-info": {"name": "torch.Tensor.apply_", "parameters": [{"name": "callable", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.is_tensor(obj)", "id": "torch.is_tensor", "summary": "Returns True if obj is a PyTorch tensor.\n\nParameters\nobj (Object) \u2013 Object to test\n\n\n", "description": "", "code-info": {"name": "torch.is_tensor", "parameters": [{"name": "obj", "is_optional": false, "type": "others", "description": "(Object) \u2013 Object to test"}]}},
{"code": "torch.nn.functional.avg_pool3d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)", "id": "torch.nn.functional.avg_pool3d", "summary": "Applies 3D average-pooling operation in kT\u00d7kH\u00d7kWkT \\times kH \\times kWkT\u00d7kH\u00d7kW\n\n regions by step\nsize sT\u00d7sH\u00d7sWsT \\times sH \\times sWsT\u00d7sH\u00d7sW\n\n steps", "description": "", "code-info": {"name": "torch.nn.functional.avg_pool3d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "count_include_pad", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "divisor_override", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.functional.max_pool1d(*args,**kwargs)", "id": "torch.nn.functional.max_pool1d", "summary": "Applies a 1D max pooling over an input signal composed of several input\nplanes.\nSee MaxPool1d for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.max_pool1d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.max_pool2d(*args,**kwargs)", "id": "torch.nn.functional.max_pool2d", "summary": "Applies a 2D max pooling over an input signal composed of several input\nplanes.\nSee MaxPool2d for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.max_pool2d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.max_pool3d(*args,**kwargs)", "id": "torch.nn.functional.max_pool3d", "summary": "Applies a 3D max pooling over an input signal composed of several input\nplanes.\nSee MaxPool3d for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.max_pool3d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.max_unpool1d(input,indices,kernel_size,stride=None,padding=0,output_size=None)", "id": "torch.nn.functional.max_unpool1d", "summary": "Computes a partial inverse of MaxPool1d.\nSee MaxUnpool1d for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.max_unpool1d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "indices", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "output_size", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.functional.max_unpool2d(input,indices,kernel_size,stride=None,padding=0,output_size=None)", "id": "torch.nn.functional.max_unpool2d", "summary": "Computes a partial inverse of MaxPool2d.\nSee MaxUnpool2d for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.max_unpool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "indices", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "output_size", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.functional.max_unpool3d(input,indices,kernel_size,stride=None,padding=0,output_size=None)", "id": "torch.nn.functional.max_unpool3d", "summary": "Computes a partial inverse of MaxPool3d.\nSee MaxUnpool3d for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.max_unpool3d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "indices", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "output_size", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.functional.lp_pool1d(input,norm_type,kernel_size,stride=None,ceil_mode=False)", "id": "torch.nn.functional.lp_pool1d", "summary": "Applies a 1D power-average pooling over an input signal composed of\nseveral input planes", "description": "", "code-info": {"name": "torch.nn.functional.lp_pool1d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "norm_type", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.lp_pool2d(input,norm_type,kernel_size,stride=None,ceil_mode=False)", "id": "torch.nn.functional.lp_pool2d", "summary": "Applies a 2D power-average pooling over an input signal composed of\nseveral input planes", "description": "", "code-info": {"name": "torch.nn.functional.lp_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "norm_type", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.adaptive_max_pool1d(*args,**kwargs)", "id": "torch.nn.functional.adaptive_max_pool1d", "summary": "Applies a 1D adaptive max pooling over an input signal composed of\nseveral input planes.\nSee AdaptiveMaxPool1d for details and output shape.\n\nParameters\n\noutput_size \u2013 the target output size (single integer)\nreturn_indices \u2013 whether to return pooling indices", "description": "", "code-info": {"name": "torch.nn.functional.adaptive_max_pool1d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.adaptive_max_pool2d(*args,**kwargs)", "id": "torch.nn.functional.adaptive_max_pool2d", "summary": "Applies a 2D adaptive max pooling over an input signal composed of\nseveral input planes.\nSee AdaptiveMaxPool2d for details and output shape.\n\nParameters\n\noutput_size \u2013 the target output size (single integer or\ndouble-integer tuple)\nreturn_indices \u2013 whether to return pooling indices", "description": "", "code-info": {"name": "torch.nn.functional.adaptive_max_pool2d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.adaptive_max_pool3d(*args,**kwargs)", "id": "torch.nn.functional.adaptive_max_pool3d", "summary": "Applies a 3D adaptive max pooling over an input signal composed of\nseveral input planes.\nSee AdaptiveMaxPool3d for details and output shape.\n\nParameters\n\noutput_size \u2013 the target output size (single integer or\ntriple-integer tuple)\nreturn_indices \u2013 whether to return pooling indices", "description": "", "code-info": {"name": "torch.nn.functional.adaptive_max_pool3d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.adaptive_avg_pool1d(input,output_size)", "id": "torch.nn.functional.adaptive_avg_pool1d", "summary": "Applies a 1D adaptive average pooling over an input signal composed of\nseveral input planes.\nSee AdaptiveAvgPool1d for details and output shape.\n\nParameters\noutput_size \u2013 the target output size (single integer)\n\n\n", "description": "", "code-info": {"name": "torch.nn.functional.adaptive_avg_pool1d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "output_size", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.adaptive_avg_pool2d(input,output_size)", "id": "torch.nn.functional.adaptive_avg_pool2d", "summary": "Applies a 2D adaptive average pooling over an input signal composed of\nseveral input planes.\nSee AdaptiveAvgPool2d for details and output shape.\n\nParameters\noutput_size \u2013 the target output size (single integer or\ndouble-integer tuple)\n\n\n", "description": "", "code-info": {"name": "torch.nn.functional.adaptive_avg_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "output_size", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.adaptive_avg_pool3d(input,output_size)", "id": "torch.nn.functional.adaptive_avg_pool3d", "summary": "Applies a 3D adaptive average pooling over an input signal composed of\nseveral input planes.\nSee AdaptiveAvgPool3d for details and output shape.\n\nParameters\noutput_size \u2013 the target output size (single integer or\ntriple-integer tuple)\n\n\n", "description": "", "code-info": {"name": "torch.nn.functional.adaptive_avg_pool3d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "output_size", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.threshold(input,threshold,value,inplace=False)", "id": "torch.nn.functional.threshold", "summary": "Thresholds each element of the input Tensor.\nSee Threshold for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.threshold", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "threshold", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.distributions.chi2.Chi2.expand(batch_shape,_instance=None)", "id": "torch.distributions.chi2.Chi2.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.chi2.Chi2.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.dirichlet.Dirichlet.entropy()", "id": "torch.distributions.dirichlet.Dirichlet.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.entropy", "parameters": []}},
{"code": "torch.distributions.dirichlet.Dirichlet.expand(batch_shape,_instance=None)", "id": "torch.distributions.dirichlet.Dirichlet.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.dirichlet.Dirichlet.log_prob(value)", "id": "torch.distributions.dirichlet.Dirichlet.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.dirichlet.Dirichlet.rsample(sample_shape=()", "id": "torch.distributions.dirichlet.Dirichlet.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.rsample", "parameters": [{"name": "sample_shape", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.exponential.Exponential.cdf(value)", "id": "torch.distributions.exponential.Exponential.cdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.exponential.Exponential.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.exponential.Exponential.entropy()", "id": "torch.distributions.exponential.Exponential.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.exponential.Exponential.entropy", "parameters": []}},
{"code": "torch.distributions.exponential.Exponential.expand(batch_shape,_instance=None)", "id": "torch.distributions.exponential.Exponential.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.exponential.Exponential.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.exponential.Exponential.icdf(value)", "id": "torch.distributions.exponential.Exponential.icdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.exponential.Exponential.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.exponential.Exponential.log_prob(value)", "id": "torch.distributions.exponential.Exponential.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.exponential.Exponential.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.exponential.Exponential.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.exponential.Exponential.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.exponential.Exponential.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.fishersnedecor.FisherSnedecor.expand(batch_shape,_instance=None)", "id": "torch.distributions.fishersnedecor.FisherSnedecor.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.fishersnedecor.FisherSnedecor.log_prob(value)", "id": "torch.distributions.fishersnedecor.FisherSnedecor.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.fishersnedecor.FisherSnedecor.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.fishersnedecor.FisherSnedecor.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.nn.quantized.Quantize(scale,zero_point,dtype)", "id": "torch.nn.quantized.Quantize", "summary": "Quantizes an incoming tensor\n\nParameters\n\nscale \u2013 scale of the output Quantized Tensor\nzero_point \u2013 zero_point of output Quantized Tensor\ndtype \u2013 data type of output Quantized Tensor\n\n\nVariables\nzero_point, dtype (`scale`,) \u2013 \n\n\n\nExamples::&gt;&gt;&gt; t = torch.tensor([[1., -1.], [1., -1.]])\n&gt;&gt;&gt; scale, zero_point, dtype = 1.0, 2, torch.qint8\n&gt;&gt;&gt; qm = Quantize(scale, zero_point, dtype)\n&gt;&gt;&gt; qt = qm(t)\n&gt;&gt;&gt; print(qt)\ntensor([[ 1., -1.],\n        [ 1., -1.]], size=(2, 2), dtype=torch.qint8, scale=1.0, zero_point=2)\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.Quantize", "parameters": [{"name": "scale", "is_optional": false, "type": "others", "description": ""}, {"name": "zero_point", "is_optional": false, "type": "others", "description": ""}, {"name": "dtype", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.quantized.Linear(in_features,out_features,bias_=True)", "id": "torch.nn.quantized.Linear", "summary": "A quantized linear module with quantized tensor as inputs and outputs.\nWe adopt the same interface as torch.nn.Linear, please see\nhttps://pytorch.org/docs/stable/nn.html#torch.nn.Linear for documentation.\nSimilar to Linear, attributes will be randomly\ninitialized at module creation time and will be overwritten later\n\nVariables\n\n~Linear.weight (Tensor) \u2013 the non-learnable quantized weights of the module of\nshape (out_features,in_features)(\\text{out\\_features}, \\text{in\\_features})(out_features,in_features)\n\n.\n~Linear.bias (Tensor) \u2013 the non-learnable bias of the module of shape (out_features)(\\text{out\\_features})(out_features)\n\n.\nIf bias is True, the values are initialized to zero.\n~Linear.scale \u2013 scale parameter of output Quantized Tensor, type: double\n~Linear.zero_point \u2013 zero_point parameter for output Quantized Tensor, type: long\n\n\n\nExamples:\n&gt;&gt;&gt; m = nn.quantized.Linear(20, 30)\n&gt;&gt;&gt; input = torch.randn(128, 20)\n&gt;&gt;&gt; input = torch.quantize_per_tensor(input, 1.0, 0, torch.quint8)\n&gt;&gt;&gt; output = m(input)\n&gt;&gt;&gt; print(output.size())\ntorch.Size([128, 30])\n\n\n\n\nclassmethod from_float(mod) \u00b6\nCreate a quantized module from a float module or qparams_dict\n\nParameters\nmod (Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.Linear", "parameters": [{"name": "in_features", "is_optional": false, "type": "others", "description": ""}, {"name": "out_features", "is_optional": false, "type": "others", "description": ""}, {"name": "bias_", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.quantized.dynamic.Linear(in_features,out_features,bias_=True)", "id": "torch.nn.quantized.dynamic.Linear", "summary": "A dynamic quantized linear module with quantized tensor as inputs and outputs.\nWe adopt the same interface as torch.nn.Linear, please see\nhttps://pytorch.org/docs/stable/nn.html#torch.nn.Linear for documentation.\nSimilar to torch.nn.Linear, attributes will be randomly\ninitialized at module creation time and will be overwritten later\n\nVariables\n\n~Linear.weight (Tensor) \u2013 the non-learnable quantized weights of the module which are of\nshape (out_features,in_features)(\\text{out\\_features}, \\text{in\\_features})(out_features,in_features)\n\n.\n~Linear.bias (Tensor) \u2013 the non-learnable bias of the module of shape (out_features)(\\text{out\\_features})(out_features)\n\n.\nIf bias is True, the values are initialized to zero.\n\n\n\nExamples:\n&gt;&gt;&gt; m = nn.quantized.dynamic.Linear(20, 30)\n&gt;&gt;&gt; input = torch.randn(128, 20)\n&gt;&gt;&gt; output = m(input)\n&gt;&gt;&gt; print(output.size())\ntorch.Size([128, 30])\n\n\n\n\nclassmethod from_float(mod) \u00b6\nCreate a dynamic quantized module from a float module or qparams_dict\n\nParameters\nmod (Module) \u2013 a float module, either produced by torch.quantization\nutilities or provided by the user\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.quantized.dynamic.Linear", "parameters": [{"name": "in_features", "is_optional": false, "type": "others", "description": ""}, {"name": "out_features", "is_optional": false, "type": "others", "description": ""}, {"name": "bias_", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.quantized.dynamic.LSTM(*args,**kwargs)", "id": "torch.nn.quantized.dynamic.LSTM", "summary": "", "description": "", "code-info": {"name": "torch.nn.quantized.dynamic.LSTM", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.cuda.max_memory_cached(device=None)", "id": "torch.cuda.max_memory_cached", "summary": "Deprecated; see max_memory_reserved().\n", "description": "", "code-info": {"name": "torch.cuda.max_memory_cached", "parameters": [{"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.cuda.reset_max_memory_cached(device=None)", "id": "torch.cuda.reset_max_memory_cached", "summary": "Resets the starting point in tracking maximum GPU memory managed by the\ncaching allocator for a given device.\nSee max_memory_cached() for details.\n\nParameters\ndevice (torch.device or python:int, optional) \u2013 selected device", "description": "", "code-info": {"name": "torch.cuda.reset_max_memory_cached", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(torch.device or python:int, optional) \u2013 selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}]}},
{"code": "torch.cuda.nvtx.mark(msg)", "id": "torch.cuda.nvtx.mark", "summary": "Describe an instantaneous event that occurred at some point.\n\nParameters\nmsg (string) \u2013 ASCII message to associate with the event.\n\n\n", "description": "", "code-info": {"name": "torch.cuda.nvtx.mark", "parameters": [{"name": "msg", "is_optional": false, "type": "string", "description": "(string) \u2013 ASCII message to associate with the event."}]}},
{"code": "torch.cuda.nvtx.range_push(msg)", "id": "torch.cuda.nvtx.range_push", "summary": "Pushes a range onto a stack of nested range span", "description": "", "code-info": {"name": "torch.cuda.nvtx.range_push", "parameters": [{"name": "msg", "is_optional": false, "type": "string", "description": "(string) \u2013 ASCII message to associate with range"}]}},
{"code": "torch.cuda.nvtx.range_pop()", "id": "torch.cuda.nvtx.range_pop", "summary": "Pops a range off of a stack of nested range spans", "description": "", "code-info": {"name": "torch.cuda.nvtx.range_pop", "parameters": []}},
{"code": "torch.cuda.Stream.query()", "id": "torch.cuda.Stream.query", "summary": "Checks if all the work submitted has been completed.\n\nReturns\nA boolean indicating if all kernels in this stream are completed.\n\n\n", "description": "", "code-info": {"name": "torch.cuda.Stream.query", "parameters": []}},
{"code": "torch.cuda.Stream.record_event(event=None)", "id": "torch.cuda.Stream.record_event", "summary": "Records an event.\n\nParameters\nevent (Event, optional) \u2013 event to record", "description": "", "code-info": {"name": "torch.cuda.Stream.record_event", "parameters": [{"name": "event", "is_optional": true, "type": "others", "default_value": "None", "description": "(Event, optional) \u2013 event to record. If not given, a new one\nwill be allocated."}]}},
{"code": "torch.cuda.Stream.synchronize()", "id": "torch.cuda.Stream.synchronize", "summary": "Wait for all the kernels in this stream to complete.\n\nNote\nThis is a wrapper around cudaStreamSynchronize(): see\nCUDA Stream documentation for more info.\n\n", "description": "", "code-info": {"name": "torch.cuda.Stream.synchronize", "parameters": []}},
{"code": "torch.cuda.Stream.wait_event(event)", "id": "torch.cuda.Stream.wait_event", "summary": "Makes all future work submitted to the stream wait for an event.\n\nParameters\nevent (Event) \u2013 an event to wait for.\n\n\n\nNote\nThis is a wrapper around cudaStreamWaitEvent(): see\nCUDA Stream documentation for more info.\nThis function returns without waiting for event: only future\noperations are affected.\n\n", "description": "", "code-info": {"name": "torch.cuda.Stream.wait_event", "parameters": [{"name": "event", "is_optional": false, "type": "others", "description": "(Event) \u2013 an event to wait for."}]}},
{"code": "torch.cuda.Stream.wait_stream(stream)", "id": "torch.cuda.Stream.wait_stream", "summary": "Synchronizes with another stream.\nAll future work submitted to this stream will wait until all kernels\nsubmitted to a given stream at the time of call complete.\n\nParameters\nstream (Stream) \u2013 a stream to synchronize.\n\n\n\nNote\nThis function returns without waiting for currently enqueued\nkernels in stream: only future operations are affected.\n\n", "description": "", "code-info": {"name": "torch.cuda.Stream.wait_stream", "parameters": [{"name": "stream", "is_optional": false, "type": "others", "description": "(Stream) \u2013 a stream to synchronize."}]}},
{"code": "torch.cuda.Event.elapsed_time(end_event)", "id": "torch.cuda.Event.elapsed_time", "summary": "Returns the time elapsed in milliseconds after the event was\nrecorded and before the end_event was recorded.\n", "description": "", "code-info": {"name": "torch.cuda.Event.elapsed_time", "parameters": [{"name": "end_event", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.cuda.Event.from_ipc_handle(device,handle)", "id": "torch.cuda.Event.from_ipc_handle", "summary": "Reconstruct an event from an IPC handle on the given device.\n", "description": "", "code-info": {"name": "torch.cuda.Event.from_ipc_handle", "parameters": [{"name": "device", "is_optional": false, "type": "others", "description": ""}, {"name": "handle", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.cuda.Event.ipc_handle()", "id": "torch.cuda.Event.ipc_handle", "summary": "Returns an IPC handle of this event", "description": "", "code-info": {"name": "torch.cuda.Event.ipc_handle", "parameters": []}},
{"code": "torch.cuda.Event.query()", "id": "torch.cuda.Event.query", "summary": "Checks if all work currently captured by event has completed.\n\nReturns\nA boolean indicating if all work currently captured by event has\ncompleted.\n\n\n", "description": "", "code-info": {"name": "torch.cuda.Event.query", "parameters": []}},
{"code": "torch.cuda.Event.record(stream=None)", "id": "torch.cuda.Event.record", "summary": "Records the event in a given stream.\nUses torch.cuda.current_stream() if no stream is specified", "description": "", "code-info": {"name": "torch.cuda.Event.record", "parameters": [{"name": "stream", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.cuda.Event.synchronize()", "id": "torch.cuda.Event.synchronize", "summary": "Waits for the event to complete.\nWaits until the completion of all work currently captured in this event.\nThis prevents the CPU thread from proceeding until the event completes.\n\n\nNote\nThis is a wrapper around cudaEventSynchronize(): see\nCUDA Event documentation for more info.\n\n\n", "description": "", "code-info": {"name": "torch.cuda.Event.synchronize", "parameters": []}},
{"code": "torch.cuda.Event.wait(stream=None)", "id": "torch.cuda.Event.wait", "summary": "Makes all future work submitted to the given stream wait for this\nevent.\nUse torch.cuda.current_stream() if no stream is specified.\n", "description": "", "code-info": {"name": "torch.cuda.Event.wait", "parameters": [{"name": "stream", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.cuda.device(device)", "id": "torch.cuda.device", "summary": "Context-manager that changes the selected device.\n\nParameters\ndevice (torch.device or python:int) \u2013 device index to select", "description": "", "code-info": {"name": "torch.cuda.device", "parameters": [{"name": "device", "is_optional": false, "type": "int", "description": "(torch.device or python:int) \u2013 device index to select. It\u2019s a no-op if\nthis argument is a negative integer or None."}]}},
{"code": "torch.cuda.device_of(obj)", "id": "torch.cuda.device_of", "summary": "Context-manager that changes the current device to that of given object.\nYou can use both tensors and storages as arguments", "description": "", "code-info": {"name": "torch.cuda.device_of", "parameters": [{"name": "obj", "is_optional": false, "type": "tensor", "description": "(Tensor or Storage) \u2013 object allocated on the selected device."}]}},
{"code": "torch.autograd.profiler.record_function(name)", "id": "torch.autograd.profiler.record_function", "summary": "Context manager that adds a label to a block of Python code when running autograd\nprofiler", "description": "", "code-info": {"name": "torch.autograd.profiler.record_function", "parameters": [{"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 Label assigned to the block of code."}]}},
{"code": "torch.autograd.profiler.emit_nvtx(enabled=True,record_shapes=False)", "id": "torch.autograd.profiler.emit_nvtx", "summary": "Context manager that makes every autograd operation emit an NVTX range.\nIt is useful when running the program under nvprof:\nnvprof --profile-from-start off -o trace_name.prof -- &lt;regular command here&gt;\n\n\nUnfortunately, there\u2019s no way to force nvprof to flush the data it collected\nto disk, so for CUDA profiling one has to use this context manager to annotate\nnvprof traces and wait for the process to exit before inspecting them.\nThen, either NVIDIA Visual Profiler (nvvp) can be used to visualize the timeline, or\ntorch.autograd.profiler.load_nvprof() can load the results for inspection\ne.g", "description": "", "code-info": {"name": "torch.autograd.profiler.emit_nvtx", "parameters": [{"name": "enabled", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional, default=True) \u2013 Setting enabled=False makes this context manager a no-op.\nDefault: True."}, {"name": "record_shapes", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional, default=False) \u2013 If record_shapes=True, the nvtx range wrapping\neach autograd op will append information about the sizes of Tensor arguments received\nby that op, in the following format:\n[[arg0.size(0), arg0.size(1), ...], [arg1.size(0), arg1.size(1), ...], ...]\nNon-tensor arguments will be represented by [].\nArguments will be listed in the order they are received by the backend op.\nPlease note that this order may not match the order in which those arguments were passed\non the Python side.  Also note that shape recording may increase the overhead of nvtx range creation."}]}},
{"code": "torch.autograd.set_detect_anomaly(mode)", "id": "torch.autograd.set_detect_anomaly", "summary": "Context-manager that sets the anomaly detection for the autograd engine on or off.\nset_detect_anomaly will enable or disable the autograd anomaly detection\nbased on its argument mode.\nIt can be used as a context-manager or as a function.\nSee detect_anomaly above for details of the anomaly detection behaviour.\n\nParameters\nmode (bool) \u2013 Flag whether to enable anomaly detection (True),\nor disable (False).\n\n\n", "description": "", "code-info": {"name": "torch.autograd.set_detect_anomaly", "parameters": [{"name": "mode", "is_optional": false, "type": "bool", "description": "(bool) \u2013 Flag whether to enable anomaly detection (True),\nor disable (False)."}]}},
{"code": "torch.Tensor.argmax(dim=None,keepdim=False)", "id": "torch.Tensor.argmax", "summary": "See torch.argmax()\n", "description": "", "code-info": {"name": "torch.Tensor.argmax", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.argmin(dim=None,keepdim=False)", "id": "torch.Tensor.argmin", "summary": "See torch.argmin()\n", "description": "", "code-info": {"name": "torch.Tensor.argmin", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.argsort(dim=-1,descending=False)", "id": "torch.Tensor.argsort", "summary": "See :func: torch.argsort\n", "description": "", "code-info": {"name": "torch.Tensor.argsort", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}, {"name": "descending", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.asin()", "id": "torch.Tensor.asin", "summary": "See torch.asin()\n", "description": "", "code-info": {"name": "torch.Tensor.asin", "parameters": []}},
{"code": "torch.Tensor.asin_()", "id": "torch.Tensor.asin_", "summary": "In-place version of asin()\n", "description": "", "code-info": {"name": "torch.Tensor.asin_", "parameters": []}},
{"code": "torch.Tensor.as_strided(size,stride,storage_offset=0)", "id": "torch.Tensor.as_strided", "summary": "See torch.as_strided()\n", "description": "", "code-info": {"name": "torch.Tensor.as_strided", "parameters": [{"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": false, "type": "others", "description": ""}, {"name": "storage_offset", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.Tensor.atan()", "id": "torch.Tensor.atan", "summary": "See torch.atan()\n", "description": "", "code-info": {"name": "torch.Tensor.atan", "parameters": []}},
{"code": "torch.Tensor.atan2(other)", "id": "torch.Tensor.atan2", "summary": "See torch.atan2()\n", "description": "", "code-info": {"name": "torch.Tensor.atan2", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.atan2_(other)", "id": "torch.Tensor.atan2_", "summary": "In-place version of atan2()\n", "description": "", "code-info": {"name": "torch.Tensor.atan2_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.atan_()", "id": "torch.Tensor.atan_", "summary": "In-place version of atan()\n", "description": "", "code-info": {"name": "torch.Tensor.atan_", "parameters": []}},
{"code": "sig-name descname(gradient=None,retain_graph=None,create_graph=False)", "id": "sig-name descname", "summary": "Computes the gradient of current tensor w.r.t", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "gradient", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor or None) \u2013 Gradient w.r.t. the\ntensor. If it is a tensor, it will be automatically converted\nto a Tensor that does not require grad unless create_graph is True.\nNone values can be specified for scalar Tensors or ones that\ndon\u2019t require grad. If a None value would be acceptable then\nthis argument is optional."}, {"name": "retain_graph", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 If False, the graph used to compute\nthe grads will be freed. Note that in nearly all cases setting\nthis option to True is not needed and often can be worked around\nin a much more efficient way. Defaults to the value of\ncreate_graph."}, {"name": "create_graph", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If True, graph of the derivative will\nbe constructed, allowing to compute higher order derivative\nproducts. Defaults to False."}]}},
{"code": "torch.Tensor.baddbmm(beta=1,alpha=1,batch1,batch2)", "id": "torch.Tensor.baddbmm", "summary": "See torch.baddbmm()\n", "description": "", "code-info": {"name": "torch.Tensor.baddbmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "batch1", "is_optional": false, "type": "others", "description": ""}, {"name": "batch2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.baddbmm_(beta=1,alpha=1,batch1,batch2)", "id": "torch.Tensor.baddbmm_", "summary": "In-place version of baddbmm()\n", "description": "", "code-info": {"name": "torch.Tensor.baddbmm_", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "batch1", "is_optional": false, "type": "others", "description": ""}, {"name": "batch2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.bernoulli(*,generator=None)", "id": "torch.Tensor.bernoulli", "summary": "Returns a result tensor where each result[i]\\texttt{result[i]}result[i]\n\n is independently\nsampled from Bernoulli(self[i])\\text{Bernoulli}(\\texttt{self[i]})Bernoulli(self[i])\n\n", "description": "", "code-info": {"name": "torch.Tensor.bernoulli", "parameters": [{"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.bernoulli_()", "id": "torch.Tensor.bernoulli_", "summary": "\n\nbernoulli_(p=0.5, *, generator=None) \u2192 Tensor\nFills each location of self with an independent sample from\nBernoulli(p)\\text{Bernoulli}(\\texttt{p})Bernoulli(p)\n\n", "description": "", "code-info": {"name": "torch.Tensor.bernoulli_", "parameters": []}},
{"code": "torch.Tensor.bfloat16()", "id": "torch.Tensor.bfloat16", "summary": "self.bfloat16() is equivalent to self.to(torch.bfloat16)", "description": "", "code-info": {"name": "torch.Tensor.bfloat16", "parameters": []}},
{"code": "torch.Tensor.bincount(weights=None,minlength=0)", "id": "torch.Tensor.bincount", "summary": "See torch.bincount()\n", "description": "", "code-info": {"name": "torch.Tensor.bincount", "parameters": [{"name": "weights", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "minlength", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.Tensor.bitwise_not()", "id": "torch.Tensor.bitwise_not", "summary": "See torch.bitwise_not()\n", "description": "", "code-info": {"name": "torch.Tensor.bitwise_not", "parameters": []}},
{"code": "torch.Tensor.bitwise_not_()", "id": "torch.Tensor.bitwise_not_", "summary": "In-place version of bitwise_not()\n", "description": "", "code-info": {"name": "torch.Tensor.bitwise_not_", "parameters": []}},
{"code": "torch.Tensor.bitwise_xor()", "id": "torch.Tensor.bitwise_xor", "summary": "See torch.bitwise_xor()\n", "description": "", "code-info": {"name": "torch.Tensor.bitwise_xor", "parameters": []}},
{"code": "torch.Tensor.bitwise_xor_()", "id": "torch.Tensor.bitwise_xor_", "summary": "In-place version of bitwise_xor()\n", "description": "", "code-info": {"name": "torch.Tensor.bitwise_xor_", "parameters": []}},
{"code": "torch.is_storage(obj)", "id": "torch.is_storage", "summary": "Returns True if obj is a PyTorch storage object.\n\nParameters\nobj (Object) \u2013 Object to test\n\n\n", "description": "", "code-info": {"name": "torch.is_storage", "parameters": [{"name": "obj", "is_optional": false, "type": "others", "description": "(Object) \u2013 Object to test"}]}},
{"code": "torch.is_floating_point(input)", "id": "torch.is_floating_point", "summary": "Returns True if the data type of input is a floating point data type i.e.,\none of torch.float64, torch.float32 and torch.float16.\n\nParameters\ninput (Tensor) \u2013 the PyTorch tensor to test\n\n\n", "description": "", "code-info": {"name": "torch.is_floating_point", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the PyTorch tensor to test"}]}},
{"code": "torch.set_default_dtype(d)", "id": "torch.set_default_dtype", "summary": "Sets the default floating point dtype to d", "description": "", "code-info": {"name": "torch.set_default_dtype", "parameters": [{"name": "d", "is_optional": false, "type": "others", "description": "(torch.dtype) \u2013 the floating point dtype to make the default"}]}},
{"code": "torch.get_default_dtype()", "id": "torch.get_default_dtype", "summary": "Get the current default floating point torch.dtype.\nExample:\n&gt;&gt;&gt; torch.get_default_dtype()  # initial default for floating point is torch.float32\ntorch.float32\n&gt;&gt;&gt; torch.set_default_dtype(torch.float64)\n&gt;&gt;&gt; torch.get_default_dtype()  # default is now changed to torch.float64\ntorch.float64\n&gt;&gt;&gt; torch.set_default_tensor_type(torch.FloatTensor)  # setting tensor type also affects this\n&gt;&gt;&gt; torch.get_default_dtype()  # changed to torch.float32, the dtype for torch.FloatTensor\ntorch.float32\n\n\n", "description": "", "code-info": {"name": "torch.get_default_dtype", "parameters": []}},
{"code": "torch.set_default_tensor_type(t)", "id": "torch.set_default_tensor_type", "summary": "Sets the default torch.Tensor type to floating point tensor type\nt", "description": "", "code-info": {"name": "torch.set_default_tensor_type", "parameters": [{"name": "t", "is_optional": false, "type": "string", "description": "(python:type or string) \u2013 the floating point tensor type or its name"}]}},
{"code": "torch.numel(input)", "id": "torch.numel", "summary": "Returns the total number of elements in the input tensor.\n\nParameters\ninput (Tensor) \u2013 the input tensor.\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(1, 2, 3, 4, 5)\n&gt;&gt;&gt; torch.numel(a)\n120\n&gt;&gt;&gt; a = torch.zeros(4,4)\n&gt;&gt;&gt; torch.numel(a)\n16\n\n\n", "description": "", "code-info": {"name": "torch.numel", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}]}},
{"code": "torch.set_printoptions(precision=None,threshold=None,edgeitems=None,linewidth=None,profile=None,sci_mode=None)", "id": "torch.set_printoptions", "summary": "Set options for printing", "description": "", "code-info": {"name": "torch.set_printoptions", "parameters": [{"name": "precision", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "threshold", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "edgeitems", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "linewidth", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "profile", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "sci_mode", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.set_flush_denormal(mode)", "id": "torch.set_flush_denormal", "summary": "Disables denormal floating numbers on CPU.\nReturns True if your system supports flushing denormal numbers and it\nsuccessfully configures flush denormal mode", "description": "", "code-info": {"name": "torch.set_flush_denormal", "parameters": [{"name": "mode", "is_optional": false, "type": "bool", "description": "(bool) \u2013 Controls whether to enable flush denormal mode or not"}]}},
{"code": "torch.tensor(data,dtype=None,device=None,requires_grad=False,pin_memory=False)", "id": "torch.tensor", "summary": "Constructs a tensor with data.\n\nWarning\ntorch.tensor() always copies data", "description": "", "code-info": {"name": "torch.tensor", "parameters": [{"name": "data", "is_optional": false, "type": "others", "description": "(array_like) \u2013 Initial data for the tensor. Can be a list, tuple,\nNumPy ndarray, scalar, and other types."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, infers data type from data."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}, {"name": "pin_memory", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If set, returned tensor would be allocated in\nthe pinned memory. Works only for CPU tensors. Default: False."}]}},
{"code": "torch.sparse_coo_tensor(indices,values,size=None,dtype=None,device=None,requires_grad=False)", "id": "torch.sparse_coo_tensor", "summary": "Constructs a sparse tensors in COO(rdinate) format with non-zero elements at the given indices\nwith the given values", "description": "", "code-info": {"name": "torch.sparse_coo_tensor", "parameters": [{"name": "indices", "is_optional": false, "type": "others", "description": "(array_like) \u2013 Initial data for the tensor. Can be a list, tuple,\nNumPy ndarray, scalar, and other types. Will be cast to a torch.LongTensor\ninternally. The indices are the coordinates of the non-zero values in the matrix, and thus\nshould be two-dimensional where the first dimension is the number of tensor dimensions and\nthe second dimension is the number of non-zero values."}, {"name": "values", "is_optional": false, "type": "others", "description": "(array_like) \u2013 Initial values for the tensor. Can be a list, tuple,\nNumPy ndarray, scalar, and other types."}, {"name": "size", "is_optional": true, "type": "others", "default_value": "None", "description": "(list, tuple, or torch.Size, optional) \u2013 Size of the sparse tensor. If not\nprovided the size will be inferred as the minimum size big enough to hold all non-zero\nelements."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, infers data type from values."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.as_tensor(data,dtype=None,device=None)", "id": "torch.as_tensor", "summary": "Convert the data into a torch.Tensor", "description": "", "code-info": {"name": "torch.as_tensor", "parameters": [{"name": "data", "is_optional": false, "type": "others", "description": "(array_like) \u2013 Initial data for the tensor. Can be a list, tuple,\nNumPy ndarray, scalar, and other types."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, infers data type from data."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}]}},
{"code": "torch.as_strided(input,size,stride,storage_offset=0)", "id": "torch.as_strided", "summary": "Create a view of an existing torch.Tensor input with specified\nsize, stride and storage_offset.\n\nWarning\nMore than one element of a created tensor may refer to a single memory\nlocation", "description": "", "code-info": {"name": "torch.as_strided", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "size", "is_optional": false, "type": "int", "description": "(tuple or python:ints) \u2013 the shape of the output tensor"}, {"name": "stride", "is_optional": false, "type": "int", "description": "(tuple or python:ints) \u2013 the stride of the output tensor"}, {"name": "storage_offset", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 the offset in the underlying storage of the output tensor"}]}},
{"code": "torch.from_numpy(ndarray)", "id": "torch.from_numpy", "summary": "Creates a Tensor from a numpy.ndarray.\nThe returned tensor and ndarray share the same memory", "description": "", "code-info": {"name": "torch.from_numpy", "parameters": [{"name": "ndarray", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.threshold_(input,threshold,value)", "id": "torch.nn.functional.threshold_", "summary": "In-place version of threshold().\n", "description": "", "code-info": {"name": "torch.nn.functional.threshold_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "threshold", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.relu(input,inplace=False)", "id": "torch.nn.functional.relu", "summary": "Applies the rectified linear unit function element-wise", "description": "", "code-info": {"name": "torch.nn.functional.relu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.relu_(input)", "id": "torch.nn.functional.relu_", "summary": "In-place version of relu().\n", "description": "", "code-info": {"name": "torch.nn.functional.relu_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.hardtanh(input,min_val=-1.,max_val=1.,inplace=False)", "id": "torch.nn.functional.hardtanh", "summary": "Applies the HardTanh function element-wise", "description": "", "code-info": {"name": "torch.nn.functional.hardtanh", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "min_val", "is_optional": true, "type": "others", "default_value": "-1.", "description": ""}, {"name": "max_val", "is_optional": true, "type": "others", "default_value": "1.", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.hardtanh_(input,min_val=-1.,max_val=1.)", "id": "torch.nn.functional.hardtanh_", "summary": "In-place version of hardtanh().\n", "description": "", "code-info": {"name": "torch.nn.functional.hardtanh_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "min_val", "is_optional": true, "type": "others", "default_value": "-1.", "description": ""}, {"name": "max_val", "is_optional": true, "type": "others", "default_value": "1.", "description": ""}]}},
{"code": "torch.nn.functional.relu6(input,inplace=False)", "id": "torch.nn.functional.relu6", "summary": "Applies the element-wise function ReLU6(x)=min\u2061(max\u2061(0,x),6)\\text{ReLU6}(x) = \\min(\\max(0,x), 6)ReLU6(x)=min(max(0,x),6)\n\n.\nSee ReLU6 for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.relu6", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.elu(input,alpha=1.0,inplace=False)", "id": "torch.nn.functional.elu", "summary": "Applies element-wise,\nELU(x)=max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x)\u22121))\\text{ELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1))ELU(x)=max(0,x)+min(0,\u03b1\u2217(exp(x)\u22121))\n\n.\nSee ELU for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.elu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "alpha", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.elu_(input,alpha=1.)", "id": "torch.nn.functional.elu_", "summary": "In-place version of elu().\n", "description": "", "code-info": {"name": "torch.nn.functional.elu_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "alpha", "is_optional": true, "type": "others", "default_value": "1.", "description": ""}]}},
{"code": "torch.nn.functional.selu(input,inplace=False)", "id": "torch.nn.functional.selu", "summary": "Applies element-wise,\nSELU(x)=scale\u2217(max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x)\u22121)))\\text{SELU}(x) = scale * (\\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)))SELU(x)=scale\u2217(max(0,x)+min(0,\u03b1\u2217(exp(x)\u22121)))\n\n,\nwith \u03b1=1.6732632423543772848170429916717\\alpha=1.6732632423543772848170429916717\u03b1=1.6732632423543772848170429916717\n\n and\nscale=1.0507009873554804934193349852946scale=1.0507009873554804934193349852946scale=1.0507009873554804934193349852946\n\n.\nSee SELU for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.selu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.celu(input,alpha=1.,inplace=False)", "id": "torch.nn.functional.celu", "summary": "Applies element-wise,\nCELU(x)=max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x/\u03b1)\u22121))\\text{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1))CELU(x)=max(0,x)+min(0,\u03b1\u2217(exp(x/\u03b1)\u22121))\n\n.\nSee CELU for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.celu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "alpha", "is_optional": true, "type": "others", "default_value": "1.", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.leaky_relu(input,negative_slope=0.01,inplace=False)", "id": "torch.nn.functional.leaky_relu", "summary": "Applies element-wise,\nLeakyReLU(x)=max\u2061(0,x)+negative_slope\u2217min\u2061(0,x)\\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x)LeakyReLU(x)=max(0,x)+negative_slope\u2217min(0,x)\n\n\nSee LeakyReLU for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.leaky_relu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "negative_slope", "is_optional": true, "type": "others", "default_value": "0.01", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.leaky_relu_(input,negative_slope=0.01)", "id": "torch.nn.functional.leaky_relu_", "summary": "In-place version of leaky_relu().\n", "description": "", "code-info": {"name": "torch.nn.functional.leaky_relu_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "negative_slope", "is_optional": true, "type": "others", "default_value": "0.01", "description": ""}]}},
{"code": "torch.nn.functional.prelu(input,weight)", "id": "torch.nn.functional.prelu", "summary": "Applies element-wise the function\nPReLU(x)=max\u2061(0,x)+weight\u2217min\u2061(0,x)\\text{PReLU}(x) = \\max(0,x) + \\text{weight} * \\min(0,x)PReLU(x)=max(0,x)+weight\u2217min(0,x)\n\n where weight is a\nlearnable parameter.\nSee PReLU for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.prelu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.rrelu(input,lower=1./8,upper=1./3,training=False,inplace=False)", "id": "torch.nn.functional.rrelu", "summary": "Randomized leaky ReLU.\nSee RReLU for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.rrelu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "lower", "is_optional": true, "type": "others", "default_value": "1./8", "description": ""}, {"name": "upper", "is_optional": true, "type": "others", "default_value": "1./3", "description": ""}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.rrelu_(input,lower=1./8,upper=1./3,training=False)", "id": "torch.nn.functional.rrelu_", "summary": "In-place version of rrelu().\n", "description": "", "code-info": {"name": "torch.nn.functional.rrelu_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "lower", "is_optional": true, "type": "others", "default_value": "1./8", "description": ""}, {"name": "upper", "is_optional": true, "type": "others", "default_value": "1./3", "description": ""}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.glu(input,dim=-1)", "id": "torch.nn.functional.glu", "summary": "The gated linear unit", "description": "", "code-info": {"name": "torch.nn.functional.glu", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input tensor"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 dimension on which to split the input. Default: -1"}]}},
{"code": "torch.nn.functional.gelu(input)", "id": "torch.nn.functional.gelu", "summary": "Applies element-wise the function\nGELU(x)=x\u2217\u03a6(x)\\text{GELU}(x) = x * \\Phi(x)GELU(x)=x\u2217\u03a6(x)\n\n\nwhere \u03a6(x)\\Phi(x)\u03a6(x)\n\n is the Cumulative Distribution Function for Gaussian Distribution.\nSee Gaussian Error Linear Units (GELUs).\n", "description": "", "code-info": {"name": "torch.nn.functional.gelu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.gamma.Gamma.entropy()", "id": "torch.distributions.gamma.Gamma.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.gamma.Gamma.entropy", "parameters": []}},
{"code": "torch.distributions.gamma.Gamma.expand(batch_shape,_instance=None)", "id": "torch.distributions.gamma.Gamma.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.gamma.Gamma.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.gamma.Gamma.log_prob(value)", "id": "torch.distributions.gamma.Gamma.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.gamma.Gamma.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.gamma.Gamma.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.gamma.Gamma.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.gamma.Gamma.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.geometric.Geometric.entropy()", "id": "torch.distributions.geometric.Geometric.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.geometric.Geometric.entropy", "parameters": []}},
{"code": "torch.distributions.geometric.Geometric.expand(batch_shape,_instance=None)", "id": "torch.distributions.geometric.Geometric.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.geometric.Geometric.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.geometric.Geometric.log_prob(value)", "id": "torch.distributions.geometric.Geometric.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.geometric.Geometric.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.geometric.Geometric.sample(sample_shape=torch.Size([])", "id": "torch.distributions.geometric.Geometric.sample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.geometric.Geometric.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.gumbel.Gumbel.entropy()", "id": "torch.distributions.gumbel.Gumbel.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.gumbel.Gumbel.entropy", "parameters": []}},
{"code": "torch.distributions.gumbel.Gumbel.expand(batch_shape,_instance=None)", "id": "torch.distributions.gumbel.Gumbel.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.gumbel.Gumbel.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.gumbel.Gumbel.log_prob(value)", "id": "torch.distributions.gumbel.Gumbel.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.gumbel.Gumbel.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.half_cauchy.HalfCauchy.cdf(value)", "id": "torch.distributions.half_cauchy.HalfCauchy.cdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.half_cauchy.HalfCauchy.entropy()", "id": "torch.distributions.half_cauchy.HalfCauchy.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.entropy", "parameters": []}},
{"code": "torch.distributions.half_cauchy.HalfCauchy.expand(batch_shape,_instance=None)", "id": "torch.distributions.half_cauchy.HalfCauchy.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.half_cauchy.HalfCauchy.icdf(prob)", "id": "torch.distributions.half_cauchy.HalfCauchy.icdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.icdf", "parameters": [{"name": "prob", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.half_cauchy.HalfCauchy.log_prob(value)", "id": "torch.distributions.half_cauchy.HalfCauchy.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-name descname(device=None,dtype=None,non_blocking=False)", "id": "sig-name descname", "summary": "", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.bmm(batch2)", "id": "torch.Tensor.bmm", "summary": "See torch.bmm()\n", "description": "", "code-info": {"name": "torch.Tensor.bmm", "parameters": [{"name": "batch2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.bool()", "id": "torch.Tensor.bool", "summary": "self.bool() is equivalent to self.to(torch.bool)", "description": "", "code-info": {"name": "torch.Tensor.bool", "parameters": []}},
{"code": "torch.Tensor.byte()", "id": "torch.Tensor.byte", "summary": "self.byte() is equivalent to self.to(torch.uint8)", "description": "", "code-info": {"name": "torch.Tensor.byte", "parameters": []}},
{"code": "torch.Tensor.cauchy_(median=0,sigma=1,*,generator=None)", "id": "torch.Tensor.cauchy_", "summary": "Fills the tensor with numbers drawn from the Cauchy distribution:\n\nf(x)=1\u03c0\u03c3(x\u2212median)2+\u03c32f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}f(x)=\u03c01\u200b(x\u2212median)2+\u03c32\u03c3\u200b\n\n", "description": "", "code-info": {"name": "torch.Tensor.cauchy_", "parameters": [{"name": "median", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "sigma", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.ceil()", "id": "torch.Tensor.ceil", "summary": "See torch.ceil()\n", "description": "", "code-info": {"name": "torch.Tensor.ceil", "parameters": []}},
{"code": "torch.Tensor.ceil_()", "id": "torch.Tensor.ceil_", "summary": "In-place version of ceil()\n", "description": "", "code-info": {"name": "torch.Tensor.ceil_", "parameters": []}},
{"code": "torch.Tensor.char()", "id": "torch.Tensor.char", "summary": "self.char() is equivalent to self.to(torch.int8)", "description": "", "code-info": {"name": "torch.Tensor.char", "parameters": []}},
{"code": "torch.Tensor.cholesky(upper=False)", "id": "torch.Tensor.cholesky", "summary": "See torch.cholesky()\n", "description": "", "code-info": {"name": "torch.Tensor.cholesky", "parameters": [{"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.cholesky_inverse(upper=False)", "id": "torch.Tensor.cholesky_inverse", "summary": "See torch.cholesky_inverse()\n", "description": "", "code-info": {"name": "torch.Tensor.cholesky_inverse", "parameters": [{"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.cholesky_solve(input2,upper=False)", "id": "torch.Tensor.cholesky_solve", "summary": "See torch.cholesky_solve()\n", "description": "", "code-info": {"name": "torch.Tensor.cholesky_solve", "parameters": [{"name": "input2", "is_optional": false, "type": "others", "description": ""}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.chunk(chunks,dim=0)", "id": "torch.Tensor.chunk", "summary": "See torch.chunk()\n", "description": "", "code-info": {"name": "torch.Tensor.chunk", "parameters": [{"name": "chunks", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.Tensor.clamp(min,max)", "id": "torch.Tensor.clamp", "summary": "See torch.clamp()\n", "description": "", "code-info": {"name": "torch.Tensor.clamp", "parameters": [{"name": "min", "is_optional": false, "type": "others", "description": ""}, {"name": "max", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.clamp_(min,max)", "id": "torch.Tensor.clamp_", "summary": "In-place version of clamp()\n", "description": "", "code-info": {"name": "torch.Tensor.clamp_", "parameters": [{"name": "min", "is_optional": false, "type": "others", "description": ""}, {"name": "max", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.clone()", "id": "torch.Tensor.clone", "summary": "Returns a copy of the self tensor", "description": "", "code-info": {"name": "torch.Tensor.clone", "parameters": []}},
{"code": "torch.Tensor.contiguous()", "id": "torch.Tensor.contiguous", "summary": "Returns a contiguous tensor containing the same data as self tensor", "description": "", "code-info": {"name": "torch.Tensor.contiguous", "parameters": []}},
{"code": "torch.Tensor.copy_(src,non_blocking=False)", "id": "torch.Tensor.copy_", "summary": "Copies the elements from src into self tensor and returns\nself.\nThe src tensor must be broadcastable\nwith the self tensor", "description": "", "code-info": {"name": "torch.Tensor.copy_", "parameters": [{"name": "src", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the source tensor to copy from"}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 if True and this copy is between CPU and GPU,\nthe copy may occur asynchronously with respect to the host. For other\ncases, this argument has no effect."}]}},
{"code": "torch.Tensor.conj()", "id": "torch.Tensor.conj", "summary": "See torch.conj()\n", "description": "", "code-info": {"name": "torch.Tensor.conj", "parameters": []}},
{"code": "torch.Tensor.cos()", "id": "torch.Tensor.cos", "summary": "See torch.cos()\n", "description": "", "code-info": {"name": "torch.Tensor.cos", "parameters": []}},
{"code": "torch.Tensor.cos_()", "id": "torch.Tensor.cos_", "summary": "In-place version of cos()\n", "description": "", "code-info": {"name": "torch.Tensor.cos_", "parameters": []}},
{"code": "torch.zeros(*size,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.zeros", "summary": "Returns a tensor filled with the scalar value 0, with the shape defined\nby the variable argument size.\n\nParameters\n\nsize (python:int...) \u2013 a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple.\nout (Tensor, optional) \u2013 the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()).\nlayout (torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type())", "description": "", "code-info": {"name": "torch.zeros", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type())."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.zeros_like(input,dtype=None,layout=None,device=None,requires_grad=False)", "id": "torch.zeros_like", "summary": "Returns a tensor filled with the scalar value 0, with the same size as\ninput", "description": "", "code-info": {"name": "torch.zeros_like", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the size of input will determine size of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: if None, defaults to the dtype of input."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.layout, optional) \u2013 the desired layout of returned tensor.\nDefault: if None, defaults to the layout of input."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, defaults to the device of input."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.ones(*size,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.ones", "summary": "Returns a tensor filled with the scalar value 1, with the shape defined\nby the variable argument size.\n\nParameters\n\nsize (python:int...) \u2013 a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple.\nout (Tensor, optional) \u2013 the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()).\nlayout (torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type())", "description": "", "code-info": {"name": "torch.ones", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type())."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.ones_like(input,dtype=None,layout=None,device=None,requires_grad=False)", "id": "torch.ones_like", "summary": "Returns a tensor filled with the scalar value 1, with the same size as\ninput", "description": "", "code-info": {"name": "torch.ones_like", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the size of input will determine size of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: if None, defaults to the dtype of input."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.layout, optional) \u2013 the desired layout of returned tensor.\nDefault: if None, defaults to the layout of input."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, defaults to the device of input."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.arange(start=0,end,step=1,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.arange", "summary": "Returns a 1-D tensor of size \u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309\n\n\nwith values from the interval [start, end) taken with common difference\nstep beginning from start.\nNote that non-integer step is subject to floating point rounding errors when\ncomparing against end; to avoid inconsistency, we advise adding a small epsilon to end\nin such cases.\n\nouti+1=outi+step\\text{out}_{{i+1}} = \\text{out}_{i} + \\text{step}\n\nouti+1\u200b=outi\u200b+step\n\n\nParameters\n\nstart (Number) \u2013 the starting value for the set of points", "description": "", "code-info": {"name": "torch.arange", "parameters": [{"name": "start", "is_optional": true, "type": "int", "default_value": "0", "description": "(Number) \u2013 the starting value for the set of points. Default: 0."}, {"name": "end", "is_optional": false, "type": "others", "description": "(Number) \u2013 the ending value for the set of points"}, {"name": "step", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number) \u2013 the gap between each pair of adjacent points. Default: 1."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()). If dtype is not given, infer the data type from the other input\narguments. If any of start, end, or stop are floating-point, the\ndtype is inferred to be the default dtype, see\nget_default_dtype(). Otherwise, the dtype is inferred to\nbe torch.int64."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.range(start=0,end,step=1,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.range", "summary": "Returns a 1-D tensor of size \u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1\n\n\nwith values from start to end with step step", "description": "", "code-info": {"name": "torch.range", "parameters": [{"name": "start", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float) \u2013 the starting value for the set of points. Default: 0."}, {"name": "end", "is_optional": false, "type": "float", "description": "(python:float) \u2013 the ending value for the set of points"}, {"name": "step", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:float) \u2013 the gap between each pair of adjacent points. Default: 1."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()). If dtype is not given, infer the data type from the other input\narguments. If any of start, end, or stop are floating-point, the\ndtype is inferred to be the default dtype, see\nget_default_dtype(). Otherwise, the dtype is inferred to\nbe torch.int64."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.linspace(start,end,steps=100,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.linspace", "summary": "Returns a one-dimensional tensor of steps\nequally spaced points between start and end.\nThe output tensor is 1-D of size steps.\n\nParameters\n\nstart (python:float) \u2013 the starting value for the set of points\nend (python:float) \u2013 the ending value for the set of points\nsteps (python:int) \u2013 number of points to sample between start\nand end", "description": "", "code-info": {"name": "torch.linspace", "parameters": [{"name": "start", "is_optional": false, "type": "float", "description": "(python:float) \u2013 the starting value for the set of points"}, {"name": "end", "is_optional": false, "type": "float", "description": "(python:float) \u2013 the ending value for the set of points"}, {"name": "steps", "is_optional": true, "type": "int", "default_value": "100", "description": "(python:int) \u2013 number of points to sample between start\nand end. Default: 100."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type())."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.logspace(start,end,steps=100,base=10.0,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.logspace", "summary": "Returns a one-dimensional tensor of steps points\nlogarithmically spaced with base base between\nbasestart{\\text{base}}^{\\text{start}}basestart\n\n and baseend{\\text{base}}^{\\text{end}}baseend\n\n.\nThe output tensor is 1-D of size steps.\n\nParameters\n\nstart (python:float) \u2013 the starting value for the set of points\nend (python:float) \u2013 the ending value for the set of points\nsteps (python:int) \u2013 number of points to sample between start\nand end", "description": "", "code-info": {"name": "torch.logspace", "parameters": [{"name": "start", "is_optional": false, "type": "float", "description": "(python:float) \u2013 the starting value for the set of points"}, {"name": "end", "is_optional": false, "type": "float", "description": "(python:float) \u2013 the ending value for the set of points"}, {"name": "steps", "is_optional": true, "type": "int", "default_value": "100", "description": "(python:int) \u2013 number of points to sample between start\nand end. Default: 100."}, {"name": "base", "is_optional": true, "type": "float", "default_value": "10.0", "description": "(python:float) \u2013 base of the logarithm function. Default: 10.0."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type())."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.eye(n,m=None,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.eye", "summary": "Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n\nParameters\n\nn (python:int) \u2013 the number of rows\nm (python:int, optional) \u2013 the number of columns with default being n\nout (Tensor, optional) \u2013 the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()).\nlayout (torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type())", "description": "", "code-info": {"name": "torch.eye", "parameters": [{"name": "n", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the number of rows"}, {"name": "m", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 the number of columns with default being n"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type())."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.nn.functional.logsigmoid(input)", "id": "torch.nn.functional.logsigmoid", "summary": "Applies element-wise LogSigmoid(xi)=log\u2061(11+exp\u2061(\u2212xi))\\text{LogSigmoid}(x_i) = \\log \\left(\\frac{1}{1 + \\exp(-x_i)}\\right)LogSigmoid(xi\u200b)=log(1+exp(\u2212xi\u200b)1\u200b)\n\n\nSee LogSigmoid for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.logsigmoid", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.hardshrink(input,lambd=0.5)", "id": "torch.nn.functional.hardshrink", "summary": "Applies the hard shrinkage function element-wise\nSee Hardshrink for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.hardshrink", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "lambd", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}]}},
{"code": "torch.nn.functional.tanhshrink(input)", "id": "torch.nn.functional.tanhshrink", "summary": "Applies element-wise, Tanhshrink(x)=x\u2212Tanh(x)\\text{Tanhshrink}(x) = x - \\text{Tanh}(x)Tanhshrink(x)=x\u2212Tanh(x)\n\n\nSee Tanhshrink for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.tanhshrink", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.softsign(input)", "id": "torch.nn.functional.softsign", "summary": "Applies element-wise, the function SoftSign(x)=x1+\u2223x\u2223\\text{SoftSign}(x) = \\frac{x}{1 + |x|}SoftSign(x)=1+\u2223x\u2223x\u200b\n\n\nSee Softsign for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.softsign", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.softplus(input,beta=1,threshold=20)", "id": "torch.nn.functional.softplus", "summary": "", "description": "", "code-info": {"name": "torch.nn.functional.softplus", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "threshold", "is_optional": true, "type": "int", "default_value": "20", "description": ""}]}},
{"code": "torch.nn.functional.softmin(input,dim=None,_stacklevel=3,dtype=None)", "id": "torch.nn.functional.softmin", "summary": "Applies a softmin function.\nNote that Softmin(x)=Softmax(\u2212x)\\text{Softmin}(x) = \\text{Softmax}(-x)Softmin(x)=Softmax(\u2212x)\n\n", "description": "", "code-info": {"name": "torch.nn.functional.softmin", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input"}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "_stacklevel", "is_optional": true, "type": "int", "default_value": "3", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed. This is useful for preventing data type overflows. Default: None."}]}},
{"code": "torch.nn.functional.softmax(input,dim=None,_stacklevel=3,dtype=None)", "id": "torch.nn.functional.softmax", "summary": "Applies a softmax function.\nSoftmax is defined as:\nSoftmax(xi)=exp(xi)\u2211jexp(xj)\\text{Softmax}(x_{i}) = \\frac{exp(x_i)}{\\sum_j exp(x_j)}Softmax(xi\u200b)=\u2211j\u200bexp(xj\u200b)exp(xi\u200b)\u200b\n\n\nIt is applied to all slices along dim, and will re-scale them so that the elements\nlie in the range [0, 1] and sum to 1.\nSee Softmax for more details.\n\nParameters\n\ninput (Tensor) \u2013 input\ndim (python:int) \u2013 A dimension along which softmax will be computed.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed", "description": "", "code-info": {"name": "torch.nn.functional.softmax", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input"}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "_stacklevel", "is_optional": true, "type": "int", "default_value": "3", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed. This is useful for preventing data type overflows. Default: None."}]}},
{"code": "torch.nn.functional.softshrink(input,lambd=0.5)", "id": "torch.nn.functional.softshrink", "summary": "Applies the soft shrinkage function elementwise\nSee Softshrink for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.softshrink", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "lambd", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}]}},
{"code": "torch.nn.functional.gumbel_softmax(logits,tau=1,hard=False,eps=1e-10,dim=-1)", "id": "torch.nn.functional.gumbel_softmax", "summary": "Samples from the Gumbel-Softmax distribution (Link 1  Link 2) and optionally discretizes.\n\nParameters\n\nlogits \u2013 [\u2026, num_features] unnormalized log probabilities\ntau \u2013 non-negative scalar temperature\nhard \u2013 if True, the returned samples will be discretized as one-hot vectors,\nbut will be differentiated as if it is the soft sample in autograd\ndim (python:int) \u2013 A dimension along which softmax will be computed", "description": "", "code-info": {"name": "torch.nn.functional.gumbel_softmax", "parameters": [{"name": "logits", "is_optional": false, "type": "others", "description": ""}, {"name": "tau", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "hard", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-10", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 A dimension along which softmax will be computed. Default: -1."}]}},
{"code": "torch.nn.functional.log_softmax(input,dim=None,_stacklevel=3,dtype=None)", "id": "torch.nn.functional.log_softmax", "summary": "Applies a softmax followed by a logarithm.\nWhile mathematically equivalent to log(softmax(x)), doing these two\noperations separately is slower, and numerically unstable", "description": "", "code-info": {"name": "torch.nn.functional.log_softmax", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input"}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "_stacklevel", "is_optional": true, "type": "int", "default_value": "3", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed. This is useful for preventing data type overflows. Default: None."}]}},
{"code": "torch.nn.functional.tanh(input)", "id": "torch.nn.functional.tanh", "summary": "Applies element-wise,\nTanh(x)=tanh\u2061(x)=exp\u2061(x)\u2212exp\u2061(\u2212x)exp\u2061(x)+exp\u2061(\u2212x)\\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}Tanh(x)=tanh(x)=exp(x)+exp(\u2212x)exp(x)\u2212exp(\u2212x)\u200b\n\n\nSee Tanh for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.tanh", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.sigmoid(input)", "id": "torch.nn.functional.sigmoid", "summary": "Applies the element-wise function Sigmoid(x)=11+exp\u2061(\u2212x)\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}Sigmoid(x)=1+exp(\u2212x)1\u200b\n\n\nSee Sigmoid for more details.\n", "description": "", "code-info": {"name": "torch.nn.functional.sigmoid", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.functional.batch_norm(input,running_mean,running_var,weight=None,bias=None,training=False,momentum=0.1,eps=1e-05)", "id": "torch.nn.functional.batch_norm", "summary": "Applies Batch Normalization for each channel across a batch of data.\nSee BatchNorm1d, BatchNorm2d,\nBatchNorm3d for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.batch_norm", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "running_mean", "is_optional": false, "type": "others", "description": ""}, {"name": "running_var", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}]}},
{"code": "torch.nn.functional.instance_norm(input,running_mean=None,running_var=None,weight=None,bias=None,use_input_stats=True,momentum=0.1,eps=1e-05)", "id": "torch.nn.functional.instance_norm", "summary": "Applies Instance Normalization for each channel in each data sample in a\nbatch.\nSee InstanceNorm1d, InstanceNorm2d,\nInstanceNorm3d for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.instance_norm", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "running_mean", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "running_var", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "use_input_stats", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}]}},
{"code": "torch.nn.functional.layer_norm(input,normalized_shape,weight=None,bias=None,eps=1e-05)", "id": "torch.nn.functional.layer_norm", "summary": "Applies Layer Normalization for last certain number of dimensions.\nSee LayerNorm for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.layer_norm", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "normalized_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}]}},
{"code": "torch.distributions.half_normal.HalfNormal.cdf(value)", "id": "torch.distributions.half_normal.HalfNormal.cdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.half_normal.HalfNormal.entropy()", "id": "torch.distributions.half_normal.HalfNormal.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.entropy", "parameters": []}},
{"code": "torch.distributions.half_normal.HalfNormal.expand(batch_shape,_instance=None)", "id": "torch.distributions.half_normal.HalfNormal.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.half_normal.HalfNormal.icdf(prob)", "id": "torch.distributions.half_normal.HalfNormal.icdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.icdf", "parameters": [{"name": "prob", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.half_normal.HalfNormal.log_prob(value)", "id": "torch.distributions.half_normal.HalfNormal.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.independent.Independent.entropy()", "id": "torch.distributions.independent.Independent.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.independent.Independent.entropy", "parameters": []}},
{"code": "torch.distributions.independent.Independent.enumerate_support(expand=True)", "id": "torch.distributions.independent.Independent.enumerate_support", "summary": "", "description": "", "code-info": {"name": "torch.distributions.independent.Independent.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.distributions.independent.Independent.expand(batch_shape,_instance=None)", "id": "torch.distributions.independent.Independent.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.independent.Independent.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.independent.Independent.log_prob(value)", "id": "torch.distributions.independent.Independent.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.independent.Independent.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.independent.Independent.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.independent.Independent.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.independent.Independent.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.independent.Independent.sample(sample_shape=torch.Size([])", "id": "torch.distributions.independent.Independent.sample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.independent.Independent.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.laplace.Laplace.cdf(value)", "id": "torch.distributions.laplace.Laplace.cdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.laplace.Laplace.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.laplace.Laplace.entropy()", "id": "torch.distributions.laplace.Laplace.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.laplace.Laplace.entropy", "parameters": []}},
{"code": "torch.distributions.laplace.Laplace.expand(batch_shape,_instance=None)", "id": "torch.distributions.laplace.Laplace.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.laplace.Laplace.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.laplace.Laplace.icdf(value)", "id": "torch.distributions.laplace.Laplace.icdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.laplace.Laplace.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-name descname(dtype,non_blocking=False)", "id": "sig-name descname", "summary": "", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "dtype", "is_optional": false, "type": "others", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "sig-name descname(tensor,non_blocking=False)", "id": "sig-name descname", "summary": "", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.utils.clip_grad_norm_(parameters,max_norm,norm_type=2)", "id": "torch.nn.utils.clip_grad_norm_", "summary": "Clips gradient norm of an iterable of parameters.\nThe norm is computed over all gradients together, as if they were\nconcatenated into a single vector", "description": "", "code-info": {"name": "torch.nn.utils.clip_grad_norm_", "parameters": [{"name": "parameters", "is_optional": false, "type": "tensor", "description": "(Iterable[Tensor] or Tensor) \u2013 an iterable of Tensors or a\nsingle Tensor that will have gradients normalized"}, {"name": "max_norm", "is_optional": false, "type": "int", "description": "(python:float or python:int) \u2013 max norm of the gradients"}, {"name": "norm_type", "is_optional": true, "type": "int", "default_value": "2", "description": "(python:float or python:int) \u2013 type of the used p-norm. Can be 'inf' for\ninfinity norm."}]}},
{"code": "torch.nn.utils.clip_grad_value_(parameters,clip_value)", "id": "torch.nn.utils.clip_grad_value_", "summary": "Clips gradient of an iterable of parameters at specified value.\nGradients are modified in-place.\n\nParameters\n\nparameters (Iterable[Tensor] or Tensor) \u2013 an iterable of Tensors or a\nsingle Tensor that will have gradients normalized\nclip_value (python:float or python:int) \u2013 maximum allowed value of the gradients.\nThe gradients are clipped in the range\n[-clip_value,clip_value]\\left[\\text{-clip\\_value}, \\text{clip\\_value}\\right][-clip_value,clip_value]\n\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.clip_grad_value_", "parameters": [{"name": "parameters", "is_optional": false, "type": "tensor", "description": "(Iterable[Tensor] or Tensor) \u2013 an iterable of Tensors or a\nsingle Tensor that will have gradients normalized"}, {"name": "clip_value", "is_optional": false, "type": "int", "description": "(python:float or python:int) \u2013 maximum allowed value of the gradients.\nThe gradients are clipped in the range\n[-clip_value,clip_value]\\left[\\text{-clip\\_value}, \\text{clip\\_value}\\right][-clip_value,clip_value]"}]}},
{"code": "torch.nn.utils.parameters_to_vector(parameters)", "id": "torch.nn.utils.parameters_to_vector", "summary": "Convert parameters to one vector\n\nParameters\nparameters (Iterable[Tensor]) \u2013 an iterator of Tensors that are the\nparameters of a model.\n\nReturns\nThe parameters represented by a single vector\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.parameters_to_vector", "parameters": [{"name": "parameters", "is_optional": false, "type": "tensor", "description": "(Iterable[Tensor]) \u2013 an iterator of Tensors that are the\nparameters of a model."}]}},
{"code": "torch.nn.utils.vector_to_parameters(vec,parameters)", "id": "torch.nn.utils.vector_to_parameters", "summary": "Convert one vector to the parameters\n\nParameters\n\nvec (Tensor) \u2013 a single vector represents the parameters of a model.\nparameters (Iterable[Tensor]) \u2013 an iterator of Tensors that are the\nparameters of a model.\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.vector_to_parameters", "parameters": [{"name": "vec", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 a single vector represents the parameters of a model."}, {"name": "parameters", "is_optional": false, "type": "tensor", "description": "(Iterable[Tensor]) \u2013 an iterator of Tensors that are the\nparameters of a model."}]}},
{"code": "torch.nn.utils.prune.identity(module,name)", "id": "torch.nn.utils.prune.identity", "summary": "Applies pruning reparametrization to the tensor corresponding to the\nparameter called name in module without actually pruning any\nunits", "description": "", "code-info": {"name": "torch.nn.utils.prune.identity", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune."}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}]}},
{"code": "torch.nn.utils.prune.random_unstructured(module,name,amount)", "id": "torch.nn.utils.prune.random_unstructured", "summary": "Prunes tensor corresponding to parameter called name in module\nby removing the specified amount of (currently unpruned) units\nselected at random.\nModifies module in place (and also return the modified module) by:\n1) adding a named buffer called name+'_mask' corresponding to the\nbinary mask applied to the parameter name by the pruning method.\n2) replacing the parameter name by its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\namount (python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.random_unstructured", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}, {"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}]}},
{"code": "torch.nn.utils.prune.l1_unstructured(module,name,amount)", "id": "torch.nn.utils.prune.l1_unstructured", "summary": "Prunes tensor corresponding to parameter called name in module\nby removing the specified amount of (currently unpruned) units with the\nlowest L1-norm.\nModifies module in place (and also return the modified module)\nby:\n1) adding a named buffer called name+'_mask' corresponding to the\nbinary mask applied to the parameter name by the pruning method.\n2) replacing the parameter name by its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\namount (python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.l1_unstructured", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}, {"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}]}},
{"code": "torch.nn.utils.prune.random_structured(module,name,amount,dim)", "id": "torch.nn.utils.prune.random_structured", "summary": "Prunes tensor corresponding to parameter called name in module\nby removing the specified amount of (currently unpruned) channels\nalong the specified dim selected at random.\nModifies module in place (and also return the modified module)\nby:\n1) adding a named buffer called name+'_mask' corresponding to the\nbinary mask applied to the parameter name by the pruning method.\n2) replacing the parameter name by its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\namount (python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.random_structured", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}, {"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}, {"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 index of the dim along which we define channels to prune."}]}},
{"code": "torch.nn.utils.prune.ln_structured(module,name,amount,n,dim)", "id": "torch.nn.utils.prune.ln_structured", "summary": "Prunes tensor corresponding to parameter called name in module\nby removing the specified amount of (currently unpruned) channels\nalong the specified dim with the lowest L``n``-norm.\nModifies module in place (and also return the modified module)\nby:\n1) adding a named buffer called name+'_mask' corresponding to the\nbinary mask applied to the parameter name by the pruning method.\n2) replacing the parameter name by its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\namount (python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.ln_structured", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}, {"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}, {"name": "n", "is_optional": false, "type": "int", "description": "(python:int, python:float, inf, -inf, 'fro', 'nuc') \u2013 See documentation of valid\nentries for argument p in torch.norm()."}, {"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 index of the dim along which we define channels to prune."}]}},
{"code": "torch.nn.utils.prune.global_unstructured(parameters,pruning_method,**kwargs)", "id": "torch.nn.utils.prune.global_unstructured", "summary": "Globally prunes tensors corresponding to all parameters in parameters\nby applying the specified pruning_method.\nModifies modules in place by:\n1) adding a named buffer called name+'_mask' corresponding to the\nbinary mask applied to the parameter name by the pruning method.\n2) replacing the parameter name by its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'.\n\nParameters\n\nparameters (Iterable of (module, name) tuples) \u2013 parameters of\nthe model to prune in a global fashion, i.e", "description": "", "code-info": {"name": "torch.nn.utils.prune.global_unstructured", "parameters": [{"name": "parameters", "is_optional": false, "type": "others", "description": "(Iterable of (module, name) tuples) \u2013 parameters of\nthe model to prune in a global fashion, i.e. by aggregating all\nweights prior to deciding which ones to prune. module must be of\ntype nn.Module, and name must be a string."}, {"name": "pruning_method", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.utils.prune.custom_from_mask(module,name,mask)", "id": "torch.nn.utils.prune.custom_from_mask", "summary": "Prunes tensor corresponding to parameter called name in module\nby applying the pre-computed mask in mask.\nModifies module in place (and also return the modified module)\nby:\n1) adding a named buffer called name+'_mask' corresponding to the\nbinary mask applied to the parameter name by the pruning method.\n2) replacing the parameter name by its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\nmask (Tensor) \u2013 binary mask to be applied to the parameter.\n\n\nReturns\nmodified (i.e", "description": "", "code-info": {"name": "torch.nn.utils.prune.custom_from_mask", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}, {"name": "mask", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 binary mask to be applied to the parameter."}]}},
{"code": "torch.nn.utils.prune.remove(module,name)", "id": "torch.nn.utils.prune.remove", "summary": "Removes the pruning reparameterization from a module and the\npruning method from the forward hook", "description": "", "code-info": {"name": "torch.nn.utils.prune.remove", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}]}},
{"code": "torch.Tensor.cosh()", "id": "torch.Tensor.cosh", "summary": "See torch.cosh()\n", "description": "", "code-info": {"name": "torch.Tensor.cosh", "parameters": []}},
{"code": "torch.Tensor.cosh_()", "id": "torch.Tensor.cosh_", "summary": "In-place version of cosh()\n", "description": "", "code-info": {"name": "torch.Tensor.cosh_", "parameters": []}},
{"code": "torch.Tensor.cpu()", "id": "torch.Tensor.cpu", "summary": "Returns a copy of this object in CPU memory.\nIf this object is already in CPU memory and on the correct device,\nthen no copy is performed and the original object is returned.\n", "description": "", "code-info": {"name": "torch.Tensor.cpu", "parameters": []}},
{"code": "torch.Tensor.cross(other,dim=-1)", "id": "torch.Tensor.cross", "summary": "See torch.cross()\n", "description": "", "code-info": {"name": "torch.Tensor.cross", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}]}},
{"code": "torch.Tensor.cuda(device=None,non_blocking=False)", "id": "torch.Tensor.cuda", "summary": "Returns a copy of this object in CUDA memory.\nIf this object is already in CUDA memory and on the correct device,\nthen no copy is performed and the original object is returned.\n\nParameters\n\ndevice (torch.device) \u2013 The destination GPU device.\nDefaults to the current CUDA device.\nnon_blocking (bool) \u2013 If True and the source is in pinned memory,\nthe copy will be asynchronous with respect to the host.\nOtherwise, the argument has no effect", "description": "", "code-info": {"name": "torch.Tensor.cuda", "parameters": [{"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device) \u2013 The destination GPU device.\nDefaults to the current CUDA device."}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 If True and the source is in pinned memory,\nthe copy will be asynchronous with respect to the host.\nOtherwise, the argument has no effect. Default: False."}]}},
{"code": "torch.Tensor.cumprod(dim,dtype=None)", "id": "torch.Tensor.cumprod", "summary": "See torch.cumprod()\n", "description": "", "code-info": {"name": "torch.Tensor.cumprod", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.cumsum(dim,dtype=None)", "id": "torch.Tensor.cumsum", "summary": "See torch.cumsum()\n", "description": "", "code-info": {"name": "torch.Tensor.cumsum", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.data_ptr()", "id": "torch.Tensor.data_ptr", "summary": "Returns the address of the first element of self tensor.\n", "description": "", "code-info": {"name": "torch.Tensor.data_ptr", "parameters": []}},
{"code": "torch.Tensor.dequantize()", "id": "torch.Tensor.dequantize", "summary": "Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n", "description": "", "code-info": {"name": "torch.Tensor.dequantize", "parameters": []}},
{"code": "torch.Tensor.det()", "id": "torch.Tensor.det", "summary": "See torch.det()\n", "description": "", "code-info": {"name": "torch.Tensor.det", "parameters": []}},
{"code": "torch.Tensor.dense_dim()", "id": "torch.Tensor.dense_dim", "summary": "If self is a sparse COO tensor (i.e., with torch.sparse_coo layout),\nthis returns the number of dense dimensions", "description": "", "code-info": {"name": "torch.Tensor.dense_dim", "parameters": []}},
{"code": "sig-name descname()", "id": "sig-name descname", "summary": "Returns a new Tensor, detached from the current graph.\nThe result will never require gradient.\n\nNote\nReturned Tensor shares the same storage with the original one.\nIn-place modifications on either of them will be seen, and may trigger\nerrors in correctness checks.\nIMPORTANT NOTE: Previously, in-place size / stride / storage changes\n(such as resize_ / resize_as_ / set_ / transpose_) to the returned tensor\nalso update the original tensor", "description": "", "code-info": {"name": "sig-name descname", "parameters": []}},
{"code": "sig-name descname()", "id": "sig-name descname", "summary": "Detaches the Tensor from the graph that created it, making it a leaf.\nViews cannot be detached in-place.\n", "description": "", "code-info": {"name": "sig-name descname", "parameters": []}},
{"code": "torch.Tensor.diag(diagonal=0)", "id": "torch.Tensor.diag", "summary": "See torch.diag()\n", "description": "", "code-info": {"name": "torch.Tensor.diag", "parameters": [{"name": "diagonal", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.Tensor.diag_embed(offset=0,dim1=-2,dim2=-1)", "id": "torch.Tensor.diag_embed", "summary": "See torch.diag_embed()\n", "description": "", "code-info": {"name": "torch.Tensor.diag_embed", "parameters": [{"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dim1", "is_optional": true, "type": "others", "default_value": "-2", "description": ""}, {"name": "dim2", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}]}},
{"code": "torch.Tensor.diagflat(offset=0)", "id": "torch.Tensor.diagflat", "summary": "See torch.diagflat()\n", "description": "", "code-info": {"name": "torch.Tensor.diagflat", "parameters": [{"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.Tensor.diagonal(offset=0,dim1=0,dim2=1)", "id": "torch.Tensor.diagonal", "summary": "See torch.diagonal()\n", "description": "", "code-info": {"name": "torch.Tensor.diagonal", "parameters": [{"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dim1", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dim2", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torch.Tensor.fill_diagonal_(fill_value,wrap=False)", "id": "torch.Tensor.fill_diagonal_", "summary": "Fill the main diagonal of a tensor that has at least 2-dimensions.\nWhen dims&gt;2, all dimensions of input must be of equal length.\nThis function modifies the input tensor in-place, and returns the input tensor.\n\nParameters\n\nfill_value (Scalar) \u2013 the fill value\nwrap (bool) \u2013 the diagonal \u2018wrapped\u2019 after N columns for tall matrices.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.zeros(3, 3)\n&gt;&gt;&gt; a.fill_diagonal_(5)\ntensor([[5., 0., 0.],\n        [0., 5., 0.],\n        [0., 0., 5.]])\n&gt;&gt;&gt; b = torch.zeros(7, 3)\n&gt;&gt;&gt; b.fill_diagonal_(5)\ntensor([[5., 0., 0.],\n        [0., 5., 0.],\n        [0., 0., 5.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]])\n&gt;&gt;&gt; c = torch.zeros(7, 3)\n&gt;&gt;&gt; c.fill_diagonal_(5, wrap=True)\ntensor([[5., 0., 0.],\n        [0., 5., 0.],\n        [0., 0., 5.],\n        [0., 0., 0.],\n        [5., 0., 0.],\n        [0., 5., 0.],\n        [0., 0., 5.]])\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.fill_diagonal_", "parameters": [{"name": "fill_value", "is_optional": false, "type": "others", "description": "(Scalar) \u2013 the fill value"}, {"name": "wrap", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 the diagonal \u2018wrapped\u2019 after N columns for tall matrices."}]}},
{"code": "torch.Tensor.digamma()", "id": "torch.Tensor.digamma", "summary": "See torch.digamma()\n", "description": "", "code-info": {"name": "torch.Tensor.digamma", "parameters": []}},
{"code": "torch.Tensor.digamma_()", "id": "torch.Tensor.digamma_", "summary": "In-place version of digamma()\n", "description": "", "code-info": {"name": "torch.Tensor.digamma_", "parameters": []}},
{"code": "torch.Tensor.dim()", "id": "torch.Tensor.dim", "summary": "Returns the number of dimensions of self tensor.\n", "description": "", "code-info": {"name": "torch.Tensor.dim", "parameters": []}},
{"code": "torch.Tensor.dist(other,p=2)", "id": "torch.Tensor.dist", "summary": "See torch.dist()\n", "description": "", "code-info": {"name": "torch.Tensor.dist", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": ""}]}},
{"code": "torch.empty(*size,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False,pin_memory=False)", "id": "torch.empty", "summary": "Returns a tensor filled with uninitialized data", "description": "", "code-info": {"name": "torch.empty", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type())."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}, {"name": "pin_memory", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If set, returned tensor would be allocated in\nthe pinned memory. Works only for CPU tensors. Default: False."}]}},
{"code": "torch.empty_like(input,dtype=None,layout=None,device=None,requires_grad=False)", "id": "torch.empty_like", "summary": "Returns an uninitialized tensor with the same size as input.\ntorch.empty_like(input) is equivalent to\ntorch.empty(input.size(), dtype=input.dtype, layout=input.layout, device=input.device).\n\nParameters\n\ninput (Tensor) \u2013 the size of input will determine size of the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: if None, defaults to the dtype of input.\nlayout (torch.layout, optional) \u2013 the desired layout of returned tensor.\nDefault: if None, defaults to the layout of input.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, defaults to the device of input.\nrequires_grad (bool, optional) \u2013 If autograd should record operations on the\nreturned tensor", "description": "", "code-info": {"name": "torch.empty_like", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the size of input will determine size of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: if None, defaults to the dtype of input."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.layout, optional) \u2013 the desired layout of returned tensor.\nDefault: if None, defaults to the layout of input."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, defaults to the device of input."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.empty_strided(size,stride,dtype=None,layout=None,device=None,requires_grad=False,pin_memory=False)", "id": "torch.empty_strided", "summary": "Returns a tensor filled with uninitialized data", "description": "", "code-info": {"name": "torch.empty_strided", "parameters": [{"name": "size", "is_optional": false, "type": "int", "description": "(tuple of python:ints) \u2013 the shape of the output tensor"}, {"name": "stride", "is_optional": false, "type": "int", "description": "(tuple of python:ints) \u2013 the strides of the output tensor"}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type())."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}, {"name": "pin_memory", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If set, returned tensor would be allocated in\nthe pinned memory. Works only for CPU tensors. Default: False."}]}},
{"code": "torch.full(size,fill_value,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.full", "summary": "Returns a tensor of size size filled with fill_value.\n\nParameters\n\nsize (python:int...) \u2013 a list, tuple, or torch.Size of integers defining the\nshape of the output tensor.\nfill_value \u2013 the number to fill the output tensor with.\nout (Tensor, optional) \u2013 the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()).\nlayout (torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type())", "description": "", "code-info": {"name": "torch.full", "parameters": [{"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "fill_value", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type())."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.full_like(input,fill_value,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.full_like", "summary": "Returns a tensor with the same size as input filled with fill_value.\ntorch.full_like(input, fill_value) is equivalent to\ntorch.full(input.size(), fill_value, dtype=input.dtype, layout=input.layout, device=input.device).\n\nParameters\n\ninput (Tensor) \u2013 the size of input will determine size of the output tensor.\nfill_value \u2013 the number to fill the output tensor with.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: if None, defaults to the dtype of input.\nlayout (torch.layout, optional) \u2013 the desired layout of returned tensor.\nDefault: if None, defaults to the layout of input.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, defaults to the device of input.\nrequires_grad (bool, optional) \u2013 If autograd should record operations on the\nreturned tensor", "description": "", "code-info": {"name": "torch.full_like", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "fill_value", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: if None, defaults to the dtype of input."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned tensor.\nDefault: if None, defaults to the layout of input."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, defaults to the device of input."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.quantize_per_tensor(input,scale,zero_point,dtype)", "id": "torch.quantize_per_tensor", "summary": "Converts a float tensor to quantized tensor with given scale and zero point.\n\nParameters\n\ninput (Tensor) \u2013 float tensor to quantize\nscale (python:float) \u2013 scale to apply in quantization formula\nzero_point (python:int) \u2013 offset in integer value that maps to float zero\ndtype (torch.dtype) \u2013 the desired data type of returned tensor.\nHas to be one of the quantized dtypes: torch.quint8, torch.qint8, torch.qint32\n\n\nReturns\nA newly quantized tensor\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8)\ntensor([-1.,  0.,  1.,  2.], size=(4,), dtype=torch.quint8,\n       quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10)\n&gt;&gt;&gt; torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8).int_repr()\ntensor([ 0, 10, 20, 30], dtype=torch.uint8)\n\n\n", "description": "", "code-info": {"name": "torch.quantize_per_tensor", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 float tensor to quantize"}, {"name": "scale", "is_optional": false, "type": "float", "description": "(python:float) \u2013 scale to apply in quantization formula"}, {"name": "zero_point", "is_optional": false, "type": "int", "description": "(python:int) \u2013 offset in integer value that maps to float zero"}, {"name": "dtype", "is_optional": false, "type": "others", "description": "(torch.dtype) \u2013 the desired data type of returned tensor.\nHas to be one of the quantized dtypes: torch.quint8, torch.qint8, torch.qint32"}]}},
{"code": "torch.quantize_per_channel(input,scales,zero_points,axis,dtype)", "id": "torch.quantize_per_channel", "summary": "Converts a float tensor to per-channel quantized tensor with given scales and zero points.\n\nParameters\n\ninput (Tensor) \u2013 float tensor to quantize\nscales (Tensor) \u2013 float 1D tensor of scales to use, size should match input.size(axis)\nzero_points (python:int) \u2013 integer 1D tensor of offset to use, size should match input.size(axis)\naxis (python:int) \u2013 dimension on which apply per-channel quantization\ndtype (torch.dtype) \u2013 the desired data type of returned tensor.\nHas to be one of the quantized dtypes: torch.quint8, torch.qint8, torch.qint32\n\n\nReturns\nA newly quantized tensor\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; x = torch.tensor([[-1.0, 0.0], [1.0, 2.0]])\n&gt;&gt;&gt; torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8)\ntensor([[-1.,  0.],\n        [ 1.,  2.]], size=(2, 2), dtype=torch.quint8,\n       quantization_scheme=torch.per_channel_affine,\n       scale=tensor([0.1000, 0.0100], dtype=torch.float64),\n       zero_point=tensor([10,  0]), axis=0)\n&gt;&gt;&gt; torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8).int_repr()\ntensor([[  0,  10],\n        [100, 200]], dtype=torch.uint8)\n\n\n", "description": "", "code-info": {"name": "torch.quantize_per_channel", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 float tensor to quantize"}, {"name": "scales", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 float 1D tensor of scales to use, size should match input.size(axis)"}, {"name": "zero_points", "is_optional": false, "type": "int", "description": "(python:int) \u2013 integer 1D tensor of offset to use, size should match input.size(axis)"}, {"name": "axis", "is_optional": false, "type": "int", "description": "(python:int) \u2013 dimension on which apply per-channel quantization"}, {"name": "dtype", "is_optional": false, "type": "others", "description": "(torch.dtype) \u2013 the desired data type of returned tensor.\nHas to be one of the quantized dtypes: torch.quint8, torch.qint8, torch.qint32"}]}},
{"code": "torch.cat(tensors,dim=0,out=None)", "id": "torch.cat", "summary": "Concatenates the given sequence of seq tensors in the given dimension.\nAll tensors must either have the same shape (except in the concatenating\ndimension) or be empty.\ntorch.cat() can be seen as an inverse operation for torch.split()\nand torch.chunk().\ntorch.cat() can be best understood via examples.\n\nParameters\n\ntensors (sequence of Tensors) \u2013 any python sequence of tensors of the same type.\nNon-empty tensors provided must have the same shape, except in the\ncat dimension.\ndim (python:int, optional) \u2013 the dimension over which the tensors are concatenated\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; x = torch.randn(2, 3)\n&gt;&gt;&gt; x\ntensor([[ 0.6580, -1.0969, -0.4614],\n        [-0.1034, -0.5790,  0.1497]])\n&gt;&gt;&gt; torch.cat((x, x, x), 0)\ntensor([[ 0.6580, -1.0969, -0.4614],\n        [-0.1034, -0.5790,  0.1497],\n        [ 0.6580, -1.0969, -0.4614],\n        [-0.1034, -0.5790,  0.1497],\n        [ 0.6580, -1.0969, -0.4614],\n        [-0.1034, -0.5790,  0.1497]])\n&gt;&gt;&gt; torch.cat((x, x, x), 1)\ntensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,\n         -1.0969, -0.4614],\n        [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,\n         -0.5790,  0.1497]])\n\n\n", "description": "", "code-info": {"name": "torch.cat", "parameters": [{"name": "tensors", "is_optional": false, "type": "tensor", "description": "(sequence of Tensors) \u2013 any python sequence of tensors of the same type.\nNon-empty tensors provided must have the same shape, except in the\ncat dimension."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 the dimension over which the tensors are concatenated"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.chunk(input,chunks,dim=0)", "id": "torch.chunk", "summary": "Splits a tensor into a specific number of chunks.\nLast chunk will be smaller if the tensor size along the given dimension\ndim is not divisible by chunks.\n\nParameters\n\ninput (Tensor) \u2013 the tensor to split\nchunks (python:int) \u2013 number of chunks to return\ndim (python:int) \u2013 dimension along which to split the tensor\n\n\n\n", "description": "", "code-info": {"name": "torch.chunk", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to split"}, {"name": "chunks", "is_optional": false, "type": "int", "description": "(python:int) \u2013 number of chunks to return"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 dimension along which to split the tensor"}]}},
{"code": "torch.gather(input,dim,index,out=None,sparse_grad=False)", "id": "torch.gather", "summary": "Gathers values along an axis specified by dim.\nFor a 3-D tensor the output is specified by:\nout[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\nout[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\nout[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n\n\nIf input is an n-dimensional tensor with size\n(x0,x1...,xi\u22121,xi,xi+1,...,xn\u22121)(x_0, x_1..., x_{i-1}, x_i, x_{i+1}, ..., x_{n-1})(x0\u200b,x1\u200b...,xi\u22121\u200b,xi\u200b,xi+1\u200b,...,xn\u22121\u200b)\n\n\nand dim = i, then index must be an nnn\n\n-dimensional tensor with\nsize (x0,x1,...,xi\u22121,y,xi+1,...,xn\u22121)(x_0, x_1, ..., x_{i-1}, y, x_{i+1}, ..., x_{n-1})(x0\u200b,x1\u200b,...,xi\u22121\u200b,y,xi+1\u200b,...,xn\u22121\u200b)\n\n where y\u22651y \\geq 1y\u22651\n\n\nand out will have the same size as index.\n\nParameters\n\ninput (Tensor) \u2013 the source tensor\ndim (python:int) \u2013 the axis along which to index\nindex (LongTensor) \u2013 the indices of elements to gather\nout (Tensor, optional) \u2013 the destination tensor\nsparse_grad (bool,optional) \u2013 If True, gradient w.r.t", "description": "", "code-info": {"name": "torch.gather", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the source tensor"}, {"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the axis along which to index"}, {"name": "index", "is_optional": false, "type": "tensor", "description": "(LongTensor) \u2013 the indices of elements to gather"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the destination tensor"}, {"name": "sparse_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool,optional) \u2013 If True, gradient w.r.t. input will be a sparse tensor."}]}},
{"code": "torch.index_select(input,dim,index,out=None)", "id": "torch.index_select", "summary": "Returns a new tensor which indexes the input tensor along dimension\ndim using the entries in index which is a LongTensor.\nThe returned tensor has the same number of dimensions as the original tensor\n(input)", "description": "", "code-info": {"name": "torch.index_select", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the dimension in which we index"}, {"name": "index", "is_optional": false, "type": "tensor", "description": "(LongTensor) \u2013 the 1-D tensor containing the indices to index"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.nn.functional.local_response_norm(input,size,alpha=0.0001,beta=0.75,k=1.0)", "id": "torch.nn.functional.local_response_norm", "summary": "Applies local response normalization over an input signal composed of\nseveral input planes, where channels occupy the second dimension.\nApplies normalization across channels.\nSee LocalResponseNorm for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.local_response_norm", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "alpha", "is_optional": true, "type": "others", "default_value": "0.0001", "description": ""}, {"name": "beta", "is_optional": true, "type": "others", "default_value": "0.75", "description": ""}, {"name": "k", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}]}},
{"code": "torch.nn.functional.normalize(input,p=2,dim=1,eps=1e-12,out=None)", "id": "torch.nn.functional.normalize", "summary": "Performs LpL_pLp\u200b\n\n normalization of inputs over specified dimension.\nFor a tensor input of sizes (n0,...,ndim,...,nk)(n_0, ..., n_{dim}, ..., n_k)(n0\u200b,...,ndim\u200b,...,nk\u200b)\n\n, each\nndimn_{dim}ndim\u200b\n\n -element vector vvv\n\n along dimension dim is transformed as\n\nv=vmax\u2061(\u2225v\u2225p,\u03f5).v = \\frac{v}{\\max(\\lVert v \\rVert_p, \\epsilon)}.\n\nv=max(\u2225v\u2225p\u200b,\u03f5)v\u200b.\n\nWith the default arguments it uses the Euclidean norm over vectors along dimension 111\n\n for normalization.\n\nParameters\n\ninput \u2013 input tensor of any shape\np (python:float) \u2013 the exponent value in the norm formulation", "description": "", "code-info": {"name": "torch.nn.functional.normalize", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": "(python:float) \u2013 the exponent value in the norm formulation. Default: 2"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int) \u2013 the dimension to reduce. Default: 1"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-12", "description": "(python:float) \u2013 small value to avoid division by zero. Default: 1e-12"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor. If out is used, this\noperation won\u2019t be differentiable."}]}},
{"code": "torch.nn.functional.linear(input,weight,bias=None)", "id": "torch.nn.functional.linear", "summary": "Applies a linear transformation to the incoming data: y=xAT+by = xA^T + by=xAT+b\n\n.\nShape:\n\n\nInput: (N,\u2217,in_features)(N, *, in\\_features)(N,\u2217,in_features)\n\n where * means any number of\nadditional dimensions\nWeight: (out_features,in_features)(out\\_features, in\\_features)(out_features,in_features)\n\n\nBias: (out_features)(out\\_features)(out_features)\n\n\nOutput: (N,\u2217,out_features)(N, *, out\\_features)(N,\u2217,out_features)\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.functional.linear", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.functional.bilinear(input1,input2,weight,bias=None)", "id": "torch.nn.functional.bilinear", "summary": "Applies a bilinear transformation to the incoming data:\ny=x1Ax2+by = x_1 A x_2 + by=x1\u200bAx2\u200b+b\n\n\nShape:\n\n\ninput1: (N,\u2217,Hin1)(N, *, H_{in1})(N,\u2217,Hin1\u200b)\n\n where Hin1=in1_featuresH_{in1}=\\text{in1\\_features}Hin1\u200b=in1_features\n\n\nand \u2217*\u2217\n\n means any number of additional dimensions.\nAll but the last dimension of the inputs should be the same.\ninput2: (N,\u2217,Hin2)(N, *, H_{in2})(N,\u2217,Hin2\u200b)\n\n where Hin2=in2_featuresH_{in2}=\\text{in2\\_features}Hin2\u200b=in2_features\n\n\nweight: (out_features,in1_features,in2_features)(\\text{out\\_features}, \\text{in1\\_features},\n\\text{in2\\_features})(out_features,in1_features,in2_features)\n\n\nbias: (out_features)(\\text{out\\_features})(out_features)\n\n\noutput: (N,\u2217,Hout)(N, *, H_{out})(N,\u2217,Hout\u200b)\n\n where Hout=out_featuresH_{out}=\\text{out\\_features}Hout\u200b=out_features\n\n\nand all but the last dimension are the same shape as the input.\n\n\n", "description": "", "code-info": {"name": "torch.nn.functional.bilinear", "parameters": [{"name": "input1", "is_optional": false, "type": "others", "description": ""}, {"name": "input2", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.functional.dropout(input,p=0.5,training=True,inplace=False)", "id": "torch.nn.functional.dropout", "summary": "During training, randomly zeroes some of the elements of the input\ntensor with probability p using samples from a Bernoulli\ndistribution.\nSee Dropout for details.\n\nParameters\n\np \u2013 probability of an element to be zeroed", "description": "", "code-info": {"name": "torch.nn.functional.dropout", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.alpha_dropout(input,p=0.5,training=False,inplace=False)", "id": "torch.nn.functional.alpha_dropout", "summary": "Applies alpha dropout to the input.\nSee AlphaDropout for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.alpha_dropout", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.dropout2d(input,p=0.5,training=True,inplace=False)", "id": "torch.nn.functional.dropout2d", "summary": "Randomly zero out entire channels (a channel is a 2D feature map,\ne.g., the jjj\n\n-th channel of the iii\n\n-th sample in the\nbatched input is a 2D tensor input[i,j]\\text{input}[i, j]input[i,j]\n\n) of the input tensor).\nEach channel will be zeroed out independently on every forward call with\nprobability p using samples from a Bernoulli distribution.\nSee Dropout2d for details.\n\nParameters\n\np \u2013 probability of a channel to be zeroed", "description": "", "code-info": {"name": "torch.nn.functional.dropout2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.dropout3d(input,p=0.5,training=True,inplace=False)", "id": "torch.nn.functional.dropout3d", "summary": "Randomly zero out entire channels (a channel is a 3D feature map,\ne.g., the jjj\n\n-th channel of the iii\n\n-th sample in the\nbatched input is a 3D tensor input[i,j]\\text{input}[i, j]input[i,j]\n\n) of the input tensor).\nEach channel will be zeroed out independently on every forward call with\nprobability p using samples from a Bernoulli distribution.\nSee Dropout3d for details.\n\nParameters\n\np \u2013 probability of a channel to be zeroed", "description": "", "code-info": {"name": "torch.nn.functional.dropout3d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.embedding(input,weight,padding_idx=None,max_norm=None,norm_type=2.0,scale_grad_by_freq=False,sparse=False)", "id": "torch.nn.functional.embedding", "summary": "A simple lookup table that looks up embeddings in a fixed dictionary and size.\nThis module is often used to retrieve word embeddings using indices.\nThe input to the module is a list of indices, and the embedding matrix,\nand the output is the corresponding word embeddings.\nSee torch.nn.Embedding for more details.\n\nParameters\n\ninput (LongTensor) \u2013 Tensor containing indices into the embedding matrix\nweight (Tensor) \u2013 The embedding matrix with number of rows equal to the maximum possible index + 1,\nand number of columns equal to the embedding size\npadding_idx (python:int, optional) \u2013 If given, pads the output with the embedding vector at padding_idx\n(initialized to zeros) whenever it encounters the index.\nmax_norm (python:float, optional) \u2013 If given, each embedding vector with norm larger than max_norm\nis renormalized to have norm max_norm.\nNote: this will modify weight in-place.\nnorm_type (python:float, optional) \u2013 The p of the p-norm to compute for the max_norm option", "description": "", "code-info": {"name": "torch.nn.functional.embedding", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(LongTensor) \u2013 Tensor containing indices into the embedding matrix"}, {"name": "weight", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 The embedding matrix with number of rows equal to the maximum possible index + 1,\nand number of columns equal to the embedding size"}, {"name": "padding_idx", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 If given, pads the output with the embedding vector at padding_idx\n(initialized to zeros) whenever it encounters the index."}, {"name": "max_norm", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float, optional) \u2013 If given, each embedding vector with norm larger than max_norm\nis renormalized to have norm max_norm.\nNote: this will modify weight in-place."}, {"name": "norm_type", "is_optional": true, "type": "float", "default_value": "2.0", "description": "(python:float, optional) \u2013 The p of the p-norm to compute for the max_norm option. Default 2."}, {"name": "scale_grad_by_freq", "is_optional": true, "type": "bool", "default_value": "False", "description": "(boolean, optional) \u2013 If given, this will scale gradients by the inverse of frequency of\nthe words in the mini-batch. Default False."}, {"name": "sparse", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If True, gradient w.r.t. weight will be a sparse tensor. See Notes under\ntorch.nn.Embedding for more details regarding sparse gradients."}]}},
{"code": "torch.nn.functional.embedding_bag(input,weight,offsets=None,max_norm=None,norm_type=2,scale_grad_by_freq=False,mode='mean',sparse=False,per_sample_weights=None)", "id": "torch.nn.functional.embedding_bag", "summary": "Computes sums, means or maxes of bags of embeddings, without instantiating the\nintermediate embeddings.\nSee torch.nn.EmbeddingBag for more details.\n\nNote\nWhen using the CUDA backend, this operation may induce nondeterministic\nbehaviour in its backward pass that is not easily switched off.\nPlease see the notes on Reproducibility for background.\n\n\nParameters\n\ninput (LongTensor) \u2013 Tensor containing bags of indices into the embedding matrix\nweight (Tensor) \u2013 The embedding matrix with number of rows equal to the maximum possible index + 1,\nand number of columns equal to the embedding size\noffsets (LongTensor, optional) \u2013 Only used when input is 1D", "description": "", "code-info": {"name": "torch.nn.functional.embedding_bag", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(LongTensor) \u2013 Tensor containing bags of indices into the embedding matrix"}, {"name": "weight", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 The embedding matrix with number of rows equal to the maximum possible index + 1,\nand number of columns equal to the embedding size"}, {"name": "offsets", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(LongTensor, optional) \u2013 Only used when input is 1D. offsets determines\nthe starting index position of each bag (sequence) in input."}, {"name": "max_norm", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float, optional) \u2013 If given, each embedding vector with norm larger than max_norm\nis renormalized to have norm max_norm.\nNote: this will modify weight in-place."}, {"name": "norm_type", "is_optional": true, "type": "int", "default_value": "2", "description": "(python:float, optional) \u2013 The p in the p-norm to compute for the max_norm option.\nDefault 2."}, {"name": "scale_grad_by_freq", "is_optional": true, "type": "bool", "default_value": "False", "description": "(boolean, optional) \u2013 if given, this will scale gradients by the inverse of frequency of\nthe words in the mini-batch. Default False.\nNote: this option is not supported when mode=\"max\"."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 \"sum\", \"mean\" or \"max\". Specifies the way to reduce the bag.\nDefault: \"mean\""}, {"name": "sparse", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 if True, gradient w.r.t. weight will be a sparse tensor. See Notes under\ntorch.nn.Embedding for more details regarding sparse gradients.\nNote: this option is not supported when mode=\"max\"."}, {"name": "per_sample_weights", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a tensor of float / double weights, or None\nto indicate all weights should be taken to be 1. If specified, per_sample_weights\nmust have exactly the same shape as input and is treated as having the same\noffsets, if those are not None."}]}},
{"code": "torch.distributions.laplace.Laplace.log_prob(value)", "id": "torch.distributions.laplace.Laplace.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.laplace.Laplace.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.laplace.Laplace.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.laplace.Laplace.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.laplace.Laplace.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.log_normal.LogNormal.entropy()", "id": "torch.distributions.log_normal.LogNormal.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.log_normal.LogNormal.entropy", "parameters": []}},
{"code": "torch.distributions.log_normal.LogNormal.expand(batch_shape,_instance=None)", "id": "torch.distributions.log_normal.LogNormal.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.log_normal.LogNormal.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.entropy()", "id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.entropy", "parameters": []}},
{"code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.expand(batch_shape,_instance=None)", "id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.log_prob(value)", "id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.multinomial.Multinomial.expand(batch_shape,_instance=None)", "id": "torch.distributions.multinomial.Multinomial.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.multinomial.Multinomial.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.multinomial.Multinomial.log_prob(value)", "id": "torch.distributions.multinomial.Multinomial.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.multinomial.Multinomial.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.multinomial.Multinomial.sample(sample_shape=torch.Size([])", "id": "torch.distributions.multinomial.Multinomial.sample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.multinomial.Multinomial.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.nn.utils.prune.is_pruned(module)", "id": "torch.nn.utils.prune.is_pruned", "summary": "Check whether module is pruned by looking for\nforward_pre_hooks in its modules that inherit from the\nBasePruningMethod.\n\nParameters\nmodule (nn.Module) \u2013 object that is either pruned or unpruned\n\nReturns\nbinary answer to whether module is pruned.\n\n\nExamples\n&gt;&gt;&gt; m = nn.Linear(5, 7)\n&gt;&gt;&gt; print(prune.is_pruned(m))\nFalse\n&gt;&gt;&gt; prune.random_pruning(m, name='weight', amount=0.2)\n&gt;&gt;&gt; print(prune.is_pruned(m))\nTrue\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.is_pruned", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 object that is either pruned or unpruned"}]}},
{"code": "torch.nn.utils.weight_norm(module,name='weight',dim=0)", "id": "torch.nn.utils.weight_norm", "summary": "Applies weight normalization to a parameter in the given module.\n\nw=gv\u2225v\u2225\\mathbf{w} = g \\dfrac{\\mathbf{v}}{\\|\\mathbf{v}\\|}\n\nw=g\u2225v\u2225v\u200b\n\nWeight normalization is a reparameterization that decouples the magnitude\nof a weight tensor from its direction", "description": "", "code-info": {"name": "torch.nn.utils.weight_norm", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(Module) \u2013 containing module"}, {"name": "name", "is_optional": true, "type": "string", "default_value": "'weight'", "description": "(str, optional) \u2013 name of weight parameter"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 dimension over which to compute the norm"}]}},
{"code": "torch.nn.utils.remove_weight_norm(module,name='weight')", "id": "torch.nn.utils.remove_weight_norm", "summary": "Removes the weight normalization reparameterization from a module.\n\nParameters\n\nmodule (Module) \u2013 containing module\nname (str, optional) \u2013 name of weight parameter\n\n\n\nExample\n&gt;&gt;&gt; m = weight_norm(nn.Linear(20, 40))\n&gt;&gt;&gt; remove_weight_norm(m)\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.remove_weight_norm", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(Module) \u2013 containing module"}, {"name": "name", "is_optional": true, "type": "string", "default_value": "'weight'", "description": "(str, optional) \u2013 name of weight parameter"}]}},
{"code": "torch.nn.utils.spectral_norm(module,name='weight',n_power_iterations=1,eps=1e-12,dim=None)", "id": "torch.nn.utils.spectral_norm", "summary": "Applies spectral normalization to a parameter in the given module.\n\nWSN=W\u03c3(W),\u03c3(W)=max\u2061h:h\u22600\u2225Wh\u22252\u2225h\u22252\\mathbf{W}_{SN} = \\dfrac{\\mathbf{W}}{\\sigma(\\mathbf{W})},\n\\sigma(\\mathbf{W}) = \\max_{\\mathbf{h}: \\mathbf{h} \\ne 0} \\dfrac{\\|\\mathbf{W} \\mathbf{h}\\|_2}{\\|\\mathbf{h}\\|_2}\n\nWSN\u200b=\u03c3(W)W\u200b,\u03c3(W)=h:h\ue020\u200b=0max\u200b\u2225h\u22252\u200b\u2225Wh\u22252\u200b\u200b\n\nSpectral normalization stabilizes the training of discriminators (critics)\nin Generative Adversarial Networks (GANs) by rescaling the weight tensor\nwith spectral norm \u03c3\\sigma\u03c3\n\n of the weight matrix calculated using\npower iteration method", "description": "", "code-info": {"name": "torch.nn.utils.spectral_norm", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 containing module"}, {"name": "name", "is_optional": true, "type": "string", "default_value": "'weight'", "description": "(str, optional) \u2013 name of weight parameter"}, {"name": "n_power_iterations", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 number of power iterations to\ncalculate spectral norm"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-12", "description": "(python:float, optional) \u2013 epsilon for numerical stability in\ncalculating norms"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 dimension corresponding to number of outputs,\nthe default is 0, except for modules that are instances of\nConvTranspose{1,2,3}d, when it is 1"}]}},
{"code": "torch.nn.utils.remove_spectral_norm(module,name='weight')", "id": "torch.nn.utils.remove_spectral_norm", "summary": "Removes the spectral normalization reparameterization from a module.\n\nParameters\n\nmodule (Module) \u2013 containing module\nname (str, optional) \u2013 name of weight parameter\n\n\n\nExample\n&gt;&gt;&gt; m = spectral_norm(nn.Linear(40, 10))\n&gt;&gt;&gt; remove_spectral_norm(m)\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.remove_spectral_norm", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(Module) \u2013 containing module"}, {"name": "name", "is_optional": true, "type": "string", "default_value": "'weight'", "description": "(str, optional) \u2013 name of weight parameter"}]}},
{"code": "torch.nn.utils.rnn.PackedSequence(data,batch_sizes=None,sorted_indices=None,unsorted_indices=None)", "id": "torch.nn.utils.rnn.PackedSequence", "summary": "Holds the data and list of batch_sizes of a packed sequence.\nAll RNN modules accept packed sequences as inputs.\n\nNote\nInstances of this class should never be created manually", "description": "", "code-info": {"name": "torch.nn.utils.rnn.PackedSequence", "parameters": [{"name": "data", "is_optional": false, "type": "others", "description": ""}, {"name": "batch_sizes", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "sorted_indices", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "unsorted_indices", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.utils.rnn.pack_padded_sequence(input,lengths,batch_first=False,enforce_sorted=True)", "id": "torch.nn.utils.rnn.pack_padded_sequence", "summary": "Packs a Tensor containing padded sequences of variable length.\ninput can be of size T x B x * where T is the length of the\nlongest sequence (equal to lengths[0]), B is the batch size, and\n* is any number of dimensions (including 0)", "description": "", "code-info": {"name": "torch.nn.utils.rnn.pack_padded_sequence", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 padded batch of variable length sequences."}, {"name": "lengths", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 list of sequences lengths of each batch element."}, {"name": "batch_first", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 if True, the input is expected in B x T x *\nformat."}, {"name": "enforce_sorted", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 if True, the input is expected to\ncontain sequences sorted by length in a decreasing order. If\nFalse, this condition is not checked. Default: True."}]}},
{"code": "torch.nn.utils.rnn.pad_packed_sequence(sequence,batch_first=False,padding_value=0.0,total_length=None)", "id": "torch.nn.utils.rnn.pad_packed_sequence", "summary": "Pads a packed batch of variable length sequences.\nIt is an inverse operation to pack_padded_sequence().\nThe returned Tensor\u2019s data will be of size T x B x *, where T is the length\nof the longest sequence and B is the batch size", "description": "", "code-info": {"name": "torch.nn.utils.rnn.pad_packed_sequence", "parameters": [{"name": "sequence", "is_optional": false, "type": "others", "description": "(PackedSequence) \u2013 batch to pad"}, {"name": "batch_first", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 if True, the output will be in B x T x *\nformat."}, {"name": "padding_value", "is_optional": true, "type": "float", "default_value": "0.0", "description": "(python:float, optional) \u2013 values for padded elements."}, {"name": "total_length", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 if not None, the output will be padded to\nhave length total_length. This method will throw ValueError\nif total_length is less than the max sequence length in\nsequence."}]}},
{"code": "torch.nn.utils.rnn.pad_sequence(sequences,batch_first=False,padding_value=0)", "id": "torch.nn.utils.rnn.pad_sequence", "summary": "Pad a list of variable length Tensors with padding_value\npad_sequence stacks a list of Tensors along a new dimension,\nand pads them to equal length", "description": "", "code-info": {"name": "torch.nn.utils.rnn.pad_sequence", "parameters": [{"name": "sequences", "is_optional": false, "type": "tensor", "description": "(list[Tensor]) \u2013 list of variable length sequences."}, {"name": "batch_first", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 output will be in B x T x * if True, or in\nT x B x * otherwise"}, {"name": "padding_value", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:float, optional) \u2013 value for padded elements. Default: 0."}]}},
{"code": "torch.nn.utils.rnn.pack_sequence(sequences,enforce_sorted=True)", "id": "torch.nn.utils.rnn.pack_sequence", "summary": "Packs a list of variable length Tensors\nsequences should be a list of Tensors of size L x *, where L is\nthe length of a sequence and * is any number of trailing dimensions,\nincluding zero.\nFor unsorted sequences, use enforce_sorted = False", "description": "", "code-info": {"name": "torch.nn.utils.rnn.pack_sequence", "parameters": [{"name": "sequences", "is_optional": false, "type": "tensor", "description": "(list[Tensor]) \u2013 A list of sequences of decreasing length."}, {"name": "enforce_sorted", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 if True, checks that the input\ncontains sequences sorted by length in a decreasing order. If\nFalse, this condition is not checked. Default: True."}]}},
{"code": "torch.nn.Module.add_module(name,module)", "id": "torch.nn.Module.add_module", "summary": "Adds a child module to the current module.\nThe module can be accessed as an attribute using the given name.\n\nParameters\n\nname (string) \u2013 name of the child module", "description": "", "code-info": {"name": "torch.nn.Module.add_module", "parameters": [{"name": "name", "is_optional": false, "type": "string", "description": "(string) \u2013 name of the child module. The child module can be\naccessed from this module using the given name"}, {"name": "module", "is_optional": false, "type": "others", "description": "(Module) \u2013 child module to be added to the module."}]}},
{"code": "torch.Tensor.div(value)", "id": "torch.Tensor.div", "summary": "See torch.div()\n", "description": "", "code-info": {"name": "torch.Tensor.div", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.div_(value)", "id": "torch.Tensor.div_", "summary": "In-place version of div()\n", "description": "", "code-info": {"name": "torch.Tensor.div_", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.dot(tensor2)", "id": "torch.Tensor.dot", "summary": "See torch.dot()\n", "description": "", "code-info": {"name": "torch.Tensor.dot", "parameters": [{"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.double()", "id": "torch.Tensor.double", "summary": "self.double() is equivalent to self.to(torch.float64)", "description": "", "code-info": {"name": "torch.Tensor.double", "parameters": []}},
{"code": "torch.Tensor.eig(eigenvectors=False)", "id": "torch.Tensor.eig", "summary": "See torch.eig()\n", "description": "", "code-info": {"name": "torch.Tensor.eig", "parameters": [{"name": "eigenvectors", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.element_size()", "id": "torch.Tensor.element_size", "summary": "Returns the size in bytes of an individual element.\nExample:\n&gt;&gt;&gt; torch.tensor([]).element_size()\n4\n&gt;&gt;&gt; torch.tensor([], dtype=torch.uint8).element_size()\n1\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.element_size", "parameters": []}},
{"code": "torch.Tensor.eq(other)", "id": "torch.Tensor.eq", "summary": "See torch.eq()\n", "description": "", "code-info": {"name": "torch.Tensor.eq", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.eq_(other)", "id": "torch.Tensor.eq_", "summary": "In-place version of eq()\n", "description": "", "code-info": {"name": "torch.Tensor.eq_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.equal(other)", "id": "torch.Tensor.equal", "summary": "See torch.equal()\n", "description": "", "code-info": {"name": "torch.Tensor.equal", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.erf()", "id": "torch.Tensor.erf", "summary": "See torch.erf()\n", "description": "", "code-info": {"name": "torch.Tensor.erf", "parameters": []}},
{"code": "torch.Tensor.erf_()", "id": "torch.Tensor.erf_", "summary": "In-place version of erf()\n", "description": "", "code-info": {"name": "torch.Tensor.erf_", "parameters": []}},
{"code": "torch.Tensor.erfc()", "id": "torch.Tensor.erfc", "summary": "See torch.erfc()\n", "description": "", "code-info": {"name": "torch.Tensor.erfc", "parameters": []}},
{"code": "torch.Tensor.erfc_()", "id": "torch.Tensor.erfc_", "summary": "In-place version of erfc()\n", "description": "", "code-info": {"name": "torch.Tensor.erfc_", "parameters": []}},
{"code": "torch.Tensor.erfinv()", "id": "torch.Tensor.erfinv", "summary": "See torch.erfinv()\n", "description": "", "code-info": {"name": "torch.Tensor.erfinv", "parameters": []}},
{"code": "torch.Tensor.erfinv_()", "id": "torch.Tensor.erfinv_", "summary": "In-place version of erfinv()\n", "description": "", "code-info": {"name": "torch.Tensor.erfinv_", "parameters": []}},
{"code": "torch.Tensor.exp()", "id": "torch.Tensor.exp", "summary": "See torch.exp()\n", "description": "", "code-info": {"name": "torch.Tensor.exp", "parameters": []}},
{"code": "torch.Tensor.exp_()", "id": "torch.Tensor.exp_", "summary": "In-place version of exp()\n", "description": "", "code-info": {"name": "torch.Tensor.exp_", "parameters": []}},
{"code": "torch.Tensor.expm1()", "id": "torch.Tensor.expm1", "summary": "See torch.expm1()\n", "description": "", "code-info": {"name": "torch.Tensor.expm1", "parameters": []}},
{"code": "torch.Tensor.expm1_()", "id": "torch.Tensor.expm1_", "summary": "In-place version of expm1()\n", "description": "", "code-info": {"name": "torch.Tensor.expm1_", "parameters": []}},
{"code": "torch.Tensor.expand(*sizes)", "id": "torch.Tensor.expand", "summary": "Returns a new view of the self tensor with singleton dimensions expanded\nto a larger size.\nPassing -1 as the size for a dimension means not changing the size of\nthat dimension.\nTensor can be also expanded to a larger number of dimensions, and the\nnew ones will be appended at the front", "description": "", "code-info": {"name": "torch.Tensor.expand", "parameters": [{"name": "*sizes", "is_optional": false, "type": "int", "description": "(torch.Size or python:int...) \u2013 the desired expanded size"}]}},
{"code": "torch.Tensor.expand_as(other)", "id": "torch.Tensor.expand_as", "summary": "Expand this tensor to the same size as other.\nself.expand_as(other) is equivalent to self.expand(other.size()).\nPlease see expand() for more information about expand.\n\nParameters\nother (torch.Tensor) \u2013 The result tensor has the same size\nas other.\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.expand_as", "parameters": [{"name": "other", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 The result tensor has the same size\nas other."}]}},
{"code": "torch.Tensor.exponential_(lambd=1,*,generator=None)", "id": "torch.Tensor.exponential_", "summary": "Fills self tensor with elements drawn from the exponential distribution:\n\nf(x)=\u03bbe\u2212\u03bbxf(x) = \\lambda e^{-\\lambda x}f(x)=\u03bbe\u2212\u03bbx\n\n", "description": "", "code-info": {"name": "torch.Tensor.exponential_", "parameters": [{"name": "lambd", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.masked_select(input,mask,out=None)", "id": "torch.masked_select", "summary": "Returns a new 1-D tensor which indexes the input tensor according to\nthe boolean mask mask which is a BoolTensor.\nThe shapes of the mask tensor and the input tensor don\u2019t need\nto match, but they must be broadcastable.\n\nNote\nThe returned tensor does not use the same storage\nas the original tensor\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nmask (ByteTensor) \u2013 the tensor containing the binary mask to index with\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; x = torch.randn(3, 4)\n&gt;&gt;&gt; x\ntensor([[ 0.3552, -2.3825, -0.8297,  0.3477],\n        [-1.2035,  1.2252,  0.5002,  0.6248],\n        [ 0.1307, -2.0608,  0.1244,  2.0139]])\n&gt;&gt;&gt; mask = x.ge(0.5)\n&gt;&gt;&gt; mask\ntensor([[False, False, False, False],\n        [False, True, True, True],\n        [False, False, False, True]])\n&gt;&gt;&gt; torch.masked_select(x, mask)\ntensor([ 1.2252,  0.5002,  0.6248,  2.0139])\n\n\n", "description": "", "code-info": {"name": "torch.masked_select", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "mask", "is_optional": false, "type": "tensor", "description": "(ByteTensor) \u2013 the tensor containing the binary mask to index with"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.narrow(input,dim,start,length)", "id": "torch.narrow", "summary": "Returns a new tensor that is a narrowed version of input tensor", "description": "", "code-info": {"name": "torch.narrow", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to narrow"}, {"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the dimension along which to narrow"}, {"name": "start", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the starting dimension"}, {"name": "length", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the distance to the ending dimension"}]}},
{"code": "torch.nonzero(input,*,out=None,as_tuple=False)", "id": "torch.nonzero", "summary": "\nNote\ntorch.nonzero(..., as_tuple=False) (default) returns a\n2-D tensor where each row is the index for a nonzero value.\ntorch.nonzero(..., as_tuple=True) returns a tuple of 1-D\nindex tensors, allowing for advanced indexing, so x[x.nonzero(as_tuple=True)]\ngives all nonzero values of tensor x", "description": "", "code-info": {"name": "torch.nonzero", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "as_tuple", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.reshape(input,shape)", "id": "torch.reshape", "summary": "Returns a tensor with the same data and number of elements as input,\nbut with the specified shape", "description": "", "code-info": {"name": "torch.reshape", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to be reshaped"}, {"name": "shape", "is_optional": false, "type": "int", "description": "(tuple of python:ints) \u2013 the new shape"}]}},
{"code": "torch.split(tensor,split_size_or_sections,dim=0)", "id": "torch.split", "summary": "Splits the tensor into chunks.\nIf split_size_or_sections is an integer type, then tensor will\nbe split into equally sized chunks (if possible)", "description": "", "code-info": {"name": "torch.split", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 tensor to split."}, {"name": "split_size_or_sections", "is_optional": false, "type": "int", "description": "(python:int) or (list(python:int)) \u2013 size of a single chunk or\nlist of sizes for each chunk"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 dimension along which to split the tensor."}]}},
{"code": "torch.squeeze(input,dim=None,out=None)", "id": "torch.squeeze", "summary": "Returns a tensor with all the dimensions of input of size 1 removed.\nFor example, if input is of shape:\n(A\u00d71\u00d7B\u00d7C\u00d71\u00d7D)(A \\times 1 \\times B \\times C \\times 1 \\times D)(A\u00d71\u00d7B\u00d7C\u00d71\u00d7D)\n\n then the out tensor\nwill be of shape: (A\u00d7B\u00d7C\u00d7D)(A \\times B \\times C \\times D)(A\u00d7B\u00d7C\u00d7D)\n\n.\nWhen dim is given, a squeeze operation is done only in the given\ndimension", "description": "", "code-info": {"name": "torch.squeeze", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 if given, the input will be squeezed only in\nthis dimension"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.stack(tensors,dim=0,out=None)", "id": "torch.stack", "summary": "Concatenates sequence of tensors along a new dimension.\nAll tensors need to be of the same size.\n\nParameters\n\ntensors (sequence of Tensors) \u2013 sequence of tensors to concatenate\ndim (python:int) \u2013 dimension to insert", "description": "", "code-info": {"name": "torch.stack", "parameters": [{"name": "tensors", "is_optional": false, "type": "tensor", "description": "(sequence of Tensors) \u2013 sequence of tensors to concatenate"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 dimension to insert. Has to be between 0 and the number\nof dimensions of concatenated tensors (inclusive)"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.t(input)", "id": "torch.t", "summary": "Expects input to be &lt;= 2-D tensor and transposes dimensions 0\nand 1.\n0-D and 1-D tensors are returned as it is and\n2-D tensor can be seen as a short-hand function for transpose(input, 0, 1).\n\nParameters\ninput (Tensor) \u2013 the input tensor.\n\n\nExample:\n&gt;&gt;&gt; x = torch.randn(())\n&gt;&gt;&gt; x\ntensor(0.1995)\n&gt;&gt;&gt; torch.t(x)\ntensor(0.1995)\n&gt;&gt;&gt; x = torch.randn(3)\n&gt;&gt;&gt; x\ntensor([ 2.4320, -0.4608,  0.7702])\n&gt;&gt;&gt; torch.t(x)\ntensor([.2.4320,.-0.4608,..0.7702])\n&gt;&gt;&gt; x = torch.randn(2, 3)\n&gt;&gt;&gt; x\ntensor([[ 0.4875,  0.9158, -0.5872],\n        [ 0.3938, -0.6929,  0.6932]])\n&gt;&gt;&gt; torch.t(x)\ntensor([[ 0.4875,  0.3938],\n        [ 0.9158, -0.6929],\n        [-0.5872,  0.6932]])\n\n\n", "description": "", "code-info": {"name": "torch.t", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}]}},
{"code": "torch.take(input,index)", "id": "torch.take", "summary": "Returns a new tensor with the elements of input at the given indices.\nThe input tensor is treated as if it were viewed as a 1-D tensor", "description": "", "code-info": {"name": "torch.take", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.transpose(input,dim0,dim1)", "id": "torch.transpose", "summary": "Returns a tensor that is a transposed version of input.\nThe given dimensions dim0 and dim1 are swapped.\nThe resulting out tensor shares it\u2019s underlying storage with the\ninput tensor, so changing the content of one would change the content\nof the other.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\ndim0 (python:int) \u2013 the first dimension to be transposed\ndim1 (python:int) \u2013 the second dimension to be transposed\n\n\n\nExample:\n&gt;&gt;&gt; x = torch.randn(2, 3)\n&gt;&gt;&gt; x\ntensor([[ 1.0028, -0.9893,  0.5809],\n        [-0.1669,  0.7299,  0.4942]])\n&gt;&gt;&gt; torch.transpose(x, 0, 1)\ntensor([[ 1.0028, -0.1669],\n        [-0.9893,  0.7299],\n        [ 0.5809,  0.4942]])\n\n\n", "description": "", "code-info": {"name": "torch.transpose", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "dim0", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the first dimension to be transposed"}, {"name": "dim1", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the second dimension to be transposed"}]}},
{"code": "torch.unbind(input,dim=0)", "id": "torch.unbind", "summary": "Removes a tensor dimension.\nReturns a tuple of all slices along a given dimension, already without it.\n\nParameters\n\ninput (Tensor) \u2013 the tensor to unbind\ndim (python:int) \u2013 dimension to remove\n\n\n\nExample:\n&gt;&gt;&gt; torch.unbind(torch.tensor([[1, 2, 3],\n&gt;&gt;&gt;                            [4, 5, 6],\n&gt;&gt;&gt;                            [7, 8, 9]]))\n(tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9]))\n\n\n", "description": "", "code-info": {"name": "torch.unbind", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to unbind"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 dimension to remove"}]}},
{"code": "torch.unsqueeze(input,dim,out=None)", "id": "torch.unsqueeze", "summary": "Returns a new tensor with a dimension of size one inserted at the\nspecified position.\nThe returned tensor shares the same underlying data with this tensor.\nA dim value within the range [-input.dim() - 1, input.dim() + 1)\ncan be used", "description": "", "code-info": {"name": "torch.unsqueeze", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the index at which to insert the singleton dimension"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.nn.functional.one_hot(tensor,num_classes=-1)", "id": "torch.nn.functional.one_hot", "summary": "Takes LongTensor with index values of shape (*) and returns a tensor\nof shape (*, num_classes) that have zeros everywhere except where the\nindex of last dimension matches the corresponding value of the input tensor,\nin which case it will be 1.\nSee also One-hot on Wikipedia .\n\nParameters\n\ntensor (LongTensor) \u2013 class values of any shape.\nnum_classes (python:int) \u2013 Total number of classes", "description": "", "code-info": {"name": "torch.nn.functional.one_hot", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(LongTensor) \u2013 class values of any shape."}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 Total number of classes. If set to -1, the number\nof classes will be inferred as one greater than the largest class\nvalue in the input tensor."}]}},
{"code": "torch.nn.functional.pairwise_distance(x1,x2,p=2.0,eps=1e-06,keepdim=False)", "id": "torch.nn.functional.pairwise_distance", "summary": "See torch.nn.PairwiseDistance for details\n", "description": "", "code-info": {"name": "torch.nn.functional.pairwise_distance", "parameters": [{"name": "x1", "is_optional": false, "type": "others", "description": ""}, {"name": "x2", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "others", "default_value": "2.0", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-06", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.functional.cosine_similarity(x1,x2,dim=1,eps=1e-8)", "id": "torch.nn.functional.cosine_similarity", "summary": "Returns cosine similarity between x1 and x2, computed along dim.\n\nsimilarity=x1\u22c5x2max\u2061(\u2225x1\u22252\u22c5\u2225x2\u22252,\u03f5)\\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)}\n\nsimilarity=max(\u2225x1\u200b\u22252\u200b\u22c5\u2225x2\u200b\u22252\u200b,\u03f5)x1\u200b\u22c5x2\u200b\u200b\n\n\nParameters\n\nx1 (Tensor) \u2013 First input.\nx2 (Tensor) \u2013 Second input (of size matching x1).\ndim (python:int, optional) \u2013 Dimension of vectors", "description": "", "code-info": {"name": "torch.nn.functional.cosine_similarity", "parameters": [{"name": "x1", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 First input."}, {"name": "x2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Second input (of size matching x1)."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 Dimension of vectors. Default: 1"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-8", "description": "(python:float, optional) \u2013 Small value to avoid division by zero.\nDefault: 1e-8"}]}},
{"code": "torch.nn.functional.pdist(input,p=2)", "id": "torch.nn.functional.pdist", "summary": "Computes the p-norm distance between every pair of row vectors in the input.\nThis is identical to the upper triangular portion, excluding the diagonal, of\ntorch.norm(input[:, None] - input, dim=2, p=p)", "description": "", "code-info": {"name": "torch.nn.functional.pdist", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": ""}]}},
{"code": "torch.nn.functional.binary_cross_entropy(input,target,weight=None,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.binary_cross_entropy", "summary": "Function that measures the Binary Cross Entropy\nbetween the target and the output.\nSee BCELoss for details.\n\nParameters\n\ninput \u2013 Tensor of arbitrary shape\ntarget \u2013 Tensor of the same shape as input\nweight (Tensor, optional) \u2013 a manual rescaling weight\nif provided it\u2019s repeated to match input tensor shape\nsize_average (bool, optional) \u2013 Deprecated (see reduction)", "description": "", "code-info": {"name": "torch.nn.functional.binary_cross_entropy", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a manual rescaling weight\nif provided it\u2019s repeated to match input tensor shape"}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.functional.binary_cross_entropy_with_logits(input,target,weight=None,size_average=None,reduce=None,reduction='mean',pos_weight=None)", "id": "torch.nn.functional.binary_cross_entropy_with_logits", "summary": "Function that measures Binary Cross Entropy between target and output\nlogits.\nSee BCEWithLogitsLoss for details.\n\nParameters\n\ninput \u2013 Tensor of arbitrary shape\ntarget \u2013 Tensor of the same shape as input\nweight (Tensor, optional) \u2013 a manual rescaling weight\nif provided it\u2019s repeated to match input tensor shape\nsize_average (bool, optional) \u2013 Deprecated (see reduction)", "description": "", "code-info": {"name": "torch.nn.functional.binary_cross_entropy_with_logits", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a manual rescaling weight\nif provided it\u2019s repeated to match input tensor shape"}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, {"name": "pos_weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a weight of positive examples.\nMust be a vector with length equal to the number of classes."}]}},
{"code": "torch.nn.functional.poisson_nll_loss(input,target,log_input=True,full=False,size_average=None,eps=1e-08,reduce=None,reduction='mean')", "id": "torch.nn.functional.poisson_nll_loss", "summary": "Poisson negative log likelihood loss.\nSee PoissonNLLLoss for details.\n\nParameters\n\ninput \u2013 expectation of underlying Poisson distribution.\ntarget \u2013 random sample target\u223cPoisson(input)target \\sim \\text{Poisson}(input)target\u223cPoisson(input)\n\n.\nlog_input \u2013 if True the loss is computed as\nexp\u2061(input)\u2212target\u2217input\\exp(\\text{input}) - \\text{target} * \\text{input}exp(input)\u2212target\u2217input\n\n, if False then loss is\ninput\u2212target\u2217log\u2061(input+eps)\\text{input} - \\text{target} * \\log(\\text{input}+\\text{eps})input\u2212target\u2217log(input+eps)\n\n", "description": "", "code-info": {"name": "torch.nn.functional.poisson_nll_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "log_input", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "full", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-08", "description": "(python:float, optional) \u2013 Small value to avoid evaluation of log\u2061(0)\\log(0)log(0)\n\n when\nlog_input`=``False`. Default: 1e-8"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.functional.cosine_embedding_loss(input1,input2,target,margin=0,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.cosine_embedding_loss", "summary": "See CosineEmbeddingLoss for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.cosine_embedding_loss", "parameters": [{"name": "input1", "is_optional": false, "type": "others", "description": ""}, {"name": "input2", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "margin", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"code": "torch.nn.functional.cross_entropy(input,target,weight=None,size_average=None,ignore_index=-100,reduce=None,reduction='mean')", "id": "torch.nn.functional.cross_entropy", "summary": "This criterion combines log_softmax and nll_loss in a single\nfunction.\nSee CrossEntropyLoss for details.\n\nParameters\n\ninput (Tensor) \u2013 (N,C)(N, C)(N,C)\n\n where C = number of classes or (N,C,H,W)(N, C, H, W)(N,C,H,W)\n\n\nin case of 2D Loss, or (N,C,d1,d2,...,dK)(N, C, d_1, d_2, ..., d_K)(N,C,d1\u200b,d2\u200b,...,dK\u200b)\n\n where K\u22651K \\geq 1K\u22651\n\n\nin the case of K-dimensional loss.\ntarget (Tensor) \u2013 (N)(N)(N)\n\n where each value is 0\u2264targets[i]\u2264C\u221210 \\leq \\text{targets}[i] \\leq C-10\u2264targets[i]\u2264C\u22121\n\n,\nor (N,d1,d2,...,dK)(N, d_1, d_2, ..., d_K)(N,d1\u200b,d2\u200b,...,dK\u200b)\n\n where K\u22651K \\geq 1K\u22651\n\n for\nK-dimensional loss.\nweight (Tensor, optional) \u2013 a manual rescaling weight given to each\nclass", "description": "", "code-info": {"name": "torch.nn.functional.cross_entropy", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 (N,C)(N, C)(N,C)\n\n where C = number of classes or (N,C,H,W)(N, C, H, W)(N,C,H,W)\n\n\nin case of 2D Loss, or (N,C,d1,d2,...,dK)(N, C, d_1, d_2, ..., d_K)(N,C,d1\u200b,d2\u200b,...,dK\u200b)\n\n where K\u22651K \\geq 1K\u22651\n\n\nin the case of K-dimensional loss."}, {"name": "target", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 (N)(N)(N)\n\n where each value is 0\u2264targets[i]\u2264C\u221210 \\leq \\text{targets}[i] \\leq C-10\u2264targets[i]\u2264C\u22121\n\n,\nor (N,d1,d2,...,dK)(N, d_1, d_2, ..., d_K)(N,d1\u200b,d2\u200b,...,dK\u200b)\n\n where K\u22651K \\geq 1K\u22651\n\n for\nK-dimensional loss."}, {"name": "weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a manual rescaling weight given to each\nclass. If given, has to be a Tensor of size C"}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "ignore_index", "is_optional": true, "type": "int", "default_value": "-100", "description": "(python:int, optional) \u2013 Specifies a target value that is ignored\nand does not contribute to the input gradient. When size_average is\nTrue, the loss is averaged over non-ignored targets. Default: -100"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.distributions.multivariate_normal.MultivariateNormal.entropy()", "id": "torch.distributions.multivariate_normal.MultivariateNormal.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.entropy", "parameters": []}},
{"code": "torch.distributions.multivariate_normal.MultivariateNormal.expand(batch_shape,_instance=None)", "id": "torch.distributions.multivariate_normal.MultivariateNormal.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.multivariate_normal.MultivariateNormal.log_prob(value)", "id": "torch.distributions.multivariate_normal.MultivariateNormal.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.multivariate_normal.MultivariateNormal.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.multivariate_normal.MultivariateNormal.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.negative_binomial.NegativeBinomial.expand(batch_shape,_instance=None)", "id": "torch.distributions.negative_binomial.NegativeBinomial.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.negative_binomial.NegativeBinomial.log_prob(value)", "id": "torch.distributions.negative_binomial.NegativeBinomial.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.negative_binomial.NegativeBinomial.sample(sample_shape=torch.Size([])", "id": "torch.distributions.negative_binomial.NegativeBinomial.sample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.normal.Normal.cdf(value)", "id": "torch.distributions.normal.Normal.cdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.normal.Normal.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.normal.Normal.entropy()", "id": "torch.distributions.normal.Normal.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.normal.Normal.entropy", "parameters": []}},
{"code": "torch.distributions.normal.Normal.expand(batch_shape,_instance=None)", "id": "torch.distributions.normal.Normal.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.normal.Normal.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.normal.Normal.icdf(value)", "id": "torch.distributions.normal.Normal.icdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.normal.Normal.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.normal.Normal.log_prob(value)", "id": "torch.distributions.normal.Normal.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.normal.Normal.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.normal.Normal.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.normal.Normal.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.normal.Normal.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.normal.Normal.sample(sample_shape=torch.Size([])", "id": "torch.distributions.normal.Normal.sample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.normal.Normal.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.one_hot_categorical.OneHotCategorical.entropy()", "id": "torch.distributions.one_hot_categorical.OneHotCategorical.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.entropy", "parameters": []}},
{"code": "torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support(expand=True)", "id": "torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support", "summary": "", "description": "", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.Module.apply(fn)", "id": "torch.nn.Module.apply", "summary": "Applies fn recursively to every submodule (as returned by .children())\nas well as self", "description": "", "code-info": {"name": "torch.nn.Module.apply", "parameters": [{"name": "fn", "is_optional": false, "type": "others", "description": "(Module -&gt; None) \u2013 function to be applied to each submodule"}]}},
{"code": "torch.nn.Module.buffers(recurse=True)", "id": "torch.nn.Module.buffers", "summary": "Returns an iterator over module buffers.\n\nParameters\nrecurse (bool) \u2013 if True, then yields buffers of this module\nand all submodules", "description": "", "code-info": {"name": "torch.nn.Module.buffers", "parameters": [{"name": "recurse", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 if True, then yields buffers of this module\nand all submodules. Otherwise, yields only buffers that\nare direct members of this module."}]}},
{"code": "torch.nn.Module.children()", "id": "torch.nn.Module.children", "summary": "Returns an iterator over immediate children modules.\n\nYields\nModule \u2013 a child module\n\n\n", "description": "", "code-info": {"name": "torch.nn.Module.children", "parameters": []}},
{"code": "torch.nn.Module.cpu()", "id": "torch.nn.Module.cpu", "summary": "Moves all model parameters and buffers to the CPU.\n\nReturns\nself\n\nReturn type\nModule\n\n\n", "description": "", "code-info": {"name": "torch.nn.Module.cpu", "parameters": []}},
{"code": "torch.nn.Module.cuda(device=None)", "id": "torch.nn.Module.cuda", "summary": "Moves all model parameters and buffers to the GPU.\nThis also makes associated parameters and buffers different objects", "description": "", "code-info": {"name": "torch.nn.Module.cuda", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 if specified, all parameters will be\ncopied to that device"}]}},
{"code": "torch.nn.Module.double()", "id": "torch.nn.Module.double", "summary": "Casts all floating point parameters and buffers to double datatype.\n\nReturns\nself\n\nReturn type\nModule\n\n\n", "description": "", "code-info": {"name": "torch.nn.Module.double", "parameters": []}},
{"code": "torch.nn.Module.eval()", "id": "torch.nn.Module.eval", "summary": "Sets the module in evaluation mode.\nThis has any effect only on certain modules", "description": "", "code-info": {"name": "torch.nn.Module.eval", "parameters": []}},
{"code": "torch.nn.Module.extra_repr()", "id": "torch.nn.Module.extra_repr", "summary": "Set the extra representation of the module\nTo print customized extra information, you should reimplement\nthis method in your own modules", "description": "", "code-info": {"name": "torch.nn.Module.extra_repr", "parameters": []}},
{"code": "torch.nn.Module.float()", "id": "torch.nn.Module.float", "summary": "Casts all floating point parameters and buffers to float datatype.\n\nReturns\nself\n\nReturn type\nModule\n\n\n", "description": "", "code-info": {"name": "torch.nn.Module.float", "parameters": []}},
{"code": "torch.nn.Module.forward(*input)", "id": "torch.nn.Module.forward", "summary": "Defines the computation performed at every call.\nShould be overridden by all subclasses.\n\nNote\nAlthough the recipe for forward pass needs to be defined within\nthis function, one should call the Module instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.\n\n", "description": "", "code-info": {"name": "torch.nn.Module.forward", "parameters": [{"name": "*input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.Module.half()", "id": "torch.nn.Module.half", "summary": "Casts all floating point parameters and buffers to half datatype.\n\nReturns\nself\n\nReturn type\nModule\n\n\n", "description": "", "code-info": {"name": "torch.nn.Module.half", "parameters": []}},
{"code": "torch.nn.Module.load_state_dict(state_dict,strict=True)", "id": "torch.nn.Module.load_state_dict", "summary": "Copies parameters and buffers from state_dict into\nthis module and its descendants", "description": "", "code-info": {"name": "torch.nn.Module.load_state_dict", "parameters": [{"name": "state_dict", "is_optional": false, "type": "others", "description": "(dict) \u2013 a dict containing parameters and\npersistent buffers."}, {"name": "strict", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 whether to strictly enforce that the keys\nin state_dict match the keys returned by this module\u2019s\nstate_dict() function. Default: True"}]}},
{"code": "torch.nn.Module.modules()", "id": "torch.nn.Module.modules", "summary": "Returns an iterator over all modules in the network.\n\nYields\nModule \u2013 a module in the network\n\n\n\nNote\nDuplicate modules are returned only once", "description": "", "code-info": {"name": "torch.nn.Module.modules", "parameters": []}},
{"code": "torch.nn.Module.named_buffers(prefix='',recurse=True)", "id": "torch.nn.Module.named_buffers", "summary": "Returns an iterator over module buffers, yielding both the\nname of the buffer as well as the buffer itself.\n\nParameters\n\nprefix (str) \u2013 prefix to prepend to all buffer names.\nrecurse (bool) \u2013 if True, then yields buffers of this module\nand all submodules", "description": "", "code-info": {"name": "torch.nn.Module.named_buffers", "parameters": [{"name": "prefix", "is_optional": true, "type": "string", "default_value": "''", "description": "(str) \u2013 prefix to prepend to all buffer names."}, {"name": "recurse", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 if True, then yields buffers of this module\nand all submodules. Otherwise, yields only buffers that\nare direct members of this module."}]}},
{"code": "torch.nn.Module.named_children()", "id": "torch.nn.Module.named_children", "summary": "Returns an iterator over immediate children modules, yielding both\nthe name of the module as well as the module itself.\n\nYields\n(string, Module) \u2013 Tuple containing a name and child module\n\n\nExample:\n&gt;&gt;&gt; for name, module in model.named_children():\n&gt;&gt;&gt;     if name in ['conv4', 'conv5']:\n&gt;&gt;&gt;         print(module)\n\n\n", "description": "", "code-info": {"name": "torch.nn.Module.named_children", "parameters": []}},
{"code": "torch.nn.Module.named_modules(memo=None,prefix='')", "id": "torch.nn.Module.named_modules", "summary": "Returns an iterator over all modules in the network, yielding\nboth the name of the module as well as the module itself.\n\nYields\n(string, Module) \u2013 Tuple of name and module\n\n\n\nNote\nDuplicate modules are returned only once", "description": "", "code-info": {"name": "torch.nn.Module.named_modules", "parameters": [{"name": "memo", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "prefix", "is_optional": true, "type": "string", "default_value": "''", "description": ""}]}},
{"code": "torch.nn.Module.named_parameters(prefix='',recurse=True)", "id": "torch.nn.Module.named_parameters", "summary": "Returns an iterator over module parameters, yielding both the\nname of the parameter as well as the parameter itself.\n\nParameters\n\nprefix (str) \u2013 prefix to prepend to all parameter names.\nrecurse (bool) \u2013 if True, then yields parameters of this module\nand all submodules", "description": "", "code-info": {"name": "torch.nn.Module.named_parameters", "parameters": [{"name": "prefix", "is_optional": true, "type": "string", "default_value": "''", "description": "(str) \u2013 prefix to prepend to all parameter names."}, {"name": "recurse", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 if True, then yields parameters of this module\nand all submodules. Otherwise, yields only parameters that\nare direct members of this module."}]}},
{"code": "torch.nn.Module.parameters(recurse=True)", "id": "torch.nn.Module.parameters", "summary": "Returns an iterator over module parameters.\nThis is typically passed to an optimizer.\n\nParameters\nrecurse (bool) \u2013 if True, then yields parameters of this module\nand all submodules", "description": "", "code-info": {"name": "torch.nn.Module.parameters", "parameters": [{"name": "recurse", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 if True, then yields parameters of this module\nand all submodules. Otherwise, yields only parameters that\nare direct members of this module."}]}},
{"code": "torch.Tensor.fft(signal_ndim,normalized=False)", "id": "torch.Tensor.fft", "summary": "See torch.fft()\n", "description": "", "code-info": {"name": "torch.Tensor.fft", "parameters": [{"name": "signal_ndim", "is_optional": false, "type": "others", "description": ""}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.fill_(value)", "id": "torch.Tensor.fill_", "summary": "Fills self tensor with the specified value.\n", "description": "", "code-info": {"name": "torch.Tensor.fill_", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.flatten(input,start_dim=0,end_dim=-1)", "id": "torch.Tensor.flatten", "summary": "see torch.flatten()\n", "description": "", "code-info": {"name": "torch.Tensor.flatten", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "start_dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "end_dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}]}},
{"code": "torch.Tensor.flip(dims)", "id": "torch.Tensor.flip", "summary": "See torch.flip()\n", "description": "", "code-info": {"name": "torch.Tensor.flip", "parameters": [{"name": "dims", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.float()", "id": "torch.Tensor.float", "summary": "self.float() is equivalent to self.to(torch.float32)", "description": "", "code-info": {"name": "torch.Tensor.float", "parameters": []}},
{"code": "torch.Tensor.floor()", "id": "torch.Tensor.floor", "summary": "See torch.floor()\n", "description": "", "code-info": {"name": "torch.Tensor.floor", "parameters": []}},
{"code": "torch.Tensor.floor_()", "id": "torch.Tensor.floor_", "summary": "In-place version of floor()\n", "description": "", "code-info": {"name": "torch.Tensor.floor_", "parameters": []}},
{"code": "torch.Tensor.fmod(divisor)", "id": "torch.Tensor.fmod", "summary": "See torch.fmod()\n", "description": "", "code-info": {"name": "torch.Tensor.fmod", "parameters": [{"name": "divisor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.fmod_(divisor)", "id": "torch.Tensor.fmod_", "summary": "In-place version of fmod()\n", "description": "", "code-info": {"name": "torch.Tensor.fmod_", "parameters": [{"name": "divisor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.frac()", "id": "torch.Tensor.frac", "summary": "See torch.frac()\n", "description": "", "code-info": {"name": "torch.Tensor.frac", "parameters": []}},
{"code": "torch.Tensor.frac_()", "id": "torch.Tensor.frac_", "summary": "In-place version of frac()\n", "description": "", "code-info": {"name": "torch.Tensor.frac_", "parameters": []}},
{"code": "torch.Tensor.gather(dim,index)", "id": "torch.Tensor.gather", "summary": "See torch.gather()\n", "description": "", "code-info": {"name": "torch.Tensor.gather", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.ge(other)", "id": "torch.Tensor.ge", "summary": "See torch.ge()\n", "description": "", "code-info": {"name": "torch.Tensor.ge", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.ge_(other)", "id": "torch.Tensor.ge_", "summary": "In-place version of ge()\n", "description": "", "code-info": {"name": "torch.Tensor.ge_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.geometric_(p,*,generator=None)", "id": "torch.Tensor.geometric_", "summary": "Fills self tensor with elements drawn from the geometric distribution:\n\nf(X=k)=pk\u22121(1\u2212p)f(X=k) = p^{k - 1} (1 - p)f(X=k)=pk\u22121(1\u2212p)\n\n", "description": "", "code-info": {"name": "torch.Tensor.geometric_", "parameters": [{"name": "p", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.geqrf()", "id": "torch.Tensor.geqrf", "summary": "See torch.geqrf()\n", "description": "", "code-info": {"name": "torch.Tensor.geqrf", "parameters": []}},
{"code": "torch.Tensor.ger(vec2)", "id": "torch.Tensor.ger", "summary": "See torch.ger()\n", "description": "", "code-info": {"name": "torch.Tensor.ger", "parameters": [{"name": "vec2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.get_device()", "id": "torch.Tensor.get_device", "summary": "For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\nFor CPU tensors, an error is thrown.\nExample:\n&gt;&gt;&gt; x = torch.randn(3, 4, 5, device='cuda:0')\n&gt;&gt;&gt; x.get_device()\n0\n&gt;&gt;&gt; x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.get_device", "parameters": []}},
{"code": "torch.Tensor.gt(other)", "id": "torch.Tensor.gt", "summary": "See torch.gt()\n", "description": "", "code-info": {"name": "torch.Tensor.gt", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.gt_(other)", "id": "torch.Tensor.gt_", "summary": "In-place version of gt()\n", "description": "", "code-info": {"name": "torch.Tensor.gt_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.half()", "id": "torch.Tensor.half", "summary": "self.half() is equivalent to self.to(torch.float16)", "description": "", "code-info": {"name": "torch.Tensor.half", "parameters": []}},
{"code": "torch.Tensor.hardshrink(lambd=0.5)", "id": "torch.Tensor.hardshrink", "summary": "See torch.nn.functional.hardshrink()\n", "description": "", "code-info": {"name": "torch.Tensor.hardshrink", "parameters": [{"name": "lambd", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}]}},
{"code": "torch.Tensor.histc(bins=100,min=0,max=0)", "id": "torch.Tensor.histc", "summary": "See torch.histc()\n", "description": "", "code-info": {"name": "torch.Tensor.histc", "parameters": [{"name": "bins", "is_optional": true, "type": "int", "default_value": "100", "description": ""}, {"name": "min", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "max", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.where()", "id": "torch.where", "summary": "\n\ntorch.where(condition, x, y) \u2192 Tensor\n\n\nReturn a tensor of elements selected from either x or y, depending on condition.\nThe operation is defined as:\n\nouti={xiif\u00a0conditioniyiotherwise\\text{out}_i = \\begin{cases}\n    \\text{x}_i &amp; \\text{if } \\text{condition}_i \\\\\n    \\text{y}_i &amp; \\text{otherwise} \\\\\n\\end{cases}\n\nouti\u200b={xi\u200byi\u200b\u200bif\u00a0conditioni\u200botherwise\u200b\n\n\nNote\nThe tensors condition, x, y must be broadcastable.\n\n\nParameters\n\ncondition (BoolTensor) \u2013 When True (nonzero), yield x, otherwise yield y\nx (Tensor) \u2013 values selected at indices where condition is True\ny (Tensor) \u2013 values selected at indices where condition is False\n\n\nReturns\nA tensor of shape equal to the broadcasted shape of condition, x, y\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; x = torch.randn(3, 2)\n&gt;&gt;&gt; y = torch.ones(3, 2)\n&gt;&gt;&gt; x\ntensor([[-0.4620,  0.3139],\n        [ 0.3898, -0.7197],\n        [ 0.0478, -0.1657]])\n&gt;&gt;&gt; torch.where(x &gt; 0, x, y)\ntensor([[ 1.0000,  0.3139],\n        [ 0.3898,  1.0000],\n        [ 0.0478,  1.0000]])\n\n\n\n\ntorch.where(condition) \u2192 tuple of LongTensor\n\n\ntorch.where(condition) is identical to\ntorch.nonzero(condition, as_tuple=True).\n\nNote\nSee also torch.nonzero().\n\n", "description": "", "code-info": {"name": "torch.where", "parameters": []}},
{"code": "sig-prename descclassname(condition,x,y)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "condition", "is_optional": false, "type": "others", "description": ""}, {"name": "x", "is_optional": false, "type": "others", "description": ""}, {"name": "y", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-prename descclassname(condition)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "condition", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.seed()", "id": "torch.seed", "summary": "Sets the seed for generating random numbers to a non-deterministic\nrandom number", "description": "", "code-info": {"name": "torch.seed", "parameters": []}},
{"code": "torch.manual_seed(seed)", "id": "torch.manual_seed", "summary": "Sets the seed for generating random numbers", "description": "", "code-info": {"name": "torch.manual_seed", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": "(python:int) \u2013 The desired seed."}]}},
{"code": "torch.initial_seed()", "id": "torch.initial_seed", "summary": "Returns the initial seed for generating random numbers as a\nPython long.\n", "description": "", "code-info": {"name": "torch.initial_seed", "parameters": []}},
{"code": "torch.get_rng_state()", "id": "torch.get_rng_state", "summary": "Returns the random number generator state as a torch.ByteTensor.\n", "description": "", "code-info": {"name": "torch.get_rng_state", "parameters": []}},
{"code": "torch.set_rng_state(new_state)", "id": "torch.set_rng_state", "summary": "Sets the random number generator state.\n\nParameters\nnew_state (torch.ByteTensor) \u2013 The desired state\n\n\n", "description": "", "code-info": {"name": "torch.set_rng_state", "parameters": [{"name": "new_state", "is_optional": false, "type": "tensor", "description": "(torch.ByteTensor) \u2013 The desired state"}]}},
{"code": "torch.bernoulli(input,*,generator=None,out=None)", "id": "torch.bernoulli", "summary": "Draws binary random numbers (0 or 1) from a Bernoulli distribution.\nThe input tensor should be a tensor containing probabilities\nto be used for drawing the binary random number.\nHence, all values in input have to be in the range:\n0\u2264inputi\u226410 \\leq \\text{input}_i \\leq 10\u2264inputi\u200b\u22641\n\n.\nThe ith\\text{i}^{th}ith\n\n element of the output tensor will draw a\nvalue 111\n\n according to the ith\\text{i}^{th}ith\n\n probability value given\nin input.\n\nouti\u223cBernoulli(p=inputi)\\text{out}_{i} \\sim \\mathrm{Bernoulli}(p = \\text{input}_{i})\n\nouti\u200b\u223cBernoulli(p=inputi\u200b)\n\nThe returned out tensor only has values 0 or 1 and is of the same\nshape as input.\nout can have integral dtype, but input must have floating\npoint dtype.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor of probability values for the Bernoulli distribution\ngenerator (torch.Generator, optional) \u2013 a pseudorandom number generator for sampling\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.empty(3, 3).uniform_(0, 1)  # generate a uniform random matrix with range [0, 1]\n&gt;&gt;&gt; a\ntensor([[ 0.1737,  0.0950,  0.3609],\n        [ 0.7148,  0.0289,  0.2676],\n        [ 0.9456,  0.8937,  0.7202]])\n&gt;&gt;&gt; torch.bernoulli(a)\ntensor([[ 1.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 1.,  1.,  1.]])\n\n&gt;&gt;&gt; a = torch.ones(3, 3) # probability of drawing \"1\" is 1\n&gt;&gt;&gt; torch.bernoulli(a)\ntensor([[ 1.,  1.,  1.],\n        [ 1.,  1.,  1.],\n        [ 1.,  1.,  1.]])\n&gt;&gt;&gt; a = torch.zeros(3, 3) # probability of drawing \"1\" is 0\n&gt;&gt;&gt; torch.bernoulli(a)\ntensor([[ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.]])\n\n\n", "description": "", "code-info": {"name": "torch.bernoulli", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.Generator, optional) \u2013 a pseudorandom number generator for sampling"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.multinomial(input,num_samples,replacement=False,*,generator=None,out=None)", "id": "torch.multinomial", "summary": "Returns a tensor where each row contains num_samples indices sampled\nfrom the multinomial probability distribution located in the corresponding row\nof tensor input.\n\nNote\nThe rows of input do not need to sum to one (in which case we use\nthe values as weights), but must be non-negative, finite and have\na non-zero sum.\n\nIndices are ordered from left to right according to when each was sampled\n(first samples are placed in first column).\nIf input is a vector, out is a vector of size num_samples.\nIf input is a matrix with m rows, out is an matrix of shape\n(m\u00d7num_samples)(m \\times \\text{num\\_samples})(m\u00d7num_samples)\n\n.\nIf replacement is True, samples are drawn with replacement.\nIf not, they are drawn without replacement, which means that when a\nsample index is drawn for a row, it cannot be drawn again for that row.\n\nNote\nWhen drawn without replacement, num_samples must be lower than\nnumber of non-zero elements in input (or the min number of non-zero\nelements in each row of input if it is a matrix).\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor containing probabilities\nnum_samples (python:int) \u2013 number of samples to draw\nreplacement (bool, optional) \u2013 whether to draw with replacement or not\ngenerator (torch.Generator, optional) \u2013 a pseudorandom number generator for sampling\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; weights = torch.tensor([0, 10, 3, 0], dtype=torch.float) # create a tensor of weights\n&gt;&gt;&gt; torch.multinomial(weights, 2)\ntensor([1, 2])\n&gt;&gt;&gt; torch.multinomial(weights, 4) # ERROR!\nRuntimeError: invalid argument 2: invalid multinomial distribution (with replacement=False,\nnot enough non-negative category to sample) at ../aten/src/TH/generic/THTensorRandom.cpp:320\n&gt;&gt;&gt; torch.multinomial(weights, 4, replacement=True)\ntensor([ 2,  1,  1,  1])\n\n\n", "description": "", "code-info": {"name": "torch.multinomial", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor containing probabilities"}, {"name": "num_samples", "is_optional": false, "type": "int", "description": "(python:int) \u2013 number of samples to draw"}, {"name": "replacement", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.Generator, optional) \u2013 a pseudorandom number generator for sampling"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.normal()", "id": "torch.normal", "summary": "\n\ntorch.normal(mean, std, *, generator=None, out=None) \u2192 Tensor\n\n\nReturns a tensor of random numbers drawn from separate normal distributions\nwhose mean and standard deviation are given.\nThe mean is a tensor with the mean of\neach output element\u2019s normal distribution\nThe std is a tensor with the standard deviation of\neach output element\u2019s normal distribution\nThe shapes of mean and std don\u2019t need to match, but the\ntotal number of elements in each tensor need to be the same.\n\nNote\nWhen the shapes do not match, the shape of mean\nis used as the shape for the returned output tensor\n\n\nParameters\n\nmean (Tensor) \u2013 the tensor of per-element means\nstd (Tensor) \u2013 the tensor of per-element standard deviations\ngenerator (torch.Generator, optional) \u2013 a pseudorandom number generator for sampling\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\ntensor([  1.0425,   3.5672,   2.7969,   4.2925,   4.7229,   6.2134,\n          8.0505,   8.1408,   9.0563,  10.0566])\n\n\n\n\ntorch.normal(mean=0.0, std, out=None) \u2192 Tensor\n\n\nSimilar to the function above, but the means are shared among all drawn\nelements.\n\nParameters\n\nmean (python:float, optional) \u2013 the mean for all distributions\nstd (Tensor) \u2013 the tensor of per-element standard deviations\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; torch.normal(mean=0.5, std=torch.arange(1., 6.))\ntensor([-1.2793, -1.0732, -2.0687,  5.1177, -1.2303])\n\n\n\n\ntorch.normal(mean, std=1.0, out=None) \u2192 Tensor\n\n\nSimilar to the function above, but the standard-deviations are shared among\nall drawn elements.\n\nParameters\n\nmean (Tensor) \u2013 the tensor of per-element means\nstd (python:float, optional) \u2013 the standard deviation for all distributions\nout (Tensor, optional) \u2013 the output tensor\n\n\n\nExample:\n&gt;&gt;&gt; torch.normal(mean=torch.arange(1., 6.))\ntensor([ 1.1552,  2.6148,  2.6535,  5.8318,  4.2361])\n\n\n\n\ntorch.normal(mean, std, size, *, out=None) \u2192 Tensor\n\n\nSimilar to the function above, but the means and standard deviations are shared\namong all drawn elements", "description": "", "code-info": {"name": "torch.normal", "parameters": []}},
{"code": "sig-prename descclassname(mean,std,*,generator=None,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "mean", "is_optional": false, "type": "others", "description": ""}, {"name": "std", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-prename descclassname(mean=0.0,std,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "mean", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}, {"name": "std", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-prename descclassname(mean,std=1.0,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "mean", "is_optional": false, "type": "others", "description": ""}, {"name": "std", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.functional.ctc_loss(log_probs,targets,input_lengths,target_lengths,blank=0,reduction='mean',zero_infinity=False)", "id": "torch.nn.functional.ctc_loss", "summary": "The Connectionist Temporal Classification loss.\nSee CTCLoss for details.\n\nNote\nIn some circumstances when using the CUDA backend with CuDNN, this operator\nmay select a nondeterministic algorithm to increase performance", "description": "", "code-info": {"name": "torch.nn.functional.ctc_loss", "parameters": [{"name": "log_probs", "is_optional": false, "type": "others", "description": ""}, {"name": "targets", "is_optional": false, "type": "others", "description": ""}, {"name": "input_lengths", "is_optional": false, "type": "others", "description": ""}, {"name": "target_lengths", "is_optional": false, "type": "others", "description": ""}, {"name": "blank", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 Blank label. Default 000\n\n."}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the output losses will be divided by the target lengths and\nthen the mean over the batch is taken, 'sum': the output will be\nsummed. Default: 'mean'"}, {"name": "zero_infinity", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether to zero infinite losses and the associated gradients.\nDefault: False\nInfinite losses mainly occur when the inputs are too short\nto be aligned to the targets."}]}},
{"code": "torch.nn.functional.hinge_embedding_loss(input,target,margin=1.0,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.hinge_embedding_loss", "summary": "See HingeEmbeddingLoss for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.hinge_embedding_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "margin", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"code": "torch.nn.functional.kl_div(input,target,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.kl_div", "summary": "The Kullback-Leibler divergence Loss.\nSee KLDivLoss for details.\n\nParameters\n\ninput \u2013 Tensor of arbitrary shape\ntarget \u2013 Tensor of the same shape as input\nsize_average (bool, optional) \u2013 Deprecated (see reduction)", "description": "", "code-info": {"name": "torch.nn.functional.kl_div", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'batchmean' | 'sum' | 'mean'.\n'none': no reduction will be applied\n'batchmean': the sum of the output will be divided by the batchsize\n'sum': the output will be summed\n'mean': the output will be divided by the number of elements in the output\nDefault: 'mean'"}]}},
{"code": "torch.nn.functional.l1_loss(input,target,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.l1_loss", "summary": "Function that takes the mean element-wise absolute value difference.\nSee L1Loss for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.l1_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"code": "torch.nn.functional.mse_loss(input,target,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.mse_loss", "summary": "Measures the element-wise mean squared error.\nSee MSELoss for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.mse_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"code": "torch.nn.functional.margin_ranking_loss(input1,input2,target,margin=0,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.margin_ranking_loss", "summary": "See MarginRankingLoss for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.margin_ranking_loss", "parameters": [{"name": "input1", "is_optional": false, "type": "others", "description": ""}, {"name": "input2", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "margin", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"code": "torch.nn.functional.multilabel_margin_loss(input,target,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.multilabel_margin_loss", "summary": "See MultiLabelMarginLoss for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.multilabel_margin_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"code": "torch.nn.functional.multilabel_soft_margin_loss(input,target,weight=None,size_average=None)", "id": "torch.nn.functional.multilabel_soft_margin_loss", "summary": "See MultiLabelSoftMarginLoss for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.multilabel_soft_margin_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.functional.multi_margin_loss(input,target,p=1,margin=1.0,weight=None,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.multi_margin_loss", "summary": "\nmulti_margin_loss(input, target, p=1, margin=1, weight=None, size_average=None,reduce=None, reduction=\u2019mean\u2019) -&gt; Tensor\n\n\nSee MultiMarginLoss for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.multi_margin_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "margin", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"code": "torch.nn.functional.nll_loss(input,target,weight=None,size_average=None,ignore_index=-100,reduce=None,reduction='mean')", "id": "torch.nn.functional.nll_loss", "summary": "The negative log likelihood loss.\nSee NLLLoss for details.\n\nParameters\n\ninput \u2013 (N,C)(N, C)(N,C)\n\n where C = number of classes or (N,C,H,W)(N, C, H, W)(N,C,H,W)\n\n\nin case of 2D Loss, or (N,C,d1,d2,...,dK)(N, C, d_1, d_2, ..., d_K)(N,C,d1\u200b,d2\u200b,...,dK\u200b)\n\n where K\u22651K \\geq 1K\u22651\n\n\nin the case of K-dimensional loss.\ntarget \u2013 (N)(N)(N)\n\n where each value is 0\u2264targets[i]\u2264C\u221210 \\leq \\text{targets}[i] \\leq C-10\u2264targets[i]\u2264C\u22121\n\n,\nor (N,d1,d2,...,dK)(N, d_1, d_2, ..., d_K)(N,d1\u200b,d2\u200b,...,dK\u200b)\n\n where K\u22651K \\geq 1K\u22651\n\n for\nK-dimensional loss.\nweight (Tensor, optional) \u2013 a manual rescaling weight given to each\nclass", "description": "", "code-info": {"name": "torch.nn.functional.nll_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a manual rescaling weight given to each\nclass. If given, has to be a Tensor of size C"}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "ignore_index", "is_optional": true, "type": "int", "default_value": "-100", "description": "(python:int, optional) \u2013 Specifies a target value that is ignored\nand does not contribute to the input gradient. When size_average is\nTrue, the loss is averaged over non-ignored targets. Default: -100"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.functional.smooth_l1_loss(input,target,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.smooth_l1_loss", "summary": "Function that uses a squared term if the absolute\nelement-wise error falls below 1 and an L1 term otherwise.\nSee SmoothL1Loss for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.smooth_l1_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"code": "torch.nn.functional.soft_margin_loss(input,target,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.soft_margin_loss", "summary": "See SoftMarginLoss for details.\n", "description": "", "code-info": {"name": "torch.nn.functional.soft_margin_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"code": "torch.nn.functional.triplet_margin_loss(anchor,positive,negative,margin=1.0,p=2,eps=1e-06,swap=False,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.functional.triplet_margin_loss", "summary": "See TripletMarginLoss for details\n", "description": "", "code-info": {"name": "torch.nn.functional.triplet_margin_loss", "parameters": [{"name": "anchor", "is_optional": false, "type": "others", "description": ""}, {"name": "positive", "is_optional": false, "type": "others", "description": ""}, {"name": "negative", "is_optional": false, "type": "others", "description": ""}, {"name": "margin", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-06", "description": ""}, {"name": "swap", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"code": "torch.nn.functional.pixel_shuffle()", "id": "torch.nn.functional.pixel_shuffle", "summary": "Rearranges elements in a tensor of shape (\u2217,C\u00d7r2,H,W)(*, C \\times r^2, H, W)(\u2217,C\u00d7r2,H,W)\n\n to a\ntensor of shape (\u2217,C,H\u00d7r,W\u00d7r)(*, C, H \\times r, W \\times r)(\u2217,C,H\u00d7r,W\u00d7r)\n\n.\nSee PixelShuffle for details.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor\nupscale_factor (python:int) \u2013 factor to increase spatial resolution by\n\n\n\nExamples:\n&gt;&gt;&gt; input = torch.randn(1, 9, 4, 4)\n&gt;&gt;&gt; output = torch.nn.functional.pixel_shuffle(input, 3)\n&gt;&gt;&gt; print(output.size())\ntorch.Size([1, 1, 12, 12])\n\n\n", "description": "", "code-info": {"name": "torch.nn.functional.pixel_shuffle", "parameters": []}},
{"code": "torch.distributions.one_hot_categorical.OneHotCategorical.expand(batch_shape,_instance=None)", "id": "torch.distributions.one_hot_categorical.OneHotCategorical.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.one_hot_categorical.OneHotCategorical.log_prob(value)", "id": "torch.distributions.one_hot_categorical.OneHotCategorical.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.one_hot_categorical.OneHotCategorical.sample(sample_shape=torch.Size([])", "id": "torch.distributions.one_hot_categorical.OneHotCategorical.sample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.pareto.Pareto.entropy()", "id": "torch.distributions.pareto.Pareto.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.pareto.Pareto.entropy", "parameters": []}},
{"code": "torch.distributions.pareto.Pareto.expand(batch_shape,_instance=None)", "id": "torch.distributions.pareto.Pareto.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.pareto.Pareto.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.poisson.Poisson.expand(batch_shape,_instance=None)", "id": "torch.distributions.poisson.Poisson.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.poisson.Poisson.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.poisson.Poisson.log_prob(value)", "id": "torch.distributions.poisson.Poisson.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.poisson.Poisson.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.poisson.Poisson.sample(sample_shape=torch.Size([])", "id": "torch.distributions.poisson.Poisson.sample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.poisson.Poisson.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.nn.Module.register_backward_hook(hook)", "id": "torch.nn.Module.register_backward_hook", "summary": "Registers a backward hook on the module.\nThe hook will be called every time the gradients with respect to module\ninputs are computed", "description": "", "code-info": {"name": "torch.nn.Module.register_backward_hook", "parameters": [{"name": "hook", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.Module.register_buffer(name,tensor)", "id": "torch.nn.Module.register_buffer", "summary": "Adds a persistent buffer to the module.\nThis is typically used to register a buffer that should not to be\nconsidered a model parameter", "description": "", "code-info": {"name": "torch.nn.Module.register_buffer", "parameters": [{"name": "name", "is_optional": false, "type": "string", "description": "(string) \u2013 name of the buffer. The buffer can be accessed\nfrom this module using the given name"}, {"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 buffer to be registered."}]}},
{"code": "torch.nn.Module.register_forward_hook(hook)", "id": "torch.nn.Module.register_forward_hook", "summary": "Registers a forward hook on the module.\nThe hook will be called every time after forward() has computed an output.\nIt should have the following signature:\nhook(module, input, output) -&gt; None or modified output\n\n\nThe hook can modify the output", "description": "", "code-info": {"name": "torch.nn.Module.register_forward_hook", "parameters": [{"name": "hook", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.Module.register_forward_pre_hook(hook)", "id": "torch.nn.Module.register_forward_pre_hook", "summary": "Registers a forward pre-hook on the module.\nThe hook will be called every time before forward() is invoked.\nIt should have the following signature:\nhook(module, input) -&gt; None or modified input\n\n\nThe hook can modify the input", "description": "", "code-info": {"name": "torch.nn.Module.register_forward_pre_hook", "parameters": [{"name": "hook", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.Module.register_parameter(name,param)", "id": "torch.nn.Module.register_parameter", "summary": "Adds a parameter to the module.\nThe parameter can be accessed as an attribute using given name.\n\nParameters\n\nname (string) \u2013 name of the parameter", "description": "", "code-info": {"name": "torch.nn.Module.register_parameter", "parameters": [{"name": "name", "is_optional": false, "type": "string", "description": "(string) \u2013 name of the parameter. The parameter can be accessed\nfrom this module using the given name"}, {"name": "param", "is_optional": false, "type": "others", "description": "(Parameter) \u2013 parameter to be added to the module."}]}},
{"code": "torch.nn.Module.requires_grad_(requires_grad=True)", "id": "torch.nn.Module.requires_grad_", "summary": "Change if autograd should record operations on parameters in this\nmodule.\nThis method sets the parameters\u2019 requires_grad attributes\nin-place.\nThis method is helpful for freezing part of the module for finetuning\nor training parts of a model individually (e.g., GAN training).\n\nParameters\nrequires_grad (bool) \u2013 whether autograd should record operations on\nparameters in this module", "description": "", "code-info": {"name": "torch.nn.Module.requires_grad_", "parameters": [{"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 whether autograd should record operations on\nparameters in this module. Default: True."}]}},
{"code": "torch.nn.Module.state_dict(destination=None,prefix='',keep_vars=False)", "id": "torch.nn.Module.state_dict", "summary": "Returns a dictionary containing a whole state of the module.\nBoth parameters and persistent buffers (e.g", "description": "", "code-info": {"name": "torch.nn.Module.state_dict", "parameters": [{"name": "destination", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "prefix", "is_optional": true, "type": "string", "default_value": "''", "description": ""}, {"name": "keep_vars", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.Module.to(*args,**kwargs)", "id": "torch.nn.Module.to", "summary": "Moves and/or casts the parameters and buffers.\nThis can be called as\n\n\nto(device=None, dtype=None, non_blocking=False) \n\n\n\n\nto(dtype, non_blocking=False) \n\n\n\n\nto(tensor, non_blocking=False) \n\n\nIts signature is similar to torch.Tensor.to(), but only accepts\nfloating point desired dtype s", "description": "", "code-info": {"name": "torch.nn.Module.to", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.Module.train(mode=True)", "id": "torch.nn.Module.train", "summary": "Sets the module in training mode.\nThis has any effect only on certain modules", "description": "", "code-info": {"name": "torch.nn.Module.train", "parameters": [{"name": "mode", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 whether to set training mode (True) or evaluation"}]}},
{"code": "torch.Tensor.ifft(signal_ndim,normalized=False)", "id": "torch.Tensor.ifft", "summary": "See torch.ifft()\n", "description": "", "code-info": {"name": "torch.Tensor.ifft", "parameters": [{"name": "signal_ndim", "is_optional": false, "type": "others", "description": ""}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.imag()", "id": "torch.Tensor.imag", "summary": "See torch.imag()\n", "description": "", "code-info": {"name": "torch.Tensor.imag", "parameters": []}},
{"code": "torch.Tensor.index_add_(dim,index,tensor)", "id": "torch.Tensor.index_add_", "summary": "Accumulate the elements of tensor into the self tensor by adding\nto the indices in the order given in index", "description": "", "code-info": {"name": "torch.Tensor.index_add_", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 dimension along which to index"}, {"name": "index", "is_optional": false, "type": "tensor", "description": "(LongTensor) \u2013 indices of tensor to select from"}, {"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor containing values to add"}]}},
{"code": "torch.Tensor.index_add(dim,index,tensor)", "id": "torch.Tensor.index_add", "summary": "Out-of-place version of torch.Tensor.index_add_()\n", "description": "", "code-info": {"name": "torch.Tensor.index_add", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.index_copy_(dim,index,tensor)", "id": "torch.Tensor.index_copy_", "summary": "Copies the elements of tensor into the self tensor by selecting\nthe indices in the order given in index", "description": "", "code-info": {"name": "torch.Tensor.index_copy_", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 dimension along which to index"}, {"name": "index", "is_optional": false, "type": "tensor", "description": "(LongTensor) \u2013 indices of tensor to select from"}, {"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor containing values to copy"}]}},
{"code": "torch.Tensor.index_copy(dim,index,tensor)", "id": "torch.Tensor.index_copy", "summary": "Out-of-place version of torch.Tensor.index_copy_()\n", "description": "", "code-info": {"name": "torch.Tensor.index_copy", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.index_fill_(dim,index,val)", "id": "torch.Tensor.index_fill_", "summary": "Fills the elements of the self tensor with value val by\nselecting the indices in the order given in index.\n\nParameters\n\ndim (python:int) \u2013 dimension along which to index\nindex (LongTensor) \u2013 indices of self tensor to fill in\nval (python:float) \u2013 the value to fill with\n\n\n\n\nExample::&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n&gt;&gt;&gt; index = torch.tensor([0, 2])\n&gt;&gt;&gt; x.index_fill_(1, index, -1)\ntensor([[-1.,  2., -1.],\n        [-1.,  5., -1.],\n        [-1.,  8., -1.]])\n\n\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.index_fill_", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 dimension along which to index"}, {"name": "index", "is_optional": false, "type": "tensor", "description": "(LongTensor) \u2013 indices of self tensor to fill in"}, {"name": "val", "is_optional": false, "type": "float", "description": "(python:float) \u2013 the value to fill with"}]}},
{"code": "torch.Tensor.index_fill(dim,index,value)", "id": "torch.Tensor.index_fill", "summary": "Out-of-place version of torch.Tensor.index_fill_()\n", "description": "", "code-info": {"name": "torch.Tensor.index_fill", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.index_put_(indices,value,accumulate=False)", "id": "torch.Tensor.index_put_", "summary": "Puts values from the tensor value into the tensor self using\nthe indices specified in indices (which is a tuple of Tensors)", "description": "", "code-info": {"name": "torch.Tensor.index_put_", "parameters": [{"name": "indices", "is_optional": false, "type": "tensor", "description": "(tuple of LongTensor) \u2013 tensors used to index into self."}, {"name": "value", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 tensor of same dtype as self."}, {"name": "accumulate", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 whether to accumulate into self"}]}},
{"code": "sig-prename descclassname(mean,std,size,*,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "mean", "is_optional": false, "type": "others", "description": ""}, {"name": "std", "is_optional": false, "type": "others", "description": ""}, {"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.rand(*size,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.rand", "summary": "Returns a tensor filled with random numbers from a uniform distribution\non the interval [0,1)[0, 1)[0,1)\n\n\nThe shape of the tensor is defined by the variable argument size.\n\nParameters\n\nsize (python:int...) \u2013 a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple.\nout (Tensor, optional) \u2013 the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()).\nlayout (torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type())", "description": "", "code-info": {"name": "torch.rand", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type())."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.rand_like(input,dtype=None,layout=None,device=None,requires_grad=False)", "id": "torch.rand_like", "summary": "Returns a tensor with the same size as input that is filled with\nrandom numbers from a uniform distribution on the interval [0,1)[0, 1)[0,1)\n\n.\ntorch.rand_like(input) is equivalent to\ntorch.rand(input.size(), dtype=input.dtype, layout=input.layout, device=input.device).\n\nParameters\n\ninput (Tensor) \u2013 the size of input will determine size of the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: if None, defaults to the dtype of input.\nlayout (torch.layout, optional) \u2013 the desired layout of returned tensor.\nDefault: if None, defaults to the layout of input.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, defaults to the device of input.\nrequires_grad (bool, optional) \u2013 If autograd should record operations on the\nreturned tensor", "description": "", "code-info": {"name": "torch.rand_like", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the size of input will determine size of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: if None, defaults to the dtype of input."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.layout, optional) \u2013 the desired layout of returned tensor.\nDefault: if None, defaults to the layout of input."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, defaults to the device of input."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.randint(low=0,high,size,*,generator=None,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.randint", "summary": "Returns a tensor filled with random integers generated uniformly\nbetween low (inclusive) and high (exclusive).\nThe shape of the tensor is defined by the variable argument size.\n\nParameters\n\nlow (python:int, optional) \u2013 Lowest integer to be drawn from the distribution", "description": "", "code-info": {"name": "torch.randint", "parameters": [{"name": "low", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 Lowest integer to be drawn from the distribution. Default: 0."}, {"name": "high", "is_optional": false, "type": "int", "description": "(python:int) \u2013 One above the highest integer to be drawn from the distribution."}, {"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.Generator, optional) \u2013 a pseudorandom number generator for sampling"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type())."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.randint_like(input,low=0,high,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.randint_like", "summary": "Returns a tensor with the same shape as Tensor input filled with\nrandom integers generated uniformly between low (inclusive) and\nhigh (exclusive).\n\nParameters\n\ninput (Tensor) \u2013 the size of input will determine size of the output tensor.\nlow (python:int, optional) \u2013 Lowest integer to be drawn from the distribution", "description": "", "code-info": {"name": "torch.randint_like", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the size of input will determine size of the output tensor."}, {"name": "low", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 Lowest integer to be drawn from the distribution. Default: 0."}, {"name": "high", "is_optional": false, "type": "others", "description": "(exclusive).\n\nParameters\n\ninput (Tensor) \u2013 the size of input will determine size of the output tensor.\nlow (python:int, optional) \u2013 Lowest integer to be drawn from the distribution. Default: 0."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: if None, defaults to the dtype of input."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned tensor.\nDefault: if None, defaults to the layout of input."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, defaults to the device of input."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.randn(*size,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.randn", "summary": "Returns a tensor filled with random numbers from a normal distribution\nwith mean 0 and variance 1 (also called the standard normal\ndistribution).\n\nouti\u223cN(0,1)\\text{out}_{i} \\sim \\mathcal{N}(0, 1)\n\nouti\u200b\u223cN(0,1)\n\nThe shape of the tensor is defined by the variable argument size.\n\nParameters\n\nsize (python:int...) \u2013 a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple.\nout (Tensor, optional) \u2013 the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()).\nlayout (torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type())", "description": "", "code-info": {"name": "torch.randn", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type())."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.nn.functional.pad(input,pad,mode='constant',value=0)", "id": "torch.nn.functional.pad", "summary": "Pads tensor.\n\nPadding size:The padding size by which to pad some dimensions of input\nare described starting from the last dimension and moving forward.\n\u230alen(pad)2\u230b\\left\\lfloor\\frac{\\text{len(pad)}}{2}\\right\\rfloor\u230a2len(pad)\u200b\u230b\n\n dimensions\nof input will be padded.\nFor example, to pad only the last dimension of the input tensor, then\npad has the form\n(padding_left,padding_right)(\\text{padding\\_left}, \\text{padding\\_right})(padding_left,padding_right)\n\n;\nto pad the last 2 dimensions of the input tensor, then use\n(padding_left,padding_right,(\\text{padding\\_left}, \\text{padding\\_right},(padding_left,padding_right,\n\n\npadding_top,padding_bottom)\\text{padding\\_top}, \\text{padding\\_bottom})padding_top,padding_bottom)\n\n;\nto pad the last 3 dimensions, use\n(padding_left,padding_right,(\\text{padding\\_left}, \\text{padding\\_right},(padding_left,padding_right,\n\n\npadding_top,padding_bottom\\text{padding\\_top}, \\text{padding\\_bottom}padding_top,padding_bottom\n\n\npadding_front,padding_back)\\text{padding\\_front}, \\text{padding\\_back})padding_front,padding_back)\n\n.\n\nPadding mode:See torch.nn.ConstantPad2d, torch.nn.ReflectionPad2d, and\ntorch.nn.ReplicationPad2d for concrete examples on how each of the\npadding modes works", "description": "", "code-info": {"name": "torch.nn.functional.pad", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 N-dimensional tensor"}, {"name": "pad", "is_optional": false, "type": "others", "description": ""}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'constant'", "description": ""}, {"name": "value", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.nn.functional.interpolate(input,size=None,scale_factor=None,mode='nearest',align_corners=None)", "id": "torch.nn.functional.interpolate", "summary": "Down/up samples the input to either the given size or the given\nscale_factor\nThe algorithm used for interpolation is determined by mode.\nCurrently temporal, spatial and volumetric sampling are supported, i.e.\nexpected inputs are 3-D, 4-D or 5-D in shape.\nThe input dimensions are interpreted in the form:\nmini-batch x channels x [optional depth] x [optional height] x width.\nThe modes available for resizing are: nearest, linear (3D-only),\nbilinear, bicubic (4D-only), trilinear (5D-only), area\n\nParameters\n\ninput (Tensor) \u2013 the input tensor\nsize (python:int or Tuple[python:int] or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) \u2013 output spatial size.\nscale_factor (python:float or Tuple[python:float]) \u2013 multiplier for spatial size", "description": "", "code-info": {"name": "torch.nn.functional.interpolate", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor"}, {"name": "size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int] or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) \u2013 output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float or Tuple[python:float]) \u2013 multiplier for spatial size. Has to match input size if it is a tuple."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'nearest'", "description": "(str) \u2013 algorithm used for upsampling:\n'nearest' | 'linear' | 'bilinear' | 'bicubic' |\n'trilinear' | 'area'. Default: 'nearest'"}, {"name": "align_corners", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Geometrically, we consider the pixels of the\ninput and output as squares rather than points.\nIf set to True, the input and output tensors are aligned by the\ncenter points of their corner pixels, preserving the values at the corner pixels.\nIf set to False, the input and output tensors are aligned by the corner\npoints of their corner pixels, and the interpolation uses edge value padding\nfor out-of-boundary values, making this operation independent of input size\nwhen scale_factor is kept the same. This only has an effect when mode\nis 'linear', 'bilinear', 'bicubic' or 'trilinear'.\nDefault: False"}]}},
{"code": "torch.nn.functional.upsample(input,size=None,scale_factor=None,mode='nearest',align_corners=None)", "id": "torch.nn.functional.upsample", "summary": "Upsamples the input to either the given size or the given\nscale_factor\n\nWarning\nThis function is deprecated in favor of torch.nn.functional.interpolate().\nThis is equivalent with nn.functional.interpolate(...).\n\n\nNote\nWhen using the CUDA backend, this operation may induce nondeterministic\nbehaviour in its backward pass that is not easily switched off.\nPlease see the notes on Reproducibility for background.\n\nThe algorithm used for upsampling is determined by mode.\nCurrently temporal, spatial and volumetric upsampling are supported, i.e.\nexpected inputs are 3-D, 4-D or 5-D in shape.\nThe input dimensions are interpreted in the form:\nmini-batch x channels x [optional depth] x [optional height] x width.\nThe modes available for upsampling are: nearest, linear (3D-only),\nbilinear, bicubic (4D-only), trilinear (5D-only)\n\nParameters\n\ninput (Tensor) \u2013 the input tensor\nsize (python:int or Tuple[python:int] or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) \u2013 output spatial size.\nscale_factor (python:float or Tuple[python:float]) \u2013 multiplier for spatial size", "description": "", "code-info": {"name": "torch.nn.functional.upsample", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor"}, {"name": "size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int] or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) \u2013 output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float or Tuple[python:float]) \u2013 multiplier for spatial size. Has to be an integer."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'nearest'", "description": "(string) \u2013 algorithm used for upsampling:\n'nearest' | 'linear' | 'bilinear' | 'bicubic' |\n'trilinear'. Default: 'nearest'"}, {"name": "align_corners", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Geometrically, we consider the pixels of the\ninput and output as squares rather than points.\nIf set to True, the input and output tensors are aligned by the\ncenter points of their corner pixels, preserving the values at the corner pixels.\nIf set to False, the input and output tensors are aligned by the corner\npoints of their corner pixels, and the interpolation uses edge value padding\nfor out-of-boundary values, making this operation independent of input size\nwhen scale_factor is kept the same. This only has an effect when mode\nis 'linear', 'bilinear', 'bicubic' or 'trilinear'.\nDefault: False"}]}},
{"code": "torch.nn.functional.upsample_nearest(input,size=None,scale_factor=None)", "id": "torch.nn.functional.upsample_nearest", "summary": "Upsamples the input, using nearest neighbours\u2019 pixel values.\n\nWarning\nThis function is deprecated in favor of torch.nn.functional.interpolate().\nThis is equivalent with nn.functional.interpolate(..., mode='nearest').\n\nCurrently spatial and volumetric upsampling are supported (i.e", "description": "", "code-info": {"name": "torch.nn.functional.upsample_nearest", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input"}, {"name": "size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) \u2013 output spatia\nsize."}, {"name": "scale_factor", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 multiplier for spatial size. Has to be an integer."}]}},
{"code": "torch.nn.functional.upsample_bilinear(input,size=None,scale_factor=None)", "id": "torch.nn.functional.upsample_bilinear", "summary": "Upsamples the input, using bilinear upsampling.\n\nWarning\nThis function is deprecated in favor of torch.nn.functional.interpolate().\nThis is equivalent with\nnn.functional.interpolate(..., mode='bilinear', align_corners=True).\n\nExpected inputs are spatial (4 dimensional)", "description": "", "code-info": {"name": "torch.nn.functional.upsample_bilinear", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input"}, {"name": "size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int, python:int]) \u2013 output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int, python:int]) \u2013 multiplier for spatial size"}]}},
{"code": "torch.nn.functional.grid_sample(input,grid,mode='bilinear',padding_mode='zeros',align_corners=None)", "id": "torch.nn.functional.grid_sample", "summary": "Given an input and a flow-field grid, computes the\noutput using input values and pixel locations from grid.\nCurrently, only spatial (4-D) and volumetric (5-D) input are\nsupported.\nIn the spatial (4-D) case, for input with shape\n(N,C,Hin,Win)(N, C, H_\\text{in}, W_\\text{in})(N,C,Hin\u200b,Win\u200b)\n\n and grid with shape\n(N,Hout,Wout,2)(N, H_\\text{out}, W_\\text{out}, 2)(N,Hout\u200b,Wout\u200b,2)\n\n, the output will have shape\n(N,C,Hout,Wout)(N, C, H_\\text{out}, W_\\text{out})(N,C,Hout\u200b,Wout\u200b)\n\n.\nFor each output location output[n, :, h, w], the size-2 vector\ngrid[n, h, w] specifies input pixel locations x and y,\nwhich are used to interpolate the output value output[n, :, h, w].\nIn the case of 5D inputs, grid[n, d, h, w] specifies the\nx, y, z pixel locations for interpolating\noutput[n, :, d, h, w]", "description": "", "code-info": {"name": "torch.nn.functional.grid_sample", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input of shape (N,C,Hin,Win)(N, C, H_\\text{in}, W_\\text{in})(N,C,Hin\u200b,Win\u200b)\n\n (4-D case)\nor (N,C,Din,Hin,Win)(N, C, D_\\text{in}, H_\\text{in}, W_\\text{in})(N,C,Din\u200b,Hin\u200b,Win\u200b)\n\n (5-D case)"}, {"name": "grid", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 flow-field of shape (N,Hout,Wout,2)(N, H_\\text{out}, W_\\text{out}, 2)(N,Hout\u200b,Wout\u200b,2)\n\n (4-D case)\nor (N,Dout,Hout,Wout,3)(N, D_\\text{out}, H_\\text{out}, W_\\text{out}, 3)(N,Dout\u200b,Hout\u200b,Wout\u200b,3)\n\n (5-D case)"}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'bilinear'", "description": "(str) \u2013 interpolation mode to calculate output values\n'bilinear' | 'nearest'. Default: 'bilinear'"}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": "(str) \u2013 padding mode for outside grid values\n'zeros' | 'border' | 'reflection'. Default: 'zeros'"}, {"name": "align_corners", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Geometrically, we consider the pixels of the\ninput  as squares rather than points.\nIf set to True, the extrema (-1 and 1) are considered as referring\nto the center points of the input\u2019s corner pixels. If set to False, they\nare instead considered as referring to the corner points of the input\u2019s corner\npixels, making the sampling more resolution agnostic.\nThis option parallels the align_corners option in\ninterpolate(), and so whichever option is used here\nshould also be used there to resize the input image before grid sampling.\nDefault: False"}]}},
{"code": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.expand(batch_shape,_instance=None)", "id": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.expand(batch_shape,_instance=None)", "id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.log_prob(value)", "id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.expand(batch_shape,_instance=None)", "id": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.studentT.StudentT.entropy()", "id": "torch.distributions.studentT.StudentT.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.studentT.StudentT.entropy", "parameters": []}},
{"code": "torch.distributions.studentT.StudentT.expand(batch_shape,_instance=None)", "id": "torch.distributions.studentT.StudentT.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.studentT.StudentT.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.studentT.StudentT.log_prob(value)", "id": "torch.distributions.studentT.StudentT.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.studentT.StudentT.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.studentT.StudentT.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.studentT.StudentT.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.studentT.StudentT.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.nn.Module.type(dst_type)", "id": "torch.nn.Module.type", "summary": "Casts all parameters and buffers to dst_type.\n\nParameters\ndst_type (python:type or string) \u2013 the desired type\n\nReturns\nself\n\nReturn type\nModule\n\n\n", "description": "", "code-info": {"name": "torch.nn.Module.type", "parameters": [{"name": "dst_type", "is_optional": false, "type": "string", "description": "(python:type or string) \u2013 the desired type"}]}},
{"code": "torch.nn.Module.zero_grad()", "id": "torch.nn.Module.zero_grad", "summary": "Sets gradients of all model parameters to zero.\n", "description": "", "code-info": {"name": "torch.nn.Module.zero_grad", "parameters": []}},
{"code": "torch.nn.ModuleList.append(module)", "id": "torch.nn.ModuleList.append", "summary": "Appends a given module to the end of the list.\n\nParameters\nmodule (nn.Module) \u2013 module to append\n\n\n", "description": "", "code-info": {"name": "torch.nn.ModuleList.append", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module to append"}]}},
{"code": "torch.nn.ModuleList.extend(modules)", "id": "torch.nn.ModuleList.extend", "summary": "Appends modules from a Python iterable to the end of the list.\n\nParameters\nmodules (iterable) \u2013 iterable of modules to append\n\n\n", "description": "", "code-info": {"name": "torch.nn.ModuleList.extend", "parameters": [{"name": "modules", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of modules to append"}]}},
{"code": "torch.nn.ModuleList.insert(index,module)", "id": "torch.nn.ModuleList.insert", "summary": "Insert a given module before a given index in the list.\n\nParameters\n\nindex (python:int) \u2013 index to insert.\nmodule (nn.Module) \u2013 module to insert\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.ModuleList.insert", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 index to insert."}, {"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module to insert"}]}},
{"code": "torch.nn.ModuleDict.clear()", "id": "torch.nn.ModuleDict.clear", "summary": "Remove all items from the ModuleDict.\n", "description": "", "code-info": {"name": "torch.nn.ModuleDict.clear", "parameters": []}},
{"code": "torch.nn.ModuleDict.items()", "id": "torch.nn.ModuleDict.items", "summary": "Return an iterable of the ModuleDict key/value pairs.\n", "description": "", "code-info": {"name": "torch.nn.ModuleDict.items", "parameters": []}},
{"code": "torch.nn.ModuleDict.keys()", "id": "torch.nn.ModuleDict.keys", "summary": "Return an iterable of the ModuleDict keys.\n", "description": "", "code-info": {"name": "torch.nn.ModuleDict.keys", "parameters": []}},
{"code": "torch.nn.ModuleDict.pop(key)", "id": "torch.nn.ModuleDict.pop", "summary": "Remove key from the ModuleDict and return its module.\n\nParameters\nkey (string) \u2013 key to pop from the ModuleDict\n\n\n", "description": "", "code-info": {"name": "torch.nn.ModuleDict.pop", "parameters": [{"name": "key", "is_optional": false, "type": "string", "description": "(string) \u2013 key to pop from the ModuleDict"}]}},
{"code": "torch.nn.ModuleDict.update(modules)", "id": "torch.nn.ModuleDict.update", "summary": "Update the ModuleDict with the key-value pairs from a\nmapping or an iterable, overwriting existing keys.\n\nNote\nIf modules is an OrderedDict, a ModuleDict, or\nan iterable of key-value pairs, the order of new elements in it is preserved.\n\n\nParameters\nmodules (iterable) \u2013 a mapping (dictionary) from string to Module,\nor an iterable of key-value pairs of type (string, Module)\n\n\n", "description": "", "code-info": {"name": "torch.nn.ModuleDict.update", "parameters": [{"name": "modules", "is_optional": false, "type": "others", "description": "(iterable) \u2013 a mapping (dictionary) from string to Module,\nor an iterable of key-value pairs of type (string, Module)"}]}},
{"code": "torch.nn.ModuleDict.values()", "id": "torch.nn.ModuleDict.values", "summary": "Return an iterable of the ModuleDict values.\n", "description": "", "code-info": {"name": "torch.nn.ModuleDict.values", "parameters": []}},
{"code": "torch.nn.ParameterList.append(parameter)", "id": "torch.nn.ParameterList.append", "summary": "Appends a given parameter at the end of the list.\n\nParameters\nparameter (nn.Parameter) \u2013 parameter to append\n\n\n", "description": "", "code-info": {"name": "torch.nn.ParameterList.append", "parameters": [{"name": "parameter", "is_optional": false, "type": "others", "description": "(nn.Parameter) \u2013 parameter to append"}]}},
{"code": "torch.nn.ParameterList.extend(parameters)", "id": "torch.nn.ParameterList.extend", "summary": "Appends parameters from a Python iterable to the end of the list.\n\nParameters\nparameters (iterable) \u2013 iterable of parameters to append\n\n\n", "description": "", "code-info": {"name": "torch.nn.ParameterList.extend", "parameters": [{"name": "parameters", "is_optional": false, "type": "others", "description": "(iterable) \u2013 iterable of parameters to append"}]}},
{"code": "torch.nn.ParameterDict.clear()", "id": "torch.nn.ParameterDict.clear", "summary": "Remove all items from the ParameterDict.\n", "description": "", "code-info": {"name": "torch.nn.ParameterDict.clear", "parameters": []}},
{"code": "torch.nn.ParameterDict.items()", "id": "torch.nn.ParameterDict.items", "summary": "Return an iterable of the ParameterDict key/value pairs.\n", "description": "", "code-info": {"name": "torch.nn.ParameterDict.items", "parameters": []}},
{"code": "torch.nn.ParameterDict.keys()", "id": "torch.nn.ParameterDict.keys", "summary": "Return an iterable of the ParameterDict keys.\n", "description": "", "code-info": {"name": "torch.nn.ParameterDict.keys", "parameters": []}},
{"code": "torch.nn.ParameterDict.pop(key)", "id": "torch.nn.ParameterDict.pop", "summary": "Remove key from the ParameterDict and return its parameter.\n\nParameters\nkey (string) \u2013 key to pop from the ParameterDict\n\n\n", "description": "", "code-info": {"name": "torch.nn.ParameterDict.pop", "parameters": [{"name": "key", "is_optional": false, "type": "string", "description": "(string) \u2013 key to pop from the ParameterDict"}]}},
{"code": "torch.nn.ParameterDict.update(parameters)", "id": "torch.nn.ParameterDict.update", "summary": "Update the ParameterDict with the key-value pairs from a\nmapping or an iterable, overwriting existing keys.\n\nNote\nIf parameters is an OrderedDict, a ParameterDict, or\nan iterable of key-value pairs, the order of new elements in it is preserved.\n\n\nParameters\nparameters (iterable) \u2013 a mapping (dictionary) from string to\nParameter, or an iterable of\nkey-value pairs of type (string, Parameter)\n\n\n", "description": "", "code-info": {"name": "torch.nn.ParameterDict.update", "parameters": [{"name": "parameters", "is_optional": false, "type": "others", "description": "(iterable) \u2013 a mapping (dictionary) from string to\nParameter, or an iterable of\nkey-value pairs of type (string, Parameter)"}]}},
{"code": "torch.Tensor.index_put(indices,value,accumulate=False)", "id": "torch.Tensor.index_put", "summary": "Out-place version of index_put_()\n", "description": "", "code-info": {"name": "torch.Tensor.index_put", "parameters": [{"name": "indices", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}, {"name": "accumulate", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.index_select(dim,index)", "id": "torch.Tensor.index_select", "summary": "See torch.index_select()\n", "description": "", "code-info": {"name": "torch.Tensor.index_select", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.indices()", "id": "torch.Tensor.indices", "summary": "If self is a sparse COO tensor (i.e., with torch.sparse_coo layout),\nthis returns a view of the contained indices tensor", "description": "", "code-info": {"name": "torch.Tensor.indices", "parameters": []}},
{"code": "torch.Tensor.int()", "id": "torch.Tensor.int", "summary": "self.int() is equivalent to self.to(torch.int32)", "description": "", "code-info": {"name": "torch.Tensor.int", "parameters": []}},
{"code": "torch.Tensor.int_repr()", "id": "torch.Tensor.int_repr", "summary": "Given a quantized Tensor,\nself.int_repr() returns a CPU Tensor with uint8_t as data type that stores the\nunderlying uint8_t values of the given Tensor.\n", "description": "", "code-info": {"name": "torch.Tensor.int_repr", "parameters": []}},
{"code": "torch.Tensor.inverse()", "id": "torch.Tensor.inverse", "summary": "See torch.inverse()\n", "description": "", "code-info": {"name": "torch.Tensor.inverse", "parameters": []}},
{"code": "torch.Tensor.irfft(signal_ndim,normalized=False,onesided=True,signal_sizes=None)", "id": "torch.Tensor.irfft", "summary": "See torch.irfft()\n", "description": "", "code-info": {"name": "torch.Tensor.irfft", "parameters": [{"name": "signal_ndim", "is_optional": false, "type": "others", "description": ""}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "signal_sizes", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.is_contiguous()", "id": "torch.Tensor.is_contiguous", "summary": "Returns True if self tensor is contiguous in memory in C order.\n", "description": "", "code-info": {"name": "torch.Tensor.is_contiguous", "parameters": []}},
{"code": "torch.Tensor.is_floating_point()", "id": "torch.Tensor.is_floating_point", "summary": "Returns True if the data type of self is a floating point data type.\n", "description": "", "code-info": {"name": "torch.Tensor.is_floating_point", "parameters": []}},
{"code": "torch.Tensor.is_pinned()", "id": "torch.Tensor.is_pinned", "summary": "Returns true if this tensor resides in pinned memory.\n", "description": "", "code-info": {"name": "torch.Tensor.is_pinned", "parameters": []}},
{"code": "torch.Tensor.is_set_to(tensor)", "id": "torch.Tensor.is_set_to", "summary": "Returns True if this object refers to the same THTensor object from the\nTorch C API as the given tensor.\n", "description": "", "code-info": {"name": "torch.Tensor.is_set_to", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.is_shared()", "id": "torch.Tensor.is_shared", "summary": "Checks if tensor is in shared memory.\nThis is always True for CUDA tensors.\n", "description": "", "code-info": {"name": "torch.Tensor.is_shared", "parameters": []}},
{"code": "torch.Tensor.is_signed()", "id": "torch.Tensor.is_signed", "summary": "Returns True if the data type of self is a signed data type.\n", "description": "", "code-info": {"name": "torch.Tensor.is_signed", "parameters": []}},
{"code": "torch.Tensor.item()", "id": "torch.Tensor.item", "summary": "Returns the value of this tensor as a standard Python number", "description": "", "code-info": {"name": "torch.Tensor.item", "parameters": []}},
{"code": "torch.Tensor.kthvalue(k,dim=None,keepdim=False)", "id": "torch.Tensor.kthvalue", "summary": "See torch.kthvalue()\n", "description": "", "code-info": {"name": "torch.Tensor.kthvalue", "parameters": [{"name": "k", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.le(other)", "id": "torch.Tensor.le", "summary": "See torch.le()\n", "description": "", "code-info": {"name": "torch.Tensor.le", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.le_(other)", "id": "torch.Tensor.le_", "summary": "In-place version of le()\n", "description": "", "code-info": {"name": "torch.Tensor.le_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.lerp(end,weight)", "id": "torch.Tensor.lerp", "summary": "See torch.lerp()\n", "description": "", "code-info": {"name": "torch.Tensor.lerp", "parameters": [{"name": "end", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.lerp_(end,weight)", "id": "torch.Tensor.lerp_", "summary": "In-place version of lerp()\n", "description": "", "code-info": {"name": "torch.Tensor.lerp_", "parameters": [{"name": "end", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.randn_like(input,dtype=None,layout=None,device=None,requires_grad=False)", "id": "torch.randn_like", "summary": "Returns a tensor with the same size as input that is filled with\nrandom numbers from a normal distribution with mean 0 and variance 1.\ntorch.randn_like(input) is equivalent to\ntorch.randn(input.size(), dtype=input.dtype, layout=input.layout, device=input.device).\n\nParameters\n\ninput (Tensor) \u2013 the size of input will determine size of the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: if None, defaults to the dtype of input.\nlayout (torch.layout, optional) \u2013 the desired layout of returned tensor.\nDefault: if None, defaults to the layout of input.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, defaults to the device of input.\nrequires_grad (bool, optional) \u2013 If autograd should record operations on the\nreturned tensor", "description": "", "code-info": {"name": "torch.randn_like", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the size of input will determine size of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned Tensor.\nDefault: if None, defaults to the dtype of input."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.layout, optional) \u2013 the desired layout of returned tensor.\nDefault: if None, defaults to the layout of input."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, defaults to the device of input."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.randperm(n,out=None,dtype=torch.int64,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.randperm", "summary": "Returns a random permutation of integers from 0 to n - 1.\n\nParameters\n\nn (python:int) \u2013 the upper bound (exclusive)\nout (Tensor, optional) \u2013 the output tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: torch.int64.\nlayout (torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided.\ndevice (torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type())", "description": "", "code-info": {"name": "torch.randperm", "parameters": [{"name": "n", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the upper bound (exclusive)"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.int64", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: torch.int64."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault: torch.strided."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.save(obj,f,pickle_module=&lt;module'pickle'from'/opt/conda/lib/python3.6/pickle.py'&gt;,pickle_protocol=2,_use_new_zipfile_serialization=False)", "id": "torch.save", "summary": "Saves an object to a disk file.\nSee also: Recommended approach for saving a model\n\nParameters\n\nobj \u2013 saved object\nf \u2013 a file-like object (has to implement write and flush) or a string\ncontaining a file name\npickle_module \u2013 module used for pickling metadata and objects\npickle_protocol \u2013 can be specified to override the default protocol\n\n\n\n\nWarning\nIf you are using Python 2, torch.save() does NOT support StringIO.StringIO\nas a valid file-like object", "description": "", "code-info": {"name": "torch.save", "parameters": [{"name": "obj", "is_optional": false, "type": "others", "description": ""}, {"name": "f", "is_optional": false, "type": "others", "description": ""}, {"name": "pickle_module", "is_optional": true, "type": "others", "default_value": "&lt;module'pickle'from'/opt/conda/lib/python3.6/pickle.py'&gt;", "description": ""}, {"name": "pickle_protocol", "is_optional": true, "type": "int", "default_value": "2", "description": ""}, {"name": "_use_new_zipfile_serialization", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.load(f,map_location=None,pickle_module=&lt;module'pickle'from'/opt/conda/lib/python3.6/pickle.py'&gt;,**pickle_load_args)", "id": "torch.load", "summary": "Loads an object saved with torch.save() from a file.\ntorch.load() uses Python\u2019s unpickling facilities but treats storages,\nwhich underlie tensors, specially", "description": "", "code-info": {"name": "torch.load", "parameters": [{"name": "f", "is_optional": false, "type": "others", "description": ""}, {"name": "map_location", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "pickle_module", "is_optional": true, "type": "others", "default_value": "&lt;module'pickle'from'/opt/conda/lib/python3.6/pickle.py'&gt;", "description": ""}, {"name": "**pickle_load_args", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.get_num_threads()", "id": "torch.get_num_threads", "summary": "Returns the number of threads used for parallelizing CPU operations\n", "description": "", "code-info": {"name": "torch.get_num_threads", "parameters": []}},
{"code": "torch.set_num_threads(int)", "id": "torch.set_num_threads", "summary": "Sets the number of threads used for intraop parallelism on CPU.\nWARNING:\nTo ensure that the correct number of threads is used, set_num_threads\nmust be called before running eager, JIT or autograd code.\n", "description": "", "code-info": {"name": "torch.set_num_threads", "parameters": [{"name": "int", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.get_num_interop_threads()", "id": "torch.get_num_interop_threads", "summary": "Returns the number of threads used for inter-op parallelism on CPU\n(e.g", "description": "", "code-info": {"name": "torch.get_num_interop_threads", "parameters": []}},
{"code": "torch.set_num_interop_threads(int)", "id": "torch.set_num_interop_threads", "summary": "Sets the number of threads used for interop parallelism\n(e.g", "description": "", "code-info": {"name": "torch.set_num_interop_threads", "parameters": [{"name": "int", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.abs(input,out=None)", "id": "torch.abs", "summary": "Computes the element-wise absolute value of the given input tensor.\n\nouti=\u2223inputi\u2223\\text{out}_{i} = |\\text{input}_{i}|\n\nouti\u200b=\u2223inputi\u200b\u2223\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; torch.abs(torch.tensor([-1, -2, 3]))\ntensor([ 1,  2,  3])\n\n\n", "description": "", "code-info": {"name": "torch.abs", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.acos(input,out=None)", "id": "torch.acos", "summary": "Returns a new tensor with the arccosine  of the elements of input.\n\nouti=cos\u2061\u22121(inputi)\\text{out}_{i} = \\cos^{-1}(\\text{input}_{i})\n\nouti\u200b=cos\u22121(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 0.3348, -0.5889,  0.2005, -0.1584])\n&gt;&gt;&gt; torch.acos(a)\ntensor([ 1.2294,  2.2004,  1.3690,  1.7298])\n\n\n", "description": "", "code-info": {"name": "torch.acos", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.add()", "id": "torch.add", "summary": "\n\ntorch.add(input, other, out=None)\n\n\nAdds the scalar other to each element of the input input\nand returns a new resulting tensor.\n\nout=input+other\\text{out} = \\text{input} + \\text{other}\n\nout=input+other\n\nIf input is of type FloatTensor or DoubleTensor, other must be\na real number, otherwise it should be an integer.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nvalue (Number) \u2013 the number to be added to each element of input\n\n\nKeyword Arguments\nout (Tensor, optional) \u2013 the output tensor.\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 0.0202,  1.0985,  1.3506, -0.6056])\n&gt;&gt;&gt; torch.add(a, 20)\ntensor([ 20.0202,  21.0985,  21.3506,  19.3944])\n\n\n\n\ntorch.add(input, alpha=1, other, out=None)\n\n\nEach element of the tensor other is multiplied by the scalar\nalpha and added to each element of the tensor input.\nThe resulting tensor is returned.\nThe shapes of input and other must be\nbroadcastable.\n\nout=input+alpha\u00d7other\\text{out} = \\text{input} + \\text{alpha} \\times \\text{other}\n\nout=input+alpha\u00d7other\n\nIf other is of type FloatTensor or DoubleTensor, alpha must be\na real number, otherwise it should be an integer.\n\nParameters\n\ninput (Tensor) \u2013 the first input tensor\nalpha (Number) \u2013 the scalar multiplier for other\nother (Tensor) \u2013 the second input tensor\n\n\nKeyword Arguments\nout (Tensor, optional) \u2013 the output tensor.\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([-0.9732, -0.3497,  0.6245,  0.4022])\n&gt;&gt;&gt; b = torch.randn(4, 1)\n&gt;&gt;&gt; b\ntensor([[ 0.3743],\n        [-1.7724],\n        [-0.5811],\n        [-0.8017]])\n&gt;&gt;&gt; torch.add(a, 10, b)\ntensor([[  2.7695,   3.3930,   4.3672,   4.1450],\n        [-18.6971, -18.0736, -17.0994, -17.3216],\n        [ -6.7845,  -6.1610,  -5.1868,  -5.4090],\n        [ -8.9902,  -8.3667,  -7.3925,  -7.6147]])\n\n\n", "description": "", "code-info": {"name": "torch.add", "parameters": []}},
{"code": "sig-prename descclassname(input,other,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.functional.affine_grid(theta,size,align_corners=None)", "id": "torch.nn.functional.affine_grid", "summary": "Generates a 2D or 3D flow field (sampling grid), given a batch of\naffine matrices theta.\n\nNote\nThis function is often used in conjunction with grid_sample()\nto build Spatial Transformer Networks .\n\n\nParameters\n\ntheta (Tensor) \u2013 input batch of affine matrices with shape\n(N\u00d72\u00d73N \\times 2 \\times 3N\u00d72\u00d73\n\n) for 2D or\n(N\u00d73\u00d74N \\times 3 \\times 4N\u00d73\u00d74\n\n) for 3D\nsize (torch.Size) \u2013 the target output image size.\n(N\u00d7C\u00d7H\u00d7WN \\times C \\times H \\times WN\u00d7C\u00d7H\u00d7W\n\n for 2D or\nN\u00d7C\u00d7D\u00d7H\u00d7WN \\times C \\times D \\times H \\times WN\u00d7C\u00d7D\u00d7H\u00d7W\n\n for 3D)\nExample: torch.Size((32, 3, 24, 24))\nalign_corners (bool, optional) \u2013 if True, consider -1 and 1\nto refer to the centers of the corner pixels rather than the image corners.\nRefer to grid_sample() for a more complete description.\nA grid generated by affine_grid() should be passed to grid_sample()\nwith the same setting for this option.\nDefault: False\n\n\nReturns\noutput Tensor of size (N\u00d7H\u00d7W\u00d72N \\times H \\times W \\times 2N\u00d7H\u00d7W\u00d72\n\n)\n\nReturn type\noutput (Tensor)\n\n\n\nWarning\nWhen align_corners = True, the grid positions depend on the pixel\nsize relative to the input image size, and so the locations sampled by\ngrid_sample() will differ for the same input given at different\nresolutions (that is, after being upsampled or downsampled).\nThe default behavior up to version 1.2.0 was align_corners = True.\nSince then, the default behavior has been changed to align_corners = False,\nin order to bring it in line with the default for interpolate().\n\n\nWarning\nWhen align_corners = True, 2D affine transforms on 1D data and\n3D affine transforms on 2D data (that is, when one of the spatial\ndimensions has unit size) are ill-defined, and not an intended use case.\nThis is not a problem when align_corners = False.\nUp to version 1.2.0, all grid points along a unit dimension were\nconsidered arbitrarily to be at -1.\nFrom version 1.3.0, under align_corners = True all grid points\nalong a unit dimension are condsidered to be at `0\n(the center of the input image).\n\n", "description": "", "code-info": {"name": "torch.nn.functional.affine_grid", "parameters": [{"name": "theta", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input batch of affine matrices with shape\n(N\u00d72\u00d73N \\times 2 \\times 3N\u00d72\u00d73\n\n) for 2D or\n(N\u00d73\u00d74N \\times 3 \\times 4N\u00d73\u00d74\n\n) for 3D"}, {"name": "size", "is_optional": false, "type": "others", "description": "(torch.Size) \u2013 the target output image size.\n(N\u00d7C\u00d7H\u00d7WN \\times C \\times H \\times WN\u00d7C\u00d7H\u00d7W\n\n for 2D or\nN\u00d7C\u00d7D\u00d7H\u00d7WN \\times C \\times D \\times H \\times WN\u00d7C\u00d7D\u00d7H\u00d7W\n\n for 3D)\nExample: torch.Size((32, 3, 24, 24))"}, {"name": "align_corners", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 if True, consider -1 and 1\nto refer to the centers of the corner pixels rather than the image corners.\nRefer to grid_sample() for a more complete description.\nA grid generated by affine_grid() should be passed to grid_sample()\nwith the same setting for this option.\nDefault: False"}]}},
{"code": "torch.nn.parallel.data_parallel(module,inputs,device_ids=None,output_device=None,dim=0,module_kwargs=None)", "id": "torch.nn.parallel.data_parallel", "summary": "Evaluates module(input) in parallel across the GPUs given in device_ids.\nThis is the functional version of the DataParallel module.\n\nParameters\n\nmodule (Module) \u2013 the module to evaluate in parallel\ninputs (Tensor) \u2013 inputs to the module\ndevice_ids (list of python:int or torch.device) \u2013 GPU ids on which to replicate module\noutput_device (list of python:int or torch.device) \u2013 GPU location of the output  Use -1 to indicate the CPU.\n(default: device_ids[0])\n\n\nReturns\na Tensor containing the result of module(input) located on\noutput_device\n\n\n", "description": "", "code-info": {"name": "torch.nn.parallel.data_parallel", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(Module) \u2013 the module to evaluate in parallel"}, {"name": "inputs", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 inputs to the module"}, {"name": "device_ids", "is_optional": true, "type": "int", "default_value": "None", "description": "(list of python:int or torch.device) \u2013 GPU ids on which to replicate module"}, {"name": "output_device", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "module_kwargs", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.transformed_distribution.TransformedDistribution.cdf(value)", "id": "torch.distributions.transformed_distribution.TransformedDistribution.cdf", "summary": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.\n", "description": "", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.transformed_distribution.TransformedDistribution.expand(batch_shape,_instance=None)", "id": "torch.distributions.transformed_distribution.TransformedDistribution.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.transformed_distribution.TransformedDistribution.icdf(value)", "id": "torch.distributions.transformed_distribution.TransformedDistribution.icdf", "summary": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.\n", "description": "", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.transformed_distribution.TransformedDistribution.log_prob(value)", "id": "torch.distributions.transformed_distribution.TransformedDistribution.log_prob", "summary": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.\n", "description": "", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.transformed_distribution.TransformedDistribution.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.transformed_distribution.TransformedDistribution.rsample", "summary": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched", "description": "", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.transformed_distribution.TransformedDistribution.sample(sample_shape=torch.Size([])", "id": "torch.distributions.transformed_distribution.TransformedDistribution.sample", "summary": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched", "description": "", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.uniform.Uniform.cdf(value)", "id": "torch.distributions.uniform.Uniform.cdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.uniform.Uniform.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.uniform.Uniform.entropy()", "id": "torch.distributions.uniform.Uniform.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.uniform.Uniform.entropy", "parameters": []}},
{"code": "torch.distributions.uniform.Uniform.expand(batch_shape,_instance=None)", "id": "torch.distributions.uniform.Uniform.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.uniform.Uniform.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.uniform.Uniform.icdf(value)", "id": "torch.distributions.uniform.Uniform.icdf", "summary": "", "description": "", "code-info": {"name": "torch.distributions.uniform.Uniform.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.uniform.Uniform.log_prob(value)", "id": "torch.distributions.uniform.Uniform.log_prob", "summary": "", "description": "", "code-info": {"name": "torch.distributions.uniform.Uniform.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.uniform.Uniform.rsample(sample_shape=torch.Size([])", "id": "torch.distributions.uniform.Uniform.rsample", "summary": "", "description": "", "code-info": {"name": "torch.distributions.uniform.Uniform.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.weibull.Weibull.entropy()", "id": "torch.distributions.weibull.Weibull.entropy", "summary": "", "description": "", "code-info": {"name": "torch.distributions.weibull.Weibull.entropy", "parameters": []}},
{"code": "torch.distributions.weibull.Weibull.expand(batch_shape,_instance=None)", "id": "torch.distributions.weibull.Weibull.expand", "summary": "", "description": "", "code-info": {"name": "torch.distributions.weibull.Weibull.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.ParameterDict.values()", "id": "torch.nn.ParameterDict.values", "summary": "Return an iterable of the ParameterDict values.\n", "description": "", "code-info": {"name": "torch.nn.ParameterDict.values", "parameters": []}},
{"code": "torch.nn.MultiheadAttention.forward(query,key,value,key_padding_mask=None,need_weights=True,attn_mask=None)", "id": "torch.nn.MultiheadAttention.forward", "summary": "\nParameters\n\nkey, value (query,) \u2013 map a query and a set of key-value pairs to an output.\nSee \u201cAttention Is All You Need\u201d for more details.\nkey_padding_mask \u2013 if provided, specified padding elements in the key will\nbe ignored by the attention", "description": "", "code-info": {"name": "torch.nn.MultiheadAttention.forward", "parameters": [{"name": "query", "is_optional": false, "type": "others", "description": ""}, {"name": "key", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}, {"name": "key_padding_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "need_weights", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "attn_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob(input)", "id": "torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob", "summary": "Computes log probabilities for all n_classesn\\_classesn_classes\n\n\n\nParameters\ninput (Tensor) \u2013 a minibatch of examples\n\nReturns\nlog-probabilities of for each class ccc\n\n\nin range 0&lt;=c&lt;=n_classes0 &lt;= c &lt;= n\\_classes0&lt;=c&lt;=n_classes\n\n, where n_classesn\\_classesn_classes\n\n is a\nparameter passed to AdaptiveLogSoftmaxWithLoss constructor.\n\n\n\nShape:\nInput: (N,in_features)(N, in\\_features)(N,in_features)\n\n\nOutput: (N,n_classes)(N, n\\_classes)(N,n_classes)\n\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 a minibatch of examples"}]}},
{"code": "torch.nn.AdaptiveLogSoftmaxWithLoss.predict(input)", "id": "torch.nn.AdaptiveLogSoftmaxWithLoss.predict", "summary": "This is equivalent to self.log_pob(input).argmax(dim=1),\nbut is more efficient in some cases.\n\nParameters\ninput (Tensor) \u2013 a minibatch of examples\n\nReturns\na class with the highest probability for each example\n\nReturn type\noutput (Tensor)\n\n\n\nShape:\nInput: (N,in_features)(N, in\\_features)(N,in_features)\n\n\nOutput: (N)(N)(N)\n\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.AdaptiveLogSoftmaxWithLoss.predict", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 a minibatch of examples"}]}},
{"code": "torch.nn.SyncBatchNorm.convert_sync_batchnorm(module,process_group=None)", "id": "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "summary": "Helper function to convert torch.nn.BatchNormND layer in the model to\ntorch.nn.SyncBatchNorm layer.\n\nParameters\n\nmodule (nn.Module) \u2013 containing module\nprocess_group (optional) \u2013 process group to scope synchronization,\n\n\n\ndefault is the whole world\n\nReturns\nThe original module with the converted torch.nn.SyncBatchNorm layer\n\n\nExample:\n&gt;&gt;&gt; # Network with nn.BatchNorm layer\n&gt;&gt;&gt; module = torch.nn.Sequential(\n&gt;&gt;&gt;            torch.nn.Linear(20, 100),\n&gt;&gt;&gt;            torch.nn.BatchNorm1d(100)\n&gt;&gt;&gt;          ).cuda()\n&gt;&gt;&gt; # creating process group (optional)\n&gt;&gt;&gt; # process_ids is a list of int identifying rank ids.\n&gt;&gt;&gt; process_group = torch.distributed.new_group(process_ids)\n&gt;&gt;&gt; sync_bn_module = convert_sync_batchnorm(module, process_group)\n\n\n", "description": "", "code-info": {"name": "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 containing module"}, {"name": "process_group", "is_optional": true, "type": "others", "default_value": "None", "description": "(optional) \u2013 process group to scope synchronization,"}]}},
{"code": "torch.nn.RNNBase.flatten_parameters()", "id": "torch.nn.RNNBase.flatten_parameters", "summary": "Resets parameter data pointer so that they can use faster code paths.\nRight now, this works only if the module is on the GPU and cuDNN is enabled.\nOtherwise, it\u2019s a no-op.\n", "description": "", "code-info": {"name": "torch.nn.RNNBase.flatten_parameters", "parameters": []}},
{"code": "torch.nn.Transformer.forward(src,tgt,src_mask=None,tgt_mask=None,memory_mask=None,src_key_padding_mask=None,tgt_key_padding_mask=None,memory_key_padding_mask=None)", "id": "torch.nn.Transformer.forward", "summary": "Take in and process masked source/target sequences.\n\nParameters\n\nsrc \u2013 the sequence to the encoder (required).\ntgt \u2013 the sequence to the decoder (required).\nsrc_mask \u2013 the additive mask for the src sequence (optional).\ntgt_mask \u2013 the additive mask for the tgt sequence (optional).\nmemory_mask \u2013 the additive mask for the encoder output (optional).\nsrc_key_padding_mask \u2013 the ByteTensor mask for src keys per batch (optional).\ntgt_key_padding_mask \u2013 the ByteTensor mask for tgt keys per batch (optional).\nmemory_key_padding_mask \u2013 the ByteTensor mask for memory keys per batch (optional).\n\n\n\n\nShape:\nsrc: (S,N,E)(S, N, E)(S,N,E)\n\n.\ntgt: (T,N,E)(T, N, E)(T,N,E)\n\n.\nsrc_mask: (S,S)(S, S)(S,S)\n\n.\ntgt_mask: (T,T)(T, T)(T,T)\n\n.\nmemory_mask: (T,S)(T, S)(T,S)\n\n.\nsrc_key_padding_mask: (N,S)(N, S)(N,S)\n\n.\ntgt_key_padding_mask: (N,T)(N, T)(N,T)\n\n.\nmemory_key_padding_mask: (N,S)(N, S)(N,S)\n\n.\n\nNote: [src/tgt/memory]_mask should be filled with\nfloat(\u2018-inf\u2019) for the masked positions and float(0.0) else", "description": "", "code-info": {"name": "torch.nn.Transformer.forward", "parameters": [{"name": "src", "is_optional": false, "type": "others", "description": ""}, {"name": "tgt", "is_optional": false, "type": "others", "description": ""}, {"name": "src_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "tgt_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "memory_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "src_key_padding_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "tgt_key_padding_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "memory_key_padding_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.Transformer.generate_square_subsequent_mask(sz)", "id": "torch.nn.Transformer.generate_square_subsequent_mask", "summary": "Generate a square mask for the sequence", "description": "", "code-info": {"name": "torch.nn.Transformer.generate_square_subsequent_mask", "parameters": [{"name": "sz", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.TransformerEncoder.forward(src,mask=None,src_key_padding_mask=None)", "id": "torch.nn.TransformerEncoder.forward", "summary": "Pass the input through the encoder layers in turn.\n\nParameters\n\nsrc \u2013 the sequnce to the encoder (required).\nmask \u2013 the mask for the src sequence (optional).\nsrc_key_padding_mask \u2013 the mask for the src keys per batch (optional).\n\n\n\n\nShape:see the docs in Transformer class.\n\n\n", "description": "", "code-info": {"name": "torch.nn.TransformerEncoder.forward", "parameters": [{"name": "src", "is_optional": false, "type": "others", "description": ""}, {"name": "mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "src_key_padding_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.TransformerDecoder.forward(tgt,memory,tgt_mask=None,memory_mask=None,tgt_key_padding_mask=None,memory_key_padding_mask=None)", "id": "torch.nn.TransformerDecoder.forward", "summary": "Pass the inputs (and mask) through the decoder layer in turn.\n\nParameters\n\ntgt \u2013 the sequence to the decoder (required).\nmemory \u2013 the sequnce from the last layer of the encoder (required).\ntgt_mask \u2013 the mask for the tgt sequence (optional).\nmemory_mask \u2013 the mask for the memory sequence (optional).\ntgt_key_padding_mask \u2013 the mask for the tgt keys per batch (optional).\nmemory_key_padding_mask \u2013 the mask for the memory keys per batch (optional).\n\n\n\n\nShape:see the docs in Transformer class.\n\n\n", "description": "", "code-info": {"name": "torch.nn.TransformerDecoder.forward", "parameters": [{"name": "tgt", "is_optional": false, "type": "others", "description": ""}, {"name": "memory", "is_optional": false, "type": "others", "description": ""}, {"name": "tgt_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "memory_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "tgt_key_padding_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "memory_key_padding_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.TransformerEncoderLayer.forward(src,src_mask=None,src_key_padding_mask=None)", "id": "torch.nn.TransformerEncoderLayer.forward", "summary": "Pass the input through the encoder layer.\n\nParameters\n\nsrc \u2013 the sequnce to the encoder layer (required).\nsrc_mask \u2013 the mask for the src sequence (optional).\nsrc_key_padding_mask \u2013 the mask for the src keys per batch (optional).\n\n\n\n\nShape:see the docs in Transformer class.\n\n\n", "description": "", "code-info": {"name": "torch.nn.TransformerEncoderLayer.forward", "parameters": [{"name": "src", "is_optional": false, "type": "others", "description": ""}, {"name": "src_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "src_key_padding_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.TransformerDecoderLayer.forward(tgt,memory,tgt_mask=None,memory_mask=None,tgt_key_padding_mask=None,memory_key_padding_mask=None)", "id": "torch.nn.TransformerDecoderLayer.forward", "summary": "Pass the inputs (and mask) through the decoder layer.\n\nParameters\n\ntgt \u2013 the sequence to the decoder layer (required).\nmemory \u2013 the sequnce from the last layer of the encoder (required).\ntgt_mask \u2013 the mask for the tgt sequence (optional).\nmemory_mask \u2013 the mask for the memory sequence (optional).\ntgt_key_padding_mask \u2013 the mask for the tgt keys per batch (optional).\nmemory_key_padding_mask \u2013 the mask for the memory keys per batch (optional).\n\n\n\n\nShape:see the docs in Transformer class.\n\n\n", "description": "", "code-info": {"name": "torch.nn.TransformerDecoderLayer.forward", "parameters": [{"name": "tgt", "is_optional": false, "type": "others", "description": ""}, {"name": "memory", "is_optional": false, "type": "others", "description": ""}, {"name": "tgt_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "memory_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "tgt_key_padding_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "memory_key_padding_mask", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.Embedding.from_pretrained(embeddings,freeze=True,padding_idx=None,max_norm=None,norm_type=2.0,scale_grad_by_freq=False,sparse=False)", "id": "torch.nn.Embedding.from_pretrained", "summary": "Creates Embedding instance from given 2-dimensional FloatTensor.\n\nParameters\n\nembeddings (Tensor) \u2013 FloatTensor containing weights for the Embedding.\nFirst dimension is being passed to Embedding as num_embeddings, second as embedding_dim.\nfreeze (boolean, optional) \u2013 If True, the tensor does not get updated in the learning process.\nEquivalent to embedding.weight.requires_grad = False", "description": "", "code-info": {"name": "torch.nn.Embedding.from_pretrained", "parameters": [{"name": "embeddings", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 FloatTensor containing weights for the Embedding.\nFirst dimension is being passed to Embedding as num_embeddings, second as embedding_dim."}, {"name": "freeze", "is_optional": true, "type": "bool", "default_value": "True", "description": "(boolean, optional) \u2013 If True, the tensor does not get updated in the learning process.\nEquivalent to embedding.weight.requires_grad = False. Default: True"}, {"name": "padding_idx", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 See module initialization documentation."}, {"name": "max_norm", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float, optional) \u2013 See module initialization documentation."}, {"name": "norm_type", "is_optional": true, "type": "float", "default_value": "2.0", "description": "(python:float, optional) \u2013 See module initialization documentation. Default 2."}, {"name": "scale_grad_by_freq", "is_optional": true, "type": "bool", "default_value": "False", "description": "(boolean, optional) \u2013 See module initialization documentation. Default False."}, {"name": "sparse", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 See module initialization documentation."}]}},
{"code": "torch.Tensor.lgamma()", "id": "torch.Tensor.lgamma", "summary": "See torch.lgamma()\n", "description": "", "code-info": {"name": "torch.Tensor.lgamma", "parameters": []}},
{"code": "torch.Tensor.lgamma_()", "id": "torch.Tensor.lgamma_", "summary": "In-place version of lgamma()\n", "description": "", "code-info": {"name": "torch.Tensor.lgamma_", "parameters": []}},
{"code": "torch.Tensor.log()", "id": "torch.Tensor.log", "summary": "See torch.log()\n", "description": "", "code-info": {"name": "torch.Tensor.log", "parameters": []}},
{"code": "torch.Tensor.log_()", "id": "torch.Tensor.log_", "summary": "In-place version of log()\n", "description": "", "code-info": {"name": "torch.Tensor.log_", "parameters": []}},
{"code": "torch.Tensor.logdet()", "id": "torch.Tensor.logdet", "summary": "See torch.logdet()\n", "description": "", "code-info": {"name": "torch.Tensor.logdet", "parameters": []}},
{"code": "torch.Tensor.log10()", "id": "torch.Tensor.log10", "summary": "See torch.log10()\n", "description": "", "code-info": {"name": "torch.Tensor.log10", "parameters": []}},
{"code": "torch.Tensor.log10_()", "id": "torch.Tensor.log10_", "summary": "In-place version of log10()\n", "description": "", "code-info": {"name": "torch.Tensor.log10_", "parameters": []}},
{"code": "torch.Tensor.log1p()", "id": "torch.Tensor.log1p", "summary": "See torch.log1p()\n", "description": "", "code-info": {"name": "torch.Tensor.log1p", "parameters": []}},
{"code": "torch.Tensor.log1p_()", "id": "torch.Tensor.log1p_", "summary": "In-place version of log1p()\n", "description": "", "code-info": {"name": "torch.Tensor.log1p_", "parameters": []}},
{"code": "torch.Tensor.log2()", "id": "torch.Tensor.log2", "summary": "See torch.log2()\n", "description": "", "code-info": {"name": "torch.Tensor.log2", "parameters": []}},
{"code": "torch.Tensor.log2_()", "id": "torch.Tensor.log2_", "summary": "In-place version of log2()\n", "description": "", "code-info": {"name": "torch.Tensor.log2_", "parameters": []}},
{"code": "torch.Tensor.log_normal_(mean=1,std=2,*,generator=None)", "id": "torch.Tensor.log_normal_", "summary": "Fills self tensor with numbers samples from the log-normal distribution\nparameterized by the given mean \u03bc\\mu\u03bc\n\n and standard deviation\n\u03c3\\sigma\u03c3\n\n", "description": "", "code-info": {"name": "torch.Tensor.log_normal_", "parameters": [{"name": "mean", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "std", "is_optional": true, "type": "int", "default_value": "2", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.logsumexp(dim,keepdim=False)", "id": "torch.Tensor.logsumexp", "summary": "See torch.logsumexp()\n", "description": "", "code-info": {"name": "torch.Tensor.logsumexp", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.logical_not()", "id": "torch.Tensor.logical_not", "summary": "See torch.logical_not()\n", "description": "", "code-info": {"name": "torch.Tensor.logical_not", "parameters": []}},
{"code": "torch.Tensor.logical_not_()", "id": "torch.Tensor.logical_not_", "summary": "In-place version of logical_not()\n", "description": "", "code-info": {"name": "torch.Tensor.logical_not_", "parameters": []}},
{"code": "torch.Tensor.logical_xor()", "id": "torch.Tensor.logical_xor", "summary": "See torch.logical_xor()\n", "description": "", "code-info": {"name": "torch.Tensor.logical_xor", "parameters": []}},
{"code": "torch.Tensor.logical_xor_()", "id": "torch.Tensor.logical_xor_", "summary": "In-place version of logical_xor()\n", "description": "", "code-info": {"name": "torch.Tensor.logical_xor_", "parameters": []}},
{"code": "torch.Tensor.long()", "id": "torch.Tensor.long", "summary": "self.long() is equivalent to self.to(torch.int64)", "description": "", "code-info": {"name": "torch.Tensor.long", "parameters": []}},
{"code": "torch.Tensor.lstsq(A)", "id": "torch.Tensor.lstsq", "summary": "See torch.lstsq()\n", "description": "", "code-info": {"name": "torch.Tensor.lstsq", "parameters": [{"name": "A", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.lt(other)", "id": "torch.Tensor.lt", "summary": "See torch.lt()\n", "description": "", "code-info": {"name": "torch.Tensor.lt", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.lt_(other)", "id": "torch.Tensor.lt_", "summary": "In-place version of lt()\n", "description": "", "code-info": {"name": "torch.Tensor.lt_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.lu(pivot=True,get_infos=False)", "id": "torch.Tensor.lu", "summary": "See torch.lu()\n", "description": "", "code-info": {"name": "torch.Tensor.lu", "parameters": [{"name": "pivot", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "get_infos", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "sig-prename descclassname(input,alpha=1,other,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.addcdiv(input,value=1,tensor1,tensor2,out=None)", "id": "torch.addcdiv", "summary": "Performs the element-wise division of tensor1 by tensor2,\nmultiply the result by the scalar value and add it to input.\n\nouti=inputi+value\u00d7tensor1itensor2i\\text{out}_i = \\text{input}_i + \\text{value} \\times \\frac{\\text{tensor1}_i}{\\text{tensor2}_i}\n\nouti\u200b=inputi\u200b+value\u00d7tensor2i\u200btensor1i\u200b\u200b\n\nThe shapes of input, tensor1, and tensor2 must be\nbroadcastable.\nFor inputs of type FloatTensor or DoubleTensor, value must be\na real number, otherwise an integer.\n\nParameters\n\ninput (Tensor) \u2013 the tensor to be added\nvalue (Number, optional) \u2013 multiplier for tensor1/tensor2\\text{tensor1} / \\text{tensor2}tensor1/tensor2\n\n\ntensor1 (Tensor) \u2013 the numerator tensor\ntensor2 (Tensor) \u2013 the denominator tensor\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; t = torch.randn(1, 3)\n&gt;&gt;&gt; t1 = torch.randn(3, 1)\n&gt;&gt;&gt; t2 = torch.randn(1, 3)\n&gt;&gt;&gt; torch.addcdiv(t, 0.1, t1, t2)\ntensor([[-0.2312, -3.6496,  0.1312],\n        [-1.0428,  3.4292, -0.1030],\n        [-0.5369, -0.9829,  0.0430]])\n\n\n", "description": "", "code-info": {"name": "torch.addcdiv", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to be added"}, {"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for tensor1/tensor2\\text{tensor1} / \\text{tensor2}tensor1/tensor2\n\n"}, {"name": "tensor1", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the numerator tensor"}, {"name": "tensor2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the denominator tensor"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.addcmul(input,value=1,tensor1,tensor2,out=None)", "id": "torch.addcmul", "summary": "Performs the element-wise multiplication of tensor1\nby tensor2, multiply the result by the scalar value\nand add it to input.\n\nouti=inputi+value\u00d7tensor1i\u00d7tensor2i\\text{out}_i = \\text{input}_i + \\text{value} \\times \\text{tensor1}_i \\times \\text{tensor2}_i\n\nouti\u200b=inputi\u200b+value\u00d7tensor1i\u200b\u00d7tensor2i\u200b\n\nThe shapes of tensor, tensor1, and tensor2 must be\nbroadcastable.\nFor inputs of type FloatTensor or DoubleTensor, value must be\na real number, otherwise an integer.\n\nParameters\n\ninput (Tensor) \u2013 the tensor to be added\nvalue (Number, optional) \u2013 multiplier for tensor1.\u2217tensor2tensor1 .* tensor2tensor1.\u2217tensor2\n\n\ntensor1 (Tensor) \u2013 the tensor to be multiplied\ntensor2 (Tensor) \u2013 the tensor to be multiplied\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; t = torch.randn(1, 3)\n&gt;&gt;&gt; t1 = torch.randn(3, 1)\n&gt;&gt;&gt; t2 = torch.randn(1, 3)\n&gt;&gt;&gt; torch.addcmul(t, 0.1, t1, t2)\ntensor([[-0.8635, -0.6391,  1.6174],\n        [-0.7617, -0.5879,  1.7388],\n        [-0.8353, -0.6249,  1.6511]])\n\n\n", "description": "", "code-info": {"name": "torch.addcmul", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to be added"}, {"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for tensor1.\u2217tensor2tensor1 .* tensor2tensor1.\u2217tensor2\n\n"}, {"name": "tensor1", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to be multiplied"}, {"name": "tensor2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to be multiplied"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.angle(input,out=None)", "id": "torch.angle", "summary": "Computes the element-wise angle (in radians) of the given input tensor.\n\nouti=angle(inputi)\\text{out}_{i} = angle(\\text{input}_{i})\n\nouti\u200b=angle(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; torch.angle(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))*180/3.14159\ntensor([ 135.,  135,  -45])\n\n\n", "description": "", "code-info": {"name": "torch.angle", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.asin(input,out=None)", "id": "torch.asin", "summary": "Returns a new tensor with the arcsine  of the elements of input.\n\nouti=sin\u2061\u22121(inputi)\\text{out}_{i} = \\sin^{-1}(\\text{input}_{i})\n\nouti\u200b=sin\u22121(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([-0.5962,  1.4985, -0.4396,  1.4525])\n&gt;&gt;&gt; torch.asin(a)\ntensor([-0.6387,     nan, -0.4552,     nan])\n\n\n", "description": "", "code-info": {"name": "torch.asin", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.atan(input,out=None)", "id": "torch.atan", "summary": "Returns a new tensor with the arctangent  of the elements of input.\n\nouti=tan\u2061\u22121(inputi)\\text{out}_{i} = \\tan^{-1}(\\text{input}_{i})\n\nouti\u200b=tan\u22121(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 0.2341,  0.2539, -0.6256, -0.6448])\n&gt;&gt;&gt; torch.atan(a)\ntensor([ 0.2299,  0.2487, -0.5591, -0.5727])\n\n\n", "description": "", "code-info": {"name": "torch.atan", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.atan2(input,other,out=None)", "id": "torch.atan2", "summary": "Element-wise arctangent of inputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200b\n\n\nwith consideration of the quadrant", "description": "", "code-info": {"name": "torch.atan2", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the first input tensor"}, {"name": "other", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the second input tensor"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.bitwise_not(input,out=None)", "id": "torch.bitwise_not", "summary": "Computes the bitwise NOT of the given input tensor", "description": "", "code-info": {"name": "torch.bitwise_not", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.bitwise_xor(input,other,out=None)", "id": "torch.bitwise_xor", "summary": "Computes the bitwise XOR of input and other", "description": "", "code-info": {"name": "torch.bitwise_xor", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.ceil(input,out=None)", "id": "torch.ceil", "summary": "Returns a new tensor with the ceil of the elements of input,\nthe smallest integer greater than or equal to each element.\n\nouti=\u2308inputi\u2309=\u230ainputi\u230b+1\\text{out}_{i} = \\left\\lceil \\text{input}_{i} \\right\\rceil = \\left\\lfloor \\text{input}_{i} \\right\\rfloor + 1\n\nouti\u200b=\u2308inputi\u200b\u2309=\u230ainputi\u200b\u230b+1\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([-0.6341, -1.4208, -1.0900,  0.5826])\n&gt;&gt;&gt; torch.ceil(a)\ntensor([-0., -1., -1.,  1.])\n\n\n", "description": "", "code-info": {"name": "torch.ceil", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.clamp(input,min,max,out=None)", "id": "torch.clamp", "summary": "Clamp all elements in input into the range [ min, max ] and return\na resulting tensor:\n\nyi={minif\u00a0xi&lt;minxiif\u00a0min\u2264xi\u2264maxmaxif\u00a0xi&gt;maxy_i = \\begin{cases}\n    \\text{min} &amp; \\text{if } x_i &lt; \\text{min} \\\\\n    x_i &amp; \\text{if } \\text{min} \\leq x_i \\leq \\text{max} \\\\\n    \\text{max} &amp; \\text{if } x_i &gt; \\text{max}\n\\end{cases}\n\nyi\u200b=\u23a9\u23aa\u23aa\u23a8\u23aa\u23aa\u23a7\u200bminxi\u200bmax\u200bif\u00a0xi\u200b&lt;minif\u00a0min\u2264xi\u200b\u2264maxif\u00a0xi\u200b&gt;max\u200b\n\nIf input is of type FloatTensor or DoubleTensor, args min\nand max must be real numbers, otherwise they should be integers.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nmin (Number) \u2013 lower-bound of the range to be clamped to\nmax (Number) \u2013 upper-bound of the range to be clamped to\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([-1.7120,  0.1734, -0.0478, -0.0922])\n&gt;&gt;&gt; torch.clamp(a, min=-0.5, max=0.5)\ntensor([-0.5000,  0.1734, -0.0478, -0.0922])\n\n\n\n\ntorch.clamp(input, *, min, out=None) \u2192 Tensor\n\n\nClamps all elements in input to be larger or equal min.\nIf input is of type FloatTensor or DoubleTensor, value\nshould be a real number, otherwise it should be an integer.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nvalue (Number) \u2013 minimal value of each element in the output\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([-0.0299, -2.3184,  2.1593, -0.8883])\n&gt;&gt;&gt; torch.clamp(a, min=0.5)\ntensor([ 0.5000,  0.5000,  2.1593,  0.5000])\n\n\n\n\ntorch.clamp(input, *, max, out=None) \u2192 Tensor\n\n\nClamps all elements in input to be smaller or equal max.\nIf input is of type FloatTensor or DoubleTensor, value\nshould be a real number, otherwise it should be an integer.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nvalue (Number) \u2013 maximal value of each element in the output\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 0.7753, -0.4702, -0.4599,  1.1899])\n&gt;&gt;&gt; torch.clamp(a, max=0.5)\ntensor([ 0.5000, -0.4702, -0.4599,  0.5000])\n\n\n", "description": "", "code-info": {"name": "torch.clamp", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "min", "is_optional": false, "type": "others", "description": "(Number) \u2013 lower-bound of the range to be clamped to"}, {"name": "max", "is_optional": false, "type": "others", "description": "(Number) \u2013 upper-bound of the range to be clamped to"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.distributions.transforms.Transform.log_abs_det_jacobian(x,y)", "id": "torch.distributions.transforms.Transform.log_abs_det_jacobian", "summary": "Computes the log det jacobian log |dy/dx| given input and output.\n", "description": "", "code-info": {"name": "torch.distributions.transforms.Transform.log_abs_det_jacobian", "parameters": [{"name": "x", "is_optional": false, "type": "others", "description": ""}, {"name": "y", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.constraints.Constraint.check(value)", "id": "torch.distributions.constraints.Constraint.check", "summary": "Returns a byte tensor of sample_shape + batch_shape indicating\nwhether each event in value satisfies this constraint.\n", "description": "", "code-info": {"name": "torch.distributions.constraints.Constraint.check", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.distributions.constraint_registry.ConstraintRegistry.register(constraint,factory=None)", "id": "torch.distributions.constraint_registry.ConstraintRegistry.register", "summary": "Registers a Constraint\nsubclass in this registry", "description": "", "code-info": {"name": "torch.distributions.constraint_registry.ConstraintRegistry.register", "parameters": [{"name": "constraint", "is_optional": false, "type": "int", "description": "(subclass of Constraint) \u2013 A subclass of Constraint, or\na singleton object of the desired class."}, {"name": "factory", "is_optional": true, "type": "others", "default_value": "None", "description": "(callable) \u2013 A callable that inputs a constraint object and returns\na  Transform object."}]}},
{"code": "torch.distributions.distribution.Distribution(batch_shape=torch.Size([])", "id": "torch.distributions.distribution.Distribution", "summary": "Bases: object\nDistribution is the abstract base class for probability distributions.\n\n\nproperty arg_constraints\u00b6\nReturns a dictionary from argument names to\nConstraint objects that\nshould be satisfied by each argument of this distribution", "description": "", "code-info": {"name": "torch.distributions.distribution.Distribution", "parameters": [{"name": "batch_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": "(torch.Size) \u2013 the desired expanded size.\n_instance \u2013 new instance provided by subclasses that\nneed to override .expand."}]}},
{"code": "torch.distributions.exp_family.ExponentialFamily(batch_shape=torch.Size([])", "id": "torch.distributions.exp_family.ExponentialFamily", "summary": "Bases: torch.distributions.distribution.Distribution\nExponentialFamily is the abstract base class for probability distributions belonging to an\nexponential family, whose probability mass/density function has the form is defined below\n\npF(x;\u03b8)=exp\u2061(\u27e8t(x),\u03b8\u27e9\u2212F(\u03b8)+k(x))p_{F}(x; \\theta) = \\exp(\\langle t(x), \\theta\\rangle - F(\\theta) + k(x))pF\u200b(x;\u03b8)=exp(\u27e8t(x),\u03b8\u27e9\u2212F(\u03b8)+k(x))\n\nwhere \u03b8\\theta\u03b8\n\n denotes the natural parameters, t(x)t(x)t(x)\n\n denotes the sufficient statistic,\nF(\u03b8)F(\\theta)F(\u03b8)\n\n is the log normalizer function for a given family and k(x)k(x)k(x)\n\n is the carrier\nmeasure.\n\nNote\nThis class is an intermediary between the Distribution class and distributions which belong\nto an exponential family mainly to check the correctness of the .entropy() and analytic KL\ndivergence methods", "description": "", "code-info": {"name": "torch.distributions.exp_family.ExponentialFamily", "parameters": [{"name": "batch_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"code": "torch.distributions.bernoulli.Bernoulli(probs=None,logits=None,validate_args=None)", "id": "torch.distributions.bernoulli.Bernoulli", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily\nCreates a Bernoulli distribution parameterized by probs\nor logits (but not both).\nSamples are binary (0 or 1)", "description": "", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli", "parameters": [{"name": "probs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Number, Tensor) \u2013 the probability of sampling 1"}, {"name": "logits", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.beta.Beta(concentration1,concentration0,validate_args=None)", "id": "torch.distributions.beta.Beta", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily\nBeta distribution parameterized by concentration1 and concentration0.\nExample:\n&gt;&gt;&gt; m = Beta(torch.tensor([0.5]), torch.tensor([0.5]))\n&gt;&gt;&gt; m.sample()  # Beta distributed with concentration concentration1 and concentration0\ntensor([ 0.1046])\n\n\n\nParameters\n\nconcentration1 (python:float or Tensor) \u2013 1st concentration parameter of the distribution\n(often referred to as alpha)\nconcentration0 (python:float or Tensor) \u2013 2nd concentration parameter of the distribution\n(often referred to as beta)\n\n\n\n\n\narg_constraints = {'concentration0': GreaterThan(lower_bound=0.0), 'concentration1': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\nproperty concentration0\u00b6\n\n\n\n\nproperty concentration1\u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nrsample(sample_shape=()) \u00b6\n\n\n\n\nsupport = Interval(lower_bound=0.0, upper_bound=1.0)\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.beta.Beta", "parameters": [{"name": "concentration1", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 1st concentration parameter of the distribution\n(often referred to as alpha)"}, {"name": "concentration0", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.binomial.Binomial(total_count=1,probs=None,logits=None,validate_args=None)", "id": "torch.distributions.binomial.Binomial", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a Binomial distribution parameterized by total_count and\neither probs or logits (but not both)", "description": "", "code-info": {"name": "torch.distributions.binomial.Binomial", "parameters": [{"name": "total_count", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or Tensor) \u2013 number of Bernoulli trials"}, {"name": "probs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor) \u2013 Event probabilities"}, {"name": "logits", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.EmbeddingBag.from_pretrained(embeddings,freeze=True,max_norm=None,norm_type=2.0,scale_grad_by_freq=False,mode='mean',sparse=False)", "id": "torch.nn.EmbeddingBag.from_pretrained", "summary": "Creates EmbeddingBag instance from given 2-dimensional FloatTensor.\n\nParameters\n\nembeddings (Tensor) \u2013 FloatTensor containing weights for the EmbeddingBag.\nFirst dimension is being passed to EmbeddingBag as \u2018num_embeddings\u2019, second as \u2018embedding_dim\u2019.\nfreeze (boolean, optional) \u2013 If True, the tensor does not get updated in the learning process.\nEquivalent to embeddingbag.weight.requires_grad = False", "description": "", "code-info": {"name": "torch.nn.EmbeddingBag.from_pretrained", "parameters": [{"name": "embeddings", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 FloatTensor containing weights for the EmbeddingBag.\nFirst dimension is being passed to EmbeddingBag as \u2018num_embeddings\u2019, second as \u2018embedding_dim\u2019."}, {"name": "freeze", "is_optional": true, "type": "bool", "default_value": "True", "description": "(boolean, optional) \u2013 If True, the tensor does not get updated in the learning process.\nEquivalent to embeddingbag.weight.requires_grad = False. Default: True"}, {"name": "max_norm", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float, optional) \u2013 See module initialization documentation. Default: None"}, {"name": "norm_type", "is_optional": true, "type": "float", "default_value": "2.0", "description": "(python:float, optional) \u2013 See module initialization documentation. Default 2."}, {"name": "scale_grad_by_freq", "is_optional": true, "type": "bool", "default_value": "False", "description": "(boolean, optional) \u2013 See module initialization documentation. Default False."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 See module initialization documentation. Default: \"mean\""}, {"name": "sparse", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 See module initialization documentation. Default: False."}]}},
{"code": "torch.nn.parallel.DistributedDataParallel.no_sync()", "id": "torch.nn.parallel.DistributedDataParallel.no_sync", "summary": "A context manager to disable gradient synchronizations across DDP\nprocesses", "description": "", "code-info": {"name": "torch.nn.parallel.DistributedDataParallel.no_sync", "parameters": []}},
{"code": "torch.nn.utils.prune.BasePruningMethod.apply(module,name,*args,**kwargs)", "id": "torch.nn.utils.prune.BasePruningMethod.apply", "summary": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\nargs \u2013 arguments passed on to a subclass of\nBasePruningMethod\nkwargs \u2013 keyword arguments passed on to a subclass of a\nBasePruningMethod\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.BasePruningMethod.apply", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": ""}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.utils.prune.BasePruningMethod.apply_mask(module)", "id": "torch.nn.utils.prune.BasePruningMethod.apply_mask", "summary": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\n\nParameters\nmodule (nn.Module) \u2013 module containing the tensor to prune\n\nReturns\npruned version of the input tensor\n\nReturn type\npruned_tensor (torch.Tensor)\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.BasePruningMethod.apply_mask", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}]}},
{"code": "torch.nn.utils.prune.BasePruningMethod.compute_mask(t,default_mask)", "id": "torch.nn.utils.prune.BasePruningMethod.compute_mask", "summary": "Computes and returns a mask for the input tensor t.\nStarting from a base default_mask (which should be a mask of ones\nif the tensor has not been pruned yet), generate a random mask to\napply on top of the default_mask according to the specific pruning\nmethod recipe.\n\nParameters\n\nt (torch.Tensor) \u2013 tensor representing the parameter to prune\ndefault_mask (torch.Tensor) \u2013 Base mask from previous pruning\niterations, that need to be respected after the new mask is\napplied", "description": "", "code-info": {"name": "torch.nn.utils.prune.BasePruningMethod.compute_mask", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor representing the parameter to prune"}, {"name": "default_mask", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 Base mask from previous pruning\niterations, that need to be respected after the new mask is\napplied. Same dims as t."}]}},
{"code": "torch.nn.utils.prune.BasePruningMethod.prune(t,default_mask=None)", "id": "torch.nn.utils.prune.BasePruningMethod.prune", "summary": "Computes and returns a pruned version of input tensor t\naccording to the pruning rule specified in compute_mask().\n\nParameters\n\nt (torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask).\ndefault_mask (torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any", "description": "", "code-info": {"name": "torch.nn.utils.prune.BasePruningMethod.prune", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask)."}, {"name": "default_mask", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}]}},
{"code": "torch.nn.utils.prune.BasePruningMethod.remove(module)", "id": "torch.nn.utils.prune.BasePruningMethod.remove", "summary": "Removes the pruning reparameterization from a module", "description": "", "code-info": {"name": "torch.nn.utils.prune.BasePruningMethod.remove", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.utils.prune.PruningContainer.add_pruning_method(method)", "id": "torch.nn.utils.prune.PruningContainer.add_pruning_method", "summary": "Adds a child pruning method to the container.\n\nParameters\nmethod (subclass of BasePruningMethod) \u2013 child pruning method\nto be added to the container.\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.add_pruning_method", "parameters": [{"name": "method", "is_optional": false, "type": "others", "description": "(subclass of BasePruningMethod) \u2013 child pruning method\nto be added to the container."}]}},
{"code": "torch.nn.utils.prune.PruningContainer.apply(module,name,*args,**kwargs)", "id": "torch.nn.utils.prune.PruningContainer.apply", "summary": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\nargs \u2013 arguments passed on to a subclass of\nBasePruningMethod\nkwargs \u2013 keyword arguments passed on to a subclass of a\nBasePruningMethod\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.apply", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": ""}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.utils.prune.PruningContainer.apply_mask(module)", "id": "torch.nn.utils.prune.PruningContainer.apply_mask", "summary": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\n\nParameters\nmodule (nn.Module) \u2013 module containing the tensor to prune\n\nReturns\npruned version of the input tensor\n\nReturn type\npruned_tensor (torch.Tensor)\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.apply_mask", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}]}},
{"code": "torch.nn.utils.prune.PruningContainer.compute_mask(t,default_mask)", "id": "torch.nn.utils.prune.PruningContainer.compute_mask", "summary": "Applies the latest method by computing the new partial masks\nand returning its combination with the default_mask.\nThe new partial mask should be computed on the entries or channels\nthat were not zeroed out by the default_mask.\nWhich portions of the tensor t the new mask will be calculated from\ndepends on the PRUNING_TYPE (handled by the type handler):\n\n\nfor \u2018unstructured\u2019, the mask will be computed from the raveled\n\nlist of nonmasked entries;\n\nfor \u2018structured\u2019, the mask will be computed from the nonmasked\n\nchannels in the tensor;\n\nfor \u2018global\u2019, the mask will be computed across all entries.\n\n\n\nParameters\n\nt (torch.Tensor) \u2013 tensor representing the parameter to prune\n(of same dimensions as default_mask).\ndefault_mask (torch.Tensor) \u2013 mask from previous pruning iteration.\n\n\nReturns\nnew mask that combines the effects\nof the default_mask and the new mask from the current\npruning method (of same dimensions as default_mask and\nt).\n\nReturn type\nmask (torch.Tensor)\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.compute_mask", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor representing the parameter to prune\n(of same dimensions as default_mask)."}, {"name": "default_mask", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 mask from previous pruning iteration."}]}},
{"code": "torch.nn.utils.prune.PruningContainer.prune(t,default_mask=None)", "id": "torch.nn.utils.prune.PruningContainer.prune", "summary": "Computes and returns a pruned version of input tensor t\naccording to the pruning rule specified in compute_mask().\n\nParameters\n\nt (torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask).\ndefault_mask (torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any", "description": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.prune", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask)."}, {"name": "default_mask", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}]}},
{"code": "torch.nn.utils.prune.PruningContainer.remove(module)", "id": "torch.nn.utils.prune.PruningContainer.remove", "summary": "Removes the pruning reparameterization from a module", "description": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.remove", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.utils.prune.Identity.apply(module,name)", "id": "torch.nn.utils.prune.Identity.apply", "summary": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.Identity.apply", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}]}},
{"code": "torch.nn.utils.prune.Identity.apply_mask(module)", "id": "torch.nn.utils.prune.Identity.apply_mask", "summary": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\n\nParameters\nmodule (nn.Module) \u2013 module containing the tensor to prune\n\nReturns\npruned version of the input tensor\n\nReturn type\npruned_tensor (torch.Tensor)\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.Identity.apply_mask", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}]}},
{"code": "torch.nn.utils.prune.Identity.prune(t,default_mask=None)", "id": "torch.nn.utils.prune.Identity.prune", "summary": "Computes and returns a pruned version of input tensor t\naccording to the pruning rule specified in compute_mask().\n\nParameters\n\nt (torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask).\ndefault_mask (torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any", "description": "", "code-info": {"name": "torch.nn.utils.prune.Identity.prune", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask)."}, {"name": "default_mask", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}]}},
{"code": "torch.nn.utils.prune.Identity.remove(module)", "id": "torch.nn.utils.prune.Identity.remove", "summary": "Removes the pruning reparameterization from a module", "description": "", "code-info": {"name": "torch.nn.utils.prune.Identity.remove", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.lu_solve(LU_data,LU_pivots)", "id": "torch.Tensor.lu_solve", "summary": "See torch.lu_solve()\n", "description": "", "code-info": {"name": "torch.Tensor.lu_solve", "parameters": [{"name": "LU_data", "is_optional": false, "type": "others", "description": ""}, {"name": "LU_pivots", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.map_(tensor,callable)", "id": "torch.Tensor.map_", "summary": "Applies callable for each element in self tensor and the given\ntensor and stores the results in self tensor", "description": "", "code-info": {"name": "torch.Tensor.map_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "callable", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.masked_scatter_(mask,source)", "id": "torch.Tensor.masked_scatter_", "summary": "Copies elements from source into self tensor at positions where\nthe mask is True.\nThe shape of mask must be broadcastable\nwith the shape of the underlying tensor", "description": "", "code-info": {"name": "torch.Tensor.masked_scatter_", "parameters": [{"name": "mask", "is_optional": false, "type": "tensor", "description": "(BoolTensor) \u2013 the boolean mask"}, {"name": "source", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to copy from"}]}},
{"code": "torch.Tensor.masked_scatter(mask,tensor)", "id": "torch.Tensor.masked_scatter", "summary": "Out-of-place version of torch.Tensor.masked_scatter_()\n", "description": "", "code-info": {"name": "torch.Tensor.masked_scatter", "parameters": [{"name": "mask", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.masked_fill_(mask,value)", "id": "torch.Tensor.masked_fill_", "summary": "Fills elements of self tensor with value where mask is\nTrue", "description": "", "code-info": {"name": "torch.Tensor.masked_fill_", "parameters": [{"name": "mask", "is_optional": false, "type": "tensor", "description": "(BoolTensor) \u2013 the boolean mask"}, {"name": "value", "is_optional": false, "type": "float", "description": "(python:float) \u2013 the value to fill in with"}]}},
{"code": "torch.Tensor.masked_fill(mask,value)", "id": "torch.Tensor.masked_fill", "summary": "Out-of-place version of torch.Tensor.masked_fill_()\n", "description": "", "code-info": {"name": "torch.Tensor.masked_fill", "parameters": [{"name": "mask", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.masked_select(mask)", "id": "torch.Tensor.masked_select", "summary": "See torch.masked_select()\n", "description": "", "code-info": {"name": "torch.Tensor.masked_select", "parameters": [{"name": "mask", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.matmul(tensor2)", "id": "torch.Tensor.matmul", "summary": "See torch.matmul()\n", "description": "", "code-info": {"name": "torch.Tensor.matmul", "parameters": [{"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.matrix_power(n)", "id": "torch.Tensor.matrix_power", "summary": "See torch.matrix_power()\n", "description": "", "code-info": {"name": "torch.Tensor.matrix_power", "parameters": [{"name": "n", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.max(dim=None,keepdim=False)", "id": "torch.Tensor.max", "summary": "See torch.max()\n", "description": "", "code-info": {"name": "torch.Tensor.max", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.mean(dim=None,keepdim=False)", "id": "torch.Tensor.mean", "summary": "See torch.mean()\n", "description": "", "code-info": {"name": "torch.Tensor.mean", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.median(dim=None,keepdim=False)", "id": "torch.Tensor.median", "summary": "See torch.median()\n", "description": "", "code-info": {"name": "torch.Tensor.median", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.min(dim=None,keepdim=False)", "id": "torch.Tensor.min", "summary": "See torch.min()\n", "description": "", "code-info": {"name": "torch.Tensor.min", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.mm(mat2)", "id": "torch.Tensor.mm", "summary": "See torch.mm()\n", "description": "", "code-info": {"name": "torch.Tensor.mm", "parameters": [{"name": "mat2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.mode(dim=None,keepdim=False)", "id": "torch.Tensor.mode", "summary": "See torch.mode()\n", "description": "", "code-info": {"name": "torch.Tensor.mode", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.mul(value)", "id": "torch.Tensor.mul", "summary": "See torch.mul()\n", "description": "", "code-info": {"name": "torch.Tensor.mul", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.mul_(value)", "id": "torch.Tensor.mul_", "summary": "In-place version of mul()\n", "description": "", "code-info": {"name": "torch.Tensor.mul_", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.multinomial(num_samples,replacement=False,*,generator=None)", "id": "torch.Tensor.multinomial", "summary": "See torch.multinomial()\n", "description": "", "code-info": {"name": "torch.Tensor.multinomial", "parameters": [{"name": "num_samples", "is_optional": false, "type": "others", "description": ""}, {"name": "replacement", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.mv(vec)", "id": "torch.Tensor.mv", "summary": "See torch.mv()\n", "description": "", "code-info": {"name": "torch.Tensor.mv", "parameters": [{"name": "vec", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.mvlgamma(p)", "id": "torch.Tensor.mvlgamma", "summary": "See torch.mvlgamma()\n", "description": "", "code-info": {"name": "torch.Tensor.mvlgamma", "parameters": [{"name": "p", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.mvlgamma_(p)", "id": "torch.Tensor.mvlgamma_", "summary": "In-place version of mvlgamma()\n", "description": "", "code-info": {"name": "torch.Tensor.mvlgamma_", "parameters": [{"name": "p", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.narrow(dimension,start,length)", "id": "torch.Tensor.narrow", "summary": "See torch.narrow()\nExample:\n&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n&gt;&gt;&gt; x.narrow(0, 0, 2)\ntensor([[ 1,  2,  3],\n        [ 4,  5,  6]])\n&gt;&gt;&gt; x.narrow(1, 1, 2)\ntensor([[ 2,  3],\n        [ 5,  6],\n        [ 8,  9]])\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.narrow", "parameters": [{"name": "dimension", "is_optional": false, "type": "others", "description": ""}, {"name": "start", "is_optional": false, "type": "others", "description": ""}, {"name": "length", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-prename descclassname(input,*,min,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "min", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-prename descclassname(input,*,max,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "max", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.conj(input,out=None)", "id": "torch.conj", "summary": "Computes the element-wise conjugate of the given input tensor.\n\nouti=conj(inputi)\\text{out}_{i} = conj(\\text{input}_{i})\n\nouti\u200b=conj(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; torch.conj(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))\ntensor([-1 - 1j, -2 - 2j, 3 + 3j])\n\n\n", "description": "", "code-info": {"name": "torch.conj", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.cos(input,out=None)", "id": "torch.cos", "summary": "Returns a new tensor with the cosine  of the elements of input.\n\nouti=cos\u2061(inputi)\\text{out}_{i} = \\cos(\\text{input}_{i})\n\nouti\u200b=cos(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 1.4309,  1.2706, -0.8562,  0.9796])\n&gt;&gt;&gt; torch.cos(a)\ntensor([ 0.1395,  0.2957,  0.6553,  0.5574])\n\n\n", "description": "", "code-info": {"name": "torch.cos", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.cosh(input,out=None)", "id": "torch.cosh", "summary": "Returns a new tensor with the hyperbolic cosine  of the elements of\ninput.\n\nouti=cosh\u2061(inputi)\\text{out}_{i} = \\cosh(\\text{input}_{i})\n\nouti\u200b=cosh(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 0.1632,  1.1835, -0.6979, -0.7325])\n&gt;&gt;&gt; torch.cosh(a)\ntensor([ 1.0133,  1.7860,  1.2536,  1.2805])\n\n\n", "description": "", "code-info": {"name": "torch.cosh", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.div()", "id": "torch.div", "summary": "\n\ntorch.div(input, other, out=None) \u2192 Tensor\n\n\nDivides each element of the input input with the scalar other and\nreturns a new resulting tensor.\n\nouti=inputiother\\text{out}_i = \\frac{\\text{input}_i}{\\text{other}}\n\nouti\u200b=otherinputi\u200b\u200b\n\nIf the torch.dtype of input and other differ, the\ntorch.dtype of the result tensor is determined following rules\ndescribed in the type promotion documentation", "description": "", "code-info": {"name": "torch.div", "parameters": []}},
{"code": "sig-prename descclassname(input,other,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-prename descclassname(input,other,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.digamma(input,out=None)", "id": "torch.digamma", "summary": "Computes the logarithmic derivative of the gamma function on input.\n\n\u03c8(x)=ddxln\u2061(\u0393(x))=\u0393\u2032(x)\u0393(x)\\psi(x) = \\frac{d}{dx} \\ln\\left(\\Gamma\\left(x\\right)\\right) = \\frac{\\Gamma'(x)}{\\Gamma(x)}\n\n\u03c8(x)=dxd\u200bln(\u0393(x))=\u0393(x)\u0393\u2032(x)\u200b\n\n\nParameters\ninput (Tensor) \u2013 the tensor to compute the digamma function on\n\n\nExample:\n&gt;&gt;&gt; a = torch.tensor([1, 0.5])\n&gt;&gt;&gt; torch.digamma(a)\ntensor([-0.5772, -1.9635])\n\n\n", "description": "", "code-info": {"name": "torch.digamma", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.erf(input,out=None)", "id": "torch.erf", "summary": "Computes the error function of each element", "description": "", "code-info": {"name": "torch.erf", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.erfc(input,out=None)", "id": "torch.erfc", "summary": "Computes the complementary error function of each element of input.\nThe complementary error function is defined as follows:\n\nerfc(x)=1\u22122\u03c0\u222b0xe\u2212t2dt\\mathrm{erfc}(x) = 1 - \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2} dt\n\nerfc(x)=1\u2212\u03c0\u200b2\u200b\u222b0x\u200be\u2212t2dt\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; torch.erfc(torch.tensor([0, -1., 10.]))\ntensor([ 1.0000, 1.8427,  0.0000])\n\n\n", "description": "", "code-info": {"name": "torch.erfc", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.distributions.categorical.Categorical(probs=None,logits=None,validate_args=None)", "id": "torch.distributions.categorical.Categorical", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a categorical distribution parameterized by either probs or\nlogits (but not both).\n\nNote\nIt is equivalent to the distribution that torch.multinomial()\nsamples from.\n\nSamples are integers from {0,\u2026,K\u22121}\\{0, \\ldots, K-1\\}{0,\u2026,K\u22121}\n\n where K is probs.size(-1).\nIf probs is 1D with length-K, each element is the relative\nprobability of sampling the class at that index.\nIf probs is 2D, it is treated as a batch of relative probability\nvectors.\n\nNote\nprobs must be non-negative, finite and have a non-zero sum,\nand it will be normalized to sum to 1.\n\nSee also: torch.multinomial()\nExample:\n&gt;&gt;&gt; m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n&gt;&gt;&gt; m.sample()  # equal probability of 0, 1, 2, 3\ntensor(3)\n\n\n\nParameters\n\nprobs (Tensor) \u2013 event probabilities\nlogits (Tensor) \u2013 event log-odds\n\n\n\n\n\narg_constraints = {'logits': Real(), 'probs': Simplex()}\u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nenumerate_support(expand=True) \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_enumerate_support = True\u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nlogits \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nproperty param_shape\u00b6\n\n\n\n\nprobs \u00b6\n\n\n\n\nsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nproperty support\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.categorical.Categorical", "parameters": [{"name": "probs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor) \u2013 event probabilities"}, {"name": "logits", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.cauchy.Cauchy(loc,scale,validate_args=None)", "id": "torch.distributions.cauchy.Cauchy", "summary": "Bases: torch.distributions.distribution.Distribution\nSamples from a Cauchy (Lorentz) distribution", "description": "", "code-info": {"name": "torch.distributions.cauchy.Cauchy", "parameters": [{"name": "loc", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 mode or median of the distribution."}, {"name": "scale", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.chi2.Chi2(df,validate_args=None)", "id": "torch.distributions.chi2.Chi2", "summary": "Bases: torch.distributions.gamma.Gamma\nCreates a Chi2 distribution parameterized by shape parameter df.\nThis is exactly equivalent to Gamma(alpha=0.5*df, beta=0.5)\nExample:\n&gt;&gt;&gt; m = Chi2(torch.tensor([1.0]))\n&gt;&gt;&gt; m.sample()  # Chi2 distributed with shape df=1\ntensor([ 0.1046])\n\n\n\nParameters\ndf (python:float or Tensor) \u2013 shape parameter of the distribution\n\n\n\n\narg_constraints = {'df': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\nproperty df\u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.chi2.Chi2", "parameters": [{"name": "df", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.dirichlet.Dirichlet(concentration,validate_args=None)", "id": "torch.distributions.dirichlet.Dirichlet", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily\nCreates a Dirichlet distribution parameterized by concentration concentration.\nExample:\n&gt;&gt;&gt; m = Dirichlet(torch.tensor([0.5, 0.5]))\n&gt;&gt;&gt; m.sample()  # Dirichlet distributed with concentrarion concentration\ntensor([ 0.1046,  0.8954])\n\n\n\nParameters\nconcentration (Tensor) \u2013 concentration parameter of the distribution\n(often referred to as alpha)\n\n\n\n\narg_constraints = {'concentration': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nrsample(sample_shape=()) \u00b6\n\n\n\n\nsupport = Simplex()\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet", "parameters": [{"name": "concentration", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.exponential.Exponential(rate,validate_args=None)", "id": "torch.distributions.exponential.Exponential", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily\nCreates a Exponential distribution parameterized by rate.\nExample:\n&gt;&gt;&gt; m = Exponential(torch.tensor([1.0]))\n&gt;&gt;&gt; m.sample()  # Exponential distributed with rate=1\ntensor([ 0.1046])\n\n\n\nParameters\nrate (python:float or Tensor) \u2013 rate = 1 / scale of the distribution\n\n\n\n\narg_constraints = {'rate': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\ncdf(value) \u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nicdf(value) \u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nrsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nproperty stddev\u00b6\n\n\n\n\nsupport = GreaterThan(lower_bound=0.0)\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.exponential.Exponential", "parameters": [{"name": "rate", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.fishersnedecor.FisherSnedecor(df1,df2,validate_args=None)", "id": "torch.distributions.fishersnedecor.FisherSnedecor", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a Fisher-Snedecor distribution parameterized by df1 and df2.\nExample:\n&gt;&gt;&gt; m = FisherSnedecor(torch.tensor([1.0]), torch.tensor([2.0]))\n&gt;&gt;&gt; m.sample()  # Fisher-Snedecor-distributed with df1=1 and df2=2\ntensor([ 0.2453])\n\n\n\nParameters\n\ndf1 (python:float or Tensor) \u2013 degrees of freedom parameter 1\ndf2 (python:float or Tensor) \u2013 degrees of freedom parameter 2\n\n\n\n\n\narg_constraints = {'df1': GreaterThan(lower_bound=0.0), 'df2': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nrsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nsupport = GreaterThan(lower_bound=0.0)\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor", "parameters": [{"name": "df1", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 degrees of freedom parameter 1"}, {"name": "df2", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.gamma.Gamma(concentration,rate,validate_args=None)", "id": "torch.distributions.gamma.Gamma", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily\nCreates a Gamma distribution parameterized by shape concentration and rate.\nExample:\n&gt;&gt;&gt; m = Gamma(torch.tensor([1.0]), torch.tensor([1.0]))\n&gt;&gt;&gt; m.sample()  # Gamma distributed with concentration=1 and rate=1\ntensor([ 0.1046])\n\n\n\nParameters\n\nconcentration (python:float or Tensor) \u2013 shape parameter of the distribution\n(often referred to as alpha)\nrate (python:float or Tensor) \u2013 rate = 1 / scale of the distribution\n(often referred to as beta)\n\n\n\n\n\narg_constraints = {'concentration': GreaterThan(lower_bound=0.0), 'rate': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nrsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nsupport = GreaterThan(lower_bound=0.0)\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.gamma.Gamma", "parameters": [{"name": "concentration", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 shape parameter of the distribution\n(often referred to as alpha)"}, {"name": "rate", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.geometric.Geometric(probs=None,logits=None,validate_args=None)", "id": "torch.distributions.geometric.Geometric", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a Geometric distribution parameterized by probs,\nwhere probs is the probability of success of Bernoulli trials.\nIt represents the probability that in k+1k + 1k+1\n\n Bernoulli trials, the\nfirst kkk\n\n trials failed, before seeing a success.\nSamples are non-negative integers [0, inf\u2061\\infinf\n\n).\nExample:\n&gt;&gt;&gt; m = Geometric(torch.tensor([0.3]))\n&gt;&gt;&gt; m.sample()  # underlying Bernoulli has 30% chance 1; 70% chance 0\ntensor([ 2.])\n\n\n\nParameters\n\nprobs (Number, Tensor) \u2013 the probability of sampling 1", "description": "", "code-info": {"name": "torch.distributions.geometric.Geometric", "parameters": [{"name": "probs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Number, Tensor) \u2013 the probability of sampling 1. Must be in range (0, 1]"}, {"name": "logits", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.gumbel.Gumbel(loc,scale,validate_args=None)", "id": "torch.distributions.gumbel.Gumbel", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution\nSamples from a Gumbel Distribution.\nExamples:\n&gt;&gt;&gt; m = Gumbel(torch.tensor([1.0]), torch.tensor([2.0]))\n&gt;&gt;&gt; m.sample()  # sample from Gumbel distribution with loc=1, scale=2\ntensor([ 1.0124])\n\n\n\nParameters\n\nloc (python:float or Tensor) \u2013 Location parameter of the distribution\nscale (python:float or Tensor) \u2013 Scale parameter of the distribution\n\n\n\n\n\narg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nproperty stddev\u00b6\n\n\n\n\nsupport = Real()\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.gumbel.Gumbel", "parameters": [{"name": "loc", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 Location parameter of the distribution"}, {"name": "scale", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.utils.prune.RandomUnstructured.apply(module,name,amount)", "id": "torch.nn.utils.prune.RandomUnstructured.apply", "summary": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\namount (python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.RandomUnstructured.apply", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}, {"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}]}},
{"code": "torch.nn.utils.prune.RandomUnstructured.apply_mask(module)", "id": "torch.nn.utils.prune.RandomUnstructured.apply_mask", "summary": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\n\nParameters\nmodule (nn.Module) \u2013 module containing the tensor to prune\n\nReturns\npruned version of the input tensor\n\nReturn type\npruned_tensor (torch.Tensor)\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.RandomUnstructured.apply_mask", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}]}},
{"code": "torch.nn.utils.prune.RandomUnstructured.prune(t,default_mask=None)", "id": "torch.nn.utils.prune.RandomUnstructured.prune", "summary": "Computes and returns a pruned version of input tensor t\naccording to the pruning rule specified in compute_mask().\n\nParameters\n\nt (torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask).\ndefault_mask (torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any", "description": "", "code-info": {"name": "torch.nn.utils.prune.RandomUnstructured.prune", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask)."}, {"name": "default_mask", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}]}},
{"code": "torch.nn.utils.prune.RandomUnstructured.remove(module)", "id": "torch.nn.utils.prune.RandomUnstructured.remove", "summary": "Removes the pruning reparameterization from a module", "description": "", "code-info": {"name": "torch.nn.utils.prune.RandomUnstructured.remove", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.utils.prune.L1Unstructured.apply(module,name,amount)", "id": "torch.nn.utils.prune.L1Unstructured.apply", "summary": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\namount (python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.L1Unstructured.apply", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}, {"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}]}},
{"code": "torch.nn.utils.prune.L1Unstructured.apply_mask(module)", "id": "torch.nn.utils.prune.L1Unstructured.apply_mask", "summary": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\n\nParameters\nmodule (nn.Module) \u2013 module containing the tensor to prune\n\nReturns\npruned version of the input tensor\n\nReturn type\npruned_tensor (torch.Tensor)\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.L1Unstructured.apply_mask", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}]}},
{"code": "torch.nn.utils.prune.L1Unstructured.prune(t,default_mask=None)", "id": "torch.nn.utils.prune.L1Unstructured.prune", "summary": "Computes and returns a pruned version of input tensor t\naccording to the pruning rule specified in compute_mask().\n\nParameters\n\nt (torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask).\ndefault_mask (torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any", "description": "", "code-info": {"name": "torch.nn.utils.prune.L1Unstructured.prune", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask)."}, {"name": "default_mask", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}]}},
{"code": "torch.nn.utils.prune.L1Unstructured.remove(module)", "id": "torch.nn.utils.prune.L1Unstructured.remove", "summary": "Removes the pruning reparameterization from a module", "description": "", "code-info": {"name": "torch.nn.utils.prune.L1Unstructured.remove", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.utils.prune.RandomStructured.apply(module,name,amount,dim=-1)", "id": "torch.nn.utils.prune.RandomStructured.apply", "summary": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\namount (python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured.apply", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}, {"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int, optional) \u2013 index of the dim along which we define\nchannels to prune. Default: -1."}]}},
{"code": "torch.nn.utils.prune.RandomStructured.apply_mask(module)", "id": "torch.nn.utils.prune.RandomStructured.apply_mask", "summary": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\n\nParameters\nmodule (nn.Module) \u2013 module containing the tensor to prune\n\nReturns\npruned version of the input tensor\n\nReturn type\npruned_tensor (torch.Tensor)\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured.apply_mask", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}]}},
{"code": "torch.nn.utils.prune.RandomStructured.compute_mask(t,default_mask)", "id": "torch.nn.utils.prune.RandomStructured.compute_mask", "summary": "Computes and returns a mask for the input tensor t.\nStarting from a base default_mask (which should be a mask of ones\nif the tensor has not been pruned yet), generate a random mask to\napply on top of the default_mask by randomly zeroing out channels\nalong the specified dim of the tensor.\n\nParameters\n\nt (torch.Tensor) \u2013 tensor representing the parameter to prune\ndefault_mask (torch.Tensor) \u2013 Base mask from previous pruning\niterations, that need to be respected after the new mask is\napplied", "description": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured.compute_mask", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor representing the parameter to prune"}, {"name": "default_mask", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 Base mask from previous pruning\niterations, that need to be respected after the new mask is\napplied. Same dims as t."}]}},
{"code": "torch.nn.utils.prune.RandomStructured.prune(t,default_mask=None)", "id": "torch.nn.utils.prune.RandomStructured.prune", "summary": "Computes and returns a pruned version of input tensor t\naccording to the pruning rule specified in compute_mask().\n\nParameters\n\nt (torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask).\ndefault_mask (torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any", "description": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured.prune", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask)."}, {"name": "default_mask", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}]}},
{"code": "torch.nn.utils.prune.RandomStructured.remove(module)", "id": "torch.nn.utils.prune.RandomStructured.remove", "summary": "Removes the pruning reparameterization from a module", "description": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured.remove", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.utils.prune.LnStructured.apply(module,name,amount,n,dim)", "id": "torch.nn.utils.prune.LnStructured.apply", "summary": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\namount (python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured.apply", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": "(str) \u2013 parameter name within module on which pruning\nwill act."}, {"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}, {"name": "n", "is_optional": false, "type": "int", "description": "(python:int, python:float, inf, -inf, 'fro', 'nuc') \u2013 See documentation of valid\nentries for argument p in torch.norm()."}, {"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 index of the dim along which we define channels to\nprune."}]}},
{"code": "torch.nn.utils.prune.LnStructured.apply_mask(module)", "id": "torch.nn.utils.prune.LnStructured.apply_mask", "summary": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\n\nParameters\nmodule (nn.Module) \u2013 module containing the tensor to prune\n\nReturns\npruned version of the input tensor\n\nReturn type\npruned_tensor (torch.Tensor)\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured.apply_mask", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}]}},
{"code": "torch.nn.utils.prune.LnStructured.compute_mask(t,default_mask)", "id": "torch.nn.utils.prune.LnStructured.compute_mask", "summary": "Computes and returns a mask for the input tensor t.\nStarting from a base default_mask (which should be a mask of ones\nif the tensor has not been pruned yet), generate a mask to apply on\ntop of the default_mask by zeroing out the channels along the\nspecified dim with the lowest Ln-norm.\n\nParameters\n\nt (torch.Tensor) \u2013 tensor representing the parameter to prune\ndefault_mask (torch.Tensor) \u2013 Base mask from previous pruning\niterations, that need to be respected after the new mask is\napplied", "description": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured.compute_mask", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor representing the parameter to prune"}, {"name": "default_mask", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 Base mask from previous pruning\niterations, that need to be respected after the new mask is\napplied.  Same dims as t."}]}},
{"code": "torch.nn.utils.prune.LnStructured.prune(t,default_mask=None)", "id": "torch.nn.utils.prune.LnStructured.prune", "summary": "Computes and returns a pruned version of input tensor t\naccording to the pruning rule specified in compute_mask().\n\nParameters\n\nt (torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask).\ndefault_mask (torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any", "description": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured.prune", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask)."}, {"name": "default_mask", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}]}},
{"code": "torch.Tensor.narrow_copy(dimension,start,length)", "id": "torch.Tensor.narrow_copy", "summary": "Same as Tensor.narrow() except returning a copy rather\nthan shared storage", "description": "", "code-info": {"name": "torch.Tensor.narrow_copy", "parameters": [{"name": "dimension", "is_optional": false, "type": "others", "description": ""}, {"name": "start", "is_optional": false, "type": "others", "description": ""}, {"name": "length", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.ndimension()", "id": "torch.Tensor.ndimension", "summary": "Alias for dim()\n", "description": "", "code-info": {"name": "torch.Tensor.ndimension", "parameters": []}},
{"code": "torch.Tensor.ne(other)", "id": "torch.Tensor.ne", "summary": "See torch.ne()\n", "description": "", "code-info": {"name": "torch.Tensor.ne", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.ne_(other)", "id": "torch.Tensor.ne_", "summary": "In-place version of ne()\n", "description": "", "code-info": {"name": "torch.Tensor.ne_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.neg()", "id": "torch.Tensor.neg", "summary": "See torch.neg()\n", "description": "", "code-info": {"name": "torch.Tensor.neg", "parameters": []}},
{"code": "torch.Tensor.neg_()", "id": "torch.Tensor.neg_", "summary": "In-place version of neg()\n", "description": "", "code-info": {"name": "torch.Tensor.neg_", "parameters": []}},
{"code": "torch.Tensor.nelement()", "id": "torch.Tensor.nelement", "summary": "Alias for numel()\n", "description": "", "code-info": {"name": "torch.Tensor.nelement", "parameters": []}},
{"code": "torch.Tensor.nonzero()", "id": "torch.Tensor.nonzero", "summary": "See torch.nonzero()\n", "description": "", "code-info": {"name": "torch.Tensor.nonzero", "parameters": []}},
{"code": "torch.Tensor.norm(p='fro',dim=None,keepdim=False,dtype=None)", "id": "torch.Tensor.norm", "summary": "See torch.norm()\n", "description": "", "code-info": {"name": "torch.Tensor.norm", "parameters": [{"name": "p", "is_optional": true, "type": "string", "default_value": "'fro'", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.normal_(mean=0,std=1,*,generator=None)", "id": "torch.Tensor.normal_", "summary": "Fills self tensor with elements samples from the normal distribution\nparameterized by mean and std.\n", "description": "", "code-info": {"name": "torch.Tensor.normal_", "parameters": [{"name": "mean", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "std", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.numel()", "id": "torch.Tensor.numel", "summary": "See torch.numel()\n", "description": "", "code-info": {"name": "torch.Tensor.numel", "parameters": []}},
{"code": "torch.Tensor.numpy()", "id": "torch.Tensor.numpy", "summary": "Returns self tensor as a NumPy ndarray", "description": "", "code-info": {"name": "torch.Tensor.numpy", "parameters": []}},
{"code": "torch.Tensor.orgqr(input2)", "id": "torch.Tensor.orgqr", "summary": "See torch.orgqr()\n", "description": "", "code-info": {"name": "torch.Tensor.orgqr", "parameters": [{"name": "input2", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.ormqr(input2,input3,left=True,transpose=False)", "id": "torch.Tensor.ormqr", "summary": "See torch.ormqr()\n", "description": "", "code-info": {"name": "torch.Tensor.ormqr", "parameters": [{"name": "input2", "is_optional": false, "type": "others", "description": ""}, {"name": "input3", "is_optional": false, "type": "others", "description": ""}, {"name": "left", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "transpose", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.permute(*dims)", "id": "torch.Tensor.permute", "summary": "Permute the dimensions of this tensor.\n\nParameters\n*dims (python:int...) \u2013 The desired ordering of dimensions\n\n\nExample\n&gt;&gt;&gt; x = torch.randn(2, 3, 5)\n&gt;&gt;&gt; x.size()\ntorch.Size([2, 3, 5])\n&gt;&gt;&gt; x.permute(2, 0, 1).size()\ntorch.Size([5, 2, 3])\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.permute", "parameters": [{"name": "*dims", "is_optional": false, "type": "int", "description": "(python:int...) \u2013 The desired ordering of dimensions"}]}},
{"code": "torch.Tensor.pin_memory()", "id": "torch.Tensor.pin_memory", "summary": "Copies the tensor to pinned memory, if it\u2019s not already pinned.\n", "description": "", "code-info": {"name": "torch.Tensor.pin_memory", "parameters": []}},
{"code": "torch.Tensor.pinverse()", "id": "torch.Tensor.pinverse", "summary": "See torch.pinverse()\n", "description": "", "code-info": {"name": "torch.Tensor.pinverse", "parameters": []}},
{"code": "torch.Tensor.polygamma(n)", "id": "torch.Tensor.polygamma", "summary": "See torch.polygamma()\n", "description": "", "code-info": {"name": "torch.Tensor.polygamma", "parameters": [{"name": "n", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.erfinv(input,out=None)", "id": "torch.erfinv", "summary": "Computes the inverse error function of each element of input.\nThe inverse error function is defined in the range (\u22121,1)(-1, 1)(\u22121,1)\n\n as:\n\nerfinv(erf(x))=x\\mathrm{erfinv}(\\mathrm{erf}(x)) = x\n\nerfinv(erf(x))=x\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; torch.erfinv(torch.tensor([0, 0.5, -1.]))\ntensor([ 0.0000,  0.4769,    -inf])\n\n\n", "description": "", "code-info": {"name": "torch.erfinv", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.exp(input,out=None)", "id": "torch.exp", "summary": "Returns a new tensor with the exponential of the elements\nof the input tensor input.\n\nyi=exiy_{i} = e^{x_{i}}\n\nyi\u200b=exi\u200b\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; torch.exp(torch.tensor([0, math.log(2.)]))\ntensor([ 1.,  2.])\n\n\n", "description": "", "code-info": {"name": "torch.exp", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.expm1(input,out=None)", "id": "torch.expm1", "summary": "Returns a new tensor with the exponential of the elements minus 1\nof input.\n\nyi=exi\u22121y_{i} = e^{x_{i}} - 1\n\nyi\u200b=exi\u200b\u22121\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; torch.expm1(torch.tensor([0, math.log(2.)]))\ntensor([ 0.,  1.])\n\n\n", "description": "", "code-info": {"name": "torch.expm1", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.floor(input,out=None)", "id": "torch.floor", "summary": "Returns a new tensor with the floor of the elements of input,\nthe largest integer less than or equal to each element.\n\nouti=\u230ainputi\u230b\\text{out}_{i} = \\left\\lfloor \\text{input}_{i} \\right\\rfloor\n\nouti\u200b=\u230ainputi\u200b\u230b\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([-0.8166,  1.5308, -0.2530, -0.2091])\n&gt;&gt;&gt; torch.floor(a)\ntensor([-1.,  1., -1., -1.])\n\n\n", "description": "", "code-info": {"name": "torch.floor", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.fmod(input,other,out=None)", "id": "torch.fmod", "summary": "Computes the element-wise remainder of division.\nThe dividend and divisor may contain both for integer and floating point\nnumbers", "description": "", "code-info": {"name": "torch.fmod", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the dividend"}, {"name": "other", "is_optional": false, "type": "float", "description": "(Tensor or python:float) \u2013 the divisor, which may be either a number or a tensor of the same shape as the dividend"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.frac(input,out=None)", "id": "torch.frac", "summary": "Computes the fractional portion of each element in input.\n\nouti=inputi\u2212\u230a\u2223inputi\u2223\u230b\u2217sgn\u2061(inputi)\\text{out}_{i} = \\text{input}_{i} - \\left\\lfloor |\\text{input}_{i}| \\right\\rfloor * \\operatorname{sgn}(\\text{input}_{i})\n\nouti\u200b=inputi\u200b\u2212\u230a\u2223inputi\u200b\u2223\u230b\u2217sgn(inputi\u200b)\n\nExample:\n&gt;&gt;&gt; torch.frac(torch.tensor([1, 2.5, -3.2]))\ntensor([ 0.0000,  0.5000, -0.2000])\n\n\n", "description": "", "code-info": {"name": "torch.frac", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.imag(input,out=None)", "id": "torch.imag", "summary": "Computes the element-wise imag value of the given input tensor.\n\nouti=imag(inputi)\\text{out}_{i} = imag(\\text{input}_{i})\n\nouti\u200b=imag(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; torch.imag(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))\ntensor([ 1,  2,  -3])\n\n\n", "description": "", "code-info": {"name": "torch.imag", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.lerp(input,end,weight,out=None)", "id": "torch.lerp", "summary": "Does a linear interpolation of two tensors start (given by input) and end based\non a scalar or tensor weight and returns the resulting out tensor.\n\nouti=starti+weighti\u00d7(endi\u2212starti)\\text{out}_i = \\text{start}_i + \\text{weight}_i \\times (\\text{end}_i - \\text{start}_i)\n\nouti\u200b=starti\u200b+weighti\u200b\u00d7(endi\u200b\u2212starti\u200b)\n\nThe shapes of start and end must be\nbroadcastable", "description": "", "code-info": {"name": "torch.lerp", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor with the starting points"}, {"name": "end", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor with the ending points"}, {"name": "weight", "is_optional": false, "type": "float", "description": "(python:float or tensor) \u2013 the weight for the interpolation formula"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.distributions.half_cauchy.HalfCauchy(scale,validate_args=None)", "id": "torch.distributions.half_cauchy.HalfCauchy", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution\nCreates a half-normal distribution parameterized by scale where:\nX ~ Cauchy(0, scale)\nY = |X| ~ HalfCauchy(scale)\n\n\nExample:\n&gt;&gt;&gt; m = HalfCauchy(torch.tensor([1.0]))\n&gt;&gt;&gt; m.sample()  # half-cauchy distributed with scale=1\ntensor([ 2.3214])\n\n\n\nParameters\nscale (python:float or Tensor) \u2013 scale of the full Cauchy distribution\n\n\n\n\narg_constraints = {'scale': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\ncdf(value) \u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nicdf(prob) \u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nproperty scale\u00b6\n\n\n\n\nsupport = GreaterThan(lower_bound=0.0)\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy", "parameters": [{"name": "scale", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.half_normal.HalfNormal(scale,validate_args=None)", "id": "torch.distributions.half_normal.HalfNormal", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution\nCreates a half-normal distribution parameterized by scale where:\nX ~ Normal(0, scale)\nY = |X| ~ HalfNormal(scale)\n\n\nExample:\n&gt;&gt;&gt; m = HalfNormal(torch.tensor([1.0]))\n&gt;&gt;&gt; m.sample()  # half-normal distributed with scale=1\ntensor([ 0.1046])\n\n\n\nParameters\nscale (python:float or Tensor) \u2013 scale of the full Normal distribution\n\n\n\n\narg_constraints = {'scale': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\ncdf(value) \u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nicdf(prob) \u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nproperty scale\u00b6\n\n\n\n\nsupport = GreaterThan(lower_bound=0.0)\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.half_normal.HalfNormal", "parameters": [{"name": "scale", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.independent.Independent(base_distribution,reinterpreted_batch_ndims,validate_args=None)", "id": "torch.distributions.independent.Independent", "summary": "Bases: torch.distributions.distribution.Distribution\nReinterprets some of the batch dims of a distribution as event dims.\nThis is mainly useful for changing the shape of the result of\nlog_prob()", "description": "", "code-info": {"name": "torch.distributions.independent.Independent", "parameters": [{"name": "base_distribution", "is_optional": false, "type": "others", "description": "(torch.distributions.distribution.Distribution) \u2013 a\nbase distribution"}, {"name": "reinterpreted_batch_ndims", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.laplace.Laplace(loc,scale,validate_args=None)", "id": "torch.distributions.laplace.Laplace", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a Laplace distribution parameterized by loc and :attr:\u2019scale\u2019.\nExample:\n&gt;&gt;&gt; m = Laplace(torch.tensor([0.0]), torch.tensor([1.0]))\n&gt;&gt;&gt; m.sample()  # Laplace distributed with loc=0, scale=1\ntensor([ 0.1046])\n\n\n\nParameters\n\nloc (python:float or Tensor) \u2013 mean of the distribution\nscale (python:float or Tensor) \u2013 scale of the distribution\n\n\n\n\n\narg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\ncdf(value) \u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nicdf(value) \u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nrsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nproperty stddev\u00b6\n\n\n\n\nsupport = Real()\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.laplace.Laplace", "parameters": [{"name": "loc", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 mean of the distribution"}, {"name": "scale", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.log_normal.LogNormal(loc,scale,validate_args=None)", "id": "torch.distributions.log_normal.LogNormal", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution\nCreates a log-normal distribution parameterized by\nloc and scale where:\nX ~ Normal(loc, scale)\nY = exp(X) ~ LogNormal(loc, scale)\n\n\nExample:\n&gt;&gt;&gt; m = LogNormal(torch.tensor([0.0]), torch.tensor([1.0]))\n&gt;&gt;&gt; m.sample()  # log-normal distributed with mean=0 and stddev=1\ntensor([ 0.1046])\n\n\n\nParameters\n\nloc (python:float or Tensor) \u2013 mean of log of distribution\nscale (python:float or Tensor) \u2013 standard deviation of log of the distribution\n\n\n\n\n\narg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nproperty loc\u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nproperty scale\u00b6\n\n\n\n\nsupport = GreaterThan(lower_bound=0.0)\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.log_normal.LogNormal", "parameters": [{"name": "loc", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 mean of log of distribution"}, {"name": "scale", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.utils.prune.LnStructured.remove(module)", "id": "torch.nn.utils.prune.LnStructured.remove", "summary": "Removes the pruning reparameterization from a module", "description": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured.remove", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.utils.prune.CustomFromMask.apply(module,name,mask)", "id": "torch.nn.utils.prune.CustomFromMask.apply", "summary": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.CustomFromMask.apply", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}, {"name": "name", "is_optional": false, "type": "others", "description": ""}, {"name": "mask", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.utils.prune.CustomFromMask.apply_mask(module)", "id": "torch.nn.utils.prune.CustomFromMask.apply_mask", "summary": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\n\nParameters\nmodule (nn.Module) \u2013 module containing the tensor to prune\n\nReturns\npruned version of the input tensor\n\nReturn type\npruned_tensor (torch.Tensor)\n\n\n", "description": "", "code-info": {"name": "torch.nn.utils.prune.CustomFromMask.apply_mask", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(nn.Module) \u2013 module containing the tensor to prune"}]}},
{"code": "torch.nn.utils.prune.CustomFromMask.prune(t,default_mask=None)", "id": "torch.nn.utils.prune.CustomFromMask.prune", "summary": "Computes and returns a pruned version of input tensor t\naccording to the pruning rule specified in compute_mask().\n\nParameters\n\nt (torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask).\ndefault_mask (torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any", "description": "", "code-info": {"name": "torch.nn.utils.prune.CustomFromMask.prune", "parameters": [{"name": "t", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask)."}, {"name": "default_mask", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}]}},
{"code": "torch.nn.utils.prune.CustomFromMask.remove(module)", "id": "torch.nn.utils.prune.CustomFromMask.remove", "summary": "Removes the pruning reparameterization from a module", "description": "", "code-info": {"name": "torch.nn.utils.prune.CustomFromMask.remove", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.polygamma_(n)", "id": "torch.Tensor.polygamma_", "summary": "In-place version of polygamma()\n", "description": "", "code-info": {"name": "torch.Tensor.polygamma_", "parameters": [{"name": "n", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.pow(exponent)", "id": "torch.Tensor.pow", "summary": "See torch.pow()\n", "description": "", "code-info": {"name": "torch.Tensor.pow", "parameters": [{"name": "exponent", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.pow_(exponent)", "id": "torch.Tensor.pow_", "summary": "In-place version of pow()\n", "description": "", "code-info": {"name": "torch.Tensor.pow_", "parameters": [{"name": "exponent", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.prod(dim=None,keepdim=False,dtype=None)", "id": "torch.Tensor.prod", "summary": "See torch.prod()\n", "description": "", "code-info": {"name": "torch.Tensor.prod", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.put_(indices,tensor,accumulate=False)", "id": "torch.Tensor.put_", "summary": "Copies the elements from tensor into the positions specified by\nindices", "description": "", "code-info": {"name": "torch.Tensor.put_", "parameters": [{"name": "indices", "is_optional": false, "type": "tensor", "description": "(LongTensor) \u2013 the indices into self"}, {"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor containing values to copy from"}, {"name": "accumulate", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 whether to accumulate into self"}]}},
{"code": "torch.Tensor.qr(some=True)", "id": "torch.Tensor.qr", "summary": "See torch.qr()\n", "description": "", "code-info": {"name": "torch.Tensor.qr", "parameters": [{"name": "some", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.Tensor.qscheme()", "id": "torch.Tensor.qscheme", "summary": "Returns the quantization scheme of a given QTensor.\n", "description": "", "code-info": {"name": "torch.Tensor.qscheme", "parameters": []}},
{"code": "torch.Tensor.q_scale()", "id": "torch.Tensor.q_scale", "summary": "Given a Tensor quantized by linear(affine) quantization,\nreturns the scale of the underlying quantizer().\n", "description": "", "code-info": {"name": "torch.Tensor.q_scale", "parameters": []}},
{"code": "torch.Tensor.q_zero_point()", "id": "torch.Tensor.q_zero_point", "summary": "Given a Tensor quantized by linear(affine) quantization,\nreturns the zero_point of the underlying quantizer().\n", "description": "", "code-info": {"name": "torch.Tensor.q_zero_point", "parameters": []}},
{"code": "torch.Tensor.q_per_channel_scales()", "id": "torch.Tensor.q_per_channel_scales", "summary": "Given a Tensor quantized by linear (affine) per-channel quantization,\nreturns a Tensor of scales of the underlying quantizer", "description": "", "code-info": {"name": "torch.Tensor.q_per_channel_scales", "parameters": []}},
{"code": "torch.Tensor.q_per_channel_zero_points()", "id": "torch.Tensor.q_per_channel_zero_points", "summary": "Given a Tensor quantized by linear (affine) per-channel quantization,\nreturns a tensor of zero_points of the underlying quantizer", "description": "", "code-info": {"name": "torch.Tensor.q_per_channel_zero_points", "parameters": []}},
{"code": "torch.Tensor.q_per_channel_axis()", "id": "torch.Tensor.q_per_channel_axis", "summary": "Given a Tensor quantized by linear (affine) per-channel quantization,\nreturns the index of dimension on which per-channel quantization is applied.\n", "description": "", "code-info": {"name": "torch.Tensor.q_per_channel_axis", "parameters": []}},
{"code": "torch.Tensor.random_(from=0,to=None,*,generator=None)", "id": "torch.Tensor.random_", "summary": "Fills self tensor with numbers sampled from the discrete uniform\ndistribution over [from, to - 1]", "description": "", "code-info": {"name": "torch.Tensor.random_", "parameters": [{"name": "from", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "to", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.reciprocal()", "id": "torch.Tensor.reciprocal", "summary": "See torch.reciprocal()\n", "description": "", "code-info": {"name": "torch.Tensor.reciprocal", "parameters": []}},
{"code": "torch.Tensor.reciprocal_()", "id": "torch.Tensor.reciprocal_", "summary": "In-place version of reciprocal()\n", "description": "", "code-info": {"name": "torch.Tensor.reciprocal_", "parameters": []}},
{"code": "torch.Tensor.record_stream(stream)", "id": "torch.Tensor.record_stream", "summary": "Ensures that the tensor memory is not reused for another tensor until all\ncurrent work queued on stream are complete.\n\nNote\nThe caching allocator is aware of only the stream where a tensor was\nallocated", "description": "", "code-info": {"name": "torch.Tensor.record_stream", "parameters": [{"name": "stream", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.lgamma(input,out=None)", "id": "torch.lgamma", "summary": "Computes the logarithm of the gamma function on input.\n\nouti=log\u2061\u0393(inputi)\\text{out}_{i} = \\log \\Gamma(\\text{input}_{i})\n\nouti\u200b=log\u0393(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.arange(0.5, 2, 0.5)\n&gt;&gt;&gt; torch.lgamma(a)\ntensor([ 0.5724,  0.0000, -0.1208])\n\n\n", "description": "", "code-info": {"name": "torch.lgamma", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.log(input,out=None)", "id": "torch.log", "summary": "Returns a new tensor with the natural logarithm of the elements\nof input.\n\nyi=log\u2061e(xi)y_{i} = \\log_{e} (x_{i})\n\nyi\u200b=loge\u200b(xi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(5)\n&gt;&gt;&gt; a\ntensor([-0.7168, -0.5471, -0.8933, -1.4428, -0.1190])\n&gt;&gt;&gt; torch.log(a)\ntensor([ nan,  nan,  nan,  nan,  nan])\n\n\n", "description": "", "code-info": {"name": "torch.log", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.log10(input,out=None)", "id": "torch.log10", "summary": "Returns a new tensor with the logarithm to the base 10 of the elements\nof input.\n\nyi=log\u206110(xi)y_{i} = \\log_{10} (x_{i})\n\nyi\u200b=log10\u200b(xi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.rand(5)\n&gt;&gt;&gt; a\ntensor([ 0.5224,  0.9354,  0.7257,  0.1301,  0.2251])\n\n\n&gt;&gt;&gt; torch.log10(a)\ntensor([-0.2820, -0.0290, -0.1392, -0.8857, -0.6476])\n\n\n", "description": "", "code-info": {"name": "torch.log10", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.log1p(input,out=None)", "id": "torch.log1p", "summary": "Returns a new tensor with the natural logarithm of (1 + input).\n\nyi=log\u2061e(xi+1)y_i = \\log_{e} (x_i + 1)\n\nyi\u200b=loge\u200b(xi\u200b+1)\n\n\nNote\nThis function is more accurate than torch.log() for small\nvalues of input\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(5)\n&gt;&gt;&gt; a\ntensor([-1.0090, -0.9923,  1.0249, -0.5372,  0.2492])\n&gt;&gt;&gt; torch.log1p(a)\ntensor([    nan, -4.8653,  0.7055, -0.7705,  0.2225])\n\n\n", "description": "", "code-info": {"name": "torch.log1p", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.log2(input,out=None)", "id": "torch.log2", "summary": "Returns a new tensor with the logarithm to the base 2 of the elements\nof input.\n\nyi=log\u20612(xi)y_{i} = \\log_{2} (x_{i})\n\nyi\u200b=log2\u200b(xi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.rand(5)\n&gt;&gt;&gt; a\ntensor([ 0.8419,  0.8003,  0.9971,  0.5287,  0.0490])\n\n\n&gt;&gt;&gt; torch.log2(a)\ntensor([-0.2483, -0.3213, -0.0042, -0.9196, -4.3504])\n\n\n", "description": "", "code-info": {"name": "torch.log2", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.logical_not(input,out=None)", "id": "torch.logical_not", "summary": "Computes the element-wise logical NOT of the given input tensor", "description": "", "code-info": {"name": "torch.logical_not", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.logical_xor(input,other,out=None)", "id": "torch.logical_xor", "summary": "Computes the element-wise logical XOR of the given input tensors", "description": "", "code-info": {"name": "torch.logical_xor", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "other", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to compute XOR with"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.mul()", "id": "torch.mul", "summary": "\n\ntorch.mul(input, other, out=None)\n\n\nMultiplies each element of the input input with the scalar\nother and returns a new resulting tensor.\n\nouti=other\u00d7inputi\\text{out}_i = \\text{other} \\times \\text{input}_i\n\nouti\u200b=other\u00d7inputi\u200b\n\nIf input is of type FloatTensor or DoubleTensor, other\nshould be a real number, otherwise it should be an integer\n\nParameters\n\n{input} \u2013 \nvalue (Number) \u2013 the number to be multiplied to each element of input\n{out} \u2013 \n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(3)\n&gt;&gt;&gt; a\ntensor([ 0.2015, -0.4255,  2.6087])\n&gt;&gt;&gt; torch.mul(a, 100)\ntensor([  20.1494,  -42.5491,  260.8663])\n\n\n\n\ntorch.mul(input, other, out=None)\n\n\nEach element of the tensor input is multiplied by the corresponding\nelement of the Tensor other", "description": "", "code-info": {"name": "torch.mul", "parameters": []}},
{"code": "sig-prename descclassname(input,other,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-prename descclassname(input,other,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(loc,cov_factor,cov_diag,validate_args=None)", "id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a multivariate normal distribution with covariance matrix having a low-rank form\nparameterized by cov_factor and cov_diag:\ncovariance_matrix = cov_factor @ cov_factor.T + cov_diag\n\n\nExample\n&gt;&gt;&gt; m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([1, 0]), torch.tensor([1, 1]))\n&gt;&gt;&gt; m.sample()  # normally distributed with mean=`[0,0]`, cov_factor=`[1,0]`, cov_diag=`[1,1]`\ntensor([-0.2102, -0.5429])\n\n\n\nParameters\n\nloc (Tensor) \u2013 mean of the distribution with shape batch_shape + event_shape\ncov_factor (Tensor) \u2013 factor part of low-rank form of covariance matrix with shape\nbatch_shape + event_shape + (rank,)\ncov_diag (Tensor) \u2013 diagonal part of low-rank form of covariance matrix with shape\nbatch_shape + event_shape\n\n\n\n\nNote\nThe computation for determinant and inverse of covariance matrix is avoided when\ncov_factor.shape[1] &lt;&lt; cov_factor.shape[0] thanks to Woodbury matrix identity and\nmatrix determinant lemma.\nThanks to these formulas, we just need to compute the determinant and inverse of\nthe small size \u201ccapacitance\u201d matrix:\ncapacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor\n\n\n\n\n\narg_constraints = {'cov_diag': GreaterThan(lower_bound=0.0), 'cov_factor': Real(), 'loc': Real()}\u00b6\n\n\n\n\ncovariance_matrix \u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nprecision_matrix \u00b6\n\n\n\n\nrsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nscale_tril \u00b6\n\n\n\n\nsupport = Real()\u00b6\n\n\n\n\nvariance \u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal", "parameters": [{"name": "loc", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 mean of the distribution with shape batch_shape + event_shape"}, {"name": "cov_factor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 factor part of low-rank form of covariance matrix with shape\nbatch_shape + event_shape + (rank,)"}, {"name": "cov_diag", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.multinomial.Multinomial(total_count=1,probs=None,logits=None,validate_args=None)", "id": "torch.distributions.multinomial.Multinomial", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a Multinomial distribution parameterized by total_count and\neither probs or logits (but not both)", "description": "", "code-info": {"name": "torch.distributions.multinomial.Multinomial", "parameters": [{"name": "total_count", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int) \u2013 number of trials"}, {"name": "probs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor) \u2013 event probabilities"}, {"name": "logits", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.multivariate_normal.MultivariateNormal(loc,covariance_matrix=None,precision_matrix=None,scale_tril=None,validate_args=None)", "id": "torch.distributions.multivariate_normal.MultivariateNormal", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a multivariate normal (also called Gaussian) distribution\nparameterized by a mean vector and a covariance matrix.\nThe multivariate normal distribution can be parameterized either\nin terms of a positive definite covariance matrix \u03a3\\mathbf{\\Sigma}\u03a3\n\n\nor a positive definite precision matrix \u03a3\u22121\\mathbf{\\Sigma}^{-1}\u03a3\u22121\n\n\nor a lower-triangular matrix L\\mathbf{L}L\n\n with positive-valued\ndiagonal entries, such that\n\u03a3=LL\u22a4\\mathbf{\\Sigma} = \\mathbf{L}\\mathbf{L}^\\top\u03a3=LL\u22a4\n\n", "description": "", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal", "parameters": [{"name": "loc", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 mean of the distribution"}, {"name": "covariance_matrix", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor) \u2013 positive-definite covariance matrix"}, {"name": "precision_matrix", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor) \u2013 positive-definite precision matrix"}, {"name": "scale_tril", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.negative_binomial.NegativeBinomial(total_count,probs=None,logits=None,validate_args=None)", "id": "torch.distributions.negative_binomial.NegativeBinomial", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a Negative Binomial distribution, i.e", "description": "", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial", "parameters": [{"name": "total_count", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 non-negative number of negative Bernoulli\ntrials to stop, although the distribution is still valid for real\nvalued count"}, {"name": "probs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor) \u2013 Event probabilities of success in the half open interval [0, 1)"}, {"name": "logits", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.normal.Normal(loc,scale,validate_args=None)", "id": "torch.distributions.normal.Normal", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily\nCreates a normal (also called Gaussian) distribution parameterized by\nloc and scale.\nExample:\n&gt;&gt;&gt; m = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n&gt;&gt;&gt; m.sample()  # normally distributed with loc=0 and scale=1\ntensor([ 0.1046])\n\n\n\nParameters\n\nloc (python:float or Tensor) \u2013 mean of the distribution (often referred to as mu)\nscale (python:float or Tensor) \u2013 standard deviation of the distribution\n(often referred to as sigma)\n\n\n\n\n\narg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\ncdf(value) \u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nicdf(value) \u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nrsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nproperty stddev\u00b6\n\n\n\n\nsupport = Real()\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.normal.Normal", "parameters": [{"name": "loc", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 mean of the distribution (often referred to as mu)"}, {"name": "scale", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.one_hot_categorical.OneHotCategorical(probs=None,logits=None,validate_args=None)", "id": "torch.distributions.one_hot_categorical.OneHotCategorical", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a one-hot categorical distribution parameterized by probs or\nlogits.\nSamples are one-hot coded vectors of size probs.size(-1).\n\nNote\nprobs must be non-negative, finite and have a non-zero sum,\nand it will be normalized to sum to 1.\n\nSee also: torch.distributions.Categorical() for specifications of\nprobs and logits.\nExample:\n&gt;&gt;&gt; m = OneHotCategorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n&gt;&gt;&gt; m.sample()  # equal probability of 0, 1, 2, 3\ntensor([ 0.,  0.,  0.,  1.])\n\n\n\nParameters\n\nprobs (Tensor) \u2013 event probabilities\nlogits (Tensor) \u2013 event log probabilities\n\n\n\n\n\narg_constraints = {'logits': Real(), 'probs': Simplex()}\u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nenumerate_support(expand=True) \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_enumerate_support = True\u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty logits\u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nproperty param_shape\u00b6\n\n\n\n\nproperty probs\u00b6\n\n\n\n\nsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nsupport = Simplex()\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical", "parameters": [{"name": "probs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor) \u2013 event probabilities"}, {"name": "logits", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.pareto.Pareto(scale,alpha,validate_args=None)", "id": "torch.distributions.pareto.Pareto", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution\nSamples from a Pareto Type 1 distribution.\nExample:\n&gt;&gt;&gt; m = Pareto(torch.tensor([1.0]), torch.tensor([1.0]))\n&gt;&gt;&gt; m.sample()  # sample from a Pareto distribution with scale=1 and alpha=1\ntensor([ 1.5623])\n\n\n\nParameters\n\nscale (python:float or Tensor) \u2013 Scale parameter of the distribution\nalpha (python:float or Tensor) \u2013 Shape parameter of the distribution\n\n\n\n\n\narg_constraints = {'alpha': GreaterThan(lower_bound=0.0), 'scale': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nproperty support\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.pareto.Pareto", "parameters": [{"name": "scale", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 Scale parameter of the distribution"}, {"name": "alpha", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.Sequential(*args)", "id": "torch.nn.Sequential", "summary": "A sequential container.\nModules will be added to it in the order they are passed in the constructor.\nAlternatively, an ordered dict of modules can also be passed in.\nTo make it easier to understand, here is a small example:\n# Example of using Sequential\nmodel = nn.Sequential(\n          nn.Conv2d(1,20,5),\n          nn.ReLU(),\n          nn.Conv2d(20,64,5),\n          nn.ReLU()\n        )\n\n# Example of using Sequential with OrderedDict\nmodel = nn.Sequential(OrderedDict([\n          ('conv1', nn.Conv2d(1,20,5)),\n          ('relu1', nn.ReLU()),\n          ('conv2', nn.Conv2d(20,64,5)),\n          ('relu2', nn.ReLU())\n        ]))\n\n\n", "description": "", "code-info": {"name": "torch.nn.Sequential", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.ModuleList(modules=None)", "id": "torch.nn.ModuleList", "summary": "Holds submodules in a list.\nModuleList can be indexed like a regular Python list, but\nmodules it contains are properly registered, and will be visible by all\nModule methods.\n\nParameters\nmodules (iterable, optional) \u2013 an iterable of modules to add\n\n\nExample:\nclass MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n\n    def forward(self, x):\n        # ModuleList can act as an iterable, or be indexed using ints\n        for i, l in enumerate(self.linears):\n            x = self.linears[i // 2](x) + l(x)\n        return x\n\n\n\n\nappend(module) \u00b6\nAppends a given module to the end of the list.\n\nParameters\nmodule (nn.Module) \u2013 module to append\n\n\n\n\n\n\nextend(modules) \u00b6\nAppends modules from a Python iterable to the end of the list.\n\nParameters\nmodules (iterable) \u2013 iterable of modules to append\n\n\n\n\n\n\ninsert(index, module) \u00b6\nInsert a given module before a given index in the list.\n\nParameters\n\nindex (python:int) \u2013 index to insert.\nmodule (nn.Module) \u2013 module to insert\n\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.ModuleList", "parameters": [{"name": "modules", "is_optional": true, "type": "others", "default_value": "None", "description": "(iterable, optional) \u2013 an iterable of modules to add"}]}},
{"code": "torch.nn.ModuleDict(modules=None)", "id": "torch.nn.ModuleDict", "summary": "Holds submodules in a dictionary.\nModuleDict can be indexed like a regular Python dictionary,\nbut modules it contains are properly registered, and will be visible by all\nModule methods.\nModuleDict is an ordered dictionary that respects\n\nthe order of insertion, and\nin update(), the order of the merged OrderedDict\nor another ModuleDict (the argument to update()).\n\nNote that update() with other unordered mapping\ntypes (e.g., Python\u2019s plain dict) does not preserve the order of the\nmerged mapping.\n\nParameters\nmodules (iterable, optional) \u2013 a mapping (dictionary) of (string: module)\nor an iterable of key-value pairs of type (string, module)\n\n\nExample:\nclass MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.choices = nn.ModuleDict({\n                'conv': nn.Conv2d(10, 10, 3),\n                'pool': nn.MaxPool2d(3)\n        })\n        self.activations = nn.ModuleDict([\n                ['lrelu', nn.LeakyReLU()],\n                ['prelu', nn.PReLU()]\n        ])\n\n    def forward(self, x, choice, act):\n        x = self.choices[choice](x)\n        x = self.activations[act](x)\n        return x\n\n\n\n\nclear() \u00b6\nRemove all items from the ModuleDict.\n\n\n\n\nitems() \u00b6\nReturn an iterable of the ModuleDict key/value pairs.\n\n\n\n\nkeys() \u00b6\nReturn an iterable of the ModuleDict keys.\n\n\n\n\npop(key) \u00b6\nRemove key from the ModuleDict and return its module.\n\nParameters\nkey (string) \u2013 key to pop from the ModuleDict\n\n\n\n\n\n\nupdate(modules) \u00b6\nUpdate the ModuleDict with the key-value pairs from a\nmapping or an iterable, overwriting existing keys.\n\nNote\nIf modules is an OrderedDict, a ModuleDict, or\nan iterable of key-value pairs, the order of new elements in it is preserved.\n\n\nParameters\nmodules (iterable) \u2013 a mapping (dictionary) from string to Module,\nor an iterable of key-value pairs of type (string, Module)\n\n\n\n\n\n\nvalues() \u00b6\nReturn an iterable of the ModuleDict values.\n\n\n", "description": "", "code-info": {"name": "torch.nn.ModuleDict", "parameters": [{"name": "modules", "is_optional": true, "type": "others", "default_value": "None", "description": "(iterable, optional) \u2013 a mapping (dictionary) of (string: module)\nor an iterable of key-value pairs of type (string, module)"}]}},
{"code": "sig-name descname(hook)", "id": "sig-name descname", "summary": "Registers a backward hook.\nThe hook will be called every time a gradient with respect to the\nTensor is computed", "description": "", "code-info": {"name": "sig-name descname", "parameters": [{"name": "hook", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.remainder(divisor)", "id": "torch.Tensor.remainder", "summary": "See torch.remainder()\n", "description": "", "code-info": {"name": "torch.Tensor.remainder", "parameters": [{"name": "divisor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.remainder_(divisor)", "id": "torch.Tensor.remainder_", "summary": "In-place version of remainder()\n", "description": "", "code-info": {"name": "torch.Tensor.remainder_", "parameters": [{"name": "divisor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.real()", "id": "torch.Tensor.real", "summary": "See torch.real()\n", "description": "", "code-info": {"name": "torch.Tensor.real", "parameters": []}},
{"code": "torch.Tensor.renorm(p,dim,maxnorm)", "id": "torch.Tensor.renorm", "summary": "See torch.renorm()\n", "description": "", "code-info": {"name": "torch.Tensor.renorm", "parameters": [{"name": "p", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "maxnorm", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.renorm_(p,dim,maxnorm)", "id": "torch.Tensor.renorm_", "summary": "In-place version of renorm()\n", "description": "", "code-info": {"name": "torch.Tensor.renorm_", "parameters": [{"name": "p", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "maxnorm", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.repeat(*sizes)", "id": "torch.Tensor.repeat", "summary": "Repeats this tensor along the specified dimensions.\nUnlike expand(), this function copies the tensor\u2019s data.\n\nWarning\ntorch.repeat() behaves differently from\nnumpy.repeat,\nbut is more similar to\nnumpy.tile.\nFor the operator similar to numpy.repeat, see torch.repeat_interleave().\n\n\nParameters\nsizes (torch.Size or python:int...) \u2013 The number of times to repeat this tensor along each\ndimension\n\n\nExample:\n&gt;&gt;&gt; x = torch.tensor([1, 2, 3])\n&gt;&gt;&gt; x.repeat(4, 2)\ntensor([[ 1,  2,  3,  1,  2,  3],\n        [ 1,  2,  3,  1,  2,  3],\n        [ 1,  2,  3,  1,  2,  3],\n        [ 1,  2,  3,  1,  2,  3]])\n&gt;&gt;&gt; x.repeat(4, 2, 1).size()\ntorch.Size([4, 2, 3])\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.repeat", "parameters": [{"name": "*sizes", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.repeat_interleave(repeats,dim=None)", "id": "torch.Tensor.repeat_interleave", "summary": "See torch.repeat_interleave().\n", "description": "", "code-info": {"name": "torch.Tensor.repeat_interleave", "parameters": [{"name": "repeats", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.requires_grad_(requires_grad=True)", "id": "torch.Tensor.requires_grad_", "summary": "Change if autograd should record operations on this tensor: sets this tensor\u2019s\nrequires_grad attribute in-place", "description": "", "code-info": {"name": "torch.Tensor.requires_grad_", "parameters": [{"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 If autograd should record operations on this tensor.\nDefault: True."}]}},
{"code": "torch.Tensor.reshape(*shape)", "id": "torch.Tensor.reshape", "summary": "Returns a tensor with the same data and number of elements as self\nbut with the specified shape", "description": "", "code-info": {"name": "torch.Tensor.reshape", "parameters": [{"name": "*shape", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.reshape_as(other)", "id": "torch.Tensor.reshape_as", "summary": "Returns this tensor as the same shape as other.\nself.reshape_as(other) is equivalent to self.reshape(other.sizes()).\nThis method returns a view if other.sizes() is compatible with the current\nshape", "description": "", "code-info": {"name": "torch.Tensor.reshape_as", "parameters": [{"name": "other", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 The result tensor has the same shape\nas other."}]}},
{"code": "torch.Tensor.resize_(*sizes)", "id": "torch.Tensor.resize_", "summary": "Resizes self tensor to the specified size", "description": "", "code-info": {"name": "torch.Tensor.resize_", "parameters": [{"name": "*sizes", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.resize_as_(tensor)", "id": "torch.Tensor.resize_as_", "summary": "Resizes the self tensor to be the same size as the specified\ntensor", "description": "", "code-info": {"name": "torch.Tensor.resize_as_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-name descname()", "id": "sig-name descname", "summary": "Enables .grad attribute for non-leaf Tensors.\n", "description": "", "code-info": {"name": "sig-name descname", "parameters": []}},
{"code": "torch.Tensor.rfft(signal_ndim,normalized=False,onesided=True)", "id": "torch.Tensor.rfft", "summary": "See torch.rfft()\n", "description": "", "code-info": {"name": "torch.Tensor.rfft", "parameters": [{"name": "signal_ndim", "is_optional": false, "type": "others", "description": ""}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.Tensor.roll(shifts,dims)", "id": "torch.Tensor.roll", "summary": "See torch.roll()\n", "description": "", "code-info": {"name": "torch.Tensor.roll", "parameters": [{"name": "shifts", "is_optional": false, "type": "others", "description": ""}, {"name": "dims", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.rot90(k,dims)", "id": "torch.Tensor.rot90", "summary": "See torch.rot90()\n", "description": "", "code-info": {"name": "torch.Tensor.rot90", "parameters": [{"name": "k", "is_optional": false, "type": "others", "description": ""}, {"name": "dims", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.round()", "id": "torch.Tensor.round", "summary": "See torch.round()\n", "description": "", "code-info": {"name": "torch.Tensor.round", "parameters": []}},
{"code": "torch.Tensor.round_()", "id": "torch.Tensor.round_", "summary": "In-place version of round()\n", "description": "", "code-info": {"name": "torch.Tensor.round_", "parameters": []}},
{"code": "torch.mvlgamma(input,p)", "id": "torch.mvlgamma", "summary": "Computes the multivariate log-gamma function ([reference]) with dimension ppp\n\n element-wise, given by\n\nlog\u2061(\u0393p(a))=C+\u2211i=1plog\u2061(\u0393(a\u2212i\u221212))\\log(\\Gamma_{p}(a)) = C + \\displaystyle \\sum_{i=1}^{p} \\log\\left(\\Gamma\\left(a - \\frac{i - 1}{2}\\right)\\right)\n\nlog(\u0393p\u200b(a))=C+i=1\u2211p\u200blog(\u0393(a\u22122i\u22121\u200b))\n\nwhere C=log\u2061(\u03c0)\u00d7p(p\u22121)4C = \\log(\\pi) \\times \\frac{p (p - 1)}{4}C=log(\u03c0)\u00d74p(p\u22121)\u200b\n\n and \u0393(\u22c5)\\Gamma(\\cdot)\u0393(\u22c5)\n\n is the Gamma function.\nIf any of the elements are less than or equal to p\u221212\\frac{p - 1}{2}2p\u22121\u200b\n\n, then an error\nis thrown.\n\nParameters\n\ninput (Tensor) \u2013 the tensor to compute the multivariate log-gamma function\np (python:int) \u2013 the number of dimensions\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.empty(2, 3).uniform_(1, 2)\n&gt;&gt;&gt; a\ntensor([[1.6835, 1.8474, 1.1929],\n        [1.0475, 1.7162, 1.4180]])\n&gt;&gt;&gt; torch.mvlgamma(a, 2)\ntensor([[0.3928, 0.4007, 0.7586],\n        [1.0311, 0.3901, 0.5049]])\n\n\n", "description": "", "code-info": {"name": "torch.mvlgamma", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to compute the multivariate log-gamma function"}, {"name": "p", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the number of dimensions"}]}},
{"code": "torch.neg(input,out=None)", "id": "torch.neg", "summary": "Returns a new tensor with the negative of the elements of input.\n\nout=\u22121\u00d7input\\text{out} = -1 \\times \\text{input}\n\nout=\u22121\u00d7input\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(5)\n&gt;&gt;&gt; a\ntensor([ 0.0090, -0.2262, -0.0682, -0.2866,  0.3940])\n&gt;&gt;&gt; torch.neg(a)\ntensor([-0.0090,  0.2262,  0.0682,  0.2866, -0.3940])\n\n\n", "description": "", "code-info": {"name": "torch.neg", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.polygamma(n,input,out=None)", "id": "torch.polygamma", "summary": "Computes the nthn^{th}nth\n\n derivative of the digamma function on input.\nn\u22650n \\geq 0n\u22650\n\n is called the order of the polygamma function.\n\n\u03c8(n)(x)=d(n)dx(n)\u03c8(x)\\psi^{(n)}(x) = \\frac{d^{(n)}}{dx^{(n)}} \\psi(x)\n\n\u03c8(n)(x)=dx(n)d(n)\u200b\u03c8(x)\n\n\nNote\nThis function is not implemented for n\u22652n \\geq 2n\u22652\n\n.\n\n\nParameters\n\nn (python:int) \u2013 the order of the polygamma function\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\n\nExample::&gt;&gt;&gt; a = torch.tensor([1, 0.5])\n&gt;&gt;&gt; torch.polygamma(1, a)\ntensor([1.64493, 4.9348])\n\n\n\n\n", "description": "", "code-info": {"name": "torch.polygamma", "parameters": [{"name": "n", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the order of the polygamma function"}, {"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.pow()", "id": "torch.pow", "summary": "\n\ntorch.pow(input, exponent, out=None) \u2192 Tensor\n\n\nTakes the power of each element in input with exponent and\nreturns a tensor with the result.\nexponent can be either a single float number or a Tensor\nwith the same number of elements as input.\nWhen exponent is a scalar value, the operation applied is:\n\nouti=xiexponent\\text{out}_i = x_i ^ \\text{exponent}\n\nouti\u200b=xiexponent\u200b\n\nWhen exponent is a tensor, the operation applied is:\n\nouti=xiexponenti\\text{out}_i = x_i ^ {\\text{exponent}_i}\n\nouti\u200b=xiexponenti\u200b\u200b\n\nWhen exponent is a tensor, the shapes of input\nand exponent must be broadcastable.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nexponent (python:float or tensor) \u2013 the exponent value\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 0.4331,  1.2475,  0.6834, -0.2791])\n&gt;&gt;&gt; torch.pow(a, 2)\ntensor([ 0.1875,  1.5561,  0.4670,  0.0779])\n&gt;&gt;&gt; exp = torch.arange(1., 5.)\n\n&gt;&gt;&gt; a = torch.arange(1., 5.)\n&gt;&gt;&gt; a\ntensor([ 1.,  2.,  3.,  4.])\n&gt;&gt;&gt; exp\ntensor([ 1.,  2.,  3.,  4.])\n&gt;&gt;&gt; torch.pow(a, exp)\ntensor([   1.,    4.,   27.,  256.])\n\n\n\n\ntorch.pow(self, exponent, out=None) \u2192 Tensor\n\n\nself is a scalar float value, and exponent is a tensor.\nThe returned tensor out is of the same shape as exponent\nThe operation applied is:\n\nouti=selfexponenti\\text{out}_i = \\text{self} ^ {\\text{exponent}_i}\n\nouti\u200b=selfexponenti\u200b\n\n\nParameters\n\nself (python:float) \u2013 the scalar base value for the power operation\nexponent (Tensor) \u2013 the exponent tensor\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; exp = torch.arange(1., 5.)\n&gt;&gt;&gt; base = 2\n&gt;&gt;&gt; torch.pow(base, exp)\ntensor([  2.,   4.,   8.,  16.])\n\n\n", "description": "", "code-info": {"name": "torch.pow", "parameters": []}},
{"code": "sig-prename descclassname(input,exponent,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "exponent", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-prename descclassname(self,exponent,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "self", "is_optional": false, "type": "others", "description": ""}, {"name": "exponent", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.real(input,out=None)", "id": "torch.real", "summary": "Computes the element-wise real value of the given input tensor.\n\nouti=real(inputi)\\text{out}_{i} = real(\\text{input}_{i})\n\nouti\u200b=real(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; torch.real(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))\ntensor([ -1,  -2,  3])\n\n\n", "description": "", "code-info": {"name": "torch.real", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.reciprocal(input,out=None)", "id": "torch.reciprocal", "summary": "Returns a new tensor with the reciprocal of the elements of input\n\nouti=1inputi\\text{out}_{i} = \\frac{1}{\\text{input}_{i}}\n\nouti\u200b=inputi\u200b1\u200b\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([-0.4595, -2.1219, -1.4314,  0.7298])\n&gt;&gt;&gt; torch.reciprocal(a)\ntensor([-2.1763, -0.4713, -0.6986,  1.3702])\n\n\n", "description": "", "code-info": {"name": "torch.reciprocal", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.remainder(input,other,out=None)", "id": "torch.remainder", "summary": "Computes the element-wise remainder of division.\nThe divisor and dividend may contain both for integer and floating point\nnumbers", "description": "", "code-info": {"name": "torch.remainder", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the dividend"}, {"name": "other", "is_optional": false, "type": "float", "description": "(Tensor or python:float) \u2013 the divisor that may be either a number or a\nTensor of the same shape as the dividend"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.round(input,out=None)", "id": "torch.round", "summary": "Returns a new tensor with each of the elements of input rounded\nto the closest integer.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 0.9920,  0.6077,  0.9734, -1.0362])\n&gt;&gt;&gt; torch.round(a)\ntensor([ 1.,  1.,  1., -1.])\n\n\n", "description": "", "code-info": {"name": "torch.round", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.rsqrt(input,out=None)", "id": "torch.rsqrt", "summary": "Returns a new tensor with the reciprocal of the square-root of each of\nthe elements of input.\n\nouti=1inputi\\text{out}_{i} = \\frac{1}{\\sqrt{\\text{input}_{i}}}\n\nouti\u200b=inputi\u200b\u200b1\u200b\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([-0.0370,  0.2970,  1.5420, -0.9105])\n&gt;&gt;&gt; torch.rsqrt(a)\ntensor([    nan,  1.8351,  0.8053,     nan])\n\n\n", "description": "", "code-info": {"name": "torch.rsqrt", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.distributions.poisson.Poisson(rate,validate_args=None)", "id": "torch.distributions.poisson.Poisson", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily\nCreates a Poisson distribution parameterized by rate, the rate parameter.\nSamples are nonnegative integers, with a pmf given by\n\nrateke\u2212ratek!\\mathrm{rate}^k \\frac{e^{-\\mathrm{rate}}}{k!}\n\nratekk!e\u2212rate\u200b\n\nExample:\n&gt;&gt;&gt; m = Poisson(torch.tensor([4]))\n&gt;&gt;&gt; m.sample()\ntensor([ 3.])\n\n\n\nParameters\nrate (Number, Tensor) \u2013 the rate parameter\n\n\n\n\narg_constraints = {'rate': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nsupport = IntegerGreaterThan(lower_bound=0)\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.poisson.Poisson", "parameters": [{"name": "rate", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli(temperature,probs=None,logits=None,validate_args=None)", "id": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution\nCreates a RelaxedBernoulli distribution, parametrized by\ntemperature, and either probs or logits\n(but not both)", "description": "", "code-info": {"name": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli", "parameters": [{"name": "temperature", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 relaxation temperature"}, {"name": "probs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Number, Tensor) \u2013 the probability of sampling 1"}, {"name": "logits", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli(temperature,probs=None,logits=None,validate_args=None)", "id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a LogitRelaxedBernoulli distribution parameterized by probs\nor logits (but not both), which is the logit of a RelaxedBernoulli\ndistribution.\nSamples are logits of values in (0, 1)", "description": "", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli", "parameters": [{"name": "temperature", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 relaxation temperature"}, {"name": "probs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Number, Tensor) \u2013 the probability of sampling 1"}, {"name": "logits", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical(temperature,probs=None,logits=None,validate_args=None)", "id": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution\nCreates a RelaxedOneHotCategorical distribution parametrized by\ntemperature, and either probs or logits.\nThis is a relaxed version of the OneHotCategorical distribution, so\nits samples are on simplex, and are reparametrizable.\nExample:\n&gt;&gt;&gt; m = RelaxedOneHotCategorical(torch.tensor([2.2]),\n                                 torch.tensor([0.1, 0.2, 0.3, 0.4]))\n&gt;&gt;&gt; m.sample()\ntensor([ 0.1294,  0.2324,  0.3859,  0.2523])\n\n\n\nParameters\n\ntemperature (Tensor) \u2013 relaxation temperature\nprobs (Tensor) \u2013 event probabilities\nlogits (Tensor) \u2013 the log probability of each event.\n\n\n\n\n\narg_constraints = {'logits': Real(), 'probs': Simplex()}\u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nproperty logits\u00b6\n\n\n\n\nproperty probs\u00b6\n\n\n\n\nsupport = Simplex()\u00b6\n\n\n\n\nproperty temperature\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical", "parameters": [{"name": "temperature", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 relaxation temperature"}, {"name": "probs", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor) \u2013 event probabilities"}, {"name": "logits", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.studentT.StudentT(df,loc=0.0,scale=1.0,validate_args=None)", "id": "torch.distributions.studentT.StudentT", "summary": "Bases: torch.distributions.distribution.Distribution\nCreates a Student\u2019s t-distribution parameterized by degree of\nfreedom df, mean loc and scale scale.\nExample:\n&gt;&gt;&gt; m = StudentT(torch.tensor([2.0]))\n&gt;&gt;&gt; m.sample()  # Student's t-distributed with degrees of freedom=2\ntensor([ 0.1046])\n\n\n\nParameters\n\ndf (python:float or Tensor) \u2013 degrees of freedom\nloc (python:float or Tensor) \u2013 mean of the distribution\nscale (python:float or Tensor) \u2013 scale of the distribution\n\n\n\n\n\narg_constraints = {'df': GreaterThan(lower_bound=0.0), 'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nrsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nsupport = Real()\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.studentT.StudentT", "parameters": [{"name": "df", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 degrees of freedom"}, {"name": "loc", "is_optional": true, "type": "float", "default_value": "0.0", "description": "(python:float or Tensor) \u2013 mean of the distribution"}, {"name": "scale", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.transformed_distribution.TransformedDistribution(base_distribution,transforms,validate_args=None)", "id": "torch.distributions.transformed_distribution.TransformedDistribution", "summary": "Bases: torch.distributions.distribution.Distribution\nExtension of the Distribution class, which applies a sequence of Transforms\nto a base distribution", "description": "", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution", "parameters": [{"name": "base_distribution", "is_optional": false, "type": "others", "description": ""}, {"name": "transforms", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.uniform.Uniform(low,high,validate_args=None)", "id": "torch.distributions.uniform.Uniform", "summary": "Bases: torch.distributions.distribution.Distribution\nGenerates uniformly distributed random samples from the half-open interval\n[low, high).\nExample:\n&gt;&gt;&gt; m = Uniform(torch.tensor([0.0]), torch.tensor([5.0]))\n&gt;&gt;&gt; m.sample()  # uniformly distributed in the range [0.0, 5.0)\ntensor([ 2.3418])\n\n\n\nParameters\n\nlow (python:float or Tensor) \u2013 lower range (inclusive).\nhigh (python:float or Tensor) \u2013 upper range (exclusive).\n\n\n\n\n\narg_constraints = {'high': Dependent(), 'low': Dependent()}\u00b6\n\n\n\n\ncdf(value) \u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nhas_rsample = True\u00b6\n\n\n\n\nicdf(value) \u00b6\n\n\n\n\nlog_prob(value) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nrsample(sample_shape=torch.Size([])) \u00b6\n\n\n\n\nproperty stddev\u00b6\n\n\n\n\nproperty support\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.uniform.Uniform", "parameters": [{"name": "low", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 lower range (inclusive)."}, {"name": "high", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.ParameterList(parameters=None)", "id": "torch.nn.ParameterList", "summary": "Holds parameters in a list.\nParameterList can be indexed like a regular Python\nlist, but parameters it contains are properly registered, and will be\nvisible by all Module methods.\n\nParameters\nparameters (iterable, optional) \u2013 an iterable of Parameter to add\n\n\nExample:\nclass MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)])\n\n    def forward(self, x):\n        # ParameterList can act as an iterable, or be indexed using ints\n        for i, p in enumerate(self.params):\n            x = self.params[i // 2].mm(x) + p.mm(x)\n        return x\n\n\n\n\nappend(parameter) \u00b6\nAppends a given parameter at the end of the list.\n\nParameters\nparameter (nn.Parameter) \u2013 parameter to append\n\n\n\n\n\n\nextend(parameters) \u00b6\nAppends parameters from a Python iterable to the end of the list.\n\nParameters\nparameters (iterable) \u2013 iterable of parameters to append\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.ParameterList", "parameters": [{"name": "parameters", "is_optional": true, "type": "others", "default_value": "None", "description": "(iterable, optional) \u2013 an iterable of Parameter to add"}]}},
{"code": "torch.nn.ParameterDict(parameters=None)", "id": "torch.nn.ParameterDict", "summary": "Holds parameters in a dictionary.\nParameterDict can be indexed like a regular Python dictionary, but parameters it\ncontains are properly registered, and will be visible by all Module methods.\nParameterDict is an ordered dictionary that respects\n\nthe order of insertion, and\nin update(), the order of the merged OrderedDict\nor another ParameterDict (the argument to\nupdate()).\n\nNote that update() with other unordered mapping\ntypes (e.g., Python\u2019s plain dict) does not preserve the order of the\nmerged mapping.\n\nParameters\nparameters (iterable, optional) \u2013 a mapping (dictionary) of\n(string : Parameter) or an iterable of key-value pairs\nof type (string, Parameter)\n\n\nExample:\nclass MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.params = nn.ParameterDict({\n                'left': nn.Parameter(torch.randn(5, 10)),\n                'right': nn.Parameter(torch.randn(5, 10))\n        })\n\n    def forward(self, x, choice):\n        x = self.params[choice].mm(x)\n        return x\n\n\n\n\nclear() \u00b6\nRemove all items from the ParameterDict.\n\n\n\n\nitems() \u00b6\nReturn an iterable of the ParameterDict key/value pairs.\n\n\n\n\nkeys() \u00b6\nReturn an iterable of the ParameterDict keys.\n\n\n\n\npop(key) \u00b6\nRemove key from the ParameterDict and return its parameter.\n\nParameters\nkey (string) \u2013 key to pop from the ParameterDict\n\n\n\n\n\n\nupdate(parameters) \u00b6\nUpdate the ParameterDict with the key-value pairs from a\nmapping or an iterable, overwriting existing keys.\n\nNote\nIf parameters is an OrderedDict, a ParameterDict, or\nan iterable of key-value pairs, the order of new elements in it is preserved.\n\n\nParameters\nparameters (iterable) \u2013 a mapping (dictionary) from string to\nParameter, or an iterable of\nkey-value pairs of type (string, Parameter)\n\n\n\n\n\n\nvalues() \u00b6\nReturn an iterable of the ParameterDict values.\n\n\n", "description": "", "code-info": {"name": "torch.nn.ParameterDict", "parameters": [{"name": "parameters", "is_optional": true, "type": "others", "default_value": "None", "description": "(iterable, optional) \u2013 a mapping (dictionary) of\n(string : Parameter) or an iterable of key-value pairs\nof type (string, Parameter)"}]}},
{"code": "torch.nn.Conv1d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')", "id": "torch.nn.Conv1d", "summary": "Applies a 1D convolution over an input signal composed of several input\nplanes.\nIn the simplest case, the output value of the layer with input size\n(N,Cin,L)(N, C_{\\text{in}}, L)(N,Cin\u200b,L)\n\n and output (N,Cout,Lout)(N, C_{\\text{out}}, L_{\\text{out}})(N,Cout\u200b,Lout\u200b)\n\n can be\nprecisely described as:\n\nout(Ni,Coutj)=bias(Coutj)+\u2211k=0Cin\u22121weight(Coutj,k)\u22c6input(Ni,k)\\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n\\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{\\text{out}_j}, k)\n\\star \\text{input}(N_i, k)\n\nout(Ni\u200b,Coutj\u200b\u200b)=bias(Coutj\u200b\u200b)+k=0\u2211Cin\u200b\u22121\u200bweight(Coutj\u200b\u200b,k)\u22c6input(Ni\u200b,k)\n\nwhere \u22c6\\star\u22c6\n\n is the valid cross-correlation operator,\nNNN\n\n is a batch size, CCC\n\n denotes a number of channels,\nLLL\n\n is a length of signal sequence.\n\nstride controls the stride for the cross-correlation, a single\nnumber or a one-element tuple.\npadding controls the amount of implicit zero-paddings on both sides\nfor padding number of points.\ndilation controls the spacing between the kernel points; also\nknown as the \u00e0 trous algorithm", "description": "", "code-info": {"name": "torch.nn.Conv1d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels in the input image"}, {"name": "out_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels produced by the convolution"}, {"name": "kernel_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 Size of the convolving kernel"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 Stride of the convolution. Default: 1"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple, optional) \u2013 Zero-padding added to both sides of\nthe input. Default: 0\npadding_mode (string, optional) \u2013 zeros"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 Spacing between kernel\nelements. Default: 1"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 Number of blocked connections from input\nchannels to output channels. Default: 1"}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, adds a learnable bias to the output. Default: True\n\n\n\n\nShape:\nInput: (N,Cin,Lin)(N, C_{in}, L_{in})(N,Cin\u200b,Lin\u200b)\n\n\nOutput: (N,Cout,Lout)(N, C_{out}, L_{out})(N,Cout\u200b,Lout\u200b)\n\n where\n\nLout=\u230aLin+2\u00d7padding\u2212dilation\u00d7(kernel_size\u22121)\u22121stride+1\u230bL_{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n          \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\n\nLout\u200b=\u230astrideLin\u200b+2\u00d7padding\u2212dilation\u00d7(kernel_size\u22121)\u22121\u200b+1\u230b\n\n\n\n\n\n\nVariables\n\n~Conv1d.weight (Tensor) \u2013 the learnable weights of the module of shape\n(out_channels,in_channelsgroups,kernel_size)(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}}, \\text{kernel\\_size})(out_channels,groupsin_channels\u200b,kernel_size)\n\n.\nThe values of these weights are sampled from\nU(\u2212k,k)\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})U(\u2212k\u200b,k\u200b)\n\n where\nk=1Cin\u2217kernel_sizek = \\frac{1}{C_\\text{in} * \\text{kernel\\_size}}k=Cin\u200b\u2217kernel_size1\u200b\n\n\n~Conv1d.bias (Tensor) \u2013 the learnable bias of the module of shape\n(out_channels). If bias is True, then the values of these weights are\nsampled from U(\u2212k,k)\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})U(\u2212k\u200b,k\u200b)\n\n where\nk=1Cin\u2217kernel_sizek = \\frac{1}{C_\\text{in} * \\text{kernel\\_size}}k=Cin\u200b\u2217kernel_size1\u200b\n\n\n\n\n\nExamples:\n&gt;&gt;&gt; m = nn.Conv1d(16, 33, 3, stride=2)\n&gt;&gt;&gt; input = torch.randn(20, 16, 50)\n&gt;&gt;&gt; output = m(input)\n\n\n"}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": "(string, optional) \u2013 zeros\ndilation (python:int or tuple, optional) \u2013 Spacing between kernel\nelements. Default: 1\ngroups (python:int, optional) \u2013 Number of blocked connections from input\nchannels to output channels. Default: 1\nbias (bool, optional) \u2013 If True, adds a learnable bias to the output. Default: True"}]}},
{"code": "torch.Tensor.rsqrt()", "id": "torch.Tensor.rsqrt", "summary": "See torch.rsqrt()\n", "description": "", "code-info": {"name": "torch.Tensor.rsqrt", "parameters": []}},
{"code": "torch.Tensor.rsqrt_()", "id": "torch.Tensor.rsqrt_", "summary": "In-place version of rsqrt()\n", "description": "", "code-info": {"name": "torch.Tensor.rsqrt_", "parameters": []}},
{"code": "torch.Tensor.scatter(dim,index,source)", "id": "torch.Tensor.scatter", "summary": "Out-of-place version of torch.Tensor.scatter_()\n", "description": "", "code-info": {"name": "torch.Tensor.scatter", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}, {"name": "source", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.scatter_(dim,index,src)", "id": "torch.Tensor.scatter_", "summary": "Writes all values from the tensor src into self at the indices\nspecified in the index tensor", "description": "", "code-info": {"name": "torch.Tensor.scatter_", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the axis along which to index"}, {"name": "index", "is_optional": false, "type": "tensor", "description": "(LongTensor) \u2013 the indices of elements to scatter,\ncan be either empty or the same size of src.\nWhen empty, the operation returns identity"}, {"name": "src", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the source element(s) to scatter,\nincase value is not specified\nvalue (python:float) \u2013 the source element(s) to scatter,\nincase src is not specified"}]}},
{"code": "torch.Tensor.scatter_add_(dim,index,other)", "id": "torch.Tensor.scatter_add_", "summary": "Adds all values from the tensor other into self at the indices\nspecified in the index tensor in a similar fashion as\nscatter_()", "description": "", "code-info": {"name": "torch.Tensor.scatter_add_", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the axis along which to index"}, {"name": "index", "is_optional": false, "type": "tensor", "description": "(LongTensor) \u2013 the indices of elements to scatter and add,\ncan be either empty or the same size of src.\nWhen empty, the operation returns identity."}, {"name": "other", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the source elements to scatter and add"}]}},
{"code": "torch.Tensor.scatter_add(dim,index,source)", "id": "torch.Tensor.scatter_add", "summary": "Out-of-place version of torch.Tensor.scatter_add_()\n", "description": "", "code-info": {"name": "torch.Tensor.scatter_add", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}, {"name": "source", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.select(dim,index)", "id": "torch.Tensor.select", "summary": "Slices the self tensor along the selected dimension at the given index.\nThis function returns a tensor with the given dimension removed.\n\nParameters\n\ndim (python:int) \u2013 the dimension to slice\nindex (python:int) \u2013 the index to select with\n\n\n\n\nNote\nselect() is equivalent to slicing", "description": "", "code-info": {"name": "torch.Tensor.select", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the dimension to slice"}, {"name": "index", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the index to select with"}]}},
{"code": "torch.Tensor.set_(source=None,storage_offset=0,size=None,stride=None)", "id": "torch.Tensor.set_", "summary": "Sets the underlying storage, size, and strides", "description": "", "code-info": {"name": "torch.Tensor.set_", "parameters": [{"name": "source", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor or Storage) \u2013 the tensor or storage to use"}, {"name": "storage_offset", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 the offset in the storage"}, {"name": "size", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.Size, optional) \u2013 the desired size. Defaults to the size of the source."}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 the desired stride. Defaults to C-contiguous strides."}]}},
{"code": "torch.Tensor.share_memory_()", "id": "torch.Tensor.share_memory_", "summary": "Moves the underlying storage to shared memory.\nThis is a no-op if the underlying storage is already in shared memory\nand for CUDA tensors", "description": "", "code-info": {"name": "torch.Tensor.share_memory_", "parameters": []}},
{"code": "torch.Tensor.short()", "id": "torch.Tensor.short", "summary": "self.short() is equivalent to self.to(torch.int16)", "description": "", "code-info": {"name": "torch.Tensor.short", "parameters": []}},
{"code": "torch.Tensor.sigmoid()", "id": "torch.Tensor.sigmoid", "summary": "See torch.sigmoid()\n", "description": "", "code-info": {"name": "torch.Tensor.sigmoid", "parameters": []}},
{"code": "torch.Tensor.sigmoid_()", "id": "torch.Tensor.sigmoid_", "summary": "In-place version of sigmoid()\n", "description": "", "code-info": {"name": "torch.Tensor.sigmoid_", "parameters": []}},
{"code": "torch.Tensor.sign()", "id": "torch.Tensor.sign", "summary": "See torch.sign()\n", "description": "", "code-info": {"name": "torch.Tensor.sign", "parameters": []}},
{"code": "torch.Tensor.sign_()", "id": "torch.Tensor.sign_", "summary": "In-place version of sign()\n", "description": "", "code-info": {"name": "torch.Tensor.sign_", "parameters": []}},
{"code": "torch.Tensor.sin()", "id": "torch.Tensor.sin", "summary": "See torch.sin()\n", "description": "", "code-info": {"name": "torch.Tensor.sin", "parameters": []}},
{"code": "torch.Tensor.sin_()", "id": "torch.Tensor.sin_", "summary": "In-place version of sin()\n", "description": "", "code-info": {"name": "torch.Tensor.sin_", "parameters": []}},
{"code": "torch.Tensor.sinh()", "id": "torch.Tensor.sinh", "summary": "See torch.sinh()\n", "description": "", "code-info": {"name": "torch.Tensor.sinh", "parameters": []}},
{"code": "torch.Tensor.sinh_()", "id": "torch.Tensor.sinh_", "summary": "In-place version of sinh()\n", "description": "", "code-info": {"name": "torch.Tensor.sinh_", "parameters": []}},
{"code": "torch.sigmoid(input,out=None)", "id": "torch.sigmoid", "summary": "Returns a new tensor with the sigmoid of the elements of input.\n\nouti=11+e\u2212inputi\\text{out}_{i} = \\frac{1}{1 + e^{-\\text{input}_{i}}}\n\nouti\u200b=1+e\u2212inputi\u200b1\u200b\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 0.9213,  1.0887, -0.8858, -1.7683])\n&gt;&gt;&gt; torch.sigmoid(a)\ntensor([ 0.7153,  0.7481,  0.2920,  0.1458])\n\n\n", "description": "", "code-info": {"name": "torch.sigmoid", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.sign(input,out=None)", "id": "torch.sign", "summary": "Returns a new tensor with the signs of the elements of input.\n\nouti=sgn\u2061(inputi)\\text{out}_{i} = \\operatorname{sgn}(\\text{input}_{i})\n\nouti\u200b=sgn(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.tensor([0.7, -1.2, 0., 2.3])\n&gt;&gt;&gt; a\ntensor([ 0.7000, -1.2000,  0.0000,  2.3000])\n&gt;&gt;&gt; torch.sign(a)\ntensor([ 1., -1.,  0.,  1.])\n\n\n", "description": "", "code-info": {"name": "torch.sign", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.sin(input,out=None)", "id": "torch.sin", "summary": "Returns a new tensor with the sine of the elements of input.\n\nouti=sin\u2061(inputi)\\text{out}_{i} = \\sin(\\text{input}_{i})\n\nouti\u200b=sin(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([-0.5461,  0.1347, -2.7266, -0.2746])\n&gt;&gt;&gt; torch.sin(a)\ntensor([-0.5194,  0.1343, -0.4032, -0.2711])\n\n\n", "description": "", "code-info": {"name": "torch.sin", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.sinh(input,out=None)", "id": "torch.sinh", "summary": "Returns a new tensor with the hyperbolic sine of the elements of\ninput.\n\nouti=sinh\u2061(inputi)\\text{out}_{i} = \\sinh(\\text{input}_{i})\n\nouti\u200b=sinh(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 0.5380, -0.8632, -0.1265,  0.9399])\n&gt;&gt;&gt; torch.sinh(a)\ntensor([ 0.5644, -0.9744, -0.1268,  1.0845])\n\n\n", "description": "", "code-info": {"name": "torch.sinh", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.sqrt(input,out=None)", "id": "torch.sqrt", "summary": "Returns a new tensor with the square-root of the elements of input.\n\nouti=inputi\\text{out}_{i} = \\sqrt{\\text{input}_{i}}\n\nouti\u200b=inputi\u200b\u200b\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([-2.0755,  1.0226,  0.0831,  0.4806])\n&gt;&gt;&gt; torch.sqrt(a)\ntensor([    nan,  1.0112,  0.2883,  0.6933])\n\n\n", "description": "", "code-info": {"name": "torch.sqrt", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.tan(input,out=None)", "id": "torch.tan", "summary": "Returns a new tensor with the tangent of the elements of input.\n\nouti=tan\u2061(inputi)\\text{out}_{i} = \\tan(\\text{input}_{i})\n\nouti\u200b=tan(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([-1.2027, -1.7687,  0.4412, -1.3856])\n&gt;&gt;&gt; torch.tan(a)\ntensor([-2.5930,  4.9859,  0.4722, -5.3366])\n\n\n", "description": "", "code-info": {"name": "torch.tan", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.tanh(input,out=None)", "id": "torch.tanh", "summary": "Returns a new tensor with the hyperbolic tangent of the elements\nof input.\n\nouti=tanh\u2061(inputi)\\text{out}_{i} = \\tanh(\\text{input}_{i})\n\nouti\u200b=tanh(inputi\u200b)\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 0.8986, -0.7279,  1.1745,  0.2611])\n&gt;&gt;&gt; torch.tanh(a)\ntensor([ 0.7156, -0.6218,  0.8257,  0.2553])\n\n\n", "description": "", "code-info": {"name": "torch.tanh", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.trunc(input,out=None)", "id": "torch.trunc", "summary": "Returns a new tensor with the truncated integer values of\nthe elements of input.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4)\n&gt;&gt;&gt; a\ntensor([ 3.4742,  0.5466, -0.8008, -0.9079])\n&gt;&gt;&gt; torch.trunc(a)\ntensor([ 3.,  0., -0., -0.])\n\n\n", "description": "", "code-info": {"name": "torch.trunc", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.argmax()", "id": "torch.argmax", "summary": "\n\ntorch.argmax(input) \u2192 LongTensor\n\n\nReturns the indices of the maximum value of all elements in the input tensor.\nThis is the second value returned by torch.max()", "description": "", "code-info": {"name": "torch.argmax", "parameters": []}},
{"code": "sig-prename descclassname(input)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim,keepdim=False)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.argmin()", "id": "torch.argmin", "summary": "\n\ntorch.argmin(input) \u2192 LongTensor\n\n\nReturns the indices of the minimum value of all elements in the input tensor.\nThis is the second value returned by torch.min()", "description": "", "code-info": {"name": "torch.argmin", "parameters": []}},
{"code": "sig-prename descclassname(input)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim,keepdim=False,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.weibull.Weibull(scale,concentration,validate_args=None)", "id": "torch.distributions.weibull.Weibull", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution\nSamples from a two-parameter Weibull distribution.\nExample\n&gt;&gt;&gt; m = Weibull(torch.tensor([1.0]), torch.tensor([1.0]))\n&gt;&gt;&gt; m.sample()  # sample from a Weibull distribution with scale=1, concentration=1\ntensor([ 0.4784])\n\n\n\nParameters\n\nscale (python:float or Tensor) \u2013 Scale parameter of distribution (lambda).\nconcentration (python:float or Tensor) \u2013 Concentration parameter of distribution (k/shape).\n\n\n\n\n\narg_constraints = {'concentration': GreaterThan(lower_bound=0.0), 'scale': GreaterThan(lower_bound=0.0)}\u00b6\n\n\n\n\nentropy() \u00b6\n\n\n\n\nexpand(batch_shape, _instance=None) \u00b6\n\n\n\n\nproperty mean\u00b6\n\n\n\n\nsupport = GreaterThan(lower_bound=0.0)\u00b6\n\n\n\n\nproperty variance\u00b6\n\n\n", "description": "", "code-info": {"name": "torch.distributions.weibull.Weibull", "parameters": [{"name": "scale", "is_optional": false, "type": "float", "description": "(python:float or Tensor) \u2013 Scale parameter of distribution (lambda)."}, {"name": "concentration", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.transforms.Transform(cache_size=0)", "id": "torch.distributions.transforms.Transform", "summary": "Abstract class for invertable transformations with computable log\ndet jacobians", "description": "", "code-info": {"name": "torch.distributions.transforms.Transform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 Size of cache. If zero, no caching is done. If one,\nthe latest single value is cached. Only 0 and 1 are supported."}]}},
{"code": "torch.distributions.transforms.ComposeTransform(parts)", "id": "torch.distributions.transforms.ComposeTransform", "summary": "Composes multiple transforms in a chain.\nThe transforms being composed are responsible for caching.\n\nParameters\nparts (list of Transform) \u2013 A list of transforms to compose.\n\n\n", "description": "", "code-info": {"name": "torch.distributions.transforms.ComposeTransform", "parameters": [{"name": "parts", "is_optional": false, "type": "others", "description": "(list of Transform) \u2013 A list of transforms to compose."}]}},
{"code": "torch.distributions.transforms.ExpTransform(cache_size=0)", "id": "torch.distributions.transforms.ExpTransform", "summary": "Transform via the mapping y=exp\u2061(x)y = \\exp(x)y=exp(x)\n\n.\n", "description": "", "code-info": {"name": "torch.distributions.transforms.ExpTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.distributions.transforms.PowerTransform(exponent,cache_size=0)", "id": "torch.distributions.transforms.PowerTransform", "summary": "Transform via the mapping y=xexponenty = x^{\\text{exponent}}y=xexponent\n\n.\n", "description": "", "code-info": {"name": "torch.distributions.transforms.PowerTransform", "parameters": [{"name": "exponent", "is_optional": false, "type": "others", "description": ""}, {"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.distributions.transforms.SigmoidTransform(cache_size=0)", "id": "torch.distributions.transforms.SigmoidTransform", "summary": "Transform via the mapping y=11+exp\u2061(\u2212x)y = \\frac{1}{1 + \\exp(-x)}y=1+exp(\u2212x)1\u200b\n\n and x=logit(y)x = \\text{logit}(y)x=logit(y)\n\n.\n", "description": "", "code-info": {"name": "torch.distributions.transforms.SigmoidTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.distributions.transforms.AbsTransform(cache_size=0)", "id": "torch.distributions.transforms.AbsTransform", "summary": "Transform via the mapping y=\u2223x\u2223y = |x|y=\u2223x\u2223\n\n.\n", "description": "", "code-info": {"name": "torch.distributions.transforms.AbsTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.distributions.transforms.AffineTransform(loc,scale,event_dim=0,cache_size=0)", "id": "torch.distributions.transforms.AffineTransform", "summary": "Transform via the pointwise affine mapping y=loc+scale\u00d7xy = \\text{loc} + \\text{scale} \\times xy=loc+scale\u00d7x\n\n.\n\nParameters\n\nloc (Tensor or python:float) \u2013 Location parameter.\nscale (Tensor or python:float) \u2013 Scale parameter.\nevent_dim (python:int) \u2013 Optional size of event_shape", "description": "", "code-info": {"name": "torch.distributions.transforms.AffineTransform", "parameters": [{"name": "loc", "is_optional": false, "type": "float", "description": "(Tensor or python:float) \u2013 Location parameter."}, {"name": "scale", "is_optional": false, "type": "float", "description": "(Tensor or python:float) \u2013 Scale parameter."}, {"name": "event_dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.distributions.transforms.SoftmaxTransform(cache_size=0)", "id": "torch.distributions.transforms.SoftmaxTransform", "summary": "Transform from unconstrained space to the simplex via y=exp\u2061(x)y = \\exp(x)y=exp(x)\n\n then\nnormalizing.\nThis is not bijective and cannot be used for HMC", "description": "", "code-info": {"name": "torch.distributions.transforms.SoftmaxTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.distributions.transforms.StickBreakingTransform(cache_size=0)", "id": "torch.distributions.transforms.StickBreakingTransform", "summary": "Transform from unconstrained space to the simplex of one additional\ndimension via a stick-breaking process.\nThis transform arises as an iterated sigmoid transform in a stick-breaking\nconstruction of the Dirichlet distribution: the first logit is\ntransformed via sigmoid to the first probability and the probability of\neverything else, and then the process recurses.\nThis is bijective and appropriate for use in HMC; however it mixes\ncoordinates together and is less appropriate for optimization.\n", "description": "", "code-info": {"name": "torch.distributions.transforms.StickBreakingTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.distributions.transforms.LowerCholeskyTransform(cache_size=0)", "id": "torch.distributions.transforms.LowerCholeskyTransform", "summary": "Transform from unconstrained matrices to lower-triangular matrices with\nnonnegative diagonal entries.\nThis is useful for parameterizing positive definite matrices in terms of\ntheir Cholesky factorization.\n", "description": "", "code-info": {"name": "torch.distributions.transforms.LowerCholeskyTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.distributions.transforms.CatTransform(tseq,dim=0,lengths=None)", "id": "torch.distributions.transforms.CatTransform", "summary": "Transform functor that applies a sequence of transforms tseq\ncomponent-wise to each submatrix at dim, of length lengths[dim],\nin a way compatible with torch.cat().\n\nExample::x0 = torch.cat([torch.range(1, 10), torch.range(1, 10)], dim=0)\nx = torch.cat([x0, x0], dim=0)\nt0 = CatTransform([ExpTransform(), identity_transform], dim=0, lengths=[10, 10])\nt = CatTransform([t0, t0], dim=0, lengths=[20, 20])\ny = t(x)\n\n\n", "description": "", "code-info": {"name": "torch.distributions.transforms.CatTransform", "parameters": [{"name": "tseq", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "lengths", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.distributions.transforms.StackTransform(tseq,dim=0)", "id": "torch.distributions.transforms.StackTransform", "summary": "Transform functor that applies a sequence of transforms tseq\ncomponent-wise to each submatrix at dim\nin a way compatible with torch.stack().\n\nExample::x = torch.stack([torch.range(1, 10), torch.range(1, 10)], dim=1)\nt = StackTransform([ExpTransform(), identity_transform], dim=1)\ny = t(x)\n\n\n", "description": "", "code-info": {"name": "torch.distributions.transforms.StackTransform", "parameters": [{"name": "tseq", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.nn.Conv2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')", "id": "torch.nn.Conv2d", "summary": "Applies a 2D convolution over an input signal composed of several input\nplanes.\nIn the simplest case, the output value of the layer with input size\n(N,Cin,H,W)(N, C_{\\text{in}}, H, W)(N,Cin\u200b,H,W)\n\n and output (N,Cout,Hout,Wout)(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})(N,Cout\u200b,Hout\u200b,Wout\u200b)\n\n\ncan be precisely described as:\n\nout(Ni,Coutj)=bias(Coutj)+\u2211k=0Cin\u22121weight(Coutj,k)\u22c6input(Ni,k)\\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n\\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n\nout(Ni\u200b,Coutj\u200b\u200b)=bias(Coutj\u200b\u200b)+k=0\u2211Cin\u200b\u22121\u200bweight(Coutj\u200b\u200b,k)\u22c6input(Ni\u200b,k)\n\nwhere \u22c6\\star\u22c6\n\n is the valid 2D cross-correlation operator,\nNNN\n\n is a batch size, CCC\n\n denotes a number of channels,\nHHH\n\n is a height of input planes in pixels, and WWW\n\n is\nwidth in pixels.\n\nstride controls the stride for the cross-correlation, a single\nnumber or a tuple.\npadding controls the amount of implicit zero-paddings on both\nsides for padding number of points for each dimension.\ndilation controls the spacing between the kernel points; also\nknown as the \u00e0 trous algorithm", "description": "", "code-info": {"name": "torch.nn.Conv2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels in the input image"}, {"name": "out_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels produced by the convolution"}, {"name": "kernel_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 Size of the convolving kernel"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 Stride of the convolution. Default: 1"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple, optional) \u2013 Zero-padding added to both sides of the input. Default: 0\npadding_mode (string, optional) \u2013 zeros"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 Spacing between kernel elements. Default: 1"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 Number of blocked connections from input channels to output channels. Default: 1"}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, adds a learnable bias to the output. Default: True\n\n\n\n\nShape:\nInput: (N,Cin,Hin,Win)(N, C_{in}, H_{in}, W_{in})(N,Cin\u200b,Hin\u200b,Win\u200b)\n\n\nOutput: (N,Cout,Hout,Wout)(N, C_{out}, H_{out}, W_{out})(N,Cout\u200b,Hout\u200b,Wout\u200b)\n\n where\n\nHout=\u230aHin+2\u00d7padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121stride[0]+1\u230bH_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n          \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n\nHout\u200b=\u230astride[0]Hin\u200b+2\u00d7padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121\u200b+1\u230b\n\n\nWout=\u230aWin+2\u00d7padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121stride[1]+1\u230bW_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n          \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n\nWout\u200b=\u230astride[1]Win\u200b+2\u00d7padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121\u200b+1\u230b\n\n\n\n\n\n\nVariables\n\n~Conv2d.weight (Tensor) \u2013 the learnable weights of the module of shape\n(out_channels,in_channelsgroups,(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},(out_channels,groupsin_channels\u200b,\n\n\nkernel_size[0],kernel_size[1])\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})kernel_size[0],kernel_size[1])\n\n.\nThe values of these weights are sampled from\nU(\u2212k,k)\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})U(\u2212k\u200b,k\u200b)\n\n where\nk=1Cin\u2217\u220fi=01kernel_size[i]k = \\frac{1}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}k=Cin\u200b\u2217\u220fi=01\u200bkernel_size[i]1\u200b\n\n\n~Conv2d.bias (Tensor) \u2013 the learnable bias of the module of shape (out_channels). If bias is True,\nthen the values of these weights are\nsampled from U(\u2212k,k)\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})U(\u2212k\u200b,k\u200b)\n\n where\nk=1Cin\u2217\u220fi=01kernel_size[i]k = \\frac{1}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}k=Cin\u200b\u2217\u220fi=01\u200bkernel_size[i]1\u200b\n\n\n\n\n\nExamples:\n&gt;&gt;&gt; # With square kernels and equal stride\n&gt;&gt;&gt; m = nn.Conv2d(16, 33, 3, stride=2)\n&gt;&gt;&gt; # non-square kernels and unequal stride and with padding\n&gt;&gt;&gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n&gt;&gt;&gt; # non-square kernels and unequal stride and with padding and dilation\n&gt;&gt;&gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n&gt;&gt;&gt; input = torch.randn(20, 16, 50, 100)\n&gt;&gt;&gt; output = m(input)\n\n\n"}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": "(string, optional) \u2013 zeros\ndilation (python:int or tuple, optional) \u2013 Spacing between kernel elements. Default: 1\ngroups (python:int, optional) \u2013 Number of blocked connections from input channels to output channels. Default: 1\nbias (bool, optional) \u2013 If True, adds a learnable bias to the output. Default: True"}]}},
{"code": "torch.nn.Conv3d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')", "id": "torch.nn.Conv3d", "summary": "Applies a 3D convolution over an input signal composed of several input\nplanes.\nIn the simplest case, the output value of the layer with input size (N,Cin,D,H,W)(N, C_{in}, D, H, W)(N,Cin\u200b,D,H,W)\n\n\nand output (N,Cout,Dout,Hout,Wout)(N, C_{out}, D_{out}, H_{out}, W_{out})(N,Cout\u200b,Dout\u200b,Hout\u200b,Wout\u200b)\n\n can be precisely described as:\n\nout(Ni,Coutj)=bias(Coutj)+\u2211k=0Cin\u22121weight(Coutj,k)\u22c6input(Ni,k)out(N_i, C_{out_j}) = bias(C_{out_j}) +\n                        \\sum_{k = 0}^{C_{in} - 1} weight(C_{out_j}, k) \\star input(N_i, k)\n\nout(Ni\u200b,Coutj\u200b\u200b)=bias(Coutj\u200b\u200b)+k=0\u2211Cin\u200b\u22121\u200bweight(Coutj\u200b\u200b,k)\u22c6input(Ni\u200b,k)\n\nwhere \u22c6\\star\u22c6\n\n is the valid 3D cross-correlation operator\n\nstride controls the stride for the cross-correlation.\npadding controls the amount of implicit zero-paddings on both\nsides for padding number of points for each dimension.\ndilation controls the spacing between the kernel points; also known as the \u00e0 trous algorithm.\nIt is harder to describe, but this link has a nice visualization of what dilation does.\ngroups controls the connections between inputs and outputs.\nin_channels and out_channels must both be divisible by\ngroups", "description": "", "code-info": {"name": "torch.nn.Conv3d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels in the input image"}, {"name": "out_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels produced by the convolution"}, {"name": "kernel_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 Size of the convolving kernel"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 Stride of the convolution. Default: 1"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple, optional) \u2013 Zero-padding added to all three sides of the input. Default: 0\npadding_mode (string, optional) \u2013 zeros"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 Spacing between kernel elements. Default: 1"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 Number of blocked connections from input channels to output channels. Default: 1"}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, adds a learnable bias to the output. Default: True\n\n\n\n\nShape:\nInput: (N,Cin,Din,Hin,Win)(N, C_{in}, D_{in}, H_{in}, W_{in})(N,Cin\u200b,Din\u200b,Hin\u200b,Win\u200b)\n\n\nOutput: (N,Cout,Dout,Hout,Wout)(N, C_{out}, D_{out}, H_{out}, W_{out})(N,Cout\u200b,Dout\u200b,Hout\u200b,Wout\u200b)\n\n where\n\nDout=\u230aDin+2\u00d7padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121stride[0]+1\u230bD_{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n      \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n\nDout\u200b=\u230astride[0]Din\u200b+2\u00d7padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121\u200b+1\u230b\n\n\nHout=\u230aHin+2\u00d7padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121stride[1]+1\u230bH_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n      \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n\nHout\u200b=\u230astride[1]Hin\u200b+2\u00d7padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121\u200b+1\u230b\n\n\nWout=\u230aWin+2\u00d7padding[2]\u2212dilation[2]\u00d7(kernel_size[2]\u22121)\u22121stride[2]+1\u230bW_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] - \\text{dilation}[2]\n      \\times (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor\n\nWout\u200b=\u230astride[2]Win\u200b+2\u00d7padding[2]\u2212dilation[2]\u00d7(kernel_size[2]\u22121)\u22121\u200b+1\u230b\n\n\n\n\n\n\nVariables\n\n~Conv3d.weight (Tensor) \u2013 the learnable weights of the module of shape\n(out_channels,in_channelsgroups,(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},(out_channels,groupsin_channels\u200b,\n\n\nkernel_size[0],kernel_size[1],kernel_size[2])\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]}, \\text{kernel\\_size[2]})kernel_size[0],kernel_size[1],kernel_size[2])\n\n.\nThe values of these weights are sampled from\nU(\u2212k,k)\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})U(\u2212k\u200b,k\u200b)\n\n where\nk=1Cin\u2217\u220fi=02kernel_size[i]k = \\frac{1}{C_\\text{in} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}k=Cin\u200b\u2217\u220fi=02\u200bkernel_size[i]1\u200b\n\n\n~Conv3d.bias (Tensor) \u2013 the learnable bias of the module of shape (out_channels). If bias is True,\nthen the values of these weights are\nsampled from U(\u2212k,k)\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})U(\u2212k\u200b,k\u200b)\n\n where\nk=1Cin\u2217\u220fi=02kernel_size[i]k = \\frac{1}{C_\\text{in} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}k=Cin\u200b\u2217\u220fi=02\u200bkernel_size[i]1\u200b\n\n\n\n\n\nExamples:\n&gt;&gt;&gt; # With square kernels and equal stride\n&gt;&gt;&gt; m = nn.Conv3d(16, 33, 3, stride=2)\n&gt;&gt;&gt; # non-square kernels and unequal stride and with padding\n&gt;&gt;&gt; m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0))\n&gt;&gt;&gt; input = torch.randn(20, 16, 10, 50, 100)\n&gt;&gt;&gt; output = m(input)\n\n\n"}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": "(string, optional) \u2013 zeros\ndilation (python:int or tuple, optional) \u2013 Spacing between kernel elements. Default: 1\ngroups (python:int, optional) \u2013 Number of blocked connections from input channels to output channels. Default: 1\nbias (bool, optional) \u2013 If True, adds a learnable bias to the output. Default: True"}]}},
{"code": "torch.Tensor.size()", "id": "torch.Tensor.size", "summary": "Returns the size of the self tensor", "description": "", "code-info": {"name": "torch.Tensor.size", "parameters": []}},
{"code": "torch.Tensor.slogdet()", "id": "torch.Tensor.slogdet", "summary": "See torch.slogdet()\n", "description": "", "code-info": {"name": "torch.Tensor.slogdet", "parameters": []}},
{"code": "torch.Tensor.solve(A)", "id": "torch.Tensor.solve", "summary": "See torch.solve()\n", "description": "", "code-info": {"name": "torch.Tensor.solve", "parameters": [{"name": "A", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.sort(dim=-1,descending=False)", "id": "torch.Tensor.sort", "summary": "See torch.sort()\n", "description": "", "code-info": {"name": "torch.Tensor.sort", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}, {"name": "descending", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.split(split_size,dim=0)", "id": "torch.Tensor.split", "summary": "See torch.split()\n", "description": "", "code-info": {"name": "torch.Tensor.split", "parameters": [{"name": "split_size", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.Tensor.sparse_mask(input,mask)", "id": "torch.Tensor.sparse_mask", "summary": "Returns a new SparseTensor with values from Tensor input filtered\nby indices of mask and values are ignored", "description": "", "code-info": {"name": "torch.Tensor.sparse_mask", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 an input Tensor"}, {"name": "mask", "is_optional": false, "type": "tensor", "description": "(SparseTensor) \u2013 a SparseTensor which we filter input based on its indices"}]}},
{"code": "torch.Tensor.sparse_dim()", "id": "torch.Tensor.sparse_dim", "summary": "If self is a sparse COO tensor (i.e., with torch.sparse_coo layout),\nthis returns the number of sparse dimensions", "description": "", "code-info": {"name": "torch.Tensor.sparse_dim", "parameters": []}},
{"code": "torch.Tensor.sqrt()", "id": "torch.Tensor.sqrt", "summary": "See torch.sqrt()\n", "description": "", "code-info": {"name": "torch.Tensor.sqrt", "parameters": []}},
{"code": "torch.Tensor.sqrt_()", "id": "torch.Tensor.sqrt_", "summary": "In-place version of sqrt()\n", "description": "", "code-info": {"name": "torch.Tensor.sqrt_", "parameters": []}},
{"code": "torch.Tensor.squeeze(dim=None)", "id": "torch.Tensor.squeeze", "summary": "See torch.squeeze()\n", "description": "", "code-info": {"name": "torch.Tensor.squeeze", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.squeeze_(dim=None)", "id": "torch.Tensor.squeeze_", "summary": "In-place version of squeeze()\n", "description": "", "code-info": {"name": "torch.Tensor.squeeze_", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.std(dim=None,unbiased=True,keepdim=False)", "id": "torch.Tensor.std", "summary": "See torch.std()\n", "description": "", "code-info": {"name": "torch.Tensor.std", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.stft(n_fft,hop_length=None,win_length=None,window=None,center=True,pad_mode='reflect',normalized=False,onesided=True)", "id": "torch.Tensor.stft", "summary": "See torch.stft()\n\nWarning\nThis function changed signature at version 0.4.1", "description": "", "code-info": {"name": "torch.Tensor.stft", "parameters": [{"name": "n_fft", "is_optional": false, "type": "others", "description": ""}, {"name": "hop_length", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "win_length", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "window", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "center", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "pad_mode", "is_optional": true, "type": "string", "default_value": "'reflect'", "description": ""}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.Tensor.storage()", "id": "torch.Tensor.storage", "summary": "Returns the underlying storage.\n", "description": "", "code-info": {"name": "torch.Tensor.storage", "parameters": []}},
{"code": "torch.Tensor.storage_offset()", "id": "torch.Tensor.storage_offset", "summary": "Returns self tensor\u2019s offset in the underlying storage in terms of\nnumber of storage elements (not bytes).\nExample:\n&gt;&gt;&gt; x = torch.tensor([1, 2, 3, 4, 5])\n&gt;&gt;&gt; x.storage_offset()\n0\n&gt;&gt;&gt; x[3:].storage_offset()\n3\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.storage_offset", "parameters": []}},
{"code": "torch.Tensor.storage_type()", "id": "torch.Tensor.storage_type", "summary": "Returns the type of the underlying storage.\n", "description": "", "code-info": {"name": "torch.Tensor.storage_type", "parameters": []}},
{"code": "torch.Tensor.stride(dim)", "id": "torch.Tensor.stride", "summary": "Returns the stride of self tensor.\nStride is the jump necessary to go from one element to the next one in the\nspecified dimension dim", "description": "", "code-info": {"name": "torch.Tensor.stride", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": "(python:int, optional) \u2013 the desired dimension in which stride is required"}]}},
{"code": "torch.Tensor.sub(value,other)", "id": "torch.Tensor.sub", "summary": "Subtracts a scalar or tensor from self tensor", "description": "", "code-info": {"name": "torch.Tensor.sub", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.sub_(x)", "id": "torch.Tensor.sub_", "summary": "In-place version of sub()\n", "description": "", "code-info": {"name": "torch.Tensor.sub_", "parameters": [{"name": "x", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.sum(dim=None,keepdim=False,dtype=None)", "id": "torch.Tensor.sum", "summary": "See torch.sum()\n", "description": "", "code-info": {"name": "torch.Tensor.sum", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.dist(input,other,p=2)", "id": "torch.dist", "summary": "Returns the p-norm of (input - other)\nThe shapes of input and other must be\nbroadcastable.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nother (Tensor) \u2013 the Right-hand-side input tensor\np (python:float, optional) \u2013 the norm to be computed\n\n\n\nExample:\n&gt;&gt;&gt; x = torch.randn(4)\n&gt;&gt;&gt; x\ntensor([-1.5393, -0.8675,  0.5916,  1.6321])\n&gt;&gt;&gt; y = torch.randn(4)\n&gt;&gt;&gt; y\ntensor([ 0.0967, -1.0511,  0.6295,  0.8360])\n&gt;&gt;&gt; torch.dist(x, y, 3.5)\ntensor(1.6727)\n&gt;&gt;&gt; torch.dist(x, y, 3)\ntensor(1.6973)\n&gt;&gt;&gt; torch.dist(x, y, 0)\ntensor(inf)\n&gt;&gt;&gt; torch.dist(x, y, 1)\ntensor(2.6537)\n\n\n", "description": "", "code-info": {"name": "torch.dist", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "other", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the Right-hand-side input tensor"}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": "(python:float, optional) \u2013 the norm to be computed"}]}},
{"code": "torch.logsumexp(input,dim,keepdim=False,out=None)", "id": "torch.logsumexp", "summary": "Returns the log of summed exponentials of each row of the input\ntensor in the given dimension dim", "description": "", "code-info": {"name": "torch.logsumexp", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "dim", "is_optional": false, "type": "int", "description": "(python:int or tuple of python:ints) \u2013 the dimension or dimensions to reduce."}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 whether the output tensor has dim retained or not."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.mean()", "id": "torch.mean", "summary": "\n\ntorch.mean(input) \u2192 Tensor\n\n\nReturns the mean value of all elements in the input tensor.\n\nParameters\ninput (Tensor) \u2013 the input tensor.\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(1, 3)\n&gt;&gt;&gt; a\ntensor([[ 0.2294, -0.5481,  1.3288]])\n&gt;&gt;&gt; torch.mean(a)\ntensor(0.3367)\n\n\n\n\ntorch.mean(input, dim, keepdim=False, out=None) \u2192 Tensor\n\n\nReturns the mean value of each row of the input tensor in the given\ndimension dim", "description": "", "code-info": {"name": "torch.mean", "parameters": []}},
{"code": "sig-prename descclassname(input)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim,keepdim=False,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.median()", "id": "torch.median", "summary": "\n\ntorch.median(input) \u2192 Tensor\n\n\nReturns the median value of all elements in the input tensor.\n\nParameters\ninput (Tensor) \u2013 the input tensor.\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(1, 3)\n&gt;&gt;&gt; a\ntensor([[ 1.5219, -1.5212,  0.2202]])\n&gt;&gt;&gt; torch.median(a)\ntensor(0.2202)\n\n\n\n\ntorch.median(input, dim=-1, keepdim=False, values=None, indices=None) -&gt; (Tensor, LongTensor)\n\n\nReturns a namedtuple (values, indices) where values is the median\nvalue of each row of the input tensor in the given dimension\ndim", "description": "", "code-info": {"name": "torch.median", "parameters": []}},
{"code": "sig-prename descclassname(input)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim=-1,keepdim=False,values=None,indices=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "values", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "indices", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.mode(input,dim=-1,keepdim=False,values=None,indices=None)", "id": "torch.mode", "summary": "Returns a namedtuple (values, indices) where values is the mode\nvalue of each row of the input tensor in the given dimension\ndim, i.e", "description": "", "code-info": {"name": "torch.mode", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 the dimension to reduce."}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 whether the output tensor has dim retained or not."}, {"name": "values", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor"}, {"name": "indices", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output index tensor"}]}},
{"code": "torch.norm(input,p='fro',dim=None,keepdim=False,out=None,dtype=None)", "id": "torch.norm", "summary": "Returns the matrix norm or vector norm of a given tensor.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor\np (python:int, python:float, inf, -inf, 'fro', 'nuc', optional) \u2013 the order of norm", "description": "", "code-info": {"name": "torch.norm", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor"}, {"name": "p", "is_optional": true, "type": "string", "default_value": "'fro'", "description": "(python:int, python:float, inf, -inf, 'fro', 'nuc', optional) \u2013 the order of norm. Default: 'fro'\nThe following norms can be calculated:\n\n\n\n\n\n\n\nord\nmatrix norm\nvector norm\n\n\n\nNone\nFrobenius norm\n2-norm\n\n\u2019fro\u2019\nFrobenius norm\n\u2013\n\n\u2018nuc\u2019\nnuclear norm\n\u2013\n\nOther\nas vec norm when dim is None\nsum(abs(x)**ord)**(1./ord)\n\n\n\n"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, 2-tuple of python:ints, 2-list of python:ints, optional) \u2013 If it is an int,\nvector norm will be calculated, if it is 2-tuple of ints, matrix norm\nwill be calculated. If the value is None, matrix norm will be calculated\nwhen the input tensor only has two dimensions, vector norm will be\ncalculated when the input tensor only has one dimension. If the input\ntensor has more than two dimensions, the vector norm will be applied to\nlast dimension."}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 whether the output tensors have dim\nretained or not. Ignored if dim = None and\nout = None. Default: False"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor. Ignored if\ndim = None and out = None."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of\nreturned tensor. If specified, the input tensor is casted to\n:attr:\u2019dtype\u2019 while performing the operation. Default: None."}]}},
{"code": "torch.prod()", "id": "torch.prod", "summary": "\n\ntorch.prod(input, dtype=None) \u2192 Tensor\n\n\nReturns the product of all elements in the input tensor.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed", "description": "", "code-info": {"name": "torch.prod", "parameters": []}},
{"code": "sig-prename descclassname(input,dtype=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.ConvTranspose1d(in_channels,out_channels,kernel_size,stride=1,padding=0,output_padding=0,groups=1,bias=True,dilation=1,padding_mode='zeros')", "id": "torch.nn.ConvTranspose1d", "summary": "Applies a 1D transposed convolution operator over an input image\ncomposed of several input planes.\nThis module can be seen as the gradient of Conv1d with respect to its input.\nIt is also known as a fractionally-strided convolution or\na deconvolution (although it is not an actual deconvolution operation).\n\nstride controls the stride for the cross-correlation.\npadding controls the amount of implicit zero-paddings on both\nsides for dilation * (kernel_size - 1) - padding number of points", "description": "", "code-info": {"name": "torch.nn.ConvTranspose1d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels in the input image"}, {"name": "out_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels produced by the convolution"}, {"name": "kernel_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 Size of the convolving kernel"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 Stride of the convolution. Default: 1"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple, optional) \u2013 dilation * (kernel_size - 1) - padding zero-padding\nwill be added to both sides of the input. Default: 0"}, {"name": "output_padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple, optional) \u2013 Additional size added to one side\nof the output shape. Default: 0"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 Number of blocked connections from input channels to output channels. Default: 1"}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, adds a learnable bias to the output. Default: True"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}]}},
{"code": "torch.nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride=1,padding=0,output_padding=0,groups=1,bias=True,dilation=1,padding_mode='zeros')", "id": "torch.nn.ConvTranspose2d", "summary": "Applies a 2D transposed convolution operator over an input image\ncomposed of several input planes.\nThis module can be seen as the gradient of Conv2d with respect to its input.\nIt is also known as a fractionally-strided convolution or\na deconvolution (although it is not an actual deconvolution operation).\n\nstride controls the stride for the cross-correlation.\npadding controls the amount of implicit zero-paddings on both\nsides for dilation * (kernel_size - 1) - padding number of points", "description": "", "code-info": {"name": "torch.nn.ConvTranspose2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels in the input image"}, {"name": "out_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels produced by the convolution"}, {"name": "kernel_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 Size of the convolving kernel"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 Stride of the convolution. Default: 1"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple, optional) \u2013 dilation * (kernel_size - 1) - padding zero-padding\nwill be added to both sides of each dimension in the input. Default: 0"}, {"name": "output_padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple, optional) \u2013 Additional size added to one side\nof each dimension in the output shape. Default: 0"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 Number of blocked connections from input channels to output channels. Default: 1"}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, adds a learnable bias to the output. Default: True"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}]}},
{"code": "torch.Tensor.sum_to_size(*size)", "id": "torch.Tensor.sum_to_size", "summary": "Sum this tensor to size.\nsize must be broadcastable to this tensor size.\n\nParameters\nsize (python:int...) \u2013 a sequence of integers defining the shape of the output tensor.\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.sum_to_size", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.svd(some=True,compute_uv=True)", "id": "torch.Tensor.svd", "summary": "See torch.svd()\n", "description": "", "code-info": {"name": "torch.Tensor.svd", "parameters": [{"name": "some", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "compute_uv", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.Tensor.symeig(eigenvectors=False,upper=True)", "id": "torch.Tensor.symeig", "summary": "See torch.symeig()\n", "description": "", "code-info": {"name": "torch.Tensor.symeig", "parameters": [{"name": "eigenvectors", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.Tensor.t()", "id": "torch.Tensor.t", "summary": "See torch.t()\n", "description": "", "code-info": {"name": "torch.Tensor.t", "parameters": []}},
{"code": "torch.Tensor.t_()", "id": "torch.Tensor.t_", "summary": "In-place version of t()\n", "description": "", "code-info": {"name": "torch.Tensor.t_", "parameters": []}},
{"code": "torch.Tensor.to(*args,**kwargs)", "id": "torch.Tensor.to", "summary": "Performs Tensor dtype and/or device conversion", "description": "", "code-info": {"name": "torch.Tensor.to", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.to_mkldnn()", "id": "torch.Tensor.to_mkldnn", "summary": "Returns a copy of the tensor in torch.mkldnn layout.\n", "description": "", "code-info": {"name": "torch.Tensor.to_mkldnn", "parameters": []}},
{"code": "torch.Tensor.take(indices)", "id": "torch.Tensor.take", "summary": "See torch.take()\n", "description": "", "code-info": {"name": "torch.Tensor.take", "parameters": [{"name": "indices", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.tan()", "id": "torch.Tensor.tan", "summary": "See torch.tan()\n", "description": "", "code-info": {"name": "torch.Tensor.tan", "parameters": []}},
{"code": "torch.Tensor.tan_()", "id": "torch.Tensor.tan_", "summary": "In-place version of tan()\n", "description": "", "code-info": {"name": "torch.Tensor.tan_", "parameters": []}},
{"code": "torch.Tensor.tanh()", "id": "torch.Tensor.tanh", "summary": "See torch.tanh()\n", "description": "", "code-info": {"name": "torch.Tensor.tanh", "parameters": []}},
{"code": "torch.Tensor.tanh_()", "id": "torch.Tensor.tanh_", "summary": "In-place version of tanh()\n", "description": "", "code-info": {"name": "torch.Tensor.tanh_", "parameters": []}},
{"code": "torch.Tensor.tolist()", "id": "torch.Tensor.tolist", "summary": "\u201d\ntolist() -&gt; list or number\nReturns the tensor as a (nested) list", "description": "", "code-info": {"name": "torch.Tensor.tolist", "parameters": []}},
{"code": "torch.Tensor.topk(k,dim=None,largest=True,sorted=True)", "id": "torch.Tensor.topk", "summary": "See torch.topk()\n", "description": "", "code-info": {"name": "torch.Tensor.topk", "parameters": [{"name": "k", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "largest", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "sorted", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim,keepdim=False,dtype=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.std()", "id": "torch.std", "summary": "\n\ntorch.std(input, unbiased=True) \u2192 Tensor\n\n\nReturns the standard-deviation of all elements in the input tensor.\nIf unbiased is False, then the standard-deviation will be calculated\nvia the biased estimator", "description": "", "code-info": {"name": "torch.std", "parameters": []}},
{"code": "sig-prename descclassname(input,unbiased=True)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim,keepdim=False,unbiased=True,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.std_mean()", "id": "torch.std_mean", "summary": "\n\ntorch.std_mean(input, unbiased=True) -&gt; (Tensor, Tensor)\n\n\nReturns the standard-deviation and mean of all elements in the input tensor.\nIf unbiased is False, then the standard-deviation will be calculated\nvia the biased estimator", "description": "", "code-info": {"name": "torch.std_mean", "parameters": []}},
{"code": "sig-prename descclassname(input,unbiased=True)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim,keepdim=False,unbiased=True)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.sum()", "id": "torch.sum", "summary": "\n\ntorch.sum(input, dtype=None) \u2192 Tensor\n\n\nReturns the sum of all elements in the input tensor.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed", "description": "", "code-info": {"name": "torch.sum", "parameters": []}},
{"code": "torch.nn.ConvTranspose3d(in_channels,out_channels,kernel_size,stride=1,padding=0,output_padding=0,groups=1,bias=True,dilation=1,padding_mode='zeros')", "id": "torch.nn.ConvTranspose3d", "summary": "Applies a 3D transposed convolution operator over an input image composed of several input\nplanes.\nThe transposed convolution operator multiplies each input value element-wise by a learnable kernel,\nand sums over the outputs from all input feature planes.\nThis module can be seen as the gradient of Conv3d with respect to its input.\nIt is also known as a fractionally-strided convolution or\na deconvolution (although it is not an actual deconvolution operation).\n\nstride controls the stride for the cross-correlation.\npadding controls the amount of implicit zero-paddings on both\nsides for dilation * (kernel_size - 1) - padding number of points", "description": "", "code-info": {"name": "torch.nn.ConvTranspose3d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels in the input image"}, {"name": "out_channels", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of channels produced by the convolution"}, {"name": "kernel_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 Size of the convolving kernel"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 Stride of the convolution. Default: 1"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple, optional) \u2013 dilation * (kernel_size - 1) - padding zero-padding\nwill be added to both sides of each dimension in the input. Default: 0"}, {"name": "output_padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple, optional) \u2013 Additional size added to one side\nof each dimension in the output shape. Default: 0"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 Number of blocked connections from input channels to output channels. Default: 1"}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, adds a learnable bias to the output. Default: True"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}]}},
{"code": "torch.Tensor.to_sparse(sparseDims)", "id": "torch.Tensor.to_sparse", "summary": "Returns a sparse copy of the tensor", "description": "", "code-info": {"name": "torch.Tensor.to_sparse", "parameters": [{"name": "sparseDims", "is_optional": false, "type": "int", "description": "(python:int, optional) \u2013 the number of sparse dimensions to include in the new sparse tensor"}]}},
{"code": "torch.Tensor.trace()", "id": "torch.Tensor.trace", "summary": "See torch.trace()\n", "description": "", "code-info": {"name": "torch.Tensor.trace", "parameters": []}},
{"code": "torch.Tensor.transpose(dim0,dim1)", "id": "torch.Tensor.transpose", "summary": "See torch.transpose()\n", "description": "", "code-info": {"name": "torch.Tensor.transpose", "parameters": [{"name": "dim0", "is_optional": false, "type": "others", "description": ""}, {"name": "dim1", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.transpose_(dim0,dim1)", "id": "torch.Tensor.transpose_", "summary": "In-place version of transpose()\n", "description": "", "code-info": {"name": "torch.Tensor.transpose_", "parameters": [{"name": "dim0", "is_optional": false, "type": "others", "description": ""}, {"name": "dim1", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.triangular_solve(A,upper=True,transpose=False,unitriangular=False)", "id": "torch.Tensor.triangular_solve", "summary": "See torch.triangular_solve()\n", "description": "", "code-info": {"name": "torch.Tensor.triangular_solve", "parameters": [{"name": "A", "is_optional": false, "type": "others", "description": ""}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "transpose", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "unitriangular", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.tril(k=0)", "id": "torch.Tensor.tril", "summary": "See torch.tril()\n", "description": "", "code-info": {"name": "torch.Tensor.tril", "parameters": [{"name": "k", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.Tensor.tril_(k=0)", "id": "torch.Tensor.tril_", "summary": "In-place version of tril()\n", "description": "", "code-info": {"name": "torch.Tensor.tril_", "parameters": [{"name": "k", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.Tensor.triu(k=0)", "id": "torch.Tensor.triu", "summary": "See torch.triu()\n", "description": "", "code-info": {"name": "torch.Tensor.triu", "parameters": [{"name": "k", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.Tensor.triu_(k=0)", "id": "torch.Tensor.triu_", "summary": "In-place version of triu()\n", "description": "", "code-info": {"name": "torch.Tensor.triu_", "parameters": [{"name": "k", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "sig-prename descclassname(input,dtype=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim,keepdim=False,dtype=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.unique(input,sorted=True,return_inverse=False,return_counts=False,dim=None)", "id": "torch.unique", "summary": "Returns the unique elements of the input tensor.\n\nNote\nThis function is different from torch.unique_consecutive() in the sense that\nthis function also eliminates non-consecutive duplicate values.\n\n\nNote\nCurrently in the CUDA implementation and the CPU implementation when dim is specified,\ntorch.unique always sort the tensor at the beginning regardless of the sort argument.\nSorting could be slow, so if your input tensor is already sorted, it is recommended to use\ntorch.unique_consecutive() which avoids the sorting.\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor\nsorted (bool) \u2013 Whether to sort the unique elements in ascending order\nbefore returning as output.\nreturn_inverse (bool) \u2013 Whether to also return the indices for where\nelements in the original input ended up in the returned unique list.\nreturn_counts (bool) \u2013 Whether to also return the counts for each unique\nelement.\ndim (python:int) \u2013 the dimension to apply unique", "description": "", "code-info": {"name": "torch.unique", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor"}, {"name": "sorted", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 Whether to sort the unique elements in ascending order\nbefore returning as output."}, {"name": "return_inverse", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 Whether to also return the indices for where\nelements in the original input ended up in the returned unique list."}, {"name": "return_counts", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 Whether to also return the counts for each unique\nelement."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 the dimension to apply unique. If None, the unique of the\nflattened input is returned. default: None"}]}},
{"code": "torch.unique_consecutive(input,return_inverse=False,return_counts=False,dim=None)", "id": "torch.unique_consecutive", "summary": "Eliminates all but the first element from every consecutive group of equivalent elements.\n\nNote\nThis function is different from torch.unique() in the sense that this function\nonly eliminates consecutive duplicate values", "description": "", "code-info": {"name": "torch.unique_consecutive", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor"}, {"name": "return_inverse", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 Whether to also return the indices for where\nelements in the original input ended up in the returned unique list."}, {"name": "return_counts", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 Whether to also return the counts for each unique\nelement."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 the dimension to apply unique. If None, the unique of the\nflattened input is returned. default: None"}]}},
{"code": "torch.var()", "id": "torch.var", "summary": "\n\ntorch.var(input, unbiased=True) \u2192 Tensor\n\n\nReturns the variance of all elements in the input tensor.\nIf unbiased is False, then the variance will be calculated via the\nbiased estimator", "description": "", "code-info": {"name": "torch.var", "parameters": []}},
{"code": "sig-prename descclassname(input,unbiased=True)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim,keepdim=False,unbiased=True,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.var_mean()", "id": "torch.var_mean", "summary": "\n\ntorch.var_mean(input, unbiased=True) -&gt; (Tensor, Tensor)\n\n\nReturns the variance and mean of all elements in the input tensor.\nIf unbiased is False, then the variance will be calculated via the\nbiased estimator", "description": "", "code-info": {"name": "torch.var_mean", "parameters": []}},
{"code": "sig-prename descclassname(input,unbiased=True)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.Unfold(kernel_size,dilation=1,padding=0,stride=1)", "id": "torch.nn.Unfold", "summary": "Extracts sliding local blocks from a batched input tensor.\nConsider a batched input tensor of shape (N,C,\u2217)(N, C, *)(N,C,\u2217)\n\n,\nwhere NNN\n\n is the batch dimension, CCC\n\n is the channel dimension,\nand \u2217*\u2217\n\n represent arbitrary spatial dimensions", "description": "", "code-info": {"name": "torch.nn.Unfold", "parameters": [{"name": "kernel_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 the size of the sliding blocks\nstride (python:int or tuple, optional) \u2013 the stride of the sliding blocks in the input\nspatial dimensions. Default: 1\npadding (python:int or tuple, optional) \u2013 implicit zero padding to be added on\nboth sides of input. Default: 0"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 a parameter that controls the\nstride of elements within the\nneighborhood. Default: 1\n\n\n\n\nIf kernel_size, dilation, padding or\nstride is an int or a tuple of length 1, their values will be\nreplicated across all spatial dimensions.\nFor the case of two input spatial dimensions this operation is sometimes\ncalled im2col.\n\n\nNote\nFold calculates each combined value in the resulting\nlarge tensor by summing all values from all containing blocks.\nUnfold extracts the values in the local blocks by\ncopying from the large tensor. So, if the blocks overlap, they are not\ninverses of each other.\nIn general, folding and unfolding operations are related as\nfollows. Consider Fold and\nUnfold instances created with the same\nparameters:\n&gt;&gt;&gt; fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...)\n&gt;&gt;&gt; fold = nn.Fold(output_size=..., **fold_params)\n&gt;&gt;&gt; unfold = nn.Unfold(**fold_params)\n\n\nThen for any (supported) input tensor the following\nequality holds:\nfold(unfold(input)) == divisor * input\n\n\nwhere divisor is a tensor that depends only on the shape\nand dtype of the input:\n&gt;&gt;&gt; input_ones = torch.ones(input.shape, dtype=input.dtype)\n&gt;&gt;&gt; divisor = fold(unfold(input_ones))\n\n\nWhen the divisor tensor contains no zero elements, then\nfold and unfold operations are inverses of each\nother (upto constant divisor).\n\n\nWarning\nCurrently, only 4-D input tensors (batched image-like tensors) are\nsupported.\n\n\nShape:\nInput: (N,C,\u2217)(N, C, *)(N,C,\u2217)\n\n\nOutput: (N,C\u00d7\u220f(kernel_size),L)(N, C \\times \\prod(\\text{kernel\\_size}), L)(N,C\u00d7\u220f(kernel_size),L)\n\n as described above\n\n\n\nExamples:\n&gt;&gt;&gt; unfold = nn.Unfold(kernel_size=(2, 3))\n&gt;&gt;&gt; input = torch.randn(2, 5, 3, 4)\n&gt;&gt;&gt; output = unfold(input)\n&gt;&gt;&gt; # each patch contains 30 values (2x3=6 vectors, each of 5 channels)\n&gt;&gt;&gt; # 4 blocks (2x3 kernels) in total in the 3x4 input\n&gt;&gt;&gt; output.size()\ntorch.Size([2, 30, 4])\n\n&gt;&gt;&gt; # Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n&gt;&gt;&gt; inp = torch.randn(1, 3, 10, 12)\n&gt;&gt;&gt; w = torch.randn(2, 3, 4, 5)\n&gt;&gt;&gt; inp_unf = torch.nn.functional.unfold(inp, (4, 5))\n&gt;&gt;&gt; out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n&gt;&gt;&gt; out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))\n&gt;&gt;&gt; # or equivalently (and avoiding a copy),\n&gt;&gt;&gt; # out = out_unf.view(1, 2, 7, 8)\n&gt;&gt;&gt; (torch.nn.functional.conv2d(inp, w) - out).abs().max()\ntensor(1.9073e-06)\n\n\n"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple, optional) \u2013 implicit zero padding to be added on\nboth sides of input. Default: 0\ndilation (python:int or tuple, optional) \u2013 a parameter that controls the\nstride of elements within the\nneighborhood. Default: 1\n\n\n\n\nIf kernel_size, dilation, padding or\nstride is an int or a tuple of length 1, their values will be\nreplicated across all spatial dimensions.\nFor the case of two input spatial dimensions this operation is sometimes\ncalled im2col.\n\n\nNote\nFold calculates each combined value in the resulting\nlarge tensor by summing all values from all containing blocks.\nUnfold extracts the values in the local blocks by\ncopying from the large tensor. So, if the blocks overlap, they are not\ninverses of each other.\nIn general, folding and unfolding operations are related as\nfollows. Consider Fold and\nUnfold instances created with the same\nparameters:\n&gt;&gt;&gt; fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...)\n&gt;&gt;&gt; fold = nn.Fold(output_size=..., **fold_params)\n&gt;&gt;&gt; unfold = nn.Unfold(**fold_params)\n\n\nThen for any (supported) input tensor the following\nequality holds:\nfold(unfold(input)) == divisor * input\n\n\nwhere divisor is a tensor that depends only on the shape\nand dtype of the input:\n&gt;&gt;&gt; input_ones = torch.ones(input.shape, dtype=input.dtype)\n&gt;&gt;&gt; divisor = fold(unfold(input_ones))\n\n\nWhen the divisor tensor contains no zero elements, then\nfold and unfold operations are inverses of each\nother (upto constant divisor).\n\n\nWarning\nCurrently, only 4-D input tensors (batched image-like tensors) are\nsupported.\n\n\nShape:\nInput: (N,C,\u2217)(N, C, *)(N,C,\u2217)\n\n\nOutput: (N,C\u00d7\u220f(kernel_size),L)(N, C \\times \\prod(\\text{kernel\\_size}), L)(N,C\u00d7\u220f(kernel_size),L)\n\n as described above\n\n\n\nExamples:\n&gt;&gt;&gt; unfold = nn.Unfold(kernel_size=(2, 3))\n&gt;&gt;&gt; input = torch.randn(2, 5, 3, 4)\n&gt;&gt;&gt; output = unfold(input)\n&gt;&gt;&gt; # each patch contains 30 values (2x3=6 vectors, each of 5 channels)\n&gt;&gt;&gt; # 4 blocks (2x3 kernels) in total in the 3x4 input\n&gt;&gt;&gt; output.size()\ntorch.Size([2, 30, 4])\n\n&gt;&gt;&gt; # Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n&gt;&gt;&gt; inp = torch.randn(1, 3, 10, 12)\n&gt;&gt;&gt; w = torch.randn(2, 3, 4, 5)\n&gt;&gt;&gt; inp_unf = torch.nn.functional.unfold(inp, (4, 5))\n&gt;&gt;&gt; out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n&gt;&gt;&gt; out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))\n&gt;&gt;&gt; # or equivalently (and avoiding a copy),\n&gt;&gt;&gt; # out = out_unf.view(1, 2, 7, 8)\n&gt;&gt;&gt; (torch.nn.functional.conv2d(inp, w) - out).abs().max()\ntensor(1.9073e-06)\n\n\n"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 the stride of the sliding blocks in the input\nspatial dimensions. Default: 1\npadding (python:int or tuple, optional) \u2013 implicit zero padding to be added on\nboth sides of input. Default: 0\ndilation (python:int or tuple, optional) \u2013 a parameter that controls the\nstride of elements within the\nneighborhood. Default: 1"}]}},
{"code": "torch.nn.Fold(output_size,kernel_size,dilation=1,padding=0,stride=1)", "id": "torch.nn.Fold", "summary": "Combines an array of sliding local blocks into a large containing\ntensor.\nConsider a batched input tensor containing sliding local blocks,\ne.g., patches of images, of shape (N,C\u00d7\u220f(kernel_size),L)(N, C \\times  \\prod(\\text{kernel\\_size}), L)(N,C\u00d7\u220f(kernel_size),L)\n\n,\nwhere NNN\n\n is batch dimension, C\u00d7\u220f(kernel_size)C \\times \\prod(\\text{kernel\\_size})C\u00d7\u220f(kernel_size)\n\n\nis the number of values within a block (a block has \u220f(kernel_size)\\prod(\\text{kernel\\_size})\u220f(kernel_size)\n\n\nspatial locations each containing a CCC\n\n-channeled vector), and\nLLL\n\n is the total number of blocks", "description": "", "code-info": {"name": "torch.nn.Fold", "parameters": [{"name": "output_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 the shape of the spatial dimensions of the\noutput (i.e., output.sizes()[2:])"}, {"name": "kernel_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 the size of the sliding blocks\nstride (python:int or tuple) \u2013 the stride of the sliding blocks in the input\nspatial dimensions. Default: 1\npadding (python:int or tuple, optional) \u2013 implicit zero padding to be added on\nboth sides of input. Default: 0"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple, optional) \u2013 a parameter that controls the\nstride of elements within the\nneighborhood. Default: 1\n\n\n\n\nIf output_size, kernel_size, dilation,\npadding or stride is an int or a tuple of length 1 then\ntheir values will be replicated across all spatial dimensions.\nFor the case of two output spatial dimensions this operation is sometimes\ncalled col2im.\n\n\nNote\nFold calculates each combined value in the resulting\nlarge tensor by summing all values from all containing blocks.\nUnfold extracts the values in the local blocks by\ncopying from the large tensor. So, if the blocks overlap, they are not\ninverses of each other.\nIn general, folding and unfolding operations are related as\nfollows. Consider Fold and\nUnfold instances created with the same\nparameters:\n&gt;&gt;&gt; fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...)\n&gt;&gt;&gt; fold = nn.Fold(output_size=..., **fold_params)\n&gt;&gt;&gt; unfold = nn.Unfold(**fold_params)\n\n\nThen for any (supported) input tensor the following\nequality holds:\nfold(unfold(input)) == divisor * input\n\n\nwhere divisor is a tensor that depends only on the shape\nand dtype of the input:\n&gt;&gt;&gt; input_ones = torch.ones(input.shape, dtype=input.dtype)\n&gt;&gt;&gt; divisor = fold(unfold(input_ones))\n\n\nWhen the divisor tensor contains no zero elements, then\nfold and unfold operations are inverses of each\nother (upto constant divisor).\n\n\nWarning\nCurrently, only 4-D output tensors (batched image-like tensors) are\nsupported.\n\n\nShape:\nInput: (N,C\u00d7\u220f(kernel_size),L)(N, C \\times \\prod(\\text{kernel\\_size}), L)(N,C\u00d7\u220f(kernel_size),L)\n\n\nOutput: (N,C,output_size[0],output_size[1],\u2026\u2009)(N, C, \\text{output\\_size}[0], \\text{output\\_size}[1], \\dots)(N,C,output_size[0],output_size[1],\u2026)\n\n as described above\n\n\n\nExamples:\n&gt;&gt;&gt; fold = nn.Fold(output_size=(4, 5), kernel_size=(2, 2))\n&gt;&gt;&gt; input = torch.randn(1, 3 * 2 * 2, 12)\n&gt;&gt;&gt; output = fold(input)\n&gt;&gt;&gt; output.size()\ntorch.Size([1, 3, 4, 5])\n\n\n"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple, optional) \u2013 implicit zero padding to be added on\nboth sides of input. Default: 0\ndilation (python:int or tuple, optional) \u2013 a parameter that controls the\nstride of elements within the\nneighborhood. Default: 1\n\n\n\n\nIf output_size, kernel_size, dilation,\npadding or stride is an int or a tuple of length 1 then\ntheir values will be replicated across all spatial dimensions.\nFor the case of two output spatial dimensions this operation is sometimes\ncalled col2im.\n\n\nNote\nFold calculates each combined value in the resulting\nlarge tensor by summing all values from all containing blocks.\nUnfold extracts the values in the local blocks by\ncopying from the large tensor. So, if the blocks overlap, they are not\ninverses of each other.\nIn general, folding and unfolding operations are related as\nfollows. Consider Fold and\nUnfold instances created with the same\nparameters:\n&gt;&gt;&gt; fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...)\n&gt;&gt;&gt; fold = nn.Fold(output_size=..., **fold_params)\n&gt;&gt;&gt; unfold = nn.Unfold(**fold_params)\n\n\nThen for any (supported) input tensor the following\nequality holds:\nfold(unfold(input)) == divisor * input\n\n\nwhere divisor is a tensor that depends only on the shape\nand dtype of the input:\n&gt;&gt;&gt; input_ones = torch.ones(input.shape, dtype=input.dtype)\n&gt;&gt;&gt; divisor = fold(unfold(input_ones))\n\n\nWhen the divisor tensor contains no zero elements, then\nfold and unfold operations are inverses of each\nother (upto constant divisor).\n\n\nWarning\nCurrently, only 4-D output tensors (batched image-like tensors) are\nsupported.\n\n\nShape:\nInput: (N,C\u00d7\u220f(kernel_size),L)(N, C \\times \\prod(\\text{kernel\\_size}), L)(N,C\u00d7\u220f(kernel_size),L)\n\n\nOutput: (N,C,output_size[0],output_size[1],\u2026\u2009)(N, C, \\text{output\\_size}[0], \\text{output\\_size}[1], \\dots)(N,C,output_size[0],output_size[1],\u2026)\n\n as described above\n\n\n\nExamples:\n&gt;&gt;&gt; fold = nn.Fold(output_size=(4, 5), kernel_size=(2, 2))\n&gt;&gt;&gt; input = torch.randn(1, 3 * 2 * 2, 12)\n&gt;&gt;&gt; output = fold(input)\n&gt;&gt;&gt; output.size()\ntorch.Size([1, 3, 4, 5])\n\n\n"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int or tuple) \u2013 the stride of the sliding blocks in the input\nspatial dimensions. Default: 1\npadding (python:int or tuple, optional) \u2013 implicit zero padding to be added on\nboth sides of input. Default: 0\ndilation (python:int or tuple, optional) \u2013 a parameter that controls the\nstride of elements within the\nneighborhood. Default: 1"}]}},
{"code": "torch.nn.MaxPool1d(kernel_size,stride=None,padding=0,dilation=1,return_indices=False,ceil_mode=False)", "id": "torch.nn.MaxPool1d", "summary": "Applies a 1D max pooling over an input signal composed of several input\nplanes.\nIn the simplest case, the output value of the layer with input size (N,C,L)(N, C, L)(N,C,L)\n\n\nand output (N,C,Lout)(N, C, L_{out})(N,C,Lout\u200b)\n\n can be precisely described as:\n\nout(Ni,Cj,k)=max\u2061m=0,\u2026,kernel_size\u22121input(Ni,Cj,stride\u00d7k+m)out(N_i, C_j, k) = \\max_{m=0, \\ldots, \\text{kernel\\_size} - 1}\n        input(N_i, C_j, stride \\times k + m)\n\nout(Ni\u200b,Cj\u200b,k)=m=0,\u2026,kernel_size\u22121max\u200binput(Ni\u200b,Cj\u200b,stride\u00d7k+m)\n\nIf padding is non-zero, then the input is implicitly zero-padded on both sides\nfor padding number of points", "description": "", "code-info": {"name": "torch.nn.MaxPool1d", "parameters": [{"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "return_indices", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.trunc()", "id": "torch.Tensor.trunc", "summary": "See torch.trunc()\n", "description": "", "code-info": {"name": "torch.Tensor.trunc", "parameters": []}},
{"code": "torch.Tensor.trunc_()", "id": "torch.Tensor.trunc_", "summary": "In-place version of trunc()\n", "description": "", "code-info": {"name": "torch.Tensor.trunc_", "parameters": []}},
{"code": "torch.Tensor.type(dtype=None,non_blocking=False,**kwargs)", "id": "torch.Tensor.type", "summary": "Returns the type if dtype is not provided, else casts this object to\nthe specified type.\nIf this is already of the correct type, no copy is performed and the\noriginal object is returned.\n\nParameters\n\ndtype (python:type or string) \u2013 The desired type\nnon_blocking (bool) \u2013 If True, and the source is in pinned memory\nand destination is on the GPU or vice versa, the copy is performed\nasynchronously with respect to the host", "description": "", "code-info": {"name": "torch.Tensor.type", "parameters": [{"name": "dtype", "is_optional": true, "type": "string", "default_value": "None", "description": "(python:type or string) \u2013 The desired type"}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.type_as(tensor)", "id": "torch.Tensor.type_as", "summary": "Returns this tensor cast to the type of the given tensor.\nThis is a no-op if the tensor is already of the correct type", "description": "", "code-info": {"name": "torch.Tensor.type_as", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor which has the desired type"}]}},
{"code": "torch.Tensor.unbind(dim=0)", "id": "torch.Tensor.unbind", "summary": "See torch.unbind()\n", "description": "", "code-info": {"name": "torch.Tensor.unbind", "parameters": [{"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.Tensor.unfold(dimension,size,step)", "id": "torch.Tensor.unfold", "summary": "Returns a tensor which contains all slices of size size from\nself tensor in the dimension dimension.\nStep between two slices is given by step.\nIf sizedim is the size of dimension dimension for self, the size of\ndimension dimension in the returned tensor will be\n(sizedim - size) / step + 1.\nAn additional dimension of size size is appended in the returned tensor.\n\nParameters\n\ndimension (python:int) \u2013 dimension in which unfolding happens\nsize (python:int) \u2013 the size of each slice that is unfolded\nstep (python:int) \u2013 the step between each slice\n\n\n\nExample:\n&gt;&gt;&gt; x = torch.arange(1., 8)\n&gt;&gt;&gt; x\ntensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n&gt;&gt;&gt; x.unfold(0, 2, 1)\ntensor([[ 1.,  2.],\n        [ 2.,  3.],\n        [ 3.,  4.],\n        [ 4.,  5.],\n        [ 5.,  6.],\n        [ 6.,  7.]])\n&gt;&gt;&gt; x.unfold(0, 2, 2)\ntensor([[ 1.,  2.],\n        [ 3.,  4.],\n        [ 5.,  6.]])\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.unfold", "parameters": [{"name": "dimension", "is_optional": false, "type": "int", "description": "(python:int) \u2013 dimension in which unfolding happens"}, {"name": "size", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the size of each slice that is unfolded"}, {"name": "step", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the step between each slice"}]}},
{"code": "torch.Tensor.uniform_(from=0,to=1)", "id": "torch.Tensor.uniform_", "summary": "Fills self tensor with numbers sampled from the continuous uniform\ndistribution:\n\nP(x)=1to\u2212fromP(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n\nP(x)=to\u2212from1\u200b\n\n", "description": "", "code-info": {"name": "torch.Tensor.uniform_", "parameters": [{"name": "from", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "to", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"code": "torch.Tensor.unique(sorted=True,return_inverse=False,return_counts=False,dim=None)", "id": "torch.Tensor.unique", "summary": "Returns the unique elements of the input tensor.\nSee torch.unique()\n", "description": "", "code-info": {"name": "torch.Tensor.unique", "parameters": [{"name": "sorted", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "return_inverse", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "return_counts", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.unique_consecutive(return_inverse=False,return_counts=False,dim=None)", "id": "torch.Tensor.unique_consecutive", "summary": "Eliminates all but the first element from every consecutive group of equivalent elements.\nSee torch.unique_consecutive()\n", "description": "", "code-info": {"name": "torch.Tensor.unique_consecutive", "parameters": [{"name": "return_inverse", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "return_counts", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.Tensor.unsqueeze(dim)", "id": "torch.Tensor.unsqueeze", "summary": "See torch.unsqueeze()\n", "description": "", "code-info": {"name": "torch.Tensor.unsqueeze", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.unsqueeze_(dim)", "id": "torch.Tensor.unsqueeze_", "summary": "In-place version of unsqueeze()\n", "description": "", "code-info": {"name": "torch.Tensor.unsqueeze_", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.values()", "id": "torch.Tensor.values", "summary": "If self is a sparse COO tensor (i.e., with torch.sparse_coo layout),\nthis returns a view of the contained values tensor", "description": "", "code-info": {"name": "torch.Tensor.values", "parameters": []}},
{"code": "torch.Tensor.var(dim=None,unbiased=True,keepdim=False)", "id": "torch.Tensor.var", "summary": "See torch.var()\n", "description": "", "code-info": {"name": "torch.Tensor.var", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.Tensor.view(*shape)", "id": "torch.Tensor.view", "summary": "Returns a new tensor with the same data as the self tensor but of a\ndifferent shape.\nThe returned tensor shares the same data and must have the same number\nof elements, but may have a different size", "description": "", "code-info": {"name": "torch.Tensor.view", "parameters": [{"name": "*shape", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim,keepdim=False,unbiased=True)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.allclose(input,other,rtol=1e-05,atol=1e-08,equal_nan=False)", "id": "torch.allclose", "summary": "This function checks if all input and other satisfy the condition:\n\n\u2223input\u2212other\u2223\u2264atol+rtol\u00d7\u2223other\u2223\\lvert \\text{input} - \\text{other} \\rvert \\leq \\texttt{atol} + \\texttt{rtol} \\times \\lvert \\text{other} \\rvert\n\n\u2223input\u2212other\u2223\u2264atol+rtol\u00d7\u2223other\u2223\n\nelementwise, for all elements of input and other", "description": "", "code-info": {"name": "torch.allclose", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 first tensor to compare"}, {"name": "other", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 second tensor to compare\natol (python:float, optional) \u2013 absolute tolerance. Default: 1e-08"}, {"name": "rtol", "is_optional": true, "type": "float", "default_value": "1e-05", "description": "(python:float, optional) \u2013 relative tolerance. Default: 1e-05\nequal_nan (bool, optional) \u2013 if True, then two NaN s will be compared as equal. Default: False\n\n\n\nExample:\n&gt;&gt;&gt; torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08]))\nFalse\n&gt;&gt;&gt; torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09]))\nTrue\n&gt;&gt;&gt; torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]))\nFalse\n&gt;&gt;&gt; torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True)\nTrue\n\n\n"}, {"name": "atol", "is_optional": true, "type": "float", "default_value": "1e-08", "description": "(python:float, optional) \u2013 absolute tolerance. Default: 1e-08\nrtol (python:float, optional) \u2013 relative tolerance. Default: 1e-05"}, {"name": "equal_nan", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 if True, then two NaN s will be compared as equal. Default: False"}]}},
{"code": "torch.argsort(input,dim=-1,descending=False,out=None)", "id": "torch.argsort", "summary": "Returns the indices that sort a tensor along a given dimension in ascending\norder by value.\nThis is the second value returned by torch.sort()", "description": "", "code-info": {"name": "torch.argsort", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int, optional) \u2013 the dimension to sort along"}, {"name": "descending", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.eq(input,other,out=None)", "id": "torch.eq", "summary": "Computes element-wise equality\nThe second argument can be a number or a tensor whose shape is\nbroadcastable with the first argument.\n\nParameters\n\ninput (Tensor) \u2013 the tensor to compare\nother (Tensor or python:float) \u2013 the tensor or value to compare\nout (Tensor, optional) \u2013 the output tensor", "description": "", "code-info": {"name": "torch.eq", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to compare"}, {"name": "other", "is_optional": false, "type": "float", "description": "(Tensor or python:float) \u2013 the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor. Must be a ByteTensor"}]}},
{"code": "torch.equal(input,other)", "id": "torch.equal", "summary": "True if two tensors have the same size and elements, False otherwise.\nExample:\n&gt;&gt;&gt; torch.equal(torch.tensor([1, 2]), torch.tensor([1, 2]))\nTrue\n\n\n", "description": "", "code-info": {"name": "torch.equal", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.ge(input,other,out=None)", "id": "torch.ge", "summary": "Computes input\u2265other\\text{input} \\geq \\text{other}input\u2265other\n\n element-wise.\nThe second argument can be a number or a tensor whose shape is\nbroadcastable with the first argument.\n\nParameters\n\ninput (Tensor) \u2013 the tensor to compare\nother (Tensor or python:float) \u2013 the tensor or value to compare\nout (Tensor, optional) \u2013 the output tensor that must be a BoolTensor\n\n\nReturns\nA torch.BoolTensor containing a True at each location where comparison is true\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; torch.ge(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\ntensor([[True, True], [False, True]])\n\n\n", "description": "", "code-info": {"name": "torch.ge", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to compare"}, {"name": "other", "is_optional": false, "type": "float", "description": "(Tensor or python:float) \u2013 the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor that must be a BoolTensor"}]}},
{"code": "torch.gt(input,other,out=None)", "id": "torch.gt", "summary": "Computes input&gt;other\\text{input} &gt; \\text{other}input&gt;other\n\n element-wise.\nThe second argument can be a number or a tensor whose shape is\nbroadcastable with the first argument.\n\nParameters\n\ninput (Tensor) \u2013 the tensor to compare\nother (Tensor or python:float) \u2013 the tensor or value to compare\nout (Tensor, optional) \u2013 the output tensor that must be a BoolTensor\n\n\nReturns\nA torch.BoolTensor containing a True at each location where comparison is true\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; torch.gt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\ntensor([[False, True], [False, False]])\n\n\n", "description": "", "code-info": {"name": "torch.gt", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to compare"}, {"name": "other", "is_optional": false, "type": "float", "description": "(Tensor or python:float) \u2013 the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor that must be a BoolTensor"}]}},
{"code": "torch.isfinite()", "id": "torch.isfinite", "summary": "Returns a new tensor with boolean elements representing if each element is Finite or not.\n\n\nArguments:tensor (Tensor): A tensor to check\n\nReturns:Tensor: A torch.Tensor with dtype torch.bool containing a True at each location of finite elements and False otherwise\n\n\nExample:\n&gt;&gt;&gt; torch.isfinite(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')]))\ntensor([True,  False,  True,  False,  False])\n\n\n\n", "description": "", "code-info": {"name": "torch.isfinite", "parameters": []}},
{"code": "torch.isinf(tensor)", "id": "torch.isinf", "summary": "Returns a new tensor with boolean elements representing if each element is +/-INF or not.\n\nParameters\ntensor (Tensor) \u2013 A tensor to check\n\nReturns\nA torch.Tensor with dtype torch.bool containing a True at each location of +/-INF elements and False otherwise\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; torch.isinf(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')]))\ntensor([False,  True,  False,  True,  False])\n\n\n", "description": "", "code-info": {"name": "torch.isinf", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 A tensor to check"}]}},
{"code": "torch.isnan()", "id": "torch.isnan", "summary": "Returns a new tensor with boolean elements representing if each element is NaN or not.\n\nParameters\ninput (Tensor) \u2013 A tensor to check\n\nReturns\nA torch.BoolTensor containing a True at each location of NaN elements.\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; torch.isnan(torch.tensor([1, float('nan'), 2]))\ntensor([False, True, False])\n\n\n", "description": "", "code-info": {"name": "torch.isnan", "parameters": []}},
{"code": "torch.kthvalue(input,k,dim=None,keepdim=False,out=None)", "id": "torch.kthvalue", "summary": "Returns a namedtuple (values, indices) where values is the k th\nsmallest element of each row of the input tensor in the given dimension\ndim", "description": "", "code-info": {"name": "torch.kthvalue", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "k", "is_optional": false, "type": "int", "description": "(python:int) \u2013 k for the k-th smallest element"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 the dimension to find the kth value along"}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 whether the output tensor has dim retained or not."}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 the output tuple of (Tensor, LongTensor)\ncan be optionally given to be used as output buffers"}]}},
{"code": "torch.le(input,other,out=None)", "id": "torch.le", "summary": "Computes input\u2264other\\text{input} \\leq \\text{other}input\u2264other\n\n element-wise.\nThe second argument can be a number or a tensor whose shape is\nbroadcastable with the first argument.\n\nParameters\n\ninput (Tensor) \u2013 the tensor to compare\nother (Tensor or python:float) \u2013 the tensor or value to compare\nout (Tensor, optional) \u2013 the output tensor that must be a BoolTensor\n\n\nReturns\nA torch.BoolTensor containing a True at each location where comparison is true\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; torch.le(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\ntensor([[True, False], [True, True]])\n\n\n", "description": "", "code-info": {"name": "torch.le", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to compare"}, {"name": "other", "is_optional": false, "type": "float", "description": "(Tensor or python:float) \u2013 the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor that must be a BoolTensor"}]}},
{"code": "torch.nn.MaxPool2d(kernel_size,stride=None,padding=0,dilation=1,return_indices=False,ceil_mode=False)", "id": "torch.nn.MaxPool2d", "summary": "Applies a 2D max pooling over an input signal composed of several input\nplanes.\nIn the simplest case, the output value of the layer with input size (N,C,H,W)(N, C, H, W)(N,C,H,W)\n\n,\noutput (N,C,Hout,Wout)(N, C, H_{out}, W_{out})(N,C,Hout\u200b,Wout\u200b)\n\n and kernel_size (kH,kW)(kH, kW)(kH,kW)\n\n\ncan be precisely described as:\n\nout(Ni,Cj,h,w)=max\u2061m=0,\u2026,kH\u22121max\u2061n=0,\u2026,kW\u22121input(Ni,Cj,stride[0]\u00d7h+m,stride[1]\u00d7w+n)\\begin{aligned}\n    out(N_i, C_j, h, w) ={} &amp; \\max_{m=0, \\ldots, kH-1} \\max_{n=0, \\ldots, kW-1} \\\\\n                            &amp; \\text{input}(N_i, C_j, \\text{stride[0]} \\times h + m,\n                                           \\text{stride[1]} \\times w + n)\n\\end{aligned}\n\nout(Ni\u200b,Cj\u200b,h,w)=\u200bm=0,\u2026,kH\u22121max\u200bn=0,\u2026,kW\u22121max\u200binput(Ni\u200b,Cj\u200b,stride[0]\u00d7h+m,stride[1]\u00d7w+n)\u200b\n\nIf padding is non-zero, then the input is implicitly zero-padded on both sides\nfor padding number of points", "description": "", "code-info": {"name": "torch.nn.MaxPool2d", "parameters": [{"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "return_indices", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.MaxPool3d(kernel_size,stride=None,padding=0,dilation=1,return_indices=False,ceil_mode=False)", "id": "torch.nn.MaxPool3d", "summary": "Applies a 3D max pooling over an input signal composed of several input\nplanes.\nIn the simplest case, the output value of the layer with input size (N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W)\n\n,\noutput (N,C,Dout,Hout,Wout)(N, C, D_{out}, H_{out}, W_{out})(N,C,Dout\u200b,Hout\u200b,Wout\u200b)\n\n and kernel_size (kD,kH,kW)(kD, kH, kW)(kD,kH,kW)\n\n\ncan be precisely described as:\n\nout(Ni,Cj,d,h,w)=max\u2061k=0,\u2026,kD\u22121max\u2061m=0,\u2026,kH\u22121max\u2061n=0,\u2026,kW\u22121input(Ni,Cj,stride[0]\u00d7d+k,stride[1]\u00d7h+m,stride[2]\u00d7w+n)\\begin{aligned}\n    \\text{out}(N_i, C_j, d, h, w) ={} &amp; \\max_{k=0, \\ldots, kD-1} \\max_{m=0, \\ldots, kH-1} \\max_{n=0, \\ldots, kW-1} \\\\\n                                      &amp; \\text{input}(N_i, C_j, \\text{stride[0]} \\times d + k,\n                                                     \\text{stride[1]} \\times h + m, \\text{stride[2]} \\times w + n)\n\\end{aligned}\n\nout(Ni\u200b,Cj\u200b,d,h,w)=\u200bk=0,\u2026,kD\u22121max\u200bm=0,\u2026,kH\u22121max\u200bn=0,\u2026,kW\u22121max\u200binput(Ni\u200b,Cj\u200b,stride[0]\u00d7d+k,stride[1]\u00d7h+m,stride[2]\u00d7w+n)\u200b\n\nIf padding is non-zero, then the input is implicitly zero-padded on both sides\nfor padding number of points", "description": "", "code-info": {"name": "torch.nn.MaxPool3d", "parameters": [{"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "return_indices", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.MaxUnpool1d(kernel_size,stride=None,padding=0)", "id": "torch.nn.MaxUnpool1d", "summary": "Computes a partial inverse of MaxPool1d.\nMaxPool1d is not fully invertible, since the non-maximal values are lost.\nMaxUnpool1d takes in as input the output of MaxPool1d\nincluding the indices of the maximal values and computes a partial inverse\nin which all non-maximal values are set to zero.\n\nNote\nMaxPool1d can map several input sizes to the same output\nsizes", "description": "", "code-info": {"name": "torch.nn.MaxUnpool1d", "parameters": [{"name": "kernel_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 Size of the max pooling window."}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or tuple) \u2013 Stride of the max pooling window.\nIt is set to kernel_size by default."}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple) \u2013 Padding that was added to the input"}]}},
{"code": "torch.Tensor.view_as(other)", "id": "torch.Tensor.view_as", "summary": "View this tensor as the same size as other.\nself.view_as(other) is equivalent to self.view(other.size()).\nPlease see view() for more information about view.\n\nParameters\nother (torch.Tensor) \u2013 The result tensor has the same size\nas other.\n\n\n", "description": "", "code-info": {"name": "torch.Tensor.view_as", "parameters": [{"name": "other", "is_optional": false, "type": "tensor", "description": "(torch.Tensor) \u2013 The result tensor has the same size\nas other."}]}},
{"code": "torch.Tensor.where(condition,y)", "id": "torch.Tensor.where", "summary": "self.where(condition, y) is equivalent to torch.where(condition, self, y).\nSee torch.where()\n", "description": "", "code-info": {"name": "torch.Tensor.where", "parameters": [{"name": "condition", "is_optional": false, "type": "others", "description": ""}, {"name": "y", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.Tensor.zero_()", "id": "torch.Tensor.zero_", "summary": "Fills self tensor with zeros.\n", "description": "", "code-info": {"name": "torch.Tensor.zero_", "parameters": []}},
{"code": "torch.BoolTensor.all()", "id": "torch.BoolTensor.all", "summary": "\n\nall() \u2192 bool\n\n\nReturns True if all elements in the tensor are True, False otherwise.\nExample:\n&gt;&gt;&gt; a = torch.rand(1, 2).bool()\n&gt;&gt;&gt; a\ntensor([[False, True]], dtype=torch.bool)\n&gt;&gt;&gt; a.all()\ntensor(False, dtype=torch.bool)\n\n\n\n\nall(dim, keepdim=False, out=None) \u2192 Tensor\n\n\nReturns True if all elements in each row of the tensor in the given\ndimension dim are True, False otherwise.\nIf keepdim is True, the output tensor is of the same size as\ninput except in the dimension dim where it is of size 1.\nOtherwise, dim is squeezed (see torch.squeeze()), resulting\nin the output tensor having 1 fewer dimension than input.\n\nParameters\n\ndim (python:int) \u2013 the dimension to reduce\nkeepdim (bool) \u2013 whether the output tensor has dim retained or not\nout (Tensor, optional) \u2013 the output tensor\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.rand(4, 2).bool()\n&gt;&gt;&gt; a\ntensor([[True, True],\n        [True, False],\n        [True, True],\n        [True, True]], dtype=torch.bool)\n&gt;&gt;&gt; a.all(dim=1)\ntensor([ True, False,  True,  True], dtype=torch.bool)\n&gt;&gt;&gt; a.all(dim=0)\ntensor([ True, False], dtype=torch.bool)\n\n\n", "description": "", "code-info": {"name": "torch.BoolTensor.all", "parameters": []}},
{"code": "torch.BoolTensor.any()", "id": "torch.BoolTensor.any", "summary": "\n\nany() \u2192 bool\n\n\nReturns True if any elements in the tensor are True, False otherwise.\nExample:\n&gt;&gt;&gt; a = torch.rand(1, 2).bool()\n&gt;&gt;&gt; a\ntensor([[False, True]], dtype=torch.bool)\n&gt;&gt;&gt; a.any()\ntensor(True, dtype=torch.bool)\n\n\n\n\nany(dim, keepdim=False, out=None) \u2192 Tensor\n\n\nReturns True if any elements in each row of the tensor in the given\ndimension dim are True, False otherwise.\nIf keepdim is True, the output tensor is of the same size as\ninput except in the dimension dim where it is of size 1.\nOtherwise, dim is squeezed (see torch.squeeze()), resulting\nin the output tensor having 1 fewer dimension than input.\n\nParameters\n\ndim (python:int) \u2013 the dimension to reduce\nkeepdim (bool) \u2013 whether the output tensor has dim retained or not\nout (Tensor, optional) \u2013 the output tensor\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4, 2) &lt; 0\n&gt;&gt;&gt; a\ntensor([[ True,  True],\n        [False,  True],\n        [ True,  True],\n        [False, False]])\n&gt;&gt;&gt; a.any(1)\ntensor([ True,  True,  True, False])\n&gt;&gt;&gt; a.any(0)\ntensor([True, True])\n\n\n", "description": "", "code-info": {"name": "torch.BoolTensor.any", "parameters": []}},
{"code": "torch.lt(input,other,out=None)", "id": "torch.lt", "summary": "Computes input&lt;other\\text{input} &lt; \\text{other}input&lt;other\n\n element-wise.\nThe second argument can be a number or a tensor whose shape is\nbroadcastable with the first argument.\n\nParameters\n\ninput (Tensor) \u2013 the tensor to compare\nother (Tensor or python:float) \u2013 the tensor or value to compare\nout (Tensor, optional) \u2013 the output tensor that must be a BoolTensor\n\n\nReturns\nA torch.BoolTensor containing a True at each location where comparison is true\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; torch.lt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\ntensor([[False, False], [True, False]])\n\n\n", "description": "", "code-info": {"name": "torch.lt", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to compare"}, {"name": "other", "is_optional": false, "type": "float", "description": "(Tensor or python:float) \u2013 the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor that must be a BoolTensor"}]}},
{"code": "torch.max()", "id": "torch.max", "summary": "\n\ntorch.max(input) \u2192 Tensor\n\n\nReturns the maximum value of all elements in the input tensor.\n\nParameters\n{input} \u2013 \n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(1, 3)\n&gt;&gt;&gt; a\ntensor([[ 0.6763,  0.7445, -2.2369]])\n&gt;&gt;&gt; torch.max(a)\ntensor(0.7445)\n\n\n\n\ntorch.max(input, dim, keepdim=False, out=None) -&gt; (Tensor, LongTensor)\n\n\nReturns a namedtuple (values, indices) where values is the maximum\nvalue of each row of the input tensor in the given dimension\ndim", "description": "", "code-info": {"name": "torch.max", "parameters": []}},
{"code": "sig-prename descclassname(input)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim,keepdim=False,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-prename descclassname(input,other,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.min()", "id": "torch.min", "summary": "\n\ntorch.min(input) \u2192 Tensor\n\n\nReturns the minimum value of all elements in the input tensor.\n\nParameters\n{input} \u2013 \n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(1, 3)\n&gt;&gt;&gt; a\ntensor([[ 0.6750,  1.0857,  1.7197]])\n&gt;&gt;&gt; torch.min(a)\ntensor(0.6750)\n\n\n\n\ntorch.min(input, dim, keepdim=False, out=None) -&gt; (Tensor, LongTensor)\n\n\nReturns a namedtuple (values, indices) where values is the minimum\nvalue of each row of the input tensor in the given dimension\ndim", "description": "", "code-info": {"name": "torch.min", "parameters": []}},
{"code": "sig-prename descclassname(input)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "sig-prename descclassname(input,dim,keepdim=False,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-prename descclassname(input,other,out=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.ne(input,other,out=None)", "id": "torch.ne", "summary": "Computes input\u2260otherinput \\neq otherinput\ue020\u200b=other\n\n element-wise.\nThe second argument can be a number or a tensor whose shape is\nbroadcastable with the first argument.\n\nParameters\n\ninput (Tensor) \u2013 the tensor to compare\nother (Tensor or python:float) \u2013 the tensor or value to compare\nout (Tensor, optional) \u2013 the output tensor that must be a BoolTensor\n\n\nReturns\nA torch.BoolTensor containing a True at each location where comparison is true.\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; torch.ne(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\ntensor([[False, True], [True, False]])\n\n\n", "description": "", "code-info": {"name": "torch.ne", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to compare"}, {"name": "other", "is_optional": false, "type": "float", "description": "(Tensor or python:float) \u2013 the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor that must be a BoolTensor"}]}},
{"code": "torch.sort(input,dim=-1,descending=False,out=None)", "id": "torch.sort", "summary": "Sorts the elements of the input tensor along a given dimension\nin ascending order by value.\nIf dim is not given, the last dimension of the input is chosen.\nIf descending is True then the elements are sorted in descending\norder by value.\nA namedtuple of (values, indices) is returned, where the values are the\nsorted values and indices are the indices of the elements in the original\ninput tensor.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\ndim (python:int, optional) \u2013 the dimension to sort along\ndescending (bool, optional) \u2013 controls the sorting order (ascending or descending)\nout (tuple, optional) \u2013 the output tuple of (Tensor, LongTensor) that can\nbe optionally given to be used as output buffers\n\n\n\nExample:\n&gt;&gt;&gt; x = torch.randn(3, 4)\n&gt;&gt;&gt; sorted, indices = torch.sort(x)\n&gt;&gt;&gt; sorted\ntensor([[-0.2162,  0.0608,  0.6719,  2.3332],\n        [-0.5793,  0.0061,  0.6058,  0.9497],\n        [-0.5071,  0.3343,  0.9553,  1.0960]])\n&gt;&gt;&gt; indices\ntensor([[ 1,  0,  2,  3],\n        [ 3,  1,  0,  2],\n        [ 0,  3,  1,  2]])\n\n&gt;&gt;&gt; sorted, indices = torch.sort(x, 0)\n&gt;&gt;&gt; sorted\ntensor([[-0.5071, -0.2162,  0.6719, -0.5793],\n        [ 0.0608,  0.0061,  0.9497,  0.3343],\n        [ 0.6058,  0.9553,  1.0960,  2.3332]])\n&gt;&gt;&gt; indices\ntensor([[ 2,  0,  0,  1],\n        [ 0,  1,  1,  2],\n        [ 1,  2,  2,  0]])\n\n\n", "description": "", "code-info": {"name": "torch.sort", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int, optional) \u2013 the dimension to sort along"}, {"name": "descending", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 controls the sorting order (ascending or descending)"}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 the output tuple of (Tensor, LongTensor) that can\nbe optionally given to be used as output buffers"}]}},
{"code": "torch.topk(input,k,dim=None,largest=True,sorted=True,out=None)", "id": "torch.topk", "summary": "Returns the k largest elements of the given input tensor along\na given dimension.\nIf dim is not given, the last dimension of the input is chosen.\nIf largest is False then the k smallest elements are returned.\nA namedtuple of (values, indices) is returned, where the indices are the indices\nof the elements in the original input tensor.\nThe boolean option sorted if True, will make sure that the returned\nk elements are themselves sorted\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nk (python:int) \u2013 the k in \u201ctop-k\u201d\ndim (python:int, optional) \u2013 the dimension to sort along\nlargest (bool, optional) \u2013 controls whether to return largest or\nsmallest elements\nsorted (bool, optional) \u2013 controls whether to return the elements\nin sorted order\nout (tuple, optional) \u2013 the output tuple of (Tensor, LongTensor) that can be\noptionally given to be used as output buffers\n\n\n\nExample:\n&gt;&gt;&gt; x = torch.arange(1., 6.)\n&gt;&gt;&gt; x\ntensor([ 1.,  2.,  3.,  4.,  5.])\n&gt;&gt;&gt; torch.topk(x, 3)\ntorch.return_types.topk(values=tensor([5., 4., 3.]), indices=tensor([4, 3, 2]))\n\n\n", "description": "", "code-info": {"name": "torch.topk", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "k", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the k in \u201ctop-k\u201d"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 the dimension to sort along"}, {"name": "largest", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 controls whether to return largest or\nsmallest elements"}, {"name": "sorted", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 controls whether to return the elements\nin sorted order"}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 the output tuple of (Tensor, LongTensor) that can be\noptionally given to be used as output buffers"}]}},
{"code": "torch.nn.MaxUnpool2d(kernel_size,stride=None,padding=0)", "id": "torch.nn.MaxUnpool2d", "summary": "Computes a partial inverse of MaxPool2d.\nMaxPool2d is not fully invertible, since the non-maximal values are lost.\nMaxUnpool2d takes in as input the output of MaxPool2d\nincluding the indices of the maximal values and computes a partial inverse\nin which all non-maximal values are set to zero.\n\nNote\nMaxPool2d can map several input sizes to the same output\nsizes", "description": "", "code-info": {"name": "torch.nn.MaxUnpool2d", "parameters": [{"name": "kernel_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 Size of the max pooling window."}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or tuple) \u2013 Stride of the max pooling window.\nIt is set to kernel_size by default."}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple) \u2013 Padding that was added to the input"}]}},
{"code": "torch.nn.MaxUnpool3d(kernel_size,stride=None,padding=0)", "id": "torch.nn.MaxUnpool3d", "summary": "Computes a partial inverse of MaxPool3d.\nMaxPool3d is not fully invertible, since the non-maximal values are lost.\nMaxUnpool3d takes in as input the output of MaxPool3d\nincluding the indices of the maximal values and computes a partial inverse\nin which all non-maximal values are set to zero.\n\nNote\nMaxPool3d can map several input sizes to the same output\nsizes", "description": "", "code-info": {"name": "torch.nn.MaxUnpool3d", "parameters": [{"name": "kernel_size", "is_optional": false, "type": "int", "description": "(python:int or tuple) \u2013 Size of the max pooling window."}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or tuple) \u2013 Stride of the max pooling window.\nIt is set to kernel_size by default."}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int or tuple) \u2013 Padding that was added to the input"}]}},
{"code": "torch.nn.AvgPool1d(kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True)", "id": "torch.nn.AvgPool1d", "summary": "Applies a 1D average pooling over an input signal composed of several\ninput planes.\nIn the simplest case, the output value of the layer with input size (N,C,L)(N, C, L)(N,C,L)\n\n,\noutput (N,C,Lout)(N, C, L_{out})(N,C,Lout\u200b)\n\n and kernel_size kkk\n\n\ncan be precisely described as:\n\nout(Ni,Cj,l)=1k\u2211m=0k\u22121input(Ni,Cj,stride\u00d7l+m)\\text{out}(N_i, C_j, l) = \\frac{1}{k} \\sum_{m=0}^{k-1}\n                       \\text{input}(N_i, C_j, \\text{stride} \\times l + m)out(Ni\u200b,Cj\u200b,l)=k1\u200bm=0\u2211k\u22121\u200binput(Ni\u200b,Cj\u200b,stride\u00d7l+m)\n\nIf padding is non-zero, then the input is implicitly zero-padded on both sides\nfor padding number of points.\nThe parameters kernel_size, stride, padding can each be\nan int or a one-element tuple.\n\nParameters\n\nkernel_size \u2013 the size of the window\nstride \u2013 the stride of the window", "description": "", "code-info": {"name": "torch.nn.AvgPool1d", "parameters": [{"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "count_include_pad", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.AvgPool2d(kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)", "id": "torch.nn.AvgPool2d", "summary": "Applies a 2D average pooling over an input signal composed of several input\nplanes.\nIn the simplest case, the output value of the layer with input size (N,C,H,W)(N, C, H, W)(N,C,H,W)\n\n,\noutput (N,C,Hout,Wout)(N, C, H_{out}, W_{out})(N,C,Hout\u200b,Wout\u200b)\n\n and kernel_size (kH,kW)(kH, kW)(kH,kW)\n\n\ncan be precisely described as:\n\nout(Ni,Cj,h,w)=1kH\u2217kW\u2211m=0kH\u22121\u2211n=0kW\u22121input(Ni,Cj,stride[0]\u00d7h+m,stride[1]\u00d7w+n)out(N_i, C_j, h, w)  = \\frac{1}{kH * kW} \\sum_{m=0}^{kH-1} \\sum_{n=0}^{kW-1}\n                       input(N_i, C_j, stride[0] \\times h + m, stride[1] \\times w + n)out(Ni\u200b,Cj\u200b,h,w)=kH\u2217kW1\u200bm=0\u2211kH\u22121\u200bn=0\u2211kW\u22121\u200binput(Ni\u200b,Cj\u200b,stride[0]\u00d7h+m,stride[1]\u00d7w+n)\n\nIf padding is non-zero, then the input is implicitly zero-padded on both sides\nfor padding number of points.\nThe parameters kernel_size, stride, padding can either be:\n\n\na single int \u2013 in which case the same value is used for the height and width dimension\na tuple of two ints \u2013 in which case, the first int is used for the height dimension,\nand the second int for the width dimension\n\n\n\nParameters\n\nkernel_size \u2013 the size of the window\nstride \u2013 the stride of the window", "description": "", "code-info": {"name": "torch.nn.AvgPool2d", "parameters": [{"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "count_include_pad", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "divisor_override", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.fft(input,signal_ndim,normalized=False)", "id": "torch.fft", "summary": "Complex-to-complex Discrete Fourier Transform\nThis method computes the complex-to-complex discrete Fourier transform.\nIgnoring the batch dimensions, it computes the following expression:\n\nX[\u03c91,\u2026,\u03c9d]=\u2211n1=0N1\u22121\u22ef\u2211nd=0Nd\u22121x[n1,\u2026,nd]e\u2212j\u00a02\u03c0\u2211i=0d\u03c9iniNi,X[\\omega_1, \\dots, \\omega_d] =\n    \\sum_{n_1=0}^{N_1-1} \\dots \\sum_{n_d=0}^{N_d-1} x[n_1, \\dots, n_d]\n     e^{-j\\ 2 \\pi \\sum_{i=0}^d \\frac{\\omega_i n_i}{N_i}},\n\nX[\u03c91\u200b,\u2026,\u03c9d\u200b]=n1\u200b=0\u2211N1\u200b\u22121\u200b\u22efnd\u200b=0\u2211Nd\u200b\u22121\u200bx[n1\u200b,\u2026,nd\u200b]e\u2212j\u00a02\u03c0\u2211i=0d\u200bNi\u200b\u03c9i\u200bni\u200b\u200b,\n\nwhere ddd\n\n = signal_ndim is number of dimensions for the\nsignal, and NiN_iNi\u200b\n\n is the size of signal dimension iii\n\n.\nThis method supports 1D, 2D and 3D complex-to-complex transforms, indicated\nby signal_ndim", "description": "", "code-info": {"name": "torch.fft", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor of at least signal_ndim + 1\ndimensions"}, {"name": "signal_ndim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the number of dimensions in each signal.\nsignal_ndim can only be 1, 2 or 3"}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 controls whether to return normalized results.\nDefault: False"}]}},
{"code": "torch.ifft(input,signal_ndim,normalized=False)", "id": "torch.ifft", "summary": "Complex-to-complex Inverse Discrete Fourier Transform\nThis method computes the complex-to-complex inverse discrete Fourier\ntransform", "description": "", "code-info": {"name": "torch.ifft", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor of at least signal_ndim + 1\ndimensions"}, {"name": "signal_ndim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the number of dimensions in each signal.\nsignal_ndim can only be 1, 2 or 3"}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 controls whether to return normalized results.\nDefault: False"}]}},
{"code": "torch.rfft(input,signal_ndim,normalized=False,onesided=True)", "id": "torch.rfft", "summary": "Real-to-complex Discrete Fourier Transform\nThis method computes the real-to-complex discrete Fourier transform", "description": "", "code-info": {"name": "torch.rfft", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor of at least signal_ndim dimensions"}, {"name": "signal_ndim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the number of dimensions in each signal.\nsignal_ndim can only be 1, 2 or 3"}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 controls whether to return normalized results.\nDefault: False"}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 controls whether to return half of results to\navoid redundancy. Default: True"}]}},
{"code": "torch.irfft(input,signal_ndim,normalized=False,onesided=True,signal_sizes=None)", "id": "torch.irfft", "summary": "Complex-to-real Inverse Discrete Fourier Transform\nThis method computes the complex-to-real inverse discrete Fourier transform.\nIt is mathematically equivalent with ifft() with differences only in\nformats of the input and output.\nThe argument specifications are almost identical with ifft().\nSimilar to ifft(), if normalized is set to True,\nthis normalizes the result by multiplying it with\n\u220fi=1KNi\\sqrt{\\prod_{i=1}^K N_i}\u220fi=1K\u200bNi\u200b\u200b\n\n so that the operator is unitary, where\nNiN_iNi\u200b\n\n is the size of signal dimension iii\n\n.\n\nNote\nDue to the conjugate symmetry, input do not need to contain the full\ncomplex frequency values", "description": "", "code-info": {"name": "torch.irfft", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor of at least signal_ndim + 1\ndimensions"}, {"name": "signal_ndim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the number of dimensions in each signal.\nsignal_ndim can only be 1, 2 or 3"}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 controls whether to return normalized results.\nDefault: False"}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 controls whether input was halfed to avoid\nredundancy, e.g., by rfft(). Default: True"}, {"name": "signal_sizes", "is_optional": true, "type": "others", "default_value": "None", "description": "(list or torch.Size, optional) \u2013 the size of the original\nsignal (without batch dimension). Default: None"}]}},
{"code": "torch.nn.AvgPool3d(kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)", "id": "torch.nn.AvgPool3d", "summary": "Applies a 3D average pooling over an input signal composed of several input\nplanes.\nIn the simplest case, the output value of the layer with input size (N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W)\n\n,\noutput (N,C,Dout,Hout,Wout)(N, C, D_{out}, H_{out}, W_{out})(N,C,Dout\u200b,Hout\u200b,Wout\u200b)\n\n and kernel_size (kD,kH,kW)(kD, kH, kW)(kD,kH,kW)\n\n\ncan be precisely described as:\n\nout(Ni,Cj,d,h,w)=\u2211k=0kD\u22121\u2211m=0kH\u22121\u2211n=0kW\u22121input(Ni,Cj,stride[0]\u00d7d+k,stride[1]\u00d7h+m,stride[2]\u00d7w+n)kD\u00d7kH\u00d7kW\\begin{aligned}\n    \\text{out}(N_i, C_j, d, h, w) ={} &amp; \\sum_{k=0}^{kD-1} \\sum_{m=0}^{kH-1} \\sum_{n=0}^{kW-1} \\\\\n                                      &amp; \\frac{\\text{input}(N_i, C_j, \\text{stride}[0] \\times d + k,\n                                              \\text{stride}[1] \\times h + m, \\text{stride}[2] \\times w + n)}\n                                             {kD \\times kH \\times kW}\n\\end{aligned}\n\nout(Ni\u200b,Cj\u200b,d,h,w)=\u200bk=0\u2211kD\u22121\u200bm=0\u2211kH\u22121\u200bn=0\u2211kW\u22121\u200bkD\u00d7kH\u00d7kWinput(Ni\u200b,Cj\u200b,stride[0]\u00d7d+k,stride[1]\u00d7h+m,stride[2]\u00d7w+n)\u200b\u200b\n\nIf padding is non-zero, then the input is implicitly zero-padded on all three sides\nfor padding number of points.\nThe parameters kernel_size, stride can either be:\n\n\na single int \u2013 in which case the same value is used for the depth, height and width dimension\na tuple of three ints \u2013 in which case, the first int is used for the depth dimension,\nthe second int for the height dimension and the third int for the width dimension\n\n\n\nParameters\n\nkernel_size \u2013 the size of the window\nstride \u2013 the stride of the window", "description": "", "code-info": {"name": "torch.nn.AvgPool3d", "parameters": [{"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "count_include_pad", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "divisor_override", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.FractionalMaxPool2d(kernel_size,output_size=None,output_ratio=None,return_indices=False,_random_samples=None)", "id": "torch.nn.FractionalMaxPool2d", "summary": "Applies a 2D fractional max pooling over an input signal composed of several input planes.\nFractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham\nThe max-pooling operation is applied in kH\u00d7kWkH \\times kWkH\u00d7kW\n\n regions by a stochastic\nstep size determined by the target output size.\nThe number of output features is equal to the number of input planes.\n\nParameters\n\nkernel_size \u2013 the size of the window to take a max over.\nCan be a single number k (for a square kernel of k x k) or a tuple (kh, kw)\noutput_size \u2013 the target output size of the image of the form oH x oW.\nCan be a tuple (oH, oW) or a single number oH for a square image oH x oH\noutput_ratio \u2013 If one wants to have an output size as a ratio of the input size, this option can be given.\nThis has to be a number or tuple in the range (0, 1)\nreturn_indices \u2013 if True, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool2d()", "description": "", "code-info": {"name": "torch.nn.FractionalMaxPool2d", "parameters": [{"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "output_size", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "output_ratio", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "return_indices", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "_random_samples", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.LPPool1d(norm_type,kernel_size,stride=None,ceil_mode=False)", "id": "torch.nn.LPPool1d", "summary": "Applies a 1D power-average pooling over an input signal composed of several input\nplanes.\nOn each window, the function computed is:\n\nf(X)=\u2211x\u2208Xxppf(X) = \\sqrt[p]{\\sum_{x \\in X} x^{p}}\n\nf(X)=p\u200bx\u2208X\u2211\u200bxp\u200b\n\n\nAt p = \u221e\\infty\u221e\n\n, one gets Max Pooling\nAt p = 1, one gets Sum Pooling (which is proportional to Average Pooling)\n\n\nNote\nIf the sum to the power of p is zero, the gradient of this function is\nnot defined", "description": "", "code-info": {"name": "torch.nn.LPPool1d", "parameters": [{"name": "norm_type", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.LPPool2d(norm_type,kernel_size,stride=None,ceil_mode=False)", "id": "torch.nn.LPPool2d", "summary": "Applies a 2D power-average pooling over an input signal composed of several input\nplanes.\nOn each window, the function computed is:\n\nf(X)=\u2211x\u2208Xxppf(X) = \\sqrt[p]{\\sum_{x \\in X} x^{p}}\n\nf(X)=p\u200bx\u2208X\u2211\u200bxp\u200b\n\n\nAt p = \u221e\\infty\u221e\n\n, one gets Max Pooling\nAt p = 1, one gets Sum Pooling (which is proportional to average pooling)\n\nThe parameters kernel_size, stride can either be:\n\n\na single int \u2013 in which case the same value is used for the height and width dimension\na tuple of two ints \u2013 in which case, the first int is used for the height dimension,\nand the second int for the width dimension\n\n\n\nNote\nIf the sum to the power of p is zero, the gradient of this function is\nnot defined", "description": "", "code-info": {"name": "torch.nn.LPPool2d", "parameters": [{"name": "norm_type", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.stft(input,n_fft,hop_length=None,win_length=None,window=None,center=True,pad_mode='reflect',normalized=False,onesided=True)", "id": "torch.stft", "summary": "Short-time Fourier transform (STFT).\nIgnoring the optional batch dimension, this method computes the following\nexpression:\n\nX[m,\u03c9]=\u2211k=0win_length-1window[k]\u00a0input[m\u00d7hop_length+k]\u00a0exp\u2061(\u2212j2\u03c0\u22c5\u03c9kwin_length),X[m, \\omega] = \\sum_{k = 0}^{\\text{win\\_length-1}}%\n                    \\text{window}[k]\\ \\text{input}[m \\times \\text{hop\\_length} + k]\\ %\n                    \\exp\\left(- j \\frac{2 \\pi \\cdot \\omega k}{\\text{win\\_length}}\\right),\n\nX[m,\u03c9]=k=0\u2211win_length-1\u200bwindow[k]\u00a0input[m\u00d7hop_length+k]\u00a0exp(\u2212jwin_length2\u03c0\u22c5\u03c9k\u200b),\n\nwhere mmm\n\n is the index of the sliding window, and \u03c9\\omega\u03c9\n\n is\nthe frequency that 0\u2264\u03c9&lt;n_fft0 \\leq \\omega &lt; \\text{n\\_fft}0\u2264\u03c9&lt;n_fft\n\n", "description": "", "code-info": {"name": "torch.stft", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor"}, {"name": "n_fft", "is_optional": false, "type": "int", "description": "(python:int) \u2013 size of Fourier transform"}, {"name": "hop_length", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 the distance between neighboring sliding window\nframes. Default: None (treated as equal to floor(n_fft / 4))"}, {"name": "win_length", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 the size of window frame and STFT filter.\nDefault: None  (treated as equal to n_fft)"}, {"name": "window", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the optional window function.\nDefault: None (treated as window of all 111\n\n s)"}, {"name": "center", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 whether to pad input on both sides so\nthat the ttt\n\n-th frame is centered at time t\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length\n\n.\nDefault: True"}, {"name": "pad_mode", "is_optional": true, "type": "string", "default_value": "'reflect'", "description": "(string, optional) \u2013 controls the padding method used when\ncenter is True. Default: \"reflect\""}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 controls whether to return the normalized STFT results\nDefault: False"}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 controls whether to return half of results to\navoid redundancy Default: True"}]}},
{"code": "torch.bartlett_window(window_length,periodic=True,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.bartlett_window", "summary": "Bartlett window function.\n\nw[n]=1\u2212\u22232nN\u22121\u22121\u2223={2nN\u22121if\u00a00\u2264n\u2264N\u2212122\u22122nN\u22121if\u00a0N\u221212&lt;n&lt;N,w[n] = 1 - \\left| \\frac{2n}{N-1} - 1 \\right| = \\begin{cases}\n    \\frac{2n}{N - 1} &amp; \\text{if } 0 \\leq n \\leq \\frac{N - 1}{2} \\\\\n    2 - \\frac{2n}{N - 1} &amp; \\text{if } \\frac{N - 1}{2} &lt; n &lt; N \\\\\n\\end{cases},\n\nw[n]=1\u2212\u2223\u2223\u2223\u2223\u2223\u200bN\u221212n\u200b\u22121\u2223\u2223\u2223\u2223\u2223\u200b={N\u221212n\u200b2\u2212N\u221212n\u200b\u200bif\u00a00\u2264n\u22642N\u22121\u200bif\u00a02N\u22121\u200b&lt;n&lt;N\u200b,\n\nwhere NNN\n\n is the full window size.\nThe input window_length is a positive integer controlling the\nreturned window size", "description": "", "code-info": {"name": "torch.bartlett_window", "parameters": [{"name": "window_length", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the size of returned window"}, {"name": "periodic", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()). Only floating point types are supported."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned window tensor. Only\ntorch.strided (dense layout) is supported."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.blackman_window(window_length,periodic=True,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.blackman_window", "summary": "Blackman window function.\n\nw[n]=0.42\u22120.5cos\u2061(2\u03c0nN\u22121)+0.08cos\u2061(4\u03c0nN\u22121)w[n] = 0.42 - 0.5 \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right) + 0.08 \\cos \\left( \\frac{4 \\pi n}{N - 1} \\right)\n\nw[n]=0.42\u22120.5cos(N\u221212\u03c0n\u200b)+0.08cos(N\u221214\u03c0n\u200b)\n\nwhere NNN\n\n is the full window size.\nThe input window_length is a positive integer controlling the\nreturned window size", "description": "", "code-info": {"name": "torch.blackman_window", "parameters": [{"name": "window_length", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the size of returned window"}, {"name": "periodic", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()). Only floating point types are supported."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned window tensor. Only\ntorch.strided (dense layout) is supported."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.hamming_window(window_length,periodic=True,alpha=0.54,beta=0.46,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.hamming_window", "summary": "Hamming window function.\n\nw[n]=\u03b1\u2212\u03b2\u00a0cos\u2061(2\u03c0nN\u22121),w[n] = \\alpha - \\beta\\ \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right),\n\nw[n]=\u03b1\u2212\u03b2\u00a0cos(N\u221212\u03c0n\u200b),\n\nwhere NNN\n\n is the full window size.\nThe input window_length is a positive integer controlling the\nreturned window size", "description": "", "code-info": {"name": "torch.hamming_window", "parameters": [{"name": "window_length", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the size of returned window"}, {"name": "periodic", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window."}, {"name": "alpha", "is_optional": true, "type": "float", "default_value": "0.54", "description": "(python:float, optional) \u2013 The coefficient \u03b1\\alpha\u03b1\n\n in the equation above"}, {"name": "beta", "is_optional": true, "type": "float", "default_value": "0.46", "description": "(python:float, optional) \u2013 The coefficient \u03b2\\beta\u03b2\n\n in the equation above"}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()). Only floating point types are supported."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned window tensor. Only\ntorch.strided (dense layout) is supported."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.hann_window(window_length,periodic=True,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "id": "torch.hann_window", "summary": "Hann window function.\n\nw[n]=12\u00a0[1\u2212cos\u2061(2\u03c0nN\u22121)]=sin\u20612(\u03c0nN\u22121),w[n] = \\frac{1}{2}\\ \\left[1 - \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right)\\right] =\n        \\sin^2 \\left( \\frac{\\pi n}{N - 1} \\right),\n\nw[n]=21\u200b\u00a0[1\u2212cos(N\u221212\u03c0n\u200b)]=sin2(N\u22121\u03c0n\u200b),\n\nwhere NNN\n\n is the full window size.\nThe input window_length is a positive integer controlling the\nreturned window size", "description": "", "code-info": {"name": "torch.hann_window", "parameters": [{"name": "window_length", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the size of returned window"}, {"name": "periodic", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, uses a global default (see torch.set_default_tensor_type()). Only floating point types are supported."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 the desired layout of returned window tensor. Only\ntorch.strided (dense layout) is supported."}, {"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If autograd should record operations on the\nreturned tensor. Default: False."}]}},
{"code": "torch.nn.AdaptiveMaxPool1d(output_size,return_indices=False)", "id": "torch.nn.AdaptiveMaxPool1d", "summary": "Applies a 1D adaptive max pooling over an input signal composed of several input planes.\nThe output size is H, for any input size.\nThe number of output features is equal to the number of input planes.\n\nParameters\n\noutput_size \u2013 the target output size H\nreturn_indices \u2013 if True, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool1d", "description": "", "code-info": {"name": "torch.nn.AdaptiveMaxPool1d", "parameters": [{"name": "output_size", "is_optional": false, "type": "others", "description": ""}, {"name": "return_indices", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.AdaptiveMaxPool2d(output_size,return_indices=False)", "id": "torch.nn.AdaptiveMaxPool2d", "summary": "Applies a 2D adaptive max pooling over an input signal composed of several input planes.\nThe output is of size H x W, for any input size.\nThe number of output features is equal to the number of input planes.\n\nParameters\n\noutput_size \u2013 the target output size of the image of the form H x W.\nCan be a tuple (H, W) or a single H for a square image H x H.\nH and W can be either a int, or None which means the size will\nbe the same as that of the input.\nreturn_indices \u2013 if True, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool2d", "description": "", "code-info": {"name": "torch.nn.AdaptiveMaxPool2d", "parameters": [{"name": "output_size", "is_optional": false, "type": "others", "description": ""}, {"name": "return_indices", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.AdaptiveMaxPool3d(output_size,return_indices=False)", "id": "torch.nn.AdaptiveMaxPool3d", "summary": "Applies a 3D adaptive max pooling over an input signal composed of several input planes.\nThe output is of size D x H x W, for any input size.\nThe number of output features is equal to the number of input planes.\n\nParameters\n\noutput_size \u2013 the target output size of the image of the form D x H x W.\nCan be a tuple (D, H, W) or a single D for a cube D x D x D.\nD, H and W can be either a int, or None which means the size will\nbe the same as that of the input.\nreturn_indices \u2013 if True, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool3d", "description": "", "code-info": {"name": "torch.nn.AdaptiveMaxPool3d", "parameters": [{"name": "output_size", "is_optional": false, "type": "others", "description": ""}, {"name": "return_indices", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.AdaptiveAvgPool1d(output_size)", "id": "torch.nn.AdaptiveAvgPool1d", "summary": "Applies a 1D adaptive average pooling over an input signal composed of several input planes.\nThe output size is H, for any input size.\nThe number of output features is equal to the number of input planes.\n\nParameters\noutput_size \u2013 the target output size H\n\n\nExamples\n&gt;&gt;&gt; # target output size of 5\n&gt;&gt;&gt; m = nn.AdaptiveAvgPool1d(5)\n&gt;&gt;&gt; input = torch.randn(1, 64, 8)\n&gt;&gt;&gt; output = m(input)\n\n\n", "description": "", "code-info": {"name": "torch.nn.AdaptiveAvgPool1d", "parameters": [{"name": "output_size", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.AdaptiveAvgPool2d(output_size)", "id": "torch.nn.AdaptiveAvgPool2d", "summary": "Applies a 2D adaptive average pooling over an input signal composed of several input planes.\nThe output is of size H x W, for any input size.\nThe number of output features is equal to the number of input planes.\n\nParameters\noutput_size \u2013 the target output size of the image of the form H x W.\nCan be a tuple (H, W) or a single H for a square image H x H.\nH and W can be either a int, or None which means the size will\nbe the same as that of the input.\n\n\nExamples\n&gt;&gt;&gt; # target output size of 5x7\n&gt;&gt;&gt; m = nn.AdaptiveAvgPool2d((5,7))\n&gt;&gt;&gt; input = torch.randn(1, 64, 8, 9)\n&gt;&gt;&gt; output = m(input)\n&gt;&gt;&gt; # target output size of 7x7 (square)\n&gt;&gt;&gt; m = nn.AdaptiveAvgPool2d(7)\n&gt;&gt;&gt; input = torch.randn(1, 64, 10, 9)\n&gt;&gt;&gt; output = m(input)\n&gt;&gt;&gt; # target output size of 10x7\n&gt;&gt;&gt; m = nn.AdaptiveMaxPool2d((None, 7))\n&gt;&gt;&gt; input = torch.randn(1, 64, 10, 9)\n&gt;&gt;&gt; output = m(input)\n\n\n", "description": "", "code-info": {"name": "torch.nn.AdaptiveAvgPool2d", "parameters": [{"name": "output_size", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.AdaptiveAvgPool3d(output_size)", "id": "torch.nn.AdaptiveAvgPool3d", "summary": "Applies a 3D adaptive average pooling over an input signal composed of several input planes.\nThe output is of size D x H x W, for any input size.\nThe number of output features is equal to the number of input planes.\n\nParameters\noutput_size \u2013 the target output size of the form D x H x W.\nCan be a tuple (D, H, W) or a single number D for a cube D x D x D.\nD, H and W can be either a int, or None which means the size will\nbe the same as that of the input.\n\n\nExamples\n&gt;&gt;&gt; # target output size of 5x7x9\n&gt;&gt;&gt; m = nn.AdaptiveAvgPool3d((5,7,9))\n&gt;&gt;&gt; input = torch.randn(1, 64, 8, 9, 10)\n&gt;&gt;&gt; output = m(input)\n&gt;&gt;&gt; # target output size of 7x7x7 (cube)\n&gt;&gt;&gt; m = nn.AdaptiveAvgPool3d(7)\n&gt;&gt;&gt; input = torch.randn(1, 64, 10, 9, 8)\n&gt;&gt;&gt; output = m(input)\n&gt;&gt;&gt; # target output size of 7x9x8\n&gt;&gt;&gt; m = nn.AdaptiveMaxPool3d((7, None, None))\n&gt;&gt;&gt; input = torch.randn(1, 64, 10, 9, 8)\n&gt;&gt;&gt; output = m(input)\n\n\n", "description": "", "code-info": {"name": "torch.nn.AdaptiveAvgPool3d", "parameters": [{"name": "output_size", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.ReflectionPad1d(padding)", "id": "torch.nn.ReflectionPad1d", "summary": "Pads the input tensor using the reflection of the input boundary.\nFor N-dimensional padding, use torch.nn.functional.pad().\n\nParameters\npadding (python:int, tuple) \u2013 the size of the padding", "description": "", "code-info": {"name": "torch.nn.ReflectionPad1d", "parameters": [{"name": "padding", "is_optional": false, "type": "int", "description": "(python:int, tuple) \u2013 the size of the padding. If is int, uses the same\npadding in all boundaries. If a 2-tuple, uses\n(padding_left\\text{padding\\_left}padding_left"}]}},
{"code": "torch.bincount(input,weights=None,minlength=0)", "id": "torch.bincount", "summary": "Count the frequency of each value in an array of non-negative ints.\nThe number of bins (size 1) is one larger than the largest value in\ninput unless input is empty, in which case the result is a\ntensor of size 0", "description": "", "code-info": {"name": "torch.bincount", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 1-d int tensor"}, {"name": "weights", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor) \u2013 optional, weight for each value in the input tensor.\nShould be of same size as input tensor."}, {"name": "minlength", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 optional, minimum number of bins. Should be non-negative."}]}},
{"code": "torch.broadcast_tensors(*tensors)", "id": "torch.broadcast_tensors", "summary": "Broadcasts the given tensors according to Broadcasting semantics.\n\nParameters\n*tensors \u2013 any number of tensors of the same type\n\n\n\nWarning\nMore than one element of a broadcasted tensor may refer to a single\nmemory location", "description": "", "code-info": {"name": "torch.broadcast_tensors", "parameters": [{"name": "*tensors", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.cartesian_prod(*tensors)", "id": "torch.cartesian_prod", "summary": "Do cartesian product of the given sequence of tensors", "description": "", "code-info": {"name": "torch.cartesian_prod", "parameters": [{"name": "*tensors", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.cdist(x1,x2,p=2,compute_mode='use_mm_for_euclid_dist_if_necessary')", "id": "torch.cdist", "summary": "Computes batched the p-norm distance between each pair of the two collections of row vectors.\n\nParameters\n\nx1 (Tensor) \u2013 input tensor of shape B\u00d7P\u00d7MB \\times P \\times MB\u00d7P\u00d7M\n\n.\nx2 (Tensor) \u2013 input tensor of shape B\u00d7R\u00d7MB \\times R \\times MB\u00d7R\u00d7M\n\n.\np \u2013 p value for the p-norm distance to calculate between each vector pair\n\u2208[0,\u221e]\\in [0, \\infty]\u2208[0,\u221e]\n\n.\ncompute_mode \u2013 \u2018use_mm_for_euclid_dist_if_necessary\u2019 - will use matrix multiplication approach to calculate\neuclidean distance (p = 2) if P &gt; 25 or R &gt; 25\n\u2018use_mm_for_euclid_dist\u2019 - will always use matrix multiplication approach to calculate\neuclidean distance (p = 2)\n\u2018donot_use_mm_for_euclid_dist\u2019 - will never use matrix multiplication approach to calculate\neuclidean distance (p = 2)\nDefault: use_mm_for_euclid_dist_if_necessary.\n\n\n\nIf x1 has shape B\u00d7P\u00d7MB \\times P \\times MB\u00d7P\u00d7M\n\n and x2 has shape B\u00d7R\u00d7MB \\times R \\times MB\u00d7R\u00d7M\n\n then the\noutput will have shape B\u00d7P\u00d7RB \\times P \\times RB\u00d7P\u00d7R\n\n.\nThis function is equivalent to scipy.spatial.distance.cdist(input,\u2019minkowski\u2019, p=p)\nif p\u2208(0,\u221e)p \\in (0, \\infty)p\u2208(0,\u221e)\n\n", "description": "", "code-info": {"name": "torch.cdist", "parameters": [{"name": "x1", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input tensor of shape B\u00d7P\u00d7MB \\times P \\times MB\u00d7P\u00d7M\n\n."}, {"name": "x2", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": ""}, {"name": "compute_mode", "is_optional": true, "type": "string", "default_value": "'use_mm_for_euclid_dist_if_necessary'", "description": ""}]}},
{"code": "torch.combinations(input,r=2,with_replacement=False)", "id": "torch.combinations", "summary": "Compute combinations of length rrr\n\n of the given tensor", "description": "", "code-info": {"name": "torch.combinations", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 1D vector."}, {"name": "r", "is_optional": true, "type": "int", "default_value": "2", "description": "(python:int, optional) \u2013 number of elements to combine"}, {"name": "with_replacement", "is_optional": true, "type": "bool", "default_value": "False", "description": "(boolean, optional) \u2013 whether to allow duplication in combination"}]}},
{"code": "torch.nn.ReflectionPad2d(padding)", "id": "torch.nn.ReflectionPad2d", "summary": "Pads the input tensor using the reflection of the input boundary.\nFor N-dimensional padding, use torch.nn.functional.pad().\n\nParameters\npadding (python:int, tuple) \u2013 the size of the padding", "description": "", "code-info": {"name": "torch.nn.ReflectionPad2d", "parameters": [{"name": "padding", "is_optional": false, "type": "int", "description": "(python:int, tuple) \u2013 the size of the padding. If is int, uses the same\npadding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left"}]}},
{"code": "torch.nn.ReplicationPad1d(padding)", "id": "torch.nn.ReplicationPad1d", "summary": "Pads the input tensor using replication of the input boundary.\nFor N-dimensional padding, use torch.nn.functional.pad().\n\nParameters\npadding (python:int, tuple) \u2013 the size of the padding", "description": "", "code-info": {"name": "torch.nn.ReplicationPad1d", "parameters": [{"name": "padding", "is_optional": false, "type": "int", "description": "(python:int, tuple) \u2013 the size of the padding. If is int, uses the same\npadding in all boundaries. If a 2-tuple, uses\n(padding_left\\text{padding\\_left}padding_left"}]}},
{"code": "torch.nn.ReplicationPad2d(padding)", "id": "torch.nn.ReplicationPad2d", "summary": "Pads the input tensor using replication of the input boundary.\nFor N-dimensional padding, use torch.nn.functional.pad().\n\nParameters\npadding (python:int, tuple) \u2013 the size of the padding", "description": "", "code-info": {"name": "torch.nn.ReplicationPad2d", "parameters": [{"name": "padding", "is_optional": false, "type": "int", "description": "(python:int, tuple) \u2013 the size of the padding. If is int, uses the same\npadding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left"}]}},
{"code": "torch.nn.ReplicationPad3d(padding)", "id": "torch.nn.ReplicationPad3d", "summary": "Pads the input tensor using replication of the input boundary.\nFor N-dimensional padding, use torch.nn.functional.pad().\n\nParameters\npadding (python:int, tuple) \u2013 the size of the padding", "description": "", "code-info": {"name": "torch.nn.ReplicationPad3d", "parameters": [{"name": "padding", "is_optional": false, "type": "int", "description": "(python:int, tuple) \u2013 the size of the padding. If is int, uses the same\npadding in all boundaries. If a 6-tuple, uses\n(padding_left\\text{padding\\_left}padding_left"}]}},
{"code": "torch.cross(input,other,dim=-1,out=None)", "id": "torch.cross", "summary": "Returns the cross product of vectors in dimension dim of input\nand other.\ninput and other must have the same size, and the size of their\ndim dimension should be 3.\nIf dim is not given, it defaults to the first dimension found with the\nsize 3.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nother (Tensor) \u2013 the second input tensor\ndim (python:int, optional) \u2013 the dimension to take the cross-product in.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(4, 3)\n&gt;&gt;&gt; a\ntensor([[-0.3956,  1.1455,  1.6895],\n        [-0.5849,  1.3672,  0.3599],\n        [-1.1626,  0.7180, -0.0521],\n        [-0.1339,  0.9902, -2.0225]])\n&gt;&gt;&gt; b = torch.randn(4, 3)\n&gt;&gt;&gt; b\ntensor([[-0.0257, -1.4725, -1.2251],\n        [-1.1479, -0.7005, -1.9757],\n        [-1.3904,  0.3726, -1.1836],\n        [-0.9688, -0.7153,  0.2159]])\n&gt;&gt;&gt; torch.cross(a, b, dim=1)\ntensor([[ 1.0844, -0.5281,  0.6120],\n        [-2.4490, -1.5687,  1.9792],\n        [-0.8304, -1.3037,  0.5650],\n        [-1.2329,  1.9883,  1.0551]])\n&gt;&gt;&gt; torch.cross(a, b)\ntensor([[ 1.0844, -0.5281,  0.6120],\n        [-2.4490, -1.5687,  1.9792],\n        [-0.8304, -1.3037,  0.5650],\n        [-1.2329,  1.9883,  1.0551]])\n\n\n", "description": "", "code-info": {"name": "torch.cross", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "other", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the second input tensor"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int, optional) \u2013 the dimension to take the cross-product in."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.cumprod(input,dim,out=None,dtype=None)", "id": "torch.cumprod", "summary": "Returns the cumulative product of elements of input in the dimension\ndim.\nFor example, if input is a vector of size N, the result will also be\na vector of size N, with elements.\n\nyi=x1\u00d7x2\u00d7x3\u00d7\u22ef\u00d7xiy_i = x_1 \\times x_2\\times x_3\\times \\dots \\times x_i\n\nyi\u200b=x1\u200b\u00d7x2\u200b\u00d7x3\u200b\u00d7\u22ef\u00d7xi\u200b\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\ndim (python:int) \u2013 the dimension to do the operation over\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed", "description": "", "code-info": {"name": "torch.cumprod", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the dimension to do the operation over\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed. This is useful for preventing data type overflows. Default: None."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(10)\n&gt;&gt;&gt; a\ntensor([ 0.6001,  0.2069, -0.1919,  0.9792,  0.6727,  1.0062,  0.4126,\n        -0.2129, -0.4206,  0.1968])\n&gt;&gt;&gt; torch.cumprod(a, dim=0)\ntensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0158, -0.0065,\n         0.0014, -0.0006, -0.0001])\n\n&gt;&gt;&gt; a[5] = 0.0\n&gt;&gt;&gt; torch.cumprod(a, dim=0)\ntensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0000, -0.0000,\n         0.0000, -0.0000, -0.0000])\n\n\n"}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed. This is useful for preventing data type overflows. Default: None.\nout (Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.cumsum(input,dim,out=None,dtype=None)", "id": "torch.cumsum", "summary": "Returns the cumulative sum of elements of input in the dimension\ndim.\nFor example, if input is a vector of size N, the result will also be\na vector of size N, with elements.\n\nyi=x1+x2+x3+\u22ef+xiy_i = x_1 + x_2 + x_3 + \\dots + x_i\n\nyi\u200b=x1\u200b+x2\u200b+x3\u200b+\u22ef+xi\u200b\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\ndim (python:int) \u2013 the dimension to do the operation over\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed", "description": "", "code-info": {"name": "torch.cumsum", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the dimension to do the operation over\ndtype (torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed. This is useful for preventing data type overflows. Default: None."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.randn(10)\n&gt;&gt;&gt; a\ntensor([-0.8286, -0.4890,  0.5155,  0.8443,  0.1865, -0.1752, -2.0595,\n         0.1850, -1.1571, -0.4243])\n&gt;&gt;&gt; torch.cumsum(a, dim=0)\ntensor([-0.8286, -1.3175, -0.8020,  0.0423,  0.2289,  0.0537, -2.0058,\n        -1.8209, -2.9780, -3.4022])\n\n\n"}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed. This is useful for preventing data type overflows. Default: None.\nout (Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.diag(input,diagonal=0,out=None)", "id": "torch.diag", "summary": "\nIf input is a vector (1-D tensor), then returns a 2-D square tensor\nwith the elements of input as the diagonal.\nIf input is a matrix (2-D tensor), then returns a 1-D tensor with\nthe diagonal elements of input.\n\nThe argument diagonal controls which diagonal to consider:\n\nIf diagonal = 0, it is the main diagonal.\nIf diagonal &gt; 0, it is above the main diagonal.\nIf diagonal &lt; 0, it is below the main diagonal.\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\ndiagonal (python:int, optional) \u2013 the diagonal to consider\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\n\nSee also\ntorch.diagonal() always returns the diagonal of its input.\ntorch.diagflat() always constructs a tensor with diagonal elements\nspecified by the input.\n\nExamples:\nGet the square matrix where the input vector is the diagonal:\n&gt;&gt;&gt; a = torch.randn(3)\n&gt;&gt;&gt; a\ntensor([ 0.5950,-0.0872, 2.3298])\n&gt;&gt;&gt; torch.diag(a)\ntensor([[ 0.5950, 0.0000, 0.0000],\n        [ 0.0000,-0.0872, 0.0000],\n        [ 0.0000, 0.0000, 2.3298]])\n&gt;&gt;&gt; torch.diag(a, 1)\ntensor([[ 0.0000, 0.5950, 0.0000, 0.0000],\n        [ 0.0000, 0.0000,-0.0872, 0.0000],\n        [ 0.0000, 0.0000, 0.0000, 2.3298],\n        [ 0.0000, 0.0000, 0.0000, 0.0000]])\n\n\nGet the k-th diagonal of a given matrix:\n&gt;&gt;&gt; a = torch.randn(3, 3)\n&gt;&gt;&gt; a\ntensor([[-0.4264, 0.0255,-0.1064],\n        [ 0.8795,-0.2429, 0.1374],\n        [ 0.1029,-0.6482,-1.6300]])\n&gt;&gt;&gt; torch.diag(a, 0)\ntensor([-0.4264,-0.2429,-1.6300])\n&gt;&gt;&gt; torch.diag(a, 1)\ntensor([ 0.0255, 0.1374])\n\n\n", "description": "", "code-info": {"name": "torch.diag", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "diagonal", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 the diagonal to consider"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.diag_embed(input,offset=0,dim1=-2,dim2=-1)", "id": "torch.diag_embed", "summary": "Creates a tensor whose diagonals of certain 2D planes (specified by\ndim1 and dim2) are filled by input.\nTo facilitate creating batched diagonal matrices, the 2D planes formed by\nthe last two dimensions of the returned tensor are chosen by default.\nThe argument offset controls which diagonal to consider:\n\nIf offset = 0, it is the main diagonal.\nIf offset &gt; 0, it is above the main diagonal.\nIf offset &lt; 0, it is below the main diagonal.\n\nThe size of the new matrix will be calculated to make the specified diagonal\nof the size of the last input dimension.\nNote that for offset other than 000\n\n, the order of dim1\nand dim2 matters", "description": "", "code-info": {"name": "torch.diag_embed", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor. Must be at least 1-dimensional."}, {"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 which diagonal to consider. Default: 0\n(main diagonal)."}, {"name": "dim1", "is_optional": true, "type": "int", "default_value": "-2", "description": "(python:int, optional) \u2013 first dimension with respect to which to\ntake diagonal. Default: -2."}, {"name": "dim2", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int, optional) \u2013 second dimension with respect to which to\ntake diagonal. Default: -1."}]}},
{"code": "torch.diagflat(input,offset=0)", "id": "torch.diagflat", "summary": "\nIf input is a vector (1-D tensor), then returns a 2-D square tensor\nwith the elements of input as the diagonal.\nIf input is a tensor with more than one dimension, then returns a\n2-D tensor with diagonal elements equal to a flattened input.\n\nThe argument offset controls which diagonal to consider:\n\nIf offset = 0, it is the main diagonal.\nIf offset &gt; 0, it is above the main diagonal.\nIf offset &lt; 0, it is below the main diagonal.\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\noffset (python:int, optional) \u2013 the diagonal to consider", "description": "", "code-info": {"name": "torch.diagflat", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 the diagonal to consider. Default: 0 (main\ndiagonal)."}]}},
{"code": "torch.diagonal(input,offset=0,dim1=0,dim2=1)", "id": "torch.diagonal", "summary": "Returns a partial view of input with the its diagonal elements\nwith respect to dim1 and dim2 appended as a dimension\nat the end of the shape.\nThe argument offset controls which diagonal to consider:\n\nIf offset = 0, it is the main diagonal.\nIf offset &gt; 0, it is above the main diagonal.\nIf offset &lt; 0, it is below the main diagonal.\n\nApplying torch.diag_embed() to the output of this function with\nthe same arguments yields a diagonal matrix with the diagonal entries\nof the input", "description": "", "code-info": {"name": "torch.diagonal", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor. Must be at least 2-dimensional."}, {"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 which diagonal to consider. Default: 0\n(main diagonal)."}, {"name": "dim1", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 first dimension with respect to which to\ntake diagonal. Default: 0."}, {"name": "dim2", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 second dimension with respect to which to\ntake diagonal. Default: 1."}]}},
{"code": "torch.nn.ZeroPad2d(padding)", "id": "torch.nn.ZeroPad2d", "summary": "Pads the input tensor boundaries with zero.\nFor N-dimensional padding, use torch.nn.functional.pad().\n\nParameters\npadding (python:int, tuple) \u2013 the size of the padding", "description": "", "code-info": {"name": "torch.nn.ZeroPad2d", "parameters": [{"name": "padding", "is_optional": false, "type": "int", "description": "(python:int, tuple) \u2013 the size of the padding. If is int, uses the same\npadding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left"}]}},
{"code": "torch.nn.ConstantPad1d(padding,value)", "id": "torch.nn.ConstantPad1d", "summary": "Pads the input tensor boundaries with a constant value.\nFor N-dimensional padding, use torch.nn.functional.pad().\n\nParameters\npadding (python:int, tuple) \u2013 the size of the padding", "description": "", "code-info": {"name": "torch.nn.ConstantPad1d", "parameters": [{"name": "padding", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.ConstantPad2d(padding,value)", "id": "torch.nn.ConstantPad2d", "summary": "Pads the input tensor boundaries with a constant value.\nFor N-dimensional padding, use torch.nn.functional.pad().\n\nParameters\npadding (python:int, tuple) \u2013 the size of the padding", "description": "", "code-info": {"name": "torch.nn.ConstantPad2d", "parameters": [{"name": "padding", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.ConstantPad3d(padding,value)", "id": "torch.nn.ConstantPad3d", "summary": "Pads the input tensor boundaries with a constant value.\nFor N-dimensional padding, use torch.nn.functional.pad().\n\nParameters\npadding (python:int, tuple) \u2013 the size of the padding", "description": "", "code-info": {"name": "torch.nn.ConstantPad3d", "parameters": [{"name": "padding", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.einsum(equation,*operands)", "id": "torch.einsum", "summary": "This function provides a way of computing multilinear expressions (i.e", "description": "", "code-info": {"name": "torch.einsum", "parameters": [{"name": "equation", "is_optional": false, "type": "others", "description": ""}, {"name": "*operands", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.flatten(input,start_dim=0,end_dim=-1)", "id": "torch.flatten", "summary": "Flattens a contiguous range of dims in a tensor.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nstart_dim (python:int) \u2013 the first dim to flatten\nend_dim (python:int) \u2013 the last dim to flatten\n\n\n\nExample:\n&gt;&gt;&gt; t = torch.tensor([[[1, 2],\n                       [3, 4]],\n                      [[5, 6],\n                       [7, 8]]])\n&gt;&gt;&gt; torch.flatten(t)\ntensor([1, 2, 3, 4, 5, 6, 7, 8])\n&gt;&gt;&gt; torch.flatten(t, start_dim=1)\ntensor([[1, 2, 3, 4],\n        [5, 6, 7, 8]])\n\n\n", "description": "", "code-info": {"name": "torch.flatten", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "start_dim", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 the first dim to flatten"}, {"name": "end_dim", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int) \u2013 the last dim to flatten"}]}},
{"code": "torch.flip(input,dims)", "id": "torch.flip", "summary": "Reverse the order of a n-D tensor along given axis in dims.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\ndims (a list or tuple) \u2013 axis to flip on\n\n\n\nExample:\n&gt;&gt;&gt; x = torch.arange(8).view(2, 2, 2)\n&gt;&gt;&gt; x\ntensor([[[ 0,  1],\n         [ 2,  3]],\n\n        [[ 4,  5],\n         [ 6,  7]]])\n&gt;&gt;&gt; torch.flip(x, [0, 1])\ntensor([[[ 6,  7],\n         [ 4,  5]],\n\n        [[ 2,  3],\n         [ 0,  1]]])\n\n\n", "description": "", "code-info": {"name": "torch.flip", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "dims", "is_optional": false, "type": "others", "description": "(a list or tuple) \u2013 axis to flip on"}]}},
{"code": "torch.rot90(input,k,dims)", "id": "torch.rot90", "summary": "Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.\nRotation direction is from the first towards the second axis if k &gt; 0, and from the second towards the first for k &lt; 0.\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nk (python:int) \u2013 number of times to rotate\ndims (a list or tuple) \u2013 axis to rotate\n\n\n\nExample:\n&gt;&gt;&gt; x = torch.arange(4).view(2, 2)\n&gt;&gt;&gt; x\ntensor([[0, 1],\n        [2, 3]])\n&gt;&gt;&gt; torch.rot90(x, 1, [0, 1])\ntensor([[1, 3],\n        [0, 2]])\n\n&gt;&gt;&gt; x = torch.arange(8).view(2, 2, 2)\n&gt;&gt;&gt; x\ntensor([[[0, 1],\n         [2, 3]],\n\n        [[4, 5],\n         [6, 7]]])\n&gt;&gt;&gt; torch.rot90(x, 1, [1, 2])\ntensor([[[1, 3],\n         [0, 2]],\n\n        [[5, 7],\n         [4, 6]]])\n\n\n", "description": "", "code-info": {"name": "torch.rot90", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "k", "is_optional": false, "type": "int", "description": "(python:int) \u2013 number of times to rotate"}, {"name": "dims", "is_optional": false, "type": "others", "description": "(a list or tuple) \u2013 axis to rotate"}]}},
{"code": "torch.histc(input,bins=100,min=0,max=0,out=None)", "id": "torch.histc", "summary": "Computes the histogram of a tensor.\nThe elements are sorted into equal width bins between min and\nmax", "description": "", "code-info": {"name": "torch.histc", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "bins", "is_optional": true, "type": "int", "default_value": "100", "description": "(python:int) \u2013 number of histogram bins"}, {"name": "min", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 lower end of the range (inclusive)"}, {"name": "max", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int) \u2013 upper end of the range (inclusive)"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.meshgrid(*tensors,**kwargs)", "id": "torch.meshgrid", "summary": "Take NNN\n\n tensors, each of which can be either scalar or 1-dimensional\nvector, and create NNN\n\n N-dimensional grids, where the iii\n\n th grid is defined by\nexpanding the iii\n\n th input over dimensions defined by other inputs.\n\n\nArgs:tensors (list of Tensor): list of scalars or 1 dimensional tensors", "description": "", "code-info": {"name": "torch.meshgrid", "parameters": [{"name": "*tensors", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.renorm(input,p,dim,maxnorm,out=None)", "id": "torch.renorm", "summary": "Returns a tensor where each sub-tensor of input along dimension\ndim is normalized such that the p-norm of the sub-tensor is lower\nthan the value maxnorm\n\nNote\nIf the norm of a row is lower than maxnorm, the row is unchanged\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\np (python:float) \u2013 the power for the norm computation\ndim (python:int) \u2013 the dimension to slice over to get the sub-tensors\nmaxnorm (python:float) \u2013 the maximum norm to keep each sub-tensor under\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; x = torch.ones(3, 3)\n&gt;&gt;&gt; x[1].fill_(2)\ntensor([ 2.,  2.,  2.])\n&gt;&gt;&gt; x[2].fill_(3)\ntensor([ 3.,  3.,  3.])\n&gt;&gt;&gt; x\ntensor([[ 1.,  1.,  1.],\n        [ 2.,  2.,  2.],\n        [ 3.,  3.,  3.]])\n&gt;&gt;&gt; torch.renorm(x, 1, 0, 5)\ntensor([[ 1.0000,  1.0000,  1.0000],\n        [ 1.6667,  1.6667,  1.6667],\n        [ 1.6667,  1.6667,  1.6667]])\n\n\n", "description": "", "code-info": {"name": "torch.renorm", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "p", "is_optional": false, "type": "float", "description": "(python:float) \u2013 the power for the norm computation"}, {"name": "dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the dimension to slice over to get the sub-tensors"}, {"name": "maxnorm", "is_optional": false, "type": "float", "description": "(python:float) \u2013 the maximum norm to keep each sub-tensor under"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.repeat_interleave()", "id": "torch.repeat_interleave", "summary": "\n\ntorch.repeat_interleave(input, repeats, dim=None) \u2192 Tensor\n\n\nRepeat elements of a tensor.\n\nWarning\nThis is different from torch.repeat() but similar to numpy.repeat.\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor.\nrepeats (Tensor or python:int) \u2013 The number of repetitions for each element.\nrepeats is broadcasted to fit the shape of the given axis.\ndim (python:int, optional) \u2013 The dimension along which to repeat values.\nBy default, use the flattened input array, and return a flat output\narray.\n\n\nReturns\n\nRepeated tensor which has the same shape as input, except along thegiven axis.\n\n\n\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; x = torch.tensor([1, 2, 3])\n&gt;&gt;&gt; x.repeat_interleave(2)\ntensor([1, 1, 2, 2, 3, 3])\n&gt;&gt;&gt; y = torch.tensor([[1, 2], [3, 4]])\n&gt;&gt;&gt; torch.repeat_interleave(y, 2)\ntensor([1, 1, 2, 2, 3, 3, 4, 4])\n&gt;&gt;&gt; torch.repeat_interleave(y, 3, dim=1)\ntensor([[1, 1, 1, 2, 2, 2],\n        [3, 3, 3, 4, 4, 4]])\n&gt;&gt;&gt; torch.repeat_interleave(y, torch.tensor([1, 2]), dim=0)\ntensor([[1, 2],\n        [3, 4],\n        [3, 4]])\n\n\n\n\ntorch.repeat_interleave(repeats) \u2192 Tensor\n\n\nIf the repeats is tensor([n1, n2, n3, \u2026]), then the output will be\ntensor([0, 0, \u2026, 1, 1, \u2026, 2, 2, \u2026, \u2026]) where 0 appears n1 times,\n1 appears n2 times, 2 appears n3 times, etc.\n", "description": "", "code-info": {"name": "torch.repeat_interleave", "parameters": []}},
{"code": "torch.nn.ELU(alpha=1.0,inplace=False)", "id": "torch.nn.ELU", "summary": "Applies the element-wise function:\n\nELU(x)=max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x)\u22121))\\text{ELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1))\n\nELU(x)=max(0,x)+min(0,\u03b1\u2217(exp(x)\u22121))\n\n\nParameters\n\nalpha \u2013 the \u03b1\\alpha\u03b1\n\n value for the ELU formulation", "description": "", "code-info": {"name": "torch.nn.ELU", "parameters": [{"name": "alpha", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.Hardshrink(lambd=0.5)", "id": "torch.nn.Hardshrink", "summary": "Applies the hard shrinkage function element-wise:\n\nHardShrink(x)={x,\u00a0if\u00a0x&gt;\u03bbx,\u00a0if\u00a0x&lt;\u2212\u03bb0,\u00a0otherwise\u00a0\\text{HardShrink}(x) =\n\\begin{cases}\nx, &amp; \\text{ if } x &gt; \\lambda \\\\\nx, &amp; \\text{ if } x &lt; -\\lambda \\\\\n0, &amp; \\text{ otherwise }\n\\end{cases}\n\nHardShrink(x)=\u23a9\u23aa\u23aa\u23a8\u23aa\u23aa\u23a7\u200bx,x,0,\u200b\u00a0if\u00a0x&gt;\u03bb\u00a0if\u00a0x&lt;\u2212\u03bb\u00a0otherwise\u00a0\u200b\n\n\nParameters\nlambd \u2013 the \u03bb\\lambda\u03bb\n\n value for the Hardshrink formulation", "description": "", "code-info": {"name": "torch.nn.Hardshrink", "parameters": [{"name": "lambd", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}]}},
{"code": "torch.nn.Hardtanh(min_val=-1.0,max_val=1.0,inplace=False,min_value=None,max_value=None)", "id": "torch.nn.Hardtanh", "summary": "Applies the HardTanh function element-wise\nHardTanh is defined as:\n\nHardTanh(x)={1\u00a0if\u00a0x&gt;1\u22121\u00a0if\u00a0x&lt;\u22121x\u00a0otherwise\u00a0\\text{HardTanh}(x) = \\begin{cases}\n    1 &amp; \\text{ if } x &gt; 1 \\\\\n    -1 &amp; \\text{ if } x &lt; -1 \\\\\n    x &amp; \\text{ otherwise } \\\\\n\\end{cases}\n\nHardTanh(x)=\u23a9\u23aa\u23aa\u23a8\u23aa\u23aa\u23a7\u200b1\u22121x\u200b\u00a0if\u00a0x&gt;1\u00a0if\u00a0x&lt;\u22121\u00a0otherwise\u00a0\u200b\n\nThe range of the linear region [\u22121,1][-1, 1][\u22121,1]\n\n can be adjusted using\nmin_val and max_val.\n\nParameters\n\nmin_val \u2013 minimum value of the linear region range", "description": "", "code-info": {"name": "torch.nn.Hardtanh", "parameters": [{"name": "min_val", "is_optional": true, "type": "others", "default_value": "-1.0", "description": ""}, {"name": "max_val", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "min_value", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "max_value", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.LeakyReLU(negative_slope=0.01,inplace=False)", "id": "torch.nn.LeakyReLU", "summary": "Applies the element-wise function:\n\nLeakyReLU(x)=max\u2061(0,x)+negative_slope\u2217min\u2061(0,x)\\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x)\n\nLeakyReLU(x)=max(0,x)+negative_slope\u2217min(0,x)\n\nor\n\nLeakyRELU(x)={x,\u00a0if\u00a0x\u22650negative_slope\u00d7x,\u00a0otherwise\u00a0\\text{LeakyRELU}(x) =\n\\begin{cases}\nx, &amp; \\text{ if } x \\geq 0 \\\\\n\\text{negative\\_slope} \\times x, &amp; \\text{ otherwise }\n\\end{cases}\n\nLeakyRELU(x)={x,negative_slope\u00d7x,\u200b\u00a0if\u00a0x\u22650\u00a0otherwise\u00a0\u200b\n\n\nParameters\n\nnegative_slope \u2013 Controls the angle of the negative slope", "description": "", "code-info": {"name": "torch.nn.LeakyReLU", "parameters": [{"name": "negative_slope", "is_optional": true, "type": "others", "default_value": "0.01", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.MultiheadAttention(embed_dim,num_heads,dropout=0.0,bias=True,add_bias_kv=False,add_zero_attn=False,kdim=None,vdim=None)", "id": "torch.nn.MultiheadAttention", "summary": "Allows the model to jointly attend to information\nfrom different representation subspaces.\nSee reference: Attention Is All You Need\n\nMultiHead(Q,K,V)=Concat(head1,\u2026,headh)WOwhereheadi=Attention(QWiQ,KWiK,VWiV)\\text{MultiHead}(Q, K, V) = \\text{Concat}(head_1,\\dots,head_h)W^O\n\\text{where} head_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n\nMultiHead(Q,K,V)=Concat(head1\u200b,\u2026,headh\u200b)WOwhereheadi\u200b=Attention(QWiQ\u200b,KWiK\u200b,VWiV\u200b)\n\n\nParameters\n\nembed_dim \u2013 total dimension of the model.\nnum_heads \u2013 parallel attention heads.\ndropout \u2013 a Dropout layer on attn_output_weights", "description": "", "code-info": {"name": "torch.nn.MultiheadAttention", "parameters": [{"name": "embed_dim", "is_optional": false, "type": "others", "description": ""}, {"name": "num_heads", "is_optional": false, "type": "others", "description": ""}, {"name": "dropout", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "add_bias_kv", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "add_zero_attn", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "kdim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "vdim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-prename descclassname(input,repeats,dim=None)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "repeats", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "sig-prename descclassname(repeats)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "repeats", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.roll(input,shifts,dims=None)", "id": "torch.roll", "summary": "Roll the tensor along the given dimension(s)", "description": "", "code-info": {"name": "torch.roll", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "shifts", "is_optional": false, "type": "int", "description": "(python:int or tuple of python:ints) \u2013 The number of places by which the elements\nof the tensor are shifted. If shifts is a tuple, dims must be a tuple of\nthe same size, and each dimension will be rolled by the corresponding\nvalue"}, {"name": "dims", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or tuple of python:ints) \u2013 Axis along which to roll"}]}},
{"code": "torch.tensordot(a,b,dims=2)", "id": "torch.tensordot", "summary": "Returns a contraction of a and b over multiple dimensions.\ntensordot implements a generalized matrix product.\n\nParameters\n\na (Tensor) \u2013 Left tensor to contract\nb (Tensor) \u2013 Right tensor to contract\ndims (python:int or tuple of two lists of python:integers) \u2013 number of dimensions to\ncontract or explicit lists of dimensions for a and\nb respectively\n\n\n\nWhen called with an integer argument dims = ddd\n\n, and the number of\ndimensions of a and b is mmm\n\n and nnn\n\n, respectively,\nit computes\n\nri0,...,im\u2212d,id,...,in=\u2211k0,...,kd\u22121ai0,...,im\u2212d,k0,...,kd\u22121\u00d7bk0,...,kd\u22121,id,...,in.r_{i_0,...,i_{m-d}, i_d,...,i_n}\n  = \\sum_{k_0,...,k_{d-1}} a_{i_0,...,i_{m-d},k_0,...,k_{d-1}} \\times b_{k_0,...,k_{d-1}, i_d,...,i_n}.\n\nri0\u200b,...,im\u2212d\u200b,id\u200b,...,in\u200b\u200b=k0\u200b,...,kd\u22121\u200b\u2211\u200bai0\u200b,...,im\u2212d\u200b,k0\u200b,...,kd\u22121\u200b\u200b\u00d7bk0\u200b,...,kd\u22121\u200b,id\u200b,...,in\u200b\u200b.\n\nWhen called with dims of the list form, the given dimensions will be contracted\nin place of the last ddd\n\n of a and the first ddd\n\n of bbb\n\n", "description": "", "code-info": {"name": "torch.tensordot", "parameters": [{"name": "a", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Left tensor to contract"}, {"name": "b", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 Right tensor to contract"}, {"name": "dims", "is_optional": true, "type": "int", "default_value": "2", "description": "(python:int or tuple of two lists of python:integers) \u2013 number of dimensions to\ncontract or explicit lists of dimensions for a and\nb respectively"}]}},
{"code": "torch.trace(input)", "id": "torch.trace", "summary": "Returns the sum of the elements of the diagonal of the input 2-D matrix.\nExample:\n&gt;&gt;&gt; x = torch.arange(1., 10.).view(3, 3)\n&gt;&gt;&gt; x\ntensor([[ 1.,  2.,  3.],\n        [ 4.,  5.,  6.],\n        [ 7.,  8.,  9.]])\n&gt;&gt;&gt; torch.trace(x)\ntensor(15.)\n\n\n", "description": "", "code-info": {"name": "torch.trace", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.tril(input,diagonal=0,out=None)", "id": "torch.tril", "summary": "Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices\ninput, the other elements of the result tensor out are set to 0.\nThe lower triangular part of the matrix is defined as the elements on and\nbelow the diagonal.\nThe argument diagonal controls which diagonal to consider", "description": "", "code-info": {"name": "torch.tril", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "diagonal", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 the diagonal to consider"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.tril_indices(row,col,offset=0,dtype=torch.long,device='cpu',layout=torch.strided)", "id": "torch.tril_indices", "summary": "Returns the indices of the lower triangular part of a row-by-\ncol matrix in a 2-by-N Tensor, where the first row contains row\ncoordinates of all indices and the second row contains column coordinates.\nIndices are ordered based on rows and then columns.\nThe lower triangular part of the matrix is defined as the elements on and\nbelow the diagonal.\nThe argument offset controls which diagonal to consider", "description": "", "code-info": {"name": "torch.tril_indices", "parameters": [{"name": "row", "is_optional": false, "type": "int", "description": "(int) \u2013 number of rows in the 2-D matrix."}, {"name": "col", "is_optional": false, "type": "int", "description": "(int) \u2013 number of columns in the 2-D matrix."}, {"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": "(int) \u2013 diagonal offset from the main diagonal.\nDefault: if not provided, 0."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.long", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, torch.long."}, {"name": "device", "is_optional": true, "type": "string", "default_value": "'cpu'", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 currently only support torch.strided."}]}},
{"code": "torch.triu(input,diagonal=0,out=None)", "id": "torch.triu", "summary": "Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices\ninput, the other elements of the result tensor out are set to 0.\nThe upper triangular part of the matrix is defined as the elements on and\nabove the diagonal.\nThe argument diagonal controls which diagonal to consider", "description": "", "code-info": {"name": "torch.triu", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "diagonal", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 the diagonal to consider"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.nn.PReLU(num_parameters=1,init=0.25)", "id": "torch.nn.PReLU", "summary": "Applies the element-wise function:\n\nPReLU(x)=max\u2061(0,x)+a\u2217min\u2061(0,x)\\text{PReLU}(x) = \\max(0,x) + a * \\min(0,x)\n\nPReLU(x)=max(0,x)+a\u2217min(0,x)\n\nor\n\nPReLU(x)={x,\u00a0if\u00a0x\u22650ax,\u00a0otherwise\u00a0\\text{PReLU}(x) =\n\\begin{cases}\nx, &amp; \\text{ if } x \\geq 0 \\\\\nax, &amp; \\text{ otherwise }\n\\end{cases}\n\nPReLU(x)={x,ax,\u200b\u00a0if\u00a0x\u22650\u00a0otherwise\u00a0\u200b\n\nHere aaa\n\n is a learnable parameter", "description": "", "code-info": {"name": "torch.nn.PReLU", "parameters": [{"name": "num_parameters", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int) \u2013 number of aaa\n\n to learn.\nAlthough it takes an int as input, there is only two values are legitimate:\n1, or the number of channels at input. Default: 1"}, {"name": "init", "is_optional": true, "type": "float", "default_value": "0.25", "description": "(python:float) \u2013 the initial value of aaa"}]}},
{"code": "torch.nn.ReLU(inplace=False)", "id": "torch.nn.ReLU", "summary": "Applies the rectified linear unit function element-wise:\nReLU(x)=max\u2061(0,x)\\text{ReLU}(x)= \\max(0, x)ReLU(x)=max(0,x)\n\n\n\nParameters\ninplace \u2013 can optionally do the operation in-place", "description": "", "code-info": {"name": "torch.nn.ReLU", "parameters": [{"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.ReLU6(inplace=False)", "id": "torch.nn.ReLU6", "summary": "Applies the element-wise function:\n\nReLU6(x)=min\u2061(max\u2061(0,x),6)\\text{ReLU6}(x) = \\min(\\max(0,x), 6)\n\nReLU6(x)=min(max(0,x),6)\n\n\nParameters\ninplace \u2013 can optionally do the operation in-place", "description": "", "code-info": {"name": "torch.nn.ReLU6", "parameters": [{"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.RReLU(lower=0.125,upper=0.3333333333333333,inplace=False)", "id": "torch.nn.RReLU", "summary": "Applies the randomized leaky rectified liner unit function, element-wise,\nas described in the paper:\nEmpirical Evaluation of Rectified Activations in Convolutional Network.\nThe function is defined as:\n\nRReLU(x)={xif\u00a0x\u22650ax\u00a0otherwise\u00a0\\text{RReLU}(x) =\n\\begin{cases}\n    x &amp; \\text{if } x \\geq 0 \\\\\n    ax &amp; \\text{ otherwise }\n\\end{cases}\n\nRReLU(x)={xax\u200bif\u00a0x\u22650\u00a0otherwise\u00a0\u200b\n\nwhere aaa\n\n is randomly sampled from uniform distribution\nU(lower,upper)\\mathcal{U}(\\text{lower}, \\text{upper})U(lower,upper)\n\n.\n\nSee: https://arxiv.org/pdf/1505.00853.pdf\n\n\nParameters\n\nlower \u2013 lower bound of the uniform distribution", "description": "", "code-info": {"name": "torch.nn.RReLU", "parameters": [{"name": "lower", "is_optional": true, "type": "others", "default_value": "0.125", "description": ""}, {"name": "upper", "is_optional": true, "type": "others", "default_value": "0.3333333333333333", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.SELU(inplace=False)", "id": "torch.nn.SELU", "summary": "Applied element-wise, as:\n\nSELU(x)=scale\u2217(max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x)\u22121)))\\text{SELU}(x) = \\text{scale} * (\\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)))\n\nSELU(x)=scale\u2217(max(0,x)+min(0,\u03b1\u2217(exp(x)\u22121)))\n\nwith \u03b1=1.6732632423543772848170429916717\\alpha = 1.6732632423543772848170429916717\u03b1=1.6732632423543772848170429916717\n\n and\nscale=1.0507009873554804934193349852946\\text{scale} = 1.0507009873554804934193349852946scale=1.0507009873554804934193349852946\n\n.\nMore details can be found in the paper Self-Normalizing Neural Networks .\n\nParameters\ninplace (bool, optional) \u2013 can optionally do the operation in-place", "description": "", "code-info": {"name": "torch.nn.SELU", "parameters": [{"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 can optionally do the operation in-place. Default: False"}]}},
{"code": "torch.nn.CELU(alpha=1.0,inplace=False)", "id": "torch.nn.CELU", "summary": "Applies the element-wise function:\n\nCELU(x)=max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x/\u03b1)\u22121))\\text{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1))\n\nCELU(x)=max(0,x)+min(0,\u03b1\u2217(exp(x/\u03b1)\u22121))\n\nMore details can be found in the paper Continuously Differentiable Exponential Linear Units .\n\nParameters\n\nalpha \u2013 the \u03b1\\alpha\u03b1\n\n value for the CELU formulation", "description": "", "code-info": {"name": "torch.nn.CELU", "parameters": [{"name": "alpha", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.triu_indices(row,col,offset=0,dtype=torch.long,device='cpu',layout=torch.strided)", "id": "torch.triu_indices", "summary": "Returns the indices of the upper triangular part of a row by\ncol matrix in a 2-by-N Tensor, where the first row contains row\ncoordinates of all indices and the second row contains column coordinates.\nIndices are ordered based on rows and then columns.\nThe upper triangular part of the matrix is defined as the elements on and\nabove the diagonal.\nThe argument offset controls which diagonal to consider", "description": "", "code-info": {"name": "torch.triu_indices", "parameters": [{"name": "row", "is_optional": false, "type": "int", "description": "(int) \u2013 number of rows in the 2-D matrix."}, {"name": "col", "is_optional": false, "type": "int", "description": "(int) \u2013 number of columns in the 2-D matrix."}, {"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": "(int) \u2013 diagonal offset from the main diagonal.\nDefault: if not provided, 0."}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.long", "description": "(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: if None, torch.long."}, {"name": "device", "is_optional": true, "type": "string", "default_value": "'cpu'", "description": "(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: if None, uses the current device for the default tensor type\n(see torch.set_default_tensor_type()). device will be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types."}, {"name": "layout", "is_optional": true, "type": "others", "default_value": "torch.strided", "description": "(torch.layout, optional) \u2013 currently only support torch.strided."}]}},
{"code": "torch.addbmm(beta=1,input,alpha=1,batch1,batch2,out=None)", "id": "torch.addbmm", "summary": "Performs a batch matrix-matrix product of matrices stored\nin batch1 and batch2,\nwith a reduced add step (all matrix multiplications get accumulated\nalong the first dimension).\ninput is added to the final result.\nbatch1 and batch2 must be 3-D tensors each containing the\nsame number of matrices.\nIf batch1 is a (b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)\n\n tensor, batch2 is a\n(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)\n\n tensor, input must be\nbroadcastable with a (n\u00d7p)(n \\times p)(n\u00d7p)\n\n tensor\nand out will be a (n\u00d7p)(n \\times p)(n\u00d7p)\n\n tensor.\n\nout=\u03b2\u00a0input+\u03b1\u00a0(\u2211i=0b\u22121batch1i@batch2i)out = \\beta\\ \\text{input} + \\alpha\\ (\\sum_{i=0}^{b-1} \\text{batch1}_i \\mathbin{@} \\text{batch2}_i)\n\nout=\u03b2\u00a0input+\u03b1\u00a0(i=0\u2211b\u22121\u200bbatch1i\u200b@batch2i\u200b)\n\nFor inputs of type FloatTensor or DoubleTensor, arguments beta and alpha\nmust be real numbers, otherwise they should be integers.\n\nParameters\n\nbeta (Number, optional) \u2013 multiplier for input (\u03b2\\beta\u03b2\n\n)\ninput (Tensor) \u2013 matrix to be added\nalpha (Number, optional) \u2013 multiplier for batch1 @ batch2 (\u03b1\\alpha\u03b1\n\n)\nbatch1 (Tensor) \u2013 the first batch of matrices to be multiplied\nbatch2 (Tensor) \u2013 the second batch of matrices to be multiplied\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; M = torch.randn(3, 5)\n&gt;&gt;&gt; batch1 = torch.randn(10, 3, 4)\n&gt;&gt;&gt; batch2 = torch.randn(10, 4, 5)\n&gt;&gt;&gt; torch.addbmm(M, batch1, batch2)\ntensor([[  6.6311,   0.0503,   6.9768, -12.0362,  -2.1653],\n        [ -4.8185,  -1.4255,  -6.6760,   8.9453,   2.5743],\n        [ -3.8202,   4.3691,   1.0943,  -1.1109,   5.4730]])\n\n\n", "description": "", "code-info": {"name": "torch.addbmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for input (\u03b2\\beta\u03b2\n\n)"}, {"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 matrix to be added"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for batch1 @ batch2 (\u03b1\\alpha\u03b1\n\n)"}, {"name": "batch1", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the first batch of matrices to be multiplied"}, {"name": "batch2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the second batch of matrices to be multiplied"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.addmm(beta=1,input,alpha=1,mat1,mat2,out=None)", "id": "torch.addmm", "summary": "Performs a matrix multiplication of the matrices mat1 and mat2.\nThe matrix input is added to the final result.\nIf mat1 is a (n\u00d7m)(n \\times m)(n\u00d7m)\n\n tensor, mat2 is a\n(m\u00d7p)(m \\times p)(m\u00d7p)\n\n tensor, then input must be\nbroadcastable with a (n\u00d7p)(n \\times p)(n\u00d7p)\n\n tensor\nand out will be a (n\u00d7p)(n \\times p)(n\u00d7p)\n\n tensor.\nalpha and beta are scaling factors on matrix-vector product between\nmat1 and mat2 and the added matrix input respectively.\n\nout=\u03b2\u00a0input+\u03b1\u00a0(mat1i@mat2i)\\text{out} = \\beta\\ \\text{input} + \\alpha\\ (\\text{mat1}_i \\mathbin{@} \\text{mat2}_i)\n\nout=\u03b2\u00a0input+\u03b1\u00a0(mat1i\u200b@mat2i\u200b)\n\nFor inputs of type FloatTensor or DoubleTensor, arguments beta and\nalpha must be real numbers, otherwise they should be integers.\n\nParameters\n\nbeta (Number, optional) \u2013 multiplier for input (\u03b2\\beta\u03b2\n\n)\ninput (Tensor) \u2013 matrix to be added\nalpha (Number, optional) \u2013 multiplier for mat1@mat2mat1 @ mat2mat1@mat2\n\n (\u03b1\\alpha\u03b1\n\n)\nmat1 (Tensor) \u2013 the first matrix to be multiplied\nmat2 (Tensor) \u2013 the second matrix to be multiplied\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; M = torch.randn(2, 3)\n&gt;&gt;&gt; mat1 = torch.randn(2, 3)\n&gt;&gt;&gt; mat2 = torch.randn(3, 3)\n&gt;&gt;&gt; torch.addmm(M, mat1, mat2)\ntensor([[-4.8716,  1.4671, -1.3746],\n        [ 0.7573, -3.9555, -2.8681]])\n\n\n", "description": "", "code-info": {"name": "torch.addmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for input (\u03b2\\beta\u03b2\n\n)"}, {"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 matrix to be added"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for mat1@mat2mat1 @ mat2mat1@mat2\n\n (\u03b1\\alpha\u03b1\n\n)"}, {"name": "mat1", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the first matrix to be multiplied"}, {"name": "mat2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the second matrix to be multiplied"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.addmv(beta=1,input,alpha=1,mat,vec,out=None)", "id": "torch.addmv", "summary": "Performs a matrix-vector product of the matrix mat and\nthe vector vec.\nThe vector input is added to the final result.\nIf mat is a (n\u00d7m)(n \\times m)(n\u00d7m)\n\n tensor, vec is a 1-D tensor of\nsize m, then input must be\nbroadcastable with a 1-D tensor of size n and\nout will be 1-D tensor of size n.\nalpha and beta are scaling factors on matrix-vector product between\nmat and vec and the added tensor input respectively.\n\nout=\u03b2\u00a0input+\u03b1\u00a0(mat@vec)\\text{out} = \\beta\\ \\text{input} + \\alpha\\ (\\text{mat} \\mathbin{@} \\text{vec})\n\nout=\u03b2\u00a0input+\u03b1\u00a0(mat@vec)\n\nFor inputs of type FloatTensor or DoubleTensor, arguments beta and\nalpha must be real numbers, otherwise they should be integers\n\nParameters\n\nbeta (Number, optional) \u2013 multiplier for input (\u03b2\\beta\u03b2\n\n)\ninput (Tensor) \u2013 vector to be added\nalpha (Number, optional) \u2013 multiplier for mat@vecmat @ vecmat@vec\n\n (\u03b1\\alpha\u03b1\n\n)\nmat (Tensor) \u2013 matrix to be multiplied\nvec (Tensor) \u2013 vector to be multiplied\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; M = torch.randn(2)\n&gt;&gt;&gt; mat = torch.randn(2, 3)\n&gt;&gt;&gt; vec = torch.randn(3)\n&gt;&gt;&gt; torch.addmv(M, mat, vec)\ntensor([-0.3768, -5.5565])\n\n\n", "description": "", "code-info": {"name": "torch.addmv", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for input (\u03b2\\beta\u03b2\n\n)"}, {"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 vector to be added"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for mat@vecmat @ vecmat@vec\n\n (\u03b1\\alpha\u03b1\n\n)"}, {"name": "mat", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 matrix to be multiplied"}, {"name": "vec", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 vector to be multiplied"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.addr(beta=1,input,alpha=1,vec1,vec2,out=None)", "id": "torch.addr", "summary": "Performs the outer-product of vectors vec1 and vec2\nand adds it to the matrix input.\nOptional values beta and alpha are scaling factors on the\nouter product between vec1 and vec2 and the added matrix\ninput respectively.\n\nout=\u03b2\u00a0input+\u03b1\u00a0(vec1\u2297vec2)\\text{out} = \\beta\\ \\text{input} + \\alpha\\ (\\text{vec1} \\otimes \\text{vec2})\n\nout=\u03b2\u00a0input+\u03b1\u00a0(vec1\u2297vec2)\n\nIf vec1 is a vector of size n and vec2 is a vector\nof size m, then input must be\nbroadcastable with a matrix of size\n(n\u00d7m)(n \\times m)(n\u00d7m)\n\n and out will be a matrix of size\n(n\u00d7m)(n \\times m)(n\u00d7m)\n\n.\nFor inputs of type FloatTensor or DoubleTensor, arguments beta and\nalpha must be real numbers, otherwise they should be integers\n\nParameters\n\nbeta (Number, optional) \u2013 multiplier for input (\u03b2\\beta\u03b2\n\n)\ninput (Tensor) \u2013 matrix to be added\nalpha (Number, optional) \u2013 multiplier for vec1\u2297vec2\\text{vec1} \\otimes \\text{vec2}vec1\u2297vec2\n\n (\u03b1\\alpha\u03b1\n\n)\nvec1 (Tensor) \u2013 the first vector of the outer product\nvec2 (Tensor) \u2013 the second vector of the outer product\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; vec1 = torch.arange(1., 4.)\n&gt;&gt;&gt; vec2 = torch.arange(1., 3.)\n&gt;&gt;&gt; M = torch.zeros(3, 2)\n&gt;&gt;&gt; torch.addr(M, vec1, vec2)\ntensor([[ 1.,  2.],\n        [ 2.,  4.],\n        [ 3.,  6.]])\n\n\n", "description": "", "code-info": {"name": "torch.addr", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for input (\u03b2\\beta\u03b2\n\n)"}, {"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 matrix to be added"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for vec1\u2297vec2\\text{vec1} \\otimes \\text{vec2}vec1\u2297vec2\n\n (\u03b1\\alpha\u03b1\n\n)"}, {"name": "vec1", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the first vector of the outer product"}, {"name": "vec2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the second vector of the outer product"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.baddbmm(beta=1,input,alpha=1,batch1,batch2,out=None)", "id": "torch.baddbmm", "summary": "Performs a batch matrix-matrix product of matrices in batch1\nand batch2.\ninput is added to the final result.\nbatch1 and batch2 must be 3-D tensors each containing the same\nnumber of matrices.\nIf batch1 is a (b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)\n\n tensor, batch2 is a\n(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)\n\n tensor, then input must be\nbroadcastable with a\n(b\u00d7n\u00d7p)(b \\times n \\times p)(b\u00d7n\u00d7p)\n\n tensor and out will be a\n(b\u00d7n\u00d7p)(b \\times n \\times p)(b\u00d7n\u00d7p)\n\n tensor", "description": "", "code-info": {"name": "torch.baddbmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for input (\u03b2\\beta\u03b2\n\n)"}, {"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to be added"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": "(Number, optional) \u2013 multiplier for batch1@batch2\\text{batch1} \\mathbin{@} \\text{batch2}batch1@batch2\n\n (\u03b1\\alpha\u03b1\n\n)"}, {"name": "batch1", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the first batch of matrices to be multiplied"}, {"name": "batch2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the second batch of matrices to be multiplied"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.nn.Softplus(beta=1,threshold=20)", "id": "torch.nn.Softplus", "summary": "Applies the element-wise function:\n\nSoftplus(x)=1\u03b2\u2217log\u2061(1+exp\u2061(\u03b2\u2217x))\\text{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 + \\exp(\\beta * x))\n\nSoftplus(x)=\u03b21\u200b\u2217log(1+exp(\u03b2\u2217x))\n\nSoftPlus is a smooth approximation to the ReLU function and can be used\nto constrain the output of a machine to always be positive.\nFor numerical stability the implementation reverts to the linear function\nfor inputs above a certain value.\n\nParameters\n\nbeta \u2013 the \u03b2\\beta\u03b2\n\n value for the Softplus formulation", "description": "", "code-info": {"name": "torch.nn.Softplus", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "threshold", "is_optional": true, "type": "int", "default_value": "20", "description": ""}]}},
{"code": "torch.nn.Softshrink(lambd=0.5)", "id": "torch.nn.Softshrink", "summary": "Applies the soft shrinkage function elementwise:\n\nSoftShrinkage(x)={x\u2212\u03bb,\u00a0if\u00a0x&gt;\u03bbx+\u03bb,\u00a0if\u00a0x&lt;\u2212\u03bb0,\u00a0otherwise\u00a0\\text{SoftShrinkage}(x) =\n\\begin{cases}\nx - \\lambda, &amp; \\text{ if } x &gt; \\lambda \\\\\nx + \\lambda, &amp; \\text{ if } x &lt; -\\lambda \\\\\n0, &amp; \\text{ otherwise }\n\\end{cases}\n\nSoftShrinkage(x)=\u23a9\u23aa\u23aa\u23a8\u23aa\u23aa\u23a7\u200bx\u2212\u03bb,x+\u03bb,0,\u200b\u00a0if\u00a0x&gt;\u03bb\u00a0if\u00a0x&lt;\u2212\u03bb\u00a0otherwise\u00a0\u200b\n\n\nParameters\nlambd \u2013 the \u03bb\\lambda\u03bb\n\n value for the Softshrink formulation", "description": "", "code-info": {"name": "torch.nn.Softshrink", "parameters": [{"name": "lambd", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}]}},
{"code": "torch.nn.Threshold(threshold,value,inplace=False)", "id": "torch.nn.Threshold", "summary": "Thresholds each element of the input Tensor.\nThreshold is defined as:\n\ny={x,\u00a0if\u00a0x&gt;thresholdvalue,\u00a0otherwise\u00a0y =\n\\begin{cases}\nx, &amp;\\text{ if } x &gt; \\text{threshold} \\\\\n\\text{value}, &amp;\\text{ otherwise }\n\\end{cases}\n\ny={x,value,\u200b\u00a0if\u00a0x&gt;threshold\u00a0otherwise\u00a0\u200b\n\n\nParameters\n\nthreshold \u2013 The value to threshold at\nvalue \u2013 The value to replace with\ninplace \u2013 can optionally do the operation in-place", "description": "", "code-info": {"name": "torch.nn.Threshold", "parameters": [{"name": "threshold", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.bmm(input,mat2,out=None)", "id": "torch.bmm", "summary": "Performs a batch matrix-matrix product of matrices stored in input\nand mat2.\ninput and mat2 must be 3-D tensors each containing\nthe same number of matrices.\nIf input is a (b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)\n\n tensor, mat2 is a\n(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)\n\n tensor, out will be a\n(b\u00d7n\u00d7p)(b \\times n \\times p)(b\u00d7n\u00d7p)\n\n tensor.\n\nouti=inputi@mat2i\\text{out}_i = \\text{input}_i \\mathbin{@} \\text{mat2}_i\n\nouti\u200b=inputi\u200b@mat2i\u200b\n\n\nNote\nThis function does not broadcast.\nFor broadcasting matrix products, see torch.matmul().\n\n\nParameters\n\ninput (Tensor) \u2013 the first batch of matrices to be multiplied\nmat2 (Tensor) \u2013 the second batch of matrices to be multiplied\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; input = torch.randn(10, 3, 4)\n&gt;&gt;&gt; mat2 = torch.randn(10, 4, 5)\n&gt;&gt;&gt; res = torch.bmm(input, mat2)\n&gt;&gt;&gt; res.size()\ntorch.Size([10, 3, 5])\n\n\n", "description": "", "code-info": {"name": "torch.bmm", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the first batch of matrices to be multiplied"}, {"name": "mat2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the second batch of matrices to be multiplied"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.chain_matmul(*matrices)", "id": "torch.chain_matmul", "summary": "Returns the matrix product of the NNN\n\n 2-D tensors", "description": "", "code-info": {"name": "torch.chain_matmul", "parameters": [{"name": "*matrices", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.cholesky(input,upper=False,out=None)", "id": "torch.cholesky", "summary": "Computes the Cholesky decomposition of a symmetric positive-definite\nmatrix AAA\n\n or for batches of symmetric positive-definite matrices.\nIf upper is True, the returned matrix U is upper-triangular, and\nthe decomposition has the form:\n\nA=UTUA = U^TUA=UTU\n\nIf upper is False, the returned matrix L is lower-triangular, and\nthe decomposition has the form:\n\nA=LLTA = LL^TA=LLT\n\nIf upper is True, and AAA\n\n is a batch of symmetric positive-definite\nmatrices, then the returned tensor will be composed of upper-triangular Cholesky factors\nof each of the individual matrices", "description": "", "code-info": {"name": "torch.cholesky", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor AAA\n\n of size (\u2217,n,n)(*, n, n)(\u2217,n,n)\n\n where * is zero or more\nbatch dimensions consisting of symmetric positive-definite matrices."}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 flag that indicates whether to return a\nupper or lower triangular matrix. Default: False"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output matrix"}]}},
{"code": "torch.cholesky_inverse(input,upper=False,out=None)", "id": "torch.cholesky_inverse", "summary": "Computes the inverse of a symmetric positive-definite matrix AAA\n\n using its\nCholesky factor uuu\n\n: returns matrix inv", "description": "", "code-info": {"name": "torch.cholesky_inverse", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input 2-D tensor uuu\n\n, a upper or lower triangular\nCholesky factor"}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 whether to return a lower (default) or upper triangular matrix"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor for inv"}]}},
{"code": "torch.cholesky_solve(input,input2,upper=False,out=None)", "id": "torch.cholesky_solve", "summary": "Solves a linear system of equations with a positive semidefinite\nmatrix to be inverted given its Cholesky factor matrix uuu\n\n.\nIf upper is False, uuu\n\n is and lower triangular and c is\nreturned such that:\n\nc=(uuT)\u22121bc = (u u^T)^{{-1}} b\n\nc=(uuT)\u22121b\n\nIf upper is True or not provided, uuu\n\n is upper triangular\nand c is returned such that:\n\nc=(uTu)\u22121bc = (u^T u)^{{-1}} b\n\nc=(uTu)\u22121b\n\ntorch.cholesky_solve(b, u) can take in 2D inputs b, u or inputs that are\nbatches of 2D matrices", "description": "", "code-info": {"name": "torch.cholesky_solve", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input matrix bbb\n\n of size (\u2217,m,k)(*, m, k)(\u2217,m,k)\n\n,\nwhere \u2217*\u2217\n\n is zero or more batch dimensions"}, {"name": "input2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input matrix uuu\n\n of size (\u2217,m,m)(*, m, m)(\u2217,m,m)\n\n,\nwhere \u2217*\u2217\n\n is zero of more batch dimensions composed of\nupper or lower triangular Cholesky factor"}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 whether to consider the Cholesky factor as a\nlower or upper triangular matrix. Default: False."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor for c"}]}},
{"code": "torch.dot(input,tensor)", "id": "torch.dot", "summary": "Computes the dot product (inner product) of two tensors.\n\nNote\nThis function does not broadcast.\n\nExample:\n&gt;&gt;&gt; torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))\ntensor(7)\n\n\n", "description": "", "code-info": {"name": "torch.dot", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.eig(input,eigenvectors=False,out=None)", "id": "torch.eig", "summary": "Computes the eigenvalues and eigenvectors of a real square matrix.\n\nNote\nSince eigenvalues and eigenvectors might be complex, backward pass is supported only\nfor torch.symeig()\n\n\nParameters\n\ninput (Tensor) \u2013 the square matrix of shape (n\u00d7n)(n \\times n)(n\u00d7n)\n\n for which the eigenvalues and eigenvectors\nwill be computed\neigenvectors (bool) \u2013 True to compute both eigenvalues and eigenvectors;\notherwise, only eigenvalues will be computed\nout (tuple, optional) \u2013 the output tensors\n\n\nReturns\nA namedtuple (eigenvalues, eigenvectors) containing\n\n\neigenvalues (Tensor): Shape (n\u00d72)(n \\times 2)(n\u00d72)\n\n", "description": "", "code-info": {"name": "torch.eig", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the square matrix of shape (n\u00d7n)(n \\times n)(n\u00d7n)\n\n for which the eigenvalues and eigenvectors\nwill be computed"}, {"name": "eigenvectors", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool) \u2013 True to compute both eigenvalues and eigenvectors;\notherwise, only eigenvalues will be computed"}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 the output tensors"}]}},
{"code": "torch.nn.Softmin(dim=None)", "id": "torch.nn.Softmin", "summary": "Applies the Softmin function to an n-dimensional input Tensor\nrescaling them so that the elements of the n-dimensional output Tensor\nlie in the range [0, 1] and sum to 1.\nSoftmin is defined as:\n\nSoftmin(xi)=exp\u2061(\u2212xi)\u2211jexp\u2061(\u2212xj)\\text{Softmin}(x_{i}) = \\frac{\\exp(-x_i)}{\\sum_j \\exp(-x_j)}\n\nSoftmin(xi\u200b)=\u2211j\u200bexp(\u2212xj\u200b)exp(\u2212xi\u200b)\u200b\n\n\nShape:\nInput: (\u2217)(*)(\u2217)\n\n where * means, any number of additional\ndimensions\nOutput: (\u2217)(*)(\u2217)\n\n, same shape as the input\n\n\n\n\nParameters\ndim (python:int) \u2013 A dimension along which Softmin will be computed (so every slice\nalong dim will sum to 1).\n\nReturns\na Tensor of the same dimension and shape as the input, with\nvalues in the range [0, 1]\n\n\nExamples:\n&gt;&gt;&gt; m = nn.Softmin()\n&gt;&gt;&gt; input = torch.randn(2, 3)\n&gt;&gt;&gt; output = m(input)\n\n\n", "description": "", "code-info": {"name": "torch.nn.Softmin", "parameters": [{"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 A dimension along which Softmin will be computed (so every slice\nalong dim will sum to 1)."}]}},
{"code": "torch.nn.Softmax(dim=None)", "id": "torch.nn.Softmax", "summary": "Applies the Softmax function to an n-dimensional input Tensor\nrescaling them so that the elements of the n-dimensional output Tensor\nlie in the range [0,1] and sum to 1.\nSoftmax is defined as:\n\nSoftmax(xi)=exp\u2061(xi)\u2211jexp\u2061(xj)\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\n\nSoftmax(xi\u200b)=\u2211j\u200bexp(xj\u200b)exp(xi\u200b)\u200b\n\n\nShape:\nInput: (\u2217)(*)(\u2217)\n\n where * means, any number of additional\ndimensions\nOutput: (\u2217)(*)(\u2217)\n\n, same shape as the input\n\n\n\n\nReturns\na Tensor of the same dimension and shape as the input with\nvalues in the range [0, 1]\n\nParameters\ndim (python:int) \u2013 A dimension along which Softmax will be computed (so every slice\nalong dim will sum to 1).\n\n\n\nNote\nThis module doesn\u2019t work directly with NLLLoss,\nwhich expects the Log to be computed between the Softmax and itself.\nUse LogSoftmax instead (it\u2019s faster and has better numerical properties).\n\nExamples:\n&gt;&gt;&gt; m = nn.Softmax(dim=1)\n&gt;&gt;&gt; input = torch.randn(2, 3)\n&gt;&gt;&gt; output = m(input)\n\n\n", "description": "", "code-info": {"name": "torch.nn.Softmax", "parameters": [{"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 A dimension along which Softmax will be computed (so every slice\nalong dim will sum to 1)."}]}},
{"code": "torch.nn.LogSoftmax(dim=None)", "id": "torch.nn.LogSoftmax", "summary": "Applies the log\u2061(Softmax(x))\\log(\\text{Softmax}(x))log(Softmax(x))\n\n function to an n-dimensional\ninput Tensor", "description": "", "code-info": {"name": "torch.nn.LogSoftmax", "parameters": [{"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int) \u2013 A dimension along which LogSoftmax will be computed."}]}},
{"code": "torch.nn.AdaptiveLogSoftmaxWithLoss(in_features,n_classes,cutoffs,div_value=4.0,head_bias=False)", "id": "torch.nn.AdaptiveLogSoftmaxWithLoss", "summary": "Efficient softmax approximation as described in\nEfficient softmax approximation for GPUs by Edouard Grave, Armand Joulin,\nMoustapha Ciss\u00e9, David Grangier, and Herv\u00e9 J\u00e9gou.\nAdaptive softmax is an approximate strategy for training models with large\noutput spaces", "description": "", "code-info": {"name": "torch.nn.AdaptiveLogSoftmaxWithLoss", "parameters": [{"name": "in_features", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of features in the input tensor"}, {"name": "n_classes", "is_optional": false, "type": "int", "description": "(python:int) \u2013 Number of classes in the dataset"}, {"name": "cutoffs", "is_optional": false, "type": "others", "description": "(Sequence) \u2013 Cutoffs used to assign targets to their buckets"}, {"name": "div_value", "is_optional": true, "type": "float", "default_value": "4.0", "description": "(python:float, optional) \u2013 value used as an exponent to compute sizes\nof the clusters. Default: 4.0"}, {"name": "head_bias", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If True, adds a bias term to the \u2018head\u2019 of the\nadaptive softmax. Default: False"}]}},
{"code": "torch.nn.BatchNorm1d(num_features,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)", "id": "torch.nn.BatchNorm1d", "summary": "Applies Batch Normalization over a 2D or 3D input (a mini-batch of 1D\ninputs with optional additional channel dimension) as described in the paper\nBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .\n\ny=x\u2212E[x]Var[x]+\u03f5\u2217\u03b3+\u03b2y = \\frac{x - \\mathrm{E}[x]}{\\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+\u03f5\u200bx\u2212E[x]\u200b\u2217\u03b3+\u03b2\n\nThe mean and standard-deviation are calculated per-dimension over\nthe mini-batches and \u03b3\\gamma\u03b3\n\n and \u03b2\\beta\u03b2\n\n are learnable parameter vectors\nof size C (where C is the input size)", "description": "", "code-info": {"name": "torch.nn.BatchNorm1d", "parameters": [{"name": "num_features", "is_optional": false, "type": "others", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "affine", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "track_running_stats", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.geqrf(input,out=None)", "id": "torch.geqrf", "summary": "This is a low-level function for calling LAPACK directly", "description": "", "code-info": {"name": "torch.geqrf", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input matrix"}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 the output tuple of (Tensor, Tensor)"}]}},
{"code": "torch.ger(input,vec2,out=None)", "id": "torch.ger", "summary": "Outer product of input and vec2.\nIf input is a vector of size nnn\n\n and vec2 is a vector of\nsize mmm\n\n, then out must be a matrix of size (n\u00d7m)(n \\times m)(n\u00d7m)\n\n.\n\nNote\nThis function does not broadcast.\n\n\nParameters\n\ninput (Tensor) \u2013 1-D input vector\nvec2 (Tensor) \u2013 1-D input vector\nout (Tensor, optional) \u2013 optional output matrix\n\n\n\nExample:\n&gt;&gt;&gt; v1 = torch.arange(1., 5.)\n&gt;&gt;&gt; v2 = torch.arange(1., 4.)\n&gt;&gt;&gt; torch.ger(v1, v2)\ntensor([[  1.,   2.,   3.],\n        [  2.,   4.,   6.],\n        [  3.,   6.,   9.],\n        [  4.,   8.,  12.]])\n\n\n", "description": "", "code-info": {"name": "torch.ger", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 1-D input vector"}, {"name": "vec2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 1-D input vector"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 optional output matrix"}]}},
{"code": "torch.inverse(input,out=None)", "id": "torch.inverse", "summary": "Takes the inverse of the square matrix input", "description": "", "code-info": {"name": "torch.inverse", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor of size (\u2217,n,n)(*, n, n)(\u2217,n,n)\n\n where * is zero or more\nbatch dimensions"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.det(input)", "id": "torch.det", "summary": "Calculates determinant of a square matrix or batches of square matrices.\n\nNote\nBackward through det() internally uses SVD results when input is\nnot invertible", "description": "", "code-info": {"name": "torch.det", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor of size (*, n, n) where * is zero or more\nbatch dimensions."}]}},
{"code": "torch.logdet(input)", "id": "torch.logdet", "summary": "Calculates log determinant of a square matrix or batches of square matrices.\n\nNote\nResult is -inf if input has zero log determinant, and is nan if\ninput has negative determinant.\n\n\nNote\nBackward through logdet() internally uses SVD results when input\nis not invertible", "description": "", "code-info": {"name": "torch.logdet", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor of size (*, n, n) where * is zero or more\nbatch dimensions."}]}},
{"code": "torch.slogdet(input)", "id": "torch.slogdet", "summary": "Calculates the sign and log absolute value of the determinant(s) of a square matrix or batches of square matrices.\n\nNote\nIf input has zero determinant, this returns (0, -inf).\n\n\nNote\nBackward through slogdet() internally uses SVD results when input\nis not invertible", "description": "", "code-info": {"name": "torch.slogdet", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor of size (*, n, n) where * is zero or more\nbatch dimensions."}]}},
{"code": "torch.lstsq(input,A,out=None)", "id": "torch.lstsq", "summary": "Computes the solution to the least squares and least norm problems for a full\nrank matrix AAA\n\n of size (m\u00d7n)(m \\times n)(m\u00d7n)\n\n and a matrix BBB\n\n of\nsize (m\u00d7k)(m \\times k)(m\u00d7k)\n\n.\nIf m\u2265nm \\geq nm\u2265n\n\n, lstsq() solves the least-squares problem:\n\nmin\u2061X\u2225AX\u2212B\u22252.\\begin{array}{ll}\n\\min_X &amp; \\|AX-B\\|_2.\n\\end{array}minX\u200b\u200b\u2225AX\u2212B\u22252\u200b.\u200b\n\nIf m&lt;nm &lt; nm&lt;n\n\n, lstsq() solves the least-norm problem:\n\nmin\u2061X\u2225X\u22252subject\u00a0toAX=B.\\begin{array}{ll}\n\\min_X &amp; \\|X\\|_2 &amp; \\text{subject to} &amp; AX = B.\n\\end{array}minX\u200b\u200b\u2225X\u22252\u200b\u200bsubject\u00a0to\u200bAX=B.\u200b\n\nReturned tensor XXX\n\n has shape (max\u2061(m,n)\u00d7k)(\\max(m, n) \\times k)(max(m,n)\u00d7k)\n\n", "description": "", "code-info": {"name": "torch.lstsq", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the matrix BBB\n\n"}, {"name": "A", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the mmm\n\n by nnn\n\n matrix AAA\n\n"}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 the optional destination tensor"}]}},
{"code": "torch.lu(A,pivot=True,get_infos=False,out=None)", "id": "torch.lu", "summary": "Computes the LU factorization of a matrix or batches of matrices\nA", "description": "", "code-info": {"name": "torch.lu", "parameters": [{"name": "A", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tensor to factor of size (\u2217,m,n)(*, m, n)(\u2217,m,n)\n\n"}, {"name": "pivot", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 controls whether pivoting is done. Default: True"}, {"name": "get_infos", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 if set to True, returns an info IntTensor.\nDefault: False"}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 optional output tuple. If get_infos is True,\nthen the elements in the tuple are Tensor, IntTensor,\nand IntTensor. If get_infos is False, then the\nelements in the tuple are Tensor, IntTensor. Default: None"}]}},
{"code": "torch.lu_solve(input,LU_data,LU_pivots,out=None)", "id": "torch.lu_solve", "summary": "Returns the LU solve of the linear system Ax=bAx = bAx=b\n\n using the partially pivoted\nLU factorization of A from torch.lu().\n\nParameters\n\nb (Tensor) \u2013 the RHS tensor of size (\u2217,m,k)(*, m, k)(\u2217,m,k)\n\n, where \u2217*\u2217\n\n\nis zero or more batch dimensions.\nLU_data (Tensor) \u2013 the pivoted LU factorization of A from torch.lu() of size (\u2217,m,m)(*, m, m)(\u2217,m,m)\n\n,\nwhere \u2217*\u2217\n\n is zero or more batch dimensions.\nLU_pivots (IntTensor) \u2013 the pivots of the LU factorization from torch.lu() of size (\u2217,m)(*, m)(\u2217,m)\n\n,\nwhere \u2217*\u2217\n\n is zero or more batch dimensions.\nThe batch dimensions of LU_pivots must be equal to the batch dimensions of\nLU_data.\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; A = torch.randn(2, 3, 3)\n&gt;&gt;&gt; b = torch.randn(2, 3, 1)\n&gt;&gt;&gt; A_LU = torch.lu(A)\n&gt;&gt;&gt; x = torch.lu_solve(b, *A_LU)\n&gt;&gt;&gt; torch.norm(torch.bmm(A, x) - b)\ntensor(1.00000e-07 *\n       2.8312)\n\n\n", "description": "", "code-info": {"name": "torch.lu_solve", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "LU_data", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the pivoted LU factorization of A from torch.lu() of size (\u2217,m,m)(*, m, m)(\u2217,m,m)\n\n,\nwhere \u2217*\u2217\n\n is zero or more batch dimensions."}, {"name": "LU_pivots", "is_optional": false, "type": "tensor", "description": "(IntTensor) \u2013 the pivots of the LU factorization from torch.lu() of size (\u2217,m)(*, m)(\u2217,m)\n\n,\nwhere \u2217*\u2217\n\n is zero or more batch dimensions.\nThe batch dimensions of LU_pivots must be equal to the batch dimensions of\nLU_data."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.nn.BatchNorm2d(num_features,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)", "id": "torch.nn.BatchNorm2d", "summary": "Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs\nwith additional channel dimension) as described in the paper\nBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .\n\ny=x\u2212E[x]Var[x]+\u03f5\u2217\u03b3+\u03b2y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+\u03f5\u200bx\u2212E[x]\u200b\u2217\u03b3+\u03b2\n\nThe mean and standard-deviation are calculated per-dimension over\nthe mini-batches and \u03b3\\gamma\u03b3\n\n and \u03b2\\beta\u03b2\n\n are learnable parameter vectors\nof size C (where C is the input size)", "description": "", "code-info": {"name": "torch.nn.BatchNorm2d", "parameters": [{"name": "num_features", "is_optional": false, "type": "others", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "affine", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "track_running_stats", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.BatchNorm3d(num_features,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)", "id": "torch.nn.BatchNorm3d", "summary": "Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs\nwith additional channel dimension) as described in the paper\nBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .\n\ny=x\u2212E[x]Var[x]+\u03f5\u2217\u03b3+\u03b2y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+\u03f5\u200bx\u2212E[x]\u200b\u2217\u03b3+\u03b2\n\nThe mean and standard-deviation are calculated per-dimension over\nthe mini-batches and \u03b3\\gamma\u03b3\n\n and \u03b2\\beta\u03b2\n\n are learnable parameter vectors\nof size C (where C is the input size)", "description": "", "code-info": {"name": "torch.nn.BatchNorm3d", "parameters": [{"name": "num_features", "is_optional": false, "type": "others", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "affine", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "track_running_stats", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.GroupNorm(num_groups,num_channels,eps=1e-05,affine=True)", "id": "torch.nn.GroupNorm", "summary": "Applies Group Normalization over a mini-batch of inputs as described in\nthe paper Group Normalization .\n\ny=x\u2212E[x]Var[x]+\u03f5\u2217\u03b3+\u03b2y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\ny=Var[x]+\u03f5\u200bx\u2212E[x]\u200b\u2217\u03b3+\u03b2\n\nThe input channels are separated into num_groups groups, each containing\nnum_channels / num_groups channels", "description": "", "code-info": {"name": "torch.nn.GroupNorm", "parameters": [{"name": "num_groups", "is_optional": false, "type": "int", "description": "(python:int) \u2013 number of groups to separate the channels into"}, {"name": "num_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "affine", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.SyncBatchNorm(num_features,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True,process_group=None)", "id": "torch.nn.SyncBatchNorm", "summary": "Applies Batch Normalization over a N-Dimensional input (a mini-batch of [N-2]D inputs\nwith additional channel dimension) as described in the paper\nBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .\n\ny=x\u2212E[x]Var[x]+\u03f5\u2217\u03b3+\u03b2y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+\u03f5\u200bx\u2212E[x]\u200b\u2217\u03b3+\u03b2\n\nThe mean and standard-deviation are calculated per-dimension over all\nmini-batches of the same process groups", "description": "", "code-info": {"name": "torch.nn.SyncBatchNorm", "parameters": [{"name": "num_features", "is_optional": false, "type": "others", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "affine", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "track_running_stats", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "process_group", "is_optional": true, "type": "others", "default_value": "None", "description": "(optional) \u2013 process group to scope synchronization,"}]}},
{"code": "torch.lu_unpack(LU_data,LU_pivots,unpack_data=True,unpack_pivots=True)", "id": "torch.lu_unpack", "summary": "Unpacks the data and pivots from a LU factorization of a tensor.\nReturns a tuple of tensors as (the pivots, the L tensor, the U tensor).\n\nParameters\n\nLU_data (Tensor) \u2013 the packed LU factorization data\nLU_pivots (Tensor) \u2013 the packed LU factorization pivots\nunpack_data (bool) \u2013 flag indicating if the data should be unpacked\nunpack_pivots (bool) \u2013 flag indicating if the pivots should be unpacked\n\n\n\nExamples:\n&gt;&gt;&gt; A = torch.randn(2, 3, 3)\n&gt;&gt;&gt; A_LU, pivots = A.lu()\n&gt;&gt;&gt; P, A_L, A_U = torch.lu_unpack(A_LU, pivots)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # can recover A from factorization\n&gt;&gt;&gt; A_ = torch.bmm(P, torch.bmm(A_L, A_U))\n\n&gt;&gt;&gt; # LU factorization of a rectangular matrix:\n&gt;&gt;&gt; A = torch.randn(2, 3, 2)\n&gt;&gt;&gt; A_LU, pivots = A.lu()\n&gt;&gt;&gt; P, A_L, A_U = torch.lu_unpack(A_LU, pivots)\n&gt;&gt;&gt; P\ntensor([[[1., 0., 0.],\n         [0., 1., 0.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 1., 0.],\n         [1., 0., 0.]]])\n&gt;&gt;&gt; A_L\ntensor([[[ 1.0000,  0.0000],\n         [ 0.4763,  1.0000],\n         [ 0.3683,  0.1135]],\n\n        [[ 1.0000,  0.0000],\n         [ 0.2957,  1.0000],\n         [-0.9668, -0.3335]]])\n&gt;&gt;&gt; A_U\ntensor([[[ 2.1962,  1.0881],\n         [ 0.0000, -0.8681]],\n\n        [[-1.0947,  0.3736],\n         [ 0.0000,  0.5718]]])\n&gt;&gt;&gt; A_ = torch.bmm(P, torch.bmm(A_L, A_U))\n&gt;&gt;&gt; torch.norm(A_ - A)\ntensor(2.9802e-08)\n\n\n", "description": "", "code-info": {"name": "torch.lu_unpack", "parameters": [{"name": "LU_data", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the packed LU factorization data"}, {"name": "LU_pivots", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the packed LU factorization pivots"}, {"name": "unpack_data", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 flag indicating if the data should be unpacked"}, {"name": "unpack_pivots", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool) \u2013 flag indicating if the pivots should be unpacked"}]}},
{"code": "torch.matmul(input,other,out=None)", "id": "torch.matmul", "summary": "Matrix product of two tensors.\nThe behavior depends on the dimensionality of the tensors as follows:\n\nIf both tensors are 1-dimensional, the dot product (scalar) is returned.\nIf both arguments are 2-dimensional, the matrix-matrix product is returned.\nIf the first argument is 1-dimensional and the second argument is 2-dimensional,\na 1 is prepended to its dimension for the purpose of the matrix multiply.\nAfter the matrix multiply, the prepended dimension is removed.\nIf the first argument is 2-dimensional and the second argument is 1-dimensional,\nthe matrix-vector product is returned.\nIf both arguments are at least 1-dimensional and at least one argument is\nN-dimensional (where N &gt; 2), then a batched matrix multiply is returned", "description": "", "code-info": {"name": "torch.matmul", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the first tensor to be multiplied"}, {"name": "other", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the second tensor to be multiplied"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.matrix_power(input,n)", "id": "torch.matrix_power", "summary": "Returns the matrix raised to the power n for square matrices.\nFor batch of matrices, each individual matrix is raised to the power n.\nIf n is negative, then the inverse of the matrix (if invertible) is\nraised to the power n", "description": "", "code-info": {"name": "torch.matrix_power", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor."}, {"name": "n", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the power to raise the matrix to"}]}},
{"code": "torch.matrix_rank(input,tol=None,symmetric=False)", "id": "torch.matrix_rank", "summary": "Returns the numerical rank of a 2-D tensor", "description": "", "code-info": {"name": "torch.matrix_rank", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input 2-D tensor"}, {"name": "tol", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float, optional) \u2013 the tolerance value. Default: None"}, {"name": "symmetric", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 indicates whether input is symmetric.\nDefault: False"}]}},
{"code": "torch.mm(input,mat2,out=None)", "id": "torch.mm", "summary": "Performs a matrix multiplication of the matrices input and mat2.\nIf input is a (n\u00d7m)(n \\times m)(n\u00d7m)\n\n tensor, mat2 is a\n(m\u00d7p)(m \\times p)(m\u00d7p)\n\n tensor, out will be a (n\u00d7p)(n \\times p)(n\u00d7p)\n\n tensor.\n\nNote\nThis function does not broadcast.\nFor broadcasting matrix products, see torch.matmul().\n\n\nParameters\n\ninput (Tensor) \u2013 the first matrix to be multiplied\nmat2 (Tensor) \u2013 the second matrix to be multiplied\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; mat1 = torch.randn(2, 3)\n&gt;&gt;&gt; mat2 = torch.randn(3, 3)\n&gt;&gt;&gt; torch.mm(mat1, mat2)\ntensor([[ 0.4851,  0.5037, -0.3633],\n        [-0.0760, -3.6705,  2.4784]])\n\n\n", "description": "", "code-info": {"name": "torch.mm", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the first matrix to be multiplied"}, {"name": "mat2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the second matrix to be multiplied"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.mv(input,vec,out=None)", "id": "torch.mv", "summary": "Performs a matrix-vector product of the matrix input and the vector\nvec.\nIf input is a (n\u00d7m)(n \\times m)(n\u00d7m)\n\n tensor, vec is a 1-D tensor of\nsize mmm\n\n, out will be 1-D of size nnn\n\n.\n\nNote\nThis function does not broadcast.\n\n\nParameters\n\ninput (Tensor) \u2013 matrix to be multiplied\nvec (Tensor) \u2013 vector to be multiplied\nout (Tensor, optional) \u2013 the output tensor.\n\n\n\nExample:\n&gt;&gt;&gt; mat = torch.randn(2, 3)\n&gt;&gt;&gt; vec = torch.randn(3)\n&gt;&gt;&gt; torch.mv(mat, vec)\ntensor([ 1.0404, -0.6361])\n\n\n", "description": "", "code-info": {"name": "torch.mv", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 matrix to be multiplied"}, {"name": "vec", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 vector to be multiplied"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 the output tensor."}]}},
{"code": "torch.orgqr(input,input2)", "id": "torch.orgqr", "summary": "Computes the orthogonal matrix Q of a QR factorization, from the (input, input2)\ntuple returned by torch.geqrf().\nThis directly calls the underlying LAPACK function ?orgqr.\nSee LAPACK documentation for orgqr for further details.\n\nParameters\n\ninput (Tensor) \u2013 the a from torch.geqrf().\ninput2 (Tensor) \u2013 the tau from torch.geqrf().\n\n\n\n", "description": "", "code-info": {"name": "torch.orgqr", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the a from torch.geqrf()."}, {"name": "input2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tau from torch.geqrf()."}]}},
{"code": "torch.ormqr(input,input2,input3,left=True,transpose=False)", "id": "torch.ormqr", "summary": "Multiplies mat (given by input3) by the orthogonal Q matrix of the QR factorization\nformed by torch.geqrf() that is represented by (a, tau) (given by (input, input2)).\nThis directly calls the underlying LAPACK function ?ormqr.\nSee LAPACK documentation for ormqr for further details.\n\nParameters\n\ninput (Tensor) \u2013 the a from torch.geqrf().\ninput2 (Tensor) \u2013 the tau from torch.geqrf().\ninput3 (Tensor) \u2013 the matrix to be multiplied.\n\n\n\n", "description": "", "code-info": {"name": "torch.ormqr", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the a from torch.geqrf()."}, {"name": "input2", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the tau from torch.geqrf()."}, {"name": "input3", "is_optional": false, "type": "others", "description": ""}, {"name": "left", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "transpose", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.pinverse(input,rcond=1e-15)", "id": "torch.pinverse", "summary": "Calculates the pseudo-inverse (also known as the Moore-Penrose inverse) of a 2D tensor.\nPlease look at Moore-Penrose inverse for more details\n\nNote\nThis method is implemented using the Singular Value Decomposition.\n\n\nNote\nThe pseudo-inverse is not necessarily a continuous function in the elements of the matrix [1].\nTherefore, derivatives are not always existent, and exist for a constant rank only [2].\nHowever, this method is backprop-able due to the implementation by using SVD results, and\ncould be unstable", "description": "", "code-info": {"name": "torch.pinverse", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 The input tensor of size (\u2217,m,n)(*, m, n)(\u2217,m,n)\n\n where \u2217*\u2217\n\n is zero or more batch dimensions"}, {"name": "rcond", "is_optional": true, "type": "float", "default_value": "1e-15", "description": "(python:float) \u2013 A floating point value to determine the cutoff for small singular values.\nDefault: 1e-15"}]}},
{"code": "torch.qr(input,some=True,out=None)", "id": "torch.qr", "summary": "Computes the QR decomposition of a matrix or a batch of matrices input,\nand returns a namedtuple (Q, R) of tensors such that input=QR\\text{input} = Q Rinput=QR\n\n\nwith QQQ\n\n being an orthogonal matrix or batch of orthogonal matrices and\nRRR\n\n being an upper triangular matrix or batch of upper triangular matrices.\nIf some is True, then this function returns the thin (reduced) QR factorization.\nOtherwise, if some is False, this function returns the complete QR factorization.\n\nNote\nprecision may be lost if the magnitudes of the elements of input\nare large\n\n\nNote\nWhile it should always give you a valid decomposition, it may not\ngive you the same one across platforms - it will depend on your\nLAPACK implementation.\n\n\nParameters\n\ninput (Tensor) \u2013 the input tensor of size (\u2217,m,n)(*, m, n)(\u2217,m,n)\n\n where * is zero or more\nbatch dimensions consisting of matrices of dimension m\u00d7nm \\times nm\u00d7n\n\n.\nsome (bool, optional) \u2013 Set to True for reduced QR decomposition and False for\ncomplete QR decomposition.\nout (tuple, optional) \u2013 tuple of Q and R tensors\nsatisfying input = torch.matmul(Q, R).\nThe dimensions of Q and R are (\u2217,m,k)(*, m, k)(\u2217,m,k)\n\n and (\u2217,k,n)(*, k, n)(\u2217,k,n)\n\n\nrespectively, where k=min\u2061(m,n)k = \\min(m, n)k=min(m,n)\n\n if some: is True and\nk=mk = mk=m\n\n otherwise.\n\n\n\nExample:\n&gt;&gt;&gt; a = torch.tensor([[12., -51, 4], [6, 167, -68], [-4, 24, -41]])\n&gt;&gt;&gt; q, r = torch.qr(a)\n&gt;&gt;&gt; q\ntensor([[-0.8571,  0.3943,  0.3314],\n        [-0.4286, -0.9029, -0.0343],\n        [ 0.2857, -0.1714,  0.9429]])\n&gt;&gt;&gt; r\ntensor([[ -14.0000,  -21.0000,   14.0000],\n        [   0.0000, -175.0000,   70.0000],\n        [   0.0000,    0.0000,  -35.0000]])\n&gt;&gt;&gt; torch.mm(q, r).round()\ntensor([[  12.,  -51.,    4.],\n        [   6.,  167.,  -68.],\n        [  -4.,   24.,  -41.]])\n&gt;&gt;&gt; torch.mm(q.t(), q).round()\ntensor([[ 1.,  0.,  0.],\n        [ 0.,  1., -0.],\n        [ 0., -0.,  1.]])\n&gt;&gt;&gt; a = torch.randn(3, 4, 5)\n&gt;&gt;&gt; q, r = torch.qr(a, some=False)\n&gt;&gt;&gt; torch.allclose(torch.matmul(q, r), a)\nTrue\n&gt;&gt;&gt; torch.allclose(torch.matmul(q.transpose(-2, -1), q), torch.eye(5))\nTrue\n\n\n", "description": "", "code-info": {"name": "torch.qr", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor of size (\u2217,m,n)(*, m, n)(\u2217,m,n)\n\n where * is zero or more\nbatch dimensions consisting of matrices of dimension m\u00d7nm \\times nm\u00d7n\n\n."}, {"name": "some", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 Set to True for reduced QR decomposition and False for\ncomplete QR decomposition."}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 tuple of Q and R tensors\nsatisfying input = torch.matmul(Q, R).\nThe dimensions of Q and R are (\u2217,m,k)(*, m, k)(\u2217,m,k)"}]}},
{"code": "torch.nn.InstanceNorm1d(num_features,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)", "id": "torch.nn.InstanceNorm1d", "summary": "Applies Instance Normalization over a 3D input (a mini-batch of 1D\ninputs with optional additional channel dimension) as described in the paper\nInstance Normalization: The Missing Ingredient for Fast Stylization .\n\ny=x\u2212E[x]Var[x]+\u03f5\u2217\u03b3+\u03b2y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+\u03f5\u200bx\u2212E[x]\u200b\u2217\u03b3+\u03b2\n\nThe mean and standard-deviation are calculated per-dimension separately\nfor each object in a mini-batch", "description": "", "code-info": {"name": "torch.nn.InstanceNorm1d", "parameters": [{"name": "num_features", "is_optional": false, "type": "others", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "affine", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "track_running_stats", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.InstanceNorm2d(num_features,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)", "id": "torch.nn.InstanceNorm2d", "summary": "Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs\nwith additional channel dimension) as described in the paper\nInstance Normalization: The Missing Ingredient for Fast Stylization .\n\ny=x\u2212E[x]Var[x]+\u03f5\u2217\u03b3+\u03b2y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+\u03f5\u200bx\u2212E[x]\u200b\u2217\u03b3+\u03b2\n\nThe mean and standard-deviation are calculated per-dimension separately\nfor each object in a mini-batch", "description": "", "code-info": {"name": "torch.nn.InstanceNorm2d", "parameters": [{"name": "num_features", "is_optional": false, "type": "others", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "affine", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "track_running_stats", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.InstanceNorm3d(num_features,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)", "id": "torch.nn.InstanceNorm3d", "summary": "Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs\nwith additional channel dimension) as described in the paper\nInstance Normalization: The Missing Ingredient for Fast Stylization .\n\ny=x\u2212E[x]Var[x]+\u03f5\u2217\u03b3+\u03b2y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+\u03f5\u200bx\u2212E[x]\u200b\u2217\u03b3+\u03b2\n\nThe mean and standard-deviation are calculated per-dimension separately\nfor each object in a mini-batch", "description": "", "code-info": {"name": "torch.nn.InstanceNorm3d", "parameters": [{"name": "num_features", "is_optional": false, "type": "others", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "affine", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "track_running_stats", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.LayerNorm(normalized_shape,eps=1e-05,elementwise_affine=True)", "id": "torch.nn.LayerNorm", "summary": "Applies Layer Normalization over a mini-batch of inputs as described in\nthe paper Layer Normalization .\n\ny=x\u2212E[x]Var[x]+\u03f5\u2217\u03b3+\u03b2y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\ny=Var[x]+\u03f5\u200bx\u2212E[x]\u200b\u2217\u03b3+\u03b2\n\nThe mean and standard-deviation are calculated separately over the last\ncertain number dimensions which have to be of the shape specified by\nnormalized_shape.\n\u03b3\\gamma\u03b3\n\n and \u03b2\\beta\u03b2\n\n are learnable affine transform parameters of\nnormalized_shape if elementwise_affine is True.\n\nNote\nUnlike Batch Normalization and Instance Normalization, which applies\nscalar scale and bias for each entire channel/plane with the\naffine option, Layer Normalization applies per-element scale and\nbias with elementwise_affine.\n\nThis layer uses statistics computed from input data in both training and\nevaluation modes.\n\nParameters\n\nnormalized_shape (python:int or list or torch.Size) \u2013 input shape from an expected input\nof size\n\n[\u2217\u00d7normalized_shape[0]\u00d7normalized_shape[1]\u00d7\u2026\u00d7normalized_shape[\u22121]][* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]\n    \\times \\ldots \\times \\text{normalized\\_shape}[-1]]\n\n[\u2217\u00d7normalized_shape[0]\u00d7normalized_shape[1]\u00d7\u2026\u00d7normalized_shape[\u22121]]\n\nIf a single integer is used, it is treated as a singleton list, and this module will\nnormalize over the last dimension which is expected to be of that specific size.\n\neps \u2013 a value added to the denominator for numerical stability", "description": "", "code-info": {"name": "torch.nn.LayerNorm", "parameters": [{"name": "normalized_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "elementwise_affine", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.LocalResponseNorm(size,alpha=0.0001,beta=0.75,k=1.0)", "id": "torch.nn.LocalResponseNorm", "summary": "Applies local response normalization over an input signal composed\nof several input planes, where channels occupy the second dimension.\nApplies normalization across channels.\n\nbc=ac(k+\u03b1n\u2211c\u2032=max\u2061(0,c\u2212n/2)min\u2061(N\u22121,c+n/2)ac\u20322)\u2212\u03b2b_{c} = a_{c}\\left(k + \\frac{\\alpha}{n}\n\\sum_{c'=\\max(0, c-n/2)}^{\\min(N-1,c+n/2)}a_{c'}^2\\right)^{-\\beta}\n\nbc\u200b=ac\u200b\u239d\u239c\u239b\u200bk+n\u03b1\u200bc\u2032=max(0,c\u2212n/2)\u2211min(N\u22121,c+n/2)\u200bac\u20322\u200b\u23a0\u239f\u239e\u200b\u2212\u03b2\n\n\nParameters\n\nsize \u2013 amount of neighbouring channels used for normalization\nalpha \u2013 multiplicative factor", "description": "", "code-info": {"name": "torch.nn.LocalResponseNorm", "parameters": [{"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "alpha", "is_optional": true, "type": "others", "default_value": "0.0001", "description": ""}, {"name": "beta", "is_optional": true, "type": "others", "default_value": "0.75", "description": ""}, {"name": "k", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}]}},
{"code": "torch.solve(input,A,out=None)", "id": "torch.solve", "summary": "This function returns the solution to the system of linear\nequations represented by AX=BAX = BAX=B\n\n and the LU factorization of\nA, in order as a namedtuple solution, LU.\nLU contains L and U factors for LU factorization of A.\ntorch.solve(B, A) can take in 2D inputs B, A or inputs that are\nbatches of 2D matrices", "description": "", "code-info": {"name": "torch.solve", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input matrix BBB\n\n of size (\u2217,m,k)(*, m, k)(\u2217,m,k)\n\n , where \u2217*\u2217\n\n\nis zero or more batch dimensions."}, {"name": "A", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 input square matrix of size (\u2217,m,m)(*, m, m)(\u2217,m,m)\n\n, where\n\u2217*\u2217\n\n is zero or more batch dimensions."}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": "((Tensor, Tensor), optional) \u2013 optional output tuple."}]}},
{"code": "torch.svd(input,some=True,compute_uv=True,out=None)", "id": "torch.svd", "summary": "This function returns a namedtuple (U, S, V) which is the singular value\ndecomposition of a input real matrix or batches of real matrices input such that\ninput=U\u00d7diag(S)\u00d7VTinput = U \\times diag(S) \\times V^Tinput=U\u00d7diag(S)\u00d7VT\n\n.\nIf some is True (default), the method returns the reduced singular value decomposition\ni.e., if the last two dimensions of input are m and n, then the returned\nU and V matrices will contain only min(n,m)min(n, m)min(n,m)\n\n orthonormal columns.\nIf compute_uv is False, the returned U and V matrices will be zero matrices\nof shape (m\u00d7m)(m \\times m)(m\u00d7m)\n\n and (n\u00d7n)(n \\times n)(n\u00d7n)\n\n respectively", "description": "", "code-info": {"name": "torch.svd", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor of size (\u2217,m,n)(*, m, n)(\u2217,m,n)\n\n where * is zero or more\nbatch dimensions consisting of m\u00d7nm \\times nm\u00d7n\n\n matrices."}, {"name": "some", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 controls the shape of returned U and V"}, {"name": "compute_uv", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 option whether to compute U and V or not"}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 the output tuple of tensors"}]}},
{"code": "torch.symeig(input,eigenvectors=False,upper=True,out=None)", "id": "torch.symeig", "summary": "This function returns eigenvalues and eigenvectors\nof a real symmetric matrix input or a batch of real symmetric matrices,\nrepresented by a namedtuple (eigenvalues, eigenvectors).\nThis function calculates all eigenvalues (and vectors) of input\nsuch that input=Vdiag(e)VT\\text{input} = V \\text{diag}(e) V^Tinput=Vdiag(e)VT\n\n.\nThe boolean argument eigenvectors defines computation of\nboth eigenvectors and eigenvalues or eigenvalues only.\nIf it is False, only eigenvalues are computed", "description": "", "code-info": {"name": "torch.symeig", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input tensor of size (\u2217,n,n)(*, n, n)(\u2217,n,n)\n\n where * is zero or more\nbatch dimensions consisting of symmetric matrices."}, {"name": "eigenvectors", "is_optional": true, "type": "bool", "default_value": "False", "description": "(boolean, optional) \u2013 controls whether eigenvectors have to be computed"}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "True", "description": "(boolean, optional) \u2013 controls whether to consider upper-triangular or lower-triangular region"}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": "(tuple, optional) \u2013 the output tuple of (Tensor, Tensor)"}]}},
{"code": "torch.trapz()", "id": "torch.trapz", "summary": "\n\ntorch.trapz(y, x, *, dim=-1) \u2192 Tensor\n\n\nEstimate \u222by\u2009dx\\int y\\,dx\u222bydx\n\n along dim, using the trapezoid rule.\n\nParameters\n\ny (Tensor) \u2013 The values of the function to integrate\nx (Tensor) \u2013 The points at which the function y is sampled.\nIf x is not in ascending order, intervals on which it is decreasing\ncontribute negatively to the estimated integral (i.e., the convention\n\u222babf=\u2212\u222bbaf\\int_a^b f = -\\int_b^a f\u222bab\u200bf=\u2212\u222bba\u200bf\n\n is followed).\ndim (python:int) \u2013 The dimension along which to integrate.\nBy default, use the last dimension.\n\n\nReturns\nA Tensor with the same shape as the input, except with dim removed.\nEach element of the returned tensor represents the estimated integral\n\u222by\u2009dx\\int y\\,dx\u222bydx\n\n along dim.\n\n\nExample:\n&gt;&gt;&gt; y = torch.randn((2, 3))\n&gt;&gt;&gt; y\ntensor([[-2.1156,  0.6857, -0.2700],\n        [-1.2145,  0.5540,  2.0431]])\n&gt;&gt;&gt; x = torch.tensor([[1, 3, 4], [1, 2, 3]])\n&gt;&gt;&gt; torch.trapz(y, x)\ntensor([-1.2220,  0.9683])\n\n\n\n\ntorch.trapz(y, *, dx=1, dim=-1) \u2192 Tensor\n\n\nAs above, but the sample points are spaced uniformly at a distance of dx.\n\nParameters\n\ny (Tensor) \u2013 The values of the function to integrate\ndx (python:float) \u2013 The distance between points at which y is sampled.\ndim (python:int) \u2013 The dimension along which to integrate.\nBy default, use the last dimension.\n\n\nReturns\nA Tensor with the same shape as the input, except with dim removed.\nEach element of the returned tensor represents the estimated integral\n\u222by\u2009dx\\int y\\,dx\u222bydx\n\n along dim.\n\n\n", "description": "", "code-info": {"name": "torch.trapz", "parameters": []}},
{"code": "sig-prename descclassname(y,x,*,dim=-1)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "y", "is_optional": false, "type": "others", "description": ""}, {"name": "x", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}]}},
{"code": "sig-prename descclassname(y,*,dx=1,dim=-1)", "id": "sig-prename descclassname", "summary": "", "description": "", "code-info": {"name": "sig-prename descclassname", "parameters": [{"name": "y", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "dx", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}]}},
{"code": "torch.triangular_solve(input,A,upper=True,transpose=False,unitriangular=False)", "id": "torch.triangular_solve", "summary": "Solves a system of equations with a triangular coefficient matrix AAA\n\n\nand multiple right-hand sides bbb\n\n.\nIn particular, solves AX=bAX = bAX=b\n\n and assumes AAA\n\n is upper-triangular\nwith the default keyword arguments.\ntorch.triangular_solve(b, A) can take in 2D inputs b, A or inputs that are\nbatches of 2D matrices", "description": "", "code-info": {"name": "torch.triangular_solve", "parameters": [{"name": "input", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 multiple right-hand sides of size (\u2217,m,k)(*, m, k)(\u2217,m,k)\n\n where\n\u2217*\u2217\n\n is zero of more batch dimensions (bbb\n\n)"}, {"name": "A", "is_optional": false, "type": "tensor", "description": "(Tensor) \u2013 the input triangular coefficient matrix of size (\u2217,m,m)(*, m, m)(\u2217,m,m)\n\n\nwhere \u2217*\u2217\n\n is zero or more batch dimensions"}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 whether to solve the upper-triangular system\nof equations (default) or the lower-triangular system of equations. Default: True."}, {"name": "transpose", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 whether AAA\n\n should be transposed before\nbeing sent into the solver. Default: False."}, {"name": "unitriangular", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 whether AAA"}]}},
{"code": "torch.compiled_with_cxx11_abi()", "id": "torch.compiled_with_cxx11_abi", "summary": "Returns whether PyTorch was built with _GLIBCXX_USE_CXX11_ABI=1\n", "description": "", "code-info": {"name": "torch.compiled_with_cxx11_abi", "parameters": []}},
{"code": "torch.result_type(tensor1,tensor2)", "id": "torch.result_type", "summary": "Returns the torch.dtype that would result from performing an arithmetic\noperation on the provided input tensors", "description": "", "code-info": {"name": "torch.result_type", "parameters": [{"name": "tensor1", "is_optional": false, "type": "tensor", "description": "(Tensor or Number) \u2013 an input tensor or number"}, {"name": "tensor2", "is_optional": false, "type": "tensor", "description": "(Tensor or Number) \u2013 an input tensor or number"}]}},
{"code": "torch.nn.RNNBase(mode,input_size,hidden_size,num_layers=1,bias=True,batch_first=False,dropout=0.0,bidirectional=False)", "id": "torch.nn.RNNBase", "summary": "\n\nflatten_parameters() \u00b6\nResets parameter data pointer so that they can use faster code paths.\nRight now, this works only if the module is on the GPU and cuDNN is enabled.\nOtherwise, it\u2019s a no-op.\n\n\n", "description": "", "code-info": {"name": "torch.nn.RNNBase", "parameters": [{"name": "mode", "is_optional": false, "type": "others", "description": ""}, {"name": "input_size", "is_optional": false, "type": "others", "description": ""}, {"name": "hidden_size", "is_optional": false, "type": "others", "description": ""}, {"name": "num_layers", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "batch_first", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dropout", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}, {"name": "bidirectional", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.RNN(*args,**kwargs)", "id": "torch.nn.RNN", "summary": "Applies a multi-layer Elman RNN with tanhtanhtanh\n\n or ReLUReLUReLU\n\n non-linearity to an\ninput sequence.\nFor each element in the input sequence, each layer computes the following\nfunction:\n\nht=tanh(Wihxt+bih+Whhh(t\u22121)+bhh)h_t = \\text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n\nht\u200b=tanh(Wih\u200bxt\u200b+bih\u200b+Whh\u200bh(t\u22121)\u200b+bhh\u200b)\n\nwhere hth_tht\u200b\n\n is the hidden state at time t, xtx_txt\u200b\n\n is\nthe input at time t, and h(t\u22121)h_{(t-1)}h(t\u22121)\u200b\n\n is the hidden state of the\nprevious layer at time t-1 or the initial hidden state at time 0.\nIf nonlinearity is 'relu', then ReLU is used instead of tanh.\n\nParameters\n\ninput_size \u2013 The number of expected features in the input x\nhidden_size \u2013 The number of features in the hidden state h\nnum_layers \u2013 Number of recurrent layers", "description": "", "code-info": {"name": "torch.nn.RNN", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.LSTM(*args,**kwargs)", "id": "torch.nn.LSTM", "summary": "Applies a multi-layer long short-term memory (LSTM) RNN to an input\nsequence.\nFor each element in the input sequence, each layer computes the following\nfunction:\n\nit=\u03c3(Wiixt+bii+Whih(t\u22121)+bhi)ft=\u03c3(Wifxt+bif+Whfh(t\u22121)+bhf)gt=tanh\u2061(Wigxt+big+Whgh(t\u22121)+bhg)ot=\u03c3(Wioxt+bio+Whoh(t\u22121)+bho)ct=ft\u2217c(t\u22121)+it\u2217gtht=ot\u2217tanh\u2061(ct)\\begin{array}{ll} \\\\\n    i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\\n    f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\\\\n    g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\\\\n    o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\\n    c_t = f_t * c_{(t-1)} + i_t * g_t \\\\\n    h_t = o_t * \\tanh(c_t) \\\\\n\\end{array}\n\nit\u200b=\u03c3(Wii\u200bxt\u200b+bii\u200b+Whi\u200bh(t\u22121)\u200b+bhi\u200b)ft\u200b=\u03c3(Wif\u200bxt\u200b+bif\u200b+Whf\u200bh(t\u22121)\u200b+bhf\u200b)gt\u200b=tanh(Wig\u200bxt\u200b+big\u200b+Whg\u200bh(t\u22121)\u200b+bhg\u200b)ot\u200b=\u03c3(Wio\u200bxt\u200b+bio\u200b+Who\u200bh(t\u22121)\u200b+bho\u200b)ct\u200b=ft\u200b\u2217c(t\u22121)\u200b+it\u200b\u2217gt\u200bht\u200b=ot\u200b\u2217tanh(ct\u200b)\u200b\n\nwhere hth_tht\u200b\n\n is the hidden state at time t, ctc_tct\u200b\n\n is the cell\nstate at time t, xtx_txt\u200b\n\n is the input at time t, h(t\u22121)h_{(t-1)}h(t\u22121)\u200b\n\n\nis the hidden state of the layer at time t-1 or the initial hidden\nstate at time 0, and iti_tit\u200b\n\n, ftf_tft\u200b\n\n, gtg_tgt\u200b\n\n,\noto_tot\u200b\n\n are the input, forget, cell, and output gates, respectively.\n\u03c3\\sigma\u03c3\n\n is the sigmoid function, and \u2217*\u2217\n\n is the Hadamard product.\nIn a multilayer LSTM, the input xt(l)x^{(l)}_txt(l)\u200b\n\n of the lll\n\n -th layer\n(l&gt;=2l &gt;= 2l&gt;=2\n\n) is the hidden state ht(l\u22121)h^{(l-1)}_tht(l\u22121)\u200b\n\n of the previous layer multiplied by\ndropout \u03b4t(l\u22121)\\delta^{(l-1)}_t\u03b4t(l\u22121)\u200b\n\n where each \u03b4t(l\u22121)\\delta^{(l-1)}_t\u03b4t(l\u22121)\u200b\n\n is a Bernoulli random\nvariable which is 000\n\n with probability dropout.\n\nParameters\n\ninput_size \u2013 The number of expected features in the input x\nhidden_size \u2013 The number of features in the hidden state h\nnum_layers \u2013 Number of recurrent layers", "description": "", "code-info": {"name": "torch.nn.LSTM", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.can_cast(from,to)", "id": "torch.can_cast", "summary": "Determines if a type conversion is allowed under PyTorch casting rules\ndescribed in the type promotion documentation.\n\nParameters\n\nfrom (dpython:type) \u2013 The original torch.dtype.\nto (dpython:type) \u2013 The target torch.dtype.\n\n\n\nExample:\n&gt;&gt;&gt; torch.can_cast(torch.double, torch.float)\nTrue\n&gt;&gt;&gt; torch.can_cast(torch.float, torch.int)\nFalse\n\n\n", "description": "", "code-info": {"name": "torch.can_cast", "parameters": [{"name": "from", "is_optional": false, "type": "others", "description": "(dpython:type) \u2013 The original torch.dtype."}, {"name": "to", "is_optional": false, "type": "others", "description": "(dpython:type) \u2013 The target torch.dtype."}]}},
{"code": "torch.promote_types(type1,type2)", "id": "torch.promote_types", "summary": "Returns the torch.dtype with the smallest size and scalar kind that is\nnot smaller nor of lower kind than either type1 or type2", "description": "", "code-info": {"name": "torch.promote_types", "parameters": [{"name": "type1", "is_optional": false, "type": "others", "description": "(torch.dtype) \u2013 "}, {"name": "type2", "is_optional": false, "type": "others", "description": "(torch.dtype) \u2013 "}]}},
{"code": "torch._C.Generator.get_state()", "id": "torch._C.Generator.get_state", "summary": "Returns the Generator state as a torch.ByteTensor.\n\nReturns\nA torch.ByteTensor which contains all the necessary bits\nto restore a Generator to a specific point in time.\n\nReturn type\nTensor\n\n\nExample:\n&gt;&gt;&gt; g_cpu = torch.Generator()\n&gt;&gt;&gt; g_cpu.get_state()\n\n\n", "description": "", "code-info": {"name": "torch._C.Generator.get_state", "parameters": []}},
{"code": "torch._C.Generator.initial_seed()", "id": "torch._C.Generator.initial_seed", "summary": "Returns the initial seed for generating random numbers.\nExample:\n&gt;&gt;&gt; g_cpu = torch.Generator()\n&gt;&gt;&gt; g_cpu.initial_seed()\n2147483647\n\n\n", "description": "", "code-info": {"name": "torch._C.Generator.initial_seed", "parameters": []}},
{"code": "torch._C.Generator.manual_seed(seed)", "id": "torch._C.Generator.manual_seed", "summary": "Sets the seed for generating random numbers", "description": "", "code-info": {"name": "torch._C.Generator.manual_seed", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": "(python:int) \u2013 The desired seed."}]}},
{"code": "torch._C.Generator.seed()", "id": "torch._C.Generator.seed", "summary": "Gets a non-deterministic random number from std::random_device or the current\ntime and uses it to seed a Generator.\nExample:\n&gt;&gt;&gt; g_cpu = torch.Generator()\n&gt;&gt;&gt; g_cpu.seed()\n1516516984916\n\n\n", "description": "", "code-info": {"name": "torch._C.Generator.seed", "parameters": []}},
{"code": "torch.nn.GRU(*args,**kwargs)", "id": "torch.nn.GRU", "summary": "Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\nFor each element in the input sequence, each layer computes the following\nfunction:\n\nrt=\u03c3(Wirxt+bir+Whrh(t\u22121)+bhr)zt=\u03c3(Wizxt+biz+Whzh(t\u22121)+bhz)nt=tanh\u2061(Winxt+bin+rt\u2217(Whnh(t\u22121)+bhn))ht=(1\u2212zt)\u2217nt+zt\u2217h(t\u22121)\\begin{array}{ll}\n    r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n    z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n    n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n    h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}\n\\end{array}\n\nrt\u200b=\u03c3(Wir\u200bxt\u200b+bir\u200b+Whr\u200bh(t\u22121)\u200b+bhr\u200b)zt\u200b=\u03c3(Wiz\u200bxt\u200b+biz\u200b+Whz\u200bh(t\u22121)\u200b+bhz\u200b)nt\u200b=tanh(Win\u200bxt\u200b+bin\u200b+rt\u200b\u2217(Whn\u200bh(t\u22121)\u200b+bhn\u200b))ht\u200b=(1\u2212zt\u200b)\u2217nt\u200b+zt\u200b\u2217h(t\u22121)\u200b\u200b\n\nwhere hth_tht\u200b\n\n is the hidden state at time t, xtx_txt\u200b\n\n is the input\nat time t, h(t\u22121)h_{(t-1)}h(t\u22121)\u200b\n\n is the hidden state of the layer\nat time t-1 or the initial hidden state at time 0, and rtr_trt\u200b\n\n,\nztz_tzt\u200b\n\n, ntn_tnt\u200b\n\n are the reset, update, and new gates, respectively.\n\u03c3\\sigma\u03c3\n\n is the sigmoid function, and \u2217*\u2217\n\n is the Hadamard product.\nIn a multilayer GRU, the input xt(l)x^{(l)}_txt(l)\u200b\n\n of the lll\n\n -th layer\n(l&gt;=2l &gt;= 2l&gt;=2\n\n) is the hidden state ht(l\u22121)h^{(l-1)}_tht(l\u22121)\u200b\n\n of the previous layer multiplied by\ndropout \u03b4t(l\u22121)\\delta^{(l-1)}_t\u03b4t(l\u22121)\u200b\n\n where each \u03b4t(l\u22121)\\delta^{(l-1)}_t\u03b4t(l\u22121)\u200b\n\n is a Bernoulli random\nvariable which is 000\n\n with probability dropout.\n\nParameters\n\ninput_size \u2013 The number of expected features in the input x\nhidden_size \u2013 The number of features in the hidden state h\nnum_layers \u2013 Number of recurrent layers", "description": "", "code-info": {"name": "torch.nn.GRU", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.RNNCell(input_size,hidden_size,bias=True,nonlinearity='tanh')", "id": "torch.nn.RNNCell", "summary": "An Elman RNN cell with tanh or ReLU non-linearity.\n\nh\u2032=tanh\u2061(Wihx+bih+Whhh+bhh)h' = \\tanh(W_{ih} x + b_{ih}  +  W_{hh} h + b_{hh})h\u2032=tanh(Wih\u200bx+bih\u200b+Whh\u200bh+bhh\u200b)\n\nIf nonlinearity is \u2018relu\u2019, then ReLU is used in place of tanh.\n\nParameters\n\ninput_size \u2013 The number of expected features in the input x\nhidden_size \u2013 The number of features in the hidden state h\nbias \u2013 If False, then the layer does not use bias weights b_ih and b_hh.\nDefault: True\nnonlinearity \u2013 The non-linearity to use", "description": "", "code-info": {"name": "torch.nn.RNNCell", "parameters": [{"name": "input_size", "is_optional": false, "type": "others", "description": ""}, {"name": "hidden_size", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "nonlinearity", "is_optional": true, "type": "string", "default_value": "'tanh'", "description": ""}]}},
{"code": "torch._C.Generator.set_state(new_state)", "id": "torch._C.Generator.set_state", "summary": "Sets the Generator state.\n\nParameters\nnew_state (torch.ByteTensor) \u2013 The desired state.\n\n\nExample:\n&gt;&gt;&gt; g_cpu = torch.Generator()\n&gt;&gt;&gt; g_cpu_other = torch.Generator()\n&gt;&gt;&gt; g_cpu.set_state(g_cpu_other.get_state())\n\n\n", "description": "", "code-info": {"name": "torch._C.Generator.set_state", "parameters": [{"name": "new_state", "is_optional": false, "type": "tensor", "description": "(torch.ByteTensor) \u2013 The desired state."}]}},
{"code": "torch.quasirandom.SobolEngine.draw(n=1,out=None,dtype=torch.float32)", "id": "torch.quasirandom.SobolEngine.draw", "summary": "Function to draw a sequence of n points from a Sobol sequence.\nNote that the samples are dependent on the previous samples", "description": "", "code-info": {"name": "torch.quasirandom.SobolEngine.draw", "parameters": [{"name": "n", "is_optional": true, "type": "int", "default_value": "1", "description": "(Int, optional) \u2013 The length of sequence of points to draw.\nDefault: 1"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 The output tensor"}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "torch.float32", "description": "(torch.dtype, optional) \u2013 the desired data type of the\nreturned tensor.\nDefault: torch.float32"}]}},
{"code": "torch.quasirandom.SobolEngine.fast_forward(n)", "id": "torch.quasirandom.SobolEngine.fast_forward", "summary": "Function to fast-forward the state of the SobolEngine by\nn steps", "description": "", "code-info": {"name": "torch.quasirandom.SobolEngine.fast_forward", "parameters": [{"name": "n", "is_optional": false, "type": "others", "description": "(Int) \u2013 The number of steps to fast-forward by."}]}},
{"code": "torch.quasirandom.SobolEngine.reset()", "id": "torch.quasirandom.SobolEngine.reset", "summary": "Function to reset the SobolEngine to base state.\n", "description": "", "code-info": {"name": "torch.quasirandom.SobolEngine.reset", "parameters": []}},
{"code": "torch._C.Generator(device='cpu')", "id": "torch._C.Generator", "summary": "Creates and returns a generator object which manages the state of the algorithm that\nproduces pseudo random numbers", "description": "", "code-info": {"name": "torch._C.Generator", "parameters": [{"name": "device", "is_optional": true, "type": "string", "default_value": "'cpu'", "description": "(torch.device, optional) \u2013 the desired device for the generator."}]}},
{"code": "torch.nn.LSTMCell(input_size,hidden_size,bias=True)", "id": "torch.nn.LSTMCell", "summary": "A long short-term memory (LSTM) cell.\n\ni=\u03c3(Wiix+bii+Whih+bhi)f=\u03c3(Wifx+bif+Whfh+bhf)g=tanh\u2061(Wigx+big+Whgh+bhg)o=\u03c3(Wiox+bio+Whoh+bho)c\u2032=f\u2217c+i\u2217gh\u2032=o\u2217tanh\u2061(c\u2032)\\begin{array}{ll}\ni = \\sigma(W_{ii} x + b_{ii} + W_{hi} h + b_{hi}) \\\\\nf = \\sigma(W_{if} x + b_{if} + W_{hf} h + b_{hf}) \\\\\ng = \\tanh(W_{ig} x + b_{ig} + W_{hg} h + b_{hg}) \\\\\no = \\sigma(W_{io} x + b_{io} + W_{ho} h + b_{ho}) \\\\\nc' = f * c + i * g \\\\\nh' = o * \\tanh(c') \\\\\n\\end{array}i=\u03c3(Wii\u200bx+bii\u200b+Whi\u200bh+bhi\u200b)f=\u03c3(Wif\u200bx+bif\u200b+Whf\u200bh+bhf\u200b)g=tanh(Wig\u200bx+big\u200b+Whg\u200bh+bhg\u200b)o=\u03c3(Wio\u200bx+bio\u200b+Who\u200bh+bho\u200b)c\u2032=f\u2217c+i\u2217gh\u2032=o\u2217tanh(c\u2032)\u200b\n\nwhere \u03c3\\sigma\u03c3\n\n is the sigmoid function, and \u2217*\u2217\n\n is the Hadamard product.\n\nParameters\n\ninput_size \u2013 The number of expected features in the input x\nhidden_size \u2013 The number of features in the hidden state h\nbias \u2013 If False, then the layer does not use bias weights b_ih and\nb_hh", "description": "", "code-info": {"name": "torch.nn.LSTMCell", "parameters": [{"name": "input_size", "is_optional": false, "type": "others", "description": ""}, {"name": "hidden_size", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.GRUCell(input_size,hidden_size,bias=True)", "id": "torch.nn.GRUCell", "summary": "A gated recurrent unit (GRU) cell\n\nr=\u03c3(Wirx+bir+Whrh+bhr)z=\u03c3(Wizx+biz+Whzh+bhz)n=tanh\u2061(Winx+bin+r\u2217(Whnh+bhn))h\u2032=(1\u2212z)\u2217n+z\u2217h\\begin{array}{ll}\nr = \\sigma(W_{ir} x + b_{ir} + W_{hr} h + b_{hr}) \\\\\nz = \\sigma(W_{iz} x + b_{iz} + W_{hz} h + b_{hz}) \\\\\nn = \\tanh(W_{in} x + b_{in} + r * (W_{hn} h + b_{hn})) \\\\\nh' = (1 - z) * n + z * h\n\\end{array}r=\u03c3(Wir\u200bx+bir\u200b+Whr\u200bh+bhr\u200b)z=\u03c3(Wiz\u200bx+biz\u200b+Whz\u200bh+bhz\u200b)n=tanh(Win\u200bx+bin\u200b+r\u2217(Whn\u200bh+bhn\u200b))h\u2032=(1\u2212z)\u2217n+z\u2217h\u200b\n\nwhere \u03c3\\sigma\u03c3\n\n is the sigmoid function, and \u2217*\u2217\n\n is the Hadamard product.\n\nParameters\n\ninput_size \u2013 The number of expected features in the input x\nhidden_size \u2013 The number of features in the hidden state h\nbias \u2013 If False, then the layer does not use bias weights b_ih and\nb_hh", "description": "", "code-info": {"name": "torch.nn.GRUCell", "parameters": [{"name": "input_size", "is_optional": false, "type": "others", "description": ""}, {"name": "hidden_size", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.Transformer(d_model=512,nhead=8,num_encoder_layers=6,num_decoder_layers=6,dim_feedforward=2048,dropout=0.1,activation='relu',custom_encoder=None,custom_decoder=None)", "id": "torch.nn.Transformer", "summary": "A transformer model", "description": "", "code-info": {"name": "torch.nn.Transformer", "parameters": [{"name": "d_model", "is_optional": true, "type": "int", "default_value": "512", "description": ""}, {"name": "nhead", "is_optional": true, "type": "int", "default_value": "8", "description": ""}, {"name": "num_encoder_layers", "is_optional": true, "type": "int", "default_value": "6", "description": ""}, {"name": "num_decoder_layers", "is_optional": true, "type": "int", "default_value": "6", "description": ""}, {"name": "dim_feedforward", "is_optional": true, "type": "int", "default_value": "2048", "description": ""}, {"name": "dropout", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "activation", "is_optional": true, "type": "string", "default_value": "'relu'", "description": ""}, {"name": "custom_encoder", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "custom_decoder", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.quasirandom.SobolEngine(dimension,scramble=False,seed=None)", "id": "torch.quasirandom.SobolEngine", "summary": "The torch.quasirandom.SobolEngine is an engine for generating\n(scrambled) Sobol sequences", "description": "", "code-info": {"name": "torch.quasirandom.SobolEngine", "parameters": [{"name": "dimension", "is_optional": false, "type": "others", "description": "(Int) \u2013 The dimensionality of the sequence to be drawn"}, {"name": "scramble", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Setting this to True will produce\nscrambled Sobol sequences. Scrambling is\ncapable of producing better Sobol\nsequences. Default: False."}, {"name": "seed", "is_optional": true, "type": "others", "default_value": "None", "description": "(Int, optional) \u2013 This is the seed for the scrambling. The seed\nof the random number generator is set to this,\nif specified. Otherwise, it uses a random seed.\nDefault: None"}]}},
{"code": "torch.nn.TransformerEncoder(encoder_layer,num_layers,norm=None)", "id": "torch.nn.TransformerEncoder", "summary": "TransformerEncoder is a stack of N encoder layers\n\nParameters\n\nencoder_layer \u2013 an instance of the TransformerEncoderLayer() class (required).\nnum_layers \u2013 the number of sub-encoder-layers in the encoder (required).\nnorm \u2013 the layer normalization component (optional).\n\n\n\n\nExamples::&gt;&gt;&gt; encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n&gt;&gt;&gt; transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n&gt;&gt;&gt; src = torch.rand(10, 32, 512)\n&gt;&gt;&gt; out = transformer_encoder(src)\n\n\n\n\n\n\nforward(src, mask=None, src_key_padding_mask=None) \u00b6\nPass the input through the encoder layers in turn.\n\nParameters\n\nsrc \u2013 the sequnce to the encoder (required).\nmask \u2013 the mask for the src sequence (optional).\nsrc_key_padding_mask \u2013 the mask for the src keys per batch (optional).\n\n\n\n\nShape:see the docs in Transformer class.\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.TransformerEncoder", "parameters": [{"name": "encoder_layer", "is_optional": false, "type": "others", "description": ""}, {"name": "num_layers", "is_optional": false, "type": "others", "description": ""}, {"name": "norm", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.TransformerDecoder(decoder_layer,num_layers,norm=None)", "id": "torch.nn.TransformerDecoder", "summary": "TransformerDecoder is a stack of N decoder layers\n\nParameters\n\ndecoder_layer \u2013 an instance of the TransformerDecoderLayer() class (required).\nnum_layers \u2013 the number of sub-decoder-layers in the decoder (required).\nnorm \u2013 the layer normalization component (optional).\n\n\n\n\nExamples::&gt;&gt;&gt; decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n&gt;&gt;&gt; transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n&gt;&gt;&gt; memory = torch.rand(10, 32, 512)\n&gt;&gt;&gt; tgt = torch.rand(20, 32, 512)\n&gt;&gt;&gt; out = transformer_decoder(tgt, memory)\n\n\n\n\n\n\nforward(tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None) \u00b6\nPass the inputs (and mask) through the decoder layer in turn.\n\nParameters\n\ntgt \u2013 the sequence to the decoder (required).\nmemory \u2013 the sequnce from the last layer of the encoder (required).\ntgt_mask \u2013 the mask for the tgt sequence (optional).\nmemory_mask \u2013 the mask for the memory sequence (optional).\ntgt_key_padding_mask \u2013 the mask for the tgt keys per batch (optional).\nmemory_key_padding_mask \u2013 the mask for the memory keys per batch (optional).\n\n\n\n\nShape:see the docs in Transformer class.\n\n\n\n\n", "description": "", "code-info": {"name": "torch.nn.TransformerDecoder", "parameters": [{"name": "decoder_layer", "is_optional": false, "type": "others", "description": ""}, {"name": "num_layers", "is_optional": false, "type": "others", "description": ""}, {"name": "norm", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.TransformerEncoderLayer(d_model,nhead,dim_feedforward=2048,dropout=0.1,activation='relu')", "id": "torch.nn.TransformerEncoderLayer", "summary": "TransformerEncoderLayer is made up of self-attn and feedforward network.\nThis standard encoder layer is based on the paper \u201cAttention Is All You Need\u201d.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\nLukasz Kaiser, and Illia Polosukhin", "description": "", "code-info": {"name": "torch.nn.TransformerEncoderLayer", "parameters": [{"name": "d_model", "is_optional": false, "type": "others", "description": ""}, {"name": "nhead", "is_optional": false, "type": "others", "description": ""}, {"name": "dim_feedforward", "is_optional": true, "type": "int", "default_value": "2048", "description": ""}, {"name": "dropout", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "activation", "is_optional": true, "type": "string", "default_value": "'relu'", "description": ""}]}},
{"code": "torch.nn.TransformerDecoderLayer(d_model,nhead,dim_feedforward=2048,dropout=0.1,activation='relu')", "id": "torch.nn.TransformerDecoderLayer", "summary": "TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.\nThis standard decoder layer is based on the paper \u201cAttention Is All You Need\u201d.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\nLukasz Kaiser, and Illia Polosukhin", "description": "", "code-info": {"name": "torch.nn.TransformerDecoderLayer", "parameters": [{"name": "d_model", "is_optional": false, "type": "others", "description": ""}, {"name": "nhead", "is_optional": false, "type": "others", "description": ""}, {"name": "dim_feedforward", "is_optional": true, "type": "int", "default_value": "2048", "description": ""}, {"name": "dropout", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "activation", "is_optional": true, "type": "string", "default_value": "'relu'", "description": ""}]}},
{"code": "torch.nn.Identity(*args,**kwargs)", "id": "torch.nn.Identity", "summary": "A placeholder identity operator that is argument-insensitive.\n\nParameters\n\nargs \u2013 any argument (unused)\nkwargs \u2013 any keyword argument (unused)\n\n\n\nExamples:\n&gt;&gt;&gt; m = nn.Identity(54, unused_argument1=0.1, unused_argument2=False)\n&gt;&gt;&gt; input = torch.randn(128, 20)\n&gt;&gt;&gt; output = m(input)\n&gt;&gt;&gt; print(output.size())\ntorch.Size([128, 20])\n\n\n", "description": "", "code-info": {"name": "torch.nn.Identity", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.Linear(in_features,out_features,bias=True)", "id": "torch.nn.Linear", "summary": "Applies a linear transformation to the incoming data: y=xAT+by = xA^T + by=xAT+b\n\n\n\nParameters\n\nin_features \u2013 size of each input sample\nout_features \u2013 size of each output sample\nbias \u2013 If set to False, the layer will not learn an additive bias.\nDefault: True\n\n\n\n\nShape:\nInput: (N,\u2217,Hin)(N, *, H_{in})(N,\u2217,Hin\u200b)\n\n where \u2217*\u2217\n\n means any number of\nadditional dimensions and Hin=in_featuresH_{in} = \\text{in\\_features}Hin\u200b=in_features\n\n\nOutput: (N,\u2217,Hout)(N, *, H_{out})(N,\u2217,Hout\u200b)\n\n where all but the last dimension\nare the same shape as the input and Hout=out_featuresH_{out} = \\text{out\\_features}Hout\u200b=out_features\n\n.\n\n\n\n\nVariables\n\n~Linear.weight \u2013 the learnable weights of the module of shape\n(out_features,in_features)(\\text{out\\_features}, \\text{in\\_features})(out_features,in_features)\n\n", "description": "", "code-info": {"name": "torch.nn.Linear", "parameters": [{"name": "in_features", "is_optional": false, "type": "others", "description": ""}, {"name": "out_features", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.Bilinear(in1_features,in2_features,out_features,bias=True)", "id": "torch.nn.Bilinear", "summary": "Applies a bilinear transformation to the incoming data:\ny=x1Ax2+by = x_1 A x_2 + by=x1\u200bAx2\u200b+b\n\n\n\nParameters\n\nin1_features \u2013 size of each first input sample\nin2_features \u2013 size of each second input sample\nout_features \u2013 size of each output sample\nbias \u2013 If set to False, the layer will not learn an additive bias.\nDefault: True\n\n\n\n\nShape:\nInput1: (N,\u2217,Hin1)(N, *, H_{in1})(N,\u2217,Hin1\u200b)\n\n where Hin1=in1_featuresH_{in1}=\\text{in1\\_features}Hin1\u200b=in1_features\n\n and\n\u2217*\u2217\n\n means any number of additional dimensions", "description": "", "code-info": {"name": "torch.nn.Bilinear", "parameters": [{"name": "in1_features", "is_optional": false, "type": "others", "description": ""}, {"name": "in2_features", "is_optional": false, "type": "others", "description": ""}, {"name": "out_features", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"code": "torch.nn.Dropout(p=0.5,inplace=False)", "id": "torch.nn.Dropout", "summary": "During training, randomly zeroes some of the elements of the input\ntensor with probability p using samples from a Bernoulli\ndistribution", "description": "", "code-info": {"name": "torch.nn.Dropout", "parameters": [{"name": "p", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.Dropout2d(p=0.5,inplace=False)", "id": "torch.nn.Dropout2d", "summary": "Randomly zero out entire channels (a channel is a 2D feature map,\ne.g., the jjj\n\n-th channel of the iii\n\n-th sample in the\nbatched input is a 2D tensor input[i,j]\\text{input}[i, j]input[i,j]\n\n).\nEach channel will be zeroed out independently on every forward call with\nprobability p using samples from a Bernoulli distribution.\nUsually the input comes from nn.Conv2d modules.\nAs described in the paper\nEfficient Object Localization Using Convolutional Networks ,\nif adjacent pixels within feature maps are strongly correlated\n(as is normally the case in early convolution layers) then i.i.d", "description": "", "code-info": {"name": "torch.nn.Dropout2d", "parameters": [{"name": "p", "is_optional": true, "type": "float", "default_value": "0.5", "description": "(python:float, optional) \u2013 probability of an element to be zero-ed."}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If set to True, will do this operation\nin-place"}]}},
{"code": "torch.nn.Dropout3d(p=0.5,inplace=False)", "id": "torch.nn.Dropout3d", "summary": "Randomly zero out entire channels (a channel is a 3D feature map,\ne.g., the jjj\n\n-th channel of the iii\n\n-th sample in the\nbatched input is a 3D tensor input[i,j]\\text{input}[i, j]input[i,j]\n\n).\nEach channel will be zeroed out independently on every forward call with\nprobability p using samples from a Bernoulli distribution.\nUsually the input comes from nn.Conv3d modules.\nAs described in the paper\nEfficient Object Localization Using Convolutional Networks ,\nif adjacent pixels within feature maps are strongly correlated\n(as is normally the case in early convolution layers) then i.i.d", "description": "", "code-info": {"name": "torch.nn.Dropout3d", "parameters": [{"name": "p", "is_optional": true, "type": "float", "default_value": "0.5", "description": "(python:float, optional) \u2013 probability of an element to be zeroed."}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If set to True, will do this operation\nin-place"}]}},
{"code": "torch.nn.AlphaDropout(p=0.5,inplace=False)", "id": "torch.nn.AlphaDropout", "summary": "Applies Alpha Dropout over the input.\nAlpha Dropout is a type of Dropout that maintains the self-normalizing\nproperty.\nFor an input with zero mean and unit standard deviation, the output of\nAlpha Dropout maintains the original mean and standard deviation of the\ninput.\nAlpha Dropout goes hand-in-hand with SELU activation function, which ensures\nthat the outputs have zero mean and unit standard deviation.\nDuring training, it randomly masks some of the elements of the input\ntensor with probability p using samples from a bernoulli distribution.\nThe elements to masked are randomized on every forward call, and scaled\nand shifted to maintain zero mean and unit standard deviation.\nDuring evaluation the module simply computes an identity function.\nMore details can be found in the paper Self-Normalizing Neural Networks .\n\nParameters\n\np (python:float) \u2013 probability of an element to be dropped", "description": "", "code-info": {"name": "torch.nn.AlphaDropout", "parameters": [{"name": "p", "is_optional": true, "type": "float", "default_value": "0.5", "description": "(python:float) \u2013 probability of an element to be dropped. Default: 0.5"}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 If set to True, will do this operation\nin-place"}]}},
{"code": "torch.nn.Embedding(num_embeddings,embedding_dim,padding_idx=None,max_norm=None,norm_type=2.0,scale_grad_by_freq=False,sparse=False,_weight=None)", "id": "torch.nn.Embedding", "summary": "A simple lookup table that stores embeddings of a fixed dictionary and size.\nThis module is often used to store word embeddings and retrieve them using indices.\nThe input to the module is a list of indices, and the output is the corresponding\nword embeddings.\n\nParameters\n\nnum_embeddings (python:int) \u2013 size of the dictionary of embeddings\nembedding_dim (python:int) \u2013 the size of each embedding vector\npadding_idx (python:int, optional) \u2013 If given, pads the output with the embedding vector at padding_idx\n(initialized to zeros) whenever it encounters the index.\nmax_norm (python:float, optional) \u2013 If given, each embedding vector with norm larger than max_norm\nis renormalized to have norm max_norm.\nnorm_type (python:float, optional) \u2013 The p of the p-norm to compute for the max_norm option", "description": "", "code-info": {"name": "torch.nn.Embedding", "parameters": [{"name": "num_embeddings", "is_optional": false, "type": "int", "description": "(python:int) \u2013 size of the dictionary of embeddings"}, {"name": "embedding_dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the size of each embedding vector"}, {"name": "padding_idx", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int, optional) \u2013 If given, pads the output with the embedding vector at padding_idx\n(initialized to zeros) whenever it encounters the index."}, {"name": "max_norm", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float, optional) \u2013 If given, each embedding vector with norm larger than max_norm\nis renormalized to have norm max_norm."}, {"name": "norm_type", "is_optional": true, "type": "float", "default_value": "2.0", "description": "(python:float, optional) \u2013 The p of the p-norm to compute for the max_norm option. Default 2."}, {"name": "scale_grad_by_freq", "is_optional": true, "type": "bool", "default_value": "False", "description": "(boolean, optional) \u2013 If given, this will scale gradients by the inverse of frequency of\nthe words in the mini-batch. Default False."}, {"name": "sparse", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "_weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.EmbeddingBag(num_embeddings,embedding_dim,max_norm=None,norm_type=2.0,scale_grad_by_freq=False,mode='mean',sparse=False,_weight=None)", "id": "torch.nn.EmbeddingBag", "summary": "Computes sums or means of \u2018bags\u2019 of embeddings, without instantiating the\nintermediate embeddings.\nFor bags of constant length and no per_sample_weights, this class\n\n\nwith mode=\"sum\" is equivalent to Embedding followed by torch.sum(dim=0),\nwith mode=\"mean\" is equivalent to Embedding followed by torch.mean(dim=0),\nwith mode=\"max\" is equivalent to Embedding followed by torch.max(dim=0).\n\n\nHowever, EmbeddingBag is much more time and memory efficient than using a chain of these\noperations.\nEmbeddingBag also supports per-sample weights as an argument to the forward\npass", "description": "", "code-info": {"name": "torch.nn.EmbeddingBag", "parameters": [{"name": "num_embeddings", "is_optional": false, "type": "int", "description": "(python:int) \u2013 size of the dictionary of embeddings"}, {"name": "embedding_dim", "is_optional": false, "type": "int", "description": "(python:int) \u2013 the size of each embedding vector"}, {"name": "max_norm", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float, optional) \u2013 If given, each embedding vector with norm larger than max_norm\nis renormalized to have norm max_norm."}, {"name": "norm_type", "is_optional": true, "type": "float", "default_value": "2.0", "description": "(python:float, optional) \u2013 The p of the p-norm to compute for the max_norm option. Default 2."}, {"name": "scale_grad_by_freq", "is_optional": true, "type": "bool", "default_value": "False", "description": "(boolean, optional) \u2013 if given, this will scale gradients by the inverse of frequency of\nthe words in the mini-batch. Default False.\nNote: this option is not supported when mode=\"max\"."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 \"sum\", \"mean\" or \"max\". Specifies the way to reduce the bag.\n\"sum\" computes the weighted sum, taking per_sample_weights\ninto consideration. \"mean\" computes the average of the values\nin the bag, \"max\" computes the max value over each bag.\nDefault: \"mean\""}, {"name": "sparse", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "_weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"code": "torch.nn.CosineSimilarity(dim=1,eps=1e-08)", "id": "torch.nn.CosineSimilarity", "summary": "Returns cosine similarity between x1x_1x1\u200b\n\n and x2x_2x2\u200b\n\n, computed along dim.\n\nsimilarity=x1\u22c5x2max\u2061(\u2225x1\u22252\u22c5\u2225x2\u22252,\u03f5).\\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)}.\n\nsimilarity=max(\u2225x1\u200b\u22252\u200b\u22c5\u2225x2\u200b\u22252\u200b,\u03f5)x1\u200b\u22c5x2\u200b\u200b.\n\n\nParameters\n\ndim (python:int, optional) \u2013 Dimension where cosine similarity is computed", "description": "", "code-info": {"name": "torch.nn.CosineSimilarity", "parameters": [{"name": "dim", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 Dimension where cosine similarity is computed. Default: 1"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-08", "description": "(python:float, optional) \u2013 Small value to avoid division by zero.\nDefault: 1e-8"}]}},
{"code": "torch.nn.PairwiseDistance(p=2.0,eps=1e-06,keepdim=False)", "id": "torch.nn.PairwiseDistance", "summary": "Computes the batchwise pairwise distance between vectors v1v_1v1\u200b\n\n, v2v_2v2\u200b\n\n using the p-norm:\n\n\u2225x\u2225p=(\u2211i=1n\u2223xi\u2223p)1/p.\\Vert x \\Vert _p = \\left( \\sum_{i=1}^n  \\vert x_i \\vert ^ p \\right) ^ {1/p}.\n\n\u2225x\u2225p\u200b=(i=1\u2211n\u200b\u2223xi\u200b\u2223p)1/p.\n\n\nParameters\n\np (real) \u2013 the norm degree", "description": "", "code-info": {"name": "torch.nn.PairwiseDistance", "parameters": [{"name": "p", "is_optional": true, "type": "others", "default_value": "2.0", "description": "(real) \u2013 the norm degree. Default: 2"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-06", "description": "(python:float, optional) \u2013 Small value to avoid division by zero.\nDefault: 1e-6"}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Determines whether or not to keep the vector dimension.\nDefault: False"}]}},
{"code": "torch.nn.L1Loss(size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.L1Loss", "summary": "Creates a criterion that measures the mean absolute error (MAE) between each element in\nthe input xxx\n\n and target yyy\n\n.\nThe unreduced (i.e", "description": "", "code-info": {"name": "torch.nn.L1Loss", "parameters": [{"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.MSELoss(size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.MSELoss", "summary": "Creates a criterion that measures the mean squared error (squared L2 norm) between\neach element in the input xxx\n\n and target yyy\n\n.\nThe unreduced (i.e", "description": "", "code-info": {"name": "torch.nn.MSELoss", "parameters": [{"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.CrossEntropyLoss(weight=None,size_average=None,ignore_index=-100,reduce=None,reduction='mean')", "id": "torch.nn.CrossEntropyLoss", "summary": "This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\nIt is useful when training a classification problem with C classes.\nIf provided, the optional argument weight should be a 1D Tensor\nassigning weight to each of the classes.\nThis is particularly useful when you have an unbalanced training set.\nThe input is expected to contain raw, unnormalized scores for each class.\ninput has to be a Tensor of size either (minibatch,C)(minibatch, C)(minibatch,C)\n\n or\n(minibatch,C,d1,d2,...,dK)(minibatch, C, d_1, d_2, ..., d_K)(minibatch,C,d1\u200b,d2\u200b,...,dK\u200b)\n\n\nwith K\u22651K \\geq 1K\u22651\n\n for the K-dimensional case (described later).\nThis criterion expects a class index in the range [0,C\u22121][0, C-1][0,C\u22121]\n\n as the\ntarget for each value of a 1D tensor of size minibatch; if ignore_index\nis specified, this criterion also accepts this class index (this index may not\nnecessarily be in the class range).\nThe loss can be described as:\n\nloss(x,class)=\u2212log\u2061(exp\u2061(x[class])\u2211jexp\u2061(x[j]))=\u2212x[class]+log\u2061(\u2211jexp\u2061(x[j]))\\text{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right)\n               = -x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)\n\nloss(x,class)=\u2212log(\u2211j\u200bexp(x[j])exp(x[class])\u200b)=\u2212x[class]+log(j\u2211\u200bexp(x[j]))\n\nor in the case of the weight argument being specified:\n\nloss(x,class)=weight[class](\u2212x[class]+log\u2061(\u2211jexp\u2061(x[j])))\\text{loss}(x, class) = weight[class] \\left(-x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)\\right)\n\nloss(x,class)=weight[class](\u2212x[class]+log(j\u2211\u200bexp(x[j])))\n\nThe losses are averaged across observations for each minibatch.\nCan also be used for higher dimension inputs, such as 2D images, by providing\nan input of size (minibatch,C,d1,d2,...,dK)(minibatch, C, d_1, d_2, ..., d_K)(minibatch,C,d1\u200b,d2\u200b,...,dK\u200b)\n\n with K\u22651K \\geq 1K\u22651\n\n,\nwhere KKK\n\n is the number of dimensions, and a target of appropriate shape\n(see below).\n\nParameters\n\nweight (Tensor, optional) \u2013 a manual rescaling weight given to each class.\nIf given, has to be a Tensor of size C\nsize_average (bool, optional) \u2013 Deprecated (see reduction)", "description": "", "code-info": {"name": "torch.nn.CrossEntropyLoss", "parameters": [{"name": "weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a manual rescaling weight given to each class.\nIf given, has to be a Tensor of size C"}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "ignore_index", "is_optional": true, "type": "int", "default_value": "-100", "description": "(python:int, optional) \u2013 Specifies a target value that is ignored\nand does not contribute to the input gradient. When size_average is\nTrue, the loss is averaged over non-ignored targets."}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.CTCLoss(blank=0,reduction='mean',zero_infinity=False)", "id": "torch.nn.CTCLoss", "summary": "The Connectionist Temporal Classification loss.\nCalculates loss between a continuous (unsegmented) time series and a target sequence", "description": "", "code-info": {"name": "torch.nn.CTCLoss", "parameters": [{"name": "blank", "is_optional": true, "type": "int", "default_value": "0", "description": "(python:int, optional) \u2013 blank label. Default 000\n\n."}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the output losses will be divided by the target lengths and\nthen the mean over the batch is taken. Default: 'mean'"}, {"name": "zero_infinity", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 Whether to zero infinite losses and the associated gradients.\nDefault: False\nInfinite losses mainly occur when the inputs are too short\nto be aligned to the targets."}]}},
{"code": "torch.nn.NLLLoss(weight=None,size_average=None,ignore_index=-100,reduce=None,reduction='mean')", "id": "torch.nn.NLLLoss", "summary": "The negative log likelihood loss", "description": "", "code-info": {"name": "torch.nn.NLLLoss", "parameters": [{"name": "weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a manual rescaling weight given to each\nclass. If given, it has to be a Tensor of size C. Otherwise, it is\ntreated as if having all ones."}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "ignore_index", "is_optional": true, "type": "int", "default_value": "-100", "description": "(python:int, optional) \u2013 Specifies a target value that is ignored\nand does not contribute to the input gradient. When\nsize_average is True, the loss is averaged over\nnon-ignored targets."}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.PoissonNLLLoss(log_input=True,full=False,size_average=None,eps=1e-08,reduce=None,reduction='mean')", "id": "torch.nn.PoissonNLLLoss", "summary": "Negative log likelihood loss with Poisson distribution of target.\nThe loss can be described as:\n\ntarget\u223cPoisson(input)loss(input,target)=input\u2212target\u2217log\u2061(input)+log\u2061(target!)\\text{target} \\sim \\mathrm{Poisson}(\\text{input})\n\n\\text{loss}(\\text{input}, \\text{target}) = \\text{input} - \\text{target} * \\log(\\text{input})\n                            + \\log(\\text{target!})target\u223cPoisson(input)loss(input,target)=input\u2212target\u2217log(input)+log(target!)\n\nThe last term can be omitted or approximated with Stirling formula", "description": "", "code-info": {"name": "torch.nn.PoissonNLLLoss", "parameters": [{"name": "log_input", "is_optional": true, "type": "bool", "default_value": "True", "description": "(bool, optional) \u2013 if True the loss is computed as\nexp\u2061(input)\u2212target\u2217input\\exp(\\text{input}) - \\text{target}*\\text{input}exp(input)\u2212target\u2217input\n\n, if False the loss is\ninput\u2212target\u2217log\u2061(input+eps)\\text{input} - \\text{target}*\\log(\\text{input}+\\text{eps})input\u2212target\u2217log(input+eps)\n\n."}, {"name": "full", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 whether to compute full loss, i. e. to add the\nStirling approximation term\n\ntarget\u2217log\u2061(target)\u2212target+0.5\u2217log\u2061(2\u03c0target).\\text{target}*\\log(\\text{target}) - \\text{target} + 0.5 * \\log(2\\pi\\text{target}).\n\ntarget\u2217log(target)\u2212target+0.5\u2217log(2\u03c0target).\n\n"}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-08", "description": "(python:float, optional) \u2013 Small value to avoid evaluation of log\u2061(0)\\log(0)log(0)\n\n when\nlog_input = False. Default: 1e-8"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.KLDivLoss(size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.KLDivLoss", "summary": "The Kullback-Leibler divergence Loss\nKL divergence is a useful distance measure for continuous distributions\nand is often useful when performing direct regression over the space of\n(discretely sampled) continuous output distributions.\nAs with NLLLoss, the input given is expected to contain\nlog-probabilities and is not restricted to a 2D Tensor.\nThe targets are given as probabilities (i.e", "description": "", "code-info": {"name": "torch.nn.KLDivLoss", "parameters": [{"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'batchmean' | 'sum' | 'mean'.\n'none': no reduction will be applied.\n'batchmean': the sum of the output will be divided by batchsize.\n'sum': the output will be summed.\n'mean': the output will be divided by the number of elements in the output.\nDefault: 'mean'"}]}},
{"code": "torch.nn.BCELoss(weight=None,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.BCELoss", "summary": "Creates a criterion that measures the Binary Cross Entropy\nbetween the target and the output:\nThe unreduced (i.e", "description": "", "code-info": {"name": "torch.nn.BCELoss", "parameters": [{"name": "weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a manual rescaling weight given to the loss\nof each batch element. If given, has to be a Tensor of size nbatch."}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.BCEWithLogitsLoss(weight=None,size_average=None,reduce=None,reduction='mean',pos_weight=None)", "id": "torch.nn.BCEWithLogitsLoss", "summary": "This loss combines a Sigmoid layer and the BCELoss in one single\nclass", "description": "", "code-info": {"name": "torch.nn.BCEWithLogitsLoss", "parameters": [{"name": "weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a manual rescaling weight given to the loss\nof each batch element. If given, has to be a Tensor of size nbatch."}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, {"name": "pos_weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a weight of positive examples.\nMust be a vector with length equal to the number of classes."}]}},
{"code": "torch.nn.MarginRankingLoss(margin=0.0,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.MarginRankingLoss", "summary": "Creates a criterion that measures the loss given\ninputs x1x1x1\n\n, x2x2x2\n\n, two 1D mini-batch Tensors,\nand a label 1D mini-batch tensor yyy\n\n (containing 1 or -1).\nIf y=1y = 1y=1\n\n then it assumed the first input should be ranked higher\n(have a larger value) than the second input, and vice-versa for y=\u22121y = -1y=\u22121\n\n.\nThe loss function for each sample in the mini-batch is:\n\nloss(x,y)=max\u2061(0,\u2212y\u2217(x1\u2212x2)+margin)\\text{loss}(x, y) = \\max(0, -y * (x1 - x2) + \\text{margin})\n\nloss(x,y)=max(0,\u2212y\u2217(x1\u2212x2)+margin)\n\n\nParameters\n\nmargin (python:float, optional) \u2013 Has a default value of 000\n\n.\nsize_average (bool, optional) \u2013 Deprecated (see reduction)", "description": "", "code-info": {"name": "torch.nn.MarginRankingLoss", "parameters": [{"name": "margin", "is_optional": true, "type": "float", "default_value": "0.0", "description": "(python:float, optional) \u2013 Has a default value of 000\n\n."}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.HingeEmbeddingLoss(margin=1.0,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.HingeEmbeddingLoss", "summary": "Measures the loss given an input tensor xxx\n\n and a labels tensor yyy\n\n\n(containing 1 or -1).\nThis is usually used for measuring whether two inputs are similar or\ndissimilar, e.g", "description": "", "code-info": {"name": "torch.nn.HingeEmbeddingLoss", "parameters": [{"name": "margin", "is_optional": true, "type": "float", "default_value": "1.0", "description": "(python:float, optional) \u2013 Has a default value of 1."}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.MultiLabelMarginLoss(size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.MultiLabelMarginLoss", "summary": "Creates a criterion that optimizes a multi-class multi-classification\nhinge loss (margin-based loss) between input xxx\n\n (a 2D mini-batch Tensor)\nand output yyy\n\n (which is a 2D Tensor of target class indices).\nFor each sample in the mini-batch:\n\nloss(x,y)=\u2211ijmax\u2061(0,1\u2212(x[y[j]]\u2212x[i]))x.size(0)\\text{loss}(x, y) = \\sum_{ij}\\frac{\\max(0, 1 - (x[y[j]] - x[i]))}{\\text{x.size}(0)}\n\nloss(x,y)=ij\u2211\u200bx.size(0)max(0,1\u2212(x[y[j]]\u2212x[i]))\u200b\n\nwhere x\u2208{0,\u2005\u200a\u22ef\u2009,\u2005\u200ax.size(0)\u22121}x \\in \\left\\{0, \\; \\cdots , \\; \\text{x.size}(0) - 1\\right\\}x\u2208{0,\u22ef,x.size(0)\u22121}\n\n, y\u2208{0,\u2005\u200a\u22ef\u2009,\u2005\u200ay.size(0)\u22121}y \\in \\left\\{0, \\; \\cdots , \\; \\text{y.size}(0) - 1\\right\\}y\u2208{0,\u22ef,y.size(0)\u22121}\n\n, 0\u2264y[j]\u2264x.size(0)\u221210 \\leq y[j] \\leq \\text{x.size}(0)-10\u2264y[j]\u2264x.size(0)\u22121\n\n, and i\u2260y[j]i \\neq y[j]i\ue020\u200b=y[j]\n\n for all iii\n\n and jjj\n\n.\nyyy\n\n and xxx\n\n must have the same size.\nThe criterion only considers a contiguous block of non-negative targets that\nstarts at the front.\nThis allows for different samples to have variable amounts of target classes.\n\nParameters\n\nsize_average (bool, optional) \u2013 Deprecated (see reduction)", "description": "", "code-info": {"name": "torch.nn.MultiLabelMarginLoss", "parameters": [{"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.SmoothL1Loss(size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.SmoothL1Loss", "summary": "Creates a criterion that uses a squared term if the absolute\nelement-wise error falls below 1 and an L1 term otherwise.\nIt is less sensitive to outliers than the MSELoss and in some cases\nprevents exploding gradients (e.g", "description": "", "code-info": {"name": "torch.nn.SmoothL1Loss", "parameters": [{"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.SoftMarginLoss(size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.SoftMarginLoss", "summary": "Creates a criterion that optimizes a two-class classification\nlogistic loss between input tensor xxx\n\n and target tensor yyy\n\n\n(containing 1 or -1).\n\nloss(x,y)=\u2211ilog\u2061(1+exp\u2061(\u2212y[i]\u2217x[i]))x.nelement()\\text{loss}(x, y) = \\sum_i \\frac{\\log(1 + \\exp(-y[i]*x[i]))}{\\text{x.nelement}()}\n\nloss(x,y)=i\u2211\u200bx.nelement()log(1+exp(\u2212y[i]\u2217x[i]))\u200b\n\n\nParameters\n\nsize_average (bool, optional) \u2013 Deprecated (see reduction)", "description": "", "code-info": {"name": "torch.nn.SoftMarginLoss", "parameters": [{"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.MultiLabelSoftMarginLoss(weight=None,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.MultiLabelSoftMarginLoss", "summary": "Creates a criterion that optimizes a multi-label one-versus-all\nloss based on max-entropy, between input xxx\n\n and target yyy\n\n of size\n(N,C)(N, C)(N,C)\n\n.\nFor each sample in the minibatch:\n\nloss(x,y)=\u22121C\u2217\u2211iy[i]\u2217log\u2061((1+exp\u2061(\u2212x[i]))\u22121)+(1\u2212y[i])\u2217log\u2061(exp\u2061(\u2212x[i])(1+exp\u2061(\u2212x[i])))loss(x, y) = - \\frac{1}{C} * \\sum_i y[i] * \\log((1 + \\exp(-x[i]))^{-1})\n                 + (1-y[i]) * \\log\\left(\\frac{\\exp(-x[i])}{(1 + \\exp(-x[i]))}\\right)\n\nloss(x,y)=\u2212C1\u200b\u2217i\u2211\u200by[i]\u2217log((1+exp(\u2212x[i]))\u22121)+(1\u2212y[i])\u2217log((1+exp(\u2212x[i]))exp(\u2212x[i])\u200b)\n\nwhere i\u2208{0,\u2005\u200a\u22ef\u2009,\u2005\u200ax.nElement()\u22121}i \\in \\left\\{0, \\; \\cdots , \\; \\text{x.nElement}() - 1\\right\\}i\u2208{0,\u22ef,x.nElement()\u22121}\n\n,\ny[i]\u2208{0,\u2005\u200a1}y[i] \\in \\left\\{0, \\; 1\\right\\}y[i]\u2208{0,1}\n\n.\n\nParameters\n\nweight (Tensor, optional) \u2013 a manual rescaling weight given to each\nclass", "description": "", "code-info": {"name": "torch.nn.MultiLabelSoftMarginLoss", "parameters": [{"name": "weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a manual rescaling weight given to each\nclass. If given, it has to be a Tensor of size C. Otherwise, it is\ntreated as if having all ones."}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.CosineEmbeddingLoss(margin=0.0,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.CosineEmbeddingLoss", "summary": "Creates a criterion that measures the loss given input tensors\nx1x_1x1\u200b\n\n, x2x_2x2\u200b\n\n and a Tensor label yyy\n\n with values 1 or -1.\nThis is used for measuring whether two inputs are similar or dissimilar,\nusing the cosine distance, and is typically used for learning nonlinear\nembeddings or semi-supervised learning.\nThe loss function for each sample is:\n\nloss(x,y)={1\u2212cos\u2061(x1,x2),if\u00a0y=1max\u2061(0,cos\u2061(x1,x2)\u2212margin),if\u00a0y=\u22121\\text{loss}(x, y) =\n\\begin{cases}\n1 - \\cos(x_1, x_2), &amp; \\text{if } y = 1 \\\\\n\\max(0, \\cos(x_1, x_2) - \\text{margin}), &amp; \\text{if } y = -1\n\\end{cases}\n\nloss(x,y)={1\u2212cos(x1\u200b,x2\u200b),max(0,cos(x1\u200b,x2\u200b)\u2212margin),\u200bif\u00a0y=1if\u00a0y=\u22121\u200b\n\n\nParameters\n\nmargin (python:float, optional) \u2013 Should be a number from \u22121-1\u22121\n\n to 111\n\n,\n000\n\n to 0.50.50.5\n\n is suggested", "description": "", "code-info": {"name": "torch.nn.CosineEmbeddingLoss", "parameters": [{"name": "margin", "is_optional": true, "type": "float", "default_value": "0.0", "description": "(python:float, optional) \u2013 Should be a number from \u22121-1\u22121\n\n to 111\n\n,\n000\n\n to 0.50.50.5\n\n is suggested. If margin is missing, the\ndefault value is 000\n\n."}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.MultiMarginLoss(p=1,margin=1.0,weight=None,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.MultiMarginLoss", "summary": "Creates a criterion that optimizes a multi-class classification hinge\nloss (margin-based loss) between input xxx\n\n (a 2D mini-batch Tensor) and\noutput yyy\n\n (which is a 1D tensor of target class indices,\n0\u2264y\u2264x.size(1)\u221210 \\leq y \\leq \\text{x.size}(1)-10\u2264y\u2264x.size(1)\u22121\n\n):\nFor each mini-batch sample, the loss in terms of the 1D input xxx\n\n and scalar\noutput yyy\n\n is:\n\nloss(x,y)=\u2211imax\u2061(0,margin\u2212x[y]+x[i]))px.size(0)\\text{loss}(x, y) = \\frac{\\sum_i \\max(0, \\text{margin} - x[y] + x[i]))^p}{\\text{x.size}(0)}\n\nloss(x,y)=x.size(0)\u2211i\u200bmax(0,margin\u2212x[y]+x[i]))p\u200b\n\nwhere x\u2208{0,\u2005\u200a\u22ef\u2009,\u2005\u200ax.size(0)\u22121}x \\in \\left\\{0, \\; \\cdots , \\; \\text{x.size}(0) - 1\\right\\}x\u2208{0,\u22ef,x.size(0)\u22121}\n\n\nand i\u2260yi \\neq yi\ue020\u200b=y\n\n.\nOptionally, you can give non-equal weighting on the classes by passing\na 1D weight tensor into the constructor.\nThe loss function then becomes:\n\nloss(x,y)=\u2211imax\u2061(0,w[y]\u2217(margin\u2212x[y]+x[i]))p)x.size(0)\\text{loss}(x, y) = \\frac{\\sum_i \\max(0, w[y] * (\\text{margin} - x[y] + x[i]))^p)}{\\text{x.size}(0)}\n\nloss(x,y)=x.size(0)\u2211i\u200bmax(0,w[y]\u2217(margin\u2212x[y]+x[i]))p)\u200b\n\n\nParameters\n\np (python:int, optional) \u2013 Has a default value of 111\n\n", "description": "", "code-info": {"name": "torch.nn.MultiMarginLoss", "parameters": [{"name": "p", "is_optional": true, "type": "int", "default_value": "1", "description": "(python:int, optional) \u2013 Has a default value of 111\n\n. 111\n\n and 222\n\n\nare the only supported values."}, {"name": "margin", "is_optional": true, "type": "float", "default_value": "1.0", "description": "(python:float, optional) \u2013 Has a default value of 111\n\n."}, {"name": "weight", "is_optional": true, "type": "tensor", "default_value": "None", "description": "(Tensor, optional) \u2013 a manual rescaling weight given to each\nclass. If given, it has to be a Tensor of size C. Otherwise, it is\ntreated as if having all ones."}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.TripletMarginLoss(margin=1.0,p=2.0,eps=1e-06,swap=False,size_average=None,reduce=None,reduction='mean')", "id": "torch.nn.TripletMarginLoss", "summary": "Creates a criterion that measures the triplet loss given an input\ntensors x1x1x1\n\n, x2x2x2\n\n, x3x3x3\n\n and a margin with a value greater than 000\n\n.\nThis is used for measuring a relative similarity between samples", "description": "", "code-info": {"name": "torch.nn.TripletMarginLoss", "parameters": [{"name": "margin", "is_optional": true, "type": "float", "default_value": "1.0", "description": "(python:float, optional) \u2013 Default: 111\n\n."}, {"name": "p", "is_optional": true, "type": "others", "default_value": "2.0", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-06", "description": ""}, {"name": "swap", "is_optional": true, "type": "bool", "default_value": "False", "description": "(bool, optional) \u2013 The distance swap is described in detail in the paper\nLearning shallow convolutional feature descriptors with triplet losses by\nV. Balntas, E. Riba et al. Default: False."}, {"name": "size_average", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True"}, {"name": "reduce", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": "(string, optional) \u2013 Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}]}},
{"code": "torch.nn.PixelShuffle(upscale_factor)", "id": "torch.nn.PixelShuffle", "summary": "Rearranges elements in a tensor of shape (\u2217,C\u00d7r2,H,W)(*, C \\times r^2, H, W)(\u2217,C\u00d7r2,H,W)\n\n\nto a tensor of shape (\u2217,C,H\u00d7r,W\u00d7r)(*, C, H \\times r, W \\times r)(\u2217,C,H\u00d7r,W\u00d7r)\n\n.\nThis is useful for implementing efficient sub-pixel convolution\nwith a stride of 1/r1/r1/r\n\n.\nLook at the paper:\nReal-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network\nby Shi et", "description": "", "code-info": {"name": "torch.nn.PixelShuffle", "parameters": [{"name": "upscale_factor", "is_optional": false, "type": "int", "description": "(python:int) \u2013 factor to increase spatial resolution by"}]}},
{"code": "torch.nn.Upsample(size=None,scale_factor=None,mode='nearest',align_corners=None)", "id": "torch.nn.Upsample", "summary": "Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.\nThe input data is assumed to be of the form\nminibatch x channels x [optional depth] x [optional height] x width.\nHence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor.\nThe algorithms available for upsampling are nearest neighbor and linear,\nbilinear, bicubic and trilinear for 3D, 4D and 5D input Tensor,\nrespectively.\nOne can either give a scale_factor or the target output size to\ncalculate the output size", "description": "", "code-info": {"name": "torch.nn.Upsample", "parameters": [{"name": "size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int] or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int], optional) \u2013 output spatial sizes"}, {"name": "scale_factor", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float or Tuple[python:float] or Tuple[python:float, python:float] or Tuple[python:float, python:float, python:float], optional) \u2013 multiplier for spatial size. Has to match input size if it is a tuple."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'nearest'", "description": "(str, optional) \u2013 the upsampling algorithm: one of 'nearest',\n'linear', 'bilinear', 'bicubic' and 'trilinear'.\nDefault: 'nearest'"}, {"name": "align_corners", "is_optional": true, "type": "bool", "default_value": "None", "description": "(bool, optional) \u2013 if True, the corner pixels of the input\nand output tensors are aligned, and thus preserving the values at\nthose pixels. This only has effect when mode is\n'linear', 'bilinear', or 'trilinear'. Default: False"}]}},
{"code": "torch.nn.UpsamplingNearest2d(size=None,scale_factor=None)", "id": "torch.nn.UpsamplingNearest2d", "summary": "Applies a 2D nearest neighbor upsampling to an input signal composed of several input\nchannels.\nTo specify the scale, it takes either the size or the scale_factor\nas it\u2019s constructor argument.\nWhen size is given, it is the output size of the image (h, w).\n\nParameters\n\nsize (python:int or Tuple[python:int, python:int], optional) \u2013 output spatial sizes\nscale_factor (python:float or Tuple[python:float, python:float], optional) \u2013 multiplier for\nspatial size.\n\n\n\n\nWarning\nThis class is deprecated in favor of interpolate().\n\n\nShape:\nInput: (N,C,Hin,Win)(N, C, H_{in}, W_{in})(N,C,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Hout,Wout)(N, C, H_{out}, W_{out})(N,C,Hout\u200b,Wout\u200b)\n\n where\n\n\n\n\nHout=\u230aHin\u00d7scale_factor\u230bH_{out} = \\left\\lfloor H_{in} \\times \\text{scale\\_factor} \\right\\rfloor\n\nHout\u200b=\u230aHin\u200b\u00d7scale_factor\u230b\n\n\nWout=\u230aWin\u00d7scale_factor\u230bW_{out} = \\left\\lfloor W_{in} \\times \\text{scale\\_factor} \\right\\rfloor\n\nWout\u200b=\u230aWin\u200b\u00d7scale_factor\u230b\n\nExamples:\n&gt;&gt;&gt; input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)\n&gt;&gt;&gt; input\ntensor([[[[ 1.,  2.],\n          [ 3.,  4.]]]])\n\n&gt;&gt;&gt; m = nn.UpsamplingNearest2d(scale_factor=2)\n&gt;&gt;&gt; m(input)\ntensor([[[[ 1.,  1.,  2.,  2.],\n          [ 1.,  1.,  2.,  2.],\n          [ 3.,  3.,  4.,  4.],\n          [ 3.,  3.,  4.,  4.]]]])\n\n\n", "description": "", "code-info": {"name": "torch.nn.UpsamplingNearest2d", "parameters": [{"name": "size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int, python:int], optional) \u2013 output spatial sizes"}, {"name": "scale_factor", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float or Tuple[python:float, python:float], optional) \u2013 multiplier for\nspatial size."}]}},
{"code": "torch.nn.UpsamplingBilinear2d(size=None,scale_factor=None)", "id": "torch.nn.UpsamplingBilinear2d", "summary": "Applies a 2D bilinear upsampling to an input signal composed of several input\nchannels.\nTo specify the scale, it takes either the size or the scale_factor\nas it\u2019s constructor argument.\nWhen size is given, it is the output size of the image (h, w).\n\nParameters\n\nsize (python:int or Tuple[python:int, python:int], optional) \u2013 output spatial sizes\nscale_factor (python:float or Tuple[python:float, python:float], optional) \u2013 multiplier for\nspatial size.\n\n\n\n\nWarning\nThis class is deprecated in favor of interpolate()", "description": "", "code-info": {"name": "torch.nn.UpsamplingBilinear2d", "parameters": [{"name": "size", "is_optional": true, "type": "int", "default_value": "None", "description": "(python:int or Tuple[python:int, python:int], optional) \u2013 output spatial sizes"}, {"name": "scale_factor", "is_optional": true, "type": "float", "default_value": "None", "description": "(python:float or Tuple[python:float, python:float], optional) \u2013 multiplier for\nspatial size."}]}},
{"code": "torch.nn.DataParallel(module,device_ids=None,output_device=None,dim=0)", "id": "torch.nn.DataParallel", "summary": "Implements data parallelism at the module level.\nThis container parallelizes the application of the given module by\nsplitting the input across the specified devices by chunking in the batch\ndimension (other objects will be copied once per device)", "description": "", "code-info": {"name": "torch.nn.DataParallel", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(Module) \u2013 module to be parallelized"}, {"name": "device_ids", "is_optional": true, "type": "int", "default_value": "None", "description": "(list of python:int or torch.device) \u2013 CUDA devices (default: all devices)"}, {"name": "output_device", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"code": "torch.nn.parallel.DistributedDataParallel(module,device_ids=None,output_device=None,dim=0,broadcast_buffers=True,process_group=None,bucket_cap_mb=25,find_unused_parameters=False,check_reduction=False)", "id": "torch.nn.parallel.DistributedDataParallel", "summary": "Implements distributed data parallelism that is based on\ntorch.distributed package at the module level.\nThis container parallelizes the application of the given module by\nsplitting the input across the specified devices by chunking in the batch\ndimension", "description": "", "code-info": {"name": "torch.nn.parallel.DistributedDataParallel", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": "(Module) \u2013 module to be parallelized"}, {"name": "device_ids", "is_optional": true, "type": "int", "default_value": "None", "description": "(list of python:int or torch.device) \u2013 CUDA devices. This should\nonly be provided when the input module resides on a single\nCUDA device. For single-device modules, the i``th\n:attr:`module` replica is placed on ``device_ids[i]. For\nmulti-device modules and CPU modules, device_ids must be None\nor an empty list, and input data for the forward pass must be\nplaced on the correct device. (default: all devices for\nsingle-device modules)"}, {"name": "output_device", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "broadcast_buffers", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "process_group", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "bucket_cap_mb", "is_optional": true, "type": "int", "default_value": "25", "description": ""}, {"name": "find_unused_parameters", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "check_reduction", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"code": "torch.nn.utils.prune.PruningContainer(*args)", "id": "torch.nn.utils.prune.PruningContainer", "summary": "Container holding a sequence of pruning methods for iterative pruning.\nKeeps track of the order in which pruning methods are applied and handles\ncombining successive pruning calls.\nAccepts as argument an instance of a BasePruningMethod or an iterable of\nthem.\n\n\nadd_pruning_method(method) \u00b6\nAdds a child pruning method to the container.\n\nParameters\nmethod (subclass of BasePruningMethod) \u2013 child pruning method\nto be added to the container.\n\n\n\n\n\n\nclassmethod apply(module, name, *args, **kwargs)\u00b6\nAdds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\nargs \u2013 arguments passed on to a subclass of\nBasePruningMethod\nkwargs \u2013 keyword arguments passed on to a subclass of a\nBasePruningMethod\n\n\n\n\n\n\n\napply_mask(module)\u00b6\nSimply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\n\nParameters\nmodule (nn.Module) \u2013 module containing the tensor to prune\n\nReturns\npruned version of the input tensor\n\nReturn type\npruned_tensor (torch.Tensor)\n\n\n\n\n\n\ncompute_mask(t, default_mask) \u00b6\nApplies the latest method by computing the new partial masks\nand returning its combination with the default_mask.\nThe new partial mask should be computed on the entries or channels\nthat were not zeroed out by the default_mask.\nWhich portions of the tensor t the new mask will be calculated from\ndepends on the PRUNING_TYPE (handled by the type handler):\n\n\nfor \u2018unstructured\u2019, the mask will be computed from the raveled\n\nlist of nonmasked entries;\n\nfor \u2018structured\u2019, the mask will be computed from the nonmasked\n\nchannels in the tensor;\n\nfor \u2018global\u2019, the mask will be computed across all entries.\n\n\n\nParameters\n\nt (torch.Tensor) \u2013 tensor representing the parameter to prune\n(of same dimensions as default_mask).\ndefault_mask (torch.Tensor) \u2013 mask from previous pruning iteration.\n\n\nReturns\nnew mask that combines the effects\nof the default_mask and the new mask from the current\npruning method (of same dimensions as default_mask and\nt).\n\nReturn type\nmask (torch.Tensor)\n\n\n\n\n\n\nprune(t, default_mask=None)\u00b6\nComputes and returns a pruned version of input tensor t\naccording to the pruning rule specified in compute_mask().\n\nParameters\n\nt (torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask).\ndefault_mask (torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any", "description": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.utils.prune.RandomUnstructured(amount)", "id": "torch.nn.utils.prune.RandomUnstructured", "summary": "Prune (currently unpruned) units in a tensor at random.\n\nParameters\n\nname (str) \u2013 parameter name within module on which pruning\nwill act.\namount (python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.RandomUnstructured", "parameters": [{"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}]}},
{"code": "torch.nn.utils.prune.L1Unstructured(amount)", "id": "torch.nn.utils.prune.L1Unstructured", "summary": "Prune (currently unpruned) units in a tensor by zeroing out the ones\nwith the lowest L1-norm.\n\nParameters\namount (python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.L1Unstructured", "parameters": [{"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}]}},
{"code": "torch.nn.utils.prune.RandomStructured(amount,dim=-1)", "id": "torch.nn.utils.prune.RandomStructured", "summary": "Prune entire (currently unpruned) channels in a tensor at random.\n\nParameters\n\namount (python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured", "parameters": [{"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int, optional) \u2013 index of the dim along which we define\nchannels to prune. Default: -1."}]}},
{"code": "torch.nn.utils.prune.LnStructured(amount,n,dim=-1)", "id": "torch.nn.utils.prune.LnStructured", "summary": "Prune entire (currently unpruned) channels in a tensor based on their\nLn-norm.\n\nParameters\n\namount (python:int or python:float) \u2013 quantity of channels to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune", "description": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured", "parameters": [{"name": "amount", "is_optional": false, "type": "int", "description": "(python:int or python:float) \u2013 quantity of channels to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}, {"name": "n", "is_optional": false, "type": "int", "description": "(python:int, python:float, inf, -inf, 'fro', 'nuc') \u2013 See documentation of valid\nentries for argument p in torch.norm()."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": "(python:int, optional) \u2013 index of the dim along which we define\nchannels to prune. Default: -1."}]}},
{"code": "torch.nn.utils.prune.CustomFromMask(mask)", "id": "torch.nn.utils.prune.CustomFromMask", "summary": "\n\nclassmethod apply(module, name, mask) \u00b6\nAdds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\n\nParameters\n\nmodule (nn.Module) \u2013 module containing the tensor to prune\nname (str) \u2013 parameter name within module on which pruning\nwill act.\n\n\n\n\n\n\n\napply_mask(module)\u00b6\nSimply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\n\nParameters\nmodule (nn.Module) \u2013 module containing the tensor to prune\n\nReturns\npruned version of the input tensor\n\nReturn type\npruned_tensor (torch.Tensor)\n\n\n\n\n\n\nprune(t, default_mask=None)\u00b6\nComputes and returns a pruned version of input tensor t\naccording to the pruning rule specified in compute_mask().\n\nParameters\n\nt (torch.Tensor) \u2013 tensor to prune (of same dimensions as\ndefault_mask).\ndefault_mask (torch.Tensor, optional) \u2013 mask from previous pruning\niteration, if any", "description": "", "code-info": {"name": "torch.nn.utils.prune.CustomFromMask", "parameters": [{"name": "mask", "is_optional": false, "type": "others", "description": ""}]}},
{"code": "torch.nn.Flatten(start_dim=1,end_dim=-1)", "id": "torch.nn.Flatten", "summary": "Flattens a contiguous range of dims into a tensor", "description": "", "code-info": {"name": "torch.nn.Flatten", "parameters": [{"name": "start_dim", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "end_dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}]}}]
