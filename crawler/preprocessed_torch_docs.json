[{"id": "torchvision.get_image_backend", "type": "function", "code": "torchvision.get_image_backend()", "example": "NA", "summary": "Gets the name of the package used to load images ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.get_image_backend", "parameters": []}},
{"id": "torchvision.set_image_backend", "type": "function", "code": "torchvision.set_image_backend(backend)", "example": "NA", "summary": "Specifies the package used to load images", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.set_image_backend", "parameters": [{"name": "backend", "is_optional": false, "type": "string", "description": " Name of the image backend. one of {\u2018PIL\u2019, \u2018accimage\u2019}.The accimage package uses the Intel IPP library. It isgenerally faster than PIL, but does not support as many operations."}]}},
{"id": "torchvision.set_video_backend", "type": "function", "code": "torchvision.set_video_backend(backend)", "example": "NA", "summary": "Specifies the package used to decode videos", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.set_video_backend", "parameters": [{"name": "backend", "is_optional": false, "type": "string", "description": " Name of the video backend. one of {\u2018pyav\u2019, \u2018video_reader\u2019}.The pyav package uses the 3rd party PyAv library. It is a Pythonicbinding for the FFmpeg libraries.The video_reader package includes a native c++ implementation ontop of FFMPEG libraries, and a python API of TorchScript custom operator.It is generally decoding faster than pyav, but perhaps is less robust."}]}},
{"id": "torchvision.ops.nms", "type": "function", "code": "torchvision.ops.nms(boxes,scores,iou_threshold)", "example": "NA", "summary": "Performs non-maximum suppression (NMS) on the boxes according to their intersection-over-union (IoU)", "returns": "keep \u2013 int64 tensor with the indicesof the elements that have been keptby NMS, sorted in decreasing order of scores", "shape": "NA", "code-info": {"name": "torchvision.ops.nms", "parameters": [{"name": "boxes", "is_optional": false, "type": "Tensor[N, 4]", "description": " boxes to perform NMS on. Theyare expected to be in (x1, y1, x2, y2 format"}, {"name": "scores", "is_optional": false, "type": "Tensor[N]", "description": " scores for each one of the boxes"}, {"name": "iou_threshold", "is_optional": false, "type": "float", "description": " discards all overlappingboxes with IoU &gt; iou_threshold"}]}},
{"id": "torchvision.ops.roi_align", "type": "function", "code": "torchvision.ops.roi_align(input,boxes,output_size,spatial_scale=1.0,sampling_ratio=-1)", "example": "NA", "summary": "Performs Region of Interest (RoI) Align operator described in Mask R-CNN  Parameters  input (Tensor[N, C, H, W]) \u2013 input tensor boxes (Tensor[K, 5] or List[Tensor[L, 4]]) \u2013 the box coordinates in (x1, y1, x2, y2) format where the regions will be taken from", "returns": "output (Tensor[K, C, output_size[0], output_size[1]])", "shape": "NA", "code-info": {"name": "torchvision.ops.roi_align", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor[N, C, H, W]", "description": " input tensor"}, {"name": "boxes", "is_optional": false, "type": "tensor", "description": " the box coordinates in (x1, y1, x2, y2format where the regions will be taken from. If a single Tensor is passed,then the first column should contain the batch index. If a list of Tensorsis passed, then each Tensor will correspond to the boxes for an element iin a batch"}, {"name": "output_size", "is_optional": false, "type": "int or Tuple[int, int]", "description": " the size of the output after the croppingis performed, as (height, width"}, {"name": "spatial_scale", "is_optional": true, "type": "float", "default_value": "1.0", "description": " a scaling factor that maps the input coordinates tothe box coordinates. Default"}, {"name": "sampling_ratio", "is_optional": true, "type": "int", "default_value": "-1", "description": " number of sampling points in the interpolation gridused to compute the output value of each pooled output bin. If &gt; 0,then exactly sampling_ratio x sampling_ratio grid points are used. If&lt;= 0, then an adaptive number of grid points are used (computed asceil(roi_width / pooled_w, and likewise for height. Default"}]}},
{"id": "torchvision.ops.roi_pool", "type": "function", "code": "torchvision.ops.roi_pool(input,boxes,output_size,spatial_scale=1.0)", "example": "NA", "summary": "Performs Region of Interest (RoI) Pool operator described in Fast R-CNN  Parameters  input (Tensor[N, C, H, W]) \u2013 input tensor boxes (Tensor[K, 5] or List[Tensor[L, 4]]) \u2013 the box coordinates in (x1, y1, x2, y2) format where the regions will be taken from", "returns": "output (Tensor[K, C, output_size[0], output_size[1]])", "shape": "NA", "code-info": {"name": "torchvision.ops.roi_pool", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor[N, C, H, W]", "description": " input tensor"}, {"name": "boxes", "is_optional": false, "type": "tensor", "description": " the box coordinates in (x1, y1, x2, y2format where the regions will be taken from. If a single Tensor is passed,then the first column should contain the batch index. If a list of Tensorsis passed, then each Tensor will correspond to the boxes for an element iin a batch"}, {"name": "output_size", "is_optional": false, "type": "int or Tuple[int, int]", "description": " the size of the output after the croppingis performed, as (height, width"}, {"name": "spatial_scale", "is_optional": true, "type": "float", "default_value": "1.0", "description": " a scaling factor that maps the input coordinates tothe box coordinates. Default"}]}},
{"id": "torchvision.ops.RoIAlign", "type": "class", "code": "torchvision.ops.RoIAlign(output_size,spatial_scale,sampling_ratio)", "example": "NA", "summary": "See roi_align ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.ops.RoIAlign", "parameters": [{"name": "output_size", "is_optional": false, "type": "others", "description": ""}, {"name": "spatial_scale", "is_optional": false, "type": "others", "description": ""}, {"name": "sampling_ratio", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.ops.RoIPool", "type": "class", "code": "torchvision.ops.RoIPool(output_size,spatial_scale)", "example": "NA", "summary": "See roi_pool ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.ops.RoIPool", "parameters": [{"name": "output_size", "is_optional": false, "type": "others", "description": ""}, {"name": "spatial_scale", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.utils.make_grid", "type": "function", "code": "torchvision.utils.make_grid(tensor,nrow=8,padding=2,normalize=False,range=None,scale_each=False,pad_value=0)", "example": "NA", "summary": "Make a grid of images", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.utils.make_grid", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor or list", "description": " 4D mini-batch Tensor of shape (B x C x H x Wor a list of images all of the same size."}, {"name": "nrow", "is_optional": true, "type": "int", "default_value": "8", "description": " Number of images displayed in each row of the grid.The final grid size is (B / nrow, nrow. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "2", "description": " amount of padding. Default"}, {"name": "normalize", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, shift the image to the range (0, 1,by the min and max values specified by range. Default"}, {"name": "range", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " tuple (min, max where min and max are numbers,then these numbers are used to normalize the image. By default, min and maxare computed from the tensor."}, {"name": "scale_each", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, scale each image in the batch ofimages separately rather than the (min, max over all images. Default"}, {"name": "pad_value", "is_optional": true, "type": "int", "default_value": "0", "description": " Value for the padded pixels. Default"}]}},
{"id": "torchvision.utils.save_image", "type": "function", "code": "torchvision.utils.save_image(tensor,fp,nrow=8,padding=2,normalize=False,range=None,scale_each=False,pad_value=0,format=None)", "example": "NA", "summary": "Save a given Tensor into an image file", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.utils.save_image", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor or list", "description": " Image to be saved. If given a mini-batch tensor,saves the tensor as a grid of images by calling make_grid."}, {"name": "fp", "is_optional": false, "type": "fp", "description": ""}, {"name": "nrow", "is_optional": true, "type": "int", "default_value": "8", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "2", "description": ""}, {"name": "normalize", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "range", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "scale_each", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "pad_value", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "format", "is_optional": true, "type": "Optional", "default_value": "None", "description": " If omitted, the format to use is determined from the filename extension.If a file object was used instead of a filename, this parameter should always be used."}]}},
{"id": "torchvision.datasets.CocoCaptions.__getitem__", "type": "method", "code": "torchvision.datasets.CocoCaptions.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns Tuple (image, target)", "returns": "Tuple (image, target). target is a list of captions for the image.", "shape": "NA", "code-info": {"name": "torchvision.datasets.CocoCaptions.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.models.alexnet", "type": "function", "code": "torchvision.models.alexnet(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "AlexNet model architecture from the \u201cOne weird trick\u2026\u201d paper", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.alexnet", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.datasets.CocoDetection.__getitem__", "type": "method", "code": "torchvision.datasets.CocoDetection.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns Tuple (image, target)", "returns": "Tuple (image, target). target is the object returned by coco.loadAnns.", "shape": "NA", "code-info": {"name": "torchvision.datasets.CocoDetection.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.LSUN.__getitem__", "type": "method", "code": "torchvision.datasets.LSUN.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns Tuple (image, target) where target is the index of the target category", "returns": "Tuple (image, target) where target is the index of the target category.", "shape": "NA", "code-info": {"name": "torchvision.datasets.LSUN.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.ImageFolder.__getitem__", "type": "method", "code": "torchvision.datasets.ImageFolder.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns (sample, target) where target is class_index of the target class", "returns": "(sample, target) where target is class_index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.ImageFolder.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.DatasetFolder.__getitem__", "type": "method", "code": "torchvision.datasets.DatasetFolder.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns (sample, target) where target is class_index of the target class", "returns": "(sample, target) where target is class_index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.DatasetFolder.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.CIFAR10.__getitem__", "type": "method", "code": "torchvision.datasets.CIFAR10.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns (image, target) where target is index of the target class", "returns": "(image, target) where target is index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.CIFAR10.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.STL10.__getitem__", "type": "method", "code": "torchvision.datasets.STL10.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns (image, target) where target is index of the target class", "returns": "(image, target) where target is index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.STL10.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.SVHN.__getitem__", "type": "method", "code": "torchvision.datasets.SVHN.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns (image, target) where target is index of the target class", "returns": "(image, target) where target is index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.SVHN.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.PhotoTour.__getitem__", "type": "method", "code": "torchvision.datasets.PhotoTour.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns (data1, data2, matches)  Return type tuple   ", "returns": "(data1, data2, matches)", "shape": "NA", "code-info": {"name": "torchvision.datasets.PhotoTour.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.SBU.__getitem__", "type": "method", "code": "torchvision.datasets.SBU.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns (image, target) where target is a caption for the photo", "returns": "(image, target) where target is a caption for the photo.", "shape": "NA", "code-info": {"name": "torchvision.datasets.SBU.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.models.vgg11", "type": "function", "code": "torchvision.models.vgg11(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "VGG 11-layer model (configuration \u201cA\u201d) from \u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.vgg11", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.vgg11_bn", "type": "function", "code": "torchvision.models.vgg11_bn(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "VGG 11-layer model (configuration \u201cA\u201d) with batch normalization \u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.vgg11_bn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.vgg13", "type": "function", "code": "torchvision.models.vgg13(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "VGG 13-layer model (configuration \u201cB\u201d) \u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.vgg13", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.vgg13_bn", "type": "function", "code": "torchvision.models.vgg13_bn(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "VGG 13-layer model (configuration \u201cB\u201d) with batch normalization \u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.vgg13_bn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.vgg16", "type": "function", "code": "torchvision.models.vgg16(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "VGG 16-layer model (configuration \u201cD\u201d) \u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.vgg16", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.vgg16_bn", "type": "function", "code": "torchvision.models.vgg16_bn(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "VGG 16-layer model (configuration \u201cD\u201d) with batch normalization \u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.vgg16_bn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.vgg19", "type": "function", "code": "torchvision.models.vgg19(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "VGG 19-layer model (configuration \u201cE\u201d) \u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.vgg19", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.vgg19_bn", "type": "function", "code": "torchvision.models.vgg19_bn(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "VGG 19-layer model (configuration \u2018E\u2019) with batch normalization \u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.vgg19_bn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.resnet18", "type": "function", "code": "torchvision.models.resnet18(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "ResNet-18 model from \u201cDeep Residual Learning for Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.resnet18", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.io.read_video", "type": "function", "code": "torchvision.io.read_video(filename,start_pts=0,end_pts=None,pts_unit='pts')", "example": "NA", "summary": "Reads a video from a file, returning both the video frames as well as the audio frames  Parameters  filename (str) \u2013 path to the video file start_pts (python:int if pts_unit = 'pts', optional) \u2013 float / Fraction if pts_unit = \u2018sec\u2019, optional the start presentation time of the video end_pts (python:int if pts_unit = 'pts', optional) \u2013 float / Fraction if pts_unit = \u2018sec\u2019, optional the end presentation time pts_unit (str, optional) \u2013 unit in which start_pts and end_pts values will be interpreted, either \u2018pts\u2019 or \u2018sec\u2019", "returns": "vframes (Tensor[T, H, W, C]) \u2013 the T video framesaframes (Tensor[K, L]) \u2013 the audio frames, where K is the number of channels and L is thenumber of pointsinfo (Dict) \u2013 metadata for the video and audio. Can contain the fields video_fps (float)and audio_fps (int)", "shape": "NA", "code-info": {"name": "torchvision.io.read_video", "parameters": [{"name": "filename", "is_optional": false, "type": "str", "description": " path to the video file"}, {"name": "start_pts", "is_optional": true, "type": "int", "default_value": "0", "description": " float / Fraction if pts_unit = \u2018sec\u2019, optionalthe start presentation time of the video"}, {"name": "end_pts", "is_optional": true, "type": "int if pts_unit = 'pts', optional", "default_value": "None", "description": " float / Fraction if pts_unit = \u2018sec\u2019, optionalthe end presentation time"}, {"name": "pts_unit", "is_optional": true, "type": "string", "default_value": "'pts'", "description": " unit in which start_pts and end_pts values will be interpreted, either \u2018pts\u2019 or \u2018sec\u2019. Defaults to \u2018pts\u2019."}]}},
{"id": "torchvision.io.read_video_timestamps", "type": "function", "code": "torchvision.io.read_video_timestamps(filename,pts_unit='pts')", "example": "NA", "summary": "List the video frames timestamps", "returns": "pts (List[int] if pts_unit = \u2018pts\u2019) \u2013 List[Fraction] if pts_unit = \u2018sec\u2019presentation timestamps for each one of the frames in the video.video_fps (int) \u2013 the frame rate for the video", "shape": "NA", "code-info": {"name": "torchvision.io.read_video_timestamps", "parameters": [{"name": "filename", "is_optional": false, "type": "str", "description": " path to the video file"}, {"name": "pts_unit", "is_optional": true, "type": "string", "default_value": "'pts'", "description": " unit in which timestamp values will be returned either \u2018pts\u2019 or \u2018sec\u2019. Defaults to \u2018pts\u2019."}]}},
{"id": "torchvision.io.write_video", "type": "function", "code": "torchvision.io.write_video(filename,video_array,fps,video_codec='libx264',options=None)", "example": "NA", "summary": "Writes a 4d tensor in [T, H, W, C] format in a video file  Parameters  filename (str) \u2013 path where the video will be saved video_array (Tensor[T, H, W, C]) \u2013 tensor containing the individual frames, as a uint8 tensor in [T, H, W, C] format fps (Number) \u2013 frames per second    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.io.write_video", "parameters": [{"name": "filename", "is_optional": false, "type": "str", "description": " path where the video will be saved"}, {"name": "video_array", "is_optional": false, "type": "Tensor[T, H, W, C]", "description": " tensor containing the individual frames, as a uint8 tensor in [T, H, W, C] format"}, {"name": "fps", "is_optional": false, "type": "Number", "description": " frames per second"}, {"name": "video_codec", "is_optional": true, "type": "string", "default_value": "'libx264'", "description": ""}, {"name": "options", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torchvision.transforms.functional.adjust_brightness", "type": "function", "code": "torchvision.transforms.functional.adjust_brightness(img,brightness_factor)", "example": "NA", "summary": "Adjust brightness of an Image", "returns": "Brightness adjusted image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.adjust_brightness", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " PIL Image to be adjusted."}, {"name": "brightness_factor", "is_optional": false, "type": "float", "description": " How much to adjust the brightness. Can beany non negative number. 0 gives a black image, 1 gives theoriginal image while 2 increases the brightness by a factor of 2."}]}},
{"id": "torchvision.transforms.functional.adjust_contrast", "type": "function", "code": "torchvision.transforms.functional.adjust_contrast(img,contrast_factor)", "example": "NA", "summary": "Adjust contrast of an Image", "returns": "Contrast adjusted image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.adjust_contrast", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " PIL Image to be adjusted."}, {"name": "contrast_factor", "is_optional": false, "type": "float", "description": " How much to adjust the contrast. Can be anynon negative number. 0 gives a solid gray image, 1 gives theoriginal image while 2 increases the contrast by a factor of 2."}]}},
{"id": "torch.Tensor.rename", "type": "method", "code": "torch.Tensor.rename(*names,**rename_map)", "example": " imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n renamed_imgs = imgs.rename(N='batch', C='channels')\n renamed_imgs.names\n('batch', 'channels', 'H', 'W')\n\n renamed_imgs = imgs.rename(None)\n renamed_imgs.names\n(None,)\n\n renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n renamed_imgs.names\n('batch', 'channel', 'height', 'width')\n\n", "summary": "Renames dimension names of self", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.rename", "parameters": [{"name": "*names", "is_optional": false, "type": "others", "description": ""}, {"name": "**rename_map", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.rename_", "type": "method", "code": "torch.Tensor.rename_(*names,**rename_map)", "example": "NA", "summary": "In-place version of rename()", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.rename_", "parameters": [{"name": "*names", "is_optional": false, "type": "others", "description": ""}, {"name": "**rename_map", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.torch.finfo", "type": "class", "code": "torch.torch.finfo", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.torch.finfo", "parameters": []}},
{"id": "torch.torch.iinfo", "type": "class", "code": "torch.torch.iinfo", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.torch.iinfo", "parameters": []}},
{"id": "torch.utils.dlpack.from_dlpack", "type": "function", "code": "torch.utils.dlpack.from_dlpack(dlpack)", "example": "NA", "summary": "Decodes a DLPack to a tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.dlpack.from_dlpack", "parameters": [{"name": "dlpack", "is_optional": false, "type": "dlpack : a PyCapsule object with the dltenso", "description": " a PyCapsule object with the dltensor"}]}},
{"id": "torch.utils.dlpack.to_dlpack", "type": "function", "code": "torch.utils.dlpack.to_dlpack(tensor)", "example": "NA", "summary": "Returns a DLPack representing the tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.dlpack.to_dlpack", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : a tensor to be exporte", "description": " a tensor to be exported"}]}},
{"id": "torchvision.datasets.Flickr8k.__getitem__", "type": "method", "code": "torchvision.datasets.Flickr8k.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns Tuple (image, target)", "returns": "Tuple (image, target). target is a list of captions for the image.", "shape": "NA", "code-info": {"name": "torchvision.datasets.Flickr8k.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.Flickr30k.__getitem__", "type": "method", "code": "torchvision.datasets.Flickr30k.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns Tuple (image, target)", "returns": "Tuple (image, target). target is a list of captions for the image.", "shape": "NA", "code-info": {"name": "torchvision.datasets.Flickr30k.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.VOCSegmentation.__getitem__", "type": "method", "code": "torchvision.datasets.VOCSegmentation.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns (image, target) where target is the image segmentation", "returns": "(image, target) where target is the image segmentation.", "shape": "NA", "code-info": {"name": "torchvision.datasets.VOCSegmentation.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.VOCDetection.__getitem__", "type": "method", "code": "torchvision.datasets.VOCDetection.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns (image, target) where target is a dictionary of the XML tree", "returns": "(image, target) where target is a dictionary of the XML tree.", "shape": "NA", "code-info": {"name": "torchvision.datasets.VOCDetection.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.Cityscapes.__getitem__", "type": "method", "code": "torchvision.datasets.Cityscapes.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns (image, target) where target is a tuple of all target types if target_type is a list with more than one item", "returns": "(image, target) where target is a tuple of all target types if target_type is a list with morethan one item. Otherwise target is a json object if target_type=\u201dpolygon\u201d, else the image segmentation.", "shape": "NA", "code-info": {"name": "torchvision.datasets.Cityscapes.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torchvision.datasets.USPS.__getitem__", "type": "method", "code": "torchvision.datasets.USPS.__getitem__(index)", "example": "NA", "summary": " Parameters index (python:int) \u2013 Index  Returns (image, target) where target is index of the target class", "returns": "(image, target) where target is index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.USPS.__getitem__", "parameters": [{"name": "index", "is_optional": false, "type": "int", "description": " Index"}]}},
{"id": "torch.utils.cpp_extension.CppExtension", "type": "function", "code": "torch.utils.cpp_extension.CppExtension(name,sources,*args,**kwargs)", "example": " from setuptools import setup\n from torch.utils.cpp_extension import BuildExtension, CppExtension\n setup(\n        name='extension',\n        ext_modules=[\n            CppExtension(\n                name='extension',\n                sources=['extension.cpp'],\n                extra_compile_args=['-g']),\n        ],\n        cmdclass={\n            'build_ext': BuildExtension\n        })\n\n", "summary": "Creates a setuptools.Extension for C++", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.cpp_extension.CppExtension", "parameters": [{"name": "name", "is_optional": false, "type": "others", "description": ""}, {"name": "sources", "is_optional": false, "type": "others", "description": ""}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.utils.cpp_extension.CUDAExtension", "type": "function", "code": "torch.utils.cpp_extension.CUDAExtension(name,sources,*args,**kwargs)", "example": " from setuptools import setup\n from torch.utils.cpp_extension import BuildExtension, CUDAExtension\n setup(\n        name='cuda_extension',\n        ext_modules=[\n            CUDAExtension(\n                    name='cuda_extension',\n                    sources=['extension.cpp', 'extension_kernel.cu'],\n                    extra_compile_args={'cxx': ['-g'],\n                                        'nvcc': ['-O2']})\n        ],\n        cmdclass={\n            'build_ext': BuildExtension\n        })\n\n", "summary": "Creates a setuptools.Extension for CUDA/C++", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.cpp_extension.CUDAExtension", "parameters": [{"name": "name", "is_optional": false, "type": "others", "description": ""}, {"name": "sources", "is_optional": false, "type": "others", "description": ""}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.utils.cpp_extension.BuildExtension", "type": "function", "code": "torch.utils.cpp_extension.BuildExtension(*args,**kwargs)", "example": "NA", "summary": "A custom setuptools build extension ", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.cpp_extension.BuildExtension", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.utils.cpp_extension.load", "type": "function", "code": "torch.utils.cpp_extension.load(name,sources,extra_cflags=None,extra_cuda_cflags=None,extra_ldflags=None,extra_include_paths=None,build_directory=None,verbose=False,with_cuda=None,is_python_module=True)", "example": " from torch.utils.cpp_extension import load\n module = load(\n        name='extension',\n        sources=['extension.cpp', 'extension_kernel.cu'],\n        extra_cflags=['-O2'],\n        verbose=True)\n\n", "summary": "Loads a PyTorch C++ extension just-in-time (JIT)", "returns": "If is_python_module is True, returns the loaded PyTorchextension as a Python module. If is_python_module is Falsereturns nothing (the shared library is loaded into the process as a sideeffect).", "shape": "NA", "code-info": {"name": "torch.utils.cpp_extension.load", "parameters": [{"name": "name", "is_optional": false, "type": "name : The name of the extension to build. This MUST be the same as thename of the pybind11 module", "description": " The name of the extension to build. This MUST be the same as thename of the pybind11 module!"}, {"name": "sources", "is_optional": false, "type": "sources : A list of relative or absolute paths to C++ source files", "description": " A list of relative or absolute paths to C++ source files."}, {"name": "extra_cflags", "is_optional": true, "type": "extra_cflags : optional list of compiler flags to forward to the build", "default_value": "None", "description": " optional list of compiler flags to forward to the build."}, {"name": "extra_cuda_cflags", "is_optional": true, "type": "extra_cuda_cflags : optional list of compiler flags to forward to nvccwhen building CUDA sources", "default_value": "None", "description": " optional list of compiler flags to forward to nvccwhen building CUDA sources."}, {"name": "extra_ldflags", "is_optional": true, "type": "extra_ldflags : optional list of linker flags to forward to the build", "default_value": "None", "description": " optional list of linker flags to forward to the build."}, {"name": "extra_include_paths", "is_optional": true, "type": "extra_include_paths : optional list of include directories to forwardto the build", "default_value": "None", "description": " optional list of include directories to forwardto the build."}, {"name": "build_directory", "is_optional": true, "type": "build_directory : optional path to use as build workspace", "default_value": "None", "description": " optional path to use as build workspace."}, {"name": "verbose", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, turns on verbose logging of load steps."}, {"name": "with_cuda", "is_optional": true, "type": "default", "default_value": "None", "description": " Determines whether CUDA headers and libraries are added tothe build. If set to None (default, this value isautomatically determined based on the existence of .cu or.cuh in sources. Set it to True` to force CUDA headersand libraries to be included."}, {"name": "is_python_module", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True (default, imports the produced sharedlibrary as a Python module. If False, loads it into the processas a plain dynamic library."}]}},
{"id": "torchvision.models.resnet34", "type": "function", "code": "torchvision.models.resnet34(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "ResNet-34 model from \u201cDeep Residual Learning for Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.resnet34", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.resnet50", "type": "function", "code": "torchvision.models.resnet50(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "ResNet-50 model from \u201cDeep Residual Learning for Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.resnet50", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.resnet101", "type": "function", "code": "torchvision.models.resnet101(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "ResNet-101 model from \u201cDeep Residual Learning for Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.resnet101", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.resnet152", "type": "function", "code": "torchvision.models.resnet152(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "ResNet-152 model from \u201cDeep Residual Learning for Image Recognition\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.resnet152", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.squeezenet1_0", "type": "function", "code": "torchvision.models.squeezenet1_0(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "SqueezeNet model architecture from the \u201cSqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size\u201d paper", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.squeezenet1_0", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.squeezenet1_1", "type": "function", "code": "torchvision.models.squeezenet1_1(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "SqueezeNet 1.1 model from the official SqueezeNet repo", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.squeezenet1_1", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.functional.adjust_gamma", "type": "function", "code": "torchvision.transforms.functional.adjust_gamma(img,gamma,gain=1)", "example": "NA", "summary": "Perform gamma correction on an image", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.adjust_gamma", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " PIL Image to be adjusted."}, {"name": "gamma", "is_optional": false, "type": "float", "description": " Non negative real number, same as \u03b3\\gamma\u03b3 in the equation.gamma larger than 1 make the shadows darker,while gamma smaller than 1 make dark regions lighter."}, {"name": "gain", "is_optional": true, "type": "int", "default_value": "1", "description": " The constant multiplier."}]}},
{"id": "torchvision.transforms.functional.adjust_hue", "type": "function", "code": "torchvision.transforms.functional.adjust_hue(img,hue_factor)", "example": "NA", "summary": "Adjust hue of an image", "returns": "Hue adjusted image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.adjust_hue", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " PIL Image to be adjusted."}, {"name": "hue_factor", "is_optional": false, "type": "float", "description": " How much to shift the hue channel. Should be in[-0.5, 0.5]. 0.5 and -0.5 give complete reversal of hue channel inHSV space in positive and negative direction respectively.0 means no shift. Therefore, both -0.5 and 0.5 will give an imagewith complementary colors while 0 gives the original image."}]}},
{"id": "torchvision.transforms.functional.adjust_saturation", "type": "function", "code": "torchvision.transforms.functional.adjust_saturation(img,saturation_factor)", "example": "NA", "summary": "Adjust color saturation of an image", "returns": "Saturation adjusted image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.adjust_saturation", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " PIL Image to be adjusted."}, {"name": "saturation_factor", "is_optional": false, "type": "float", "description": " How much to adjust the saturation. 0 willgive a black and white image, 1 will give the original image while2 will enhance the saturation by a factor of 2."}]}},
{"id": "torchvision.transforms.functional.affine", "type": "function", "code": "torchvision.transforms.functional.affine(img,angle,translate,scale,shear,resample=0,fillcolor=None)", "example": "NA", "summary": "Apply affine transformation on the image keeping image center invariant  Parameters  img (PIL Image) \u2013 PIL Image to be rotated", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.affine", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " PIL Image to be rotated."}, {"name": "angle", "is_optional": false, "type": "float or int", "description": " rotation angle in degrees between -180 and 180, clockwise direction."}, {"name": "translate", "is_optional": false, "type": "list or tuple of integers", "description": " horizontal and vertical translations (post-rotation translation"}, {"name": "scale", "is_optional": false, "type": "float", "description": " overall scale"}, {"name": "shear", "is_optional": false, "type": "float or tuple or list", "description": " shear angle value in degrees between -180 to 180, clockwise direction."}, {"name": "resample", "is_optional": true, "type": "int", "default_value": "0", "description": " An optional resampling filter.See filters for more information.If omitted, or if the image has mode \u201c1\u201d or \u201cP\u201d, it is set to PIL.Image.NEAREST."}, {"name": "fillcolor", "is_optional": true, "type": "int", "default_value": "None", "description": " Optional fill color for the area outside the transform in the output image. (Pillow&gt;=5.0.0"}]}},
{"id": "torch.utils.checkpoint.checkpoint", "type": "function", "code": "torch.utils.checkpoint.checkpoint(function,*args,**kwargs)", "example": "NA", "summary": "Checkpoint a model or part of the model Checkpointing works by trading compute for memory", "returns": "Output of running function on *args", "shape": "NA", "code-info": {"name": "torch.utils.checkpoint.checkpoint", "parameters": [{"name": "function", "is_optional": false, "type": "activation, hidden", "description": " describes what to run in the forward pass of the model orpart of the model. It should also know how to handle the inputspassed as the tuple. For example, in LSTM, if user passes(activation, hidden, function should correctly use thefirst input as activation and the second input as hidden"}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.utils.checkpoint.checkpoint_sequential", "type": "function", "code": "torch.utils.checkpoint.checkpoint_sequential(functions,segments,*inputs,**kwargs)", "example": " model = nn.Sequential(...)\n input_var = checkpoint_sequential(model, chunks, input_var)\n\n", "summary": "A helper function for checkpointing sequential models", "returns": "Output of running functions sequentially on *inputs", "shape": "NA", "code-info": {"name": "torch.utils.checkpoint.checkpoint_sequential", "parameters": [{"name": "functions", "is_optional": false, "type": "comprising the model", "description": " A torch.nn.Sequential or the list of modules orfunctions (comprising the model to run sequentially."}, {"name": "segments", "is_optional": false, "type": "segments : Number of chunks to create in the mode", "description": " Number of chunks to create in the model"}, {"name": "*inputs", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.__init__", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.__init__(log_dir=None,comment='',purge_step=None,max_queue=10,flush_secs=120,filename_suffix='')", "example": "NA", "summary": "Creates a SummaryWriter that will write out events and summaries to the event file", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.__init__", "parameters": [{"name": "log_dir", "is_optional": true, "type": "string", "default_value": "None", "description": " Save directory location. Default isruns/CURRENT_DATETIME_HOSTNAME, which changes after each run.Use hierarchical folder structure to comparebetween runs easily. e.g. pass in \u2018runs/exp1\u2019, \u2018runs/exp2\u2019, etc.for each new experiment to compare across them."}, {"name": "comment", "is_optional": true, "type": "string", "default_value": "''", "description": " Comment log_dir suffix appended to the defaultlog_dir. If log_dir is assigned, this argument has no effect."}, {"name": "purge_step", "is_optional": true, "type": "int", "default_value": "None", "description": " When logging crashes at step T+XT+XT+X and restarts at step TTT,any events whose global_step larger or equal to TTT will bepurged and hidden from TensorBoard.Note that crashed and resumed experiments should have the same log_dir."}, {"name": "max_queue", "is_optional": true, "type": "int", "default_value": "10", "description": " Size of the queue for pending events andsummaries before one of the \u2018add\u2019 calls forces a flush to disk.Default is ten items."}, {"name": "flush_secs", "is_optional": true, "type": "int", "default_value": "120", "description": " How often, in seconds, to flush thepending events and summaries to disk. Default is every two minutes."}, {"name": "filename_suffix", "is_optional": true, "type": "string", "default_value": "''", "description": " Suffix added to all event filenames inthe log_dir directory. More details on filename construction intensorboard.summary.writer.event_file_writer.EventFileWriter."}]}},
{"id": "torch.utils.model_zoo.load_url", "type": "function", "code": "torch.utils.model_zoo.load_url(url,model_dir=None,map_location=None,progress=True,check_hash=False)", "example": "NA", "summary": "Loads the Torch serialized object at the given URL", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.model_zoo.load_url", "parameters": [{"name": "url", "is_optional": false, "type": "string", "description": " URL of the object to download"}, {"name": "model_dir", "is_optional": true, "type": "string, optional", "default_value": "None", "description": " directory in which to save the object"}, {"name": "map_location", "is_optional": true, "type": "optional", "default_value": "None", "description": " a function or a dict specifying how to remap storage locations (see torch.load"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " whether or not to display a progress bar to stderr.Default"}, {"name": "check_hash", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, the filename part of the URL should follow the naming conventionfilename-&lt;sha256&gt;.ext where &lt;sha256&gt; is the first eight or moredigits of the SHA256 hash of the contents of the file. The hash is used toensure unique names and to verify the contents of the file.Default"}]}},
{"id": "torch.utils.data.get_worker_info", "type": "function", "code": "torch.utils.data.get_worker_info()", "example": "NA", "summary": "Returns the information about the current DataLoader iterator worker process", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.get_worker_info", "parameters": []}},
{"id": "torch.utils.data.random_split", "type": "function", "code": "torch.utils.data.random_split(dataset,lengths)", "example": "NA", "summary": "Randomly split a dataset into non-overlapping new datasets of given lengths", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.random_split", "parameters": [{"name": "dataset", "is_optional": false, "type": "Dataset", "description": " Dataset to be split"}, {"name": "lengths", "is_optional": false, "type": "sequence", "description": " lengths of splits to be produced"}]}},
{"id": "torch.FloatStorage.bfloat16", "type": "method", "code": "torch.FloatStorage.bfloat16()", "example": "NA", "summary": "Casts this storage to bfloat16 type ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.bfloat16", "parameters": []}},
{"id": "torch.FloatStorage.bool", "type": "method", "code": "torch.FloatStorage.bool()", "example": "NA", "summary": "Casts this storage to bool type ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.bool", "parameters": []}},
{"id": "torch.FloatStorage.byte", "type": "method", "code": "torch.FloatStorage.byte()", "example": "NA", "summary": "Casts this storage to byte type ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.byte", "parameters": []}},
{"id": "torch.FloatStorage.char", "type": "method", "code": "torch.FloatStorage.char()", "example": "NA", "summary": "Casts this storage to char type ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.char", "parameters": []}},
{"id": "torch.FloatStorage.clone", "type": "method", "code": "torch.FloatStorage.clone()", "example": "NA", "summary": "Returns a copy of this storage ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.clone", "parameters": []}},
{"id": "torch.FloatStorage.copy_", "type": "method", "code": "torch.FloatStorage.copy_()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.copy_", "parameters": []}},
{"id": "torch.FloatStorage.cpu", "type": "method", "code": "torch.FloatStorage.cpu()", "example": "NA", "summary": "Returns a CPU copy of this storage if it\u2019s not already on the CPU ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.cpu", "parameters": []}},
{"id": "torch.FloatStorage.cuda", "type": "method", "code": "torch.FloatStorage.cuda(device=None,non_blocking=False,**kwargs)", "example": "NA", "summary": "Returns a copy of this object in CUDA memory", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.cuda", "parameters": [{"name": "device", "is_optional": true, "type": "int", "default_value": "None", "description": " The destination GPU id. Defaults to the current device."}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True and the source is in pinned memory,the copy will be asynchronous with respect to the host. Otherwise,the argument has no effect."}, {"name": "**kwargs", "is_optional": false, "type": "**kwargs : For compatibility, may contain the key async in place ofthe non_blocking argument", "description": " For compatibility, may contain the key async in place ofthe non_blocking argument."}]}},
{"id": "torch.FloatStorage.data_ptr", "type": "method", "code": "torch.FloatStorage.data_ptr()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.data_ptr", "parameters": []}},
{"id": "torch.FloatStorage.double", "type": "method", "code": "torch.FloatStorage.double()", "example": "NA", "summary": "Casts this storage to double type ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.double", "parameters": []}},
{"id": "torch.Tensor.refine_names", "type": "method", "code": "torch.Tensor.refine_names(*names)", "example": " imgs = torch.randn(32, 3, 128, 128)\n named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n named_imgs.names\n('N', 'C', 'H', 'W')\n\n tensor = torch.randn(2, 3, 5, 7, 11)\n tensor = tensor.refine_names('A', ..., 'B', 'C')\n tensor.names\n('A', None, None, 'B', 'C')\n\n", "summary": "Refines the dimension names of self according to names", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.refine_names", "parameters": [{"name": "*names", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.align_as", "type": "method", "code": "torch.Tensor.align_as(other)", "example": "# Example 1: Applying a mask\n mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n imgs.masked_fill_(mask.align_as(imgs), 0)\n\n\n# Example 2: Applying a per-channel-scale\ndef scale_channels(input, scale):\n    scale = scale.refine_names('C')\n    return input * scale.align_as(input)\n\n num_channels = 3\n scale = torch.randn(num_channels, names=('C',))\n imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n\n# scale_channels is agnostic to the dimension order of the input\n scale_channels(imgs, scale)\n scale_channels(more_imgs, scale)\n scale_channels(videos, scale)\n\n", "summary": "Permutes the dimensions of the self tensor to match the dimension order in the other tensor, adding size-one dims for any new names", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.align_as", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.align_to", "type": "method", "code": "torch.Tensor.align_to(*names)", "example": " tensor = torch.randn(2, 2, 2, 2, 2, 2)\n named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n\n# Move the F and E dims to the front while keeping the rest in order\n named_tensor.align_to('F', 'E', ...)\n\n", "summary": "Permutes the dimensions of the self tensor to match the order specified in names, adding size-one dims for any new names", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.align_to", "parameters": [{"name": "*names", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.unflatten", "type": "method", "code": "torch.Tensor.unflatten(dim,namedshape)", "example": " flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features'))\n imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128)))\n imgs.names, images.shape\n(('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128]))\n\n", "summary": "Unflattens the named dimension dim, viewing it in the shape specified by namedshape", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.unflatten", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "namedshape", "is_optional": false, "type": "iterable of (name, size", "description": " (iterable of (name, size tuples."}]}},
{"id": "NA", "type": "method", "code": "NA(dims,out_dim)", "example": "NA", "summary": "Flattens dims into a single dimension with name out_dim", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "dims", "is_optional": false, "type": "others", "description": ""}, {"name": "out_dim", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.datasets.MNIST", "type": "class", "code": "torchvision.datasets.MNIST(root,train=True,transform=None,target_transform=None,download=False)", "example": "NA", "summary": "MNIST Dataset", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.datasets.MNIST", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of dataset where MNIST/processed/training.ptand  MNIST/processed/test.pt exist."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, creates dataset from training.pt,otherwise from test.pt."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": " If true, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again."}]}},
{"id": "torchvision.datasets.FashionMNIST", "type": "class", "code": "torchvision.datasets.FashionMNIST(root,train=True,transform=None,target_transform=None,download=False)", "example": "NA", "summary": "Fashion-MNIST Dataset", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.datasets.FashionMNIST", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of dataset where Fashion-MNIST/processed/training.ptand  Fashion-MNIST/processed/test.pt exist."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, creates dataset from training.pt,otherwise from test.pt."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": " If true, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again."}]}},
{"id": "torchvision.datasets.KMNIST", "type": "class", "code": "torchvision.datasets.KMNIST(root,train=True,transform=None,target_transform=None,download=False)", "example": "NA", "summary": "Kuzushiji-MNIST Dataset", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.datasets.KMNIST", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of dataset where KMNIST/processed/training.ptand  KMNIST/processed/test.pt exist."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, creates dataset from training.pt,otherwise from test.pt."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": " If true, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again."}]}},
{"id": "torchvision.datasets.EMNIST", "type": "class", "code": "torchvision.datasets.EMNIST(root,split,**kwargs)", "example": "NA", "summary": "EMNIST Dataset", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.datasets.EMNIST", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of dataset where EMNIST/processed/training.ptand  EMNIST/processed/test.pt exist."}, {"name": "split", "is_optional": false, "type": "string", "description": " The dataset has 6 different splits"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.utils.cpp_extension.load_inline", "type": "function", "code": "torch.utils.cpp_extension.load_inline(name,cpp_sources,cuda_sources=None,functions=None,extra_cflags=None,extra_cuda_cflags=None,extra_ldflags=None,extra_include_paths=None,build_directory=None,verbose=False,with_cuda=None,is_python_module=True,with_pytorch_error_handling=True)", "example": " from torch.utils.cpp_extension import load_inline\n source = '''\nat::Tensor sin_add(at::Tensor x, at::Tensor y) {\n  return x.sin() + y.sin();\n}\n'''\n module = load_inline(name='inline_extension',\n                         cpp_sources=[source],\n                         functions=['sin_add'])\n\n", "summary": "Loads a PyTorch C++ extension just-in-time (JIT) from string sources", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.cpp_extension.load_inline", "parameters": [{"name": "name", "is_optional": false, "type": "which are otherwise just the function names", "description": ""}, {"name": "cpp_sources", "is_optional": false, "type": "cpp_sources : A string, or list of strings, containing C++ source code", "description": " A string, or list of strings, containing C++ source code."}, {"name": "cuda_sources", "is_optional": true, "type": "cuda_sources : A string, or list of strings, containing CUDA source code", "default_value": "None", "description": " A string, or list of strings, containing CUDA source code."}, {"name": "functions", "is_optional": true, "type": "which are otherwise just the function names", "default_value": "None", "description": " A list of function names for which to generate functionbindings. If a dictionary is given, it should map function names todocstrings (which are otherwise just the function names."}, {"name": "extra_cflags", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extra_cuda_cflags", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extra_ldflags", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extra_include_paths", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "build_directory", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "verbose", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "with_cuda", "is_optional": true, "type": "default", "default_value": "None", "description": " Determines whether CUDA headers and libraries are added tothe build. If set to None (default, this value isautomatically determined based on whether cuda_sources isprovided. Set it to True to force CUDA headersand libraries to be included."}, {"name": "is_python_module", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "with_pytorch_error_handling", "is_optional": true, "type": "bool", "default_value": "True", "description": " Determines whether pytorch error andwarning macros are handled by pytorch instead of pybind. To dothis, each function foo is called via an intermediary _safe_foofunction. This redirection might cause issues in obscure casesof cpp. This flag should be set to False when this redirectcauses issues."}]}},
{"id": "torch.utils.cpp_extension.include_paths", "type": "function", "code": "torch.utils.cpp_extension.include_paths(cuda=False)", "example": "NA", "summary": "Get the include paths required to build a C++ or CUDA extension", "returns": "A list of include path strings.", "shape": "NA", "code-info": {"name": "torch.utils.cpp_extension.include_paths", "parameters": [{"name": "cuda", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, includes CUDA-specific include paths."}]}},
{"id": "torch.utils.cpp_extension.check_compiler_abi_compatibility", "type": "function", "code": "torch.utils.cpp_extension.check_compiler_abi_compatibility(compiler)", "example": "NA", "summary": "Verifies that the given compiler is ABI-compatible with PyTorch", "returns": "False if the compiler is (likely) ABI-incompatible with PyTorch,else True.", "shape": "NA", "code-info": {"name": "torch.utils.cpp_extension.check_compiler_abi_compatibility", "parameters": [{"name": "compiler", "is_optional": false, "type": "str", "description": " The compiler executable name to check (e.g. g++.Must be executable in a shell process."}]}},
{"id": "torchvision.models.densenet121", "type": "function", "code": "torchvision.models.densenet121(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Densenet-121 model from \u201cDensely Connected Convolutional Networks\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr memory_efficient (bool) \u2013 but slower", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.densenet121", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.densenet169", "type": "function", "code": "torchvision.models.densenet169(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Densenet-169 model from \u201cDensely Connected Convolutional Networks\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr memory_efficient (bool) \u2013 but slower", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.densenet169", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.densenet161", "type": "function", "code": "torchvision.models.densenet161(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Densenet-161 model from \u201cDensely Connected Convolutional Networks\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr memory_efficient (bool) \u2013 but slower", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.densenet161", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.densenet201", "type": "function", "code": "torchvision.models.densenet201(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Densenet-201 model from \u201cDensely Connected Convolutional Networks\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr memory_efficient (bool) \u2013 but slower", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.densenet201", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.inception_v3", "type": "function", "code": "torchvision.models.inception_v3(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Inception v3 model architecture from \u201cRethinking the Inception Architecture for Computer Vision\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.inception_v3", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.googlenet", "type": "function", "code": "torchvision.models.googlenet(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "GoogLeNet (Inception v1) model architecture from \u201cGoing Deeper with Convolutions\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.googlenet", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.shufflenet_v2_x0_5", "type": "function", "code": "torchvision.models.shufflenet_v2_x0_5(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Constructs a ShuffleNetV2 with 0.5x output channels, as described in \u201cShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.shufflenet_v2_x0_5", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.functional.center_crop", "type": "function", "code": "torchvision.transforms.functional.center_crop(img,output_size)", "example": "NA", "summary": "Crop the given PIL Image and resize it to desired size", "returns": "Cropped image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.center_crop", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " Image to be cropped. (0,0 denotes the top left corner of the image."}, {"name": "output_size", "is_optional": false, "type": "int", "description": " (height, width of the crop box. If int,it is used for both directions"}]}},
{"id": "torchvision.transforms.functional.crop", "type": "function", "code": "torchvision.transforms.functional.crop(img,top,left,height,width)", "example": "NA", "summary": "Crop the given PIL Image", "returns": "Cropped image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.crop", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": ""}, {"name": "top", "is_optional": false, "type": "others", "description": ""}, {"name": "left", "is_optional": false, "type": "others", "description": ""}, {"name": "height", "is_optional": false, "type": "others", "description": ""}, {"name": "width", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.functional.erase", "type": "function", "code": "torchvision.transforms.functional.erase(img,i,j,h,w,v,inplace=False)", "example": "NA", "summary": "Erase the input Tensor Image with given value", "returns": "Erased image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.erase", "parameters": [{"name": "img", "is_optional": false, "type": "Tensor Image", "description": " Tensor image of size (C, H, W to be erased"}, {"name": "i", "is_optional": false, "type": "Tensor Image", "description": " i in (i,j i.e coordinates of the upper left corner."}, {"name": "j", "is_optional": false, "type": "int", "description": " j in (i,j i.e coordinates of the upper left corner."}, {"name": "h", "is_optional": false, "type": "int", "description": " Height of the erased region."}, {"name": "w", "is_optional": false, "type": "int", "description": " Width of the erased region."}, {"name": "v", "is_optional": false, "type": "v : Erasing value", "description": " Erasing value."}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " For in-place operations. By default is set False."}]}},
{"id": "torchvision.transforms.functional.five_crop", "type": "function", "code": "torchvision.transforms.functional.five_crop(img,size)", "example": "NA", "summary": "Crop the given PIL Image into four corners and the central crop", "returns": "tuple (tl, tr, bl, br, center)Corresponding top left, top right, bottom left, bottom right and center crop.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.five_crop", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": ""}, {"name": "size", "is_optional": false, "type": "sequence or int", "description": " Desired output size of the crop. If size is anint instead of sequence like (h, w, a square crop (size, size ismade."}]}},
{"id": "torchvision.transforms.functional.hflip", "type": "function", "code": "torchvision.transforms.functional.hflip(img)", "example": "NA", "summary": "Horizontally flip the given PIL Image", "returns": "Horizontall flipped image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.hflip", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " Image to be flipped."}]}},
{"id": "torchvision.transforms.functional.normalize", "type": "function", "code": "torchvision.transforms.functional.normalize(tensor,mean,std,inplace=False)", "example": "NA", "summary": "Normalize a tensor image with mean and standard deviation", "returns": "Normalized Tensor image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.normalize", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " Tensor image of size (C, H, W to be normalized."}, {"name": "mean", "is_optional": false, "type": "sequence", "description": " Sequence of means for each channel."}, {"name": "std", "is_optional": false, "type": "sequence", "description": " Sequence of standard deviations for each channel."}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " Bool to make this operation inplace."}]}},
{"id": "torchvision.transforms.functional.pad", "type": "function", "code": "torchvision.transforms.functional.pad(img,padding,fill=0,padding_mode='constant')", "example": "NA", "summary": "Pad the given PIL Image on all sides with specified padding mode and fill value", "returns": "Padded image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.pad", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " Image to be padded."}, {"name": "padding", "is_optional": false, "type": "int or tuple", "description": " Padding on each border. If a single int is provided thisis used to pad all borders. If tuple of length 2 is provided this is the paddingon left/right and top/bottom respectively. If a tuple of length 4 is providedthis is the padding for the left, top, right and bottom bordersrespectively."}, {"name": "fill", "is_optional": true, "type": "int", "default_value": "0", "description": " Pixel fill value for constant fill. Default is 0. If a tuple oflength 3, it is used to fill R, G, B channels respectively.This value is only used when the padding_mode is constant"}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'constant'", "description": " Type of padding. Should be"}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_scalar", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_scalar(tag,scalar_value,global_step=None,walltime=None)", "example": "from torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\nx = range(100)\nfor i in x:\n    writer.add_scalar('y=2x', i * 2, i)\nwriter.close()\n\n", "summary": "Add scalar data to summary", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_scalar", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": " Data identifier"}, {"name": "scalar_value", "is_optional": false, "type": "float or string/blobname", "description": " Value to save"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": " Optional override default walltime (time.time(with seconds after epoch of event"}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_scalars", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_scalars(main_tag,tag_scalar_dict,global_step=None,walltime=None)", "example": "from torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\nr = 5\nfor i in range(100):\n    writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r),\n                                    'xcosx':i*np.cos(i/r),\n                                    'tanx': np.tan(i/r)}, i)\nwriter.close()\n# This call adds three values to the same scalar plot with the tag\n# 'run_14h' in TensorBoard's scalar section.\n\n", "summary": "Adds many scalar data to summary", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_scalars", "parameters": [{"name": "main_tag", "is_optional": false, "type": "string", "description": " The parent name for the tags"}, {"name": "tag_scalar_dict", "is_optional": false, "type": "dict", "description": " Key-value pair storing the tag and corresponding values"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": " Optional override default walltime (time.time(seconds after epoch of event"}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_histogram", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_histogram(tag,values,global_step=None,bins='tensorflow',walltime=None,max_bins=None)", "example": "from torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nwriter = SummaryWriter()\nfor i in range(10):\n    x = np.random.random(1000)\n    writer.add_histogram('distribution centers', x + i, i)\nwriter.close()\n\n", "summary": "Add histogram to summary", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_histogram", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": " Data identifier"}, {"name": "values", "is_optional": false, "type": "torch.Tensor, numpy.array, or string/blobname", "description": " Values to build histogram"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "bins", "is_optional": true, "type": "string", "default_value": "'tensorflow'", "description": " One of {\u2018tensorflow\u2019,\u2019auto\u2019, \u2018fd\u2019, \u2026}. This determines how the bins are made. You can findother options in"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": " Optional override default walltime (time.time(seconds after epoch of event"}, {"name": "max_bins", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_image", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_image(tag,img_tensor,global_step=None,walltime=None,dataformats='CHW')", "example": "from torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nimg = np.zeros((3, 100, 100))\nimg[0] = np.arange(0, 10000).reshape(100, 100) / 10000\nimg[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n\nimg_HWC = np.zeros((100, 100, 3))\nimg_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000\nimg_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n\nwriter = SummaryWriter()\nwriter.add_image('my_image', img, 0)\n\n# If you have non-default dimension setting, set the dataformats argument.\nwriter.add_image('my_image_HWC', img_HWC, 0, dataformats='HWC')\nwriter.close()\n\n", "summary": "Add image data to summary", "returns": null, "shape": "img_tensor: Default is (3,H,W)(3, H, W)(3,H,W)  . You can use torchvision.utils.make_grid() to convert a batch of tensor into 3xHxW format or call add_images and let us do the job. Tensor with (1,H,W)(1, H, W)(1,H,W)  , (H,W)(H, W)(H,W)  , (H,W,3)(H, W, 3)(H,W,3)   is also suitible as long as corresponding dataformats argument is passed. e.g. CHW, HWC, HW. ", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_image", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": " Data identifier"}, {"name": "img_tensor", "is_optional": false, "type": "torch.Tensor, numpy.array, or string/blobname", "description": " Image data"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": " Optional override default walltime (time.time(seconds after epoch of event"}, {"name": "dataformats", "is_optional": true, "type": "string", "default_value": "'CHW'", "description": ""}]}},
{"id": "torch.utils.data.DataLoader", "type": "class", "code": "torch.utils.data.DataLoader(dataset,batch_size=1,shuffle=False,sampler=None,batch_sampler=None,num_workers=0,collate_fn=None,pin_memory=False,drop_last=False,timeout=0,worker_init_fn=None,multiprocessing_context=None)", "example": "NA", "summary": "Data loader", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.DataLoader", "parameters": [{"name": "dataset", "is_optional": false, "type": "Dataset", "description": " dataset from which to load the data."}, {"name": "batch_size", "is_optional": true, "type": "int", "default_value": "1", "description": " how many samples per batch to load(default"}, {"name": "shuffle", "is_optional": true, "type": "bool", "default_value": "False", "description": " set to True to have the data reshuffledat every epoch (default"}, {"name": "sampler", "is_optional": true, "type": "Sampler, optional", "default_value": "None", "description": " defines the strategy to draw samples fromthe dataset. If specified, shuffle must be False."}, {"name": "batch_sampler", "is_optional": true, "type": "Sampler, optional", "default_value": "None", "description": " like sampler, but returns a batch ofindices at a time. Mutually exclusive with batch_size,shuffle, sampler, and drop_last."}, {"name": "num_workers", "is_optional": true, "type": "int", "default_value": "0", "description": " how many subprocesses to use for dataloading. 0 means that the data will be loaded in the main process.(default"}, {"name": "collate_fn", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " merges a list of samples to form amini-batch of Tensor(s.  Used when using batched loading from amap-style dataset."}, {"name": "pin_memory", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, the data loader will copy Tensorsinto CUDA pinned memory before returning them.  If your data elementsare a custom type, or your collate_fn returns a batch that is a custom type,see the example below."}, {"name": "drop_last", "is_optional": true, "type": "bool", "default_value": "False", "description": " set to True to drop the last incomplete batch,if the dataset size is not divisible by the batch size. If False andthe size of dataset is not divisible by the batch size, then the last batchwill be smaller. (default"}, {"name": "timeout", "is_optional": true, "type": "int", "default_value": "0", "description": " if positive, the timeout value for collecting a batchfrom workers. Should always be non-negative. (default"}, {"name": "worker_init_fn", "is_optional": true, "type": "int", "default_value": "None", "description": " If not None, this will be called on eachworker subprocess with the worker id (an int in [0, num_workers - 1] asinput, after seeding and before data loading. (default"}, {"name": "multiprocessing_context", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.utils.data.Dataset", "type": "class", "code": "torch.utils.data.Dataset", "example": "NA", "summary": "An abstract class representing a Dataset", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.Dataset", "parameters": []}},
{"id": "torch.utils.data.IterableDataset", "type": "class", "code": "torch.utils.data.IterableDataset", "example": " class MyIterableDataset(torch.utils.data.IterableDataset):\n...     def __init__(self, start, end):\n...         super(MyIterableDataset).__init__()\n...         assert end  start, \"this example code only works with end = start\"\n...         self.start = start\n...         self.end = end\n...\n...     def __iter__(self):\n...         worker_info = torch.utils.data.get_worker_info()\n...         if worker_info is None:  # single-process data loading, return the full iterator\n...             iter_start = self.start\n...             iter_end = self.end\n...         else:  # in a worker process\n...             # split workload\n...             per_worker = int(math.ceil((self.end - self.start) / float(worker_info.num_workers)))\n...             worker_id = worker_info.id\n...             iter_start = self.start + worker_id * per_worker\n...             iter_end = min(iter_start + per_worker, self.end)\n...         return iter(range(iter_start, iter_end))\n...\n # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].\n ds = MyIterableDataset(start=3, end=7)\n\n # Single-process loading\n print(list(torch.utils.data.DataLoader(ds, num_workers=0)))\n[3, 4, 5, 6]\n\n # Mult-process loading with two worker processes\n # Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].\n print(list(torch.utils.data.DataLoader(ds, num_workers=2)))\n[3, 5, 4, 6]\n\n # With even more workers\n print(list(torch.utils.data.DataLoader(ds, num_workers=20)))\n[3, 4, 5, 6]\n\n", "summary": "An iterable Dataset", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.IterableDataset", "parameters": []}},
{"id": "torch.random.fork_rng", "type": "function", "code": "torch.random.fork_rng(devices=None,enabled=True,_caller='fork_rng',_devices_kw='devices')", "example": "NA", "summary": "Forks the RNG, so that when you return, the RNG is reset to the state that it was previously in", "returns": null, "shape": "NA", "code-info": {"name": "torch.random.fork_rng", "parameters": [{"name": "devices", "is_optional": true, "type": "iterable of CUDA IDs", "default_value": "None", "description": " CUDA devices for which to forkthe RNG.  CPU RNG state is always forked.  By default, fork_rng( operateson all devices, but will emit a warning if your machine has a lotof devices, since this function will run very slowly in that case.If you explicitly specify devices, this warning will be suppressed"}, {"name": "enabled", "is_optional": true, "type": "bool", "default_value": "True", "description": " if False, the RNG is not forked.  This is a convenienceargument for easily disabling the context manager without havingto delete it and unindent your Python code under it."}, {"name": "_caller", "is_optional": true, "type": "string", "default_value": "'fork_rng'", "description": ""}, {"name": "_devices_kw", "is_optional": true, "type": "string", "default_value": "'devices'", "description": ""}]}},
{"id": "torch.random.get_rng_state", "type": "function", "code": "torch.random.get_rng_state()", "example": "NA", "summary": "Returns the random number generator state as a torch.ByteTensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.random.get_rng_state", "parameters": []}},
{"id": "torch.random.initial_seed", "type": "function", "code": "torch.random.initial_seed()", "example": "NA", "summary": "Returns the initial seed for generating random numbers as a Python long", "returns": null, "shape": "NA", "code-info": {"name": "torch.random.initial_seed", "parameters": []}},
{"id": "torch.random.manual_seed", "type": "function", "code": "torch.random.manual_seed(seed)", "example": "NA", "summary": "Sets the seed for generating random numbers", "returns": null, "shape": "NA", "code-info": {"name": "torch.random.manual_seed", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": " The desired seed."}]}},
{"id": "torch.random.seed", "type": "function", "code": "torch.random.seed()", "example": "NA", "summary": "Sets the seed for generating random numbers to a non-deterministic random number", "returns": null, "shape": "NA", "code-info": {"name": "torch.random.seed", "parameters": []}},
{"id": "torch.random.set_rng_state", "type": "function", "code": "torch.random.set_rng_state(new_state)", "example": "NA", "summary": "Sets the random number generator state", "returns": null, "shape": "NA", "code-info": {"name": "torch.random.set_rng_state", "parameters": [{"name": "new_state", "is_optional": false, "type": "torch.ByteTensor", "description": " The desired state"}]}},
{"id": "NA", "type": "function", "code": "NA()", "example": "NA", "summary": "Returns the random number generator state as a torch.ByteTensor", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": []}},
{"id": "torch.distributed.rpc.init_rpc", "type": "function", "code": "torch.distributed.rpc.init_rpc(name,backend=BackendType.PROCESS_GROUP,rank=-1,world_size=None,rpc_backend_options=None)", "example": "NA", "summary": "Initializes RPC primitives such as the local RPC agent and distributed autograd", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.rpc.init_rpc", "parameters": [{"name": "name", "is_optional": false, "type": "str", "description": " a globally unique name of this node. (e.g.,Trainer3, ParameterServer2, Master,Worker1 Name can only contain number, alphabet,underscore, and/or dash, and must be shorter than128 characters."}, {"name": "backend", "is_optional": true, "type": "Enum", "default_value": "BackendType.PROCESS_GROUP", "description": " type of RPC backend implementation.Currently, process group backend is the onlyavailable backend implementation. (default"}, {"name": "rank", "is_optional": true, "type": "int", "default_value": "-1", "description": " a globally unique id/rank of this node."}, {"name": "world_size", "is_optional": true, "type": "int", "default_value": "None", "description": " The number of workers in the group."}, {"name": "rpc_backend_options", "is_optional": true, "type": "RpcBackendOptions", "default_value": "None", "description": " The options passed to RpcAgentconsturctor."}]}},
{"id": "torch.distributed.rpc.rpc_sync", "type": "function", "code": "torch.distributed.rpc.rpc_sync(to,func,args=None,kwargs=None)", "example": " On worker 0:  import torch.distributed.rpc as rpc  rpc.init_rpc(\"worker0\", rank=0, world_size=2)  ret = rpc.rpc_sync(\"worker1\", torch.add, args=(torch.ones(2), 3))  rpc.shutdown()  On worker 1:  import torch.distributed.rpc as rpc  rpc.init_rpc(\"worker1\", rank=1, world_size=2)  rpc.shutdown()   ", "summary": "Make a blocking RPC call to run function func on worker to", "returns": "Returns the result of running func on args and kwargs.", "shape": "NA", "code-info": {"name": "torch.distributed.rpc.rpc_sync", "parameters": [{"name": "to", "is_optional": false, "type": "str or WorkerInfo", "description": " id or name of the destination worker."}, {"name": "func", "is_optional": false, "type": "callable", "description": " any callable function. builtin functions (liketorch.add( can be sent over RPC more efficiently."}, {"name": "args", "is_optional": true, "type": "tuple", "default_value": "None", "description": " the argument tuple for the func invocation."}, {"name": "kwargs", "is_optional": true, "type": "dict", "default_value": "None", "description": " is a dictionary of keyword arguments for the funcinvocation."}]}},
{"id": "torch.distributed.rpc.rpc_async", "type": "function", "code": "torch.distributed.rpc.rpc_async(to,func,args=None,kwargs=None)", "example": " On worker 0:  import torch.distributed.rpc as rpc  rpc.init_rpc(\"worker0\", rank=0, world_size=2)  fut1 = rpc.rpc_async(\"worker1\", torch.add, args=(torch.ones(2), 3))  fut2 = rpc.rpc_async(\"worker1\", min, args=(1, 2))  result = fut1.wait() + fut2.wait()  rpc.shutdown()  On worker 1:  import torch.distributed.rpc as rpc  rpc.init_rpc(\"worker1\", rank=1, world_size=2)  rpc.shutdown()   ", "summary": "Make a non-blocking RPC call to run function func on worker to", "returns": "Returns a torch.distributed.FutureMessage object that can be waitedon. When completed, the return value of func on args andkwargs can be retrieved from the FutureMessage object.", "shape": "NA", "code-info": {"name": "torch.distributed.rpc.rpc_async", "parameters": [{"name": "to", "is_optional": false, "type": "str or WorkerInfo", "description": " id or name of the destination worker."}, {"name": "func", "is_optional": false, "type": "callable", "description": " any callable function. builtin functions (liketorch.add( can be sent over RPC more efficiently."}, {"name": "args", "is_optional": true, "type": "tuple", "default_value": "None", "description": " the argument tuple for the func invocation."}, {"name": "kwargs", "is_optional": true, "type": "dict", "default_value": "None", "description": " is a dictionary of keyword arguments for the funcinvocation."}]}},
{"id": "torch.FloatStorage.element_size", "type": "method", "code": "torch.FloatStorage.element_size()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.element_size", "parameters": []}},
{"id": "torch.FloatStorage.fill_", "type": "method", "code": "torch.FloatStorage.fill_()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.fill_", "parameters": []}},
{"id": "torch.FloatStorage.float", "type": "method", "code": "torch.FloatStorage.float()", "example": "NA", "summary": "Casts this storage to float type ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.float", "parameters": []}},
{"id": "torch.FloatStorage.from_buffer", "type": "method", "code": "torch.FloatStorage.from_buffer()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.from_buffer", "parameters": []}},
{"id": "torch.FloatStorage.from_file", "type": "method", "code": "torch.FloatStorage.from_file(filename,shared=False,size=0)", "example": "NA", "summary": "If shared is True, then memory is shared between all processes", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.from_file", "parameters": [{"name": "filename", "is_optional": false, "type": "str", "description": " file name to map"}, {"name": "shared", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether to share memory"}, {"name": "size", "is_optional": true, "type": "int", "default_value": "0", "description": " number of elements in the storage"}]}},
{"id": "torch.FloatStorage.half", "type": "method", "code": "torch.FloatStorage.half()", "example": "NA", "summary": "Casts this storage to half type ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.half", "parameters": []}},
{"id": "torch.FloatStorage.int", "type": "method", "code": "torch.FloatStorage.int()", "example": "NA", "summary": "Casts this storage to int type ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.int", "parameters": []}},
{"id": "torch.FloatStorage.is_pinned", "type": "method", "code": "torch.FloatStorage.is_pinned()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.is_pinned", "parameters": []}},
{"id": "torch.FloatStorage.is_shared", "type": "method", "code": "torch.FloatStorage.is_shared()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.is_shared", "parameters": []}},
{"id": "torch.FloatStorage.long", "type": "method", "code": "torch.FloatStorage.long()", "example": "NA", "summary": "Casts this storage to long type ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.long", "parameters": []}},
{"id": "torch.FloatStorage.new", "type": "method", "code": "torch.FloatStorage.new()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.new", "parameters": []}},
{"id": "torch.FloatStorage.pin_memory", "type": "method", "code": "torch.FloatStorage.pin_memory()", "example": "NA", "summary": "Copies the storage to pinned memory, if it\u2019s not already pinned", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.pin_memory", "parameters": []}},
{"id": "torch.quantization.quantize", "type": "function", "code": "torch.quantization.quantize(model,run_fn,run_args,mapping=None,inplace=False)", "example": "NA", "summary": "Converts a float model to quantized model", "returns": "Quantized model.", "shape": "NA", "code-info": {"name": "torch.quantization.quantize", "parameters": [{"name": "model", "is_optional": false, "type": "model : input mode", "description": " input model"}, {"name": "run_fn", "is_optional": false, "type": "run_fn : a function for evaluating the prepared model, can be afunction that simply runs the prepared model or a training loo", "description": " a function for evaluating the prepared model, can be afunction that simply runs the prepared model or a training loop"}, {"name": "run_args", "is_optional": false, "type": "run_args : positional arguments for run_f", "description": " positional arguments for run_fn"}, {"name": "mapping", "is_optional": true, "type": "mapping : correspondence between original module types and quantized counterpart", "default_value": "None", "description": " correspondence between original module types and quantized counterparts"}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " carry out model transformations in-place, the original module is mutated"}]}},
{"id": "torch.optim.Optimizer.add_param_group", "type": "method", "code": "torch.optim.Optimizer.add_param_group(param_group)", "example": "NA", "summary": "Add a param group to the Optimizer s param_groups", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Optimizer.add_param_group", "parameters": [{"name": "param_group", "is_optional": false, "type": "dict", "description": " Specifies what Tensors should be optimized along with group"}]}},
{"id": "torch.onnx.export", "type": "function", "code": "torch.onnx.export(model,args,f,export_params=True,verbose=False,training=False,input_names=None,output_names=None,aten=False,export_raw_ir=False,operator_export_type=None,opset_version=None,_retain_param_name=True,do_constant_folding=False,example_outputs=None,strip_doc_string=True,dynamic_axes=None,keep_initializers_as_inputs=None)", "example": "NA", "summary": "Export a model into ONNX format", "returns": null, "shape": "NA", "code-info": {"name": "torch.onnx.export", "parameters": [{"name": "model", "is_optional": false, "type": "torch.nn.Module", "description": " the model to be exported."}, {"name": "args", "is_optional": false, "type": "int", "description": " the inputs tothe model, e.g., such that model(*args is a validinvocation of the model.  Any non-Tensor arguments willbe hard-coded into the exported model; any Tensor argumentswill become inputs of the exported model, in the order theyoccur in args.  If args is a Tensor, this is equivalentto having called it with a 1-ary tuple of that Tensor.(Note"}, {"name": "f", "is_optional": false, "type": "string", "description": " a file-like object (has to implement fileno that returns a file descriptoror a string containing a file name.  A binary Protobuf will be writtento this file."}, {"name": "export_params", "is_optional": true, "type": "bool", "default_value": "True", "description": " if specified, all parameters willbe exported.  Set this to False if you want to export an untrained model.In this case, the exported model will first take all of its parametersas arguments, the ordering as specified by model.state_dict(.values("}, {"name": "verbose", "is_optional": true, "type": "bool", "default_value": "False", "description": " if specified, we will print out a debugdescription of the trace being exported."}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "False", "description": " export the model in training mode.  Atthe moment, ONNX is oriented towards exporting models for inferenceonly, so you will generally not need to set this to True."}, {"name": "input_names", "is_optional": true, "type": "list of strings, default empty list", "default_value": "None", "description": " names to assign to theinput nodes of the graph, in order"}, {"name": "output_names", "is_optional": true, "type": "list of strings, default empty list", "default_value": "None", "description": " names to assign to theoutput nodes of the graph, in order"}, {"name": "aten", "is_optional": true, "type": "bool", "default_value": "False", "description": " [DEPRECATED. use operator_export_type] export themodel in aten mode. If using aten mode, all the ops original exportedby the functions in symbolic_opset&lt;version&gt;.py are exported as ATen ops."}, {"name": "export_raw_ir", "is_optional": true, "type": "bool", "default_value": "False", "description": " [DEPRECATED. use operator_export_type]export the internal IR directly instead of converting it to ONNX ops."}, {"name": "operator_export_type", "is_optional": true, "type": "bool, default False", "default_value": "None", "description": " OperatorExportTypes.ONNX"}, {"name": "opset_version", "is_optional": true, "type": "int, default is 9", "default_value": "None", "description": " by default we export the model to theopset version of the onnx submodule. Since ONNX\u2019s latest opset mayevolve before next stable release, by default we export to one stableopset version. Right now, supported stable opset version is 9.The opset_version must be _onnx_master_opset or in _onnx_stable_opsetswhich are defined in torch/onnx/symbolic_helper.py"}, {"name": "_retain_param_name", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "do_constant_folding", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, the constant-foldingoptimization is applied to the model during export. Constant-foldingoptimization will replace some of the ops that have all constantinputs, with pre-computed constant nodes."}, {"name": "example_outputs", "is_optional": true, "type": "tuple of Tensors, default None", "default_value": "None", "description": " example outputs of the model that is being exported."}, {"name": "strip_doc_string", "is_optional": true, "type": "bool", "default_value": "True", "description": " if True, strips the field\u201cdoc_string\u201d from the exported model, which information about the stacktrace."}, {"name": "dynamic_axes", "is_optional": true, "type": "dict&lt;string, dict&lt;int, string&gt;&gt; or dict&lt;string, list(int", "default_value": "None", "description": " a dictionary to specify dynamic axes of input/output, such that"}, {"name": "keep_initializers_as_inputs", "is_optional": true, "type": "bool, default None", "default_value": "None", "description": " If True, all the initializers(typically corresponding to parameters in the exported graph will also beadded as inputs to the graph. If False, then initializers are not added asinputs to the graph, and only the non-parameter inputs are added as inputs.This may allow for better optimizations (such as constant folding etc. bybackends/runtimes that execute these graphs. If unspecified (default None,then the behavior is chosen automatically as follows. If operator_export_typeis OperatorExportTypes.ONNX, the behavior is equivalent to setting thisargument to False. For other values of operator_export_type, the behavior isequivalent to setting this argument to True. Note that for ONNX opset version &lt; 9,initializers MUST be part of graph inputs. Therefore, if opset_version argument isset to a 8 or lower, this argument will be ignored."}]}},
{"id": "torchvision.datasets.QMNIST", "type": "class", "code": "torchvision.datasets.QMNIST(root,what=None,compat=True,train=True,**kwargs)", "example": "NA", "summary": "QMNIST Dataset", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.datasets.QMNIST", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of dataset whose ``processed\u2019\u2019subdir contains torch binary files with the datasets."}, {"name": "what", "is_optional": true, "type": "string,optional", "default_value": "None", "description": " Can be \u2018train\u2019, \u2018test\u2019, \u2018test10k\u2019,\u2018test50k\u2019, or \u2018nist\u2019 for respectively the mnist compatibletraining set, the 60k qmnist testing set, the 10k qmnistexamples that match the mnist testing set, the 50kremaining qmnist testing examples, or all the nistdigits. The default is to select \u2018train\u2019 or \u2018test\u2019according to the compatibility argument \u2018train\u2019."}, {"name": "compat", "is_optional": true, "type": "bool", "default_value": "True", "description": " A boolean that says whether the targetfor each example is class number (for compatibility withthe MNIST dataloader or a torch vector containing thefull qmnist information. Default=True."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": " When argument \u2018what\u2019 isnot specified, this boolean decides whether to load thetraining set ot the testing set.  Default"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.datasets.FakeData", "type": "class", "code": "torchvision.datasets.FakeData(size=1000,image_size=(3,224,224)", "example": "NA", "summary": "A fake dataset that returns randomly generated images and returns them as PIL images  Parameters  size (python:int, optional) \u2013 Size of the dataset", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.datasets.FakeData", "parameters": [{"name": "size", "is_optional": true, "type": "int", "default_value": "1000", "description": " Size of the dataset. Default"}, {"name": "image_size", "is_optional": false, "type": "tuple, optional", "description": " Size if the returned images. Default"}]}},
{"id": "torchvision.datasets.CocoCaptions", "type": "class", "code": "torchvision.datasets.CocoCaptions(root,annFile,transform=None,target_transform=None,transforms=None)", "example": "import torchvision.datasets as dset\nimport torchvision.transforms as transforms\ncap = dset.CocoCaptions(root = 'dir where images are',\n                        annFile = 'json annotation file',\n                        transform=transforms.ToTensor())\n\nprint('Number of samples: ', len(cap))\nimg, target = cap[3] # load 4th sample\n\nprint(\"Image Size: \", img.size())\nprint(target)\n\n", "summary": "MS Coco Captions Dataset", "returns": "Tuple (image, target). target is a list of captions for the image.", "shape": "NA", "code-info": {"name": "torchvision.datasets.CocoCaptions", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory where images are downloaded to."}, {"name": "annFile", "is_optional": false, "type": "string", "description": " Path to json annotation file."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.ToTensor"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "transforms", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes input sample and its target as entryand returns a transformed version."}]}},
{"id": "torchvision.datasets.CocoDetection", "type": "class", "code": "torchvision.datasets.CocoDetection(root,annFile,transform=None,target_transform=None,transforms=None)", "example": "NA", "summary": "MS Coco Detection Dataset", "returns": "Tuple (image, target). target is the object returned by coco.loadAnns.", "shape": "NA", "code-info": {"name": "torchvision.datasets.CocoDetection", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory where images are downloaded to."}, {"name": "annFile", "is_optional": false, "type": "string", "description": " Path to json annotation file."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.ToTensor"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "transforms", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes input sample and its target as entryand returns a transformed version."}]}},
{"id": "torch.sparse.addmm", "type": "function", "code": "torch.sparse.addmm(mat,mat1,mat2,beta=1,alpha=1)", "example": "NA", "summary": "This function does exact same thing as torch.addmm() in the forward, except that it supports backward for sparse matrix mat1", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.addmm", "parameters": [{"name": "mat", "is_optional": false, "type": "Tensor", "description": " a dense matrix to be added"}, {"name": "mat1", "is_optional": false, "type": "SparseTensor", "description": " a sparse matrix to be multiplied"}, {"name": "mat2", "is_optional": false, "type": "Tensor", "description": " a dense matrix be multiplied"}, {"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for mat (\u03b2\\beta\u03b2"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for mat1@mat2mat1 @ mat2mat1@mat2 (\u03b1\\alpha\u03b1"}]}},
{"id": "torch.sparse.mm", "type": "function", "code": "torch.sparse.mm(mat1,mat2)", "example": "  a = torch.randn(2, 3).to_sparse().requires_grad_(True)  a tensor(indices=tensor([[0, 0, 0, 1, 1, 1],                        [0, 1, 2, 0, 1, 2]]),        values=tensor([ 1.5901,  0.0183, -0.6146,  1.8061, -0.0112,  0.6302]),        size=(2, 3), nnz=6, layout=torch.sparse_coo, requires_grad=True)   b = torch.randn(3, 2, requires_grad=True)  b tensor([[-0.6479,  0.7874],         [-1.2056,  0.5641],         [-1.1716, -0.9923]], requires_grad=True)   y = torch.sparse.mm(a, b)  y tensor([[-0.3323,  1.8723],         [-1.8951,  0.7904]], grad_fn=&lt;SparseAddmmBackward)  y.sum().backward()  a.grad tensor(indices=tensor([[0, 0, 0, 1, 1, 1],                        [0, 1, 2, 0, 1, 2]]),        values=tensor([ 0.1394, -0.6415, -2.1639,  0.1394, -0.6415, -2.1639]),        size=(2, 3), nnz=6, layout=torch.sparse_coo)   ", "summary": "Performs a matrix multiplication of the sparse matrix mat1 and dense matrix mat2", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.mm", "parameters": [{"name": "mat1", "is_optional": false, "type": "SparseTensor", "description": " the first sparse matrix to be multiplied"}, {"name": "mat2", "is_optional": false, "type": "Tensor", "description": " the second dense matrix to be multiplied"}]}},
{"id": "torch.sparse.sum", "type": "function", "code": "torch.sparse.sum(input,dim=None,dtype=None)", "example": "  nnz = 3  dims = [5, 5, 2, 3]  I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),                    torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)  V = torch.randn(nnz, dims[2], dims[3])  size = torch.Size(dims)  S = torch.sparse_coo_tensor(I, V, size)  S tensor(indices=tensor([[2, 0, 3],                        [2, 4, 1]]),        values=tensor([[[-0.6438, -1.6467,  1.4004],                        [ 0.3411,  0.0918, -0.2312]],                        [[ 0.5348,  0.0634, -2.0494],                        [-0.7125, -1.0646,  2.1844]],                        [[ 0.1276,  0.1874, -0.6334],                        [-1.9682, -0.5340,  0.7483]]]),        size=(5, 5, 2, 3), nnz=3, layout=torch.sparse_coo)  # when sum over only part of sparse_dims, return a SparseTensor  torch.sparse.sum(S, [1, 3]) tensor(indices=tensor([[0, 2, 3]]),        values=tensor([[-1.4512,  0.4073],                       [-0.8901,  0.2017],                       [-0.3183, -1.7539]]),        size=(5, 2), nnz=3, layout=torch.sparse_coo)  # when sum over all sparse dim, return a dense Tensor # with summed dims squeezed  torch.sparse.sum(S, [0, 1, 3]) tensor([-2.6596, -1.1450])   ", "summary": "Returns the sum of each row of SparseTensor input in the given dimensions dim", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.sum", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input SparseTensor"}, {"name": "dim", "is_optional": true, "type": "int or tuple of ints", "default_value": "None", "description": " a dimension or a list of dimensions to reduce. Default"}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned Tensor.Default"}]}},
{"id": "torch.utils.cpp_extension.verify_ninja_availability", "type": "function", "code": "torch.utils.cpp_extension.verify_ninja_availability()", "example": "NA", "summary": "Returns True if the ninja build system is available on the system", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.cpp_extension.verify_ninja_availability", "parameters": []}},
{"id": "torchvision.models.shufflenet_v2_x1_0", "type": "function", "code": "torchvision.models.shufflenet_v2_x1_0(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Constructs a ShuffleNetV2 with 1.0x output channels, as described in \u201cShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.shufflenet_v2_x1_0", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.shufflenet_v2_x1_5", "type": "function", "code": "torchvision.models.shufflenet_v2_x1_5(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Constructs a ShuffleNetV2 with 1.5x output channels, as described in \u201cShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.shufflenet_v2_x1_5", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.shufflenet_v2_x2_0", "type": "function", "code": "torchvision.models.shufflenet_v2_x2_0(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Constructs a ShuffleNetV2 with 2.0x output channels, as described in \u201cShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.shufflenet_v2_x2_0", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.mobilenet_v2", "type": "function", "code": "torchvision.models.mobilenet_v2(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Constructs a MobileNetV2 architecture from \u201cMobileNetV2: Inverted Residuals and Linear Bottlenecks\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.mobilenet_v2", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.resnext50_32x4d", "type": "function", "code": "torchvision.models.resnext50_32x4d(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "ResNeXt-50 32x4d model from \u201cAggregated Residual Transformation for Deep Neural Networks\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.resnext50_32x4d", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.resnext101_32x8d", "type": "function", "code": "torchvision.models.resnext101_32x8d(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "ResNeXt-101 32x8d model from \u201cAggregated Residual Transformation for Deep Neural Networks\u201d  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on ImageNet progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.resnext101_32x8d", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.wide_resnet50_2", "type": "function", "code": "torchvision.models.wide_resnet50_2(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Wide ResNet-50-2 model from \u201cWide Residual Networks\u201d The model is the same as ResNet except for the bottleneck number of channels which is twice larger in every block", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.wide_resnet50_2", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.wide_resnet101_2", "type": "function", "code": "torchvision.models.wide_resnet101_2(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Wide ResNet-101-2 model from \u201cWide Residual Networks\u201d The model is the same as ResNet except for the bottleneck number of channels which is twice larger in every block", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.wide_resnet101_2", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on ImageNet"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.functional.perspective", "type": "function", "code": "torchvision.transforms.functional.perspective(img,startpoints,endpoints,interpolation=3)", "example": "NA", "summary": "Perform perspective transform of the given PIL Image", "returns": "Perspectively transformed Image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.perspective", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " Image to be transformed."}, {"name": "startpoints", "is_optional": false, "type": "startpoints : List containing [top-left, top-right, bottom-right, bottom-left] of the orignal imag", "description": " List containing [top-left, top-right, bottom-right, bottom-left] of the orignal image"}, {"name": "endpoints", "is_optional": false, "type": "endpoints : List containing [top-left, top-right, bottom-right, bottom-left] of the transformed imag", "description": " List containing [top-left, top-right, bottom-right, bottom-left] of the transformed image"}, {"name": "interpolation", "is_optional": true, "type": "int", "default_value": "3", "description": " Default- Image.BICUBIC"}]}},
{"id": "torchvision.transforms.functional.resize", "type": "function", "code": "torchvision.transforms.functional.resize(img,size,interpolation=2)", "example": "NA", "summary": "Resize the input PIL Image to the given size", "returns": "Resized image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.resize", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " Image to be resized."}, {"name": "size", "is_optional": false, "type": "int", "description": " Desired output size. If size is a sequence like(h, w, the output size will be matched to this. If size is an int,the smaller edge of the image will be matched to this number maintaingthe aspect ratio. i.e, if height &gt; width, then image will be rescaled to(size\u00d7heightwidth,size\\left(\\text{size} \\times \\frac{\\text{height}}{\\text{width}}, \\text{size}\\right(size\u00d7widthheight\u200b,size"}, {"name": "interpolation", "is_optional": true, "type": "int", "default_value": "2", "description": " Desired interpolation. Default isPIL.Image.BILINEAR"}]}},
{"id": "torchvision.transforms.functional.resized_crop", "type": "function", "code": "torchvision.transforms.functional.resized_crop(img,top,left,height,width,size,interpolation=2)", "example": "NA", "summary": "Crop the given PIL Image and resize it to desired size", "returns": "Cropped image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.resized_crop", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " Image to be cropped. (0,0 denotes the top left corner of the image."}, {"name": "top", "is_optional": false, "type": "PIL Image", "description": " Vertical component of the top left corner of the crop box."}, {"name": "left", "is_optional": false, "type": "PIL Image", "description": " Horizontal component of the top left corner of the crop box."}, {"name": "height", "is_optional": false, "type": "int", "description": " Height of the crop box."}, {"name": "width", "is_optional": false, "type": "int", "description": " Width of the crop box."}, {"name": "size", "is_optional": false, "type": "sequence or int", "description": " Desired output size. Same semantics as resize."}, {"name": "interpolation", "is_optional": true, "type": "int", "default_value": "2", "description": " Desired interpolation. Default isPIL.Image.BILINEAR."}]}},
{"id": "torchvision.transforms.functional.rotate", "type": "function", "code": "torchvision.transforms.functional.rotate(img,angle,resample=False,expand=False,center=None,fill=0)", "example": "NA", "summary": "Rotate the image by angle", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.rotate", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " PIL Image to be rotated."}, {"name": "angle", "is_optional": false, "type": "float or int", "description": " In degrees degrees counter clockwise order."}, {"name": "resample", "is_optional": true, "type": "bool", "default_value": "False", "description": " An optional resampling filter. See filters for more information.If omitted, or if the image has mode \u201c1\u201d or \u201cP\u201d, it is set to PIL.Image.NEAREST."}, {"name": "expand", "is_optional": true, "type": "bool", "default_value": "False", "description": " Optional expansion flag.If true, expands the output image to make it large enough to hold the entire rotated image.If false or omitted, make the output image the same size as the input image.Note that the expand flag assumes rotation around the center and no translation."}, {"name": "center", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Optional center of rotation.Origin is the upper left corner.Default is the center of the image."}, {"name": "fill", "is_optional": true, "type": "int", "default_value": "0", "description": " RGB pixel fill value for area outside the rotated image.If int, it is used for all channels respectively."}]}},
{"id": "torchvision.transforms.functional.ten_crop", "type": "function", "code": "torchvision.transforms.functional.ten_crop(img,size,vertical_flip=False)", "example": "NA", "summary": " Crop the given PIL Image into four corners and the central crop plus theflipped version of these (horizontal flipping is used by default)", "returns": "tuple (tl, tr, bl, br, center, tl_flip, tr_flip, bl_flip, br_flip, center_flip)Corresponding top left, top right, bottom left, bottom right and center cropand same for the flipped image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.ten_crop", "parameters": [{"name": "img", "is_optional": false, "type": "others", "description": ""}, {"name": "size", "is_optional": false, "type": "sequence or int", "description": " Desired output size of the crop. If size is anint instead of sequence like (h, w, a square crop (size, size ismade."}, {"name": "vertical_flip", "is_optional": true, "type": "bool", "default_value": "False", "description": " Use vertical flipping instead of horizontal"}]}},
{"id": "torchvision.transforms.functional.to_grayscale", "type": "function", "code": "torchvision.transforms.functional.to_grayscale(img,num_output_channels=1)", "example": "NA", "summary": "Convert image to grayscale version of image", "returns": "Grayscale version of the image.if num_output_channels = 1 : returned image is single channelif num_output_channels = 3 : returned image is 3 channel with r = g = b", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.to_grayscale", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " Image to be converted to grayscale."}, {"name": "num_output_channels", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"id": "torch.nn.init.calculate_gain", "type": "function", "code": "torch.nn.init.calculate_gain(nonlinearity,param=None)", "example": " gain = nn.init.calculate_gain('leaky_relu', 0.2)  # leaky_relu with negative_slope=0.2\n\n", "summary": "Return the recommended gain value for the given nonlinearity function", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.calculate_gain", "parameters": [{"name": "nonlinearity", "is_optional": false, "type": "nn.functional name", "description": " the non-linear function (nn.functional name"}, {"name": "param", "is_optional": true, "type": "param : optional parameter for the non-linear functio", "default_value": "None", "description": " optional parameter for the non-linear function"}]}},
{"id": "torch.nn.init.uniform_", "type": "function", "code": "torch.nn.init.uniform_(tensor,a=0.0,b=1.0)", "example": " w = torch.empty(3, 5)\n nn.init.uniform_(w)\n\n", "summary": "Fills the input Tensor with values drawn from the uniform distribution U(a,b)\\mathcal{U}(a, b)U(a,b)  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.uniform_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : an n-dimensional torch.Tenso", "description": " an n-dimensional torch.Tensor"}, {"name": "a", "is_optional": true, "type": "tensor : an n-dimensional torch.Tenso", "default_value": "0.0", "description": " the lower bound of the uniform distribution"}, {"name": "b", "is_optional": true, "type": "a : the lower bound of the uniform distributio", "default_value": "1.0", "description": " the upper bound of the uniform distribution"}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_images", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_images(tag,img_tensor,global_step=None,walltime=None,dataformats='NCHW')", "example": "from torch.utils.tensorboard import SummaryWriter\nimport numpy as np\n\nimg_batch = np.zeros((16, 3, 100, 100))\nfor i in range(16):\n    img_batch[i, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 / 16 * i\n    img_batch[i, 1] = (1 - np.arange(0, 10000).reshape(100, 100) / 10000) / 16 * i\n\nwriter = SummaryWriter()\nwriter.add_images('my_image_batch', img_batch, 0)\nwriter.close()\n\n", "summary": "Add batched image data to summary", "returns": null, "shape": "img_tensor: Default is (N,3,H,W)(N, 3, H, W)(N,3,H,W)  . If dataformats is specified, other shape will be accepted. e.g. NCHW or NHWC. ", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_images", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": " Data identifier"}, {"name": "img_tensor", "is_optional": false, "type": "torch.Tensor, numpy.array, or string/blobname", "description": " Image data"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": " Optional override default walltime (time.time(seconds after epoch of event"}, {"name": "dataformats", "is_optional": true, "type": "string", "default_value": "'NCHW'", "description": " Image data format specification of the formNCHW, NHWC, CHW, HWC, HW, WH, etc."}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_figure", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_figure(tag,figure,global_step=None,close=True,walltime=None)", "example": "NA", "summary": "Render matplotlib figure into an image and add it to summary", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_figure", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": " Data identifier"}, {"name": "figure", "is_optional": false, "type": "matplotlib.pyplot.figure", "description": " Figure or a list of figures"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "close", "is_optional": true, "type": "bool", "default_value": "True", "description": " Flag to automatically close the figure"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": " Optional override default walltime (time.time(seconds after epoch of event"}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_video", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_video(tag,vid_tensor,global_step=None,fps=4,walltime=None)", "example": "NA", "summary": "Add video data to summary", "returns": null, "shape": "vid_tensor: (N,T,C,H,W)(N, T, C, H, W)(N,T,C,H,W)  . The values should lie in [0, 255] for type uint8 or [0, 1] for type float. ", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_video", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": " Data identifier"}, {"name": "vid_tensor", "is_optional": false, "type": "torch.Tensor", "description": " Video data"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "fps", "is_optional": true, "type": "int", "default_value": "4", "description": " Frames per second"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": " Optional override default walltime (time.time(seconds after epoch of event"}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_audio", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_audio(tag,snd_tensor,global_step=None,sample_rate=44100,walltime=None)", "example": "NA", "summary": "Add audio data to summary", "returns": null, "shape": "snd_tensor: (1,L)(1, L)(1,L)  . The values should lie between [-1, 1]. ", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_audio", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": " Data identifier"}, {"name": "snd_tensor", "is_optional": false, "type": "torch.Tensor", "description": " Sound data"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "sample_rate", "is_optional": true, "type": "int", "default_value": "44100", "description": " sample rate in Hz"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": " Optional override default walltime (time.time(seconds after epoch of event"}]}},
{"id": "torch.jit.script", "type": "function", "code": "torch.jit.script(obj)", "example": "import torch\n\n@torch.jit.script\ndef foo(x, y):\n    if x.max()  y.max():\n        r = x\n    else:\n        r = y\n    return r\n\nprint(type(foo))  # torch.jit.ScriptFuncion\n\n# See the compiled graph as Python code\nprint(foo.code)\n\n# Call the function using the TorchScript interpreter\nfoo(torch.ones(2, 2), torch.ones(2, 2))\n\n", "summary": "Scripting a function or nn.Module will inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return a ScriptModule or ScriptFunction", "returns": null, "shape": "NA", "code-info": {"name": "torch.jit.script", "parameters": [{"name": "obj", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.utils.data.TensorDataset", "type": "class", "code": "torch.utils.data.TensorDataset(*tensors)", "example": "NA", "summary": "Dataset wrapping tensors", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.TensorDataset", "parameters": [{"name": "*tensors", "is_optional": false, "type": "Tensor", "description": " tensors that have the same size of the first dimension."}]}},
{"id": "torch.utils.data.ConcatDataset", "type": "class", "code": "torch.utils.data.ConcatDataset(datasets)", "example": "NA", "summary": "Dataset as a concatenation of multiple datasets", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.ConcatDataset", "parameters": [{"name": "datasets", "is_optional": false, "type": "sequence", "description": " List of datasets to be concatenated"}]}},
{"id": "torch.utils.data.ChainDataset", "type": "class", "code": "torch.utils.data.ChainDataset(datasets)", "example": "NA", "summary": "Dataset for chainning multiple IterableDataset s", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.ChainDataset", "parameters": [{"name": "datasets", "is_optional": false, "type": "iterable of IterableDataset", "description": " datasets to be chained together"}]}},
{"id": "torch.utils.data.Subset", "type": "class", "code": "torch.utils.data.Subset(dataset,indices)", "example": "NA", "summary": "Subset of a dataset at specified indices", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.Subset", "parameters": [{"name": "dataset", "is_optional": false, "type": "Dataset", "description": " The whole Dataset"}, {"name": "indices", "is_optional": false, "type": "sequence", "description": " Indices in the whole set selected for subset"}]}},
{"id": "torch.utils.data.Sampler", "type": "class", "code": "torch.utils.data.Sampler(data_source)", "example": "NA", "summary": "Base class for all Samplers", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.Sampler", "parameters": [{"name": "data_source", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.utils.data.SequentialSampler", "type": "class", "code": "torch.utils.data.SequentialSampler(data_source)", "example": "NA", "summary": "Samples elements sequentially, always in the same order", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.SequentialSampler", "parameters": [{"name": "data_source", "is_optional": false, "type": "Dataset", "description": " dataset to sample from"}]}},
{"id": "torch.utils.data.RandomSampler", "type": "class", "code": "torch.utils.data.RandomSampler(data_source,replacement=False,num_samples=None)", "example": "NA", "summary": "Samples elements randomly", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.RandomSampler", "parameters": [{"name": "data_source", "is_optional": false, "type": "Dataset", "description": " dataset to sample from"}, {"name": "replacement", "is_optional": true, "type": "bool", "default_value": "False", "description": " samples are drawn with replacement if True, default=``False``"}, {"name": "num_samples", "is_optional": true, "type": "int", "default_value": "None", "description": " number of samples to draw, default=`len(dataset`. This argumentis supposed to be specified only when replacement is True."}]}},
{"id": "torch.utils.data.SubsetRandomSampler", "type": "class", "code": "torch.utils.data.SubsetRandomSampler(indices)", "example": "NA", "summary": "Samples elements randomly from a given list of indices, without replacement", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.SubsetRandomSampler", "parameters": [{"name": "indices", "is_optional": false, "type": "sequence", "description": " a sequence of indices"}]}},
{"id": "NA", "type": "function", "code": "NA(new_state)", "example": "NA", "summary": "Sets the random number generator state", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "new_state", "is_optional": false, "type": "torch.ByteTensor", "description": " The desired state"}]}},
{"id": "NA", "type": "function", "code": "NA(seed)", "example": "NA", "summary": "Sets the seed for generating random numbers", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": " The desired seed."}]}},
{"id": "NA", "type": "function", "code": "NA()", "example": "NA", "summary": "Sets the seed for generating random numbers to a non-deterministic random number", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA()", "example": "NA", "summary": "Returns the initial seed for generating random numbers as a Python long", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(devices=None,enabled=True,_caller='fork_rng',_devices_kw='devices')", "example": "NA", "summary": "Forks the RNG, so that when you return, the RNG is reset to the state that it was previously in", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "devices", "is_optional": true, "type": "iterable of CUDA IDs", "default_value": "None", "description": " CUDA devices for which to forkthe RNG.  CPU RNG state is always forked.  By default, fork_rng( operateson all devices, but will emit a warning if your machine has a lotof devices, since this function will run very slowly in that case.If you explicitly specify devices, this warning will be suppressed"}, {"name": "enabled", "is_optional": true, "type": "bool", "default_value": "True", "description": " if False, the RNG is not forked.  This is a convenienceargument for easily disabling the context manager without havingto delete it and unindent your Python code under it."}, {"name": "_caller", "is_optional": true, "type": "string", "default_value": "'fork_rng'", "description": ""}, {"name": "_devices_kw", "is_optional": true, "type": "string", "default_value": "'devices'", "description": ""}]}},
{"id": "torch.distributed.rpc.remote", "type": "function", "code": "torch.distributed.rpc.remote(to,func,args=None,kwargs=None)", "example": " On worker 0:  import torch.distributed.rpc as rpc  rpc.init_rpc(\"worker0\", rank=0, world_size=2)  rref1 = rpc.remote(\"worker1\", torch.add, args=(torch.ones(2), 3))  rref2 = rpc.remote(\"worker1\", torch.add, args=(torch.ones(2), 1))  x = rref1.to_here() + rref2.to_here()  rpc.shutdown()  On worker 1:  import torch.distributed.rpc as rpc  rpc.init_rpc(\"worker1\", rank=1, world_size=2)  rpc.shutdown()   ", "summary": "Make a remote call to run func on worker to and return an RRef to the result value immediately", "returns": "A user RRef instance to the resultvalue. Use the blocking API torch.distributed.rpc.RRef.to_here()to retrieve the result value locally.", "shape": "NA", "code-info": {"name": "torch.distributed.rpc.remote", "parameters": [{"name": "to", "is_optional": false, "type": "str or WorkerInfo", "description": " id or name of the destination worker."}, {"name": "func", "is_optional": false, "type": "callable", "description": " builtin functions (like torch.add(."}, {"name": "args", "is_optional": true, "type": "tuple", "default_value": "None", "description": " the argument tuple for the func invocation."}, {"name": "kwargs", "is_optional": true, "type": "dict", "default_value": "None", "description": " is a dictionary of keyword arguments for the funcinvocation."}]}},
{"id": "torch.distributed.rpc.get_worker_info", "type": "function", "code": "torch.distributed.rpc.get_worker_info(worker_name=None)", "example": "NA", "summary": "Get WorkerInfo of a given worker name", "returns": "WorkerInfo instance for the givenworker_name or WorkerInfo of thecurrent worker if worker_name is None.", "shape": "NA", "code-info": {"name": "torch.distributed.rpc.get_worker_info", "parameters": [{"name": "worker_name", "is_optional": true, "type": "str", "default_value": "None", "description": " the string name of a worker. If None, return thethe id of the current worker. (default None"}]}},
{"id": "torch.distributed.rpc.shutdown", "type": "function", "code": "torch.distributed.rpc.shutdown(graceful=True)", "example": " On worker 0:  import torch.distributed.rpc as rpc  rpc.init_rpc(\"worker0\", rank=0, world_size=2)  # do some work  result = rpc.rpc_sync(\"worker1\", torch.add, args=(torch.ones(1), 1))  # ready to shutdown  rpc.shutdown()  On worker 1:  import torch.distributed.rpc as rpc  rpc.init_rpc(\"worker1\", rank=1, world_size=2)  # wait for worker 0 to finish work, and then shutdown.  rpc.shutdown()   ", "summary": "Perform a shutdown of the RPC agent, and then destroy the RPC agent", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.rpc.shutdown", "parameters": [{"name": "graceful", "is_optional": true, "type": "bool", "default_value": "True", "description": " Whether to do a graceful shutdown or not. If True,this will block until all local and remote RPCprocesses have reached this method and wait for alloutstanding work to complete."}]}},
{"id": "torch.FloatStorage.resize_", "type": "method", "code": "torch.FloatStorage.resize_()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.resize_", "parameters": []}},
{"id": "torch.FloatStorage.share_memory_", "type": "method", "code": "torch.FloatStorage.share_memory_()", "example": "NA", "summary": "Moves the storage to shared memory", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.share_memory_", "parameters": []}},
{"id": "torch.FloatStorage.short", "type": "method", "code": "torch.FloatStorage.short()", "example": "NA", "summary": "Casts this storage to short type ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.short", "parameters": []}},
{"id": "torch.FloatStorage.size", "type": "method", "code": "torch.FloatStorage.size()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.size", "parameters": []}},
{"id": "torch.FloatStorage.tolist", "type": "method", "code": "torch.FloatStorage.tolist()", "example": "NA", "summary": "Returns a list containing the elements of this storage ", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.tolist", "parameters": []}},
{"id": "torch.FloatStorage.type", "type": "method", "code": "torch.FloatStorage.type(dtype=None,non_blocking=False,**kwargs)", "example": "NA", "summary": "Returns the type if dtype is not provided, else casts this object to the specified type", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.type", "parameters": [{"name": "dtype", "is_optional": true, "type": "type or string", "default_value": "None", "description": " The desired type"}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, and the source is in pinned memoryand destination is on the GPU or vice versa, the copy is performedasynchronously with respect to the host. Otherwise, the argumenthas no effect."}, {"name": "**kwargs", "is_optional": false, "type": "**kwargs : For compatibility, may contain the key async in place ofthe non_blocking argument. The async arg is deprecated", "description": " For compatibility, may contain the key async in place ofthe non_blocking argument. The async arg is deprecated."}]}},
{"id": "torch.quantization.quantize_dynamic", "type": "function", "code": "torch.quantization.quantize_dynamic(model,qconfig_spec=None,dtype=torch.qint8,mapping=None,inplace=False)", "example": "NA", "summary": "Converts a float model to dynamic (i.e", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.quantize_dynamic", "parameters": [{"name": "model", "is_optional": false, "type": "module : input mode", "description": ""}, {"name": "qconfig_spec", "is_optional": true, "type": "when thesubmodule already has qconfig attribute", "default_value": "None", "description": " Either"}, {"name": "dtype", "is_optional": true, "type": "when thesubmodule already has qconfig attribute", "default_value": "torch.qint8", "description": ""}, {"name": "mapping", "is_optional": true, "type": "mapping : maps type of a submodule to a type of corresponding dynamically quantized versionwith which the submodule needs to be replace", "default_value": "None", "description": " maps type of a submodule to a type of corresponding dynamically quantized versionwith which the submodule needs to be replaced"}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " carry out model transformations in-place, the original module is mutated"}]}},
{"id": "torch.quantization.quantize_qat", "type": "function", "code": "torch.quantization.quantize_qat(model,run_fn,run_args,inplace=False)", "example": "NA", "summary": "Do quantization aware training and output a quantized model  Parameters  model \u2013 input model run_fn \u2013 a function for evaluating the prepared model, can be a function that simply runs the prepared model or a training loop run_args \u2013 positional arguments for run_fn   Returns Quantized model", "returns": "Quantized model.", "shape": "NA", "code-info": {"name": "torch.quantization.quantize_qat", "parameters": [{"name": "model", "is_optional": false, "type": "model : input mode", "description": " input model"}, {"name": "run_fn", "is_optional": false, "type": "run_fn : a function for evaluating the prepared model, can be afunction that simply runs the prepared model or a trainingloo", "description": " a function for evaluating the prepared model, can be afunction that simply runs the prepared model or a trainingloop"}, {"name": "run_args", "is_optional": false, "type": "run_args : positional arguments for run_f", "description": " positional arguments for run_fn"}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.quantization.prepare", "type": "function", "code": "torch.quantization.prepare(model,qconfig_dict=None,inplace=False)", "example": "NA", "summary": "Prepares a copy of the model for quantization calibration or quantization-aware training", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.prepare", "parameters": [{"name": "model", "is_optional": false, "type": "model : input model to be modified in-plac", "description": " input model to be modified in-place"}, {"name": "qconfig_dict", "is_optional": true, "type": "when thesubmodule already has qconfig attribute", "default_value": "None", "description": " dictionary that maps from name or type of submodule to quantizationconfiguration, qconfig applies to all submodules of a givenmodule unless qconfig for the submodules are specified (when thesubmodule already has qconfig attribute"}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " carry out model transformations in-place, the original module is mutated"}]}},
{"id": "torch.quantization.prepare_qat", "type": "function", "code": "torch.quantization.prepare_qat(model,mapping=None,inplace=False)", "example": "NA", "summary": "Prepares a copy of the model for quantization calibration or quantization-aware training and convers it to quantized version", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.prepare_qat", "parameters": [{"name": "model", "is_optional": false, "type": "model : input model to be modified in-plac", "description": " input model to be modified in-place"}, {"name": "mapping", "is_optional": true, "type": "mapping : dictionary that maps float modules to quantized modules to bereplaced", "default_value": "None", "description": " dictionary that maps float modules to quantized modules to bereplaced."}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " carry out model transformations in-place, the original moduleis mutated"}]}},
{"id": "torch.quantization.convert", "type": "function", "code": "torch.quantization.convert(module,mapping=None,inplace=False)", "example": "NA", "summary": "Converts the float module with observers (where we can get quantization parameters) to a quantized module", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.convert", "parameters": [{"name": "module", "is_optional": false, "type": "module : calibrated module with observer", "description": " calibrated module with observers"}, {"name": "mapping", "is_optional": true, "type": "mapping : a dictionary that maps from float module type to quantizedmodule type, can be overwrritten to allow swapping user definedModule", "default_value": "None", "description": " a dictionary that maps from float module type to quantizedmodule type, can be overwrritten to allow swapping user definedModules"}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " carry out model transformations in-place, the original moduleis mutated"}]}},
{"id": "torch.quantization.fuse_modules", "type": "function", "code": "torch.quantization.fuse_modules(model,modules_to_fuse,inplace=False,fuser_func=&lt;functionfuse_known_modules&gt;)", "example": " m = myModel()\n # m is a module containing  the sub-modules below\n modules_to_fuse = [ ['conv1', 'bn1', 'relu1'], ['submodule.conv', 'submodule.relu']]\n fused_m = torch.quantization.fuse_modules(m, modules_to_fuse)\n output = fused_m(input)\n\n m = myModel()\n # Alternately provide a single list of modules to fuse\n modules_to_fuse = ['conv1', 'bn1', 'relu1']\n fused_m = torch.quantization.fuse_modules(m, modules_to_fuse)\n output = fused_m(input)\n\n", "summary": "Fuses a list of modules into a single module Fuses only the following sequence of modules:  conv, bn conv, bn, relu conv, relu linear, relu  All other sequences are left unchanged", "returns": "model with fused modules. A new copy is created if inplace=True.", "shape": "NA", "code-info": {"name": "torch.quantization.fuse_modules", "parameters": [{"name": "model", "is_optional": false, "type": "model : Model containing the modules to be fuse", "description": " Model containing the modules to be fused"}, {"name": "modules_to_fuse", "is_optional": false, "type": "modules_to_fuse : list of list of module names to fuse. Can also be a listof strings if there is only a single list of modules to fuse", "description": " list of list of module names to fuse. Can also be a listof strings if there is only a single list of modules to fuse."}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " bool specifying if fusion happens in place on the model, by defaulta new model is returned"}, {"name": "fuser_func", "is_optional": true, "type": "[convModule, BNModule]", "default_value": "&lt;functionfuse_known_modules&gt;", "description": " Function that takes in a list of modules and outputs a list of fused modulesof the same length. For example,fuser_func([convModule, BNModule] returns the list [ConvBNModule, nn.Identity(]Defaults to torch.quantization.fuse_known_modules"}]}},
{"id": "torch.quantization.add_quant_dequant", "type": "function", "code": "torch.quantization.add_quant_dequant(module)", "example": "NA", "summary": "Wrap the leaf child module in QuantWrapper if it has a valid qconfig Note that this function will modify the children of module inplace and it can return a new module which wraps the input module as well", "returns": "Either the inplace modified module with submodules wrapped inQuantWrapper based on qconfig or a new QuantWrapper module whichwraps the input module, the latter case only happens when the inputmodule is a leaf module and we want to quantize it.", "shape": "NA", "code-info": {"name": "torch.quantization.add_quant_dequant", "parameters": [{"name": "module", "is_optional": false, "type": "module : input module with qconfig attributes for all the leaf module", "description": " input module with qconfig attributes for all the leaf modules"}]}},
{"id": "torch.optim.Optimizer.load_state_dict", "type": "method", "code": "torch.optim.Optimizer.load_state_dict(state_dict)", "example": "NA", "summary": "Loads the optimizer state", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Optimizer.load_state_dict", "parameters": [{"name": "state_dict", "is_optional": false, "type": "dict", "description": " optimizer state. Should be an object returnedfrom a call to state_dict(."}]}},
{"id": "torch.optim.Optimizer.state_dict", "type": "method", "code": "torch.optim.Optimizer.state_dict()", "example": "NA", "summary": "Returns the state of the optimizer as a dict", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Optimizer.state_dict", "parameters": []}},
{"id": "torch.optim.Optimizer.step", "type": "method", "code": "torch.optim.Optimizer.step(closure)", "example": "NA", "summary": "Performs a single optimization step (parameter update)", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Optimizer.step", "parameters": [{"name": "closure", "is_optional": false, "type": "callable", "description": " A closure that reevaluates the model andreturns the loss. Optional for most optimizers."}]}},
{"id": "torch.optim.Optimizer.zero_grad", "type": "method", "code": "torch.optim.Optimizer.zero_grad()", "example": "NA", "summary": "Clears the gradients of all optimized torch.Tensor s", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Optimizer.zero_grad", "parameters": []}},
{"id": "torch.optim.Adadelta.step", "type": "method", "code": "torch.optim.Adadelta.step(closure=None)", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Adadelta.step", "parameters": [{"name": "closure", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A closure that reevaluates the modeland returns the loss."}]}},
{"id": "torch.optim.Adagrad.step", "type": "method", "code": "torch.optim.Adagrad.step(closure=None)", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Adagrad.step", "parameters": [{"name": "closure", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A closure that reevaluates the modeland returns the loss."}]}},
{"id": "torch.optim.Adam.step", "type": "method", "code": "torch.optim.Adam.step(closure=None)", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Adam.step", "parameters": [{"name": "closure", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A closure that reevaluates the modeland returns the loss."}]}},
{"id": "torch.optim.AdamW.step", "type": "method", "code": "torch.optim.AdamW.step(closure=None)", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.AdamW.step", "parameters": [{"name": "closure", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A closure that reevaluates the modeland returns the loss."}]}},
{"id": "torch.onnx.register_custom_op_symbolic", "type": "function", "code": "torch.onnx.register_custom_op_symbolic(symbolic_name,symbolic_fn,opset_version)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.onnx.register_custom_op_symbolic", "parameters": [{"name": "symbolic_name", "is_optional": false, "type": "others", "description": ""}, {"name": "symbolic_fn", "is_optional": false, "type": "others", "description": ""}, {"name": "opset_version", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.onnx.operators.shape_as_tensor", "type": "function", "code": "torch.onnx.operators.shape_as_tensor(x)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.onnx.operators.shape_as_tensor", "parameters": [{"name": "x", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.onnx.set_training", "type": "function", "code": "torch.onnx.set_training(model,mode)", "example": "NA", "summary": "A context manager to temporarily set the training mode of \u2018model\u2019 to \u2018mode\u2019, resetting it when we exit the with-block", "returns": null, "shape": "NA", "code-info": {"name": "torch.onnx.set_training", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "mode", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.onnx.is_in_onnx_export", "type": "function", "code": "torch.onnx.is_in_onnx_export()", "example": "NA", "summary": "Check whether it\u2019s in the middle of the ONNX export", "returns": null, "shape": "NA", "code-info": {"name": "torch.onnx.is_in_onnx_export", "parameters": []}},
{"id": "torchvision.datasets.LSUN", "type": "class", "code": "torchvision.datasets.LSUN(root,classes='train',transform=None,target_transform=None)", "example": "NA", "summary": "LSUN dataset", "returns": "Tuple (image, target) where target is the index of the target category.", "shape": "NA", "code-info": {"name": "torchvision.datasets.LSUN", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory for the database files."}, {"name": "classes", "is_optional": true, "type": "string", "default_value": "'train'", "description": " One of {\u2018train\u2019, \u2018val\u2019, \u2018test\u2019} or a list ofcategories to load. e,g. [\u2018bedroom_train\u2019, \u2018church_train\u2019]."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}]}},
{"id": "torchvision.datasets.ImageFolder", "type": "class", "code": "torchvision.datasets.ImageFolder(root,transform=None,target_transform=None,loader=&lt;functiondefault_loader&gt;,is_valid_file=None)", "example": "NA", "summary": "A generic data loader where the images are arranged in this way: root/dog/xxx.png root/dog/xxy.png root/dog/xxz.png  root/cat/123.png root/cat/nsdf3.png root/cat/asd932_.png    Parameters  root (string) \u2013 Root directory path", "returns": "(sample, target) where target is class_index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.ImageFolder", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory path."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "loader", "is_optional": true, "type": "callable, optional", "default_value": "&lt;functiondefault_loader&gt;", "description": " A function to load an image given its path."}, {"name": "is_valid_file", "is_optional": true, "type": "used to check of corrupt files", "default_value": "None", "description": " A function that takes path of an Image fileand check if the file is a valid file (used to check of corrupt files"}]}},
{"id": "torchvision.datasets.DatasetFolder", "type": "class", "code": "torchvision.datasets.DatasetFolder(root,loader,extensions=None,transform=None,target_transform=None,is_valid_file=None)", "example": "NA", "summary": "A generic data loader where the samples are arranged in this way: root/class_x/xxx.ext root/class_x/xxy.ext root/class_x/xxz.ext  root/class_y/123.ext root/class_y/nsdf3.ext root/class_y/asd932_.ext    Parameters  root (string) \u2013 Root directory path", "returns": "(sample, target) where target is class_index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.DatasetFolder", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory path."}, {"name": "loader", "is_optional": false, "type": "callable", "description": " A function to load a sample given its path."}, {"name": "extensions", "is_optional": true, "type": "tuple[string]", "default_value": "None", "description": " A list of allowed extensions.both extensions and is_valid_file should not be passed."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes ina sample and returns a transformed version.E.g, transforms.RandomCrop for images."}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takesin the target and transforms it."}, {"name": "is_valid_file", "is_optional": true, "type": "tuple[string]", "default_value": "None", "description": " A function that takes path of a fileand check if the file is a valid file (used to check of corrupt filesboth extensions and is_valid_file should not be passed."}]}},
{"id": "torchvision.datasets.ImageNet", "type": "class", "code": "torchvision.datasets.ImageNet(root,split='train',download=None,**kwargs)", "example": "NA", "summary": "ImageNet 2012 Classification Dataset", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.datasets.ImageNet", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of the ImageNet Dataset."}, {"name": "split", "is_optional": true, "type": "string", "default_value": "'train'", "description": " The dataset split, supports train, or val."}, {"name": "download", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.sparse.FloatTensor.add", "type": "method", "code": "torch.sparse.FloatTensor.add()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.add", "parameters": []}},
{"id": "torch.sparse.FloatTensor.add_", "type": "method", "code": "torch.sparse.FloatTensor.add_()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.add_", "parameters": []}},
{"id": "torch.sparse.FloatTensor.clone", "type": "method", "code": "torch.sparse.FloatTensor.clone()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.clone", "parameters": []}},
{"id": "torch.sparse.FloatTensor.dim", "type": "method", "code": "torch.sparse.FloatTensor.dim()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.dim", "parameters": []}},
{"id": "torch.sparse.FloatTensor.div", "type": "method", "code": "torch.sparse.FloatTensor.div()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.div", "parameters": []}},
{"id": "torch.sparse.FloatTensor.div_", "type": "method", "code": "torch.sparse.FloatTensor.div_()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.div_", "parameters": []}},
{"id": "torch.sparse.FloatTensor.get_device", "type": "method", "code": "torch.sparse.FloatTensor.get_device()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.get_device", "parameters": []}},
{"id": "torch.sparse.FloatTensor.hspmm", "type": "method", "code": "torch.sparse.FloatTensor.hspmm()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.hspmm", "parameters": []}},
{"id": "torch.sparse.FloatTensor.mm", "type": "method", "code": "torch.sparse.FloatTensor.mm()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.mm", "parameters": []}},
{"id": "torch.sparse.FloatTensor.mul", "type": "method", "code": "torch.sparse.FloatTensor.mul()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.mul", "parameters": []}},
{"id": "torch.sparse.FloatTensor.mul_", "type": "method", "code": "torch.sparse.FloatTensor.mul_()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.mul_", "parameters": []}},
{"id": "torchvision.models.mnasnet0_5", "type": "function", "code": "torchvision.models.mnasnet0_5(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "MNASNet with depth multiplier of 0.5 from \u201cMnasNet: Platform-Aware Neural Architecture Search for Mobile\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.mnasnet0_5", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.mnasnet0_75", "type": "function", "code": "torchvision.models.mnasnet0_75(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "MNASNet with depth multiplier of 0.75 from \u201cMnasNet: Platform-Aware Neural Architecture Search for Mobile\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.mnasnet0_75", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.mnasnet1_0", "type": "function", "code": "torchvision.models.mnasnet1_0(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "MNASNet with depth multiplier of 1.0 from \u201cMnasNet: Platform-Aware Neural Architecture Search for Mobile\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.mnasnet1_0", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.mnasnet1_3", "type": "function", "code": "torchvision.models.mnasnet1_3(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "MNASNet with depth multiplier of 1.3 from \u201cMnasNet: Platform-Aware Neural Architecture Search for Mobile\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.mnasnet1_3", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.segmentation.fcn_resnet50", "type": "function", "code": "torchvision.models.segmentation.fcn_resnet50(pretrained=False,progress=True,num_classes=21,aux_loss=None,**kwargs)", "example": "NA", "summary": "Constructs a Fully-Convolutional Network model with a ResNet-50 backbone", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.segmentation.fcn_resnet50", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on COCO train2017 whichcontains the same classes as Pascal VOC"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "21", "description": ""}, {"name": "aux_loss", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.segmentation.fcn_resnet101", "type": "function", "code": "torchvision.models.segmentation.fcn_resnet101(pretrained=False,progress=True,num_classes=21,aux_loss=None,**kwargs)", "example": "NA", "summary": "Constructs a Fully-Convolutional Network model with a ResNet-101 backbone", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.segmentation.fcn_resnet101", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on COCO train2017 whichcontains the same classes as Pascal VOC"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "21", "description": ""}, {"name": "aux_loss", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.segmentation.deeplabv3_resnet50", "type": "function", "code": "torchvision.models.segmentation.deeplabv3_resnet50(pretrained=False,progress=True,num_classes=21,aux_loss=None,**kwargs)", "example": "NA", "summary": "Constructs a DeepLabV3 model with a ResNet-50 backbone", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.segmentation.deeplabv3_resnet50", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on COCO train2017 whichcontains the same classes as Pascal VOC"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "21", "description": ""}, {"name": "aux_loss", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.functional.to_pil_image", "type": "function", "code": "torchvision.transforms.functional.to_pil_image(pic,mode=None)", "example": "NA", "summary": "Convert a tensor or an ndarray to PIL Image", "returns": "Image converted to PIL Image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.to_pil_image", "parameters": [{"name": "pic", "is_optional": false, "type": "Tensor or numpy.ndarray", "description": " Image to be converted to PIL Image."}, {"name": "mode", "is_optional": true, "type": "PIL.Image mode", "default_value": "None", "description": " color space and pixel depth of input data (optional."}]}},
{"id": "torchvision.transforms.functional.to_tensor", "type": "function", "code": "torchvision.transforms.functional.to_tensor(pic)", "example": "NA", "summary": "Convert a PIL Image or numpy.ndarray to tensor", "returns": "Converted image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.to_tensor", "parameters": [{"name": "pic", "is_optional": false, "type": "PIL Image or numpy.ndarray", "description": " Image to be converted to tensor."}]}},
{"id": "torchvision.transforms.functional.vflip", "type": "function", "code": "torchvision.transforms.functional.vflip(img)", "example": "NA", "summary": "Vertically flip the given PIL Image", "returns": "Vertically flipped image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.functional.vflip", "parameters": [{"name": "img", "is_optional": false, "type": "PIL Image", "description": " Image to be flipped."}]}},
{"id": "torchvision.transforms.Normalize.__call__", "type": "method", "code": "torchvision.transforms.Normalize.__call__(tensor)", "example": "NA", "summary": " Parameters tensor (Tensor) \u2013 Tensor image of size (C, H, W) to be normalized", "returns": "Normalized Tensor image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.Normalize.__call__", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " Tensor image of size (C, H, W to be normalized."}]}},
{"id": "torchvision.transforms.ToPILImage.__call__", "type": "method", "code": "torchvision.transforms.ToPILImage.__call__(pic)", "example": "NA", "summary": " Parameters pic (Tensor or numpy.ndarray) \u2013 Image to be converted to PIL Image", "returns": "Image converted to PIL Image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.ToPILImage.__call__", "parameters": [{"name": "pic", "is_optional": false, "type": "Tensor or numpy.ndarray", "description": " Image to be converted to PIL Image."}]}},
{"id": "torch.hub.list", "type": "function", "code": "torch.hub.list(github,force_reload=False)", "example": " \u2018pytorch/vision[:hub]\u2019 force_reload (bool, optional) \u2013 whether to discard the existing cache and force a fresh download. Default is False.   Returns a list of available entrypoint names  Return type entrypoints   Example  entrypoints = torch.hub.list('pytorch/vision', force_reload=True)   ", "summary": "List all entrypoints available in github hubconf", "returns": "a list of available entrypoint names", "shape": "NA", "code-info": {"name": "torch.hub.list", "parameters": [{"name": "github", "is_optional": false, "type": "string", "description": " a string with format \u201crepo_owner/repo_name["}, {"name": "force_reload", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether to discard the existing cache and force a fresh download.Default is False."}]}},
{"id": "torch.hub.help", "type": "function", "code": "torch.hub.help(github,model,force_reload=False)", "example": " \u2018pytorch/vision[:hub]\u2019 model (string) \u2013 a string of entrypoint name defined in repo\u2019s hubconf.py force_reload (bool, optional) \u2013 whether to discard the existing cache and force a fresh download. Default is False.    Example  print(torch.hub.help('pytorch/vision', 'resnet18', force_reload=True))   ", "summary": "Show the docstring of entrypoint model", "returns": null, "shape": "NA", "code-info": {"name": "torch.hub.help", "parameters": [{"name": "github", "is_optional": false, "type": "string", "description": " a string with format &lt;repo_owner/repo_name["}, {"name": "model", "is_optional": false, "type": "string", "description": " a string of entrypoint name defined in repo\u2019s hubconf.py"}, {"name": "force_reload", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether to discard the existing cache and force a fresh download.Default is False."}]}},
{"id": "torch.hub.load", "type": "function", "code": "torch.hub.load(github,model,*args,**kwargs)", "example": " \u2018pytorch/vision[:hub]\u2019 model (string) \u2013 a string of entrypoint name defined in repo\u2019s hubconf.py *args (optional) \u2013 the corresponding args for callable model. force_reload (bool, optional) \u2013 whether to force a fresh download of github repo unconditionally. Default is False. verbose (bool, optional) \u2013 If False, mute messages about hitting local caches. Note that the message about first download is cannot be muted. Default is True. **kwargs (optional) \u2013 the corresponding kwargs for callable model.   Returns a single model with corresponding pretrained weights.   Example  model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)   ", "summary": "Load a model from a github repo, with pretrained weights", "returns": "a single model with corresponding pretrained weights.", "shape": "NA", "code-info": {"name": "torch.hub.load", "parameters": [{"name": "github", "is_optional": false, "type": "string", "description": " a string with format \u201crepo_owner/repo_name["}, {"name": "model", "is_optional": false, "type": "string", "description": " a string of entrypoint name defined in repo\u2019s hubconf.py"}, {"name": "*args", "is_optional": false, "type": "optional", "description": " the corresponding args for callable model."}, {"name": "**kwargs", "is_optional": false, "type": "optional", "description": " the corresponding kwargs for callable model."}]}},
{"id": "torch.distributions.kl.kl_divergence", "type": "function", "code": "torch.distributions.kl.kl_divergence(p,q)", "example": "NA", "summary": "Compute Kullback-Leibler divergence KL(p\u2225q)KL(p \\| q)KL(p\u2225q)   between two distributions", "returns": "A batch of KL divergences of shape batch_shape.", "shape": "NA", "code-info": {"name": "torch.distributions.kl.kl_divergence", "parameters": [{"name": "p", "is_optional": false, "type": "Distribution", "description": " A Distribution object."}, {"name": "q", "is_optional": false, "type": "Distribution", "description": " A Distribution object."}]}},
{"id": "torch.nn.init.normal_", "type": "function", "code": "torch.nn.init.normal_(tensor,mean=0.0,std=1.0)", "example": " w = torch.empty(3, 5)\n nn.init.normal_(w)\n\n", "summary": "Fills the input Tensor with values drawn from the normal distribution N(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2)  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.normal_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : an n-dimensional torch.Tenso", "description": " an n-dimensional torch.Tensor"}, {"name": "mean", "is_optional": true, "type": "mean : the mean of the normal distributio", "default_value": "0.0", "description": " the mean of the normal distribution"}, {"name": "std", "is_optional": true, "type": "std : the standard deviation of the normal distributio", "default_value": "1.0", "description": " the standard deviation of the normal distribution"}]}},
{"id": "torch.nn.init.constant_", "type": "function", "code": "torch.nn.init.constant_(tensor,val)", "example": " w = torch.empty(3, 5)\n nn.init.constant_(w, 0.3)\n\n", "summary": "Fills the input Tensor with the value val\\text{val}val  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.constant_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : an n-dimensional torch.Tenso", "description": " an n-dimensional torch.Tensor"}, {"name": "val", "is_optional": false, "type": "val : the value to fill the tensor wit", "description": " the value to fill the tensor with"}]}},
{"id": "torch.nn.init.ones_", "type": "function", "code": "torch.nn.init.ones_(tensor)", "example": " w = torch.empty(3, 5)\n nn.init.ones_(w)\n\n", "summary": "Fills the input Tensor with the scalar value 1", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.ones_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : an n-dimensional torch.Tenso", "description": " an n-dimensional torch.Tensor"}]}},
{"id": "torch.nn.init.zeros_", "type": "function", "code": "torch.nn.init.zeros_(tensor)", "example": " w = torch.empty(3, 5)\n nn.init.zeros_(w)\n\n", "summary": "Fills the input Tensor with the scalar value 0", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.zeros_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : an n-dimensional torch.Tenso", "description": " an n-dimensional torch.Tensor"}]}},
{"id": "torch.nn.init.eye_", "type": "function", "code": "torch.nn.init.eye_(tensor)", "example": " w = torch.empty(3, 5)\n nn.init.eye_(w)\n\n", "summary": "Fills the 2-dimensional input Tensor with the identity matrix", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.eye_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : a 2-dimensional torch.Tenso", "description": " a 2-dimensional torch.Tensor"}]}},
{"id": "torch.nn.init.dirac_", "type": "function", "code": "torch.nn.init.dirac_(tensor)", "example": " w = torch.empty(3, 16, 5, 5)\n nn.init.dirac_(w)\n\n", "summary": "Fills the {3, 4, 5}-dimensional input Tensor with the Dirac delta function", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.dirac_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : a {3, 4, 5}-dimensional torch.Tenso", "description": " a {3, 4, 5}-dimensional torch.Tensor"}]}},
{"id": "torch.nn.init.xavier_uniform_", "type": "function", "code": "torch.nn.init.xavier_uniform_(tensor,gain=1.0)", "example": " w = torch.empty(3, 5)\n nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu'))\n\n", "summary": "Fills the input Tensor with values according to the method described in Understanding the difficulty of training deep feedforward neural networks - Glorot, X", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.xavier_uniform_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : an n-dimensional torch.Tenso", "description": " an n-dimensional torch.Tensor"}, {"name": "gain", "is_optional": true, "type": "gain : an optional scaling facto", "default_value": "1.0", "description": " an optional scaling factor"}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_text", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_text(tag,text_string,global_step=None,walltime=None)", "example": "writer.add_text('lstm', 'This is an lstm', 0)\nwriter.add_text('rnn', 'This is an rnn', 10)\n\n", "summary": "Add text data to summary", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_text", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": " Data identifier"}, {"name": "text_string", "is_optional": false, "type": "string", "description": " String to save"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": " Optional override default walltime (time.time(seconds after epoch of event"}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_graph", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_graph(model,input_to_model=None,verbose=False)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_graph", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "input_to_model", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "verbose", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_embedding", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_embedding(mat,metadata=None,label_img=None,global_step=None,tag='default',metadata_header=None)", "example": "import keyword\nimport torch\nmeta = []\nwhile len(meta)&lt;100:\n    meta = meta+keyword.kwlist # get some strings\nmeta = meta[:100]\n\nfor i, v in enumerate(meta):\n    meta[i] = v+str(i)\n\nlabel_img = torch.rand(100, 3, 10, 32)\nfor i in range(100):\n    label_img[i]*=i/100.0\n\nwriter.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)\nwriter.add_embedding(torch.randn(100, 5), label_img=label_img)\nwriter.add_embedding(torch.randn(100, 5), metadata=meta)\n\n", "summary": "Add embedding projector data to summary", "returns": null, "shape": "mat: (N,D)(N, D)(N,D)  , where N is number of data and D is feature dimension label_img: (N,C,H,W)(N, C, H, W)(N,C,H,W)   ", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_embedding", "parameters": [{"name": "mat", "is_optional": false, "type": "torch.Tensor or numpy.array", "description": " A matrix which each row is the feature vector of the data point"}, {"name": "metadata", "is_optional": true, "type": "list", "default_value": "None", "description": " A list of labels, each element will be convert to string"}, {"name": "label_img", "is_optional": true, "type": "torch.Tensor", "default_value": "None", "description": " Images correspond to each data point"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "tag", "is_optional": true, "type": "string", "default_value": "'default'", "description": " Name for the embedding"}, {"name": "metadata_header", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve(tag,labels,predictions,global_step=None,num_thresholds=127,weights=None,walltime=None)", "example": "from torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nlabels = np.random.randint(2, size=100)  # binary label\npredictions = np.random.rand(100)\nwriter = SummaryWriter()\nwriter.add_pr_curve('pr_curve', labels, predictions, 0)\nwriter.close()\n\n", "summary": "Adds precision recall curve", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": " Data identifier"}, {"name": "labels", "is_optional": false, "type": "torch.Tensor, numpy.array, or string/blobname", "description": " Ground truth data. Binary label for each element."}, {"name": "predictions", "is_optional": false, "type": "torch.Tensor, numpy.array, or string/blobname", "description": " The probability that an element be classified as true.Value should in [0, 1]"}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "num_thresholds", "is_optional": true, "type": "int", "default_value": "127", "description": " Number of thresholds used to draw the curve."}, {"name": "weights", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": " Optional override default walltime (time.time(seconds after epoch of event"}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars(layout)", "example": "layout = {'Taiwan':{'twse':['Multiline',['twse/0050', 'twse/2330']]},\n             'USA':{ 'dow':['Margin',   ['dow/aaa', 'dow/bbb', 'dow/ccc']],\n                  'nasdaq':['Margin',   ['nasdaq/aaa', 'nasdaq/bbb', 'nasdaq/ccc']]}}\n\nwriter.add_custom_scalars(layout)\n\n", "summary": "Create special chart by collecting charts tags in \u2018scalars\u2019", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars", "parameters": [{"name": "layout", "is_optional": false, "type": "dict", "description": " {categoryName"}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_mesh", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_mesh(tag,vertices,colors=None,faces=None,config_dict=None,global_step=None,walltime=None)", "example": "from torch.utils.tensorboard import SummaryWriter\nvertices_tensor = torch.as_tensor([\n    [1, 1, 1],\n    [-1, -1, 1],\n    [1, -1, -1],\n    [-1, 1, -1],\n], dtype=torch.float).unsqueeze(0)\ncolors_tensor = torch.as_tensor([\n    [255, 0, 0],\n    [0, 255, 0],\n    [0, 0, 255],\n    [255, 0, 255],\n], dtype=torch.int).unsqueeze(0)\nfaces_tensor = torch.as_tensor([\n    [0, 2, 3],\n    [0, 3, 1],\n    [0, 1, 2],\n    [1, 3, 2],\n], dtype=torch.int).unsqueeze(0)\n\nwriter = SummaryWriter()\nwriter.add_mesh('my_mesh', vertices=vertices_tensor, colors=colors_tensor, faces=faces_tensor)\n\nwriter.close()\n\n", "summary": "Add meshes or 3D point clouds to TensorBoard", "returns": null, "shape": "vertices: (B,N,3)(B, N, 3)(B,N,3)  . (batch, number_of_vertices, channels) colors: (B,N,3)(B, N, 3)(B,N,3)  . The values should lie in [0, 255] for type uint8 or [0, 1] for type float. faces: (B,N,3)(B, N, 3)(B,N,3)  . The values should lie in [0, number_of_vertices] for type uint8. ", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_mesh", "parameters": [{"name": "tag", "is_optional": false, "type": "string", "description": " Data identifier"}, {"name": "vertices", "is_optional": false, "type": "torch.Tensor", "description": " List of the 3D coordinates of vertices."}, {"name": "colors", "is_optional": true, "type": "torch.Tensor", "default_value": "None", "description": " Colors for each vertex"}, {"name": "faces", "is_optional": true, "type": "torch.Tensor", "default_value": "None", "description": " Indices of vertices within each triangle. (Optional"}, {"name": "config_dict", "is_optional": true, "type": "config_dict : Dictionary with ThreeJS classes names and configuration", "default_value": "None", "description": " Dictionary with ThreeJS classes names and configuration."}, {"name": "global_step", "is_optional": true, "type": "int", "default_value": "None", "description": " Global step value to record"}, {"name": "walltime", "is_optional": true, "type": "float", "default_value": "None", "description": " Optional override default walltime (time.time(seconds after epoch of event"}]}},
{"id": "torch.distributed.init_process_group", "type": "function", "code": "torch.distributed.init_process_group(backend,init_method=None,timeout=datetime.timedelta(0,1800)", "example": "NA", "summary": "Initializes the default distributed process group, and this will also initialize the distributed package", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.init_process_group", "parameters": [{"name": "backend", "is_optional": false, "type": "str or Backend", "description": " The backend to use. Depending onbuild-time configurations, valid values include mpi, gloo,and nccl. This field should be given as a lowercase string(e.g., \"gloo\", which can also be accessed viaBackend attributes (e.g., Backend.GLOO. If usingmultiple processes per machine with nccl backend, each processmust have exclusive access to every GPU it uses, as sharing GPUsbetween processes can result in deadlocks."}, {"name": "init_method", "is_optional": true, "type": "str, optional", "default_value": "None", "description": " URL specifying how to initialize theprocess group. Default is \u201cenv"}, {"name": "timeout", "is_optional": true, "type": "timedelta, optional", "default_value": "datetime.timedelt", "description": " Timeout for operations executed againstthe process group. Default value equals 30 minutes.This is applicable for the gloo backend. For nccl, this isapplicable only if the environment variable NCCL_BLOCKING_WAITis set to 1."}]}},
{"id": "torch.cuda.current_blas_handle", "type": "function", "code": "torch.cuda.current_blas_handle()", "example": "NA", "summary": "Returns cublasHandle_t pointer to current cuBLAS handle ", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.current_blas_handle", "parameters": []}},
{"id": "torch.cuda.current_device", "type": "function", "code": "torch.cuda.current_device()", "example": "NA", "summary": "Returns the index of a currently selected device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.current_device", "parameters": []}},
{"id": "torch.cuda.current_stream", "type": "function", "code": "torch.cuda.current_stream(device=None)", "example": "NA", "summary": "Returns the currently selected Stream for a given device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.current_stream", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " selected device. Returnsthe currently selected Stream for the current device, givenby current_device(, if device is None(default."}]}},
{"id": "torch.cuda.default_stream", "type": "function", "code": "torch.cuda.default_stream(device=None)", "example": "NA", "summary": "Returns the default Stream for a given device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.default_stream", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " selected device. Returnsthe default Stream for the current device, given bycurrent_device(, if device is None(default."}]}},
{"id": "torch.jit.trace", "type": "function", "code": "torch.jit.trace(func,example_inputs,optimize=None,check_trace=True,check_inputs=None,check_tolerance=1e-5)", "example": "import torch\n\ndef foo(x, y):\n    return 2 * x + y\n\n# Run `foo` with the provided inputs and record the tensor operations\ntraced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))\n\n# `traced_foo` can now be run with the TorchScript interpreter or saved\n# and loaded in a Python-free environment\n\n", "summary": "Trace a function and return an executable  or ScriptFunction that will be optimized using just-in-time compilation", "returns": "If callable is nn.Module or forward of nn.Module, trace returnsa ScriptModule object with a single forward method containing the traced code.The returned ScriptModule will have the same set of sub-modules and parameters as theoriginal nn.Module.If callable is a standalone function, trace returns ScriptFunction", "shape": "NA", "code-info": {"name": "torch.jit.trace", "parameters": [{"name": "func", "is_optional": false, "type": "callable or torch.nn.Module", "description": " A Python function or torch.nn.Modulethat will be run with example_inputs.arguments and returns to func must be tensorsor (possibly nested tuples thatcontain tensors. When a module is passed totorch.jit.trace, only theforward method is run and traced(see torch.jit.trace for details."}, {"name": "example_inputs", "is_optional": false, "type": "callable or torch.nn.Module", "description": " A tuple of example inputs that will be passed to the functionwhile tracing. The resulting trace can be run withinputs of different types and shapes assuming the traced operationssupport those types and shapes. example_inputs may also be a singleTensor in which case it is automatically wrapped in a tuple."}, {"name": "optimize", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "check_trace", "is_optional": true, "type": "bool", "default_value": "True", "description": " Check if the same inputs run throughtraced code produce the same outputs. Default"}, {"name": "check_inputs", "is_optional": true, "type": "list of tuples, optional", "default_value": "None", "description": " A list of tuples of input arguments that should be usedto check the trace against what is expected. Each tupleis equivalent to a set of input arguments that wouldbe specified in example_inputs. For best results, pass in aset of checking inputs representative of the space ofshapes and types of inputs you expect the network to see.If not specified, the original example_inputs are used for checking"}, {"name": "check_tolerance", "is_optional": true, "type": "float, optional", "default_value": "1e-5", "description": " Floating-point comparison tolerance to use in the checker procedure.This can be used to relax the checker strictness in the event thatresults diverge numerically for a known reason, such as operator fusion."}]}},
{"id": "torch.jit.trace_module", "type": "function", "code": "torch.jit.trace_module(mod,inputs,optimize=None,check_trace=True,check_inputs=None,check_tolerance=1e-5)", "example": "import torch\nimport torch.nn as nn\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv = nn.Conv2d(1, 1, 3)\n\n    def forward(self, x):\n        return self.conv(x)\n\n    def weighted_kernel_sum(self, weight):\n        return weight * self.conv.weight\n\n\nn = Net()\nexample_weight = torch.rand(1, 1, 3, 3)\nexample_forward_input = torch.rand(1, 1, 3, 3)\n\n# Trace a specific method and construct `ScriptModule` with\n# a single `forward` method\nmodule = torch.jit.trace(n.forward, example_forward_input)\n\n# Trace a module (implicitly traces `forward`) and construct a\n# `ScriptModule` with a single `forward` method\nmodule = torch.jit.trace(n, example_forward_input)\n\n# Trace specific methods on a module (specified in `inputs`), constructs\n# a `ScriptModule` with `forward` and `weighted_kernel_sum` methods\ninputs = {'forward' : example_forward_input, 'weighted_kernel_sum' : example_weight}\nmodule = torch.jit.trace_module(n, inputs)\n\n", "summary": "Trace a module and return an executable ScriptModule that will be optimized using just-in-time compilation", "returns": "A ScriptModule object with a single forward method containing the traced code.When func is a torch.nn.Module, the returned ScriptModule will have the same set ofsub-modules and parameters as func.", "shape": "NA", "code-info": {"name": "torch.jit.trace_module", "parameters": [{"name": "mod", "is_optional": false, "type": "torch.nn.Module", "description": " A torch.nn.Module containing methods whose names arespecified in example_inputs. The given methods will be compiledas a part of a single ScriptModule."}, {"name": "inputs", "is_optional": false, "type": "torch.nn.Module", "description": ""}, {"name": "optimize", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "check_trace", "is_optional": true, "type": "bool", "default_value": "True", "description": " Check if the same inputs run throughtraced code produce the same outputs. Default"}, {"name": "check_inputs", "is_optional": true, "type": "list of dicts, optional", "default_value": "None", "description": " A list of dicts of input arguments that should be usedto check the trace against what is expected. Each tupleis equivalent to a set of input arguments that wouldbe specified in example_inputs. For best results, pass in aset of checking inputs representative of the space ofshapes and types of inputs you expect the network to see.If not specified, the original example_inputs are used for checking"}, {"name": "check_tolerance", "is_optional": true, "type": "float, optional", "default_value": "1e-5", "description": " Floating-point comparison tolerance to use in the checker procedure.This can be used to relax the checker strictness in the event thatresults diverge numerically for a known reason, such as operator fusion."}]}},
{"id": "torch.autograd.backward", "type": "function", "code": "torch.autograd.backward(tensors,grad_tensors=None,retain_graph=None,create_graph=False,grad_variables=None)", "example": "NA", "summary": "Computes the sum of gradients of given tensors w.r.t", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.backward", "parameters": [{"name": "tensors", "is_optional": false, "type": "sequence of Tensor", "description": " Tensors of which the derivative will becomputed."}, {"name": "grad_tensors", "is_optional": true, "type": "sequence of (Tensor or None", "default_value": "None", "description": " The \u201cvector\u201d in the Jacobian-vectorproduct, usually gradients w.r.t. each element of corresponding tensors.None values can be specified for scalar Tensors or ones that don\u2019t requiregrad. If a None value would be acceptable for all grad_tensors, then thisargument is optional."}, {"name": "retain_graph", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " If False, the graph used to compute the gradwill be freed. Note that in nearly all cases setting this option to Trueis not needed and often can be worked around in a much more efficientway. Defaults to the value of create_graph."}, {"name": "create_graph", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, graph of the derivative willbe constructed, allowing to compute higher order derivative products.Defaults to False."}, {"name": "grad_variables", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.autograd.grad", "type": "function", "code": "torch.autograd.grad(outputs,inputs,grad_outputs=None,retain_graph=None,create_graph=False,only_inputs=True,allow_unused=False)", "example": "NA", "summary": "Computes and returns the sum of gradients of outputs w.r.t", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.grad", "parameters": [{"name": "outputs", "is_optional": false, "type": "sequence of Tensor", "description": " outputs of the differentiated function."}, {"name": "inputs", "is_optional": false, "type": "int", "description": " Inputs w.r.t. which the gradient will bereturned (and not accumulated into .grad."}, {"name": "grad_outputs", "is_optional": true, "type": "sequence of Tensor", "default_value": "None", "description": " The \u201cvector\u201d in the Jacobian-vector product.Usually gradients w.r.t. each output. None values can be specified for scalarTensors or ones that don\u2019t require grad. If a None value would be acceptablefor all grad_tensors, then this argument is optional. Default"}, {"name": "retain_graph", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " If False, the graph used to compute the gradwill be freed. Note that in nearly all cases setting this option to Trueis not needed and often can be worked around in a much more efficientway. Defaults to the value of create_graph."}, {"name": "create_graph", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, graph of the derivative willbe constructed, allowing to compute higher order derivative products.Default"}, {"name": "only_inputs", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "allow_unused", "is_optional": true, "type": "bool", "default_value": "False", "description": " If False, specifying inputs that were notused when computing outputs (and therefore their grad is always zerois an error. Defaults to False."}]}},
{"id": "torch.utils.data.WeightedRandomSampler", "type": "class", "code": "torch.utils.data.WeightedRandomSampler(weights,num_samples,replacement=True)", "example": " list(WeightedRandomSampler([0.1, 0.9, 0.4, 0.7, 3.0, 0.6], 5, replacement=True))\n[0, 0, 0, 1, 0]\n list(WeightedRandomSampler([0.9, 0.4, 0.05, 0.2, 0.3, 0.1], 5, replacement=False))\n[0, 1, 4, 3, 2]\n\n", "summary": "Samples elements from [0,..,len(weights)-1] with given probabilities (weights)", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.WeightedRandomSampler", "parameters": [{"name": "weights", "is_optional": false, "type": "sequence", "description": " a sequence of weights, not necessary summing up to one"}, {"name": "num_samples", "is_optional": false, "type": "int", "description": " number of samples to draw"}, {"name": "replacement", "is_optional": true, "type": "bool", "default_value": "True", "description": " if True, samples are drawn with replacement.If not, they are drawn without replacement, which means that when asample index is drawn for a row, it cannot be drawn again for that row."}]}},
{"id": "torch.utils.data.BatchSampler", "type": "class", "code": "torch.utils.data.BatchSampler(sampler,batch_size,drop_last)", "example": " list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))\n[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))\n[[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n\n", "summary": "Wraps another sampler to yield a mini-batch of indices", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.BatchSampler", "parameters": [{"name": "sampler", "is_optional": false, "type": "Sampler", "description": " Base sampler."}, {"name": "batch_size", "is_optional": false, "type": "int", "description": " Size of mini-batch."}, {"name": "drop_last", "is_optional": false, "type": "bool", "description": " If True, the sampler will drop the last batch ifits size would be less than batch_size"}]}},
{"id": "torch.utils.data.distributed.DistributedSampler", "type": "class", "code": "torch.utils.data.distributed.DistributedSampler(dataset,num_replicas=None,rank=None,shuffle=True)", "example": "NA", "summary": "Sampler that restricts data loading to a subset of the dataset", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.data.distributed.DistributedSampler", "parameters": [{"name": "dataset", "is_optional": false, "type": "dataset : Dataset used for sampling", "description": " Dataset used for sampling."}, {"name": "num_replicas", "is_optional": true, "type": "optional", "default_value": "None", "description": " Number of processes participating indistributed training."}, {"name": "rank", "is_optional": true, "type": "optional", "default_value": "None", "description": " Rank of the current process within num_replicas."}, {"name": "shuffle", "is_optional": true, "type": "bool", "default_value": "True", "description": " If true (default, sampler will shuffle the indices"}]}},
{"id": "torch.torch.dtype", "type": "class", "code": "torch.torch.dtype", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.torch.dtype", "parameters": []}},
{"id": "torch.torch.device", "type": "class", "code": "torch.torch.device", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.torch.device", "parameters": []}},
{"id": "torch.torch.layout", "type": "class", "code": "torch.torch.layout", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.torch.layout", "parameters": []}},
{"id": "torch.distributed.autograd.backward", "type": "function", "code": "torch.distributed.autograd.backward(roots:List[Tensor])", "example": "  import torch.distributed.autograd as dist_autograd  with dist_autograd.context() as context_id:       pred = model.forward()       loss = loss_func(pred, loss)       dist_autograd.backward(loss)   ", "summary": "Kicks off the distributed backward pass using the provided roots", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.autograd.backward", "parameters": [{"name": "roots:List[Tensor]", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributed.autograd.get_gradients", "type": "function", "code": "torch.distributed.autograd.get_gradients(context_id:int)", "example": "  import torch.distributed.autograd as dist_autograd  with dist_autograd.context() as context_id:       t1 = torch.rand((3, 3), requires_grad=True)       t2 = torch.rand((3, 3), requires_grad=True)       loss = t1 + t2       dist_autograd.backward([loss.sum()])       grads = dist_autograd.get_gradients(context_id)       print (grads[t1])       print (grads[t2])   ", "summary": "Retrieves a map from Tensor to the appropriate gradient for that Tensor accumulated in the provided context_id as part of the distributed autograd backward pass", "returns": "A map where the key is the Tensor and the value is the associated gradient for that Tensor.", "shape": "NA", "code-info": {"name": "torch.distributed.autograd.get_gradients", "parameters": [{"name": "context_id:int", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributed.rpc.RRef.is_owner", "type": "method", "code": "torch.distributed.rpc.RRef.is_owner(self:torch.distributed.rpc.RRef)", "example": "NA", "summary": "Returns whether or not the current node is the owner of this RRef", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.rpc.RRef.is_owner", "parameters": [{"name": "self:torch.distributed.rpc.RRef", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributed.rpc.RRef.local_value", "type": "method", "code": "torch.distributed.rpc.RRef.local_value(self:torch.distributed.rpc.RRef)", "example": "NA", "summary": "If the current node is the owner, returns a reference to the local value", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.rpc.RRef.local_value", "parameters": [{"name": "self:torch.distributed.rpc.RRef", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributed.rpc.RRef.owner", "type": "method", "code": "torch.distributed.rpc.RRef.owner(self:torch.distributed.rpc.RRef)", "example": "NA", "summary": "Returns worker information of the node that owns this RRef", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.rpc.RRef.owner", "parameters": [{"name": "self:torch.distributed.rpc.RRef", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributed.rpc.RRef.to_here", "type": "method", "code": "torch.distributed.rpc.RRef.to_here(self:torch.distributed.rpc.RRef)", "example": "NA", "summary": "Blocking call that copies the value of the RRef from the owner to the local node and returns it", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.rpc.RRef.to_here", "parameters": [{"name": "self:torch.distributed.rpc.RRef", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributed.optim.DistributedOptimizer.step", "type": "method", "code": "torch.distributed.optim.DistributedOptimizer.step()", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.optim.DistributedOptimizer.step", "parameters": []}},
{"id": "torch.distributed.rpc.RRef", "type": "class", "code": "torch.distributed.rpc.RRef", "example": "NA", "summary": "A class encapsulating a reference to a value of some type on a remote worker", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.rpc.RRef", "parameters": []}},
{"id": "torch.FloatStorage", "type": "class", "code": "torch.FloatStorage", "example": "NA", "summary": "  bfloat16() Casts this storage to bfloat16 type     bool() Casts this storage to bool type     byte() Casts this storage to byte type     char() Casts this storage to char type     clone() Returns a copy of this storage     copy_()     cpu() Returns a CPU copy of this storage if it\u2019s not already on the CPU     cuda(device=None, non_blocking=False, **kwargs) Returns a copy of this object in CUDA memory", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage", "parameters": []}},
{"id": "torch.FloatStorage.device", "type": "attribute", "code": "torch.FloatStorage.device", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.device", "parameters": []}},
{"id": "torch.FloatStorage.dtype", "type": "attribute", "code": "torch.FloatStorage.dtype", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.dtype", "parameters": []}},
{"id": "torch.FloatStorage.is_cuda", "type": "attribute", "code": "torch.FloatStorage.is_cuda", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.is_cuda", "parameters": []}},
{"id": "torch.FloatStorage.is_sparse", "type": "attribute", "code": "torch.FloatStorage.is_sparse", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.FloatStorage.is_sparse", "parameters": []}},
{"id": "torch.quantization.add_observer_", "type": "function", "code": "torch.quantization.add_observer_(module)", "example": "NA", "summary": "Add observer for the leaf child of the module", "returns": "None, module is modified inplace with added observer modules and forward_hooks", "shape": "NA", "code-info": {"name": "torch.quantization.add_observer_", "parameters": [{"name": "module", "is_optional": false, "type": "module : input module with qconfig attributes for all the leaf modules that we want to quantiz", "description": " input module with qconfig attributes for all the leaf modules that we want to quantize"}]}},
{"id": "torch.quantization.swap_module", "type": "function", "code": "torch.quantization.swap_module(mod,mapping)", "example": "NA", "summary": "Swaps the module if it has a quantized counterpart and it has an observer attached", "returns": "The corresponding quantized module of mod", "shape": "NA", "code-info": {"name": "torch.quantization.swap_module", "parameters": [{"name": "mod", "is_optional": false, "type": "mod : input modul", "description": " input module"}, {"name": "mapping", "is_optional": false, "type": "mapping : a dictionary that maps from nn module to nnq modul", "description": " a dictionary that maps from nn module to nnq module"}]}},
{"id": "torch.quantization.propagate_qconfig_", "type": "function", "code": "torch.quantization.propagate_qconfig_(module,qconfig_dict=None)", "example": "NA", "summary": "Propagate qconfig through the module hierarchy and assign qconfig attribute on each leaf module  Parameters  module \u2013 input module qconfig_dict \u2013 dictionary that maps from name or type of submodule to quantization configuration, qconfig applies to all submodules of a given module unless qconfig for the submodules are specified (when the submodule already has qconfig attribute)   Returns None, module is modified inplace with qconfig attached   ", "returns": "None, module is modified inplace with qconfig attached", "shape": "NA", "code-info": {"name": "torch.quantization.propagate_qconfig_", "parameters": [{"name": "module", "is_optional": false, "type": "module : input modul", "description": " input module"}, {"name": "qconfig_dict", "is_optional": true, "type": "whenthe submodule already has qconfig attribute", "default_value": "None", "description": " dictionary that maps from name or type of submodule toquantization configuration, qconfig applies to all submodules of agiven module unless qconfig for the submodules are specified (whenthe submodule already has qconfig attribute"}]}},
{"id": "torch.quantization.default_eval_fn", "type": "function", "code": "torch.quantization.default_eval_fn(model,calib_data)", "example": "NA", "summary": "Default evaluation function takes a torch.utils.data.Dataset or a list of input Tensors and run the model on the dataset ", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.default_eval_fn", "parameters": [{"name": "model", "is_optional": false, "type": "others", "description": ""}, {"name": "calib_data", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.quantization.get_observer_dict", "type": "function", "code": "torch.quantization.get_observer_dict(mod,target_dict,prefix='')", "example": "NA", "summary": "Traverse the modules and save all observers into dict", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.get_observer_dict", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": ""}, {"name": "target_dict", "is_optional": false, "type": "others", "description": ""}, {"name": "prefix", "is_optional": true, "type": "string", "default_value": "''", "description": ""}]}},
{"id": "torch.nn.quantized.functional.relu", "type": "function", "code": "torch.nn.quantized.functional.relu(input,inplace=False)", "example": "NA", "summary": "Applies the rectified linear unit function element-wise", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.functional.relu", "parameters": [{"name": "input", "is_optional": false, "type": "input : quantized inpu", "description": " quantized input"}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " perform the computation inplace"}]}},
{"id": "torch.nn.quantized.functional.linear", "type": "function", "code": "torch.nn.quantized.functional.linear(input,weight,bias=None,scale=None,zero_point=None)", "example": "NA", "summary": "Applies a linear transformation to the incoming quantized data: y=xAT+by = xA^T + by=xAT+b  ", "returns": null, "shape": " Input: (N,\u2217,in_features)(N, *, in\\_features)(N,\u2217,in_features)   where * means any number of additional dimensions Weight: (out_features,in_features)(out\\_features, in\\_features)(out_features,in_features)   Bias: (out_features)(out\\_features)(out_features)   Output: (N,\u2217,out_features)(N, *, out\\_features)(N,\u2217,out_features)    ", "code-info": {"name": "torch.nn.quantized.functional.linear", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " Quantized input of type torch.quint8"}, {"name": "weight", "is_optional": false, "type": "Tensor", "description": " Quantized weight of type torch.qint8"}, {"name": "bias", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " None or fp32 bias of type torch.float"}, {"name": "scale", "is_optional": true, "type": "double", "default_value": "None", "description": " output scale. If None, derived from the input scale"}, {"name": "zero_point", "is_optional": true, "type": "long", "default_value": "None", "description": " output zero point. If None, derived from the input zero_point"}]}},
{"id": "torch.optim.SparseAdam.step", "type": "method", "code": "torch.optim.SparseAdam.step(closure=None)", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.SparseAdam.step", "parameters": [{"name": "closure", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A closure that reevaluates the modeland returns the loss."}]}},
{"id": "torch.optim.Adamax.step", "type": "method", "code": "torch.optim.Adamax.step(closure=None)", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Adamax.step", "parameters": [{"name": "closure", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A closure that reevaluates the modeland returns the loss."}]}},
{"id": "torch.optim.ASGD.step", "type": "method", "code": "torch.optim.ASGD.step(closure=None)", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.ASGD.step", "parameters": [{"name": "closure", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A closure that reevaluates the modeland returns the loss."}]}},
{"id": "torch.optim.LBFGS.step", "type": "method", "code": "torch.optim.LBFGS.step(closure)", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.LBFGS.step", "parameters": [{"name": "closure", "is_optional": false, "type": "callable", "description": " A closure that reevaluates the modeland returns the loss."}]}},
{"id": "torch.optim.RMSprop.step", "type": "method", "code": "torch.optim.RMSprop.step(closure=None)", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.RMSprop.step", "parameters": [{"name": "closure", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A closure that reevaluates the modeland returns the loss."}]}},
{"id": "torch.optim.Rprop.step", "type": "method", "code": "torch.optim.Rprop.step(closure=None)", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Rprop.step", "parameters": [{"name": "closure", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A closure that reevaluates the modeland returns the loss."}]}},
{"id": "torch.optim.SGD.step", "type": "method", "code": "torch.optim.SGD.step(closure=None)", "example": "NA", "summary": "Performs a single optimization step", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.SGD.step", "parameters": [{"name": "closure", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A closure that reevaluates the modeland returns the loss."}]}},
{"id": "torch.optim.lr_scheduler.LambdaLR.load_state_dict", "type": "method", "code": "torch.optim.lr_scheduler.LambdaLR.load_state_dict(state_dict)", "example": "NA", "summary": "Loads the schedulers state", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.LambdaLR.load_state_dict", "parameters": [{"name": "state_dict", "is_optional": false, "type": "dict", "description": " scheduler state. Should be an object returnedfrom a call to state_dict(."}]}},
{"id": "torchvision.datasets.CIFAR10", "type": "class", "code": "torchvision.datasets.CIFAR10(root,train=True,transform=None,target_transform=None,download=False)", "example": "NA", "summary": "CIFAR10 Dataset", "returns": "(image, target) where target is index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.CIFAR10", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of dataset where directorycifar-10-batches-py exists or will be saved to if download is set to True."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, creates dataset from training set, otherwisecreates from test set."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in an PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": " If true, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again."}]}},
{"id": "torchvision.datasets.CIFAR100", "type": "class", "code": "torchvision.datasets.CIFAR100(root,train=True,transform=None,target_transform=None,download=False)", "example": "NA", "summary": "CIFAR100 Dataset", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.datasets.CIFAR100", "parameters": [{"name": "root", "is_optional": false, "type": "others", "description": ""}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "transform", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "target_transform", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torchvision.datasets.STL10", "type": "class", "code": "torchvision.datasets.STL10(root,split='train',folds=None,transform=None,target_transform=None,download=False)", "example": "NA", "summary": "STL10 Dataset", "returns": "(image, target) where target is index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.STL10", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of dataset where directorystl10_binary exists."}, {"name": "split", "is_optional": true, "type": "string", "default_value": "'train'", "description": " One of {\u2018train\u2019, \u2018test\u2019, \u2018unlabeled\u2019, \u2018train+unlabeled\u2019}.Accordingly dataset is selected."}, {"name": "folds", "is_optional": true, "type": "int, optional", "default_value": "None", "description": " One of {0-9} or None.For training, loads one of the 10 pre-defined folds of 1k samples for thestandard evaluation procedure. If no value is passed, loads the 5k samples."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": " If true, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again."}]}},
{"id": "torchvision.datasets.SVHN", "type": "class", "code": "torchvision.datasets.SVHN(root,split='train',transform=None,target_transform=None,download=False)", "example": "NA", "summary": "SVHN Dataset", "returns": "(image, target) where target is index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.SVHN", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of dataset where directorySVHN exists."}, {"name": "split", "is_optional": true, "type": "string", "default_value": "'train'", "description": " One of {\u2018train\u2019, \u2018test\u2019, \u2018extra\u2019}.Accordingly dataset is selected. \u2018extra\u2019 is Extra training set."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": " If true, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again."}]}},
{"id": "torchvision.datasets.PhotoTour", "type": "class", "code": "torchvision.datasets.PhotoTour(root,name,train=True,transform=None,download=False)", "example": "NA", "summary": "Learning Local Image Descriptors Data Dataset", "returns": "(data1, data2, matches)", "shape": "NA", "code-info": {"name": "torchvision.datasets.PhotoTour", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory where images are."}, {"name": "name", "is_optional": false, "type": "string", "description": " Name of the dataset to load."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": " If true, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again."}]}},
{"id": "NA", "type": "function", "code": "NA(p=0.5,*,generator=None)", "example": "NA", "summary": "Fills each location of self with an independent sample from Bernoulli(p)\\text{Bernoulli}(\\texttt{p})Bernoulli(p)  ", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "p", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.sparse.FloatTensor.narrow_copy", "type": "method", "code": "torch.sparse.FloatTensor.narrow_copy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.narrow_copy", "parameters": []}},
{"id": "torch.sparse.FloatTensor.resizeAs_", "type": "method", "code": "torch.sparse.FloatTensor.resizeAs_()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.resizeAs_", "parameters": []}},
{"id": "torch.sparse.FloatTensor.size", "type": "method", "code": "torch.sparse.FloatTensor.size()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.size", "parameters": []}},
{"id": "torch.sparse.FloatTensor.spadd", "type": "method", "code": "torch.sparse.FloatTensor.spadd()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.spadd", "parameters": []}},
{"id": "torch.sparse.FloatTensor.spmm", "type": "method", "code": "torch.sparse.FloatTensor.spmm()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.spmm", "parameters": []}},
{"id": "torch.sparse.FloatTensor.sspaddmm", "type": "method", "code": "torch.sparse.FloatTensor.sspaddmm()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.sspaddmm", "parameters": []}},
{"id": "torch.sparse.FloatTensor.sspmm", "type": "method", "code": "torch.sparse.FloatTensor.sspmm()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.sspmm", "parameters": []}},
{"id": "torch.sparse.FloatTensor.sub", "type": "method", "code": "torch.sparse.FloatTensor.sub()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.sub", "parameters": []}},
{"id": "torch.sparse.FloatTensor.sub_", "type": "method", "code": "torch.sparse.FloatTensor.sub_()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.sub_", "parameters": []}},
{"id": "torch.sparse.FloatTensor.t_", "type": "method", "code": "torch.sparse.FloatTensor.t_()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.t_", "parameters": []}},
{"id": "torch.sparse.FloatTensor.to_dense", "type": "method", "code": "torch.sparse.FloatTensor.to_dense()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.to_dense", "parameters": []}},
{"id": "torch.sparse.FloatTensor.transpose", "type": "method", "code": "torch.sparse.FloatTensor.transpose()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.transpose", "parameters": []}},
{"id": "torch.nn.functional.conv1d", "type": "function", "code": "torch.nn.functional.conv1d(input,weight,bias=None,stride=1,padding=0,dilation=1,groups=1)", "example": " filters = torch.randn(33, 16, 3)\n inputs = torch.randn(20, 16, 50)\n F.conv1d(inputs, filters)\n\n", "summary": "Applies a 1D convolution over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.conv1d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iW", "description": " input tensor of shape (minibatch,in_channels,iW(\\text{minibatch} , \\text{in\\_channels} , iW(minibatch,in_channels,iW"}, {"name": "weight", "is_optional": false, "type": "out_channels,in_channelsgroups,kW", "description": " filters of shape (out_channels,in_channelsgroups,kW(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kW(out_channels,groupsin_channels\u200b,kW"}, {"name": "bias", "is_optional": true, "type": "out_channels", "default_value": "None", "description": " optional bias of shape (out_channels(\\text{out\\_channels}(out_channels. Default"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": " the stride of the convolving kernel. Can be a single number ora one-element tuple (sW,. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " implicit paddings on both sides of the input. Can be asingle number or a one-element tuple (padW,. Default"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": " the spacing between kernel elements. Can be a single number ora one-element tuple (dW,. Default"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": " split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible bythe number of groups. Default"}]}},
{"id": "torchvision.models.segmentation.deeplabv3_resnet101", "type": "function", "code": "torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False,progress=True,num_classes=21,aux_loss=None,**kwargs)", "example": "NA", "summary": "Constructs a DeepLabV3 model with a ResNet-101 backbone", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.segmentation.deeplabv3_resnet101", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on COCO train2017 whichcontains the same classes as Pascal VOC"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "21", "description": ""}, {"name": "aux_loss", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.detection.fasterrcnn_resnet50_fpn", "type": "function", "code": "torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False,progress=True,num_classes=91,pretrained_backbone=True,**kwargs)", "example": "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)  # For training  images, boxes = torch.rand(4, 3, 600, 1200), torch.rand(4, 11, 4)  labels = torch.randint(1, 91, (4, 11))  images = list(image for image in images)  targets = []  for i in range(len(images)):      d = {}      d['boxes'] = boxes[i]      d['labels'] = labels[i]      targets.append(d)  output = model(images, targets)  # For inference  model.eval()  x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]  predictions = model(x)    Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on COCO train2017 progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "summary": "Constructs a Faster R-CNN model with a ResNet-50-FPN backbone", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.detection.fasterrcnn_resnet50_fpn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on COCO train2017"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "91", "description": ""}, {"name": "pretrained_backbone", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.detection.maskrcnn_resnet50_fpn", "type": "function", "code": "torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=False,progress=True,num_classes=91,pretrained_backbone=True,**kwargs)", "example": "  model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)  model.eval()  x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]  predictions = model(x)    Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on COCO train2017 progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "summary": "Constructs a Mask R-CNN model with a ResNet-50-FPN backbone", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.detection.maskrcnn_resnet50_fpn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on COCO train2017"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "91", "description": ""}, {"name": "pretrained_backbone", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.ToTensor.__call__", "type": "method", "code": "torchvision.transforms.ToTensor.__call__(pic)", "example": "NA", "summary": " Parameters pic (PIL Image or numpy.ndarray) \u2013 Image to be converted to tensor", "returns": "Converted image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.ToTensor.__call__", "parameters": [{"name": "pic", "is_optional": false, "type": "PIL Image or numpy.ndarray", "description": " Image to be converted to tensor."}]}},
{"id": "torchvision.transforms.Compose", "type": "class", "code": "torchvision.transforms.Compose(transforms)", "example": " transforms.Compose([\n     transforms.CenterCrop(10),\n     transforms.ToTensor(),\n ])\n\n", "summary": "Composes several transforms together", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.Compose", "parameters": [{"name": "transforms", "is_optional": false, "type": "list of Transform objects", "description": " list of transforms to compose."}]}},
{"id": "torchvision.transforms.CenterCrop", "type": "class", "code": "torchvision.transforms.CenterCrop(size)", "example": "NA", "summary": "Crops the given PIL Image at the center", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.CenterCrop", "parameters": [{"name": "size", "is_optional": false, "type": "sequence or int", "description": " Desired output size of the crop. If size is anint instead of sequence like (h, w, a square crop (size, size ismade."}]}},
{"id": "torchvision.transforms.ColorJitter", "type": "class", "code": "torchvision.transforms.ColorJitter(brightness=0,contrast=0,saturation=0,hue=0)", "example": "NA", "summary": "Randomly change the brightness, contrast and saturation of an image", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.ColorJitter", "parameters": [{"name": "brightness", "is_optional": true, "type": "int", "default_value": "0", "description": " How much to jitter brightness.brightness_factor is chosen uniformly from [max(0, 1 - brightness, 1 + brightness]or the given [min, max]. Should be non negative numbers."}, {"name": "contrast", "is_optional": true, "type": "int", "default_value": "0", "description": " How much to jitter contrast.contrast_factor is chosen uniformly from [max(0, 1 - contrast, 1 + contrast]or the given [min, max]. Should be non negative numbers."}, {"name": "saturation", "is_optional": true, "type": "int", "default_value": "0", "description": " How much to jitter saturation.saturation_factor is chosen uniformly from [max(0, 1 - saturation, 1 + saturation]or the given [min, max]. Should be non negative numbers."}, {"name": "hue", "is_optional": true, "type": "int", "default_value": "0", "description": " How much to jitter hue.hue_factor is chosen uniformly from [-hue, hue] or the given [min, max].Should have 0&lt;= hue &lt;= 0.5 or -0.5 &lt;= min &lt;= max &lt;= 0.5."}]}},
{"id": "torch.hub.download_url_to_file", "type": "function", "code": "torch.hub.download_url_to_file(url,dst,hash_prefix=None,progress=True)", "example": " torch.hub.download_url_to_file('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth', '/tmp/temporary_file')\n\n", "summary": "Download object at the given URL to a local path", "returns": null, "shape": "NA", "code-info": {"name": "torch.hub.download_url_to_file", "parameters": [{"name": "url", "is_optional": false, "type": "string", "description": " URL of the object to download"}, {"name": "dst", "is_optional": false, "type": "string", "description": " Full path where object will be saved, e.g. /tmp/temporary_file"}, {"name": "hash_prefix", "is_optional": true, "type": "string, optional", "default_value": "None", "description": " If not None, the SHA256 downloaded file should start with hash_prefix.Default"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " whether or not to display a progress bar to stderrDefault"}]}},
{"id": "torch.hub.load_state_dict_from_url", "type": "function", "code": "torch.hub.load_state_dict_from_url(url,model_dir=None,map_location=None,progress=True,check_hash=False)", "example": " state_dict = torch.hub.load_state_dict_from_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth')\n\n", "summary": "Loads the Torch serialized object at the given URL", "returns": null, "shape": "NA", "code-info": {"name": "torch.hub.load_state_dict_from_url", "parameters": [{"name": "url", "is_optional": false, "type": "string", "description": " URL of the object to download"}, {"name": "model_dir", "is_optional": true, "type": "string, optional", "default_value": "None", "description": " directory in which to save the object"}, {"name": "map_location", "is_optional": true, "type": "optional", "default_value": "None", "description": " a function or a dict specifying how to remap storage locations (see torch.load"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " whether or not to display a progress bar to stderr.Default"}, {"name": "check_hash", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, the filename part of the URL should follow the naming conventionfilename-&lt;sha256&gt;.ext where &lt;sha256&gt; is the first eight or moredigits of the SHA256 hash of the contents of the file. The hash is used toensure unique names and to verify the contents of the file.Default"}]}},
{"id": "torch.hub.set_dir", "type": "function", "code": "torch.hub.set_dir(d)", "example": "NA", "summary": "Optionally set hub_dir to a local dir to save downloaded models &amp; weights", "returns": null, "shape": "NA", "code-info": {"name": "torch.hub.set_dir", "parameters": [{"name": "d", "is_optional": false, "type": "string", "description": " path to a local folder to save downloaded models &amp; weights."}]}},
{"id": "torch.distributions.kl.register_kl", "type": "function", "code": "torch.distributions.kl.register_kl(type_p,type_q)", "example": "NA", "summary": "Decorator to register a pairwise function with kl_divergence()", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.kl.register_kl", "parameters": [{"name": "type_p", "is_optional": false, "type": "type", "description": " A subclass of Distribution."}, {"name": "type_q", "is_optional": false, "type": "type", "description": " A subclass of Distribution."}]}},
{"id": "torch.distributions.distribution.Distribution.arg_constraints", "type": "method", "code": "torch.distributions.distribution.Distribution.arg_constraints", "example": "NA", "summary": "Returns a dictionary from argument names to Constraint objects that should be satisfied by each argument of this distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.arg_constraints", "parameters": []}},
{"id": "torch.distributions.distribution.Distribution.batch_shape", "type": "method", "code": "torch.distributions.distribution.Distribution.batch_shape", "example": "NA", "summary": "Returns the shape over which parameters are batched", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.batch_shape", "parameters": []}},
{"id": "torch.distributions.distribution.Distribution.cdf", "type": "method", "code": "torch.distributions.distribution.Distribution.cdf(value)", "example": "NA", "summary": "Returns the cumulative density/mass function evaluated at value", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "Tensor", "description": " "}]}},
{"id": "torch.distributions.distribution.Distribution.entropy", "type": "method", "code": "torch.distributions.distribution.Distribution.entropy()", "example": "NA", "summary": "Returns entropy of distribution, batched over batch_shape", "returns": "Tensor of shape batch_shape.", "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.entropy", "parameters": []}},
{"id": "torch.distributions.distribution.Distribution.enumerate_support", "type": "method", "code": "torch.distributions.distribution.Distribution.enumerate_support(expand=True)", "example": "NA", "summary": "Returns tensor containing all values supported by a discrete distribution", "returns": "Tensor iterating over dimension 0.", "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": " whether to expand the support over thebatch dims to match the distribution\u2019s batch_shape."}]}},
{"id": "torch.distributions.distribution.Distribution.event_shape", "type": "method", "code": "torch.distributions.distribution.Distribution.event_shape", "example": "NA", "summary": "Returns the shape of a single sample (without batching)", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.event_shape", "parameters": []}},
{"id": "torch.distributions.distribution.Distribution.expand", "type": "method", "code": "torch.distributions.distribution.Distribution.expand(batch_shape,_instance=None)", "example": "NA", "summary": "Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to batch_shape", "returns": "New distribution instance with batch dimensions expanded tobatch_size.", "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "torch.Size", "description": " the desired expanded size."}, {"name": "_instance", "is_optional": true, "type": "_instance : new instance provided by subclasses thatneed to override .expand", "default_value": "None", "description": " new instance provided by subclasses thatneed to override .expand."}]}},
{"id": "torch.nn.init.xavier_normal_", "type": "function", "code": "torch.nn.init.xavier_normal_(tensor,gain=1.0)", "example": " w = torch.empty(3, 5)\n nn.init.xavier_normal_(w)\n\n", "summary": "Fills the input Tensor with values according to the method described in Understanding the difficulty of training deep feedforward neural networks - Glorot, X", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.xavier_normal_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : an n-dimensional torch.Tenso", "description": " an n-dimensional torch.Tensor"}, {"name": "gain", "is_optional": true, "type": "gain : an optional scaling facto", "default_value": "1.0", "description": " an optional scaling factor"}]}},
{"id": "torch.nn.init.kaiming_uniform_", "type": "function", "code": "torch.nn.init.kaiming_uniform_(tensor,a=0,mode='fan_in',nonlinearity='leaky_relu')", "example": " w = torch.empty(3, 5)\n nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')\n\n", "summary": "Fills the input Tensor with values according to the method described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification - He, K", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.kaiming_uniform_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : an n-dimensional torch.Tenso", "description": " an n-dimensional torch.Tensor"}, {"name": "a", "is_optional": true, "type": "int", "default_value": "0", "description": " the negative slope of the rectifier used after this layer (only"}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'fan_in'", "description": " either 'fan_in' (default or 'fan_out'. Choosing 'fan_in'preserves the magnitude of the variance of the weights in theforward pass. Choosing 'fan_out' preserves the magnitudes in thebackwards pass."}, {"name": "nonlinearity", "is_optional": true, "type": "string", "default_value": "'leaky_relu'", "description": " the non-linear function (nn.functional name,recommended to use only with 'relu' or 'leaky_relu' (default."}]}},
{"id": "torch.nn.init.kaiming_normal_", "type": "function", "code": "torch.nn.init.kaiming_normal_(tensor,a=0,mode='fan_in',nonlinearity='leaky_relu')", "example": " w = torch.empty(3, 5)\n nn.init.kaiming_normal_(w, mode='fan_out', nonlinearity='relu')\n\n", "summary": "Fills the input Tensor with values according to the method described in Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification - He, K", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.kaiming_normal_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : an n-dimensional torch.Tenso", "description": " an n-dimensional torch.Tensor"}, {"name": "a", "is_optional": true, "type": "int", "default_value": "0", "description": " the negative slope of the rectifier used after this layer (only"}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'fan_in'", "description": " either 'fan_in' (default or 'fan_out'. Choosing 'fan_in'preserves the magnitude of the variance of the weights in theforward pass. Choosing 'fan_out' preserves the magnitudes in thebackwards pass."}, {"name": "nonlinearity", "is_optional": true, "type": "string", "default_value": "'leaky_relu'", "description": " the non-linear function (nn.functional name,recommended to use only with 'relu' or 'leaky_relu' (default."}]}},
{"id": "torch.nn.init.orthogonal_", "type": "function", "code": "torch.nn.init.orthogonal_(tensor,gain=1)", "example": " w = torch.empty(3, 5)\n nn.init.orthogonal_(w)\n\n", "summary": "Fills the input Tensor with a (semi) orthogonal matrix, as described in Exact solutions to the nonlinear dynamics of learning in deep linear neural networks - Saxe, A", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.orthogonal_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : an n-dimensional torch.Tensor, where n\u22652n \\geq 2n\u2265", "description": " an n-dimensional torch.Tensor, where n\u22652n \\geq 2n\u22652"}, {"name": "gain", "is_optional": true, "type": "int", "default_value": "1", "description": " optional scaling factor"}]}},
{"id": "torch.nn.init.sparse_", "type": "function", "code": "torch.nn.init.sparse_(tensor,sparsity,std=0.01)", "example": " w = torch.empty(3, 5)\n nn.init.sparse_(w, sparsity=0.1)\n\n", "summary": "Fills the 2D input Tensor as a sparse matrix, where the non-zero elements will be drawn from the normal distribution N(0,0.01)\\mathcal{N}(0, 0.01)N(0,0.01)  , as described in Deep learning via Hessian-free optimization - Martens, J", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.init.sparse_", "parameters": [{"name": "tensor", "is_optional": false, "type": "tensor : an n-dimensional torch.Tenso", "description": " an n-dimensional torch.Tensor"}, {"name": "sparsity", "is_optional": false, "type": "sparsity : The fraction of elements in each column to be set to zer", "description": " The fraction of elements in each column to be set to zero"}, {"name": "std", "is_optional": true, "type": "std : the standard deviation of the normal distribution used to generatethe non-zero value", "default_value": "0.01", "description": " the standard deviation of the normal distribution used to generatethe non-zero values"}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.add_hparams", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.add_hparams(hparam_dict=None,metric_dict=None)", "example": "from torch.utils.tensorboard import SummaryWriter\nwith SummaryWriter() as w:\n    for i in range(5):\n        w.add_hparams({'lr': 0.1*i, 'bsize': i},\n                      {'hparam/accuracy': 10*i, 'hparam/loss': 10*i})\n\n", "summary": "Add a set of hyperparameters to be compared in TensorBoard", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.add_hparams", "parameters": [{"name": "hparam_dict", "is_optional": true, "type": "dict", "default_value": "None", "description": " Each key-value pair in the dictionary is thename of the hyper parameter and it\u2019s corresponding value."}, {"name": "metric_dict", "is_optional": true, "type": "dict", "default_value": "None", "description": " Each key-value pair in the dictionary is thename of the metric and it\u2019s corresponding value. Note that the key usedhere should be unique in the tensorboard record. Otherwise the valueyou added by add_scalar will be displayed in hparam plugin. In mostcases, this is unwanted."}]}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.flush", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.flush()", "example": "NA", "summary": "Flushes the event file to disk", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.flush", "parameters": []}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter.close", "type": "method", "code": "torch.utils.tensorboard.writer.SummaryWriter.close()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter.close", "parameters": []}},
{"id": "torch.utils.tensorboard.writer.SummaryWriter", "type": "class", "code": "torch.utils.tensorboard.writer.SummaryWriter(log_dir=None,comment='',purge_step=None,max_queue=10,flush_secs=120,filename_suffix='')", "example": "from torch.utils.tensorboard import SummaryWriter\n\n# create a summary writer with automatically generated folder name.\nwriter = SummaryWriter()\n# folder location: runs/May04_22-14-54_s-MacBook-Pro.local/\n\n# create a summary writer using the specified folder name.\nwriter = SummaryWriter(\"my_experiment\")\n# folder location: my_experiment\n\n# create a summary writer with comment appended.\nwriter = SummaryWriter(comment=\"LR_0.1_BATCH_16\")\n# folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/\n\n", "summary": "Writes entries directly to event files in the log_dir to be consumed by TensorBoard", "returns": null, "shape": "img_tensor: Default is (3,H,W)(3, H, W)(3,H,W)  . You can use torchvision.utils.make_grid() to convert a batch of tensor into 3xHxW format or call add_images and let us do the job. Tensor with (1,H,W)(1, H, W)(1,H,W)  , (H,W)(H, W)(H,W)  , (H,W,3)(H, W, 3)(H,W,3)   is also suitible as long as corresponding dataformats argument is passed. e.g. CHW, HWC, HW. ", "code-info": {"name": "torch.utils.tensorboard.writer.SummaryWriter", "parameters": [{"name": "log_dir", "is_optional": true, "type": "string", "default_value": "None", "description": " Save directory location. Default isruns/CURRENT_DATETIME_HOSTNAME, which changes after each run.Use hierarchical folder structure to comparebetween runs easily. e.g. pass in \u2018runs/exp1\u2019, \u2018runs/exp2\u2019, etc.for each new experiment to compare across them."}, {"name": "comment", "is_optional": true, "type": "string", "default_value": "''", "description": " Comment log_dir suffix appended to the defaultlog_dir. If log_dir is assigned, this argument has no effect."}, {"name": "purge_step", "is_optional": true, "type": "int", "default_value": "None", "description": " When logging crashes at step T+XT+XT+X and restarts at step TTT,any events whose global_step larger or equal to TTT will bepurged and hidden from TensorBoard.Note that crashed and resumed experiments should have the same log_dir."}, {"name": "max_queue", "is_optional": true, "type": "int", "default_value": "10", "description": " Size of the queue for pending events andsummaries before one of the \u2018add\u2019 calls forces a flush to disk.Default is ten items."}, {"name": "flush_secs", "is_optional": true, "type": "int", "default_value": "120", "description": " How often, in seconds, to flush thepending events and summaries to disk. Default is every two minutes."}, {"name": "filename_suffix", "is_optional": true, "type": "string", "default_value": "''", "description": " Suffix added to all event filenames inthe log_dir directory. More details on filename construction intensorboard.summary.writer.event_file_writer.EventFileWriter."}]}},
{"id": "torch.distributed.get_backend", "type": "function", "code": "torch.distributed.get_backend(group=&lt;objectobject&gt;)", "example": "NA", "summary": "Returns the backend of the given process group", "returns": "The backend of the given process group as a lower case string.", "shape": "NA", "code-info": {"name": "torch.distributed.get_backend", "parameters": [{"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on. Thedefault is the general main process group. If another specific groupis specified, the calling process must be part of group."}]}},
{"id": "torch.distributed.get_rank", "type": "function", "code": "torch.distributed.get_rank(group=&lt;objectobject&gt;)", "example": "NA", "summary": "Returns the rank of current process group Rank is a unique identifier assigned to each process within a distributed process group", "returns": "The rank of the process group-1, if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.get_rank", "parameters": [{"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}]}},
{"id": "torch.distributed.get_world_size", "type": "function", "code": "torch.distributed.get_world_size(group=&lt;objectobject&gt;)", "example": "NA", "summary": "Returns the number of processes in the current process group  Parameters group (ProcessGroup, optional) \u2013 The process group to work on  Returns The world size of the process group -1, if not part of the group   ", "returns": "The world size of the process group-1, if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.get_world_size", "parameters": [{"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}]}},
{"id": "torch.distributed.is_initialized", "type": "function", "code": "torch.distributed.is_initialized()", "example": "NA", "summary": "Checking if the default process group has been initialized ", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.is_initialized", "parameters": []}},
{"id": "torch.distributed.is_mpi_available", "type": "function", "code": "torch.distributed.is_mpi_available()", "example": "NA", "summary": "Checks if the MPI backend is available", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.is_mpi_available", "parameters": []}},
{"id": "torch.distributed.is_nccl_available", "type": "function", "code": "torch.distributed.is_nccl_available()", "example": "NA", "summary": "Checks if the NCCL backend is available", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.is_nccl_available", "parameters": []}},
{"id": "torch.distributed.new_group", "type": "function", "code": "torch.distributed.new_group(ranks=None,timeout=datetime.timedelta(0,1800)", "example": "NA", "summary": "Creates a new distributed group", "returns": "A handle of distributed group that can be given to collective calls.", "shape": "NA", "code-info": {"name": "torch.distributed.new_group", "parameters": [{"name": "ranks", "is_optional": true, "type": "list[int]", "default_value": "None", "description": " List of ranks of group members."}, {"name": "timeout", "is_optional": true, "type": "timedelta, optional", "default_value": "datetime.timedelt", "description": " Timeout for operations executed againstthe process group. Default value equals 30 minutes.This is only applicable for the gloo backend."}]}},
{"id": "torch.distributed.send", "type": "function", "code": "torch.distributed.send(tensor,dst,group=&lt;objectobject&gt;,tag=0)", "example": "NA", "summary": "Sends a tensor synchronously", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.send", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " Tensor to send."}, {"name": "dst", "is_optional": false, "type": "int", "description": " Destination rank."}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "tag", "is_optional": true, "type": "int", "default_value": "0", "description": " Tag to match send with remote recv"}]}},
{"id": "torch.distributed.recv", "type": "function", "code": "torch.distributed.recv(tensor,src=None,group=&lt;objectobject&gt;,tag=0)", "example": "NA", "summary": "Receives a tensor synchronously", "returns": "Sender rank-1, if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.recv", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " Tensor to fill with received data."}, {"name": "src", "is_optional": true, "type": "int, optional", "default_value": "None", "description": " Source rank. Will receive from anyprocess if unspecified."}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "tag", "is_optional": true, "type": "int", "default_value": "0", "description": " Tag to match recv with remote send"}]}},
{"id": "torch.cuda.device_count", "type": "function", "code": "torch.cuda.device_count()", "example": "NA", "summary": "Returns the number of GPUs available", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.device_count", "parameters": []}},
{"id": "torch.cuda.get_device_capability", "type": "function", "code": "torch.cuda.get_device_capability(device=None)", "example": "NA", "summary": "Gets the cuda capability of a device", "returns": "the major and minor cuda capability of the device", "shape": "NA", "code-info": {"name": "torch.cuda.get_device_capability", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " device for which to return thedevice capability. This function is a no-op if this argument isa negative integer. It uses the current device, given bycurrent_device(, if device is None(default."}]}},
{"id": "torch.cuda.get_device_name", "type": "function", "code": "torch.cuda.get_device_name(device=None)", "example": "NA", "summary": "Gets the name of a device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.get_device_name", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " device for which to return thename. This function is a no-op if this argument is a negativeinteger. It uses the current device, given by current_device(,if device is None (default."}]}},
{"id": "torch.cuda.init", "type": "function", "code": "torch.cuda.init()", "example": "NA", "summary": "Initialize PyTorch\u2019s CUDA state", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.init", "parameters": []}},
{"id": "torch.cuda.ipc_collect", "type": "function", "code": "torch.cuda.ipc_collect()", "example": "NA", "summary": "Force collects GPU memory after it has been released by CUDA IPC", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.ipc_collect", "parameters": []}},
{"id": "torch.cuda.is_available", "type": "function", "code": "torch.cuda.is_available()", "example": "NA", "summary": "Returns a bool indicating if CUDA is currently available", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.is_available", "parameters": []}},
{"id": "torch.cuda.is_initialized", "type": "function", "code": "torch.cuda.is_initialized()", "example": "NA", "summary": "Returns whether PyTorch\u2019s CUDA state has been initialized", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.is_initialized", "parameters": []}},
{"id": "torch.cuda.set_device", "type": "function", "code": "torch.cuda.set_device(device)", "example": "NA", "summary": "Sets the current device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.set_device", "parameters": [{"name": "device", "is_optional": false, "type": "torch.device or int", "description": " selected device. This function is a no-opif this argument is negative."}]}},
{"id": "torch.jit.save", "type": "function", "code": "torch.jit.save(m,f,_extra_files=ExtraFilesMap{})", "example": " import torch import io  class MyModule(torch.nn.Module):     def forward(self, x):         return x + 10  m = torch.jit.script(MyModule())  # Save to file torch.jit.save(m, 'scriptmodule.pt') # This line is equivalent to the previous m.save(\"scriptmodule.pt\")  # Save to io.BytesIO buffer buffer = io.BytesIO() torch.jit.save(m, buffer)  # Save with extra files extra_files = torch._C.ExtraFilesMap() extra_files['foo.txt'] = 'bar' torch.jit.save(m, 'scriptmodule.pt', _extra_files=extra_files)   ", "summary": "Save an offline version of this module for use in a separate process", "returns": null, "shape": "NA", "code-info": {"name": "torch.jit.save", "parameters": [{"name": "m", "is_optional": false, "type": "m : A ScriptModule to save", "description": " A ScriptModule to save."}, {"name": "f", "is_optional": false, "type": "string", "description": " A file-like object (has to implement write and flush or a stringcontaining a file name."}, {"name": "_extra_files", "is_optional": true, "type": "_extra_files : Map from filename to contents which will be stored as part of \u2018f\u2019", "default_value": "ExtraFilesMap{}", "description": " Map from filename to contents which will be stored as part of \u2018f\u2019."}]}},
{"id": "torch.jit.load", "type": "function", "code": "torch.jit.load(f,map_location=None,_extra_files=ExtraFilesMap{})", "example": " import torch import io  torch.jit.load('scriptmodule.pt')  # Load ScriptModule from io.BytesIO object with open('scriptmodule.pt', 'rb') as f:     buffer = io.BytesIO(f.read())  # Load all tensors to the original device torch.jit.load(buffer)  # Load all tensors onto CPU, using a device buffer.seek(0) torch.jit.load(buffer, map_location=torch.device('cpu'))  # Load all tensors onto CPU, using a string buffer.seek(0) torch.jit.load(buffer, map_location='cpu')  # Load with extra files. extra_files = torch._C.ExtraFilesMap() extra_files['foo.txt'] = 'bar' torch.jit.load('scriptmodule.pt', _extra_files=extra_files) print(extra_files['foo.txt'])   ", "summary": "Load a ScriptModule or ScriptFunction previously saved with torch.jit.save All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from", "returns": "A ScriptModule object.", "shape": "NA", "code-info": {"name": "torch.jit.load", "parameters": [{"name": "f", "is_optional": false, "type": "string", "description": " a file-like object (has to implement read, readline, tell, and seek,or a string containing a file name"}, {"name": "map_location", "is_optional": true, "type": "string or torch.device", "default_value": "None", "description": " A simplified version of map_location intorch.save used to dynamically remap storages to an alternative set of devices."}, {"name": "_extra_files", "is_optional": true, "type": "dictionary of filename to content", "default_value": "ExtraFilesMap{}", "description": " The extrafilenames given in the map would be loaded and their contentwould be stored in the provided map."}]}},
{"id": "torch.jit.export", "type": "function", "code": "torch.jit.export(fn)", "example": "import torch\nimport torch.nn as nn\n\nclass MyModule(nn.Module):\n    def implicitly_compiled_method(self, x):\n        return x + 99\n\n    # `forward` is implicitly decorated with `@torch.jit.export`,\n    # so adding it here would have no effect\n    def forward(self, x):\n        return x + 10\n\n    @torch.jit.export\n    def another_forward(self, x):\n        # When the compiler sees this call, it will compile\n        # `implicitly_compiled_method`\n        return self.implicitly_compiled_method(x)\n\n    def unused_method(self, x):\n        return x - 20\n\n# `m` will contain compiled methods:\n#     `forward`\n#     `another_forward`\n#     `implicitly_compiled_method`\n# `unused_method` will not be compiled since it was not called from\n# any compiled methods and wasn't decorated with `@torch.jit.export`\nm = torch.jit.script(MyModule())\n\n", "summary": "This decorator indicates that a method on an nn.Module is used as an entry point into a ScriptModule and should be compiled", "returns": null, "shape": "NA", "code-info": {"name": "torch.jit.export", "parameters": [{"name": "fn", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.autograd.gradcheck", "type": "function", "code": "torch.autograd.gradcheck(func,inputs,eps=1e-06,atol=1e-05,rtol=0.001,raise_exception=True,check_sparse_nnz=False,nondet_tol=0.0)", "example": "NA", "summary": "Check gradients computed via small finite differences against analytical gradients w.r.t", "returns": "True if all differences satisfy allclose condition", "shape": "NA", "code-info": {"name": "torch.autograd.gradcheck", "parameters": [{"name": "func", "is_optional": false, "type": "function", "description": " a Python function that takes Tensor inputs and returnsa Tensor or a tuple of Tensors"}, {"name": "inputs", "is_optional": false, "type": "function", "description": " inputs to the function"}, {"name": "eps", "is_optional": true, "type": "float, optional", "default_value": "1e-06", "description": " perturbation for finite differences"}, {"name": "atol", "is_optional": true, "type": "float, optional", "default_value": "1e-05", "description": " absolute tolerance"}, {"name": "rtol", "is_optional": true, "type": "float, optional", "default_value": "0.001", "description": " relative tolerance"}, {"name": "raise_exception", "is_optional": true, "type": "bool", "default_value": "True", "description": " indicating whether to raise an exception ifthe check fails. The exception gives more information about theexact nature of the failure. This is helpful when debugging gradchecks."}, {"name": "check_sparse_nnz", "is_optional": true, "type": "bool", "default_value": "False", "description": " if True, gradcheck allows for SparseTensor input,and for any SparseTensor at input, gradcheck will perform check at nnz positions only."}, {"name": "nondet_tol", "is_optional": true, "type": "float, optional", "default_value": "0.0", "description": " tolerance for non-determinism. When runningidentical inputs through the differentiation, the results must either matchexactly (default, 0.0 or be within this tolerance."}]}},
{"id": "torch.autograd.gradgradcheck", "type": "function", "code": "torch.autograd.gradgradcheck(func,inputs,grad_outputs=None,eps=1e-06,atol=1e-05,rtol=0.001,gen_non_contig_grad_outputs=False,raise_exception=True,nondet_tol=0.0)", "example": "NA", "summary": "Check gradients of gradients computed via small finite differences against analytical gradients w.r.t", "returns": "True if all differences satisfy allclose condition", "shape": "NA", "code-info": {"name": "torch.autograd.gradgradcheck", "parameters": [{"name": "func", "is_optional": false, "type": "function", "description": " a Python function that takes Tensor inputs and returnsa Tensor or a tuple of Tensors"}, {"name": "inputs", "is_optional": false, "type": "function", "description": " inputs to the function"}, {"name": "grad_outputs", "is_optional": true, "type": "tuple of Tensor or Tensor, optional", "default_value": "None", "description": " The gradients withrespect to the function\u2019s outputs."}, {"name": "eps", "is_optional": true, "type": "float, optional", "default_value": "1e-06", "description": " perturbation for finite differences"}, {"name": "atol", "is_optional": true, "type": "float, optional", "default_value": "1e-05", "description": " absolute tolerance"}, {"name": "rtol", "is_optional": true, "type": "float, optional", "default_value": "0.001", "description": " relative tolerance"}, {"name": "gen_non_contig_grad_outputs", "is_optional": true, "type": "bool", "default_value": "False", "description": " if grad_outputs isNone and gen_non_contig_grad_outputs is True, therandomly generated gradient outputs are made to be noncontiguous"}, {"name": "raise_exception", "is_optional": true, "type": "bool", "default_value": "True", "description": " indicating whether to raise an exception ifthe check fails. The exception gives more information about theexact nature of the failure. This is helpful when debugging gradchecks."}, {"name": "nondet_tol", "is_optional": true, "type": "int", "default_value": "0.0", "description": " tolerance for non-determinism. When runningidentical inputs through the differentiation, the results must either matchexactly (default, 0.0 or be within this tolerance. Note that a small amountof nondeterminism in the gradient will lead to larger inaccuracies inthe second derivative."}]}},
{"id": "torch.autograd.profiler.load_nvprof", "type": "function", "code": "torch.autograd.profiler.load_nvprof(path)", "example": "NA", "summary": "Opens an nvprof trace file and parses autograd annotations", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.profiler.load_nvprof", "parameters": [{"name": "path", "is_optional": false, "type": "str", "description": " path to nvprof trace"}]}},
{"id": "torch.Tensor.backward", "type": "method", "code": "torch.Tensor.backward(gradient=None,retain_graph=None,create_graph=False)", "example": "NA", "summary": "Computes the gradient of current tensor w.r.t", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.backward", "parameters": [{"name": "gradient", "is_optional": true, "type": "Tensor or None", "default_value": "None", "description": " Gradient w.r.t. thetensor. If it is a tensor, it will be automatically convertedto a Tensor that does not require grad unless create_graph is True.None values can be specified for scalar Tensors or ones thatdon\u2019t require grad. If a None value would be acceptable thenthis argument is optional."}, {"name": "retain_graph", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " If False, the graph used to computethe grads will be freed. Note that in nearly all cases settingthis option to True is not needed and often can be worked aroundin a much more efficient way. Defaults to the value ofcreate_graph."}, {"name": "create_graph", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, graph of the derivative willbe constructed, allowing to compute higher order derivativeproducts. Defaults to False."}]}},
{"id": "torch.distributed.autograd.context", "type": "class", "code": "torch.distributed.autograd.context", "example": "  import torch.distributed.autograd as dist_autograd  with dist_autograd.context() as context_id:    t1 = torch.rand((3, 3), requires_grad=True)    t2 = torch.rand((3, 3), requires_grad=True)    loss = rpc.rpc_sync(\"worker1\", torch.add, args=(t1, t2)).sum()    dist_autograd.backward([loss])   ", "summary": "Context object to wrap forward and backward passes when using distributed autograd", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.autograd.context", "parameters": []}},
{"id": "torch.distributed.optim.DistributedOptimizer", "type": "class", "code": "torch.distributed.optim.DistributedOptimizer(optimizer_class,params_rref,*args,**kwargs)", "example": "  import torch.distributed.autograd as dist_autograd  import torch.distributed.rpc as rpc  from torch import optim  from torch.distributed.optim import DistributedOptimizer   with dist_autograd.context() as context_id:    # Forward pass.    rref1 = rpc.remote(\"worker1\", torch.add, args=(torch.ones(2), 3))    rref2 = rpc.remote(\"worker1\", torch.add, args=(torch.ones(2), 1))    loss = rref1.to_here() + rref2.to_here()     # Backward pass.    dist_autograd.backward([loss.sum()])     # Optimizer.    dist_optim = DistributedOptimizer(       optim.SGD,       [rref1, rref2],       lr=0.05,    )    dist_optim.step()     step()  Performs a single optimization step. This will call torch.optim.Optimizer.step() on each worker containing parameters to be optimized, and will block until all workers return. The current distributed autograd context will be used globally.   ", "summary": "DistributedOptimizer takes remote references to parameters scattered across workers and applies the given optimizer locally for each parameter", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.optim.DistributedOptimizer", "parameters": [{"name": "optimizer_class", "is_optional": false, "type": "optim.Optimizer", "description": " the class of optimizer toinstantiate on each worker."}, {"name": "params_rref", "is_optional": false, "type": "list[RRef]", "description": " list of RRefs to local or remote parametersto optimize."}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.quantized.functional.conv2d", "type": "function", "code": "torch.nn.quantized.functional.conv2d(input,weight,bias,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',scale=1.0,zero_point=0,dtype=torch.quint8)", "example": " from torch.nn.quantized import functional as qF\n filters = torch.randn(8, 4, 3, 3, dtype=torch.float)\n inputs = torch.randn(1, 4, 5, 5, dtype=torch.float)\n bias = torch.randn(4, dtype=torch.float)\n\n scale, zero_point = 1.0, 0\n dtype = torch.quint8\n\n q_filters = torch.quantize_per_tensor(filters, scale, zero_point, dtype)\n q_inputs = torch.quantize_per_tensor(inputs, scale, zero_point, dtype)\n qF.conv2d(q_inputs, q_filters, bias, scale, zero_point, padding=1)\n\n", "summary": "Applies a 2D convolution over a quantized 2D input composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.functional.conv2d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iH,iW", "description": " quantized input tensor of shape (minibatch,in_channels,iH,iW(\\text{minibatch} , \\text{in\\_channels} , iH , iW(minibatch,in_channels,iH,iW"}, {"name": "weight", "is_optional": false, "type": "out_channels,in_channelsgroups,kH,kW", "description": " quantized filters of shape (out_channels,in_channelsgroups,kH,kW(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kH , kW(out_channels,groupsin_channels\u200b,kH,kW"}, {"name": "bias", "is_optional": false, "type": "out_channels", "description": " non-quantized bias tensor of shape (out_channels(\\text{out\\_channels}(out_channels. The tensor type must be torch.float."}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": " the stride of the convolving kernel. Can be a single number or atuple (sH, sW. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " implicit paddings on both sides of the input. Can be asingle number or a tuple (padH, padW. Default"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": " the spacing between kernel elements. Can be a single number ora tuple (dH, dW. Default"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": " split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by thenumber of groups. Default"}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": " the padding mode to use. Only \u201czeros\u201d is supported for quantized convolution at the moment. Default"}, {"name": "scale", "is_optional": true, "type": "scale : quantization scale for the output. Default: 1.", "default_value": "1.0", "description": " quantization scale for the output. Default"}, {"name": "zero_point", "is_optional": true, "type": "int", "default_value": "0", "description": " quantization zero_point for the output. Default"}, {"name": "dtype", "is_optional": true, "type": "dtype : quantization data type to use. Default: torch.quint", "default_value": "torch.quint8", "description": " quantization data type to use. Default"}]}},
{"id": "torch.nn.quantized.functional.conv3d", "type": "function", "code": "torch.nn.quantized.functional.conv3d(input,weight,bias,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',scale=1.0,zero_point=0,dtype=torch.quint8)", "example": " from torch.nn.quantized import functional as qF\n filters = torch.randn(8, 4, 3, 3, 3, dtype=torch.float)\n inputs = torch.randn(1, 4, 5, 5, 5, dtype=torch.float)\n bias = torch.randn(4, dtype=torch.float)\n\n scale, zero_point = 1.0, 0\n dtype = torch.quint8\n\n q_filters = torch.quantize_per_tensor(filters, scale, zero_point, dtype)\n q_inputs = torch.quantize_per_tensor(inputs, scale, zero_point, dtype)\n qF.conv3d(q_inputs, q_filters, bias, scale, zero_point, padding=1)\n\n", "summary": "Applies a 3D convolution over a quantized 3D input composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.functional.conv3d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iD,iH,iW", "description": " quantized input tensor of shape(minibatch,in_channels,iD,iH,iW(\\text{minibatch} , \\text{in\\_channels} , iD , iH , iW(minibatch,in_channels,iD,iH,iW"}, {"name": "weight", "is_optional": false, "type": "out_channels,in_channelsgroups,kD,kH,kW", "description": " quantized filters of shape(out_channels,in_channelsgroups,kD,kH,kW(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kD , kH , kW(out_channels,groupsin_channels\u200b,kD,kH,kW"}, {"name": "bias", "is_optional": false, "type": "out_channels", "description": " non-quantized bias tensor of shape(out_channels(\\text{out\\_channels}(out_channels. The tensor type must be torch.float."}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": " the stride of the convolving kernel. Can be a single number or atuple (sD, sH, sW. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " implicit paddings on both sides of the input. Can be asingle number or a tuple (padD, padH, padW. Default"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": " the spacing between kernel elements. Can be a single number ora tuple (dD, dH, dW. Default"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": " split input into groups, in_channels\\text{in\\_channels}in_channels should bedivisible by the number of groups. Default"}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": " the padding mode to use. Only \u201czeros\u201d is supported forquantized convolution at the moment. Default"}, {"name": "scale", "is_optional": true, "type": "scale : quantization scale for the output. Default: 1.", "default_value": "1.0", "description": " quantization scale for the output. Default"}, {"name": "zero_point", "is_optional": true, "type": "int", "default_value": "0", "description": " quantization zero_point for the output. Default"}, {"name": "dtype", "is_optional": true, "type": "dtype : quantization data type to use. Default: torch.quint", "default_value": "torch.quint8", "description": " quantization data type to use. Default"}]}},
{"id": "torch.optim.lr_scheduler.LambdaLR.state_dict", "type": "method", "code": "torch.optim.lr_scheduler.LambdaLR.state_dict()", "example": "NA", "summary": "Returns the state of the scheduler as a dict", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.LambdaLR.state_dict", "parameters": []}},
{"id": "torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict", "type": "method", "code": "torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict(state_dict)", "example": "NA", "summary": "Loads the schedulers state", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict", "parameters": [{"name": "state_dict", "is_optional": false, "type": "dict", "description": " scheduler state. Should be an object returnedfrom a call to state_dict(."}]}},
{"id": "torch.optim.lr_scheduler.MultiplicativeLR.state_dict", "type": "method", "code": "torch.optim.lr_scheduler.MultiplicativeLR.state_dict()", "example": "NA", "summary": "Returns the state of the scheduler as a dict", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.MultiplicativeLR.state_dict", "parameters": []}},
{"id": "torch.optim.lr_scheduler.CyclicLR.get_lr", "type": "method", "code": "torch.optim.lr_scheduler.CyclicLR.get_lr()", "example": "NA", "summary": "Calculates the learning rate at batch index", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.CyclicLR.get_lr", "parameters": []}},
{"id": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.step", "type": "method", "code": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.step(epoch=None)", "example": " scheduler = CosineAnnealingWarmRestarts(optimizer, T_0, T_mult)\n iters = len(dataloader)\n for epoch in range(20):\n     for i, sample in enumerate(dataloader):\n         inputs, labels = sample['inputs'], sample['labels']\n         scheduler.step(epoch + i / iters)\n         optimizer.zero_grad()\n         outputs = net(inputs)\n         loss = criterion(outputs, labels)\n         loss.backward()\n         optimizer.step()\n\n", "summary": "Step could be called after every batch update Example &gt;&gt;&gt; scheduler = CosineAnnealingWarmRestarts(optimizer, T_0, T_mult) &gt;&gt;&gt; iters = len(dataloader) &gt;&gt;&gt; for epoch in range(20): &gt;&gt;&gt;     for i, sample in enumerate(dataloader): &gt;&gt;&gt;         inputs, labels = sample['inputs'], sample['labels'] &gt;&gt;&gt;         scheduler.step(epoch + i / iters) &gt;&gt;&gt;         optimizer.zero_grad() &gt;&gt;&gt;         outputs = net(inputs) &gt;&gt;&gt;         loss = criterion(outputs, labels) &gt;&gt;&gt;         loss.backward() &gt;&gt;&gt;         optimizer.step()   This function can be called in an interleaved way", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.step", "parameters": [{"name": "epoch", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.optim.Optimizer", "type": "class", "code": "torch.optim.Optimizer(params,defaults)", "example": "NA", "summary": "Base class for all optimizers", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Optimizer", "parameters": [{"name": "params", "is_optional": false, "type": "iterable", "description": " an iterable of torch.Tensor s ordict s. Specifies what Tensors should be optimized."}, {"name": "defaults", "is_optional": false, "type": "dict", "description": " (dict"}]}},
{"id": "torch.optim.Adadelta", "type": "class", "code": "torch.optim.Adadelta(params,lr=1.0,rho=0.9,eps=1e-06,weight_decay=0)", "example": "NA", "summary": "Implements Adadelta algorithm", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Adadelta", "parameters": [{"name": "params", "is_optional": false, "type": "iterable", "description": " iterable of parameters to optimize or dicts definingparameter groups"}, {"name": "lr", "is_optional": true, "type": "float, optional", "default_value": "1.0", "description": " coefficient that scale delta before it is appliedto the parameters (default"}, {"name": "rho", "is_optional": true, "type": "float, optional", "default_value": "0.9", "description": " coefficient used for computing a running averageof squared gradients (default"}, {"name": "eps", "is_optional": true, "type": "float, optional", "default_value": "1e-06", "description": " term added to the denominator to improvenumerical stability (default"}, {"name": "weight_decay", "is_optional": true, "type": "int", "default_value": "0", "description": " weight decay (L2 penalty (default"}]}},
{"id": "torchvision.datasets.SBU", "type": "class", "code": "torchvision.datasets.SBU(root,transform=None,target_transform=None,download=True)", "example": "NA", "summary": "SBU Captioned Photo Dataset", "returns": "(image, target) where target is a caption for the photo.", "shape": "NA", "code-info": {"name": "torchvision.datasets.SBU", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of dataset where tarballSBUCaptionedPhotoDataset.tar.gz exists."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in a PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again."}]}},
{"id": "torchvision.datasets.Flickr8k", "type": "class", "code": "torchvision.datasets.Flickr8k(root,ann_file,transform=None,target_transform=None)", "example": "NA", "summary": "Flickr8k Entities Dataset", "returns": "Tuple (image, target). target is a list of captions for the image.", "shape": "NA", "code-info": {"name": "torchvision.datasets.Flickr8k", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory where images are downloaded to."}, {"name": "ann_file", "is_optional": false, "type": "string", "description": " Path to annotation file."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in a PIL imageand returns a transformed version. E.g, transforms.ToTensor"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}]}},
{"id": "torchvision.datasets.Flickr30k", "type": "class", "code": "torchvision.datasets.Flickr30k(root,ann_file,transform=None,target_transform=None)", "example": "NA", "summary": "Flickr30k Entities Dataset", "returns": "Tuple (image, target). target is a list of captions for the image.", "shape": "NA", "code-info": {"name": "torchvision.datasets.Flickr30k", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory where images are downloaded to."}, {"name": "ann_file", "is_optional": false, "type": "string", "description": " Path to annotation file."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in a PIL imageand returns a transformed version. E.g, transforms.ToTensor"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}]}},
{"id": "torchvision.datasets.VOCSegmentation", "type": "class", "code": "torchvision.datasets.VOCSegmentation(root,year='2012',image_set='train',download=False,transform=None,target_transform=None,transforms=None)", "example": "NA", "summary": "Pascal VOC Segmentation Dataset", "returns": "(image, target) where target is the image segmentation.", "shape": "NA", "code-info": {"name": "torchvision.datasets.VOCSegmentation", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of the VOC Dataset."}, {"name": "year", "is_optional": true, "type": "string", "default_value": "'2012'", "description": " The dataset year, supports years 2007 to 2012."}, {"name": "image_set", "is_optional": true, "type": "string", "default_value": "'train'", "description": " Select the image_set to use, train, trainval or val"}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": " If true, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "transforms", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes input sample and its target as entryand returns a transformed version."}]}},
{"id": "torchvision.datasets.VOCDetection", "type": "class", "code": "torchvision.datasets.VOCDetection(root,year='2012',image_set='train',download=False,transform=None,target_transform=None,transforms=None)", "example": "NA", "summary": "Pascal VOC Detection Dataset", "returns": "(image, target) where target is a dictionary of the XML tree.", "shape": "NA", "code-info": {"name": "torchvision.datasets.VOCDetection", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of the VOC Dataset."}, {"name": "year", "is_optional": true, "type": "string", "default_value": "'2012'", "description": " The dataset year, supports years 2007 to 2012."}, {"name": "image_set", "is_optional": true, "type": "string", "default_value": "'train'", "description": " Select the image_set to use, train, trainval or val"}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": " If true, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again.(default"}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, required", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "transforms", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes input sample and its target as entryand returns a transformed version."}]}},
{"id": "NA", "type": "function", "code": "NA(p_tensor,*,generator=None)", "example": "NA", "summary": "p_tensor should be a tensor containing probabilities to be used for drawing the binary random number", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "p_tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(dtype,non_blocking=False,copy=False)", "example": "NA", "summary": "Returns a Tensor with the specified dtype ", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "dtype", "is_optional": false, "type": "others", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "copy", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(device=None,dtype=None,non_blocking=False,copy=False)", "example": "NA", "summary": "Returns a Tensor with the specified device and (optional) dtype", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "copy", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(other,non_blocking=False,copy=False)", "example": "NA", "summary": "Returns a Tensor with same torch.dtype and torch.device as the Tensor other", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "copy", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(dim,keepdim=False,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(dim,keepdim=False,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.new_tensor", "type": "method", "code": "torch.Tensor.new_tensor(data,dtype=None,device=None,requires_grad=False)", "example": "  tensor = torch.ones((2,), dtype=torch.int8)  data = [[0, 1], [2, 3]]  tensor.new_tensor(data) tensor([[ 0,  1],         [ 2,  3]], dtype=torch.int8)   ", "summary": "Returns a new Tensor with data as the tensor data", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.new_tensor", "parameters": [{"name": "data", "is_optional": false, "type": "array_like", "description": " The returned Tensor copies data."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired type of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.sparse.FloatTensor.transpose_", "type": "method", "code": "torch.sparse.FloatTensor.transpose_()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.transpose_", "parameters": []}},
{"id": "torch.sparse.FloatTensor.zero_", "type": "method", "code": "torch.sparse.FloatTensor.zero_()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.zero_", "parameters": []}},
{"id": "torch.sparse.FloatTensor.coalesce", "type": "method", "code": "torch.sparse.FloatTensor.coalesce()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.coalesce", "parameters": []}},
{"id": "torch.sparse.FloatTensor.is_coalesced", "type": "method", "code": "torch.sparse.FloatTensor.is_coalesced()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor.is_coalesced", "parameters": []}},
{"id": "torch.sparse.FloatTensor._indices", "type": "method", "code": "torch.sparse.FloatTensor._indices()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor._indices", "parameters": []}},
{"id": "torch.sparse.FloatTensor._values", "type": "method", "code": "torch.sparse.FloatTensor._values()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor._values", "parameters": []}},
{"id": "torch.sparse.FloatTensor._nnz", "type": "method", "code": "torch.sparse.FloatTensor._nnz()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor._nnz", "parameters": []}},
{"id": "torch.sparse.FloatTensor", "type": "class", "code": "torch.sparse.FloatTensor", "example": "NA", "summary": "  add()     add_()     clone()     dim()     div()     div_()     get_device()     hspmm()     mm()     mul()     mul_()     narrow_copy()     resizeAs_()     size()     spadd()     spmm()     sspaddmm()     sspmm()     sub()     sub_()     t_()     to_dense()     transpose()     transpose_()     zero_()     coalesce()     is_coalesced()     _indices()     _values()     _nnz()   ", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse.FloatTensor", "parameters": []}},
{"id": "torch.nn.functional.conv2d", "type": "function", "code": "torch.nn.functional.conv2d(input,weight,bias=None,stride=1,padding=0,dilation=1,groups=1)", "example": " # With square kernels and equal stride\n filters = torch.randn(8,4,3,3)\n inputs = torch.randn(1,4,5,5)\n F.conv2d(inputs, filters, padding=1)\n\n", "summary": "Applies a 2D convolution over an input image composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.conv2d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iH,iW", "description": " input tensor of shape (minibatch,in_channels,iH,iW(\\text{minibatch} , \\text{in\\_channels} , iH , iW(minibatch,in_channels,iH,iW"}, {"name": "weight", "is_optional": false, "type": "out_channels,in_channelsgroups,kH,kW", "description": " filters of shape (out_channels,in_channelsgroups,kH,kW(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kH , kW(out_channels,groupsin_channels\u200b,kH,kW"}, {"name": "bias", "is_optional": true, "type": "out_channels", "default_value": "None", "description": " optional bias tensor of shape (out_channels(\\text{out\\_channels}(out_channels. Default"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": " the stride of the convolving kernel. Can be a single number or atuple (sH, sW. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " implicit paddings on both sides of the input. Can be asingle number or a tuple (padH, padW. Default"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": " the spacing between kernel elements. Can be a single number ora tuple (dH, dW. Default"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": " split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by thenumber of groups. Default"}]}},
{"id": "torch.nn.functional.conv3d", "type": "function", "code": "torch.nn.functional.conv3d(input,weight,bias=None,stride=1,padding=0,dilation=1,groups=1)", "example": " filters = torch.randn(33, 16, 3, 3, 3)\n inputs = torch.randn(20, 16, 50, 10, 20)\n F.conv3d(inputs, filters)\n\n", "summary": "Applies a 3D convolution over an input image composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.conv3d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iT,iH,iW", "description": " input tensor of shape (minibatch,in_channels,iT,iH,iW(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW(minibatch,in_channels,iT,iH,iW"}, {"name": "weight", "is_optional": false, "type": "out_channels,in_channelsgroups,kT,kH,kW", "description": " filters of shape (out_channels,in_channelsgroups,kT,kH,kW(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kT , kH , kW(out_channels,groupsin_channels\u200b,kT,kH,kW"}, {"name": "bias", "is_optional": true, "type": "out_channels", "default_value": "None", "description": " optional bias tensor of shape (out_channels(\\text{out\\_channels}(out_channels. Default"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": " the stride of the convolving kernel. Can be a single number or atuple (sT, sH, sW. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " implicit paddings on both sides of the input. Can be asingle number or a tuple (padT, padH, padW. Default"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": " the spacing between kernel elements. Can be a single number ora tuple (dT, dH, dW. Default"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": " split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible bythe number of groups. Default"}]}},
{"id": "torch.nn.functional.conv_transpose1d", "type": "function", "code": "torch.nn.functional.conv_transpose1d(input,weight,bias=None,stride=1,padding=0,output_padding=0,groups=1,dilation=1)", "example": " inputs = torch.randn(20, 16, 50)\n weights = torch.randn(16, 33, 5)\n F.conv_transpose1d(inputs, weights)\n\n", "summary": "Applies a 1D transposed convolution operator over an input signal composed of several input planes, sometimes also called \u201cdeconvolution\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.conv_transpose1d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iW", "description": " input tensor of shape (minibatch,in_channels,iW(\\text{minibatch} , \\text{in\\_channels} , iW(minibatch,in_channels,iW"}, {"name": "weight", "is_optional": false, "type": "in_channels,out_channelsgroups,kW", "description": " filters of shape (in_channels,out_channelsgroups,kW(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kW(in_channels,groupsout_channels\u200b,kW"}, {"name": "bias", "is_optional": true, "type": "out_channels", "default_value": "None", "description": " optional bias of shape (out_channels(\\text{out\\_channels}(out_channels. Default"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": " the stride of the convolving kernel. Can be a single number or atuple (sW,. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " dilation * (kernel_size - 1 - padding zero-padding will be added to bothsides of each dimension in the input. Can be a single number or a tuple(padW,. Default"}, {"name": "output_padding", "is_optional": true, "type": "int", "default_value": "0", "description": " additional size added to one side of each dimension in theoutput shape. Can be a single number or a tuple (out_padW. Default"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": " split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by thenumber of groups. Default"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": " the spacing between kernel elements. Can be a single number ora tuple (dW,. Default"}]}},
{"id": "torchvision.models.detection.keypointrcnn_resnet50_fpn", "type": "function", "code": "torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=False,progress=True,num_classes=2,num_keypoints=17,pretrained_backbone=True,**kwargs)", "example": "  model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True)  model.eval()  x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]  predictions = model(x)    Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on COCO train2017 progress (bool) \u2013 If True, displays a progress bar of the download to stderr    ", "summary": "Constructs a Keypoint R-CNN model with a ResNet-50-FPN backbone", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.models.detection.keypointrcnn_resnet50_fpn", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on COCO train2017"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "2", "description": ""}, {"name": "num_keypoints", "is_optional": true, "type": "int", "default_value": "17", "description": ""}, {"name": "pretrained_backbone", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.video.r3d_18", "type": "function", "code": "torchvision.models.video.r3d_18(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Construct 18 layer Resnet3D model as in https://arxiv.org/abs/1711.11248  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on Kinetics-400 progress (bool) \u2013 If True, displays a progress bar of the download to stderr   Returns R3D-18 network  Return type nn.Module   ", "returns": "R3D-18 network", "shape": "NA", "code-info": {"name": "torchvision.models.video.r3d_18", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on Kinetics-400"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.video.mc3_18", "type": "function", "code": "torchvision.models.video.mc3_18(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Constructor for 18 layer Mixed Convolution network as in https://arxiv.org/abs/1711.11248  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on Kinetics-400 progress (bool) \u2013 If True, displays a progress bar of the download to stderr   Returns MC3 Network definition  Return type nn.Module   ", "returns": "MC3 Network definition", "shape": "NA", "code-info": {"name": "torchvision.models.video.mc3_18", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on Kinetics-400"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.models.video.r2plus1d_18", "type": "function", "code": "torchvision.models.video.r2plus1d_18(pretrained=False,progress=True,**kwargs)", "example": "NA", "summary": "Constructor for the 18 layer deep R(2+1)D network as in https://arxiv.org/abs/1711.11248  Parameters  pretrained (bool) \u2013 If True, returns a model pre-trained on Kinetics-400 progress (bool) \u2013 If True, displays a progress bar of the download to stderr   Returns R(2+1)D-18 network  Return type nn.Module   ", "returns": "R(2+1)D-18 network", "shape": "NA", "code-info": {"name": "torchvision.models.video.r2plus1d_18", "parameters": [{"name": "pretrained", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, returns a model pre-trained on Kinetics-400"}, {"name": "progress", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, displays a progress bar of the download to stderr"}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.FiveCrop", "type": "class", "code": "torchvision.transforms.FiveCrop(size)", "example": " transform = Compose([\n    FiveCrop(size), # this is a list of PIL Images\n    Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])) # returns a 4D tensor\n ])\n #In your test loop you can do the following:\n input, target = batch # input is a 5d tensor, target is 2d\n bs, ncrops, c, h, w = input.size()\n result = model(input.view(-1, c, h, w)) # fuse batch size and ncrops\n result_avg = result.view(bs, ncrops, -1).mean(1) # avg over crops\n\n", "summary": "Crop the given PIL Image into four corners and the central crop  Note This transform returns a tuple of images and there may be a mismatch in the number of inputs and targets your Dataset returns", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.FiveCrop", "parameters": [{"name": "size", "is_optional": false, "type": "sequence or int", "description": " Desired output size of the crop. If size is an intinstead of sequence like (h, w, a square crop of size (size, size is made."}]}},
{"id": "torchvision.transforms.Grayscale", "type": "class", "code": "torchvision.transforms.Grayscale(num_output_channels=1)", "example": "NA", "summary": "Convert image to grayscale", "returns": "Grayscale version of the input.- If num_output_channels == 1 : returned image is single channel- If num_output_channels == 3 : returned image is 3 channel with r == g == b", "shape": "NA", "code-info": {"name": "torchvision.transforms.Grayscale", "parameters": [{"name": "num_output_channels", "is_optional": true, "type": "int", "default_value": "1", "description": " (1 or 3 number of channels desired for output image"}]}},
{"id": "torchvision.transforms.Pad", "type": "class", "code": "torchvision.transforms.Pad(padding,fill=0,padding_mode='constant')", "example": "NA", "summary": "Pad the given PIL Image on all sides with the given \u201cpad\u201d value", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.Pad", "parameters": [{"name": "padding", "is_optional": false, "type": "int or tuple", "description": " Padding on each border. If a single int is provided thisis used to pad all borders. If tuple of length 2 is provided this is the paddingon left/right and top/bottom respectively. If a tuple of length 4 is providedthis is the padding for the left, top, right and bottom bordersrespectively."}, {"name": "fill", "is_optional": true, "type": "int", "default_value": "0", "description": " Pixel fill value for constant fill. Default is 0. If a tuple oflength 3, it is used to fill R, G, B channels respectively.This value is only used when the padding_mode is constant"}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'constant'", "description": " Type of padding. Should be"}]}},
{"id": "torch.distributions.distribution.Distribution.icdf", "type": "method", "code": "torch.distributions.distribution.Distribution.icdf(value)", "example": "NA", "summary": "Returns the inverse cumulative density/mass function evaluated at value", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "Tensor", "description": " "}]}},
{"id": "torch.distributions.distribution.Distribution.log_prob", "type": "method", "code": "torch.distributions.distribution.Distribution.log_prob(value)", "example": "NA", "summary": "Returns the log of the probability density/mass function evaluated at value", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "Tensor", "description": " "}]}},
{"id": "torch.distributions.distribution.Distribution.mean", "type": "method", "code": "torch.distributions.distribution.Distribution.mean", "example": "NA", "summary": "Returns the mean of the distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.mean", "parameters": []}},
{"id": "torch.distributions.distribution.Distribution.perplexity", "type": "method", "code": "torch.distributions.distribution.Distribution.perplexity()", "example": "NA", "summary": "Returns perplexity of distribution, batched over batch_shape", "returns": "Tensor of shape batch_shape.", "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.perplexity", "parameters": []}},
{"id": "torch.distributions.distribution.Distribution.rsample", "type": "method", "code": "torch.distributions.distribution.Distribution.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples if the distribution parameters are batched", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.distribution.Distribution.sample", "type": "method", "code": "torch.distributions.distribution.Distribution.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "Generates a sample_shape shaped sample or sample_shape shaped batch of samples if the distribution parameters are batched", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.distribution.Distribution.sample_n", "type": "method", "code": "torch.distributions.distribution.Distribution.sample_n(n)", "example": "NA", "summary": "Generates n samples or n batches of samples if the distribution parameters are batched", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.sample_n", "parameters": [{"name": "n", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.distribution.Distribution.stddev", "type": "method", "code": "torch.distributions.distribution.Distribution.stddev", "example": "NA", "summary": "Returns the standard deviation of the distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.stddev", "parameters": []}},
{"id": "torch.distributions.distribution.Distribution.support", "type": "method", "code": "torch.distributions.distribution.Distribution.support", "example": "NA", "summary": "Returns a Constraint object representing this distribution\u2019s support", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.support", "parameters": []}},
{"id": "torch.distributions.distribution.Distribution.variance", "type": "method", "code": "torch.distributions.distribution.Distribution.variance", "example": "NA", "summary": "Returns the variance of the distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution.variance", "parameters": []}},
{"id": "torch.distributions.exp_family.ExponentialFamily.entropy", "type": "method", "code": "torch.distributions.exp_family.ExponentialFamily.entropy()", "example": "NA", "summary": "Method to compute the entropy using Bregman divergence of the log normalizer", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exp_family.ExponentialFamily.entropy", "parameters": []}},
{"id": "torch.distributed.isend", "type": "function", "code": "torch.distributed.isend(tensor,dst,group=&lt;objectobject&gt;,tag=0)", "example": "NA", "summary": "Sends a tensor asynchronously", "returns": "A distributed request object.None, if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.isend", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " Tensor to send."}, {"name": "dst", "is_optional": false, "type": "int", "description": " Destination rank."}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "tag", "is_optional": true, "type": "int", "default_value": "0", "description": " Tag to match send with remote recv"}]}},
{"id": "torch.distributed.irecv", "type": "function", "code": "torch.distributed.irecv(tensor,src,group=&lt;objectobject&gt;,tag=0)", "example": "NA", "summary": "Receives a tensor asynchronously", "returns": "A distributed request object.None, if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.irecv", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " Tensor to fill with received data."}, {"name": "src", "is_optional": false, "type": "int", "description": " Source rank."}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "tag", "is_optional": true, "type": "int", "default_value": "0", "description": " Tag to match recv with remote send"}]}},
{"id": "torch.distributed.broadcast", "type": "function", "code": "torch.distributed.broadcast(tensor,src,group=&lt;objectobject&gt;,async_op=False)", "example": "NA", "summary": "Broadcasts the tensor to the whole group", "returns": "Async work handle, if async_op is set to True.None, if not async_op or if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.broadcast", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " Data to be sent if src is the rank of currentprocess, and tensor to be used to save received data otherwise."}, {"name": "src", "is_optional": false, "type": "Tensor", "description": " Source rank."}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether this op should be an async op"}]}},
{"id": "torch.distributed.all_reduce", "type": "function", "code": "torch.distributed.all_reduce(tensor,op=ReduceOp.SUM,group=&lt;objectobject&gt;,async_op=False)", "example": "NA", "summary": "Reduces the tensor data across all machines in such a way that all get the final result", "returns": "Async work handle, if async_op is set to True.None, if not async_op or if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.all_reduce", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " Input and output of the collective. The functionoperates in-place."}, {"name": "op", "is_optional": true, "type": "Tensor", "default_value": "ReduceOp.SUM", "description": " One of the values fromtorch.distributed.ReduceOpenum.  Specifies an operation used for element-wise reductions."}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether this op should be an async op"}]}},
{"id": "torch.distributed.reduce", "type": "function", "code": "torch.distributed.reduce(tensor,dst,op=ReduceOp.SUM,group=&lt;objectobject&gt;,async_op=False)", "example": "NA", "summary": "Reduces the tensor data across all machines", "returns": "Async work handle, if async_op is set to True.None, if not async_op or if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.reduce", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " Input and output of the collective. The functionoperates in-place."}, {"name": "dst", "is_optional": false, "type": "int", "description": " Destination rank"}, {"name": "op", "is_optional": true, "type": "Tensor", "default_value": "ReduceOp.SUM", "description": " One of the values fromtorch.distributed.ReduceOpenum.  Specifies an operation used for element-wise reductions."}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether this op should be an async op"}]}},
{"id": "torch.distributed.all_gather", "type": "function", "code": "torch.distributed.all_gather(tensor_list,tensor,group=&lt;objectobject&gt;,async_op=False)", "example": "NA", "summary": "Gathers tensors from the whole group in a list", "returns": "Async work handle, if async_op is set to True.None, if not async_op or if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.all_gather", "parameters": [{"name": "tensor_list", "is_optional": false, "type": "list[Tensor]", "description": " Output list. It should containcorrectly-sized tensors to be used for output of the collective."}, {"name": "tensor", "is_optional": false, "type": "list[Tensor]", "description": " Tensor to be broadcast from current process."}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether this op should be an async op"}]}},
{"id": "torch.cuda.stream", "type": "function", "code": "torch.cuda.stream(stream)", "example": "NA", "summary": "Context-manager that selects a given stream", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.stream", "parameters": [{"name": "stream", "is_optional": false, "type": "Stream", "description": " selected stream. This manager is a no-op if it\u2019sNone."}]}},
{"id": "torch.cuda.synchronize", "type": "function", "code": "torch.cuda.synchronize(device=None)", "example": "NA", "summary": "Waits for all kernels in all streams on a CUDA device to complete", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.synchronize", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " device for which to synchronize.It uses the current device, given by current_device(,if device is None (default."}]}},
{"id": "torch.cuda.get_rng_state", "type": "function", "code": "torch.cuda.get_rng_state(device='cuda')", "example": "NA", "summary": "Returns the random number generator state of the specified GPU as a ByteTensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.get_rng_state", "parameters": [{"name": "device", "is_optional": true, "type": "string", "default_value": "'cuda'", "description": " The device to return the RNG state of.Default"}]}},
{"id": "torch.cuda.get_rng_state_all", "type": "function", "code": "torch.cuda.get_rng_state_all()", "example": "NA", "summary": "Returns a tuple of ByteTensor representing the random number states of all devices", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.get_rng_state_all", "parameters": []}},
{"id": "torch.cuda.set_rng_state", "type": "function", "code": "torch.cuda.set_rng_state(new_state,device='cuda')", "example": "NA", "summary": "Sets the random number generator state of the specified GPU", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.set_rng_state", "parameters": [{"name": "new_state", "is_optional": false, "type": "torch.ByteTensor", "description": " The desired state"}, {"name": "device", "is_optional": true, "type": "string", "default_value": "'cuda'", "description": " The device to set the RNG state.Default"}]}},
{"id": "torch.cuda.set_rng_state_all", "type": "function", "code": "torch.cuda.set_rng_state_all(new_states)", "example": "NA", "summary": "Sets the random number generator state of all devices", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.set_rng_state_all", "parameters": [{"name": "new_states", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.cuda.manual_seed", "type": "function", "code": "torch.cuda.manual_seed(seed)", "example": "NA", "summary": "Sets the seed for generating random numbers for the current GPU", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.manual_seed", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": " The desired seed."}]}},
{"id": "torch.cuda.manual_seed_all", "type": "function", "code": "torch.cuda.manual_seed_all(seed)", "example": "NA", "summary": "Sets the seed for generating random numbers on all GPUs", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.manual_seed_all", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": " The desired seed."}]}},
{"id": "torch.jit.ignore", "type": "function", "code": "torch.jit.ignore(drop=False,**kwargs)", "example": "import torch\nimport torch.nn as nn\n\nclass MyModule(nn.Module):\n    @torch.jit.ignore\n    def debugger(self, x):\n        import pdb\n        pdb.set_trace()\n\n    def forward(self, x):\n        x += 10\n        # The compiler would normally try to compile `debugger`,\n        # but since it is `@ignore`d, it will be left as a call\n        # to Python\n        self.debugger(x)\n        return x\n\nm = torch.jit.script(MyModule())\n\n# Error! The call `debugger` cannot be saved since it calls into Python\nm.save(\"m.pt\")\n\n", "summary": "This decorator indicates to the compiler that a function or method should be ignored and left as a Python function", "returns": null, "shape": "NA", "code-info": {"name": "torch.jit.ignore", "parameters": [{"name": "drop", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.jit.unused", "type": "function", "code": "torch.jit.unused(fn)", "example": "import torch\nimport torch.nn as nn\n\nclass MyModule(nn.Module):\n    def __init__(self, use_memory_efficent):\n        super(MyModule, self).__init__()\n        self.use_memory_efficent = use_memory_efficent\n\n    @torch.jit.unused\n    def memory_efficient(self, x):\n        import pdb\n        pdb.set_trace()\n        return x + 10\n\n    def forward(self, x):\n        # Use not-yet-scriptable memory efficient mode\n        if self.use_memory_efficient:\n            return self.memory_efficient(x)\n        else:\n            return x + 10\n\nm = torch.jit.script(MyModule(use_memory_efficent=False))\nm.save(\"m.pt\")\n\nm = torch.jit.script(MyModule(use_memory_efficient=True))\n# exception raised\nm(torch.rand(100))\n\n", "summary": "This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception", "returns": null, "shape": "NA", "code-info": {"name": "torch.jit.unused", "parameters": [{"name": "fn", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.jit.is_scripting", "type": "function", "code": "torch.jit.is_scripting()", "example": "NA", "summary": "Function that returns True when in compilation and False otherwise", "returns": null, "shape": "NA", "code-info": {"name": "torch.jit.is_scripting", "parameters": []}},
{"id": "torch.jit.ScriptModule.code", "type": "method", "code": "torch.jit.ScriptModule.code", "example": "NA", "summary": "Returns a pretty-printed representation (as valid Python syntax) of the internal graph for the forward method", "returns": null, "shape": "NA", "code-info": {"name": "torch.jit.ScriptModule.code", "parameters": []}},
{"id": "torch.jit.ScriptModule.graph", "type": "method", "code": "torch.jit.ScriptModule.graph", "example": "NA", "summary": "Returns a string representation of the internal graph for the forward method", "returns": null, "shape": "NA", "code-info": {"name": "torch.jit.ScriptModule.graph", "parameters": []}},
{"id": "torch.jit.ScriptModule.save", "type": "method", "code": "torch.jit.ScriptModule.save(f,_extra_files=ExtraFilesMap{})", "example": "NA", "summary": "See torch.jit.save for details", "returns": null, "shape": "NA", "code-info": {"name": "torch.jit.ScriptModule.save", "parameters": [{"name": "f", "is_optional": false, "type": "others", "description": ""}, {"name": "_extra_files", "is_optional": true, "type": "others", "default_value": "ExtraFilesMap{}", "description": ""}]}},
{"id": "torch.Tensor.detach", "type": "method", "code": "torch.Tensor.detach()", "example": "NA", "summary": "Returns a new Tensor, detached from the current graph", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.detach", "parameters": []}},
{"id": "torch.Tensor.detach_", "type": "method", "code": "torch.Tensor.detach_()", "example": "NA", "summary": "Detaches the Tensor from the graph that created it, making it a leaf", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.detach_", "parameters": []}},
{"id": "torch.Tensor.register_hook", "type": "method", "code": "torch.Tensor.register_hook(hook)", "example": "  v = torch.tensor([0., 0., 0.], requires_grad=True)  h = v.register_hook(lambda grad: grad * 2)  # double the gradient  v.backward(torch.tensor([1., 2., 3.]))  v.grad   2  4  6 [torch.FloatTensor of size (3,)]   h.remove()  # removes the hook   ", "summary": "Registers a backward hook", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.register_hook", "parameters": [{"name": "hook", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.retain_grad", "type": "method", "code": "torch.Tensor.retain_grad()", "example": "NA", "summary": "Enables .grad attribute for non-leaf Tensors", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.retain_grad", "parameters": []}},
{"id": "torch.autograd.Function.backward", "type": "method", "code": "torch.autograd.Function.backward(ctx,*grad_outputs)", "example": "NA", "summary": "Defines a formula for differentiating the operation", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.Function.backward", "parameters": [{"name": "ctx", "is_optional": false, "type": "others", "description": ""}, {"name": "*grad_outputs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.autograd.Function.forward", "type": "method", "code": "torch.autograd.Function.forward(ctx,*args,**kwargs)", "example": "NA", "summary": "Performs the operation", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.Function.forward", "parameters": [{"name": "ctx", "is_optional": false, "type": "others", "description": ""}, {"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.autograd.function._ContextMethodMixin.mark_dirty", "type": "method", "code": "torch.autograd.function._ContextMethodMixin.mark_dirty(*args)", "example": "NA", "summary": "Marks given tensors as modified in an in-place operation", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.function._ContextMethodMixin.mark_dirty", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.quantized.functional.max_pool2d", "type": "function", "code": "torch.nn.quantized.functional.max_pool2d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)", "example": "NA", "summary": "Applies a 2D max pooling over a quantized input signal composed of several quantized input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.functional.max_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "return_indices", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.quantized.functional.adaptive_avg_pool2d", "type": "function", "code": "torch.nn.quantized.functional.adaptive_avg_pool2d(input,output_size)", "example": "NA", "summary": "Applies a 2D adaptive average pooling over a quantized input signal composed of several quantized input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.functional.adaptive_avg_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "output_size", "is_optional": false, "type": "int", "description": " the target output size (single integer ordouble-integer tuple"}]}},
{"id": "torch.nn.quantized.functional.avg_pool2d", "type": "function", "code": "torch.nn.quantized.functional.avg_pool2d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)", "example": "NA", "summary": "Applies 2D average-pooling operation in kH\u00d7kWkH \\times kWkH\u00d7kW   regions by step size sH\u00d7sWsH \\times sWsH\u00d7sW   steps", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.functional.avg_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iH,iW", "description": " quantized input tensor (minibatch,in_channels,iH,iW(\\text{minibatch} , \\text{in\\_channels} , iH , iW(minibatch,in_channels,iH,iW"}, {"name": "kernel_size", "is_optional": false, "type": "kH, kW", "description": " size of the pooling region. Can be a single number or atuple (kH, kW"}, {"name": "stride", "is_optional": true, "type": "sH, sW", "default_value": "None", "description": " stride of the pooling operation. Can be a single number or atuple (sH, sW. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " implicit zero paddings on both sides of the input. Can be asingle number or a tuple (padH, padW. Default"}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": " when True, will use ceil instead of floor in the formulato compute the output shape. Default"}, {"name": "count_include_pad", "is_optional": true, "type": "bool", "default_value": "True", "description": " when True, will include the zero-padding in theaveraging calculation. Default"}, {"name": "divisor_override", "is_optional": true, "type": "divisor_override : if specified, it will be used as divisor, otherwisesize of the pooling region will be used. Default: Non", "default_value": "None", "description": " if specified, it will be used as divisor, otherwisesize of the pooling region will be used. Default"}]}},
{"id": "torch.nn.quantized.functional.interpolate", "type": "function", "code": "torch.nn.quantized.functional.interpolate(input,size=None,scale_factor=None,mode='nearest',align_corners=None)", "example": "NA", "summary": "Down/up samples the input to either the given size or the given scale_factor See torch.nn.functional.interpolate() for implementation details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.functional.interpolate", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor"}, {"name": "size", "is_optional": true, "type": "int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]", "default_value": "None", "description": " output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "float or Tuple[float]", "default_value": "None", "description": " multiplier for spatial size. Has to match input size if it is a tuple."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'nearest'", "description": " algorithm used for upsampling"}, {"name": "align_corners", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Geometrically, we consider the pixels of theinput and output as squares rather than points.If set to True, the input and output tensors are aligned by thecenter points of their corner pixels, preserving the values at the corner pixels.If set to False, the input and output tensors are aligned by the cornerpoints of their corner pixels, and the interpolation uses edge value paddingfor out-of-boundary values, making this operation independent of input sizewhen scale_factor is kept the same. This only has an effect when modeis 'bilinear'.Default"}]}},
{"id": "torch.nn.quantized.functional.upsample", "type": "function", "code": "torch.nn.quantized.functional.upsample(input,size=None,scale_factor=None,mode='nearest',align_corners=None)", "example": "NA", "summary": "Upsamples the input to either the given size or the given scale_factor  Warning This function is deprecated in favor of torch.nn.quantized.functional.interpolate()", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.functional.upsample", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " quantized input tensor"}, {"name": "size", "is_optional": true, "type": "int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]", "default_value": "None", "description": " output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "float or Tuple[float]", "default_value": "None", "description": " multiplier for spatial size. Has to be an integer."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'nearest'", "description": " algorithm used for upsampling"}, {"name": "align_corners", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Geometrically, we consider the pixels of theinput and output as squares rather than points.If set to True, the input and output tensors are aligned by thecenter points of their corner pixels, preserving the values at the corner pixels.If set to False, the input and output tensors are aligned by the cornerpoints of their corner pixels, and the interpolation uses edge value paddingfor out-of-boundary values, making this operation independent of input sizewhen scale_factor is kept the same. This only has an effect when modeis 'bilinear'.Default"}]}},
{"id": "torch.optim.Adagrad", "type": "class", "code": "torch.optim.Adagrad(params,lr=0.01,lr_decay=0,weight_decay=0,initial_accumulator_value=0,eps=1e-10)", "example": "NA", "summary": "Implements Adagrad algorithm", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Adagrad", "parameters": [{"name": "params", "is_optional": false, "type": "iterable", "description": " iterable of parameters to optimize or dicts definingparameter groups"}, {"name": "lr", "is_optional": true, "type": "float, optional", "default_value": "0.01", "description": " learning rate (default"}, {"name": "lr_decay", "is_optional": true, "type": "int", "default_value": "0", "description": " learning rate decay (default"}, {"name": "weight_decay", "is_optional": true, "type": "int", "default_value": "0", "description": " weight decay (L2 penalty (default"}, {"name": "initial_accumulator_value", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "eps", "is_optional": true, "type": "float, optional", "default_value": "1e-10", "description": " term added to the denominator to improvenumerical stability (default"}]}},
{"id": "torch.optim.Adam", "type": "class", "code": "torch.optim.Adam(params,lr=0.001,betas=(0.9,0.999)", "example": "NA", "summary": "Implements Adam algorithm", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Adam", "parameters": [{"name": "params", "is_optional": false, "type": "iterable", "description": " iterable of parameters to optimize or dicts definingparameter groups"}, {"name": "lr", "is_optional": true, "type": "float, optional", "default_value": "0.001", "description": " learning rate (default"}, {"name": "betas", "is_optional": false, "type": "Tuple[float, float], optional", "description": " coefficients used for computingrunning averages of gradient and its square (default"}]}},
{"id": "torch.optim.AdamW", "type": "class", "code": "torch.optim.AdamW(params,lr=0.001,betas=(0.9,0.999)", "example": "NA", "summary": "Implements AdamW algorithm", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.AdamW", "parameters": [{"name": "params", "is_optional": false, "type": "iterable", "description": " iterable of parameters to optimize or dicts definingparameter groups"}, {"name": "lr", "is_optional": true, "type": "float, optional", "default_value": "0.001", "description": " learning rate (default"}, {"name": "betas", "is_optional": false, "type": "Tuple[float, float], optional", "description": " coefficients used for computingrunning averages of gradient and its square (default"}]}},
{"id": "torch.optim.SparseAdam", "type": "class", "code": "torch.optim.SparseAdam(params,lr=0.001,betas=(0.9,0.999)", "example": "NA", "summary": "Implements lazy version of Adam algorithm suitable for sparse tensors", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.SparseAdam", "parameters": [{"name": "params", "is_optional": false, "type": "iterable", "description": " iterable of parameters to optimize or dicts definingparameter groups"}, {"name": "lr", "is_optional": true, "type": "float, optional", "default_value": "0.001", "description": " learning rate (default"}, {"name": "betas", "is_optional": false, "type": "Tuple[float, float], optional", "description": " coefficients used for computingrunning averages of gradient and its square (default"}]}},
{"id": "torchvision.datasets.Cityscapes", "type": "class", "code": "torchvision.datasets.Cityscapes(root,split='train',mode='fine',target_type='instance',transform=None,target_transform=None,transforms=None)", "example": "dataset = Cityscapes('./data/cityscapes', split='train', mode='fine',\n                     target_type='semantic')\n\nimg, smnt = dataset[0]\n\n", "summary": "Cityscapes Dataset", "returns": "(image, target) where target is a tuple of all target types if target_type is a list with morethan one item. Otherwise target is a json object if target_type=\u201dpolygon\u201d, else the image segmentation.", "shape": "NA", "code-info": {"name": "torchvision.datasets.Cityscapes", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of dataset where directory leftImg8bitand gtFine or gtCoarse are located."}, {"name": "split", "is_optional": true, "type": "string", "default_value": "'train'", "description": " The image split to use, train, test or val if mode=\u201dgtFine\u201dotherwise train, train_extra or val"}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'fine'", "description": " The quality mode to use, gtFine or gtCoarse"}, {"name": "target_type", "is_optional": true, "type": "string", "default_value": "'instance'", "description": " Type of target to use, instance, semantic, polygonor color. Can also be a list to output a tuple with all specified target types."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in a PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "transforms", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes input sample and its target as entryand returns a transformed version."}]}},
{"id": "torchvision.datasets.SBDataset", "type": "class", "code": "torchvision.datasets.SBDataset(root,image_set='train',mode='boundaries',download=False,transforms=None)", "example": "NA", "summary": "Semantic Boundaries Dataset The SBD currently contains annotations from 11355 images taken from the PASCAL VOC 2011 dataset", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.datasets.SBDataset", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of the Semantic Boundaries Dataset"}, {"name": "image_set", "is_optional": true, "type": "string", "default_value": "'train'", "description": " Select the image_set to use, train, val or train_noval.Image set train_noval excludes VOC 2012 val images."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'boundaries'", "description": " Select target type. Possible values \u2018boundaries\u2019 or \u2018segmentation\u2019.In case of \u2018boundaries\u2019, the target is an array of shape [num_classes, H, W],where num_classes=20."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": " If true, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again."}, {"name": "transforms", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes input sample and its target as entryand returns a transformed version. Input sample is PIL image and target is a numpy arrayif mode=\u2019boundaries\u2019 or PIL image if mode=\u2019segmentation\u2019."}]}},
{"id": "torchvision.datasets.USPS", "type": "class", "code": "torchvision.datasets.USPS(root,train=True,transform=None,target_transform=None,download=False)", "example": "NA", "summary": "USPS Dataset", "returns": "(image, target) where target is index of the target class.", "shape": "NA", "code-info": {"name": "torchvision.datasets.USPS", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of dataset to store``USPS`` data files."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, creates dataset from usps.bz2,otherwise from usps.t.bz2."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in an PIL imageand returns a transformed version. E.g, transforms.RandomCrop"}, {"name": "target_transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that takes in thetarget and transforms it."}, {"name": "download", "is_optional": true, "type": "bool", "default_value": "False", "description": " If true, downloads the dataset from the internet andputs it in root directory. If dataset is already downloaded, it is notdownloaded again."}]}},
{"id": "torch.Tensor.new_full", "type": "method", "code": "torch.Tensor.new_full(size,fill_value,dtype=None,device=None,requires_grad=False)", "example": "  tensor = torch.ones((2,), dtype=torch.float64)  tensor.new_full((3, 4), 3.141592) tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],         [ 3.1416,  3.1416,  3.1416,  3.1416],         [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)   ", "summary": "Returns a Tensor of size size filled with fill_value", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.new_full", "parameters": [{"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "fill_value", "is_optional": false, "type": "scalar", "description": " the number to fill the output tensor with."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired type of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.Tensor.new_empty", "type": "method", "code": "torch.Tensor.new_empty(size,dtype=None,device=None,requires_grad=False)", "example": "  tensor = torch.ones(())  tensor.new_empty((2, 3)) tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],         [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])   ", "summary": "Returns a Tensor of size size filled with uninitialized data", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.new_empty", "parameters": [{"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired type of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.Tensor.new_ones", "type": "method", "code": "torch.Tensor.new_ones(size,dtype=None,device=None,requires_grad=False)", "example": "  tensor = torch.tensor((), dtype=torch.int32)  tensor.new_ones((2, 3)) tensor([[ 1,  1,  1],         [ 1,  1,  1]], dtype=torch.int32)   ", "summary": "Returns a Tensor of size size filled with 1", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.new_ones", "parameters": [{"name": "size", "is_optional": false, "type": "int...", "description": " a list, tuple, or torch.Size of integers defining theshape of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired type of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.Tensor.new_zeros", "type": "method", "code": "torch.Tensor.new_zeros(size,dtype=None,device=None,requires_grad=False)", "example": "  tensor = torch.tensor((), dtype=torch.float64)  tensor.new_zeros((2, 3)) tensor([[ 0.,  0.,  0.],         [ 0.,  0.,  0.]], dtype=torch.float64)   ", "summary": "Returns a Tensor of size size filled with 0", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.new_zeros", "parameters": [{"name": "size", "is_optional": false, "type": "int...", "description": " a list, tuple, or torch.Size of integers defining theshape of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired type of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.Tensor.abs", "type": "method", "code": "torch.Tensor.abs()", "example": "NA", "summary": "See torch.abs() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.abs", "parameters": []}},
{"id": "torch.Tensor.abs_", "type": "method", "code": "torch.Tensor.abs_()", "example": "NA", "summary": "In-place version of abs() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.abs_", "parameters": []}},
{"id": "torch.Tensor.acos", "type": "method", "code": "torch.Tensor.acos()", "example": "NA", "summary": "See torch.acos() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.acos", "parameters": []}},
{"id": "torch.Tensor.acos_", "type": "method", "code": "torch.Tensor.acos_()", "example": "NA", "summary": "In-place version of acos() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.acos_", "parameters": []}},
{"id": "torch.Tensor.add", "type": "method", "code": "torch.Tensor.add(value)", "example": "NA", "summary": "add(value=1, other) -&gt; Tensor See torch.add() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.add", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.conv_transpose2d", "type": "function", "code": "torch.nn.functional.conv_transpose2d(input,weight,bias=None,stride=1,padding=0,output_padding=0,groups=1,dilation=1)", "example": " # With square kernels and equal stride\n inputs = torch.randn(1, 4, 5, 5)\n weights = torch.randn(4, 8, 3, 3)\n F.conv_transpose2d(inputs, weights, padding=1)\n\n", "summary": "Applies a 2D transposed convolution operator over an input image composed of several input planes, sometimes also called \u201cdeconvolution\u201d", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.conv_transpose2d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iH,iW", "description": " input tensor of shape (minibatch,in_channels,iH,iW(\\text{minibatch} , \\text{in\\_channels} , iH , iW(minibatch,in_channels,iH,iW"}, {"name": "weight", "is_optional": false, "type": "in_channels,out_channelsgroups,kH,kW", "description": " filters of shape (in_channels,out_channelsgroups,kH,kW(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kH , kW(in_channels,groupsout_channels\u200b,kH,kW"}, {"name": "bias", "is_optional": true, "type": "out_channels", "default_value": "None", "description": " optional bias of shape (out_channels(\\text{out\\_channels}(out_channels. Default"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": " the stride of the convolving kernel. Can be a single number or atuple (sH, sW. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " dilation * (kernel_size - 1 - padding zero-padding will be added to bothsides of each dimension in the input. Can be a single number or a tuple(padH, padW. Default"}, {"name": "output_padding", "is_optional": true, "type": "int", "default_value": "0", "description": " additional size added to one side of each dimension in theoutput shape. Can be a single number or a tuple (out_padH, out_padW.Default"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": " split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by thenumber of groups. Default"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": " the spacing between kernel elements. Can be a single number ora tuple (dH, dW. Default"}]}},
{"id": "torch.nn.functional.conv_transpose3d", "type": "function", "code": "torch.nn.functional.conv_transpose3d(input,weight,bias=None,stride=1,padding=0,output_padding=0,groups=1,dilation=1)", "example": " inputs = torch.randn(20, 16, 50, 10, 20)\n weights = torch.randn(16, 33, 3, 3, 3)\n F.conv_transpose3d(inputs, weights)\n\n", "summary": "Applies a 3D transposed convolution operator over an input image composed of several input planes, sometimes also called \u201cdeconvolution\u201d See ConvTranspose3d for details and output shape", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.conv_transpose3d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iT,iH,iW", "description": " input tensor of shape (minibatch,in_channels,iT,iH,iW(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW(minibatch,in_channels,iT,iH,iW"}, {"name": "weight", "is_optional": false, "type": "in_channels,out_channelsgroups,kT,kH,kW", "description": " filters of shape (in_channels,out_channelsgroups,kT,kH,kW(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kT , kH , kW(in_channels,groupsout_channels\u200b,kT,kH,kW"}, {"name": "bias", "is_optional": true, "type": "out_channels", "default_value": "None", "description": " optional bias of shape (out_channels(\\text{out\\_channels}(out_channels. Default"}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": " the stride of the convolving kernel. Can be a single number or atuple (sT, sH, sW. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " dilation * (kernel_size - 1 - padding zero-padding will be added to bothsides of each dimension in the input. Can be a single number or a tuple(padT, padH, padW. Default"}, {"name": "output_padding", "is_optional": true, "type": "int", "default_value": "0", "description": " additional size added to one side of each dimension in theoutput shape. Can be a single number or a tuple(out_padT, out_padH, out_padW. Default"}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": " split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by thenumber of groups. Default"}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": " the spacing between kernel elements. Can be a single number ora tuple (dT, dH, dW. Default"}]}},
{"id": "torchvision.transforms.RandomAffine", "type": "class", "code": "torchvision.transforms.RandomAffine(degrees,translate=None,scale=None,shear=None,resample=False,fillcolor=0)", "example": "NA", "summary": "Random affine transformation of the image keeping center invariant  Parameters  degrees (sequence or python:float or python:int) \u2013 Range of degrees to select from", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomAffine", "parameters": [{"name": "degrees", "is_optional": false, "type": "sequence or float or int", "description": " Range of degrees to select from.If degrees is a number instead of sequence like (min, max, the range of degreeswill be (-degrees, +degrees. Set to 0 to deactivate rotations."}, {"name": "translate", "is_optional": true, "type": "tuple, optional", "default_value": "None", "description": " tuple of maximum absolute fraction for horizontaland vertical translations. For example translate=(a, b, then horizontal shiftis randomly sampled in the range -img_width * a &lt; dx &lt; img_width * a and vertical shift israndomly sampled in the range -img_height * b &lt; dy &lt; img_height * b. Will not translate by default."}, {"name": "scale", "is_optional": true, "type": "tuple, optional", "default_value": "None", "description": " scaling factor interval, e.g (a, b, then scale israndomly sampled from the range a &lt;= scale &lt;= b. Will keep original scale by default."}, {"name": "shear", "is_optional": true, "type": "sequence or float or int, optional", "default_value": "None", "description": " Range of degrees to select from.If shear is a number, a shear parallel to the x axis in the range (-shear, +shearwill be apllied. Else if shear is a tuple or list of 2 values a shear parallel to the x axis in therange (shear[0], shear[1] will be applied. Else if shear is a tuple or list of 4 values,a x-axis shear in (shear[0], shear[1] and y-axis shear in (shear[2], shear[3] will be applied.Will not apply shear by default"}, {"name": "resample", "is_optional": true, "type": "bool", "default_value": "False", "description": " An optional resampling filter. See filters for more information.If omitted, or if the image has mode \u201c1\u201d or \u201cP\u201d, it is set to PIL.Image.NEAREST."}, {"name": "fillcolor", "is_optional": true, "type": "int", "default_value": "0", "description": " Optional fill color (Tuple for RGB Image And int for grayscale for the areaoutside the transform in the output image.(Pillow&gt;=5.0.0"}]}},
{"id": "torchvision.transforms.RandomApply", "type": "class", "code": "torchvision.transforms.RandomApply(transforms,p=0.5)", "example": "NA", "summary": "Apply randomly a list of transformations with a given probability  Parameters  transforms (list or tuple) \u2013 list of transformations p (python:float) \u2013 probability    ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomApply", "parameters": [{"name": "transforms", "is_optional": false, "type": "list or tuple", "description": " list of transformations"}, {"name": "p", "is_optional": true, "type": "list or tuple", "default_value": "0.5", "description": " probability"}]}},
{"id": "torchvision.transforms.RandomChoice", "type": "class", "code": "torchvision.transforms.RandomChoice(transforms)", "example": "NA", "summary": "Apply single transformation randomly picked from a list ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomChoice", "parameters": [{"name": "transforms", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.RandomCrop", "type": "class", "code": "torchvision.transforms.RandomCrop(size,padding=None,pad_if_needed=False,fill=0,padding_mode='constant')", "example": "NA", "summary": "Crop the given PIL Image at a random location", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomCrop", "parameters": [{"name": "size", "is_optional": false, "type": "sequence or int", "description": " Desired output size of the crop. If size is anint instead of sequence like (h, w, a square crop (size, size ismade."}, {"name": "padding", "is_optional": true, "type": "int or sequence, optional", "default_value": "None", "description": " Optional padding on each borderof the image. Default is None, i.e no padding. If a sequence of length4 is provided, it is used to pad left, top, right, bottom bordersrespectively. If a sequence of length 2 is provided, it is used topad left/right, top/bottom borders, respectively."}, {"name": "pad_if_needed", "is_optional": true, "type": "bool", "default_value": "False", "description": " It will pad the image if smaller than thedesired size to avoid raising an exception. Since cropping is doneafter padding, the padding seems to be done at a random offset."}, {"name": "fill", "is_optional": true, "type": "int", "default_value": "0", "description": " Pixel fill value for constant fill. Default is 0. If a tuple oflength 3, it is used to fill R, G, B channels respectively.This value is only used when the padding_mode is constant"}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'constant'", "description": " Type of padding. Should be"}]}},
{"id": "torch.distributions.bernoulli.Bernoulli.entropy", "type": "method", "code": "torch.distributions.bernoulli.Bernoulli.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.entropy", "parameters": []}},
{"id": "torch.distributions.bernoulli.Bernoulli.enumerate_support", "type": "method", "code": "torch.distributions.bernoulli.Bernoulli.enumerate_support(expand=True)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.distributions.bernoulli.Bernoulli.expand", "type": "method", "code": "torch.distributions.bernoulli.Bernoulli.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.bernoulli.Bernoulli.log_prob", "type": "method", "code": "torch.distributions.bernoulli.Bernoulli.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.bernoulli.Bernoulli.mean", "type": "method", "code": "torch.distributions.bernoulli.Bernoulli.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.mean", "parameters": []}},
{"id": "torch.distributions.bernoulli.Bernoulli.param_shape", "type": "method", "code": "torch.distributions.bernoulli.Bernoulli.param_shape", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.param_shape", "parameters": []}},
{"id": "torch.distributions.bernoulli.Bernoulli.sample", "type": "method", "code": "torch.distributions.bernoulli.Bernoulli.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.bernoulli.Bernoulli.variance", "type": "method", "code": "torch.distributions.bernoulli.Bernoulli.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.variance", "parameters": []}},
{"id": "torch.distributions.beta.Beta.concentration0", "type": "method", "code": "torch.distributions.beta.Beta.concentration0", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta.concentration0", "parameters": []}},
{"id": "torch.distributions.beta.Beta.concentration1", "type": "method", "code": "torch.distributions.beta.Beta.concentration1", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta.concentration1", "parameters": []}},
{"id": "torch.distributions.beta.Beta.entropy", "type": "method", "code": "torch.distributions.beta.Beta.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta.entropy", "parameters": []}},
{"id": "torch.distributions.beta.Beta.expand", "type": "method", "code": "torch.distributions.beta.Beta.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.beta.Beta.log_prob", "type": "method", "code": "torch.distributions.beta.Beta.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributed.gather", "type": "function", "code": "torch.distributed.gather(tensor,gather_list=None,dst=0,group=&lt;objectobject&gt;,async_op=False)", "example": "NA", "summary": "Gathers a list of tensors in a single process", "returns": "Async work handle, if async_op is set to True.None, if not async_op or if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.gather", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " Input tensor."}, {"name": "gather_list", "is_optional": true, "type": "list[Tensor], optional", "default_value": "None", "description": " List of appropriately-sizedtensors to use for gathered data (default is None, must be specifiedon the destination rank"}, {"name": "dst", "is_optional": true, "type": "int", "default_value": "0", "description": " Destination rank (default is 0"}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether this op should be an async op"}]}},
{"id": "torch.distributed.scatter", "type": "function", "code": "torch.distributed.scatter(tensor,scatter_list=None,src=0,group=&lt;objectobject&gt;,async_op=False)", "example": "NA", "summary": "Scatters a list of tensors to all processes in a group", "returns": "Async work handle, if async_op is set to True.None, if not async_op or if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.scatter", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " Output tensor."}, {"name": "scatter_list", "is_optional": true, "type": "list[Tensor]", "default_value": "None", "description": " List of tensors to scatter (default isNone, must be specified on the source rank"}, {"name": "src", "is_optional": true, "type": "int", "default_value": "0", "description": " Source rank (default is 0"}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether this op should be an async op"}]}},
{"id": "torch.distributed.barrier", "type": "function", "code": "torch.distributed.barrier(group=&lt;objectobject&gt;,async_op=False)", "example": "NA", "summary": "Synchronizes all processes", "returns": "Async work handle, if async_op is set to True.None, if not async_op or if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.barrier", "parameters": [{"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether this op should be an async op"}]}},
{"id": "torch.distributed.broadcast_multigpu", "type": "function", "code": "torch.distributed.broadcast_multigpu(tensor_list,src,group=&lt;objectobject&gt;,async_op=False,src_tensor=0)", "example": "NA", "summary": "Broadcasts the tensor to the whole group with multiple GPU tensors per node", "returns": "Async work handle, if async_op is set to True.None, if not async_op or if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.broadcast_multigpu", "parameters": [{"name": "tensor_list", "is_optional": false, "type": "List[Tensor]", "description": " Tensors that participate in the collectiveoperation. If src is the rank, then the specified src_tensorelement of tensor_list (tensor_list[src_tensor] will bebroadcast to all other tensors (on different GPUs in the src processand all tensors in tensor_list of other non-src processes.You also need to make sure that len(tensor_list is the samefor all the distributed processes calling this function."}, {"name": "src", "is_optional": false, "type": "List[Tensor]", "description": " Source rank."}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether this op should be an async op"}, {"name": "src_tensor", "is_optional": true, "type": "int", "default_value": "0", "description": " Source tensor rank within tensor_list"}]}},
{"id": "torch.distributed.all_reduce_multigpu", "type": "function", "code": "torch.distributed.all_reduce_multigpu(tensor_list,op=ReduceOp.SUM,group=&lt;objectobject&gt;,async_op=False)", "example": "NA", "summary": "Reduces the tensor data across all machines in such a way that all get the final result", "returns": "Async work handle, if async_op is set to True.None, if not async_op or if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.all_reduce_multigpu", "parameters": [{"name": "tensor_list", "is_optional": false, "type": "tensor", "description": ""}, {"name": "op", "is_optional": true, "type": "tensor", "default_value": "ReduceOp.SUM", "description": " One of the values fromtorch.distributed.ReduceOpenum.  Specifies an operation used for element-wise reductions."}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether this op should be an async op"}]}},
{"id": "torch.distributed.reduce_multigpu", "type": "function", "code": "torch.distributed.reduce_multigpu(tensor_list,dst,op=ReduceOp.SUM,group=&lt;objectobject&gt;,async_op=False,dst_tensor=0)", "example": "NA", "summary": "Reduces the tensor data on multiple GPUs across all machines", "returns": "Async work handle, if async_op is set to True.None, otherwise", "shape": "NA", "code-info": {"name": "torch.distributed.reduce_multigpu", "parameters": [{"name": "tensor_list", "is_optional": false, "type": "List[Tensor]", "description": " Input and output GPU tensors of thecollective. The function operates in-place.You also need to make sure that len(tensor_list is the same forall the distributed processes calling this function."}, {"name": "dst", "is_optional": false, "type": "int", "description": " Destination rank"}, {"name": "op", "is_optional": true, "type": "List[Tensor]", "default_value": "ReduceOp.SUM", "description": " One of the values fromtorch.distributed.ReduceOpenum.  Specifies an operation used for element-wise reductions."}, {"name": "group", "is_optional": true, "type": "ProcessGroup, optional", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether this op should be an async op"}, {"name": "dst_tensor", "is_optional": true, "type": "int", "default_value": "0", "description": " Destination tensor rank withintensor_list"}]}},
{"id": "torch.distributed.all_gather_multigpu", "type": "function", "code": "torch.distributed.all_gather_multigpu(output_tensor_lists,input_tensor_list,group=&lt;objectobject&gt;,async_op=False)", "example": "NA", "summary": "Gathers tensors from the whole group in a list", "returns": "Async work handle, if async_op is set to True.None, if not async_op or if not part of the group", "shape": "NA", "code-info": {"name": "torch.distributed.all_gather_multigpu", "parameters": [{"name": "output_tensor_lists", "is_optional": false, "type": "int", "description": " Output lists. It shouldcontain correctly-sized tensors on each GPU to be used for outputof the collective, e.g. output_tensor_lists[i] contains theall_gather result that resides on the GPU ofinput_tensor_list[i].Note that each element of output_tensor_lists has the size ofworld_size * len(input_tensor_list, since the function allgathers the result from every single GPU in the group. To interpreteach element of output_tensor_lists[i], note thatinput_tensor_list[j] of rank k will be appear inoutput_tensor_lists[i][k * world_size + j]Also note that len(output_tensor_lists, and the size of eachelement in output_tensor_lists (each element is a list,therefore len(output_tensor_lists[i] need to be the samefor all the distributed processes calling this function."}, {"name": "input_tensor_list", "is_optional": false, "type": "List[List[Tensor]]", "description": " List of tensors(on different GPUs tobe broadcast from current process.Note that len(input_tensor_list needs to be the same forall the distributed processes calling this function."}, {"name": "group", "is_optional": true, "type": "List[List[Tensor]]", "default_value": "&lt;objectobject&gt;", "description": " The process group to work on"}, {"name": "async_op", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether this op should be an async op"}]}},
{"id": "torch.cuda.seed", "type": "function", "code": "torch.cuda.seed()", "example": "NA", "summary": "Sets the seed for generating random numbers to a random number for the current GPU", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.seed", "parameters": []}},
{"id": "torch.cuda.seed_all", "type": "function", "code": "torch.cuda.seed_all()", "example": "NA", "summary": "Sets the seed for generating random numbers to a random number on all GPUs", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.seed_all", "parameters": []}},
{"id": "torch.cuda.initial_seed", "type": "function", "code": "torch.cuda.initial_seed()", "example": "NA", "summary": "Returns the current random seed of the current GPU", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.initial_seed", "parameters": []}},
{"id": "torch.cuda.comm.broadcast", "type": "function", "code": "torch.cuda.comm.broadcast(tensor,devices)", "example": "NA", "summary": "Broadcasts a tensor to a number of GPUs", "returns": "A tuple containing copies of the tensor, placed on devicescorresponding to indices from devices.", "shape": "NA", "code-info": {"name": "torch.cuda.comm.broadcast", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " tensor to broadcast."}, {"name": "devices", "is_optional": false, "type": "Iterable", "description": " an iterable of devices among which to broadcast.Note that it should be like (src, dst1, dst2, \u2026, the first elementof which is the source device to broadcast from."}]}},
{"id": "torch.cuda.comm.broadcast_coalesced", "type": "function", "code": "torch.cuda.comm.broadcast_coalesced(tensors,devices,buffer_size=10485760)", "example": "NA", "summary": "Broadcasts a sequence tensors to the specified GPUs", "returns": "A tuple containing copies of the tensor, placed on devicescorresponding to indices from devices.", "shape": "NA", "code-info": {"name": "torch.cuda.comm.broadcast_coalesced", "parameters": [{"name": "tensors", "is_optional": false, "type": "sequence", "description": " tensors to broadcast."}, {"name": "devices", "is_optional": false, "type": "Iterable", "description": " an iterable of devices among which to broadcast.Note that it should be like (src, dst1, dst2, \u2026, the first elementof which is the source device to broadcast from."}, {"name": "buffer_size", "is_optional": true, "type": "int", "default_value": "10485760", "description": " maximum size of the buffer used for coalescing"}]}},
{"id": "torch.cuda.comm.reduce_add", "type": "function", "code": "torch.cuda.comm.reduce_add(inputs,destination=None)", "example": "NA", "summary": "Sums tensors from multiple GPUs", "returns": "A tensor containing an elementwise sum of all inputs, placed on thedestination device.", "shape": "NA", "code-info": {"name": "torch.cuda.comm.reduce_add", "parameters": [{"name": "inputs", "is_optional": false, "type": "Iterable[Tensor]", "description": " an iterable of tensors to add."}, {"name": "destination", "is_optional": true, "type": "int, optional", "default_value": "None", "description": " a device on which the output will beplaced (default"}]}},
{"id": "torch.cuda.comm.scatter", "type": "function", "code": "torch.cuda.comm.scatter(tensor,devices,chunk_sizes=None,dim=0,streams=None)", "example": "NA", "summary": "Scatters tensor across multiple GPUs", "returns": "A tuple containing chunks of the tensor, spread across givendevices.", "shape": "NA", "code-info": {"name": "torch.cuda.comm.scatter", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " tensor to scatter."}, {"name": "devices", "is_optional": false, "type": "Iterable[int]", "description": " iterable of ints, specifying among whichdevices the tensor should be scattered."}, {"name": "chunk_sizes", "is_optional": true, "type": "int", "default_value": "None", "description": " sizes of chunks to be placed oneach device. It should match devices in length and sum totensor.size(dim. If not specified, the tensor will be dividedinto equal chunks."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": " A dimension along which to chunk the tensor."}, {"name": "streams", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.cuda.comm.gather", "type": "function", "code": "torch.cuda.comm.gather(tensors,dim=0,destination=None)", "example": "NA", "summary": "Gathers tensors from multiple GPUs", "returns": "A tensor located on destination device, that is a result ofconcatenating tensors along dim.", "shape": "NA", "code-info": {"name": "torch.cuda.comm.gather", "parameters": [{"name": "tensors", "is_optional": false, "type": "Iterable[Tensor]", "description": " iterable of tensors to gather."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": " a dimension along which the tensors will be concatenated."}, {"name": "destination", "is_optional": true, "type": "int, optional", "default_value": "None", "description": " output device (-1 means CPU, default"}]}},
{"id": "torch.jit.ScriptModule", "type": "class", "code": "torch.jit.ScriptModule", "example": "NA", "summary": "  property code Returns a pretty-printed representation (as valid Python syntax) of the internal graph for the forward method", "returns": null, "shape": "NA", "code-info": {"name": "torch.jit.ScriptModule", "parameters": []}},
{"id": "torch.jit.ScriptFunction", "type": "class", "code": "torch.jit.ScriptFunction", "example": "NA", "summary": "Functionally equivalent to a ScriptModule, but represents a single function and does not have any attributes or Parameters", "returns": null, "shape": "NA", "code-info": {"name": "torch.jit.ScriptFunction", "parameters": []}},
{"id": "torch.autograd.function._ContextMethodMixin.mark_non_differentiable", "type": "method", "code": "torch.autograd.function._ContextMethodMixin.mark_non_differentiable(*args)", "example": "NA", "summary": "Marks outputs as non-differentiable", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.function._ContextMethodMixin.mark_non_differentiable", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.autograd.function._ContextMethodMixin.save_for_backward", "type": "method", "code": "torch.autograd.function._ContextMethodMixin.save_for_backward(*tensors)", "example": "NA", "summary": "Saves given tensors for a future call to backward()", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.function._ContextMethodMixin.save_for_backward", "parameters": [{"name": "*tensors", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.autograd.profiler.profile.export_chrome_trace", "type": "method", "code": "torch.autograd.profiler.profile.export_chrome_trace(path)", "example": "NA", "summary": "Exports an EventList as a Chrome tracing tools file", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.profiler.profile.export_chrome_trace", "parameters": [{"name": "path", "is_optional": false, "type": "str", "description": " Path where the trace will be written."}]}},
{"id": "torch.autograd.profiler.profile.key_averages", "type": "method", "code": "torch.autograd.profiler.profile.key_averages(group_by_input_shape=False)", "example": "NA", "summary": "Averages all function events over their keys", "returns": "An EventList containing FunctionEventAvg objects.", "shape": "NA", "code-info": {"name": "torch.autograd.profiler.profile.key_averages", "parameters": [{"name": "group_by_input_shape", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.autograd.profiler.profile.self_cpu_time_total", "type": "method", "code": "torch.autograd.profiler.profile.self_cpu_time_total", "example": "NA", "summary": "Returns total time spent on CPU obtained as a sum of all self times across all the events", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.profiler.profile.self_cpu_time_total", "parameters": []}},
{"id": "torch.autograd.profiler.profile.table", "type": "method", "code": "torch.autograd.profiler.profile.table(sort_by=None,row_limit=100,header=None)", "example": "NA", "summary": "Prints an EventList as a nicely formatted table", "returns": "A string containing the table.", "shape": "NA", "code-info": {"name": "torch.autograd.profiler.profile.table", "parameters": [{"name": "sort_by", "is_optional": true, "type": "str, optional", "default_value": "None", "description": " Attribute used to sort entries. By defaultthey are printed in the same order as they were registered.Valid keys include"}, {"name": "row_limit", "is_optional": true, "type": "int", "default_value": "100", "description": ""}, {"name": "header", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.autograd.profiler.profile.total_average", "type": "method", "code": "torch.autograd.profiler.profile.total_average()", "example": "NA", "summary": "Averages all events", "returns": "A FunctionEventAvg object.", "shape": "NA", "code-info": {"name": "torch.autograd.profiler.profile.total_average", "parameters": []}},
{"id": "torch.autograd.no_grad", "type": "class", "code": "torch.autograd.no_grad", "example": "  x = torch.tensor([1], requires_grad=True)  with torch.no_grad(): ...   y = x * 2  y.requires_grad False  @torch.no_grad() ... def doubler(x): ...     return x * 2  z = doubler(x)  z.requires_grad False   ", "summary": "Context-manager that disabled gradient calculation", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.no_grad", "parameters": []}},
{"id": "torch.nn.quantized.functional.upsample_bilinear", "type": "function", "code": "torch.nn.quantized.functional.upsample_bilinear(input,size=None,scale_factor=None)", "example": "NA", "summary": "Upsamples the input, using bilinear upsampling", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.functional.upsample_bilinear", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " quantized input"}, {"name": "size", "is_optional": true, "type": "int or Tuple[int, int]", "default_value": "None", "description": " output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "int or Tuple[int, int]", "default_value": "None", "description": " multiplier for spatial size"}]}},
{"id": "torch.nn.quantized.functional.upsample_nearest", "type": "function", "code": "torch.nn.quantized.functional.upsample_nearest(input,size=None,scale_factor=None)", "example": "NA", "summary": "Upsamples the input, using nearest neighbours\u2019 pixel values", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.functional.upsample_nearest", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " quantized input"}, {"name": "size", "is_optional": true, "type": "int or Tuple[int, int] or Tuple[int, int, int]", "default_value": "None", "description": " output spatialsize."}, {"name": "scale_factor", "is_optional": true, "type": "int", "default_value": "None", "description": " multiplier for spatial size. Has to be an integer."}]}},
{"id": "torch.nn.intrinsic.qat.ConvBn2d.from_float", "type": "method", "code": "torch.nn.intrinsic.qat.ConvBn2d.from_float(mod,qconfig=None)", "example": "NA", "summary": "Create a qat module from a float module or qparams_dict Args: mod a float module, either produced by torch.quantization utilities or directly from user ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.qat.ConvBn2d.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.qat.Conv2d.from_float", "type": "method", "code": "torch.nn.qat.Conv2d.from_float(mod,qconfig=None)", "example": "NA", "summary": "Create a qat module from a float module or qparams_dict Args: mod a float module, either produced by torch.quantization utilities or directly from user ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.qat.Conv2d.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.qat.Linear.from_float", "type": "method", "code": "torch.nn.qat.Linear.from_float(mod,qconfig=None)", "example": "NA", "summary": "Create a qat module from a float module or qparams_dict Args: mod a float module, either produced by torch.quantization utilities or directly from user ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.qat.Linear.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "others", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.quantized.Conv2d.from_float", "type": "method", "code": "torch.nn.quantized.Conv2d.from_float(mod)", "example": "NA", "summary": "Creates a quantized module from a float module or qparams_dict", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.Conv2d.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "Module", "description": " a float module, either produced by torch.quantizationutilities or provided by the user"}]}},
{"id": "torch.nn.quantized.Conv3d.from_float", "type": "method", "code": "torch.nn.quantized.Conv3d.from_float(mod)", "example": "NA", "summary": "Creates a quantized module from a float module or qparams_dict", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.Conv3d.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "Module", "description": " a float module, either produced by torch.quantizationutilities or provided by the user"}]}},
{"id": "torch.nn.quantized.Linear.from_float", "type": "method", "code": "torch.nn.quantized.Linear.from_float(mod)", "example": "NA", "summary": "Create a quantized module from a float module or qparams_dict  Parameters mod (Module) \u2013 a float module, either produced by torch.quantization utilities or provided by the user   ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.Linear.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "Module", "description": " a float module, either produced by torch.quantizationutilities or provided by the user"}]}},
{"id": "torch.optim.Adamax", "type": "class", "code": "torch.optim.Adamax(params,lr=0.002,betas=(0.9,0.999)", "example": "NA", "summary": "Implements Adamax algorithm (a variant of Adam based on infinity norm)", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Adamax", "parameters": [{"name": "params", "is_optional": false, "type": "iterable", "description": " iterable of parameters to optimize or dicts definingparameter groups"}, {"name": "lr", "is_optional": true, "type": "float, optional", "default_value": "0.002", "description": " learning rate (default"}, {"name": "betas", "is_optional": false, "type": "Tuple[float, float], optional", "description": " coefficients used for computingrunning averages of gradient and its square"}]}},
{"id": "torch.optim.ASGD", "type": "class", "code": "torch.optim.ASGD(params,lr=0.01,lambd=0.0001,alpha=0.75,t0=1000000.0,weight_decay=0)", "example": "NA", "summary": "Implements Averaged Stochastic Gradient Descent", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.ASGD", "parameters": [{"name": "params", "is_optional": false, "type": "iterable", "description": " iterable of parameters to optimize or dicts definingparameter groups"}, {"name": "lr", "is_optional": true, "type": "float, optional", "default_value": "0.01", "description": " learning rate (default"}, {"name": "lambd", "is_optional": true, "type": "float, optional", "default_value": "0.0001", "description": " decay term (default"}, {"name": "alpha", "is_optional": true, "type": "float, optional", "default_value": "0.75", "description": " power for eta update (default"}, {"name": "t0", "is_optional": true, "type": "float, optional", "default_value": "1000000.0", "description": " point at which to start averaging (default"}, {"name": "weight_decay", "is_optional": true, "type": "int", "default_value": "0", "description": " weight decay (L2 penalty (default"}]}},
{"id": "torch.optim.LBFGS", "type": "class", "code": "torch.optim.LBFGS(params,lr=1,max_iter=20,max_eval=None,tolerance_grad=1e-07,tolerance_change=1e-09,history_size=100,line_search_fn=None)", "example": "NA", "summary": "Implements L-BFGS algorithm, heavily inspired by minFunc &lt;https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html&gt;", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.LBFGS", "parameters": [{"name": "params", "is_optional": false, "type": "others", "description": ""}, {"name": "lr", "is_optional": true, "type": "int", "default_value": "1", "description": " learning rate (default"}, {"name": "max_iter", "is_optional": true, "type": "int", "default_value": "20", "description": " maximal number of iterations per optimization step(default"}, {"name": "max_eval", "is_optional": true, "type": "int", "default_value": "None", "description": " maximal number of function evaluations per optimizationstep (default"}, {"name": "tolerance_grad", "is_optional": true, "type": "float", "default_value": "1e-07", "description": " termination tolerance on first order optimality(default"}, {"name": "tolerance_change", "is_optional": true, "type": "float", "default_value": "1e-09", "description": " termination tolerance on functionvalue/parameter changes (default"}, {"name": "history_size", "is_optional": true, "type": "int", "default_value": "100", "description": " update history size (default"}, {"name": "line_search_fn", "is_optional": true, "type": "str", "default_value": "None", "description": " either \u2018strong_wolfe\u2019 or None (default"}]}},
{"id": "torch.optim.RMSprop", "type": "class", "code": "torch.optim.RMSprop(params,lr=0.01,alpha=0.99,eps=1e-08,weight_decay=0,momentum=0,centered=False)", "example": "NA", "summary": "Implements RMSprop algorithm", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.RMSprop", "parameters": [{"name": "params", "is_optional": false, "type": "iterable", "description": " iterable of parameters to optimize or dicts definingparameter groups"}, {"name": "lr", "is_optional": true, "type": "float, optional", "default_value": "0.01", "description": " learning rate (default"}, {"name": "alpha", "is_optional": true, "type": "float, optional", "default_value": "0.99", "description": " smoothing constant (default"}, {"name": "eps", "is_optional": true, "type": "float, optional", "default_value": "1e-08", "description": " term added to the denominator to improvenumerical stability (default"}, {"name": "weight_decay", "is_optional": true, "type": "int", "default_value": "0", "description": " weight decay (L2 penalty (default"}, {"name": "momentum", "is_optional": true, "type": "int", "default_value": "0", "description": " momentum factor (default"}, {"name": "centered", "is_optional": true, "type": "bool", "default_value": "False", "description": " if True, compute the centered RMSProp,the gradient is normalized by an estimation of its variance"}]}},
{"id": "torch.optim.Rprop", "type": "class", "code": "torch.optim.Rprop(params,lr=0.01,etas=(0.5,1.2)", "example": "NA", "summary": "Implements the resilient backpropagation algorithm", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.Rprop", "parameters": [{"name": "params", "is_optional": false, "type": "iterable", "description": " iterable of parameters to optimize or dicts definingparameter groups"}, {"name": "lr", "is_optional": true, "type": "float, optional", "default_value": "0.01", "description": " learning rate (default"}, {"name": "etas", "is_optional": false, "type": "Tuple[float, float], optional", "description": " pair of (etaminus, etaplis, thatare multiplicative increase and decrease factors(default"}]}},
{"id": "torchvision.datasets.Kinetics400", "type": "class", "code": "torchvision.datasets.Kinetics400(root,frames_per_clip,step_between_clips=1,frame_rate=None,extensions=('avi',)", "example": "NA", "summary": "Kinetics-400 dataset", "returns": "the T video framesaudio(Tensor[K, L]): the audio frames, where K is the number of channelsand L is the number of pointslabel (int): class of the video clip", "shape": "NA", "code-info": {"name": "torchvision.datasets.Kinetics400", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of the Kinetics-400 Dataset."}, {"name": "frames_per_clip", "is_optional": false, "type": "int", "description": " number of frames in a clip"}, {"name": "step_between_clips", "is_optional": true, "type": "int", "default_value": "1", "description": " number of frames between each clip"}, {"name": "frame_rate", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "extensions", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.datasets.HMDB51", "type": "class", "code": "torchvision.datasets.HMDB51(root,annotation_path,frames_per_clip,step_between_clips=1,frame_rate=None,fold=1,train=True,transform=None,_precomputed_metadata=None,num_workers=1,_video_width=0,_video_height=0,_video_min_dimension=0,_audio_samples=0)", "example": "NA", "summary": "HMDB51 dataset", "returns": "the T video framesaudio(Tensor[K, L]): the audio frames, where K is the number of channelsand L is the number of pointslabel (int): class of the video clip", "shape": "NA", "code-info": {"name": "torchvision.datasets.HMDB51", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of the HMDB51 Dataset."}, {"name": "annotation_path", "is_optional": false, "type": "str", "description": " path to the folder containing the split files"}, {"name": "frames_per_clip", "is_optional": false, "type": "int", "description": " number of frames in a clip."}, {"name": "step_between_clips", "is_optional": true, "type": "int", "default_value": "1", "description": " number of frames between each clip."}, {"name": "frame_rate", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "fold", "is_optional": true, "type": "int", "default_value": "1", "description": " which fold to use. Should be between 1 and 3."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": " if True, creates a dataset from the train split,otherwise from the test split."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in a TxHxWxC videoand returns a transformed version."}, {"name": "_precomputed_metadata", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "num_workers", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "_video_width", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_video_height", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_video_min_dimension", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_audio_samples", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torchvision.datasets.UCF101", "type": "class", "code": "torchvision.datasets.UCF101(root,annotation_path,frames_per_clip,step_between_clips=1,frame_rate=None,fold=1,train=True,transform=None,_precomputed_metadata=None,num_workers=1,_video_width=0,_video_height=0,_video_min_dimension=0,_audio_samples=0)", "example": "NA", "summary": "UCF101 dataset", "returns": "the T video framesaudio(Tensor[K, L]): the audio frames, where K is the number of channelsand L is the number of pointslabel (int): class of the video clip", "shape": "NA", "code-info": {"name": "torchvision.datasets.UCF101", "parameters": [{"name": "root", "is_optional": false, "type": "string", "description": " Root directory of the UCF101 Dataset."}, {"name": "annotation_path", "is_optional": false, "type": "str", "description": " path to the folder containing the split files"}, {"name": "frames_per_clip", "is_optional": false, "type": "int", "description": " number of frames in a clip."}, {"name": "step_between_clips", "is_optional": true, "type": "int", "default_value": "1", "description": " number of frames between each clip."}, {"name": "frame_rate", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "fold", "is_optional": true, "type": "int", "default_value": "1", "description": " which fold to use. Should be between 1 and 3."}, {"name": "train", "is_optional": true, "type": "bool", "default_value": "True", "description": " if True, creates a dataset from the train split,otherwise from the test split."}, {"name": "transform", "is_optional": true, "type": "callable, optional", "default_value": "None", "description": " A function/transform that  takes in a TxHxWxC videoand returns a transformed version."}, {"name": "_precomputed_metadata", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "num_workers", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "_video_width", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_video_height", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_video_min_dimension", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "_audio_samples", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.Tensor.add_", "type": "method", "code": "torch.Tensor.add_(value)", "example": "NA", "summary": "add_(value=1, other) -&gt; Tensor In-place version of add() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.add_", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.addbmm", "type": "method", "code": "torch.Tensor.addbmm(beta=1,alpha=1,batch1,batch2)", "example": "NA", "summary": "See torch.addbmm() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addbmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "batch1", "is_optional": false, "type": "others", "description": ""}, {"name": "batch2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.addbmm_", "type": "method", "code": "torch.Tensor.addbmm_(beta=1,alpha=1,batch1,batch2)", "example": "NA", "summary": "In-place version of addbmm() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addbmm_", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "batch1", "is_optional": false, "type": "others", "description": ""}, {"name": "batch2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.addcdiv", "type": "method", "code": "torch.Tensor.addcdiv(value=1,tensor1,tensor2)", "example": "NA", "summary": "See torch.addcdiv() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addcdiv", "parameters": [{"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "tensor1", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.addcdiv_", "type": "method", "code": "torch.Tensor.addcdiv_(value=1,tensor1,tensor2)", "example": "NA", "summary": "In-place version of addcdiv() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addcdiv_", "parameters": [{"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "tensor1", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.addcmul", "type": "method", "code": "torch.Tensor.addcmul(value=1,tensor1,tensor2)", "example": "NA", "summary": "See torch.addcmul() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addcmul", "parameters": [{"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "tensor1", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.addcmul_", "type": "method", "code": "torch.Tensor.addcmul_(value=1,tensor1,tensor2)", "example": "NA", "summary": "In-place version of addcmul() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addcmul_", "parameters": [{"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "tensor1", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.addmm", "type": "method", "code": "torch.Tensor.addmm(beta=1,alpha=1,mat1,mat2)", "example": "NA", "summary": "See torch.addmm() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "mat1", "is_optional": false, "type": "others", "description": ""}, {"name": "mat2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.addmm_", "type": "method", "code": "torch.Tensor.addmm_(beta=1,alpha=1,mat1,mat2)", "example": "NA", "summary": "In-place version of addmm() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addmm_", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "mat1", "is_optional": false, "type": "others", "description": ""}, {"name": "mat2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.addmv", "type": "method", "code": "torch.Tensor.addmv(beta=1,alpha=1,mat,vec)", "example": "NA", "summary": "See torch.addmv() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addmv", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "mat", "is_optional": false, "type": "others", "description": ""}, {"name": "vec", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.addmv_", "type": "method", "code": "torch.Tensor.addmv_(beta=1,alpha=1,mat,vec)", "example": "NA", "summary": "In-place version of addmv() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addmv_", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "mat", "is_optional": false, "type": "others", "description": ""}, {"name": "vec", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.unfold", "type": "function", "code": "torch.nn.functional.unfold(input,kernel_size,dilation=1,padding=0,stride=1)", "example": "NA", "summary": "Extracts sliding local blocks from an batched input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.unfold", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"id": "torch.nn.functional.fold", "type": "function", "code": "torch.nn.functional.fold(input,output_size,kernel_size,dilation=1,padding=0,stride=1)", "example": "NA", "summary": "Combines an array of sliding local blocks into a large containing tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.fold", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "output_size", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"id": "torch.nn.functional.avg_pool1d", "type": "function", "code": "torch.nn.functional.avg_pool1d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True)", "example": " # pool of square window of size=3, stride=2\n input = torch.tensor([[[1, 2, 3, 4, 5, 6, 7]]], dtype=torch.float32)\n F.avg_pool1d(input, kernel_size=3, stride=2)\ntensor([[[ 2.,  4.,  6.]]])\n\n", "summary": "Applies a 1D average pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.avg_pool1d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iW", "description": " input tensor of shape (minibatch,in_channels,iW(\\text{minibatch} , \\text{in\\_channels} , iW(minibatch,in_channels,iW"}, {"name": "kernel_size", "is_optional": false, "type": "kW,", "description": " the size of the window. Can be a single number or atuple (kW,"}, {"name": "stride", "is_optional": true, "type": "sW,", "default_value": "None", "description": " the stride of the window. Can be a single number or a tuple(sW,. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " implicit zero paddings on both sides of the input. Can be asingle number or a tuple (padW,. Default"}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": " when True, will use ceil instead of floor to compute theoutput shape. Default"}, {"name": "count_include_pad", "is_optional": true, "type": "bool", "default_value": "True", "description": " when True, will include the zero-padding in theaveraging calculation. Default"}]}},
{"id": "torch.nn.functional.avg_pool2d", "type": "function", "code": "torch.nn.functional.avg_pool2d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)", "example": "NA", "summary": "Applies 2D average-pooling operation in kH\u00d7kWkH \\times kWkH\u00d7kW   regions by step size sH\u00d7sWsH \\times sWsH\u00d7sW   steps", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.avg_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iH,iW", "description": " input tensor (minibatch,in_channels,iH,iW(\\text{minibatch} , \\text{in\\_channels} , iH , iW(minibatch,in_channels,iH,iW"}, {"name": "kernel_size", "is_optional": false, "type": "kH, kW", "description": " size of the pooling region. Can be a single number or atuple (kH, kW"}, {"name": "stride", "is_optional": true, "type": "sH, sW", "default_value": "None", "description": " stride of the pooling operation. Can be a single number or atuple (sH, sW. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " implicit zero paddings on both sides of the input. Can be asingle number or a tuple (padH, padW. Default"}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": " when True, will use ceil instead of floor in the formulato compute the output shape. Default"}, {"name": "count_include_pad", "is_optional": true, "type": "bool", "default_value": "True", "description": " when True, will include the zero-padding in theaveraging calculation. Default"}, {"name": "divisor_override", "is_optional": true, "type": "divisor_override : if specified, it will be used as divisor, otherwisesize of the pooling region will be used. Default: Non", "default_value": "None", "description": " if specified, it will be used as divisor, otherwisesize of the pooling region will be used. Default"}]}},
{"id": "torch.nn.functional.avg_pool3d", "type": "function", "code": "torch.nn.functional.avg_pool3d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)", "example": "NA", "summary": "Applies 3D average-pooling operation in kT\u00d7kH\u00d7kWkT \\times kH \\times kWkT\u00d7kH\u00d7kW   regions by step size sT\u00d7sH\u00d7sWsT \\times sH \\times sWsT\u00d7sH\u00d7sW   steps", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.avg_pool3d", "parameters": [{"name": "input", "is_optional": false, "type": "minibatch,in_channels,iT\u00d7iH,iW", "description": " input tensor (minibatch,in_channels,iT\u00d7iH,iW(\\text{minibatch} , \\text{in\\_channels} , iT \\times iH , iW(minibatch,in_channels,iT\u00d7iH,iW"}, {"name": "kernel_size", "is_optional": false, "type": "kT, kH, kW", "description": " size of the pooling region. Can be a single number or atuple (kT, kH, kW"}, {"name": "stride", "is_optional": true, "type": "sT, sH, sW", "default_value": "None", "description": " stride of the pooling operation. Can be a single number or atuple (sT, sH, sW. Default"}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": " implicit zero paddings on both sides of the input. Can be asingle number or a tuple (padT, padH, padW, Default"}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": " when True, will use ceil instead of floor in the formulato compute the output shape"}, {"name": "count_include_pad", "is_optional": true, "type": "bool", "default_value": "True", "description": " when True, will include the zero-padding in theaveraging calculation"}, {"name": "divisor_override", "is_optional": true, "type": "divisor_override : if specified, it will be used as divisor, otherwisesize of the pooling region will be used. Default: Non", "default_value": "None", "description": " if specified, it will be used as divisor, otherwisesize of the pooling region will be used. Default"}]}},
{"id": "torchvision.transforms.RandomGrayscale", "type": "class", "code": "torchvision.transforms.RandomGrayscale(p=0.1)", "example": "NA", "summary": "Randomly convert image to grayscale with a probability of p (default 0.1)", "returns": "Grayscale version of the input image with probability p and unchangedwith probability (1-p).- If input image is 1 channel: grayscale version is 1 channel- If input image is 3 channel: grayscale version is 3 channel with r == g == b", "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomGrayscale", "parameters": [{"name": "p", "is_optional": true, "type": "float", "default_value": "0.1", "description": " probability that image should be converted to grayscale."}]}},
{"id": "torchvision.transforms.RandomHorizontalFlip", "type": "class", "code": "torchvision.transforms.RandomHorizontalFlip(p=0.5)", "example": "NA", "summary": "Horizontally flip the given PIL Image randomly with a given probability", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomHorizontalFlip", "parameters": [{"name": "p", "is_optional": true, "type": "float", "default_value": "0.5", "description": " probability of the image being flipped. Default value is 0.5"}]}},
{"id": "torchvision.transforms.RandomOrder", "type": "class", "code": "torchvision.transforms.RandomOrder(transforms)", "example": "NA", "summary": "Apply a list of transformations in a random order ", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomOrder", "parameters": [{"name": "transforms", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.RandomPerspective", "type": "class", "code": "torchvision.transforms.RandomPerspective(distortion_scale=0.5,p=0.5,interpolation=3)", "example": "NA", "summary": "Performs Perspective transformation of the given PIL Image randomly with a given probability", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomPerspective", "parameters": [{"name": "distortion_scale", "is_optional": true, "type": "float", "default_value": "0.5", "description": " it controls the degree of distortion and ranges from 0 to 1. Default value is 0.5."}, {"name": "p", "is_optional": true, "type": "interpolation : Default- Image.BICUBI", "default_value": "0.5", "description": " probability of the image being perspectively transformed. Default value is 0.5"}, {"name": "interpolation", "is_optional": true, "type": "int", "default_value": "3", "description": " Default- Image.BICUBIC"}]}},
{"id": "torchvision.transforms.RandomResizedCrop", "type": "class", "code": "torchvision.transforms.RandomResizedCrop(size,scale=(0.08,1.0)", "example": "NA", "summary": "Crop the given PIL Image to random size and aspect ratio", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomResizedCrop", "parameters": [{"name": "size", "is_optional": false, "type": "size : expected output size of each edg", "description": " expected output size of each edge"}, {"name": "scale", "is_optional": false, "type": "scale : range of size of the origin size croppe", "description": " range of size of the origin size cropped"}]}},
{"id": "torchvision.transforms.RandomRotation", "type": "class", "code": "torchvision.transforms.RandomRotation(degrees,resample=False,expand=False,center=None,fill=0)", "example": "NA", "summary": "Rotate the image by angle", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomRotation", "parameters": [{"name": "degrees", "is_optional": false, "type": "sequence or float or int", "description": " Range of degrees to select from.If degrees is a number instead of sequence like (min, max, the range of degreeswill be (-degrees, +degrees."}, {"name": "resample", "is_optional": true, "type": "bool", "default_value": "False", "description": " An optional resampling filter. See filters for more information.If omitted, or if the image has mode \u201c1\u201d or \u201cP\u201d, it is set to PIL.Image.NEAREST."}, {"name": "expand", "is_optional": true, "type": "bool", "default_value": "False", "description": " Optional expansion flag.If true, expands the output to make it large enough to hold the entire rotated image.If false or omitted, make the output image the same size as the input image.Note that the expand flag assumes rotation around the center and no translation."}, {"name": "center", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Optional center of rotation.Origin is the upper left corner.Default is the center of the image."}, {"name": "fill", "is_optional": true, "type": "int", "default_value": "0", "description": " RGB pixel fill value for area outside the rotated image.If int, it is used for all channels respectively."}]}},
{"id": "torchvision.transforms.RandomSizedCrop", "type": "class", "code": "torchvision.transforms.RandomSizedCrop(*args,**kwargs)", "example": "NA", "summary": "Note: This transform is deprecated in favor of RandomResizedCrop", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomSizedCrop", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.RandomVerticalFlip", "type": "class", "code": "torchvision.transforms.RandomVerticalFlip(p=0.5)", "example": "NA", "summary": "Vertically flip the given PIL Image randomly with a given probability", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomVerticalFlip", "parameters": [{"name": "p", "is_optional": true, "type": "float", "default_value": "0.5", "description": " probability of the image being flipped. Default value is 0.5"}]}},
{"id": "torch.is_tensor", "type": "function", "code": "torch.is_tensor(obj)", "example": "NA", "summary": "Returns True if obj is a PyTorch tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.is_tensor", "parameters": [{"name": "obj", "is_optional": false, "type": "Object", "description": " Object to test"}]}},
{"id": "torch.distributions.beta.Beta.mean", "type": "method", "code": "torch.distributions.beta.Beta.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta.mean", "parameters": []}},
{"id": "torch.distributions.beta.Beta.rsample", "type": "method", "code": "torch.distributions.beta.Beta.rsample(sample_shape=()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta.rsample", "parameters": [{"name": "sample_shape", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.beta.Beta.variance", "type": "method", "code": "torch.distributions.beta.Beta.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta.variance", "parameters": []}},
{"id": "torch.distributions.binomial.Binomial.enumerate_support", "type": "method", "code": "torch.distributions.binomial.Binomial.enumerate_support(expand=True)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.distributions.binomial.Binomial.expand", "type": "method", "code": "torch.distributions.binomial.Binomial.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.binomial.Binomial.log_prob", "type": "method", "code": "torch.distributions.binomial.Binomial.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.binomial.Binomial.mean", "type": "method", "code": "torch.distributions.binomial.Binomial.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.mean", "parameters": []}},
{"id": "torch.distributions.binomial.Binomial.param_shape", "type": "method", "code": "torch.distributions.binomial.Binomial.param_shape", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.param_shape", "parameters": []}},
{"id": "torch.distributions.binomial.Binomial.sample", "type": "method", "code": "torch.distributions.binomial.Binomial.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.binomial.Binomial.support", "type": "method", "code": "torch.distributions.binomial.Binomial.support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.support", "parameters": []}},
{"id": "torch.distributions.binomial.Binomial.variance", "type": "method", "code": "torch.distributions.binomial.Binomial.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.variance", "parameters": []}},
{"id": "torch.distributions.categorical.Categorical.entropy", "type": "method", "code": "torch.distributions.categorical.Categorical.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.entropy", "parameters": []}},
{"id": "torch.distributed.Backend", "type": "class", "code": "torch.distributed.Backend", "example": "NA", "summary": "An enum-like class of available backends: GLOO, NCCL, and MPI", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.Backend", "parameters": []}},
{"id": "torch.distributed.ReduceOp", "type": "class", "code": "torch.distributed.ReduceOp", "example": "NA", "summary": "An enum-like class for available reduction operations: SUM, PRODUCT, MIN, MAX, BAND, BOR, and BXOR", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.ReduceOp", "parameters": []}},
{"id": "torch.distributed.reduce_op", "type": "class", "code": "torch.distributed.reduce_op", "example": "NA", "summary": "Deprecated enum-like class for reduction operations: SUM, PRODUCT, MIN, and MAX", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributed.reduce_op", "parameters": []}},
{"id": "torch.cuda.empty_cache", "type": "function", "code": "torch.cuda.empty_cache()", "example": "NA", "summary": "Releases all unoccupied cached memory currently held by the caching allocator so that those can be used in other GPU application and visible in nvidia-smi", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.empty_cache", "parameters": []}},
{"id": "torch.cuda.memory_stats", "type": "function", "code": "torch.cuda.memory_stats(device=None)", "example": "NA", "summary": "Returns a dictionary of CUDA memory allocator statistics for a given device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.memory_stats", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " selected device. Returnsstatistics for the current device, given by current_device(,if device is None (default."}]}},
{"id": "torch.cuda.memory_summary", "type": "function", "code": "torch.cuda.memory_summary(device=None,abbreviated=False)", "example": "NA", "summary": "Returns a human-readable printout of the current memory allocator statistics for a given device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.memory_summary", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " selected device. Returnsprintout for the current device, given by current_device(,if device is None (default."}, {"name": "abbreviated", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether to return an abbreviated summary(default"}]}},
{"id": "torch.cuda.memory_snapshot", "type": "function", "code": "torch.cuda.memory_snapshot()", "example": "NA", "summary": "Returns a snapshot of the CUDA memory allocator state across all devices", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.memory_snapshot", "parameters": []}},
{"id": "torch.cuda.memory_allocated", "type": "function", "code": "torch.cuda.memory_allocated(device=None)", "example": "NA", "summary": "Returns the current GPU memory occupied by tensors in bytes for a given device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.memory_allocated", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " selected device. Returnsstatistic for the current device, given by current_device(,if device is None (default."}]}},
{"id": "torch.cuda.max_memory_allocated", "type": "function", "code": "torch.cuda.max_memory_allocated(device=None)", "example": "NA", "summary": "Returns the maximum GPU memory occupied by tensors in bytes for a given device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.max_memory_allocated", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " selected device. Returnsstatistic for the current device, given by current_device(,if device is None (default."}]}},
{"id": "torch.cuda.reset_max_memory_allocated", "type": "function", "code": "torch.cuda.reset_max_memory_allocated(device=None)", "example": "NA", "summary": "Resets the starting point in tracking maximum GPU memory occupied by tensors for a given device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.reset_max_memory_allocated", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " selected device. Returnsstatistic for the current device, given by current_device(,if device is None (default."}]}},
{"id": "torch.autograd.enable_grad", "type": "class", "code": "torch.autograd.enable_grad", "example": "  x = torch.tensor([1], requires_grad=True)  with torch.no_grad(): ...   with torch.enable_grad(): ...     y = x * 2  y.requires_grad True  y.backward()  x.grad  @torch.enable_grad() ... def doubler(x): ...     return x * 2  with torch.no_grad(): ...     z = doubler(x)  z.requires_grad True   ", "summary": "Context-manager that enables gradient calculation", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.enable_grad", "parameters": []}},
{"id": "torch.autograd.set_grad_enabled", "type": "class", "code": "torch.autograd.set_grad_enabled(mode)", "example": "  x = torch.tensor([1], requires_grad=True)  is_train = False  with torch.set_grad_enabled(is_train): ...   y = x * 2  y.requires_grad False  torch.set_grad_enabled(True)  y = x * 2  y.requires_grad True  torch.set_grad_enabled(False)  y = x * 2  y.requires_grad False   ", "summary": "Context-manager that sets gradient calculation to on or off", "returns": null, "shape": "NA", "code-info": {"name": "torch.autograd.set_grad_enabled", "parameters": [{"name": "mode", "is_optional": false, "type": "bool", "description": " Flag whether to enable grad (True, or disable(False. This can be used to conditionally enablegradients."}]}},
{"id": "torch.nn.quantized.dynamic.Linear.from_float", "type": "method", "code": "torch.nn.quantized.dynamic.Linear.from_float(mod)", "example": "NA", "summary": "Create a dynamic quantized module from a float module or qparams_dict  Parameters mod (Module) \u2013 a float module, either produced by torch.quantization utilities or provided by the user   ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.dynamic.Linear.from_float", "parameters": [{"name": "mod", "is_optional": false, "type": "Module", "description": " a float module, either produced by torch.quantizationutilities or provided by the user"}]}},
{"id": "torch.quantization.QConfig", "type": "class", "code": "torch.quantization.QConfig", "example": "NA", "summary": "Describes how to quantize a layer or a part of the network by providing settings (observer classes) for activations and weights respectively", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.QConfig", "parameters": []}},
{"id": "torch.quantization.QConfigDynamic", "type": "class", "code": "torch.quantization.QConfigDynamic", "example": "NA", "summary": "Describes how to dynamically quantize a layer or a part of the network by providing settings (observer classe) for weights", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.QConfigDynamic", "parameters": []}},
{"id": "torch.quantization.QuantStub", "type": "class", "code": "torch.quantization.QuantStub(qconfig=None)", "example": "NA", "summary": "Quantize stub module, before calibration, this is same as an observer, it will be swapped as nnq.Quantize in convert", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.QuantStub", "parameters": [{"name": "qconfig", "is_optional": true, "type": "qconfig : quantization configuration for the tensor,if qconfig is not provided, we will get qconfig from parent module", "default_value": "None", "description": " quantization configuration for the tensor,if qconfig is not provided, we will get qconfig from parent modules"}]}},
{"id": "torch.quantization.DeQuantStub", "type": "class", "code": "torch.quantization.DeQuantStub", "example": "NA", "summary": "Dequantize stub module, before calibration, this is same as identity, this will be swapped as nnq.DeQuantize in convert", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.DeQuantStub", "parameters": []}},
{"id": "torch.quantization.QuantWrapper", "type": "class", "code": "torch.quantization.QuantWrapper(module)", "example": "NA", "summary": "A wrapper class that wraps the input module, adds QuantStub and DeQuantStub and surround the call to module with call to quant and dequant modules", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.QuantWrapper", "parameters": [{"name": "module", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.quantization.MinMaxObserver", "type": "class", "code": "torch.quantization.MinMaxObserver(dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False)", "example": "NA", "summary": "Observer module for computing the quantization parameters based on the running min and max values", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.MinMaxObserver", "parameters": [{"name": "dtype", "is_optional": true, "type": "dtype : Quantized data typ", "default_value": "torch.quint8", "description": " Quantized data type"}, {"name": "qscheme", "is_optional": true, "type": "qscheme : Quantization scheme to be use", "default_value": "torch.per_tensor_affine", "description": " Quantization scheme to be used"}, {"name": "reduce_range", "is_optional": true, "type": "bool", "default_value": "False", "description": " Reduces the range of the quantized data type by 1 bit"}]}},
{"id": "torch.optim.SGD", "type": "class", "code": "torch.optim.SGD(params,lr=&lt;requiredparameter&gt;,momentum=0,dampening=0,weight_decay=0,nesterov=False)", "example": " optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n optimizer.zero_grad()\n loss_fn(model(input), target).backward()\n optimizer.step()\n\n", "summary": "Implements stochastic gradient descent (optionally with momentum)", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.SGD", "parameters": [{"name": "params", "is_optional": false, "type": "iterable", "description": " iterable of parameters to optimize or dicts definingparameter groups"}, {"name": "lr", "is_optional": true, "type": "float", "default_value": "&lt;requiredparameter&gt;", "description": " learning rate"}, {"name": "momentum", "is_optional": true, "type": "int", "default_value": "0", "description": " momentum factor (default"}, {"name": "dampening", "is_optional": true, "type": "int", "default_value": "0", "description": " dampening for momentum (default"}, {"name": "weight_decay", "is_optional": true, "type": "int", "default_value": "0", "description": " weight decay (L2 penalty (default"}, {"name": "nesterov", "is_optional": true, "type": "bool", "default_value": "False", "description": " enables Nesterov momentum (default"}]}},
{"id": "torch.optim.lr_scheduler.LambdaLR", "type": "class", "code": "torch.optim.lr_scheduler.LambdaLR(optimizer,lr_lambda,last_epoch=-1)", "example": " # Assuming optimizer has two groups.\n lambda1 = lambda epoch: epoch // 30\n lambda2 = lambda epoch: 0.95 ** epoch\n scheduler = LambdaLR(optimizer, lr_lambda=[lambda1, lambda2])\n for epoch in range(100):\n     train(...)\n     validate(...)\n     scheduler.step()\n\n", "summary": "Sets the learning rate of each parameter group to the initial lr times a given function", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.LambdaLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "Optimizer", "description": " Wrapped optimizer."}, {"name": "lr_lambda", "is_optional": false, "type": "function or list", "description": " A function which computes a multiplicativefactor given an integer parameter epoch, or a list of suchfunctions, one for each group in optimizer.param_groups."}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": " The index of last epoch. Default"}]}},
{"id": "torch.optim.lr_scheduler.MultiplicativeLR", "type": "class", "code": "torch.optim.lr_scheduler.MultiplicativeLR(optimizer,lr_lambda,last_epoch=-1)", "example": "NA", "summary": "Multiply the learning rate of each parameter group by the factor given in the specified function", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.MultiplicativeLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "Optimizer", "description": " Wrapped optimizer."}, {"name": "lr_lambda", "is_optional": false, "type": "function or list", "description": " A function which computes a multiplicativefactor given an integer parameter epoch, or a list of suchfunctions, one for each group in optimizer.param_groups."}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": " The index of last epoch. Default"}]}},
{"id": "torch.optim.lr_scheduler.StepLR", "type": "class", "code": "torch.optim.lr_scheduler.StepLR(optimizer,step_size,gamma=0.1,last_epoch=-1)", "example": " # Assuming optimizer uses lr = 0.05 for all groups\n # lr = 0.05     if epoch &lt; 30\n # lr = 0.005    if 30 &lt;= epoch &lt; 60\n # lr = 0.0005   if 60 &lt;= epoch &lt; 90\n # ...\n scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n for epoch in range(100):\n     train(...)\n     validate(...)\n     scheduler.step()\n\n", "summary": "Decays the learning rate of each parameter group by gamma every step_size epochs", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.StepLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "Optimizer", "description": " Wrapped optimizer."}, {"name": "step_size", "is_optional": false, "type": "int", "description": " Period of learning rate decay."}, {"name": "gamma", "is_optional": true, "type": "float", "default_value": "0.1", "description": " Multiplicative factor of learning rate decay.Default"}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": " The index of last epoch. Default"}]}},
{"id": "torch.Tensor.addr", "type": "method", "code": "torch.Tensor.addr(beta=1,alpha=1,vec1,vec2)", "example": "NA", "summary": "See torch.addr() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addr", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "vec1", "is_optional": false, "type": "others", "description": ""}, {"name": "vec2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.addr_", "type": "method", "code": "torch.Tensor.addr_(beta=1,alpha=1,vec1,vec2)", "example": "NA", "summary": "In-place version of addr() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.addr_", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "vec1", "is_optional": false, "type": "others", "description": ""}, {"name": "vec2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.allclose", "type": "method", "code": "torch.Tensor.allclose(other,rtol=1e-05,atol=1e-08,equal_nan=False)", "example": "NA", "summary": "See torch.allclose() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.allclose", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "rtol", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "atol", "is_optional": true, "type": "others", "default_value": "1e-08", "description": ""}, {"name": "equal_nan", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.angle", "type": "method", "code": "torch.Tensor.angle()", "example": "NA", "summary": "See torch.angle() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.angle", "parameters": []}},
{"id": "torch.Tensor.apply_", "type": "method", "code": "torch.Tensor.apply_(callable)", "example": "NA", "summary": "Applies the function callable to each element in the tensor, replacing each element with the value returned by callable", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.apply_", "parameters": [{"name": "callable", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.argmax", "type": "method", "code": "torch.Tensor.argmax(dim=None,keepdim=False)", "example": "NA", "summary": "See torch.argmax() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.argmax", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.argmin", "type": "method", "code": "torch.Tensor.argmin(dim=None,keepdim=False)", "example": "NA", "summary": "See torch.argmin() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.argmin", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.argsort", "type": "method", "code": "torch.Tensor.argsort(dim=-1,descending=False)", "example": "NA", "summary": "See :func: torch.argsort ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.argsort", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}, {"name": "descending", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.asin", "type": "method", "code": "torch.Tensor.asin()", "example": "NA", "summary": "See torch.asin() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.asin", "parameters": []}},
{"id": "torch.Tensor.asin_", "type": "method", "code": "torch.Tensor.asin_()", "example": "NA", "summary": "In-place version of asin() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.asin_", "parameters": []}},
{"id": "torch.Tensor.as_strided", "type": "method", "code": "torch.Tensor.as_strided(size,stride,storage_offset=0)", "example": "NA", "summary": "See torch.as_strided() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.as_strided", "parameters": [{"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": false, "type": "others", "description": ""}, {"name": "storage_offset", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.Tensor.atan", "type": "method", "code": "torch.Tensor.atan()", "example": "NA", "summary": "See torch.atan() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.atan", "parameters": []}},
{"id": "torch.Tensor.atan2", "type": "method", "code": "torch.Tensor.atan2(other)", "example": "NA", "summary": "See torch.atan2() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.atan2", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.max_pool1d", "type": "function", "code": "torch.nn.functional.max_pool1d(*args,**kwargs)", "example": "NA", "summary": "Applies a 1D max pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.max_pool1d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.max_pool2d", "type": "function", "code": "torch.nn.functional.max_pool2d(*args,**kwargs)", "example": "NA", "summary": "Applies a 2D max pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.max_pool2d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.max_pool3d", "type": "function", "code": "torch.nn.functional.max_pool3d(*args,**kwargs)", "example": "NA", "summary": "Applies a 3D max pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.max_pool3d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.max_unpool1d", "type": "function", "code": "torch.nn.functional.max_unpool1d(input,indices,kernel_size,stride=None,padding=0,output_size=None)", "example": "NA", "summary": "Computes a partial inverse of MaxPool1d", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.max_unpool1d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "indices", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "output_size", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.functional.max_unpool2d", "type": "function", "code": "torch.nn.functional.max_unpool2d(input,indices,kernel_size,stride=None,padding=0,output_size=None)", "example": "NA", "summary": "Computes a partial inverse of MaxPool2d", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.max_unpool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "indices", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "output_size", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.functional.max_unpool3d", "type": "function", "code": "torch.nn.functional.max_unpool3d(input,indices,kernel_size,stride=None,padding=0,output_size=None)", "example": "NA", "summary": "Computes a partial inverse of MaxPool3d", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.max_unpool3d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "indices", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "output_size", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.functional.lp_pool1d", "type": "function", "code": "torch.nn.functional.lp_pool1d(input,norm_type,kernel_size,stride=None,ceil_mode=False)", "example": "NA", "summary": "Applies a 1D power-average pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.lp_pool1d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "norm_type", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.lp_pool2d", "type": "function", "code": "torch.nn.functional.lp_pool2d(input,norm_type,kernel_size,stride=None,ceil_mode=False)", "example": "NA", "summary": "Applies a 2D power-average pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.lp_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "norm_type", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "ceil_mode", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.adaptive_max_pool1d", "type": "function", "code": "torch.nn.functional.adaptive_max_pool1d(*args,**kwargs)", "example": "NA", "summary": "Applies a 1D adaptive max pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.adaptive_max_pool1d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.adaptive_max_pool2d", "type": "function", "code": "torch.nn.functional.adaptive_max_pool2d(*args,**kwargs)", "example": "NA", "summary": "Applies a 2D adaptive max pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.adaptive_max_pool2d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.adaptive_max_pool3d", "type": "function", "code": "torch.nn.functional.adaptive_max_pool3d(*args,**kwargs)", "example": "NA", "summary": "Applies a 3D adaptive max pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.adaptive_max_pool3d", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.Resize", "type": "class", "code": "torchvision.transforms.Resize(size,interpolation=2)", "example": "NA", "summary": "Resize the input PIL Image to the given size", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.Resize", "parameters": [{"name": "size", "is_optional": false, "type": "int", "description": " Desired output size. If size is a sequence like(h, w, output size will be matched to this. If size is an int,smaller edge of the image will be matched to this number.i.e, if height &gt; width, then image will be rescaled to(size * height / width, size"}, {"name": "interpolation", "is_optional": true, "type": "int", "default_value": "2", "description": " Desired interpolation. Default isPIL.Image.BILINEAR"}]}},
{"id": "torchvision.transforms.Scale", "type": "class", "code": "torchvision.transforms.Scale(*args,**kwargs)", "example": "NA", "summary": "Note: This transform is deprecated in favor of Resize", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.Scale", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torchvision.transforms.TenCrop", "type": "class", "code": "torchvision.transforms.TenCrop(size,vertical_flip=False)", "example": " transform = Compose([\n    TenCrop(size), # this is a list of PIL Images\n    Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])) # returns a 4D tensor\n ])\n #In your test loop you can do the following:\n input, target = batch # input is a 5d tensor, target is 2d\n bs, ncrops, c, h, w = input.size()\n result = model(input.view(-1, c, h, w)) # fuse batch size and ncrops\n result_avg = result.view(bs, ncrops, -1).mean(1) # avg over crops\n\n", "summary": "Crop the given PIL Image into four corners and the central crop plus the flipped version of these (horizontal flipping is used by default)  Note This transform returns a tuple of images and there may be a mismatch in the number of inputs and targets your Dataset returns", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.TenCrop", "parameters": [{"name": "size", "is_optional": false, "type": "sequence or int", "description": " Desired output size of the crop. If size is anint instead of sequence like (h, w, a square crop (size, size ismade."}, {"name": "vertical_flip", "is_optional": true, "type": "bool", "default_value": "False", "description": " Use vertical flipping instead of horizontal"}]}},
{"id": "torchvision.transforms.LinearTransformation", "type": "class", "code": "torchvision.transforms.LinearTransformation(transformation_matrix,mean_vector)", "example": "NA", "summary": "Transform a tensor image with a square transformation matrix and a mean_vector computed offline", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.LinearTransformation", "parameters": [{"name": "transformation_matrix", "is_optional": false, "type": "Tensor", "description": " tensor [D x D], D = C x H x W"}, {"name": "mean_vector", "is_optional": false, "type": "Tensor", "description": " tensor [D], D = C x H x W"}]}},
{"id": "torch.is_storage", "type": "function", "code": "torch.is_storage(obj)", "example": "NA", "summary": "Returns True if obj is a PyTorch storage object", "returns": null, "shape": "NA", "code-info": {"name": "torch.is_storage", "parameters": [{"name": "obj", "is_optional": false, "type": "Object", "description": " Object to test"}]}},
{"id": "torch.is_floating_point", "type": "function", "code": "torch.is_floating_point(input)", "example": "NA", "summary": "Returns True if the data type of input is a floating point data type i.e., one of torch.float64, torch.float32 and torch.float16", "returns": null, "shape": "NA", "code-info": {"name": "torch.is_floating_point", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the PyTorch tensor to test"}]}},
{"id": "torch.set_default_dtype", "type": "function", "code": "torch.set_default_dtype(d)", "example": "  torch.tensor([1.2, 3]).dtype           # initial default for floating point is torch.float32 torch.float32  torch.set_default_dtype(torch.float64)  torch.tensor([1.2, 3]).dtype           # a new floating point tensor torch.float64   ", "summary": "Sets the default floating point dtype to d", "returns": null, "shape": "NA", "code-info": {"name": "torch.set_default_dtype", "parameters": [{"name": "d", "is_optional": false, "type": "torch.dtype", "description": " the floating point dtype to make the default"}]}},
{"id": "torch.get_default_dtype", "type": "function", "code": "torch.get_default_dtype()", "example": "  torch.get_default_dtype()  # initial default for floating point is torch.float32 torch.float32  torch.set_default_dtype(torch.float64)  torch.get_default_dtype()  # default is now changed to torch.float64 torch.float64  torch.set_default_tensor_type(torch.FloatTensor)  # setting tensor type also affects this  torch.get_default_dtype()  # changed to torch.float32, the dtype for torch.FloatTensor torch.float32   ", "summary": "Get the current default floating point torch.dtype", "returns": null, "shape": "NA", "code-info": {"name": "torch.get_default_dtype", "parameters": []}},
{"id": "torch.set_default_tensor_type", "type": "function", "code": "torch.set_default_tensor_type(t)", "example": "  torch.tensor([1.2, 3]).dtype    # initial default for floating point is torch.float32 torch.float32  torch.set_default_tensor_type(torch.DoubleTensor)  torch.tensor([1.2, 3]).dtype    # a new floating point tensor torch.float64   ", "summary": "Sets the default torch.Tensor type to floating point tensor type t", "returns": null, "shape": "NA", "code-info": {"name": "torch.set_default_tensor_type", "parameters": [{"name": "t", "is_optional": false, "type": "type or string", "description": " the floating point tensor type or its name"}]}},
{"id": "torch.numel", "type": "function", "code": "torch.numel(input)", "example": "  a = torch.randn(1, 2, 3, 4, 5)  torch.numel(a) 120  a = torch.zeros(4,4)  torch.numel(a) 16   ", "summary": "Returns the total number of elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.numel", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}]}},
{"id": "torch.set_printoptions", "type": "function", "code": "torch.set_printoptions(precision=None,threshold=None,edgeitems=None,linewidth=None,profile=None,sci_mode=None)", "example": "NA", "summary": "Set options for printing", "returns": null, "shape": "NA", "code-info": {"name": "torch.set_printoptions", "parameters": [{"name": "precision", "is_optional": true, "type": "default = 4", "default_value": "None", "description": " Number of digits of precision for floating point output(default = 4."}, {"name": "threshold", "is_optional": true, "type": "default = 1000", "default_value": "None", "description": " Total number of array elements which trigger summarizationrather than full repr (default = 1000."}, {"name": "edgeitems", "is_optional": true, "type": "default = 3", "default_value": "None", "description": " Number of array items in summary at beginning and end ofeach dimension (default = 3."}, {"name": "linewidth", "is_optional": true, "type": "default = 80", "default_value": "None", "description": " The number of characters per line for the purpose ofinserting line breaks (default = 80. Thresholded matrices willignore this parameter."}, {"name": "profile", "is_optional": true, "type": "any one of default, short, full", "default_value": "None", "description": " Sane defaults for pretty printing. Can override with any ofthe above options. (any one of default, short, full"}, {"name": "sci_mode", "is_optional": true, "type": "True", "default_value": "None", "description": " Enable (True or disable (False scientific notation. IfNone (default is specified, the value is defined by _Formatter"}]}},
{"id": "torch.distributions.categorical.Categorical.enumerate_support", "type": "method", "code": "torch.distributions.categorical.Categorical.enumerate_support(expand=True)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.distributions.categorical.Categorical.expand", "type": "method", "code": "torch.distributions.categorical.Categorical.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.categorical.Categorical.log_prob", "type": "method", "code": "torch.distributions.categorical.Categorical.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.categorical.Categorical.mean", "type": "method", "code": "torch.distributions.categorical.Categorical.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.mean", "parameters": []}},
{"id": "torch.distributions.categorical.Categorical.param_shape", "type": "method", "code": "torch.distributions.categorical.Categorical.param_shape", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.param_shape", "parameters": []}},
{"id": "torch.distributions.categorical.Categorical.sample", "type": "method", "code": "torch.distributions.categorical.Categorical.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.categorical.Categorical.support", "type": "method", "code": "torch.distributions.categorical.Categorical.support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.support", "parameters": []}},
{"id": "torch.distributions.categorical.Categorical.variance", "type": "method", "code": "torch.distributions.categorical.Categorical.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.variance", "parameters": []}},
{"id": "torch.distributions.cauchy.Cauchy.cdf", "type": "method", "code": "torch.distributions.cauchy.Cauchy.cdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.cauchy.Cauchy.entropy", "type": "method", "code": "torch.distributions.cauchy.Cauchy.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy.entropy", "parameters": []}},
{"id": "torch.distributions.cauchy.Cauchy.expand", "type": "method", "code": "torch.distributions.cauchy.Cauchy.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.cauchy.Cauchy.icdf", "type": "method", "code": "torch.distributions.cauchy.Cauchy.icdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.cauchy.Cauchy.log_prob", "type": "method", "code": "torch.distributions.cauchy.Cauchy.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.cauchy.Cauchy.mean", "type": "method", "code": "torch.distributions.cauchy.Cauchy.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy.mean", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(device=None,dtype=None,non_blocking=False)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.cuda.memory_reserved", "type": "function", "code": "torch.cuda.memory_reserved(device=None)", "example": "NA", "summary": "Returns the current GPU memory managed by the caching allocator in bytes for a given device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.memory_reserved", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " selected device. Returnsstatistic for the current device, given by current_device(,if device is None (default."}]}},
{"id": "torch.cuda.max_memory_reserved", "type": "function", "code": "torch.cuda.max_memory_reserved(device=None)", "example": "NA", "summary": "Returns the maximum GPU memory managed by the caching allocator in bytes for a given device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.max_memory_reserved", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " selected device. Returnsstatistic for the current device, given by current_device(,if device is None (default."}]}},
{"id": "torch.cuda.memory_cached", "type": "function", "code": "torch.cuda.memory_cached(device=None)", "example": "NA", "summary": "Deprecated; see memory_reserved()", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.memory_cached", "parameters": [{"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.cuda.max_memory_cached", "type": "function", "code": "torch.cuda.max_memory_cached(device=None)", "example": "NA", "summary": "Deprecated; see max_memory_reserved()", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.max_memory_cached", "parameters": [{"name": "device", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.cuda.reset_max_memory_cached", "type": "function", "code": "torch.cuda.reset_max_memory_cached(device=None)", "example": "NA", "summary": "Resets the starting point in tracking maximum GPU memory managed by the caching allocator for a given device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.reset_max_memory_cached", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device or int, optional", "default_value": "None", "description": " selected device. Returnsstatistic for the current device, given by current_device(,if device is None (default."}]}},
{"id": "torch.cuda.nvtx.mark", "type": "function", "code": "torch.cuda.nvtx.mark(msg)", "example": "NA", "summary": "Describe an instantaneous event that occurred at some point", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.nvtx.mark", "parameters": [{"name": "msg", "is_optional": false, "type": "string", "description": " ASCII message to associate with the event."}]}},
{"id": "torch.cuda.nvtx.range_push", "type": "function", "code": "torch.cuda.nvtx.range_push(msg)", "example": "NA", "summary": "Pushes a range onto a stack of nested range span", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.nvtx.range_push", "parameters": [{"name": "msg", "is_optional": false, "type": "string", "description": " ASCII message to associate with range"}]}},
{"id": "torch.cuda.nvtx.range_pop", "type": "function", "code": "torch.cuda.nvtx.range_pop()", "example": "NA", "summary": "Pops a range off of a stack of nested range spans", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.nvtx.range_pop", "parameters": []}},
{"id": "torch.cuda.Stream.query", "type": "method", "code": "torch.cuda.Stream.query()", "example": "NA", "summary": "Checks if all the work submitted has been completed", "returns": "A boolean indicating if all kernels in this stream are completed.", "shape": "NA", "code-info": {"name": "torch.cuda.Stream.query", "parameters": []}},
{"id": "torch.cuda.Stream.record_event", "type": "method", "code": "torch.cuda.Stream.record_event(event=None)", "example": "NA", "summary": "Records an event", "returns": "Recorded event.", "shape": "NA", "code-info": {"name": "torch.cuda.Stream.record_event", "parameters": [{"name": "event", "is_optional": true, "type": "Event, optional", "default_value": "None", "description": " event to record. If not given, a new onewill be allocated."}]}},
{"id": "torch.quantization.MovingAverageMinMaxObserver", "type": "class", "code": "torch.quantization.MovingAverageMinMaxObserver(averaging_constant=0.01,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False)", "example": "NA", "summary": "Observer module for computing the quantization parameters based on the moving average of the min and max values", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.MovingAverageMinMaxObserver", "parameters": [{"name": "averaging_constant", "is_optional": true, "type": "averaging_constant : Averaging constant for min/max", "default_value": "0.01", "description": " Averaging constant for min/max."}, {"name": "dtype", "is_optional": true, "type": "dtype : Quantized data typ", "default_value": "torch.quint8", "description": " Quantized data type"}, {"name": "qscheme", "is_optional": true, "type": "qscheme : Quantization scheme to be use", "default_value": "torch.per_tensor_affine", "description": " Quantization scheme to be used"}, {"name": "reduce_range", "is_optional": true, "type": "bool", "default_value": "False", "description": " Reduces the range of the quantized data type by 1 bit"}]}},
{"id": "torch.quantization.PerChannelMinMaxObserver", "type": "class", "code": "torch.quantization.PerChannelMinMaxObserver(ch_axis=0,dtype=torch.quint8,qscheme=torch.per_channel_affine,reduce_range=False)", "example": "NA", "summary": "Observer module for computing the quantization parameters based on the running per channel min and max values", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.PerChannelMinMaxObserver", "parameters": [{"name": "ch_axis", "is_optional": true, "type": "int", "default_value": "0", "description": " Channel axis"}, {"name": "dtype", "is_optional": true, "type": "dtype : Quantized data typ", "default_value": "torch.quint8", "description": " Quantized data type"}, {"name": "qscheme", "is_optional": true, "type": "qscheme : Quantization scheme to be use", "default_value": "torch.per_channel_affine", "description": " Quantization scheme to be used"}, {"name": "reduce_range", "is_optional": true, "type": "bool", "default_value": "False", "description": " Reduces the range of the quantized data type by 1 bit"}]}},
{"id": "torch.quantization.MovingAveragePerChannelMinMaxObserver", "type": "class", "code": "torch.quantization.MovingAveragePerChannelMinMaxObserver(averaging_constant=0.01,ch_axis=0,dtype=torch.quint8,qscheme=torch.per_channel_affine,reduce_range=False)", "example": "NA", "summary": "Observer module for computing the quantization parameters based on the running per channel min and max values", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.MovingAveragePerChannelMinMaxObserver", "parameters": [{"name": "averaging_constant", "is_optional": true, "type": "averaging_constant : Averaging constant for min/max", "default_value": "0.01", "description": " Averaging constant for min/max."}, {"name": "ch_axis", "is_optional": true, "type": "int", "default_value": "0", "description": " Channel axis"}, {"name": "dtype", "is_optional": true, "type": "dtype : Quantized data typ", "default_value": "torch.quint8", "description": " Quantized data type"}, {"name": "qscheme", "is_optional": true, "type": "qscheme : Quantization scheme to be use", "default_value": "torch.per_channel_affine", "description": " Quantization scheme to be used"}, {"name": "reduce_range", "is_optional": true, "type": "bool", "default_value": "False", "description": " Reduces the range of the quantized data type by 1 bit"}]}},
{"id": "torch.quantization.HistogramObserver", "type": "class", "code": "torch.quantization.HistogramObserver(bins=2048,upsample_rate=128,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False)", "example": "NA", "summary": "The module records the running histogram of tensor values along with min/max values", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.HistogramObserver", "parameters": [{"name": "bins", "is_optional": true, "type": "int", "default_value": "2048", "description": " Number of bins to use for the histogram"}, {"name": "upsample_rate", "is_optional": true, "type": "int", "default_value": "128", "description": " Factor by which the histograms are upsampled, this isused to interpolate histograms with varying ranges across observations"}, {"name": "dtype", "is_optional": true, "type": "dtype : Quantized data typ", "default_value": "torch.quint8", "description": " Quantized data type"}, {"name": "qscheme", "is_optional": true, "type": "qscheme : Quantization scheme to be use", "default_value": "torch.per_tensor_affine", "description": " Quantization scheme to be used"}, {"name": "reduce_range", "is_optional": true, "type": "bool", "default_value": "False", "description": " Reduces the range of the quantized data type by 1 bit"}]}},
{"id": "torch.quantization.FakeQuantize", "type": "class", "code": "torch.quantization.FakeQuantize(observer=&lt;class'torch.quantization.observer.MovingAverageMinMaxObserver'&gt;,quant_min=0,quant_max=255,**observer_kwargs)", "example": "NA", "summary": "Simulate the quantize and dequantize operations in training time", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.FakeQuantize", "parameters": [{"name": "observer", "is_optional": true, "type": "module", "default_value": "&lt;class'torch.quantization.observer.MovingAverageMinMaxObserver'&gt;", "description": " Module for observing statistics on input tensors and calculating scaleand zero-point."}, {"name": "quant_min", "is_optional": true, "type": "int", "default_value": "0", "description": " The minimum allowable quantized value."}, {"name": "quant_max", "is_optional": true, "type": "int", "default_value": "255", "description": " The maximum allowable quantized value."}, {"name": "**observer_kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.quantization.NoopObserver", "type": "class", "code": "torch.quantization.NoopObserver(dtype=torch.float16)", "example": "NA", "summary": "Observer that doesn\u2019t do anything and just passes its configuration to the quantized module\u2019s .from_float()", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.NoopObserver", "parameters": [{"name": "dtype", "is_optional": true, "type": "dtype : Quantized data typ", "default_value": "torch.float16", "description": " Quantized data type"}]}},
{"id": "torch.quantization.RecordingObserver", "type": "class", "code": "torch.quantization.RecordingObserver(**kwargs)", "example": "NA", "summary": "The module is mainly for debug and records the tensor values during runtime", "returns": null, "shape": "NA", "code-info": {"name": "torch.quantization.RecordingObserver", "parameters": [{"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.optim.lr_scheduler.MultiStepLR", "type": "class", "code": "torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones,gamma=0.1,last_epoch=-1)", "example": " # Assuming optimizer uses lr = 0.05 for all groups\n # lr = 0.05     if epoch &lt; 30\n # lr = 0.005    if 30 &lt;= epoch &lt; 80\n # lr = 0.0005   if epoch = 80\n scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\n for epoch in range(100):\n     train(...)\n     validate(...)\n     scheduler.step()\n\n", "summary": "Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.MultiStepLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "Optimizer", "description": " Wrapped optimizer."}, {"name": "milestones", "is_optional": false, "type": "list", "description": " List of epoch indices. Must be increasing."}, {"name": "gamma", "is_optional": true, "type": "float", "default_value": "0.1", "description": " Multiplicative factor of learning rate decay.Default"}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": " The index of last epoch. Default"}]}},
{"id": "torch.optim.lr_scheduler.ExponentialLR", "type": "class", "code": "torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma,last_epoch=-1)", "example": "NA", "summary": "Decays the learning rate of each parameter group by gamma every epoch", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.ExponentialLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "Optimizer", "description": " Wrapped optimizer."}, {"name": "gamma", "is_optional": false, "type": "float", "description": " Multiplicative factor of learning rate decay."}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": " The index of last epoch. Default"}]}},
{"id": "torch.optim.lr_scheduler.CosineAnnealingLR", "type": "class", "code": "torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max,eta_min=0,last_epoch=-1)", "example": "NA", "summary": "Set the learning rate of each parameter group using a cosine annealing schedule, where \u03b7max\\eta_{max}\u03b7max\u200b   is set to the initial lr and TcurT_{cur}Tcur\u200b   is the number of epochs since the last restart in SGDR:  \u03b7t=\u03b7min+12(\u03b7max\u2212\u03b7min)(1+cos\u2061(TcurTmax\u03c0))Tcur\u2260(2k+1)Tmax;\u03b7t+1=\u03b7t+(\u03b7max\u2212\u03b7min)1\u2212cos\u2061(1Tmax\u03c0)2,Tcur=(2k+1)Tmax.\\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})\\left(1 + \\cos\\left(\\frac{T_{cur}}{T_{max}}\\pi\\right)\\right) T_{cur} \\neq (2k+1)T_{max};\\\\ \\eta_{t+1} = \\eta_{t} + (\\eta_{max} - \\eta_{min})\\frac{1 - \\cos(\\frac{1}{T_{max}}\\pi)}{2}, T_{cur} = (2k+1)T_{max}.\\\\  \u03b7t\u200b=\u03b7min\u200b+21\u200b(\u03b7max\u200b\u2212\u03b7min\u200b)(1+cos(Tmax\u200bTcur\u200b\u200b\u03c0))Tcur\u200b\ue020\u200b=(2k+1)Tmax\u200b;\u03b7t+1\u200b=\u03b7t\u200b+(\u03b7max\u200b\u2212\u03b7min\u200b)21\u2212cos(Tmax\u200b1\u200b\u03c0)\u200b,Tcur\u200b=(2k+1)Tmax\u200b", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.CosineAnnealingLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "Optimizer", "description": " Wrapped optimizer."}, {"name": "T_max", "is_optional": false, "type": "int", "description": " Maximum number of iterations."}, {"name": "eta_min", "is_optional": true, "type": "int", "default_value": "0", "description": " Minimum learning rate. Default"}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": " The index of last epoch. Default"}]}},
{"id": "torch.optim.lr_scheduler.ReduceLROnPlateau", "type": "class", "code": "torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.1,patience=10,verbose=False,threshold=0.0001,threshold_mode='rel',cooldown=0,min_lr=0,eps=1e-08)", "example": " optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n scheduler = ReduceLROnPlateau(optimizer, 'min')\n for epoch in range(10):\n     train(...)\n     val_loss = validate(...)\n     # Note that step should be called after validate()\n     scheduler.step(val_loss)\n\n", "summary": "Reduce learning rate when a metric has stopped improving", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.ReduceLROnPlateau", "parameters": [{"name": "optimizer", "is_optional": false, "type": "Optimizer", "description": " Wrapped optimizer."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'min'", "description": " One of min, max. In min mode, lr willbe reduced when the quantity monitored has stoppeddecreasing; in max mode it will be reduced when thequantity monitored has stopped increasing. Default"}, {"name": "factor", "is_optional": true, "type": "float", "default_value": "0.1", "description": " Factor by which the learning rate will bereduced. new_lr = lr * factor. Default"}, {"name": "patience", "is_optional": true, "type": "int", "default_value": "10", "description": " Number of epochs with no improvement afterwhich learning rate will be reduced. For example, ifpatience = 2, then we will ignore the first 2 epochswith no improvement, and will only decrease the LR after the3rd epoch if the loss still hasn\u2019t improved then.Default"}, {"name": "verbose", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, prints a message to stdout foreach update. Default"}, {"name": "threshold", "is_optional": true, "type": "float", "default_value": "0.0001", "description": " Threshold for measuring the new optimum,to only focus on significant changes. Default"}, {"name": "threshold_mode", "is_optional": true, "type": "string", "default_value": "'rel'", "description": " One of rel, abs. In rel mode,dynamic_threshold = best * ( 1 + threshold  in \u2018max\u2019mode or best * ( 1 - threshold  in min mode.In abs mode, dynamic_threshold = best + threshold inmax mode or best - threshold in min mode. Default"}, {"name": "cooldown", "is_optional": true, "type": "int", "default_value": "0", "description": " Number of epochs to wait before resumingnormal operation after lr has been reduced. Default"}, {"name": "min_lr", "is_optional": true, "type": "int", "default_value": "0", "description": " A scalar or a list of scalars. Alower bound on the learning rate of all param groupsor each group respectively. Default"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-08", "description": " Minimal decay applied to lr. If the differencebetween new and old lr is smaller than eps, the update isignored. Default"}]}},
{"id": "torch.optim.lr_scheduler.CyclicLR", "type": "class", "code": "torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr,max_lr,step_size_up=2000,step_size_down=None,mode='triangular',gamma=1.0,scale_fn=None,scale_mode='cycle',cycle_momentum=True,base_momentum=0.8,max_momentum=0.9,last_epoch=-1)", "example": " optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1)\n data_loader = torch.utils.data.DataLoader(...)\n for epoch in range(10):\n     for batch in data_loader:\n         train_batch(...)\n         scheduler.step()\n\n", "summary": "Sets the learning rate of each parameter group according to cyclical learning rate policy (CLR)", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.CyclicLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "Optimizer", "description": " Wrapped optimizer."}, {"name": "base_lr", "is_optional": false, "type": "float or list", "description": " Initial learning rate which is thelower boundary in the cycle for each parameter group."}, {"name": "max_lr", "is_optional": false, "type": "float or list", "description": " Upper learning rate boundaries in the cyclefor each parameter group. Functionally,it defines the cycle amplitude (max_lr - base_lr.The lr at any cycle is the sum of base_lrand some scaling of the amplitude; thereforemax_lr may not actually be reached depending onscaling function."}, {"name": "step_size_up", "is_optional": true, "type": "int", "default_value": "2000", "description": " Number of training iterations in theincreasing half of a cycle. Default"}, {"name": "step_size_down", "is_optional": true, "type": "int", "default_value": "None", "description": " Number of training iterations in thedecreasing half of a cycle. If step_size_down is None,it is set to step_size_up. Default"}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'triangular'", "description": " One of {triangular, triangular2, exp_range}.Values correspond to policies detailed above.If scale_fn is not None, this argument is ignored.Default"}, {"name": "gamma", "is_optional": true, "type": "float", "default_value": "1.0", "description": " Constant in \u2018exp_range\u2019 scaling function"}, {"name": "scale_fn", "is_optional": true, "type": "str", "default_value": "None", "description": " Custom scaling policy defined by a singleargument lambda function, where0 &lt;= scale_fn(x &lt;= 1 for all x &gt;= 0.If specified, then \u2018mode\u2019 is ignored.Default"}, {"name": "scale_mode", "is_optional": true, "type": "string", "default_value": "'cycle'", "description": " {\u2018cycle\u2019, \u2018iterations\u2019}.Defines whether scale_fn is evaluated oncycle number or cycle iterations (trainingiterations since start of cycle.Default"}, {"name": "cycle_momentum", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, momentum is cycled inverselyto learning rate between \u2018base_momentum\u2019 and \u2018max_momentum\u2019.Default"}, {"name": "base_momentum", "is_optional": true, "type": "bool", "default_value": "0.8", "description": " Lower momentum boundaries in the cyclefor each parameter group. Note that momentum is cycled inverselyto learning rate; at the peak of a cycle, momentum is\u2018base_momentum\u2019 and learning rate is \u2018max_lr\u2019.Default"}, {"name": "max_momentum", "is_optional": true, "type": "bool", "default_value": "0.9", "description": " Upper momentum boundaries in the cyclefor each parameter group. Functionally,it defines the cycle amplitude (max_momentum - base_momentum.The momentum at any cycle is the difference of max_momentumand some scaling of the amplitude; thereforebase_momentum may not actually be reached depending onscaling function. Note that momentum is cycled inverselyto learning rate; at the start of a cycle, momentum is \u2018max_momentum\u2019and learning rate is \u2018base_lr\u2019Default"}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": " The index of the last batch. This parameter is used whenresuming a training job. Since step( should be invoked after eachbatch instead of after each epoch, this number represents the totalnumber of batches computed, not the total number of epochs computed.When last_epoch=-1, the schedule is started from the beginning.Default"}]}},
{"id": "torch.Tensor.atan2_", "type": "method", "code": "torch.Tensor.atan2_(other)", "example": "NA", "summary": "In-place version of atan2() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.atan2_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.atan_", "type": "method", "code": "torch.Tensor.atan_()", "example": "NA", "summary": "In-place version of atan() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.atan_", "parameters": []}},
{"id": "NA", "type": "method", "code": "NA(gradient=None,retain_graph=None,create_graph=False)", "example": "NA", "summary": "Computes the gradient of current tensor w.r.t", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "gradient", "is_optional": true, "type": "Tensor or None", "default_value": "None", "description": " Gradient w.r.t. thetensor. If it is a tensor, it will be automatically convertedto a Tensor that does not require grad unless create_graph is True.None values can be specified for scalar Tensors or ones thatdon\u2019t require grad. If a None value would be acceptable thenthis argument is optional."}, {"name": "retain_graph", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " If False, the graph used to computethe grads will be freed. Note that in nearly all cases settingthis option to True is not needed and often can be worked aroundin a much more efficient way. Defaults to the value ofcreate_graph."}, {"name": "create_graph", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, graph of the derivative willbe constructed, allowing to compute higher order derivativeproducts. Defaults to False."}]}},
{"id": "torch.Tensor.baddbmm", "type": "method", "code": "torch.Tensor.baddbmm(beta=1,alpha=1,batch1,batch2)", "example": "NA", "summary": "See torch.baddbmm() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.baddbmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "batch1", "is_optional": false, "type": "others", "description": ""}, {"name": "batch2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.baddbmm_", "type": "method", "code": "torch.Tensor.baddbmm_(beta=1,alpha=1,batch1,batch2)", "example": "NA", "summary": "In-place version of baddbmm() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.baddbmm_", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "batch1", "is_optional": false, "type": "others", "description": ""}, {"name": "batch2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.bernoulli", "type": "method", "code": "torch.Tensor.bernoulli(*,generator=None)", "example": "NA", "summary": "Returns a result tensor where each result[i]\\texttt{result[i]}result[i]   is independently sampled from Bernoulli(self[i])\\text{Bernoulli}(\\texttt{self[i]})Bernoulli(self[i])  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.bernoulli", "parameters": [{"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.bernoulli_", "type": "method", "code": "torch.Tensor.bernoulli_()", "example": "NA", "summary": "  bernoulli_(p=0.5, *, generator=None) \u2192 Tensor Fills each location of self with an independent sample from Bernoulli(p)\\text{Bernoulli}(\\texttt{p})Bernoulli(p)  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.bernoulli_", "parameters": []}},
{"id": "torch.Tensor.bfloat16", "type": "method", "code": "torch.Tensor.bfloat16()", "example": "NA", "summary": "self.bfloat16() is equivalent to self.to(torch.bfloat16)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.bfloat16", "parameters": []}},
{"id": "torch.Tensor.bincount", "type": "method", "code": "torch.Tensor.bincount(weights=None,minlength=0)", "example": "NA", "summary": "See torch.bincount() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.bincount", "parameters": [{"name": "weights", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "minlength", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.Tensor.bitwise_not", "type": "method", "code": "torch.Tensor.bitwise_not()", "example": "NA", "summary": "See torch.bitwise_not() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.bitwise_not", "parameters": []}},
{"id": "torch.Tensor.bitwise_not_", "type": "method", "code": "torch.Tensor.bitwise_not_()", "example": "NA", "summary": "In-place version of bitwise_not() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.bitwise_not_", "parameters": []}},
{"id": "torch.nn.functional.adaptive_avg_pool1d", "type": "function", "code": "torch.nn.functional.adaptive_avg_pool1d(input,output_size)", "example": "NA", "summary": "Applies a 1D adaptive average pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.adaptive_avg_pool1d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "output_size", "is_optional": false, "type": "int", "description": " the target output size (single integer"}]}},
{"id": "torch.nn.functional.adaptive_avg_pool2d", "type": "function", "code": "torch.nn.functional.adaptive_avg_pool2d(input,output_size)", "example": "NA", "summary": "Applies a 2D adaptive average pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.adaptive_avg_pool2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "output_size", "is_optional": false, "type": "int", "description": " the target output size (single integer ordouble-integer tuple"}]}},
{"id": "torch.nn.functional.adaptive_avg_pool3d", "type": "function", "code": "torch.nn.functional.adaptive_avg_pool3d(input,output_size)", "example": "NA", "summary": "Applies a 3D adaptive average pooling over an input signal composed of several input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.adaptive_avg_pool3d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "output_size", "is_optional": false, "type": "int", "description": " the target output size (single integer ortriple-integer tuple"}]}},
{"id": "torch.nn.functional.threshold", "type": "function", "code": "torch.nn.functional.threshold(input,threshold,value,inplace=False)", "example": "NA", "summary": "Thresholds each element of the input Tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.threshold", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "threshold", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.threshold_", "type": "function", "code": "torch.nn.functional.threshold_(input,threshold,value)", "example": "NA", "summary": "In-place version of threshold()", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.threshold_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "threshold", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.relu", "type": "function", "code": "torch.nn.functional.relu(input,inplace=False)", "example": "NA", "summary": "Applies the rectified linear unit function element-wise", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.relu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.relu_", "type": "function", "code": "torch.nn.functional.relu_(input)", "example": "NA", "summary": "In-place version of relu()", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.relu_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.hardtanh", "type": "function", "code": "torch.nn.functional.hardtanh(input,min_val=-1.,max_val=1.,inplace=False)", "example": "NA", "summary": "Applies the HardTanh function element-wise", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.hardtanh", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "min_val", "is_optional": true, "type": "others", "default_value": "-1.", "description": ""}, {"name": "max_val", "is_optional": true, "type": "others", "default_value": "1.", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.hardtanh_", "type": "function", "code": "torch.nn.functional.hardtanh_(input,min_val=-1.,max_val=1.)", "example": "NA", "summary": "In-place version of hardtanh()", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.hardtanh_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "min_val", "is_optional": true, "type": "others", "default_value": "-1.", "description": ""}, {"name": "max_val", "is_optional": true, "type": "others", "default_value": "1.", "description": ""}]}},
{"id": "torch.nn.functional.relu6", "type": "function", "code": "torch.nn.functional.relu6(input,inplace=False)", "example": "NA", "summary": "Applies the element-wise function ReLU6(x)=min\u2061(max\u2061(0,x),6)\\text{ReLU6}(x) = \\min(\\max(0,x), 6)ReLU6(x)=min(max(0,x),6)  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.relu6", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.elu", "type": "function", "code": "torch.nn.functional.elu(input,alpha=1.0,inplace=False)", "example": "NA", "summary": "Applies element-wise, ELU(x)=max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x)\u22121))\\text{ELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1))ELU(x)=max(0,x)+min(0,\u03b1\u2217(exp(x)\u22121))  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.elu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "alpha", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torchvision.transforms.Normalize", "type": "class", "code": "torchvision.transforms.Normalize(mean,std,inplace=False)", "example": "NA", "summary": "Normalize a tensor image with mean and standard deviation", "returns": "Normalized Tensor image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.Normalize", "parameters": [{"name": "mean", "is_optional": false, "type": "sequence", "description": " Sequence of means for each channel."}, {"name": "std", "is_optional": false, "type": "sequence", "description": " Sequence of standard deviations for each channel."}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " Bool to make this operation in-place."}]}},
{"id": "torchvision.transforms.RandomErasing", "type": "class", "code": "torchvision.transforms.RandomErasing(p=0.5,scale=(0.02,0.33)", "example": " transform = transforms.Compose([\n transforms.RandomHorizontalFlip(),\n transforms.ToTensor(),\n transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n transforms.RandomErasing(),\n ])\n\n\n", "summary": " Randomly selects a rectangle region in an image and erases its pixels.\u2018Random Erasing Data Augmentation\u2019 by Zhong et al", "returns": "Erased Image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.RandomErasing", "parameters": [{"name": "p", "is_optional": true, "type": "p : probability that the random erasing operation will be performed", "default_value": "0.5", "description": " probability that the random erasing operation will be performed."}, {"name": "scale", "is_optional": false, "type": "scale : range of proportion of erased area against input image", "description": " range of proportion of erased area against input image."}]}},
{"id": "torchvision.transforms.ToPILImage", "type": "class", "code": "torchvision.transforms.ToPILImage(mode=None)", "example": "NA", "summary": "Convert a tensor or an ndarray to PIL Image", "returns": "Image converted to PIL Image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.ToPILImage", "parameters": [{"name": "mode", "is_optional": true, "type": "If the input has 4 channels, the mode is assumed to be RGBA", "default_value": "None", "description": ""}]}},
{"id": "torchvision.transforms.ToTensor", "type": "class", "code": "torchvision.transforms.ToTensor", "example": "NA", "summary": "Convert a PIL Image or numpy.ndarray to tensor", "returns": "Converted image.", "shape": "NA", "code-info": {"name": "torchvision.transforms.ToTensor", "parameters": []}},
{"id": "torchvision.transforms.Lambda", "type": "class", "code": "torchvision.transforms.Lambda(lambd)", "example": "NA", "summary": "Apply a user-defined lambda as a transform", "returns": null, "shape": "NA", "code-info": {"name": "torchvision.transforms.Lambda", "parameters": [{"name": "lambd", "is_optional": false, "type": "function", "description": " Lambda/function to be used for transform."}]}},
{"id": "torch.set_flush_denormal", "type": "function", "code": "torch.set_flush_denormal(mode)", "example": "  torch.set_flush_denormal(True) True  torch.tensor([1e-323], dtype=torch.float64) tensor([ 0.], dtype=torch.float64)  torch.set_flush_denormal(False) True  torch.tensor([1e-323], dtype=torch.float64) tensor(9.88131e-324 *        [ 1.0000], dtype=torch.float64)   ", "summary": "Disables denormal floating numbers on CPU", "returns": null, "shape": "NA", "code-info": {"name": "torch.set_flush_denormal", "parameters": [{"name": "mode", "is_optional": false, "type": "bool", "description": " Controls whether to enable flush denormal mode or not"}]}},
{"id": "torch.tensor", "type": "function", "code": "torch.tensor(data,dtype=None,device=None,requires_grad=False,pin_memory=False)", "example": "  torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]]) tensor([[ 0.1000,  1.2000],         [ 2.2000,  3.1000],         [ 4.9000,  5.2000]])   torch.tensor([0, 1])  # Type inference on data tensor([ 0,  1])   torch.tensor([[0.11111, 0.222222, 0.3333333]],                  dtype=torch.float64,                  device=torch.device('cuda:0'))  # creates a torch.cuda.DoubleTensor tensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device='cuda:0')   torch.tensor(3.14159)  # Create a scalar (zero-dimensional tensor) tensor(3.1416)   torch.tensor([])  # Create an empty tensor (of size (0,)) tensor([])   ", "summary": "Constructs a tensor with data", "returns": null, "shape": "NA", "code-info": {"name": "torch.tensor", "parameters": [{"name": "data", "is_optional": false, "type": "array_like", "description": " Initial data for the tensor. Can be a list, tuple,NumPy ndarray, scalar, and other types."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}, {"name": "pin_memory", "is_optional": true, "type": "bool", "default_value": "False", "description": " If set, returned tensor would be allocated inthe pinned memory. Works only for CPU tensors. Default"}]}},
{"id": "torch.sparse_coo_tensor", "type": "function", "code": "torch.sparse_coo_tensor(indices,values,size=None,dtype=None,device=None,requires_grad=False)", "example": "  i = torch.tensor([[0, 1, 1],                       [2, 0, 2]])  v = torch.tensor([3, 4, 5], dtype=torch.float32)  torch.sparse_coo_tensor(i, v, [2, 4]) tensor(indices=tensor([[0, 1, 1],                        [2, 0, 2]]),        values=tensor([3., 4., 5.]),        size=(2, 4), nnz=3, layout=torch.sparse_coo)   torch.sparse_coo_tensor(i, v)  # Shape inference tensor(indices=tensor([[0, 1, 1],                        [2, 0, 2]]),        values=tensor([3., 4., 5.]),        size=(2, 3), nnz=3, layout=torch.sparse_coo)   torch.sparse_coo_tensor(i, v, [2, 4],                             dtype=torch.float64,                             device=torch.device('cuda:0')) tensor(indices=tensor([[0, 1, 1],                        [2, 0, 2]]),        values=tensor([3., 4., 5.]),        device='cuda:0', size=(2, 4), nnz=3, dtype=torch.float64,        layout=torch.sparse_coo)  # Create an empty sparse tensor with the following invariants: #   1. sparse_dim + dense_dim = len(SparseTensor.shape) #   2. SparseTensor._indices().shape = (sparse_dim, nnz) #   3. SparseTensor._values().shape = (nnz, SparseTensor.shape[sparse_dim:]) # # For instance, to create an empty sparse tensor with nnz = 0, dense_dim = 0 and # sparse_dim = 1 (hence indices is a 2D tensor of shape = (1, 0))  S = torch.sparse_coo_tensor(torch.empty([1, 0]), [], [1]) tensor(indices=tensor([], size=(1, 0)),        values=tensor([], size=(0,)),        size=(1,), nnz=0, layout=torch.sparse_coo)  # and to create an empty sparse tensor with nnz = 0, dense_dim = 1 and # sparse_dim = 1  S = torch.sparse_coo_tensor(torch.empty([1, 0]), torch.empty([0, 2]), [1, 2]) tensor(indices=tensor([], size=(1, 0)),        values=tensor([], size=(0, 2)),        size=(1, 2), nnz=0, layout=torch.sparse_coo)   ", "summary": "Constructs a sparse tensors in COO(rdinate) format with non-zero elements at the given indices with the given values", "returns": null, "shape": "NA", "code-info": {"name": "torch.sparse_coo_tensor", "parameters": [{"name": "indices", "is_optional": false, "type": "array_like", "description": " Initial data for the tensor. Can be a list, tuple,NumPy ndarray, scalar, and other types. Will be cast to a torch.LongTensorinternally. The indices are the coordinates of the non-zero values in the matrix, and thusshould be two-dimensional where the first dimension is the number of tensor dimensions andthe second dimension is the number of non-zero values."}, {"name": "values", "is_optional": false, "type": "array_like", "description": " Initial values for the tensor. Can be a list, tuple,NumPy ndarray, scalar, and other types."}, {"name": "size", "is_optional": true, "type": "list, tuple, or torch.Size, optional", "default_value": "None", "description": " Size of the sparse tensor. If notprovided the size will be inferred as the minimum size big enough to hold all non-zeroelements."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.distributions.cauchy.Cauchy.rsample", "type": "method", "code": "torch.distributions.cauchy.Cauchy.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.cauchy.Cauchy.variance", "type": "method", "code": "torch.distributions.cauchy.Cauchy.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy.variance", "parameters": []}},
{"id": "torch.distributions.chi2.Chi2.df", "type": "method", "code": "torch.distributions.chi2.Chi2.df", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.chi2.Chi2.df", "parameters": []}},
{"id": "torch.distributions.chi2.Chi2.expand", "type": "method", "code": "torch.distributions.chi2.Chi2.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.chi2.Chi2.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.dirichlet.Dirichlet.entropy", "type": "method", "code": "torch.distributions.dirichlet.Dirichlet.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.entropy", "parameters": []}},
{"id": "torch.distributions.dirichlet.Dirichlet.expand", "type": "method", "code": "torch.distributions.dirichlet.Dirichlet.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.dirichlet.Dirichlet.log_prob", "type": "method", "code": "torch.distributions.dirichlet.Dirichlet.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.dirichlet.Dirichlet.mean", "type": "method", "code": "torch.distributions.dirichlet.Dirichlet.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.mean", "parameters": []}},
{"id": "torch.distributions.dirichlet.Dirichlet.rsample", "type": "method", "code": "torch.distributions.dirichlet.Dirichlet.rsample(sample_shape=()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.rsample", "parameters": [{"name": "sample_shape", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.dirichlet.Dirichlet.variance", "type": "method", "code": "torch.distributions.dirichlet.Dirichlet.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.variance", "parameters": []}},
{"id": "torch.distributions.exponential.Exponential.cdf", "type": "method", "code": "torch.distributions.exponential.Exponential.cdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.exponential.Exponential.entropy", "type": "method", "code": "torch.distributions.exponential.Exponential.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.entropy", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(dtype,non_blocking=False)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "dtype", "is_optional": false, "type": "others", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(tensor,non_blocking=False)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.utils.clip_grad_norm_", "type": "function", "code": "torch.nn.utils.clip_grad_norm_(parameters,max_norm,norm_type=2)", "example": "NA", "summary": "Clips gradient norm of an iterable of parameters", "returns": "Total norm of the parameters (viewed as a single vector).", "shape": "", "code-info": {"name": "torch.nn.utils.clip_grad_norm_", "parameters": []}},
{"id": "torch.nn.utils.clip_grad_value_", "type": "function", "code": "torch.nn.utils.clip_grad_value_(parameters,clip_value)", "example": "NA", "summary": "Clips gradient of an iterable of parameters at specified value", "returns": [], "shape": "", "code-info": {"name": "torch.nn.utils.clip_grad_value_", "parameters": []}},
{"id": "torch.nn.utils.parameters_to_vector", "type": "function", "code": "torch.nn.utils.parameters_to_vector(parameters)", "example": "NA", "summary": "Convert parameters to one vector  Parameters parameters (Iterable[Tensor]) \u2013 an iterator of Tensors that are the parameters of a model", "returns": "The parameters represented by a single vector", "shape": "", "code-info": {"name": "torch.nn.utils.parameters_to_vector", "parameters": []}},
{"id": "torch.nn.utils.vector_to_parameters", "type": "function", "code": "torch.nn.utils.vector_to_parameters(vec,parameters)", "example": "NA", "summary": "Convert one vector to the parameters  Parameters  vec (Tensor) \u2013 a single vector represents the parameters of a model", "returns": [], "shape": "", "code-info": {"name": "torch.nn.utils.vector_to_parameters", "parameters": []}},
{"id": "torch.nn.utils.prune.identity", "type": "function", "code": "torch.nn.utils.prune.identity(module,name)", "example": "NA", "summary": "Applies pruning reparametrization to the tensor corresponding to the parameter called name in module without actually pruning any units", "returns": "modified (i.e. pruned) version of the input module", "shape": "", "code-info": {"name": "torch.nn.utils.prune.identity", "parameters": []}},
{"id": "torch.nn.utils.prune.random_unstructured", "type": "function", "code": "torch.nn.utils.prune.random_unstructured(module,name,amount)", "example": "NA", "summary": "Prunes tensor corresponding to parameter called name in module by removing the specified amount of (currently unpruned) units selected at random", "returns": "modified (i.e. pruned) version of the input module", "shape": "", "code-info": {"name": "torch.nn.utils.prune.random_unstructured", "parameters": []}},
{"id": "torch.cuda.Stream.synchronize", "type": "method", "code": "torch.cuda.Stream.synchronize()", "example": "NA", "summary": "Wait for all the kernels in this stream to complete", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.Stream.synchronize", "parameters": []}},
{"id": "torch.cuda.Stream.wait_event", "type": "method", "code": "torch.cuda.Stream.wait_event(event)", "example": "NA", "summary": "Makes all future work submitted to the stream wait for an event", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.Stream.wait_event", "parameters": [{"name": "event", "is_optional": false, "type": "Event", "description": " an event to wait for."}]}},
{"id": "torch.cuda.Stream.wait_stream", "type": "method", "code": "torch.cuda.Stream.wait_stream(stream)", "example": "NA", "summary": "Synchronizes with another stream", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.Stream.wait_stream", "parameters": [{"name": "stream", "is_optional": false, "type": "Stream", "description": " a stream to synchronize."}]}},
{"id": "torch.cuda.Event.elapsed_time", "type": "method", "code": "torch.cuda.Event.elapsed_time(end_event)", "example": "NA", "summary": "Returns the time elapsed in milliseconds after the event was recorded and before the end_event was recorded", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.Event.elapsed_time", "parameters": [{"name": "end_event", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.cuda.Event.from_ipc_handle", "type": "method", "code": "torch.cuda.Event.from_ipc_handle(device,handle)", "example": "NA", "summary": "Reconstruct an event from an IPC handle on the given device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.Event.from_ipc_handle", "parameters": [{"name": "device", "is_optional": false, "type": "others", "description": ""}, {"name": "handle", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.cuda.Event.ipc_handle", "type": "method", "code": "torch.cuda.Event.ipc_handle()", "example": "NA", "summary": "Returns an IPC handle of this event", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.Event.ipc_handle", "parameters": []}},
{"id": "torch.cuda.Event.query", "type": "method", "code": "torch.cuda.Event.query()", "example": "NA", "summary": "Checks if all work currently captured by event has completed", "returns": "A boolean indicating if all work currently captured by event hascompleted.", "shape": "NA", "code-info": {"name": "torch.cuda.Event.query", "parameters": []}},
{"id": "torch.cuda.Event.record", "type": "method", "code": "torch.cuda.Event.record(stream=None)", "example": "NA", "summary": "Records the event in a given stream", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.Event.record", "parameters": [{"name": "stream", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.cuda.Event.synchronize", "type": "method", "code": "torch.cuda.Event.synchronize()", "example": "NA", "summary": "Waits for the event to complete", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.Event.synchronize", "parameters": []}},
{"id": "torch.cuda.Event.wait", "type": "method", "code": "torch.cuda.Event.wait(stream=None)", "example": "NA", "summary": "Makes all future work submitted to the given stream wait for this event", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.Event.wait", "parameters": [{"name": "stream", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.cuda.device", "type": "class", "code": "torch.cuda.device(device)", "example": "NA", "summary": "Context-manager that changes the selected device", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.device", "parameters": [{"name": "device", "is_optional": false, "type": "torch.device or int", "description": " device index to select. It\u2019s a no-op ifthis argument is a negative integer or None."}]}},
{"id": "torch.nn.intrinsic.ConvBn2d", "type": "class", "code": "torch.nn.intrinsic.ConvBn2d(conv,bn)", "example": "NA", "summary": "This is a sequential container which calls the Conv 2d and Batch Norm 2d modules", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.ConvBn2d", "parameters": [{"name": "conv", "is_optional": false, "type": "others", "description": ""}, {"name": "bn", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.intrinsic.ConvBnReLU2d", "type": "class", "code": "torch.nn.intrinsic.ConvBnReLU2d(conv,bn,relu)", "example": "NA", "summary": "This is a sequential container which calls the Conv 2d, Batch Norm 2d, and ReLU modules", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.ConvBnReLU2d", "parameters": [{"name": "conv", "is_optional": false, "type": "others", "description": ""}, {"name": "bn", "is_optional": false, "type": "others", "description": ""}, {"name": "relu", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.intrinsic.ConvReLU2d", "type": "class", "code": "torch.nn.intrinsic.ConvReLU2d(conv,relu)", "example": "NA", "summary": "This is a sequential container which calls the Conv 2d and ReLU modules", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.ConvReLU2d", "parameters": [{"name": "conv", "is_optional": false, "type": "others", "description": ""}, {"name": "relu", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.intrinsic.ConvReLU3d", "type": "class", "code": "torch.nn.intrinsic.ConvReLU3d(conv,relu)", "example": "NA", "summary": "This is a sequential container which calls the Conv 3d and ReLU modules", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.ConvReLU3d", "parameters": [{"name": "conv", "is_optional": false, "type": "others", "description": ""}, {"name": "relu", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.intrinsic.LinearReLU", "type": "class", "code": "torch.nn.intrinsic.LinearReLU(linear,relu)", "example": "NA", "summary": "This is a sequential container which calls the Linear and ReLU modules", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.LinearReLU", "parameters": [{"name": "linear", "is_optional": false, "type": "others", "description": ""}, {"name": "relu", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.intrinsic.qat.ConvBn2d", "type": "class", "code": "torch.nn.intrinsic.qat.ConvBn2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)", "example": "NA", "summary": "A ConvBn2d module is a module fused from Conv2d and BatchNorm2d, attached with FakeQuantize modules for both output activation and weight, used in quantization aware training", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.qat.ConvBn2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "freeze_bn", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.intrinsic.qat.ConvBnReLU2d", "type": "class", "code": "torch.nn.intrinsic.qat.ConvBnReLU2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)", "example": "NA", "summary": "A ConvBnReLU2d module is a module fused from Conv2d, BatchNorm2d and ReLU, attached with FakeQuantize modules for both output activation and weight, used in quantization aware training", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.qat.ConvBnReLU2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "freeze_bn", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.intrinsic.qat.ConvReLU2d", "type": "class", "code": "torch.nn.intrinsic.qat.ConvReLU2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros',qconfig=None)", "example": "NA", "summary": "A ConvReLU2d module is a fused module of Conv2d and ReLU, attached with FakeQuantize modules for both output activation and weight for quantization aware training", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.qat.ConvReLU2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.optim.lr_scheduler.OneCycleLR", "type": "class", "code": "torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr,total_steps=None,epochs=None,steps_per_epoch=None,pct_start=0.3,anneal_strategy='cos',cycle_momentum=True,base_momentum=0.85,max_momentum=0.95,div_factor=25.0,final_div_factor=10000.0,last_epoch=-1)", "example": " data_loader = torch.utils.data.DataLoader(...)\n optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(data_loader), epochs=10)\n for epoch in range(10):\n     for batch in data_loader:\n         train_batch(...)\n         scheduler.step()\n\n", "summary": "Sets the learning rate of each parameter group according to the 1cycle learning rate policy", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.OneCycleLR", "parameters": [{"name": "optimizer", "is_optional": false, "type": "Optimizer", "description": " Wrapped optimizer."}, {"name": "max_lr", "is_optional": false, "type": "float or list", "description": " Upper learning rate boundaries in the cyclefor each parameter group."}, {"name": "total_steps", "is_optional": true, "type": "int", "default_value": "None", "description": " The total number of steps in the cycle. Note thatif a value is provided here, then it must be inferred by providinga value for epochs and steps_per_epoch.Default"}, {"name": "epochs", "is_optional": true, "type": "int", "default_value": "None", "description": " The number of epochs to train for. This is used alongwith steps_per_epoch in order to infer the total number of steps in the cycleif a value for total_steps is not provided.Default"}, {"name": "steps_per_epoch", "is_optional": true, "type": "int", "default_value": "None", "description": " The number of steps per epoch to train for. This isused along with epochs in order to infer the total number of steps in thecycle if a value for total_steps is not provided.Default"}, {"name": "pct_start", "is_optional": true, "type": "float", "default_value": "0.3", "description": " The percentage of the cycle (in number of steps spentincreasing the learning rate.Default"}, {"name": "anneal_strategy", "is_optional": true, "type": "string", "default_value": "'cos'", "description": " {\u2018cos\u2019, \u2018linear\u2019}Specifies the annealing strategy"}, {"name": "cycle_momentum", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, momentum is cycled inverselyto learning rate between \u2018base_momentum\u2019 and \u2018max_momentum\u2019.Default"}, {"name": "base_momentum", "is_optional": true, "type": "bool", "default_value": "0.85", "description": " Lower momentum boundaries in the cyclefor each parameter group. Note that momentum is cycled inverselyto learning rate; at the peak of a cycle, momentum is\u2018base_momentum\u2019 and learning rate is \u2018max_lr\u2019.Default"}, {"name": "max_momentum", "is_optional": true, "type": "bool", "default_value": "0.95", "description": " Upper momentum boundaries in the cyclefor each parameter group. Functionally,it defines the cycle amplitude (max_momentum - base_momentum.Note that momentum is cycled inverselyto learning rate; at the start of a cycle, momentum is \u2018max_momentum\u2019and learning rate is \u2018base_lr\u2019Default"}, {"name": "div_factor", "is_optional": true, "type": "float", "default_value": "25.0", "description": " Determines the initial learning rate viainitial_lr = max_lr/div_factorDefault"}, {"name": "final_div_factor", "is_optional": true, "type": "float", "default_value": "10000.0", "description": " Determines the minimum learning rate viamin_lr = initial_lr/final_div_factorDefault"}, {"name": "last_epoch", "is_optional": true, "type": "int", "default_value": "-1", "description": " The index of the last batch. This parameter is used whenresuming a training job. Since step( should be invoked after eachbatch instead of after each epoch, this number represents the totalnumber of batches computed, not the total number of epochs computed.When last_epoch=-1, the schedule is started from the beginning.Default"}]}},
{"id": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts", "type": "class", "code": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0,T_mult=1,eta_min=0,last_epoch=-1)", "example": " scheduler = CosineAnnealingWarmRestarts(optimizer, T_0, T_mult)\n iters = len(dataloader)\n for epoch in range(20):\n     for i, sample in enumerate(dataloader):\n         inputs, labels = sample['inputs'], sample['labels']\n         scheduler.step(epoch + i / iters)\n         optimizer.zero_grad()\n         outputs = net(inputs)\n         loss = criterion(outputs, labels)\n         loss.backward()\n         optimizer.step()\n\n", "summary": "Set the learning rate of each parameter group using a cosine annealing schedule, where \u03b7max\\eta_{max}\u03b7max\u200b   is set to the initial lr, TcurT_{cur}Tcur\u200b   is the number of epochs since the last restart and TiT_{i}Ti\u200b   is the number of epochs between two warm restarts in SGDR:  \u03b7t=\u03b7min+12(\u03b7max\u2212\u03b7min)(1+cos\u2061(TcurTi\u03c0))\\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})\\left(1 + \\cos\\left(\\frac{T_{cur}}{T_{i}}\\pi\\right)\\right)  \u03b7t\u200b=\u03b7min\u200b+21\u200b(\u03b7max\u200b\u2212\u03b7min\u200b)(1+cos(Ti\u200bTcur\u200b\u200b\u03c0))  When Tcur=TiT_{cur}=T_{i}Tcur\u200b=Ti\u200b  , set \u03b7t=\u03b7min\\eta_t = \\eta_{min}\u03b7t\u200b=\u03b7min\u200b  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts", "parameters": [{"name": "optimizer", "is_optional": false, "type": "Optimizer", "description": " Wrapped optimizer."}, {"name": "T_0", "is_optional": false, "type": "int", "description": " Number of iterations for the first restart."}, {"name": "T_mult", "is_optional": true, "type": "int", "default_value": "1", "description": " A factor increases TiT_{i}Ti\u200b after a restart. Default"}, {"name": "eta_min", "is_optional": true, "type": "int", "default_value": "0", "description": " Minimum learning rate. Default"}, {"name": "last_epoch", "is_optional": true, "type": "int, optional", "default_value": "-1", "description": " The index of last epoch. Default"}]}},
{"id": "torch.Tensor.bitwise_xor", "type": "method", "code": "torch.Tensor.bitwise_xor()", "example": "NA", "summary": "See torch.bitwise_xor() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.bitwise_xor", "parameters": []}},
{"id": "torch.Tensor.bitwise_xor_", "type": "method", "code": "torch.Tensor.bitwise_xor_()", "example": "NA", "summary": "In-place version of bitwise_xor() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.bitwise_xor_", "parameters": []}},
{"id": "torch.Tensor.bmm", "type": "method", "code": "torch.Tensor.bmm(batch2)", "example": "NA", "summary": "See torch.bmm() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.bmm", "parameters": [{"name": "batch2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.bool", "type": "method", "code": "torch.Tensor.bool()", "example": "NA", "summary": "self.bool() is equivalent to self.to(torch.bool)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.bool", "parameters": []}},
{"id": "torch.Tensor.byte", "type": "method", "code": "torch.Tensor.byte()", "example": "NA", "summary": "self.byte() is equivalent to self.to(torch.uint8)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.byte", "parameters": []}},
{"id": "torch.Tensor.cauchy_", "type": "method", "code": "torch.Tensor.cauchy_(median=0,sigma=1,*,generator=None)", "example": "NA", "summary": "Fills the tensor with numbers drawn from the Cauchy distribution:  f(x)=1\u03c0\u03c3(x\u2212median)2+\u03c32f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}f(x)=\u03c01\u200b(x\u2212median)2+\u03c32\u03c3\u200b  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cauchy_", "parameters": [{"name": "median", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "sigma", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.ceil", "type": "method", "code": "torch.Tensor.ceil()", "example": "NA", "summary": "See torch.ceil() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.ceil", "parameters": []}},
{"id": "torch.Tensor.ceil_", "type": "method", "code": "torch.Tensor.ceil_()", "example": "NA", "summary": "In-place version of ceil() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.ceil_", "parameters": []}},
{"id": "torch.Tensor.char", "type": "method", "code": "torch.Tensor.char()", "example": "NA", "summary": "self.char() is equivalent to self.to(torch.int8)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.char", "parameters": []}},
{"id": "torch.Tensor.cholesky", "type": "method", "code": "torch.Tensor.cholesky(upper=False)", "example": "NA", "summary": "See torch.cholesky() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cholesky", "parameters": [{"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.cholesky_inverse", "type": "method", "code": "torch.Tensor.cholesky_inverse(upper=False)", "example": "NA", "summary": "See torch.cholesky_inverse() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cholesky_inverse", "parameters": [{"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.cholesky_solve", "type": "method", "code": "torch.Tensor.cholesky_solve(input2,upper=False)", "example": "NA", "summary": "See torch.cholesky_solve() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cholesky_solve", "parameters": [{"name": "input2", "is_optional": false, "type": "others", "description": ""}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.elu_", "type": "function", "code": "torch.nn.functional.elu_(input,alpha=1.)", "example": "NA", "summary": "In-place version of elu()", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.elu_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "alpha", "is_optional": true, "type": "others", "default_value": "1.", "description": ""}]}},
{"id": "torch.nn.functional.selu", "type": "function", "code": "torch.nn.functional.selu(input,inplace=False)", "example": "NA", "summary": "Applies element-wise, SELU(x)=scale\u2217(max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x)\u22121)))\\text{SELU}(x) = scale * (\\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)))SELU(x)=scale\u2217(max(0,x)+min(0,\u03b1\u2217(exp(x)\u22121)))  , with \u03b1=1.6732632423543772848170429916717\\alpha=1.6732632423543772848170429916717\u03b1=1.6732632423543772848170429916717   and scale=1.0507009873554804934193349852946scale=1.0507009873554804934193349852946scale=1.0507009873554804934193349852946  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.selu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.celu", "type": "function", "code": "torch.nn.functional.celu(input,alpha=1.,inplace=False)", "example": "NA", "summary": "Applies element-wise, CELU(x)=max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x/\u03b1)\u22121))\\text{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1))CELU(x)=max(0,x)+min(0,\u03b1\u2217(exp(x/\u03b1)\u22121))  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.celu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "alpha", "is_optional": true, "type": "others", "default_value": "1.", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.leaky_relu", "type": "function", "code": "torch.nn.functional.leaky_relu(input,negative_slope=0.01,inplace=False)", "example": "NA", "summary": "Applies element-wise, LeakyReLU(x)=max\u2061(0,x)+negative_slope\u2217min\u2061(0,x)\\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x)LeakyReLU(x)=max(0,x)+negative_slope\u2217min(0,x)   See LeakyReLU for more details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.leaky_relu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "negative_slope", "is_optional": true, "type": "others", "default_value": "0.01", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.leaky_relu_", "type": "function", "code": "torch.nn.functional.leaky_relu_(input,negative_slope=0.01)", "example": "NA", "summary": "In-place version of leaky_relu()", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.leaky_relu_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "negative_slope", "is_optional": true, "type": "others", "default_value": "0.01", "description": ""}]}},
{"id": "torch.nn.functional.prelu", "type": "function", "code": "torch.nn.functional.prelu(input,weight)", "example": "NA", "summary": "Applies element-wise the function PReLU(x)=max\u2061(0,x)+weight\u2217min\u2061(0,x)\\text{PReLU}(x) = \\max(0,x) + \\text{weight} * \\min(0,x)PReLU(x)=max(0,x)+weight\u2217min(0,x)   where weight is a learnable parameter", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.prelu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.rrelu", "type": "function", "code": "torch.nn.functional.rrelu(input,lower=1./8,upper=1./3,training=False,inplace=False)", "example": "NA", "summary": "Randomized leaky ReLU", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.rrelu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "lower", "is_optional": true, "type": "others", "default_value": "1./8", "description": ""}, {"name": "upper", "is_optional": true, "type": "others", "default_value": "1./3", "description": ""}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.rrelu_", "type": "function", "code": "torch.nn.functional.rrelu_(input,lower=1./8,upper=1./3,training=False)", "example": "NA", "summary": "In-place version of rrelu()", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.rrelu_", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "lower", "is_optional": true, "type": "others", "default_value": "1./8", "description": ""}, {"name": "upper", "is_optional": true, "type": "others", "default_value": "1./3", "description": ""}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.glu", "type": "function", "code": "torch.nn.functional.glu(input,dim=-1)", "example": "NA", "summary": "The gated linear unit", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.glu", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " input tensor"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": " dimension on which to split the input. Default"}]}},
{"id": "torch.as_tensor", "type": "function", "code": "torch.as_tensor(data,dtype=None,device=None)", "example": "  a = numpy.array([1, 2, 3])  t = torch.as_tensor(a)  t tensor([ 1,  2,  3])  t[0] = -1  a array([-1,  2,  3])   a = numpy.array([1, 2, 3])  t = torch.as_tensor(a, device=torch.device('cuda'))  t tensor([ 1,  2,  3])  t[0] = -1  a array([1,  2,  3])   ", "summary": "Convert the data into a torch.Tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.as_tensor", "parameters": [{"name": "data", "is_optional": false, "type": "array_like", "description": " Initial data for the tensor. Can be a list, tuple,NumPy ndarray, scalar, and other types."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}]}},
{"id": "torch.as_strided", "type": "function", "code": "torch.as_strided(input,size,stride,storage_offset=0)", "example": "  x = torch.randn(3, 3)  x tensor([[ 0.9039,  0.6291,  1.0795],         [ 0.1586,  2.1939, -0.4900],         [-0.1909, -0.7503,  1.9355]])  t = torch.as_strided(x, (2, 2), (1, 2))  t tensor([[0.9039, 1.0795],         [0.6291, 0.1586]])  t = torch.as_strided(x, (2, 2), (1, 2), 1) tensor([[0.6291, 0.1586],         [1.0795, 2.1939]])   ", "summary": "Create a view of an existing torch.Tensor input with specified size, stride and storage_offset", "returns": null, "shape": "NA", "code-info": {"name": "torch.as_strided", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "size", "is_optional": false, "type": "tuple or ints", "description": " the shape of the output tensor"}, {"name": "stride", "is_optional": false, "type": "tuple or ints", "description": " the stride of the output tensor"}, {"name": "storage_offset", "is_optional": true, "type": "int", "default_value": "0", "description": " the offset in the underlying storage of the output tensor"}]}},
{"id": "torch.from_numpy", "type": "function", "code": "torch.from_numpy(ndarray)", "example": "  a = numpy.array([1, 2, 3])  t = torch.from_numpy(a)  t tensor([ 1,  2,  3])  t[0] = -1  a array([-1,  2,  3])   ", "summary": "Creates a Tensor from a numpy.ndarray", "returns": null, "shape": "NA", "code-info": {"name": "torch.from_numpy", "parameters": [{"name": "ndarray", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.zeros", "type": "function", "code": "torch.zeros(*size,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.zeros(2, 3) tensor([[ 0.,  0.,  0.],         [ 0.,  0.,  0.]])   torch.zeros(5) tensor([ 0.,  0.,  0.,  0.,  0.])   ", "summary": "Returns a tensor filled with the scalar value 0, with the shape defined by the variable argument size", "returns": null, "shape": "NA", "code-info": {"name": "torch.zeros", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "int...", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.distributions.exponential.Exponential.expand", "type": "method", "code": "torch.distributions.exponential.Exponential.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.exponential.Exponential.icdf", "type": "method", "code": "torch.distributions.exponential.Exponential.icdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.exponential.Exponential.log_prob", "type": "method", "code": "torch.distributions.exponential.Exponential.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.exponential.Exponential.mean", "type": "method", "code": "torch.distributions.exponential.Exponential.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.mean", "parameters": []}},
{"id": "torch.distributions.exponential.Exponential.rsample", "type": "method", "code": "torch.distributions.exponential.Exponential.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.exponential.Exponential.stddev", "type": "method", "code": "torch.distributions.exponential.Exponential.stddev", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.stddev", "parameters": []}},
{"id": "torch.distributions.exponential.Exponential.variance", "type": "method", "code": "torch.distributions.exponential.Exponential.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.variance", "parameters": []}},
{"id": "torch.distributions.fishersnedecor.FisherSnedecor.expand", "type": "method", "code": "torch.distributions.fishersnedecor.FisherSnedecor.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.fishersnedecor.FisherSnedecor.log_prob", "type": "method", "code": "torch.distributions.fishersnedecor.FisherSnedecor.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.fishersnedecor.FisherSnedecor.mean", "type": "method", "code": "torch.distributions.fishersnedecor.FisherSnedecor.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor.mean", "parameters": []}},
{"id": "torch.distributions.fishersnedecor.FisherSnedecor.rsample", "type": "method", "code": "torch.distributions.fishersnedecor.FisherSnedecor.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.fishersnedecor.FisherSnedecor.variance", "type": "method", "code": "torch.distributions.fishersnedecor.FisherSnedecor.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor.variance", "parameters": []}},
{"id": "torch.nn.utils.prune.l1_unstructured", "type": "function", "code": "torch.nn.utils.prune.l1_unstructured(module,name,amount)", "example": "NA", "summary": "Prunes tensor corresponding to parameter called name in module by removing the specified amount of (currently unpruned) units with the lowest L1-norm", "returns": "modified (i.e. pruned) version of the input module", "shape": "", "code-info": {"name": "torch.nn.utils.prune.l1_unstructured", "parameters": []}},
{"id": "torch.nn.utils.prune.random_structured", "type": "function", "code": "torch.nn.utils.prune.random_structured(module,name,amount,dim)", "example": "NA", "summary": "Prunes tensor corresponding to parameter called name in module by removing the specified amount of (currently unpruned) channels along the specified dim selected at random", "returns": "modified (i.e. pruned) version of the input module", "shape": "", "code-info": {"name": "torch.nn.utils.prune.random_structured", "parameters": []}},
{"id": "torch.nn.utils.prune.ln_structured", "type": "function", "code": "torch.nn.utils.prune.ln_structured(module,name,amount,n,dim)", "example": "NA", "summary": "Prunes tensor corresponding to parameter called name in module by removing the specified amount of (currently unpruned) channels along the specified dim with the lowest L``n``-norm", "returns": "modified (i.e. pruned) version of the input module", "shape": "", "code-info": {"name": "torch.nn.utils.prune.ln_structured", "parameters": []}},
{"id": "torch.nn.utils.prune.global_unstructured", "type": "function", "code": "torch.nn.utils.prune.global_unstructured(parameters,pruning_method,**kwargs)", "example": "NA", "summary": "Globally prunes tensors corresponding to all parameters in parameters by applying the specified pruning_method", "returns": [], "shape": "", "code-info": {"name": "torch.nn.utils.prune.global_unstructured", "parameters": []}},
{"id": "torch.cuda.device_of", "type": "class", "code": "torch.cuda.device_of(obj)", "example": "NA", "summary": "Context-manager that changes the current device to that of given object", "returns": null, "shape": "NA", "code-info": {"name": "torch.cuda.device_of", "parameters": [{"name": "obj", "is_optional": false, "type": "Tensor or Storage", "description": " object allocated on the selected device."}]}},
{"id": "torch.cuda.Stream", "type": "class", "code": "torch.cuda.Stream", "example": "NA", "summary": "Wrapper around a CUDA stream", "returns": "A boolean indicating if all kernels in this stream are completed.", "shape": "NA", "code-info": {"name": "torch.cuda.Stream", "parameters": []}},
{"id": "torch.cuda.Event", "type": "class", "code": "torch.cuda.Event", "example": "NA", "summary": "Wrapper around a CUDA event", "returns": "A boolean indicating if all work currently captured by event hascompleted.", "shape": "NA", "code-info": {"name": "torch.cuda.Event", "parameters": []}},
{"id": "torch.nn.intrinsic.qat.LinearReLU", "type": "class", "code": "torch.nn.intrinsic.qat.LinearReLU(in_features,out_features,bias=True,qconfig=None)", "example": " m = nn.qat.LinearReLU(20, 30)\n input = torch.randn(128, 20)\n output = m(input)\n print(output.size())\ntorch.Size([128, 30])\n\n", "summary": "A LinearReLU module fused from Linear and ReLU modules, attached with FakeQuantize modules for output activation and weight, used in quantization aware training", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.qat.LinearReLU", "parameters": [{"name": "in_features", "is_optional": false, "type": "others", "description": ""}, {"name": "out_features", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.intrinsic.quantized.ConvReLU2d", "type": "class", "code": "torch.nn.intrinsic.quantized.ConvReLU2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')", "example": "NA", "summary": "A ConvReLU2d module is a fused module of Conv2d and ReLU We adopt the same interface as torch.nn.quantized.Conv2d", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.quantized.ConvReLU2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}]}},
{"id": "torch.nn.intrinsic.quantized.ConvReLU3d", "type": "class", "code": "torch.nn.intrinsic.quantized.ConvReLU3d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')", "example": "NA", "summary": "A ConvReLU3d module is a fused module of Conv3d and ReLU We adopt the same interface as torch.nn.quantized.Conv3d", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.quantized.ConvReLU3d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}]}},
{"id": "torch.nn.intrinsic.quantized.LinearReLU", "type": "class", "code": "torch.nn.intrinsic.quantized.LinearReLU(in_features,out_features,bias=True)", "example": " m = nn.intrinsic.LinearReLU(20, 30)\n input = torch.randn(128, 20)\n output = m(input)\n print(output.size())\ntorch.Size([128, 30])\n\n", "summary": "A LinearReLU module fused from Linear and ReLU modules We adopt the same interface as torch.nn.quantized.Linear", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.intrinsic.quantized.LinearReLU", "parameters": [{"name": "in_features", "is_optional": false, "type": "others", "description": ""}, {"name": "out_features", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.nn.qat.Conv2d", "type": "class", "code": "torch.nn.qat.Conv2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros',qconfig=None)", "example": "NA", "summary": "A Conv2d module attached with FakeQuantize modules for both output activation and weight, used for quantization aware training", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.qat.Conv2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.qat.Linear", "type": "class", "code": "torch.nn.qat.Linear(in_features,out_features,bias=True,qconfig=None)", "example": "NA", "summary": "A linear module attached with FakeQuantize modules for both output activation and weight, used for quantization aware training", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.qat.Linear", "parameters": [{"name": "in_features", "is_optional": false, "type": "others", "description": ""}, {"name": "out_features", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "qconfig", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.quantized.ReLU", "type": "class", "code": "torch.nn.quantized.ReLU(inplace=False)", "example": " m = nn.quantized.ReLU()\n input = torch.randn(2)\n input = torch.quantize_per_tensor(input, 1.0, 0, dtype=torch.qint32)\n output = m(input)\n\n", "summary": "Applies quantized rectified linear unit function element-wise: ReLU(x)=max\u2061(x0,x)\\text{ReLU}(x)= \\max(x_0, x)ReLU(x)=max(x0\u200b,x)  , where x0x_0x0\u200b   is the zero point", "returns": null, "shape": " Input: (N,\u2217)(N, *)(N,\u2217)   where * means, any number of additional dimensions Output: (N,\u2217)(N, *)(N,\u2217)  , same shape as the input  ", "code-info": {"name": "torch.nn.quantized.ReLU", "parameters": [{"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " (Currently not supported can optionally do the operation in-place."}]}},
{"id": "torch.nn.quantized.ReLU6", "type": "class", "code": "torch.nn.quantized.ReLU6(inplace=False)", "example": " m = nn.quantized.ReLU6()\n input = torch.randn(2)\n input = torch.quantize_per_tensor(input, 1.0, 0, dtype=torch.qint32)\n output = m(input)\n\n", "summary": "Applies the element-wise function: ReLU6(x)=min\u2061(max\u2061(x0,x),q(6))\\text{ReLU6}(x) = \\min(\\max(x_0, x), q(6))ReLU6(x)=min(max(x0\u200b,x),q(6))  , where x0x_0x0\u200b   is the zero_point, and q(6)q(6)q(6)   is the quantized representation of number 6", "returns": null, "shape": " Input: (N,\u2217)(N, *)(N,\u2217)   where * means, any number of additional dimensions Output: (N,\u2217)(N, *)(N,\u2217)  , same shape as the input  ", "code-info": {"name": "torch.nn.quantized.ReLU6", "parameters": [{"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " can optionally do the operation in-place. Default"}]}},
{"id": "torch.Tensor.chunk", "type": "method", "code": "torch.Tensor.chunk(chunks,dim=0)", "example": "NA", "summary": "See torch.chunk() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.chunk", "parameters": [{"name": "chunks", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.Tensor.clamp", "type": "method", "code": "torch.Tensor.clamp(min,max)", "example": "NA", "summary": "See torch.clamp() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.clamp", "parameters": [{"name": "min", "is_optional": false, "type": "others", "description": ""}, {"name": "max", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.clamp_", "type": "method", "code": "torch.Tensor.clamp_(min,max)", "example": "NA", "summary": "In-place version of clamp() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.clamp_", "parameters": [{"name": "min", "is_optional": false, "type": "others", "description": ""}, {"name": "max", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.clone", "type": "method", "code": "torch.Tensor.clone()", "example": "NA", "summary": "Returns a copy of the self tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.clone", "parameters": []}},
{"id": "torch.Tensor.contiguous", "type": "method", "code": "torch.Tensor.contiguous()", "example": "NA", "summary": "Returns a contiguous tensor containing the same data as self tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.contiguous", "parameters": []}},
{"id": "torch.Tensor.copy_", "type": "method", "code": "torch.Tensor.copy_(src,non_blocking=False)", "example": "NA", "summary": "Copies the elements from src into self tensor and returns self", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.copy_", "parameters": [{"name": "src", "is_optional": false, "type": "Tensor", "description": " the source tensor to copy from"}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": " if True and this copy is between CPU and GPU,the copy may occur asynchronously with respect to the host. For othercases, this argument has no effect."}]}},
{"id": "torch.Tensor.conj", "type": "method", "code": "torch.Tensor.conj()", "example": "NA", "summary": "See torch.conj() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.conj", "parameters": []}},
{"id": "torch.Tensor.cos", "type": "method", "code": "torch.Tensor.cos()", "example": "NA", "summary": "See torch.cos() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cos", "parameters": []}},
{"id": "torch.Tensor.cos_", "type": "method", "code": "torch.Tensor.cos_()", "example": "NA", "summary": "In-place version of cos() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cos_", "parameters": []}},
{"id": "torch.Tensor.cosh", "type": "method", "code": "torch.Tensor.cosh()", "example": "NA", "summary": "See torch.cosh() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cosh", "parameters": []}},
{"id": "torch.Tensor.cosh_", "type": "method", "code": "torch.Tensor.cosh_()", "example": "NA", "summary": "In-place version of cosh() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cosh_", "parameters": []}},
{"id": "torch.Tensor.cpu", "type": "method", "code": "torch.Tensor.cpu()", "example": "NA", "summary": "Returns a copy of this object in CPU memory", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cpu", "parameters": []}},
{"id": "torch.nn.functional.gelu", "type": "function", "code": "torch.nn.functional.gelu(input)", "example": "NA", "summary": "Applies element-wise the function GELU(x)=x\u2217\u03a6(x)\\text{GELU}(x) = x * \\Phi(x)GELU(x)=x\u2217\u03a6(x)   where \u03a6(x)\\Phi(x)\u03a6(x)   is the Cumulative Distribution Function for Gaussian Distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.gelu", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.logsigmoid", "type": "function", "code": "torch.nn.functional.logsigmoid(input)", "example": "NA", "summary": "Applies element-wise LogSigmoid(xi)=log\u2061(11+exp\u2061(\u2212xi))\\text{LogSigmoid}(x_i) = \\log \\left(\\frac{1}{1 + \\exp(-x_i)}\\right)LogSigmoid(xi\u200b)=log(1+exp(\u2212xi\u200b)1\u200b)   See LogSigmoid for more details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.logsigmoid", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.hardshrink", "type": "function", "code": "torch.nn.functional.hardshrink(input,lambd=0.5)", "example": "NA", "summary": "Applies the hard shrinkage function element-wise See Hardshrink for more details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.hardshrink", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "lambd", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}]}},
{"id": "torch.nn.functional.tanhshrink", "type": "function", "code": "torch.nn.functional.tanhshrink(input)", "example": "NA", "summary": "Applies element-wise, Tanhshrink(x)=x\u2212Tanh(x)\\text{Tanhshrink}(x) = x - \\text{Tanh}(x)Tanhshrink(x)=x\u2212Tanh(x)   See Tanhshrink for more details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.tanhshrink", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.softsign", "type": "function", "code": "torch.nn.functional.softsign(input)", "example": "NA", "summary": "Applies element-wise, the function SoftSign(x)=x1+\u2223x\u2223\\text{SoftSign}(x) = \\frac{x}{1 + |x|}SoftSign(x)=1+\u2223x\u2223x\u200b   See Softsign for more details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.softsign", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.softplus", "type": "function", "code": "torch.nn.functional.softplus(input,beta=1,threshold=20)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.softplus", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "threshold", "is_optional": true, "type": "int", "default_value": "20", "description": ""}]}},
{"id": "torch.nn.functional.softmin", "type": "function", "code": "torch.nn.functional.softmin(input,dim=None,_stacklevel=3,dtype=None)", "example": "NA", "summary": "Applies a softmin function", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.softmin", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " input"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": " A dimension along which softmin will be computed (so every slicealong dim will sum to 1."}, {"name": "_stacklevel", "is_optional": true, "type": "int", "default_value": "3", "description": ""}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.If specified, the input tensor is casted to dtype before the operationis performed. This is useful for preventing data type overflows. Default"}]}},
{"id": "torch.nn.functional.softmax", "type": "function", "code": "torch.nn.functional.softmax(input,dim=None,_stacklevel=3,dtype=None)", "example": "NA", "summary": "Applies a softmax function", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.softmax", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " input"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": " A dimension along which softmax will be computed."}, {"name": "_stacklevel", "is_optional": true, "type": "int", "default_value": "3", "description": ""}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.If specified, the input tensor is casted to dtype before the operationis performed. This is useful for preventing data type overflows. Default"}]}},
{"id": "torch.zeros_like", "type": "function", "code": "torch.zeros_like(input,dtype=None,layout=None,device=None,requires_grad=False)", "example": "  input = torch.empty(2, 3)  torch.zeros_like(input) tensor([[ 0.,  0.,  0.],         [ 0.,  0.,  0.]])   ", "summary": "Returns a tensor filled with the scalar value 0, with the same size as input", "returns": null, "shape": "NA", "code-info": {"name": "torch.zeros_like", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the size of input will determine size of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned Tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "None", "description": " the desired layout of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.ones", "type": "function", "code": "torch.ones(*size,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.ones(2, 3) tensor([[ 1.,  1.,  1.],         [ 1.,  1.,  1.]])   torch.ones(5) tensor([ 1.,  1.,  1.,  1.,  1.])   ", "summary": "Returns a tensor filled with the scalar value 1, with the shape defined by the variable argument size", "returns": null, "shape": "NA", "code-info": {"name": "torch.ones", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "int...", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.ones_like", "type": "function", "code": "torch.ones_like(input,dtype=None,layout=None,device=None,requires_grad=False)", "example": "  input = torch.empty(2, 3)  torch.ones_like(input) tensor([[ 1.,  1.,  1.],         [ 1.,  1.,  1.]])   ", "summary": "Returns a tensor filled with the scalar value 1, with the same size as input", "returns": null, "shape": "NA", "code-info": {"name": "torch.ones_like", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the size of input will determine size of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned Tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "None", "description": " the desired layout of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.distributions.gamma.Gamma.entropy", "type": "method", "code": "torch.distributions.gamma.Gamma.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gamma.Gamma.entropy", "parameters": []}},
{"id": "torch.distributions.gamma.Gamma.expand", "type": "method", "code": "torch.distributions.gamma.Gamma.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gamma.Gamma.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.gamma.Gamma.log_prob", "type": "method", "code": "torch.distributions.gamma.Gamma.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gamma.Gamma.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.gamma.Gamma.mean", "type": "method", "code": "torch.distributions.gamma.Gamma.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gamma.Gamma.mean", "parameters": []}},
{"id": "torch.distributions.gamma.Gamma.rsample", "type": "method", "code": "torch.distributions.gamma.Gamma.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gamma.Gamma.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.gamma.Gamma.variance", "type": "method", "code": "torch.distributions.gamma.Gamma.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gamma.Gamma.variance", "parameters": []}},
{"id": "torch.distributions.geometric.Geometric.entropy", "type": "method", "code": "torch.distributions.geometric.Geometric.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.geometric.Geometric.entropy", "parameters": []}},
{"id": "torch.distributions.geometric.Geometric.expand", "type": "method", "code": "torch.distributions.geometric.Geometric.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.geometric.Geometric.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.geometric.Geometric.log_prob", "type": "method", "code": "torch.distributions.geometric.Geometric.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.geometric.Geometric.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.geometric.Geometric.mean", "type": "method", "code": "torch.distributions.geometric.Geometric.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.geometric.Geometric.mean", "parameters": []}},
{"id": "torch.distributions.geometric.Geometric.sample", "type": "method", "code": "torch.distributions.geometric.Geometric.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.geometric.Geometric.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.geometric.Geometric.variance", "type": "method", "code": "torch.distributions.geometric.Geometric.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.geometric.Geometric.variance", "parameters": []}},
{"id": "torch.nn.utils.prune.custom_from_mask", "type": "function", "code": "torch.nn.utils.prune.custom_from_mask(module,name,mask)", "example": "NA", "summary": "Prunes tensor corresponding to parameter called name in module by applying the pre-computed mask in mask", "returns": "modified (i.e. pruned) version of the input module", "shape": "", "code-info": {"name": "torch.nn.utils.prune.custom_from_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.remove", "type": "function", "code": "torch.nn.utils.prune.remove(module,name)", "example": "NA", "summary": "Removes the pruning reparameterization from a module and the pruning method from the forward hook", "returns": [], "shape": "", "code-info": {"name": "torch.nn.utils.prune.remove", "parameters": []}},
{"id": "torch.nn.utils.prune.is_pruned", "type": "function", "code": "torch.nn.utils.prune.is_pruned(module)", "example": "NA", "summary": "Check whether module is pruned by looking for forward_pre_hooks in its modules that inherit from the BasePruningMethod", "returns": "binary answer to whether module is pruned.", "shape": "", "code-info": {"name": "torch.nn.utils.prune.is_pruned", "parameters": []}},
{"id": "torch.nn.utils.weight_norm", "type": "function", "code": "torch.nn.utils.weight_norm(module,name='weight',dim=0)", "example": "  m = weight_norm(nn.Linear(20, 40), name='weight')  m Linear(in_features=20, out_features=40, bias=True)  m.weight_g.size() torch.Size([40, 1])  m.weight_v.size() torch.Size([40, 20])   ", "summary": "Applies weight normalization to a parameter in the given module", "returns": "The original module with the weight norm hook", "shape": "", "code-info": {"name": "torch.nn.utils.weight_norm", "parameters": []}},
{"id": "torch.nn.utils.remove_weight_norm", "type": "function", "code": "torch.nn.utils.remove_weight_norm(module,name='weight')", "example": "NA", "summary": "Removes the weight normalization reparameterization from a module", "returns": [], "shape": "", "code-info": {"name": "torch.nn.utils.remove_weight_norm", "parameters": []}},
{"id": "torch.nn.quantized.Conv2d", "type": "class", "code": "torch.nn.quantized.Conv2d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')", "example": " # With square kernels and equal stride\n m = nn.quantized.Conv2d(16, 33, 3, stride=2)\n # non-square kernels and unequal stride and with padding\n m = nn.quantized.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n # non-square kernels and unequal stride and with padding and dilation\n m = nn.quantized.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n input = torch.randn(20, 16, 50, 100)\n # quantize input to qint8\n q_input = torch.quantize_per_tensor(input, scale=1.0, zero_point=0, dtype=torch.qint32)\n output = m(input)\n\n", "summary": "Applies a 2D convolution over a quantized input signal composed of several quantized input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.Conv2d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}]}},
{"id": "torch.nn.quantized.Conv3d", "type": "class", "code": "torch.nn.quantized.Conv3d(in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')", "example": " # With square kernels and equal stride\n m = nn.quantized.Conv3d(16, 33, 3, stride=2)\n # non-square kernels and unequal stride and with padding\n m = nn.quantized.Conv3d(16, 33, (3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2))\n # non-square kernels and unequal stride and with padding and dilation\n m = nn.quantized.Conv3d(16, 33, (3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2), dilation=(1, 2, 2))\n input = torch.randn(20, 16, 56, 56, 56)\n # quantize input to qint8\n q_input = torch.quantize_per_tensor(input, scale=1.0, zero_point=0, dtype=torch.qint32)\n output = m(input)\n\n", "summary": "Applies a 3D convolution over a quantized input signal composed of several quantized input planes", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.Conv3d", "parameters": [{"name": "in_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "out_channels", "is_optional": false, "type": "others", "description": ""}, {"name": "kernel_size", "is_optional": false, "type": "others", "description": ""}, {"name": "stride", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "padding", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dilation", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "groups", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "bias", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": ""}]}},
{"id": "torch.nn.quantized.FloatFunctional", "type": "class", "code": "torch.nn.quantized.FloatFunctional", "example": " f_add = FloatFunctional()\n a = torch.tensor(3.0)\n b = torch.tensor(4.0)\n f_add.add(a, b)  # Equivalent to ``torch.add(3, 4)\n\n", "summary": "State collector class for float operatitons", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.FloatFunctional", "parameters": []}},
{"id": "torch.Tensor.cross", "type": "method", "code": "torch.Tensor.cross(other,dim=-1)", "example": "NA", "summary": "See torch.cross() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cross", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}]}},
{"id": "torch.Tensor.cuda", "type": "method", "code": "torch.Tensor.cuda(device=None,non_blocking=False)", "example": "NA", "summary": "Returns a copy of this object in CUDA memory", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cuda", "parameters": [{"name": "device", "is_optional": true, "type": "torch.device", "default_value": "None", "description": " The destination GPU device.Defaults to the current CUDA device."}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True and the source is in pinned memory,the copy will be asynchronous with respect to the host.Otherwise, the argument has no effect. Default"}]}},
{"id": "torch.Tensor.cumprod", "type": "method", "code": "torch.Tensor.cumprod(dim,dtype=None)", "example": "NA", "summary": "See torch.cumprod() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cumprod", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.cumsum", "type": "method", "code": "torch.Tensor.cumsum(dim,dtype=None)", "example": "NA", "summary": "See torch.cumsum() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.cumsum", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.data_ptr", "type": "method", "code": "torch.Tensor.data_ptr()", "example": "NA", "summary": "Returns the address of the first element of self tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.data_ptr", "parameters": []}},
{"id": "torch.Tensor.dequantize", "type": "method", "code": "torch.Tensor.dequantize()", "example": "NA", "summary": "Given a quantized Tensor, dequantize it and return the dequantized float Tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.dequantize", "parameters": []}},
{"id": "torch.Tensor.det", "type": "method", "code": "torch.Tensor.det()", "example": "NA", "summary": "See torch.det() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.det", "parameters": []}},
{"id": "torch.Tensor.dense_dim", "type": "method", "code": "torch.Tensor.dense_dim()", "example": "NA", "summary": "If self is a sparse COO tensor (i.e., with torch.sparse_coo layout), this returns the number of dense dimensions", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.dense_dim", "parameters": []}},
{"id": "NA", "type": "method", "code": "NA()", "example": "NA", "summary": "Returns a new Tensor, detached from the current graph", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": []}},
{"id": "NA", "type": "method", "code": "NA()", "example": "NA", "summary": "Detaches the Tensor from the graph that created it, making it a leaf", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": []}},
{"id": "torch.Tensor.diag", "type": "method", "code": "torch.Tensor.diag(diagonal=0)", "example": "NA", "summary": "See torch.diag() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.diag", "parameters": [{"name": "diagonal", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.nn.functional.softshrink", "type": "function", "code": "torch.nn.functional.softshrink(input,lambd=0.5)", "example": "NA", "summary": "Applies the soft shrinkage function elementwise See Softshrink for more details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.softshrink", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "lambd", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}]}},
{"id": "torch.nn.functional.gumbel_softmax", "type": "function", "code": "torch.nn.functional.gumbel_softmax(logits,tau=1,hard=False,eps=1e-10,dim=-1)", "example": " logits = torch.randn(20, 32)\n # Sample soft categorical using reparametrization trick:\n F.gumbel_softmax(logits, tau=1, hard=False)\n # Sample hard categorical using \"Straight-through\" trick:\n F.gumbel_softmax(logits, tau=1, hard=True)\n\n\n", "summary": "Samples from the Gumbel-Softmax distribution (Link 1  Link 2) and optionally discretizes", "returns": "Sampled tensor of same shape as logits from the Gumbel-Softmax distribution.If hard=True, the returned samples will be one-hot, otherwise they willbe probability distributions that sum to 1 across dim.", "shape": "NA", "code-info": {"name": "torch.nn.functional.gumbel_softmax", "parameters": [{"name": "logits", "is_optional": false, "type": "logits : [\u2026, num_features] unnormalized log probabilitie", "description": " [\u2026, num_features] unnormalized log probabilities"}, {"name": "tau", "is_optional": true, "type": "int", "default_value": "1", "description": " non-negative scalar temperature"}, {"name": "hard", "is_optional": true, "type": "bool", "default_value": "False", "description": " if True, the returned samples will be discretized as one-hot vectors,but will be differentiated as if it is the soft sample in autograd"}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-10", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": " A dimension along which softmax will be computed. Default"}]}},
{"id": "torch.nn.functional.log_softmax", "type": "function", "code": "torch.nn.functional.log_softmax(input,dim=None,_stacklevel=3,dtype=None)", "example": "NA", "summary": "Applies a softmax followed by a logarithm", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.log_softmax", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " input"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": " A dimension along which log_softmax will be computed."}, {"name": "_stacklevel", "is_optional": true, "type": "int", "default_value": "3", "description": ""}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.If specified, the input tensor is casted to dtype before the operationis performed. This is useful for preventing data type overflows. Default"}]}},
{"id": "torch.nn.functional.tanh", "type": "function", "code": "torch.nn.functional.tanh(input)", "example": "NA", "summary": "Applies element-wise, Tanh(x)=tanh\u2061(x)=exp\u2061(x)\u2212exp\u2061(\u2212x)exp\u2061(x)+exp\u2061(\u2212x)\\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}Tanh(x)=tanh(x)=exp(x)+exp(\u2212x)exp(x)\u2212exp(\u2212x)\u200b   See Tanh for more details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.tanh", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.sigmoid", "type": "function", "code": "torch.nn.functional.sigmoid(input)", "example": "NA", "summary": "Applies the element-wise function Sigmoid(x)=11+exp\u2061(\u2212x)\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}Sigmoid(x)=1+exp(\u2212x)1\u200b   See Sigmoid for more details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.sigmoid", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.batch_norm", "type": "function", "code": "torch.nn.functional.batch_norm(input,running_mean,running_var,weight=None,bias=None,training=False,momentum=0.1,eps=1e-05)", "example": "NA", "summary": "Applies Batch Normalization for each channel across a batch of data", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.batch_norm", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "running_mean", "is_optional": false, "type": "others", "description": ""}, {"name": "running_var", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}]}},
{"id": "torch.nn.functional.instance_norm", "type": "function", "code": "torch.nn.functional.instance_norm(input,running_mean=None,running_var=None,weight=None,bias=None,use_input_stats=True,momentum=0.1,eps=1e-05)", "example": "NA", "summary": "Applies Instance Normalization for each channel in each data sample in a batch", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.instance_norm", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "running_mean", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "running_var", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "use_input_stats", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "momentum", "is_optional": true, "type": "others", "default_value": "0.1", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}]}},
{"id": "torch.arange", "type": "function", "code": "torch.arange(start=0,end,step=1,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.arange(5) tensor([ 0,  1,  2,  3,  4])  torch.arange(1, 4) tensor([ 1,  2,  3])  torch.arange(1, 2.5, 0.5) tensor([ 1.0000,  1.5000,  2.0000])   ", "summary": "Returns a 1-D tensor of size \u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309   with values from the interval [start, end) taken with common difference step beginning from start", "returns": null, "shape": "NA", "code-info": {"name": "torch.arange", "parameters": [{"name": "start", "is_optional": true, "type": "int", "default_value": "0", "description": " the starting value for the set of points. Default"}, {"name": "end", "is_optional": false, "type": "Number", "description": " the ending value for the set of points"}, {"name": "step", "is_optional": true, "type": "int", "default_value": "1", "description": " the gap between each pair of adjacent points. Default"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.range", "type": "function", "code": "torch.range(start=0,end,step=1,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.range(1, 4) tensor([ 1.,  2.,  3.,  4.])  torch.range(1, 4, 0.5) tensor([ 1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000])   ", "summary": "Returns a 1-D tensor of size \u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1   with values from start to end with step step", "returns": null, "shape": "NA", "code-info": {"name": "torch.range", "parameters": [{"name": "start", "is_optional": true, "type": "int", "default_value": "0", "description": " the starting value for the set of points. Default"}, {"name": "end", "is_optional": false, "type": "float", "description": " the ending value for the set of points"}, {"name": "step", "is_optional": true, "type": "int", "default_value": "1", "description": " the gap between each pair of adjacent points. Default"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.distributions.gumbel.Gumbel.entropy", "type": "method", "code": "torch.distributions.gumbel.Gumbel.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gumbel.Gumbel.entropy", "parameters": []}},
{"id": "torch.distributions.gumbel.Gumbel.expand", "type": "method", "code": "torch.distributions.gumbel.Gumbel.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gumbel.Gumbel.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.gumbel.Gumbel.log_prob", "type": "method", "code": "torch.distributions.gumbel.Gumbel.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gumbel.Gumbel.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.gumbel.Gumbel.mean", "type": "method", "code": "torch.distributions.gumbel.Gumbel.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gumbel.Gumbel.mean", "parameters": []}},
{"id": "torch.distributions.gumbel.Gumbel.stddev", "type": "method", "code": "torch.distributions.gumbel.Gumbel.stddev", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gumbel.Gumbel.stddev", "parameters": []}},
{"id": "torch.distributions.gumbel.Gumbel.variance", "type": "method", "code": "torch.distributions.gumbel.Gumbel.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gumbel.Gumbel.variance", "parameters": []}},
{"id": "torch.distributions.half_cauchy.HalfCauchy.cdf", "type": "method", "code": "torch.distributions.half_cauchy.HalfCauchy.cdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.half_cauchy.HalfCauchy.entropy", "type": "method", "code": "torch.distributions.half_cauchy.HalfCauchy.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.entropy", "parameters": []}},
{"id": "torch.distributions.half_cauchy.HalfCauchy.expand", "type": "method", "code": "torch.distributions.half_cauchy.HalfCauchy.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.half_cauchy.HalfCauchy.icdf", "type": "method", "code": "torch.distributions.half_cauchy.HalfCauchy.icdf(prob)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.icdf", "parameters": [{"name": "prob", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.half_cauchy.HalfCauchy.log_prob", "type": "method", "code": "torch.distributions.half_cauchy.HalfCauchy.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.half_cauchy.HalfCauchy.mean", "type": "method", "code": "torch.distributions.half_cauchy.HalfCauchy.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.mean", "parameters": []}},
{"id": "torch.distributions.half_cauchy.HalfCauchy.scale", "type": "method", "code": "torch.distributions.half_cauchy.HalfCauchy.scale", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.scale", "parameters": []}},
{"id": "torch.distributions.half_cauchy.HalfCauchy.variance", "type": "method", "code": "torch.distributions.half_cauchy.HalfCauchy.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.variance", "parameters": []}},
{"id": "torch.nn.utils.spectral_norm", "type": "function", "code": "torch.nn.utils.spectral_norm(module,name='weight',n_power_iterations=1,eps=1e-12,dim=None)", "example": "  m = spectral_norm(nn.Linear(20, 40))  m Linear(in_features=20, out_features=40, bias=True)  m.weight_u.size() torch.Size([40])   ", "summary": "Applies spectral normalization to a parameter in the given module", "returns": "The original module with the spectral norm hook", "shape": "", "code-info": {"name": "torch.nn.utils.spectral_norm", "parameters": []}},
{"id": "torch.nn.utils.remove_spectral_norm", "type": "function", "code": "torch.nn.utils.remove_spectral_norm(module,name='weight')", "example": "NA", "summary": "Removes the spectral normalization reparameterization from a module", "returns": [], "shape": "", "code-info": {"name": "torch.nn.utils.remove_spectral_norm", "parameters": []}},
{"id": "torch.nn.utils.rnn.PackedSequence", "type": "class", "code": "torch.nn.utils.rnn.PackedSequence", "example": "NA", "summary": "Holds the data and list of batch_sizes of a packed sequence", "returns": [], "shape": "", "code-info": {"name": "torch.nn.utils.rnn.PackedSequence", "parameters": []}},
{"id": "torch.nn.utils.rnn.pack_padded_sequence", "type": "function", "code": "torch.nn.utils.rnn.pack_padded_sequence(input,lengths,batch_first=False,enforce_sorted=True)", "example": "NA", "summary": "Packs a Tensor containing padded sequences of variable length", "returns": "a PackedSequence object", "shape": "", "code-info": {"name": "torch.nn.utils.rnn.pack_padded_sequence", "parameters": []}},
{"id": "torch.nn.utils.rnn.pad_packed_sequence", "type": "function", "code": "torch.nn.utils.rnn.pad_packed_sequence(sequence,batch_first=False,padding_value=0.0,total_length=None)", "example": "NA", "summary": "Pads a packed batch of variable length sequences", "returns": "Tuple of Tensor containing the padded sequence, and a Tensorcontaining the list of lengths of each sequence in the batch.Batch elements will be re-ordered as they were ordered originally whenthe batch was passed to pack_padded_sequence or pack_sequence.", "shape": "", "code-info": {"name": "torch.nn.utils.rnn.pad_packed_sequence", "parameters": []}},
{"id": "torch.nn.utils.rnn.pad_sequence", "type": "function", "code": "torch.nn.utils.rnn.pad_sequence(sequences,batch_first=False,padding_value=0.0)", "example": "NA", "summary": "Pad a list of variable length Tensors with padding_value pad_sequence stacks a list of Tensors along a new dimension, and pads them to equal length", "returns": "Tensor of size T x B x * if batch_first is False.Tensor of size B x T x * otherwise", "shape": "", "code-info": {"name": "torch.nn.utils.rnn.pad_sequence", "parameters": []}},
{"id": "torch.nn.quantized.QFunctional", "type": "class", "code": "torch.nn.quantized.QFunctional", "example": " q_add = QFunctional('add')\n a = torch.quantize_per_tensor(torch.tensor(3.0), 1.0, 0, torch.qint32)\n b = torch.quantize_per_tensor(torch.tensor(4.0), 1.0, 0, torch.qint32)\n q_add.add(a, b)  # Equivalent to ``torch.ops.quantized.add(3, 4)\n\n", "summary": "Wrapper class for quantized operatitons", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.QFunctional", "parameters": []}},
{"id": "torch.nn.quantized.Quantize", "type": "class", "code": "torch.nn.quantized.Quantize(scale,zero_point,dtype)", "example": " t = torch.tensor([[1., -1.], [1., -1.]])\n scale, zero_point, dtype = 1.0, 2, torch.qint8\n qm = Quantize(scale, zero_point, dtype)\n qt = qm(t)\n print(qt)\ntensor([[ 1., -1.],\n        [ 1., -1.]], size=(2, 2), dtype=torch.qint8, scale=1.0, zero_point=2)\n\n\n", "summary": "Quantizes an incoming tensor  Parameters  scale \u2013 scale of the output Quantized Tensor zero_point \u2013 zero_point of output Quantized Tensor dtype \u2013 data type of output Quantized Tensor   Variables zero_point, dtype (`scale`,) \u2013     Examples::&gt;&gt;&gt; t = torch.tensor([[1., -1.], [1., -1.]]) &gt;&gt;&gt; scale, zero_point, dtype = 1.0, 2, torch.qint8 &gt;&gt;&gt; qm = Quantize(scale, zero_point, dtype) &gt;&gt;&gt; qt = qm(t) &gt;&gt;&gt; print(qt) tensor([[ 1., -1.],         [ 1., -1.]], size=(2, 2), dtype=torch.qint8, scale=1.0, zero_point=2)     ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.Quantize", "parameters": [{"name": "scale", "is_optional": false, "type": "scale : scale of the output Quantized Tenso", "description": " scale of the output Quantized Tensor"}, {"name": "zero_point", "is_optional": false, "type": "zero_point : zero_point of output Quantized Tenso", "description": " zero_point of output Quantized Tensor"}, {"name": "dtype", "is_optional": false, "type": "dtype : data type of output Quantized Tenso", "description": " data type of output Quantized Tensor"}]}},
{"id": "torch.nn.quantized.DeQuantize", "type": "class", "code": "torch.nn.quantized.DeQuantize", "example": " input = torch.tensor([[1., -1.], [1., -1.]])\n scale, zero_point, dtype = 1.0, 2, torch.qint8\n qm = Quantize(scale, zero_point, dtype)\n quantized_input = qm(input)\n dqm = DeQuantize()\n dequantized = dqm(quantized_input)\n print(dequantized)\ntensor([[ 1., -1.],\n        [ 1., -1.]], dtype=torch.float32)\n\n\n", "summary": "Dequantizes an incoming tensor  Examples::&gt;&gt;&gt; input = torch.tensor([[1., -1.], [1., -1.]]) &gt;&gt;&gt; scale, zero_point, dtype = 1.0, 2, torch.qint8 &gt;&gt;&gt; qm = Quantize(scale, zero_point, dtype) &gt;&gt;&gt; quantized_input = qm(input) &gt;&gt;&gt; dqm = DeQuantize() &gt;&gt;&gt; dequantized = dqm(quantized_input) &gt;&gt;&gt; print(dequantized) tensor([[ 1., -1.],         [ 1., -1.]], dtype=torch.float32)     ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.DeQuantize", "parameters": []}},
{"id": "torch.nn.quantized.Linear", "type": "class", "code": "torch.nn.quantized.Linear(in_features,out_features,bias_=True)", "example": " m = nn.quantized.Linear(20, 30)\n input = torch.randn(128, 20)\n input = torch.quantize_per_tensor(input, 1.0, 0, torch.quint8)\n output = m(input)\n print(output.size())\ntorch.Size([128, 30])\n\n", "summary": "A quantized linear module with quantized tensor as inputs and outputs", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.Linear", "parameters": [{"name": "in_features", "is_optional": false, "type": "Tensor", "description": ""}, {"name": "out_features", "is_optional": false, "type": "Tensor", "description": ""}, {"name": "bias_", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.nn.quantized.dynamic.Linear", "type": "class", "code": "torch.nn.quantized.dynamic.Linear(in_features,out_features,bias_=True)", "example": " m = nn.quantized.dynamic.Linear(20, 30)\n input = torch.randn(128, 20)\n output = m(input)\n print(output.size())\ntorch.Size([128, 30])\n\n", "summary": "A dynamic quantized linear module with quantized tensor as inputs and outputs", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.dynamic.Linear", "parameters": [{"name": "in_features", "is_optional": false, "type": "Tensor", "description": ""}, {"name": "out_features", "is_optional": false, "type": "Tensor", "description": ""}, {"name": "bias_", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.nn.quantized.dynamic.LSTM", "type": "class", "code": "torch.nn.quantized.dynamic.LSTM(*args,**kwargs)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.quantized.dynamic.LSTM", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.diag_embed", "type": "method", "code": "torch.Tensor.diag_embed(offset=0,dim1=-2,dim2=-1)", "example": "NA", "summary": "See torch.diag_embed() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.diag_embed", "parameters": [{"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dim1", "is_optional": true, "type": "others", "default_value": "-2", "description": ""}, {"name": "dim2", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}]}},
{"id": "torch.Tensor.diagflat", "type": "method", "code": "torch.Tensor.diagflat(offset=0)", "example": "NA", "summary": "See torch.diagflat() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.diagflat", "parameters": [{"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.Tensor.diagonal", "type": "method", "code": "torch.Tensor.diagonal(offset=0,dim1=0,dim2=1)", "example": "NA", "summary": "See torch.diagonal() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.diagonal", "parameters": [{"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dim1", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "dim2", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"id": "torch.Tensor.fill_diagonal_", "type": "method", "code": "torch.Tensor.fill_diagonal_(fill_value,wrap=False)", "example": "  a = torch.zeros(3, 3)  a.fill_diagonal_(5) tensor([[5., 0., 0.],         [0., 5., 0.],         [0., 0., 5.]])  b = torch.zeros(7, 3)  b.fill_diagonal_(5) tensor([[5., 0., 0.],         [0., 5., 0.],         [0., 0., 5.],         [0., 0., 0.],         [0., 0., 0.],         [0., 0., 0.],         [0., 0., 0.]])  c = torch.zeros(7, 3)  c.fill_diagonal_(5, wrap=True) tensor([[5., 0., 0.],         [0., 5., 0.],         [0., 0., 5.],         [0., 0., 0.],         [5., 0., 0.],         [0., 5., 0.],         [0., 0., 5.]])   ", "summary": "Fill the main diagonal of a tensor that has at least 2-dimensions", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.fill_diagonal_", "parameters": [{"name": "fill_value", "is_optional": false, "type": "Scalar", "description": " the fill value"}, {"name": "wrap", "is_optional": true, "type": "bool", "default_value": "False", "description": " the diagonal \u2018wrapped\u2019 after N columns for tall matrices."}]}},
{"id": "torch.Tensor.digamma", "type": "method", "code": "torch.Tensor.digamma()", "example": "NA", "summary": "See torch.digamma() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.digamma", "parameters": []}},
{"id": "torch.Tensor.digamma_", "type": "method", "code": "torch.Tensor.digamma_()", "example": "NA", "summary": "In-place version of digamma() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.digamma_", "parameters": []}},
{"id": "torch.Tensor.dim", "type": "method", "code": "torch.Tensor.dim()", "example": "NA", "summary": "Returns the number of dimensions of self tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.dim", "parameters": []}},
{"id": "torch.Tensor.dist", "type": "method", "code": "torch.Tensor.dist(other,p=2)", "example": "NA", "summary": "See torch.dist() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.dist", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": ""}]}},
{"id": "torch.Tensor.div", "type": "method", "code": "torch.Tensor.div(value)", "example": "NA", "summary": "See torch.div() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.div", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.div_", "type": "method", "code": "torch.Tensor.div_(value)", "example": "NA", "summary": "In-place version of div() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.div_", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.dot", "type": "method", "code": "torch.Tensor.dot(tensor2)", "example": "NA", "summary": "See torch.dot() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.dot", "parameters": [{"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.double", "type": "method", "code": "torch.Tensor.double()", "example": "NA", "summary": "self.double() is equivalent to self.to(torch.float64)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.double", "parameters": []}},
{"id": "torch.Tensor.eig", "type": "method", "code": "torch.Tensor.eig(eigenvectors=False)", "example": "NA", "summary": "See torch.eig() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.eig", "parameters": [{"name": "eigenvectors", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.layer_norm", "type": "function", "code": "torch.nn.functional.layer_norm(input,normalized_shape,weight=None,bias=None,eps=1e-05)", "example": "NA", "summary": "Applies Layer Normalization for last certain number of dimensions", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.layer_norm", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "normalized_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-05", "description": ""}]}},
{"id": "torch.nn.functional.local_response_norm", "type": "function", "code": "torch.nn.functional.local_response_norm(input,size,alpha=0.0001,beta=0.75,k=1.0)", "example": "NA", "summary": "Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.local_response_norm", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "alpha", "is_optional": true, "type": "others", "default_value": "0.0001", "description": ""}, {"name": "beta", "is_optional": true, "type": "others", "default_value": "0.75", "description": ""}, {"name": "k", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}]}},
{"id": "torch.nn.functional.normalize", "type": "function", "code": "torch.nn.functional.normalize(input,p=2,dim=1,eps=1e-12,out=None)", "example": "NA", "summary": "Performs LpL_pLp\u200b   normalization of inputs over specified dimension", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.normalize", "parameters": [{"name": "input", "is_optional": false, "type": "input : input tensor of any shap", "description": " input tensor of any shape"}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": " the exponent value in the norm formulation. Default"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "1", "description": " the dimension to reduce. Default"}, {"name": "eps", "is_optional": true, "type": "float", "default_value": "1e-12", "description": " small value to avoid division by zero. Default"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor. If out is used, thisoperation won\u2019t be differentiable."}]}},
{"id": "torch.nn.functional.linear", "type": "function", "code": "torch.nn.functional.linear(input,weight,bias=None)", "example": "NA", "summary": "Applies a linear transformation to the incoming data: y=xAT+by = xA^T + by=xAT+b  ", "returns": null, "shape": "  Input: (N,\u2217,in_features)(N, *, in\\_features)(N,\u2217,in_features)   where * means any number of additional dimensions Weight: (out_features,in_features)(out\\_features, in\\_features)(out_features,in_features)   Bias: (out_features)(out\\_features)(out_features)   Output: (N,\u2217,out_features)(N, *, out\\_features)(N,\u2217,out_features)    ", "code-info": {"name": "torch.nn.functional.linear", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.functional.bilinear", "type": "function", "code": "torch.nn.functional.bilinear(input1,input2,weight,bias=None)", "example": "NA", "summary": "Applies a bilinear transformation to the incoming data: y=x1Ax2+by = x_1 A x_2 + by=x1\u200bAx2\u200b+b   Shape:   input1: (N,\u2217,Hin1)(N, *, H_{in1})(N,\u2217,Hin1\u200b)   where Hin1=in1_featuresH_{in1}=\\text{in1\\_features}Hin1\u200b=in1_features   and \u2217*\u2217   means any number of additional dimensions", "returns": null, "shape": "  input1: (N,\u2217,Hin1)(N, *, H_{in1})(N,\u2217,Hin1\u200b)   where Hin1=in1_featuresH_{in1}=\\text{in1\\_features}Hin1\u200b=in1_features   and \u2217*\u2217   means any number of additional dimensions. All but the last dimension of the inputs should be the same. input2: (N,\u2217,Hin2)(N, *, H_{in2})(N,\u2217,Hin2\u200b)   where Hin2=in2_featuresH_{in2}=\\text{in2\\_features}Hin2\u200b=in2_features   weight: (out_features,in1_features,in2_features)(\\text{out\\_features}, \\text{in1\\_features}, \\text{in2\\_features})(out_features,in1_features,in2_features)   bias: (out_features)(\\text{out\\_features})(out_features)   output: (N,\u2217,Hout)(N, *, H_{out})(N,\u2217,Hout\u200b)   where Hout=out_featuresH_{out}=\\text{out\\_features}Hout\u200b=out_features   and all but the last dimension are the same shape as the input.  ", "code-info": {"name": "torch.nn.functional.bilinear", "parameters": [{"name": "input1", "is_optional": false, "type": "others", "description": ""}, {"name": "input2", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}, {"name": "bias", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.linspace", "type": "function", "code": "torch.linspace(start,end,steps=100,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.linspace(3, 10, steps=5) tensor([  3.0000,   4.7500,   6.5000,   8.2500,  10.0000])  torch.linspace(-10, 10, steps=5) tensor([-10.,  -5.,   0.,   5.,  10.])  torch.linspace(start=-10, end=10, steps=5) tensor([-10.,  -5.,   0.,   5.,  10.])  torch.linspace(start=-10, end=10, steps=1) tensor([-10.])   ", "summary": "Returns a one-dimensional tensor of steps equally spaced points between start and end", "returns": null, "shape": "NA", "code-info": {"name": "torch.linspace", "parameters": [{"name": "start", "is_optional": false, "type": "float", "description": " the starting value for the set of points"}, {"name": "end", "is_optional": false, "type": "float", "description": " the ending value for the set of points"}, {"name": "steps", "is_optional": true, "type": "int", "default_value": "100", "description": " number of points to sample between startand end. Default"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.logspace", "type": "function", "code": "torch.logspace(start,end,steps=100,base=10.0,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.logspace(start=-10, end=10, steps=5) tensor([ 1.0000e-10,  1.0000e-05,  1.0000e+00,  1.0000e+05,  1.0000e+10])  torch.logspace(start=0.1, end=1.0, steps=5) tensor([  1.2589,   2.1135,   3.5481,   5.9566,  10.0000])  torch.logspace(start=0.1, end=1.0, steps=1) tensor([1.2589])  torch.logspace(start=2, end=2, steps=1, base=2) tensor([4.0])   ", "summary": "Returns a one-dimensional tensor of steps points logarithmically spaced with base base between basestart{\\text{base}}^{\\text{start}}basestart   and baseend{\\text{base}}^{\\text{end}}baseend  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.logspace", "parameters": [{"name": "start", "is_optional": false, "type": "float", "description": " the starting value for the set of points"}, {"name": "end", "is_optional": false, "type": "float", "description": " the ending value for the set of points"}, {"name": "steps", "is_optional": true, "type": "int", "default_value": "100", "description": " number of points to sample between startand end. Default"}, {"name": "base", "is_optional": true, "type": "float", "default_value": "10.0", "description": " base of the logarithm function. Default"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.eye", "type": "function", "code": "torch.eye(n,m=None,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.eye(3) tensor([[ 1.,  0.,  0.],         [ 0.,  1.,  0.],         [ 0.,  0.,  1.]])   ", "summary": "Returns a 2-D tensor with ones on the diagonal and zeros elsewhere", "returns": "A 2-D tensor with ones on the diagonal and zeros elsewhere", "shape": "NA", "code-info": {"name": "torch.eye", "parameters": [{"name": "n", "is_optional": false, "type": "int", "description": " the number of rows"}, {"name": "m", "is_optional": true, "type": "int", "default_value": "None", "description": " the number of columns with default being n"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.empty", "type": "function", "code": "torch.empty(*size,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False,pin_memory=False)", "example": "  torch.empty(2, 3) tensor(1.00000e-08 *        [[ 6.3984,  0.0000,  0.0000],         [ 0.0000,  0.0000,  0.0000]])   ", "summary": "Returns a tensor filled with uninitialized data", "returns": null, "shape": "NA", "code-info": {"name": "torch.empty", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "int...", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}, {"name": "pin_memory", "is_optional": true, "type": "bool", "default_value": "False", "description": " If set, returned tensor would be allocated inthe pinned memory. Works only for CPU tensors. Default"}]}},
{"id": "torch.distributions.half_normal.HalfNormal.cdf", "type": "method", "code": "torch.distributions.half_normal.HalfNormal.cdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.half_normal.HalfNormal.entropy", "type": "method", "code": "torch.distributions.half_normal.HalfNormal.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.entropy", "parameters": []}},
{"id": "torch.distributions.half_normal.HalfNormal.expand", "type": "method", "code": "torch.distributions.half_normal.HalfNormal.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.half_normal.HalfNormal.icdf", "type": "method", "code": "torch.distributions.half_normal.HalfNormal.icdf(prob)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.icdf", "parameters": [{"name": "prob", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.half_normal.HalfNormal.log_prob", "type": "method", "code": "torch.distributions.half_normal.HalfNormal.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.half_normal.HalfNormal.mean", "type": "method", "code": "torch.distributions.half_normal.HalfNormal.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.mean", "parameters": []}},
{"id": "torch.distributions.half_normal.HalfNormal.scale", "type": "method", "code": "torch.distributions.half_normal.HalfNormal.scale", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.scale", "parameters": []}},
{"id": "torch.distributions.half_normal.HalfNormal.variance", "type": "method", "code": "torch.distributions.half_normal.HalfNormal.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.variance", "parameters": []}},
{"id": "torch.distributions.independent.Independent.entropy", "type": "method", "code": "torch.distributions.independent.Independent.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.entropy", "parameters": []}},
{"id": "torch.distributions.independent.Independent.enumerate_support", "type": "method", "code": "torch.distributions.independent.Independent.enumerate_support(expand=True)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.distributions.independent.Independent.expand", "type": "method", "code": "torch.distributions.independent.Independent.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.independent.Independent.has_enumerate_support", "type": "method", "code": "torch.distributions.independent.Independent.has_enumerate_support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.has_enumerate_support", "parameters": []}},
{"id": "torch.distributions.independent.Independent.has_rsample", "type": "method", "code": "torch.distributions.independent.Independent.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.has_rsample", "parameters": []}},
{"id": "torch.distributions.independent.Independent.log_prob", "type": "method", "code": "torch.distributions.independent.Independent.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.utils.rnn.pack_sequence", "type": "function", "code": "torch.nn.utils.rnn.pack_sequence(sequences,enforce_sorted=True)", "example": "NA", "summary": "Packs a list of variable length Tensors sequences should be a list of Tensors of size L x *, where L is the length of a sequence and * is any number of trailing dimensions, including zero", "returns": "a PackedSequence object", "shape": "", "code-info": {"name": "torch.nn.utils.rnn.pack_sequence", "parameters": []}},
{"id": "torch.nn.Module.add_module", "type": "method", "code": "torch.nn.Module.add_module(name:str,module:Optional[Module])", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Adds a child module to the current module", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.add_module", "parameters": [{"name": "name", "type": "str", "is_optional": false, "description": "name of the child module. The child module can beaccessed from this module using the given name"}, {"name": "module", "type": "Optional[Module]", "is_optional": false, "description": "child module to be added to the module."}]}},
{"id": "torch.nn.Module.apply", "type": "method", "code": "torch.nn.Module.apply(fn:Callable[Module,None])", "example": "  @torch.no_grad()  def init_weights(m):      print(m)      if type(m) == nn.Linear:          m.weight.fill_(1.0)          print(m.weight)  net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))  net.apply(init_weights) Linear(in_features=2, out_features=2, bias=True) Parameter containing: tensor([[ 1.,  1.],         [ 1.,  1.]]) Linear(in_features=2, out_features=2, bias=True) Parameter containing: tensor([[ 1.,  1.],         [ 1.,  1.]]) Sequential(   (0): Linear(in_features=2, out_features=2, bias=True)   (1): Linear(in_features=2, out_features=2, bias=True) ) Sequential(   (0): Linear(in_features=2, out_features=2, bias=True)   (1): Linear(in_features=2, out_features=2, bias=True) )   ", "summary": "Applies fn recursively to every submodule (as returned by .children()) as well as self", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.apply", "parameters": [{"name": "fn", "type": "Callable[Module,None]", "is_optional": false, "description": "function to be applied to each submodule"}]}},
{"id": "torch.Tensor.element_size", "type": "method", "code": "torch.Tensor.element_size()", "example": "  torch.tensor([]).element_size() 4  torch.tensor([], dtype=torch.uint8).element_size() 1   ", "summary": "Returns the size in bytes of an individual element", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.element_size", "parameters": []}},
{"id": "torch.Tensor.eq", "type": "method", "code": "torch.Tensor.eq(other)", "example": "NA", "summary": "See torch.eq() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.eq", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.eq_", "type": "method", "code": "torch.Tensor.eq_(other)", "example": "NA", "summary": "In-place version of eq() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.eq_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.equal", "type": "method", "code": "torch.Tensor.equal(other)", "example": "NA", "summary": "See torch.equal() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.equal", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.erf", "type": "method", "code": "torch.Tensor.erf()", "example": "NA", "summary": "See torch.erf() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.erf", "parameters": []}},
{"id": "torch.Tensor.erf_", "type": "method", "code": "torch.Tensor.erf_()", "example": "NA", "summary": "In-place version of erf() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.erf_", "parameters": []}},
{"id": "torch.Tensor.erfc", "type": "method", "code": "torch.Tensor.erfc()", "example": "NA", "summary": "See torch.erfc() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.erfc", "parameters": []}},
{"id": "torch.Tensor.erfc_", "type": "method", "code": "torch.Tensor.erfc_()", "example": "NA", "summary": "In-place version of erfc() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.erfc_", "parameters": []}},
{"id": "torch.Tensor.erfinv", "type": "method", "code": "torch.Tensor.erfinv()", "example": "NA", "summary": "See torch.erfinv() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.erfinv", "parameters": []}},
{"id": "torch.Tensor.erfinv_", "type": "method", "code": "torch.Tensor.erfinv_()", "example": "NA", "summary": "In-place version of erfinv() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.erfinv_", "parameters": []}},
{"id": "torch.Tensor.exp", "type": "method", "code": "torch.Tensor.exp()", "example": "NA", "summary": "See torch.exp() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.exp", "parameters": []}},
{"id": "torch.Tensor.exp_", "type": "method", "code": "torch.Tensor.exp_()", "example": "NA", "summary": "In-place version of exp() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.exp_", "parameters": []}},
{"id": "torch.Tensor.expm1", "type": "method", "code": "torch.Tensor.expm1()", "example": "NA", "summary": "See torch.expm1() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.expm1", "parameters": []}},
{"id": "torch.nn.functional.dropout", "type": "function", "code": "torch.nn.functional.dropout(input,p=0.5,training=True,inplace=False)", "example": "NA", "summary": "During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.dropout", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "p : probability of an element to be zeroed. Default: 0.", "default_value": "0.5", "description": " probability of an element to be zeroed. Default"}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "True", "description": " apply dropout if is True. Default"}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " If set to True, will do this operation in-place. Default"}]}},
{"id": "torch.nn.functional.alpha_dropout", "type": "function", "code": "torch.nn.functional.alpha_dropout(input,p=0.5,training=False,inplace=False)", "example": "NA", "summary": "Applies alpha dropout to the input", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.alpha_dropout", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.dropout2d", "type": "function", "code": "torch.nn.functional.dropout2d(input,p=0.5,training=True,inplace=False)", "example": "NA", "summary": "Randomly zero out entire channels (a channel is a 2D feature map, e.g., the jjj  -th channel of the iii  -th sample in the batched input is a 2D tensor input[i,j]\\text{input}[i, j]input[i,j]  ) of the input tensor)", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.dropout2d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "p : probability of a channel to be zeroed. Default: 0.", "default_value": "0.5", "description": " probability of a channel to be zeroed. Default"}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "True", "description": " apply dropout if is True. Default"}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " If set to True, will do this operation in-place. Default"}]}},
{"id": "torch.nn.functional.dropout3d", "type": "function", "code": "torch.nn.functional.dropout3d(input,p=0.5,training=True,inplace=False)", "example": "NA", "summary": "Randomly zero out entire channels (a channel is a 3D feature map, e.g., the jjj  -th channel of the iii  -th sample in the batched input is a 3D tensor input[i,j]\\text{input}[i, j]input[i,j]  ) of the input tensor)", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.dropout3d", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "p : probability of a channel to be zeroed. Default: 0.", "default_value": "0.5", "description": " probability of a channel to be zeroed. Default"}, {"name": "training", "is_optional": true, "type": "bool", "default_value": "True", "description": " apply dropout if is True. Default"}, {"name": "inplace", "is_optional": true, "type": "bool", "default_value": "False", "description": " If set to True, will do this operation in-place. Default"}]}},
{"id": "torch.nn.functional.embedding", "type": "function", "code": "torch.nn.functional.embedding(input,weight,padding_idx=None,max_norm=None,norm_type=2.0,scale_grad_by_freq=False,sparse=False)", "example": " # a batch of 2 samples of 4 indices each\n input = torch.tensor([[1,2,4,5],[4,3,2,9]])\n # an embedding matrix containing 10 tensors of size 3\n embedding_matrix = torch.rand(10, 3)\n F.embedding(input, embedding_matrix)\ntensor([[[ 0.8490,  0.9625,  0.6753],\n         [ 0.9666,  0.7761,  0.6108],\n         [ 0.6246,  0.9751,  0.3618],\n         [ 0.4161,  0.2419,  0.7383]],\n\n        [[ 0.6246,  0.9751,  0.3618],\n         [ 0.0237,  0.7794,  0.0528],\n         [ 0.9666,  0.7761,  0.6108],\n         [ 0.3385,  0.8612,  0.1867]]])\n\n # example with padding_idx\n weights = torch.rand(10, 3)\n weights[0, :].zero_()\n embedding_matrix = weights\n input = torch.tensor([[0,2,0,5]])\n F.embedding(input, embedding_matrix, padding_idx=0)\ntensor([[[ 0.0000,  0.0000,  0.0000],\n         [ 0.5609,  0.5384,  0.8720],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.6262,  0.2438,  0.7471]]])\n\n", "summary": "A simple lookup table that looks up embeddings in a fixed dictionary and size", "returns": null, "shape": " Input: LongTensor of arbitrary shape containing the indices to extract  Weight: Embedding matrix of floating point type with shape (V, embedding_dim),where V = maximum index + 1 and embedding_dim = the embedding size    Output: (*, embedding_dim), where * is the input shape  ", "code-info": {"name": "torch.nn.functional.embedding", "parameters": [{"name": "input", "is_optional": false, "type": "LongTensor", "description": " Tensor containing indices into the embedding matrix"}, {"name": "weight", "is_optional": false, "type": "Tensor", "description": " The embedding matrix with number of rows equal to the maximum possible index + 1,and number of columns equal to the embedding size"}, {"name": "padding_idx", "is_optional": true, "type": "int, optional", "default_value": "None", "description": " If given, pads the output with the embedding vector at padding_idx(initialized to zeros whenever it encounters the index."}, {"name": "max_norm", "is_optional": true, "type": "float, optional", "default_value": "None", "description": " If given, each embedding vector with norm larger than max_normis renormalized to have norm max_norm.Note"}, {"name": "norm_type", "is_optional": true, "type": "float, optional", "default_value": "2.0", "description": " The p of the p-norm to compute for the max_norm option. Default 2."}, {"name": "scale_grad_by_freq", "is_optional": true, "type": "bool", "default_value": "False", "description": " If given, this will scale gradients by the inverse of frequency ofthe words in the mini-batch. Default False."}, {"name": "sparse", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, gradient w.r.t. weight will be a sparse tensor. See Notes undertorch.nn.Embedding for more details regarding sparse gradients."}]}},
{"id": "torch.empty_like", "type": "function", "code": "torch.empty_like(input,dtype=None,layout=None,device=None,requires_grad=False)", "example": "  torch.empty((2,3), dtype=torch.int64) tensor([[ 9.4064e+13,  2.8000e+01,  9.3493e+13],         [ 7.5751e+18,  7.1428e+18,  7.5955e+18]])   ", "summary": "Returns an uninitialized tensor with the same size as input", "returns": null, "shape": "NA", "code-info": {"name": "torch.empty_like", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the size of input will determine size of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned Tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "None", "description": " the desired layout of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.empty_strided", "type": "function", "code": "torch.empty_strided(size,stride,dtype=None,layout=None,device=None,requires_grad=False,pin_memory=False)", "example": "  a = torch.empty_strided((2, 3), (1, 2))  a tensor([[8.9683e-44, 4.4842e-44, 5.1239e+07],         [0.0000e+00, 0.0000e+00, 3.0705e-41]])  a.stride() (1, 2)  a.size() torch.Size([2, 3])   ", "summary": "Returns a tensor filled with uninitialized data", "returns": null, "shape": "NA", "code-info": {"name": "torch.empty_strided", "parameters": [{"name": "size", "is_optional": false, "type": "tuple of ints", "description": " the shape of the output tensor"}, {"name": "stride", "is_optional": false, "type": "tuple of ints", "description": " the strides of the output tensor"}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "None", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}, {"name": "pin_memory", "is_optional": true, "type": "bool", "default_value": "False", "description": " If set, returned tensor would be allocated inthe pinned memory. Works only for CPU tensors. Default"}]}},
{"id": "torch.full", "type": "function", "code": "torch.full(size,fill_value,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.full((2, 3), 3.141592) tensor([[ 3.1416,  3.1416,  3.1416],         [ 3.1416,  3.1416,  3.1416]])   ", "summary": "Returns a tensor of size size filled with fill_value", "returns": null, "shape": "NA", "code-info": {"name": "torch.full", "parameters": [{"name": "size", "is_optional": false, "type": "int...", "description": " a list, tuple, or torch.Size of integers defining theshape of the output tensor."}, {"name": "fill_value", "is_optional": false, "type": "fill_value : the number to fill the output tensor with", "description": " the number to fill the output tensor with."}, {"name": "out", "is_optional": true, "type": "int...", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.full_like", "type": "function", "code": "torch.full_like(input,fill_value,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "NA", "summary": "Returns a tensor with the same size as input filled with fill_value", "returns": null, "shape": "NA", "code-info": {"name": "torch.full_like", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the size of input will determine size of the output tensor."}, {"name": "fill_value", "is_optional": false, "type": "fill_value : the number to fill the output tensor with", "description": " the number to fill the output tensor with."}, {"name": "out", "is_optional": true, "type": "Tensor", "default_value": "None", "description": ""}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned Tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.distributions.independent.Independent.mean", "type": "method", "code": "torch.distributions.independent.Independent.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.mean", "parameters": []}},
{"id": "torch.distributions.independent.Independent.rsample", "type": "method", "code": "torch.distributions.independent.Independent.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.independent.Independent.sample", "type": "method", "code": "torch.distributions.independent.Independent.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.independent.Independent.support", "type": "method", "code": "torch.distributions.independent.Independent.support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.support", "parameters": []}},
{"id": "torch.distributions.independent.Independent.variance", "type": "method", "code": "torch.distributions.independent.Independent.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.variance", "parameters": []}},
{"id": "torch.distributions.laplace.Laplace.cdf", "type": "method", "code": "torch.distributions.laplace.Laplace.cdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.laplace.Laplace.entropy", "type": "method", "code": "torch.distributions.laplace.Laplace.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.entropy", "parameters": []}},
{"id": "torch.distributions.laplace.Laplace.expand", "type": "method", "code": "torch.distributions.laplace.Laplace.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.laplace.Laplace.icdf", "type": "method", "code": "torch.distributions.laplace.Laplace.icdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.laplace.Laplace.log_prob", "type": "method", "code": "torch.distributions.laplace.Laplace.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.laplace.Laplace.mean", "type": "method", "code": "torch.distributions.laplace.Laplace.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.mean", "parameters": []}},
{"id": "torch.nn.Module.buffers", "type": "method", "code": "torch.nn.Module.buffers(recurse:bool=True)", "example": "  for buf in model.buffers():      print(type(buf), buf.size()) &lt;class 'torch.Tensor' (20L,) &lt;class 'torch.Tensor' (20L, 1L, 5L, 5L)   ", "summary": "Returns an iterator over module buffers", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.buffers", "parameters": [{"name": "recurse", "type": "bool", "default_value": "True", "is_optional": false, "description": "if True, then yields buffers of this moduleand all submodules. Otherwise, yields only buffers thatare direct members of this module."}]}},
{"id": "torch.nn.Module.children", "type": "method", "code": "torch.nn.Module.children()", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Returns an iterator over immediate children modules", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.children", "parameters": []}},
{"id": "torch.nn.Module.cpu", "type": "method", "code": "torch.nn.Module.cpu()", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Moves all model parameters and buffers to the CPU", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.cpu", "parameters": []}},
{"id": "torch.nn.Module.cuda", "type": "method", "code": "torch.nn.Module.cuda(device:Union[int,torch.device,None]=None)", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Moves all model parameters and buffers to the GPU", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.cuda", "parameters": [{"name": "device", "type": "Union[int,torch.device,None]", "default_value": "None", "is_optional": true, "description": "if specified, all parameters will becopied to that device"}]}},
{"id": "torch.nn.Module.double", "type": "method", "code": "torch.nn.Module.double()", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Casts all floating point parameters and buffers to double datatype", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.double", "parameters": []}},
{"id": "torch.nn.Module.eval", "type": "method", "code": "torch.nn.Module.eval()", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Sets the module in evaluation mode", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.eval", "parameters": []}},
{"id": "torch.nn.Module.extra_repr", "type": "method", "code": "torch.nn.Module.extra_repr()", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Set the extra representation of the module To print customized extra information, you should re-implement this method in your own modules", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.extra_repr", "parameters": []}},
{"id": "torch.nn.Module.float", "type": "method", "code": "torch.nn.Module.float()", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Casts all floating point parameters and buffers to float datatype", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.float", "parameters": []}},
{"id": "torch.nn.Module.forward", "type": "method", "code": "torch.nn.Module.forward(*input)", "example": "NA", "summary": "Defines the computation performed at every call", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.Module.forward", "parameters": [{"name": "*input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.expm1_", "type": "method", "code": "torch.Tensor.expm1_()", "example": "NA", "summary": "In-place version of expm1() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.expm1_", "parameters": []}},
{"id": "torch.Tensor.expand", "type": "method", "code": "torch.Tensor.expand(*sizes)", "example": "  x = torch.tensor([[1], [2], [3]])  x.size() torch.Size([3, 1])  x.expand(3, 4) tensor([[ 1,  1,  1,  1],         [ 2,  2,  2,  2],         [ 3,  3,  3,  3]])  x.expand(-1, 4)   # -1 means not changing the size of that dimension tensor([[ 1,  1,  1,  1],         [ 2,  2,  2,  2],         [ 3,  3,  3,  3]])   ", "summary": "Returns a new view of the self tensor with singleton dimensions expanded to a larger size", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.expand", "parameters": [{"name": "*sizes", "is_optional": false, "type": "torch.Size or int...", "description": " the desired expanded size"}]}},
{"id": "torch.Tensor.expand_as", "type": "method", "code": "torch.Tensor.expand_as(other)", "example": "NA", "summary": "Expand this tensor to the same size as other", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.expand_as", "parameters": [{"name": "other", "is_optional": false, "type": "torch.Tensor", "description": " The result tensor has the same sizeas other."}]}},
{"id": "torch.Tensor.exponential_", "type": "method", "code": "torch.Tensor.exponential_(lambd=1,*,generator=None)", "example": "NA", "summary": "Fills self tensor with elements drawn from the exponential distribution:  f(x)=\u03bbe\u2212\u03bbxf(x) = \\lambda e^{-\\lambda x}f(x)=\u03bbe\u2212\u03bbx  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.exponential_", "parameters": [{"name": "lambd", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.fft", "type": "method", "code": "torch.Tensor.fft(signal_ndim,normalized=False)", "example": "NA", "summary": "See torch.fft() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.fft", "parameters": [{"name": "signal_ndim", "is_optional": false, "type": "others", "description": ""}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.fill_", "type": "method", "code": "torch.Tensor.fill_(value)", "example": "NA", "summary": "Fills self tensor with the specified value", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.fill_", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.flatten", "type": "method", "code": "torch.Tensor.flatten(input,start_dim=0,end_dim=-1)", "example": "NA", "summary": "see torch.flatten() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.flatten", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "start_dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "end_dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}]}},
{"id": "torch.Tensor.flip", "type": "method", "code": "torch.Tensor.flip(dims)", "example": "NA", "summary": "See torch.flip() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.flip", "parameters": [{"name": "dims", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.float", "type": "method", "code": "torch.Tensor.float()", "example": "NA", "summary": "self.float() is equivalent to self.to(torch.float32)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.float", "parameters": []}},
{"id": "torch.nn.functional.embedding_bag", "type": "function", "code": "torch.nn.functional.embedding_bag(input,weight,offsets=None,max_norm=None,norm_type=2,scale_grad_by_freq=False,mode='mean',sparse=False,per_sample_weights=None)", "example": " # an Embedding module containing 10 tensors of size 3\n embedding_matrix = torch.rand(10, 3)\n # a batch of 2 samples of 4 indices each\n input = torch.tensor([1,2,4,5,4,3,2,9])\n offsets = torch.tensor([0,4])\n F.embedding_bag(embedding_matrix, input, offsets)\ntensor([[ 0.3397,  0.3552,  0.5545],\n        [ 0.5893,  0.4386,  0.5882]])\n\n", "summary": "Computes sums, means or maxes of bags of embeddings, without instantiating the intermediate embeddings", "returns": null, "shape": "  input (LongTensor) and offsets (LongTensor, optional)  If input is 2D of shape (B, N), it will be treated as B bags (sequences) each of fixed length N, and this will return B values aggregated in a way depending on the mode. offsets is ignored and required to be None in this case.  If input is 1D of shape (N), it will be treated as a concatenation of multiple bags (sequences). offsets is required to be a 1D tensor containing the starting index positions of each bag in input. Therefore, for offsets of shape (B), input will be viewed as having B bags. Empty bags (i.e., having 0-length) will have returned vectors filled by zeros.    weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim) per_sample_weights (Tensor, optional). Has the same shape as input. output: aggregated embedding values of shape (B, embedding_dim)  ", "code-info": {"name": "torch.nn.functional.embedding_bag", "parameters": [{"name": "input", "is_optional": false, "type": "LongTensor", "description": " Tensor containing bags of indices into the embedding matrix"}, {"name": "weight", "is_optional": false, "type": "Tensor", "description": " The embedding matrix with number of rows equal to the maximum possible index + 1,and number of columns equal to the embedding size"}, {"name": "offsets", "is_optional": true, "type": "LongTensor, optional", "default_value": "None", "description": " Only used when input is 1D. offsets determinesthe starting index position of each bag (sequence in input."}, {"name": "max_norm", "is_optional": true, "type": "float, optional", "default_value": "None", "description": " If given, each embedding vector with norm larger than max_normis renormalized to have norm max_norm.Note"}, {"name": "norm_type", "is_optional": true, "type": "int", "default_value": "2", "description": " The p in the p-norm to compute for the max_norm option.Default 2."}, {"name": "scale_grad_by_freq", "is_optional": true, "type": "bool", "default_value": "False", "description": " if given, this will scale gradients by the inverse of frequency ofthe words in the mini-batch. Default False.Note"}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'mean'", "description": " \"sum\", \"mean\" or \"max\". Specifies the way to reduce the bag.Default"}, {"name": "sparse", "is_optional": true, "type": "bool", "default_value": "False", "description": " if True, gradient w.r.t. weight will be a sparse tensor. See Notes undertorch.nn.Embedding for more details regarding sparse gradients.Note"}, {"name": "per_sample_weights", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " a tensor of float / double weights, or Noneto indicate all weights should be taken to be 1. If specified, per_sample_weightsmust have exactly the same shape as input and is treated as having the sameoffsets, if those are not None."}]}},
{"id": "torch.nn.functional.one_hot", "type": "function", "code": "torch.nn.functional.one_hot(tensor,num_classes=-1)", "example": " F.one_hot(torch.arange(0, 5) % 3)\ntensor([[1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1],\n        [1, 0, 0],\n        [0, 1, 0]])\n F.one_hot(torch.arange(0, 5) % 3, num_classes=5)\ntensor([[1, 0, 0, 0, 0],\n        [0, 1, 0, 0, 0],\n        [0, 0, 1, 0, 0],\n        [1, 0, 0, 0, 0],\n        [0, 1, 0, 0, 0]])\n F.one_hot(torch.arange(0, 6).view(3,2) % 3)\ntensor([[[1, 0, 0],\n         [0, 1, 0]],\n        [[0, 0, 1],\n         [1, 0, 0]],\n        [[0, 1, 0],\n         [0, 0, 1]]])\n\n", "summary": "Takes LongTensor with index values of shape (*) and returns a tensor of shape (*, num_classes) that have zeros everywhere except where the index of last dimension matches the corresponding value of the input tensor, in which case it will be 1", "returns": "LongTensor that has one more dimension with 1 values at theindex of last dimension indicated by the input, and 0 everywhereelse.", "shape": "NA", "code-info": {"name": "torch.nn.functional.one_hot", "parameters": [{"name": "tensor", "is_optional": false, "type": "LongTensor", "description": " class values of any shape."}, {"name": "num_classes", "is_optional": true, "type": "int", "default_value": "-1", "description": " Total number of classes. If set to -1, the numberof classes will be inferred as one greater than the largest classvalue in the input tensor."}]}},
{"id": "torch.quantize_per_tensor", "type": "function", "code": "torch.quantize_per_tensor(input,scale,zero_point,dtype)", "example": "  torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8) tensor([-1.,  0.,  1.,  2.], size=(4,), dtype=torch.quint8,        quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10)  torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8).int_repr() tensor([ 0, 10, 20, 30], dtype=torch.uint8)   ", "summary": "Converts a float tensor to quantized tensor with given scale and zero point", "returns": "A newly quantized tensor", "shape": "NA", "code-info": {"name": "torch.quantize_per_tensor", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " float tensor to quantize"}, {"name": "scale", "is_optional": false, "type": "float", "description": " scale to apply in quantization formula"}, {"name": "zero_point", "is_optional": false, "type": "int", "description": " offset in integer value that maps to float zero"}, {"name": "dtype", "is_optional": false, "type": "torch.dtype", "description": " the desired data type of returned tensor.Has to be one of the quantized dtypes"}]}},
{"id": "torch.quantize_per_channel", "type": "function", "code": "torch.quantize_per_channel(input,scales,zero_points,axis,dtype)", "example": "  x = torch.tensor([[-1.0, 0.0], [1.0, 2.0]])  torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8) tensor([[-1.,  0.],         [ 1.,  2.]], size=(2, 2), dtype=torch.quint8,        quantization_scheme=torch.per_channel_affine,        scale=tensor([0.1000, 0.0100], dtype=torch.float64),        zero_point=tensor([10,  0]), axis=0)  torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8).int_repr() tensor([[  0,  10],         [100, 200]], dtype=torch.uint8)   ", "summary": "Converts a float tensor to per-channel quantized tensor with given scales and zero points", "returns": "A newly quantized tensor", "shape": "NA", "code-info": {"name": "torch.quantize_per_channel", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " float tensor to quantize"}, {"name": "scales", "is_optional": false, "type": "Tensor", "description": " float 1D tensor of scales to use, size should match input.size(axis"}, {"name": "zero_points", "is_optional": false, "type": "int", "description": " integer 1D tensor of offset to use, size should match input.size(axis"}, {"name": "axis", "is_optional": false, "type": "Tensor", "description": " dimension on which apply per-channel quantization"}, {"name": "dtype", "is_optional": false, "type": "torch.dtype", "description": " the desired data type of returned tensor.Has to be one of the quantized dtypes"}]}},
{"id": "torch.cat", "type": "function", "code": "torch.cat(tensors,dim=0,out=None)", "example": "  x = torch.randn(2, 3)  x tensor([[ 0.6580, -1.0969, -0.4614],         [-0.1034, -0.5790,  0.1497]])  torch.cat((x, x, x), 0) tensor([[ 0.6580, -1.0969, -0.4614],         [-0.1034, -0.5790,  0.1497],         [ 0.6580, -1.0969, -0.4614],         [-0.1034, -0.5790,  0.1497],         [ 0.6580, -1.0969, -0.4614],         [-0.1034, -0.5790,  0.1497]])  torch.cat((x, x, x), 1) tensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,          -1.0969, -0.4614],         [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,          -0.5790,  0.1497]])   ", "summary": "Concatenates the given sequence of seq tensors in the given dimension", "returns": null, "shape": "NA", "code-info": {"name": "torch.cat", "parameters": [{"name": "tensors", "is_optional": false, "type": "sequence of Tensors", "description": " any python sequence of tensors of the same type.Non-empty tensors provided must have the same shape, except in thecat dimension."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": " the dimension over which the tensors are concatenated"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.distributions.laplace.Laplace.rsample", "type": "method", "code": "torch.distributions.laplace.Laplace.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.laplace.Laplace.stddev", "type": "method", "code": "torch.distributions.laplace.Laplace.stddev", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.stddev", "parameters": []}},
{"id": "torch.distributions.laplace.Laplace.variance", "type": "method", "code": "torch.distributions.laplace.Laplace.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.variance", "parameters": []}},
{"id": "torch.distributions.log_normal.LogNormal.entropy", "type": "method", "code": "torch.distributions.log_normal.LogNormal.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.log_normal.LogNormal.entropy", "parameters": []}},
{"id": "torch.distributions.log_normal.LogNormal.expand", "type": "method", "code": "torch.distributions.log_normal.LogNormal.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.log_normal.LogNormal.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.log_normal.LogNormal.loc", "type": "method", "code": "torch.distributions.log_normal.LogNormal.loc", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.log_normal.LogNormal.loc", "parameters": []}},
{"id": "torch.distributions.log_normal.LogNormal.mean", "type": "method", "code": "torch.distributions.log_normal.LogNormal.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.log_normal.LogNormal.mean", "parameters": []}},
{"id": "torch.distributions.log_normal.LogNormal.scale", "type": "method", "code": "torch.distributions.log_normal.LogNormal.scale", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.log_normal.LogNormal.scale", "parameters": []}},
{"id": "torch.distributions.log_normal.LogNormal.variance", "type": "method", "code": "torch.distributions.log_normal.LogNormal.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.log_normal.LogNormal.variance", "parameters": []}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.entropy", "type": "method", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.entropy", "parameters": []}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.expand", "type": "method", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.log_prob", "type": "method", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.Module.half", "type": "method", "code": "torch.nn.Module.half()", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Casts all floating point parameters and buffers to half datatype", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.half", "parameters": []}},
{"id": "torch.nn.Module.load_state_dict", "type": "method", "code": "torch.nn.Module.load_state_dict(state_dict:Dict[str,torch.Tensor],strict:bool=True)", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Copies parameters and buffers from state_dict into this module and its descendants", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.load_state_dict", "parameters": [{"name": "state_dict", "type": "Dict[str,torch.Tensor]", "is_optional": false, "description": "a dict containing parameters andpersistent buffers."}, {"name": "strict", "type": "bool", "default_value": "True", "is_optional": true, "description": "whether to strictly enforce that the keysin state_dict match the keys returned by this module\u2019sstate_dict() function. Default: True"}]}},
{"id": "torch.nn.Module.modules", "type": "method", "code": "torch.nn.Module.modules()", "example": "  l = nn.Linear(2, 2)  net = nn.Sequential(l, l)  for idx, m in enumerate(net.modules()):         print(idx, '-', m)  0 - Sequential(   (0): Linear(in_features=2, out_features=2, bias=True)   (1): Linear(in_features=2, out_features=2, bias=True) ) 1 - Linear(in_features=2, out_features=2, bias=True)   ", "summary": "Returns an iterator over all modules in the network", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.modules", "parameters": []}},
{"id": "torch.nn.Module.named_buffers", "type": "method", "code": "torch.nn.Module.named_buffers(prefix:str='',recurse:bool=True)", "example": "  for name, buf in self.named_buffers():     if name in ['running_var']:         print(buf.size())   ", "summary": "Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.named_buffers", "parameters": [{"name": "prefix", "type": "str", "default_value": "''", "is_optional": false, "description": "prefix to prepend to all buffer names."}, {"name": "recurse", "type": "bool", "default_value": "True", "is_optional": false, "description": "if True, then yields buffers of this moduleand all submodules. Otherwise, yields only buffers thatare direct members of this module."}]}},
{"id": "torch.nn.Module.named_children", "type": "method", "code": "torch.nn.Module.named_children()", "example": "  for name, module in model.named_children():      if name in ['conv4', 'conv5']:          print(module)   ", "summary": "Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.named_children", "parameters": []}},
{"id": "torch.nn.Module.named_modules", "type": "method", "code": "torch.nn.Module.named_modules(memo:Optional[Set[Module]]=None,prefix:str='')", "example": "  l = nn.Linear(2, 2)  net = nn.Sequential(l, l)  for idx, m in enumerate(net.named_modules()):         print(idx, '-', m)  0 - ('', Sequential(   (0): Linear(in_features=2, out_features=2, bias=True)   (1): Linear(in_features=2, out_features=2, bias=True) )) 1 - ('0', Linear(in_features=2, out_features=2, bias=True))   ", "summary": "Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.named_modules", "parameters": [{"name": "memo", "type": "Optional[Set[Module]]", "default_value": "None", "is_optional": false, "description": ""}, {"name": "prefix", "type": "str", "default_value": "''", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.Module.named_parameters", "type": "method", "code": "torch.nn.Module.named_parameters(prefix:str='',recurse:bool=True)", "example": "  for name, param in self.named_parameters():     if name in ['bias']:         print(param.size())   ", "summary": "Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.named_parameters", "parameters": [{"name": "prefix", "type": "str", "default_value": "''", "is_optional": false, "description": "prefix to prepend to all parameter names."}, {"name": "recurse", "type": "bool", "default_value": "True", "is_optional": false, "description": "if True, then yields parameters of this moduleand all submodules. Otherwise, yields only parameters thatare direct members of this module."}]}},
{"id": "torch.nn.Module.parameters", "type": "method", "code": "torch.nn.Module.parameters(recurse:bool=True)", "example": "  for param in model.parameters():      print(type(param), param.size()) &lt;class 'torch.Tensor' (20L,) &lt;class 'torch.Tensor' (20L, 1L, 5L, 5L)   ", "summary": "Returns an iterator over module parameters", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.parameters", "parameters": [{"name": "recurse", "type": "bool", "default_value": "True", "is_optional": false, "description": "if True, then yields parameters of this moduleand all submodules. Otherwise, yields only parameters thatare direct members of this module."}]}},
{"id": "torch.Tensor.floor", "type": "method", "code": "torch.Tensor.floor()", "example": "NA", "summary": "See torch.floor() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.floor", "parameters": []}},
{"id": "torch.Tensor.floor_", "type": "method", "code": "torch.Tensor.floor_()", "example": "NA", "summary": "In-place version of floor() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.floor_", "parameters": []}},
{"id": "torch.Tensor.fmod", "type": "method", "code": "torch.Tensor.fmod(divisor)", "example": "NA", "summary": "See torch.fmod() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.fmod", "parameters": [{"name": "divisor", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.fmod_", "type": "method", "code": "torch.Tensor.fmod_(divisor)", "example": "NA", "summary": "In-place version of fmod() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.fmod_", "parameters": [{"name": "divisor", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.frac", "type": "method", "code": "torch.Tensor.frac()", "example": "NA", "summary": "See torch.frac() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.frac", "parameters": []}},
{"id": "torch.Tensor.frac_", "type": "method", "code": "torch.Tensor.frac_()", "example": "NA", "summary": "In-place version of frac() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.frac_", "parameters": []}},
{"id": "torch.Tensor.gather", "type": "method", "code": "torch.Tensor.gather(dim,index)", "example": "NA", "summary": "See torch.gather() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.gather", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.ge", "type": "method", "code": "torch.Tensor.ge(other)", "example": "NA", "summary": "See torch.ge() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.ge", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.ge_", "type": "method", "code": "torch.Tensor.ge_(other)", "example": "NA", "summary": "In-place version of ge() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.ge_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.geometric_", "type": "method", "code": "torch.Tensor.geometric_(p,*,generator=None)", "example": "NA", "summary": "Fills self tensor with elements drawn from the geometric distribution:  f(X=k)=pk\u22121(1\u2212p)f(X=k) = p^{k - 1} (1 - p)f(X=k)=pk\u22121(1\u2212p)  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.geometric_", "parameters": [{"name": "p", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.geqrf", "type": "method", "code": "torch.Tensor.geqrf()", "example": "NA", "summary": "See torch.geqrf() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.geqrf", "parameters": []}},
{"id": "torch.Tensor.ger", "type": "method", "code": "torch.Tensor.ger(vec2)", "example": "NA", "summary": "See torch.ger() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.ger", "parameters": [{"name": "vec2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.get_device", "type": "method", "code": "torch.Tensor.get_device()", "example": "  x = torch.randn(3, 4, 5, device='cuda:0')  x.get_device() 0  x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor   ", "summary": "For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.get_device", "parameters": []}},
{"id": "torch.nn.functional.pairwise_distance", "type": "function", "code": "torch.nn.functional.pairwise_distance(x1,x2,p=2.0,eps=1e-06,keepdim=False)", "example": "NA", "summary": "See torch.nn.PairwiseDistance for details ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.pairwise_distance", "parameters": [{"name": "x1", "is_optional": false, "type": "others", "description": ""}, {"name": "x2", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "others", "default_value": "2.0", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-06", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.nn.functional.cosine_similarity", "type": "function", "code": "torch.nn.functional.cosine_similarity(x1,x2,dim=1,eps=1e-8)", "example": "  input1 = torch.randn(100, 128)  input2 = torch.randn(100, 128)  output = F.cosine_similarity(input1, input2)  print(output)   ", "summary": "Returns cosine similarity between x1 and x2, computed along dim", "returns": null, "shape": " Input: (\u22171,D,\u22172)(\\ast_1, D, \\ast_2)(\u22171\u200b,D,\u22172\u200b)   where D is at position dim. Output: (\u22171,\u22172)(\\ast_1, \\ast_2)(\u22171\u200b,\u22172\u200b)   where 1 is at position dim.  ", "code-info": {"name": "torch.nn.functional.cosine_similarity", "parameters": [{"name": "x1", "is_optional": false, "type": "Tensor", "description": " First input."}, {"name": "x2", "is_optional": false, "type": "Tensor", "description": " Second input (of size matching x1."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "1", "description": " Dimension of vectors. Default"}, {"name": "eps", "is_optional": true, "type": "float, optional", "default_value": "1e-8", "description": " Small value to avoid division by zero.Default"}]}},
{"id": "torch.nn.functional.pdist", "type": "function", "code": "torch.nn.functional.pdist(input,p=2)", "example": "NA", "summary": "Computes the p-norm distance between every pair of row vectors in the input", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.pdist", "parameters": [{"name": "input", "is_optional": false, "type": "input : input tensor of shape N\u00d7MN \\times MN\u00d7M", "description": " input tensor of shape N\u00d7MN \\times MN\u00d7M."}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": " p value for the p-norm distance to calculate between each vector pair\u2208[0,\u221e]\\in [0, \\infty]\u2208[0,\u221e]."}]}},
{"id": "torch.nn.functional.binary_cross_entropy", "type": "function", "code": "torch.nn.functional.binary_cross_entropy(input,target,weight=None,size_average=None,reduce=None,reduction='mean')", "example": " input = torch.randn((3, 2), requires_grad=True)\n target = torch.rand((3, 2), requires_grad=False)\n loss = F.binary_cross_entropy(F.sigmoid(input), target)\n loss.backward()\n\n", "summary": "Function that measures the Binary Cross Entropy between the target and the output", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.binary_cross_entropy", "parameters": [{"name": "input", "is_optional": false, "type": "input : Tensor of arbitrary shap", "description": " Tensor of arbitrary shape"}, {"name": "target", "is_optional": false, "type": "target : Tensor of the same shape as inpu", "description": " Tensor of the same shape as input"}, {"name": "weight", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " a manual rescaling weightif provided it\u2019s repeated to match input tensor shape"}, {"name": "size_average", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default,the losses are averaged over each loss element in the batch. Note that forsome losses, there multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignoredwhen reduce is False. Default"}, {"name": "reduce", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default, thelosses are averaged or summed over observations for each minibatch dependingon size_average. When reduce is False, returns a loss perbatch element instead and ignores size_average. Default"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": " Specifies the reduction to apply to the output"}]}},
{"id": "torch.nn.functional.binary_cross_entropy_with_logits", "type": "function", "code": "torch.nn.functional.binary_cross_entropy_with_logits(input,target,weight=None,size_average=None,reduce=None,reduction='mean',pos_weight=None)", "example": " input = torch.randn(3, requires_grad=True)\n target = torch.empty(3).random_(2)\n loss = F.binary_cross_entropy_with_logits(input, target)\n loss.backward()\n\n", "summary": "Function that measures Binary Cross Entropy between target and output logits", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.binary_cross_entropy_with_logits", "parameters": [{"name": "input", "is_optional": false, "type": "input : Tensor of arbitrary shap", "description": " Tensor of arbitrary shape"}, {"name": "target", "is_optional": false, "type": "target : Tensor of the same shape as inpu", "description": " Tensor of the same shape as input"}, {"name": "weight", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " a manual rescaling weightif provided it\u2019s repeated to match input tensor shape"}, {"name": "size_average", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default,the losses are averaged over each loss element in the batch. Note that forsome losses, there multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignoredwhen reduce is False. Default"}, {"name": "reduce", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default, thelosses are averaged or summed over observations for each minibatch dependingon size_average. When reduce is False, returns a loss perbatch element instead and ignores size_average. Default"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": " Specifies the reduction to apply to the output"}, {"name": "pos_weight", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " a weight of positive examples.Must be a vector with length equal to the number of classes."}]}},
{"id": "torch.chunk", "type": "function", "code": "torch.chunk(input,chunks,dim=0)", "example": "NA", "summary": "Splits a tensor into a specific number of chunks", "returns": null, "shape": "NA", "code-info": {"name": "torch.chunk", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to split"}, {"name": "chunks", "is_optional": false, "type": "int", "description": " number of chunks to return"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": " dimension along which to split the tensor"}]}},
{"id": "torch.gather", "type": "function", "code": "torch.gather(input,dim,index,out=None,sparse_grad=False)", "example": "  t = torch.tensor([[1,2],[3,4]])  torch.gather(t, 1, torch.tensor([[0,0],[1,0]])) tensor([[ 1,  1],         [ 4,  3]])   ", "summary": "Gathers values along an axis specified by dim", "returns": null, "shape": "NA", "code-info": {"name": "torch.gather", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the source tensor"}, {"name": "dim", "is_optional": false, "type": "int", "description": " the axis along which to index"}, {"name": "index", "is_optional": false, "type": "int", "description": " the indices of elements to gather"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the destination tensor"}, {"name": "sparse_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, gradient w.r.t. input will be a sparse tensor."}]}},
{"id": "torch.index_select", "type": "function", "code": "torch.index_select(input,dim,index,out=None)", "example": "  x = torch.randn(3, 4)  x tensor([[ 0.1427,  0.0231, -0.5414, -1.0009],         [-0.4664,  0.2647, -0.1228, -1.1068],         [-1.1734, -0.6571,  0.7230, -0.6004]])  indices = torch.tensor([0, 2])  torch.index_select(x, 0, indices) tensor([[ 0.1427,  0.0231, -0.5414, -1.0009],         [-1.1734, -0.6571,  0.7230, -0.6004]])  torch.index_select(x, 1, indices) tensor([[ 0.1427, -0.5414],         [-0.4664, -0.1228],         [-1.1734,  0.7230]])   ", "summary": "Returns a new tensor which indexes the input tensor along dimension dim using the entries in index which is a LongTensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.index_select", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "dim", "is_optional": false, "type": "int", "description": " the dimension in which we index"}, {"name": "index", "is_optional": false, "type": "int", "description": " the 1-D tensor containing the indices to index"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.masked_select", "type": "function", "code": "torch.masked_select(input,mask,out=None)", "example": "  x = torch.randn(3, 4)  x tensor([[ 0.3552, -2.3825, -0.8297,  0.3477],         [-1.2035,  1.2252,  0.5002,  0.6248],         [ 0.1307, -2.0608,  0.1244,  2.0139]])  mask = x.ge(0.5)  mask tensor([[False, False, False, False],         [False, True, True, True],         [False, False, False, True]])  torch.masked_select(x, mask) tensor([ 1.2252,  0.5002,  0.6248,  2.0139])   ", "summary": "Returns a new 1-D tensor which indexes the input tensor according to the boolean mask mask which is a BoolTensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.masked_select", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "mask", "is_optional": false, "type": "ByteTensor", "description": " the tensor containing the binary mask to index with"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mean", "type": "method", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mean", "parameters": []}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.rsample", "type": "method", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.multinomial.Multinomial.expand", "type": "method", "code": "torch.distributions.multinomial.Multinomial.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multinomial.Multinomial.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.multinomial.Multinomial.log_prob", "type": "method", "code": "torch.distributions.multinomial.Multinomial.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multinomial.Multinomial.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.multinomial.Multinomial.logits", "type": "method", "code": "torch.distributions.multinomial.Multinomial.logits", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multinomial.Multinomial.logits", "parameters": []}},
{"id": "torch.distributions.multinomial.Multinomial.mean", "type": "method", "code": "torch.distributions.multinomial.Multinomial.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multinomial.Multinomial.mean", "parameters": []}},
{"id": "torch.distributions.multinomial.Multinomial.param_shape", "type": "method", "code": "torch.distributions.multinomial.Multinomial.param_shape", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multinomial.Multinomial.param_shape", "parameters": []}},
{"id": "torch.distributions.multinomial.Multinomial.probs", "type": "method", "code": "torch.distributions.multinomial.Multinomial.probs", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multinomial.Multinomial.probs", "parameters": []}},
{"id": "torch.distributions.multinomial.Multinomial.sample", "type": "method", "code": "torch.distributions.multinomial.Multinomial.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multinomial.Multinomial.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.multinomial.Multinomial.support", "type": "method", "code": "torch.distributions.multinomial.Multinomial.support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multinomial.Multinomial.support", "parameters": []}},
{"id": "torch.distributions.multinomial.Multinomial.variance", "type": "method", "code": "torch.distributions.multinomial.Multinomial.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multinomial.Multinomial.variance", "parameters": []}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.entropy", "type": "method", "code": "torch.distributions.multivariate_normal.MultivariateNormal.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.entropy", "parameters": []}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.expand", "type": "method", "code": "torch.distributions.multivariate_normal.MultivariateNormal.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.log_prob", "type": "method", "code": "torch.distributions.multivariate_normal.MultivariateNormal.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.Module.register_backward_hook", "type": "method", "code": "torch.nn.Module.register_backward_hook(hook:Callable[[Module,Union[Tuple[torch.Tensor,...],torch.Tensor],Union[Tuple[torch.Tensor,...],torch.Tensor]],Union[None,torch.Tensor]])", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Registers a backward hook on the module", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.register_backward_hook", "parameters": [{"name": "hook", "type": "Callable[[Module,Union[Tuple[torch.Tensor,...],torch.Tensor],Union[Tuple[torch.Tensor,...],torch.Tensor]],Union[None,torch.Tensor]]", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.Module.register_buffer", "type": "method", "code": "torch.nn.Module.register_buffer(name:str,tensor:Optional[torch.Tensor],persistent:bool=True)", "example": "  self.register_buffer('running_mean', torch.zeros(num_features))   ", "summary": "Adds a buffer to the module", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.register_buffer", "parameters": [{"name": "name", "type": "str", "is_optional": false, "description": "name of the buffer. The buffer can be accessedfrom this module using the given name"}, {"name": "tensor", "type": "Optional[torch.Tensor]", "is_optional": false, "description": "buffer to be registered."}, {"name": "persistent", "type": "bool", "default_value": "True", "is_optional": false, "description": "whether the buffer is part of this module\u2019sstate_dict."}]}},
{"id": "torch.nn.Module.register_forward_hook", "type": "method", "code": "torch.nn.Module.register_forward_hook(hook:Callable[...,None])", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Registers a forward hook on the module", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.register_forward_hook", "parameters": [{"name": "hook", "type": "Callable[...,None]", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.Module.register_forward_pre_hook", "type": "method", "code": "torch.nn.Module.register_forward_pre_hook(hook:Callable[...,None])", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Registers a forward pre-hook on the module", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.register_forward_pre_hook", "parameters": [{"name": "hook", "type": "Callable[...,None]", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.Module.register_parameter", "type": "method", "code": "torch.nn.Module.register_parameter(name:str,param:Optional[torch.nn.parameter.Parameter])", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Adds a parameter to the module", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.register_parameter", "parameters": [{"name": "name", "type": "str", "is_optional": false, "description": "name of the parameter. The parameter can be accessedfrom this module using the given name"}, {"name": "param", "type": "Optional[torch.nn.parameter.Parameter]", "is_optional": false, "description": "parameter to be added to the module."}]}},
{"id": "torch.nn.Module.requires_grad_", "type": "method", "code": "torch.nn.Module.requires_grad_(requires_grad:bool=True)", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Change if autograd should record operations on parameters in this module", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.requires_grad_", "parameters": [{"name": "requires_grad", "type": "bool", "default_value": "True", "is_optional": false, "description": "whether autograd should record operations onparameters in this module. Default: True."}]}},
{"id": "torch.nn.Module.state_dict", "type": "method", "code": "torch.nn.Module.state_dict(destination=None,prefix='',keep_vars=False)", "example": "  module.state_dict().keys() ['bias', 'weight']   ", "summary": "Returns a dictionary containing a whole state of the module", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.state_dict", "parameters": []}},
{"id": "torch.nn.Module.to", "type": "method", "code": "torch.nn.Module.to(*args,**kwargs)", "example": "  linear = nn.Linear(2, 2)  linear.weight Parameter containing: tensor([[ 0.1913, -0.3420],         [-0.5113, -0.2325]])  linear.to(torch.double) Linear(in_features=2, out_features=2, bias=True)  linear.weight Parameter containing: tensor([[ 0.1913, -0.3420],         [-0.5113, -0.2325]], dtype=torch.float64)  gpu1 = torch.device(\"cuda:1\")  linear.to(gpu1, dtype=torch.half, non_blocking=True) Linear(in_features=2, out_features=2, bias=True)  linear.weight Parameter containing: tensor([[ 0.1914, -0.3420],         [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')  cpu = torch.device(\"cpu\")  linear.to(cpu) Linear(in_features=2, out_features=2, bias=True)  linear.weight Parameter containing: tensor([[ 0.1914, -0.3420],         [-0.5112, -0.2324]], dtype=torch.float16)   ", "summary": "Moves and/or casts the parameters and buffers", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.to", "parameters": []}},
{"id": "torch.Tensor.gt", "type": "method", "code": "torch.Tensor.gt(other)", "example": "NA", "summary": "See torch.gt() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.gt", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.gt_", "type": "method", "code": "torch.Tensor.gt_(other)", "example": "NA", "summary": "In-place version of gt() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.gt_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.half", "type": "method", "code": "torch.Tensor.half()", "example": "NA", "summary": "self.half() is equivalent to self.to(torch.float16)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.half", "parameters": []}},
{"id": "torch.Tensor.hardshrink", "type": "method", "code": "torch.Tensor.hardshrink(lambd=0.5)", "example": "NA", "summary": "See torch.nn.functional.hardshrink() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.hardshrink", "parameters": [{"name": "lambd", "is_optional": true, "type": "others", "default_value": "0.5", "description": ""}]}},
{"id": "torch.Tensor.histc", "type": "method", "code": "torch.Tensor.histc(bins=100,min=0,max=0)", "example": "NA", "summary": "See torch.histc() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.histc", "parameters": [{"name": "bins", "is_optional": true, "type": "int", "default_value": "100", "description": ""}, {"name": "min", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "max", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.Tensor.ifft", "type": "method", "code": "torch.Tensor.ifft(signal_ndim,normalized=False)", "example": "NA", "summary": "See torch.ifft() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.ifft", "parameters": [{"name": "signal_ndim", "is_optional": false, "type": "others", "description": ""}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.imag", "type": "method", "code": "torch.Tensor.imag()", "example": "NA", "summary": "See torch.imag() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.imag", "parameters": []}},
{"id": "torch.Tensor.index_add_", "type": "method", "code": "torch.Tensor.index_add_(dim,index,tensor)", "example": "  x = torch.ones(5, 3)  t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)  index = torch.tensor([0, 4, 2])  x.index_add_(0, index, t) tensor([[  2.,   3.,   4.],         [  1.,   1.,   1.],         [  8.,   9.,  10.],         [  1.,   1.,   1.],         [  5.,   6.,   7.]])   ", "summary": "Accumulate the elements of tensor into the self tensor by adding to the indices in the order given in index", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.index_add_", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": " dimension along which to index"}, {"name": "index", "is_optional": false, "type": "int", "description": " indices of tensor to select from"}, {"name": "tensor", "is_optional": false, "type": "LongTensor", "description": " the tensor containing values to add"}]}},
{"id": "torch.Tensor.index_add", "type": "method", "code": "torch.Tensor.index_add(dim,index,tensor)", "example": "NA", "summary": "Out-of-place version of torch.Tensor.index_add_() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.index_add", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.poisson_nll_loss", "type": "function", "code": "torch.nn.functional.poisson_nll_loss(input,target,log_input=True,full=False,size_average=None,eps=1e-08,reduce=None,reduction='mean')", "example": "NA", "summary": "Poisson negative log likelihood loss", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.poisson_nll_loss", "parameters": [{"name": "input", "is_optional": false, "type": "input : expectation of underlying Poisson distribution", "description": " expectation of underlying Poisson distribution."}, {"name": "target", "is_optional": false, "type": "input", "description": " random sample target\u223cPoisson(inputtarget \\sim \\text{Poisson}(inputtarget\u223cPoisson(input."}, {"name": "log_input", "is_optional": true, "type": "bool", "default_value": "True", "description": " if True the loss is computed asexp\u2061(input\u2212target\u2217input\\exp(\\text{input} - \\text{target} * \\text{input}exp(input\u2212target\u2217input, if False then loss isinput\u2212target\u2217log\u2061(input+eps\\text{input} - \\text{target} * \\log(\\text{input}+\\text{eps}input\u2212target\u2217log(input+eps. Default"}, {"name": "full", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether to compute full loss, i. e. to add the Stirlingapproximation term. Default"}, {"name": "size_average", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default,the losses are averaged over each loss element in the batch. Note that forsome losses, there multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignoredwhen reduce is False. Default"}, {"name": "eps", "is_optional": true, "type": "input", "default_value": "1e-08", "description": " Small value to avoid evaluation of log\u2061(0\\log(0log(0 whenlog_input`=``False`. Default"}, {"name": "reduce", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default, thelosses are averaged or summed over observations for each minibatch dependingon size_average. When reduce is False, returns a loss perbatch element instead and ignores size_average. Default"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": " Specifies the reduction to apply to the output"}]}},
{"id": "torch.nn.functional.cosine_embedding_loss", "type": "function", "code": "torch.nn.functional.cosine_embedding_loss(input1,input2,target,margin=0,size_average=None,reduce=None,reduction='mean')", "example": "NA", "summary": "See CosineEmbeddingLoss for details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.cosine_embedding_loss", "parameters": [{"name": "input1", "is_optional": false, "type": "others", "description": ""}, {"name": "input2", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "margin", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"id": "torch.nn.functional.cross_entropy", "type": "function", "code": "torch.nn.functional.cross_entropy(input,target,weight=None,size_average=None,ignore_index=-100,reduce=None,reduction='mean')", "example": " input = torch.randn(3, 5, requires_grad=True)\n target = torch.randint(5, (3,), dtype=torch.int64)\n loss = F.cross_entropy(input, target)\n loss.backward()\n\n", "summary": "This criterion combines log_softmax and nll_loss in a single function", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.cross_entropy", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " (N,C(N, C(N,C where C = number of classes or (N,C,H,W(N, C, H, W(N,C,H,Win case of 2D Loss, or (N,C,d1,d2,...,dK(N, C, d_1, d_2, ..., d_K(N,C,d1\u200b,d2\u200b,...,dK\u200b where K\u22651K \\geq 1K\u22651in the case of K-dimensional loss."}, {"name": "target", "is_optional": false, "type": "Tensor", "description": " (N(N(N where each value is 0\u2264targets[i]\u2264C\u221210 \\leq \\text{targets}[i] \\leq C-10\u2264targets[i]\u2264C\u22121,or (N,d1,d2,...,dK(N, d_1, d_2, ..., d_K(N,d1\u200b,d2\u200b,...,dK\u200b where K\u22651K \\geq 1K\u22651 forK-dimensional loss."}, {"name": "weight", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " a manual rescaling weight given to eachclass. If given, has to be a Tensor of size C"}, {"name": "size_average", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default,the losses are averaged over each loss element in the batch. Note that forsome losses, there multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignoredwhen reduce is False. Default"}, {"name": "ignore_index", "is_optional": true, "type": "int, optional", "default_value": "-100", "description": " Specifies a target value that is ignoredand does not contribute to the input gradient. When size_average isTrue, the loss is averaged over non-ignored targets. Default"}, {"name": "reduce", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default, thelosses are averaged or summed over observations for each minibatch dependingon size_average. When reduce is False, returns a loss perbatch element instead and ignores size_average. Default"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": " Specifies the reduction to apply to the output"}]}},
{"id": "torch.narrow", "type": "function", "code": "torch.narrow(input,dim,start,length)", "example": "  x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  torch.narrow(x, 0, 0, 2) tensor([[ 1,  2,  3],         [ 4,  5,  6]])  torch.narrow(x, 1, 1, 2) tensor([[ 2,  3],         [ 5,  6],         [ 8,  9]])   ", "summary": "Returns a new tensor that is a narrowed version of input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.narrow", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to narrow"}, {"name": "dim", "is_optional": false, "type": "int", "description": " the dimension along which to narrow"}, {"name": "start", "is_optional": false, "type": "int", "description": " the starting dimension"}, {"name": "length", "is_optional": false, "type": "int", "description": " the distance to the ending dimension"}]}},
{"id": "torch.nonzero", "type": "function", "code": "torch.nonzero(input,*,out=None,as_tuple=False)", "example": "  torch.nonzero(torch.tensor([1, 1, 1, 0, 1])) tensor([[ 0],         [ 1],         [ 2],         [ 4]])  torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],                                 [0.0, 0.4, 0.0, 0.0],                                 [0.0, 0.0, 1.2, 0.0],                                 [0.0, 0.0, 0.0,-0.4]])) tensor([[ 0,  0],         [ 1,  1],         [ 2,  2],         [ 3,  3]])  torch.nonzero(torch.tensor([1, 1, 1, 0, 1]), as_tuple=True) (tensor([0, 1, 2, 4]),)  torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],                                 [0.0, 0.4, 0.0, 0.0],                                 [0.0, 0.0, 1.2, 0.0],                                 [0.0, 0.0, 0.0,-0.4]]), as_tuple=True) (tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3]))  torch.nonzero(torch.tensor(5), as_tuple=True) (tensor([0]),)   ", "summary": " Note torch.nonzero(..., as_tuple=False) (default) returns a 2-D tensor where each row is the index for a nonzero value", "returns": "If as_tuple is False, the outputtensor containing indices. If as_tuple is True, one 1-D tensor foreach dimension, containing the indices of each nonzero element along thatdimension.", "shape": "NA", "code-info": {"name": "torch.nonzero", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "LongTensor, optional", "default_value": "None", "description": " the output tensor containing indices"}, {"name": "as_tuple", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.reshape", "type": "function", "code": "torch.reshape(input,shape)", "example": "  a = torch.arange(4.)  torch.reshape(a, (2, 2)) tensor([[ 0.,  1.],         [ 2.,  3.]])  b = torch.tensor([[0, 1], [2, 3]])  torch.reshape(b, (-1,)) tensor([ 0,  1,  2,  3])   ", "summary": "Returns a tensor with the same data and number of elements as input, but with the specified shape", "returns": null, "shape": "NA", "code-info": {"name": "torch.reshape", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to be reshaped"}, {"name": "shape", "is_optional": false, "type": "Tensor", "description": " the new shape"}]}},
{"id": "torch.split", "type": "function", "code": "torch.split(tensor,split_size_or_sections,dim=0)", "example": "NA", "summary": "Splits the tensor into chunks", "returns": null, "shape": "NA", "code-info": {"name": "torch.split", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " tensor to split."}, {"name": "split_size_or_sections", "is_optional": false, "type": "int", "description": " size of a single chunk orlist of sizes for each chunk"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": " dimension along which to split the tensor."}]}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.mean", "type": "method", "code": "torch.distributions.multivariate_normal.MultivariateNormal.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.mean", "parameters": []}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.rsample", "type": "method", "code": "torch.distributions.multivariate_normal.MultivariateNormal.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.variance", "type": "method", "code": "torch.distributions.multivariate_normal.MultivariateNormal.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.variance", "parameters": []}},
{"id": "torch.distributions.negative_binomial.NegativeBinomial.expand", "type": "method", "code": "torch.distributions.negative_binomial.NegativeBinomial.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.negative_binomial.NegativeBinomial.log_prob", "type": "method", "code": "torch.distributions.negative_binomial.NegativeBinomial.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.negative_binomial.NegativeBinomial.mean", "type": "method", "code": "torch.distributions.negative_binomial.NegativeBinomial.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.mean", "parameters": []}},
{"id": "torch.distributions.negative_binomial.NegativeBinomial.param_shape", "type": "method", "code": "torch.distributions.negative_binomial.NegativeBinomial.param_shape", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.param_shape", "parameters": []}},
{"id": "torch.distributions.negative_binomial.NegativeBinomial.sample", "type": "method", "code": "torch.distributions.negative_binomial.NegativeBinomial.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.negative_binomial.NegativeBinomial.variance", "type": "method", "code": "torch.distributions.negative_binomial.NegativeBinomial.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.variance", "parameters": []}},
{"id": "torch.distributions.normal.Normal.cdf", "type": "method", "code": "torch.distributions.normal.Normal.cdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.Module.train", "type": "method", "code": "torch.nn.Module.train(mode:bool=True)", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Sets the module in training mode", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.train", "parameters": [{"name": "mode", "type": "bool", "default_value": "True", "is_optional": false, "description": "whether to set training mode (True) or evaluationmode (False). Default: True."}]}},
{"id": "torch.nn.Module.type", "type": "method", "code": "torch.nn.Module.type(dst_type:Union[torch.dtype,str])", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Casts all parameters and buffers to dst_type", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.type", "parameters": [{"name": "dst_type", "type": "Union[torch.dtype,str]", "is_optional": false, "description": "the desired type"}]}},
{"id": "torch.nn.Module.zero_grad", "type": "method", "code": "torch.nn.Module.zero_grad()", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "Sets gradients of all model parameters to zero", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.zero_grad", "parameters": []}},
{"id": "torch.nn.ModuleList.append", "type": "method", "code": "torch.nn.ModuleList.append(module:torch.nn.modules.module.Module)", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n\n    def forward(self, x):\n        # ModuleList can act as an iterable, or be indexed using ints\n        for i, l in enumerate(self.linears):\n            x = self.linears[i // 2](x) + l(x)\n        return x\n\n", "summary": "Appends a given module to the end of the list", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ModuleList.append", "parameters": [{"name": "module", "type": "torch.nn.modules.module.Module", "is_optional": false, "description": "module to append"}]}},
{"id": "torch.nn.ModuleList.extend", "type": "method", "code": "torch.nn.ModuleList.extend(modules:Iterable[torch.nn.modules.module.Module])", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n\n    def forward(self, x):\n        # ModuleList can act as an iterable, or be indexed using ints\n        for i, l in enumerate(self.linears):\n            x = self.linears[i // 2](x) + l(x)\n        return x\n\n", "summary": "Appends modules from a Python iterable to the end of the list", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ModuleList.extend", "parameters": [{"name": "modules", "type": "Iterable[torch.nn.modules.module.Module]", "is_optional": false, "description": "iterable of modules to append"}]}},
{"id": "torch.nn.ModuleList.insert", "type": "method", "code": "torch.nn.ModuleList.insert(index:int,module:torch.nn.modules.module.Module)", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n\n    def forward(self, x):\n        # ModuleList can act as an iterable, or be indexed using ints\n        for i, l in enumerate(self.linears):\n            x = self.linears[i // 2](x) + l(x)\n        return x\n\n", "summary": "Insert a given module before a given index in the list", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ModuleList.insert", "parameters": [{"name": "index", "type": "int", "is_optional": false, "description": "index to insert."}, {"name": "module", "type": "torch.nn.modules.module.Module", "is_optional": false, "description": "module to insert"}]}},
{"id": "torch.nn.ModuleDict.clear", "type": "method", "code": "torch.nn.ModuleDict.clear()", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.choices = nn.ModuleDict({\n                'conv': nn.Conv2d(10, 10, 3),\n                'pool': nn.MaxPool2d(3)\n        })\n        self.activations = nn.ModuleDict([\n                ['lrelu', nn.LeakyReLU()],\n                ['prelu', nn.PReLU()]\n        ])\n\n    def forward(self, x, choice, act):\n        x = self.choices[choice](x)\n        x = self.activations[act](x)\n        return x\n\n", "summary": "Remove all items from the ModuleDict", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ModuleDict.clear", "parameters": []}},
{"id": "torch.nn.ModuleDict.items", "type": "method", "code": "torch.nn.ModuleDict.items()", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.choices = nn.ModuleDict({\n                'conv': nn.Conv2d(10, 10, 3),\n                'pool': nn.MaxPool2d(3)\n        })\n        self.activations = nn.ModuleDict([\n                ['lrelu', nn.LeakyReLU()],\n                ['prelu', nn.PReLU()]\n        ])\n\n    def forward(self, x, choice, act):\n        x = self.choices[choice](x)\n        x = self.activations[act](x)\n        return x\n\n", "summary": "Return an iterable of the ModuleDict key/value pairs", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ModuleDict.items", "parameters": []}},
{"id": "torch.nn.ModuleDict.keys", "type": "method", "code": "torch.nn.ModuleDict.keys()", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.choices = nn.ModuleDict({\n                'conv': nn.Conv2d(10, 10, 3),\n                'pool': nn.MaxPool2d(3)\n        })\n        self.activations = nn.ModuleDict([\n                ['lrelu', nn.LeakyReLU()],\n                ['prelu', nn.PReLU()]\n        ])\n\n    def forward(self, x, choice, act):\n        x = self.choices[choice](x)\n        x = self.activations[act](x)\n        return x\n\n", "summary": "Return an iterable of the ModuleDict keys", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ModuleDict.keys", "parameters": []}},
{"id": "torch.nn.ModuleDict.pop", "type": "method", "code": "torch.nn.ModuleDict.pop(key:str)", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.choices = nn.ModuleDict({\n                'conv': nn.Conv2d(10, 10, 3),\n                'pool': nn.MaxPool2d(3)\n        })\n        self.activations = nn.ModuleDict([\n                ['lrelu', nn.LeakyReLU()],\n                ['prelu', nn.PReLU()]\n        ])\n\n    def forward(self, x, choice, act):\n        x = self.choices[choice](x)\n        x = self.activations[act](x)\n        return x\n\n", "summary": "Remove key from the ModuleDict and return its module", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ModuleDict.pop", "parameters": [{"name": "key", "type": "str", "is_optional": false, "description": "key to pop from the ModuleDict"}]}},
{"id": "torch.Tensor.index_copy_", "type": "method", "code": "torch.Tensor.index_copy_(dim,index,tensor)", "example": "  x = torch.zeros(5, 3)  t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)  index = torch.tensor([0, 4, 2])  x.index_copy_(0, index, t) tensor([[ 1.,  2.,  3.],         [ 0.,  0.,  0.],         [ 7.,  8.,  9.],         [ 0.,  0.,  0.],         [ 4.,  5.,  6.]])   ", "summary": "Copies the elements of tensor into the self tensor by selecting the indices in the order given in index", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.index_copy_", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": " dimension along which to index"}, {"name": "index", "is_optional": false, "type": "int", "description": " indices of tensor to select from"}, {"name": "tensor", "is_optional": false, "type": "LongTensor", "description": " the tensor containing values to copy"}]}},
{"id": "torch.Tensor.index_copy", "type": "method", "code": "torch.Tensor.index_copy(dim,index,tensor)", "example": "NA", "summary": "Out-of-place version of torch.Tensor.index_copy_() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.index_copy", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.index_fill_", "type": "method", "code": "torch.Tensor.index_fill_(dim,index,val)", "example": ": x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)  index = torch.tensor([0, 2])  x.index_fill_(1, index, -1) tensor([[-1.,  2., -1.],         [-1.,  5., -1.],         [-1.,  8., -1.]])     ", "summary": "Fills the elements of the self tensor with value val by selecting the indices in the order given in index", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.index_fill_", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": " dimension along which to index"}, {"name": "index", "is_optional": false, "type": "int", "description": " indices of self tensor to fill in"}, {"name": "val", "is_optional": false, "type": "float", "description": " the value to fill with"}]}},
{"id": "torch.Tensor.index_fill", "type": "method", "code": "torch.Tensor.index_fill(dim,index,value)", "example": "NA", "summary": "Out-of-place version of torch.Tensor.index_fill_() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.index_fill", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.index_put_", "type": "method", "code": "torch.Tensor.index_put_(indices,value,accumulate=False)", "example": "NA", "summary": "Puts values from the tensor value into the tensor self using the indices specified in indices (which is a tuple of Tensors)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.index_put_", "parameters": [{"name": "indices", "is_optional": false, "type": "tuple of LongTensor", "description": " tensors used to index into self."}, {"name": "value", "is_optional": false, "type": "Tensor", "description": " tensor of same dtype as self."}, {"name": "accumulate", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether to accumulate into self"}]}},
{"id": "torch.nn.functional.ctc_loss", "type": "function", "code": "torch.nn.functional.ctc_loss(log_probs,targets,input_lengths,target_lengths,blank=0,reduction='mean',zero_infinity=False)", "example": "  log_probs = torch.randn(50, 16, 20).log_softmax(2).detach().requires_grad_()  targets = torch.randint(1, 20, (16, 30), dtype=torch.long)  input_lengths = torch.full((16,), 50, dtype=torch.long)  target_lengths = torch.randint(10,30,(16,), dtype=torch.long)  loss = F.ctc_loss(log_probs, targets, input_lengths, target_lengths)  loss.backward()   ", "summary": "The Connectionist Temporal Classification loss", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.ctc_loss", "parameters": [{"name": "log_probs", "is_optional": false, "type": "T,N,C", "description": " (T,N,C(T, N, C(T,N,C where C = number of characters in alphabet including blank,T = input length, and N = batch size.The logarithmized probabilities of the outputs(e.g. obtained with torch.nn.functional.log_softmax(."}, {"name": "targets", "is_optional": false, "type": "N,S", "description": " (N,S(N, S(N,S or (sum(target_lengths.Targets cannot be blank. In the second form, the targets are assumed to be concatenated."}, {"name": "input_lengths", "is_optional": false, "type": "N", "description": " (N(N(N.Lengths of the inputs (must each be \u2264T\\leq T\u2264T"}, {"name": "target_lengths", "is_optional": false, "type": "N,S", "description": " (N(N(N.Lengths of the targets"}, {"name": "blank", "is_optional": true, "type": "int", "default_value": "0", "description": " Blank label. Default 000."}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": " Specifies the reduction to apply to the output"}, {"name": "zero_infinity", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether to zero infinite losses and the associated gradients.Default"}]}},
{"id": "torch.nn.functional.hinge_embedding_loss", "type": "function", "code": "torch.nn.functional.hinge_embedding_loss(input,target,margin=1.0,size_average=None,reduce=None,reduction='mean')", "example": "NA", "summary": "See HingeEmbeddingLoss for details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.hinge_embedding_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "margin", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"id": "torch.nn.functional.kl_div", "type": "function", "code": "torch.nn.functional.kl_div(input,target,size_average=None,reduce=None,reduction='mean')", "example": "NA", "summary": "The Kullback-Leibler divergence Loss", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.kl_div", "parameters": [{"name": "input", "is_optional": false, "type": "input : Tensor of arbitrary shap", "description": " Tensor of arbitrary shape"}, {"name": "target", "is_optional": false, "type": "target : Tensor of the same shape as inpu", "description": " Tensor of the same shape as input"}, {"name": "size_average", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default,the losses are averaged over each loss element in the batch. Note that forsome losses, there multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignoredwhen reduce is False. Default"}, {"name": "reduce", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default, thelosses are averaged or summed over observations for each minibatch dependingon size_average. When reduce is False, returns a loss perbatch element instead and ignores size_average. Default"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": " Specifies the reduction to apply to the output"}]}},
{"id": "torch.squeeze", "type": "function", "code": "torch.squeeze(input,dim=None,out=None)", "example": "  x = torch.zeros(2, 1, 2, 1, 2)  x.size() torch.Size([2, 1, 2, 1, 2])  y = torch.squeeze(x)  y.size() torch.Size([2, 2, 2])  y = torch.squeeze(x, 0)  y.size() torch.Size([2, 1, 2, 1, 2])  y = torch.squeeze(x, 1)  y.size() torch.Size([2, 2, 1, 2])   ", "summary": "Returns a tensor with all the dimensions of input of size 1 removed", "returns": null, "shape": "NA", "code-info": {"name": "torch.squeeze", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "dim", "is_optional": true, "type": "int, optional", "default_value": "None", "description": " if given, the input will be squeezed only inthis dimension"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.stack", "type": "function", "code": "torch.stack(tensors,dim=0,out=None)", "example": "NA", "summary": "Concatenates sequence of tensors along a new dimension", "returns": null, "shape": "NA", "code-info": {"name": "torch.stack", "parameters": [{"name": "tensors", "is_optional": false, "type": "sequence of Tensors", "description": " sequence of tensors to concatenate"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": " dimension to insert. Has to be between 0 and the numberof dimensions of concatenated tensors (inclusive"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.t", "type": "function", "code": "torch.t(input)", "example": "  x = torch.randn(())  x tensor(0.1995)  torch.t(x) tensor(0.1995)  x = torch.randn(3)  x tensor([ 2.4320, -0.4608,  0.7702])  torch.t(x) tensor([.2.4320,.-0.4608,..0.7702])  x = torch.randn(2, 3)  x tensor([[ 0.4875,  0.9158, -0.5872],         [ 0.3938, -0.6929,  0.6932]])  torch.t(x) tensor([[ 0.4875,  0.3938],         [ 0.9158, -0.6929],         [-0.5872,  0.6932]])   ", "summary": "Expects input to be &lt;= 2-D tensor and transposes dimensions 0 and 1", "returns": null, "shape": "NA", "code-info": {"name": "torch.t", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}]}},
{"id": "torch.take", "type": "function", "code": "torch.take(input,index)", "example": "  src = torch.tensor([[4, 3, 5],                         [6, 7, 8]])  torch.take(src, torch.tensor([0, 2, 5])) tensor([ 4,  5,  8])   ", "summary": "Returns a new tensor with the elements of input at the given indices", "returns": null, "shape": "NA", "code-info": {"name": "torch.take", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "index", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.transpose", "type": "function", "code": "torch.transpose(input,dim0,dim1)", "example": "  x = torch.randn(2, 3)  x tensor([[ 1.0028, -0.9893,  0.5809],         [-0.1669,  0.7299,  0.4942]])  torch.transpose(x, 0, 1) tensor([[ 1.0028, -0.1669],         [-0.9893,  0.7299],         [ 0.5809,  0.4942]])   ", "summary": "Returns a tensor that is a transposed version of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.transpose", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "dim0", "is_optional": false, "type": "int", "description": " the first dimension to be transposed"}, {"name": "dim1", "is_optional": false, "type": "int", "description": " the second dimension to be transposed"}]}},
{"id": "torch.unbind", "type": "function", "code": "torch.unbind(input,dim=0)", "example": "  torch.unbind(torch.tensor([[1, 2, 3],                             [4, 5, 6],                             [7, 8, 9]])) (tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9]))   ", "summary": "Removes a tensor dimension", "returns": null, "shape": "NA", "code-info": {"name": "torch.unbind", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to unbind"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": " dimension to remove"}]}},
{"id": "torch.distributions.normal.Normal.entropy", "type": "method", "code": "torch.distributions.normal.Normal.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.entropy", "parameters": []}},
{"id": "torch.distributions.normal.Normal.expand", "type": "method", "code": "torch.distributions.normal.Normal.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.normal.Normal.icdf", "type": "method", "code": "torch.distributions.normal.Normal.icdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.normal.Normal.log_prob", "type": "method", "code": "torch.distributions.normal.Normal.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.normal.Normal.mean", "type": "method", "code": "torch.distributions.normal.Normal.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.mean", "parameters": []}},
{"id": "torch.distributions.normal.Normal.rsample", "type": "method", "code": "torch.distributions.normal.Normal.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.normal.Normal.sample", "type": "method", "code": "torch.distributions.normal.Normal.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.normal.Normal.stddev", "type": "method", "code": "torch.distributions.normal.Normal.stddev", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.stddev", "parameters": []}},
{"id": "torch.distributions.normal.Normal.variance", "type": "method", "code": "torch.distributions.normal.Normal.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.variance", "parameters": []}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.entropy", "type": "method", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.entropy", "parameters": []}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support", "type": "method", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support(expand=True)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support", "parameters": [{"name": "expand", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.expand", "type": "method", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.ModuleDict.update", "type": "method", "code": "torch.nn.ModuleDict.update(modules:Mapping[str,torch.nn.modules.module.Module])", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.choices = nn.ModuleDict({\n                'conv': nn.Conv2d(10, 10, 3),\n                'pool': nn.MaxPool2d(3)\n        })\n        self.activations = nn.ModuleDict([\n                ['lrelu', nn.LeakyReLU()],\n                ['prelu', nn.PReLU()]\n        ])\n\n    def forward(self, x, choice, act):\n        x = self.choices[choice](x)\n        x = self.activations[act](x)\n        return x\n\n", "summary": "Update the ModuleDict with the key-value pairs from a mapping or an iterable, overwriting existing keys", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ModuleDict.update", "parameters": [{"name": "modules", "type": "Mapping[str,torch.nn.modules.module.Module]", "is_optional": false, "description": "a mapping (dictionary) from string to Module,or an iterable of key-value pairs of type (string, Module)"}]}},
{"id": "torch.nn.ModuleDict.values", "type": "method", "code": "torch.nn.ModuleDict.values()", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.choices = nn.ModuleDict({\n                'conv': nn.Conv2d(10, 10, 3),\n                'pool': nn.MaxPool2d(3)\n        })\n        self.activations = nn.ModuleDict([\n                ['lrelu', nn.LeakyReLU()],\n                ['prelu', nn.PReLU()]\n        ])\n\n    def forward(self, x, choice, act):\n        x = self.choices[choice](x)\n        x = self.activations[act](x)\n        return x\n\n", "summary": "Return an iterable of the ModuleDict values", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ModuleDict.values", "parameters": []}},
{"id": "torch.nn.ParameterList.append", "type": "method", "code": "torch.nn.ParameterList.append(parameter:Parameter)", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)])\n\n    def forward(self, x):\n        # ParameterList can act as an iterable, or be indexed using ints\n        for i, p in enumerate(self.params):\n            x = self.params[i // 2].mm(x) + p.mm(x)\n        return x\n\n", "summary": "Appends a given parameter at the end of the list", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ParameterList.append", "parameters": [{"name": "parameter", "type": "Parameter", "is_optional": false, "description": "parameter to append"}]}},
{"id": "torch.nn.ParameterList.extend", "type": "method", "code": "torch.nn.ParameterList.extend(parameters:Iterable[Parameter])", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)])\n\n    def forward(self, x):\n        # ParameterList can act as an iterable, or be indexed using ints\n        for i, p in enumerate(self.params):\n            x = self.params[i // 2].mm(x) + p.mm(x)\n        return x\n\n", "summary": "Appends parameters from a Python iterable to the end of the list", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ParameterList.extend", "parameters": [{"name": "parameters", "type": "Iterable[Parameter]", "is_optional": false, "description": "iterable of parameters to append"}]}},
{"id": "torch.nn.ParameterDict.clear", "type": "method", "code": "torch.nn.ParameterDict.clear()", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.params = nn.ParameterDict({\n                'left': nn.Parameter(torch.randn(5, 10)),\n                'right': nn.Parameter(torch.randn(5, 10))\n        })\n\n    def forward(self, x, choice):\n        x = self.params[choice].mm(x)\n        return x\n\n", "summary": "Remove all items from the ParameterDict", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ParameterDict.clear", "parameters": []}},
{"id": "torch.nn.ParameterDict.items", "type": "method", "code": "torch.nn.ParameterDict.items()", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.params = nn.ParameterDict({\n                'left': nn.Parameter(torch.randn(5, 10)),\n                'right': nn.Parameter(torch.randn(5, 10))\n        })\n\n    def forward(self, x, choice):\n        x = self.params[choice].mm(x)\n        return x\n\n", "summary": "Return an iterable of the ParameterDict key/value pairs", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ParameterDict.items", "parameters": []}},
{"id": "torch.nn.ParameterDict.keys", "type": "method", "code": "torch.nn.ParameterDict.keys()", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.params = nn.ParameterDict({\n                'left': nn.Parameter(torch.randn(5, 10)),\n                'right': nn.Parameter(torch.randn(5, 10))\n        })\n\n    def forward(self, x, choice):\n        x = self.params[choice].mm(x)\n        return x\n\n", "summary": "Return an iterable of the ParameterDict keys", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ParameterDict.keys", "parameters": []}},
{"id": "torch.nn.ParameterDict.pop", "type": "method", "code": "torch.nn.ParameterDict.pop(key:str)", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.params = nn.ParameterDict({\n                'left': nn.Parameter(torch.randn(5, 10)),\n                'right': nn.Parameter(torch.randn(5, 10))\n        })\n\n    def forward(self, x, choice):\n        x = self.params[choice].mm(x)\n        return x\n\n", "summary": "Remove key from the ParameterDict and return its parameter", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ParameterDict.pop", "parameters": [{"name": "key", "type": "str", "is_optional": false, "description": "key to pop from the ParameterDict"}]}},
{"id": "torch.nn.ParameterDict.update", "type": "method", "code": "torch.nn.ParameterDict.update(parameters:Mapping[str,Parameter])", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.params = nn.ParameterDict({\n                'left': nn.Parameter(torch.randn(5, 10)),\n                'right': nn.Parameter(torch.randn(5, 10))\n        })\n\n    def forward(self, x, choice):\n        x = self.params[choice].mm(x)\n        return x\n\n", "summary": "Update the ParameterDict with the key-value pairs from a mapping or an iterable, overwriting existing keys", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ParameterDict.update", "parameters": [{"name": "parameters", "type": "Mapping[str,Parameter]", "is_optional": false, "description": "a mapping (dictionary) from string toParameter, or an iterable ofkey-value pairs of type (string, Parameter)"}]}},
{"id": "torch.Tensor.index_put", "type": "method", "code": "torch.Tensor.index_put(indices,value,accumulate=False)", "example": "NA", "summary": "Out-place version of index_put_() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.index_put", "parameters": [{"name": "indices", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}, {"name": "accumulate", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.index_select", "type": "method", "code": "torch.Tensor.index_select(dim,index)", "example": "NA", "summary": "See torch.index_select() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.index_select", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.indices", "type": "method", "code": "torch.Tensor.indices()", "example": "NA", "summary": "If self is a sparse COO tensor (i.e., with torch.sparse_coo layout), this returns a view of the contained indices tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.indices", "parameters": []}},
{"id": "torch.Tensor.int", "type": "method", "code": "torch.Tensor.int()", "example": "NA", "summary": "self.int() is equivalent to self.to(torch.int32)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.int", "parameters": []}},
{"id": "torch.Tensor.int_repr", "type": "method", "code": "torch.Tensor.int_repr()", "example": "NA", "summary": "Given a quantized Tensor, self.int_repr() returns a CPU Tensor with uint8_t as data type that stores the underlying uint8_t values of the given Tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.int_repr", "parameters": []}},
{"id": "torch.Tensor.inverse", "type": "method", "code": "torch.Tensor.inverse()", "example": "NA", "summary": "See torch.inverse() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.inverse", "parameters": []}},
{"id": "torch.Tensor.irfft", "type": "method", "code": "torch.Tensor.irfft(signal_ndim,normalized=False,onesided=True,signal_sizes=None)", "example": "NA", "summary": "See torch.irfft() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.irfft", "parameters": [{"name": "signal_ndim", "is_optional": false, "type": "others", "description": ""}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "signal_sizes", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.is_contiguous", "type": "method", "code": "torch.Tensor.is_contiguous()", "example": "NA", "summary": "Returns True if self tensor is contiguous in memory in C order", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.is_contiguous", "parameters": []}},
{"id": "torch.Tensor.is_floating_point", "type": "method", "code": "torch.Tensor.is_floating_point()", "example": "NA", "summary": "Returns True if the data type of self is a floating point data type", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.is_floating_point", "parameters": []}},
{"id": "torch.Tensor.is_pinned", "type": "method", "code": "torch.Tensor.is_pinned()", "example": "NA", "summary": "Returns true if this tensor resides in pinned memory", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.is_pinned", "parameters": []}},
{"id": "torch.Tensor.is_set_to", "type": "method", "code": "torch.Tensor.is_set_to(tensor)", "example": "NA", "summary": "Returns True if this object refers to the same THTensor object from the Torch C API as the given tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.is_set_to", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.is_shared", "type": "method", "code": "torch.Tensor.is_shared()", "example": "NA", "summary": "Checks if tensor is in shared memory", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.is_shared", "parameters": []}},
{"id": "torch.nn.functional.l1_loss", "type": "function", "code": "torch.nn.functional.l1_loss(input,target,size_average=None,reduce=None,reduction='mean')", "example": "NA", "summary": "Function that takes the mean element-wise absolute value difference", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.l1_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"id": "torch.nn.functional.mse_loss", "type": "function", "code": "torch.nn.functional.mse_loss(input,target,size_average=None,reduce=None,reduction='mean')", "example": "NA", "summary": "Measures the element-wise mean squared error", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.mse_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"id": "torch.nn.functional.margin_ranking_loss", "type": "function", "code": "torch.nn.functional.margin_ranking_loss(input1,input2,target,margin=0,size_average=None,reduce=None,reduction='mean')", "example": "NA", "summary": "See MarginRankingLoss for details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.margin_ranking_loss", "parameters": [{"name": "input1", "is_optional": false, "type": "others", "description": ""}, {"name": "input2", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "margin", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"id": "torch.nn.functional.multilabel_margin_loss", "type": "function", "code": "torch.nn.functional.multilabel_margin_loss(input,target,size_average=None,reduce=None,reduction='mean')", "example": "NA", "summary": "See MultiLabelMarginLoss for details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.multilabel_margin_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"id": "torch.nn.functional.multilabel_soft_margin_loss", "type": "function", "code": "torch.nn.functional.multilabel_soft_margin_loss(input,target,weight=None,size_average=None)", "example": "NA", "summary": "See MultiLabelSoftMarginLoss for details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.multilabel_soft_margin_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.functional.multi_margin_loss", "type": "function", "code": "torch.nn.functional.multi_margin_loss(input,target,p=1,margin=1.0,weight=None,size_average=None,reduce=None,reduction='mean')", "example": "NA", "summary": " multi_margin_loss(input, target, p=1, margin=1, weight=None, size_average=None,reduce=None, reduction=\u2019mean\u2019) -&gt; Tensor   See MultiMarginLoss for details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.multi_margin_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "p", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "margin", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "weight", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"id": "torch.nn.functional.nll_loss", "type": "function", "code": "torch.nn.functional.nll_loss(input,target,weight=None,size_average=None,ignore_index=-100,reduce=None,reduction='mean')", "example": "  # input is of size N x C = 3 x 5  input = torch.randn(3, 5, requires_grad=True)  # each element in target has to have 0 &lt;= value &lt; C  target = torch.tensor([1, 0, 4])  output = F.nll_loss(F.log_softmax(input), target)  output.backward()   ", "summary": "The negative log likelihood loss", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.nll_loss", "parameters": [{"name": "input", "is_optional": false, "type": "N,C", "description": " (N,C(N, C(N,C where C = number of classes or (N,C,H,W(N, C, H, W(N,C,H,Win case of 2D Loss, or (N,C,d1,d2,...,dK(N, C, d_1, d_2, ..., d_K(N,C,d1\u200b,d2\u200b,...,dK\u200b where K\u22651K \\geq 1K\u22651in the case of K-dimensional loss."}, {"name": "target", "is_optional": false, "type": "N", "description": " (N(N(N where each value is 0\u2264targets[i]\u2264C\u221210 \\leq \\text{targets}[i] \\leq C-10\u2264targets[i]\u2264C\u22121,or (N,d1,d2,...,dK(N, d_1, d_2, ..., d_K(N,d1\u200b,d2\u200b,...,dK\u200b where K\u22651K \\geq 1K\u22651 forK-dimensional loss."}, {"name": "weight", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " a manual rescaling weight given to eachclass. If given, has to be a Tensor of size C"}, {"name": "size_average", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default,the losses are averaged over each loss element in the batch. Note that forsome losses, there multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignoredwhen reduce is False. Default"}, {"name": "ignore_index", "is_optional": true, "type": "int, optional", "default_value": "-100", "description": " Specifies a target value that is ignoredand does not contribute to the input gradient. When size_average isTrue, the loss is averaged over non-ignored targets. Default"}, {"name": "reduce", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Deprecated (see reduction. By default, thelosses are averaged or summed over observations for each minibatch dependingon size_average. When reduce is False, returns a loss perbatch element instead and ignores size_average. Default"}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": " Specifies the reduction to apply to the output"}]}},
{"id": "torch.unsqueeze", "type": "function", "code": "torch.unsqueeze(input,dim,out=None)", "example": "  x = torch.tensor([1, 2, 3, 4])  torch.unsqueeze(x, 0) tensor([[ 1,  2,  3,  4]])  torch.unsqueeze(x, 1) tensor([[ 1],         [ 2],         [ 3],         [ 4]])   ", "summary": "Returns a new tensor with a dimension of size one inserted at the specified position", "returns": null, "shape": "NA", "code-info": {"name": "torch.unsqueeze", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "dim", "is_optional": false, "type": "int", "description": " the index at which to insert the singleton dimension"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.where", "type": "function", "code": "torch.where()", "example": "  x = torch.randn(3, 2)  y = torch.ones(3, 2)  x tensor([[-0.4620,  0.3139],         [ 0.3898, -0.7197],         [ 0.0478, -0.1657]])  torch.where(x  0, x, y) tensor([[ 1.0000,  0.3139],         [ 0.3898,  1.0000],         [ 0.0478,  1.0000]])     torch.where(condition) \u2192 tuple of LongTensor   torch.where(condition) is identical to torch.nonzero(condition, as_tuple=True).  Note See also torch.nonzero().  ", "summary": "  torch.where(condition, x, y) \u2192 Tensor   Return a tensor of elements selected from either x or y, depending on condition", "returns": "A tensor of shape equal to the broadcasted shape of condition, x, y", "shape": "NA", "code-info": {"name": "torch.where", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(condition,x,y)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "condition", "is_optional": false, "type": "others", "description": ""}, {"name": "x", "is_optional": false, "type": "others", "description": ""}, {"name": "y", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(condition)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "condition", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.seed", "type": "function", "code": "torch.seed()", "example": "NA", "summary": "Sets the seed for generating random numbers to a non-deterministic random number", "returns": null, "shape": "NA", "code-info": {"name": "torch.seed", "parameters": []}},
{"id": "torch.manual_seed", "type": "function", "code": "torch.manual_seed(seed)", "example": "NA", "summary": "Sets the seed for generating random numbers", "returns": null, "shape": "NA", "code-info": {"name": "torch.manual_seed", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": " The desired seed."}]}},
{"id": "torch.initial_seed", "type": "function", "code": "torch.initial_seed()", "example": "NA", "summary": "Returns the initial seed for generating random numbers as a Python long", "returns": null, "shape": "NA", "code-info": {"name": "torch.initial_seed", "parameters": []}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.log_prob", "type": "method", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.logits", "type": "method", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.logits", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.logits", "parameters": []}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.mean", "type": "method", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.mean", "parameters": []}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.param_shape", "type": "method", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.param_shape", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.param_shape", "parameters": []}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.probs", "type": "method", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.probs", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.probs", "parameters": []}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.sample", "type": "method", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.variance", "type": "method", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.variance", "parameters": []}},
{"id": "torch.distributions.pareto.Pareto.entropy", "type": "method", "code": "torch.distributions.pareto.Pareto.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.pareto.Pareto.entropy", "parameters": []}},
{"id": "torch.distributions.pareto.Pareto.expand", "type": "method", "code": "torch.distributions.pareto.Pareto.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.pareto.Pareto.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.pareto.Pareto.mean", "type": "method", "code": "torch.distributions.pareto.Pareto.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.pareto.Pareto.mean", "parameters": []}},
{"id": "torch.distributions.pareto.Pareto.support", "type": "method", "code": "torch.distributions.pareto.Pareto.support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.pareto.Pareto.support", "parameters": []}},
{"id": "torch.distributions.pareto.Pareto.variance", "type": "method", "code": "torch.distributions.pareto.Pareto.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.pareto.Pareto.variance", "parameters": []}},
{"id": "torch.distributions.poisson.Poisson.expand", "type": "method", "code": "torch.distributions.poisson.Poisson.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.poisson.Poisson.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.poisson.Poisson.log_prob", "type": "method", "code": "torch.distributions.poisson.Poisson.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.poisson.Poisson.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.poisson.Poisson.mean", "type": "method", "code": "torch.distributions.poisson.Poisson.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.poisson.Poisson.mean", "parameters": []}},
{"id": "torch.nn.ParameterDict.values", "type": "method", "code": "torch.nn.ParameterDict.values()", "example": "class MyModule(nn.Module):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.params = nn.ParameterDict({\n                'left': nn.Parameter(torch.randn(5, 10)),\n                'right': nn.Parameter(torch.randn(5, 10))\n        })\n\n    def forward(self, x, choice):\n        x = self.params[choice].mm(x)\n        return x\n\n", "summary": "Return an iterable of the ParameterDict values", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ParameterDict.values", "parameters": []}},
{"id": "torch.nn.MultiheadAttention.forward", "type": "method", "code": "torch.nn.MultiheadAttention.forward(query,key,value,key_padding_mask=None,need_weights=True,attn_mask=None)", "example": "NA", "summary": " Parameters  key, value (query,) \u2013 map a query and a set of key-value pairs to an output", "returns": [], "shape": "", "code-info": {"name": "torch.nn.MultiheadAttention.forward", "parameters": []}},
{"id": "torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob", "type": "method", "code": "torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob(input:torch.Tensor)", "example": "NA", "summary": "Computes log probabilities for all n_classes\\texttt{n\\_classes}n_classes    Parameters input (Tensor) \u2013 a minibatch of examples  Returns log-probabilities of for each class ccc   in range 0&lt;=c&lt;=n_classes0 &lt;= c &lt;= \\texttt{n\\_classes}0&lt;=c&lt;=n_classes  , where n_classes\\texttt{n\\_classes}n_classes   is a parameter passed to AdaptiveLogSoftmaxWithLoss constructor", "returns": "output is a Tensor of size N containing computed targetlog probabilities for each exampleloss is a Scalar representing the computed negativelog likelihood loss", "shape": "", "code-info": {"name": "torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob", "parameters": [{"name": "input", "type": "torch.Tensor", "is_optional": false, "description": "a minibatch of examples"}]}},
{"id": "torch.nn.AdaptiveLogSoftmaxWithLoss.predict", "type": "method", "code": "torch.nn.AdaptiveLogSoftmaxWithLoss.predict(input:torch.Tensor)", "example": "NA", "summary": "This is equivalent to self.log_pob(input).argmax(dim=1), but is more efficient in some cases", "returns": "output is a Tensor of size N containing computed targetlog probabilities for each exampleloss is a Scalar representing the computed negativelog likelihood loss", "shape": "", "code-info": {"name": "torch.nn.AdaptiveLogSoftmaxWithLoss.predict", "parameters": [{"name": "input", "type": "torch.Tensor", "is_optional": false, "description": "a minibatch of examples"}]}},
{"id": "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "type": "method", "code": "torch.nn.SyncBatchNorm.convert_sync_batchnorm(module,process_group=None)", "example": "  # Network with nn.BatchNorm layer  module = torch.nn.Sequential(             torch.nn.Linear(20, 100),             torch.nn.BatchNorm1d(100),           ).cuda()  # creating process group (optional)  # process_ids is a list of int identifying rank ids.  process_group = torch.distributed.new_group(process_ids)  sync_bn_module = torch.nn.SyncBatchNorm.convert_sync_batchnorm(module, process_group)   ", "summary": "Helper function to convert all BatchNorm*D layers in the model to torch.nn.SyncBatchNorm layers", "returns": "The original module with the converted torch.nn.SyncBatchNormlayers. If the original module is a BatchNorm*D layer,a new torch.nn.SyncBatchNorm layer object will be returnedinstead.", "shape": "", "code-info": {"name": "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "parameters": []}},
{"id": "torch.nn.RNNBase.flatten_parameters", "type": "method", "code": "torch.nn.RNNBase.flatten_parameters()", "example": "NA", "summary": "Resets parameter data pointer so that they can use faster code paths", "returns": [], "shape": "", "code-info": {"name": "torch.nn.RNNBase.flatten_parameters", "parameters": []}},
{"id": "torch.Tensor.is_signed", "type": "method", "code": "torch.Tensor.is_signed()", "example": "NA", "summary": "Returns True if the data type of self is a signed data type", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.is_signed", "parameters": []}},
{"id": "torch.Tensor.item", "type": "method", "code": "torch.Tensor.item()", "example": "  x = torch.tensor([1.0])  x.item() 1.0   ", "summary": "Returns the value of this tensor as a standard Python number", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.item", "parameters": []}},
{"id": "torch.Tensor.kthvalue", "type": "method", "code": "torch.Tensor.kthvalue(k,dim=None,keepdim=False)", "example": "NA", "summary": "See torch.kthvalue() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.kthvalue", "parameters": [{"name": "k", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.le", "type": "method", "code": "torch.Tensor.le(other)", "example": "NA", "summary": "See torch.le() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.le", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.le_", "type": "method", "code": "torch.Tensor.le_(other)", "example": "NA", "summary": "In-place version of le() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.le_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.lerp", "type": "method", "code": "torch.Tensor.lerp(end,weight)", "example": "NA", "summary": "See torch.lerp() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.lerp", "parameters": [{"name": "end", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.lerp_", "type": "method", "code": "torch.Tensor.lerp_(end,weight)", "example": "NA", "summary": "In-place version of lerp() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.lerp_", "parameters": [{"name": "end", "is_optional": false, "type": "others", "description": ""}, {"name": "weight", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.lgamma", "type": "method", "code": "torch.Tensor.lgamma()", "example": "NA", "summary": "See torch.lgamma() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.lgamma", "parameters": []}},
{"id": "torch.Tensor.lgamma_", "type": "method", "code": "torch.Tensor.lgamma_()", "example": "NA", "summary": "In-place version of lgamma() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.lgamma_", "parameters": []}},
{"id": "torch.Tensor.log", "type": "method", "code": "torch.Tensor.log()", "example": "NA", "summary": "See torch.log() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.log", "parameters": []}},
{"id": "torch.Tensor.log_", "type": "method", "code": "torch.Tensor.log_()", "example": "NA", "summary": "In-place version of log() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.log_", "parameters": []}},
{"id": "torch.Tensor.logdet", "type": "method", "code": "torch.Tensor.logdet()", "example": "NA", "summary": "See torch.logdet() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.logdet", "parameters": []}},
{"id": "torch.Tensor.log10", "type": "method", "code": "torch.Tensor.log10()", "example": "NA", "summary": "See torch.log10() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.log10", "parameters": []}},
{"id": "torch.nn.functional.smooth_l1_loss", "type": "function", "code": "torch.nn.functional.smooth_l1_loss(input,target,size_average=None,reduce=None,reduction='mean')", "example": "NA", "summary": "Function that uses a squared term if the absolute element-wise error falls below 1 and an L1 term otherwise", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.smooth_l1_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"id": "torch.nn.functional.soft_margin_loss", "type": "function", "code": "torch.nn.functional.soft_margin_loss(input,target,size_average=None,reduce=None,reduction='mean')", "example": "NA", "summary": "See SoftMarginLoss for details", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.soft_margin_loss", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "target", "is_optional": false, "type": "others", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"id": "torch.nn.functional.triplet_margin_loss", "type": "function", "code": "torch.nn.functional.triplet_margin_loss(anchor,positive,negative,margin=1.0,p=2,eps=1e-06,swap=False,size_average=None,reduce=None,reduction='mean')", "example": "NA", "summary": "See TripletMarginLoss for details ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.triplet_margin_loss", "parameters": [{"name": "anchor", "is_optional": false, "type": "others", "description": ""}, {"name": "positive", "is_optional": false, "type": "others", "description": ""}, {"name": "negative", "is_optional": false, "type": "others", "description": ""}, {"name": "margin", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": ""}, {"name": "eps", "is_optional": true, "type": "others", "default_value": "1e-06", "description": ""}, {"name": "swap", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "size_average", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduce", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "reduction", "is_optional": true, "type": "string", "default_value": "'mean'", "description": ""}]}},
{"id": "torch.nn.functional.pixel_shuffle", "type": "function", "code": "torch.nn.functional.pixel_shuffle()", "example": " input = torch.randn(1, 9, 4, 4)\n output = torch.nn.functional.pixel_shuffle(input, 3)\n print(output.size())\ntorch.Size([1, 1, 12, 12])\n\n", "summary": "Rearranges elements in a tensor of shape (\u2217,C\u00d7r2,H,W)(*, C \\times r^2, H, W)(\u2217,C\u00d7r2,H,W)   to a tensor of shape (\u2217,C,H\u00d7r,W\u00d7r)(*, C, H \\times r, W \\times r)(\u2217,C,H\u00d7r,W\u00d7r)  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.pixel_shuffle", "parameters": []}},
{"id": "torch.nn.functional.pad", "type": "function", "code": "torch.nn.functional.pad(input,pad,mode='constant',value=0)", "example": " t4d = torch.empty(3, 3, 4, 2)\n p1d = (1, 1) # pad last dim by 1 on each side\n out = F.pad(t4d, p1d, \"constant\", 0)  # effectively zero padding\n print(out.data.size())\ntorch.Size([3, 3, 4, 4])\n p2d = (1, 1, 2, 2) # pad last dim by (1, 1) and 2nd to last by (2, 2)\n out = F.pad(t4d, p2d, \"constant\", 0)\n print(out.data.size())\ntorch.Size([3, 3, 8, 4])\n t4d = torch.empty(3, 3, 4, 2)\n p3d = (0, 1, 2, 1, 3, 3) # pad by (0, 1), (2, 1), and (3, 3)\n out = F.pad(t4d, p3d, \"constant\", 0)\n print(out.data.size())\ntorch.Size([3, 9, 7, 3])\n\n", "summary": "Pads tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.pad", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " N-dimensional tensor"}, {"name": "pad", "is_optional": false, "type": "tuple", "description": " m-elements tuple, wherem2\u2264\\frac{m}{2} \\leq2m\u200b\u2264 input dimensions and mmm is even."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'constant'", "description": " 'constant', 'reflect', 'replicate' or 'circular'.Default"}, {"name": "value", "is_optional": true, "type": "int", "default_value": "0", "description": " fill value for 'constant' padding. Default"}]}},
{"id": "torch.get_rng_state", "type": "function", "code": "torch.get_rng_state()", "example": "NA", "summary": "Returns the random number generator state as a torch.ByteTensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.get_rng_state", "parameters": []}},
{"id": "torch.set_rng_state", "type": "function", "code": "torch.set_rng_state(new_state)", "example": "NA", "summary": "Sets the random number generator state", "returns": null, "shape": "NA", "code-info": {"name": "torch.set_rng_state", "parameters": [{"name": "new_state", "is_optional": false, "type": "torch.ByteTensor", "description": " The desired state"}]}},
{"id": "torch.bernoulli", "type": "function", "code": "torch.bernoulli(input,*,generator=None,out=None)", "example": "  a = torch.empty(3, 3).uniform_(0, 1)  # generate a uniform random matrix with range [0, 1]  a tensor([[ 0.1737,  0.0950,  0.3609],         [ 0.7148,  0.0289,  0.2676],         [ 0.9456,  0.8937,  0.7202]])  torch.bernoulli(a) tensor([[ 1.,  0.,  0.],         [ 0.,  0.,  0.],         [ 1.,  1.,  1.]])   a = torch.ones(3, 3) # probability of drawing \"1\" is 1  torch.bernoulli(a) tensor([[ 1.,  1.,  1.],         [ 1.,  1.,  1.],         [ 1.,  1.,  1.]])  a = torch.zeros(3, 3) # probability of drawing \"1\" is 0  torch.bernoulli(a) tensor([[ 0.,  0.,  0.],         [ 0.,  0.,  0.],         [ 0.,  0.,  0.]])   ", "summary": "Draws binary random numbers (0 or 1) from a Bernoulli distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.bernoulli", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of probability values for the Bernoulli distribution"}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "torch.Generator, optional", "default_value": "None", "description": " a pseudorandom number generator for sampling"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.multinomial", "type": "function", "code": "torch.multinomial(input,num_samples,replacement=False,*,generator=None,out=None)", "example": "  weights = torch.tensor([0, 10, 3, 0], dtype=torch.float) # create a tensor of weights  torch.multinomial(weights, 2) tensor([1, 2])  torch.multinomial(weights, 4) # ERROR! RuntimeError: invalid argument 2: invalid multinomial distribution (with replacement=False, not enough non-negative category to sample) at ../aten/src/TH/generic/THTensorRandom.cpp:320  torch.multinomial(weights, 4, replacement=True) tensor([ 2,  1,  1,  1])   ", "summary": "Returns a tensor where each row contains num_samples indices sampled from the multinomial probability distribution located in the corresponding row of tensor input", "returns": null, "shape": "NA", "code-info": {"name": "torch.multinomial", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor containing probabilities"}, {"name": "num_samples", "is_optional": false, "type": "int", "description": " number of samples to draw"}, {"name": "replacement", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether to draw with replacement or not"}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "torch.Generator, optional", "default_value": "None", "description": " a pseudorandom number generator for sampling"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.normal", "type": "function", "code": "torch.normal()", "example": "  torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1)) tensor([  1.0425,   3.5672,   2.7969,   4.2925,   4.7229,   6.2134,           8.0505,   8.1408,   9.0563,  10.0566])     torch.normal(mean=0.0, std, out=None) \u2192 Tensor   Similar to the function above, but the means are shared among all drawn elements.  Parameters  mean (python:float, optional) \u2013 the mean for all distributions std (Tensor) \u2013 the tensor of per-element standard deviations out (Tensor, optional) \u2013 the output tensor.    ", "summary": "  torch.normal(mean, std, *, generator=None, out=None) \u2192 Tensor   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given", "returns": null, "shape": "NA", "code-info": {"name": "torch.normal", "parameters": []}},
{"id": "torch.distributions.poisson.Poisson.sample", "type": "method", "code": "torch.distributions.poisson.Poisson.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.poisson.Poisson.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.poisson.Poisson.variance", "type": "method", "code": "torch.distributions.poisson.Poisson.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.poisson.Poisson.variance", "parameters": []}},
{"id": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.expand", "type": "method", "code": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits", "type": "method", "code": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits", "parameters": []}},
{"id": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs", "type": "method", "code": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs", "parameters": []}},
{"id": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature", "type": "method", "code": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature", "parameters": []}},
{"id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.expand", "type": "method", "code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.log_prob", "type": "method", "code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.param_shape", "type": "method", "code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.param_shape", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.param_shape", "parameters": []}},
{"id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.rsample", "type": "method", "code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.expand", "type": "method", "code": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits", "type": "method", "code": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits", "parameters": []}},
{"id": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs", "type": "method", "code": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs", "parameters": []}},
{"id": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature", "type": "method", "code": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature", "parameters": []}},
{"id": "torch.distributions.studentT.StudentT.entropy", "type": "method", "code": "torch.distributions.studentT.StudentT.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.studentT.StudentT.entropy", "parameters": []}},
{"id": "torch.nn.Transformer.forward", "type": "method", "code": "torch.nn.Transformer.forward(src:torch.Tensor,tgt:torch.Tensor,src_mask:Optional[torch.Tensor]=None,tgt_mask:Optional[torch.Tensor]=None,memory_mask:Optional[torch.Tensor]=None,src_key_padding_mask:Optional[torch.Tensor]=None,tgt_key_padding_mask:Optional[torch.Tensor]=None,memory_key_padding_mask:Optional[torch.Tensor]=None)", "example": "NA", "summary": "Take in and process masked source/target sequences", "returns": [], "shape": "\nsrc: (S,N,E)(S, N, E)(S,N,E)\n\n.\ntgt: (T,N,E)(T, N, E)(T,N,E)\n\n.\nsrc_mask: (S,S)(S, S)(S,S)\n\n.\ntgt_mask: (T,T)(T, T)(T,T)\n\n.\nmemory_mask: (T,S)(T, S)(T,S)\n\n.\nsrc_key_padding_mask: (N,S)(N, S)(N,S)\n\n.\ntgt_key_padding_mask: (N,T)(N, T)(N,T)\n\n.\nmemory_key_padding_mask: (N,S)(N, S)(N,S)\n\n.\n\nNote: [src/tgt/memory]_mask ensures that position i is allowed to attend the unmasked\npositions. If a ByteTensor is provided, the non-zero positions are not allowed to attend\nwhile the zero positions will be unchanged. If a BoolTensor is provided, positions with True\nare not allowed to attend while False values will be unchanged. If a FloatTensor\nis provided, it will be added to the attention weight.\n[src/tgt/memory]_key_padding_mask provides specified elements in the key to be ignored by\nthe attention. If a ByteTensor is provided, the non-zero positions will be ignored while the zero\npositions will be unchanged. If a BoolTensor is provided, the positions with the\nvalue of True will be ignored while the position with the value of False will be unchanged.\n\noutput: (T,N,E)(T, N, E)(T,N,E)\n\n.\n\nNote: Due to the multi-head attention architecture in the transformer model,\nthe output sequence length of a transformer is same as the input sequence\n(i.e. target) length of the decode.\nwhere S is the source sequence length, T is the target sequence length, N is the\nbatch size, E is the feature number\n", "code-info": {"name": "torch.nn.Transformer.forward", "parameters": [{"name": "src", "type": "torch.Tensor", "is_optional": false, "description": "the sequence to the encoder (required)."}, {"name": "tgt", "type": "torch.Tensor", "is_optional": false, "description": "the sequence to the decoder (required)."}, {"name": "src_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the additive mask for the src sequence (optional)."}, {"name": "tgt_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the additive mask for the tgt sequence (optional)."}, {"name": "memory_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the additive mask for the encoder output (optional)."}, {"name": "src_key_padding_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the ByteTensor mask for src keys per batch (optional)."}, {"name": "tgt_key_padding_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the ByteTensor mask for tgt keys per batch (optional)."}, {"name": "memory_key_padding_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the ByteTensor mask for memory keys per batch (optional)."}]}},
{"id": "torch.nn.Transformer.generate_square_subsequent_mask", "type": "method", "code": "torch.nn.Transformer.generate_square_subsequent_mask(sz:int)", "example": "NA", "summary": "Generate a square mask for the sequence", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Transformer.generate_square_subsequent_mask", "parameters": [{"name": "sz", "type": "int", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.TransformerEncoder.forward", "type": "method", "code": "torch.nn.TransformerEncoder.forward(src:torch.Tensor,mask:Optional[torch.Tensor]=None,src_key_padding_mask:Optional[torch.Tensor]=None)", "example": "NA", "summary": "Pass the input through the encoder layers in turn", "returns": [], "shape": "", "code-info": {"name": "torch.nn.TransformerEncoder.forward", "parameters": [{"name": "src", "type": "torch.Tensor", "is_optional": false, "description": "the sequence to the encoder (required)."}, {"name": "mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the src sequence (optional)."}, {"name": "src_key_padding_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the src keys per batch (optional)."}]}},
{"id": "torch.Tensor.log10_", "type": "method", "code": "torch.Tensor.log10_()", "example": "NA", "summary": "In-place version of log10() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.log10_", "parameters": []}},
{"id": "torch.Tensor.log1p", "type": "method", "code": "torch.Tensor.log1p()", "example": "NA", "summary": "See torch.log1p() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.log1p", "parameters": []}},
{"id": "torch.Tensor.log1p_", "type": "method", "code": "torch.Tensor.log1p_()", "example": "NA", "summary": "In-place version of log1p() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.log1p_", "parameters": []}},
{"id": "torch.Tensor.log2", "type": "method", "code": "torch.Tensor.log2()", "example": "NA", "summary": "See torch.log2() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.log2", "parameters": []}},
{"id": "torch.Tensor.log2_", "type": "method", "code": "torch.Tensor.log2_()", "example": "NA", "summary": "In-place version of log2() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.log2_", "parameters": []}},
{"id": "torch.Tensor.log_normal_", "type": "method", "code": "torch.Tensor.log_normal_(mean=1,std=2,*,generator=None)", "example": "NA", "summary": "Fills self tensor with numbers samples from the log-normal distribution parameterized by the given mean \u03bc\\mu\u03bc   and standard deviation \u03c3\\sigma\u03c3  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.log_normal_", "parameters": [{"name": "mean", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "std", "is_optional": true, "type": "int", "default_value": "2", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.logsumexp", "type": "method", "code": "torch.Tensor.logsumexp(dim,keepdim=False)", "example": "NA", "summary": "See torch.logsumexp() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.logsumexp", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.logical_not", "type": "method", "code": "torch.Tensor.logical_not()", "example": "NA", "summary": "See torch.logical_not() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.logical_not", "parameters": []}},
{"id": "torch.Tensor.logical_not_", "type": "method", "code": "torch.Tensor.logical_not_()", "example": "NA", "summary": "In-place version of logical_not() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.logical_not_", "parameters": []}},
{"id": "torch.Tensor.logical_xor", "type": "method", "code": "torch.Tensor.logical_xor()", "example": "NA", "summary": "See torch.logical_xor() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.logical_xor", "parameters": []}},
{"id": "torch.Tensor.logical_xor_", "type": "method", "code": "torch.Tensor.logical_xor_()", "example": "NA", "summary": "In-place version of logical_xor() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.logical_xor_", "parameters": []}},
{"id": "torch.nn.functional.interpolate", "type": "function", "code": "torch.nn.functional.interpolate(input,size=None,scale_factor=None,mode='nearest',align_corners=None)", "example": "NA", "summary": "Down/up samples the input to either the given size or the given scale_factor The algorithm used for interpolation is determined by mode", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.interpolate", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor"}, {"name": "size", "is_optional": true, "type": "int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]", "default_value": "None", "description": " output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "float or Tuple[float]", "default_value": "None", "description": " multiplier for spatial size. Has to match input size if it is a tuple."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'nearest'", "description": " algorithm used for upsampling"}, {"name": "align_corners", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Geometrically, we consider the pixels of theinput and output as squares rather than points.If set to True, the input and output tensors are aligned by thecenter points of their corner pixels, preserving the values at the corner pixels.If set to False, the input and output tensors are aligned by the cornerpoints of their corner pixels, and the interpolation uses edge value paddingfor out-of-boundary values, making this operation independent of input sizewhen scale_factor is kept the same. This only has an effect when modeis 'linear', 'bilinear', 'bicubic' or 'trilinear'.Default"}]}},
{"id": "torch.nn.functional.upsample", "type": "function", "code": "torch.nn.functional.upsample(input,size=None,scale_factor=None,mode='nearest',align_corners=None)", "example": "NA", "summary": "Upsamples the input to either the given size or the given scale_factor  Warning This function is deprecated in favor of torch.nn.functional.interpolate()", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.upsample", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor"}, {"name": "size", "is_optional": true, "type": "int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]", "default_value": "None", "description": " output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "float or Tuple[float]", "default_value": "None", "description": " multiplier for spatial size. Has to be an integer."}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'nearest'", "description": " algorithm used for upsampling"}, {"name": "align_corners", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " Geometrically, we consider the pixels of theinput and output as squares rather than points.If set to True, the input and output tensors are aligned by thecenter points of their corner pixels, preserving the values at the corner pixels.If set to False, the input and output tensors are aligned by the cornerpoints of their corner pixels, and the interpolation uses edge value paddingfor out-of-boundary values, making this operation independent of input sizewhen scale_factor is kept the same. This only has an effect when modeis 'linear', 'bilinear', 'bicubic' or 'trilinear'.Default"}]}},
{"id": "NA", "type": "function", "code": "NA(mean,std,*,generator=None,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "mean", "is_optional": false, "type": "others", "description": ""}, {"name": "std", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(mean=0.0,std,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "mean", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}, {"name": "std", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(mean,std=1.0,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "mean", "is_optional": false, "type": "others", "description": ""}, {"name": "std", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(mean,std,size,*,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "mean", "is_optional": false, "type": "others", "description": ""}, {"name": "std", "is_optional": false, "type": "others", "description": ""}, {"name": "size", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.rand", "type": "function", "code": "torch.rand(*size,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.rand(4) tensor([ 0.5204,  0.2503,  0.3525,  0.5673])  torch.rand(2, 3) tensor([[ 0.8237,  0.5781,  0.6879],         [ 0.3816,  0.7249,  0.0998]])   ", "summary": "Returns a tensor filled with random numbers from a uniform distribution on the interval [0,1)[0, 1)[0,1)   The shape of the tensor is defined by the variable argument size", "returns": null, "shape": "NA", "code-info": {"name": "torch.rand", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "int...", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.rand_like", "type": "function", "code": "torch.rand_like(input,dtype=None,layout=None,device=None,requires_grad=False)", "example": "NA", "summary": "Returns a tensor with the same size as input that is filled with random numbers from a uniform distribution on the interval [0,1)[0, 1)[0,1)  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.rand_like", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the size of input will determine size of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned Tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "None", "description": " the desired layout of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.randint", "type": "function", "code": "torch.randint(low=0,high,size,*,generator=None,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.randint(3, 5, (3,)) tensor([4, 3, 4])    torch.randint(10, (2, 2)) tensor([[0, 2],         [5, 5]])    torch.randint(3, 10, (2, 2)) tensor([[4, 5],         [6, 7]])   ", "summary": "Returns a tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive)", "returns": null, "shape": "NA", "code-info": {"name": "torch.randint", "parameters": [{"name": "low", "is_optional": true, "type": "int", "default_value": "0", "description": " Lowest integer to be drawn from the distribution. Default"}, {"name": "high", "is_optional": false, "type": "int", "description": " One above the highest integer to be drawn from the distribution."}, {"name": "size", "is_optional": false, "type": "tuple", "description": " a tuple defining the shape of the output tensor."}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "torch.Generator, optional", "default_value": "None", "description": " a pseudorandom number generator for sampling"}, {"name": "out", "is_optional": true, "type": "tuple", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.distributions.studentT.StudentT.expand", "type": "method", "code": "torch.distributions.studentT.StudentT.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.studentT.StudentT.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.studentT.StudentT.log_prob", "type": "method", "code": "torch.distributions.studentT.StudentT.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.studentT.StudentT.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.studentT.StudentT.mean", "type": "method", "code": "torch.distributions.studentT.StudentT.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.studentT.StudentT.mean", "parameters": []}},
{"id": "torch.distributions.studentT.StudentT.rsample", "type": "method", "code": "torch.distributions.studentT.StudentT.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.studentT.StudentT.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.studentT.StudentT.variance", "type": "method", "code": "torch.distributions.studentT.StudentT.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.studentT.StudentT.variance", "parameters": []}},
{"id": "torch.distributions.transformed_distribution.TransformedDistribution.cdf", "type": "method", "code": "torch.distributions.transformed_distribution.TransformedDistribution.cdf(value)", "example": "NA", "summary": "Computes the cumulative distribution function by inverting the transform(s) and computing the score of the base distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.transformed_distribution.TransformedDistribution.expand", "type": "method", "code": "torch.distributions.transformed_distribution.TransformedDistribution.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.transformed_distribution.TransformedDistribution.has_rsample", "type": "method", "code": "torch.distributions.transformed_distribution.TransformedDistribution.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.has_rsample", "parameters": []}},
{"id": "torch.distributions.transformed_distribution.TransformedDistribution.icdf", "type": "method", "code": "torch.distributions.transformed_distribution.TransformedDistribution.icdf(value)", "example": "NA", "summary": "Computes the inverse cumulative distribution function using transform(s) and computing the score of the base distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.transformed_distribution.TransformedDistribution.log_prob", "type": "method", "code": "torch.distributions.transformed_distribution.TransformedDistribution.log_prob(value)", "example": "NA", "summary": "Scores the sample by inverting the transform(s) and computing the score using the score of the base distribution and the log abs det jacobian", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.transformed_distribution.TransformedDistribution.rsample", "type": "method", "code": "torch.distributions.transformed_distribution.TransformedDistribution.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples if the distribution parameters are batched", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.transformed_distribution.TransformedDistribution.sample", "type": "method", "code": "torch.distributions.transformed_distribution.TransformedDistribution.sample(sample_shape=torch.Size([])", "example": "NA", "summary": "Generates a sample_shape shaped sample or sample_shape shaped batch of samples if the distribution parameters are batched", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.sample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.nn.TransformerDecoder.forward", "type": "method", "code": "torch.nn.TransformerDecoder.forward(tgt:torch.Tensor,memory:torch.Tensor,tgt_mask:Optional[torch.Tensor]=None,memory_mask:Optional[torch.Tensor]=None,tgt_key_padding_mask:Optional[torch.Tensor]=None,memory_key_padding_mask:Optional[torch.Tensor]=None)", "example": "NA", "summary": "Pass the inputs (and mask) through the decoder layer in turn", "returns": [], "shape": "", "code-info": {"name": "torch.nn.TransformerDecoder.forward", "parameters": [{"name": "tgt", "type": "torch.Tensor", "is_optional": false, "description": "the sequence to the decoder (required)."}, {"name": "memory", "type": "torch.Tensor", "is_optional": false, "description": "the sequence from the last layer of the encoder (required)."}, {"name": "tgt_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the tgt sequence (optional)."}, {"name": "memory_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the memory sequence (optional)."}, {"name": "tgt_key_padding_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the tgt keys per batch (optional)."}, {"name": "memory_key_padding_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the memory keys per batch (optional)."}]}},
{"id": "torch.nn.TransformerEncoderLayer.forward", "type": "method", "code": "torch.nn.TransformerEncoderLayer.forward(src:torch.Tensor,src_mask:Optional[torch.Tensor]=None,src_key_padding_mask:Optional[torch.Tensor]=None)", "example": "NA", "summary": "Pass the input through the encoder layer", "returns": [], "shape": "", "code-info": {"name": "torch.nn.TransformerEncoderLayer.forward", "parameters": [{"name": "src", "type": "torch.Tensor", "is_optional": false, "description": "the sequence to the encoder layer (required)."}, {"name": "src_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the src sequence (optional)."}, {"name": "src_key_padding_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the src keys per batch (optional)."}]}},
{"id": "torch.nn.TransformerDecoderLayer.forward", "type": "method", "code": "torch.nn.TransformerDecoderLayer.forward(tgt:torch.Tensor,memory:torch.Tensor,tgt_mask:Optional[torch.Tensor]=None,memory_mask:Optional[torch.Tensor]=None,tgt_key_padding_mask:Optional[torch.Tensor]=None,memory_key_padding_mask:Optional[torch.Tensor]=None)", "example": "NA", "summary": "Pass the inputs (and mask) through the decoder layer", "returns": [], "shape": "", "code-info": {"name": "torch.nn.TransformerDecoderLayer.forward", "parameters": [{"name": "tgt", "type": "torch.Tensor", "is_optional": false, "description": "the sequence to the decoder layer (required)."}, {"name": "memory", "type": "torch.Tensor", "is_optional": false, "description": "the sequence from the last layer of the encoder (required)."}, {"name": "tgt_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the tgt sequence (optional)."}, {"name": "memory_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the memory sequence (optional)."}, {"name": "tgt_key_padding_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the tgt keys per batch (optional)."}, {"name": "memory_key_padding_mask", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "the mask for the memory keys per batch (optional)."}]}},
{"id": "torch.nn.Embedding.from_pretrained", "type": "method", "code": "torch.nn.Embedding.from_pretrained(embeddings,freeze=True,padding_idx=None,max_norm=None,norm_type=2.0,scale_grad_by_freq=False,sparse=False)", "example": "NA", "summary": "Creates Embedding instance from given 2-dimensional FloatTensor", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Embedding.from_pretrained", "parameters": []}},
{"id": "torch.nn.EmbeddingBag.from_pretrained", "type": "method", "code": "torch.nn.EmbeddingBag.from_pretrained(embeddings:torch.Tensor,freeze:bool=True,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,mode:str='mean',sparse:bool=False,include_last_offset:bool=False)", "example": "NA", "summary": "Creates EmbeddingBag instance from given 2-dimensional FloatTensor", "returns": [], "shape": "", "code-info": {"name": "torch.nn.EmbeddingBag.from_pretrained", "parameters": [{"name": "embeddings", "type": "torch.Tensor", "is_optional": false, "description": "FloatTensor containing weights for the EmbeddingBag.First dimension is being passed to EmbeddingBag as \u2018num_embeddings\u2019, second as \u2018embedding_dim\u2019."}, {"name": "freeze", "type": "bool", "default_value": "True", "is_optional": true, "description": "If True, the tensor does not get updated in the learning process.Equivalent to embeddingbag.weight.requires_grad = False. Default: True"}, {"name": "max_norm", "type": "Optional[float]", "default_value": "None", "is_optional": true, "description": "See module initialization documentation. Default: None"}, {"name": "norm_type", "type": "float", "default_value": "2.0", "is_optional": true, "description": "See module initialization documentation. Default 2."}, {"name": "scale_grad_by_freq", "type": "bool", "default_value": "False", "is_optional": true, "description": "See module initialization documentation. Default False."}, {"name": "mode", "type": "str", "default_value": "\"mean\"", "is_optional": true, "description": "See module initialization documentation. Default: \"mean\""}, {"name": "sparse", "type": "bool", "default_value": "False", "is_optional": true, "description": "See module initialization documentation. Default: False."}, {"name": "include_last_offset", "type": "bool", "default_value": "False", "is_optional": true, "description": "See module initialization documentation. Default: False."}]}},
{"id": "torch.Tensor.long", "type": "method", "code": "torch.Tensor.long()", "example": "NA", "summary": "self.long() is equivalent to self.to(torch.int64)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.long", "parameters": []}},
{"id": "torch.Tensor.lstsq", "type": "method", "code": "torch.Tensor.lstsq(A)", "example": "NA", "summary": "See torch.lstsq() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.lstsq", "parameters": [{"name": "A", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.lt", "type": "method", "code": "torch.Tensor.lt(other)", "example": "NA", "summary": "See torch.lt() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.lt", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.lt_", "type": "method", "code": "torch.Tensor.lt_(other)", "example": "NA", "summary": "In-place version of lt() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.lt_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.lu", "type": "method", "code": "torch.Tensor.lu(pivot=True,get_infos=False)", "example": "NA", "summary": "See torch.lu() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.lu", "parameters": [{"name": "pivot", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "get_infos", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.lu_solve", "type": "method", "code": "torch.Tensor.lu_solve(LU_data,LU_pivots)", "example": "NA", "summary": "See torch.lu_solve() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.lu_solve", "parameters": [{"name": "LU_data", "is_optional": false, "type": "others", "description": ""}, {"name": "LU_pivots", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.map_", "type": "method", "code": "torch.Tensor.map_(tensor,callable)", "example": "NA", "summary": "Applies callable for each element in self tensor and the given tensor and stores the results in self tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.map_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}, {"name": "callable", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.masked_scatter_", "type": "method", "code": "torch.Tensor.masked_scatter_(mask,source)", "example": "NA", "summary": "Copies elements from source into self tensor at positions where the mask is True", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.masked_scatter_", "parameters": [{"name": "mask", "is_optional": false, "type": "BoolTensor", "description": " the boolean mask"}, {"name": "source", "is_optional": false, "type": "Tensor", "description": " the tensor to copy from"}]}},
{"id": "torch.Tensor.masked_scatter", "type": "method", "code": "torch.Tensor.masked_scatter(mask,tensor)", "example": "NA", "summary": "Out-of-place version of torch.Tensor.masked_scatter_() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.masked_scatter", "parameters": [{"name": "mask", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.masked_fill_", "type": "method", "code": "torch.Tensor.masked_fill_(mask,value)", "example": "NA", "summary": "Fills elements of self tensor with value where mask is True", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.masked_fill_", "parameters": [{"name": "mask", "is_optional": false, "type": "BoolTensor", "description": " the boolean mask"}, {"name": "value", "is_optional": false, "type": "float", "description": " the value to fill in with"}]}},
{"id": "torch.Tensor.masked_fill", "type": "method", "code": "torch.Tensor.masked_fill(mask,value)", "example": "NA", "summary": "Out-of-place version of torch.Tensor.masked_fill_() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.masked_fill", "parameters": [{"name": "mask", "is_optional": false, "type": "others", "description": ""}, {"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.functional.upsample_nearest", "type": "function", "code": "torch.nn.functional.upsample_nearest(input,size=None,scale_factor=None)", "example": "NA", "summary": "Upsamples the input, using nearest neighbours\u2019 pixel values", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.upsample_nearest", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " input"}, {"name": "size", "is_optional": true, "type": "int or Tuple[int, int] or Tuple[int, int, int]", "default_value": "None", "description": " output spatiasize."}, {"name": "scale_factor", "is_optional": true, "type": "int", "default_value": "None", "description": " multiplier for spatial size. Has to be an integer."}]}},
{"id": "torch.nn.functional.upsample_bilinear", "type": "function", "code": "torch.nn.functional.upsample_bilinear(input,size=None,scale_factor=None)", "example": "NA", "summary": "Upsamples the input, using bilinear upsampling", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.functional.upsample_bilinear", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " input"}, {"name": "size", "is_optional": true, "type": "int or Tuple[int, int]", "default_value": "None", "description": " output spatial size."}, {"name": "scale_factor", "is_optional": true, "type": "int or Tuple[int, int]", "default_value": "None", "description": " multiplier for spatial size"}]}},
{"id": "torch.nn.functional.grid_sample", "type": "function", "code": "torch.nn.functional.grid_sample(input,grid,mode='bilinear',padding_mode='zeros',align_corners=None)", "example": "NA", "summary": "Given an input and a flow-field grid, computes the output using input values and pixel locations from grid", "returns": "output Tensor", "shape": "NA", "code-info": {"name": "torch.nn.functional.grid_sample", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " input of shape (N,C,Hin,Win(N, C, H_\\text{in}, W_\\text{in}(N,C,Hin\u200b,Win\u200b (4-D caseor (N,C,Din,Hin,Win(N, C, D_\\text{in}, H_\\text{in}, W_\\text{in}(N,C,Din\u200b,Hin\u200b,Win\u200b (5-D case"}, {"name": "grid", "is_optional": false, "type": "Tensor", "description": " flow-field of shape (N,Hout,Wout,2(N, H_\\text{out}, W_\\text{out}, 2(N,Hout\u200b,Wout\u200b,2 (4-D caseor (N,Dout,Hout,Wout,3(N, D_\\text{out}, H_\\text{out}, W_\\text{out}, 3(N,Dout\u200b,Hout\u200b,Wout\u200b,3 (5-D case"}, {"name": "mode", "is_optional": true, "type": "string", "default_value": "'bilinear'", "description": " interpolation mode to calculate output values'bilinear' | 'nearest'. Default"}, {"name": "padding_mode", "is_optional": true, "type": "string", "default_value": "'zeros'", "description": " padding mode for outside grid values'zeros' | 'border' | 'reflection'. Default"}, {"name": "align_corners", "is_optional": true, "type": "int", "default_value": "None", "description": " Geometrically, we consider the pixels of theinput  as squares rather than points.If set to True, the extrema (-1 and 1 are considered as referringto the center points of the input\u2019s corner pixels. If set to False, theyare instead considered as referring to the corner points of the input\u2019s cornerpixels, making the sampling more resolution agnostic.This option parallels the align_corners option ininterpolate(, and so whichever option is used hereshould also be used there to resize the input image before grid sampling.Default"}]}},
{"id": "torch.randint_like", "type": "function", "code": "torch.randint_like(input,low=0,high,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "NA", "summary": "Returns a tensor with the same shape as Tensor input filled with random integers generated uniformly between low (inclusive) and high (exclusive)", "returns": null, "shape": "NA", "code-info": {"name": "torch.randint_like", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the size of input will determine size of the output tensor."}, {"name": "low", "is_optional": true, "type": "int", "default_value": "0", "description": " Lowest integer to be drawn from the distribution. Default"}, {"name": "high", "is_optional": false, "type": "int", "description": " One above the highest integer to be drawn from the distribution."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned Tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.randn", "type": "function", "code": "torch.randn(*size,out=None,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.randn(4) tensor([-2.1436,  0.9966,  2.3426, -0.6366])  torch.randn(2, 3) tensor([[ 1.5954,  2.8929, -1.0923],         [ 1.1719, -0.4709, -0.1996]])   ", "summary": "Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 (also called the standard normal distribution)", "returns": null, "shape": "NA", "code-info": {"name": "torch.randn", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "int...", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.randn_like", "type": "function", "code": "torch.randn_like(input,dtype=None,layout=None,device=None,requires_grad=False)", "example": "NA", "summary": "Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1", "returns": null, "shape": "NA", "code-info": {"name": "torch.randn_like", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the size of input will determine size of the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned Tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "None", "description": " the desired layout of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.randperm", "type": "function", "code": "torch.randperm(n,out=None,dtype=torch.int64,layout=torch.strided,device=None,requires_grad=False)", "example": "  torch.randperm(4) tensor([2, 1, 0, 3])   ", "summary": "Returns a random permutation of integers from 0 to n - 1", "returns": null, "shape": "NA", "code-info": {"name": "torch.randperm", "parameters": [{"name": "n", "is_optional": false, "type": "int", "description": " the upper bound (exclusive"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "torch.int64", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned Tensor.Default"}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.distributions.transformed_distribution.TransformedDistribution.support", "type": "method", "code": "torch.distributions.transformed_distribution.TransformedDistribution.support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.support", "parameters": []}},
{"id": "torch.distributions.uniform.Uniform.cdf", "type": "method", "code": "torch.distributions.uniform.Uniform.cdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.cdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.uniform.Uniform.entropy", "type": "method", "code": "torch.distributions.uniform.Uniform.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.entropy", "parameters": []}},
{"id": "torch.distributions.uniform.Uniform.expand", "type": "method", "code": "torch.distributions.uniform.Uniform.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.uniform.Uniform.icdf", "type": "method", "code": "torch.distributions.uniform.Uniform.icdf(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.icdf", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.uniform.Uniform.log_prob", "type": "method", "code": "torch.distributions.uniform.Uniform.log_prob(value)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.log_prob", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.uniform.Uniform.mean", "type": "method", "code": "torch.distributions.uniform.Uniform.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.mean", "parameters": []}},
{"id": "torch.distributions.uniform.Uniform.rsample", "type": "method", "code": "torch.distributions.uniform.Uniform.rsample(sample_shape=torch.Size([])", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.rsample", "parameters": [{"name": "sample_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.uniform.Uniform.stddev", "type": "method", "code": "torch.distributions.uniform.Uniform.stddev", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.stddev", "parameters": []}},
{"id": "torch.distributions.uniform.Uniform.support", "type": "method", "code": "torch.distributions.uniform.Uniform.support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.support", "parameters": []}},
{"id": "torch.distributions.uniform.Uniform.variance", "type": "method", "code": "torch.distributions.uniform.Uniform.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.variance", "parameters": []}},
{"id": "torch.distributions.weibull.Weibull.entropy", "type": "method", "code": "torch.distributions.weibull.Weibull.entropy()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.weibull.Weibull.entropy", "parameters": []}},
{"id": "torch.distributions.weibull.Weibull.expand", "type": "method", "code": "torch.distributions.weibull.Weibull.expand(batch_shape,_instance=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.weibull.Weibull.expand", "parameters": [{"name": "batch_shape", "is_optional": false, "type": "others", "description": ""}, {"name": "_instance", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.parallel.DistributedDataParallel.no_sync", "type": "method", "code": "torch.nn.parallel.DistributedDataParallel.no_sync()", "example": "  ddp = torch.nn.DistributedDataParallel(model, pg)  with ddp.no_sync(): ...   for input in inputs: ...     ddp(input).backward()  # no synchronization, accumulate grads ... ddp(another_input).backward()  # synchronize grads   ", "summary": "A context manager to disable gradient synchronizations across DDP processes", "returns": [], "shape": "", "code-info": {"name": "torch.nn.parallel.DistributedDataParallel.no_sync", "parameters": []}},
{"id": "torch.nn.utils.prune.BasePruningMethod.apply", "type": "method", "code": "torch.nn.utils.prune.BasePruningMethod.apply(module,name,*args,**kwargs)", "example": "NA", "summary": "Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.BasePruningMethod.apply", "parameters": []}},
{"id": "torch.nn.utils.prune.BasePruningMethod.apply_mask", "type": "method", "code": "torch.nn.utils.prune.BasePruningMethod.apply_mask(module)", "example": "NA", "summary": "Simply handles the multiplication between the parameter being pruned and the generated mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.BasePruningMethod.apply_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.BasePruningMethod.compute_mask", "type": "method", "code": "torch.nn.utils.prune.BasePruningMethod.compute_mask(t,default_mask)", "example": "NA", "summary": "Computes and returns a mask for the input tensor t", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.BasePruningMethod.compute_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.BasePruningMethod.prune", "type": "method", "code": "torch.nn.utils.prune.BasePruningMethod.prune(t,default_mask=None)", "example": "NA", "summary": "Computes and returns a pruned version of input tensor t according to the pruning rule specified in compute_mask()", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.BasePruningMethod.prune", "parameters": []}},
{"id": "torch.nn.utils.prune.BasePruningMethod.remove", "type": "method", "code": "torch.nn.utils.prune.BasePruningMethod.remove(module)", "example": "NA", "summary": "Removes the pruning reparameterization from a module", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.BasePruningMethod.remove", "parameters": []}},
{"id": "torch.nn.utils.prune.PruningContainer.add_pruning_method", "type": "method", "code": "torch.nn.utils.prune.PruningContainer.add_pruning_method(method)", "example": "NA", "summary": "Adds a child pruning method to the container", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.add_pruning_method", "parameters": []}},
{"id": "torch.nn.utils.prune.PruningContainer.apply", "type": "method", "code": "torch.nn.utils.prune.PruningContainer.apply(module,name,*args,**kwargs)", "example": "NA", "summary": "Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.apply", "parameters": []}},
{"id": "torch.Tensor.masked_select", "type": "method", "code": "torch.Tensor.masked_select(mask)", "example": "NA", "summary": "See torch.masked_select() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.masked_select", "parameters": [{"name": "mask", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.matmul", "type": "method", "code": "torch.Tensor.matmul(tensor2)", "example": "NA", "summary": "See torch.matmul() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.matmul", "parameters": [{"name": "tensor2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.matrix_power", "type": "method", "code": "torch.Tensor.matrix_power(n)", "example": "NA", "summary": "See torch.matrix_power() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.matrix_power", "parameters": [{"name": "n", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.max", "type": "method", "code": "torch.Tensor.max(dim=None,keepdim=False)", "example": "NA", "summary": "See torch.max() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.max", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.mean", "type": "method", "code": "torch.Tensor.mean(dim=None,keepdim=False)", "example": "NA", "summary": "See torch.mean() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.mean", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.median", "type": "method", "code": "torch.Tensor.median(dim=None,keepdim=False)", "example": "NA", "summary": "See torch.median() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.median", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.min", "type": "method", "code": "torch.Tensor.min(dim=None,keepdim=False)", "example": "NA", "summary": "See torch.min() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.min", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.mm", "type": "method", "code": "torch.Tensor.mm(mat2)", "example": "NA", "summary": "See torch.mm() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.mm", "parameters": [{"name": "mat2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.mode", "type": "method", "code": "torch.Tensor.mode(dim=None,keepdim=False)", "example": "NA", "summary": "See torch.mode() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.mode", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.mul", "type": "method", "code": "torch.Tensor.mul(value)", "example": "NA", "summary": "See torch.mul() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.mul", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.mul_", "type": "method", "code": "torch.Tensor.mul_(value)", "example": "NA", "summary": "In-place version of mul() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.mul_", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.multinomial", "type": "method", "code": "torch.Tensor.multinomial(num_samples,replacement=False,*,generator=None)", "example": "NA", "summary": "See torch.multinomial() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.multinomial", "parameters": [{"name": "num_samples", "is_optional": false, "type": "others", "description": ""}, {"name": "replacement", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.functional.affine_grid", "type": "function", "code": "torch.nn.functional.affine_grid(theta,size,align_corners=None)", "example": " torch.Size((32, 3, 24, 24)) align_corners (bool, optional) \u2013 if True, consider -1 and 1 to refer to the centers of the corner pixels rather than the image corners. Refer to grid_sample() for a more complete description. A grid generated by affine_grid() should be passed to grid_sample() with the same setting for this option. Default: False   Returns output Tensor of size (N\u00d7H\u00d7W\u00d72N \\times H \\times W \\times 2N\u00d7H\u00d7W\u00d72  )  Return type output (Tensor)    Warning When align_corners = True, the grid positions depend on the pixel size relative to the input image size, and so the locations sampled by grid_sample() will differ for the same input given at different resolutions (that is, after being upsampled or downsampled). The default behavior up to version 1.2.0 was align_corners = True. Since then, the default behavior has been changed to align_corners = False, in order to bring it in line with the default for interpolate().   Warning When align_corners = True, 2D affine transforms on 1D data and 3D affine transforms on 2D data (that is, when one of the spatial dimensions has unit size) are ill-defined, and not an intended use case. This is not a problem when align_corners = False. Up to version 1.2.0, all grid points along a unit dimension were considered arbitrarily to be at -1. From version 1.3.0, under align_corners = True all grid points along a unit dimension are condsidered to be at `0 (the center of the input image).  ", "summary": "Generates a 2D or 3D flow field (sampling grid), given a batch of affine matrices theta", "returns": "output Tensor of size (N\u00d7H\u00d7W\u00d72N \\times H \\times W \\times 2N\u00d7H\u00d7W\u00d72)", "shape": "NA", "code-info": {"name": "torch.nn.functional.affine_grid", "parameters": [{"name": "theta", "is_optional": false, "type": "Tensor", "description": " input batch of affine matrices with shape(N\u00d72\u00d73N \\times 2 \\times 3N\u00d72\u00d73 for 2D or(N\u00d73\u00d74N \\times 3 \\times 4N\u00d73\u00d74 for 3D"}, {"name": "size", "is_optional": false, "type": "torch.Size", "description": " the target output image size.(N\u00d7C\u00d7H\u00d7WN \\times C \\times H \\times WN\u00d7C\u00d7H\u00d7W for 2D orN\u00d7C\u00d7D\u00d7H\u00d7WN \\times C \\times D \\times H \\times WN\u00d7C\u00d7D\u00d7H\u00d7W for 3DExample"}, {"name": "align_corners", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " if True, consider -1 and 1to refer to the centers of the corner pixels rather than the image corners.Refer to grid_sample( for a more complete description.A grid generated by affine_grid( should be passed to grid_sample(with the same setting for this option.Default"}]}},
{"id": "torch.nn.parallel.data_parallel", "type": "function", "code": "torch.nn.parallel.data_parallel(module,inputs,device_ids=None,output_device=None,dim=0,module_kwargs=None)", "example": "NA", "summary": "Evaluates module(input) in parallel across the GPUs given in device_ids", "returns": "a Tensor containing the result of module(input) located onoutput_device", "shape": "NA", "code-info": {"name": "torch.nn.parallel.data_parallel", "parameters": [{"name": "module", "is_optional": false, "type": "Module", "description": " the module to evaluate in parallel"}, {"name": "inputs", "is_optional": false, "type": "Tensor", "description": " inputs to the module"}, {"name": "device_ids", "is_optional": true, "type": "list of int or torch.device", "default_value": "None", "description": " GPU ids on which to replicate module"}, {"name": "output_device", "is_optional": true, "type": "list of int or torch.device", "default_value": "None", "description": " GPU location of the output  Use -1 to indicate the CPU.(default"}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "module_kwargs", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.save", "type": "function", "code": "torch.save(obj,f,pickle_module=&lt;module'pickle'from'/opt/conda/lib/python3.6/pickle.py'&gt;,pickle_protocol=2,_use_new_zipfile_serialization=False)", "example": " # Save to file\n x = torch.tensor([0, 1, 2, 3, 4])\n torch.save(x, 'tensor.pt')\n # Save to io.BytesIO buffer\n buffer = io.BytesIO()\n torch.save(x, buffer)\n\n", "summary": "Saves an object to a disk file", "returns": null, "shape": "NA", "code-info": {"name": "torch.save", "parameters": [{"name": "obj", "is_optional": false, "type": "obj : saved objec", "description": " saved object"}, {"name": "f", "is_optional": false, "type": "string", "description": " a file-like object (has to implement write and flush or a stringcontaining a file name"}, {"name": "pickle_module", "is_optional": true, "type": "pickle_module : module used for pickling metadata and object", "default_value": "&lt;module'pickle'from'/opt/conda/lib/python3.6/pickle.py'&gt;", "description": " module used for pickling metadata and objects"}, {"name": "pickle_protocol", "is_optional": true, "type": "int", "default_value": "2", "description": " can be specified to override the default protocol"}, {"name": "_use_new_zipfile_serialization", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.load", "type": "function", "code": "torch.load(f,map_location=None,pickle_module=&lt;module'pickle'from'/opt/conda/lib/python3.6/pickle.py'&gt;,**pickle_load_args)", "example": " torch.load('tensors.pt')\n# Load all tensors onto the CPU\n torch.load('tensors.pt', map_location=torch.device('cpu'))\n# Load all tensors onto the CPU, using a function\n torch.load('tensors.pt', map_location=lambda storage, loc: storage)\n# Load all tensors onto GPU 1\n torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1))\n# Map tensors from GPU 1 to GPU 0\n torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'})\n# Load tensor from io.BytesIO object\n with open('tensor.pt', 'rb') as f:\n        buffer = io.BytesIO(f.read())\n torch.load(buffer)\n# Load a module with 'ascii' encoding for unpickling\n torch.load('module.pt', encoding='ascii')\n\n", "summary": "Loads an object saved with torch.save() from a file", "returns": null, "shape": "NA", "code-info": {"name": "torch.load", "parameters": [{"name": "f", "is_optional": false, "type": "has to implement read(", "description": " a file-like object (has to implement read(, "}, {"name": "map_location", "is_optional": true, "type": "map_location : a function, torch.device, string or a dict specifying how to remap storagelocation", "default_value": "None", "description": " a function, torch.device, string or a dict specifying how to remap storagelocations"}, {"name": "pickle_module", "is_optional": true, "type": "has tomatch the pickle_module used to serialize file", "default_value": "&lt;module'pickle'from'/opt/conda/lib/python3.6/pickle.py'&gt;", "description": " module used for unpickling metadata and objects (has tomatch the pickle_module used to serialize file"}, {"name": "**pickle_load_args", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.weibull.Weibull.mean", "type": "method", "code": "torch.distributions.weibull.Weibull.mean", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.weibull.Weibull.mean", "parameters": []}},
{"id": "torch.distributions.weibull.Weibull.variance", "type": "method", "code": "torch.distributions.weibull.Weibull.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.weibull.Weibull.variance", "parameters": []}},
{"id": "torch.distributions.transforms.Transform.inv", "type": "method", "code": "torch.distributions.transforms.Transform.inv", "example": "NA", "summary": "Returns the inverse Transform of this transform", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.Transform.inv", "parameters": []}},
{"id": "torch.distributions.transforms.Transform.sign", "type": "method", "code": "torch.distributions.transforms.Transform.sign", "example": "NA", "summary": "Returns the sign of the determinant of the Jacobian, if applicable", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.Transform.sign", "parameters": []}},
{"id": "torch.distributions.transforms.Transform.log_abs_det_jacobian", "type": "method", "code": "torch.distributions.transforms.Transform.log_abs_det_jacobian(x,y)", "example": "NA", "summary": "Computes the log det jacobian log |dy/dx| given input and output", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.Transform.log_abs_det_jacobian", "parameters": [{"name": "x", "is_optional": false, "type": "others", "description": ""}, {"name": "y", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.constraints.Constraint.check", "type": "method", "code": "torch.distributions.constraints.Constraint.check(value)", "example": "NA", "summary": "Returns a byte tensor of sample_shape + batch_shape indicating whether each event in value satisfies this constraint", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.constraints.Constraint.check", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.constraint_registry.ConstraintRegistry.register", "type": "method", "code": "torch.distributions.constraint_registry.ConstraintRegistry.register(constraint,factory=None)", "example": "NA", "summary": "Registers a Constraint subclass in this registry", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.constraint_registry.ConstraintRegistry.register", "parameters": [{"name": "constraint", "is_optional": false, "type": "subclass of Constraint", "description": " A subclass of Constraint, ora singleton object of the desired class."}, {"name": "factory", "is_optional": true, "type": "callable", "default_value": "None", "description": " A callable that inputs a constraint object and returnsa  Transform object."}]}},
{"id": "torch.distributions.distribution.Distribution", "type": "class", "code": "torch.distributions.distribution.Distribution(batch_shape=torch.Size([])", "example": "NA", "summary": "Bases: object Distribution is the abstract base class for probability distributions", "returns": "Tensor of shape batch_shape.", "shape": "NA", "code-info": {"name": "torch.distributions.distribution.Distribution", "parameters": [{"name": "batch_shape", "is_optional": true, "type": "torch.Size", "default_value": "torch.Siz", "description": " the desired expanded size."}]}},
{"id": "torch.nn.utils.prune.PruningContainer.apply_mask", "type": "method", "code": "torch.nn.utils.prune.PruningContainer.apply_mask(module)", "example": "NA", "summary": "Simply handles the multiplication between the parameter being pruned and the generated mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.apply_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.PruningContainer.compute_mask", "type": "method", "code": "torch.nn.utils.prune.PruningContainer.compute_mask(t,default_mask)", "example": "NA", "summary": "Applies the latest method by computing the new partial masks and returning its combination with the default_mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.compute_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.PruningContainer.prune", "type": "method", "code": "torch.nn.utils.prune.PruningContainer.prune(t,default_mask=None)", "example": "NA", "summary": "Computes and returns a pruned version of input tensor t according to the pruning rule specified in compute_mask()", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.prune", "parameters": []}},
{"id": "torch.nn.utils.prune.PruningContainer.remove", "type": "method", "code": "torch.nn.utils.prune.PruningContainer.remove(module)", "example": "NA", "summary": "Removes the pruning reparameterization from a module", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer.remove", "parameters": []}},
{"id": "torch.nn.utils.prune.Identity.apply", "type": "method", "code": "torch.nn.utils.prune.Identity.apply(module,name)", "example": "NA", "summary": "Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.Identity.apply", "parameters": []}},
{"id": "torch.nn.utils.prune.Identity.apply_mask", "type": "method", "code": "torch.nn.utils.prune.Identity.apply_mask(module)", "example": "NA", "summary": "Simply handles the multiplication between the parameter being pruned and the generated mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.Identity.apply_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.Identity.prune", "type": "method", "code": "torch.nn.utils.prune.Identity.prune(t,default_mask=None)", "example": "NA", "summary": "Computes and returns a pruned version of input tensor t according to the pruning rule specified in compute_mask()", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.Identity.prune", "parameters": []}},
{"id": "torch.Tensor.mv", "type": "method", "code": "torch.Tensor.mv(vec)", "example": "NA", "summary": "See torch.mv() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.mv", "parameters": [{"name": "vec", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.mvlgamma", "type": "method", "code": "torch.Tensor.mvlgamma(p)", "example": "NA", "summary": "See torch.mvlgamma() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.mvlgamma", "parameters": [{"name": "p", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.mvlgamma_", "type": "method", "code": "torch.Tensor.mvlgamma_(p)", "example": "NA", "summary": "In-place version of mvlgamma() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.mvlgamma_", "parameters": [{"name": "p", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.narrow", "type": "method", "code": "torch.Tensor.narrow(dimension,start,length)", "example": "  x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  x.narrow(0, 0, 2) tensor([[ 1,  2,  3],         [ 4,  5,  6]])  x.narrow(1, 1, 2) tensor([[ 2,  3],         [ 5,  6],         [ 8,  9]])   ", "summary": "See torch.narrow() Example: &gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) &gt;&gt;&gt; x.narrow(0, 0, 2) tensor([[ 1,  2,  3],         [ 4,  5,  6]]) &gt;&gt;&gt; x.narrow(1, 1, 2) tensor([[ 2,  3],         [ 5,  6],         [ 8,  9]])   ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.narrow", "parameters": [{"name": "dimension", "is_optional": false, "type": "others", "description": ""}, {"name": "start", "is_optional": false, "type": "others", "description": ""}, {"name": "length", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.narrow_copy", "type": "method", "code": "torch.Tensor.narrow_copy(dimension,start,length)", "example": "NA", "summary": "Same as Tensor.narrow() except returning a copy rather than shared storage", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.narrow_copy", "parameters": [{"name": "dimension", "is_optional": false, "type": "others", "description": ""}, {"name": "start", "is_optional": false, "type": "others", "description": ""}, {"name": "length", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.ndimension", "type": "method", "code": "torch.Tensor.ndimension()", "example": "NA", "summary": "Alias for dim() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.ndimension", "parameters": []}},
{"id": "torch.Tensor.ne", "type": "method", "code": "torch.Tensor.ne(other)", "example": "NA", "summary": "See torch.ne() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.ne", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.ne_", "type": "method", "code": "torch.Tensor.ne_(other)", "example": "NA", "summary": "In-place version of ne() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.ne_", "parameters": [{"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.neg", "type": "method", "code": "torch.Tensor.neg()", "example": "NA", "summary": "See torch.neg() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.neg", "parameters": []}},
{"id": "torch.Tensor.neg_", "type": "method", "code": "torch.Tensor.neg_()", "example": "NA", "summary": "In-place version of neg() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.neg_", "parameters": []}},
{"id": "torch.Tensor.nelement", "type": "method", "code": "torch.Tensor.nelement()", "example": "NA", "summary": "Alias for numel() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.nelement", "parameters": []}},
{"id": "torch.Tensor.nonzero", "type": "method", "code": "torch.Tensor.nonzero()", "example": "NA", "summary": "See torch.nonzero() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.nonzero", "parameters": []}},
{"id": "torch.get_num_threads", "type": "function", "code": "torch.get_num_threads()", "example": "NA", "summary": "Returns the number of threads used for parallelizing CPU operations ", "returns": null, "shape": "NA", "code-info": {"name": "torch.get_num_threads", "parameters": []}},
{"id": "torch.set_num_threads", "type": "function", "code": "torch.set_num_threads(int)", "example": "NA", "summary": "Sets the number of threads used for intraop parallelism on CPU", "returns": null, "shape": "NA", "code-info": {"name": "torch.set_num_threads", "parameters": [{"name": "int", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.get_num_interop_threads", "type": "function", "code": "torch.get_num_interop_threads()", "example": "NA", "summary": "Returns the number of threads used for inter-op parallelism on CPU (e.g", "returns": null, "shape": "NA", "code-info": {"name": "torch.get_num_interop_threads", "parameters": []}},
{"id": "torch.set_num_interop_threads", "type": "function", "code": "torch.set_num_interop_threads(int)", "example": "NA", "summary": "Sets the number of threads used for interop parallelism (e.g", "returns": null, "shape": "NA", "code-info": {"name": "torch.set_num_interop_threads", "parameters": [{"name": "int", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.abs", "type": "function", "code": "torch.abs(input,out=None)", "example": "  torch.abs(torch.tensor([-1, -2, 3])) tensor([ 1,  2,  3])   ", "summary": "Computes the element-wise absolute value of the given input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.abs", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.acos", "type": "function", "code": "torch.acos(input,out=None)", "example": "  a = torch.randn(4)  a tensor([ 0.3348, -0.5889,  0.2005, -0.1584])  torch.acos(a) tensor([ 1.2294,  2.2004,  1.3690,  1.7298])   ", "summary": "Returns a new tensor with the arccosine  of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.acos", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.add", "type": "function", "code": "torch.add()", "example": "  a = torch.randn(4)  a tensor([ 0.0202,  1.0985,  1.3506, -0.6056])  torch.add(a, 20) tensor([ 20.0202,  21.0985,  21.3506,  19.3944])     torch.add(input, alpha=1, other, out=None)   Each element of the tensor other is multiplied by the scalar alpha and added to each element of the tensor input. The resulting tensor is returned. The shapes of input and other must be broadcastable.  out=input+alpha\u00d7other\\text{out} = \\text{input} + \\text{alpha} \\times \\text{other}  out=input+alpha\u00d7other  If other is of type FloatTensor or DoubleTensor, alpha must be a real number, otherwise it should be an integer.  Parameters  input (Tensor) \u2013 the first input tensor alpha (Number) \u2013 the scalar multiplier for other other (Tensor) \u2013 the second input tensor   Keyword Arguments out (Tensor, optional) \u2013 the output tensor.   ", "summary": "  torch.add(input, other, out=None)   Adds the scalar other to each element of the input input and returns a new resulting tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.add", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input,other,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,alpha=1,other,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.exp_family.ExponentialFamily", "type": "class", "code": "torch.distributions.exp_family.ExponentialFamily(batch_shape=torch.Size([])", "example": "NA", "summary": "Bases: torch.distributions.distribution.Distribution ExponentialFamily is the abstract base class for probability distributions belonging to an exponential family, whose probability mass/density function has the form is defined below  pF(x;\u03b8)=exp\u2061(\u27e8t(x),\u03b8\u27e9\u2212F(\u03b8)+k(x))p_{F}(x; \\theta) = \\exp(\\langle t(x), \\theta\\rangle - F(\\theta) + k(x))pF\u200b(x;\u03b8)=exp(\u27e8t(x),\u03b8\u27e9\u2212F(\u03b8)+k(x))  where \u03b8\\theta\u03b8   denotes the natural parameters, t(x)t(x)t(x)   denotes the sufficient statistic, F(\u03b8)F(\\theta)F(\u03b8)   is the log normalizer function for a given family and k(x)k(x)k(x)   is the carrier measure", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exp_family.ExponentialFamily", "parameters": [{"name": "batch_shape", "is_optional": true, "type": "others", "default_value": "torch.Siz", "description": ""}]}},
{"id": "torch.distributions.bernoulli.Bernoulli", "type": "class", "code": "torch.distributions.bernoulli.Bernoulli(probs=None,logits=None,validate_args=None)", "example": "  m = Bernoulli(torch.tensor([0.3]))  m.sample()  # 30% chance 1; 70% chance 0 tensor([ 0.])    Parameters  probs (Number, Tensor) \u2013 the probability of sampling 1 logits (Number, Tensor) \u2013 the log-odds of sampling 1      arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)}     entropy()      enumerate_support(expand=True)      expand(batch_shape, _instance=None)      has_enumerate_support = True     log_prob(value)      logits      property mean     property param_shape     probs      sample(sample_shape=torch.Size([]))      support = Boolean()     property variance   ", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily Creates a Bernoulli distribution parameterized by probs or logits (but not both)", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli", "parameters": [{"name": "probs", "is_optional": true, "type": "Number, Tensor", "default_value": "None", "description": " the probability of sampling 1"}, {"name": "logits", "is_optional": true, "type": "Number, Tensor", "default_value": "None", "description": " the log-odds of sampling 1"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.bernoulli.Bernoulli.arg_constraints", "type": "attribute", "code": "torch.distributions.bernoulli.Bernoulli.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.arg_constraints", "parameters": []}},
{"id": "torch.distributions.bernoulli.Bernoulli.has_enumerate_support", "type": "attribute", "code": "torch.distributions.bernoulli.Bernoulli.has_enumerate_support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.has_enumerate_support", "parameters": []}},
{"id": "torch.distributions.bernoulli.Bernoulli.logits", "type": "attribute", "code": "torch.distributions.bernoulli.Bernoulli.logits", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.logits", "parameters": []}},
{"id": "torch.distributions.bernoulli.Bernoulli.probs", "type": "attribute", "code": "torch.distributions.bernoulli.Bernoulli.probs", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.probs", "parameters": []}},
{"id": "torch.distributions.bernoulli.Bernoulli.support", "type": "attribute", "code": "torch.distributions.bernoulli.Bernoulli.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.bernoulli.Bernoulli.support", "parameters": []}},
{"id": "torch.distributions.beta.Beta", "type": "class", "code": "torch.distributions.beta.Beta(concentration1,concentration0,validate_args=None)", "example": "  m = Beta(torch.tensor([0.5]), torch.tensor([0.5]))  m.sample()  # Beta distributed with concentration concentration1 and concentration0 tensor([ 0.1046])    Parameters  concentration1 (python:float or Tensor) \u2013 1st concentration parameter of the distribution (often referred to as alpha) concentration0 (python:float or Tensor) \u2013 2nd concentration parameter of the distribution (often referred to as beta)      arg_constraints = {'concentration0': GreaterThan(lower_bound=0.0), 'concentration1': GreaterThan(lower_bound=0.0)}     property concentration0     property concentration1     entropy()      expand(batch_shape, _instance=None)      has_rsample = True     log_prob(value)      property mean     rsample(sample_shape=())      support = Interval(lower_bound=0.0, upper_bound=1.0)     property variance   ", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily Beta distribution parameterized by concentration1 and concentration0", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta", "parameters": [{"name": "concentration1", "is_optional": false, "type": "float or Tensor", "description": " 1st concentration parameter of the distribution(often referred to as alpha"}, {"name": "concentration0", "is_optional": false, "type": "float or Tensor", "description": " 2nd concentration parameter of the distribution(often referred to as beta"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.beta.Beta.arg_constraints", "type": "attribute", "code": "torch.distributions.beta.Beta.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.nn.utils.prune.Identity.remove", "type": "method", "code": "torch.nn.utils.prune.Identity.remove(module)", "example": "NA", "summary": "Removes the pruning reparameterization from a module", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.Identity.remove", "parameters": []}},
{"id": "torch.nn.utils.prune.RandomUnstructured.apply", "type": "method", "code": "torch.nn.utils.prune.RandomUnstructured.apply(module,name,amount)", "example": "NA", "summary": "Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.RandomUnstructured.apply", "parameters": []}},
{"id": "torch.nn.utils.prune.RandomUnstructured.apply_mask", "type": "method", "code": "torch.nn.utils.prune.RandomUnstructured.apply_mask(module)", "example": "NA", "summary": "Simply handles the multiplication between the parameter being pruned and the generated mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.RandomUnstructured.apply_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.RandomUnstructured.prune", "type": "method", "code": "torch.nn.utils.prune.RandomUnstructured.prune(t,default_mask=None)", "example": "NA", "summary": "Computes and returns a pruned version of input tensor t according to the pruning rule specified in compute_mask()", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.RandomUnstructured.prune", "parameters": []}},
{"id": "torch.nn.utils.prune.RandomUnstructured.remove", "type": "method", "code": "torch.nn.utils.prune.RandomUnstructured.remove(module)", "example": "NA", "summary": "Removes the pruning reparameterization from a module", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.RandomUnstructured.remove", "parameters": []}},
{"id": "torch.nn.utils.prune.L1Unstructured.apply", "type": "method", "code": "torch.nn.utils.prune.L1Unstructured.apply(module,name,amount)", "example": "NA", "summary": "Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.L1Unstructured.apply", "parameters": []}},
{"id": "torch.nn.utils.prune.L1Unstructured.apply_mask", "type": "method", "code": "torch.nn.utils.prune.L1Unstructured.apply_mask(module)", "example": "NA", "summary": "Simply handles the multiplication between the parameter being pruned and the generated mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.L1Unstructured.apply_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.L1Unstructured.prune", "type": "method", "code": "torch.nn.utils.prune.L1Unstructured.prune(t,default_mask=None)", "example": "NA", "summary": "Computes and returns a pruned version of input tensor t according to the pruning rule specified in compute_mask()", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.L1Unstructured.prune", "parameters": []}},
{"id": "torch.nn.utils.prune.L1Unstructured.remove", "type": "method", "code": "torch.nn.utils.prune.L1Unstructured.remove(module)", "example": "NA", "summary": "Removes the pruning reparameterization from a module", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.L1Unstructured.remove", "parameters": []}},
{"id": "torch.Tensor.norm", "type": "method", "code": "torch.Tensor.norm(p='fro',dim=None,keepdim=False,dtype=None)", "example": "NA", "summary": "See torch.norm() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.norm", "parameters": [{"name": "p", "is_optional": true, "type": "string", "default_value": "'fro'", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.normal_", "type": "method", "code": "torch.Tensor.normal_(mean=0,std=1,*,generator=None)", "example": "NA", "summary": "Fills self tensor with elements samples from the normal distribution parameterized by mean and std", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.normal_", "parameters": [{"name": "mean", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "std", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.numel", "type": "method", "code": "torch.Tensor.numel()", "example": "NA", "summary": "See torch.numel() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.numel", "parameters": []}},
{"id": "torch.Tensor.numpy", "type": "method", "code": "torch.Tensor.numpy()", "example": "NA", "summary": "Returns self tensor as a NumPy ndarray", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.numpy", "parameters": []}},
{"id": "torch.Tensor.orgqr", "type": "method", "code": "torch.Tensor.orgqr(input2)", "example": "NA", "summary": "See torch.orgqr() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.orgqr", "parameters": [{"name": "input2", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.ormqr", "type": "method", "code": "torch.Tensor.ormqr(input2,input3,left=True,transpose=False)", "example": "NA", "summary": "See torch.ormqr() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.ormqr", "parameters": [{"name": "input2", "is_optional": false, "type": "others", "description": ""}, {"name": "input3", "is_optional": false, "type": "others", "description": ""}, {"name": "left", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "transpose", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.permute", "type": "method", "code": "torch.Tensor.permute(*dims)", "example": " x = torch.randn(2, 3, 5)\n x.size()\ntorch.Size([2, 3, 5])\n x.permute(2, 0, 1).size()\ntorch.Size([5, 2, 3])\n\n", "summary": "Permute the dimensions of this tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.permute", "parameters": [{"name": "*dims", "is_optional": false, "type": "int...", "description": " The desired ordering of dimensions"}]}},
{"id": "torch.Tensor.pin_memory", "type": "method", "code": "torch.Tensor.pin_memory()", "example": "NA", "summary": "Copies the tensor to pinned memory, if it\u2019s not already pinned", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.pin_memory", "parameters": []}},
{"id": "torch.Tensor.pinverse", "type": "method", "code": "torch.Tensor.pinverse()", "example": "NA", "summary": "See torch.pinverse() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.pinverse", "parameters": []}},
{"id": "torch.Tensor.polygamma", "type": "method", "code": "torch.Tensor.polygamma(n)", "example": "NA", "summary": "See torch.polygamma() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.polygamma", "parameters": [{"name": "n", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.addcdiv", "type": "function", "code": "torch.addcdiv(input,value=1,tensor1,tensor2,out=None)", "example": "  t = torch.randn(1, 3)  t1 = torch.randn(3, 1)  t2 = torch.randn(1, 3)  torch.addcdiv(t, 0.1, t1, t2) tensor([[-0.2312, -3.6496,  0.1312],         [-1.0428,  3.4292, -0.1030],         [-0.5369, -0.9829,  0.0430]])   ", "summary": "Performs the element-wise division of tensor1 by tensor2, multiply the result by the scalar value and add it to input", "returns": null, "shape": "NA", "code-info": {"name": "torch.addcdiv", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to be added"}, {"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for tensor1/tensor2\\text{tensor1} / \\text{tensor2}tensor1/tensor2"}, {"name": "tensor1", "is_optional": false, "type": "Number, optional", "description": " the numerator tensor"}, {"name": "tensor2", "is_optional": false, "type": "Number, optional", "description": " the denominator tensor"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.addcmul", "type": "function", "code": "torch.addcmul(input,value=1,tensor1,tensor2,out=None)", "example": "  t = torch.randn(1, 3)  t1 = torch.randn(3, 1)  t2 = torch.randn(1, 3)  torch.addcmul(t, 0.1, t1, t2) tensor([[-0.8635, -0.6391,  1.6174],         [-0.7617, -0.5879,  1.7388],         [-0.8353, -0.6249,  1.6511]])   ", "summary": "Performs the element-wise multiplication of tensor1 by tensor2, multiply the result by the scalar value and add it to input", "returns": null, "shape": "NA", "code-info": {"name": "torch.addcmul", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to be added"}, {"name": "value", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for tensor1.\u2217tensor2tensor1 .* tensor2tensor1.\u2217tensor2"}, {"name": "tensor1", "is_optional": false, "type": "Number, optional", "description": " the tensor to be multiplied"}, {"name": "tensor2", "is_optional": false, "type": "Number, optional", "description": " the tensor to be multiplied"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.angle", "type": "function", "code": "torch.angle(input,out=None)", "example": "  torch.angle(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))*180/3.14159 tensor([ 135.,  135,  -45])   ", "summary": "Computes the element-wise angle (in radians) of the given input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.angle", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.asin", "type": "function", "code": "torch.asin(input,out=None)", "example": "  a = torch.randn(4)  a tensor([-0.5962,  1.4985, -0.4396,  1.4525])  torch.asin(a) tensor([-0.6387,     nan, -0.4552,     nan])   ", "summary": "Returns a new tensor with the arcsine  of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.asin", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.atan", "type": "function", "code": "torch.atan(input,out=None)", "example": "  a = torch.randn(4)  a tensor([ 0.2341,  0.2539, -0.6256, -0.6448])  torch.atan(a) tensor([ 0.2299,  0.2487, -0.5591, -0.5727])   ", "summary": "Returns a new tensor with the arctangent  of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.atan", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.distributions.beta.Beta.has_rsample", "type": "attribute", "code": "torch.distributions.beta.Beta.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta.has_rsample", "parameters": []}},
{"id": "torch.distributions.beta.Beta.support", "type": "attribute", "code": "torch.distributions.beta.Beta.support(lower_bound=0.0,upper_bound=1.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.beta.Beta.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}, {"name": "upper_bound", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}]}},
{"id": "torch.distributions.binomial.Binomial", "type": "class", "code": "torch.distributions.binomial.Binomial(total_count=1,probs=None,logits=None,validate_args=None)", "example": "  m = Binomial(100, torch.tensor([0 , .2, .8, 1]))  x = m.sample() tensor([   0.,   22.,   71.,  100.])   m = Binomial(torch.tensor([[5.], [10.]]), torch.tensor([0.5, 0.8]))  x = m.sample() tensor([[ 4.,  5.],         [ 7.,  6.]])    Parameters  total_count (python:int or Tensor) \u2013 number of Bernoulli trials probs (Tensor) \u2013 Event probabilities logits (Tensor) \u2013 Event log-odds      arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0), 'total_count': IntegerGreaterThan(lower_bound=0)}     enumerate_support(expand=True)      expand(batch_shape, _instance=None)      has_enumerate_support = True     log_prob(value)      logits      property mean     property param_shape     probs      sample(sample_shape=torch.Size([]))      property support     property variance   ", "summary": "Bases: torch.distributions.distribution.Distribution Creates a Binomial distribution parameterized by total_count and either probs or logits (but not both)", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial", "parameters": [{"name": "total_count", "is_optional": true, "type": "int", "default_value": "1", "description": " number of Bernoulli trials"}, {"name": "probs", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " Event probabilities"}, {"name": "logits", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " Event log-odds"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.binomial.Binomial.arg_constraints", "type": "attribute", "code": "torch.distributions.binomial.Binomial.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.arg_constraints", "parameters": []}},
{"id": "torch.distributions.binomial.Binomial.has_enumerate_support", "type": "attribute", "code": "torch.distributions.binomial.Binomial.has_enumerate_support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.has_enumerate_support", "parameters": []}},
{"id": "torch.distributions.binomial.Binomial.logits", "type": "attribute", "code": "torch.distributions.binomial.Binomial.logits", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.logits", "parameters": []}},
{"id": "torch.distributions.binomial.Binomial.probs", "type": "attribute", "code": "torch.distributions.binomial.Binomial.probs", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.binomial.Binomial.probs", "parameters": []}},
{"id": "torch.nn.utils.prune.RandomStructured.apply", "type": "method", "code": "torch.nn.utils.prune.RandomStructured.apply(module,name,amount,dim=-1)", "example": "NA", "summary": "Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured.apply", "parameters": []}},
{"id": "torch.nn.utils.prune.RandomStructured.apply_mask", "type": "method", "code": "torch.nn.utils.prune.RandomStructured.apply_mask(module)", "example": "NA", "summary": "Simply handles the multiplication between the parameter being pruned and the generated mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured.apply_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.RandomStructured.compute_mask", "type": "method", "code": "torch.nn.utils.prune.RandomStructured.compute_mask(t,default_mask)", "example": "NA", "summary": "Computes and returns a mask for the input tensor t", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured.compute_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.RandomStructured.prune", "type": "method", "code": "torch.nn.utils.prune.RandomStructured.prune(t,default_mask=None)", "example": "NA", "summary": "Computes and returns a pruned version of input tensor t according to the pruning rule specified in compute_mask()", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured.prune", "parameters": []}},
{"id": "torch.nn.utils.prune.RandomStructured.remove", "type": "method", "code": "torch.nn.utils.prune.RandomStructured.remove(module)", "example": "NA", "summary": "Removes the pruning reparameterization from a module", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured.remove", "parameters": []}},
{"id": "torch.nn.utils.prune.LnStructured.apply", "type": "method", "code": "torch.nn.utils.prune.LnStructured.apply(module,name,amount,n,dim)", "example": "NA", "summary": "Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured.apply", "parameters": []}},
{"id": "torch.nn.utils.prune.LnStructured.apply_mask", "type": "method", "code": "torch.nn.utils.prune.LnStructured.apply_mask(module)", "example": "NA", "summary": "Simply handles the multiplication between the parameter being pruned and the generated mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured.apply_mask", "parameters": []}},
{"id": "torch.Tensor.polygamma_", "type": "method", "code": "torch.Tensor.polygamma_(n)", "example": "NA", "summary": "In-place version of polygamma() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.polygamma_", "parameters": [{"name": "n", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.pow", "type": "method", "code": "torch.Tensor.pow(exponent)", "example": "NA", "summary": "See torch.pow() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.pow", "parameters": [{"name": "exponent", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.pow_", "type": "method", "code": "torch.Tensor.pow_(exponent)", "example": "NA", "summary": "In-place version of pow() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.pow_", "parameters": [{"name": "exponent", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.prod", "type": "method", "code": "torch.Tensor.prod(dim=None,keepdim=False,dtype=None)", "example": "NA", "summary": "See torch.prod() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.prod", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.put_", "type": "method", "code": "torch.Tensor.put_(indices,tensor,accumulate=False)", "example": "  src = torch.tensor([[4, 3, 5],                         [6, 7, 8]])  src.put_(torch.tensor([1, 3]), torch.tensor([9, 10])) tensor([[  4,   9,   5],         [ 10,   7,   8]])   ", "summary": "Copies the elements from tensor into the positions specified by indices", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.put_", "parameters": [{"name": "indices", "is_optional": false, "type": "LongTensor", "description": " the indices into self"}, {"name": "tensor", "is_optional": false, "type": "Tensor", "description": " the tensor containing values to copy from"}, {"name": "accumulate", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether to accumulate into self"}]}},
{"id": "torch.Tensor.qr", "type": "method", "code": "torch.Tensor.qr(some=True)", "example": "NA", "summary": "See torch.qr() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.qr", "parameters": [{"name": "some", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.Tensor.qscheme", "type": "method", "code": "torch.Tensor.qscheme()", "example": "NA", "summary": "Returns the quantization scheme of a given QTensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.qscheme", "parameters": []}},
{"id": "torch.Tensor.q_scale", "type": "method", "code": "torch.Tensor.q_scale()", "example": "NA", "summary": "Given a Tensor quantized by linear(affine) quantization, returns the scale of the underlying quantizer()", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.q_scale", "parameters": []}},
{"id": "torch.Tensor.q_zero_point", "type": "method", "code": "torch.Tensor.q_zero_point()", "example": "NA", "summary": "Given a Tensor quantized by linear(affine) quantization, returns the zero_point of the underlying quantizer()", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.q_zero_point", "parameters": []}},
{"id": "torch.Tensor.q_per_channel_scales", "type": "method", "code": "torch.Tensor.q_per_channel_scales()", "example": "NA", "summary": "Given a Tensor quantized by linear (affine) per-channel quantization, returns a Tensor of scales of the underlying quantizer", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.q_per_channel_scales", "parameters": []}},
{"id": "torch.Tensor.q_per_channel_zero_points", "type": "method", "code": "torch.Tensor.q_per_channel_zero_points()", "example": "NA", "summary": "Given a Tensor quantized by linear (affine) per-channel quantization, returns a tensor of zero_points of the underlying quantizer", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.q_per_channel_zero_points", "parameters": []}},
{"id": "torch.Tensor.q_per_channel_axis", "type": "method", "code": "torch.Tensor.q_per_channel_axis()", "example": "NA", "summary": "Given a Tensor quantized by linear (affine) per-channel quantization, returns the index of dimension on which per-channel quantization is applied", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.q_per_channel_axis", "parameters": []}},
{"id": "torch.atan2", "type": "function", "code": "torch.atan2(input,other,out=None)", "example": "  a = torch.randn(4)  a tensor([ 0.9041,  0.0196, -0.3108, -2.4423])  torch.atan2(a, torch.randn(4)) tensor([ 0.9833,  0.0811, -1.9743, -1.4151])   ", "summary": "Element-wise arctangent of inputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200b   with consideration of the quadrant", "returns": null, "shape": "NA", "code-info": {"name": "torch.atan2", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the first input tensor"}, {"name": "other", "is_optional": false, "type": "Tensor", "description": " the second input tensor"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.bitwise_not", "type": "function", "code": "torch.bitwise_not(input,out=None)", "example": " torch.bitwise_not(torch.tensor([-1, -2, 3], dtype=torch.int8))\ntensor([ 0,  1, -4], dtype=torch.int8)\n\n", "summary": "Computes the bitwise NOT of the given input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.bitwise_not", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.bitwise_xor", "type": "function", "code": "torch.bitwise_xor(input,other,out=None)", "example": " torch.bitwise_xor(torch.tensor([-1, -2, 3], dtype=torch.int8), torch.tensor([1, 0, 3], dtype=torch.int8))\ntensor([-2, -2,  0], dtype=torch.int8)\n torch.bitwise_xor(torch.tensor([True, True, False]), torch.tensor([False, True, False]))\ntensor([ True, False, False])\n\n", "summary": "Computes the bitwise XOR of input and other", "returns": null, "shape": "NA", "code-info": {"name": "torch.bitwise_xor", "parameters": [{"name": "input", "is_optional": false, "type": "input : the first input tenso", "description": " the first input tensor"}, {"name": "other", "is_optional": false, "type": "other : the second input tenso", "description": " the second input tensor"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.ceil", "type": "function", "code": "torch.ceil(input,out=None)", "example": "  a = torch.randn(4)  a tensor([-0.6341, -1.4208, -1.0900,  0.5826])  torch.ceil(a) tensor([-0., -1., -1.,  1.])   ", "summary": "Returns a new tensor with the ceil of the elements of input, the smallest integer greater than or equal to each element", "returns": null, "shape": "NA", "code-info": {"name": "torch.ceil", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.distributions.categorical.Categorical", "type": "class", "code": "torch.distributions.categorical.Categorical(probs=None,logits=None,validate_args=None)", "example": "  m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))  m.sample()  # equal probability of 0, 1, 2, 3 tensor(3)    Parameters  probs (Tensor) \u2013 event probabilities logits (Tensor) \u2013 event log-odds      arg_constraints = {'logits': Real(), 'probs': Simplex()}     entropy()      enumerate_support(expand=True)      expand(batch_shape, _instance=None)      has_enumerate_support = True     log_prob(value)      logits      property mean     property param_shape     probs      sample(sample_shape=torch.Size([]))      property support     property variance   ", "summary": "Bases: torch.distributions.distribution.Distribution Creates a categorical distribution parameterized by either probs or logits (but not both)", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical", "parameters": [{"name": "probs", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " event probabilities"}, {"name": "logits", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " event log-odds"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.categorical.Categorical.arg_constraints", "type": "attribute", "code": "torch.distributions.categorical.Categorical.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.arg_constraints", "parameters": []}},
{"id": "torch.distributions.categorical.Categorical.has_enumerate_support", "type": "attribute", "code": "torch.distributions.categorical.Categorical.has_enumerate_support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.has_enumerate_support", "parameters": []}},
{"id": "torch.distributions.categorical.Categorical.logits", "type": "attribute", "code": "torch.distributions.categorical.Categorical.logits", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.logits", "parameters": []}},
{"id": "torch.distributions.categorical.Categorical.probs", "type": "attribute", "code": "torch.distributions.categorical.Categorical.probs", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.categorical.Categorical.probs", "parameters": []}},
{"id": "torch.distributions.cauchy.Cauchy", "type": "class", "code": "torch.distributions.cauchy.Cauchy(loc,scale,validate_args=None)", "example": "  m = Cauchy(torch.tensor([0.0]), torch.tensor([1.0]))  m.sample()  # sample from a Cauchy distribution with loc=0 and scale=1 tensor([ 2.3214])    Parameters  loc (python:float or Tensor) \u2013 mode or median of the distribution. scale (python:float or Tensor) \u2013 half width at half maximum.      arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}     cdf(value)      entropy()      expand(batch_shape, _instance=None)      has_rsample = True     icdf(value)      log_prob(value)      property mean     rsample(sample_shape=torch.Size([]))      support = Real()     property variance   ", "summary": "Bases: torch.distributions.distribution.Distribution Samples from a Cauchy (Lorentz) distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy", "parameters": [{"name": "loc", "is_optional": false, "type": "float or Tensor", "description": " mode or median of the distribution."}, {"name": "scale", "is_optional": false, "type": "float or Tensor", "description": " half width at half maximum."}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.cauchy.Cauchy.arg_constraints", "type": "attribute", "code": "torch.distributions.cauchy.Cauchy.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy.arg_constraints", "parameters": []}},
{"id": "torch.distributions.cauchy.Cauchy.has_rsample", "type": "attribute", "code": "torch.distributions.cauchy.Cauchy.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy.has_rsample", "parameters": []}},
{"id": "torch.distributions.cauchy.Cauchy.support", "type": "attribute", "code": "torch.distributions.cauchy.Cauchy.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.cauchy.Cauchy.support", "parameters": []}},
{"id": "torch.nn.utils.prune.LnStructured.compute_mask", "type": "method", "code": "torch.nn.utils.prune.LnStructured.compute_mask(t,default_mask)", "example": "NA", "summary": "Computes and returns a mask for the input tensor t", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured.compute_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.LnStructured.prune", "type": "method", "code": "torch.nn.utils.prune.LnStructured.prune(t,default_mask=None)", "example": "NA", "summary": "Computes and returns a pruned version of input tensor t according to the pruning rule specified in compute_mask()", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured.prune", "parameters": []}},
{"id": "torch.nn.utils.prune.LnStructured.remove", "type": "method", "code": "torch.nn.utils.prune.LnStructured.remove(module)", "example": "NA", "summary": "Removes the pruning reparameterization from a module", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured.remove", "parameters": []}},
{"id": "torch.nn.utils.prune.CustomFromMask.apply", "type": "method", "code": "torch.nn.utils.prune.CustomFromMask.apply(module,name,mask)", "example": "NA", "summary": "Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.CustomFromMask.apply", "parameters": []}},
{"id": "torch.nn.utils.prune.CustomFromMask.apply_mask", "type": "method", "code": "torch.nn.utils.prune.CustomFromMask.apply_mask(module)", "example": "NA", "summary": "Simply handles the multiplication between the parameter being pruned and the generated mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.CustomFromMask.apply_mask", "parameters": []}},
{"id": "torch.nn.utils.prune.CustomFromMask.prune", "type": "method", "code": "torch.nn.utils.prune.CustomFromMask.prune(t,default_mask=None)", "example": "NA", "summary": "Computes and returns a pruned version of input tensor t according to the pruning rule specified in compute_mask()", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.CustomFromMask.prune", "parameters": []}},
{"id": "torch.nn.utils.prune.CustomFromMask.remove", "type": "method", "code": "torch.nn.utils.prune.CustomFromMask.remove(module)", "example": "NA", "summary": "Removes the pruning reparameterization from a module", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.CustomFromMask.remove", "parameters": []}},
{"id": "torch.Tensor.random_", "type": "method", "code": "torch.Tensor.random_(from=0,to=None,*,generator=None)", "example": "NA", "summary": "Fills self tensor with numbers sampled from the discrete uniform distribution over [from, to - 1]", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.random_", "parameters": [{"name": "from", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "to", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "generator", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.reciprocal", "type": "method", "code": "torch.Tensor.reciprocal()", "example": "NA", "summary": "See torch.reciprocal() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.reciprocal", "parameters": []}},
{"id": "torch.Tensor.reciprocal_", "type": "method", "code": "torch.Tensor.reciprocal_()", "example": "NA", "summary": "In-place version of reciprocal() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.reciprocal_", "parameters": []}},
{"id": "torch.Tensor.record_stream", "type": "method", "code": "torch.Tensor.record_stream(stream)", "example": "NA", "summary": "Ensures that the tensor memory is not reused for another tensor until all current work queued on stream are complete", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.record_stream", "parameters": [{"name": "stream", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "NA", "type": "method", "code": "NA(hook)", "example": "  v = torch.tensor([0., 0., 0.], requires_grad=True)  h = v.register_hook(lambda grad: grad * 2)  # double the gradient  v.backward(torch.tensor([1., 2., 3.]))  v.grad   2  4  6 [torch.FloatTensor of size (3,)]   h.remove()  # removes the hook   ", "summary": "Registers a backward hook", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "hook", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.remainder", "type": "method", "code": "torch.Tensor.remainder(divisor)", "example": "NA", "summary": "See torch.remainder() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.remainder", "parameters": [{"name": "divisor", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.remainder_", "type": "method", "code": "torch.Tensor.remainder_(divisor)", "example": "NA", "summary": "In-place version of remainder() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.remainder_", "parameters": [{"name": "divisor", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.real", "type": "method", "code": "torch.Tensor.real()", "example": "NA", "summary": "See torch.real() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.real", "parameters": []}},
{"id": "torch.Tensor.renorm", "type": "method", "code": "torch.Tensor.renorm(p,dim,maxnorm)", "example": "NA", "summary": "See torch.renorm() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.renorm", "parameters": [{"name": "p", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "maxnorm", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.clamp", "type": "function", "code": "torch.clamp(input,min,max,out=None)", "example": "  a = torch.randn(4)  a tensor([-1.7120,  0.1734, -0.0478, -0.0922])  torch.clamp(a, min=-0.5, max=0.5) tensor([-0.5000,  0.1734, -0.0478, -0.0922])     torch.clamp(input, *, min, out=None) \u2192 Tensor   Clamps all elements in input to be larger or equal min. If input is of type FloatTensor or DoubleTensor, value should be a real number, otherwise it should be an integer.  Parameters  input (Tensor) \u2013 the input tensor. value (Number) \u2013 minimal value of each element in the output out (Tensor, optional) \u2013 the output tensor.    ", "summary": "Clamp all elements in input into the range [ min, max ] and return a resulting tensor:  yi={minif\u00a0xi&lt;minxiif\u00a0min\u2264xi\u2264maxmaxif\u00a0xi&gt;maxy_i = \\begin{cases}     \\text{min} &amp; \\text{if } x_i &lt; \\text{min} \\\\     x_i &amp; \\text{if } \\text{min} \\leq x_i \\leq \\text{max} \\\\     \\text{max} &amp; \\text{if } x_i &gt; \\text{max} \\end{cases}  yi\u200b=\u23a9\u23aa\u23aa\u23a8\u23aa\u23aa\u23a7\u200bminxi\u200bmax\u200bif\u00a0xi\u200b&lt;minif\u00a0min\u2264xi\u200b\u2264maxif\u00a0xi\u200b&gt;max\u200b  If input is of type FloatTensor or DoubleTensor, args min and max must be real numbers, otherwise they should be integers", "returns": null, "shape": "NA", "code-info": {"name": "torch.clamp", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "min", "is_optional": false, "type": "Number", "description": " lower-bound of the range to be clamped to"}, {"name": "max", "is_optional": false, "type": "Number", "description": " upper-bound of the range to be clamped to"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "NA", "type": "function", "code": "NA(input,*,min,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "min", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,*,max,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "max", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.chi2.Chi2", "type": "class", "code": "torch.distributions.chi2.Chi2(df,validate_args=None)", "example": "  m = Chi2(torch.tensor([1.0]))  m.sample()  # Chi2 distributed with shape df=1 tensor([ 0.1046])    Parameters df (python:float or Tensor) \u2013 shape parameter of the distribution     arg_constraints = {'df': GreaterThan(lower_bound=0.0)}     property df     expand(batch_shape, _instance=None)    ", "summary": "Bases: torch.distributions.gamma.Gamma Creates a Chi2 distribution parameterized by shape parameter df", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.chi2.Chi2", "parameters": [{"name": "df", "is_optional": false, "type": "float or Tensor", "description": " shape parameter of the distribution"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.chi2.Chi2.arg_constraints", "type": "attribute", "code": "torch.distributions.chi2.Chi2.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.chi2.Chi2.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.dirichlet.Dirichlet", "type": "class", "code": "torch.distributions.dirichlet.Dirichlet(concentration,validate_args=None)", "example": "  m = Dirichlet(torch.tensor([0.5, 0.5]))  m.sample()  # Dirichlet distributed with concentrarion concentration tensor([ 0.1046,  0.8954])    Parameters concentration (Tensor) \u2013 concentration parameter of the distribution (often referred to as alpha)     arg_constraints = {'concentration': GreaterThan(lower_bound=0.0)}     entropy()      expand(batch_shape, _instance=None)      has_rsample = True     log_prob(value)      property mean     rsample(sample_shape=())      support = Simplex()     property variance   ", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily Creates a Dirichlet distribution parameterized by concentration concentration", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet", "parameters": [{"name": "concentration", "is_optional": false, "type": "Tensor", "description": " concentration parameter of the distribution(often referred to as alpha"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.dirichlet.Dirichlet.arg_constraints", "type": "attribute", "code": "torch.distributions.dirichlet.Dirichlet.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.dirichlet.Dirichlet.has_rsample", "type": "attribute", "code": "torch.distributions.dirichlet.Dirichlet.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.has_rsample", "parameters": []}},
{"id": "torch.distributions.dirichlet.Dirichlet.support", "type": "attribute", "code": "torch.distributions.dirichlet.Dirichlet.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.dirichlet.Dirichlet.support", "parameters": []}},
{"id": "torch.distributions.exponential.Exponential", "type": "class", "code": "torch.distributions.exponential.Exponential(rate,validate_args=None)", "example": "  m = Exponential(torch.tensor([1.0]))  m.sample()  # Exponential distributed with rate=1 tensor([ 0.1046])    Parameters rate (python:float or Tensor) \u2013 rate = 1 / scale of the distribution     arg_constraints = {'rate': GreaterThan(lower_bound=0.0)}     cdf(value)      entropy()      expand(batch_shape, _instance=None)      has_rsample = True     icdf(value)      log_prob(value)      property mean     rsample(sample_shape=torch.Size([]))      property stddev     support = GreaterThan(lower_bound=0.0)     property variance   ", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily Creates a Exponential distribution parameterized by rate", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential", "parameters": [{"name": "rate", "is_optional": false, "type": "float or Tensor", "description": " rate = 1 / scale of the distribution"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.exponential.Exponential.arg_constraints", "type": "attribute", "code": "torch.distributions.exponential.Exponential.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.nn.Parameter", "type": "class", "code": "torch.nn.Parameter", "example": "NA", "summary": "A kind of Tensor that is to be considered a module parameter", "returns": null, "shape": "NA", "code-info": {"name": "torch.nn.Parameter", "parameters": []}},
{"id": "torch.nn.Module", "type": "class", "code": "torch.nn.Module", "example": "  @torch.no_grad()  def init_weights(m):      print(m)      if type(m) == nn.Linear:          m.weight.fill_(1.0)          print(m.weight)  net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))  net.apply(init_weights) Linear(in_features=2, out_features=2, bias=True) Parameter containing: tensor([[ 1.,  1.],         [ 1.,  1.]]) Linear(in_features=2, out_features=2, bias=True) Parameter containing: tensor([[ 1.,  1.],         [ 1.,  1.]]) Sequential(   (0): Linear(in_features=2, out_features=2, bias=True)   (1): Linear(in_features=2, out_features=2, bias=True) ) Sequential(   (0): Linear(in_features=2, out_features=2, bias=True)   (1): Linear(in_features=2, out_features=2, bias=True) )       bfloat16() \u2192 T  Casts all floating point parameters and buffers to bfloat16 datatype.  Returns self  Return type Module       buffers(recurse: bool = True) \u2192 Iterator[torch.Tensor]  Returns an iterator over module buffers.  Parameters recurse (bool) \u2013 if True, then yields buffers of this module and all submodules. Otherwise, yields only buffers that are direct members of this module.  Yields torch.Tensor \u2013 module buffer   ", "summary": "Base class for all neural network modules", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module", "parameters": []}},
{"id": "torch.Tensor.renorm_", "type": "method", "code": "torch.Tensor.renorm_(p,dim,maxnorm)", "example": "NA", "summary": "In-place version of renorm() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.renorm_", "parameters": [{"name": "p", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "maxnorm", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.repeat", "type": "method", "code": "torch.Tensor.repeat(*sizes)", "example": "  x = torch.tensor([1, 2, 3])  x.repeat(4, 2) tensor([[ 1,  2,  3,  1,  2,  3],         [ 1,  2,  3,  1,  2,  3],         [ 1,  2,  3,  1,  2,  3],         [ 1,  2,  3,  1,  2,  3]])  x.repeat(4, 2, 1).size() torch.Size([4, 2, 3])   ", "summary": "Repeats this tensor along the specified dimensions", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.repeat", "parameters": [{"name": "*sizes", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.repeat_interleave", "type": "method", "code": "torch.Tensor.repeat_interleave(repeats,dim=None)", "example": "NA", "summary": "See torch.repeat_interleave()", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.repeat_interleave", "parameters": [{"name": "repeats", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.requires_grad_", "type": "method", "code": "torch.Tensor.requires_grad_(requires_grad=True)", "example": "  # Let's say we want to preprocess some saved weights and use  # the result as new weights.  saved_weights = [0.1, 0.2, 0.3, 0.25]  loaded_weights = torch.tensor(saved_weights)  weights = preprocess(loaded_weights)  # some function  weights tensor([-0.5503,  0.4926, -2.1158, -0.8303])   # Now, start to record operations done to weights  weights.requires_grad_()  out = weights.pow(2).sum()  out.backward()  weights.grad tensor([-1.1007,  0.9853, -4.2316, -1.6606])   ", "summary": "Change if autograd should record operations on this tensor: sets this tensor\u2019s requires_grad attribute in-place", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.requires_grad_", "parameters": [{"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "True", "description": " If autograd should record operations on this tensor.Default"}]}},
{"id": "torch.Tensor.reshape", "type": "method", "code": "torch.Tensor.reshape(*shape)", "example": "NA", "summary": "Returns a tensor with the same data and number of elements as self but with the specified shape", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.reshape", "parameters": [{"name": "*shape", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.reshape_as", "type": "method", "code": "torch.Tensor.reshape_as(other)", "example": "NA", "summary": "Returns this tensor as the same shape as other", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.reshape_as", "parameters": [{"name": "other", "is_optional": false, "type": "torch.Tensor", "description": " The result tensor has the same shapeas other."}]}},
{"id": "torch.Tensor.resize_", "type": "method", "code": "torch.Tensor.resize_(*sizes)", "example": "  x = torch.tensor([[1, 2], [3, 4], [5, 6]])  x.resize_(2, 2) tensor([[ 1,  2],         [ 3,  4]])   ", "summary": "Resizes self tensor to the specified size", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.resize_", "parameters": [{"name": "*sizes", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.conj", "type": "function", "code": "torch.conj(input,out=None)", "example": "  torch.conj(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j])) tensor([-1 - 1j, -2 - 2j, 3 + 3j])   ", "summary": "Computes the element-wise conjugate of the given input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.conj", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.cos", "type": "function", "code": "torch.cos(input,out=None)", "example": "  a = torch.randn(4)  a tensor([ 1.4309,  1.2706, -0.8562,  0.9796])  torch.cos(a) tensor([ 0.1395,  0.2957,  0.6553,  0.5574])   ", "summary": "Returns a new tensor with the cosine  of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.cos", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.cosh", "type": "function", "code": "torch.cosh(input,out=None)", "example": "  a = torch.randn(4)  a tensor([ 0.1632,  1.1835, -0.6979, -0.7325])  torch.cosh(a) tensor([ 1.0133,  1.7860,  1.2536,  1.2805])   ", "summary": "Returns a new tensor with the hyperbolic cosine  of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.cosh", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.div", "type": "function", "code": "torch.div()", "example": "  a = torch.randn(5)  a tensor([ 0.3810,  1.2774, -0.2972, -0.3719,  0.4637])  torch.div(a, 0.5) tensor([ 0.7620,  2.5548, -0.5944, -0.7439,  0.9275])     torch.div(input, other, out=None) \u2192 Tensor   Each element of the tensor input is divided by each element of the tensor other. The resulting tensor is returned.  outi=inputiotheri\\text{out}_i = \\frac{\\text{input}_i}{\\text{other}_i}  outi\u200b=otheri\u200binputi\u200b\u200b  The shapes of input and other must be broadcastable. If the torch.dtype of input and other differ, the torch.dtype of the result tensor is determined following rules described in the type promotion documentation. If out is specified, the result must be castable to the torch.dtype of the specified output tensor. Integral division by zero leads to undefined behavior.  Parameters  input (Tensor) \u2013 the numerator tensor other (Tensor) \u2013 the denominator tensor   Keyword Arguments out (Tensor, optional) \u2013 the output tensor.   ", "summary": "  torch.div(input, other, out=None) \u2192 Tensor   Divides each element of the input input with the scalar other and returns a new resulting tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.div", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input,other,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,other,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.digamma", "type": "function", "code": "torch.digamma(input,out=None)", "example": "  a = torch.tensor([1, 0.5])  torch.digamma(a) tensor([-0.5772, -1.9635])   ", "summary": "Computes the logarithmic derivative of the gamma function on input", "returns": null, "shape": "NA", "code-info": {"name": "torch.digamma", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to compute the digamma function on"}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.exponential.Exponential.has_rsample", "type": "attribute", "code": "torch.distributions.exponential.Exponential.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.has_rsample", "parameters": []}},
{"id": "torch.distributions.exponential.Exponential.support", "type": "attribute", "code": "torch.distributions.exponential.Exponential.support(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.exponential.Exponential.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.fishersnedecor.FisherSnedecor", "type": "class", "code": "torch.distributions.fishersnedecor.FisherSnedecor(df1,df2,validate_args=None)", "example": "  m = FisherSnedecor(torch.tensor([1.0]), torch.tensor([2.0]))  m.sample()  # Fisher-Snedecor-distributed with df1=1 and df2=2 tensor([ 0.2453])    Parameters  df1 (python:float or Tensor) \u2013 degrees of freedom parameter 1 df2 (python:float or Tensor) \u2013 degrees of freedom parameter 2      arg_constraints = {'df1': GreaterThan(lower_bound=0.0), 'df2': GreaterThan(lower_bound=0.0)}     expand(batch_shape, _instance=None)      has_rsample = True     log_prob(value)      property mean     rsample(sample_shape=torch.Size([]))      support = GreaterThan(lower_bound=0.0)     property variance   ", "summary": "Bases: torch.distributions.distribution.Distribution Creates a Fisher-Snedecor distribution parameterized by df1 and df2", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor", "parameters": [{"name": "df1", "is_optional": false, "type": "float or Tensor", "description": " degrees of freedom parameter 1"}, {"name": "df2", "is_optional": false, "type": "float or Tensor", "description": " degrees of freedom parameter 2"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.fishersnedecor.FisherSnedecor.arg_constraints", "type": "attribute", "code": "torch.distributions.fishersnedecor.FisherSnedecor.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.fishersnedecor.FisherSnedecor.has_rsample", "type": "attribute", "code": "torch.distributions.fishersnedecor.FisherSnedecor.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor.has_rsample", "parameters": []}},
{"id": "torch.distributions.fishersnedecor.FisherSnedecor.support", "type": "attribute", "code": "torch.distributions.fishersnedecor.FisherSnedecor.support(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.fishersnedecor.FisherSnedecor.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.gamma.Gamma", "type": "class", "code": "torch.distributions.gamma.Gamma(concentration,rate,validate_args=None)", "example": "  m = Gamma(torch.tensor([1.0]), torch.tensor([1.0]))  m.sample()  # Gamma distributed with concentration=1 and rate=1 tensor([ 0.1046])    Parameters  concentration (python:float or Tensor) \u2013 shape parameter of the distribution (often referred to as alpha) rate (python:float or Tensor) \u2013 rate = 1 / scale of the distribution (often referred to as beta)      arg_constraints = {'concentration': GreaterThan(lower_bound=0.0), 'rate': GreaterThan(lower_bound=0.0)}     entropy()      expand(batch_shape, _instance=None)      has_rsample = True     log_prob(value)      property mean     rsample(sample_shape=torch.Size([]))      support = GreaterThan(lower_bound=0.0)     property variance   ", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily Creates a Gamma distribution parameterized by shape concentration and rate", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gamma.Gamma", "parameters": [{"name": "concentration", "is_optional": false, "type": "float or Tensor", "description": " shape parameter of the distribution(often referred to as alpha"}, {"name": "rate", "is_optional": false, "type": "float or Tensor", "description": " rate = 1 / scale of the distribution(often referred to as beta"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.Module.dump_patches", "type": "attribute", "code": "torch.nn.Module.dump_patches", "example": "&gt;&gt;&gt; linear = nn.Linear(2, 2)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]])\n&gt;&gt;&gt; linear.to(torch.double)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n        [-0.5113, -0.2325]], dtype=torch.float64)\n&gt;&gt;&gt; gpu1 = torch.device(\"cuda:1\")\n&gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n&gt;&gt;&gt; cpu = torch.device(\"cpu\")\n&gt;&gt;&gt; linear.to(cpu)\nLinear(in_features=2, out_features=2, bias=True)\n&gt;&gt;&gt; linear.weight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n        [-0.5112, -0.2324]], dtype=torch.float16)\n\n", "summary": "This allows better BC support for load_state_dict()", "returns": "self", "shape": "", "code-info": {"name": "torch.nn.Module.dump_patches", "parameters": []}},
{"id": "torch.nn.Sequential", "type": "class", "code": "torch.nn.Sequential(*args:Any)", "example": "NA", "summary": "A sequential container", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Sequential", "parameters": [{"name": "*args", "type": "Any", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.ModuleList", "type": "class", "code": "torch.nn.ModuleList(modules:Optional[Iterable[torch.nn.modules.module.Module]]=None)", "example": " class MyModule(nn.Module):     def __init__(self):         super(MyModule, self).__init__()         self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])      def forward(self, x):         # ModuleList can act as an iterable, or be indexed using ints         for i, l in enumerate(self.linears):             x = self.linears[i // 2](x) + l(x)         return x     append(module: torch.nn.modules.module.Module) \u2192 T  Appends a given module to the end of the list.  Parameters module (nn.Module) \u2013 module to append       extend(modules: Iterable[torch.nn.modules.module.Module]) \u2192 T  Appends modules from a Python iterable to the end of the list.  Parameters modules (iterable) \u2013 iterable of modules to append       insert(index: int, module: torch.nn.modules.module.Module) \u2192 None  Insert a given module before a given index in the list.  Parameters  index (int) \u2013 index to insert. module (nn.Module) \u2013 module to insert      ", "summary": "Holds submodules in a list", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ModuleList", "parameters": [{"name": "modules", "type": "Optional[Iterable[torch.nn.modules.module.Module]]", "default_value": "None", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.ModuleDict", "type": "class", "code": "torch.nn.ModuleDict(modules:Optional[Mapping[str,torch.nn.modules.module.Module]]=None)", "example": " class MyModule(nn.Module):     def __init__(self):         super(MyModule, self).__init__()         self.choices = nn.ModuleDict({                 'conv': nn.Conv2d(10, 10, 3),                 'pool': nn.MaxPool2d(3)         })         self.activations = nn.ModuleDict([                 ['lrelu', nn.LeakyReLU()],                 ['prelu', nn.PReLU()]         ])      def forward(self, x, choice, act):         x = self.choices[choice](x)         x = self.activations[act](x)         return x     clear() \u2192 None  Remove all items from the ModuleDict.     items() \u2192 Iterable[Tuple[str, torch.nn.modules.module.Module]]  Return an iterable of the ModuleDict key/value pairs.     keys() \u2192 Iterable[str]  Return an iterable of the ModuleDict keys.     pop(key: str) \u2192 torch.nn.modules.module.Module  Remove key from the ModuleDict and return its module.  Parameters key (string) \u2013 key to pop from the ModuleDict       update(modules: Mapping[str, torch.nn.modules.module.Module]) \u2192 None  Update the ModuleDict with the key-value pairs from a mapping or an iterable, overwriting existing keys.  Note If modules is an OrderedDict, a ModuleDict, or an iterable of key-value pairs, the order of new elements in it is preserved.   Parameters modules (iterable) \u2013 a mapping (dictionary) from string to Module, or an iterable of key-value pairs of type (string, Module)       values() \u2192 Iterable[torch.nn.modules.module.Module]  Return an iterable of the ModuleDict values.   ", "summary": "Holds submodules in a dictionary", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ModuleDict", "parameters": [{"name": "modules", "type": "Optional[Mapping[str,torch.nn.modules.module.Module]]", "default_value": "None", "is_optional": true, "description": "a mapping (dictionary) from string to Module,or an iterable of key-value pairs of type (string, Module)"}]}},
{"id": "torch.nn.ParameterList", "type": "class", "code": "torch.nn.ParameterList(parameters:Optional[Iterable[Parameter]]=None)", "example": " class MyModule(nn.Module):     def __init__(self):         super(MyModule, self).__init__()         self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)])      def forward(self, x):         # ParameterList can act as an iterable, or be indexed using ints         for i, p in enumerate(self.params):             x = self.params[i // 2].mm(x) + p.mm(x)         return x     append(parameter: Parameter) \u2192 T  Appends a given parameter at the end of the list.  Parameters parameter (nn.Parameter) \u2013 parameter to append       extend(parameters: Iterable[Parameter]) \u2192 T  Appends parameters from a Python iterable to the end of the list.  Parameters parameters (iterable) \u2013 iterable of parameters to append     ", "summary": "Holds parameters in a list", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ParameterList", "parameters": [{"name": "parameters", "type": "Optional[Iterable[Parameter]]", "default_value": "None", "is_optional": true, "description": "iterable of parameters to append"}]}},
{"id": "torch.nn.ParameterDict", "type": "class", "code": "torch.nn.ParameterDict(parameters:Optional[Mapping[str,Parameter]]=None)", "example": " class MyModule(nn.Module):     def __init__(self):         super(MyModule, self).__init__()         self.params = nn.ParameterDict({                 'left': nn.Parameter(torch.randn(5, 10)),                 'right': nn.Parameter(torch.randn(5, 10))         })      def forward(self, x, choice):         x = self.params[choice].mm(x)         return x     clear() \u2192 None  Remove all items from the ParameterDict.     items() \u2192 Iterable[Tuple[str, Parameter]]  Return an iterable of the ParameterDict key/value pairs.     keys() \u2192 Iterable[str]  Return an iterable of the ParameterDict keys.     pop(key: str) \u2192 Parameter  Remove key from the ParameterDict and return its parameter.  Parameters key (string) \u2013 key to pop from the ParameterDict       update(parameters: Mapping[str, Parameter]) \u2192 None  Update the ParameterDict with the key-value pairs from a mapping or an iterable, overwriting existing keys.  Note If parameters is an OrderedDict, a ParameterDict, or an iterable of key-value pairs, the order of new elements in it is preserved.   Parameters parameters (iterable) \u2013 a mapping (dictionary) from string to Parameter, or an iterable of key-value pairs of type (string, Parameter)       values() \u2192 Iterable[Parameter]  Return an iterable of the ParameterDict values.   ", "summary": "Holds parameters in a dictionary", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ParameterDict", "parameters": [{"name": "parameters", "type": "Optional[Mapping[str,Parameter]]", "default_value": "None", "is_optional": true, "description": "a mapping (dictionary) from string toParameter, or an iterable ofkey-value pairs of type (string, Parameter)"}]}},
{"id": "torch.Tensor.resize_as_", "type": "method", "code": "torch.Tensor.resize_as_(tensor)", "example": "NA", "summary": "Resizes the self tensor to be the same size as the specified tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.resize_as_", "parameters": [{"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "NA", "type": "method", "code": "NA()", "example": "NA", "summary": "Enables .grad attribute for non-leaf Tensors", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": []}},
{"id": "torch.Tensor.rfft", "type": "method", "code": "torch.Tensor.rfft(signal_ndim,normalized=False,onesided=True)", "example": "NA", "summary": "See torch.rfft() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.rfft", "parameters": [{"name": "signal_ndim", "is_optional": false, "type": "others", "description": ""}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.Tensor.roll", "type": "method", "code": "torch.Tensor.roll(shifts,dims)", "example": "NA", "summary": "See torch.roll() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.roll", "parameters": [{"name": "shifts", "is_optional": false, "type": "others", "description": ""}, {"name": "dims", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.rot90", "type": "method", "code": "torch.Tensor.rot90(k,dims)", "example": "NA", "summary": "See torch.rot90() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.rot90", "parameters": [{"name": "k", "is_optional": false, "type": "others", "description": ""}, {"name": "dims", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.round", "type": "method", "code": "torch.Tensor.round()", "example": "NA", "summary": "See torch.round() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.round", "parameters": []}},
{"id": "torch.Tensor.round_", "type": "method", "code": "torch.Tensor.round_()", "example": "NA", "summary": "In-place version of round() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.round_", "parameters": []}},
{"id": "torch.Tensor.rsqrt", "type": "method", "code": "torch.Tensor.rsqrt()", "example": "NA", "summary": "See torch.rsqrt() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.rsqrt", "parameters": []}},
{"id": "torch.Tensor.rsqrt_", "type": "method", "code": "torch.Tensor.rsqrt_()", "example": "NA", "summary": "In-place version of rsqrt() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.rsqrt_", "parameters": []}},
{"id": "torch.Tensor.scatter", "type": "method", "code": "torch.Tensor.scatter(dim,index,source)", "example": "NA", "summary": "Out-of-place version of torch.Tensor.scatter_() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.scatter", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}, {"name": "source", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.scatter_", "type": "method", "code": "torch.Tensor.scatter_(dim,index,src)", "example": "  x = torch.rand(2, 5)  x tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],         [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])  torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x) tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],         [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],         [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])   z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)  z tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],         [ 0.0000,  0.0000,  0.0000,  1.2300]])   ", "summary": "Writes all values from the tensor src into self at the indices specified in the index tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.scatter_", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": " the axis along which to index"}, {"name": "index", "is_optional": false, "type": "int", "description": " the indices of elements to scatter,can be either empty or the same size of src.When empty, the operation returns identity"}, {"name": "src", "is_optional": false, "type": "LongTensor", "description": " the source element(s to scatter,incase value is not specified"}]}},
{"id": "torch.erf", "type": "function", "code": "torch.erf(input,out=None)", "example": "  torch.erf(torch.tensor([0, -1., 10.])) tensor([ 0.0000, -0.8427,  1.0000])   ", "summary": "Computes the error function of each element", "returns": null, "shape": "NA", "code-info": {"name": "torch.erf", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.erfc", "type": "function", "code": "torch.erfc(input,out=None)", "example": "  torch.erfc(torch.tensor([0, -1., 10.])) tensor([ 1.0000, 1.8427,  0.0000])   ", "summary": "Computes the complementary error function of each element of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.erfc", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.erfinv", "type": "function", "code": "torch.erfinv(input,out=None)", "example": "  torch.erfinv(torch.tensor([0, 0.5, -1.])) tensor([ 0.0000,  0.4769,    -inf])   ", "summary": "Computes the inverse error function of each element of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.erfinv", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.exp", "type": "function", "code": "torch.exp(input,out=None)", "example": "  torch.exp(torch.tensor([0, math.log(2.)])) tensor([ 1.,  2.])   ", "summary": "Returns a new tensor with the exponential of the elements of the input tensor input", "returns": null, "shape": "NA", "code-info": {"name": "torch.exp", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.expm1", "type": "function", "code": "torch.expm1(input,out=None)", "example": "  torch.expm1(torch.tensor([0, math.log(2.)])) tensor([ 0.,  1.])   ", "summary": "Returns a new tensor with the exponential of the elements minus 1 of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.expm1", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.floor", "type": "function", "code": "torch.floor(input,out=None)", "example": "  a = torch.randn(4)  a tensor([-0.8166,  1.5308, -0.2530, -0.2091])  torch.floor(a) tensor([-1.,  1., -1., -1.])   ", "summary": "Returns a new tensor with the floor of the elements of input, the largest integer less than or equal to each element", "returns": null, "shape": "NA", "code-info": {"name": "torch.floor", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.distributions.gamma.Gamma.arg_constraints", "type": "attribute", "code": "torch.distributions.gamma.Gamma.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gamma.Gamma.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.gamma.Gamma.has_rsample", "type": "attribute", "code": "torch.distributions.gamma.Gamma.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gamma.Gamma.has_rsample", "parameters": []}},
{"id": "torch.distributions.gamma.Gamma.support", "type": "attribute", "code": "torch.distributions.gamma.Gamma.support(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gamma.Gamma.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.geometric.Geometric", "type": "class", "code": "torch.distributions.geometric.Geometric(probs=None,logits=None,validate_args=None)", "example": "  m = Geometric(torch.tensor([0.3]))  m.sample()  # underlying Bernoulli has 30% chance 1; 70% chance 0 tensor([ 2.])    Parameters  probs (Number, Tensor) \u2013 the probability of sampling 1. Must be in range (0, 1] logits (Number, Tensor) \u2013 the log-odds of sampling 1.      arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)}     entropy()      expand(batch_shape, _instance=None)      log_prob(value)      logits      property mean     probs      sample(sample_shape=torch.Size([]))      support = IntegerGreaterThan(lower_bound=0)     property variance   ", "summary": "Bases: torch.distributions.distribution.Distribution Creates a Geometric distribution parameterized by probs, where probs is the probability of success of Bernoulli trials", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.geometric.Geometric", "parameters": [{"name": "probs", "is_optional": true, "type": "Number, Tensor", "default_value": "None", "description": " the probability of sampling 1. Must be in range (0, 1]"}, {"name": "logits", "is_optional": true, "type": "Number, Tensor", "default_value": "None", "description": " the log-odds of sampling 1."}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.geometric.Geometric.arg_constraints", "type": "attribute", "code": "torch.distributions.geometric.Geometric.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.geometric.Geometric.arg_constraints", "parameters": []}},
{"id": "torch.distributions.geometric.Geometric.logits", "type": "attribute", "code": "torch.distributions.geometric.Geometric.logits", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.geometric.Geometric.logits", "parameters": []}},
{"id": "torch.distributions.geometric.Geometric.probs", "type": "attribute", "code": "torch.distributions.geometric.Geometric.probs", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.geometric.Geometric.probs", "parameters": []}},
{"id": "torch.distributions.geometric.Geometric.support", "type": "attribute", "code": "torch.distributions.geometric.Geometric.support(lower_bound=0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.geometric.Geometric.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.distributions.gumbel.Gumbel", "type": "class", "code": "torch.distributions.gumbel.Gumbel(loc,scale,validate_args=None)", "example": " m = Gumbel(torch.tensor([1.0]), torch.tensor([2.0]))\n m.sample()  # sample from Gumbel distribution with loc=1, scale=2\ntensor([ 1.0124])\n\n", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution Samples from a Gumbel Distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gumbel.Gumbel", "parameters": [{"name": "loc", "is_optional": false, "type": "float or Tensor", "description": " Location parameter of the distribution"}, {"name": "scale", "is_optional": false, "type": "float or Tensor", "description": " Scale parameter of the distribution"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.Conv1d", "type": "class", "code": "torch.nn.Conv1d(in_channels:int,out_channels:int,kernel_size:Union[T,Tuple[T]],stride:Union[T,Tuple[T]]=1,padding:Union[T,Tuple[T]]=0,dilation:Union[T,Tuple[T]]=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')", "example": "NA", "summary": "Applies a 1D convolution over an input signal composed of several input planes", "returns": [], "shape": "\nInput: (N,Cin,Lin)(N, C_{in}, L_{in})(N,Cin\u200b,Lin\u200b)\n\n\nOutput: (N,Cout,Lout)(N, C_{out}, L_{out})(N,Cout\u200b,Lout\u200b)\n\n where\n\nLout=\u230aLin+2\u00d7padding\u2212dilation\u00d7(kernel_size\u22121)\u22121stride+1\u230bL_{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n          \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\n\nLout\u200b=\u230astrideLin\u200b+2\u00d7padding\u2212dilation\u00d7(kernel_size\u22121)\u22121\u200b+1\u230b\n\n\n\n", "code-info": {"name": "torch.nn.Conv1d", "parameters": [{"name": "in_channels", "type": "int", "is_optional": false, "description": "Number of channels in the input image"}, {"name": "out_channels", "type": "int", "is_optional": false, "description": "Number of channels produced by the convolution"}, {"name": "kernel_size", "type": "Union[T,Tuple[T]]", "is_optional": false, "description": "Size of the convolving kernel"}, {"name": "stride", "type": "Union[T,Tuple[T]]", "default_value": "1", "is_optional": true, "description": "Stride of the convolution. Default: 1"}, {"name": "padding", "type": "Union[T,Tuple[T]]", "default_value": "0", "is_optional": true, "description": "Zero-padding added to both sides ofthe input. Default: 0"}, {"name": "dilation", "type": "Union[T,Tuple[T]]", "default_value": "1", "is_optional": true, "description": "Spacing between kernelelements. Default: 1"}, {"name": "groups", "type": "int", "default_value": "1", "is_optional": true, "description": "Number of blocked connections from inputchannels to output channels. Default: 1"}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": true, "description": "If True, adds a learnable bias to theoutput. Default: True"}, {"name": "padding_mode", "type": "str", "default_value": "'zeros'", "is_optional": true, "description": "'zeros', 'reflect','replicate' or 'circular'. Default: 'zeros'"}]}},
{"id": "torch.Tensor.scatter_add_", "type": "method", "code": "torch.Tensor.scatter_add_(dim,index,other)", "example": "  x = torch.rand(2, 5)  x tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],         [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])  torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x) tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],         [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],         [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])   ", "summary": "Adds all values from the tensor other into self at the indices specified in the index tensor in a similar fashion as scatter_()", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.scatter_add_", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": " the axis along which to index"}, {"name": "index", "is_optional": false, "type": "int", "description": " the indices of elements to scatter and add,can be either empty or the same size of src.When empty, the operation returns identity."}, {"name": "other", "is_optional": false, "type": "Tensor", "description": " the source elements to scatter and add"}]}},
{"id": "torch.Tensor.scatter_add", "type": "method", "code": "torch.Tensor.scatter_add(dim,index,source)", "example": "NA", "summary": "Out-of-place version of torch.Tensor.scatter_add_() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.scatter_add", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "index", "is_optional": false, "type": "others", "description": ""}, {"name": "source", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.select", "type": "method", "code": "torch.Tensor.select(dim,index)", "example": "NA", "summary": "Slices the self tensor along the selected dimension at the given index", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.select", "parameters": [{"name": "dim", "is_optional": false, "type": "int", "description": " the dimension to slice"}, {"name": "index", "is_optional": false, "type": "int", "description": " the index to select with"}]}},
{"id": "torch.Tensor.set_", "type": "method", "code": "torch.Tensor.set_(source=None,storage_offset=0,size=None,stride=None)", "example": "NA", "summary": "Sets the underlying storage, size, and strides", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.set_", "parameters": [{"name": "source", "is_optional": true, "type": "Tensor or Storage", "default_value": "None", "description": " the tensor or storage to use"}, {"name": "storage_offset", "is_optional": true, "type": "int", "default_value": "0", "description": " the offset in the storage"}, {"name": "size", "is_optional": true, "type": "torch.Size, optional", "default_value": "None", "description": " the desired size. Defaults to the size of the source."}, {"name": "stride", "is_optional": true, "type": "tuple, optional", "default_value": "None", "description": " the desired stride. Defaults to C-contiguous strides."}]}},
{"id": "torch.Tensor.share_memory_", "type": "method", "code": "torch.Tensor.share_memory_()", "example": "NA", "summary": "Moves the underlying storage to shared memory", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.share_memory_", "parameters": []}},
{"id": "torch.Tensor.short", "type": "method", "code": "torch.Tensor.short()", "example": "NA", "summary": "self.short() is equivalent to self.to(torch.int16)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.short", "parameters": []}},
{"id": "torch.fmod", "type": "function", "code": "torch.fmod(input,other,out=None)", "example": "  torch.fmod(torch.tensor([-3., -2, -1, 1, 2, 3]), 2) tensor([-1., -0., -1.,  1.,  0.,  1.])  torch.fmod(torch.tensor([1., 2, 3, 4, 5]), 1.5) tensor([ 1.0000,  0.5000,  0.0000,  1.0000,  0.5000])   ", "summary": "Computes the element-wise remainder of division", "returns": null, "shape": "NA", "code-info": {"name": "torch.fmod", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the dividend"}, {"name": "other", "is_optional": false, "type": "Tensor or float", "description": " the divisor, which may be either a number or a tensor of the same shape as the dividend"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.frac", "type": "function", "code": "torch.frac(input,out=None)", "example": "  torch.frac(torch.tensor([1, 2.5, -3.2])) tensor([ 0.0000,  0.5000, -0.2000])   ", "summary": "Computes the fractional portion of each element in input", "returns": null, "shape": "NA", "code-info": {"name": "torch.frac", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.imag", "type": "function", "code": "torch.imag(input,out=None)", "example": "  torch.imag(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j])) tensor([ 1,  2,  -3])   ", "summary": "Computes the element-wise imag value of the given input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.imag", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.lerp", "type": "function", "code": "torch.lerp(input,end,weight,out=None)", "example": "  start = torch.arange(1., 5.)  end = torch.empty(4).fill_(10)  start tensor([ 1.,  2.,  3.,  4.])  end tensor([ 10.,  10.,  10.,  10.])  torch.lerp(start, end, 0.5) tensor([ 5.5000,  6.0000,  6.5000,  7.0000])  torch.lerp(start, end, torch.full_like(start, 0.5)) tensor([ 5.5000,  6.0000,  6.5000,  7.0000])   ", "summary": "Does a linear interpolation of two tensors start (given by input) and end based on a scalar or tensor weight and returns the resulting out tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.lerp", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor with the starting points"}, {"name": "end", "is_optional": false, "type": "Tensor", "description": " the tensor with the ending points"}, {"name": "weight", "is_optional": false, "type": "float or tensor", "description": " the weight for the interpolation formula"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.lgamma", "type": "function", "code": "torch.lgamma(input,out=None)", "example": "  a = torch.arange(0.5, 2, 0.5)  torch.lgamma(a) tensor([ 0.5724,  0.0000, -0.1208])   ", "summary": "Computes the logarithm of the gamma function on input", "returns": null, "shape": "NA", "code-info": {"name": "torch.lgamma", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.log", "type": "function", "code": "torch.log(input,out=None)", "example": "  a = torch.randn(5)  a tensor([-0.7168, -0.5471, -0.8933, -1.4428, -0.1190])  torch.log(a) tensor([ nan,  nan,  nan,  nan,  nan])   ", "summary": "Returns a new tensor with the natural logarithm of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.log", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.distributions.gumbel.Gumbel.arg_constraints", "type": "attribute", "code": "torch.distributions.gumbel.Gumbel.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gumbel.Gumbel.arg_constraints", "parameters": []}},
{"id": "torch.distributions.gumbel.Gumbel.support", "type": "attribute", "code": "torch.distributions.gumbel.Gumbel.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.gumbel.Gumbel.support", "parameters": []}},
{"id": "torch.distributions.half_cauchy.HalfCauchy", "type": "class", "code": "torch.distributions.half_cauchy.HalfCauchy(scale,validate_args=None)", "example": "  m = HalfCauchy(torch.tensor([1.0]))  m.sample()  # half-cauchy distributed with scale=1 tensor([ 2.3214])    Parameters scale (python:float or Tensor) \u2013 scale of the full Cauchy distribution     arg_constraints = {'scale': GreaterThan(lower_bound=0.0)}     cdf(value)      entropy()      expand(batch_shape, _instance=None)      has_rsample = True     icdf(prob)      log_prob(value)      property mean     property scale     support = GreaterThan(lower_bound=0.0)     property variance   ", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution Creates a half-normal distribution parameterized by scale where: X ~ Cauchy(0, scale) Y = |X| ~ HalfCauchy(scale)   Example: &gt;&gt;&gt; m = HalfCauchy(torch.tensor([1.0])) &gt;&gt;&gt; m.sample()  # half-cauchy distributed with scale=1 tensor([ 2.3214])    Parameters scale (python:float or Tensor) \u2013 scale of the full Cauchy distribution     arg_constraints = {'scale': GreaterThan(lower_bound=0.0)}     cdf(value)      entropy()      expand(batch_shape, _instance=None)      has_rsample = True     icdf(prob)      log_prob(value)      property mean     property scale     support = GreaterThan(lower_bound=0.0)     property variance   ", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy", "parameters": [{"name": "scale", "is_optional": false, "type": "float or Tensor", "description": " scale of the full Cauchy distribution"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.half_cauchy.HalfCauchy.arg_constraints", "type": "attribute", "code": "torch.distributions.half_cauchy.HalfCauchy.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.nn.Conv2d", "type": "class", "code": "torch.nn.Conv2d(in_channels:int,out_channels:int,kernel_size:Union[T,Tuple[T,T]],stride:Union[T,Tuple[T,T]]=1,padding:Union[T,Tuple[T,T]]=0,dilation:Union[T,Tuple[T,T]]=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')", "example": "NA", "summary": "Applies a 2D convolution over an input signal composed of several input planes", "returns": [], "shape": "\nInput: (N,Cin,Hin,Win)(N, C_{in}, H_{in}, W_{in})(N,Cin\u200b,Hin\u200b,Win\u200b)\n\n\nOutput: (N,Cout,Hout,Wout)(N, C_{out}, H_{out}, W_{out})(N,Cout\u200b,Hout\u200b,Wout\u200b)\n\n where\n\nHout=\u230aHin+2\u00d7padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121stride[0]+1\u230bH_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n          \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n\nHout\u200b=\u230astride[0]Hin\u200b+2\u00d7padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121\u200b+1\u230b\n\n\nWout=\u230aWin+2\u00d7padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121stride[1]+1\u230bW_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n          \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n\nWout\u200b=\u230astride[1]Win\u200b+2\u00d7padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121\u200b+1\u230b\n\n\n\n", "code-info": {"name": "torch.nn.Conv2d", "parameters": [{"name": "in_channels", "type": "int", "is_optional": false, "description": "Number of channels in the input image"}, {"name": "out_channels", "type": "int", "is_optional": false, "description": "Number of channels produced by the convolution"}, {"name": "kernel_size", "type": "Union[T,Tuple[T,T]]", "is_optional": false, "description": "Size of the convolving kernel"}, {"name": "stride", "type": "Union[T,Tuple[T,T]]", "default_value": "1", "is_optional": true, "description": "Stride of the convolution. Default: 1"}, {"name": "padding", "type": "Union[T,Tuple[T,T]]", "default_value": "0", "is_optional": true, "description": "Zero-padding added to both sides ofthe input. Default: 0"}, {"name": "dilation", "type": "Union[T,Tuple[T,T]]", "default_value": "1", "is_optional": true, "description": "Spacing between kernel elements. Default: 1"}, {"name": "groups", "type": "int", "default_value": "1", "is_optional": true, "description": "Number of blocked connections from inputchannels to output channels. Default: 1"}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": true, "description": "If True, adds a learnable bias to theoutput. Default: True"}, {"name": "padding_mode", "type": "str", "default_value": "'zeros'", "is_optional": true, "description": "'zeros', 'reflect','replicate' or 'circular'. Default: 'zeros'"}]}},
{"id": "torch.Tensor.sigmoid", "type": "method", "code": "torch.Tensor.sigmoid()", "example": "NA", "summary": "See torch.sigmoid() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sigmoid", "parameters": []}},
{"id": "torch.Tensor.sigmoid_", "type": "method", "code": "torch.Tensor.sigmoid_()", "example": "NA", "summary": "In-place version of sigmoid() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sigmoid_", "parameters": []}},
{"id": "torch.Tensor.sign", "type": "method", "code": "torch.Tensor.sign()", "example": "NA", "summary": "See torch.sign() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sign", "parameters": []}},
{"id": "torch.Tensor.sign_", "type": "method", "code": "torch.Tensor.sign_()", "example": "NA", "summary": "In-place version of sign() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sign_", "parameters": []}},
{"id": "torch.Tensor.sin", "type": "method", "code": "torch.Tensor.sin()", "example": "NA", "summary": "See torch.sin() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sin", "parameters": []}},
{"id": "torch.Tensor.sin_", "type": "method", "code": "torch.Tensor.sin_()", "example": "NA", "summary": "In-place version of sin() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sin_", "parameters": []}},
{"id": "torch.Tensor.sinh", "type": "method", "code": "torch.Tensor.sinh()", "example": "NA", "summary": "See torch.sinh() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sinh", "parameters": []}},
{"id": "torch.Tensor.sinh_", "type": "method", "code": "torch.Tensor.sinh_()", "example": "NA", "summary": "In-place version of sinh() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sinh_", "parameters": []}},
{"id": "torch.Tensor.size", "type": "method", "code": "torch.Tensor.size()", "example": "  torch.empty(3, 4, 5).size() torch.Size([3, 4, 5])   ", "summary": "Returns the size of the self tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.size", "parameters": []}},
{"id": "torch.Tensor.slogdet", "type": "method", "code": "torch.Tensor.slogdet()", "example": "NA", "summary": "See torch.slogdet() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.slogdet", "parameters": []}},
{"id": "torch.Tensor.solve", "type": "method", "code": "torch.Tensor.solve(A)", "example": "NA", "summary": "See torch.solve() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.solve", "parameters": [{"name": "A", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.sort", "type": "method", "code": "torch.Tensor.sort(dim=-1,descending=False)", "example": "NA", "summary": "See torch.sort() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sort", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}, {"name": "descending", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.split", "type": "method", "code": "torch.Tensor.split(split_size,dim=0)", "example": "NA", "summary": "See torch.split() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.split", "parameters": [{"name": "split_size", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.log10", "type": "function", "code": "torch.log10(input,out=None)", "example": "  a = torch.rand(5)  a tensor([ 0.5224,  0.9354,  0.7257,  0.1301,  0.2251])    torch.log10(a) tensor([-0.2820, -0.0290, -0.1392, -0.8857, -0.6476])   ", "summary": "Returns a new tensor with the logarithm to the base 10 of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.log10", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.log1p", "type": "function", "code": "torch.log1p(input,out=None)", "example": "  a = torch.randn(5)  a tensor([-1.0090, -0.9923,  1.0249, -0.5372,  0.2492])  torch.log1p(a) tensor([    nan, -4.8653,  0.7055, -0.7705,  0.2225])   ", "summary": "Returns a new tensor with the natural logarithm of (1 + input)", "returns": null, "shape": "NA", "code-info": {"name": "torch.log1p", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.log2", "type": "function", "code": "torch.log2(input,out=None)", "example": "  a = torch.rand(5)  a tensor([ 0.8419,  0.8003,  0.9971,  0.5287,  0.0490])    torch.log2(a) tensor([-0.2483, -0.3213, -0.0042, -0.9196, -4.3504])   ", "summary": "Returns a new tensor with the logarithm to the base 2 of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.log2", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.logical_not", "type": "function", "code": "torch.logical_not(input,out=None)", "example": "  torch.logical_not(torch.tensor([True, False])) tensor([ False,  True])  torch.logical_not(torch.tensor([0, 1, -10], dtype=torch.int8)) tensor([ True, False, False])  torch.logical_not(torch.tensor([0., 1.5, -10.], dtype=torch.double)) tensor([ True, False, False])  torch.logical_not(torch.tensor([0., 1., -10.], dtype=torch.double), out=torch.empty(3, dtype=torch.int16)) tensor([1, 0, 0], dtype=torch.int16)   ", "summary": "Computes the element-wise logical NOT of the given input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.logical_not", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.logical_xor", "type": "function", "code": "torch.logical_xor(input,other,out=None)", "example": "  torch.logical_xor(torch.tensor([True, False, True]), torch.tensor([True, False, False])) tensor([ False, False,  True])  a = torch.tensor([0, 1, 10, 0], dtype=torch.int8)  b = torch.tensor([4, 0, 1, 0], dtype=torch.int8)  torch.logical_xor(a, b) tensor([ True,  True, False, False])  torch.logical_xor(a.double(), b.double()) tensor([ True,  True, False, False])  torch.logical_xor(a.double(), b) tensor([ True,  True, False, False])  torch.logical_xor(a, b, out=torch.empty(4, dtype=torch.bool)) tensor([ True,  True, False, False])   ", "summary": "Computes the element-wise logical XOR of the given input tensors", "returns": null, "shape": "NA", "code-info": {"name": "torch.logical_xor", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "other", "is_optional": false, "type": "Tensor", "description": " the tensor to compute XOR with"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.mul", "type": "function", "code": "torch.mul()", "example": "  a = torch.randn(3)  a tensor([ 0.2015, -0.4255,  2.6087])  torch.mul(a, 100) tensor([  20.1494,  -42.5491,  260.8663])     torch.mul(input, other, out=None)   Each element of the tensor input is multiplied by the corresponding element of the Tensor other. The resulting tensor is returned. The shapes of input and other must be broadcastable.  outi=inputi\u00d7otheri\\text{out}_i = \\text{input}_i \\times \\text{other}_i  outi\u200b=inputi\u200b\u00d7otheri\u200b   Parameters  input (Tensor) \u2013 the first multiplicand tensor other (Tensor) \u2013 the second multiplicand tensor out (Tensor, optional) \u2013 the output tensor.    ", "summary": "  torch.mul(input, other, out=None)   Multiplies each element of the input input with the scalar other and returns a new resulting tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.mul", "parameters": []}},
{"id": "torch.distributions.half_cauchy.HalfCauchy.has_rsample", "type": "attribute", "code": "torch.distributions.half_cauchy.HalfCauchy.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.has_rsample", "parameters": []}},
{"id": "torch.distributions.half_cauchy.HalfCauchy.support", "type": "attribute", "code": "torch.distributions.half_cauchy.HalfCauchy.support(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_cauchy.HalfCauchy.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.half_normal.HalfNormal", "type": "class", "code": "torch.distributions.half_normal.HalfNormal(scale,validate_args=None)", "example": "  m = HalfNormal(torch.tensor([1.0]))  m.sample()  # half-normal distributed with scale=1 tensor([ 0.1046])    Parameters scale (python:float or Tensor) \u2013 scale of the full Normal distribution     arg_constraints = {'scale': GreaterThan(lower_bound=0.0)}     cdf(value)      entropy()      expand(batch_shape, _instance=None)      has_rsample = True     icdf(prob)      log_prob(value)      property mean     property scale     support = GreaterThan(lower_bound=0.0)     property variance   ", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution Creates a half-normal distribution parameterized by scale where: X ~ Normal(0, scale) Y = |X| ~ HalfNormal(scale)   Example: &gt;&gt;&gt; m = HalfNormal(torch.tensor([1.0])) &gt;&gt;&gt; m.sample()  # half-normal distributed with scale=1 tensor([ 0.1046])    Parameters scale (python:float or Tensor) \u2013 scale of the full Normal distribution     arg_constraints = {'scale': GreaterThan(lower_bound=0.0)}     cdf(value)      entropy()      expand(batch_shape, _instance=None)      has_rsample = True     icdf(prob)      log_prob(value)      property mean     property scale     support = GreaterThan(lower_bound=0.0)     property variance   ", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal", "parameters": [{"name": "scale", "is_optional": false, "type": "float or Tensor", "description": " scale of the full Normal distribution"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.half_normal.HalfNormal.arg_constraints", "type": "attribute", "code": "torch.distributions.half_normal.HalfNormal.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.half_normal.HalfNormal.has_rsample", "type": "attribute", "code": "torch.distributions.half_normal.HalfNormal.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.has_rsample", "parameters": []}},
{"id": "torch.distributions.half_normal.HalfNormal.support", "type": "attribute", "code": "torch.distributions.half_normal.HalfNormal.support(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.half_normal.HalfNormal.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.independent.Independent", "type": "class", "code": "torch.distributions.independent.Independent(base_distribution,reinterpreted_batch_ndims,validate_args=None)", "example": "NA", "summary": "Bases: torch.distributions.distribution.Distribution Reinterprets some of the batch dims of a distribution as event dims", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent", "parameters": [{"name": "base_distribution", "is_optional": false, "type": "torch.distributions.distribution.Distribution", "description": " abase distribution"}, {"name": "reinterpreted_batch_ndims", "is_optional": false, "type": "int", "description": " the number of batch dims toreinterpret as event dims"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.independent.Independent.arg_constraints", "type": "attribute", "code": "torch.distributions.independent.Independent.arg_constraints", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.independent.Independent.arg_constraints", "parameters": []}},
{"id": "torch.distributions.laplace.Laplace", "type": "class", "code": "torch.distributions.laplace.Laplace(loc,scale,validate_args=None)", "example": "  m = Laplace(torch.tensor([0.0]), torch.tensor([1.0]))  m.sample()  # Laplace distributed with loc=0, scale=1 tensor([ 0.1046])    Parameters  loc (python:float or Tensor) \u2013 mean of the distribution scale (python:float or Tensor) \u2013 scale of the distribution      arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}     cdf(value)      entropy()      expand(batch_shape, _instance=None)      has_rsample = True     icdf(value)      log_prob(value)      property mean     rsample(sample_shape=torch.Size([]))      property stddev     support = Real()     property variance   ", "summary": "Bases: torch.distributions.distribution.Distribution Creates a Laplace distribution parameterized by loc and :attr:\u2019scale\u2019", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace", "parameters": [{"name": "loc", "is_optional": false, "type": "float or Tensor", "description": " mean of the distribution"}, {"name": "scale", "is_optional": false, "type": "float or Tensor", "description": " scale of the distribution"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.Conv3d", "type": "class", "code": "torch.nn.Conv3d(in_channels:int,out_channels:int,kernel_size:Union[T,Tuple[T,T,T]],stride:Union[T,Tuple[T,T,T]]=1,padding:Union[T,Tuple[T,T,T]]=0,dilation:Union[T,Tuple[T,T,T]]=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')", "example": "NA", "summary": "Applies a 3D convolution over an input signal composed of several input planes", "returns": [], "shape": "\nInput: (N,Cin,Din,Hin,Win)(N, C_{in}, D_{in}, H_{in}, W_{in})(N,Cin\u200b,Din\u200b,Hin\u200b,Win\u200b)\n\n\nOutput: (N,Cout,Dout,Hout,Wout)(N, C_{out}, D_{out}, H_{out}, W_{out})(N,Cout\u200b,Dout\u200b,Hout\u200b,Wout\u200b)\n\n where\n\nDout=\u230aDin+2\u00d7padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121stride[0]+1\u230bD_{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n      \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n\nDout\u200b=\u230astride[0]Din\u200b+2\u00d7padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121\u200b+1\u230b\n\n\nHout=\u230aHin+2\u00d7padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121stride[1]+1\u230bH_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n      \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n\nHout\u200b=\u230astride[1]Hin\u200b+2\u00d7padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121\u200b+1\u230b\n\n\nWout=\u230aWin+2\u00d7padding[2]\u2212dilation[2]\u00d7(kernel_size[2]\u22121)\u22121stride[2]+1\u230bW_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] - \\text{dilation}[2]\n      \\times (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor\n\nWout\u200b=\u230astride[2]Win\u200b+2\u00d7padding[2]\u2212dilation[2]\u00d7(kernel_size[2]\u22121)\u22121\u200b+1\u230b\n\n\n\n", "code-info": {"name": "torch.nn.Conv3d", "parameters": [{"name": "in_channels", "type": "int", "is_optional": false, "description": "Number of channels in the input image"}, {"name": "out_channels", "type": "int", "is_optional": false, "description": "Number of channels produced by the convolution"}, {"name": "kernel_size", "type": "Union[T,Tuple[T,T,T]]", "is_optional": false, "description": "Size of the convolving kernel"}, {"name": "stride", "type": "Union[T,Tuple[T,T,T]]", "default_value": "1", "is_optional": true, "description": "Stride of the convolution. Default: 1"}, {"name": "padding", "type": "Union[T,Tuple[T,T,T]]", "default_value": "0", "is_optional": true, "description": "Zero-padding added to all three sides of the input. Default: 0"}, {"name": "dilation", "type": "Union[T,Tuple[T,T,T]]", "default_value": "1", "is_optional": true, "description": "Spacing between kernel elements. Default: 1"}, {"name": "groups", "type": "int", "default_value": "1", "is_optional": true, "description": "Number of blocked connections from input channels to output channels. Default: 1"}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": true, "description": "If True, adds a learnable bias to the output. Default: True"}, {"name": "padding_mode", "type": "str", "default_value": "'zeros'", "is_optional": true, "description": "'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'"}]}},
{"id": "torch.Tensor.sparse_mask", "type": "method", "code": "torch.Tensor.sparse_mask(input,mask)", "example": "  nnz = 5  dims = [5, 5, 2, 2]  I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),                    torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)  V = torch.randn(nnz, dims[2], dims[3])  size = torch.Size(dims)  S = torch.sparse_coo_tensor(I, V, size).coalesce()  D = torch.randn(dims)  D.sparse_mask(S) tensor(indices=tensor([[0, 0, 0, 2],                        [0, 1, 4, 3]]),        values=tensor([[[ 1.6550,  0.2397],                        [-0.1611, -0.0779]],                        [[ 0.2326, -1.0558],                        [ 1.4711,  1.9678]],                        [[-0.5138, -0.0411],                        [ 1.9417,  0.5158]],                        [[ 0.0793,  0.0036],                        [-0.2569, -0.1055]]]),        size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)   ", "summary": "Returns a new SparseTensor with values from Tensor input filtered by indices of mask and values are ignored", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sparse_mask", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " an input Tensor"}, {"name": "mask", "is_optional": false, "type": "SparseTensor", "description": " a SparseTensor which we filter input based on its indices"}]}},
{"id": "torch.Tensor.sparse_dim", "type": "method", "code": "torch.Tensor.sparse_dim()", "example": "NA", "summary": "If self is a sparse COO tensor (i.e., with torch.sparse_coo layout), this returns the number of sparse dimensions", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sparse_dim", "parameters": []}},
{"id": "torch.Tensor.sqrt", "type": "method", "code": "torch.Tensor.sqrt()", "example": "NA", "summary": "See torch.sqrt() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sqrt", "parameters": []}},
{"id": "torch.Tensor.sqrt_", "type": "method", "code": "torch.Tensor.sqrt_()", "example": "NA", "summary": "In-place version of sqrt() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sqrt_", "parameters": []}},
{"id": "torch.Tensor.squeeze", "type": "method", "code": "torch.Tensor.squeeze(dim=None)", "example": "NA", "summary": "See torch.squeeze() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.squeeze", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.squeeze_", "type": "method", "code": "torch.Tensor.squeeze_(dim=None)", "example": "NA", "summary": "In-place version of squeeze() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.squeeze_", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.std", "type": "method", "code": "torch.Tensor.std(dim=None,unbiased=True,keepdim=False)", "example": "NA", "summary": "See torch.std() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.std", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,other,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,other,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.mvlgamma", "type": "function", "code": "torch.mvlgamma(input,p)", "example": "  a = torch.empty(2, 3).uniform_(1, 2)  a tensor([[1.6835, 1.8474, 1.1929],         [1.0475, 1.7162, 1.4180]])  torch.mvlgamma(a, 2) tensor([[0.3928, 0.4007, 0.7586],         [1.0311, 0.3901, 0.5049]])   ", "summary": "Computes the multivariate log-gamma function ([reference]) with dimension ppp   element-wise, given by  log\u2061(\u0393p(a))=C+\u2211i=1plog\u2061(\u0393(a\u2212i\u221212))\\log(\\Gamma_{p}(a)) = C + \\displaystyle \\sum_{i=1}^{p} \\log\\left(\\Gamma\\left(a - \\frac{i - 1}{2}\\right)\\right)  log(\u0393p\u200b(a))=C+i=1\u2211p\u200blog(\u0393(a\u22122i\u22121\u200b))  where C=log\u2061(\u03c0)\u00d7p(p\u22121)4C = \\log(\\pi) \\times \\frac{p (p - 1)}{4}C=log(\u03c0)\u00d74p(p\u22121)\u200b   and \u0393(\u22c5)\\Gamma(\\cdot)\u0393(\u22c5)   is the Gamma function", "returns": null, "shape": "NA", "code-info": {"name": "torch.mvlgamma", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to compute the multivariate log-gamma function"}, {"name": "p", "is_optional": false, "type": "Tensor", "description": " the number of dimensions"}]}},
{"id": "torch.neg", "type": "function", "code": "torch.neg(input,out=None)", "example": "  a = torch.randn(5)  a tensor([ 0.0090, -0.2262, -0.0682, -0.2866,  0.3940])  torch.neg(a) tensor([-0.0090,  0.2262,  0.0682,  0.2866, -0.3940])   ", "summary": "Returns a new tensor with the negative of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.neg", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.polygamma", "type": "function", "code": "torch.polygamma(n,input,out=None)", "example": ": a = torch.tensor([1, 0.5])  torch.polygamma(1, a) tensor([1.64493, 4.9348])     ", "summary": "Computes the nthn^{th}nth   derivative of the digamma function on input", "returns": null, "shape": "NA", "code-info": {"name": "torch.polygamma", "parameters": [{"name": "n", "is_optional": false, "type": "int", "description": " the order of the polygamma function"}, {"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.pow", "type": "function", "code": "torch.pow()", "example": "  a = torch.randn(4)  a tensor([ 0.4331,  1.2475,  0.6834, -0.2791])  torch.pow(a, 2) tensor([ 0.1875,  1.5561,  0.4670,  0.0779])  exp = torch.arange(1., 5.)   a = torch.arange(1., 5.)  a tensor([ 1.,  2.,  3.,  4.])  exp tensor([ 1.,  2.,  3.,  4.])  torch.pow(a, exp) tensor([   1.,    4.,   27.,  256.])     torch.pow(self, exponent, out=None) \u2192 Tensor   self is a scalar float value, and exponent is a tensor. The returned tensor out is of the same shape as exponent The operation applied is:  outi=selfexponenti\\text{out}_i = \\text{self} ^ {\\text{exponent}_i}  outi\u200b=selfexponenti\u200b   Parameters  self (python:float) \u2013 the scalar base value for the power operation exponent (Tensor) \u2013 the exponent tensor out (Tensor, optional) \u2013 the output tensor.    ", "summary": "  torch.pow(input, exponent, out=None) \u2192 Tensor   Takes the power of each element in input with exponent and returns a tensor with the result", "returns": null, "shape": "NA", "code-info": {"name": "torch.pow", "parameters": []}},
{"id": "torch.distributions.laplace.Laplace.arg_constraints", "type": "attribute", "code": "torch.distributions.laplace.Laplace.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.arg_constraints", "parameters": []}},
{"id": "torch.distributions.laplace.Laplace.has_rsample", "type": "attribute", "code": "torch.distributions.laplace.Laplace.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.has_rsample", "parameters": []}},
{"id": "torch.distributions.laplace.Laplace.support", "type": "attribute", "code": "torch.distributions.laplace.Laplace.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.laplace.Laplace.support", "parameters": []}},
{"id": "torch.distributions.log_normal.LogNormal", "type": "class", "code": "torch.distributions.log_normal.LogNormal(loc,scale,validate_args=None)", "example": "  m = LogNormal(torch.tensor([0.0]), torch.tensor([1.0]))  m.sample()  # log-normal distributed with mean=0 and stddev=1 tensor([ 0.1046])    Parameters  loc (python:float or Tensor) \u2013 mean of log of distribution scale (python:float or Tensor) \u2013 standard deviation of log of the distribution      arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}     entropy()      expand(batch_shape, _instance=None)      has_rsample = True     property loc     property mean     property scale     support = GreaterThan(lower_bound=0.0)     property variance   ", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution Creates a log-normal distribution parameterized by loc and scale where: X ~ Normal(loc, scale) Y = exp(X) ~ LogNormal(loc, scale)   Example: &gt;&gt;&gt; m = LogNormal(torch.tensor([0.0]), torch.tensor([1.0])) &gt;&gt;&gt; m.sample()  # log-normal distributed with mean=0 and stddev=1 tensor([ 0.1046])    Parameters  loc (python:float or Tensor) \u2013 mean of log of distribution scale (python:float or Tensor) \u2013 standard deviation of log of the distribution      arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}     entropy()      expand(batch_shape, _instance=None)      has_rsample = True     property loc     property mean     property scale     support = GreaterThan(lower_bound=0.0)     property variance   ", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.log_normal.LogNormal", "parameters": [{"name": "loc", "is_optional": false, "type": "float or Tensor", "description": " mean of log of distribution"}, {"name": "scale", "is_optional": false, "type": "float or Tensor", "description": " standard deviation of log of the distribution"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.log_normal.LogNormal.arg_constraints", "type": "attribute", "code": "torch.distributions.log_normal.LogNormal.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.log_normal.LogNormal.arg_constraints", "parameters": []}},
{"id": "torch.distributions.log_normal.LogNormal.has_rsample", "type": "attribute", "code": "torch.distributions.log_normal.LogNormal.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.log_normal.LogNormal.has_rsample", "parameters": []}},
{"id": "torch.distributions.log_normal.LogNormal.support", "type": "attribute", "code": "torch.distributions.log_normal.LogNormal.support(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.log_normal.LogNormal.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal", "type": "class", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(loc,cov_factor,cov_diag,validate_args=None)", "example": " m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([1, 0]), torch.tensor([1, 1]))\n m.sample()  # normally distributed with mean=`[0,0]`, cov_factor=`[1,0]`, cov_diag=`[1,1]`\ntensor([-0.2102, -0.5429])\n\n", "summary": "Bases: torch.distributions.distribution.Distribution Creates a multivariate normal distribution with covariance matrix having a low-rank form parameterized by cov_factor and cov_diag: covariance_matrix = cov_factor @ cov_factor.T + cov_diag   Example &gt;&gt;&gt; m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([1, 0]), torch.tensor([1, 1])) &gt;&gt;&gt; m.sample()  # normally distributed with mean=`[0,0]`, cov_factor=`[1,0]`, cov_diag=`[1,1]` tensor([-0.2102, -0.5429])    Parameters  loc (Tensor) \u2013 mean of the distribution with shape batch_shape + event_shape cov_factor (Tensor) \u2013 factor part of low-rank form of covariance matrix with shape batch_shape + event_shape + (rank,) cov_diag (Tensor) \u2013 diagonal part of low-rank form of covariance matrix with shape batch_shape + event_shape     Note The computation for determinant and inverse of covariance matrix is avoided when cov_factor.shape[1] &lt;&lt; cov_factor.shape[0] thanks to Woodbury matrix identity and matrix determinant lemma", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal", "parameters": [{"name": "loc", "is_optional": false, "type": "Tensor", "description": " mean of the distribution with shape batch_shape + event_shape"}, {"name": "cov_factor", "is_optional": false, "type": "Tensor", "description": " factor part of low-rank form of covariance matrix with shapebatch_shape + event_shape + (rank,"}, {"name": "cov_diag", "is_optional": false, "type": "Tensor", "description": " diagonal part of low-rank form of covariance matrix with shapebatch_shape + event_shape"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.arg_constraints", "type": "attribute", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.covariance_matrix", "type": "attribute", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.covariance_matrix", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.covariance_matrix", "parameters": []}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.has_rsample", "type": "attribute", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.has_rsample", "parameters": []}},
{"id": "torch.nn.ConvTranspose1d", "type": "class", "code": "torch.nn.ConvTranspose1d(in_channels:int,out_channels:int,kernel_size:Union[T,Tuple[T]],stride:Union[T,Tuple[T]]=1,padding:Union[T,Tuple[T]]=0,output_padding:Union[T,Tuple[T]]=0,groups:int=1,bias:bool=True,dilation:Union[T,Tuple[T]]=1,padding_mode:str='zeros')", "example": "NA", "summary": "Applies a 1D transposed convolution operator over an input image composed of several input planes", "returns": [], "shape": "\nInput: (N,Cin,Lin)(N, C_{in}, L_{in})(N,Cin\u200b,Lin\u200b)\n\n\nOutput: (N,Cout,Lout)(N, C_{out}, L_{out})(N,Cout\u200b,Lout\u200b)\n\n where\n\nLout=(Lin\u22121)\u00d7stride\u22122\u00d7padding+dilation\u00d7(kernel_size\u22121)+output_padding+1L_{out} = (L_{in} - 1) \\times \\text{stride} - 2 \\times \\text{padding} + \\text{dilation}\n          \\times (\\text{kernel\\_size} - 1) + \\text{output\\_padding} + 1\n\nLout\u200b=(Lin\u200b\u22121)\u00d7stride\u22122\u00d7padding+dilation\u00d7(kernel_size\u22121)+output_padding+1\n\n\n\n", "code-info": {"name": "torch.nn.ConvTranspose1d", "parameters": [{"name": "in_channels", "type": "int", "is_optional": false, "description": "Number of channels in the input image"}, {"name": "out_channels", "type": "int", "is_optional": false, "description": "Number of channels produced by the convolution"}, {"name": "kernel_size", "type": "Union[T,Tuple[T]]", "is_optional": false, "description": "Size of the convolving kernel"}, {"name": "stride", "type": "Union[T,Tuple[T]]", "default_value": "1", "is_optional": true, "description": "Stride of the convolution. Default: 1"}, {"name": "padding", "type": "Union[T,Tuple[T]]", "default_value": "0", "is_optional": true, "description": "dilation * (kernel_size - 1) - padding zero-paddingwill be added to both sides of the input. Default: 0"}, {"name": "output_padding", "type": "Union[T,Tuple[T]]", "default_value": "0", "is_optional": true, "description": "Additional size added to one sideof the output shape. Default: 0"}, {"name": "groups", "type": "int", "default_value": "1", "is_optional": true, "description": "Number of blocked connections from input channels to output channels. Default: 1"}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": true, "description": "If True, adds a learnable bias to the output. Default: True"}, {"name": "dilation", "type": "Union[T,Tuple[T]]", "default_value": "1", "is_optional": true, "description": "Spacing between kernel elements. Default: 1"}, {"name": "padding_mode", "type": "str", "default_value": "'zeros'", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.ConvTranspose2d", "type": "class", "code": "torch.nn.ConvTranspose2d(in_channels:int,out_channels:int,kernel_size:Union[T,Tuple[T,T]],stride:Union[T,Tuple[T,T]]=1,padding:Union[T,Tuple[T,T]]=0,output_padding:Union[T,Tuple[T,T]]=0,groups:int=1,bias:bool=True,dilation:int=1,padding_mode:str='zeros')", "example": "NA", "summary": "Applies a 2D transposed convolution operator over an input image composed of several input planes", "returns": [], "shape": "\nInput: (N,Cin,Hin,Win)(N, C_{in}, H_{in}, W_{in})(N,Cin\u200b,Hin\u200b,Win\u200b)\n\n\nOutput: (N,Cout,Hout,Wout)(N, C_{out}, H_{out}, W_{out})(N,Cout\u200b,Hout\u200b,Wout\u200b)\n\n where\n\n\nHout=(Hin\u22121)\u00d7stride[0]\u22122\u00d7padding[0]+dilation[0]\u00d7(kernel_size[0]\u22121)+output_padding[0]+1H_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0]\n          \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1\n\nHout\u200b=(Hin\u200b\u22121)\u00d7stride[0]\u22122\u00d7padding[0]+dilation[0]\u00d7(kernel_size[0]\u22121)+output_padding[0]+1\n\n\nWout=(Win\u22121)\u00d7stride[1]\u22122\u00d7padding[1]+dilation[1]\u00d7(kernel_size[1]\u22121)+output_padding[1]+1W_{out} = (W_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1]\n          \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1\n\nWout\u200b=(Win\u200b\u22121)\u00d7stride[1]\u22122\u00d7padding[1]+dilation[1]\u00d7(kernel_size[1]\u22121)+output_padding[1]+1\n\n", "code-info": {"name": "torch.nn.ConvTranspose2d", "parameters": [{"name": "in_channels", "type": "int", "is_optional": false, "description": "Number of channels in the input image"}, {"name": "out_channels", "type": "int", "is_optional": false, "description": "Number of channels produced by the convolution"}, {"name": "kernel_size", "type": "Union[T,Tuple[T,T]]", "is_optional": false, "description": "Size of the convolving kernel"}, {"name": "stride", "type": "Union[T,Tuple[T,T]]", "default_value": "1", "is_optional": true, "description": "Stride of the convolution. Default: 1"}, {"name": "padding", "type": "Union[T,Tuple[T,T]]", "default_value": "0", "is_optional": true, "description": "dilation * (kernel_size - 1) - padding zero-paddingwill be added to both sides of each dimension in the input. Default: 0"}, {"name": "output_padding", "type": "Union[T,Tuple[T,T]]", "default_value": "0", "is_optional": true, "description": "Additional size added to one sideof each dimension in the output shape. Default: 0"}, {"name": "groups", "type": "int", "default_value": "1", "is_optional": true, "description": "Number of blocked connections from input channels to output channels. Default: 1"}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": true, "description": "If True, adds a learnable bias to the output. Default: True"}, {"name": "dilation", "type": "int", "default_value": "1", "is_optional": true, "description": "Spacing between kernel elements. Default: 1"}, {"name": "padding_mode", "type": "str", "default_value": "'zeros'", "is_optional": false, "description": ""}]}},
{"id": "torch.Tensor.stft", "type": "method", "code": "torch.Tensor.stft(n_fft,hop_length=None,win_length=None,window=None,center=True,pad_mode='reflect',normalized=False,onesided=True)", "example": "NA", "summary": "See torch.stft()  Warning This function changed signature at version 0.4.1", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.stft", "parameters": [{"name": "n_fft", "is_optional": false, "type": "others", "description": ""}, {"name": "hop_length", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "win_length", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "window", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "center", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "pad_mode", "is_optional": true, "type": "string", "default_value": "'reflect'", "description": ""}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.Tensor.storage", "type": "method", "code": "torch.Tensor.storage()", "example": "NA", "summary": "Returns the underlying storage", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.storage", "parameters": []}},
{"id": "torch.Tensor.storage_offset", "type": "method", "code": "torch.Tensor.storage_offset()", "example": "  x = torch.tensor([1, 2, 3, 4, 5])  x.storage_offset() 0  x[3:].storage_offset() 3   ", "summary": "Returns self tensor\u2019s offset in the underlying storage in terms of number of storage elements (not bytes)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.storage_offset", "parameters": []}},
{"id": "torch.Tensor.storage_type", "type": "method", "code": "torch.Tensor.storage_type()", "example": "NA", "summary": "Returns the type of the underlying storage", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.storage_type", "parameters": []}},
{"id": "torch.Tensor.stride", "type": "method", "code": "torch.Tensor.stride(dim)", "example": "  x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])  x.stride() (5, 1) x.stride(0) 5  x.stride(-1) 1   ", "summary": "Returns the stride of self tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.stride", "parameters": [{"name": "dim", "is_optional": false, "type": "int, optional", "description": " the desired dimension in which stride is required"}]}},
{"id": "torch.Tensor.sub", "type": "method", "code": "torch.Tensor.sub(value,other)", "example": "NA", "summary": "Subtracts a scalar or tensor from self tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sub", "parameters": [{"name": "value", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.sub_", "type": "method", "code": "torch.Tensor.sub_(x)", "example": "NA", "summary": "In-place version of sub() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sub_", "parameters": [{"name": "x", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.sum", "type": "method", "code": "torch.Tensor.sum(dim=None,keepdim=False,dtype=None)", "example": "NA", "summary": "See torch.sum() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sum", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.sum_to_size", "type": "method", "code": "torch.Tensor.sum_to_size(*size)", "example": "NA", "summary": "Sum this tensor to size", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.sum_to_size", "parameters": [{"name": "*size", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.svd", "type": "method", "code": "torch.Tensor.svd(some=True,compute_uv=True)", "example": "NA", "summary": "See torch.svd() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.svd", "parameters": [{"name": "some", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "compute_uv", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,exponent,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "exponent", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(self,exponent,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "self", "is_optional": false, "type": "others", "description": ""}, {"name": "exponent", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.real", "type": "function", "code": "torch.real(input,out=None)", "example": "  torch.real(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j])) tensor([ -1,  -2,  3])   ", "summary": "Computes the element-wise real value of the given input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.real", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.reciprocal", "type": "function", "code": "torch.reciprocal(input,out=None)", "example": "  a = torch.randn(4)  a tensor([-0.4595, -2.1219, -1.4314,  0.7298])  torch.reciprocal(a) tensor([-2.1763, -0.4713, -0.6986,  1.3702])   ", "summary": "Returns a new tensor with the reciprocal of the elements of input  outi=1inputi\\text{out}_{i} = \\frac{1}{\\text{input}_{i}}  outi\u200b=inputi\u200b1\u200b   Parameters  input (Tensor) \u2013 the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.reciprocal", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.remainder", "type": "function", "code": "torch.remainder(input,other,out=None)", "example": "  torch.remainder(torch.tensor([-3., -2, -1, 1, 2, 3]), 2) tensor([ 1.,  0.,  1.,  1.,  0.,  1.])  torch.remainder(torch.tensor([1., 2, 3, 4, 5]), 1.5) tensor([ 1.0000,  0.5000,  0.0000,  1.0000,  0.5000])    See also torch.fmod(), which computes the element-wise remainder of division equivalently to the C library function fmod().  ", "summary": "Computes the element-wise remainder of division", "returns": null, "shape": "NA", "code-info": {"name": "torch.remainder", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the dividend"}, {"name": "other", "is_optional": false, "type": "Tensor or float", "description": " the divisor that may be either a number or aTensor of the same shape as the dividend"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.round", "type": "function", "code": "torch.round(input,out=None)", "example": "  a = torch.randn(4)  a tensor([ 0.9920,  0.6077,  0.9734, -1.0362])  torch.round(a) tensor([ 1.,  1.,  1., -1.])   ", "summary": "Returns a new tensor with each of the elements of input rounded to the closest integer", "returns": null, "shape": "NA", "code-info": {"name": "torch.round", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.rsqrt", "type": "function", "code": "torch.rsqrt(input,out=None)", "example": "  a = torch.randn(4)  a tensor([-0.0370,  0.2970,  1.5420, -0.9105])  torch.rsqrt(a) tensor([    nan,  1.8351,  0.8053,     nan])   ", "summary": "Returns a new tensor with the reciprocal of the square-root of each of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.rsqrt", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.precision_matrix", "type": "attribute", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.precision_matrix", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.precision_matrix", "parameters": []}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.scale_tril", "type": "attribute", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.scale_tril", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.scale_tril", "parameters": []}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.support", "type": "attribute", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.support", "parameters": []}},
{"id": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.variance", "type": "attribute", "code": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.variance", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.variance", "parameters": []}},
{"id": "torch.distributions.multinomial.Multinomial", "type": "class", "code": "torch.distributions.multinomial.Multinomial(total_count=1,probs=None,logits=None,validate_args=None)", "example": "  m = Multinomial(100, torch.tensor([ 1., 1., 1., 1.]))  x = m.sample()  # equal probability of 0, 1, 2, 3 tensor([ 21.,  24.,  30.,  25.])   Multinomial(probs=torch.tensor([1., 1., 1., 1.])).log_prob(x) tensor([-4.1338])    Parameters  total_count (python:int) \u2013 number of trials probs (Tensor) \u2013 event probabilities logits (Tensor) \u2013 event log probabilities      arg_constraints = {'logits': Real(), 'probs': Simplex()}     expand(batch_shape, _instance=None)      log_prob(value)      property logits     property mean     property param_shape     property probs     sample(sample_shape=torch.Size([]))      property support     property variance   ", "summary": "Bases: torch.distributions.distribution.Distribution Creates a Multinomial distribution parameterized by total_count and either probs or logits (but not both)", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multinomial.Multinomial", "parameters": [{"name": "total_count", "is_optional": true, "type": "int", "default_value": "1", "description": " number of trials"}, {"name": "probs", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " event probabilities"}, {"name": "logits", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " event log probabilities"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.multinomial.Multinomial.arg_constraints", "type": "attribute", "code": "torch.distributions.multinomial.Multinomial.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multinomial.Multinomial.arg_constraints", "parameters": []}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal", "type": "class", "code": "torch.distributions.multivariate_normal.MultivariateNormal(loc,covariance_matrix=None,precision_matrix=None,scale_tril=None,validate_args=None)", "example": " m = MultivariateNormal(torch.zeros(2), torch.eye(2))\n m.sample()  # normally distributed with mean=`[0,0]` and covariance_matrix=`I`\ntensor([-0.2102, -0.5429])\n\n", "summary": "Bases: torch.distributions.distribution.Distribution Creates a multivariate normal (also called Gaussian) distribution parameterized by a mean vector and a covariance matrix", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal", "parameters": [{"name": "loc", "is_optional": false, "type": "Tensor", "description": " mean of the distribution"}, {"name": "covariance_matrix", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " positive-definite covariance matrix"}, {"name": "precision_matrix", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " positive-definite precision matrix"}, {"name": "scale_tril", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " lower-triangular factor of covariance, with positive-valued diagonal"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.ConvTranspose3d", "type": "class", "code": "torch.nn.ConvTranspose3d(in_channels:int,out_channels:int,kernel_size:Union[T,Tuple[T,T,T]],stride:Union[T,Tuple[T,T,T]]=1,padding:Union[T,Tuple[T,T,T]]=0,output_padding:Union[T,Tuple[T,T,T]]=0,groups:int=1,bias:bool=True,dilation:Union[T,Tuple[T,T,T]]=1,padding_mode:str='zeros')", "example": "NA", "summary": "Applies a 3D transposed convolution operator over an input image composed of several input planes", "returns": [], "shape": "\nInput: (N,Cin,Din,Hin,Win)(N, C_{in}, D_{in}, H_{in}, W_{in})(N,Cin\u200b,Din\u200b,Hin\u200b,Win\u200b)\n\n\nOutput: (N,Cout,Dout,Hout,Wout)(N, C_{out}, D_{out}, H_{out}, W_{out})(N,Cout\u200b,Dout\u200b,Hout\u200b,Wout\u200b)\n\n where\n\n\nDout=(Din\u22121)\u00d7stride[0]\u22122\u00d7padding[0]+dilation[0]\u00d7(kernel_size[0]\u22121)+output_padding[0]+1D_{out} = (D_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0]\n          \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1\n\nDout\u200b=(Din\u200b\u22121)\u00d7stride[0]\u22122\u00d7padding[0]+dilation[0]\u00d7(kernel_size[0]\u22121)+output_padding[0]+1\n\n\nHout=(Hin\u22121)\u00d7stride[1]\u22122\u00d7padding[1]+dilation[1]\u00d7(kernel_size[1]\u22121)+output_padding[1]+1H_{out} = (H_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1]\n          \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1\n\nHout\u200b=(Hin\u200b\u22121)\u00d7stride[1]\u22122\u00d7padding[1]+dilation[1]\u00d7(kernel_size[1]\u22121)+output_padding[1]+1\n\n\nWout=(Win\u22121)\u00d7stride[2]\u22122\u00d7padding[2]+dilation[2]\u00d7(kernel_size[2]\u22121)+output_padding[2]+1W_{out} = (W_{in} - 1) \\times \\text{stride}[2] - 2 \\times \\text{padding}[2] + \\text{dilation}[2]\n          \\times (\\text{kernel\\_size}[2] - 1) + \\text{output\\_padding}[2] + 1\n\nWout\u200b=(Win\u200b\u22121)\u00d7stride[2]\u22122\u00d7padding[2]+dilation[2]\u00d7(kernel_size[2]\u22121)+output_padding[2]+1\n\n", "code-info": {"name": "torch.nn.ConvTranspose3d", "parameters": [{"name": "in_channels", "type": "int", "is_optional": false, "description": "Number of channels in the input image"}, {"name": "out_channels", "type": "int", "is_optional": false, "description": "Number of channels produced by the convolution"}, {"name": "kernel_size", "type": "Union[T,Tuple[T,T,T]]", "is_optional": false, "description": "Size of the convolving kernel"}, {"name": "stride", "type": "Union[T,Tuple[T,T,T]]", "default_value": "1", "is_optional": true, "description": "Stride of the convolution. Default: 1"}, {"name": "padding", "type": "Union[T,Tuple[T,T,T]]", "default_value": "0", "is_optional": true, "description": "dilation * (kernel_size - 1) - padding zero-paddingwill be added to both sides of each dimension in the input. Default: 0"}, {"name": "output_padding", "type": "Union[T,Tuple[T,T,T]]", "default_value": "0", "is_optional": true, "description": "Additional size added to one sideof each dimension in the output shape. Default: 0"}, {"name": "groups", "type": "int", "default_value": "1", "is_optional": true, "description": "Number of blocked connections from input channels to output channels. Default: 1"}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": true, "description": "If True, adds a learnable bias to the output. Default: True"}, {"name": "dilation", "type": "Union[T,Tuple[T,T,T]]", "default_value": "1", "is_optional": true, "description": "Spacing between kernel elements. Default: 1"}, {"name": "padding_mode", "type": "str", "default_value": "'zeros'", "is_optional": false, "description": ""}]}},
{"id": "torch.Tensor.symeig", "type": "method", "code": "torch.Tensor.symeig(eigenvectors=False,upper=True)", "example": "NA", "summary": "See torch.symeig() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.symeig", "parameters": [{"name": "eigenvectors", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.Tensor.t", "type": "method", "code": "torch.Tensor.t()", "example": "NA", "summary": "See torch.t() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.t", "parameters": []}},
{"id": "torch.Tensor.t_", "type": "method", "code": "torch.Tensor.t_()", "example": "NA", "summary": "In-place version of t() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.t_", "parameters": []}},
{"id": "torch.Tensor.to", "type": "method", "code": "torch.Tensor.to(*args,**kwargs)", "example": "  tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu  tensor.to(torch.float64) tensor([[-0.5044,  0.0005],         [ 0.3310, -0.0584]], dtype=torch.float64)   cuda0 = torch.device('cuda:0')  tensor.to(cuda0) tensor([[-0.5044,  0.0005],         [ 0.3310, -0.0584]], device='cuda:0')   tensor.to(cuda0, dtype=torch.float64) tensor([[-0.5044,  0.0005],         [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')   other = torch.randn((), dtype=torch.float64, device=cuda0)  tensor.to(other, non_blocking=True) tensor([[-0.5044,  0.0005],         [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')   ", "summary": "Performs Tensor dtype and/or device conversion", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.to", "parameters": [{"name": "*args", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.to_mkldnn", "type": "method", "code": "torch.Tensor.to_mkldnn()", "example": "NA", "summary": "Returns a copy of the tensor in torch.mkldnn layout", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.to_mkldnn", "parameters": []}},
{"id": "torch.Tensor.take", "type": "method", "code": "torch.Tensor.take(indices)", "example": "NA", "summary": "See torch.take() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.take", "parameters": [{"name": "indices", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.tan", "type": "method", "code": "torch.Tensor.tan()", "example": "NA", "summary": "See torch.tan() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.tan", "parameters": []}},
{"id": "torch.Tensor.tan_", "type": "method", "code": "torch.Tensor.tan_()", "example": "NA", "summary": "In-place version of tan() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.tan_", "parameters": []}},
{"id": "torch.Tensor.tanh", "type": "method", "code": "torch.Tensor.tanh()", "example": "NA", "summary": "See torch.tanh() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.tanh", "parameters": []}},
{"id": "torch.Tensor.tanh_", "type": "method", "code": "torch.Tensor.tanh_()", "example": "NA", "summary": "In-place version of tanh() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.tanh_", "parameters": []}},
{"id": "torch.sigmoid", "type": "function", "code": "torch.sigmoid(input,out=None)", "example": "  a = torch.randn(4)  a tensor([ 0.9213,  1.0887, -0.8858, -1.7683])  torch.sigmoid(a) tensor([ 0.7153,  0.7481,  0.2920,  0.1458])   ", "summary": "Returns a new tensor with the sigmoid of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.sigmoid", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.sign", "type": "function", "code": "torch.sign(input,out=None)", "example": "  a = torch.tensor([0.7, -1.2, 0., 2.3])  a tensor([ 0.7000, -1.2000,  0.0000,  2.3000])  torch.sign(a) tensor([ 1., -1.,  0.,  1.])   ", "summary": "Returns a new tensor with the signs of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.sign", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.sin", "type": "function", "code": "torch.sin(input,out=None)", "example": "  a = torch.randn(4)  a tensor([-0.5461,  0.1347, -2.7266, -0.2746])  torch.sin(a) tensor([-0.5194,  0.1343, -0.4032, -0.2711])   ", "summary": "Returns a new tensor with the sine of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.sin", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.sinh", "type": "function", "code": "torch.sinh(input,out=None)", "example": "  a = torch.randn(4)  a tensor([ 0.5380, -0.8632, -0.1265,  0.9399])  torch.sinh(a) tensor([ 0.5644, -0.9744, -0.1268,  1.0845])   ", "summary": "Returns a new tensor with the hyperbolic sine of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.sinh", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.sqrt", "type": "function", "code": "torch.sqrt(input,out=None)", "example": "  a = torch.randn(4)  a tensor([-2.0755,  1.0226,  0.0831,  0.4806])  torch.sqrt(a) tensor([    nan,  1.0112,  0.2883,  0.6933])   ", "summary": "Returns a new tensor with the square-root of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.sqrt", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.tan", "type": "function", "code": "torch.tan(input,out=None)", "example": "  a = torch.randn(4)  a tensor([-1.2027, -1.7687,  0.4412, -1.3856])  torch.tan(a) tensor([-2.5930,  4.9859,  0.4722, -5.3366])   ", "summary": "Returns a new tensor with the tangent of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.tan", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.arg_constraints", "type": "attribute", "code": "torch.distributions.multivariate_normal.MultivariateNormal.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.arg_constraints", "parameters": []}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix", "type": "attribute", "code": "torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix", "parameters": []}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.has_rsample", "type": "attribute", "code": "torch.distributions.multivariate_normal.MultivariateNormal.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.has_rsample", "parameters": []}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix", "type": "attribute", "code": "torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix", "parameters": []}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.scale_tril", "type": "attribute", "code": "torch.distributions.multivariate_normal.MultivariateNormal.scale_tril", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.scale_tril", "parameters": []}},
{"id": "torch.distributions.multivariate_normal.MultivariateNormal.support", "type": "attribute", "code": "torch.distributions.multivariate_normal.MultivariateNormal.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.multivariate_normal.MultivariateNormal.support", "parameters": []}},
{"id": "torch.distributions.negative_binomial.NegativeBinomial", "type": "class", "code": "torch.distributions.negative_binomial.NegativeBinomial(total_count,probs=None,logits=None,validate_args=None)", "example": "NA", "summary": "Bases: torch.distributions.distribution.Distribution Creates a Negative Binomial distribution, i.e", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial", "parameters": [{"name": "total_count", "is_optional": false, "type": "float or Tensor", "description": " non-negative number of negative Bernoullitrials to stop, although the distribution is still valid for realvalued count"}, {"name": "probs", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " Event probabilities of success in the half open interval [0, 1"}, {"name": "logits", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " Event log-odds for probabilities of success"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.negative_binomial.NegativeBinomial.arg_constraints", "type": "attribute", "code": "torch.distributions.negative_binomial.NegativeBinomial.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.arg_constraints", "parameters": []}},
{"id": "torch.distributions.negative_binomial.NegativeBinomial.logits", "type": "attribute", "code": "torch.distributions.negative_binomial.NegativeBinomial.logits", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.logits", "parameters": []}},
{"id": "torch.distributions.negative_binomial.NegativeBinomial.probs", "type": "attribute", "code": "torch.distributions.negative_binomial.NegativeBinomial.probs", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.probs", "parameters": []}},
{"id": "torch.distributions.negative_binomial.NegativeBinomial.support", "type": "attribute", "code": "torch.distributions.negative_binomial.NegativeBinomial.support(lower_bound=0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.negative_binomial.NegativeBinomial.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.nn.Unfold", "type": "class", "code": "torch.nn.Unfold(kernel_size:Union[T,Tuple[T,...]],dilation:Union[T,Tuple[T,...]]=1,padding:Union[T,Tuple[T,...]]=0,stride:Union[T,Tuple[T,...]]=1)", "example": "NA", "summary": "Extracts sliding local blocks from a batched input tensor", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Unfold", "parameters": [{"name": "kernel_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the size of the sliding blocks"}, {"name": "dilation", "type": "Union[T,Tuple[T,...]]", "default_value": "1", "is_optional": true, "description": "a parameter that controls thestride of elements within theneighborhood. Default: 1"}, {"name": "padding", "type": "Union[T,Tuple[T,...]]", "default_value": "0", "is_optional": true, "description": "implicit zero padding to be added onboth sides of input. Default: 0"}, {"name": "stride", "type": "Union[T,Tuple[T,...]]", "default_value": "1", "is_optional": true, "description": "the stride of the sliding blocks in the inputspatial dimensions. Default: 1"}]}},
{"id": "torch.nn.Fold", "type": "class", "code": "torch.nn.Fold(output_size:Union[T,Tuple[T,...]],kernel_size:Union[T,Tuple[T,...]],dilation:Union[T,Tuple[T,...]]=1,padding:Union[T,Tuple[T,...]]=0,stride:Union[T,Tuple[T,...]]=1)", "example": "NA", "summary": "Combines an array of sliding local blocks into a large containing tensor", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Fold", "parameters": [{"name": "output_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the shape of the spatial dimensions of theoutput (i.e., output.sizes()[2:])"}, {"name": "kernel_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the size of the sliding blocks"}, {"name": "dilation", "type": "Union[T,Tuple[T,...]]", "default_value": "1", "is_optional": true, "description": "a parameter that controls thestride of elements within theneighborhood. Default: 1"}, {"name": "padding", "type": "Union[T,Tuple[T,...]]", "default_value": "0", "is_optional": true, "description": "implicit zero padding to be added onboth sides of input. Default: 0"}, {"name": "stride", "type": "Union[T,Tuple[T,...]]", "default_value": "1", "is_optional": false, "description": "the stride of the sliding blocks in the inputspatial dimensions. Default: 1"}]}},
{"id": "torch.Tensor.tolist", "type": "method", "code": "torch.Tensor.tolist()", "example": " a = torch.randn(2, 2)\n a.tolist()\n[[0.012766935862600803, 0.5415473580360413],\n [-0.08909505605697632, 0.7729271650314331]]\n a[0,0].tolist()\n0.012766935862600803\n\n", "summary": "\u201d tolist() -&gt; list or number Returns the tensor as a (nested) list", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.tolist", "parameters": []}},
{"id": "torch.Tensor.topk", "type": "method", "code": "torch.Tensor.topk(k,dim=None,largest=True,sorted=True)", "example": "NA", "summary": "See torch.topk() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.topk", "parameters": [{"name": "k", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "largest", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "sorted", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.Tensor.trace", "type": "method", "code": "torch.Tensor.trace()", "example": "NA", "summary": "See torch.trace() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.trace", "parameters": []}},
{"id": "torch.Tensor.transpose", "type": "method", "code": "torch.Tensor.transpose(dim0,dim1)", "example": "NA", "summary": "See torch.transpose() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.transpose", "parameters": [{"name": "dim0", "is_optional": false, "type": "others", "description": ""}, {"name": "dim1", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.transpose_", "type": "method", "code": "torch.Tensor.transpose_(dim0,dim1)", "example": "NA", "summary": "In-place version of transpose() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.transpose_", "parameters": [{"name": "dim0", "is_optional": false, "type": "others", "description": ""}, {"name": "dim1", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.triangular_solve", "type": "method", "code": "torch.Tensor.triangular_solve(A,upper=True,transpose=False,unitriangular=False)", "example": "NA", "summary": "See torch.triangular_solve() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.triangular_solve", "parameters": [{"name": "A", "is_optional": false, "type": "others", "description": ""}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "transpose", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "unitriangular", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.tril", "type": "method", "code": "torch.Tensor.tril(k=0)", "example": "NA", "summary": "See torch.tril() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.tril", "parameters": [{"name": "k", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.Tensor.tril_", "type": "method", "code": "torch.Tensor.tril_(k=0)", "example": "NA", "summary": "In-place version of tril() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.tril_", "parameters": [{"name": "k", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.Tensor.triu", "type": "method", "code": "torch.Tensor.triu(k=0)", "example": "NA", "summary": "See torch.triu() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.triu", "parameters": [{"name": "k", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.Tensor.triu_", "type": "method", "code": "torch.Tensor.triu_(k=0)", "example": "NA", "summary": "In-place version of triu() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.triu_", "parameters": [{"name": "k", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.tanh", "type": "function", "code": "torch.tanh(input,out=None)", "example": "  a = torch.randn(4)  a tensor([ 0.8986, -0.7279,  1.1745,  0.2611])  torch.tanh(a) tensor([ 0.7156, -0.6218,  0.8257,  0.2553])   ", "summary": "Returns a new tensor with the hyperbolic tangent of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.tanh", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.trunc", "type": "function", "code": "torch.trunc(input,out=None)", "example": "  a = torch.randn(4)  a tensor([ 3.4742,  0.5466, -0.8008, -0.9079])  torch.trunc(a) tensor([ 3.,  0., -0., -0.])   ", "summary": "Returns a new tensor with the truncated integer values of the elements of input", "returns": null, "shape": "NA", "code-info": {"name": "torch.trunc", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.argmax", "type": "function", "code": "torch.argmax()", "example": "  a = torch.randn(4, 4)  a tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],         [-0.7401, -0.8805, -0.3402, -1.1936],         [ 0.4907, -1.3948, -1.0691, -0.3132],         [-1.6092,  0.5419, -0.2993,  0.3195]])  torch.argmax(a) tensor(0)     torch.argmax(input, dim, keepdim=False) \u2192 LongTensor   Returns the indices of the maximum values of a tensor across a dimension. This is the second value returned by torch.max(). See its documentation for the exact semantics of this method.  Parameters  input (Tensor) \u2013 the input tensor. dim (python:int) \u2013 the dimension to reduce. If None, the argmax of the flattened input is returned. keepdim (bool) \u2013 whether the output tensor has dim retained or not. Ignored if dim=None.    ", "summary": "  torch.argmax(input) \u2192 LongTensor   Returns the indices of the maximum value of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.argmax", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,dim,keepdim=False)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.argmin", "type": "function", "code": "torch.argmin()", "example": "  a = torch.randn(4, 4)  a tensor([[ 0.1139,  0.2254, -0.1381,  0.3687],         [ 1.0100, -1.1975, -0.0102, -0.4732],         [-0.9240,  0.1207, -0.7506, -1.0213],         [ 1.7809, -1.2960,  0.9384,  0.1438]])  torch.argmin(a) tensor(13)     torch.argmin(input, dim, keepdim=False, out=None) \u2192 LongTensor   Returns the indices of the minimum values of a tensor across a dimension. This is the second value returned by torch.min(). See its documentation for the exact semantics of this method.  Parameters  input (Tensor) \u2013 the input tensor. dim (python:int) \u2013 the dimension to reduce. If None, the argmin of the flattened input is returned. keepdim (bool) \u2013 whether the output tensor has dim retained or not. Ignored if dim=None.    ", "summary": "  torch.argmin(input) \u2192 LongTensor   Returns the indices of the minimum value of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.argmin", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,dim,keepdim=False,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.normal.Normal", "type": "class", "code": "torch.distributions.normal.Normal(loc,scale,validate_args=None)", "example": "  m = Normal(torch.tensor([0.0]), torch.tensor([1.0]))  m.sample()  # normally distributed with loc=0 and scale=1 tensor([ 0.1046])    Parameters  loc (python:float or Tensor) \u2013 mean of the distribution (often referred to as mu) scale (python:float or Tensor) \u2013 standard deviation of the distribution (often referred to as sigma)      arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}     cdf(value)      entropy()      expand(batch_shape, _instance=None)      has_rsample = True     icdf(value)      log_prob(value)      property mean     rsample(sample_shape=torch.Size([]))      sample(sample_shape=torch.Size([]))      property stddev     support = Real()     property variance   ", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily Creates a normal (also called Gaussian) distribution parameterized by loc and scale", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal", "parameters": [{"name": "loc", "is_optional": false, "type": "float or Tensor", "description": " mean of the distribution (often referred to as mu"}, {"name": "scale", "is_optional": false, "type": "float or Tensor", "description": " standard deviation of the distribution(often referred to as sigma"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.normal.Normal.arg_constraints", "type": "attribute", "code": "torch.distributions.normal.Normal.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.arg_constraints", "parameters": []}},
{"id": "torch.distributions.normal.Normal.has_rsample", "type": "attribute", "code": "torch.distributions.normal.Normal.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.has_rsample", "parameters": []}},
{"id": "torch.distributions.normal.Normal.support", "type": "attribute", "code": "torch.distributions.normal.Normal.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.normal.Normal.support", "parameters": []}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical", "type": "class", "code": "torch.distributions.one_hot_categorical.OneHotCategorical(probs=None,logits=None,validate_args=None)", "example": "  m = OneHotCategorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))  m.sample()  # equal probability of 0, 1, 2, 3 tensor([ 0.,  0.,  0.,  1.])    Parameters  probs (Tensor) \u2013 event probabilities logits (Tensor) \u2013 event log probabilities      arg_constraints = {'logits': Real(), 'probs': Simplex()}     entropy()      enumerate_support(expand=True)      expand(batch_shape, _instance=None)      has_enumerate_support = True     log_prob(value)      property logits     property mean     property param_shape     property probs     sample(sample_shape=torch.Size([]))      support = Simplex()     property variance   ", "summary": "Bases: torch.distributions.distribution.Distribution Creates a one-hot categorical distribution parameterized by probs or logits", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical", "parameters": [{"name": "probs", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " event probabilities"}, {"name": "logits", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " event log probabilities"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.arg_constraints", "type": "attribute", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.arg_constraints", "parameters": []}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.has_enumerate_support", "type": "attribute", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.has_enumerate_support", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.has_enumerate_support", "parameters": []}},
{"id": "torch.distributions.one_hot_categorical.OneHotCategorical.support", "type": "attribute", "code": "torch.distributions.one_hot_categorical.OneHotCategorical.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.one_hot_categorical.OneHotCategorical.support", "parameters": []}},
{"id": "torch.distributions.pareto.Pareto", "type": "class", "code": "torch.distributions.pareto.Pareto(scale,alpha,validate_args=None)", "example": "  m = Pareto(torch.tensor([1.0]), torch.tensor([1.0]))  m.sample()  # sample from a Pareto distribution with scale=1 and alpha=1 tensor([ 1.5623])    Parameters  scale (python:float or Tensor) \u2013 Scale parameter of the distribution alpha (python:float or Tensor) \u2013 Shape parameter of the distribution      arg_constraints = {'alpha': GreaterThan(lower_bound=0.0), 'scale': GreaterThan(lower_bound=0.0)}     entropy()      expand(batch_shape, _instance=None)      property mean     property support     property variance   ", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution Samples from a Pareto Type 1 distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.pareto.Pareto", "parameters": [{"name": "scale", "is_optional": false, "type": "float or Tensor", "description": " Scale parameter of the distribution"}, {"name": "alpha", "is_optional": false, "type": "float or Tensor", "description": " Shape parameter of the distribution"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.MaxPool1d", "type": "class", "code": "torch.nn.MaxPool1d(kernel_size:Union[T,Tuple[T,...]],stride:Optional[Union[T,Tuple[T,...]]]=None,padding:Union[T,Tuple[T,...]]=0,dilation:Union[T,Tuple[T,...]]=1,return_indices:bool=False,ceil_mode:bool=False)", "example": "NA", "summary": "Applies a 1D max pooling over an input signal composed of several input planes", "returns": [], "shape": "\nInput: (N,C,Lin)(N, C, L_{in})(N,C,Lin\u200b)\n\n\nOutput: (N,C,Lout)(N, C, L_{out})(N,C,Lout\u200b)\n\n, where\n\nLout=\u230aLin+2\u00d7padding\u2212dilation\u00d7(kernel_size\u22121)\u22121stride+1\u230bL_{out} = \\left\\lfloor \\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n      \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\n\nLout\u200b=\u230astrideLin\u200b+2\u00d7padding\u2212dilation\u00d7(kernel_size\u22121)\u22121\u200b+1\u230b\n\n\n\n", "code-info": {"name": "torch.nn.MaxPool1d", "parameters": [{"name": "kernel_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the size of the window to take a max over"}, {"name": "stride", "type": "Optional[Union[T,Tuple[T,...]]]", "default_value": "None", "is_optional": false, "description": "the stride of the window. Default value is kernel_size"}, {"name": "padding", "type": "Union[T,Tuple[T,...]]", "default_value": "0", "is_optional": false, "description": "implicit zero padding to be added on both sides"}, {"name": "dilation", "type": "Union[T,Tuple[T,...]]", "default_value": "1", "is_optional": false, "description": "a parameter that controls the stride of elements in the window"}, {"name": "return_indices", "type": "bool", "default_value": "False", "is_optional": false, "description": "if True, will return the max indices along with the outputs.Useful for torch.nn.MaxUnpool1d later"}, {"name": "ceil_mode", "type": "bool", "default_value": "False", "is_optional": false, "description": "when True, will use ceil instead of floor to compute the output shape"}]}},
{"id": "torch.nn.MaxPool2d", "type": "class", "code": "torch.nn.MaxPool2d(kernel_size:Union[T,Tuple[T,...]],stride:Optional[Union[T,Tuple[T,...]]]=None,padding:Union[T,Tuple[T,...]]=0,dilation:Union[T,Tuple[T,...]]=1,return_indices:bool=False,ceil_mode:bool=False)", "example": "NA", "summary": "Applies a 2D max pooling over an input signal composed of several input planes", "returns": [], "shape": "\nInput: (N,C,Hin,Win)(N, C, H_{in}, W_{in})(N,C,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Hout,Wout)(N, C, H_{out}, W_{out})(N,C,Hout\u200b,Wout\u200b)\n\n, where\n\nHout=\u230aHin+2\u2217padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121stride[0]+1\u230bH_{out} = \\left\\lfloor\\frac{H_{in} + 2 * \\text{padding[0]} - \\text{dilation[0]}\n      \\times (\\text{kernel\\_size[0]} - 1) - 1}{\\text{stride[0]}} + 1\\right\\rfloor\n\nHout\u200b=\u230astride[0]Hin\u200b+2\u2217padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121\u200b+1\u230b\n\n\nWout=\u230aWin+2\u2217padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121stride[1]+1\u230bW_{out} = \\left\\lfloor\\frac{W_{in} + 2 * \\text{padding[1]} - \\text{dilation[1]}\n      \\times (\\text{kernel\\_size[1]} - 1) - 1}{\\text{stride[1]}} + 1\\right\\rfloor\n\nWout\u200b=\u230astride[1]Win\u200b+2\u2217padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121\u200b+1\u230b\n\n\n\n", "code-info": {"name": "torch.nn.MaxPool2d", "parameters": [{"name": "kernel_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the size of the window to take a max over"}, {"name": "stride", "type": "Optional[Union[T,Tuple[T,...]]]", "default_value": "None", "is_optional": false, "description": "the stride of the window. Default value is kernel_size"}, {"name": "padding", "type": "Union[T,Tuple[T,...]]", "default_value": "0", "is_optional": false, "description": "implicit zero padding to be added on both sides"}, {"name": "dilation", "type": "Union[T,Tuple[T,...]]", "default_value": "1", "is_optional": false, "description": "a parameter that controls the stride of elements in the window"}, {"name": "return_indices", "type": "bool", "default_value": "False", "is_optional": false, "description": "if True, will return the max indices along with the outputs.Useful for torch.nn.MaxUnpool2d later"}, {"name": "ceil_mode", "type": "bool", "default_value": "False", "is_optional": false, "description": "when True, will use ceil instead of floor to compute the output shape"}]}},
{"id": "torch.Tensor.trunc", "type": "method", "code": "torch.Tensor.trunc()", "example": "NA", "summary": "See torch.trunc() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.trunc", "parameters": []}},
{"id": "torch.Tensor.trunc_", "type": "method", "code": "torch.Tensor.trunc_()", "example": "NA", "summary": "In-place version of trunc() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.trunc_", "parameters": []}},
{"id": "torch.Tensor.type", "type": "method", "code": "torch.Tensor.type(dtype=None,non_blocking=False,**kwargs)", "example": "NA", "summary": "Returns the type if dtype is not provided, else casts this object to the specified type", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.type", "parameters": [{"name": "dtype", "is_optional": true, "type": "type or string", "default_value": "None", "description": " The desired type"}, {"name": "non_blocking", "is_optional": true, "type": "bool", "default_value": "False", "description": " If True, and the source is in pinned memoryand destination is on the GPU or vice versa, the copy is performedasynchronously with respect to the host. Otherwise, the argumenthas no effect."}, {"name": "**kwargs", "is_optional": false, "type": "**kwargs : For compatibility, may contain the key async in place ofthe non_blocking argument. The async arg is deprecated", "description": " For compatibility, may contain the key async in place ofthe non_blocking argument. The async arg is deprecated."}]}},
{"id": "torch.Tensor.type_as", "type": "method", "code": "torch.Tensor.type_as(tensor)", "example": "NA", "summary": "Returns this tensor cast to the type of the given tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.type_as", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " the tensor which has the desired type"}]}},
{"id": "torch.Tensor.unbind", "type": "method", "code": "torch.Tensor.unbind(dim=0)", "example": "NA", "summary": "See torch.unbind() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.unbind", "parameters": [{"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.Tensor.unfold", "type": "method", "code": "torch.Tensor.unfold(dimension,size,step)", "example": "  x = torch.arange(1., 8)  x tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])  x.unfold(0, 2, 1) tensor([[ 1.,  2.],         [ 2.,  3.],         [ 3.,  4.],         [ 4.,  5.],         [ 5.,  6.],         [ 6.,  7.]])  x.unfold(0, 2, 2) tensor([[ 1.,  2.],         [ 3.,  4.],         [ 5.,  6.]])   ", "summary": "Returns a tensor which contains all slices of size size from self tensor in the dimension dimension", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.unfold", "parameters": [{"name": "dimension", "is_optional": false, "type": "int", "description": " dimension in which unfolding happens"}, {"name": "size", "is_optional": false, "type": "int", "description": " the size of each slice that is unfolded"}, {"name": "step", "is_optional": false, "type": "int", "description": " the step between each slice"}]}},
{"id": "torch.Tensor.uniform_", "type": "method", "code": "torch.Tensor.uniform_(from=0,to=1)", "example": "NA", "summary": "Fills self tensor with numbers sampled from the continuous uniform distribution:  P(x)=1to\u2212fromP(x) = \\dfrac{1}{\\text{to} - \\text{from}}  P(x)=to\u2212from1\u200b  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.uniform_", "parameters": [{"name": "from", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "to", "is_optional": true, "type": "int", "default_value": "1", "description": ""}]}},
{"id": "torch.Tensor.unique", "type": "method", "code": "torch.Tensor.unique(sorted=True,return_inverse=False,return_counts=False,dim=None)", "example": "NA", "summary": "Returns the unique elements of the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.unique", "parameters": [{"name": "sorted", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "return_inverse", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "return_counts", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.unique_consecutive", "type": "method", "code": "torch.Tensor.unique_consecutive(return_inverse=False,return_counts=False,dim=None)", "example": "NA", "summary": "Eliminates all but the first element from every consecutive group of equivalent elements", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.unique_consecutive", "parameters": [{"name": "return_inverse", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "return_counts", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.Tensor.unsqueeze", "type": "method", "code": "torch.Tensor.unsqueeze(dim)", "example": "NA", "summary": "See torch.unsqueeze() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.unsqueeze", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.dist", "type": "function", "code": "torch.dist(input,other,p=2)", "example": "  x = torch.randn(4)  x tensor([-1.5393, -0.8675,  0.5916,  1.6321])  y = torch.randn(4)  y tensor([ 0.0967, -1.0511,  0.6295,  0.8360])  torch.dist(x, y, 3.5) tensor(1.6727)  torch.dist(x, y, 3) tensor(1.6973)  torch.dist(x, y, 0) tensor(inf)  torch.dist(x, y, 1) tensor(2.6537)   ", "summary": "Returns the p-norm of (input - other) The shapes of input and other must be broadcastable", "returns": null, "shape": "NA", "code-info": {"name": "torch.dist", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "other", "is_optional": false, "type": "Tensor", "description": " the Right-hand-side input tensor"}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": " the norm to be computed"}]}},
{"id": "torch.logsumexp", "type": "function", "code": "torch.logsumexp(input,dim,keepdim=False,out=None)", "example": ": a = torch.randn(3, 3)  torch.logsumexp(a, 1) tensor([ 0.8442,  1.4322,  0.8711])     ", "summary": "Returns the log of summed exponentials of each row of the input tensor in the given dimension dim", "returns": null, "shape": "NA", "code-info": {"name": "torch.logsumexp", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "dim", "is_optional": false, "type": "int or tuple of ints", "description": " the dimension or dimensions to reduce."}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether the output tensor has dim retained or not."}, {"name": "out", "is_optional": true, "type": "bool", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.mean", "type": "function", "code": "torch.mean()", "example": "  a = torch.randn(1, 3)  a tensor([[ 0.2294, -0.5481,  1.3288]])  torch.mean(a) tensor(0.3367)     torch.mean(input, dim, keepdim=False, out=None) \u2192 Tensor   Returns the mean value of each row of the input tensor in the given dimension dim. If dim is a list of dimensions, reduce over all of them. If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s).  Parameters  input (Tensor) \u2013 the input tensor. dim (python:int or tuple of python:ints) \u2013 the dimension or dimensions to reduce. keepdim (bool) \u2013 whether the output tensor has dim retained or not. out (Tensor, optional) \u2013 the output tensor.    ", "summary": "  torch.mean(input) \u2192 Tensor   Returns the mean value of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.mean", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,dim,keepdim=False,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.median", "type": "function", "code": "torch.median()", "example": "  a = torch.randn(1, 3)  a tensor([[ 1.5219, -1.5212,  0.2202]])  torch.median(a) tensor(0.2202)     torch.median(input, dim=-1, keepdim=False, values=None, indices=None) - (Tensor, LongTensor)   Returns a namedtuple (values, indices) where values is the median value of each row of the input tensor in the given dimension dim. And indices is the index location of each median value found. By default, dim is the last dimension of the input tensor. If keepdim is True, the output tensors are of the same size as input except in the dimension dim where they are of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the outputs tensor having 1 fewer dimension than input.  Parameters  input (Tensor) \u2013 the input tensor. dim (python:int) \u2013 the dimension to reduce. keepdim (bool) \u2013 whether the output tensor has dim retained or not. values (Tensor, optional) \u2013 the output tensor indices (Tensor, optional) \u2013 the output index tensor    ", "summary": "  torch.median(input) \u2192 Tensor   Returns the median value of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.median", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,dim=-1,keepdim=False,values=None,indices=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "values", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "indices", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.pareto.Pareto.arg_constraints", "type": "attribute", "code": "torch.distributions.pareto.Pareto.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.pareto.Pareto.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.poisson.Poisson", "type": "class", "code": "torch.distributions.poisson.Poisson(rate,validate_args=None)", "example": "  m = Poisson(torch.tensor([4]))  m.sample() tensor([ 3.])    Parameters rate (Number, Tensor) \u2013 the rate parameter     arg_constraints = {'rate': GreaterThan(lower_bound=0.0)}     expand(batch_shape, _instance=None)      log_prob(value)      property mean     sample(sample_shape=torch.Size([]))      support = IntegerGreaterThan(lower_bound=0)     property variance   ", "summary": "Bases: torch.distributions.exp_family.ExponentialFamily Creates a Poisson distribution parameterized by rate, the rate parameter", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.poisson.Poisson", "parameters": [{"name": "rate", "is_optional": false, "type": "Number, Tensor", "description": " the rate parameter"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.poisson.Poisson.arg_constraints", "type": "attribute", "code": "torch.distributions.poisson.Poisson.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.poisson.Poisson.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.poisson.Poisson.support", "type": "attribute", "code": "torch.distributions.poisson.Poisson.support(lower_bound=0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.poisson.Poisson.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli", "type": "class", "code": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli(temperature,probs=None,logits=None,validate_args=None)", "example": "  m = RelaxedBernoulli(torch.tensor([2.2]),                          torch.tensor([0.1, 0.2, 0.3, 0.99]))  m.sample() tensor([ 0.2951,  0.3442,  0.8918,  0.9021])    Parameters  temperature (Tensor) \u2013 relaxation temperature probs (Number, Tensor) \u2013 the probability of sampling 1 logits (Number, Tensor) \u2013 the log-odds of sampling 1      arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)}     expand(batch_shape, _instance=None)      has_rsample = True     property logits     property probs     support = Interval(lower_bound=0.0, upper_bound=1.0)     property temperature   ", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution Creates a RelaxedBernoulli distribution, parametrized by temperature, and either probs or logits (but not both)", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli", "parameters": [{"name": "temperature", "is_optional": false, "type": "Tensor", "description": " relaxation temperature"}, {"name": "probs", "is_optional": true, "type": "Number, Tensor", "default_value": "None", "description": " the probability of sampling 1"}, {"name": "logits", "is_optional": true, "type": "Number, Tensor", "default_value": "None", "description": " the log-odds of sampling 1"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.arg_constraints", "type": "attribute", "code": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.arg_constraints", "parameters": []}},
{"id": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.has_rsample", "type": "attribute", "code": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.has_rsample", "parameters": []}},
{"id": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.support", "type": "attribute", "code": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.support(lower_bound=0.0,upper_bound=1.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}, {"name": "upper_bound", "is_optional": true, "type": "others", "default_value": "1.0", "description": ""}]}},
{"id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli", "type": "class", "code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli(temperature,probs=None,logits=None,validate_args=None)", "example": "NA", "summary": "Bases: torch.distributions.distribution.Distribution Creates a LogitRelaxedBernoulli distribution parameterized by probs or logits (but not both), which is the logit of a RelaxedBernoulli distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli", "parameters": [{"name": "temperature", "is_optional": false, "type": "Tensor", "description": " relaxation temperature"}, {"name": "probs", "is_optional": true, "type": "Number, Tensor", "default_value": "None", "description": " the probability of sampling 1"}, {"name": "logits", "is_optional": true, "type": "Number, Tensor", "default_value": "None", "description": " the log-odds of sampling 1"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.MaxPool3d", "type": "class", "code": "torch.nn.MaxPool3d(kernel_size:Union[T,Tuple[T,...]],stride:Optional[Union[T,Tuple[T,...]]]=None,padding:Union[T,Tuple[T,...]]=0,dilation:Union[T,Tuple[T,...]]=1,return_indices:bool=False,ceil_mode:bool=False)", "example": "NA", "summary": "Applies a 3D max pooling over an input signal composed of several input planes", "returns": [], "shape": "\nInput: (N,C,Din,Hin,Win)(N, C, D_{in}, H_{in}, W_{in})(N,C,Din\u200b,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Dout,Hout,Wout)(N, C, D_{out}, H_{out}, W_{out})(N,C,Dout\u200b,Hout\u200b,Wout\u200b)\n\n, where\n\nDout=\u230aDin+2\u00d7padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121stride[0]+1\u230bD_{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times\n  (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n\nDout\u200b=\u230astride[0]Din\u200b+2\u00d7padding[0]\u2212dilation[0]\u00d7(kernel_size[0]\u22121)\u22121\u200b+1\u230b\n\n\nHout=\u230aHin+2\u00d7padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121stride[1]+1\u230bH_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times\n  (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n\nHout\u200b=\u230astride[1]Hin\u200b+2\u00d7padding[1]\u2212dilation[1]\u00d7(kernel_size[1]\u22121)\u22121\u200b+1\u230b\n\n\nWout=\u230aWin+2\u00d7padding[2]\u2212dilation[2]\u00d7(kernel_size[2]\u22121)\u22121stride[2]+1\u230bW_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] - \\text{dilation}[2] \\times\n  (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor\n\nWout\u200b=\u230astride[2]Win\u200b+2\u00d7padding[2]\u2212dilation[2]\u00d7(kernel_size[2]\u22121)\u22121\u200b+1\u230b\n\n\n\n", "code-info": {"name": "torch.nn.MaxPool3d", "parameters": [{"name": "kernel_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the size of the window to take a max over"}, {"name": "stride", "type": "Optional[Union[T,Tuple[T,...]]]", "default_value": "None", "is_optional": false, "description": "the stride of the window. Default value is kernel_size"}, {"name": "padding", "type": "Union[T,Tuple[T,...]]", "default_value": "0", "is_optional": false, "description": "implicit zero padding to be added on all three sides"}, {"name": "dilation", "type": "Union[T,Tuple[T,...]]", "default_value": "1", "is_optional": false, "description": "a parameter that controls the stride of elements in the window"}, {"name": "return_indices", "type": "bool", "default_value": "False", "is_optional": false, "description": "if True, will return the max indices along with the outputs.Useful for torch.nn.MaxUnpool3d later"}, {"name": "ceil_mode", "type": "bool", "default_value": "False", "is_optional": false, "description": "when True, will use ceil instead of floor to compute the output shape"}]}},
{"id": "torch.Tensor.unsqueeze_", "type": "method", "code": "torch.Tensor.unsqueeze_(dim)", "example": "NA", "summary": "In-place version of unsqueeze() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.unsqueeze_", "parameters": [{"name": "dim", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.values", "type": "method", "code": "torch.Tensor.values()", "example": "NA", "summary": "If self is a sparse COO tensor (i.e., with torch.sparse_coo layout), this returns a view of the contained values tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.values", "parameters": []}},
{"id": "torch.Tensor.var", "type": "method", "code": "torch.Tensor.var(dim=None,unbiased=True,keepdim=False)", "example": "NA", "summary": "See torch.var() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.var", "parameters": [{"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.Tensor.view", "type": "method", "code": "torch.Tensor.view(*shape)", "example": "  x = torch.randn(4, 4)  x.size() torch.Size([4, 4])  y = x.view(16)  y.size() torch.Size([16])  z = x.view(-1, 8)  # the size -1 is inferred from other dimensions  z.size() torch.Size([2, 8])   a = torch.randn(1, 2, 3, 4)  a.size() torch.Size([1, 2, 3, 4])  b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension  b.size() torch.Size([1, 3, 2, 4])  c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory  c.size() torch.Size([1, 3, 2, 4])  torch.equal(b, c) False   ", "summary": "Returns a new tensor with the same data as the self tensor but of a different shape", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.view", "parameters": [{"name": "*shape", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.view_as", "type": "method", "code": "torch.Tensor.view_as(other)", "example": "NA", "summary": "View this tensor as the same size as other", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.view_as", "parameters": [{"name": "other", "is_optional": false, "type": "torch.Tensor", "description": " The result tensor has the same sizeas other."}]}},
{"id": "torch.mode", "type": "function", "code": "torch.mode(input,dim=-1,keepdim=False,values=None,indices=None)", "example": "  a = torch.randint(10, (5,))  a tensor([6, 5, 1, 0, 2])  b = a + (torch.randn(50, 1) * 5).long()  torch.mode(b, 0) torch.return_types.mode(values=tensor([6, 5, 1, 0, 2]), indices=tensor([2, 2, 2, 2, 2]))   ", "summary": "Returns a namedtuple (values, indices) where values is the mode value of each row of the input tensor in the given dimension dim, i.e", "returns": null, "shape": "NA", "code-info": {"name": "torch.mode", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "-1", "description": " the dimension to reduce."}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether the output tensor has dim retained or not."}, {"name": "values", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor"}, {"name": "indices", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output index tensor"}]}},
{"id": "torch.norm", "type": "function", "code": "torch.norm(input,p='fro',dim=None,keepdim=False,out=None,dtype=None)", "example": "  import torch  a = torch.arange(9, dtype= torch.float) - 4  b = a.reshape((3, 3))  torch.norm(a) tensor(7.7460)  torch.norm(b) tensor(7.7460)  torch.norm(a, float('inf')) tensor(4.)  torch.norm(b, float('inf')) tensor(4.)  c = torch.tensor([[ 1, 2, 3],[-1, 1, 4]] , dtype= torch.float)  torch.norm(c, dim=0) tensor([1.4142, 2.2361, 5.0000])  torch.norm(c, dim=1) tensor([3.7417, 4.2426])  torch.norm(c, p=1, dim=1) tensor([6., 6.])  d = torch.arange(8, dtype= torch.float).reshape(2,2,2)  torch.norm(d, dim=(1,2)) tensor([ 3.7417, 11.2250])  torch.norm(d[0, :, :]), torch.norm(d[1, :, :]) (tensor(3.7417), tensor(11.2250))   ", "summary": "Returns the matrix norm or vector norm of a given tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.norm", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor"}, {"name": "p", "is_optional": true, "type": "string", "default_value": "'fro'", "description": " the order of norm. Default"}, {"name": "dim", "is_optional": true, "type": "int, float, inf, -inf, 'fro', 'nuc', optional", "default_value": "None", "description": " If it is an int,vector norm will be calculated, if it is 2-tuple of ints, matrix normwill be calculated. If the value is None, matrix norm will be calculatedwhen the input tensor only has two dimensions, vector norm will becalculated when the input tensor only has one dimension. If the inputtensor has more than two dimensions, the vector norm will be applied tolast dimension."}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether the output tensors have dimretained or not. Ignored if dim = None andout = None. Default"}, {"name": "out", "is_optional": true, "type": "bool, optional", "default_value": "None", "description": " the output tensor. Ignored ifdim = None and out = None."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type ofreturned tensor. If specified, the input tensor is casted to"}]}},
{"id": "torch.prod", "type": "function", "code": "torch.prod()", "example": "  a = torch.randn(1, 3)  a tensor([[-0.8020,  0.5428, -1.5854]])  torch.prod(a) tensor(0.6902)     torch.prod(input, dim, keepdim=False, dtype=None) \u2192 Tensor   Returns the product of each row of the input tensor in the given dimension dim. If keepdim is True, the output tensor is of the same size as input except in the dimension dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 fewer dimension than input.  Parameters  input (Tensor) \u2013 the input tensor. dim (python:int) \u2013 the dimension to reduce. keepdim (bool) \u2013 whether the output tensor has dim retained or not. dtype (torch.dtype, optional) \u2013 the desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None.    ", "summary": "  torch.prod(input, dtype=None) \u2192 Tensor   Returns the product of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.prod", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input,dtype=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.arg_constraints", "type": "attribute", "code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.arg_constraints", "parameters": []}},
{"id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.logits", "type": "attribute", "code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.logits", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.logits", "parameters": []}},
{"id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.probs", "type": "attribute", "code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.probs", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.probs", "parameters": []}},
{"id": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.support", "type": "attribute", "code": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.support", "parameters": []}},
{"id": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical", "type": "class", "code": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical(temperature,probs=None,logits=None,validate_args=None)", "example": "  m = RelaxedOneHotCategorical(torch.tensor([2.2]),                                  torch.tensor([0.1, 0.2, 0.3, 0.4]))  m.sample() tensor([ 0.1294,  0.2324,  0.3859,  0.2523])    Parameters  temperature (Tensor) \u2013 relaxation temperature probs (Tensor) \u2013 event probabilities logits (Tensor) \u2013 the log probability of each event.      arg_constraints = {'logits': Real(), 'probs': Simplex()}     expand(batch_shape, _instance=None)      has_rsample = True     property logits     property probs     support = Simplex()     property temperature   ", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution Creates a RelaxedOneHotCategorical distribution parametrized by temperature, and either probs or logits", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical", "parameters": [{"name": "temperature", "is_optional": false, "type": "Tensor", "description": " relaxation temperature"}, {"name": "probs", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " event probabilities"}, {"name": "logits", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " the log probability of each event."}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.arg_constraints", "type": "attribute", "code": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.arg_constraints", "parameters": []}},
{"id": "torch.nn.MaxUnpool1d", "type": "class", "code": "torch.nn.MaxUnpool1d(kernel_size:Union[T,Tuple[T]],stride:Optional[Union[T,Tuple[T]]]=None,padding:Union[T,Tuple[T]]=0)", "example": "  pool = nn.MaxPool1d(2, stride=2, return_indices=True)  unpool = nn.MaxUnpool1d(2, stride=2)  input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8]]])  output, indices = pool(input)  unpool(output, indices) tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])   # Example showcasing the use of output_size  input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8, 9]]])  output, indices = pool(input)  unpool(output, indices, output_size=input.size()) tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.,  0.]]])   unpool(output, indices) tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])   ", "summary": "Computes a partial inverse of MaxPool1d", "returns": [], "shape": "\ninput: the input Tensor to invert\nindices: the indices given out by MaxPool1d\noutput_size (optional): the targeted output size\n\n", "code-info": {"name": "torch.nn.MaxUnpool1d", "parameters": [{"name": "kernel_size", "type": "Union[T,Tuple[T]]", "is_optional": false, "description": "Size of the max pooling window."}, {"name": "stride", "type": "Optional[Union[T,Tuple[T]]]", "default_value": "None", "is_optional": false, "description": "Stride of the max pooling window.It is set to kernel_size by default."}, {"name": "padding", "type": "Union[T,Tuple[T]]", "default_value": "0", "is_optional": false, "description": "Padding that was added to the input"}]}},
{"id": "torch.nn.MaxUnpool2d", "type": "class", "code": "torch.nn.MaxUnpool2d(kernel_size:Union[T,Tuple[T,T]],stride:Optional[Union[T,Tuple[T,T]]]=None,padding:Union[T,Tuple[T,T]]=0)", "example": "  pool = nn.MaxPool2d(2, stride=2, return_indices=True)  unpool = nn.MaxUnpool2d(2, stride=2)  input = torch.tensor([[[[ 1.,  2,  3,  4],                             [ 5,  6,  7,  8],                             [ 9, 10, 11, 12],                             [13, 14, 15, 16]]]])  output, indices = pool(input)  unpool(output, indices) tensor([[[[  0.,   0.,   0.,   0.],           [  0.,   6.,   0.,   8.],           [  0.,   0.,   0.,   0.],           [  0.,  14.,   0.,  16.]]]])   # specify a different output size than input size  unpool(output, indices, output_size=torch.Size([1, 1, 5, 5])) tensor([[[[  0.,   0.,   0.,   0.,   0.],           [  6.,   0.,   8.,   0.,   0.],           [  0.,   0.,   0.,  14.,   0.],           [ 16.,   0.,   0.,   0.,   0.],           [  0.,   0.,   0.,   0.,   0.]]]])   ", "summary": "Computes a partial inverse of MaxPool2d", "returns": [], "shape": "\ninput: the input Tensor to invert\nindices: the indices given out by MaxPool2d\noutput_size (optional): the targeted output size\n\n", "code-info": {"name": "torch.nn.MaxUnpool2d", "parameters": [{"name": "kernel_size", "type": "Union[T,Tuple[T,T]]", "is_optional": false, "description": "Size of the max pooling window."}, {"name": "stride", "type": "Optional[Union[T,Tuple[T,T]]]", "default_value": "None", "is_optional": false, "description": "Stride of the max pooling window.It is set to kernel_size by default."}, {"name": "padding", "type": "Union[T,Tuple[T,T]]", "default_value": "0", "is_optional": false, "description": "Padding that was added to the input"}]}},
{"id": "torch.Tensor.where", "type": "method", "code": "torch.Tensor.where(condition,y)", "example": "NA", "summary": "self.where(condition, y) is equivalent to torch.where(condition, self, y)", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.where", "parameters": [{"name": "condition", "is_optional": false, "type": "others", "description": ""}, {"name": "y", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.Tensor.zero_", "type": "method", "code": "torch.Tensor.zero_()", "example": "NA", "summary": "Fills self tensor with zeros", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.zero_", "parameters": []}},
{"id": "torch.BoolTensor.all", "type": "method", "code": "torch.BoolTensor.all()", "example": "  a = torch.rand(1, 2).bool()  a tensor([[False, True]], dtype=torch.bool)  a.all() tensor(False, dtype=torch.bool)     all(dim, keepdim=False, out=None) \u2192 Tensor   Returns True if all elements in each row of the tensor in the given dimension dim are True, False otherwise. If keepdim is True, the output tensor is of the same size as input except in the dimension dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 fewer dimension than input.  Parameters  dim (python:int) \u2013 the dimension to reduce keepdim (bool) \u2013 whether the output tensor has dim retained or not out (Tensor, optional) \u2013 the output tensor    ", "summary": "  all() \u2192 bool   Returns True if all elements in the tensor are True, False otherwise", "returns": null, "shape": "NA", "code-info": {"name": "torch.BoolTensor.all", "parameters": []}},
{"id": "torch.BoolTensor.any", "type": "method", "code": "torch.BoolTensor.any()", "example": "  a = torch.rand(1, 2).bool()  a tensor([[False, True]], dtype=torch.bool)  a.any() tensor(True, dtype=torch.bool)     any(dim, keepdim=False, out=None) \u2192 Tensor   Returns True if any elements in each row of the tensor in the given dimension dim are True, False otherwise. If keepdim is True, the output tensor is of the same size as input except in the dimension dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 fewer dimension than input.  Parameters  dim (python:int) \u2013 the dimension to reduce keepdim (bool) \u2013 whether the output tensor has dim retained or not out (Tensor, optional) \u2013 the output tensor    ", "summary": "  any() \u2192 bool   Returns True if any elements in the tensor are True, False otherwise", "returns": null, "shape": "NA", "code-info": {"name": "torch.BoolTensor.any", "parameters": []}},
{"id": "torch.Tensor", "type": "class", "code": "torch.Tensor", "example": "  tensor = torch.ones((2,), dtype=torch.int8)  data = [[0, 1], [2, 3]]  tensor.new_tensor(data) tensor([[ 0,  1],         [ 2,  3]], dtype=torch.int8)       new_full(size, fill_value, dtype=None, device=None, requires_grad=False) \u2192 Tensor Returns a Tensor of size size filled with fill_value. By default, the returned Tensor has the same torch.dtype and torch.device as this tensor.  Parameters  fill_value (scalar) \u2013 the number to fill the output tensor with. dtype (torch.dtype, optional) \u2013 the desired type of returned tensor. Default: if None, same torch.dtype as this tensor. device (torch.device, optional) \u2013 the desired device of returned tensor. Default: if None, same torch.device as this tensor. requires_grad (bool, optional) \u2013 If autograd should record operations on the returned tensor. Default: False.    ", "summary": "There are a few main ways to create a tensor, depending on your use case", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input,dim,keepdim=False,dtype=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.std", "type": "function", "code": "torch.std()", "example": "  a = torch.randn(1, 3)  a tensor([[-0.8166, -1.3802, -0.3560]])  torch.std(a) tensor(0.5130)     torch.std(input, dim, keepdim=False, unbiased=True, out=None) \u2192 Tensor   Returns the standard-deviation of each row of the input tensor in the dimension dim. If dim is a list of dimensions, reduce over all of them. If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiased is False, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel\u2019s correction will be used.  Parameters  input (Tensor) \u2013 the input tensor. dim (python:int or tuple of python:ints) \u2013 the dimension or dimensions to reduce. keepdim (bool) \u2013 whether the output tensor has dim retained or not. unbiased (bool) \u2013 whether to use the unbiased estimation or not out (Tensor, optional) \u2013 the output tensor.    ", "summary": "  torch.std(input, unbiased=True) \u2192 Tensor   Returns the standard-deviation of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.std", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input,unbiased=True)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,dim,keepdim=False,unbiased=True,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.std_mean", "type": "function", "code": "torch.std_mean()", "example": "  a = torch.randn(1, 3)  a tensor([[0.3364, 0.3591, 0.9462]])  torch.std_mean(a) (tensor(0.3457), tensor(0.5472))     torch.std(input, dim, keepdim=False, unbiased=True) - (Tensor, Tensor)   Returns the standard-deviation and mean of each row of the input tensor in the dimension dim. If dim is a list of dimensions, reduce over all of them. If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiased is False, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel\u2019s correction will be used.  Parameters  input (Tensor) \u2013 the input tensor. dim (python:int or tuple of python:ints) \u2013 the dimension or dimensions to reduce. keepdim (bool) \u2013 whether the output tensor has dim retained or not. unbiased (bool) \u2013 whether to use the unbiased estimation or not    ", "summary": "  torch.std_mean(input, unbiased=True) -&gt; (Tensor, Tensor)   Returns the standard-deviation and mean of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.std_mean", "parameters": []}},
{"id": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.has_rsample", "type": "attribute", "code": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.has_rsample", "parameters": []}},
{"id": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.support", "type": "attribute", "code": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.support", "parameters": []}},
{"id": "torch.distributions.studentT.StudentT", "type": "class", "code": "torch.distributions.studentT.StudentT(df,loc=0.0,scale=1.0,validate_args=None)", "example": "  m = StudentT(torch.tensor([2.0]))  m.sample()  # Student's t-distributed with degrees of freedom=2 tensor([ 0.1046])    Parameters  df (python:float or Tensor) \u2013 degrees of freedom loc (python:float or Tensor) \u2013 mean of the distribution scale (python:float or Tensor) \u2013 scale of the distribution      arg_constraints = {'df': GreaterThan(lower_bound=0.0), 'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}     entropy()      expand(batch_shape, _instance=None)      has_rsample = True     log_prob(value)      property mean     rsample(sample_shape=torch.Size([]))      support = Real()     property variance   ", "summary": "Bases: torch.distributions.distribution.Distribution Creates a Student\u2019s t-distribution parameterized by degree of freedom df, mean loc and scale scale", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.studentT.StudentT", "parameters": [{"name": "df", "is_optional": false, "type": "float or Tensor", "description": " degrees of freedom"}, {"name": "loc", "is_optional": true, "type": "float or Tensor", "default_value": "0.0", "description": " mean of the distribution"}, {"name": "scale", "is_optional": true, "type": "float or Tensor", "default_value": "1.0", "description": " scale of the distribution"}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.studentT.StudentT.arg_constraints", "type": "attribute", "code": "torch.distributions.studentT.StudentT.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.studentT.StudentT.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.studentT.StudentT.has_rsample", "type": "attribute", "code": "torch.distributions.studentT.StudentT.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.studentT.StudentT.has_rsample", "parameters": []}},
{"id": "torch.distributions.studentT.StudentT.support", "type": "attribute", "code": "torch.distributions.studentT.StudentT.support()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.studentT.StudentT.support", "parameters": []}},
{"id": "torch.distributions.transformed_distribution.TransformedDistribution", "type": "class", "code": "torch.distributions.transformed_distribution.TransformedDistribution(base_distribution,transforms,validate_args=None)", "example": "NA", "summary": "Bases: torch.distributions.distribution.Distribution Extension of the Distribution class, which applies a sequence of Transforms to a base distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution", "parameters": [{"name": "base_distribution", "is_optional": false, "type": "others", "description": ""}, {"name": "transforms", "is_optional": false, "type": "others", "description": ""}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.nn.MaxUnpool3d", "type": "class", "code": "torch.nn.MaxUnpool3d(kernel_size:Union[T,Tuple[T,T,T]],stride:Optional[Union[T,Tuple[T,T,T]]]=None,padding:Union[T,Tuple[T,T,T]]=0)", "example": "  # pool of square window of size=3, stride=2  pool = nn.MaxPool3d(3, stride=2, return_indices=True)  unpool = nn.MaxUnpool3d(3, stride=2)  output, indices = pool(torch.randn(20, 16, 51, 33, 15))  unpooled_output = unpool(output, indices)  unpooled_output.size() torch.Size([20, 16, 51, 33, 15])   ", "summary": "Computes a partial inverse of MaxPool3d", "returns": [], "shape": "\ninput: the input Tensor to invert\nindices: the indices given out by MaxPool3d\noutput_size (optional): the targeted output size\n\n", "code-info": {"name": "torch.nn.MaxUnpool3d", "parameters": [{"name": "kernel_size", "type": "Union[T,Tuple[T,T,T]]", "is_optional": false, "description": "Size of the max pooling window."}, {"name": "stride", "type": "Optional[Union[T,Tuple[T,T,T]]]", "default_value": "None", "is_optional": false, "description": "Stride of the max pooling window.It is set to kernel_size by default."}, {"name": "padding", "type": "Union[T,Tuple[T,T,T]]", "default_value": "0", "is_optional": false, "description": "Padding that was added to the input"}]}},
{"id": "torch.nn.AvgPool1d", "type": "class", "code": "torch.nn.AvgPool1d(kernel_size:Union[T,Tuple[T]],stride:Union[T,Tuple[T]]=None,padding:Union[T,Tuple[T]]=0,ceil_mode:bool=False,count_include_pad:bool=True)", "example": "NA", "summary": "Applies a 1D average pooling over an input signal composed of several input planes", "returns": [], "shape": "\nInput: (N,C,Lin)(N, C, L_{in})(N,C,Lin\u200b)\n\n\nOutput: (N,C,Lout)(N, C, L_{out})(N,C,Lout\u200b)\n\n, where\n\nLout=\u230aLin+2\u00d7padding\u2212kernel_sizestride+1\u230bL_{out} = \\left\\lfloor \\frac{L_{in} +\n2 \\times \\text{padding} - \\text{kernel\\_size}}{\\text{stride}} + 1\\right\\rfloor\n\nLout\u200b=\u230astrideLin\u200b+2\u00d7padding\u2212kernel_size\u200b+1\u230b\n\n\n\n", "code-info": {"name": "torch.nn.AvgPool1d", "parameters": [{"name": "kernel_size", "type": "Union[T,Tuple[T]]", "is_optional": false, "description": "the size of the window"}, {"name": "stride", "type": "Union[T,Tuple[T]]", "default_value": "None", "is_optional": false, "description": "the stride of the window. Default value is kernel_size"}, {"name": "padding", "type": "Union[T,Tuple[T]]", "default_value": "0", "is_optional": false, "description": "implicit zero padding to be added on both sides"}, {"name": "ceil_mode", "type": "bool", "default_value": "False", "is_optional": false, "description": "when True, will use ceil instead of floor to compute the output shape"}, {"name": "count_include_pad", "type": "bool", "default_value": "True", "is_optional": false, "description": "when True, will include the zero-padding in the averaging calculation"}]}},
{"id": "torch.Tensor.is_cuda", "type": "attribute", "code": "torch.Tensor.is_cuda", "example": "NA", "summary": "Is True if the Tensor is stored on the GPU, False otherwise", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.is_cuda", "parameters": []}},
{"id": "torch.Tensor.device", "type": "attribute", "code": "torch.Tensor.device", "example": "NA", "summary": "Is the torch.device where this Tensor is", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.device", "parameters": []}},
{"id": "NA", "type": "attribute", "code": "NA", "example": "NA", "summary": "This attribute is None by default and becomes a Tensor the first time a call to backward() computes gradients for self", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": []}},
{"id": "torch.Tensor.ndim", "type": "attribute", "code": "torch.Tensor.ndim", "example": "NA", "summary": "Alias for dim() ", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.ndim", "parameters": []}},
{"id": "torch.Tensor.T", "type": "attribute", "code": "torch.Tensor.T", "example": "NA", "summary": "Is this Tensor with its dimensions reversed", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.T", "parameters": []}},
{"id": "NA", "type": "attribute", "code": "NA", "example": "  a = torch.rand(10, requires_grad=True)  a.is_leaf True  b = torch.rand(10, requires_grad=True).cuda()  b.is_leaf False # b was created by the operation that cast a cpu Tensor into a cuda Tensor  c = torch.rand(10, requires_grad=True) + 2  c.is_leaf False # c was created by the addition operation  d = torch.rand(10).cuda()  d.is_leaf True # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)  e = torch.rand(10).cuda().requires_grad_()  e.is_leaf True # e requires gradients and has no operations creating it  f = torch.rand(10, requires_grad=True, device=\"cuda\")  f.is_leaf True # f requires grad, has no operation creating it   ", "summary": "All Tensors that have requires_grad which is False will be leaf Tensors by convention", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": []}},
{"id": "torch.Tensor.is_sparse", "type": "attribute", "code": "torch.Tensor.is_sparse", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.Tensor.is_sparse", "parameters": []}},
{"id": "NA", "type": "attribute", "code": "NA", "example": "NA", "summary": "Is True if gradients need to be computed for this Tensor, False otherwise", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": []}},
{"id": "torch.BoolTensor", "type": "class", "code": "torch.BoolTensor", "example": "  a = torch.rand(1, 2).bool()  a tensor([[False, True]], dtype=torch.bool)  a.all() tensor(False, dtype=torch.bool)     all(dim, keepdim=False, out=None) \u2192 Tensor   Returns True if all elements in each row of the tensor in the given dimension dim are True, False otherwise. If keepdim is True, the output tensor is of the same size as input except in the dimension dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 fewer dimension than input.  Parameters  dim (python:int) \u2013 the dimension to reduce keepdim (bool) \u2013 whether the output tensor has dim retained or not out (Tensor, optional) \u2013 the output tensor    ", "summary": "The following methods are unique to torch.BoolTensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.BoolTensor", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input,unbiased=True)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,dim,keepdim=False,unbiased=True)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.sum", "type": "function", "code": "torch.sum()", "example": "  a = torch.randn(1, 3)  a tensor([[ 0.1133, -0.9567,  0.2958]])  torch.sum(a) tensor(-0.5475)     torch.sum(input, dim, keepdim=False, dtype=None) \u2192 Tensor   Returns the sum of each row of the input tensor in the given dimension dim. If dim is a list of dimensions, reduce over all of them. If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s).  Parameters  input (Tensor) \u2013 the input tensor. dim (python:int or tuple of python:ints) \u2013 the dimension or dimensions to reduce. keepdim (bool) \u2013 whether the output tensor has dim retained or not. dtype (torch.dtype, optional) \u2013 the desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None.    ", "summary": "  torch.sum(input, dtype=None) \u2192 Tensor   Returns the sum of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.sum", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input,dtype=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,dim,keepdim=False,dtype=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "dtype", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.unique", "type": "function", "code": "torch.unique(input,sorted=True,return_inverse=False,return_counts=False,dim=None)", "example": "  output = torch.unique(torch.tensor([1, 3, 2, 3], dtype=torch.long))  output tensor([ 2,  3,  1])   output, inverse_indices = torch.unique(         torch.tensor([1, 3, 2, 3], dtype=torch.long), sorted=True, return_inverse=True)  output tensor([ 1,  2,  3])  inverse_indices tensor([ 0,  2,  1,  2])   output, inverse_indices = torch.unique(         torch.tensor([[1, 3], [2, 3]], dtype=torch.long), sorted=True, return_inverse=True)  output tensor([ 1,  2,  3])  inverse_indices tensor([[ 0,  2],         [ 1,  2]])   ", "summary": "Returns the unique elements of the input tensor", "returns": "A tensor or a tuple of tensors containingoutput (Tensor): the output list of unique scalar elements.inverse_indices (Tensor): (optional) ifreturn_inverse is True, there will be an additionalreturned tensor (same shape as input) representing the indicesfor where elements in the original input map to in the output;otherwise, this function will only return a single tensor.counts (Tensor): (optional) ifreturn_counts is True, there will be an additionalreturned tensor (same shape as output or output.size(dim),if dim was specified) representing the number of occurrencesfor each unique value or tensor.", "shape": "NA", "code-info": {"name": "torch.unique", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor"}, {"name": "sorted", "is_optional": true, "type": "bool", "default_value": "True", "description": " Whether to sort the unique elements in ascending orderbefore returning as output."}, {"name": "return_inverse", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether to also return the indices for whereelements in the original input ended up in the returned unique list."}, {"name": "return_counts", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether to also return the counts for each uniqueelement."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": " the dimension to apply unique. If None, the unique of theflattened input is returned. default"}]}},
{"id": "torch.distributions.transformed_distribution.TransformedDistribution.arg_constraints", "type": "attribute", "code": "torch.distributions.transformed_distribution.TransformedDistribution.arg_constraints", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transformed_distribution.TransformedDistribution.arg_constraints", "parameters": []}},
{"id": "torch.distributions.uniform.Uniform", "type": "class", "code": "torch.distributions.uniform.Uniform(low,high,validate_args=None)", "example": "  m = Uniform(torch.tensor([0.0]), torch.tensor([5.0]))  m.sample()  # uniformly distributed in the range [0.0, 5.0) tensor([ 2.3418])    Parameters  low (python:float or Tensor) \u2013 lower range (inclusive). high (python:float or Tensor) \u2013 upper range (exclusive).      arg_constraints = {'high': Dependent(), 'low': Dependent()}     cdf(value)      entropy()      expand(batch_shape, _instance=None)      has_rsample = True     icdf(value)      log_prob(value)      property mean     rsample(sample_shape=torch.Size([]))      property stddev     property support     property variance   ", "summary": "Bases: torch.distributions.distribution.Distribution Generates uniformly distributed random samples from the half-open interval [low, high)", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform", "parameters": [{"name": "low", "is_optional": false, "type": "float or Tensor", "description": " lower range (inclusive."}, {"name": "high", "is_optional": false, "type": "float or Tensor", "description": " upper range (exclusive."}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.uniform.Uniform.arg_constraints", "type": "attribute", "code": "torch.distributions.uniform.Uniform.arg_constraints()", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.arg_constraints", "parameters": []}},
{"id": "torch.distributions.uniform.Uniform.has_rsample", "type": "attribute", "code": "torch.distributions.uniform.Uniform.has_rsample", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.uniform.Uniform.has_rsample", "parameters": []}},
{"id": "torch.distributions.weibull.Weibull", "type": "class", "code": "torch.distributions.weibull.Weibull(scale,concentration,validate_args=None)", "example": " m = Weibull(torch.tensor([1.0]), torch.tensor([1.0]))\n m.sample()  # sample from a Weibull distribution with scale=1, concentration=1\ntensor([ 0.4784])\n\n", "summary": "Bases: torch.distributions.transformed_distribution.TransformedDistribution Samples from a two-parameter Weibull distribution", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.weibull.Weibull", "parameters": [{"name": "scale", "is_optional": false, "type": "float or Tensor", "description": " Scale parameter of distribution (lambda."}, {"name": "concentration", "is_optional": false, "type": "float or Tensor", "description": " Concentration parameter of distribution (k/shape."}, {"name": "validate_args", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.weibull.Weibull.arg_constraints", "type": "attribute", "code": "torch.distributions.weibull.Weibull.arg_constraints(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.weibull.Weibull.arg_constraints", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.weibull.Weibull.support", "type": "attribute", "code": "torch.distributions.weibull.Weibull.support(lower_bound=0.0)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.weibull.Weibull.support", "parameters": [{"name": "lower_bound", "is_optional": true, "type": "others", "default_value": "0.0", "description": ""}]}},
{"id": "torch.distributions.transforms.Transform", "type": "class", "code": "torch.distributions.transforms.Transform(cache_size=0)", "example": "NA", "summary": "Abstract class for invertable transformations with computable log det jacobians", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.Transform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.nn.AvgPool2d", "type": "class", "code": "torch.nn.AvgPool2d(kernel_size:Union[T,Tuple[T,T]],stride:Optional[Union[T,Tuple[T,T]]]=None,padding:Union[T,Tuple[T,T]]=0,ceil_mode:bool=False,count_include_pad:bool=True,divisor_override:bool=None)", "example": "NA", "summary": "Applies a 2D average pooling over an input signal composed of several input planes", "returns": [], "shape": "\nInput: (N,C,Hin,Win)(N, C, H_{in}, W_{in})(N,C,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Hout,Wout)(N, C, H_{out}, W_{out})(N,C,Hout\u200b,Wout\u200b)\n\n, where\n\nHout=\u230aHin+2\u00d7padding[0]\u2212kernel_size[0]stride[0]+1\u230bH_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] -\n  \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor\n\nHout\u200b=\u230astride[0]Hin\u200b+2\u00d7padding[0]\u2212kernel_size[0]\u200b+1\u230b\n\n\nWout=\u230aWin+2\u00d7padding[1]\u2212kernel_size[1]stride[1]+1\u230bW_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] -\n  \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor\n\nWout\u200b=\u230astride[1]Win\u200b+2\u00d7padding[1]\u2212kernel_size[1]\u200b+1\u230b\n\n\n\n", "code-info": {"name": "torch.nn.AvgPool2d", "parameters": [{"name": "kernel_size", "type": "Union[T,Tuple[T,T]]", "is_optional": false, "description": "the size of the window"}, {"name": "stride", "type": "Optional[Union[T,Tuple[T,T]]]", "default_value": "None", "is_optional": false, "description": "the stride of the window. Default value is kernel_size"}, {"name": "padding", "type": "Union[T,Tuple[T,T]]", "default_value": "0", "is_optional": false, "description": "implicit zero padding to be added on both sides"}, {"name": "ceil_mode", "type": "bool", "default_value": "False", "is_optional": false, "description": "when True, will use ceil instead of floor to compute the output shape"}, {"name": "count_include_pad", "type": "bool", "default_value": "True", "is_optional": false, "description": "when True, will include the zero-padding in the averaging calculation"}, {"name": "divisor_override", "type": "bool", "default_value": "None", "is_optional": false, "description": "if specified, it will be used as divisor, otherwise kernel_size will be used"}]}},
{"id": "torch.nn.AvgPool3d", "type": "class", "code": "torch.nn.AvgPool3d(kernel_size:Union[T,Tuple[T,T,T]],stride:Optional[Union[T,Tuple[T,T,T]]]=None,padding:Union[T,Tuple[T,T,T]]=0,ceil_mode:bool=False,count_include_pad:bool=True,divisor_override=None)", "example": "NA", "summary": "Applies a 3D average pooling over an input signal composed of several input planes", "returns": [], "shape": "\nInput: (N,C,Din,Hin,Win)(N, C, D_{in}, H_{in}, W_{in})(N,C,Din\u200b,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Dout,Hout,Wout)(N, C, D_{out}, H_{out}, W_{out})(N,C,Dout\u200b,Hout\u200b,Wout\u200b)\n\n, where\n\nDout=\u230aDin+2\u00d7padding[0]\u2212kernel_size[0]stride[0]+1\u230bD_{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] -\n      \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor\n\nDout\u200b=\u230astride[0]Din\u200b+2\u00d7padding[0]\u2212kernel_size[0]\u200b+1\u230b\n\n\nHout=\u230aHin+2\u00d7padding[1]\u2212kernel_size[1]stride[1]+1\u230bH_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] -\n      \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor\n\nHout\u200b=\u230astride[1]Hin\u200b+2\u00d7padding[1]\u2212kernel_size[1]\u200b+1\u230b\n\n\nWout=\u230aWin+2\u00d7padding[2]\u2212kernel_size[2]stride[2]+1\u230bW_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] -\n      \\text{kernel\\_size}[2]}{\\text{stride}[2]} + 1\\right\\rfloor\n\nWout\u200b=\u230astride[2]Win\u200b+2\u00d7padding[2]\u2212kernel_size[2]\u200b+1\u230b\n\n\n\n", "code-info": {"name": "torch.nn.AvgPool3d", "parameters": [{"name": "kernel_size", "type": "Union[T,Tuple[T,T,T]]", "is_optional": false, "description": "the size of the window"}, {"name": "stride", "type": "Optional[Union[T,Tuple[T,T,T]]]", "default_value": "None", "is_optional": false, "description": "the stride of the window. Default value is kernel_size"}, {"name": "padding", "type": "Union[T,Tuple[T,T,T]]", "default_value": "0", "is_optional": false, "description": "implicit zero padding to be added on all three sides"}, {"name": "ceil_mode", "type": "bool", "default_value": "False", "is_optional": false, "description": "when True, will use ceil instead of floor to compute the output shape"}, {"name": "count_include_pad", "type": "bool", "default_value": "True", "is_optional": false, "description": "when True, will include the zero-padding in the averaging calculation"}]}},
{"id": "torch.unique_consecutive", "type": "function", "code": "torch.unique_consecutive(input,return_inverse=False,return_counts=False,dim=None)", "example": "  x = torch.tensor([1, 1, 2, 2, 3, 1, 1, 2])  output = torch.unique_consecutive(x)  output tensor([1, 2, 3, 1, 2])   output, inverse_indices = torch.unique_consecutive(x, return_inverse=True)  output tensor([1, 2, 3, 1, 2])  inverse_indices tensor([0, 0, 1, 1, 2, 3, 3, 4])   output, counts = torch.unique_consecutive(x, return_counts=True)  output tensor([1, 2, 3, 1, 2])  counts tensor([2, 2, 1, 2, 1])   ", "summary": "Eliminates all but the first element from every consecutive group of equivalent elements", "returns": "A tensor or a tuple of tensors containingoutput (Tensor): the output list of unique scalar elements.inverse_indices (Tensor): (optional) ifreturn_inverse is True, there will be an additionalreturned tensor (same shape as input) representing the indicesfor where elements in the original input map to in the output;otherwise, this function will only return a single tensor.counts (Tensor): (optional) ifreturn_counts is True, there will be an additionalreturned tensor (same shape as output or output.size(dim),if dim was specified) representing the number of occurrencesfor each unique value or tensor.", "shape": "NA", "code-info": {"name": "torch.unique_consecutive", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor"}, {"name": "return_inverse", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether to also return the indices for whereelements in the original input ended up in the returned unique list."}, {"name": "return_counts", "is_optional": true, "type": "bool", "default_value": "False", "description": " Whether to also return the counts for each uniqueelement."}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "None", "description": " the dimension to apply unique. If None, the unique of theflattened input is returned. default"}]}},
{"id": "torch.var", "type": "function", "code": "torch.var()", "example": "  a = torch.randn(1, 3)  a tensor([[-0.3425, -1.2636, -0.4864]])  torch.var(a) tensor(0.2455)     torch.var(input, dim, keepdim=False, unbiased=True, out=None) \u2192 Tensor   Returns the variance of each row of the input tensor in the given dimension dim. If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiased is False, then the variance will be calculated via the biased estimator. Otherwise, Bessel\u2019s correction will be used.  Parameters  input (Tensor) \u2013 the input tensor. dim (python:int or tuple of python:ints) \u2013 the dimension or dimensions to reduce. keepdim (bool) \u2013 whether the output tensor has dim retained or not. unbiased (bool) \u2013 whether to use the unbiased estimation or not out (Tensor, optional) \u2013 the output tensor.    ", "summary": "  torch.var(input, unbiased=True) \u2192 Tensor   Returns the variance of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.var", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input,unbiased=True)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,dim,keepdim=False,unbiased=True,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.transforms.ComposeTransform", "type": "class", "code": "torch.distributions.transforms.ComposeTransform(parts)", "example": "NA", "summary": "Composes multiple transforms in a chain", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.ComposeTransform", "parameters": [{"name": "parts", "is_optional": false, "type": "list of Transform", "description": " A list of transforms to compose."}]}},
{"id": "torch.distributions.transforms.ExpTransform", "type": "class", "code": "torch.distributions.transforms.ExpTransform(cache_size=0)", "example": "NA", "summary": "Transform via the mapping y=exp\u2061(x)y = \\exp(x)y=exp(x)  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.ExpTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.distributions.transforms.PowerTransform", "type": "class", "code": "torch.distributions.transforms.PowerTransform(exponent,cache_size=0)", "example": "NA", "summary": "Transform via the mapping y=xexponenty = x^{\\text{exponent}}y=xexponent  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.PowerTransform", "parameters": [{"name": "exponent", "is_optional": false, "type": "others", "description": ""}, {"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.distributions.transforms.SigmoidTransform", "type": "class", "code": "torch.distributions.transforms.SigmoidTransform(cache_size=0)", "example": "NA", "summary": "Transform via the mapping y=11+exp\u2061(\u2212x)y = \\frac{1}{1 + \\exp(-x)}y=1+exp(\u2212x)1\u200b   and x=logit(y)x = \\text{logit}(y)x=logit(y)  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.SigmoidTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.distributions.transforms.AbsTransform", "type": "class", "code": "torch.distributions.transforms.AbsTransform(cache_size=0)", "example": "NA", "summary": "Transform via the mapping y=\u2223x\u2223y = |x|y=\u2223x\u2223  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.AbsTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.distributions.transforms.AffineTransform", "type": "class", "code": "torch.distributions.transforms.AffineTransform(loc,scale,event_dim=0,cache_size=0)", "example": "NA", "summary": "Transform via the pointwise affine mapping y=loc+scale\u00d7xy = \\text{loc} + \\text{scale} \\times xy=loc+scale\u00d7x  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.AffineTransform", "parameters": [{"name": "loc", "is_optional": false, "type": "Tensor or float", "description": " Location parameter."}, {"name": "scale", "is_optional": false, "type": "Tensor or float", "description": " Scale parameter."}, {"name": "event_dim", "is_optional": true, "type": "int", "default_value": "0", "description": " Optional size of event_shape. This should be zerofor univariate random variables, 1 for distributions over vectors,2 for distributions over matrices, etc."}, {"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.distributions.transforms.SoftmaxTransform", "type": "class", "code": "torch.distributions.transforms.SoftmaxTransform(cache_size=0)", "example": "NA", "summary": "Transform from unconstrained space to the simplex via y=exp\u2061(x)y = \\exp(x)y=exp(x)   then normalizing", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.SoftmaxTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.nn.FractionalMaxPool2d", "type": "class", "code": "torch.nn.FractionalMaxPool2d(kernel_size:Union[T,Tuple[T,T]],output_size:Optional[Union[T,Tuple[T,T]]]=None,output_ratio:Optional[Union[T,Tuple[T,T]]]=None,return_indices:bool=False,_random_samples=None)", "example": "NA", "summary": "Applies a 2D fractional max pooling over an input signal composed of several input planes", "returns": [], "shape": "", "code-info": {"name": "torch.nn.FractionalMaxPool2d", "parameters": [{"name": "kernel_size", "type": "Union[T,Tuple[T,T]]", "is_optional": false, "description": "the size of the window to take a max over.Can be a single number k (for a square kernel of k x k) or a tuple (kh, kw)"}, {"name": "output_size", "type": "Optional[Union[T,Tuple[T,T]]]", "default_value": "None", "is_optional": false, "description": "the target output size of the image of the form oH x oW.Can be a tuple (oH, oW) or a single number oH for a square image oH x oH"}, {"name": "output_ratio", "type": "Optional[Union[T,Tuple[T,T]]]", "default_value": "None", "is_optional": false, "description": "If one wants to have an output size as a ratio of the input size, this option can be given.This has to be a number or tuple in the range (0, 1)"}, {"name": "return_indices", "type": "bool", "default_value": "False", "is_optional": false, "description": "if True, will return the indices along with the outputs.Useful to pass to nn.MaxUnpool2d(). Default: False"}]}},
{"id": "torch.nn.LPPool1d", "type": "class", "code": "torch.nn.LPPool1d(norm_type:float,kernel_size:Union[T,Tuple[T,...]],stride:Optional[Union[T,Tuple[T,...]]]=None,ceil_mode:bool=False)", "example": "NA", "summary": "Applies a 1D power-average pooling over an input signal composed of several input planes", "returns": [], "shape": "\nInput: (N,C,Lin)(N, C, L_{in})(N,C,Lin\u200b)\n\n\nOutput: (N,C,Lout)(N, C, L_{out})(N,C,Lout\u200b)\n\n, where\n\nLout=\u230aLin\u2212kernel_sizestride+1\u230bL_{out} = \\left\\lfloor\\frac{L_{in} - \\text{kernel\\_size}}{\\text{stride}} + 1\\right\\rfloor\n\nLout\u200b=\u230astrideLin\u200b\u2212kernel_size\u200b+1\u230b\n\n\n\n", "code-info": {"name": "torch.nn.LPPool1d", "parameters": [{"name": "norm_type", "type": "float", "is_optional": false, "description": ""}, {"name": "kernel_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "a single int, the size of the window"}, {"name": "stride", "type": "Optional[Union[T,Tuple[T,...]]]", "default_value": "None", "is_optional": false, "description": "a single int, the stride of the window. Default value is kernel_size"}, {"name": "ceil_mode", "type": "bool", "default_value": "False", "is_optional": false, "description": "when True, will use ceil instead of floor to compute the output shape"}]}},
{"id": "torch.nn.LPPool2d", "type": "class", "code": "torch.nn.LPPool2d(norm_type:float,kernel_size:Union[T,Tuple[T,...]],stride:Optional[Union[T,Tuple[T,...]]]=None,ceil_mode:bool=False)", "example": "NA", "summary": "Applies a 2D power-average pooling over an input signal composed of several input planes", "returns": [], "shape": "\nInput: (N,C,Hin,Win)(N, C, H_{in}, W_{in})(N,C,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Hout,Wout)(N, C, H_{out}, W_{out})(N,C,Hout\u200b,Wout\u200b)\n\n, where\n\nHout=\u230aHin\u2212kernel_size[0]stride[0]+1\u230bH_{out} = \\left\\lfloor\\frac{H_{in} - \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor\n\nHout\u200b=\u230astride[0]Hin\u200b\u2212kernel_size[0]\u200b+1\u230b\n\n\nWout=\u230aWin\u2212kernel_size[1]stride[1]+1\u230bW_{out} = \\left\\lfloor\\frac{W_{in} - \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor\n\nWout\u200b=\u230astride[1]Win\u200b\u2212kernel_size[1]\u200b+1\u230b\n\n\n\n", "code-info": {"name": "torch.nn.LPPool2d", "parameters": [{"name": "norm_type", "type": "float", "is_optional": false, "description": ""}, {"name": "kernel_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the size of the window"}, {"name": "stride", "type": "Optional[Union[T,Tuple[T,...]]]", "default_value": "None", "is_optional": false, "description": "the stride of the window. Default value is kernel_size"}, {"name": "ceil_mode", "type": "bool", "default_value": "False", "is_optional": false, "description": "when True, will use ceil instead of floor to compute the output shape"}]}},
{"id": "torch.var_mean", "type": "function", "code": "torch.var_mean()", "example": "  a = torch.randn(1, 3)  a tensor([[0.0146, 0.4258, 0.2211]])  torch.var_mean(a) (tensor(0.0423), tensor(0.2205))     torch.var_mean(input, dim, keepdim=False, unbiased=True) - (Tensor, Tensor)   Returns the variance and mean of each row of the input tensor in the given dimension dim. If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiased is False, then the variance will be calculated via the biased estimator. Otherwise, Bessel\u2019s correction will be used.  Parameters  input (Tensor) \u2013 the input tensor. dim (python:int or tuple of python:ints) \u2013 the dimension or dimensions to reduce. keepdim (bool) \u2013 whether the output tensor has dim retained or not. unbiased (bool) \u2013 whether to use the unbiased estimation or not    ", "summary": "  torch.var_mean(input, unbiased=True) -&gt; (Tensor, Tensor)   Returns the variance and mean of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.var_mean", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input,unbiased=True)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,dim,keepdim=False,unbiased=True)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "unbiased", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}]}},
{"id": "torch.allclose", "type": "function", "code": "torch.allclose(input,other,rtol=1e-05,atol=1e-08,equal_nan=False)", "example": "  torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08])) False  torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09])) True  torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')])) False  torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True) True   ", "summary": "This function checks if all input and other satisfy the condition:  \u2223input\u2212other\u2223\u2264atol+rtol\u00d7\u2223other\u2223\\lvert \\text{input} - \\text{other} \\rvert \\leq \\texttt{atol} + \\texttt{rtol} \\times \\lvert \\text{other} \\rvert  \u2223input\u2212other\u2223\u2264atol+rtol\u00d7\u2223other\u2223  elementwise, for all elements of input and other", "returns": null, "shape": "NA", "code-info": {"name": "torch.allclose", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " first tensor to compare"}, {"name": "other", "is_optional": false, "type": "Tensor", "description": " second tensor to compare"}, {"name": "rtol", "is_optional": true, "type": "float, optional", "default_value": "1e-05", "description": " relative tolerance. Default"}, {"name": "atol", "is_optional": true, "type": "float, optional", "default_value": "1e-08", "description": " absolute tolerance. Default"}, {"name": "equal_nan", "is_optional": true, "type": "bool", "default_value": "False", "description": " if True, then two NaN s will be compared as equal. Default"}]}},
{"id": "torch.argsort", "type": "function", "code": "torch.argsort(input,dim=-1,descending=False,out=None)", "example": "  a = torch.randn(4, 4)  a tensor([[ 0.0785,  1.5267, -0.8521,  0.4065],         [ 0.1598,  0.0788, -0.0745, -1.2700],         [ 1.2208,  1.0722, -0.7064,  1.2564],         [ 0.0669, -0.2318, -0.8229, -0.9280]])    torch.argsort(a, dim=1) tensor([[2, 0, 3, 1],         [3, 2, 1, 0],         [2, 1, 0, 3],         [3, 2, 1, 0]])   ", "summary": "Returns the indices that sort a tensor along a given dimension in ascending order by value", "returns": null, "shape": "NA", "code-info": {"name": "torch.argsort", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "dim", "is_optional": true, "type": "int, optional", "default_value": "-1", "description": " the dimension to sort along"}, {"name": "descending", "is_optional": true, "type": "bool", "default_value": "False", "description": " controls the sorting order (ascending or descending"}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.eq", "type": "function", "code": "torch.eq(input,other,out=None)", "example": "  torch.eq(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[ 1,  0],         [ 0,  1]], dtype=torch.uint8)   ", "summary": "Computes element-wise equality The second argument can be a number or a tensor whose shape is broadcastable with the first argument", "returns": "A torch.BoolTensor containing a True at each location where comparison is true", "shape": "NA", "code-info": {"name": "torch.eq", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to compare"}, {"name": "other", "is_optional": false, "type": "Tensor or float", "description": " the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor. Must be a ByteTensor"}]}},
{"id": "torch.equal", "type": "function", "code": "torch.equal(input,other)", "example": "  torch.equal(torch.tensor([1, 2]), torch.tensor([1, 2])) True   ", "summary": "True if two tensors have the same size and elements, False otherwise", "returns": null, "shape": "NA", "code-info": {"name": "torch.equal", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.distributions.transforms.StickBreakingTransform", "type": "class", "code": "torch.distributions.transforms.StickBreakingTransform(cache_size=0)", "example": "NA", "summary": "Transform from unconstrained space to the simplex of one additional dimension via a stick-breaking process", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.StickBreakingTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.distributions.transforms.LowerCholeskyTransform", "type": "class", "code": "torch.distributions.transforms.LowerCholeskyTransform(cache_size=0)", "example": "NA", "summary": "Transform from unconstrained matrices to lower-triangular matrices with nonnegative diagonal entries", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.LowerCholeskyTransform", "parameters": [{"name": "cache_size", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.distributions.transforms.CatTransform", "type": "class", "code": "torch.distributions.transforms.CatTransform(tseq,dim=0,lengths=None)", "example": ":x0 = torch.cat([torch.range(1, 10), torch.range(1, 10)], dim=0) x = torch.cat([x0, x0], dim=0) t0 = CatTransform([ExpTransform(), identity_transform], dim=0, lengths=[10, 10]) t = CatTransform([t0, t0], dim=0, lengths=[20, 20]) y = t(x)   ", "summary": "Transform functor that applies a sequence of transforms tseq component-wise to each submatrix at dim, of length lengths[dim], in a way compatible with torch.cat()", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.CatTransform", "parameters": [{"name": "tseq", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}, {"name": "lengths", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.distributions.transforms.StackTransform", "type": "class", "code": "torch.distributions.transforms.StackTransform(tseq,dim=0)", "example": ":x = torch.stack([torch.range(1, 10), torch.range(1, 10)], dim=1) t = StackTransform([ExpTransform(), identity_transform], dim=1) y = t(x)   ", "summary": "Transform functor that applies a sequence of transforms tseq component-wise to each submatrix at dim in a way compatible with torch.stack()", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.transforms.StackTransform", "parameters": [{"name": "tseq", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "int", "default_value": "0", "description": ""}]}},
{"id": "torch.distributions.constraints.Constraint", "type": "class", "code": "torch.distributions.constraints.Constraint", "example": "NA", "summary": "Abstract base class for constraints", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.constraints.Constraint", "parameters": []}},
{"id": "torch.distributions.constraint_registry.ConstraintRegistry", "type": "class", "code": "torch.distributions.constraint_registry.ConstraintRegistry", "example": "NA", "summary": "Registry to link constraints to transforms", "returns": null, "shape": "NA", "code-info": {"name": "torch.distributions.constraint_registry.ConstraintRegistry", "parameters": []}},
{"id": "torch.nn.AdaptiveMaxPool1d", "type": "class", "code": "torch.nn.AdaptiveMaxPool1d(output_size:Union[T,Tuple[T,...]],return_indices:bool=False)", "example": "NA", "summary": "Applies a 1D adaptive max pooling over an input signal composed of several input planes", "returns": [], "shape": "", "code-info": {"name": "torch.nn.AdaptiveMaxPool1d", "parameters": [{"name": "output_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the target output size H"}, {"name": "return_indices", "type": "bool", "default_value": "False", "is_optional": false, "description": "if True, will return the indices along with the outputs.Useful to pass to nn.MaxUnpool1d. Default: False"}]}},
{"id": "torch.nn.AdaptiveMaxPool2d", "type": "class", "code": "torch.nn.AdaptiveMaxPool2d(output_size:Union[T,Tuple[T,...]],return_indices:bool=False)", "example": "NA", "summary": "Applies a 2D adaptive max pooling over an input signal composed of several input planes", "returns": [], "shape": "", "code-info": {"name": "torch.nn.AdaptiveMaxPool2d", "parameters": [{"name": "output_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the target output size of the image of the form H x W.Can be a tuple (H, W) or a single H for a square image H x H.H and W can be either a int, or None which means the size willbe the same as that of the input."}, {"name": "return_indices", "type": "bool", "default_value": "False", "is_optional": false, "description": "if True, will return the indices along with the outputs.Useful to pass to nn.MaxUnpool2d. Default: False"}]}},
{"id": "torch.nn.AdaptiveMaxPool3d", "type": "class", "code": "torch.nn.AdaptiveMaxPool3d(output_size:Union[T,Tuple[T,...]],return_indices:bool=False)", "example": "NA", "summary": "Applies a 3D adaptive max pooling over an input signal composed of several input planes", "returns": [], "shape": "", "code-info": {"name": "torch.nn.AdaptiveMaxPool3d", "parameters": [{"name": "output_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the target output size of the image of the form D x H x W.Can be a tuple (D, H, W) or a single D for a cube D x D x D.D, H and W can be either a int, or None which means the size willbe the same as that of the input."}, {"name": "return_indices", "type": "bool", "default_value": "False", "is_optional": false, "description": "if True, will return the indices along with the outputs.Useful to pass to nn.MaxUnpool3d. Default: False"}]}},
{"id": "torch.ge", "type": "function", "code": "torch.ge(input,other,out=None)", "example": "  torch.ge(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[True, True], [False, True]])   ", "summary": "Computes input\u2265other\\text{input} \\geq \\text{other}input\u2265other   element-wise", "returns": "A torch.BoolTensor containing a True at each location where comparison is true", "shape": "NA", "code-info": {"name": "torch.ge", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to compare"}, {"name": "other", "is_optional": false, "type": "Tensor or float", "description": " the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor that must be a BoolTensor"}]}},
{"id": "torch.gt", "type": "function", "code": "torch.gt(input,other,out=None)", "example": "  torch.gt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[False, True], [False, False]])   ", "summary": "Computes input&gt;other\\text{input} &gt; \\text{other}input&gt;other   element-wise", "returns": "A torch.BoolTensor containing a True at each location where comparison is true", "shape": "NA", "code-info": {"name": "torch.gt", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to compare"}, {"name": "other", "is_optional": false, "type": "Tensor or float", "description": " the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor that must be a BoolTensor"}]}},
{"id": "torch.isfinite", "type": "function", "code": "torch.isfinite()", "example": "  torch.isfinite(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')])) tensor([True,  False,  True,  False,  False])    ", "summary": "Returns a new tensor with boolean elements representing if each element is Finite or not", "returns": "Tensor: A torch.Tensor with dtype torch.bool containing a True at each location of finite elements and False otherwise", "shape": "NA", "code-info": {"name": "torch.isfinite", "parameters": []}},
{"id": "torch.isinf", "type": "function", "code": "torch.isinf(tensor)", "example": "  torch.isinf(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')])) tensor([False,  True,  False,  True,  False])   ", "summary": "Returns a new tensor with boolean elements representing if each element is +/-INF or not", "returns": "A torch.Tensor with dtype torch.bool containing a True at each location of +/-INF elements and False otherwise", "shape": "NA", "code-info": {"name": "torch.isinf", "parameters": [{"name": "tensor", "is_optional": false, "type": "Tensor", "description": " A tensor to check"}]}},
{"id": "torch.nn.AdaptiveAvgPool1d", "type": "class", "code": "torch.nn.AdaptiveAvgPool1d(output_size:Union[T,Tuple[T,...]])", "example": "NA", "summary": "Applies a 1D adaptive average pooling over an input signal composed of several input planes", "returns": [], "shape": "", "code-info": {"name": "torch.nn.AdaptiveAvgPool1d", "parameters": [{"name": "output_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the target output size H"}]}},
{"id": "torch.nn.AdaptiveAvgPool2d", "type": "class", "code": "torch.nn.AdaptiveAvgPool2d(output_size:Union[T,Tuple[T,...]])", "example": "NA", "summary": "Applies a 2D adaptive average pooling over an input signal composed of several input planes", "returns": [], "shape": "", "code-info": {"name": "torch.nn.AdaptiveAvgPool2d", "parameters": [{"name": "output_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the target output size of the image of the form H x W.Can be a tuple (H, W) or a single H for a square image H x H.H and W can be either a int, or None which means the size willbe the same as that of the input."}]}},
{"id": "torch.nn.AdaptiveAvgPool3d", "type": "class", "code": "torch.nn.AdaptiveAvgPool3d(output_size:Union[T,Tuple[T,...]])", "example": "NA", "summary": "Applies a 3D adaptive average pooling over an input signal composed of several input planes", "returns": [], "shape": "", "code-info": {"name": "torch.nn.AdaptiveAvgPool3d", "parameters": [{"name": "output_size", "type": "Union[T,Tuple[T,...]]", "is_optional": false, "description": "the target output size of the form D x H x W.Can be a tuple (D, H, W) or a single number D for a cube D x D x D.D, H and W can be either a int, or None which means the size willbe the same as that of the input."}]}},
{"id": "torch.nn.ReflectionPad1d", "type": "class", "code": "torch.nn.ReflectionPad1d(padding:Union[T,Tuple[T,T]])", "example": "NA", "summary": "Pads the input tensor using the reflection of the input boundary", "returns": [], "shape": "\nInput: (N,C,Win)(N, C, W_{in})(N,C,Win\u200b)\n\n\nOutput: (N,C,Wout)(N, C, W_{out})(N,C,Wout\u200b)\n\n where\nWout=Win+padding_left+padding_rightW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout\u200b=Win\u200b+padding_left+padding_right\n\n\n\n\n", "code-info": {"name": "torch.nn.ReflectionPad1d", "parameters": [{"name": "padding", "type": "Union[T,Tuple[T,T]]", "is_optional": false, "description": "the size of the padding. If is int, uses the samepadding in all boundaries. If a 2-tuple, uses(padding_left\\text{padding\\_left}padding_left, padding_right\\text{padding\\_right}padding_right)"}]}},
{"id": "torch.isnan", "type": "function", "code": "torch.isnan()", "example": "  torch.isnan(torch.tensor([1, float('nan'), 2])) tensor([False, True, False])   ", "summary": "Returns a new tensor with boolean elements representing if each element is NaN or not", "returns": "A torch.BoolTensor containing a True at each location of NaN elements.", "shape": "NA", "code-info": {"name": "torch.isnan", "parameters": []}},
{"id": "torch.kthvalue", "type": "function", "code": "torch.kthvalue(input,k,dim=None,keepdim=False,out=None)", "example": "  x = torch.arange(1., 6.)  x tensor([ 1.,  2.,  3.,  4.,  5.])  torch.kthvalue(x, 4) torch.return_types.kthvalue(values=tensor(4.), indices=tensor(3))   x=torch.arange(1.,7.).resize_(2,3)  x tensor([[ 1.,  2.,  3.],         [ 4.,  5.,  6.]])  torch.kthvalue(x, 2, 0, True) torch.return_types.kthvalue(values=tensor([[4., 5., 6.]]), indices=tensor([[1, 1, 1]]))   ", "summary": "Returns a namedtuple (values, indices) where values is the k th smallest element of each row of the input tensor in the given dimension dim", "returns": null, "shape": "NA", "code-info": {"name": "torch.kthvalue", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "k", "is_optional": false, "type": "int", "description": " k for the k-th smallest element"}, {"name": "dim", "is_optional": true, "type": "int, optional", "default_value": "None", "description": " the dimension to find the kth value along"}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether the output tensor has dim retained or not."}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": " the output tuple of (Tensor, LongTensorcan be optionally given to be used as output buffers"}]}},
{"id": "torch.le", "type": "function", "code": "torch.le(input,other,out=None)", "example": "  torch.le(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[True, False], [True, True]])   ", "summary": "Computes input\u2264other\\text{input} \\leq \\text{other}input\u2264other   element-wise", "returns": "A torch.BoolTensor containing a True at each location where comparison is true", "shape": "NA", "code-info": {"name": "torch.le", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to compare"}, {"name": "other", "is_optional": false, "type": "Tensor or float", "description": " the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor that must be a BoolTensor"}]}},
{"id": "torch.lt", "type": "function", "code": "torch.lt(input,other,out=None)", "example": "  torch.lt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[False, False], [True, False]])   ", "summary": "Computes input&lt;other\\text{input} &lt; \\text{other}input&lt;other   element-wise", "returns": "A torch.BoolTensor containing a True at each location where comparison is true", "shape": "NA", "code-info": {"name": "torch.lt", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to compare"}, {"name": "other", "is_optional": false, "type": "Tensor or float", "description": " the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor that must be a BoolTensor"}]}},
{"id": "torch.nn.ReflectionPad2d", "type": "class", "code": "torch.nn.ReflectionPad2d(padding:Union[T,Tuple[T,T,T,T]])", "example": "NA", "summary": "Pads the input tensor using the reflection of the input boundary", "returns": [], "shape": "\nInput: (N,C,Hin,Win)(N, C, H_{in}, W_{in})(N,C,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Hout,Wout)(N, C, H_{out}, W_{out})(N,C,Hout\u200b,Wout\u200b)\n\n where\nHout=Hin+padding_top+padding_bottomH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}Hout\u200b=Hin\u200b+padding_top+padding_bottom\n\n\nWout=Win+padding_left+padding_rightW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout\u200b=Win\u200b+padding_left+padding_right\n\n\n\n\n", "code-info": {"name": "torch.nn.ReflectionPad2d", "parameters": [{"name": "padding", "type": "Union[T,Tuple[T,T,T,T]]", "is_optional": false, "description": "the size of the padding. If is int, uses the samepadding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left,padding_right\\text{padding\\_right}padding_right, padding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom)"}]}},
{"id": "torch.nn.ReplicationPad1d", "type": "class", "code": "torch.nn.ReplicationPad1d(padding:Union[T,Tuple[T,T]])", "example": "NA", "summary": "Pads the input tensor using replication of the input boundary", "returns": [], "shape": "\nInput: (N,C,Win)(N, C, W_{in})(N,C,Win\u200b)\n\n\nOutput: (N,C,Wout)(N, C, W_{out})(N,C,Wout\u200b)\n\n where\nWout=Win+padding_left+padding_rightW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout\u200b=Win\u200b+padding_left+padding_right\n\n\n\n\n", "code-info": {"name": "torch.nn.ReplicationPad1d", "parameters": [{"name": "padding", "type": "Union[T,Tuple[T,T]]", "is_optional": false, "description": "the size of the padding. If is int, uses the samepadding in all boundaries. If a 2-tuple, uses(padding_left\\text{padding\\_left}padding_left, padding_right\\text{padding\\_right}padding_right)"}]}},
{"id": "torch.nn.ReplicationPad2d", "type": "class", "code": "torch.nn.ReplicationPad2d(padding:Union[T,Tuple[T,T,T,T]])", "example": "NA", "summary": "Pads the input tensor using replication of the input boundary", "returns": [], "shape": "\nInput: (N,C,Hin,Win)(N, C, H_{in}, W_{in})(N,C,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Hout,Wout)(N, C, H_{out}, W_{out})(N,C,Hout\u200b,Wout\u200b)\n\n where\nHout=Hin+padding_top+padding_bottomH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}Hout\u200b=Hin\u200b+padding_top+padding_bottom\n\n\nWout=Win+padding_left+padding_rightW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout\u200b=Win\u200b+padding_left+padding_right\n\n\n\n\n", "code-info": {"name": "torch.nn.ReplicationPad2d", "parameters": [{"name": "padding", "type": "Union[T,Tuple[T,T,T,T]]", "is_optional": false, "description": "the size of the padding. If is int, uses the samepadding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left,padding_right\\text{padding\\_right}padding_right, padding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom)"}]}},
{"id": "torch.max", "type": "function", "code": "torch.max()", "example": "  a = torch.randn(1, 3)  a tensor([[ 0.6763,  0.7445, -2.2369]])  torch.max(a) tensor(0.7445)     torch.max(input, dim, keepdim=False, out=None) - (Tensor, LongTensor)   Returns a namedtuple (values, indices) where values is the maximum value of each row of the input tensor in the given dimension dim. And indices is the index location of each maximum value found (argmax). If keepdim is True, the output tensors are of the same size as input except in the dimension dim where they are of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensors having 1 fewer dimension than input.  Parameters  {input} \u2013  {dim} \u2013  Default ({keepdim}) \u2013 False. out (tuple, optional) \u2013 the result tuple of two output tensors (max, max_indices)    ", "summary": "  torch.max(input) \u2192 Tensor   Returns the maximum value of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.max", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,dim,keepdim=False,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,other,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.min", "type": "function", "code": "torch.min()", "example": "  a = torch.randn(1, 3)  a tensor([[ 0.6750,  1.0857,  1.7197]])  torch.min(a) tensor(0.6750)     torch.min(input, dim, keepdim=False, out=None) - (Tensor, LongTensor)   Returns a namedtuple (values, indices) where values is the minimum value of each row of the input tensor in the given dimension dim. And indices is the index location of each minimum value found (argmin). If keepdim is True, the output tensors are of the same size as input except in the dimension dim where they are of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensors having 1 fewer dimension than input.  Parameters  {input} \u2013  {dim} \u2013  {keepdim} \u2013  out (tuple, optional) \u2013 the tuple of two output tensors (min, min_indices)    ", "summary": "  torch.min(input) \u2192 Tensor   Returns the minimum value of all elements in the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.min", "parameters": []}},
{"id": "torch.nn.ReplicationPad3d", "type": "class", "code": "torch.nn.ReplicationPad3d(padding:Union[T,Tuple[T,T,T,T,T,T]])", "example": "NA", "summary": "Pads the input tensor using replication of the input boundary", "returns": [], "shape": "\nInput: (N,C,Din,Hin,Win)(N, C, D_{in}, H_{in}, W_{in})(N,C,Din\u200b,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Dout,Hout,Wout)(N, C, D_{out}, H_{out}, W_{out})(N,C,Dout\u200b,Hout\u200b,Wout\u200b)\n\n where\nDout=Din+padding_front+padding_backD_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}Dout\u200b=Din\u200b+padding_front+padding_back\n\n\nHout=Hin+padding_top+padding_bottomH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}Hout\u200b=Hin\u200b+padding_top+padding_bottom\n\n\nWout=Win+padding_left+padding_rightW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout\u200b=Win\u200b+padding_left+padding_right\n\n\n\n\n", "code-info": {"name": "torch.nn.ReplicationPad3d", "parameters": [{"name": "padding", "type": "Union[T,Tuple[T,T,T,T,T,T]]", "is_optional": false, "description": "the size of the padding. If is int, uses the samepadding in all boundaries. If a 6-tuple, uses(padding_left\\text{padding\\_left}padding_left, padding_right\\text{padding\\_right}padding_right,padding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom,padding_front\\text{padding\\_front}padding_front, padding_back\\text{padding\\_back}padding_back)"}]}},
{"id": "torch.nn.ZeroPad2d", "type": "class", "code": "torch.nn.ZeroPad2d(padding:Union[T,Tuple[T,T,T,T]])", "example": "NA", "summary": "Pads the input tensor boundaries with zero", "returns": [], "shape": "\nInput: (N,C,Hin,Win)(N, C, H_{in}, W_{in})(N,C,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Hout,Wout)(N, C, H_{out}, W_{out})(N,C,Hout\u200b,Wout\u200b)\n\n where\nHout=Hin+padding_top+padding_bottomH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}Hout\u200b=Hin\u200b+padding_top+padding_bottom\n\n\nWout=Win+padding_left+padding_rightW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout\u200b=Win\u200b+padding_left+padding_right\n\n\n\n\n", "code-info": {"name": "torch.nn.ZeroPad2d", "parameters": [{"name": "padding", "type": "Union[T,Tuple[T,T,T,T]]", "is_optional": false, "description": "the size of the padding. If is int, uses the samepadding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left,padding_right\\text{padding\\_right}padding_right, padding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom)"}]}},
{"id": "torch.nn.ConstantPad1d", "type": "class", "code": "torch.nn.ConstantPad1d(padding:Union[T,Tuple[T,T]],value:float)", "example": "NA", "summary": "Pads the input tensor boundaries with a constant value", "returns": [], "shape": "\nInput: (N,C,Win)(N, C, W_{in})(N,C,Win\u200b)\n\n\nOutput: (N,C,Wout)(N, C, W_{out})(N,C,Wout\u200b)\n\n where\nWout=Win+padding_left+padding_rightW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout\u200b=Win\u200b+padding_left+padding_right\n\n\n\n\n", "code-info": {"name": "torch.nn.ConstantPad1d", "parameters": [{"name": "padding", "type": "Union[T,Tuple[T,T]]", "is_optional": false, "description": "the size of the padding. If is int, uses the samepadding in both boundaries. If a 2-tuple, uses(padding_left\\text{padding\\_left}padding_left, padding_right\\text{padding\\_right}padding_right)"}, {"name": "value", "type": "float", "is_optional": false, "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,dim,keepdim=False,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": false, "type": "others", "description": ""}, {"name": "keepdim", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(input,other,out=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "other", "is_optional": false, "type": "others", "description": ""}, {"name": "out", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "torch.ne", "type": "function", "code": "torch.ne(input,other,out=None)", "example": "  torch.ne(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[False, True], [True, False]])   ", "summary": "Computes input\u2260otherinput \\neq otherinput\ue020\u200b=other   element-wise", "returns": "A torch.BoolTensor containing a True at each location where comparison is true.", "shape": "NA", "code-info": {"name": "torch.ne", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the tensor to compare"}, {"name": "other", "is_optional": false, "type": "Tensor or float", "description": " the tensor or value to compare"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor that must be a BoolTensor"}]}},
{"id": "torch.sort", "type": "function", "code": "torch.sort(input,dim=-1,descending=False,out=None)", "example": "  x = torch.randn(3, 4)  sorted, indices = torch.sort(x)  sorted tensor([[-0.2162,  0.0608,  0.6719,  2.3332],         [-0.5793,  0.0061,  0.6058,  0.9497],         [-0.5071,  0.3343,  0.9553,  1.0960]])  indices tensor([[ 1,  0,  2,  3],         [ 3,  1,  0,  2],         [ 0,  3,  1,  2]])   sorted, indices = torch.sort(x, 0)  sorted tensor([[-0.5071, -0.2162,  0.6719, -0.5793],         [ 0.0608,  0.0061,  0.9497,  0.3343],         [ 0.6058,  0.9553,  1.0960,  2.3332]])  indices tensor([[ 2,  0,  0,  1],         [ 0,  1,  1,  2],         [ 1,  2,  2,  0]])   ", "summary": "Sorts the elements of the input tensor along a given dimension in ascending order by value", "returns": null, "shape": "NA", "code-info": {"name": "torch.sort", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "dim", "is_optional": true, "type": "int, optional", "default_value": "-1", "description": " the dimension to sort along"}, {"name": "descending", "is_optional": true, "type": "bool", "default_value": "False", "description": " controls the sorting order (ascending or descending"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": " the output tuple of (Tensor, LongTensor that canbe optionally given to be used as output buffers"}]}},
{"id": "torch.topk", "type": "function", "code": "torch.topk(input,k,dim=None,largest=True,sorted=True,out=None)", "example": "  x = torch.arange(1., 6.)  x tensor([ 1.,  2.,  3.,  4.,  5.])  torch.topk(x, 3) torch.return_types.topk(values=tensor([5., 4., 3.]), indices=tensor([4, 3, 2]))   ", "summary": "Returns the k largest elements of the given input tensor along a given dimension", "returns": null, "shape": "NA", "code-info": {"name": "torch.topk", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "k", "is_optional": false, "type": "int", "description": " the k in \u201ctop-k\u201d"}, {"name": "dim", "is_optional": true, "type": "int, optional", "default_value": "None", "description": " the dimension to sort along"}, {"name": "largest", "is_optional": true, "type": "bool", "default_value": "True", "description": " controls whether to return largest orsmallest elements"}, {"name": "sorted", "is_optional": true, "type": "bool", "default_value": "True", "description": " controls whether to return the elementsin sorted order"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": " the output tuple of (Tensor, LongTensor that can beoptionally given to be used as output buffers"}]}},
{"id": "torch.fft", "type": "function", "code": "torch.fft(input,signal_ndim,normalized=False)", "example": "  # unbatched 2D FFT  x = torch.randn(4, 3, 2)  torch.fft(x, 2) tensor([[[-0.0876,  1.7835],          [-2.0399, -2.9754],          [ 4.4773, -5.0119]],          [[-1.5716,  2.7631],          [-3.8846,  5.2652],          [ 0.2046, -0.7088]],          [[ 1.9938, -0.5901],          [ 6.5637,  6.4556],          [ 2.9865,  4.9318]],          [[ 7.0193,  1.1742],          [-1.3717, -2.1084],          [ 2.0289,  2.9357]]])  # batched 1D FFT  torch.fft(x, 1) tensor([[[ 1.8385,  1.2827],          [-0.1831,  1.6593],          [ 2.4243,  0.5367]],          [[-0.9176, -1.5543],          [-3.9943, -2.9860],          [ 1.2838, -2.9420]],          [[-0.8854, -0.6860],          [ 2.4450,  0.0808],          [ 1.3076, -0.5768]],          [[-0.1231,  2.7411],          [-0.3075, -1.7295],          [-0.5384, -2.0299]]])  # arbitrary number of batch dimensions, 2D FFT  x = torch.randn(3, 3, 5, 5, 2)  y = torch.fft(x, 2)  y.shape torch.Size([3, 3, 5, 5, 2])   ", "summary": "Complex-to-complex Discrete Fourier Transform This method computes the complex-to-complex discrete Fourier transform", "returns": "A tensor containing the complex-to-complex Fourier transform result", "shape": "NA", "code-info": {"name": "torch.fft", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of at least signal_ndim + 1dimensions"}, {"name": "signal_ndim", "is_optional": false, "type": "Tensor", "description": " the number of dimensions in each signal.signal_ndim can only be 1, 2 or 3"}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": " controls whether to return normalized results.Default"}]}},
{"id": "torch.nn.ConstantPad2d", "type": "class", "code": "torch.nn.ConstantPad2d(padding:Union[T,Tuple[T,T,T,T]],value:float)", "example": "NA", "summary": "Pads the input tensor boundaries with a constant value", "returns": [], "shape": "\nInput: (N,C,Hin,Win)(N, C, H_{in}, W_{in})(N,C,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Hout,Wout)(N, C, H_{out}, W_{out})(N,C,Hout\u200b,Wout\u200b)\n\n where\nHout=Hin+padding_top+padding_bottomH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}Hout\u200b=Hin\u200b+padding_top+padding_bottom\n\n\nWout=Win+padding_left+padding_rightW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout\u200b=Win\u200b+padding_left+padding_right\n\n\n\n\n", "code-info": {"name": "torch.nn.ConstantPad2d", "parameters": [{"name": "padding", "type": "Union[T,Tuple[T,T,T,T]]", "is_optional": false, "description": "the size of the padding. If is int, uses the samepadding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left,padding_right\\text{padding\\_right}padding_right, padding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom)"}, {"name": "value", "type": "float", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.ConstantPad3d", "type": "class", "code": "torch.nn.ConstantPad3d(padding:Union[T,Tuple[T,T,T,T,T,T]],value:float)", "example": "NA", "summary": "Pads the input tensor boundaries with a constant value", "returns": [], "shape": "\nInput: (N,C,Din,Hin,Win)(N, C, D_{in}, H_{in}, W_{in})(N,C,Din\u200b,Hin\u200b,Win\u200b)\n\n\nOutput: (N,C,Dout,Hout,Wout)(N, C, D_{out}, H_{out}, W_{out})(N,C,Dout\u200b,Hout\u200b,Wout\u200b)\n\n where\nDout=Din+padding_front+padding_backD_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}Dout\u200b=Din\u200b+padding_front+padding_back\n\n\nHout=Hin+padding_top+padding_bottomH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}Hout\u200b=Hin\u200b+padding_top+padding_bottom\n\n\nWout=Win+padding_left+padding_rightW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout\u200b=Win\u200b+padding_left+padding_right\n\n\n\n\n", "code-info": {"name": "torch.nn.ConstantPad3d", "parameters": [{"name": "padding", "type": "Union[T,Tuple[T,T,T,T,T,T]]", "is_optional": false, "description": "the size of the padding. If is int, uses the samepadding in all boundaries. If a 6-tuple, uses(padding_left\\text{padding\\_left}padding_left, padding_right\\text{padding\\_right}padding_right,padding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom,padding_front\\text{padding\\_front}padding_front, padding_back\\text{padding\\_back}padding_back)"}, {"name": "value", "type": "float", "is_optional": false, "description": ""}]}},
{"id": "torch.ifft", "type": "function", "code": "torch.ifft(input,signal_ndim,normalized=False)", "example": "  x = torch.randn(3, 3, 2)  x tensor([[[ 1.2766,  1.3680],          [-0.8337,  2.0251],          [ 0.9465, -1.4390]],          [[-0.1890,  1.6010],          [ 1.1034, -1.9230],          [-0.9482,  1.0775]],          [[-0.7708, -0.8176],          [-0.1843, -0.2287],          [-1.9034, -0.2196]]])  y = torch.fft(x, 2)  torch.ifft(y, 2)  # recover x tensor([[[ 1.2766,  1.3680],          [-0.8337,  2.0251],          [ 0.9465, -1.4390]],          [[-0.1890,  1.6010],          [ 1.1034, -1.9230],          [-0.9482,  1.0775]],          [[-0.7708, -0.8176],          [-0.1843, -0.2287],          [-1.9034, -0.2196]]])   ", "summary": "Complex-to-complex Inverse Discrete Fourier Transform This method computes the complex-to-complex inverse discrete Fourier transform", "returns": "A tensor containing the complex-to-complex inverse Fourier transform result", "shape": "NA", "code-info": {"name": "torch.ifft", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of at least signal_ndim + 1dimensions"}, {"name": "signal_ndim", "is_optional": false, "type": "Tensor", "description": " the number of dimensions in each signal.signal_ndim can only be 1, 2 or 3"}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": " controls whether to return normalized results.Default"}]}},
{"id": "torch.rfft", "type": "function", "code": "torch.rfft(input,signal_ndim,normalized=False,onesided=True)", "example": "  x = torch.randn(5, 5)  torch.rfft(x, 2).shape torch.Size([5, 3, 2])  torch.rfft(x, 2, onesided=False).shape torch.Size([5, 5, 2])   ", "summary": "Real-to-complex Discrete Fourier Transform This method computes the real-to-complex discrete Fourier transform", "returns": "A tensor containing the real-to-complex Fourier transform result", "shape": "NA", "code-info": {"name": "torch.rfft", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of at least signal_ndim dimensions"}, {"name": "signal_ndim", "is_optional": false, "type": "Tensor", "description": " the number of dimensions in each signal.signal_ndim can only be 1, 2 or 3"}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": " controls whether to return normalized results.Default"}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": " controls whether to return half of results toavoid redundancy. Default"}]}},
{"id": "torch.nn.ELU", "type": "class", "code": "torch.nn.ELU(alpha:float=1.0,inplace:bool=False)", "example": "NA", "summary": "Applies the element-wise function:  ELU(x)=max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x)\u22121))\\text{ELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1))  ELU(x)=max(0,x)+min(0,\u03b1\u2217(exp(x)\u22121))   Parameters  alpha \u2013 the \u03b1\\alpha\u03b1   value for the ELU formulation", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ELU", "parameters": [{"name": "alpha", "type": "float", "default_value": "10", "is_optional": false, "description": "the \u03b1\\alpha\u03b1 value for the ELU formulation. Default: 1.0"}, {"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "can optionally do the operation in-place. Default: False"}]}},
{"id": "torch.nn.Hardshrink", "type": "class", "code": "torch.nn.Hardshrink(lambd:float=0.5)", "example": "NA", "summary": "Applies the hard shrinkage function element-wise:  HardShrink(x)={x,\u00a0if\u00a0x&gt;\u03bbx,\u00a0if\u00a0x&lt;\u2212\u03bb0,\u00a0otherwise\u00a0\\text{HardShrink}(x) = \\begin{cases} x, &amp; \\text{ if } x &gt; \\lambda \\\\ x, &amp; \\text{ if } x &lt; -\\lambda \\\\ 0, &amp; \\text{ otherwise } \\end{cases}  HardShrink(x)=\u23a9\u23aa\u23aa\u23a8\u23aa\u23aa\u23a7\u200bx,x,0,\u200b\u00a0if\u00a0x&gt;\u03bb\u00a0if\u00a0x&lt;\u2212\u03bb\u00a0otherwise\u00a0\u200b   Parameters lambd \u2013 the \u03bb\\lambda\u03bb   value for the Hardshrink formulation", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Hardshrink", "parameters": [{"name": "lambd", "type": "float", "default_value": "05", "is_optional": false, "description": "the \u03bb\\lambda\u03bb value for the Hardshrink formulation. Default: 0.5"}]}},
{"id": "torch.nn.Hardtanh", "type": "class", "code": "torch.nn.Hardtanh(min_val:float=-1.0,max_val:float=1.0,inplace:bool=False,min_value:Optional[float]=None,max_value:Optional[float]=None)", "example": "NA", "summary": "Applies the HardTanh function element-wise HardTanh is defined as:  HardTanh(x)={1\u00a0if\u00a0x&gt;1\u22121\u00a0if\u00a0x&lt;\u22121x\u00a0otherwise\u00a0\\text{HardTanh}(x) = \\begin{cases}     1 &amp; \\text{ if } x &gt; 1 \\\\     -1 &amp; \\text{ if } x &lt; -1 \\\\     x &amp; \\text{ otherwise } \\\\ \\end{cases}  HardTanh(x)=\u23a9\u23aa\u23aa\u23a8\u23aa\u23aa\u23a7\u200b1\u22121x\u200b\u00a0if\u00a0x&gt;1\u00a0if\u00a0x&lt;\u22121\u00a0otherwise\u00a0\u200b  The range of the linear region [\u22121,1][-1, 1][\u22121,1]   can be adjusted using min_val and max_val", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Hardtanh", "parameters": [{"name": "min_val", "type": "float", "default_value": "-1", "is_optional": false, "description": "minimum value of the linear region range. Default: -1"}, {"name": "max_val", "type": "float", "default_value": "1", "is_optional": false, "description": "maximum value of the linear region range. Default: 1"}, {"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "can optionally do the operation in-place. Default: False"}, {"name": "min_value", "type": "Optional[float]", "default_value": "None", "is_optional": false, "description": ""}, {"name": "max_value", "type": "Optional[float]", "default_value": "None", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.LeakyReLU", "type": "class", "code": "torch.nn.LeakyReLU(negative_slope:float=0.01,inplace:bool=False)", "example": "NA", "summary": "Applies the element-wise function:  LeakyReLU(x)=max\u2061(0,x)+negative_slope\u2217min\u2061(0,x)\\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x)  LeakyReLU(x)=max(0,x)+negative_slope\u2217min(0,x)  or  LeakyRELU(x)={x,\u00a0if\u00a0x\u22650negative_slope\u00d7x,\u00a0otherwise\u00a0\\text{LeakyRELU}(x) = \\begin{cases} x, &amp; \\text{ if } x \\geq 0 \\\\ \\text{negative\\_slope} \\times x, &amp; \\text{ otherwise } \\end{cases}  LeakyRELU(x)={x,negative_slope\u00d7x,\u200b\u00a0if\u00a0x\u22650\u00a0otherwise\u00a0\u200b   Parameters  negative_slope \u2013 Controls the angle of the negative slope", "returns": [], "shape": "", "code-info": {"name": "torch.nn.LeakyReLU", "parameters": [{"name": "negative_slope", "type": "float", "default_value": "1e-2", "is_optional": false, "description": "Controls the angle of the negative slope. Default: 1e-2"}, {"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "can optionally do the operation in-place. Default: False"}]}},
{"id": "torch.nn.LogSigmoid", "type": "class", "code": "torch.nn.LogSigmoid", "example": "NA", "summary": "Applies the element-wise function:  LogSigmoid(x)=log\u2061(11+exp\u2061(\u2212x))\\text{LogSigmoid}(x) = \\log\\left(\\frac{ 1 }{ 1 + \\exp(-x)}\\right)  LogSigmoid(x)=log(1+exp(\u2212x)1\u200b)   Shape: Input: (N,\u2217)(N, *)(N,\u2217)   where * means, any number of additional dimensions Output: (N,\u2217)(N, *)(N,\u2217)  , same shape as the input     Examples: &gt;&gt;&gt; m = nn.LogSigmoid() &gt;&gt;&gt; input = torch.randn(2) &gt;&gt;&gt; output = m(input)   ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.LogSigmoid", "parameters": []}},
{"id": "torch.irfft", "type": "function", "code": "torch.irfft(input,signal_ndim,normalized=False,onesided=True,signal_sizes=None)", "example": "  x = torch.randn(4, 4)  torch.rfft(x, 2, onesided=True).shape torch.Size([4, 3, 2])   # notice that with onesided=True, output size does not determine the original signal size  x = torch.randn(4, 5)   torch.rfft(x, 2, onesided=True).shape torch.Size([4, 3, 2])   # now we use the original shape to recover x  x tensor([[-0.8992,  0.6117, -1.6091, -0.4155, -0.8346],         [-2.1596, -0.0853,  0.7232,  0.1941, -0.0789],         [-2.0329,  1.1031,  0.6869, -0.5042,  0.9895],         [-0.1884,  0.2858, -1.5831,  0.9917, -0.8356]])  y = torch.rfft(x, 2, onesided=True)  torch.irfft(y, 2, onesided=True, signal_sizes=x.shape)  # recover x tensor([[-0.8992,  0.6117, -1.6091, -0.4155, -0.8346],         [-2.1596, -0.0853,  0.7232,  0.1941, -0.0789],         [-2.0329,  1.1031,  0.6869, -0.5042,  0.9895],         [-0.1884,  0.2858, -1.5831,  0.9917, -0.8356]])   ", "summary": "Complex-to-real Inverse Discrete Fourier Transform This method computes the complex-to-real inverse discrete Fourier transform", "returns": "A tensor containing the complex-to-real inverse Fourier transform result", "shape": "NA", "code-info": {"name": "torch.irfft", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of at least signal_ndim + 1dimensions"}, {"name": "signal_ndim", "is_optional": false, "type": "Tensor", "description": " the number of dimensions in each signal.signal_ndim can only be 1, 2 or 3"}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": " controls whether to return normalized results.Default"}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": " controls whether input was halfed to avoidredundancy, e.g., by rfft(. Default"}, {"name": "signal_sizes", "is_optional": true, "type": "list or torch.Size, optional", "default_value": "None", "description": " the size of the originalsignal (without batch dimension. Default"}]}},
{"id": "torch.stft", "type": "function", "code": "torch.stft(input,n_fft,hop_length=None,win_length=None,window=None,center=True,pad_mode='reflect',normalized=False,onesided=True)", "example": "NA", "summary": "Short-time Fourier transform (STFT)", "returns": "A tensor containing the STFT result with shape described above", "shape": "NA", "code-info": {"name": "torch.stft", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor"}, {"name": "n_fft", "is_optional": false, "type": "int", "description": " size of Fourier transform"}, {"name": "hop_length", "is_optional": true, "type": "int, optional", "default_value": "None", "description": " the distance between neighboring sliding windowframes. Default"}, {"name": "win_length", "is_optional": true, "type": "int, optional", "default_value": "None", "description": " the size of window frame and STFT filter.Default"}, {"name": "window", "is_optional": true, "type": "int, optional", "default_value": "None", "description": " the optional window function.Default"}, {"name": "center", "is_optional": true, "type": "bool", "default_value": "True", "description": " whether to pad input on both sides sothat the ttt-th frame is centered at time t\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.Default"}, {"name": "pad_mode", "is_optional": true, "type": "string", "default_value": "'reflect'", "description": " controls the padding method used whencenter is True. Default"}, {"name": "normalized", "is_optional": true, "type": "bool", "default_value": "False", "description": " controls whether to return the normalized STFT resultsDefault"}, {"name": "onesided", "is_optional": true, "type": "bool", "default_value": "True", "description": " controls whether to return half of results toavoid redundancy Default"}]}},
{"id": "torch.nn.MultiheadAttention", "type": "class", "code": "torch.nn.MultiheadAttention(embed_dim,num_heads,dropout=0.0,bias=True,add_bias_kv=False,add_zero_attn=False,kdim=None,vdim=None)", "example": "NA", "summary": "Allows the model to jointly attend to information from different representation subspaces", "returns": [], "shape": "", "code-info": {"name": "torch.nn.MultiheadAttention", "parameters": []}},
{"id": "torch.nn.PReLU", "type": "class", "code": "torch.nn.PReLU(num_parameters:int=1,init:float=0.25)", "example": "NA", "summary": "Applies the element-wise function:  PReLU(x)=max\u2061(0,x)+a\u2217min\u2061(0,x)\\text{PReLU}(x) = \\max(0,x) + a * \\min(0,x)  PReLU(x)=max(0,x)+a\u2217min(0,x)  or  PReLU(x)={x,\u00a0if\u00a0x\u22650ax,\u00a0otherwise\u00a0\\text{PReLU}(x) = \\begin{cases} x, &amp; \\text{ if } x \\geq 0 \\\\ ax, &amp; \\text{ otherwise } \\end{cases}  PReLU(x)={x,ax,\u200b\u00a0if\u00a0x\u22650\u00a0otherwise\u00a0\u200b  Here aaa   is a learnable parameter", "returns": [], "shape": "", "code-info": {"name": "torch.nn.PReLU", "parameters": [{"name": "num_parameters", "type": "int", "default_value": "1", "is_optional": false, "description": "number of aaa to learn.Although it takes an int as input, there is only two values are legitimate:1, or the number of channels at input. Default: 1"}, {"name": "init", "type": "float", "default_value": "025", "is_optional": false, "description": "the initial value of aaa. Default: 0.25"}]}},
{"id": "torch.nn.ReLU", "type": "class", "code": "torch.nn.ReLU(inplace:bool=False)", "example": "NA", "summary": "Applies the rectified linear unit function element-wise: ReLU(x)=(x)+=max\u2061(0,x)\\text{ReLU}(x) = (x)^+ = \\max(0, x)ReLU(x)=(x)+=max(0,x)    Parameters inplace \u2013 can optionally do the operation in-place", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ReLU", "parameters": [{"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "can optionally do the operation in-place. Default: False"}]}},
{"id": "torch.bartlett_window", "type": "function", "code": "torch.bartlett_window(window_length,periodic=True,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "NA", "summary": "Bartlett window function", "returns": "A 1-D tensor of size (window_length,)(\\text{window\\_length},)(window_length,) containing the window", "shape": "NA", "code-info": {"name": "torch.bartlett_window", "parameters": [{"name": "window_length", "is_optional": false, "type": "int", "description": " the size of returned window"}, {"name": "periodic", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, returns a window to be used as periodicfunction. If False, return a symmetric window."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned window tensor. Onlytorch.strided (dense layout is supported."}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.blackman_window", "type": "function", "code": "torch.blackman_window(window_length,periodic=True,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "NA", "summary": "Blackman window function", "returns": "A 1-D tensor of size (window_length,)(\\text{window\\_length},)(window_length,) containing the window", "shape": "NA", "code-info": {"name": "torch.blackman_window", "parameters": [{"name": "window_length", "is_optional": false, "type": "int", "description": " the size of returned window"}, {"name": "periodic", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, returns a window to be used as periodicfunction. If False, return a symmetric window."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned window tensor. Onlytorch.strided (dense layout is supported."}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.nn.ReLU6", "type": "class", "code": "torch.nn.ReLU6(inplace:bool=False)", "example": "NA", "summary": "Applies the element-wise function:  ReLU6(x)=min\u2061(max\u2061(0,x),6)\\text{ReLU6}(x) = \\min(\\max(0,x), 6)  ReLU6(x)=min(max(0,x),6)   Parameters inplace \u2013 can optionally do the operation in-place", "returns": [], "shape": "", "code-info": {"name": "torch.nn.ReLU6", "parameters": [{"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "can optionally do the operation in-place. Default: False"}]}},
{"id": "torch.nn.RReLU", "type": "class", "code": "torch.nn.RReLU(lower:float=0.125,upper:float=0.3333333333333333,inplace:bool=False)", "example": "NA", "summary": "Applies the randomized leaky rectified liner unit function, element-wise, as described in the paper: Empirical Evaluation of Rectified Activations in Convolutional Network", "returns": [], "shape": "", "code-info": {"name": "torch.nn.RReLU", "parameters": [{"name": "lower", "type": "float", "default_value": "18\\frac{1}{8}81\u200b", "is_optional": false, "description": "lower bound of the uniform distribution. Default: 18\\frac{1}{8}81\u200b"}, {"name": "upper", "type": "float", "default_value": "13\\frac{1}{3}31\u200b", "is_optional": false, "description": "upper bound of the uniform distribution. Default: 13\\frac{1}{3}31\u200b"}, {"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "can optionally do the operation in-place. Default: False"}]}},
{"id": "torch.nn.SELU", "type": "class", "code": "torch.nn.SELU(inplace:bool=False)", "example": "NA", "summary": "Applied element-wise, as:  SELU(x)=scale\u2217(max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x)\u22121)))\\text{SELU}(x) = \\text{scale} * (\\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)))  SELU(x)=scale\u2217(max(0,x)+min(0,\u03b1\u2217(exp(x)\u22121)))  with \u03b1=1.6732632423543772848170429916717\\alpha = 1.6732632423543772848170429916717\u03b1=1.6732632423543772848170429916717   and scale=1.0507009873554804934193349852946\\text{scale} = 1.0507009873554804934193349852946scale=1.0507009873554804934193349852946  ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.SELU", "parameters": [{"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "can optionally do the operation in-place. Default: False"}]}},
{"id": "torch.nn.CELU", "type": "class", "code": "torch.nn.CELU(alpha:float=1.0,inplace:bool=False)", "example": "NA", "summary": "Applies the element-wise function:  CELU(x)=max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x/\u03b1)\u22121))\\text{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1))  CELU(x)=max(0,x)+min(0,\u03b1\u2217(exp(x/\u03b1)\u22121))  More details can be found in the paper Continuously Differentiable Exponential Linear Units ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.CELU", "parameters": [{"name": "alpha", "type": "float", "default_value": "10", "is_optional": false, "description": "the \u03b1\\alpha\u03b1 value for the CELU formulation. Default: 1.0"}, {"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "can optionally do the operation in-place. Default: False"}]}},
{"id": "torch.hamming_window", "type": "function", "code": "torch.hamming_window(window_length,periodic=True,alpha=0.54,beta=0.46,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "NA", "summary": "Hamming window function", "returns": "A 1-D tensor of size (window_length,)(\\text{window\\_length},)(window_length,) containing the window", "shape": "NA", "code-info": {"name": "torch.hamming_window", "parameters": [{"name": "window_length", "is_optional": false, "type": "int", "description": " the size of returned window"}, {"name": "periodic", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, returns a window to be used as periodicfunction. If False, return a symmetric window."}, {"name": "alpha", "is_optional": true, "type": "float, optional", "default_value": "0.54", "description": " The coefficient \u03b1\\alpha\u03b1 in the equation above"}, {"name": "beta", "is_optional": true, "type": "float, optional", "default_value": "0.46", "description": " The coefficient \u03b2\\beta\u03b2 in the equation above"}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned window tensor. Onlytorch.strided (dense layout is supported."}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.hann_window", "type": "function", "code": "torch.hann_window(window_length,periodic=True,dtype=None,layout=torch.strided,device=None,requires_grad=False)", "example": "NA", "summary": "Hann window function", "returns": "A 1-D tensor of size (window_length,)(\\text{window\\_length},)(window_length,) containing the window", "shape": "NA", "code-info": {"name": "torch.hann_window", "parameters": [{"name": "window_length", "is_optional": false, "type": "int", "description": " the size of returned window"}, {"name": "periodic", "is_optional": true, "type": "bool", "default_value": "True", "description": " If True, returns a window to be used as periodicfunction. If False, return a symmetric window."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " the desired layout of returned window tensor. Onlytorch.strided (dense layout is supported."}, {"name": "device", "is_optional": true, "type": "torch.device, optional", "default_value": "None", "description": " the desired device of returned tensor.Default"}, {"name": "requires_grad", "is_optional": true, "type": "bool", "default_value": "False", "description": " If autograd should record operations on thereturned tensor. Default"}]}},
{"id": "torch.nn.GELU", "type": "class", "code": "torch.nn.GELU", "example": "NA", "summary": "Applies the Gaussian Error Linear Units function:  GELU(x)=x\u2217\u03a6(x)\\text{GELU}(x) = x * \\Phi(x)  GELU(x)=x\u2217\u03a6(x)  where \u03a6(x)\\Phi(x)\u03a6(x)   is the Cumulative Distribution Function for Gaussian Distribution", "returns": [], "shape": "", "code-info": {"name": "torch.nn.GELU", "parameters": []}},
{"id": "torch.nn.Sigmoid", "type": "class", "code": "torch.nn.Sigmoid", "example": "NA", "summary": "Applies the element-wise function:  Sigmoid(x)=\u03c3(x)=11+exp\u2061(\u2212x)\\text{Sigmoid}(x) = \\sigma(x) = \\frac{1}{1 + \\exp(-x)}  Sigmoid(x)=\u03c3(x)=1+exp(\u2212x)1\u200b   Shape: Input: (N,\u2217)(N, *)(N,\u2217)   where * means, any number of additional dimensions Output: (N,\u2217)(N, *)(N,\u2217)  , same shape as the input     Examples: &gt;&gt;&gt; m = nn.Sigmoid() &gt;&gt;&gt; input = torch.randn(2) &gt;&gt;&gt; output = m(input)   ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Sigmoid", "parameters": []}},
{"id": "torch.nn.Softplus", "type": "class", "code": "torch.nn.Softplus(beta:int=1,threshold:int=20)", "example": "NA", "summary": "Applies the element-wise function:  Softplus(x)=1\u03b2\u2217log\u2061(1+exp\u2061(\u03b2\u2217x))\\text{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 + \\exp(\\beta * x))  Softplus(x)=\u03b21\u200b\u2217log(1+exp(\u03b2\u2217x))  SoftPlus is a smooth approximation to the ReLU function and can be used to constrain the output of a machine to always be positive", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Softplus", "parameters": [{"name": "beta", "type": "int", "default_value": "1", "is_optional": false, "description": "the \u03b2\\beta\u03b2 value for the Softplus formulation. Default: 1"}, {"name": "threshold", "type": "int", "default_value": "20", "is_optional": false, "description": "values above this revert to a linear function. Default: 20"}]}},
{"id": "torch.nn.Softshrink", "type": "class", "code": "torch.nn.Softshrink(lambd:float=0.5)", "example": "NA", "summary": "Applies the soft shrinkage function elementwise:  SoftShrinkage(x)={x\u2212\u03bb,\u00a0if\u00a0x&gt;\u03bbx+\u03bb,\u00a0if\u00a0x&lt;\u2212\u03bb0,\u00a0otherwise\u00a0\\text{SoftShrinkage}(x) = \\begin{cases} x - \\lambda, &amp; \\text{ if } x &gt; \\lambda \\\\ x + \\lambda, &amp; \\text{ if } x &lt; -\\lambda \\\\ 0, &amp; \\text{ otherwise } \\end{cases}  SoftShrinkage(x)=\u23a9\u23aa\u23aa\u23a8\u23aa\u23aa\u23a7\u200bx\u2212\u03bb,x+\u03bb,0,\u200b\u00a0if\u00a0x&gt;\u03bb\u00a0if\u00a0x&lt;\u2212\u03bb\u00a0otherwise\u00a0\u200b   Parameters lambd \u2013 the \u03bb\\lambda\u03bb   (must be no less than zero) value for the Softshrink formulation", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Softshrink", "parameters": [{"name": "lambd", "type": "float", "default_value": "05", "is_optional": false, "description": "the \u03bb\\lambda\u03bb (must be no less than zero) value for the Softshrink formulation. Default: 0.5"}]}},
{"id": "torch.nn.Softsign", "type": "class", "code": "torch.nn.Softsign", "example": "NA", "summary": "Applies the element-wise function:  SoftSign(x)=x1+\u2223x\u2223\\text{SoftSign}(x) = \\frac{x}{ 1 + |x|}  SoftSign(x)=1+\u2223x\u2223x\u200b   Shape: Input: (N,\u2217)(N, *)(N,\u2217)   where * means, any number of additional dimensions Output: (N,\u2217)(N, *)(N,\u2217)  , same shape as the input     Examples: &gt;&gt;&gt; m = nn.Softsign() &gt;&gt;&gt; input = torch.randn(2) &gt;&gt;&gt; output = m(input)   ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Softsign", "parameters": []}},
{"id": "torch.bincount", "type": "function", "code": "torch.bincount(input,weights=None,minlength=0)", "example": "  input = torch.randint(0, 8, (5,), dtype=torch.int64)  weights = torch.linspace(0, 1, steps=5)  input, weights (tensor([4, 3, 6, 3, 4]),  tensor([ 0.0000,  0.2500,  0.5000,  0.7500,  1.0000])   torch.bincount(input) tensor([0, 0, 0, 2, 2, 0, 1])   input.bincount(weights) tensor([0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.5000])   ", "summary": "Count the frequency of each value in an array of non-negative ints", "returns": "a tensor of shape Size([max(input) + 1]) ifinput is non-empty, else Size(0)", "shape": "NA", "code-info": {"name": "torch.bincount", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " 1-d int tensor"}, {"name": "weights", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " optional, weight for each value in the input tensor.Should be of same size as input tensor."}, {"name": "minlength", "is_optional": true, "type": "int", "default_value": "0", "description": " optional, minimum number of bins. Should be non-negative."}]}},
{"id": "torch.broadcast_tensors", "type": "function", "code": "torch.broadcast_tensors(*tensors)", "example": "  x = torch.arange(3).view(1, 3)  y = torch.arange(2).view(2, 1)  a, b = torch.broadcast_tensors(x, y)  a.size() torch.Size([2, 3])  a tensor([[0, 1, 2],         [0, 1, 2]])   ", "summary": "Broadcasts the given tensors according to Broadcasting semantics", "returns": null, "shape": "NA", "code-info": {"name": "torch.broadcast_tensors", "parameters": [{"name": "*tensors", "is_optional": false, "type": "*tensors : any number of tensors of the same typ", "description": " any number of tensors of the same type"}]}},
{"id": "torch.cartesian_prod", "type": "function", "code": "torch.cartesian_prod(*tensors)", "example": "  a = [1, 2, 3]  b = [4, 5]  list(itertools.product(a, b)) [(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)]  tensor_a = torch.tensor(a)  tensor_b = torch.tensor(b)  torch.cartesian_prod(tensor_a, tensor_b) tensor([[1, 4],         [1, 5],         [2, 4],         [2, 5],         [3, 4],         [3, 5]])   ", "summary": "Do cartesian product of the given sequence of tensors", "returns": "A tensor equivalent to converting all the input tensors into lists,do itertools.product on these lists, and finally convert the resulting listinto tensor.", "shape": "NA", "code-info": {"name": "torch.cartesian_prod", "parameters": [{"name": "*tensors", "is_optional": false, "type": "*tensors : any number of 1 dimensional tensors", "description": " any number of 1 dimensional tensors."}]}},
{"id": "torch.cdist", "type": "function", "code": "torch.cdist(x1,x2,p=2,compute_mode='use_mm_for_euclid_dist_if_necessary')", "example": " a = torch.tensor([[0.9041,  0.0196], [-0.3108, -2.4423], [-0.4821,  1.059]])\n a\ntensor([[ 0.9041,  0.0196],\n        [-0.3108, -2.4423],\n        [-0.4821,  1.0590]])\n b = torch.tensor([[-2.1763, -0.4713], [-0.6986,  1.3702]])\n b\ntensor([[-2.1763, -0.4713],\n        [-0.6986,  1.3702]])\n torch.cdist(a, b, p=2)\ntensor([[3.1193, 2.0959],\n        [2.7138, 3.8322],\n        [2.2830, 0.3791]])\n\n", "summary": "Computes batched the p-norm distance between each pair of the two collections of row vectors", "returns": null, "shape": "NA", "code-info": {"name": "torch.cdist", "parameters": [{"name": "x1", "is_optional": false, "type": "Tensor", "description": " input tensor of shape B\u00d7P\u00d7MB \\times P \\times MB\u00d7P\u00d7M."}, {"name": "x2", "is_optional": false, "type": "Tensor", "description": " input tensor of shape B\u00d7R\u00d7MB \\times R \\times MB\u00d7R\u00d7M."}, {"name": "p", "is_optional": true, "type": "int", "default_value": "2", "description": " p value for the p-norm distance to calculate between each vector pair\u2208[0,\u221e]\\in [0, \\infty]\u2208[0,\u221e]."}, {"name": "compute_mode", "is_optional": true, "type": "string", "default_value": "'use_mm_for_euclid_dist_if_necessary'", "description": " \u2018use_mm_for_euclid_dist_if_necessary\u2019 - will use matrix multiplication approach to calculateeuclidean distance (p = 2 if P &gt; 25 or R &gt; 25\u2018use_mm_for_euclid_dist\u2019 - will always use matrix multiplication approach to calculateeuclidean distance (p = 2\u2018donot_use_mm_for_euclid_dist\u2019 - will never use matrix multiplication approach to calculateeuclidean distance (p = 2Default"}]}},
{"id": "torch.nn.Tanh", "type": "class", "code": "torch.nn.Tanh", "example": "NA", "summary": "Applies the element-wise function:  Tanh(x)=tanh\u2061(x)=exp\u2061(x)\u2212exp\u2061(\u2212x)exp\u2061(x)+exp\u2061(\u2212x)\\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)} {\\exp(x) + \\exp(-x)}  Tanh(x)=tanh(x)=exp(x)+exp(\u2212x)exp(x)\u2212exp(\u2212x)\u200b   Shape: Input: (N,\u2217)(N, *)(N,\u2217)   where * means, any number of additional dimensions Output: (N,\u2217)(N, *)(N,\u2217)  , same shape as the input     Examples: &gt;&gt;&gt; m = nn.Tanh() &gt;&gt;&gt; input = torch.randn(2) &gt;&gt;&gt; output = m(input)   ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Tanh", "parameters": []}},
{"id": "torch.nn.Tanhshrink", "type": "class", "code": "torch.nn.Tanhshrink", "example": "NA", "summary": "Applies the element-wise function:  Tanhshrink(x)=x\u2212tanh\u2061(x)\\text{Tanhshrink}(x) = x - \\tanh(x)  Tanhshrink(x)=x\u2212tanh(x)   Shape: Input: (N,\u2217)(N, *)(N,\u2217)   where * means, any number of additional dimensions Output: (N,\u2217)(N, *)(N,\u2217)  , same shape as the input     Examples: &gt;&gt;&gt; m = nn.Tanhshrink() &gt;&gt;&gt; input = torch.randn(2) &gt;&gt;&gt; output = m(input)   ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Tanhshrink", "parameters": []}},
{"id": "torch.nn.Threshold", "type": "class", "code": "torch.nn.Threshold(threshold:float,value:float,inplace:bool=False)", "example": "NA", "summary": "Thresholds each element of the input Tensor", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Threshold", "parameters": [{"name": "threshold", "type": "float", "is_optional": false, "description": "The value to threshold at"}, {"name": "value", "type": "float", "is_optional": false, "description": "The value to replace with"}, {"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "can optionally do the operation in-place. Default: False"}]}},
{"id": "torch.nn.Softmin", "type": "class", "code": "torch.nn.Softmin(dim:Optional[int]=None)", "example": "NA", "summary": "Applies the Softmin function to an n-dimensional input Tensor rescaling them so that the elements of the n-dimensional output Tensor lie in the range [0, 1] and sum to 1", "returns": "a Tensor of the same dimension and shape as the input, withvalues in the range [0, 1]", "shape": "", "code-info": {"name": "torch.nn.Softmin", "parameters": [{"name": "dim", "type": "Optional[int]", "default_value": "None", "is_optional": false, "description": "A dimension along which Softmin will be computed (so every slicealong dim will sum to 1)."}]}},
{"id": "torch.nn.Softmax", "type": "class", "code": "torch.nn.Softmax(dim:Optional[int]=None)", "example": "NA", "summary": "Applies the Softmax function to an n-dimensional input Tensor rescaling them so that the elements of the n-dimensional output Tensor lie in the range [0,1] and sum to 1", "returns": "a Tensor of the same dimension and shape as the input withvalues in the range [0, 1]", "shape": "", "code-info": {"name": "torch.nn.Softmax", "parameters": [{"name": "dim", "type": "Optional[int]", "default_value": "None", "is_optional": false, "description": "A dimension along which Softmax will be computed (so every slicealong dim will sum to 1)."}]}},
{"id": "torch.combinations", "type": "function", "code": "torch.combinations(input,r=2,with_replacement=False)", "example": "  a = [1, 2, 3]  list(itertools.combinations(a, r=2)) [(1, 2), (1, 3), (2, 3)]  list(itertools.combinations(a, r=3)) [(1, 2, 3)]  list(itertools.combinations_with_replacement(a, r=2)) [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)]  tensor_a = torch.tensor(a)  torch.combinations(tensor_a) tensor([[1, 2],         [1, 3],         [2, 3]])  torch.combinations(tensor_a, r=3) tensor([[1, 2, 3]])  torch.combinations(tensor_a, with_replacement=True) tensor([[1, 1],         [1, 2],         [1, 3],         [2, 2],         [2, 3],         [3, 3]])   ", "summary": "Compute combinations of length rrr   of the given tensor", "returns": "A tensor equivalent to converting all the input tensors into lists, doitertools.combinations or itertools.combinations_with_replacement on theselists, and finally convert the resulting list into tensor.", "shape": "NA", "code-info": {"name": "torch.combinations", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " 1D vector."}, {"name": "r", "is_optional": true, "type": "int", "default_value": "2", "description": " number of elements to combine"}, {"name": "with_replacement", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether to allow duplication in combination"}]}},
{"id": "torch.cross", "type": "function", "code": "torch.cross(input,other,dim=-1,out=None)", "example": "  a = torch.randn(4, 3)  a tensor([[-0.3956,  1.1455,  1.6895],         [-0.5849,  1.3672,  0.3599],         [-1.1626,  0.7180, -0.0521],         [-0.1339,  0.9902, -2.0225]])  b = torch.randn(4, 3)  b tensor([[-0.0257, -1.4725, -1.2251],         [-1.1479, -0.7005, -1.9757],         [-1.3904,  0.3726, -1.1836],         [-0.9688, -0.7153,  0.2159]])  torch.cross(a, b, dim=1) tensor([[ 1.0844, -0.5281,  0.6120],         [-2.4490, -1.5687,  1.9792],         [-0.8304, -1.3037,  0.5650],         [-1.2329,  1.9883,  1.0551]])  torch.cross(a, b) tensor([[ 1.0844, -0.5281,  0.6120],         [-2.4490, -1.5687,  1.9792],         [-0.8304, -1.3037,  0.5650],         [-1.2329,  1.9883,  1.0551]])   ", "summary": "Returns the cross product of vectors in dimension dim of input and other", "returns": null, "shape": "NA", "code-info": {"name": "torch.cross", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "other", "is_optional": false, "type": "Tensor", "description": " the second input tensor"}, {"name": "dim", "is_optional": true, "type": "int, optional", "default_value": "-1", "description": " the dimension to take the cross-product in."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.cumprod", "type": "function", "code": "torch.cumprod(input,dim,out=None,dtype=None)", "example": "  a = torch.randn(10)  a tensor([ 0.6001,  0.2069, -0.1919,  0.9792,  0.6727,  1.0062,  0.4126,         -0.2129, -0.4206,  0.1968])  torch.cumprod(a, dim=0) tensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0158, -0.0065,          0.0014, -0.0006, -0.0001])   a[5] = 0.0  torch.cumprod(a, dim=0) tensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0000, -0.0000,          0.0000, -0.0000, -0.0000])   ", "summary": "Returns the cumulative product of elements of input in the dimension dim", "returns": null, "shape": "NA", "code-info": {"name": "torch.cumprod", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "dim", "is_optional": false, "type": "int", "description": " the dimension to do the operation over"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.If specified, the input tensor is casted to dtype before the operationis performed. This is useful for preventing data type overflows. Default"}]}},
{"id": "torch.nn.Softmax2d", "type": "class", "code": "torch.nn.Softmax2d", "example": "NA", "summary": "Applies SoftMax over features to each spatial location", "returns": "a Tensor of the same dimension and shape as the input withvalues in the range [0, 1]", "shape": "", "code-info": {"name": "torch.nn.Softmax2d", "parameters": []}},
{"id": "torch.nn.LogSoftmax", "type": "class", "code": "torch.nn.LogSoftmax(dim:Optional[int]=None)", "example": "NA", "summary": "Applies the log\u2061(Softmax(x))\\log(\\text{Softmax}(x))log(Softmax(x))   function to an n-dimensional input Tensor", "returns": "a Tensor of the same dimension and shape as the input withvalues in the range [-inf, 0)", "shape": "", "code-info": {"name": "torch.nn.LogSoftmax", "parameters": [{"name": "dim", "type": "Optional[int]", "default_value": "None", "is_optional": false, "description": "A dimension along which LogSoftmax will be computed."}]}},
{"id": "torch.nn.AdaptiveLogSoftmaxWithLoss", "type": "class", "code": "torch.nn.AdaptiveLogSoftmaxWithLoss(in_features:int,n_classes:int,cutoffs:Sequence[int],div_value:float=4.0,head_bias:bool=False)", "example": "NA", "summary": "Efficient softmax approximation as described in Efficient softmax approximation for GPUs by Edouard Grave, Armand Joulin, Moustapha Ciss\u00e9, David Grangier, and Herv\u00e9 J\u00e9gou", "returns": "output is a Tensor of size N containing computed targetlog probabilities for each exampleloss is a Scalar representing the computed negativelog likelihood loss", "shape": "", "code-info": {"name": "torch.nn.AdaptiveLogSoftmaxWithLoss", "parameters": [{"name": "in_features", "type": "int", "is_optional": false, "description": "Number of features in the input tensor"}, {"name": "n_classes", "type": "int", "is_optional": false, "description": "Number of classes in the dataset"}, {"name": "cutoffs", "type": "Sequence[int]", "is_optional": false, "description": "Cutoffs used to assign targets to their buckets"}, {"name": "div_value", "type": "float", "default_value": "40", "is_optional": true, "description": "value used as an exponent to compute sizesof the clusters. Default: 4.0"}, {"name": "head_bias", "type": "bool", "default_value": "False", "is_optional": true, "description": "If True, adds a bias term to the \u2018head\u2019 of theadaptive softmax. Default: False"}]}},
{"id": "torch.cumsum", "type": "function", "code": "torch.cumsum(input,dim,out=None,dtype=None)", "example": "  a = torch.randn(10)  a tensor([-0.8286, -0.4890,  0.5155,  0.8443,  0.1865, -0.1752, -2.0595,          0.1850, -1.1571, -0.4243])  torch.cumsum(a, dim=0) tensor([-0.8286, -1.3175, -0.8020,  0.0423,  0.2289,  0.0537, -2.0058,         -1.8209, -2.9780, -3.4022])   ", "summary": "Returns the cumulative sum of elements of input in the dimension dim", "returns": null, "shape": "NA", "code-info": {"name": "torch.cumsum", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "dim", "is_optional": false, "type": "int", "description": " the dimension to do the operation over"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "None", "description": " the desired data type of returned tensor.If specified, the input tensor is casted to dtype before the operationis performed. This is useful for preventing data type overflows. Default"}]}},
{"id": "torch.diag", "type": "function", "code": "torch.diag(input,diagonal=0,out=None)", "example": " a = torch.randn(3)\n a\ntensor([ 0.5950,-0.0872, 2.3298])\n torch.diag(a)\ntensor([[ 0.5950, 0.0000, 0.0000],\n        [ 0.0000,-0.0872, 0.0000],\n        [ 0.0000, 0.0000, 2.3298]])\n torch.diag(a, 1)\ntensor([[ 0.0000, 0.5950, 0.0000, 0.0000],\n        [ 0.0000, 0.0000,-0.0872, 0.0000],\n        [ 0.0000, 0.0000, 0.0000, 2.3298],\n        [ 0.0000, 0.0000, 0.0000, 0.0000]])\n\n", "summary": " If input is a vector (1-D tensor), then returns a 2-D square tensor with the elements of input as the diagonal", "returns": null, "shape": "NA", "code-info": {"name": "torch.diag", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "diagonal", "is_optional": true, "type": "int", "default_value": "0", "description": " the diagonal to consider"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.diag_embed", "type": "function", "code": "torch.diag_embed(input,offset=0,dim1=-2,dim2=-1)", "example": "  a = torch.randn(2, 3)  torch.diag_embed(a) tensor([[[ 1.5410,  0.0000,  0.0000],          [ 0.0000, -0.2934,  0.0000],          [ 0.0000,  0.0000, -2.1788]],          [[ 0.5684,  0.0000,  0.0000],          [ 0.0000, -1.0845,  0.0000],          [ 0.0000,  0.0000, -1.3986]]])   torch.diag_embed(a, offset=1, dim1=0, dim2=2) tensor([[[ 0.0000,  1.5410,  0.0000,  0.0000],          [ 0.0000,  0.5684,  0.0000,  0.0000]],          [[ 0.0000,  0.0000, -0.2934,  0.0000],          [ 0.0000,  0.0000, -1.0845,  0.0000]],          [[ 0.0000,  0.0000,  0.0000, -2.1788],          [ 0.0000,  0.0000,  0.0000, -1.3986]],          [[ 0.0000,  0.0000,  0.0000,  0.0000],          [ 0.0000,  0.0000,  0.0000,  0.0000]]])   ", "summary": "Creates a tensor whose diagonals of certain 2D planes (specified by dim1 and dim2) are filled by input", "returns": null, "shape": "NA", "code-info": {"name": "torch.diag_embed", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor. Must be at least 1-dimensional."}, {"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": " which diagonal to consider. Default"}, {"name": "dim1", "is_optional": true, "type": "int, optional", "default_value": "-2", "description": " first dimension with respect to which totake diagonal. Default"}, {"name": "dim2", "is_optional": true, "type": "int, optional", "default_value": "-1", "description": " second dimension with respect to which totake diagonal. Default"}]}},
{"id": "torch.nn.BatchNorm1d", "type": "class", "code": "torch.nn.BatchNorm1d(num_features,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)", "example": "NA", "summary": "Applies Batch Normalization over a 2D or 3D input (a mini-batch of 1D inputs with optional additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.BatchNorm1d", "parameters": []}},
{"id": "torch.nn.BatchNorm2d", "type": "class", "code": "torch.nn.BatchNorm2d(num_features,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)", "example": "NA", "summary": "Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.BatchNorm2d", "parameters": []}},
{"id": "torch.diagflat", "type": "function", "code": "torch.diagflat(input,offset=0)", "example": " a = torch.randn(3)\n a\ntensor([-0.2956, -0.9068,  0.1695])\n torch.diagflat(a)\ntensor([[-0.2956,  0.0000,  0.0000],\n        [ 0.0000, -0.9068,  0.0000],\n        [ 0.0000,  0.0000,  0.1695]])\n torch.diagflat(a, 1)\ntensor([[ 0.0000, -0.2956,  0.0000,  0.0000],\n        [ 0.0000,  0.0000, -0.9068,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.1695],\n        [ 0.0000,  0.0000,  0.0000,  0.0000]])\n\n a = torch.randn(2, 2)\n a\ntensor([[ 0.2094, -0.3018],\n        [-0.1516,  1.9342]])\n torch.diagflat(a)\ntensor([[ 0.2094,  0.0000,  0.0000,  0.0000],\n        [ 0.0000, -0.3018,  0.0000,  0.0000],\n        [ 0.0000,  0.0000, -0.1516,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  1.9342]])\n\n", "summary": " If input is a vector (1-D tensor), then returns a 2-D square tensor with the elements of input as the diagonal", "returns": null, "shape": "NA", "code-info": {"name": "torch.diagflat", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": " the diagonal to consider. Default"}]}},
{"id": "torch.diagonal", "type": "function", "code": "torch.diagonal(input,offset=0,dim1=0,dim2=1)", "example": " a = torch.randn(3, 3)\n a\ntensor([[-1.0854,  1.1431, -0.1752],\n        [ 0.8536, -0.0905,  0.0360],\n        [ 0.6927, -0.3735, -0.4945]])\n\n\n torch.diagonal(a, 0)\ntensor([-1.0854, -0.0905, -0.4945])\n\n\n torch.diagonal(a, 1)\ntensor([ 1.1431,  0.0360])\n\n\n x = torch.randn(2, 5, 4, 2)\n torch.diagonal(x, offset=-1, dim1=1, dim2=2)\ntensor([[[-1.2631,  0.3755, -1.5977, -1.8172],\n         [-1.1065,  1.0401, -0.2235, -0.7938]],\n\n        [[-1.7325, -0.3081,  0.6166,  0.2335],\n         [ 1.0500,  0.7336, -0.3836, -1.1015]]])\n\n", "summary": "Returns a partial view of input with the its diagonal elements with respect to dim1 and dim2 appended as a dimension at the end of the shape", "returns": null, "shape": "NA", "code-info": {"name": "torch.diagonal", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor. Must be at least 2-dimensional."}, {"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": " which diagonal to consider. Default"}, {"name": "dim1", "is_optional": true, "type": "int", "default_value": "0", "description": " first dimension with respect to which totake diagonal. Default"}, {"name": "dim2", "is_optional": true, "type": "int", "default_value": "1", "description": " second dimension with respect to which totake diagonal. Default"}]}},
{"id": "torch.einsum", "type": "function", "code": "torch.einsum(equation,*operands)", "example": " x = torch.randn(5)\n y = torch.randn(4)\n torch.einsum('i,j-ij', x, y)  # outer product\ntensor([[-0.0570, -0.0286, -0.0231,  0.0197],\n        [ 1.2616,  0.6335,  0.5113, -0.4351],\n        [ 1.4452,  0.7257,  0.5857, -0.4984],\n        [-0.4647, -0.2333, -0.1883,  0.1603],\n        [-1.1130, -0.5588, -0.4510,  0.3838]])\n\n\n A = torch.randn(3,5,4)\n l = torch.randn(2,5)\n r = torch.randn(2,4)\n torch.einsum('bn,anm,bm-ba', l, A, r) # compare torch.nn.functional.bilinear\ntensor([[-0.3430, -5.2405,  0.4494],\n        [ 0.3311,  5.5201, -3.0356]])\n\n\n As = torch.randn(3,2,5)\n Bs = torch.randn(3,5,4)\n torch.einsum('bij,bjk-bik', As, Bs) # batch matrix multiplication\ntensor([[[-1.0564, -1.5904,  3.2023,  3.1271],\n         [-1.6706, -0.8097, -0.8025, -2.1183]],\n\n        [[ 4.2239,  0.3107, -0.5756, -0.2354],\n         [-1.4558, -0.3460,  1.5087, -0.8530]],\n\n        [[ 2.8153,  1.8787, -4.3839, -1.2112],\n         [ 0.3728, -2.1131,  0.0921,  0.8305]]])\n\n A = torch.randn(3, 3)\n torch.einsum('ii-i', A) # diagonal\ntensor([-0.7825,  0.8291, -0.1936])\n\n A = torch.randn(4, 3, 3)\n torch.einsum('...ii-...i', A) # batch diagonal\ntensor([[-1.0864,  0.7292,  0.0569],\n        [-0.9725, -1.0270,  0.6493],\n        [ 0.5832, -1.1716, -1.5084],\n        [ 0.4041, -1.1690,  0.8570]])\n\n A = torch.randn(2, 3, 4, 5)\n torch.einsum('...ij-...ji', A).shape # batch permute\ntorch.Size([2, 3, 5, 4])\n\n", "summary": "This function provides a way of computing multilinear expressions (i.e", "returns": null, "shape": "NA", "code-info": {"name": "torch.einsum", "parameters": [{"name": "equation", "is_optional": false, "type": "string", "description": " The equation is given in terms of lower case letters (indices to be associatedwith each dimension of the operands and result. The left hand side lists the operandsdimensions, separated by commas. There should be one index letter per tensor dimension.The right hand side follows after -&gt; and gives the indices for the output.If the -&gt; and right hand side are omitted, it implicitly defined as the alphabeticallysorted list of all indices appearing exactly once in the left hand side.The indices not apprearing in the output are summed over after multiplying the operandsentries.If an index appears several times for the same operand, a diagonal is taken.Ellipses \u2026 represent a fixed number of dimensions. If the right hand side is inferred,the ellipsis dimensions are at the beginning of the output."}, {"name": "*operands", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.BatchNorm3d", "type": "class", "code": "torch.nn.BatchNorm3d(num_features,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)", "example": "NA", "summary": "Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.BatchNorm3d", "parameters": []}},
{"id": "torch.nn.GroupNorm", "type": "class", "code": "torch.nn.GroupNorm(num_groups:int,num_channels:int,eps:float=1e-05,affine:bool=True)", "example": "NA", "summary": "Applies Group Normalization over a mini-batch of inputs as described in the paper Group Normalization  y=x\u2212E[x]Var[x]+\u03f5\u2217\u03b3+\u03b2y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta  y=Var[x]+\u03f5\u200bx\u2212E[x]\u200b\u2217\u03b3+\u03b2  The input channels are separated into num_groups groups, each containing num_channels / num_groups channels", "returns": [], "shape": "", "code-info": {"name": "torch.nn.GroupNorm", "parameters": [{"name": "num_groups", "type": "int", "is_optional": false, "description": "number of groups to separate the channels into"}, {"name": "num_channels", "type": "int", "is_optional": false, "description": "number of channels expected in input"}, {"name": "eps", "type": "float", "default_value": "1e-5", "is_optional": false, "description": "a value added to the denominator for numerical stability. Default: 1e-5"}, {"name": "affine", "type": "bool", "default_value": "True", "is_optional": false, "description": "a boolean value that when set to True, this modulehas learnable per-channel affine parameters initialized to ones (for weights)and zeros (for biases). Default: True."}]}},
{"id": "torch.nn.SyncBatchNorm", "type": "class", "code": "torch.nn.SyncBatchNorm(num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=True,track_running_stats:bool=True,process_group:Optional[Any]=None)", "example": "  # Network with nn.BatchNorm layer  module = torch.nn.Sequential(             torch.nn.Linear(20, 100),             torch.nn.BatchNorm1d(100),           ).cuda()  # creating process group (optional)  # process_ids is a list of int identifying rank ids.  process_group = torch.distributed.new_group(process_ids)  sync_bn_module = torch.nn.SyncBatchNorm.convert_sync_batchnorm(module, process_group)     ", "summary": "Applies Batch Normalization over a N-Dimensional input (a mini-batch of [N-2]D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift ", "returns": "The original module with the converted torch.nn.SyncBatchNormlayers. If the original module is a BatchNorm*D layer,a new torch.nn.SyncBatchNorm layer object will be returnedinstead.", "shape": "", "code-info": {"name": "torch.nn.SyncBatchNorm", "parameters": [{"name": "num_features", "type": "int", "is_optional": false, "description": "CCC from an expected input of size(N,C,+)(N, C, +)(N,C,+)"}, {"name": "eps", "type": "float", "default_value": "1e-5", "is_optional": false, "description": "a value added to the denominator for numerical stability.Default: 1e-5"}, {"name": "momentum", "type": "float", "default_value": "01", "is_optional": false, "description": "the value used for the running_mean and running_varcomputation. Can be set to None for cumulative moving average(i.e. simple average). Default: 0.1"}, {"name": "affine", "type": "bool", "default_value": "True", "is_optional": false, "description": "a boolean value that when set to True, this module haslearnable affine parameters. Default: True"}, {"name": "track_running_stats", "type": "bool", "default_value": "True", "is_optional": false, "description": "a boolean value that when set to True, thismodule tracks the running mean and variance, and when set to False,this module does not track such statistics and uses batch statistics insteadin both training and eval modes if the running mean and variance are None. Default: True"}, {"name": "process_group", "type": "Optional[Any]", "default_value": "None", "is_optional": true, "description": "process group to scope synchronization,default is the whole world"}]}},
{"id": "torch.flatten", "type": "function", "code": "torch.flatten(input,start_dim=0,end_dim=-1)", "example": "  t = torch.tensor([[[1, 2],                        [3, 4]],                       [[5, 6],                        [7, 8]]])  torch.flatten(t) tensor([1, 2, 3, 4, 5, 6, 7, 8])  torch.flatten(t, start_dim=1) tensor([[1, 2, 3, 4],         [5, 6, 7, 8]])   ", "summary": "Flattens a contiguous range of dims in a tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.flatten", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "start_dim", "is_optional": true, "type": "int", "default_value": "0", "description": " the first dim to flatten"}, {"name": "end_dim", "is_optional": true, "type": "int", "default_value": "-1", "description": " the last dim to flatten"}]}},
{"id": "torch.flip", "type": "function", "code": "torch.flip(input,dims)", "example": "  x = torch.arange(8).view(2, 2, 2)  x tensor([[[ 0,  1],          [ 2,  3]],          [[ 4,  5],          [ 6,  7]]])  torch.flip(x, [0, 1]) tensor([[[ 6,  7],          [ 4,  5]],          [[ 2,  3],          [ 0,  1]]])   ", "summary": "Reverse the order of a n-D tensor along given axis in dims", "returns": null, "shape": "NA", "code-info": {"name": "torch.flip", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "dims", "is_optional": false, "type": "a list or tuple", "description": " axis to flip on"}]}},
{"id": "torch.rot90", "type": "function", "code": "torch.rot90(input,k,dims)", "example": "  x = torch.arange(4).view(2, 2)  x tensor([[0, 1],         [2, 3]])  torch.rot90(x, 1, [0, 1]) tensor([[1, 3],         [0, 2]])   x = torch.arange(8).view(2, 2, 2)  x tensor([[[0, 1],          [2, 3]],          [[4, 5],          [6, 7]]])  torch.rot90(x, 1, [1, 2]) tensor([[[1, 3],          [0, 2]],          [[5, 7],          [4, 6]]])   ", "summary": "Rotate a n-D tensor by 90 degrees in the plane specified by dims axis", "returns": null, "shape": "NA", "code-info": {"name": "torch.rot90", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "k", "is_optional": false, "type": "int", "description": " number of times to rotate"}, {"name": "dims", "is_optional": false, "type": "a list or tuple", "description": " axis to rotate"}]}},
{"id": "torch.histc", "type": "function", "code": "torch.histc(input,bins=100,min=0,max=0,out=None)", "example": "  torch.histc(torch.tensor([1., 2, 1]), bins=4, min=0, max=3) tensor([ 0.,  2.,  1.,  0.])   ", "summary": "Computes the histogram of a tensor", "returns": "Histogram represented as a tensor", "shape": "NA", "code-info": {"name": "torch.histc", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "bins", "is_optional": true, "type": "int", "default_value": "100", "description": " number of histogram bins"}, {"name": "min", "is_optional": true, "type": "int", "default_value": "0", "description": " lower end of the range (inclusive"}, {"name": "max", "is_optional": true, "type": "int", "default_value": "0", "description": " upper end of the range (inclusive"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.meshgrid", "type": "function", "code": "torch.meshgrid(*tensors,**kwargs)", "example": "  x = torch.tensor([1, 2, 3])  y = torch.tensor([4, 5, 6])  grid_x, grid_y = torch.meshgrid(x, y)  grid_x tensor([[1, 1, 1],         [2, 2, 2],         [3, 3, 3]])  grid_y tensor([[4, 5, 6],         [4, 5, 6],         [4, 5, 6]])    ", "summary": "Take NNN   tensors, each of which can be either scalar or 1-dimensional vector, and create NNN   N-dimensional grids, where the iii   th grid is defined by expanding the iii   th input over dimensions defined by other inputs", "returns": "seq (sequence of Tensors): If the input has kkk tensors of size(N1,),(N2,),\u2026,(Nk,)(N_1,), (N_2,), \\ldots , (N_k,)(N1\u200b,),(N2\u200b,),\u2026,(Nk\u200b,), then the output would also have kkk tensors,where all tensors are of size (N1,N2,\u2026,Nk)(N_1, N_2, \\ldots , N_k)(N1\u200b,N2\u200b,\u2026,Nk\u200b).", "shape": "NA", "code-info": {"name": "torch.meshgrid", "parameters": [{"name": "*tensors", "is_optional": false, "type": "others", "description": ""}, {"name": "**kwargs", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.renorm", "type": "function", "code": "torch.renorm(input,p,dim,maxnorm,out=None)", "example": "  x = torch.ones(3, 3)  x[1].fill_(2) tensor([ 2.,  2.,  2.])  x[2].fill_(3) tensor([ 3.,  3.,  3.])  x tensor([[ 1.,  1.,  1.],         [ 2.,  2.,  2.],         [ 3.,  3.,  3.]])  torch.renorm(x, 1, 0, 5) tensor([[ 1.0000,  1.0000,  1.0000],         [ 1.6667,  1.6667,  1.6667],         [ 1.6667,  1.6667,  1.6667]])   ", "summary": "Returns a tensor where each sub-tensor of input along dimension dim is normalized such that the p-norm of the sub-tensor is lower than the value maxnorm  Note If the norm of a row is lower than maxnorm, the row is unchanged   Parameters  input (Tensor) \u2013 the input tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.renorm", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "p", "is_optional": false, "type": "Tensor", "description": " the power for the norm computation"}, {"name": "dim", "is_optional": false, "type": "int", "description": " the dimension to slice over to get the sub-tensors"}, {"name": "maxnorm", "is_optional": false, "type": "float", "description": " the maximum norm to keep each sub-tensor under"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.nn.InstanceNorm1d", "type": "class", "code": "torch.nn.InstanceNorm1d(num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=False,track_running_stats:bool=False)", "example": "NA", "summary": "Applies Instance Normalization over a 3D input (a mini-batch of 1D inputs with optional additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization", "returns": [], "shape": "", "code-info": {"name": "torch.nn.InstanceNorm1d", "parameters": [{"name": "num_features", "type": "int", "is_optional": false, "description": "CCC from an expected input of size(N,C,L)(N, C, L)(N,C,L) or LLL from input of size (N,L)(N, L)(N,L)"}, {"name": "eps", "type": "float", "default_value": "1e-5", "is_optional": false, "description": "a value added to the denominator for numerical stability. Default: 1e-5"}, {"name": "momentum", "type": "float", "default_value": "01", "is_optional": false, "description": "the value used for the running_mean and running_var computation. Default: 0.1"}, {"name": "affine", "type": "bool", "default_value": "False", "is_optional": false, "description": "a boolean value that when set to True, this module haslearnable affine parameters, initialized the same way as done for batch normalization.Default: False."}, {"name": "track_running_stats", "type": "bool", "default_value": "False", "is_optional": false, "description": "a boolean value that when set to True, thismodule tracks the running mean and variance, and when set to False,this module does not track such statistics and always uses batchstatistics in both training and eval modes. Default: False"}]}},
{"id": "torch.nn.InstanceNorm2d", "type": "class", "code": "torch.nn.InstanceNorm2d(num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=False,track_running_stats:bool=False)", "example": "NA", "summary": "Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization", "returns": [], "shape": "", "code-info": {"name": "torch.nn.InstanceNorm2d", "parameters": [{"name": "num_features", "type": "int", "is_optional": false, "description": "CCC from an expected input of size(N,C,H,W)(N, C, H, W)(N,C,H,W)"}, {"name": "eps", "type": "float", "default_value": "1e-5", "is_optional": false, "description": "a value added to the denominator for numerical stability. Default: 1e-5"}, {"name": "momentum", "type": "float", "default_value": "01", "is_optional": false, "description": "the value used for the running_mean and running_var computation. Default: 0.1"}, {"name": "affine", "type": "bool", "default_value": "False", "is_optional": false, "description": "a boolean value that when set to True, this module haslearnable affine parameters, initialized the same way as done for batch normalization.Default: False."}, {"name": "track_running_stats", "type": "bool", "default_value": "False", "is_optional": false, "description": "a boolean value that when set to True, thismodule tracks the running mean and variance, and when set to False,this module does not track such statistics and always uses batchstatistics in both training and eval modes. Default: False"}]}},
{"id": "torch.repeat_interleave", "type": "function", "code": "torch.repeat_interleave()", "example": "  x = torch.tensor([1, 2, 3])  x.repeat_interleave(2) tensor([1, 1, 2, 2, 3, 3])  y = torch.tensor([[1, 2], [3, 4]])  torch.repeat_interleave(y, 2) tensor([1, 1, 2, 2, 3, 3, 4, 4])  torch.repeat_interleave(y, 3, dim=1) tensor([[1, 1, 1, 2, 2, 2],         [3, 3, 3, 4, 4, 4]])  torch.repeat_interleave(y, torch.tensor([1, 2]), dim=0) tensor([[1, 2],         [3, 4],         [3, 4]])     torch.repeat_interleave(repeats) \u2192 Tensor   If the repeats is tensor([n1, n2, n3, \u2026]), then the output will be tensor([0, 0, \u2026, 1, 1, \u2026, 2, 2, \u2026, \u2026]) where 0 appears n1 times, 1 appears n2 times, 2 appears n3 times, etc. ", "summary": "  torch.repeat_interleave(input, repeats, dim=None) \u2192 Tensor   Repeat elements of a tensor", "returns": "Repeated tensor which has the same shape as input, except along thegiven axis.", "shape": "NA", "code-info": {"name": "torch.repeat_interleave", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(input,repeats,dim=None)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "repeats", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "None", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(repeats)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "repeats", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.roll", "type": "function", "code": "torch.roll(input,shifts,dims=None)", "example": "  x = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8]).view(4, 2)  x tensor([[1, 2],         [3, 4],         [5, 6],         [7, 8]])  torch.roll(x, 1, 0) tensor([[7, 8],         [1, 2],         [3, 4],         [5, 6]])  torch.roll(x, -1, 0) tensor([[3, 4],         [5, 6],         [7, 8],         [1, 2]])  torch.roll(x, shifts=(2, 1), dims=(0, 1)) tensor([[6, 5],         [8, 7],         [2, 1],         [4, 3]])   ", "summary": "Roll the tensor along the given dimension(s)", "returns": null, "shape": "NA", "code-info": {"name": "torch.roll", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "shifts", "is_optional": false, "type": "int or tuple of ints", "description": " The number of places by which the elementsof the tensor are shifted. If shifts is a tuple, dims must be a tuple ofthe same size, and each dimension will be rolled by the correspondingvalue"}, {"name": "dims", "is_optional": true, "type": "int or tuple of ints", "default_value": "None", "description": " Axis along which to roll"}]}},
{"id": "torch.tensordot", "type": "function", "code": "torch.tensordot(a,b,dims=2)", "example": " a = torch.arange(60.).reshape(3, 4, 5)\n b = torch.arange(24.).reshape(4, 3, 2)\n torch.tensordot(a, b, dims=([1, 0], [0, 1]))\ntensor([[4400., 4730.],\n        [4532., 4874.],\n        [4664., 5018.],\n        [4796., 5162.],\n        [4928., 5306.]])\n\n a = torch.randn(3, 4, 5, device='cuda')\n b = torch.randn(4, 5, 6, device='cuda')\n c = torch.tensordot(a, b, dims=2).cpu()\ntensor([[ 8.3504, -2.5436,  6.2922,  2.7556, -1.0732,  3.2741],\n        [ 3.3161,  0.0704,  5.0187, -0.4079, -4.3126,  4.8744],\n        [ 0.8223,  3.9445,  3.2168, -0.2400,  3.4117,  1.7780]])\n\n", "summary": "Returns a contraction of a and b over multiple dimensions", "returns": null, "shape": "NA", "code-info": {"name": "torch.tensordot", "parameters": [{"name": "a", "is_optional": false, "type": "Tensor", "description": " Left tensor to contract"}, {"name": "b", "is_optional": false, "type": "Tensor", "description": " Right tensor to contract"}, {"name": "dims", "is_optional": true, "type": "int", "default_value": "2", "description": " number of dimensions tocontract or explicit lists of dimensions for a andb respectively"}]}},
{"id": "torch.nn.InstanceNorm3d", "type": "class", "code": "torch.nn.InstanceNorm3d(num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=False,track_running_stats:bool=False)", "example": "NA", "summary": "Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization", "returns": [], "shape": "", "code-info": {"name": "torch.nn.InstanceNorm3d", "parameters": [{"name": "num_features", "type": "int", "is_optional": false, "description": "CCC from an expected input of size(N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W)"}, {"name": "eps", "type": "float", "default_value": "1e-5", "is_optional": false, "description": "a value added to the denominator for numerical stability. Default: 1e-5"}, {"name": "momentum", "type": "float", "default_value": "01", "is_optional": false, "description": "the value used for the running_mean and running_var computation. Default: 0.1"}, {"name": "affine", "type": "bool", "default_value": "False", "is_optional": false, "description": "a boolean value that when set to True, this module haslearnable affine parameters, initialized the same way as done for batch normalization.Default: False."}, {"name": "track_running_stats", "type": "bool", "default_value": "False", "is_optional": false, "description": "a boolean value that when set to True, thismodule tracks the running mean and variance, and when set to False,this module does not track such statistics and always uses batchstatistics in both training and eval modes. Default: False"}]}},
{"id": "torch.nn.LayerNorm", "type": "class", "code": "torch.nn.LayerNorm(normalized_shape:Union[int,List[int],torch.Size],eps:float=1e-05,elementwise_affine:bool=True)", "example": "NA", "summary": "Applies Layer Normalization over a mini-batch of inputs as described in the paper Layer Normalization  y=x\u2212E[x]Var[x]+\u03f5\u2217\u03b3+\u03b2y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta  y=Var[x]+\u03f5\u200bx\u2212E[x]\u200b\u2217\u03b3+\u03b2  The mean and standard-deviation are calculated separately over the last certain number dimensions which have to be of the shape specified by normalized_shape", "returns": [], "shape": "", "code-info": {"name": "torch.nn.LayerNorm", "parameters": [{"name": "normalized_shape", "type": "Union[int,List[int],torch.Size]", "is_optional": false, "description": "input shape from an expected inputof size[\u2217\u00d7normalized_shape[0]\u00d7normalized_shape[1]\u00d7\u2026\u00d7normalized_shape[\u22121]][* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]    \\times \\ldots \\times \\text{normalized\\_shape}[-1]][\u2217\u00d7normalized_shape[0]\u00d7normalized_shape[1]\u00d7\u2026\u00d7normalized_shape[\u22121]]If a single integer is used, it is treated as a singleton list, and this module willnormalize over the last dimension which is expected to be of that specific size."}, {"name": "eps", "type": "float", "default_value": "1e-5", "is_optional": false, "description": "a value added to the denominator for numerical stability. Default: 1e-5"}, {"name": "elementwise_affine", "type": "bool", "default_value": "True", "is_optional": false, "description": "a boolean value that when set to True, this modulehas learnable per-element affine parameters initialized to ones (for weights)and zeros (for biases). Default: True."}]}},
{"id": "torch.trace", "type": "function", "code": "torch.trace(input)", "example": "  x = torch.arange(1., 10.).view(3, 3)  x tensor([[ 1.,  2.,  3.],         [ 4.,  5.,  6.],         [ 7.,  8.,  9.]])  torch.trace(x) tensor(15.)   ", "summary": "Returns the sum of the elements of the diagonal of the input 2-D matrix", "returns": null, "shape": "NA", "code-info": {"name": "torch.trace", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.tril", "type": "function", "code": "torch.tril(input,diagonal=0,out=None)", "example": "  a = torch.randn(3, 3)  a tensor([[-1.0813, -0.8619,  0.7105],         [ 0.0935,  0.1380,  2.2112],         [-0.3409, -0.9828,  0.0289]])  torch.tril(a) tensor([[-1.0813,  0.0000,  0.0000],         [ 0.0935,  0.1380,  0.0000],         [-0.3409, -0.9828,  0.0289]])   b = torch.randn(4, 6)  b tensor([[ 1.2219,  0.5653, -0.2521, -0.2345,  1.2544,  0.3461],         [ 0.4785, -0.4477,  0.6049,  0.6368,  0.8775,  0.7145],         [ 1.1502,  3.2716, -1.1243, -0.5413,  0.3615,  0.6864],         [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024,  0.0978]])  torch.tril(b, diagonal=1) tensor([[ 1.2219,  0.5653,  0.0000,  0.0000,  0.0000,  0.0000],         [ 0.4785, -0.4477,  0.6049,  0.0000,  0.0000,  0.0000],         [ 1.1502,  3.2716, -1.1243, -0.5413,  0.0000,  0.0000],         [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024,  0.0000]])  torch.tril(b, diagonal=-1) tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],         [ 0.4785,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],         [ 1.1502,  3.2716,  0.0000,  0.0000,  0.0000,  0.0000],         [-0.0614, -0.7344, -1.3164,  0.0000,  0.0000,  0.0000]])   ", "summary": "Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices input, the other elements of the result tensor out are set to 0", "returns": null, "shape": "NA", "code-info": {"name": "torch.tril", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "diagonal", "is_optional": true, "type": "int", "default_value": "0", "description": " the diagonal to consider"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.tril_indices", "type": "function", "code": "torch.tril_indices(row,col,offset=0,dtype=torch.long,device='cpu',layout=torch.strided)", "example": ": a = torch.tril_indices(3, 3)  a tensor([[0, 1, 1, 2, 2, 2],         [0, 0, 1, 0, 1, 2]])    a = torch.tril_indices(4, 3, -1)  a tensor([[1, 2, 2, 3, 3, 3],         [0, 0, 1, 0, 1, 2]])    a = torch.tril_indices(4, 3, 1)  a tensor([[0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],         [0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2]])     ", "summary": "Returns the indices of the lower triangular part of a row-by- col matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates", "returns": null, "shape": "NA", "code-info": {"name": "torch.tril_indices", "parameters": [{"name": "row", "is_optional": false, "type": "int", "description": " number of rows in the 2-D matrix."}, {"name": "col", "is_optional": false, "type": "int", "description": " number of columns in the 2-D matrix."}, {"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": " diagonal offset from the main diagonal.Default"}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "torch.long", "description": " the desired data type of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "string", "default_value": "'cpu'", "description": " the desired device of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " currently only support torch.strided."}]}},
{"id": "torch.nn.LocalResponseNorm", "type": "class", "code": "torch.nn.LocalResponseNorm(size:int,alpha:float=0.0001,beta:float=0.75,k:float=1.0)", "example": "NA", "summary": "Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension", "returns": [], "shape": "", "code-info": {"name": "torch.nn.LocalResponseNorm", "parameters": [{"name": "size", "type": "int", "is_optional": false, "description": "amount of neighbouring channels used for normalization"}, {"name": "alpha", "type": "float", "default_value": "00001", "is_optional": false, "description": "multiplicative factor. Default: 0.0001"}, {"name": "beta", "type": "float", "default_value": "075", "is_optional": false, "description": "exponent. Default: 0.75"}, {"name": "k", "type": "float", "default_value": "1", "is_optional": false, "description": "additive factor. Default: 1"}]}},
{"id": "torch.nn.RNNBase", "type": "class", "code": "torch.nn.RNNBase(mode:str,input_size:int,hidden_size:int,num_layers:int=1,bias:bool=True,batch_first:bool=False,dropout:float=0.0,bidirectional:bool=False)", "example": "NA", "summary": "  flatten_parameters() \u2192 None  Resets parameter data pointer so that they can use faster code paths", "returns": [], "shape": "", "code-info": {"name": "torch.nn.RNNBase", "parameters": [{"name": "mode", "type": "str", "is_optional": false, "description": ""}, {"name": "input_size", "type": "int", "is_optional": false, "description": ""}, {"name": "hidden_size", "type": "int", "is_optional": false, "description": ""}, {"name": "num_layers", "type": "int", "default_value": "1", "is_optional": false, "description": ""}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": false, "description": ""}, {"name": "batch_first", "type": "bool", "default_value": "False", "is_optional": false, "description": ""}, {"name": "dropout", "type": "float", "default_value": "0.0", "is_optional": false, "description": ""}, {"name": "bidirectional", "type": "bool", "default_value": "False", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.RNN", "type": "class", "code": "torch.nn.RNN(*args,**kwargs)", "example": "NA", "summary": "Applies a multi-layer Elman RNN with tanh\u2061\\tanhtanh   or ReLU\\text{ReLU}ReLU   non-linearity to an input sequence", "returns": [], "shape": "\ninput of shape (seq_len, batch, input_size): tensor containing the features\nof the input sequence. The input can also be a packed variable length\nsequence. See torch.nn.utils.rnn.pack_padded_sequence()\nor torch.nn.utils.rnn.pack_sequence()\nfor details.\nh_0 of shape (num_layers * num_directions, batch, hidden_size): tensor\ncontaining the initial hidden state for each element in the batch.\nDefaults to zero if not provided. If the RNN is bidirectional,\nnum_directions should be 2, else it should be 1.\n\n", "code-info": {"name": "torch.nn.RNN", "parameters": []}},
{"id": "torch.triu", "type": "function", "code": "torch.triu(input,diagonal=0,out=None)", "example": "  a = torch.randn(3, 3)  a tensor([[ 0.2309,  0.5207,  2.0049],         [ 0.2072, -1.0680,  0.6602],         [ 0.3480, -0.5211, -0.4573]])  torch.triu(a) tensor([[ 0.2309,  0.5207,  2.0049],         [ 0.0000, -1.0680,  0.6602],         [ 0.0000,  0.0000, -0.4573]])  torch.triu(a, diagonal=1) tensor([[ 0.0000,  0.5207,  2.0049],         [ 0.0000,  0.0000,  0.6602],         [ 0.0000,  0.0000,  0.0000]])  torch.triu(a, diagonal=-1) tensor([[ 0.2309,  0.5207,  2.0049],         [ 0.2072, -1.0680,  0.6602],         [ 0.0000, -0.5211, -0.4573]])   b = torch.randn(4, 6)  b tensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],         [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],         [ 0.4333,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],         [-0.9888,  1.0679, -1.3337, -1.6556,  0.4798,  0.2830]])  torch.triu(b, diagonal=1) tensor([[ 0.0000, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],         [ 0.0000,  0.0000, -1.2919,  1.3378, -0.1768, -1.0857],         [ 0.0000,  0.0000,  0.0000, -1.0432,  0.9348, -0.4410],         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4798,  0.2830]])  torch.triu(b, diagonal=-1) tensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],         [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],         [ 0.0000,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],         [ 0.0000,  0.0000, -1.3337, -1.6556,  0.4798,  0.2830]])   ", "summary": "Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices input, the other elements of the result tensor out are set to 0", "returns": null, "shape": "NA", "code-info": {"name": "torch.triu", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "diagonal", "is_optional": true, "type": "int", "default_value": "0", "description": " the diagonal to consider"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.triu_indices", "type": "function", "code": "torch.triu_indices(row,col,offset=0,dtype=torch.long,device='cpu',layout=torch.strided)", "example": ": a = torch.triu_indices(3, 3)  a tensor([[0, 0, 0, 1, 1, 2],         [0, 1, 2, 1, 2, 2]])    a = torch.triu_indices(4, 3, -1)  a tensor([[0, 0, 0, 1, 1, 1, 2, 2, 3],         [0, 1, 2, 0, 1, 2, 1, 2, 2]])    a = torch.triu_indices(4, 3, 1)  a tensor([[0, 0, 1],         [1, 2, 2]])     ", "summary": "Returns the indices of the upper triangular part of a row by col matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates", "returns": null, "shape": "NA", "code-info": {"name": "torch.triu_indices", "parameters": [{"name": "row", "is_optional": false, "type": "int", "description": " number of rows in the 2-D matrix."}, {"name": "col", "is_optional": false, "type": "int", "description": " number of columns in the 2-D matrix."}, {"name": "offset", "is_optional": true, "type": "int", "default_value": "0", "description": " diagonal offset from the main diagonal.Default"}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "torch.long", "description": " the desired data type of returned tensor.Default"}, {"name": "device", "is_optional": true, "type": "string", "default_value": "'cpu'", "description": " the desired device of returned tensor.Default"}, {"name": "layout", "is_optional": true, "type": "torch.layout, optional", "default_value": "torch.strided", "description": " currently only support torch.strided."}]}},
{"id": "torch.nn.LSTM", "type": "class", "code": "torch.nn.LSTM(*args,**kwargs)", "example": "NA", "summary": "Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence", "returns": [], "shape": "", "code-info": {"name": "torch.nn.LSTM", "parameters": []}},
{"id": "torch.addbmm", "type": "function", "code": "torch.addbmm(beta=1,input,alpha=1,batch1,batch2,out=None)", "example": "  M = torch.randn(3, 5)  batch1 = torch.randn(10, 3, 4)  batch2 = torch.randn(10, 4, 5)  torch.addbmm(M, batch1, batch2) tensor([[  6.6311,   0.0503,   6.9768, -12.0362,  -2.1653],         [ -4.8185,  -1.4255,  -6.6760,   8.9453,   2.5743],         [ -3.8202,   4.3691,   1.0943,  -1.1109,   5.4730]])   ", "summary": "Performs a batch matrix-matrix product of matrices stored in batch1 and batch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension)", "returns": null, "shape": "NA", "code-info": {"name": "torch.addbmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for input (\u03b2\\beta\u03b2"}, {"name": "input", "is_optional": false, "type": "Number, optional", "description": " matrix to be added"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for batch1 @ batch2 (\u03b1\\alpha\u03b1"}, {"name": "batch1", "is_optional": false, "type": "Number, optional", "description": " the first batch of matrices to be multiplied"}, {"name": "batch2", "is_optional": false, "type": "Number, optional", "description": " the second batch of matrices to be multiplied"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.addmm", "type": "function", "code": "torch.addmm(beta=1,input,alpha=1,mat1,mat2,out=None)", "example": "  M = torch.randn(2, 3)  mat1 = torch.randn(2, 3)  mat2 = torch.randn(3, 3)  torch.addmm(M, mat1, mat2) tensor([[-4.8716,  1.4671, -1.3746],         [ 0.7573, -3.9555, -2.8681]])   ", "summary": "Performs a matrix multiplication of the matrices mat1 and mat2", "returns": null, "shape": "NA", "code-info": {"name": "torch.addmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for input (\u03b2\\beta\u03b2"}, {"name": "input", "is_optional": false, "type": "Number, optional", "description": " matrix to be added"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for mat1@mat2mat1 @ mat2mat1@mat2 (\u03b1\\alpha\u03b1"}, {"name": "mat1", "is_optional": false, "type": "Number, optional", "description": " the first matrix to be multiplied"}, {"name": "mat2", "is_optional": false, "type": "Number, optional", "description": " the second matrix to be multiplied"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.addmv", "type": "function", "code": "torch.addmv(beta=1,input,alpha=1,mat,vec,out=None)", "example": "  M = torch.randn(2)  mat = torch.randn(2, 3)  vec = torch.randn(3)  torch.addmv(M, mat, vec) tensor([-0.3768, -5.5565])   ", "summary": "Performs a matrix-vector product of the matrix mat and the vector vec", "returns": null, "shape": "NA", "code-info": {"name": "torch.addmv", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for input (\u03b2\\beta\u03b2"}, {"name": "input", "is_optional": false, "type": "Number, optional", "description": " vector to be added"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for mat@vecmat @ vecmat@vec (\u03b1\\alpha\u03b1"}, {"name": "mat", "is_optional": false, "type": "Number, optional", "description": " matrix to be multiplied"}, {"name": "vec", "is_optional": false, "type": "Tensor", "description": " vector to be multiplied"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.addr", "type": "function", "code": "torch.addr(beta=1,input,alpha=1,vec1,vec2,out=None)", "example": "  vec1 = torch.arange(1., 4.)  vec2 = torch.arange(1., 3.)  M = torch.zeros(3, 2)  torch.addr(M, vec1, vec2) tensor([[ 1.,  2.],         [ 2.,  4.],         [ 3.,  6.]])   ", "summary": "Performs the outer-product of vectors vec1 and vec2 and adds it to the matrix input", "returns": null, "shape": "NA", "code-info": {"name": "torch.addr", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for input (\u03b2\\beta\u03b2"}, {"name": "input", "is_optional": false, "type": "Number, optional", "description": " matrix to be added"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for vec1\u2297vec2\\text{vec1} \\otimes \\text{vec2}vec1\u2297vec2 (\u03b1\\alpha\u03b1"}, {"name": "vec1", "is_optional": false, "type": "Number, optional", "description": " the first vector of the outer product"}, {"name": "vec2", "is_optional": false, "type": "Number, optional", "description": " the second vector of the outer product"}, {"name": "out", "is_optional": true, "type": "Tensor", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.nn.GRU", "type": "class", "code": "torch.nn.GRU(input_size:int, hidden_size:int, num_layers:int)", "example": "NA", "summary": "Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence", "returns": [], "shape": "\ninput of shape (seq_len, batch, input_size): tensor containing the features\nof the input sequence. The input can also be a packed variable length\nsequence. See torch.nn.utils.rnn.pack_padded_sequence()\nfor details.\nh_0 of shape (num_layers * num_directions, batch, hidden_size): tensor\ncontaining the initial hidden state for each element in the batch.\nDefaults to zero if not provided. If the RNN is bidirectional,\nnum_directions should be 2, else it should be 1.\n\n", "code-info": {"name": "torch.nn.GRU", "parameters": [{"name": "input_size", "type": "int", "is_optional": false, "description": "the number of expected features in the input x"}, {"name": "hidden_size", "type": "int", "is_optional": false, "description": "the number of features in the hidden state h"}, {"name": "num_layers", "type": "int", "is_optional": true, "description": "number of recurrent layers. E.g., setting num_layers=2 would mean stacking two GRUs together to form a stacked GRU, with the second GRU taking in outputs of the first GRU and computing the final results. Default: 1"}]}}, {"id": "torch.baddbmm", "type": "function", "code": "torch.baddbmm(beta=1,input,alpha=1,batch1,batch2,out=None)", "example": "  M = torch.randn(10, 3, 5)  batch1 = torch.randn(10, 3, 4)  batch2 = torch.randn(10, 4, 5)  torch.baddbmm(M, batch1, batch2).size() torch.Size([10, 3, 5])   ", "summary": "Performs a batch matrix-matrix product of matrices in batch1 and batch2", "returns": null, "shape": "NA", "code-info": {"name": "torch.baddbmm", "parameters": [{"name": "beta", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for input (\u03b2\\beta\u03b2"}, {"name": "input", "is_optional": false, "type": "Number, optional", "description": " the tensor to be added"}, {"name": "alpha", "is_optional": true, "type": "int", "default_value": "1", "description": " multiplier for batch1@batch2\\text{batch1} \\mathbin{@} \\text{batch2}batch1@batch2 (\u03b1\\alpha\u03b1"}, {"name": "batch1", "is_optional": false, "type": "Number, optional", "description": " the first batch of matrices to be multiplied"}, {"name": "batch2", "is_optional": false, "type": "Number, optional", "description": " the second batch of matrices to be multiplied"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.bmm", "type": "function", "code": "torch.bmm(input,mat2,out=None)", "example": "  input = torch.randn(10, 3, 4)  mat2 = torch.randn(10, 4, 5)  res = torch.bmm(input, mat2)  res.size() torch.Size([10, 3, 5])   ", "summary": "Performs a batch matrix-matrix product of matrices stored in input and mat2", "returns": null, "shape": "NA", "code-info": {"name": "torch.bmm", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the first batch of matrices to be multiplied"}, {"name": "mat2", "is_optional": false, "type": "Tensor", "description": " the second batch of matrices to be multiplied"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.chain_matmul", "type": "function", "code": "torch.chain_matmul(*matrices)", "example": "  a = torch.randn(3, 4)  b = torch.randn(4, 5)  c = torch.randn(5, 6)  d = torch.randn(6, 7)  torch.chain_matmul(a, b, c, d) tensor([[ -2.3375,  -3.9790,  -4.1119,  -6.6577,   9.5609, -11.5095,  -3.2614],         [ 21.4038,   3.3378,  -8.4982,  -5.2457, -10.2561,  -2.4684,   2.7163],         [ -0.9647,  -5.8917,  -2.3213,  -5.2284,  12.8615, -12.2816,  -2.5095]])   ", "summary": "Returns the matrix product of the NNN   2-D tensors", "returns": "if the ithi^{th}ith tensor was of dimensions pi\u00d7pi+1p_{i} \\times p_{i + 1}pi\u200b\u00d7pi+1\u200b, then the productwould be of dimensions p1\u00d7pN+1p_{1} \\times p_{N + 1}p1\u200b\u00d7pN+1\u200b.", "shape": "NA", "code-info": {"name": "torch.chain_matmul", "parameters": [{"name": "*matrices", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.nn.RNNCell", "type": "class", "code": "torch.nn.RNNCell(input_size:int,hidden_size:int,bias:bool=True,nonlinearity:str='tanh')", "example": "NA", "summary": "An Elman RNN cell with tanh or ReLU non-linearity", "returns": [], "shape": "", "code-info": {"name": "torch.nn.RNNCell", "parameters": [{"name": "input_size", "type": "int", "is_optional": false, "description": "The number of expected features in the input x"}, {"name": "hidden_size", "type": "int", "is_optional": false, "description": "The number of features in the hidden state h"}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": false, "description": "If False, then the layer does not use bias weights b_ih and b_hh.Default: True"}, {"name": "nonlinearity", "type": "str", "default_value": "'tanh'", "is_optional": false, "description": "The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'"}]}},
{"id": "torch.nn.LSTMCell", "type": "class", "code": "torch.nn.LSTMCell(input_size:int,hidden_size:int,bias:bool=True)", "example": "NA", "summary": "A long short-term memory (LSTM) cell", "returns": [], "shape": "", "code-info": {"name": "torch.nn.LSTMCell", "parameters": [{"name": "input_size", "type": "int", "is_optional": false, "description": "The number of expected features in the input x"}, {"name": "hidden_size", "type": "int", "is_optional": false, "description": "The number of features in the hidden state h"}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": false, "description": "If False, then the layer does not use bias weights b_ih andb_hh. Default: True"}]}},
{"id": "torch.cholesky", "type": "function", "code": "torch.cholesky(input,upper=False,out=None)", "example": "  a = torch.randn(3, 3)  a = torch.mm(a, a.t()) # make symmetric positive-definite  l = torch.cholesky(a)  a tensor([[ 2.4112, -0.7486,  1.4551],         [-0.7486,  1.3544,  0.1294],         [ 1.4551,  0.1294,  1.6724]])  l tensor([[ 1.5528,  0.0000,  0.0000],         [-0.4821,  1.0592,  0.0000],         [ 0.9371,  0.5487,  0.7023]])  torch.mm(l, l.t()) tensor([[ 2.4112, -0.7486,  1.4551],         [-0.7486,  1.3544,  0.1294],         [ 1.4551,  0.1294,  1.6724]])  a = torch.randn(3, 2, 2)  a = torch.matmul(a, a.transpose(-1, -2)) + 1e-03 # make symmetric positive-definite  l = torch.cholesky(a)  z = torch.matmul(l, l.transpose(-1, -2))  torch.max(torch.abs(z - a)) # Max non-zero tensor(2.3842e-07)   ", "summary": "Computes the Cholesky decomposition of a symmetric positive-definite matrix AAA   or for batches of symmetric positive-definite matrices", "returns": null, "shape": "NA", "code-info": {"name": "torch.cholesky", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor AAA of size (\u2217,n,n(*, n, n(\u2217,n,n where * is zero or morebatch dimensions consisting of symmetric positive-definite matrices."}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": " flag that indicates whether to return aupper or lower triangular matrix. Default"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output matrix"}]}},
{"id": "torch.cholesky_inverse", "type": "function", "code": "torch.cholesky_inverse(input,upper=False,out=None)", "example": "  a = torch.randn(3, 3)  a = torch.mm(a, a.t()) + 1e-05 * torch.eye(3) # make symmetric positive definite  u = torch.cholesky(a)  a tensor([[  0.9935,  -0.6353,   1.5806],         [ -0.6353,   0.8769,  -1.7183],         [  1.5806,  -1.7183,  10.6618]])  torch.cholesky_inverse(u) tensor([[ 1.9314,  1.2251, -0.0889],         [ 1.2251,  2.4439,  0.2122],         [-0.0889,  0.2122,  0.1412]])  a.inverse() tensor([[ 1.9314,  1.2251, -0.0889],         [ 1.2251,  2.4439,  0.2122],         [-0.0889,  0.2122,  0.1412]])   ", "summary": "Computes the inverse of a symmetric positive-definite matrix AAA   using its Cholesky factor uuu  : returns matrix inv", "returns": null, "shape": "NA", "code-info": {"name": "torch.cholesky_inverse", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input 2-D tensor uuu, a upper or lower triangularCholesky factor"}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether to return a lower (default or upper triangular matrix"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor for inv"}]}},
{"id": "torch.cholesky_solve", "type": "function", "code": "torch.cholesky_solve(input,input2,upper=False,out=None)", "example": "  a = torch.randn(3, 3)  a = torch.mm(a, a.t()) # make symmetric positive definite  u = torch.cholesky(a)  a tensor([[ 0.7747, -1.9549,  1.3086],         [-1.9549,  6.7546, -5.4114],         [ 1.3086, -5.4114,  4.8733]])  b = torch.randn(3, 2)  b tensor([[-0.6355,  0.9891],         [ 0.1974,  1.4706],         [-0.4115, -0.6225]])  torch.cholesky_solve(b, u) tensor([[ -8.1625,  19.6097],         [ -5.8398,  14.2387],         [ -4.3771,  10.4173]])  torch.mm(a.inverse(), b) tensor([[ -8.1626,  19.6097],         [ -5.8398,  14.2387],         [ -4.3771,  10.4173]])   ", "summary": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix uuu  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.cholesky_solve", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " input matrix bbb of size (\u2217,m,k(*, m, k(\u2217,m,k,where \u2217*\u2217 is zero or more batch dimensions"}, {"name": "input2", "is_optional": false, "type": "Tensor", "description": " input matrix uuu of size (\u2217,m,m(*, m, m(\u2217,m,m,where \u2217*\u2217 is zero of more batch dimensions composed ofupper or lower triangular Cholesky factor"}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether to consider the Cholesky factor as alower or upper triangular matrix. Default"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor for c"}]}},
{"id": "torch.nn.GRUCell", "type": "class", "code": "torch.nn.GRUCell(input_size:int,hidden_size:int,bias:bool=True)", "example": "NA", "summary": "A gated recurrent unit (GRU) cell  r=\u03c3(Wirx+bir+Whrh+bhr)z=\u03c3(Wizx+biz+Whzh+bhz)n=tanh\u2061(Winx+bin+r\u2217(Whnh+bhn))h\u2032=(1\u2212z)\u2217n+z\u2217h\\begin{array}{ll} r = \\sigma(W_{ir} x + b_{ir} + W_{hr} h + b_{hr}) \\\\ z = \\sigma(W_{iz} x + b_{iz} + W_{hz} h + b_{hz}) \\\\ n = \\tanh(W_{in} x + b_{in} + r * (W_{hn} h + b_{hn})) \\\\ h' = (1 - z) * n + z * h \\end{array}r=\u03c3(Wir\u200bx+bir\u200b+Whr\u200bh+bhr\u200b)z=\u03c3(Wiz\u200bx+biz\u200b+Whz\u200bh+bhz\u200b)n=tanh(Win\u200bx+bin\u200b+r\u2217(Whn\u200bh+bhn\u200b))h\u2032=(1\u2212z)\u2217n+z\u2217h\u200b  where \u03c3\\sigma\u03c3   is the sigmoid function, and \u2217*\u2217   is the Hadamard product", "returns": [], "shape": "", "code-info": {"name": "torch.nn.GRUCell", "parameters": [{"name": "input_size", "type": "int", "is_optional": false, "description": "The number of expected features in the input x"}, {"name": "hidden_size", "type": "int", "is_optional": false, "description": "The number of features in the hidden state h"}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": false, "description": "If False, then the layer does not use bias weights b_ih andb_hh. Default: True"}]}},
{"id": "torch.nn.Transformer", "type": "class", "code": "torch.nn.Transformer(d_model:int=512,nhead:int=8,num_encoder_layers:int=6,num_decoder_layers:int=6,dim_feedforward:int=2048,dropout:float=0.1,activation:str='relu',custom_encoder:Optional[Any]=None,custom_decoder:Optional[Any]=None)", "example": "NA", "summary": "A transformer model", "returns": [], "shape": "&gt;&gt;&gt; transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n&gt;&gt;&gt; src = torch.rand((10, 32, 512))\n&gt;&gt;&gt; tgt = torch.rand((20, 32, 512))\n&gt;&gt;&gt; out = transformer_model(src, tgt)\n\n\n", "code-info": {"name": "torch.nn.Transformer", "parameters": [{"name": "d_model", "type": "int", "default_value": "512", "is_optional": false, "description": "the number of expected features in the encoder/decoder inputs (default=512)."}, {"name": "nhead", "type": "int", "default_value": "8", "is_optional": false, "description": "the number of heads in the multiheadattention models (default=8)."}, {"name": "num_encoder_layers", "type": "int", "default_value": "6", "is_optional": false, "description": "the number of sub-encoder-layers in the encoder (default=6)."}, {"name": "num_decoder_layers", "type": "int", "default_value": "6", "is_optional": false, "description": "the number of sub-decoder-layers in the decoder (default=6)."}, {"name": "dim_feedforward", "type": "int", "default_value": "2048", "is_optional": false, "description": "the dimension of the feedforward network model (default=2048)."}, {"name": "dropout", "type": "float", "default_value": "0.1", "is_optional": false, "description": "the dropout value (default=0.1)."}, {"name": "activation", "type": "str", "default_value": "'relu'", "is_optional": false, "description": "the activation function of encoder/decoder intermediate layer, relu or gelu (default=relu)."}, {"name": "custom_encoder", "type": "Optional[Any]", "default_value": "None", "is_optional": false, "description": "custom encoder (default=None)."}, {"name": "custom_decoder", "type": "Optional[Any]", "default_value": "None", "is_optional": false, "description": "custom decoder (default=None)."}]}},
{"id": "torch.dot", "type": "function", "code": "torch.dot(input,tensor)", "example": "  torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1])) tensor(7)   ", "summary": "Computes the dot product (inner product) of two tensors", "returns": null, "shape": "NA", "code-info": {"name": "torch.dot", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "tensor", "is_optional": false, "type": "others", "description": ""}]}},
{"id": "torch.eig", "type": "function", "code": "torch.eig(input,eigenvectors=False,out=None)", "example": "NA", "summary": "Computes the eigenvalues and eigenvectors of a real square matrix", "returns": "A namedtuple (eigenvalues, eigenvectors) containingeigenvalues (Tensor): Shape (n\u00d72)(n \\times 2)(n\u00d72). Each row is an eigenvalue of input,where the first element is the real part and the second element is the imaginary part.The eigenvalues are not necessarily ordered.eigenvectors (Tensor): If eigenvectors=False, it\u2019s an empty tensor.Otherwise, this tensor of shape (n\u00d7n)(n \\times n)(n\u00d7n) can be used to compute normalized (unit length)eigenvectors of corresponding eigenvalues as follows.If the corresponding eigenvalues[j] is a real number, column eigenvectors[:, j] is the eigenvectorcorresponding to eigenvalues[j].If the corresponding eigenvalues[j] and eigenvalues[j + 1] form a complex conjugate pair, then thetrue eigenvectors can be computed astrue\u00a0eigenvector[j]=eigenvectors[:,j]+i\u00d7eigenvectors[:,j+1]\\text{true eigenvector}[j] = eigenvectors[:, j] + i \\times eigenvectors[:, j + 1]true\u00a0eigenvector[j]=eigenvectors[:,j]+i\u00d7eigenvectors[:,j+1],true\u00a0eigenvector[j+1]=eigenvectors[:,j]\u2212i\u00d7eigenvectors[:,j+1]\\text{true eigenvector}[j + 1] = eigenvectors[:, j] - i \\times eigenvectors[:, j + 1]true\u00a0eigenvector[j+1]=eigenvectors[:,j]\u2212i\u00d7eigenvectors[:,j+1].", "shape": "NA", "code-info": {"name": "torch.eig", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the square matrix of shape (n\u00d7n(n \\times n(n\u00d7n for which the eigenvalues and eigenvectorswill be computed"}, {"name": "eigenvectors", "is_optional": true, "type": "bool", "default_value": "False", "description": " If eigenvectors=False, it\u2019s an empty tensor.Otherwise, this tensor of shape (n\u00d7n(n \\times n(n\u00d7n can be used to compute normalized (unit lengtheigenvectors of corresponding eigenvalues as follows.If the corresponding eigenvalues[j] is a real number, column eigenvectors["}, {"name": "out", "is_optional": true, "type": "tuple, optional", "default_value": "None", "description": " the output tensors"}]}},
{"id": "torch.geqrf", "type": "function", "code": "torch.geqrf(input,out=None)", "example": "NA", "summary": "This is a low-level function for calling LAPACK directly", "returns": null, "shape": "NA", "code-info": {"name": "torch.geqrf", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input matrix"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": " the output tuple of (Tensor, Tensor"}]}},
{"id": "torch.nn.TransformerEncoder", "type": "class", "code": "torch.nn.TransformerEncoder(encoder_layer,num_layers,norm=None)", "example": "NA", "summary": "TransformerEncoder is a stack of N encoder layers  Parameters  encoder_layer \u2013 an instance of the TransformerEncoderLayer() class (required)", "returns": [], "shape": "&gt;&gt;&gt; encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n&gt;&gt;&gt; transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n&gt;&gt;&gt; src = torch.rand(10, 32, 512)\n&gt;&gt;&gt; out = transformer_encoder(src)\n\n\n", "code-info": {"name": "torch.nn.TransformerEncoder", "parameters": []}},
{"id": "torch.nn.TransformerDecoder", "type": "class", "code": "torch.nn.TransformerDecoder(decoder_layer,num_layers,norm=None)", "example": "NA", "summary": "TransformerDecoder is a stack of N decoder layers  Parameters  decoder_layer \u2013 an instance of the TransformerDecoderLayer() class (required)", "returns": [], "shape": "&gt;&gt;&gt; decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n&gt;&gt;&gt; transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n&gt;&gt;&gt; memory = torch.rand(10, 32, 512)\n&gt;&gt;&gt; tgt = torch.rand(20, 32, 512)\n&gt;&gt;&gt; out = transformer_decoder(tgt, memory)\n\n\n", "code-info": {"name": "torch.nn.TransformerDecoder", "parameters": []}},
{"id": "torch.nn.TransformerEncoderLayer", "type": "class", "code": "torch.nn.TransformerEncoderLayer(d_model,nhead,dim_feedforward=2048,dropout=0.1,activation='relu')", "example": "NA", "summary": "TransformerEncoderLayer is made up of self-attn and feedforward network", "returns": [], "shape": "&gt;&gt;&gt; encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n&gt;&gt;&gt; src = torch.rand(10, 32, 512)\n&gt;&gt;&gt; out = encoder_layer(src)\n\n\n", "code-info": {"name": "torch.nn.TransformerEncoderLayer", "parameters": []}},
{"id": "torch.nn.TransformerDecoderLayer", "type": "class", "code": "torch.nn.TransformerDecoderLayer(d_model,nhead,dim_feedforward=2048,dropout=0.1,activation='relu')", "example": "NA", "summary": "TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network", "returns": [], "shape": "&gt;&gt;&gt; decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n&gt;&gt;&gt; memory = torch.rand(10, 32, 512)\n&gt;&gt;&gt; tgt = torch.rand(20, 32, 512)\n&gt;&gt;&gt; out = decoder_layer(tgt, memory)\n\n\n", "code-info": {"name": "torch.nn.TransformerDecoderLayer", "parameters": []}},
{"id": "torch.nn.Identity", "type": "class", "code": "torch.nn.Identity(*args,**kwargs)", "example": "NA", "summary": "A placeholder identity operator that is argument-insensitive", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Identity", "parameters": []}},
{"id": "torch.ger", "type": "function", "code": "torch.ger(input,vec2,out=None)", "example": "  v1 = torch.arange(1., 5.)  v2 = torch.arange(1., 4.)  torch.ger(v1, v2) tensor([[  1.,   2.,   3.],         [  2.,   4.,   6.],         [  3.,   6.,   9.],         [  4.,   8.,  12.]])   ", "summary": "Outer product of input and vec2", "returns": null, "shape": "NA", "code-info": {"name": "torch.ger", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " 1-D input vector"}, {"name": "vec2", "is_optional": false, "type": "Tensor", "description": " 1-D input vector"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " optional output matrix"}]}},
{"id": "torch.inverse", "type": "function", "code": "torch.inverse(input,out=None)", "example": "  x = torch.rand(4, 4)  y = torch.inverse(x)  z = torch.mm(x, y)  z tensor([[ 1.0000, -0.0000, -0.0000,  0.0000],         [ 0.0000,  1.0000,  0.0000,  0.0000],         [ 0.0000,  0.0000,  1.0000,  0.0000],         [ 0.0000, -0.0000, -0.0000,  1.0000]])  torch.max(torch.abs(z - torch.eye(4))) # Max non-zero tensor(1.1921e-07)  # Batched inverse example  x = torch.randn(2, 3, 4, 4)  y = torch.inverse(x)  z = torch.matmul(x, y)  torch.max(torch.abs(z - torch.eye(4).expand_as(x))) # Max non-zero tensor(1.9073e-06)   ", "summary": "Takes the inverse of the square matrix input", "returns": null, "shape": "NA", "code-info": {"name": "torch.inverse", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of size (\u2217,n,n(*, n, n(\u2217,n,n where * is zero or morebatch dimensions"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.det", "type": "function", "code": "torch.det(input)", "example": "  A = torch.randn(3, 3)  torch.det(A) tensor(3.7641)   A = torch.randn(3, 2, 2)  A tensor([[[ 0.9254, -0.6213],          [-0.5787,  1.6843]],          [[ 0.3242, -0.9665],          [ 0.4539, -0.0887]],          [[ 1.1336, -0.4025],          [-0.7089,  0.9032]]])  A.det() tensor([1.1990, 0.4099, 0.7386])   ", "summary": "Calculates determinant of a square matrix or batches of square matrices", "returns": null, "shape": "NA", "code-info": {"name": "torch.det", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of size (*, n, n where * is zero or morebatch dimensions."}]}},
{"id": "torch.logdet", "type": "function", "code": "torch.logdet(input)", "example": "  A = torch.randn(3, 3)  torch.det(A) tensor(0.2611)  torch.logdet(A) tensor(-1.3430)  A tensor([[[ 0.9254, -0.6213],          [-0.5787,  1.6843]],          [[ 0.3242, -0.9665],          [ 0.4539, -0.0887]],          [[ 1.1336, -0.4025],          [-0.7089,  0.9032]]])  A.det() tensor([1.1990, 0.4099, 0.7386])  A.det().log() tensor([ 0.1815, -0.8917, -0.3031])   ", "summary": "Calculates log determinant of a square matrix or batches of square matrices", "returns": null, "shape": "NA", "code-info": {"name": "torch.logdet", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of size (*, n, n where * is zero or morebatch dimensions."}]}},
{"id": "torch.slogdet", "type": "function", "code": "torch.slogdet(input)", "example": "  A = torch.randn(3, 3)  A tensor([[ 0.0032, -0.2239, -1.1219],         [-0.6690,  0.1161,  0.4053],         [-1.6218, -0.9273, -0.0082]])  torch.det(A) tensor(-0.7576)  torch.logdet(A) tensor(nan)  torch.slogdet(A) torch.return_types.slogdet(sign=tensor(-1.), logabsdet=tensor(-0.2776))   ", "summary": "Calculates the sign and log absolute value of the determinant(s) of a square matrix or batches of square matrices", "returns": "A namedtuple (sign, logabsdet) containing the sign of the determinant, and the logvalue of the absolute determinant.", "shape": "NA", "code-info": {"name": "torch.slogdet", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of size (*, n, n where * is zero or morebatch dimensions."}]}},
{"id": "torch.nn.Linear", "type": "class", "code": "torch.nn.Linear(in_features:int,out_features:int,bias:bool=True)", "example": "NA", "summary": "Applies a linear transformation to the incoming data: y=xAT+by = xA^T + by=xAT+b    Parameters  in_features \u2013 size of each input sample out_features \u2013 size of each output sample bias \u2013 If set to False, the layer will not learn an additive bias", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Linear", "parameters": [{"name": "in_features", "type": "int", "is_optional": false, "description": "size of each input sample"}, {"name": "out_features", "type": "int", "is_optional": false, "description": "size of each output sample"}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": false, "description": "If set to False, the layer will not learn an additive bias.Default: True"}]}},
{"id": "torch.nn.Bilinear", "type": "class", "code": "torch.nn.Bilinear(in1_features:int,in2_features:int,out_features:int,bias:bool=True)", "example": "NA", "summary": "Applies a bilinear transformation to the incoming data: y=x1TAx2+by = x_1^T A x_2 + by=x1T\u200bAx2\u200b+b    Parameters  in1_features \u2013 size of each first input sample in2_features \u2013 size of each second input sample out_features \u2013 size of each output sample bias \u2013 If set to False, the layer will not learn an additive bias", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Bilinear", "parameters": [{"name": "in1_features", "type": "int", "is_optional": false, "description": "size of each first input sample"}, {"name": "in2_features", "type": "int", "is_optional": false, "description": "size of each second input sample"}, {"name": "out_features", "type": "int", "is_optional": false, "description": "size of each output sample"}, {"name": "bias", "type": "bool", "default_value": "True", "is_optional": false, "description": "If set to False, the layer will not learn an additive bias.Default: True"}]}},
{"id": "torch.lstsq", "type": "function", "code": "torch.lstsq(input,A,out=None)", "example": "  A = torch.tensor([[1., 1, 1],                       [2, 3, 4],                       [3, 5, 2],                       [4, 2, 5],                       [5, 4, 3]])  B = torch.tensor([[-10., -3],                       [ 12, 14],                       [ 14, 12],                       [ 16, 16],                       [ 18, 16]])  X, _ = torch.lstsq(B, A)  X tensor([[  2.0000,   1.0000],         [  1.0000,   1.0000],         [  1.0000,   2.0000],         [ 10.9635,   4.8501],         [  8.9332,   5.2418]])   ", "summary": "Computes the solution to the least squares and least norm problems for a full rank matrix AAA   of size (m\u00d7n)(m \\times n)(m\u00d7n)   and a matrix BBB   of size (m\u00d7k)(m \\times k)(m\u00d7k)  ", "returns": "A namedtuple (solution, QR) containing:solution (Tensor): the least squares solutionQR (Tensor): the details of the QR factorization", "shape": "NA", "code-info": {"name": "torch.lstsq", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the matrix BBB"}, {"name": "A", "is_optional": false, "type": "Tensor", "description": " the mmm by nnn matrix AAA"}, {"name": "out", "is_optional": true, "type": "tuple, optional", "default_value": "None", "description": " the optional destination tensor"}]}},
{"id": "torch.lu", "type": "function", "code": "torch.lu(A,pivot=True,get_infos=False,out=None)", "example": "  A = torch.randn(2, 3, 3)  A_LU, pivots = torch.lu(A)  A_LU tensor([[[ 1.3506,  2.5558, -0.0816],          [ 0.1684,  1.1551,  0.1940],          [ 0.1193,  0.6189, -0.5497]],          [[ 0.4526,  1.2526, -0.3285],          [-0.7988,  0.7175, -0.9701],          [ 0.2634, -0.9255, -0.3459]]])  pivots tensor([[ 3,  3,  3],         [ 3,  3,  3]], dtype=torch.int32)  A_LU, pivots, info = torch.lu(A, get_infos=True)  if info.nonzero().size(0) == 0: ...   print('LU factorization succeeded for all samples!') LU factorization succeeded for all samples!   ", "summary": "Computes the LU factorization of a matrix or batches of matrices A", "returns": "A tuple of tensors containingfactorization (Tensor): the factorization of size (\u2217,m,n)(*, m, n)(\u2217,m,n)pivots (IntTensor): the pivots of size (\u2217,m)(*, m)(\u2217,m)infos (IntTensor, optional): if get_infos is True, this is a tensor ofsize (\u2217)(*)(\u2217) where non-zero values indicate whether factorization for the matrix oreach minibatch has succeeded or failed", "shape": "NA", "code-info": {"name": "torch.lu", "parameters": [{"name": "A", "is_optional": false, "type": "Tensor", "description": " the tensor to factor of size (\u2217,m,n(*, m, n(\u2217,m,n"}, {"name": "pivot", "is_optional": true, "type": "bool", "default_value": "True", "description": " controls whether pivoting is done. Default"}, {"name": "get_infos", "is_optional": true, "type": "bool", "default_value": "False", "description": " if set to True, returns an info IntTensor.Default"}, {"name": "out", "is_optional": true, "type": "tuple, optional", "default_value": "None", "description": " optional output tuple. If get_infos is True,then the elements in the tuple are Tensor, IntTensor,and IntTensor. If get_infos is False, then theelements in the tuple are Tensor, IntTensor. Default"}]}},
{"id": "torch.nn.Dropout", "type": "class", "code": "torch.nn.Dropout(p:float=0.5,inplace:bool=False)", "example": "NA", "summary": "During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Dropout", "parameters": [{"name": "p", "type": "float", "default_value": "05", "is_optional": false, "description": "probability of an element to be zeroed. Default: 0.5"}, {"name": "inplace", "type": "bool", "default_value": "False", "is_optional": false, "description": "If set to True, will do this operation in-place. Default: False"}]}},
{"id": "torch.nn.Dropout2d", "type": "class", "code": "torch.nn.Dropout2d(p:float=0.5,inplace:bool=False)", "example": "NA", "summary": "Randomly zero out entire channels (a channel is a 2D feature map, e.g., the jjj  -th channel of the iii  -th sample in the batched input is a 2D tensor input[i,j]\\text{input}[i, j]input[i,j]  )", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Dropout2d", "parameters": [{"name": "p", "type": "float", "default_value": "0.5", "is_optional": true, "description": "probability of an element to be zero-ed."}, {"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "If set to True, will do this operationin-place"}]}},
{"id": "torch.nn.Dropout3d", "type": "class", "code": "torch.nn.Dropout3d(p:float=0.5,inplace:bool=False)", "example": "NA", "summary": "Randomly zero out entire channels (a channel is a 3D feature map, e.g., the jjj  -th channel of the iii  -th sample in the batched input is a 3D tensor input[i,j]\\text{input}[i, j]input[i,j]  )", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Dropout3d", "parameters": [{"name": "p", "type": "float", "default_value": "0.5", "is_optional": true, "description": "probability of an element to be zeroed."}, {"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "If set to True, will do this operationin-place"}]}},
{"id": "torch.lu_solve", "type": "function", "code": "torch.lu_solve(input,LU_data,LU_pivots,out=None)", "example": "  A = torch.randn(2, 3, 3)  b = torch.randn(2, 3, 1)  A_LU = torch.lu(A)  x = torch.lu_solve(b, *A_LU)  torch.norm(torch.bmm(A, x) - b) tensor(1.00000e-07 *        2.8312)   ", "summary": "Returns the LU solve of the linear system Ax=bAx = bAx=b   using the partially pivoted LU factorization of A from torch.lu()", "returns": null, "shape": "NA", "code-info": {"name": "torch.lu_solve", "parameters": [{"name": "input", "is_optional": false, "type": "others", "description": ""}, {"name": "LU_data", "is_optional": false, "type": "Tensor", "description": " the pivoted LU factorization of A from torch.lu( of size (\u2217,m,m(*, m, m(\u2217,m,m,where \u2217*\u2217 is zero or more batch dimensions."}, {"name": "LU_pivots", "is_optional": false, "type": "IntTensor", "description": " the pivots of the LU factorization from torch.lu( of size (\u2217,m(*, m(\u2217,m,where \u2217*\u2217 is zero or more batch dimensions.The batch dimensions of LU_pivots must be equal to the batch dimensions ofLU_data."}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.lu_unpack", "type": "function", "code": "torch.lu_unpack(LU_data,LU_pivots,unpack_data=True,unpack_pivots=True)", "example": " A = torch.randn(2, 3, 3)\n A_LU, pivots = A.lu()\n P, A_L, A_U = torch.lu_unpack(A_LU, pivots)\n\n # can recover A from factorization\n A_ = torch.bmm(P, torch.bmm(A_L, A_U))\n\n # LU factorization of a rectangular matrix:\n A = torch.randn(2, 3, 2)\n A_LU, pivots = A.lu()\n P, A_L, A_U = torch.lu_unpack(A_LU, pivots)\n P\ntensor([[[1., 0., 0.],\n         [0., 1., 0.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 1., 0.],\n         [1., 0., 0.]]])\n A_L\ntensor([[[ 1.0000,  0.0000],\n         [ 0.4763,  1.0000],\n         [ 0.3683,  0.1135]],\n\n        [[ 1.0000,  0.0000],\n         [ 0.2957,  1.0000],\n         [-0.9668, -0.3335]]])\n A_U\ntensor([[[ 2.1962,  1.0881],\n         [ 0.0000, -0.8681]],\n\n        [[-1.0947,  0.3736],\n         [ 0.0000,  0.5718]]])\n A_ = torch.bmm(P, torch.bmm(A_L, A_U))\n torch.norm(A_ - A)\ntensor(2.9802e-08)\n\n", "summary": "Unpacks the data and pivots from a LU factorization of a tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.lu_unpack", "parameters": [{"name": "LU_data", "is_optional": false, "type": "Tensor", "description": " the packed LU factorization data"}, {"name": "LU_pivots", "is_optional": false, "type": "Tensor", "description": " the packed LU factorization pivots"}, {"name": "unpack_data", "is_optional": true, "type": "bool", "default_value": "True", "description": " flag indicating if the data should be unpacked"}, {"name": "unpack_pivots", "is_optional": true, "type": "bool", "default_value": "True", "description": " flag indicating if the pivots should be unpacked"}]}},
{"id": "torch.matmul", "type": "function", "code": "torch.matmul(input,other,out=None)", "example": "  # vector x vector  tensor1 = torch.randn(3)  tensor2 = torch.randn(3)  torch.matmul(tensor1, tensor2).size() torch.Size([])  # matrix x vector  tensor1 = torch.randn(3, 4)  tensor2 = torch.randn(4)  torch.matmul(tensor1, tensor2).size() torch.Size([3])  # batched matrix x broadcasted vector  tensor1 = torch.randn(10, 3, 4)  tensor2 = torch.randn(4)  torch.matmul(tensor1, tensor2).size() torch.Size([10, 3])  # batched matrix x batched matrix  tensor1 = torch.randn(10, 3, 4)  tensor2 = torch.randn(10, 4, 5)  torch.matmul(tensor1, tensor2).size() torch.Size([10, 3, 5])  # batched matrix x broadcasted matrix  tensor1 = torch.randn(10, 3, 4)  tensor2 = torch.randn(4, 5)  torch.matmul(tensor1, tensor2).size() torch.Size([10, 3, 5])   ", "summary": "Matrix product of two tensors", "returns": null, "shape": "NA", "code-info": {"name": "torch.matmul", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the first tensor to be multiplied"}, {"name": "other", "is_optional": false, "type": "Tensor", "description": " the second tensor to be multiplied"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.nn.AlphaDropout", "type": "class", "code": "torch.nn.AlphaDropout(p:float=0.5,inplace:bool=False)", "example": "NA", "summary": "Applies Alpha Dropout over the input", "returns": [], "shape": "", "code-info": {"name": "torch.nn.AlphaDropout", "parameters": [{"name": "p", "type": "float", "default_value": "05", "is_optional": false, "description": "probability of an element to be dropped. Default: 0.5"}, {"name": "inplace", "type": "bool", "default_value": "False", "is_optional": true, "description": "If set to True, will do this operationin-place"}]}},
{"id": "torch.nn.Embedding", "type": "class", "code": "torch.nn.Embedding(num_embeddings:int,embedding_dim:int,padding_idx:Optional[int]=None,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,sparse:bool=False,_weight:Optional[torch.Tensor]=None)", "example": "NA", "summary": "A simple lookup table that stores embeddings of a fixed dictionary and size", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Embedding", "parameters": [{"name": "num_embeddings", "type": "int", "is_optional": false, "description": "size of the dictionary of embeddings"}, {"name": "embedding_dim", "type": "int", "is_optional": false, "description": "the size of each embedding vector"}, {"name": "padding_idx", "type": "Optional[int]", "default_value": "None", "is_optional": true, "description": "See module initialization documentation."}, {"name": "max_norm", "type": "Optional[float]", "default_value": "None", "is_optional": true, "description": "See module initialization documentation."}, {"name": "norm_type", "type": "float", "default_value": "2.0", "is_optional": true, "description": "See module initialization documentation. Default 2."}, {"name": "scale_grad_by_freq", "type": "bool", "default_value": "False", "is_optional": true, "description": "See module initialization documentation. Default False."}, {"name": "sparse", "type": "bool", "default_value": "False", "is_optional": true, "description": "See module initialization documentation."}, {"name": "_weight", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": false, "description": ""}]}},
{"id": "torch.nn.EmbeddingBag", "type": "class", "code": "torch.nn.EmbeddingBag(num_embeddings:int,embedding_dim:int,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,mode:str='mean',sparse:bool=False,_weight:Optional[torch.Tensor]=None,include_last_offset:bool=False)", "example": "NA", "summary": "Computes sums or means of \u2018bags\u2019 of embeddings, without instantiating the intermediate embeddings", "returns": [], "shape": "", "code-info": {"name": "torch.nn.EmbeddingBag", "parameters": [{"name": "num_embeddings", "type": "int", "is_optional": false, "description": "size of the dictionary of embeddings"}, {"name": "embedding_dim", "type": "int", "is_optional": false, "description": "the size of each embedding vector"}, {"name": "max_norm", "type": "Optional[float]", "default_value": "None", "is_optional": true, "description": "See module initialization documentation. Default: None"}, {"name": "norm_type", "type": "float", "default_value": "2.0", "is_optional": true, "description": "See module initialization documentation. Default 2."}, {"name": "scale_grad_by_freq", "type": "bool", "default_value": "False", "is_optional": true, "description": "See module initialization documentation. Default False."}, {"name": "mode", "type": "str", "default_value": "\"mean\"", "is_optional": true, "description": "See module initialization documentation. Default: \"mean\""}, {"name": "sparse", "type": "bool", "default_value": "False", "is_optional": true, "description": "See module initialization documentation. Default: False."}, {"name": "_weight", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": false, "description": ""}, {"name": "include_last_offset", "type": "bool", "default_value": "False", "is_optional": true, "description": "See module initialization documentation. Default: False."}]}},
{"id": "torch.matrix_power", "type": "function", "code": "torch.matrix_power(input,n)", "example": "  a = torch.randn(2, 2, 2)  a tensor([[[-1.9975, -1.9610],          [ 0.9592, -2.3364]],          [[-1.2534, -1.3429],          [ 0.4153, -1.4664]]])  torch.matrix_power(a, 3) tensor([[[  3.9392, -23.9916],          [ 11.7357,  -0.2070]],          [[  0.2468,  -6.7168],          [  2.0774,  -0.8187]]])   ", "summary": "Returns the matrix raised to the power n for square matrices", "returns": null, "shape": "NA", "code-info": {"name": "torch.matrix_power", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor."}, {"name": "n", "is_optional": false, "type": "Tensor", "description": " the power to raise the matrix to"}]}},
{"id": "torch.matrix_rank", "type": "function", "code": "torch.matrix_rank(input,tol=None,symmetric=False)", "example": "  a = torch.eye(10)  torch.matrix_rank(a) tensor(10)  b = torch.eye(10)  b[0, 0] = 0  torch.matrix_rank(b) tensor(9)   ", "summary": "Returns the numerical rank of a 2-D tensor", "returns": null, "shape": "NA", "code-info": {"name": "torch.matrix_rank", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input 2-D tensor"}, {"name": "tol", "is_optional": true, "type": "float, optional", "default_value": "None", "description": " the tolerance value. Default"}, {"name": "symmetric", "is_optional": true, "type": "bool", "default_value": "False", "description": " indicates whether input is symmetric.Default"}]}},
{"id": "torch.mm", "type": "function", "code": "torch.mm(input,mat2,out=None)", "example": "  mat1 = torch.randn(2, 3)  mat2 = torch.randn(3, 3)  torch.mm(mat1, mat2) tensor([[ 0.4851,  0.5037, -0.3633],         [-0.0760, -3.6705,  2.4784]])   ", "summary": "Performs a matrix multiplication of the matrices input and mat2", "returns": null, "shape": "NA", "code-info": {"name": "torch.mm", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the first matrix to be multiplied"}, {"name": "mat2", "is_optional": false, "type": "Tensor", "description": " the second matrix to be multiplied"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.mv", "type": "function", "code": "torch.mv(input,vec,out=None)", "example": "  mat = torch.randn(2, 3)  vec = torch.randn(3)  torch.mv(mat, vec) tensor([ 1.0404, -0.6361])   ", "summary": "Performs a matrix-vector product of the matrix input and the vector vec", "returns": null, "shape": "NA", "code-info": {"name": "torch.mv", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " matrix to be multiplied"}, {"name": "vec", "is_optional": false, "type": "Tensor", "description": " vector to be multiplied"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " the output tensor."}]}},
{"id": "torch.orgqr", "type": "function", "code": "torch.orgqr(input,input2)", "example": "NA", "summary": "Computes the orthogonal matrix Q of a QR factorization, from the (input, input2) tuple returned by torch.geqrf()", "returns": null, "shape": "NA", "code-info": {"name": "torch.orgqr", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the a from torch.geqrf(."}, {"name": "input2", "is_optional": false, "type": "Tensor", "description": " the tau from torch.geqrf(."}]}},
{"id": "torch.nn.CosineSimilarity", "type": "class", "code": "torch.nn.CosineSimilarity(dim:int=1,eps:float=1e-08)", "example": "NA", "summary": "Returns cosine similarity between x1x_1x1\u200b   and x2x_2x2\u200b  , computed along dim", "returns": [], "shape": "\nInput1: (\u22171,D,\u22172)(\\ast_1, D, \\ast_2)(\u22171\u200b,D,\u22172\u200b)\n\n where D is at position dim\nInput2: (\u22171,D,\u22172)(\\ast_1, D, \\ast_2)(\u22171\u200b,D,\u22172\u200b)\n\n, same shape as the Input1\nOutput: (\u22171,\u22172)(\\ast_1, \\ast_2)(\u22171\u200b,\u22172\u200b)\n\n\n\n", "code-info": {"name": "torch.nn.CosineSimilarity", "parameters": [{"name": "dim", "type": "int", "default_value": "1", "is_optional": true, "description": "Dimension where cosine similarity is computed. Default: 1"}, {"name": "eps", "type": "float", "default_value": "1e-8", "is_optional": true, "description": "Small value to avoid division by zero.Default: 1e-8"}]}},
{"id": "torch.nn.PairwiseDistance", "type": "class", "code": "torch.nn.PairwiseDistance(p:float=2.0,eps:float=1e-06,keepdim:bool=False)", "example": "NA", "summary": "Computes the batchwise pairwise distance between vectors v1v_1v1\u200b  , v2v_2v2\u200b   using the p-norm:  \u2225x\u2225p=(\u2211i=1n\u2223xi\u2223p)1/p.\\Vert x \\Vert _p = \\left( \\sum_{i=1}^n  \\vert x_i \\vert ^ p \\right) ^ {1/p}", "returns": [], "shape": "\nInput1: (N,D)(N, D)(N,D)\n\n where D = vector dimension\nInput2: (N,D)(N, D)(N,D)\n\n, same shape as the Input1\nOutput: (N)(N)(N)\n\n. If keepdim is True, then (N,1)(N, 1)(N,1)\n\n.\n\n", "code-info": {"name": "torch.nn.PairwiseDistance", "parameters": [{"name": "p", "type": "float", "default_value": "2", "is_optional": false, "description": "the norm degree. Default: 2"}, {"name": "eps", "type": "float", "default_value": "1e-6", "is_optional": true, "description": "Small value to avoid division by zero.Default: 1e-6"}, {"name": "keepdim", "type": "bool", "default_value": "False", "is_optional": true, "description": "Determines whether or not to keep the vector dimension.Default: False"}]}},
{"id": "torch.nn.L1Loss", "type": "class", "code": "torch.nn.L1Loss(size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Creates a criterion that measures the mean absolute error (MAE) between each element in the input xxx   and target yyy  ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.L1Loss", "parameters": [{"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch.ormqr", "type": "function", "code": "torch.ormqr(input,input2,input3,left=True,transpose=False)", "example": "NA", "summary": "Multiplies mat (given by input3) by the orthogonal Q matrix of the QR factorization formed by torch.geqrf() that is represented by (a, tau) (given by (input, input2))", "returns": null, "shape": "NA", "code-info": {"name": "torch.ormqr", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the a from torch.geqrf(."}, {"name": "input2", "is_optional": false, "type": "Tensor", "description": " the tau from torch.geqrf(."}, {"name": "input3", "is_optional": false, "type": "Tensor", "description": " the matrix to be multiplied."}, {"name": "left", "is_optional": true, "type": "bool", "default_value": "True", "description": ""}, {"name": "transpose", "is_optional": true, "type": "bool", "default_value": "False", "description": ""}]}},
{"id": "torch.pinverse", "type": "function", "code": "torch.pinverse(input,rcond=1e-15)", "example": "  input = torch.randn(3, 5)  input tensor([[ 0.5495,  0.0979, -1.4092, -0.1128,  0.4132],         [-1.1143, -0.3662,  0.3042,  1.6374, -0.9294],         [-0.3269, -0.5745, -0.0382, -0.5922, -0.6759]])  torch.pinverse(input) tensor([[ 0.0600, -0.1933, -0.2090],         [-0.0903, -0.0817, -0.4752],         [-0.7124, -0.1631, -0.2272],         [ 0.1356,  0.3933, -0.5023],         [-0.0308, -0.1725, -0.5216]])  # Batched pinverse example  a = torch.randn(2,6,3)  b = torch.pinverse(a)  torch.matmul(b, a) tensor([[[ 1.0000e+00,  1.6391e-07, -1.1548e-07],         [ 8.3121e-08,  1.0000e+00, -2.7567e-07],         [ 3.5390e-08,  1.4901e-08,  1.0000e+00]],          [[ 1.0000e+00, -8.9407e-08,  2.9802e-08],         [-2.2352e-07,  1.0000e+00,  1.1921e-07],         [ 0.0000e+00,  8.9407e-08,  1.0000e+00]]])   ", "summary": "Calculates the pseudo-inverse (also known as the Moore-Penrose inverse) of a 2D tensor", "returns": "The pseudo-inverse of input of dimensions (\u2217,n,m)(*, n, m)(\u2217,n,m)", "shape": "NA", "code-info": {"name": "torch.pinverse", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " The input tensor of size (\u2217,m,n(*, m, n(\u2217,m,n where \u2217*\u2217 is zero or more batch dimensions"}, {"name": "rcond", "is_optional": true, "type": "float", "default_value": "1e-15", "description": " A floating point value to determine the cutoff for small singular values.Default"}]}},
{"id": "torch.nn.MSELoss", "type": "class", "code": "torch.nn.MSELoss(size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Creates a criterion that measures the mean squared error (squared L2 norm) between each element in the input xxx   and target yyy  ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.MSELoss", "parameters": [{"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch.nn.CrossEntropyLoss", "type": "class", "code": "torch.nn.CrossEntropyLoss(weight:Optional[torch.Tensor]=None,size_average=None,ignore_index:int=-100,reduce=None,reduction:str='mean')", "example": "NA", "summary": "This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class", "returns": [], "shape": "", "code-info": {"name": "torch.nn.CrossEntropyLoss", "parameters": [{"name": "weight", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "a manual rescaling weight given to each class.If given, has to be a Tensor of size C"}, {"name": "ignore_index", "type": "int", "default_value": "-100", "is_optional": true, "description": "Specifies a target value that is ignoredand does not contribute to the input gradient. When size_average isTrue, the loss is averaged over non-ignored targets."}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction willbe applied, 'mean': the weighted mean of the output is taken,'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and inthe meantime, specifying either of those two args will overridereduction. Default: 'mean'"}]}},
{"id": "torch.qr", "type": "function", "code": "torch.qr(input,some=True,out=None)", "example": "  a = torch.tensor([[12., -51, 4], [6, 167, -68], [-4, 24, -41]])  q, r = torch.qr(a)  q tensor([[-0.8571,  0.3943,  0.3314],         [-0.4286, -0.9029, -0.0343],         [ 0.2857, -0.1714,  0.9429]])  r tensor([[ -14.0000,  -21.0000,   14.0000],         [   0.0000, -175.0000,   70.0000],         [   0.0000,    0.0000,  -35.0000]])  torch.mm(q, r).round() tensor([[  12.,  -51.,    4.],         [   6.,  167.,  -68.],         [  -4.,   24.,  -41.]])  torch.mm(q.t(), q).round() tensor([[ 1.,  0.,  0.],         [ 0.,  1., -0.],         [ 0., -0.,  1.]])  a = torch.randn(3, 4, 5)  q, r = torch.qr(a, some=False)  torch.allclose(torch.matmul(q, r), a) True  torch.allclose(torch.matmul(q.transpose(-2, -1), q), torch.eye(5)) True   ", "summary": "Computes the QR decomposition of a matrix or a batch of matrices input, and returns a namedtuple (Q, R) of tensors such that input=QR\\text{input} = Q Rinput=QR   with QQQ   being an orthogonal matrix or batch of orthogonal matrices and RRR   being an upper triangular matrix or batch of upper triangular matrices", "returns": null, "shape": "NA", "code-info": {"name": "torch.qr", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of size (\u2217,m,n(*, m, n(\u2217,m,n where * is zero or morebatch dimensions consisting of matrices of dimension m\u00d7nm \\times nm\u00d7n."}, {"name": "some", "is_optional": true, "type": "bool", "default_value": "True", "description": " Set to True for reduced QR decomposition and False forcomplete QR decomposition."}, {"name": "out", "is_optional": true, "type": "tuple, optional", "default_value": "None", "description": " tuple of Q and R tensorssatisfying input = torch.matmul(Q, R.The dimensions of Q and R are (\u2217,m,k(*, m, k(\u2217,m,k and (\u2217,k,n(*, k, n(\u2217,k,nrespectively, where k=min\u2061(m,nk = \\min(m, nk=min(m,n if some"}]}},
{"id": "torch.solve", "type": "function", "code": "torch.solve(input,A,out=None)", "example": "  A = torch.tensor([[6.80, -2.11,  5.66,  5.97,  8.23],                       [-6.05, -3.30,  5.36, -4.44,  1.08],                       [-0.45,  2.58, -2.70,  0.27,  9.04],                       [8.32,  2.71,  4.35,  -7.17,  2.14],                       [-9.67, -5.14, -7.26,  6.08, -6.87]]).t()  B = torch.tensor([[4.02,  6.19, -8.22, -7.57, -3.03],                       [-1.56,  4.00, -8.67,  1.75,  2.86],                       [9.81, -4.09, -4.57, -8.61,  8.99]]).t()  X, LU = torch.solve(B, A)  torch.dist(B, torch.mm(A, X)) tensor(1.00000e-06 *        7.0977)   # Batched solver example  A = torch.randn(2, 3, 1, 4, 4)  B = torch.randn(2, 3, 1, 4, 6)  X, LU = torch.solve(B, A)  torch.dist(B, A.matmul(X)) tensor(1.00000e-06 *    3.6386)   ", "summary": "This function returns the solution to the system of linear equations represented by AX=BAX = BAX=B   and the LU factorization of A, in order as a namedtuple solution, LU", "returns": null, "shape": "NA", "code-info": {"name": "torch.solve", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " input matrix BBB of size (\u2217,m,k(*, m, k(\u2217,m,k , where \u2217*\u2217is zero or more batch dimensions."}, {"name": "A", "is_optional": false, "type": "Tensor", "description": " input square matrix of size (\u2217,m,m(*, m, m(\u2217,m,m, where\u2217*\u2217 is zero or more batch dimensions."}, {"name": "out", "is_optional": true, "type": "(Tensor, Tensor", "default_value": "None", "description": " optional output tuple."}]}},
{"id": "torch.nn.CTCLoss", "type": "class", "code": "torch.nn.CTCLoss(blank:int=0,reduction:str='mean',zero_infinity:bool=False)", "example": "NA", "summary": "The Connectionist Temporal Classification loss", "returns": [], "shape": "", "code-info": {"name": "torch.nn.CTCLoss", "parameters": [{"name": "blank", "type": "int", "default_value": "0", "is_optional": true, "description": "blank label. Default 000."}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the output losses will be divided by the target lengths andthen the mean over the batch is taken. Default: 'mean'"}, {"name": "zero_infinity", "type": "bool", "default_value": "FalseInfinite", "is_optional": true, "description": "Whether to zero infinite losses and the associated gradients.Default: FalseInfinite losses mainly occur when the inputs are too shortto be aligned to the targets."}]}},
{"id": "torch.nn.NLLLoss", "type": "class", "code": "torch.nn.NLLLoss(weight:Optional[torch.Tensor]=None,size_average=None,ignore_index:int=-100,reduce=None,reduction:str='mean')", "example": "NA", "summary": "The negative log likelihood loss", "returns": [], "shape": "", "code-info": {"name": "torch.nn.NLLLoss", "parameters": [{"name": "weight", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "a manual rescaling weight given to eachclass. If given, it has to be a Tensor of size C. Otherwise, it istreated as if having all ones."}, {"name": "ignore_index", "type": "int", "default_value": "-100", "is_optional": true, "description": "Specifies a target value that is ignoredand does not contribute to the input gradient. Whensize_average is True, the loss is averaged overnon-ignored targets."}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction willbe applied, 'mean': the weighted mean of the output is taken,'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and inthe meantime, specifying either of those two args will overridereduction. Default: 'mean'"}]}},
{"id": "torch.svd", "type": "function", "code": "torch.svd(input,some=True,compute_uv=True,out=None)", "example": "  a = torch.randn(5, 3)  a tensor([[ 0.2364, -0.7752,  0.6372],         [ 1.7201,  0.7394, -0.0504],         [-0.3371, -1.0584,  0.5296],         [ 0.3550, -0.4022,  1.5569],         [ 0.2445, -0.0158,  1.1414]])  u, s, v = torch.svd(a)  u tensor([[ 0.4027,  0.0287,  0.5434],         [-0.1946,  0.8833,  0.3679],         [ 0.4296, -0.2890,  0.5261],         [ 0.6604,  0.2717, -0.2618],         [ 0.4234,  0.2481, -0.4733]])  s tensor([2.3289, 2.0315, 0.7806])  v tensor([[-0.0199,  0.8766,  0.4809],         [-0.5080,  0.4054, -0.7600],         [ 0.8611,  0.2594, -0.4373]])  torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t())) tensor(8.6531e-07)  a_big = torch.randn(7, 5, 3)  u, s, v = torch.svd(a_big)  torch.dist(a_big, torch.matmul(torch.matmul(u, torch.diag_embed(s)), v.transpose(-2, -1))) tensor(2.6503e-06)   ", "summary": "This function returns a namedtuple (U, S, V) which is the singular value decomposition of a input real matrix or batches of real matrices input such that input=U\u00d7diag(S)\u00d7VTinput = U \\times diag(S) \\times V^Tinput=U\u00d7diag(S)\u00d7VT  ", "returns": null, "shape": "NA", "code-info": {"name": "torch.svd", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of size (\u2217,m,n(*, m, n(\u2217,m,n where * is zero or morebatch dimensions consisting of m\u00d7nm \\times nm\u00d7n matrices."}, {"name": "some", "is_optional": true, "type": "bool", "default_value": "True", "description": " controls the shape of returned U and V"}, {"name": "compute_uv", "is_optional": true, "type": "bool", "default_value": "True", "description": " option whether to compute U and V or not"}, {"name": "out", "is_optional": true, "type": "tuple, optional", "default_value": "None", "description": " the output tuple of tensors"}]}},
{"id": "torch.symeig", "type": "function", "code": "torch.symeig(input,eigenvectors=False,upper=True,out=None)", "example": " a = torch.randn(5, 5)\n a = a + a.t()  # To make a symmetric\n a\ntensor([[-5.7827,  4.4559, -0.2344, -1.7123, -1.8330],\n        [ 4.4559,  1.4250, -2.8636, -3.2100, -0.1798],\n        [-0.2344, -2.8636,  1.7112, -5.5785,  7.1988],\n        [-1.7123, -3.2100, -5.5785, -2.6227,  3.1036],\n        [-1.8330, -0.1798,  7.1988,  3.1036, -5.1453]])\n e, v = torch.symeig(a, eigenvectors=True)\n e\ntensor([-13.7012,  -7.7497,  -2.3163,   5.2477,   8.1050])\n v\ntensor([[ 0.1643,  0.9034, -0.0291,  0.3508,  0.1817],\n        [-0.2417, -0.3071, -0.5081,  0.6534,  0.4026],\n        [-0.5176,  0.1223, -0.0220,  0.3295, -0.7798],\n        [-0.4850,  0.2695, -0.5773, -0.5840,  0.1337],\n        [ 0.6415, -0.0447, -0.6381, -0.0193, -0.4230]])\n a_big = torch.randn(5, 2, 2)\n a_big = a_big + a_big.transpose(-2, -1)  # To make a_big symmetric\n e, v = a_big.symeig(eigenvectors=True)\n torch.allclose(torch.matmul(v, torch.matmul(e.diag_embed(), v.transpose(-2, -1))), a_big)\nTrue\n\n", "summary": "This function returns eigenvalues and eigenvectors of a real symmetric matrix input or a batch of real symmetric matrices, represented by a namedtuple (eigenvalues, eigenvectors)", "returns": "A namedtuple (eigenvalues, eigenvectors) containingeigenvalues (Tensor): Shape (\u2217,m)(*, m)(\u2217,m). The eigenvalues in ascending order.eigenvectors (Tensor): Shape (\u2217,m,m)(*, m, m)(\u2217,m,m).If eigenvectors=False, it\u2019s an empty tensor.Otherwise, this tensor contains the orthonormal eigenvectors of the input.", "shape": "NA", "code-info": {"name": "torch.symeig", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " the input tensor of size (\u2217,n,n(*, n, n(\u2217,n,n where * is zero or morebatch dimensions consisting of symmetric matrices."}, {"name": "eigenvectors", "is_optional": true, "type": "bool", "default_value": "False", "description": " Shape (\u2217,m,m(*, m, m(\u2217,m,m.If eigenvectors=False, it\u2019s an empty tensor.Otherwise, this tensor contains the orthonormal eigenvectors of the input."}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "True", "description": " controls whether to consider upper-triangular or lower-triangular region"}, {"name": "out", "is_optional": true, "type": "tensor", "default_value": "None", "description": " the output tuple of (Tensor, Tensor"}]}},
{"id": "torch.nn.PoissonNLLLoss", "type": "class", "code": "torch.nn.PoissonNLLLoss(log_input:bool=True,full:bool=False,size_average=None,eps:float=1e-08,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Negative log likelihood loss with Poisson distribution of target", "returns": [], "shape": "", "code-info": {"name": "torch.nn.PoissonNLLLoss", "parameters": [{"name": "log_input", "type": "bool", "default_value": "True", "is_optional": true, "description": "if True the loss is computed asexp\u2061(input)\u2212target\u2217input\\exp(\\text{input}) - \\text{target}*\\text{input}exp(input)\u2212target\u2217input, if False the loss isinput\u2212target\u2217log\u2061(input+eps)\\text{input} - \\text{target}*\\log(\\text{input}+\\text{eps})input\u2212target\u2217log(input+eps)."}, {"name": "full", "type": "bool", "default_value": "False", "is_optional": true, "description": "whether to compute full loss, i. e. to add theStirling approximation termtarget\u2217log\u2061(target)\u2212target+0.5\u2217log\u2061(2\u03c0target).\\text{target}*\\log(\\text{target}) - \\text{target} + 0.5 * \\log(2\\pi\\text{target}).target\u2217log(target)\u2212target+0.5\u2217log(2\u03c0target)."}, {"name": "eps", "type": "float", "default_value": "1e-8", "is_optional": true, "description": "Small value to avoid evaluation of log\u2061(0)\\log(0)log(0) whenlog_input = False. Default: 1e-8"}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch.nn.KLDivLoss", "type": "class", "code": "torch.nn.KLDivLoss(size_average=None,reduce=None,reduction:str='mean',log_target:bool=False)", "example": "NA", "summary": "The Kullback-Leibler divergence Loss KL divergence is a useful distance measure for continuous distributions and is often useful when performing direct regression over the space of (discretely sampled) continuous output distributions", "returns": [], "shape": "", "code-info": {"name": "torch.nn.KLDivLoss", "parameters": [{"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'batchmean' | 'sum' | 'mean'.'none': no reduction will be applied.'batchmean': the sum of the output will be divided by batchsize.'sum': the output will be summed.'mean': the output will be divided by the number of elements in the output.Default: 'mean'"}, {"name": "log_target", "type": "bool", "default_value": "False", "is_optional": true, "description": "Specifies whether target is passed in the log space.Default: False"}]}},
{"id": "torch.trapz", "type": "function", "code": "torch.trapz()", "example": "  y = torch.randn((2, 3))  y tensor([[-2.1156,  0.6857, -0.2700],         [-1.2145,  0.5540,  2.0431]])  x = torch.tensor([[1, 3, 4], [1, 2, 3]])  torch.trapz(y, x) tensor([-1.2220,  0.9683])     torch.trapz(y, *, dx=1, dim=-1) \u2192 Tensor   As above, but the sample points are spaced uniformly at a distance of dx.  Parameters  y (Tensor) \u2013 The values of the function to integrate dx (python:float) \u2013 The distance between points at which y is sampled. dim (python:int) \u2013 The dimension along which to integrate. By default, use the last dimension.   Returns A Tensor with the same shape as the input, except with dim removed. Each element of the returned tensor represents the estimated integral \u222by\u2009dx\\int y\\,dx\u222bydx   along dim.   ", "summary": "  torch.trapz(y, x, *, dim=-1) \u2192 Tensor   Estimate \u222by\u2009dx\\int y\\,dx\u222bydx   along dim, using the trapezoid rule", "returns": "A Tensor with the same shape as the input, except with dim removed.Each element of the returned tensor represents the estimated integral\u222by\u2009dx\\int y\\,dx\u222bydx along dim.", "shape": "NA", "code-info": {"name": "torch.trapz", "parameters": []}},
{"id": "NA", "type": "function", "code": "NA(y,x,*,dim=-1)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "y", "is_optional": false, "type": "others", "description": ""}, {"name": "x", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}]}},
{"id": "NA", "type": "function", "code": "NA(y,*,dx=1,dim=-1)", "example": "NA", "summary": "", "returns": null, "shape": "NA", "code-info": {"name": "NA", "parameters": [{"name": "y", "is_optional": false, "type": "others", "description": ""}, {"name": "*", "is_optional": false, "type": "others", "description": ""}, {"name": "dx", "is_optional": true, "type": "int", "default_value": "1", "description": ""}, {"name": "dim", "is_optional": true, "type": "others", "default_value": "-1", "description": ""}]}},
{"id": "torch.triangular_solve", "type": "function", "code": "torch.triangular_solve(input,A,upper=True,transpose=False,unitriangular=False)", "example": " A = torch.randn(2, 2).triu()\n A\ntensor([[ 1.1527, -1.0753],\n        [ 0.0000,  0.7986]])\n b = torch.randn(2, 3)\n b\ntensor([[-0.0210,  2.3513, -1.5492],\n        [ 1.5429,  0.7403, -1.0243]])\n torch.triangular_solve(b, A)\ntorch.return_types.triangular_solve(\nsolution=tensor([[ 1.7841,  2.9046, -2.5405],\n        [ 1.9320,  0.9270, -1.2826]]),\ncloned_coefficient=tensor([[ 1.1527, -1.0753],\n        [ 0.0000,  0.7986]]))\n\n", "summary": "Solves a system of equations with a triangular coefficient matrix AAA   and multiple right-hand sides bbb  ", "returns": "A namedtuple (solution, cloned_coefficient) where cloned_coefficientis a clone of AAA and solution is the solution XXX to AX=bAX = bAX=b(or whatever variant of the system of equations, depending on the keyword arguments.)", "shape": "NA", "code-info": {"name": "torch.triangular_solve", "parameters": [{"name": "input", "is_optional": false, "type": "Tensor", "description": " multiple right-hand sides of size (\u2217,m,k(*, m, k(\u2217,m,k where\u2217*\u2217 is zero of more batch dimensions (bbb"}, {"name": "A", "is_optional": false, "type": "Tensor", "description": " the input triangular coefficient matrix of size (\u2217,m,m(*, m, m(\u2217,m,mwhere \u2217*\u2217 is zero or more batch dimensions"}, {"name": "upper", "is_optional": true, "type": "bool", "default_value": "True", "description": " whether to solve the upper-triangular systemof equations (default or the lower-triangular system of equations. Default"}, {"name": "transpose", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether AAA should be transposed beforebeing sent into the solver. Default"}, {"name": "unitriangular", "is_optional": true, "type": "bool", "default_value": "False", "description": " whether AAA is unit triangular.If True, the diagonal elements of AAA are assumed to be1 and not referenced from AAA. Default"}]}},
{"id": "torch.nn.BCELoss", "type": "class", "code": "torch.nn.BCELoss(weight:Optional[torch.Tensor]=None,size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Creates a criterion that measures the Binary Cross Entropy between the target and the output: The unreduced (i.e", "returns": [], "shape": "", "code-info": {"name": "torch.nn.BCELoss", "parameters": [{"name": "weight", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "a manual rescaling weight given to the lossof each batch element. If given, has to be a Tensor of size nbatch."}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch.nn.BCEWithLogitsLoss", "type": "class", "code": "torch.nn.BCEWithLogitsLoss(weight:Optional[torch.Tensor]=None,size_average=None,reduce=None,reduction:str='mean',pos_weight:Optional[torch.Tensor]=None)", "example": "NA", "summary": "This loss combines a Sigmoid layer and the BCELoss in one single class", "returns": [], "shape": "\n\nInput: (N,\u2217)(N, *)(N,\u2217)\n\n where \u2217*\u2217\n\n means, any number of additional dimensions\nTarget: (N,\u2217)(N, *)(N,\u2217)\n\n, same shape as the input\nOutput: scalar. If reduction is 'none', then (N,\u2217)(N, *)(N,\u2217)\n\n, same\nshape as input.\n\n\nExamples:\n&gt;&gt;&gt; loss = nn.BCEWithLogitsLoss()\n&gt;&gt;&gt; input = torch.randn(3, requires_grad=True)\n&gt;&gt;&gt; target = torch.empty(3).random_(2)\n&gt;&gt;&gt; output = loss(input, target)\n&gt;&gt;&gt; output.backward()\n\n\n", "code-info": {"name": "torch.nn.BCEWithLogitsLoss", "parameters": [{"name": "weight", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "a manual rescaling weight given to the lossof each batch element. If given, has to be a Tensor of size nbatch."}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}, {"name": "pos_weight", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "a weight of positive examples.Must be a vector with length equal to the number of classes."}]}},
{"id": "torch.compiled_with_cxx11_abi", "type": "function", "code": "torch.compiled_with_cxx11_abi()", "example": "NA", "summary": "Returns whether PyTorch was built with _GLIBCXX_USE_CXX11_ABI=1 ", "returns": null, "shape": "NA", "code-info": {"name": "torch.compiled_with_cxx11_abi", "parameters": []}},
{"id": "torch.result_type", "type": "function", "code": "torch.result_type(tensor1,tensor2)", "example": "  torch.result_type(torch.tensor([1, 2], dtype=torch.int), 1.0) torch.float32  torch.result_type(torch.tensor([1, 2], dtype=torch.uint8), torch.tensor(1)) torch.uint8   ", "summary": "Returns the torch.dtype that would result from performing an arithmetic operation on the provided input tensors", "returns": null, "shape": "NA", "code-info": {"name": "torch.result_type", "parameters": [{"name": "tensor1", "is_optional": false, "type": "Tensor or Number", "description": " an input tensor or number"}, {"name": "tensor2", "is_optional": false, "type": "Tensor or Number", "description": " an input tensor or number"}]}},
{"id": "torch.can_cast", "type": "function", "code": "torch.can_cast(from,to)", "example": "  torch.can_cast(torch.double, torch.float) True  torch.can_cast(torch.float, torch.int) False   ", "summary": "Determines if a type conversion is allowed under PyTorch casting rules described in the type promotion documentation", "returns": null, "shape": "NA", "code-info": {"name": "torch.can_cast", "parameters": [{"name": "from", "is_optional": false, "type": "dtype", "description": " The original torch.dtype."}, {"name": "to", "is_optional": false, "type": "dtype", "description": " The target torch.dtype."}]}},
{"id": "torch.promote_types", "type": "function", "code": "torch.promote_types(type1,type2)", "example": "  torch.promote_types(torch.int32, torch.float32)) torch.float32  torch.promote_types(torch.uint8, torch.long) torch.long   ", "summary": "Returns the torch.dtype with the smallest size and scalar kind that is not smaller nor of lower kind than either type1 or type2", "returns": [], "shape": "", "code-info": {"name": "torch.promote_types", "parameters": []}},
{"id": "torch._C.Generator.get_state", "type": "method", "code": "torch._C.Generator.get_state()", "example": "  g_cpu = torch.Generator()  g_cpu.get_state()   ", "summary": "Returns the Generator state as a torch.ByteTensor", "returns": "A torch.ByteTensor which contains all the necessary bitsto restore a Generator to a specific point in time.", "shape": "NA", "code-info": {"name": "torch._C.Generator.get_state", "parameters": []}},
{"id": "torch.nn.MarginRankingLoss", "type": "class", "code": "torch.nn.MarginRankingLoss(margin:float=0.0,size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Creates a criterion that measures the loss given inputs x1x1x1  , x2x2x2  , two 1D mini-batch Tensors, and a label 1D mini-batch tensor yyy   (containing 1 or -1)", "returns": [], "shape": "", "code-info": {"name": "torch.nn.MarginRankingLoss", "parameters": [{"name": "margin", "type": "float", "default_value": "0.0", "is_optional": true, "description": "Has a default value of 000."}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch.nn.HingeEmbeddingLoss", "type": "class", "code": "torch.nn.HingeEmbeddingLoss(margin:float=1.0,size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Measures the loss given an input tensor xxx   and a labels tensor yyy   (containing 1 or -1)", "returns": [], "shape": "", "code-info": {"name": "torch.nn.HingeEmbeddingLoss", "parameters": [{"name": "margin", "type": "float", "default_value": "1.0", "is_optional": true, "description": "Has a default value of 1."}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch._C.Generator.initial_seed", "type": "method", "code": "torch._C.Generator.initial_seed()", "example": "  g_cpu = torch.Generator()  g_cpu.initial_seed() 2147483647   ", "summary": "Returns the initial seed for generating random numbers", "returns": null, "shape": "NA", "code-info": {"name": "torch._C.Generator.initial_seed", "parameters": []}},
{"id": "torch._C.Generator.manual_seed", "type": "method", "code": "torch._C.Generator.manual_seed(seed)", "example": "  g_cpu = torch.Generator()  g_cpu.manual_seed(2147483647)   ", "summary": "Sets the seed for generating random numbers", "returns": "An torch.Generator object.", "shape": "NA", "code-info": {"name": "torch._C.Generator.manual_seed", "parameters": [{"name": "seed", "is_optional": false, "type": "int", "description": " The desired seed."}]}},
{"id": "torch._C.Generator.seed", "type": "method", "code": "torch._C.Generator.seed()", "example": "  g_cpu = torch.Generator()  g_cpu.seed() 1516516984916   ", "summary": "Gets a non-deterministic random number from std::random_device or the current time and uses it to seed a Generator", "returns": null, "shape": "NA", "code-info": {"name": "torch._C.Generator.seed", "parameters": []}},
{"id": "torch._C.Generator.set_state", "type": "method", "code": "torch._C.Generator.set_state(new_state)", "example": "  g_cpu = torch.Generator()  g_cpu_other = torch.Generator()  g_cpu.set_state(g_cpu_other.get_state())   ", "summary": "Sets the Generator state", "returns": null, "shape": "NA", "code-info": {"name": "torch._C.Generator.set_state", "parameters": [{"name": "new_state", "is_optional": false, "type": "torch.ByteTensor", "description": " The desired state."}]}},
{"id": "torch.quasirandom.SobolEngine.draw", "type": "method", "code": "torch.quasirandom.SobolEngine.draw(n=1,out=None,dtype=torch.float32)", "example": "NA", "summary": "Function to draw a sequence of n points from a Sobol sequence", "returns": null, "shape": "NA", "code-info": {"name": "torch.quasirandom.SobolEngine.draw", "parameters": [{"name": "n", "is_optional": true, "type": "int", "default_value": "1", "description": " The length of sequence of points to draw.Default"}, {"name": "out", "is_optional": true, "type": "Tensor, optional", "default_value": "None", "description": " The output tensor"}, {"name": "dtype", "is_optional": true, "type": "torch.dtype, optional", "default_value": "torch.float32", "description": " the desired data type of thereturned tensor.Default"}]}},
{"id": "torch.quasirandom.SobolEngine.fast_forward", "type": "method", "code": "torch.quasirandom.SobolEngine.fast_forward(n)", "example": "NA", "summary": "Function to fast-forward the state of the SobolEngine by n steps", "returns": null, "shape": "NA", "code-info": {"name": "torch.quasirandom.SobolEngine.fast_forward", "parameters": [{"name": "n", "is_optional": false, "type": "Int", "description": " The number of steps to fast-forward by."}]}},
{"id": "torch.quasirandom.SobolEngine.reset", "type": "method", "code": "torch.quasirandom.SobolEngine.reset()", "example": "NA", "summary": "Function to reset the SobolEngine to base state", "returns": null, "shape": "NA", "code-info": {"name": "torch.quasirandom.SobolEngine.reset", "parameters": []}},
{"id": "torch._C.Generator", "type": "class", "code": "torch._C.Generator(device='cpu')", "example": "  g_cpu = torch.Generator()  g_cuda = torch.Generator(device='cuda')     device Generator.device - device Gets the current device of the generator. ", "summary": "Creates and returns a generator object which manages the state of the algorithm that produces pseudo random numbers", "returns": "An torch.Generator object.", "shape": "NA", "code-info": {"name": "torch._C.Generator", "parameters": [{"name": "device", "is_optional": true, "type": "string", "default_value": "'cpu'", "description": " the desired device for the generator."}]}},
{"id": "torch.nn.MultiLabelMarginLoss", "type": "class", "code": "torch.nn.MultiLabelMarginLoss(size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Creates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input xxx   (a 2D mini-batch Tensor) and output yyy   (which is a 2D Tensor of target class indices)", "returns": [], "shape": "", "code-info": {"name": "torch.nn.MultiLabelMarginLoss", "parameters": [{"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch.nn.SmoothL1Loss", "type": "class", "code": "torch.nn.SmoothL1Loss(size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Creates a criterion that uses a squared term if the absolute element-wise error falls below 1 and an L1 term otherwise", "returns": [], "shape": "", "code-info": {"name": "torch.nn.SmoothL1Loss", "parameters": [{"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch._C.Generator.device", "type": "attribute", "code": "torch._C.Generator.device", "example": "  g_cpu = torch.Generator()  g_cpu.device device(type='cpu')   ", "summary": "Generator.device -&gt; device Gets the current device of the generator", "returns": null, "shape": "NA", "code-info": {"name": "torch._C.Generator.device", "parameters": []}},
{"id": "torch.quasirandom.SobolEngine", "type": "class", "code": "torch.quasirandom.SobolEngine(dimension,scramble=False,seed=None)", "example": " soboleng = torch.quasirandom.SobolEngine(dimension=5)\n soboleng.draw(3)\ntensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n        [0.7500, 0.2500, 0.7500, 0.2500, 0.7500],\n        [0.2500, 0.7500, 0.2500, 0.7500, 0.2500]])\n\n", "summary": "The torch.quasirandom.SobolEngine is an engine for generating (scrambled) Sobol sequences", "returns": null, "shape": "NA", "code-info": {"name": "torch.quasirandom.SobolEngine", "parameters": [{"name": "dimension", "is_optional": false, "type": "Int", "description": " The dimensionality of the sequence to be drawn"}, {"name": "scramble", "is_optional": true, "type": "bool", "default_value": "False", "description": " Setting this to True will producescrambled Sobol sequences. Scrambling iscapable of producing better Sobolsequences. Default"}, {"name": "seed", "is_optional": true, "type": "Int, optional", "default_value": "None", "description": " This is the seed for the scrambling. The seedof the random number generator is set to this,if specified. Otherwise, it uses a random seed.Default"}]}},
{"id": "torch.nn.SoftMarginLoss", "type": "class", "code": "torch.nn.SoftMarginLoss(size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Creates a criterion that optimizes a two-class classification logistic loss between input tensor xxx   and target tensor yyy   (containing 1 or -1)", "returns": [], "shape": "", "code-info": {"name": "torch.nn.SoftMarginLoss", "parameters": [{"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch.nn.MultiLabelSoftMarginLoss", "type": "class", "code": "torch.nn.MultiLabelSoftMarginLoss(weight:Optional[torch.Tensor]=None,size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Creates a criterion that optimizes a multi-label one-versus-all loss based on max-entropy, between input xxx   and target yyy   of size (N,C)(N, C)(N,C)  ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.MultiLabelSoftMarginLoss", "parameters": [{"name": "weight", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "a manual rescaling weight given to eachclass. If given, it has to be a Tensor of size C. Otherwise, it istreated as if having all ones."}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch.nn.CosineEmbeddingLoss", "type": "class", "code": "torch.nn.CosineEmbeddingLoss(margin:float=0.0,size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Creates a criterion that measures the loss given input tensors x1x_1x1\u200b  , x2x_2x2\u200b   and a Tensor label yyy   with values 1 or -1", "returns": [], "shape": "", "code-info": {"name": "torch.nn.CosineEmbeddingLoss", "parameters": [{"name": "margin", "type": "float", "default_value": "0.0", "is_optional": true, "description": "Should be a number from \u22121-1\u22121 to 111,000 to 0.50.50.5 is suggested. If margin is missing, thedefault value is 000."}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch.nn.MultiMarginLoss", "type": "class", "code": "torch.nn.MultiMarginLoss(p:int=1,margin:float=1.0,weight:Optional[torch.Tensor]=None,size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Creates a criterion that optimizes a multi-class classification hinge loss (margin-based loss) between input xxx   (a 2D mini-batch Tensor) and output yyy   (which is a 1D tensor of target class indices, 0\u2264y\u2264x.size(1)\u221210 \\leq y \\leq \\text{x.size}(1)-10\u2264y\u2264x.size(1)\u22121  ): For each mini-batch sample, the loss in terms of the 1D input xxx   and scalar output yyy   is:  loss(x,y)=\u2211imax\u2061(0,margin\u2212x[y]+x[i]))px.size(0)\\text{loss}(x, y) = \\frac{\\sum_i \\max(0, \\text{margin} - x[y] + x[i]))^p}{\\text{x.size}(0)}  loss(x,y)=x.size(0)\u2211i\u200bmax(0,margin\u2212x[y]+x[i]))p\u200b  where x\u2208{0,\u2005\u200a\u22ef\u2009,\u2005\u200ax.size(0)\u22121}x \\in \\left\\{0, \\; \\cdots , \\; \\text{x.size}(0) - 1\\right\\}x\u2208{0,\u22ef,x.size(0)\u22121}   and i\u2260yi \\neq yi\ue020\u200b=y  ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.MultiMarginLoss", "parameters": [{"name": "p", "type": "int", "default_value": "1", "is_optional": true, "description": "Has a default value of 111. 111 and 222are the only supported values."}, {"name": "margin", "type": "float", "default_value": "1.0", "is_optional": true, "description": "Has a default value of 111."}, {"name": "weight", "type": "Optional[torch.Tensor]", "default_value": "None", "is_optional": true, "description": "a manual rescaling weight given to eachclass. If given, it has to be a Tensor of size C. Otherwise, it istreated as if having all ones."}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch.nn.TripletMarginLoss", "type": "class", "code": "torch.nn.TripletMarginLoss(margin:float=1.0,p:float=2.0,eps:float=1e-06,swap:bool=False,size_average=None,reduce=None,reduction:str='mean')", "example": "NA", "summary": "Creates a criterion that measures the triplet loss given an input tensors x1x1x1  , x2x2x2  , x3x3x3   and a margin with a value greater than 000  ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.TripletMarginLoss", "parameters": [{"name": "margin", "type": "float", "default_value": "111", "is_optional": true, "description": "Default: 111."}, {"name": "p", "type": "float", "default_value": "222", "is_optional": true, "description": "The norm degree for pairwise distance. Default: 222."}, {"name": "eps", "type": "float", "default_value": "1e-06", "is_optional": false, "description": ""}, {"name": "swap", "type": "bool", "default_value": "False", "is_optional": true, "description": "The distance swap is described in detail in the paperLearning shallow convolutional feature descriptors with triplet losses byV. Balntas, E. Riba et al. Default: False."}, {"name": "reduction", "type": "str", "default_value": "'mean'", "is_optional": true, "description": "Specifies the reduction to apply to the output:'none' | 'mean' | 'sum'. 'none': no reduction will be applied,'mean': the sum of the output will be divided by the number ofelements in the output, 'sum': the output will be summed. Note: size_averageand reduce are in the process of being deprecated, and in the meantime,specifying either of those two args will override reduction. Default: 'mean'"}]}},
{"id": "torch.nn.PixelShuffle", "type": "class", "code": "torch.nn.PixelShuffle(upscale_factor:int)", "example": "NA", "summary": "Rearranges elements in a tensor of shape (\u2217,C\u00d7r2,H,W)(*, C \\times r^2, H, W)(\u2217,C\u00d7r2,H,W)   to a tensor of shape (\u2217,C,H\u00d7r,W\u00d7r)(*, C, H \\times r, W \\times r)(\u2217,C,H\u00d7r,W\u00d7r)  ", "returns": [], "shape": "", "code-info": {"name": "torch.nn.PixelShuffle", "parameters": [{"name": "upscale_factor", "type": "int", "is_optional": false, "description": "factor to increase spatial resolution by"}]}},
{"id": "torch.nn.Upsample", "type": "class", "code": "torch.nn.Upsample(size:Optional[Union[T,Tuple[T,...]]]=None,scale_factor:Optional[Union[T,Tuple[T,...]]]=None,mode:str='nearest',align_corners:Optional[bool]=None)", "example": "NA", "summary": "Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data", "returns": [], "shape": "", "code-info": {"name": "torch.nn.Upsample", "parameters": [{"name": "size", "type": "Optional[Union[T,Tuple[T,...]]]", "default_value": "None", "is_optional": true, "description": "output spatial sizes"}, {"name": "scale_factor", "type": "Optional[Union[T,Tuple[T,...]]]", "default_value": "None", "is_optional": true, "description": "multiplier for spatial size. Has to match input size if it is a tuple."}, {"name": "mode", "type": "str", "default_value": "'nearest'", "is_optional": true, "description": "the upsampling algorithm: one of 'nearest','linear', 'bilinear', 'bicubic' and 'trilinear'.Default: 'nearest'"}, {"name": "align_corners", "type": "Optional[bool]", "default_value": "False", "is_optional": true, "description": "if True, the corner pixels of the inputand output tensors are aligned, and thus preserving the values atthose pixels. This only has effect when mode is'linear', 'bilinear', or 'trilinear'. Default: False"}]}},
{"id": "torch.nn.UpsamplingNearest2d", "type": "class", "code": "torch.nn.UpsamplingNearest2d(size:Optional[Union[T,Tuple[T,T]]]=None,scale_factor:Optional[Union[T,Tuple[T,T]]]=None)", "example": "NA", "summary": "Applies a 2D nearest neighbor upsampling to an input signal composed of several input channels", "returns": [], "shape": "", "code-info": {"name": "torch.nn.UpsamplingNearest2d", "parameters": [{"name": "size", "type": "Optional[Union[T,Tuple[T,T]]]", "default_value": "None", "is_optional": true, "description": "output spatial sizes"}, {"name": "scale_factor", "type": "Optional[Union[T,Tuple[T,T]]]", "default_value": "None", "is_optional": true, "description": "multiplier forspatial size."}]}},
{"id": "torch.nn.UpsamplingBilinear2d", "type": "class", "code": "torch.nn.UpsamplingBilinear2d(size:Optional[Union[T,Tuple[T,T]]]=None,scale_factor:Optional[Union[T,Tuple[T,T]]]=None)", "example": "NA", "summary": "Applies a 2D bilinear upsampling to an input signal composed of several input channels", "returns": [], "shape": "", "code-info": {"name": "torch.nn.UpsamplingBilinear2d", "parameters": [{"name": "size", "type": "Optional[Union[T,Tuple[T,T]]]", "default_value": "None", "is_optional": true, "description": "output spatial sizes"}, {"name": "scale_factor", "type": "Optional[Union[T,Tuple[T,T]]]", "default_value": "None", "is_optional": true, "description": "multiplier forspatial size."}]}},
{"id": "torch.nn.DataParallel", "type": "class", "code": "torch.nn.DataParallel(module,device_ids=None,output_device=None,dim=0)", "example": "  net = torch.nn.DataParallel(model, device_ids=[0, 1, 2])  output = net(input_var)  # input_var can be on any device, including CPU   ", "summary": "Implements data parallelism at the module level", "returns": [], "shape": "", "code-info": {"name": "torch.nn.DataParallel", "parameters": []}},
{"id": "torch.nn.parallel.DistributedDataParallel", "type": "class", "code": "torch.nn.parallel.DistributedDataParallel(module,device_ids=None,output_device=None,dim=0,broadcast_buffers=True,process_group=None,bucket_cap_mb=25,find_unused_parameters=False,check_reduction=False)", "example": ": import torch.distributed.autograd as dist_autograd  from torch.nn.parallel import DistributedDataParallel as DDP  from torch import optim  from torch.distributed.optim import DistributedOptimizer  from torch.distributed.rpc import RRef   t1 = torch.rand((3, 3), requires_grad=True)  t2 = torch.rand((3, 3), requires_grad=True)  rref = rpc.remote(\"worker1\", torch.add, args=(t1, t2))  ddp_model = DDP(my_model)   # Setup optimizer  optimizer_params = [rref]  for param in ddp_model.parameters():      optimizer_params.append(RRef(param))   dist_optim = DistributedOptimizer(      optim.SGD,      optimizer_params,      lr=0.05,  )   with dist_autograd.context() as context_id:      pred = ddp_model(rref.to_here())      loss = loss_func(pred, loss)      dist_autograd.backward(context_id, loss)      dist_optim.step()      Warning Using DistributedDataParallel in conjuction with the Distributed RPC Framework is experimental and subject to change.   Parameters  module (Module) \u2013 module to be parallelized device_ids (list of python:int or torch.device) \u2013 CUDA devices. This should only be provided when the input module resides on a single CUDA device. For single-device modules, the i``th :attr:`module` replica is placed on ``device_ids[i]. For multi-device modules and CPU modules, device_ids must be None or an empty list, and input data for the forward pass must be placed on the correct device. (default: all devices for single-device modules) output_device (int or torch.device) \u2013 device location of output for single-device CUDA modules. For multi-device modules and CPU modules, it must be None, and the module itself dictates the output location. (default: device_ids[0] for single-device modules) broadcast_buffers (bool) \u2013 flag that enables syncing (broadcasting) buffers of the module at beginning of the forward function. (default: True) process_group \u2013 the process group to be used for distributed data all-reduction. If None, the default process group, which is created by `torch.distributed.init_process_group`, will be used. (default: None) bucket_cap_mb \u2013 DistributedDataParallel will bucket parameters into multiple buckets so that gradient reduction of each bucket can potentially overlap with backward computation. bucket_cap_mb controls the bucket size in MegaBytes (MB) (default: 25) find_unused_parameters (bool) \u2013 Traverse the autograd graph of all tensors contained in the return value of the wrapped module\u2019s forward function. Parameters that don\u2019t receive gradients as part of this graph are preemptively marked as being ready to be reduced. Note that all forward outputs that are derived from module parameters must participate in calculating loss and later the gradient computation. If they don\u2019t, this wrapper will hang waiting for autograd to produce gradients for those parameters. Any outputs derived from module parameters that are otherwise unused can be detached from the autograd graph using torch.Tensor.detach. (default: False) check_reduction \u2013 when setting to True, it enables DistributedDataParallel to automatically check if the previous iteration\u2019s backward reductions were successfully issued at the beginning of every iteration\u2019s forward function. You normally don\u2019t need this option enabled unless you are observing weird behaviors such as different ranks are getting different gradients, which should not happen if DistributedDataParallel is correctly used. (default: False)   Variables ~DistributedDataParallel.module (Module) \u2013 the module to be parallelized   ", "summary": "Implements distributed data parallelism that is based on torch.distributed package at the module level", "returns": [], "shape": "", "code-info": {"name": "torch.nn.parallel.DistributedDataParallel", "parameters": []}},
{"id": "torch.nn.utils.prune.BasePruningMethod", "type": "class", "code": "torch.nn.utils.prune.BasePruningMethod", "example": "NA", "summary": "Abstract base class for creation of new pruning techniques", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.BasePruningMethod", "parameters": []}},
{"id": "torch.nn.utils.prune.PruningContainer", "type": "class", "code": "torch.nn.utils.prune.PruningContainer(*args)", "example": "NA", "summary": "Container holding a sequence of pruning methods for iterative pruning", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.PruningContainer", "parameters": []}},
{"id": "torch.nn.utils.prune.Identity", "type": "class", "code": "torch.nn.utils.prune.Identity", "example": "NA", "summary": "Utility pruning method that does not prune any units but generates the pruning parametrization with a mask of ones", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.Identity", "parameters": []}},
{"id": "torch.nn.utils.prune.RandomUnstructured", "type": "class", "code": "torch.nn.utils.prune.RandomUnstructured(amount)", "example": "NA", "summary": "Prune (currently unpruned) units in a tensor at random", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.RandomUnstructured", "parameters": []}},
{"id": "torch.nn.utils.prune.L1Unstructured", "type": "class", "code": "torch.nn.utils.prune.L1Unstructured(amount)", "example": "NA", "summary": "Prune (currently unpruned) units in a tensor by zeroing out the ones with the lowest L1-norm", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.L1Unstructured", "parameters": []}},
{"id": "torch.nn.utils.prune.RandomStructured", "type": "class", "code": "torch.nn.utils.prune.RandomStructured(amount,dim=-1)", "example": "NA", "summary": "Prune entire (currently unpruned) channels in a tensor at random", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.RandomStructured", "parameters": []}},
{"id": "torch.nn.utils.prune.LnStructured", "type": "class", "code": "torch.nn.utils.prune.LnStructured(amount,n,dim=-1)", "example": "NA", "summary": "Prune entire (currently unpruned) channels in a tensor based on their Ln-norm", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.LnStructured", "parameters": []}},
{"id": "torch.nn.utils.prune.CustomFromMask", "type": "class", "code": "torch.nn.utils.prune.CustomFromMask(mask)", "example": "NA", "summary": "  classmethod apply(module, name, mask)  Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask", "returns": "pruned version of the input tensor", "shape": "", "code-info": {"name": "torch.nn.utils.prune.CustomFromMask", "parameters": []}},
{"id": "torch.nn.Flatten", "type": "class", "code": "torch.nn.Flatten(start_dim:int=1,end_dim:int=-1)", "example": "  @torch.no_grad()  def init_weights(m):      print(m)      if type(m) == nn.Linear:          m.weight.fill_(1.0)          print(m.weight)  net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))  net.apply(init_weights) Linear(in_features=2, out_features=2, bias=True) Parameter containing: tensor([[ 1.,  1.],         [ 1.,  1.]]) Linear(in_features=2, out_features=2, bias=True) Parameter containing: tensor([[ 1.,  1.],         [ 1.,  1.]]) Sequential(   (0): Linear(in_features=2, out_features=2, bias=True)   (1): Linear(in_features=2, out_features=2, bias=True) ) Sequential(   (0): Linear(in_features=2, out_features=2, bias=True)   (1): Linear(in_features=2, out_features=2, bias=True) )       bfloat16() \u2192 T Casts all floating point parameters and buffers to bfloat16 datatype.  Returns self  Return type Module       buffers(recurse: bool = True) \u2192 Iterator[torch.Tensor] Returns an iterator over module buffers.  Parameters recurse (bool) \u2013 if True, then yields buffers of this module and all submodules. Otherwise, yields only buffers that are direct members of this module.  Yields torch.Tensor \u2013 module buffer   ", "summary": "Flattens a contiguous range of dims into a tensor", "returns": "self", "shape": "\nInput: (N,\u2217dims)(N, *dims)(N,\u2217dims)\n\n\nOutput: (N,\u220f\u2217dims)(N, \\prod *dims)(N,\u220f\u2217dims)\n\n (for the default case).\n\n", "code-info": {"name": "torch.nn.Flatten", "parameters": [{"name": "start_dim", "type": "int", "default_value": "1", "is_optional": false, "description": ""}, {"name": "end_dim", "type": "int", "default_value": "-1", "is_optional": false, "description": ""}]}}]
