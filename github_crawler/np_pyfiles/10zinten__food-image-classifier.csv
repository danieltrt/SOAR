file_path,api_count,code
make_datasets.py,0,"b""import os\nfrom scipy.misc import imread, imresize, imsave\nfrom random import shuffle\n\nIMAGE_SIZE = 128\nDATASET_DIR = 'Gaze_UPMC_Food20/images'\nTRAIN_DIR = 'dataset/train_set/'\nTEST_DIR = 'dataset/test_set/'\n\n# save train and test image in train_set and test_set folder\ndef save_image(images, path, name):\n    for index, img in enumerate(images):\n        imsave(os.path.join(path, name + str(index) + '.jpg'), img)\n\n\ndef create_dataset(test_size):\n\n    for index, img_dir in enumerate(sorted(os.listdir(DATASET_DIR))):\n        datasets = []\n        dir_path = os.path.join(DATASET_DIR, img_dir)\n        for img in os.listdir(dir_path):\n            img_path = os.path.join(dir_path, img)\n            img = imresize(imread(img_path), (IMAGE_SIZE, IMAGE_SIZE))\n            datasets.append(img)\n\n        shuffle(datasets)\n        if not os.path.isdir(os.path.join(TRAIN_DIR, img_dir)):\n            os.makedirs(os.path.join(TRAIN_DIR, img_dir))\n        train_set = datasets[: len(datasets) - int(len(datasets) * test_size)]\n        save_image(train_set, os.path.join(TRAIN_DIR, img_dir), img_dir)\n\n        if not os.path.isdir(os.path.join(TEST_DIR, img_dir)):\n            os.makedirs(os.path.join(TEST_DIR, img_dir))\n        test_set = datasets[len(train_set):]\n        save_image(test_set, os.path.join(TEST_DIR, img_dir), img_dir)\n        del datasets[:]\n\nif __name__ == '__main__':\n    create_dataset(0.20)\n"""
rename_datasets.py,0,"b""''' This module rename the images in each class in a consistent manner\n    final name image of the datapoint will will be classname_count.extension\n'''\nimport os\nimport argparse\n\n\ndef rename(args):\n    for dir_name in os.listdir(args.dir):\n        dir_path = os.path.join(args.dir, dir_name)\n        count = 1\n        for img_name in os.listdir(dir_path):\n            img_path = os.path.join(dir_path, img_name)\n            extension = img_name.split('.')[-1]\n            os.rename(img_path, os.path.join(dir_path, dir_name + '_' + \\\n                                             str(count) + '.' + extension))\n            count += 1\n\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='renaming data to consisten name')\n    parser.add_argument('-d', '--dir', type=str, required=True,\n                        help='Location of Datasets')\n    args = parser.parse_args()\n    rename(args)\n"""
resnet50.py,1,"b'# -*- coding: utf-8 -*-\n\'\'\'ResNet50 model for Keras.\n# Reference:\n- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\nAdapted from code contributed by BigMoyan.\n\'\'\'\nfrom __future__ import print_function\n\nimport os\nimport numpy as np\nimport warnings\n\nfrom keras.layers import Input\nfrom keras import layers\nfrom keras.layers import Dense\nfrom keras.layers import Activation\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.models import Model\nfrom keras.preprocessing import image\nimport keras.backend as K\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.applications.imagenet_utils import _obtain_input_shape\nfrom keras.engine.topology import get_source_inputs\n\n\nWEIGHTS_PATH = \'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\'\nWEIGHTS_PATH_NO_TOP = \'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\'\n\n\ndef identity_block(input_tensor, kernel_size, filters, stage, block):\n    """"""The identity block is the block that has no conv layer at shortcut.\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n        filters: list of integers, the filterss of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: \'a\',\'b\'..., current block label, used for generating layer names\n    # Returns\n        Output tensor for the block.\n    """"""\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == \'channels_last\':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = \'res\' + str(stage) + block + \'_branch\'\n    bn_name_base = \'bn\' + str(stage) + block + \'_branch\'\n\n    x = Conv2D(filters1, (1, 1), name=conv_name_base + \'2a\')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + \'2a\')(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters2, kernel_size,\n               padding=\'same\', name=conv_name_base + \'2b\')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + \'2b\')(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv_name_base + \'2c\')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + \'2c\')(x)\n\n    x = layers.add([x, input_tensor])\n    x = Activation(\'relu\')(x)\n    return x\n\n\ndef conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n    """"""conv_block is the block that has a conv layer at shortcut\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n        filters: list of integers, the filterss of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: \'a\',\'b\'..., current block label, used for generating layer names\n    # Returns\n        Output tensor for the block.\n    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n    And the shortcut should have strides=(2,2) as well\n    """"""\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == \'channels_last\':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = \'res\' + str(stage) + block + \'_branch\'\n    bn_name_base = \'bn\' + str(stage) + block + \'_branch\'\n\n    x = Conv2D(filters1, (1, 1), strides=strides,\n               name=conv_name_base + \'2a\')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + \'2a\')(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters2, kernel_size, padding=\'same\',\n               name=conv_name_base + \'2b\')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + \'2b\')(x)\n    x = Activation(\'relu\')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv_name_base + \'2c\')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + \'2c\')(x)\n\n    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n                      name=conv_name_base + \'1\')(input_tensor)\n    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + \'1\')(shortcut)\n\n    x = layers.add([x, shortcut])\n    x = Activation(\'relu\')(x)\n    return x\n\n\ndef ResNet50(include_top=True, weights=\'imagenet\',\n             input_tensor=None, input_shape=None,\n             pooling=None,\n             classes=1000):\n    """"""Instantiates the ResNet50 architecture.\n    Optionally loads weights pre-trained\n    on ImageNet. Note that when using TensorFlow,\n    for best performance you should set\n    `image_data_format=""channels_last""` in your Keras config\n    at ~/.keras/keras.json.\n    The model and the weights are compatible with both\n    TensorFlow and Theano. The data format\n    convention used by the model is the one\n    specified in your Keras config file.\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization)\n            or ""imagenet"" (pre-training on ImageNet).\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 244)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 197.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    """"""\n    if weights not in {\'imagenet\', None}:\n        raise ValueError(\'The `weights` argument should be either \'\n                         \'`None` (random initialization) or `imagenet` \'\n                         \'(pre-training on ImageNet).\')\n\n    if weights == \'imagenet\' and include_top and classes != 1000:\n        raise ValueError(\'If using `weights` as imagenet with `include_top`\'\n                         \' as true, `classes` should be 1000\')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=197,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top)\n\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    if K.image_data_format() == \'channels_last\':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n\n    x = ZeroPadding2D((3, 3))(img_input)\n    x = Conv2D(64, (7, 7), strides=(2, 2), name=\'conv1\')(x)\n    x = BatchNormalization(axis=bn_axis, name=\'bn_conv1\')(x)\n    x = Activation(\'relu\')(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = conv_block(x, 3, [64, 64, 256], stage=2, block=\'a\', strides=(1, 1))\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block=\'b\')\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block=\'c\')\n\n    x = conv_block(x, 3, [128, 128, 512], stage=3, block=\'a\')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block=\'b\')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block=\'c\')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block=\'d\')\n\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block=\'a\')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=\'b\')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=\'c\')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=\'d\')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=\'e\')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=\'f\')\n\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block=\'a\')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=\'b\')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=\'c\')\n\n    x = AveragePooling2D((7, 7), name=\'avg_pool\')(x)\n\n    if include_top:\n        x = Flatten()(x)\n        x = Dense(classes, activation=\'softmax\', name=\'fc1000\')(x)\n    else:\n        if pooling == \'avg\':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == \'max\':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name=\'resnet50\')\n\n    # load weights\n    if weights == \'imagenet\':\n        PATH = os.getcwd()\n        if include_top:\n            weights_path = os.path.join(PATH, \'resnet50_weights_tf_dim_ordering_tf_kernels.h5\')\n            \'\'\' get_file(\'resnet50_weights_tf_dim_ordering_tf_kernels.h5\',\n                                    WEIGHTS_PATH,\n                                    cache_subdir=\'models\',\n                                    md5_hash=\'a7b3fe01876f51b976af0dea6bc144eb\') \'\'\'\n        else:\n            weights_path = os.path.join(PATH, \'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\')\n            \'\'\' get_file(\'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\',\n                                    WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir=\'models\',\n                                    md5_hash=\'a268eb855778b3df3c7506639542a6af\') \'\'\'\n        model.load_weights(weights_path)\n        if K.backend() == \'theano\':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == \'channels_first\':\n            if include_top:\n                maxpool = model.get_layer(name=\'avg_pool\')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name=\'fc1000\')\n                layer_utils.convert_dense_weights_data_format(dense, shape, \'channels_first\')\n\n            if K.backend() == \'tensorflow\':\n                warnings.warn(\'You are using the TensorFlow backend, yet you \'\n                              \'are using the Theano \'\n                              \'image data format convention \'\n                              \'(`image_data_format=""channels_first""`). \'\n                              \'For best performance, set \'\n                              \'`image_data_format=""channels_last""` in \'\n                              \'your Keras config \'\n                              \'at ~/.keras/keras.json.\')\n    return model\n\n\nif __name__ == \'__main__\':\n    model = ResNet50(include_top=True, weights=\'imagenet\')\n\n    img_path = \'elephant.jpg\'\n    img = image.load_img(img_path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    print(\'Input image shape:\', x.shape)\n\n    preds = model.predict(x)\n    print(\'Predicted:\', decode_predictions(preds))'"
foodImageClassifier/manage.py,0,"b'#!/usr/bin/env python\nimport os\nimport sys\n\nif __name__ == ""__main__"":\n    os.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""foodImageClassifier.settings"")\n    try:\n        from django.core.management import execute_from_command_line\n    except ImportError:\n        # The above import may fail for some other reason. Ensure that the\n        # issue is really that Django is missing to avoid masking other\n        # exceptions on Python 2.\n        try:\n            import django\n        except ImportError:\n            raise ImportError(\n                ""Couldn\'t import Django. Are you sure it\'s installed and ""\n                ""available on your PYTHONPATH environment variable? Did you ""\n                ""forget to activate a virtual environment?""\n            )\n        raise\n    execute_from_command_line(sys.argv)\n'"
foodImageClassifier/classifier/__init__.py,0,b''
foodImageClassifier/classifier/admin.py,0,"b""from django.contrib import admin\n\nfrom .models import Classifier\n\nclass ClassifierAdmin(admin.ModelAdmin):\n    list_display = ['image']\n\n    class Meta:\n        model = Classifier\n\nadmin.site.register(Classifier, ClassifierAdmin)\n"""
foodImageClassifier/classifier/apps.py,0,"b""from django.apps import AppConfig\n\n\nclass ClassifierConfig(AppConfig):\n    name = 'classifier'\n"""
foodImageClassifier/classifier/forms.py,0,"b""from django import forms\n\nclass ClassifierForm(forms.Form):\n    '''Image upload form.'''\n    image = forms.ImageField()\n"""
foodImageClassifier/classifier/models.py,0,"b""from django.db import models\nimport os\n\ndef path_and_rename(instance, filename):\n    upload_to = 'images'\n    ext = filename.split('.')[-1]\n    filename = '{}.{}'.format('dish', ext)\n    return os.path.join(upload_to, filename)\n\nclass Classifier(models.Model):\n    image = models.ImageField(upload_to=path_and_rename, default='images/None/no-img.jpg')\n"""
foodImageClassifier/classifier/tests.py,0,b'from django.test import TestCase\n\n# Create your tests here.\n'
foodImageClassifier/classifier/views.py,2,"b'import os\nfrom django.shortcuts import render\nfrom django.http import HttpResponse, HttpResponseRedirect\nfrom django.conf import settings\n\nfrom .forms import ClassifierForm\nfrom .models import Classifier\n\n# from scipy.misc import imresize, imsave\nfrom keras.models import model_from_json\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras import backend as K\nimport numpy as np\nfrom PIL import Image\nimport wikipedia as wk\nfrom bs4 import BeautifulSoup as bs\n\n# Path to input image\nmedia_path = os.path.join(os.path.dirname(settings.BASE_DIR), \'media_cdn/images\')\n\n# Model names\nindian_model_name = \'FIC-In-C7-B32-E11\'\nwestern_model_name = \'FIC-ResNet-50-TL-Model\'\n\n# Class names\nnames = [\'biryani\', \'mosa\', \'mulab Jamun\', \'malebi\', \'momo (food)\', \'samosa\', \'tandoori chicken\']\n\n# Model paths\nmodel_dir = os.path.join(os.path.dirname(settings.BASE_DIR), \'models\', \'keras\')\nmodel_arch_path = os.path.join(model_dir, indian_model_name + \'.json\')\nmodel_weight_path = os.path.join(model_dir, indian_model_name + \'.h5\')\n\n# load json and create model\njson_file = open(model_arch_path)\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n\n# load weights into new model\nloaded_model.load_weights(model_weight_path)\nprint(\'Loaded model from disk\')\n\ngraph = K.get_session().graph\n\n\ndef upload_img(request):\n\n    form = ClassifierForm(request.POST or None, request.FILES or None)\n    if form.is_valid():\n        m = Classifier()\n        m.image = form.cleaned_data[\'image\']\n        print(type(form.cleaned_data[\'image\']))\n        m.save()\n\n        # result = feedfowrd()\n        return HttpResponseRedirect(\'/predict\')\n\n    context = {\n        ""form"": form,\n    }\n    return render(request, \'indian_food.html\', context)\n\ndef parse_ingredients(dish_name):\n\n    # Extract dish page and convert into html\n    dish = wk.page(dish_name)\n    html = dish.html()\n\n    # Parse html and extract ingredients\n    soup = bs(html, \'html.parser\')\n    ingredient_table = soup.find_all(\'td\', class_=\'ingredient\')\n    ingredients = ingredient_table[0].find_all(\'a\')\n\n    # store all ingredients and return\n    ingredient_list = []\n\n    if not ingredients:\n        ing_string = ingredient_table[0].text\n        ing_string = ing_string[1:]\n        ing_string_list = ing_string.split(\'optional ingredients:\')\n        ingredients = ing_string_list[0].split(\',\') # [0] - main ingredients\n\n        for ingredient in ingredients:\n            ingredient_list.append(ingredient)\n\n        return ingredient_list\n\n    for ingredient in ingredients:\n        ingredient_list.append(ingredient.string)\n\n    return ingredient_list\n\n\ndef predict(request):\n\n    # Preprocess image\n    img_path = os.path.join(media_path, os.listdir(media_path)[0])\n    print(img_path)\n    img = image.load_img(img_path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    print(x.shape)\n\n    # Prediction\n    global graph\n    with graph.as_default():\n        preds = loaded_model.predict(x)\n\n    # Extract name of dish and ingredients\n    classes = [name.title() for name in names]\n    dish_name = classes[np.argmax(preds)]\n    context = {\n        \'dish_name\': dish_name,\n        \'ingredients\': parse_ingredients(dish_name)\n    }\n\n    print(context)\n\n    return render(request, \'result.html\', context)\n\ndef clean_up(request):\n    # Delete image instance from model\n    Classifier.objects.all().delete()\n\n    # Delete image from media directory\n    for img in os.listdir(media_path):\n        os.remove(os.path.join(media_path, img))\n\n    return HttpResponseRedirect(\'/\')\n'"
foodImageClassifier/foodImageClassifier/__init__.py,0,b''
foodImageClassifier/foodImageClassifier/settings.py,0,"b'""""""\nDjango settings for foodImageClassifier project.\n\nGenerated by \'django-admin startproject\' using Django 1.11.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/1.11/topics/settings/\n\nFor the full list of settings and their values, see\nhttps://docs.djangoproject.com/en/1.11/ref/settings/\n""""""\n\nimport os\n\n# Build paths inside the project like this: os.path.join(BASE_DIR, ...)\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n\n\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/1.11/howto/deployment/checklist/\n\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = \'on5bcz6%gsq)8plr3y(!*^#sg*gewqw+8wxhk$sfot4&(2++m3\'\n\n# SECURITY WARNING: don\'t run with debug turned on in production!\nDEBUG = True\n\nALLOWED_HOSTS = []\n\n\n# Application definition\n\nINSTALLED_APPS = [\n    \'django.contrib.admin\',\n    \'django.contrib.auth\',\n    \'django.contrib.contenttypes\',\n    \'django.contrib.sessions\',\n    \'django.contrib.messages\',\n    \'django.contrib.staticfiles\',\n    \'classifier\',\n]\n\nMIDDLEWARE = [\n    \'django.middleware.security.SecurityMiddleware\',\n    \'django.contrib.sessions.middleware.SessionMiddleware\',\n    \'django.middleware.common.CommonMiddleware\',\n    \'django.middleware.csrf.CsrfViewMiddleware\',\n    \'django.contrib.auth.middleware.AuthenticationMiddleware\',\n    \'django.contrib.messages.middleware.MessageMiddleware\',\n    \'django.middleware.clickjacking.XFrameOptionsMiddleware\',\n]\n\nROOT_URLCONF = \'foodImageClassifier.urls\'\n\nTEMPLATES = [\n    {\n        \'BACKEND\': \'django.template.backends.django.DjangoTemplates\',\n        \'DIRS\': [],\n        \'APP_DIRS\': True,\n        \'OPTIONS\': {\n            \'context_processors\': [\n                \'django.template.context_processors.debug\',\n                \'django.template.context_processors.request\',\n                \'django.contrib.auth.context_processors.auth\',\n                \'django.contrib.messages.context_processors.messages\',\n            ],\n        },\n    },\n]\n\nWSGI_APPLICATION = \'foodImageClassifier.wsgi.application\'\n\n\n# Database\n# https://docs.djangoproject.com/en/1.11/ref/settings/#databases\n\nDATABASES = {\n    \'default\': {\n        \'ENGINE\': \'django.db.backends.sqlite3\',\n        \'NAME\': os.path.join(BASE_DIR, \'db.sqlite3\'),\n    }\n}\n\n\n# Password validation\n# https://docs.djangoproject.com/en/1.11/ref/settings/#auth-password-validators\n\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.UserAttributeSimilarityValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.MinimumLengthValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.CommonPasswordValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.NumericPasswordValidator\',\n    },\n]\n\n\n# Internationalization\n# https://docs.djangoproject.com/en/1.11/topics/i18n/\n\nLANGUAGE_CODE = \'en-us\'\n\nTIME_ZONE = \'UTC\'\n\nUSE_I18N = True\n\nUSE_L10N = True\n\nUSE_TZ = True\n\n\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/1.11/howto/static-files/\n\nSTATIC_URL = \'/static/\'\nSTATIC_ROOT = os.path.join(os.path.dirname(BASE_DIR), ""static_cdn"")\n\nMEDIA_URL = \'/media/\'\nMEDIA_ROOT = os.path.join(os.path.dirname(BASE_DIR), ""media_cdn"")\n'"
foodImageClassifier/foodImageClassifier/urls.py,0,"b'""""""foodImageClassifier URL Configuration\n\nThe `urlpatterns` list routes URLs to views. For more information please see:\n    https://docs.djangoproject.com/en/1.11/topics/http/urls/\nExamples:\nFunction views\n    1. Add an import:  from my_app import views\n    2. Add a URL to urlpatterns:  url(r\'^$\', views.home, name=\'home\')\nClass-based views\n    1. Add an import:  from other_app.views import Home\n    2. Add a URL to urlpatterns:  url(r\'^$\', Home.as_view(), name=\'home\')\nIncluding another URLconf\n    1. Import the include() function: from django.conf.urls import url, include\n    2. Add a URL to urlpatterns:  url(r\'^blog/\', include(\'blog.urls\'))\n""""""\nfrom django.conf import settings\nfrom django.conf.urls import url\nfrom django.conf.urls.static import static\nfrom django.contrib import admin\nfrom classifier.views import upload_img, predict, clean_up\n\nurlpatterns = [\n    url(r\'^admin/\', admin.site.urls),\n    url(r\'^$\', upload_img, name=\'upload_img\'),\n    url(r\'^predict/$\', predict, name=\'predict\'),\n    url(r\'^back/$\', clean_up, name=\'clean_up\')\n]\n\nif settings.DEBUG:\n    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)\n    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)\n'"
foodImageClassifier/foodImageClassifier/wsgi.py,0,"b'""""""\nWSGI config for foodImageClassifier project.\n\nIt exposes the WSGI callable as a module-level variable named ``application``.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/1.11/howto/deployment/wsgi/\n""""""\n\nimport os\n\nfrom django.core.wsgi import get_wsgi_application\n\nos.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""foodImageClassifier.settings"")\n\napplication = get_wsgi_application()\n'"
foodImageClassifier/classifier/migrations/0001_initial.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.11 on 2017-12-13 15:32\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    initial = True\n\n    dependencies = [\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='Classifier',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('image', models.ImageField(upload_to='')),\n            ],\n        ),\n    ]\n"""
foodImageClassifier/classifier/migrations/0002_auto_20171215_0555.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.11 on 2017-12-15 05:55\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('classifier', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='classifier',\n            name='image',\n            field=models.ImageField(default='images/None/no-img.jpg', upload_to='images/'),\n        ),\n    ]\n"""
foodImageClassifier/classifier/migrations/0003_auto_20180213_1933.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.11 on 2018-02-13 19:33\nfrom __future__ import unicode_literals\n\nimport classifier.models\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('classifier', '0002_auto_20171215_0555'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='classifier',\n            name='image',\n            field=models.ImageField(default='images/None/no-img.jpg', upload_to=classifier.models.path_and_rename),\n        ),\n    ]\n"""
foodImageClassifier/classifier/migrations/__init__.py,0,b''
