file_path,api_count,code
common.py,9,"b'from collections import namedtuple\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport requests\nfrom sklearn import datasets\n\n\nData = namedtuple(\'Data\', [\'features\', \'target\', \'target1D\'])\n\n\ndef load_iris():\n    dataset = datasets.load_iris()\n    features = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n    target = pd.DataFrame(pd.get_dummies(dataset.target))\n    target.columns = dataset.target_names\n    assert features.shape[0] == target.shape[0]\n    print(\'The Iris dataset was used in R.A. Fisher\\\'s classic 1936 paper *The Use of Multiple Measurements in Taxonomic Problems*.\')\n    print(\'\')\n    print(\'features.shape = {}\'.format(features.shape))\n    print(\'target.shape = {}\'.format(target.shape))\n    return Data(features, target, pd.DataFrame(dataset.target, columns=[\'class\']))\n\n\ndef load_forest_fires():\n    os.makedirs(\'./data\', exist_ok=True)\n\n    files = [\'forestfires.csv\']\n    print(\'Downloading forest fires dataset - the aim is to predict the burned area of forest fires, in the northeast region of Portugal, by using meteorological and other data\')\n    print(""""""For more information, read [Cortez and Morais, 2007].\n        1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n        2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n        3. month - month of the year: \'jan\' to \'dec\'\n        4. day - day of the week: \'mon\' to \'sun\'\n        5. FFMC - FFMC index from the FWI system: 18.7 to 96.20\n        6. DMC - DMC index from the FWI system: 1.1 to 291.3\n        7. DC - DC index from the FWI system: 7.9 to 860.6\n        8. ISI - ISI index from the FWI system: 0.0 to 56.10\n        9. temp - temperature in Celsius degrees: 2.2 to 33.30\n        10. RH - relative humidity in %: 15.0 to 100\n        11. wind - wind speed in km/h: 0.40 to 9.40\n        12. rain - outside rain in mm/m2 : 0.0 to 6.4\n        13. area - the burned area of the forest (in ha): 0.00 to 1090.84\n    (this output variable is very skewed towards 0.0, thus it may make\n    sense to model with the logarithm transform).\')"""""")\n    for name in files:\n        res = requests.get(\'http://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/{}\'.format(name))\n        with open(\'./data/{}\'.format(name) , \'wb\') as f:\n            f.write(res.content)\n    data = pd.read_csv(\'./data/forestfires.csv\')\n    \n    print(\'\')\n    print(\'data.shape = {}\'.format(data.shape))\n    print(\'columns {}\'.format(list(data.columns)))\n    return data\n\n\ndef dirty_forest():\n    forest = load_forest_fires()\n\n    dirty = forest.copy()\n\n    for col in dirty:\n        print(col)\n        if dirty.loc[:, col].dtype == \'float64\':\n            mask = (np.random.rand(forest.shape[0]) > 0.98).astype(bool)\n            dirty.loc[mask, col] += 2 * dirty.loc[:, col].std()\n\n            mask = (np.random.rand(forest.shape[0]) > 0.98).astype(bool)\n            dirty.loc[mask, col] -= 2 * dirty.loc[:, col].std()\n\n    missing_mask = (np.random.rand(*forest.shape) > 0.95).astype(bool)\n\n    dirty[missing_mask] = np.nan\n\n\ndef make_pmf(samples):\n    uniq, counts = np.unique(samples, return_counts=True)\n    pmf = counts / np.sum(counts, axis=0)\n    return uniq, pmf\n\n\ndef percentile_rank(value, samples):\n    count = 0\n    return sum([count + 1 for s in samples if s <= value]) / len(samples)\n\n\ndef percentile(rank, samples):\n    samples = sorted(samples)\n    idx = int(rank * (len(samples) - 1))\n    return samples[idx]\n\n\ndef make_cdf(samples):\n    samples = sorted(samples)\n    return [(percentile_rank(s, samples), s) for s in sorted(samples)]\n\n\ndef generate_bandit_dataset(arms=20, samples=2):\n    np.random.seed(42)\n\n    Param = namedtuple(\'Parameter\', [\'loc\', \'scale\', \'initial_size\'])\n    start = 10\n    end = 50\n    num_options = arms\n\n    params = {\n        str(option): Param(loc, scale, samples) \n        for option, (loc, scale) \n        in enumerate(zip(np.linspace(start, end, num_options), np.random.uniform(10, size=num_options)))\n    }\n\n    return params, {\n        arm: list(np.random.normal(*stats))\n        for arm, stats in params.items()\n    }\n'"
data-science/answers.py,6,"b""import numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\n\n\ndef stability_selection_rf_regressor(x, y, params, depths, straps=4, k=5):\n    rows, cols = x.shape\n    regs = depths\n    scores = np.zeros((cols, depths.shape[0]))\n    for idx, reg in enumerate(regs.flatten()):\n\n        bootstrap_features = np.zeros((cols, straps))\n        for strap in range(straps):\n            sample = np.random.choice(np.arange(rows), size=rows//2, replace=False)\n\n            x_tr = x.values[sample, :]\n            y_tr = y.values[sample]\n            params['max_depth'] = reg\n            model = RandomForestRegressor(**params)\n            model.fit(x_tr, y_tr)\n\n            impts = model.feature_importances_\n            bootstrap_features[:, strap] = (impts > np.mean(impts)).astype(int)\n\n        scores[:, idx] = np.mean(bootstrap_features, axis=1)\n\n    feature_scores = np.mean(scores, axis=1).flatten()\n    feature_scores.shape[0] == x.shape[1]\n    best = feature_scores.argsort()[-k:][::-1]\n    return x.columns[best]"""
data-science/create_dataset.py,4,"b""import pandas as pd\nimport numpy as np\n\n\nds = pd.DataFrame([\n    {'customers-category': 'A', 'contract-length': 10, 'location': 'us'},\n    {'customers-category': 'A', 'contract-length': 9, 'location': 'us'},\n    {'customers-category': 'A', 'contract-length': 9, 'location': 'us'},\n\n    {'customers-category': 'B', 'contract-length': 20, 'location': 'nz'},\n    {'customers-category': 'B', 'contract-length': 30, 'location': np.nan},\n    {'customers-category': 'B', 'contract-length': 10, 'location': 'nz'},\n\n    {'customers-category': 'C', 'contract-length': np.nan, 'location': 'nz'},\n    {'customers-category': 'C', 'contract-length': 5, 'location': 'nz'},\n    {'customers-category': 'C', 'contract-length': np.nan, 'location': 'us'},\n    {'customers-category': np.nan, 'contract-length': 1, 'location': 'nz'},\n    {'customers-category': 'C', 'contract-length': 100, 'location': 'nz'},\n])"""
distributed-computing/async_counter.py,0,"b'import asyncio, time\n\n\nasync def count():\n    print(""One"")\n    await asyncio.sleep(1)\n    print(""Two"")\n\n    \nasync def main():\n    await asyncio.gather(count(), count(), count())\n    \n    \nif __name__ == ""__main__"":\n    s = time.perf_counter()\n    \n    #  in Python 3.7 you can do: \n    # asyncio.run(main())\n    \n    #  otherwise:\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(main())\n    \n    elapsed = time.perf_counter() - s\n    print(\'executed in {:0.2f} seconds\'.format(elapsed))'"
distributed-computing/evolution.py,12,"b""import os\nfrom os.path import join\n\nimport gym\nimport numpy as np\n\n\ndef forward_mountaincar(x, params):\n    #  sometimes gym gives (2, 1) from mountaincar\n    x = np.array(x).reshape(-1)\n    #  input -> hidden\n    z0 = x.dot(params['w0']) + params['b0']\n    #  relu\n    a0 = np.maximum(z0, 0)\n    #  hidden -> output\n    return a0.dot(params['w1']) + params['b1']\n\n\ndef forward_cartpole(x, params, threshold=0.5):\n    x = np.array(x).reshape(-1)\n    #  input -> hidden\n    z0 = x.dot(params['w0']) + params['b0']\n    #  relu\n    a0 = np.maximum(z0, 0)\n    #  hidden -> output\n    z1 = a0.dot(params['w1']) + params['b1']\n    #  sigmoid\n    a1 = 1 / (1 + np.exp(-z1))\n    return np.where(a1 > threshold, 1, 0)[0][0]\n\n\ndef make_env(env_id='CartPole-v0'):\n    env = gym.make(env_id)\n    if env_id == 'CartPole-v0':\n        return env, forward_cartpole, env.observation_space.shape[0], 1\n    elif env_id == 'MountainCarContinuous-v0':\n        return env, forward_mountaincar, env.observation_space.shape[0], env.action_space.shape[0]\n    else:\n        raise ValueError('env {} not supported'.format(env_id))\n\n\ndef initialize_parameters(i_size, h_size, o_size):\n    return {\n        'w0': np.random.randn(i_size, h_size),\n        'b0': np.zeros((1, h_size)),\n        'w1': np.random.randn(h_size, o_size),\n        'b1': np.zeros((1, o_size))\n    }\n\n\ndef episode(params, render=False, env_id='MountainCarContinuous-v0'):\n    env, forward, _, _ = make_env(env_id)\n    done = False\n    rewards = []\n    obs = env.reset()\n    while not done:\n        action = forward(obs, params)\n        next_obs, reward, done, info = env.step(action)\n        rewards.append(reward)\n        obs = next_obs\n        if render:\n            img = env.render(mode='human')\n    return sum(rewards)\n\n\ndef save_params(params, env_id, agent_id=0):\n    home = join('agents', env_id, 'agent_{}'.format(agent_id))\n    os.makedirs(home, exist_ok=True)\n    print('saving to {}'.format(home))\n    for k, arr in params.items():\n        np.save(join(home, '{}.npy'.format(k)), arr)\n\n\ndef load_params(env_id, agent_id):\n    home = join('agents', env_id, 'agent_{}'.format(agent_id))\n    print('loading from {}'.format(home))\n    params = [join(home, p) for p in os.listdir(home) if 'npy' in p]\n    return {\n        p.split('/')[-1].split('.')[0]: np.load(p) for p in params\n    }\n"""
distributed-computing/render.py,0,"b""import argparse\n\nfrom evolution import episode, load_params\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--env_id', default='CartPole-v0', nargs='?')\n    parser.add_argument('--agent_id', default=8, nargs='?')\n    args = parser.parse_args()\n    params = load_params(args.env_id, args.agent_id)\n    reward = episode(params, env_id=args.env_id, render=True)\n    print('total epsisode reward {}'.format(reward))\n"""
statistics/answers.py,24,"b""import math\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import entropy as entropy_from_probs\n\n\ndef central_limit():\n    num_plots = 12\n    nrows = 3\n    epochs = 5000\n\n    freq = int(epochs / num_plots)\n\n    def sample_means(iters=100):\n        return [\n            np.mean(pop[np.random.randint(0, pop.shape[0], size=100)])\n            for _ in range(iters)\n        ]\n\n    pop = np.random.uniform(0, 100, size=10000)\n\n    f, axes = plt.subplots(ncols=int(num_plots/nrows), nrows=nrows, figsize=(25, 10))\n    means = []\n    for num, ax in enumerate(axes.flatten()):\n        me = sample_means(freq)\n\n        s = []\n        for de in me:\n            if de > 50.0 and np.random.rand() > 0.5:\n                means.append(de)\n\n        pd.DataFrame(means).plot(ax=ax, kind='hist', legend=None, title=num*freq)\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n\ndef distributions():\n    name = 'temp'\n    data = raw.loc[:, name]\n\n    f = plt.hist(data)\n    _ = plt.ylabel('frequency')\n    _ = plt.xlabel(name)\n\n    percentile(0.25, data)\n    percentile(0.75, data)\n\n    rank = percentile_rank(10, data)\n    percentile(rank, raw.loc[:, 'wind'])\n\n\ndef entropy_from_classes(y):\n    probs = [sum(y == i) / len(y) for i in set(y)]\n    np.testing.assert_allclose(sum(probs), 1)\n    return entropy_from_probs(probs)\n\n\ndef expectation(results):\n    return {arm: np.mean(data) for arm, data in results.items()}\n\n\ndef cross_entropy_from_probs(p, q):\n    epsilon = 1e-16\n    return sum([-tr * math.log(est + epsilon, 2) for tr, est in zip(p, q)])\n\n\ndef run_bandit(eps, params, steps=5000):\n    print('bandit {}'.format(eps))\n    results = {\n        arm: list(np.random.normal(*stats))\n        for arm, stats in params.items()\n    }\n\n    choices = list(params.keys())\n\n    values = np.zeros((steps, len(choices)))\n    actions = np.empty((steps)).astype(str)\n    eps_performance = np.zeros(steps)\n\n    for step in range(steps):\n        prob = np.random.rand()\n        if prob < eps:\n            strat = 'random'\n            action = np.random.choice(choices)\n\n        else:\n            strat = 'greedy'\n            expectations = expectation(results)\n            values[step, :] = list(expectations.values())\n            action = max(expectations, key=expectations.get)\n\n        actions[step] = action\n\n        p = params[action]\n        results[action].append(float(np.random.normal(p.loc, p.scale, 1)))\n        eps_performance[step] = get_performance(results)\n\n    return eps_performance\n\n\ndef ucb(results, step, c):\n    return {\n        arm: np.mean(data)+ c * np.sqrt(np.log(step)/len(data))\n        for arm, data in results.items()\n    }\n\n\ndef get_performance(results):\n    d = []\n    for arm, data in results.items():\n        d.extend(data)\n    return np.mean(d)\n\n\ndef run_ucb_expt(c, params):\n    print('running UCB')\n\n    results = {\n        arm: list(np.random.normal(*stats))\n        for arm, stats in params.items()\n    }\n\n    steps = 5000\n    values = np.zeros((steps, len(params.values())))\n    actions = np.empty((steps)).astype(str)\n    ucb_performance = np.zeros(steps)\n\n    for step in range(steps):\n        ucbs = ucb(results, 2, c)\n\n        action = max(ucbs, key=ucbs.get)\n        actions[step] = action\n        values[step, :] = list(ucbs.values())\n\n        p = params[action]\n        results[action].append(float(np.random.normal(p.loc, p.scale, 1)))\n        ucb_performance[step] = get_performance(results)\n\n    return ucb_performance\n\n\ndef fair_coin_hypothesis_test(data, test_statistic, null_hypothesis):\n    observed = test_statistic(data)\n\n    test_stats = []\n    for expt in range(len(data)):\n        data = null_hypothesis(len(data))\n        test_stats.append(test_statistic(data))\n\n    test_stats = np.array(test_stats)\n    p_val = sum(test_stats > observed) / test_stats.shape[0]\n\n    print('If the null hypothesis is true, we expect to see the effect of {} {} % of the time'.format(\n        observed, p_val*100))\n    return p_val\n\n\ndef test_means(observed, expected):\n    return abs(np.mean(observed) - np.mean(expected))\n\n\ndef run_shuffle(pool):\n    mask = np.random.randint(0, 2, size=pool.shape[0]).astype(bool)\n    return pool[mask], pool[~mask]\n\n\ndef flower_mean_hypothesis(first, second, iters=1000):\n    observed = test_means(first, second)\n    pool = np.concatenate([first, second])\n    test_stats = np.array([\n        test_means(*run_shuffle(pool)) for _ in range(iters)\n    ])\n    p_val = sum(test_stats > observed) / test_stats.shape[0]\n    return p_val, test_stats\n\n"""
statistics/common.py,5,"b""from collections import namedtuple\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport requests\nfrom sklearn import datasets\n\n\nData = namedtuple('Data', ['features', 'target', 'target1D'])\n\n\ndef load_iris():\n    dataset = datasets.load_iris()\n    features = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n    target = pd.DataFrame(pd.get_dummies(dataset.target))\n    target.columns = dataset.target_names\n    assert features.shape[0] == target.shape[0]\n    print('The Iris dataset was used in R.A. Fisher\\'s classic 1936 paper *The Use of Multiple Measurements in Taxonomic Problems*.')\n    print('')\n    print('features.shape = {}'.format(features.shape))\n    print('target.shape = {}'.format(target.shape))\n    return Data(features, target, pd.DataFrame(dataset.target, columns=['class']))\n\n\ndef load_forest_fires():\n    os.makedirs('./data', exist_ok=True)\n\n    files = ['forestfires.csv']\n    print('Downloading forest fires dataset - the aim is to predict the burned area of forest fires, in the northeast region of Portugal, by using meteorological and other data')\n    for name in files:\n        res = requests.get('http://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/{}'.format(name))\n        with open('./data/{}'.format(name) , 'wb') as f:\n            f.write(res.content)\n    data = pd.read_csv('./data/forestfires.csv')\n    \n    print('')\n    print('data.shape = {}'.format(data.shape))\n    print('columns {}'.format(list(data.columns)))\n    return data\n\n\ndef make_pmf(samples):\n    uniq, counts = np.unique(samples, return_counts=True)\n    pmf = counts / np.sum(counts, axis=0)\n    return uniq, pmf\n\n\ndef percentile_rank(value, samples):\n    count = 0\n    return sum([count + 1 for s in samples if s <= value]) / len(samples)\n\n\ndef percentile(rank, samples):\n    samples = sorted(samples)\n    idx = int(rank * (len(samples) - 1))\n    return samples[idx]\n\n\ndef make_cdf(samples):\n    samples = sorted(samples)\n    return [(percentile_rank(s, samples), s) for s in sorted(samples)]\n\n\ndef generate_bandit_dataset(arms=20, samples=2):\n    np.random.seed(42)\n\n    Param = namedtuple('Parameter', ['loc', 'scale', 'initial_size'])\n    start = 10\n    end = 50\n    num_options = arms\n\n    params = {\n        str(option): Param(loc, scale, samples) \n        for option, (loc, scale) \n        in enumerate(zip(np.linspace(start, end, num_options), np.random.uniform(10, size=num_options)))\n    }\n\n    return params, {\n        arm: list(np.random.normal(*stats))\n        for arm, stats in params.items()\n    }\n"""
test-driven-development/answers.py,12,"b'import numpy as np\nimport pandas as pd\n\n\ndef one_hot(data):\n    columns = sorted(set(data))\n\n    values = np.zeros((len(data), len(columns)))\n\n    for row, d in enumerate(data):\n        col = columns.index(d)\n        values[row, col] = 1\n        \n    return pd.DataFrame(values, columns=columns)\n\n\ndef test_normalize():\n    arr = np.array([[-5, 0], [0, 10], [5, -10]]).astype(np.float32)\n    norm = normalize(arr)\n\n    np.testing.assert_array_equal(norm, [[0, 0.5], [0.5, 1], [1, 0]])\n    assert norm.shape == arr.shape\n    assert (np.min(norm, axis=0) == 0).all()\n    assert (np.max(norm, axis=0) == 1.0).all()\n\n\ndef normalize(arr):\n    mins = np.min(arr, axis=0)\n    maxs = np.max(arr, axis=0)\n    return (arr - mins) / (maxs - mins)\n\n\ndef test_standardizer():\n    data = np.random.uniform(size=20).reshape((10, 1, 2)) * 100\n    standardized = standardizer(data)\n    np.testing.assert_array_less(np.mean(standardized, axis=0), 1e-14)\n    np.testing.assert_allclose(np.var(standardized, axis=0), 1)\n\n\ndef standardizer(x):\n    means = np.mean(x, axis=0, keepdims=True)\n    stds = np.std(x, axis=0, keepdims=True)\n    return (x - means) / stds\n'"
distributed-computing/ray/ray_example.py,0,"b""import ray\nimport time\n\n\n@ray.remote\ndef f(x):\n    print('hi from {}'.format(x))\n    return x\n\n# Start Ray.\nray.init()\n\n# Start 4 tasks in parallel.\nresult_ids = []\nfor i in range(4):\n    result_ids.append(f.remote(i))\n\n# Wait for the tasks to complete and retrieve the results.\n# With at least 4 cores, this will take 1 second.\nresults = ray.get(result_ids)  # [0, 1, 2, 3]\n"""
distributed-computing/ray/ray_tune.py,0,"b'import torch.optim as optim\nfrom ray import tune\n\n\ndef train_mnist(config):\n    # train_loader, test_loader = get_data_loaders()\n    # model = ConvNet()\n    # optimizer = optim.SGD(model.parameters(), lr=config[""lr""])\n    # for i in range(10):\n    #     train(model, optimizer, train_loader)\n    #     acc = test(model, test_loader)\n    tune.track.log(mean_accuracy=0.5)\n    print(config)\n\n\nanalysis = tune.run(\n    train_mnist, config={""lr"": tune.grid_search([0.001, 0.01, 0.1])})\n\nprint(""Best config: "", analysis.get_best_config(metric=""mean_accuracy""))\n\n# Get a dataframe for analyzing trial results.\ndf = analysis.dataframe()\nprint(df)\n'"
python/basics/answers.py,0,b'def factorial(n):\n    if n == 0:\n        return 1\n    else:\n        return n * factorial(n-1)'
trees/scratch/boost.py,8,"b""import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.tree import DecisionTreeRegressor\n\n\nif __name__ == '__main__':\n    #  simple dataset\n    x = np.random.uniform(0, 100, 10000).reshape(-1, 1)\n    y = np.sin(x).ravel()\n    assert x.shape[0] == y.shape[0]\n    assert len(y.shape) == 1\n\n    bootstrap_size = 1000\n    rounds = 5\n\n    preds = np.zeros((rounds, bootstrap_size))\n\n    for rnd in range(rounds):\n        idxs = np.random.randint(0, bootstrap_size, bootstrap_size)\n\n        tree = DecisionTreeRegressor()\n\n        #  use all features\n        feature_idx = np.arange(x.shape[1])\n        batch = x[idxs, feature_idx].reshape(-1, x.shape[1]), y[idxs]\n\n        tree.fit(*batch)\n\n        pred = tree.predict(batch[0])\n        error = np.mean(pred - batch[1])\n        print(np.sum(error))\n        preds[rnd, :] = pred\n\n        #  learning rate goes here\n        y = pred - batch[1]\n\n    f, a = plt.subplots()\n    plt.plot(np.mean(preds, axis=1))\n    plt.savefig('./out.png')\n"""
trees/scratch/decision_tree.py,2,"b""from collections import namedtuple\nimport sys\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import entropy\n\nsys.path.append('../statistics')\nfrom common import load_iris\n\n#  used when iterating over potential splits\nCandidateSplit = namedtuple('Candidate', ['entropy', 'weight'])\n\n#  used when iterating over features\nBestSplit = namedtuple(\n    'Best',\n    ['feature', 'entropy', 'boundary', 'left', 'right']\n)\n\n#  a node in the decision tree\nNode = namedtuple('Node', ['left', 'right', 'boundary', 'feature', 'num'])\n\n\ndef calc_entropy(y):\n    probs = [sum(y == i) / len(y) for i in set(y)]\n    np.testing.assert_allclose(sum(probs), 1)\n    return entropy(probs)\n\n\ndef make_split(target):\n    ents = []\n    splits = range(1, target.shape[0])\n    for split in splits:\n        left, right = target[:split], target[split:]\n\n        l = CandidateSplit(calc_entropy(left), len(left) / len(target))\n        r = CandidateSplit(calc_entropy(right), len(right) / len(target))\n\n        split_entropy = l.entropy * l.weight + r.entropy * r.weight\n        ents.append(split_entropy)\n\n    best = np.argmin(ents)\n    entropy = ents[best]\n    split = splits[best]\n\n    return entropy, split\n\n\ndef split_dataset_on_feature(data, feature):\n    sorted_data = data.sort_values(feature).reset_index(drop=True)\n    ent, split = make_split(sorted_data.loc[:, 'class'])\n    boundary = sorted_data.iloc[split, :].loc[feature]\n\n    left = sorted_data.iloc[:split, :]\n    right = sorted_data.iloc[split:, :]\n    return BestSplit(feature, ent, boundary, left, right)\n\n\ndef get_best_split(data, features):\n    if isinstance(features, str):\n        features = [features]\n\n    results = []\n    for feature in features:\n        results.append(split_dataset_on_feature(data, feature))\n\n    sort = sorted(results, key=lambda tup: tup.entropy)\n    best = sort[0]\n    print(best.feature, best.boundary)\n    return best\n\n\ndef train_decision_tree(data, features=None, node=0):\n    node += 1\n    if len(set(data.loc[:, 'class'])) == 1 or data.shape[0] < 5:\n        return 'leaf'\n\n    feature, ent, boundary, left, right = get_best_split(data, features)\n\n    if len(set(left.loc[:, 'class'])) > 1:\n        left_node = train_decision_tree(left, features, node)\n    else:\n        left_node = None\n\n    if len(set(right.loc[:, 'class'])) > 1:\n        right_node = train_decision_tree(right, features, node)\n    else:\n        right_node = None\n\n    return Node(left_node, right_node, boundary, feature, node)\n\nif __name__ == '__main__':\n    data = load_iris()\n\n    raw = pd.concat([data.features, data.target1D], axis=1)\n\n    cols = raw.columns\n    tree = train_decision_tree(raw, cols[:-1]) # -1 to not include the class :)\n    print(tree)\n"""
