file_path,api_count,code
convolutional_neural_network.py,0,"b""from keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport crayons as cr\nimport os\n\n\nclass CNN:\n    def __init__(self, train_generator, test_generator):\n        self.epochs = 5\n        self.classes = 7\n        self.train_generator = train_generator\n        self.test_generator = test_generator\n        self.model = Sequential()\n\n    def create(self):\n        try:\n            # 1st Convolution\n\n            self.model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n            self.model.add(MaxPooling2D((2, 2)))\n            self.model.add(Conv2D(64, (3, 3), activation='relu'))\n            self.model.add(MaxPooling2D((2, 2)))\n            self.model.add(Conv2D(128, (3, 3), activation='relu'))\n            self.model.add(MaxPooling2D((2, 2)))\n            self.model.add(Conv2D(128, (3, 3), activation='relu'))\n            self.model.add(MaxPooling2D((2, 2)))\n            self.model.add(Flatten())\n            self.model.add(Dropout(0.5))\n            self.model.add(Dense(512, activation='relu'))\n            self.model.add(Dense(self.classes, activation='sigmoid'))\n\n            # opt = RMSprop(lr=1e-4)\n            opt = Adam()\n            self.model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n\n            # Set a learning rate annealer\n            learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n                                                        patience=3,\n                                                        verbose=1,\n                                                        factor=0.5,\n                                                        min_lr=0.00001)\n\n            history = self.model.fit_generator(generator=self.train_generator,\n                                               steps_per_epoch=self.train_generator.n // self.train_generator.batch_size,\n                                               epochs=self.epochs,\n                                               validation_data=self.test_generator,\n                                               validation_steps=self.test_generator.n // self.test_generator.batch_size,\n                                               callbacks=[learning_rate_reduction])\n\n            if not os.path.exists('models'):\n                os.makedirs('models')\n            # Save Model\n            self.model.save('models/CNN.h5')\n\n            return history\n        except Exception as e:\n            print()\n            print(cr.red(str(e), bold=True))\n            exit(1)\n"""
data_generator.py,0,"b'from keras.preprocessing.image import ImageDataGenerator\nimport crayons as cr\n\n\nclass PrepareData:\n\n    def __init__(self):\n        self.data_generator_train = ImageDataGenerator()\n        self.data_generator_test = ImageDataGenerator()\n\n        # number of images to feed in the CNN\n        self.batch_size = 32\n\n        # image size 48*48 pixels\n        self.img_size = 48\n\n        # input path for the images\n        self.path = ""dataset/""\n\n    def run(self):\n        try:\n            train_generator = self.data_generator_train.flow_from_directory(self.path + ""train"",\n                                                                            target_size=(self.img_size, self.img_size),\n                                                                            color_mode=""grayscale"",\n                                                                            batch_size=self.batch_size,\n                                                                            class_mode=\'categorical\',\n                                                                            shuffle=True)\n\n            test_generator = self.data_generator_test.flow_from_directory(self.path + ""test"",\n                                                                          target_size=(self.img_size, self.img_size),\n                                                                          color_mode=""grayscale"",\n                                                                          batch_size=self.batch_size,\n                                                                          class_mode=\'categorical\',\n                                                                          shuffle=False)\n\n            return train_generator, test_generator\n        except Exception as e:\n            print()\n            print(cr.red(str(e), bold=True))\n            exit(1)\n'"
generate_dataset.py,1,"b'from PIL import Image\nimport numpy as np\nimport crayons as cr\nimport shutil\nimport os\n\n\nclass GenerateDataset:\n\n    # Initialise variables required.\n    def __init__(self, df):\n        self.df = df\n        self.__parent_dir_list = [\'train\', \'test\']\n        self.__child_dir_list = [\'angry\', \'disgust\', \'fear\', \'happy\', \'neutral\', \'sad\', \'surprise\']\n\n    def csv_2img(self):\n        print()\n        if os.path.exists(\'dataset\'):\n            if self.get_size() > 6000000:\n                print(cr.blue(\'Dataset already present!\\nRegenerate data? (Y/N) :\', bold=True), end=\'\')\n                a = input().strip().lower()\n                if a == \'n\':\n                    return\n                elif a == \'y\':\n                    shutil.rmtree(\'dataset/\')\n                else:\n                    print(cr.red(""Invalid Input"", bold=True))\n                    exit(1)\n\n        print(cr.blue(\'Extracting data...\', bold=True))\n        try:\n            # Create required directories if they don\'t exist.\n            if not os.path.exists(\'dataset\'):\n                os.makedirs(\'dataset\')\n            for par_dir in self.__parent_dir_list:\n                if not os.path.exists(\'dataset/\' + par_dir):\n                    os.makedirs(\'dataset/\' + par_dir)\n                for child_dir in self.__child_dir_list:\n                    if not os.path.exists(\'dataset/\' + par_dir + \'/\' + child_dir):\n                        os.makedirs(\'dataset/\' + par_dir + \'/\' + child_dir)\n\n            # Paths to store the images extracted from the csv file.\n            # 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n            data_loc = {\n                0: \'dataset/train/angry/\',\n                1: \'dataset/train/disgust/\',\n                2: \'dataset/train/fear/\',\n                3: \'dataset/train/happy/\',\n                4: \'dataset/train/sad/\',\n                5: \'dataset/train/surprise/\',\n                6: \'dataset/train/neutral/\'\n            }\n\n            # Iterate through all the rows of the DataFrame.\n            for index, row in self.df.iterrows():\n                # Get pixel data from the DataFrame\n                pixel = str(row[\'pixels\']).split()\n\n                # Reshape the pixel matrix to 48x48.\n                data = np.array(pixel).reshape(48, 48)\n\n                # Generate image from pixel data.\n                img = Image.fromarray(data.astype(\'uint8\'))\n\n                # Put the image in the appropriate folder according to their emotions mentioned.\n                if str(row[\'Usage\']).strip().lower() == \'training\':\n                    path = data_loc.get(row[\'emotion\'], \'\')\n                else:\n                    path = data_loc.get(row[\'emotion\'], \'\').replace(\'train\', \'test\')\n\n                # Save Image\n                img.save(path + str(index) + \'.png\')\n            print(cr.blue(\'Data Extraction Finished!\', bold=True))\n        except Exception as e:\n            print()\n            print(cr.red(str(e), bold=True))\n            exit(1)\n\n    @staticmethod\n    def get_size(start_path=r\'dataset/\'):\n        total_size = 0\n        for dirpath, dirnames, filenames in os.walk(start_path):\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                # skip if it is symbolic link\n                if not os.path.islink(fp):\n                    total_size += os.path.getsize(fp)\n        return total_size\n'"
main.py,3,"b'import convolutional_neural_network\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt\nimport generate_dataset as gd\nimport data_generator as gen\nimport pandas as pd\nimport numpy as np\nimport requests\nimport crayons as cr\nimport cv2\nimport os\n\n\nclass EmotionRecognition:\n\n    def __init__(self):\n        self.emotions_list = [""ANGRY"", ""DISGUSTED"", ""FEAR"", ""HAPPY"",\n                              ""NEUTRAL"", ""SAD"", ""SURPRISED""]\n        self.classifier = cv2.CascadeClassifier(\'models/haarcascade_frontalface_default.xml\')\n        self.url = \'http://192.168.1.3:8080/shot.jpg\'\n\n    @staticmethod\n    def load():\n        return load_model(\'models/CNN.h5\')\n\n    def predict_emotion(self, img, new_model):\n        prediction = new_model.predict(img)\n        emotions = self.emotions_list[np.argmax(prediction)]\n        return emotions\n\n    # returns camera frames along with bounding boxes and predictions\n    def stream_video(self, m):\n\n        while True:\n            img_resp = requests.get(self.url)\n            img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n            frame = cv2.imdecode(img_arr, -1)\n\n            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n            faces = self.classifier.detectMultiScale(frame_gray, 1.3, 5)\n\n            if str(type(faces)) == str(type(())):\n                cv2.imshow(""Live Stream"", frame)\n                if cv2.waitKey(1) == 27:\n                    break\n                continue\n\n            for (x, y, w, h) in faces:\n                crop_frame = frame_gray[y:y + h, x:x + w]\n\n                image = cv2.resize(crop_frame, (48, 48))\n                pred = self.predict_emotion(image[np.newaxis, :, :, np.newaxis], m)\n\n                cv2.putText(frame, pred, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n\n                cv2.imshow(""Live Stream"", frame)\n\n            if cv2.waitKey(1) == 27:\n                break\n\n        # cleanup the camera and close any open windows\n        cv2.destroyAllWindows()\n\n    @staticmethod\n    def plot_graph(history0):\n        plt.figure(figsize=(20, 10))\n        plt.subplot(1, 2, 1)\n        plt.xlabel(\'Epoch\', fontsize=14)\n        plt.ylabel(\'Loss\', fontsize=14)\n\n        plt.plot(history0.history[\'loss\'], label=\'Training Loss\')\n        plt.plot(history0.history[\'val_loss\'], label=\'Testing Loss\')\n        plt.legend()\n\n        plt.subplot(1, 2, 2)\n        plt.xlabel(\'Epoch\', fontsize=14)\n        plt.ylabel(\'Accuracy\', fontsize=14)\n\n        plt.plot(history0.history[\'acc\'], label=\'Training Accuracy\')\n        plt.plot(history0.history[\'val_acc\'], label=\'Testing Accuracy\')\n        plt.legend()\n\n        plt.show()\n\n\nif __name__ == \'__main__\':\n\n    try:\n        df = pd.read_csv(\'emotionData.csv\')\n\n        er = gd.GenerateDataset(df)\n        er.csv_2img()\n\n        train_generator, test_generator = gen.PrepareData().run()\n\n        model = convolutional_neural_network.CNN(train_generator, test_generator)\n\n        emotion_recognition = EmotionRecognition()\n\n        if not os.path.exists(\'models\'):\n            os.makedirs(\'models\')\n\n        if os.path.isfile(\'models/CNN.h5\'):\n            print(cr.blue(\'Model Already Exists! Do you want to retrain the model? (Y/N): \', bold=True), end=\'\')\n            y = input().lower().strip()\n            if y == \'y\':\n                os.remove(\'models/CNN.h5\')\n                history = model.create()\n                print(cr.blue(\'Do you want to plot the analysis graphs? (Y/N): \', bold=True), end=\'\', )\n                x = input().lower().strip()\n                if x == \'y\':\n                    emotion_recognition.plot_graph(history)\n                elif x == \'n\':\n                    pass\n                else:\n                    print(cr.red(""Invalid Input"", bold=True))\n                    exit(1)\n            elif y == \'n\':\n                pass\n            else:\n                print(cr.red(""Invalid Input"", bold=True))\n                exit(1)\n\n        else:\n            print(cr.blue(\'Training Model...\', bold=True))\n            history = model.create()\n            print(cr.blue(\'Do you want to plot the analysis graphs? (Y/N): \', bold=True), end=\'0\')\n            a = input().lower().strip()\n            if a == \'y\':\n                emotion_recognition.plot_graph(history)\n            elif a == \'n\':\n                pass\n            else:\n                print(cr.red(""Invalid Input"", bold=True))\n                exit(1)\n        emotion_recognition.stream_video(emotion_recognition.load())\n    except Exception as e:\n        print()\n        print(cr.red(str(e), bold=True))\n        exit(1)\n'"
