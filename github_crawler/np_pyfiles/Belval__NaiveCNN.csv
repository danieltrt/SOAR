file_path,api_count,code
NaiveCNN/data_manager.py,0,"b'import os\nimport numpy as np\nimport _pickle as cPickle\n\nfrom utils import cifar_rgb_to_grayscale\n\ndef load_data(path):\n    """"""\n        Description: Load the CIFAR dataset for a repository\n    """"""\n\n    # Our two lists, containing the training and testing data\n    train_data = []\n    train_labels = []\n    test_data = []\n    test_labels = []\n    \n    # Since not everything is in one file...\n    for f in os.listdir(path):\n        if \'test\' in f:\n            test_data, test_labels = _load_file(os.path.join(path, f))\n        elif \'data\' in f:\n            print(f)\n            sub_train_data, sub_train_labels = _load_file(os.path.join(path, f))\n            train_data.extend(sub_train_data)\n            train_labels.extend(sub_train_labels)\n        else:\n            continue\n\n    return (\n        [cifar_rgb_to_grayscale(row) for row in train_data],\n        train_labels,\n        [cifar_rgb_to_grayscale(row) for row in test_data],\n        test_labels\n    )\n\ndef _load_file(path):\n    """"""\n        Description: Simple function that loads the CIFAR data as described on the\n                     official website.\n    """"""\n\n    with open(path, \'rb\') as f:\n        d = cPickle.load(f, encoding=\'bytes\')\n    return d.get(b\'data\'), d.get(b\'labels\')\n\ndef save_data(path, weights):\n    """"""\n        Description: Simple function to write the weights to a file.\n    """"""\n\n    with open(path, \'rb\') as f:\n        f.write(weights)\n'"
NaiveCNN/model.py,22,"b'import numpy as np\n\nfrom utils import im2col\n\nclass ConvolutionalNet():\n    """"""\n        Description:\n            The definition of our naive CNN, it is made of\n                One convolution layer\n                One ReLU layer\n                One pooling layer\n                One fully connected layer\n                One softmax layer / output layer\n            It is loosely based on the ninth chapter of the excellent deep learning book\n            (http://www.deeplearningbook.org/contents/convnets.html)\n        Good read on the subject:\n            Deep Learning Book (http://www.deeplearningbook.org/)\n            Understanding the difficulty of training deep feedforward neural neural network (http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n            Delving Deep into Rectifiers (https://arxiv.org/pdf/1502.01852.pdf)\n    """"""\n\n    def __init__(self, kernel_count, kernel_size, input_size, output_size):\n        """"""\n            Description: The ConvNet contructor.\n            Parameters:\n                kernel_count -> The number of kernel to use\n                kernel_size -> The size of the kernel to use (always a square)\n                output_size -> The number of classes\n                input_size -> A tuple that defines the size of the input\n        """"""\n        \n        self.kernel_count = kernel_count\n        self.kernel_size = kernel_size\n        self.input_size = input_size\n        self.output_size = output_size\n\n        # Random initialization of our kernels based on a gaussian distribution with a std of 1.0\n        # See https://arxiv.org/pdf/1502.01852.pdf Page 3\n        self.kernels = [\n            np.random.normal(size=(kernel_size, kernel_size)) for x in range(kernel_count)\n        ]\n\n    def __convolution(self, inputs, stride=1, padding=0):\n        """"""\n            Description: Convolution layer\n        """"""\n\n        new_size = (np.shape(inputs)[1] - self.kernel_size + 2 * padding) / stride + 1\n\n        tile_col = im2col(inputs, self.kernel_size, stride, padding)\n\n        kernel_col = np.reshape(self.kernel_count, -1)\n\n        result = np.dot(tile_col, kernel_col)\n\n        return np.reshape(self.kernel_count, new_size, new_size)\n        \n\n    def __max_pool(self, inputs, size, stride, padding):\n        """"""\n            Description: Max pool layer\n            Parameters:\n                inputs -> The input of size [batch_size] x [filter] x [shape_x] x [shape_y]\n                size -> The size of the tiling\n                stride -> The applied translation at each step\n                padding -> The padding (padding with 0 so the last column isn\'t left out)\n        """"""\n\n        inp_sp = np.shape(inputs)\n        # We reshape it so every filter is considered an image.\n        tile_col = im2col(reshaped, size, stride=stride, padding=padding)\n        # We take the max of each column\n        max_ids = np.argmax(tile_col, axis=0)\n        # We get the resulting 1 x 10240 vector\n        result = tile_col[max_ids, range(max_ids.size)]\n\n        new_size = (inp_sp[2] - size + 2 * padding) / stride + 1\n\n        result = np.reshape(result, (new_size, new_size, inp_sp[0]))\n\n        # Make it from 16 x 16 x 10 to 10 x 16 x 16\n        return np.transpose(result, (2, 0, 1))\n\n    def __avg_pool(self, inputs, size, stride, padding):\n        """"""\n            (Copy & paste of the max pool code with np.mean instead of np.argmax)\n            Description: Average pool layer\n            Parameters:\n                inputs -> The input of size [batch_size] x [filter] x [shape_x] x [shape_y]\n                size -> The size of the tiling\n                stride -> The applied translation at each step\n                padding -> The padding (padding with 0 so the last column isn\'t left out)\n        """"""\n\n        inp_sp = np.shape(inputs)\n        tile_col = im2col(reshaped, size, stride=stride, padding=padding)\n        max_ids = np.mean(tile_col, axis=0)\n        result = tile_col[max_ids, range(max_ids.size)]\n        new_size = (inp_sp[2] - size + 2 * padding) / stride + 1\n        result = np.reshape(result, (new_size, new_size, inp_sp[0]))\n        return np.transpose(result, (2, 0, 1))\n\n    def __rectified_linear(self, inputs):\n        """"""\n            Description: Rectified Linear Unit layer (ReLU)\n        """"""\n\n        return np.maximum(inputs, 0, inputs)\n\n    def __fully_connected(self, inputs, weights):\n        """"""\n            Description: Fully connected layer\n            Parameters:\n                unit_count -> The number of units in the layer\n        """"""\n\n        return np.dot(inputs, np.reshape(weights, (np.shape(inputs), np.shape(self.unit_count))))\n\n    def __softmax(self, inputs):\n        """"""\n            Description: Softmax function for the output layer\n        """"""\n\n        return np.exp(x) / np.sum(np.exp(x), axis=0)\n\n    def __forwardpropagation(self, inputs):\n        """"""\n            Description: Gives a response based on input\n        """"""\n\n        # My goal was to do something like this, but it\'s unreadable\n        #return _fully_connected(_max_pooling(_rectified_linear(_convolution(inputs, kernels))))\n\n        res_conv = self.__convolution(inputs)\n        res_relu = self.__rectified_linear(res_conv)\n        res_pool = self.__avg_pool(res_relu)\n        res_full = self.__fully_connected(res_pool, self.full_connected_weights)\n        return self.__softmax(res_full)\n\n    def __backpropagation(self, mean_squared_error):\n        """"""\n            Description: Weight adjusting algorithm\n        """"""\n\n    def train(self, data, labels, batch_size, iteration_count, alpha):\n        """"""\n            Description: Train the ConvNet\n            Parameters:\n                data -> The data to be used for training\n                labels -> The labels for the data\n                batch_size -> The size of a batch used for one iteration\n                iteration_count -> The number of iterations for a full training\n                alpha -> The learning rate alpha\n        """"""\n\n        # For the sake of simplicity we use Mean Squared Error\n        for x in range(iteration_count):\n            print(\'Iteration #{}\'.format(x))\n            errors = np.zeros((batch_size, self.output_size))\n            for y in range(batch_size):\n                errors[y, :] = (self.__forwardpropagation(data[x * batch_size + y]) - labels[x * batch_size + y])**2\n            self.__backpropagation(np.mean(errors, axis=1))\n\n    def test(self, data, labels):\n        """"""\n            Description: Test the ConvNet\n            Parameters:\n                data -> The data to be used for testing\n                labels -> The labels to be used for testing\n        """"""\n\n        good = 0\n        for x in range(np.shape(data)[0]):\n            if np.argmax(feedforward(data[x, :])) == np.argmax(labels[x, :]):\n                good += 1\n\n        print(\'The network successfully identified {} / {} examples.\'.format(good, np.shape(data)[0]))'"
NaiveCNN/run.py,3,"b'import sys\nimport numpy as np\n\nfrom model import ConvolutionalNet\nfrom data_manager import load_data\n\n\ndef main(args):\n    """"""\n        Description: Create, train and test the conv net\n    """"""\n\n    # Get the data\n    train_data, train_labels, test_data, test_labels = load_data(args[1])\n\n    print(np.shape(train_data))\n\n    # Build our ConvNet\n    conv_net = ConvolutionalNet(\n        int(args[5]), \n        int(args[6]), \n        np.shape(train_data)[1], \n        np.shape(test_data[0])[1]\n    )\n\n    # Train the ConvNet\n    conv_net.train(train_data, train_labels, int(args[2]), int(args[3]), float(args[4]))\n\n    # Test the ConvNet\n    conv_net.test(test_data, test_labels)\n\nif __name__==\'__main__\':\n    # Usage: run.py [data_path] [batch_size] [iteration_count] [alpha] [kernel_count] [kernel_size]\n    main(sys.argv)\n'"
NaiveCNN/utils.py,9,"b""import numpy as np\n\n# That very smart code was taken from http://stackoverflow.com/questions/30109068/implement-matlabs-im2col-sliding-in-python/30110497\ndef im2col(array, size, stride=1, padding=0):\n    # Add padding to our array\n    padded_array = np.pad(\n        array,\n        ((0, 0), (0, 0), (padding, padding), (padding, padding)),\n        mode='constant'\n    )\n    # Get the shape of our newly made array\n    H,W = np.shape(padded_array)\n    # Get the extent\n    extent = H - size + 1\n\n    # Start index\n    start_idx = np.arange(size)[:, None] * H + np.arange(size)\n    offset_idx = np.arange(extent)[:, None] * H + np.arange(extent)\n\n    return np.take(\n        array, \n        np.ravel(start_idx)[:, None] + np.ravel(offset_idx)[::stride]\n    )\n\ndef cifar_rgb_to_grayscale(image):\n    red = np.reshape(image[0:1024], (32, 32))\n    green = np.reshape(image[1024:2048], (32, 32))\n    blue = np.reshape(image[2048:3072], (32, 32))\n\n    return 0.2989 * red + 0.5870 * green + 0.1140 * blue\n\n"""
