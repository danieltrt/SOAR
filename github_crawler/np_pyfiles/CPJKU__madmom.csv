file_path,api_count,code
setup.py,1,"b'#!/usr/bin/env python\n# encoding: utf-8\n""""""\nThis file contains the setup for setuptools to distribute everything as a\n(PyPI) package.\n\n""""""\n\nfrom setuptools import setup, find_packages\nfrom distutils.extension import Extension\n\nfrom Cython.Build import cythonize, build_ext\n\nimport glob\nimport numpy as np\n\n# define version\nversion = \'0.17.dev0\'\n\n# define which extensions to compile\ninclude_dirs = [np.get_include()]\n\nextensions = [\n    Extension(\'madmom.audio.comb_filters\', [\'madmom/audio/comb_filters.pyx\'],\n              include_dirs=include_dirs),\n    Extension(\'madmom.features.beats_crf\', [\'madmom/features/beats_crf.pyx\'],\n              include_dirs=include_dirs),\n    Extension(\'madmom.ml.hmm\', [\'madmom/ml/hmm.pyx\'],\n              include_dirs=include_dirs),\n    Extension(\'madmom.ml.nn.layers\', [\'madmom/ml/nn/layers.py\'],\n              include_dirs=include_dirs),\n]\n\n# define scripts to be installed by the PyPI package\nscripts = glob.glob(\'bin/*\')\n\n# define the models to be included in the PyPI package\npackage_data = [\'models/LICENSE\',\n                \'models/README.rst\',\n                \'models/beats/201[56]/*\',\n                \'models/chords/*/*\',\n                \'models/chroma/*/*\',\n                \'models/downbeats/*/*\',\n                \'models/key/2018/*\',\n                \'models/notes/*/*\',\n                \'models/onsets/*/*\',\n                \'models/patterns/*/*\',\n                ]\n\n# some PyPI metadata\nclassifiers = [\'Development Status :: 3 - Alpha\',\n               \'Programming Language :: Python :: 2.7\',\n               \'Programming Language :: Python :: 3.5\',\n               \'Programming Language :: Python :: 3.6\',\n               \'Programming Language :: Python :: 3.7\',\n               \'Environment :: Console\',\n               \'License :: OSI Approved :: BSD License\',\n               \'License :: Free for non-commercial use\',\n               \'Topic :: Multimedia :: Sound/Audio :: Analysis\',\n               \'Topic :: Scientific/Engineering :: Artificial Intelligence\']\n\n# requirements\nrequirements = [\'numpy>=1.13.4\',\n                \'scipy>=0.16\',\n                \'cython>=0.25\',\n                \'mido>=1.2.6\',\n                ]\n\n# docs to be included\ntry:\n    long_description = open(\'README.rst\', encoding=\'utf-8\').read()\n    long_description += \'\\n\' + open(\'CHANGES.rst\', encoding=\'utf-8\').read()\nexcept TypeError:\n    long_description = open(\'README.rst\').read()\n    long_description += \'\\n\' + open(\'CHANGES.rst\').read()\n\n# the actual setup routine\nsetup(name=\'madmom\',\n      version=version,\n      description=\'Python audio signal processing library\',\n      long_description=long_description,\n      author=\'Department of Computational Perception, Johannes Kepler \'\n             \'University, Linz, Austria and Austrian Research Institute for \'\n             \'Artificial Intelligence (OFAI), Vienna, Austria\',\n      author_email=\'madmom-users@googlegroups.com\',\n      url=\'https://github.com/CPJKU/madmom\',\n      license=\'BSD, CC BY-NC-SA\',\n      packages=find_packages(exclude=[\'tests\', \'docs\']),\n      ext_modules=cythonize(extensions),\n      package_data={\'madmom\': package_data},\n      exclude_package_data={\'\': [\'tests\', \'docs\']},\n      scripts=scripts,\n      install_requires=requirements,\n      cmdclass={\'build_ext\': build_ext},\n      setup_requires=[\'pytest-runner\'],\n      tests_require=[\'pytest\'],\n      classifiers=classifiers)\n'"
docs/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# madmom documentation build configuration file, created by\n# sphinx-quickstart on Sat Oct 17 10:26:54 2015.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\nimport pkg_resources\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\nsys.path.insert(0, os.path.abspath(\'../madmom\'))\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.autosummary\',\n    \'sphinx.ext.doctest\',\n    \'sphinx.ext.todo\',\n    \'sphinx.ext.coverage\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.viewcode\',\n    \'numpydoc\',\n]\n\n# see http://stackoverflow.com/q/12206334/562769\nnumpydoc_show_class_members = False\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The encoding of source files.\n# source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = u\'madmom\'\ncopyright = u\'2015, madmom development team\'\nauthor = u\'madmom development team\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = pkg_resources.get_distribution(""madmom"").version\n# The full version, including alpha/beta/rc tags.\nrelease = version\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n# today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n# today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\'_build\']\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n# default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n# add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n# add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n# If true, keep warnings as ""system message"" paragraphs in the built documents.\n# keep_warnings = False\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\n# todo_include_todos = True\n\n# -- Options for HTML output ----------------------------------------------\n\n# only import and set the theme if we\'re building docs locally\nif os.environ.get(\'READTHEDOCS\') != \'True\':\n    import sphinx_rtd_theme\n    html_theme = \'sphinx_rtd_theme\'\n    html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n# html_theme = \'alabaster\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n# html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n# html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n# html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n# html_extra_path = []\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page bottom,\n# using the given strftime format.\n# html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n# html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n# html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_domain_indices = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n# html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\n# html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n# html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n# html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n# html_file_suffix = None\n\n# Language to be used for generating the HTML full-text search index.\n# Sphinx supports the following languages:\n#   \'da\', \'de\', \'en\', \'es\', \'fi\', \'fr\', \'hu\', \'it\', \'ja\'\n#   \'nl\', \'no\', \'pt\', \'ro\', \'ru\', \'sv\', \'tr\'\n# html_search_language = \'en\'\n\n# A dictionary with options for the search language support, empty by default.\n# Now only \'ja\' uses this config value\n# html_search_options = {\'type\': \'default\'}\n\n# The name of a javascript file (relative to the configuration directory) that\n# implements a search results scorer. If empty, the default will be used.\n# html_search_scorer = \'scorer.js\'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'madmomdoc\'\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n  (master_doc, \'madmom.tex\', u\'madmom Documentation\',\n   u\'madmom development team\', \'manual\'),\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = None\n\n# For ""manual"" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n# latex_use_parts = False\n\n# If true, show page references after internal links.\n# latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n# latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n# latex_appendices = []\n\n# If false, no module index is generated.\n# latex_domain_indices = True\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'madmom\', u\'madmom Documentation\',\n     [author], 1)\n]\n\n# If true, show URL addresses after external links.\n# man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n  (master_doc, \'madmom\', u\'madmom Documentation\',\n   author, \'madmom\', \'One line description of project.\',\n   \'Miscellaneous\'),\n]\n\n# Documents to append as an appendix to all manuals.\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n# texinfo_domain_indices = True\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n# texinfo_show_urls = \'footnote\'\n\n# If true, do not generate a @detailmenu in the ""Top"" node\'s menu.\n# texinfo_no_detailmenu = False\n\n# -- other options --------------------------------------------------------\nautodoc_member_order = \'bysource\'\n'"
madmom/__init__.py,0,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=wrong-import-position\n""""""\nMadmom is an audio and music signal processing library.\n\nThis library is used internally by the Department of Computational Perception,\nJohannes Kepler University, Linz, Austria (http://www.cp.jku.at) and the\nAustrian Research Institute for Artificial Intelligence (OFAI), Vienna, Austria\n(http://www.ofai.at).\n\nPlease see the README for further details of this package.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport doctest\n\nimport numpy as np\nimport pkg_resources\n\n# import all packages\nfrom . import audio, evaluation, features, io, ml, models, processors, utils\n\n# define a version variable\n__version__ = pkg_resources.get_distribution(""madmom"").version\n\n# Create a doctest output checker that optionally ignores the unicode string\n# literal.\n\n# declare the new doctest directives\n_NORMALIZE_ARRAYS = doctest.register_optionflag(""NORMALIZE_ARRAYS"")\ndoctest.NORMALIZE_ARRAYS = _NORMALIZE_ARRAYS\ndoctest.__all__.append(""NORMALIZE_ARRAYS"")\ndoctest.COMPARISON_FLAGS = doctest.COMPARISON_FLAGS | _NORMALIZE_ARRAYS\n\n_NORMALIZE_FFT = doctest.register_optionflag(""NORMALIZE_FFT"")\ndoctest.NORMALIZE_FFT = _NORMALIZE_FFT\ndoctest.__all__.append(""NORMALIZE_FFT"")\ndoctest.COMPARISON_FLAGS = doctest.COMPARISON_FLAGS | _NORMALIZE_FFT\n\n_doctest_OutputChecker = doctest.OutputChecker\n\n\nclass _OutputChecker(_doctest_OutputChecker):\n    """"""\n    Output checker which enhances `doctest.OutputChecker` to compare doctests\n    and computed output with additional flags.\n\n    """"""\n\n    def check_output(self, want, got, optionflags):\n        """"""\n        Return \'True\' if the actual output from an example matches the\n        expected.\n\n        Parameters\n        ----------\n        want : str\n            Expected output.\n        got : str\n            Actual output.\n        optionflags : int\n            Comparison flags.\n\n        Returns\n        -------\n        bool\n            \'True\' if the output matches the expectation.\n\n        """"""\n        import re\n        if optionflags & _NORMALIZE_ARRAYS:\n            # in different versions of numpy arrays sometimes are displayed as\n            # \'array([ 0. ,\' or \'array([0.0,\', thus correct both whitespace\n            # after parenthesis and before commas as well as .0 decimals\n            got = re.sub(r\'\\( \', \'(\', got)\n            got = re.sub(r\'\\[ \', \'[\', got)\n            got = re.sub(r\'0\\.0\', \'0.\', got)\n            got = re.sub(r\'\\s*,\', \',\', got)\n            want = re.sub(r\'\\( \', \'(\', want)\n            want = re.sub(r\'\\[ \', \'[\', want)\n            want = re.sub(r\'0\\.0\', \'0.\', want)\n            want = re.sub(r\'\\s*,\', \',\', want)\n        if optionflags & _NORMALIZE_FFT:\n            # in different versions of numpy arrays, FFT results can be \xc2\xb10.j\n            # and the unwrapped phase \xc2\xb1pi\n            got = re.sub(r\'-0.j\', \'+0.j\', got)\n            want = re.sub(r\'-0.j\', \'+0.j\', want)\n            got = re.sub(r\'-3.14159\', \' 3.14159\', got)\n            want = re.sub(r\'-3.14159\', \' 3.14159\', want)\n\n        super_check_output = _doctest_OutputChecker.check_output\n        return super_check_output(self, want, got, optionflags)\n\n\n# monkey-patching\ndoctest.OutputChecker = _OutputChecker\n\n# keep namespace clean\ndel pkg_resources, doctest\n'"
madmom/conftest.py,3,"b'# encoding: utf-8\n""""""\nThis files contains pytest fixtures and other test related stuff.\n\n""""""\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\nimport pytest\n\n# save numpy\'s current print options\n_NP_PRINT_OPTIONS = np.get_printoptions()\n\n\n@pytest.fixture(autouse=True)\ndef setup_doctest(request):\n    """"""Set up the environment for doctests (when run through pytest).""""""\n    np.set_printoptions(precision=5, edgeitems=2, suppress=True)\n\n    def fin():\n        """"""Restore the environment after doctests (when run through pytest).""""""\n        np.set_printoptions(**_NP_PRINT_OPTIONS)\n\n    request.addfinalizer(fin)\n'"
madmom/processors.py,4,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains all processor related functionality.\n\nNotes\n-----\nAll features should be implemented as classes which inherit from Processor\n(or provide a XYZProcessor(Processor) variant). This way, multiple Processor\nobjects can be chained/combined to achieve the wanted functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport argparse\nimport itertools as it\nimport multiprocessing as mp\nimport os\nimport sys\nfrom collections import MutableSequence\n\nimport madmom\nimport numpy as np\n\nfrom .utils import integer_types\n\n\nclass Processor(object):\n    """"""\n    Abstract base class for processing data.\n\n    """"""\n\n    @classmethod\n    def load(cls, infile):\n        """"""\n        Instantiate a new Processor from a file.\n\n        This method un-pickles a saved Processor object. Subclasses should\n        overwrite this method with a better performing solution if speed is an\n        issue.\n\n        Parameters\n        ----------\n        infile : str or file handle\n            Pickled processor.\n\n        Returns\n        -------\n        :class:`Processor` instance\n            Processor.\n\n        """"""\n        import pickle\n        from .io import open_file\n        # instantiate a new Processor and return it\n        with open_file(infile, \'rb\') as f:\n            # Python 2 and 3 behave differently\n            try:\n                # Python 3\n                obj = pickle.load(f, encoding=\'latin1\')\n            except TypeError:\n                # Python 2 doesn\'t have/need the encoding\n                obj = pickle.load(f)\n        return obj\n\n    def dump(self, outfile):\n        """"""\n        Save the Processor to a file.\n\n        This method pickles a Processor object and saves it. Subclasses should\n        overwrite this method with a better performing solution if speed is an\n        issue.\n\n        Parameters\n        ----------\n        outfile : str or file handle\n            Output file for pickling the processor.\n\n        """"""\n        import pickle\n        from .io import open_file\n        # dump the Processor to the given file\n        # Note: for Python 2 / 3 compatibility reason use protocol 2\n        with open_file(outfile, \'wb\') as f:\n            pickle.dump(self, f, protocol=2)\n\n    def process(self, data, **kwargs):\n        """"""\n        Process the data.\n\n        This method must be implemented by the derived class and should\n        process the given data and return the processed output.\n\n        Parameters\n        ----------\n        data : depends on the implementation of subclass\n            Data to be processed.\n        kwargs : dict, optional\n            Keyword arguments for processing.\n\n        Returns\n        -------\n        depends on the implementation of subclass\n            Processed data.\n\n        """"""\n        raise NotImplementedError(\'Must be implemented by subclass.\')\n\n    def __call__(self, *args, **kwargs):\n        # this magic method makes a Processor callable\n        return self.process(*args, **kwargs)\n\n\nclass OnlineProcessor(Processor):\n    """"""\n    Abstract base class for processing data in online mode.\n\n    Derived classes must implement the following methods:\n\n    - process_online(): process the data in online mode,\n    - process_offline(): process the data in offline mode.\n\n    """"""\n\n    def __init__(self, online=False):\n        self.online = online\n\n    def process(self, data, **kwargs):\n        """"""\n        Process the data either in online or offline mode.\n\n        Parameters\n        ----------\n        data : depends on the implementation of subclass\n            Data to be processed.\n        kwargs : dict, optional\n            Keyword arguments for processing.\n\n        Returns\n        -------\n        depends on the implementation of subclass\n            Processed data.\n\n        Notes\n        -----\n        This method is used to pass the data to either `process_online` or\n        `process_offline`, depending on the `online` setting of the processor.\n\n        """"""\n        if self.online:\n            return self.process_online(data, **kwargs)\n        return self.process_offline(data, **kwargs)\n\n    def process_online(self, data, reset=True, **kwargs):\n        """"""\n        Process the data in online mode.\n\n        This method must be implemented by the derived class and should process\n        the given data frame by frame and return the processed output.\n\n        Parameters\n        ----------\n        data : depends on the implementation of subclass\n            Data to be processed.\n        reset : bool, optional\n            Reset the processor to its initial state before processing.\n        kwargs : dict, optional\n            Keyword arguments for processing.\n\n        Returns\n        -------\n        depends on the implementation of subclass\n            Processed data.\n\n        """"""\n        raise NotImplementedError(\'Must be implemented by subclass.\')\n\n    def process_offline(self, data, **kwargs):\n        """"""\n        Process the data in offline mode.\n\n        This method must be implemented by the derived class and should process\n        the given data and return the processed output.\n\n        Parameters\n        ----------\n        data : depends on the implementation of subclass\n            Data to be processed.\n        kwargs : dict, optional\n            Keyword arguments for processing.\n\n        Returns\n        -------\n        depends on the implementation of subclass\n            Processed data.\n\n        """"""\n        raise NotImplementedError(\'Must be implemented by subclass.\')\n\n    def reset(self):\n        """"""\n        Reset the OnlineProcessor.\n\n        This method must be implemented by the derived class and should reset\n        the processor to its initial state.\n\n        """"""\n        raise NotImplementedError(\'Must be implemented by subclass.\')\n\n\nclass OutputProcessor(Processor):\n    """"""\n    Class for processing data and/or feeding it into some sort of output.\n\n    """"""\n\n    def process(self, data, output, **kwargs):\n        """"""\n        Processes the data and feed it to the output.\n\n        This method must be implemented by the derived class and should\n        process the given data and return the processed output.\n\n        Parameters\n        ----------\n        data : depends on the implementation of subclass\n            Data to be processed (e.g. written to file).\n        output : str or file handle\n            Output file name or file handle.\n        kwargs : dict, optional\n            Keyword arguments for processing.\n\n        Returns\n        -------\n        depends on the implementation of subclass\n            Processed data.\n\n        """"""\n        # pylint: disable=arguments-differ\n        raise NotImplementedError(\'Must be implemented by subclass.\')\n\n\n# functions for processing file(s) with a Processor\ndef _process(process_tuple):\n    """"""\n    Function to process a Processor with data.\n\n    The processed data is returned and if applicable also piped to the given\n    output.\n\n    Parameters\n    ----------\n    process_tuple : tuple (Processor/function, data[, output], kwargs)\n\n        The tuple must contain a Processor object as the first item and the\n        data to be processed as the second tuple item. If a third tuple item\n        is given, it is used as an output argument. The last item is passed\n        as keyword arguments to the processor\'s process() method.\n        Instead of a Processor also a function accepting a single positional\n        argument (data) or two positional arguments (data, output) can be\n        given. It must behave exactly as a :class:`Processor`, i.e. return\n        the processed data and optionally pipe it to the output. Keyword\n        arguments are not passed to the function.\n\n    Returns\n    -------\n    depends on the processor\n        Processed data.\n\n    Notes\n    -----\n    This must be a top-level function to be pickle-able.\n\n    """"""\n    # do not process the data, if the first item (i.e. Processor) is None\n    if process_tuple[0] is None:\n        return process_tuple[1]\n    # call the Processor with data and kwargs\n    elif isinstance(process_tuple[0], Processor):\n        return process_tuple[0](*process_tuple[1:-1], **process_tuple[-1])\n    # just call whatever we got here (e.g. a function) without kwargs\n    return process_tuple[0](*process_tuple[1:-1])\n\n\nclass SequentialProcessor(MutableSequence, Processor):\n    """"""\n    Processor class for sequential processing of data.\n\n    Parameters\n    ----------\n    processors : list\n         Processor instances to be processed sequentially.\n\n    Notes\n    -----\n    If the `processors` list contains lists or tuples, these get wrapped as a\n    SequentialProcessor itself.\n\n    """"""\n\n    def __init__(self, processors):\n        self.processors = []\n        # iterate over all given processors and save them\n        for processor in processors:\n            # wrap lists and tuples as a SequentialProcessor\n            if isinstance(processor, (list, tuple)):\n                processor = SequentialProcessor(processor)\n            # save the processors\n            self.processors.append(processor)\n\n    def __getitem__(self, index):\n        """"""\n        Get the Processor at the given processing chain position.\n\n        Parameters\n        ----------\n        index : int\n            Position inside the processing chain.\n\n        Returns\n        -------\n        :class:`Processor`\n            Processor at the given position.\n\n        """"""\n        return self.processors[index]\n\n    def __setitem__(self, index, processor):\n        """"""\n        Set the Processor at the given processing chain position.\n\n        Parameters\n        ----------\n        index : int\n            Position inside the processing chain.\n        processor : :class:`Processor`\n            Processor to set.\n\n        """"""\n        self.processors[index] = processor\n\n    def __delitem__(self, index):\n        """"""\n        Delete the Processor at the given processing chain position.\n\n        Parameters\n        ----------\n        index : int\n            Position inside the processing chain.\n\n        """"""\n        del self.processors[index]\n\n    def __len__(self):\n        """"""Length of the processing chain.""""""\n        return len(self.processors)\n\n    def insert(self, index, processor):\n        """"""\n        Insert a Processor at the given processing chain position.\n\n        Parameters\n        ----------\n        index : int\n            Position inside the processing chain.\n        processor : :class:`Processor`\n            Processor to insert.\n\n        """"""\n        self.processors.insert(index, processor)\n\n    def append(self, other):\n        """"""\n        Append another Processor to the processing chain.\n\n        Parameters\n        ----------\n        other : :class:`Processor`\n            Processor to append to the processing chain.\n\n        """"""\n        self.processors.append(other)\n\n    def extend(self, other):\n        """"""\n        Extend the processing chain with a list of Processors.\n\n        Parameters\n        ----------\n        other : list\n            Processors to be appended to the processing chain.\n\n        """"""\n        self.processors.extend(other)\n\n    def process(self, data, **kwargs):\n        """"""\n        Process the data sequentially with the defined processing chain.\n\n        Parameters\n        ----------\n        data : depends on the first processor of the processing chain\n            Data to be processed.\n        kwargs : dict, optional\n            Keyword arguments for processing.\n\n        Returns\n        -------\n        depends on the last processor of the processing chain\n            Processed data.\n\n        """"""\n        # sequentially process the data\n        for processor in self.processors:\n            data = _process((processor, data, kwargs))\n        return data\n\n\n# inherit from SequentialProcessor because of append() and extend()\nclass ParallelProcessor(SequentialProcessor):\n    """"""\n    Processor class for parallel processing of data.\n\n    Parameters\n    ----------\n    processors : list\n        Processor instances to be processed in parallel.\n    num_threads : int, optional\n        Number of parallel working threads.\n\n    Notes\n    -----\n    If the `processors` list contains lists or tuples, these get wrapped as a\n    :class:`SequentialProcessor`.\n\n    """"""\n    # pylint: disable=too-many-ancestors\n\n    def __init__(self, processors, num_threads=None):\n        # set the processing chain\n        super(ParallelProcessor, self).__init__(processors)\n        # number of threads\n        if num_threads is None:\n            num_threads = 1\n        # Note: we must define the map function here, otherwise it leaks both\n        #       memory and file descriptors if we init the pool in the process\n        #       method. This also means that we must use only 1 thread if we\n        #       want to pickle the Processor, because map is pickle-able,\n        #       whereas mp.Pool().map is not.\n        self.map = map\n        if min(len(processors), max(1, num_threads)) > 1:\n            self.map = mp.Pool(num_threads).map\n\n    def process(self, data, **kwargs):\n        """"""\n        Process the data in parallel.\n\n        Parameters\n        ----------\n        data : depends on the processors\n            Data to be processed.\n        kwargs : dict, optional\n            Keyword arguments for processing.\n\n        Returns\n        -------\n        list\n            Processed data.\n\n        """"""\n        # if only a single processor is given, there\'s no need to map()\n        if len(self.processors) == 1:\n            return [_process((self.processors[0], data, kwargs))]\n        # process data in parallel and return a list with processed data\n        return list(self.map(_process, zip(self.processors, it.repeat(data),\n                                           it.repeat(kwargs))))\n\n\nclass IOProcessor(OutputProcessor):\n    """"""\n    Input/Output Processor which processes the input data with the input\n    processor and pipes everything into the given output processor.\n\n    All Processors defined in the input chain are sequentially called with the\n    \'data\' argument only. The output Processor is the only one ever called with\n    two arguments (\'data\', \'output\').\n\n    Parameters\n    ----------\n    in_processor : :class:`Processor`, function, tuple or list\n        Input processor. Can be a :class:`Processor` (or subclass thereof\n        like :class:`SequentialProcessor` or :class:`ParallelProcessor`), a\n        function accepting a single argument (\'data\'). If a tuple or list\n        is given, it is wrapped as a :class:`SequentialProcessor`.\n    out_processor : :class:`OutputProcessor`, function, tuple or list\n        OutputProcessor or function accepting two arguments (\'data\', \'output\').\n        If a tuple or list is given, it is wrapped in an :class:`IOProcessor`\n        itself with the last element regarded as the `out_processor` and all\n        others as `in_processor`.\n\n    """"""\n\n    def __init__(self, in_processor, out_processor=None):\n        # TODO: check the input and output processors!?\n        #       as input a Processor, SequentialProcessor, ParallelProcessor\n        #       or a function with only one argument should be accepted\n        #       as output a OutputProcessor, IOProcessor or function with two\n        #       arguments should be accepted\n        # wrap the input processor in a SequentialProcessor if needed\n        if isinstance(in_processor, (list, tuple)):\n            self.in_processor = SequentialProcessor(in_processor)\n        else:\n            self.in_processor = in_processor\n        # wrap the output processor in an IOProcessor if needed\n        if isinstance(out_processor, (list, tuple)):\n            if len(out_processor) >= 2:\n                # use the last processor as output and all others as input\n                self.out_processor = IOProcessor(out_processor[:-1],\n                                                 out_processor[-1])\n            if len(out_processor) == 1:\n                self.out_processor = out_processor[0]\n        else:\n            self.out_processor = out_processor\n\n    def __getitem__(self, index):\n        """"""\n        Get the Processor at the given position.\n\n        Parameters\n        ----------\n        index : int\n            Processor position. Index \'0\' refers to the `in_processor`,\n            index \'1\' to the `out_processor`.\n\n        Returns\n        -------\n        :class:`Processor`\n            Processor at the given position.\n\n        """"""\n        if index == 0:\n            return self.in_processor\n        elif index == 1:\n            return self.out_processor\n        else:\n            raise IndexError(\'Only `in_processor` at index 0 and \'\n                             \'`out_processor` at index 1 are defined.\')\n\n    def process(self, data, output=None, **kwargs):\n        """"""\n        Processes the data with the input processor and pipe everything into\n        the output processor, which also pipes it to `output`.\n\n        Parameters\n        ----------\n        data : depends on the input processors\n            Data to be processed.\n        output: str or file handle\n            Output file (handle).\n        kwargs : dict, optional\n            Keyword arguments for processing.\n\n        Returns\n        -------\n        depends on the output processors\n            Processed data.\n\n        """"""\n        # process the data by the input processor\n        data = _process((self.in_processor, data, kwargs))\n        # process the data by the output processor and return it\n        return _process((self.out_processor, data, output, kwargs))\n\n\n# functions and classes to process files with a Processor\ndef process_single(processor, infile, outfile, **kwargs):\n    """"""\n    Process a single file with the given Processor.\n\n    Parameters\n    ----------\n    processor : :class:`Processor` instance\n        Processor to be processed.\n    infile : str or file handle\n        Input file (handle).\n    outfile : str or file handle\n        Output file (handle).\n\n    """"""\n    # pylint: disable=unused-argument\n    # adjust origin in online mode\n    if kwargs.get(\'online\'):\n        kwargs[\'origin\'] = \'online\'\n        kwargs[\'reset\'] = False\n    # process the input file\n    _process((processor, infile, outfile, kwargs))\n\n\nclass _ParallelProcess(mp.Process):\n    """"""\n    Class for processing tasks in a queue.\n\n    Parameters\n    ----------\n    task_queue :\n        Queue with tasks, i.e. tuples (\'processor\', \'infile\', \'outfile\')\n\n    Notes\n    -----\n    Usually, multiple instances are created via :func:`process_batch`.\n\n    """"""\n    def __init__(self, task_queue):\n        super(_ParallelProcess, self).__init__()\n        self.task_queue = task_queue\n\n    def run(self):\n        """"""Process all tasks from the task queue.""""""\n        from .io.audio import LoadAudioFileError\n        while True:\n            # get the task tuple\n            processor, infile, outfile, kwargs = self.task_queue.get()\n            try:\n                # process the Processor with the data\n                _process((processor, infile, outfile, kwargs))\n            except LoadAudioFileError as e:\n                print(e)\n            finally:\n                # signal that it is done\n                self.task_queue.task_done()\n\n\n# function to batch process multiple files with a processor\ndef process_batch(processor, files, output_dir=None, output_suffix=None,\n                  strip_ext=True, num_workers=mp.cpu_count(), shuffle=False,\n                  **kwargs):\n    """"""\n    Process a list of files with the given Processor in batch mode.\n\n    Parameters\n    ----------\n    processor : :class:`Processor` instance\n        Processor to be processed.\n    files : list\n        Input file(s) (handles).\n    output_dir : str, optional\n        Output directory.\n    output_suffix : str, optional\n        Output suffix (e.g. \'.txt\' including the dot).\n    strip_ext : bool, optional\n        Strip off the extension from the input files.\n    num_workers : int, optional\n        Number of parallel working threads.\n    shuffle : bool, optional\n        Shuffle the `files` before distributing them to the working threads\n\n    Notes\n    -----\n    Either `output_dir` and/or `output_suffix` must be set. If `strip_ext` is\n    True, the extension of the input file names is stripped off before the\n    `output_suffix` is appended to the input file names.\n\n    Use `shuffle` if you experience out of memory errors (can occur for certain\n    methods with high memory consumptions if consecutive files are rather\n    long).\n\n    """"""\n    # pylint: disable=unused-argument\n    # either output_dir or output_suffix must be given\n    if output_dir is None and output_suffix is None:\n        raise ValueError(\'either output directory or suffix must be given\')\n    # make sure the directory exists\n    if output_dir is not None:\n        try:\n            # create output directory\n            os.mkdir(output_dir)\n        except OSError:\n            # directory exists already\n            pass\n\n    # create task queue\n    tasks = mp.JoinableQueue()\n    # create working threads\n    processes = [_ParallelProcess(tasks) for _ in range(num_workers)]\n    for p in processes:\n        p.daemon = True\n        p.start()\n\n    # shuffle files?\n    if shuffle:\n        from random import shuffle\n        shuffle(files)\n\n    # process all the files\n    for input_file in files:\n        # set the output file name\n        if output_dir is not None:\n            output_file = ""%s/%s"" % (output_dir, os.path.basename(input_file))\n        else:\n            output_file = input_file\n        # strip off the extension\n        if strip_ext:\n            output_file = os.path.splitext(output_file)[0]\n        # append the suffix if needed\n        if output_suffix is not None:\n            output_file += output_suffix\n        # put processing tasks in the queue\n        tasks.put((processor, input_file, output_file, kwargs))\n    # wait for all processing tasks to finish\n    tasks.join()\n\n\n# processor for buffering data\nclass BufferProcessor(Processor):\n    """"""\n    Buffer for processors which need context to do their processing.\n\n    Parameters\n    ----------\n    buffer_size : int or tuple\n        Size of the buffer (time steps, [additional dimensions]).\n    init : numpy array, optional\n        Init the buffer with this array.\n    init_value : float, optional\n        If only `buffer_size` is given but no `init`, use this value to\n        initialise the buffer.\n\n    Notes\n    -----\n    If `buffer_size` (or the first item thereof in case of tuple) is 1,\n    only the un-buffered current value is returned.\n\n    If context is needed, `buffer_size` must be set to >1.\n    E.g. SpectrogramDifference needs a context of two frames to be able to\n    compute the difference between two consecutive frames.\n\n    """"""\n\n    def __init__(self, buffer_size=None, init=None, init_value=0):\n        # if init is given, infer buffer_size from it\n        if buffer_size is None and init is not None:\n            buffer_size = init.shape\n        # if buffer_size is int, make a tuple\n        elif isinstance(buffer_size, integer_types):\n            buffer_size = (buffer_size, )\n        # TODO: use np.pad for fancy initialisation (can be done in process())\n        # init buffer if needed\n        if buffer_size is not None and init is None:\n            init = np.ones(buffer_size) * init_value\n        # save variables\n        self.buffer_size = buffer_size\n        self.init = init\n        self.data = init\n\n    @property\n    def buffer_length(self):\n        """"""Length of the buffer (time steps).""""""\n        return self.buffer_size[0]\n\n    def reset(self, init=None):\n        """"""\n        Reset BufferProcessor to its initial state.\n\n        Parameters\n        ----------\n        init : numpy array, shape (num_hiddens,), optional\n            Reset BufferProcessor to this initial state.\n\n        """"""\n        self.data = init if init is not None else self.init\n\n    def process(self, data, **kwargs):\n        """"""\n        Buffer the data.\n\n        Parameters\n        ----------\n        data : numpy array or subclass thereof\n            Data to be buffered.\n\n        Returns\n        -------\n        numpy array or subclass thereof\n            Data with buffered context.\n\n        Notes\n        -----\n        If the length of data is the same as the buffer\'s length, the data of\n        the buffer is completely overwritten by new data. If it exceeds the\n        length, only the latest \'buffer_length\' items of data are used.\n\n        """"""\n        # expected minimum number of dimensions\n        ndmin = len(self.buffer_size)\n        # cast the data to have that many dimensions\n        if data.ndim < ndmin:\n            data = np.array(data, copy=False, subok=True, ndmin=ndmin)\n        # length of the data\n        data_length = len(data)\n        # if length of data exceeds buffer length simply replace buffer data\n        if data_length >= self.buffer_length:\n            self.data = data[-self.buffer_length:]\n        else:\n            # roll buffer by `data_length`, i.e. move data to the \'left\'\n            self.data = np.roll(self.data, -data_length, axis=0)\n            # overwrite \'right\' part with new data\n            self.data[-data_length:] = data\n        # return the complete buffer\n        return self.data\n\n    # alias for easier / more intuitive calling\n    buffer = process\n\n    def __getitem__(self, index):\n        """"""\n        Direct access to the buffer data.\n\n        Parameters\n        ----------\n        index : int, slice, ndarray,\n            Any NumPy indexing method to access the buffer data directly.\n\n        Returns\n        -------\n        numpy array or subclass thereof\n            Requested view of the buffered data.\n\n        """"""\n        return self.data[index]\n\n\n# function to process live input\ndef process_online(processor, infile, outfile, **kwargs):\n    """"""\n    Process a file or audio stream with the given Processor.\n\n    Parameters\n    ----------\n    processor : :class:`Processor` instance\n        Processor to be processed.\n    infile : str or file handle, optional\n        Input file (handle). If none is given, the stream present at the\n        system\'s audio input is used. Additional keyword arguments can be used\n        to influence the frame size and hop size.\n    outfile : str or file handle\n        Output file (handle).\n    kwargs : dict, optional\n        Keyword arguments passed to :class:`.audio.signal.Stream` if\n        `in_stream` is \'None\'.\n\n    Notes\n    -----\n    Right now there is no way to determine if a processor is online-capable or\n    not. Thus, calling any processor with this function may not produce the\n    results expected.\n\n    """"""\n    from madmom.audio.signal import Stream, FramedSignal\n    # set default values\n    kwargs[\'sample_rate\'] = kwargs.get(\'sample_rate\', 44100)\n    kwargs[\'num_channels\'] = kwargs.get(\'num_channels\', 1)\n    # list all available PyAudio devices and exit afterwards\n    if kwargs[\'list_stream_input_device\']:\n        import pyaudio\n        pa = pyaudio.PyAudio()\n        for i in range(pa.get_device_count()):\n            info = pa.get_device_info_by_index(i)\n            print(\'%d: %s\' % (info[\'index\'], info[\'name\']))\n        exit(0)\n\n    # if no input file is given, create a Stream with the given arguments\n    if infile is None:\n        # open a stream and start if not running already\n        stream = Stream(**kwargs)\n        if not stream.is_running():\n            stream.start()\n    # use the input file\n    else:\n        # set parameters for opening the file\n        from .audio.signal import FRAME_SIZE, HOP_SIZE, FPS, NUM_CHANNELS\n        frame_size = kwargs.get(\'frame_size\', FRAME_SIZE)\n        hop_size = kwargs.get(\'hop_size\', HOP_SIZE)\n        fps = kwargs.get(\'fps\', FPS)\n        num_channels = kwargs.get(\'num_channels\', NUM_CHANNELS)\n        # FIXME: overwrite the frame size with the maximum value of all used\n        #        processors. This is needed if multiple frame sizes are used\n        import warnings\n        warnings.warn(\'make sure that the `frame_size` (%d) is equal to the \'\n                      \'maximum value used by any `FramedSignalProcessor`.\' %\n                      frame_size)\n        # Note: origin must be \'online\' and num_frames \'None\' to behave exactly\n        #       the same as with live input\n        stream = FramedSignal(infile, frame_size=frame_size, hop_size=hop_size,\n                              fps=fps, origin=\'online\', num_frames=None,\n                              num_channels=num_channels)\n    # set arguments for online processing\n    # Note: pass only certain arguments, because these will be passed to the\n    #       processors at every time step (kwargs contains file handles etc.)\n    process_args = {\'reset\': False}  # do not reset stateful processors\n    # process everything frame-by-frame\n    for frame in stream:\n        _process((processor, frame, outfile, process_args))\n\n\n# function for pickling a processor\ndef pickle_processor(processor, outfile, **kwargs):\n    """"""\n    Pickle the Processor to a file.\n\n    Parameters\n    ----------\n    processor : :class:`Processor` instance\n        Processor to be pickled.\n    outfile : str or file handle\n        Output file (handle) where to pickle it.\n\n    """"""\n    # pylint: disable=unused-argument\n    processor.dump(outfile)\n\n\n# generic input/output arguments for scripts\ndef io_arguments(parser, output_suffix=\'.txt\', pickle=True, online=False):\n    """"""\n    Add input / output related arguments to an existing parser.\n\n    Parameters\n    ----------\n    parser : argparse parser instance\n        Existing argparse parser object.\n    output_suffix : str, optional\n        Suffix appended to the output files.\n    pickle : bool, optional\n        Add a \'pickle\' sub-parser to the parser.\n    online : bool, optional\n        Add a \'online\' sub-parser to the parser.\n\n    """"""\n    # default output\n    try:\n        output = sys.stdout.buffer\n    except AttributeError:\n        output = sys.stdout\n    # add general options\n    parser.add_argument(\'-v\', dest=\'verbose\', action=\'count\',\n                        help=\'increase verbosity level\')\n    # add subparsers\n    sub_parsers = parser.add_subparsers(title=\'processing options\')\n\n    # pickle processor options\n    if pickle:\n        sp = sub_parsers.add_parser(\'pickle\', help=\'pickle processor\')\n        sp.set_defaults(func=pickle_processor)\n        # Note: requiring \'-o\' is a simple safety measure to not overwrite\n        #       existing audio files after using the processor in \'batch\' mode\n        sp.add_argument(\'-o\', dest=\'outfile\', type=argparse.FileType(\'wb\'),\n                        default=output, help=\'output file [default: STDOUT]\')\n\n    # single file processing options\n    sp = sub_parsers.add_parser(\'single\', help=\'single file processing\')\n    sp.set_defaults(func=process_single)\n    sp.add_argument(\'infile\', type=argparse.FileType(\'rb\'),\n                    help=\'input audio file\')\n    # Note: requiring \'-o\' is a simple safety measure to not overwrite existing\n    #       audio files after using the processor in \'batch\' mode\n    sp.add_argument(\'-o\', dest=\'outfile\', type=argparse.FileType(\'wb\'),\n                    default=output, help=\'output file [default: STDOUT]\')\n    sp.add_argument(\'-j\', dest=\'num_threads\', type=int, default=mp.cpu_count(),\n                    help=\'number of threads [default=%(default)s]\')\n    # add arguments needed for loading processors\n    if online:\n        sp.add_argument(\'--online\', action=\'store_true\', default=None,\n                        help=\'use online settings [default: offline]\')\n\n    # batch file processing options\n    sp = sub_parsers.add_parser(\'batch\', help=\'batch file processing\')\n    sp.set_defaults(func=process_batch)\n    sp.add_argument(\'files\', nargs=\'+\', help=\'files to be processed\')\n    sp.add_argument(\'-o\', dest=\'output_dir\', default=None,\n                    help=\'output directory [default=%(default)s]\')\n    sp.add_argument(\'-s\', dest=\'output_suffix\', default=output_suffix,\n                    help=\'suffix appended to the files (dot must be included \'\n                         \'if wanted) [default=%(default)s]\')\n    sp.add_argument(\'--ext\', dest=\'strip_ext\', action=\'store_false\',\n                    help=\'keep the extension of the input file [default=\'\n                         \'strip it off before appending the output suffix]\')\n    sp.add_argument(\'-j\', dest=\'num_workers\', type=int, default=mp.cpu_count(),\n                    help=\'number of workers [default=%(default)s]\')\n    sp.add_argument(\'--shuffle\', action=\'store_true\',\n                    help=\'shuffle files before distributing them to the \'\n                         \'working threads [default=process them in sorted \'\n                         \'order]\')\n    sp.set_defaults(num_threads=1)\n\n    # online processing options\n    if online:\n        sp = sub_parsers.add_parser(\'online\', help=\'online processing\')\n        sp.set_defaults(func=process_online)\n        sp.add_argument(\'infile\', nargs=\'?\', type=argparse.FileType(\'rb\'),\n                        default=None, help=\'input audio file (if no file is \'\n                                           \'given, a stream operating on the \'\n                                           \'system audio input is used)\')\n        sp.add_argument(\'-o\', dest=\'outfile\', type=argparse.FileType(\'wb\'),\n                        default=output, help=\'output file [default: STDOUT]\')\n        sp.add_argument(\'-j\', dest=\'num_threads\', type=int, default=1,\n                        help=\'number of threads [default=%(default)s]\')\n        sp.add_argument(\'--device\', dest=\'stream_input_device\', type=int,\n                        default=None, help=\'PyAudio device index of the \'\n                                           \'desired input device \'\n                                           \'[default=%(default)s]\')\n        sp.add_argument(\'--list\', dest=\'list_stream_input_device\',\n                        action=\'store_true\', default=False,\n                        help=\'show a list of available PyAudio devices; index \'\n                             \'can be used as STREAM_INPUT_DEVICE for the \'\n                             \'--device argument\')\n        # set arguments for loading processors\n        sp.set_defaults(online=True)      # use online settings/parameters\n        sp.set_defaults(num_frames=1)     # process everything frame-by-frame\n        sp.set_defaults(origin=\'stream\')  # set origin to get whole frame\n'"
tests/__init__.py,0,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis module contains tests.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport os\n\nBASE_PATH = os.path.dirname(os.path.realpath(__file__))\nDATA_PATH = os.path.join(BASE_PATH, \'data\')\nAUDIO_PATH = os.path.join(DATA_PATH, \'audio\')\nACTIVATIONS_PATH = os.path.join(DATA_PATH, \'activations\')\nANNOTATIONS_PATH = os.path.join(DATA_PATH, \'annotations\')\nDETECTIONS_PATH = os.path.join(DATA_PATH, \'detections\')\n'"
tests/test_audio_chroma.py,12,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.audio.chroma module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\nimport unittest\nfrom . import AUDIO_PATH, ACTIVATIONS_PATH\nfrom madmom.audio.chroma import DeepChromaProcessor, CLPChroma\nfrom madmom.features import Activations\nfrom os.path import join as pj\nfrom madmom.audio.signal import Signal\n\nsample_files = [pj(AUDIO_PATH, sf) for sf in [\'sample.wav\', \'sample2.wav\']]\nsample_acts = [Activations(pj(ACTIVATIONS_PATH, af))\n               for af in [\'sample.deep_chroma.npz\', \'sample2.deep_chroma.npz\']]\nsample_file = pj(AUDIO_PATH, \'sample.wav\')\nsample_file_22050 = pj(AUDIO_PATH, \'sample_22050.wav\')\nsample_act_deep_chroma = Activations(pj(ACTIVATIONS_PATH,\n                                        \'sample.deep_chroma.npz\'))\n\n\nclass TestDeepChromaProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = DeepChromaProcessor()\n\n    def test_process(self):\n        for f, a in zip(sample_files, sample_acts):\n            self.assertTrue(np.allclose(self.processor(f), a))\n\n\nclass TestCLPChromaClass(unittest.TestCase):\n\n    def setUp(self):\n        self.clp_50 = CLPChroma(sample_file, fps=50)\n        self.clp_10 = CLPChroma(sample_file, fps=10)\n        self.clp_22050 = CLPChroma(sample_file_22050, fps=50, fmin=2637,\n                                   fmax=4200)\n        data = Signal(sample_file)\n        self.clp_10_from_signal = CLPChroma(data, fps=10)\n\n    def test_process(self):\n        # test with fps=50\n        self.assertTrue(self.clp_50.bin_labels[0] == \'C\')\n        self.assertTrue(self.clp_50.fps == 50)\n        # results\n        self.assertTrue(self.clp_50.shape == (141, 12))\n        tar = [0.28222724, 0.2145749, 0.29143909, 0.31838085, 0.21754939,\n               0.24475572, 0.16546808, 0.32018109, 0.39918812, 0.30166908,\n               0.26142349, 0.3635601]\n        self.assertTrue(np.allclose(self.clp_50[39, :], tar, atol=1e-4))\n        tar = [0.62827758, 0.63810707, 0.64559874, 0.63725388, 0.60231739,\n               0.56549827, 0.49675867, 0.40509999, 0.38589308, 0.39961286,\n               0.43776578]\n        self.assertTrue(np.allclose(self.clp_50[100:111, 8], tar, atol=1e-5))\n        # test with fps=10\n        self.assertTrue(self.clp_10.bin_labels[0] == \'C\')\n        self.assertTrue(self.clp_10.fps == 10)\n        # results\n        self.assertTrue(self.clp_10.shape == (29, 12))\n        tar = [[0.23144638, 0.42642003], [0.23364208, 0.49532055],\n               [0.2099782, 0.53246478], [0.2120323, 0.49525887]]\n        self.assertTrue(np.allclose(self.clp_10[2:6, 7:9], tar, atol=1e-4))\n        # test clp from signal\n        self.assertTrue(self.clp_10_from_signal.shape == (29, 12))\n        self.assertTrue(np.allclose(self.clp_10_from_signal[2:6, 7:9],\n                                    tar, atol=1e-4))\n        # test 22050 Hz sampling rate. If we use only bands above 2637 Hz,\n        # no resampling is necessary and we can therefore compare with\n        # smaller tolerances.\n        self.assertTrue(self.clp_22050.shape == (141, 12))\n        tar = [[0.11270745, 0, 0, 0, 0.25741291, 0.58624929, 0.43997279,\n                0.0999583, 0.21696206, 0.54994475, 0.05542545, 0.14558826]]\n        self.assertTrue(np.allclose(self.clp_22050[140, :], tar))\n\n    def test_compare_with_matlab_toolbox(self):\n        # compare the results with the MATLAB chroma toolbox. There are\n        # differences because of different resampling and filtering with\n        # filtfilt, therefore we compare with higher tolerances\n        tar = np.array([0.28202948, 0.21473163, 0.29178235, 0.31837119,\n                        0.21773027, 0.24484771, 0.16606759, 0.32054708,\n                        0.39850856, 0.30126012, 0.26116133, 0.36386101])\n        self.assertTrue(np.allclose(self.clp_50[39, :], tar, rtol=1e-02))\n        tar = np.array([0.62898520, 0.63870508, 0.64272228, 0.63746036,\n                        0.60277398, 0.56819617, 0.49709058, 0.40472238,\n                        0.38589948, 0.39892429, 0.43579584])\n        self.assertTrue(np.allclose(self.clp_50[100:111, 8], tar, rtol=1e-02))\n        tar = np.array([[0.22728066, 0.42691203], [0.23012684, 0.49625964],\n                        [0.20832211, 0.53284996], [0.21247771, 0.49591485]])\n        self.assertTrue(np.allclose(self.clp_10[2:6, 7:9], tar, rtol=2e-02))\n'"
tests/test_audio_comb_filters.py,40,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.audio.comb_filters module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\n\nfrom madmom.audio.comb_filters import *\n\nsig_1d = np.asarray([0, 0, 1, 0, 0, 1, 0, 0, 1], dtype=np.float)\nsig_2d = np.asarray([[0, 0, 1, 0, 0, 1, 0, 0, 1],\n                     [1, 0, 1, 0, 1, 0, 1, 0, 1]], dtype=np.float).T\n\n\n# test forward filters\nres_1d_fw_2 = np.asarray([0, 0, 1, 0, 0.5, 1, 0, 0.5, 1])\nres_1d_fw_3 = np.asarray([0, 0, 1, 0, 0, 1.5, 0, 0, 1.5])\nres_2d_fw_2 = np.asarray([[0, 0, 1, 0, 0.5, 1, 0, 0.5, 1],\n                          [1, 0, 1.5, 0, 1.5, 0, 1.5, 0, 1.5]]).T\nres_2d_fw_3 = np.asarray([[0, 0, 1, 0, 0, 1.5, 0, 0, 1.5],\n                          [1, 0, 1, 0.5, 1, 0.5, 1, 0.5, 1]]).T\n\n\nclass TestFeedForwardFilterFunction(unittest.TestCase):\n\n    def test_types(self):\n        result = feed_forward_comb_filter(sig_1d, 2, 0.5)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(type(result), float)\n\n    def test_values(self):\n        result = feed_forward_comb_filter(sig_1d, 2, 0.5)\n        self.assertTrue(np.allclose(result, res_1d_fw_2))\n        result = feed_forward_comb_filter(sig_1d, 3, 0.5)\n        self.assertTrue(np.allclose(result, res_1d_fw_3))\n        result = feed_forward_comb_filter(sig_2d, 2, 0.5)\n        self.assertTrue(np.allclose(result, res_2d_fw_2))\n        result = feed_forward_comb_filter(sig_2d, 3, 0.5)\n        self.assertTrue(np.allclose(result, res_2d_fw_3))\n\n\n# test backward filters\nres_1d_bw_2 = np.asarray([0, 0, 1, 0, 0.5, 1, 0.25, 0.5, 1.125])\n\nres_1d_bw_3 = np.asarray([0, 0, 1, 0, 0, 1.5, 0, 0, 1.75])\n\nres_2d_bw_2 = np.asarray([[0, 0, 1, 0, 0.5, 1, 0.25, 0.5, 1.125],\n                          [1, 0, 1.5, 0, 1.75, 0, 1.875, 0, 1.9375]]).T\n\nres_2d_bw_3 = np.asarray([[0, 0, 1, 0, 0, 1.5, 0, 0, 1.75],\n                          [1, 0, 1, 0.5, 1, 0.5, 1.25, 0.5, 1.25]]).T\n\n\nclass TestFeedBackwardFilterFunction(unittest.TestCase):\n\n    def test_types(self):\n        result = feed_forward_comb_filter(sig_1d, 2, 0.5)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(type(result), float)\n        result = feed_backward_comb_filter(sig_2d, 2, 0.5)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(type(result), float)\n\n    def test_values(self):\n        result = feed_backward_comb_filter(sig_1d, 2, 0.5)\n        self.assertTrue(np.allclose(result, res_1d_bw_2))\n        result = feed_backward_comb_filter(sig_1d, 3, 0.5)\n        self.assertTrue(np.allclose(result, res_1d_bw_3))\n        result = feed_backward_comb_filter(sig_2d, 2, 0.5)\n        self.assertTrue(np.allclose(result, res_2d_bw_2))\n        result = feed_backward_comb_filter(sig_2d, 3, 0.5)\n        self.assertTrue(np.allclose(result, res_2d_bw_3))\n\n\n# test other stuff\nclass TestCombFilterFunction(unittest.TestCase):\n\n    def test_types(self):\n        function = feed_backward_comb_filter\n        result = comb_filter(sig_1d, function, [2, 3], [0.5, 0.5])\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(type(result), float)\n        function = feed_forward_comb_filter\n        result = comb_filter(sig_1d, function, [2, 3], [0.5, 0.5])\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(type(result), float)\n\n    def test_values_backward(self):\n        function = feed_backward_comb_filter\n        result = comb_filter(sig_1d, function, [2, 3], [0.5, 0.5])\n        self.assertTrue(np.allclose(result[:, 0], res_1d_bw_2))\n        self.assertTrue(np.allclose(result[:, 1], res_1d_bw_3))\n        result = comb_filter(sig_2d, function, [2, 3], [0.5, 0.5])\n        self.assertTrue(np.allclose(result[:, :, 0], res_2d_bw_2))\n        self.assertTrue(np.allclose(result[:, :, 1], res_2d_bw_3))\n\n    def test_values_forward(self):\n        function = feed_forward_comb_filter\n        result = comb_filter(sig_1d, function, [2, 3], [0.5, 0.5])\n        self.assertTrue(np.allclose(result[:, 0], res_1d_fw_2))\n        self.assertTrue(np.allclose(result[:, 1], res_1d_fw_3))\n        result = comb_filter(sig_2d, function, [2, 3], [0.5, 0.5])\n        self.assertTrue(np.allclose(result[:, :, 0], res_2d_fw_2))\n        self.assertTrue(np.allclose(result[:, :, 1], res_2d_fw_3))\n\n\nclass TestCombFilterbankClass(unittest.TestCase):\n\n    def test_types(self):\n        # backward function\n        processor = CombFilterbankProcessor(feed_backward_comb_filter,\n                                            [2, 3], [0.5, 0.5])\n        self.assertIsInstance(processor, CombFilterbankProcessor)\n        self.assertIsInstance(processor, Processor)\n        self.assertTrue(processor.filter_function == feed_backward_comb_filter)\n        processor = CombFilterbankProcessor(\'backward\', [2, 3], [0.5, 0.5])\n        self.assertTrue(processor.filter_function == feed_backward_comb_filter)\n        # forward function\n        processor = CombFilterbankProcessor(feed_forward_comb_filter,\n                                            [2, 3], [0.5, 0.5])\n        self.assertTrue(processor.filter_function == feed_forward_comb_filter)\n        processor = CombFilterbankProcessor(\'forward\', [2, 3], [0.5, 0.5])\n        self.assertTrue(processor.filter_function == feed_forward_comb_filter)\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            CombFilterbankProcessor(\'xyz\', [2, 3], [0.5, 0.5])\n\n    def test_values_backward(self):\n        processor = CombFilterbankProcessor(feed_backward_comb_filter,\n                                            [2, 3], [0.5, 0.5])\n        result = processor.process(sig_1d)\n        self.assertTrue(np.allclose(result[:, 0], res_1d_bw_2))\n        self.assertTrue(np.allclose(result[:, 1], res_1d_bw_3))\n        result = processor.process(sig_2d)\n        self.assertTrue(np.allclose(result[:, :, 0], res_2d_bw_2))\n        self.assertTrue(np.allclose(result[:, :, 1], res_2d_bw_3))\n\n    def test_values_forward(self):\n        processor = CombFilterbankProcessor(feed_forward_comb_filter,\n                                            [2, 3], [0.5, 0.5])\n        result = processor.process(sig_1d)\n        self.assertTrue(np.allclose(result[:, 0], res_1d_fw_2))\n        self.assertTrue(np.allclose(result[:, 1], res_1d_fw_3))\n        result = processor.process(sig_2d)\n        self.assertTrue(np.allclose(result[:, :, 0], res_2d_fw_2))\n        self.assertTrue(np.allclose(result[:, :, 1], res_2d_fw_3))\n'"
tests/test_audio_filters.py,248,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.audio.filters module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nimport types\nimport tempfile\n\nfrom madmom.audio.filters import *\n\n\n# Mel frequency scale\nHZ = np.asarray([20, 258.7484, 576.6645, 1000])\nMEL = np.asarray([31.749, 354.5, 677.25, 1000])\nFFT_FREQS_1024 = np.fft.fftfreq(2048, 1. / 44100)[:1024]\nLOG_FILTERBANK_CENTER_FREQS = np.array(\n    [43.066406, 64.5996093, 86.1328125, 107.6660156, 129.199218, 150.732421,\n     172.265625, 193.798828, 215.332031, 236.865234, 258.398437, 279.931640,\n     301.464843, 322.998046, 344.531250, 366.064453, 387.597656, 409.130859,\n     430.664062, 452.197265, 495.263671, 516.796875, 538.330078, 581.396484,\n     624.462890, 645.996093, 689.062500, 732.128906, 775.195312, 839.794921,\n     882.861328, 925.927734, 990.527343, 1055.126953, 1098.193359, 1184.326171,\n     1248.925781, 1313.525390, 1399.658203, 1485.791015, 1571.923828,\n     1658.056640, 1765.722656, 1873.388671, 1981.054687, 2088.720703,\n     2217.919921, 2347.119140, 2497.851562, 2627.050781, 2799.316406,\n     2950.048828, 3143.847656, 3316.113281, 3509.912109, 3725.244140,\n     3940.576171, 4177.441406, 4435.839843, 4694.238281, 4974.169921,\n     5275.634765, 5577.099609, 5921.630859, 6266.162109, 6653.759765,\n     7041.357421, 7450.488281, 7902.685546, 8376.416015, 8871.679687,\n     9388.476562, 9948.339843, 10551.269531, 11175.732421, 11843.261718,\n     12553.857421, 13285.986328, 14082.714843, 14922.509765, 15805.37109375])\nLOG_FILTERBANK_CORNER_FREQS = np.array(\n    [[43.066406, 43.066406], [64.599609, 64.599609], [86.132812, 86.132812],\n     [107.666015, 107.666015], [129.199218, 129.199218],\n     [150.732421, 150.732421], [172.265625, 172.265625],\n     [193.798828, 193.798828], [215.332031, 215.332031],\n     [236.865234, 236.865234], [258.398437, 258.398437],\n     [279.931640, 279.931640], [301.464843, 301.464843],\n     [322.998046, 322.998046], [344.531250, 344.531250],\n     [366.064453, 366.064453], [387.597656, 387.597656],\n     [409.130859, 409.130859], [430.664062, 452.197265],\n     [452.197265, 473.730468], [495.263671, 495.263671],\n     [516.796875, 538.330078], [538.330078, 559.863281],\n     [581.396484, 602.929687], [602.929687, 645.996093],\n     [645.996093, 667.529296], [689.062500, 710.595703],\n     [710.595703, 753.662109], [753.662109, 818.261718],\n     [796.728515, 861.328125], [861.328125, 904.394531],\n     [904.394531, 968.994140], [947.460937, 1033.59375],\n     [1012.060546, 1076.660156], [1076.660156, 1162.792968],\n     [1119.726562, 1227.392578], [1205.859375, 1291.992187],\n     [1270.458984, 1378.125000], [1335.058593, 1464.257812],\n     [1421.191406, 1550.390625], [1507.324218, 1636.523437],\n     [1593.457031, 1744.189453], [1679.589843, 1851.855468],\n     [1787.255859, 1959.521484], [1894.921875, 2067.187500],\n     [2002.587890, 2196.386718], [2110.253906, 2325.585937],\n     [2239.453125, 2476.318359], [2368.652343, 2605.517578],\n     [2519.384765, 2777.783203], [2648.583984, 2928.515625],\n     [2820.849609, 3122.314453], [2971.582031, 3294.580078],\n     [3165.380859, 3488.378906], [3337.646484, 3703.710937],\n     [3531.445312, 3919.042968], [3746.777343, 4155.908203],\n     [3962.109375, 4414.306640], [4198.974609, 4672.705078],\n     [4457.373046, 4952.636718], [4715.771484, 5254.101562],\n     [4995.703125, 5555.566406], [5297.167968, 5900.097656],\n     [5598.632812, 6244.628906], [5943.164062, 6632.226562],\n     [6287.695312, 7019.824218], [6675.292968, 7428.955078],\n     [7062.890625, 7881.152343], [7472.021484, 8354.882812],\n     [7924.218750, 8850.146484], [8397.949218, 9366.943359],\n     [8893.212890, 9926.806640], [9410.009765, 10529.736328],\n     [9969.873046, 11154.199218], [10572.802734, 11821.728515],\n     [11197.265625, 12532.324218], [11864.794921, 13264.453125],\n     [12575.390625, 14061.181640], [13307.519531, 14900.976562],\n     [14104.248046, 15783.837890], [14944.042968, 16731.298828]])\n\n\nclass TestHz2MelFunction(unittest.TestCase):\n\n    def test_types(self):\n        # array\n        result = hz2mel(HZ)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n        # list\n        result = hz2mel([1, 2.])\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n        # single value\n        result = hz2mel(1.1)\n        self.assertIsInstance(result, float)\n        self.assertEqual(result.dtype, np.float)\n\n    def test_value(self):\n        self.assertTrue(np.allclose(hz2mel(HZ), MEL))\n\n\nclass TestMel2HzFunction(unittest.TestCase):\n\n    def test_types(self):\n        # array\n        result = mel2hz(HZ)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n        # list\n        result = mel2hz([1, 2.])\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n        # single value\n        result = mel2hz(1.1)\n        self.assertIsInstance(result, float)\n        self.assertEqual(result.dtype, np.float)\n\n    def test_values(self):\n        self.assertTrue(np.allclose(mel2hz(MEL), HZ))\n\n\nclass TestMelFrequenciesFunction(unittest.TestCase):\n\n    def test_types(self):\n        result = mel_frequencies(4, 20, 1000)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n\n    def test_values(self):\n        # HZ is already mel-scaled, so use this for comparison\n        result = mel_frequencies(4, 20, 1000)\n        self.assertTrue(np.allclose(result, HZ))\n        self.assertEqual(len(result), 4)\n\n\n# Bark frequency scale\nBARK = np.array([20, 100, 200, 300, 400, 510, 630, 770, 920, 1080,\n                 1270, 1480, 1720, 2000, 2320, 2700, 3150, 3700,\n                 4400, 5300, 6400, 7700, 9500, 12000, 15500])\n\nBARK_DOUBLE = np.array([20, 50, 100, 150, 200, 250, 300, 350, 400, 450,\n                        510, 570, 630, 700, 770, 840, 920, 1000, 1080,\n                        1170, 1270, 1370, 1480, 1600, 1720, 1850, 2000,\n                        2150, 2320, 2500, 2700, 2900, 3150, 3400, 3700,\n                        4000, 4400, 4800, 5300, 5800, 6400, 7000, 7700,\n                        8500, 9500, 10500, 12000, 13500, 15500])\n\n\nclass TestHz2BarkFunction(unittest.TestCase):\n\n    def test_raises_warning(self):\n        with self.assertRaises(NotImplementedError):\n            # TODO: write test when implemented\n            hz2bark(HZ)\n\n\nclass TestBark2HzFunction(unittest.TestCase):\n\n    def test_raises_warning(self):\n        with self.assertRaises(NotImplementedError):\n            # TODO: write test when implemented\n            bark2hz(BARK)\n\n\nclass TestBarkFrequenciesFunction(unittest.TestCase):\n\n    def test_types(self):\n        # array\n        result = bark_frequencies()\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.int)\n\n    def test_values(self):\n        # all values\n        self.assertTrue(np.allclose(bark_frequencies(), BARK))\n        # limit range\n        result = bark_frequencies(20, 18000)\n        self.assertTrue(np.allclose(result, BARK))\n        result = bark_frequencies(40, 18000)\n        self.assertTrue(np.allclose(result, BARK[1:]))\n        result = bark_frequencies(40, 12000)\n        self.assertTrue(np.allclose(result, BARK[1:-1]))\n        result = bark_frequencies(40, 11999)\n        self.assertTrue(np.allclose(result, BARK[1:-2]))\n\n\nclass TestBarkDoubleFrequenciesFunction(unittest.TestCase):\n\n    def test_types(self):\n        # array\n        result = bark_double_frequencies()\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.int)\n\n    def test_values(self):\n        # all values\n        self.assertTrue(np.allclose(bark_double_frequencies(), BARK_DOUBLE))\n        # limit range\n        result = bark_double_frequencies(20, 18000)\n        self.assertTrue(np.allclose(result, BARK_DOUBLE))\n        result = bark_double_frequencies(40, 18000)\n        self.assertTrue(np.allclose(result, BARK_DOUBLE[1:]))\n        result = bark_double_frequencies(40, 12000)\n        self.assertTrue(np.allclose(result, BARK_DOUBLE[1:-2]))\n        result = bark_double_frequencies(40, 11999)\n        self.assertTrue(np.allclose(result, BARK_DOUBLE[1:-3]))\n\n\n# logarithmic frequency scale stuff\nclass TestLogFrequenciesFunction(unittest.TestCase):\n\n    def test_num_arguments(self):\n        # number of arguments arguments\n        with self.assertRaises(TypeError):\n            log_frequencies()\n        with self.assertRaises(TypeError):\n            log_frequencies(1)\n        with self.assertRaises(TypeError):\n            log_frequencies(1, 2)\n        with self.assertRaises(TypeError):\n            log_frequencies(1, 2, 3, 4, 5)\n\n    def test_types(self):\n        # return types\n        result = log_frequencies(12, 20, 20000)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n\n    def test_values(self):\n        # all values\n        result = log_frequencies(6, 30, 17000)\n        self.assertTrue(len(result) == 55)\n        # 1 band per octave\n        result = log_frequencies(1, 100, 1000)\n        self.assertTrue(np.allclose(result, [110., 220., 440., 880.]))\n        # different reference frequency\n        result = log_frequencies(1, 100, 1000, 441)\n        self.assertTrue(np.allclose(result, [110.25, 220.5, 441., 882.]))\n\n\nclass TestSemitoneFrequenciesFunction(unittest.TestCase):\n\n    def test_num_arguments(self):\n        # number of arguments\n        with self.assertRaises(TypeError):\n            semitone_frequencies()\n        with self.assertRaises(TypeError):\n            semitone_frequencies(1)\n        with self.assertRaises(TypeError):\n            semitone_frequencies(1, 2, 3, 4)\n\n    def test_types(self):\n        # return types\n        result = semitone_frequencies(20, 20000)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n\n    def test_values(self):\n        # all values\n        result = semitone_frequencies(30, 17000)\n        self.assertTrue(len(result) == 110)\n        # 12 bands per octave\n        result = semitone_frequencies(250, 500)\n        result_ = [261.6255653, 277.18263098, 293.66476792, 311.12698372,\n                   329.62755691, 349.22823143, 369.99442271, 391.99543598,\n                   415.30469758, 440, 466.16376152, 493.88330126]\n        self.assertTrue(len(result) == 12)\n        self.assertTrue(np.allclose(result, result_))\n        # different reference frequency\n        result = semitone_frequencies(441, 500, 441)\n        self.assertTrue(np.allclose(result, [441, 467.22322461, 495.0057633]))\n\n\n# MIDI\nclass TestHz2MidiFunction(unittest.TestCase):\n\n    def test_num_arguments(self):\n        # number of arguments\n        with self.assertRaises(TypeError):\n            hz2midi()\n        with self.assertRaises(TypeError):\n            hz2midi(1, 2, 3)\n\n    def test_types(self):\n        # return types\n        result = hz2midi(20, 440)\n        self.assertIsInstance(result, float)\n        result = hz2midi([20, 40], 440)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n        result = hz2midi(np.arange(10, 20), 440)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n\n    def test_values(self):\n        # single value\n        result = hz2midi(440, 440)\n        self.assertTrue(result == 69)\n        # 12 bands per octave\n        result = hz2midi([220, 440], 440)\n        self.assertTrue(len(result) == 2)\n        self.assertTrue(np.allclose(result, [57, 69]))\n\n\nclass TestMidi2HzFunction(unittest.TestCase):\n\n    def test_num_arguments(self):\n        # number of arguments\n        with self.assertRaises(TypeError):\n            midi2hz()\n        with self.assertRaises(TypeError):\n            midi2hz(1, 2, 3)\n\n    def test_types(self):\n        # return types\n        result = midi2hz(20, 440)\n        self.assertIsInstance(result, float)\n        result = midi2hz([20, 40], 440)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n        result = midi2hz(np.arange(10, 20), 440)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n\n    def test_values(self):\n        # single value\n        result = midi2hz(69, 440)\n        self.assertTrue(result == 440)\n        # 12 bands per octave\n        result = midi2hz([57, 69], 440)\n        self.assertTrue(len(result) == 2)\n        self.assertTrue(np.allclose(result, [220, 440]))\n\n\n# ERB\nERB = np.asarray([0.77873163, 7.03051042, 11.69607601, 15.62144971])\n\n\nclass TestHz2ErbFunction(unittest.TestCase):\n\n    def test_types(self):\n        # array\n        result = hz2erb(HZ)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n        # list\n        result = hz2erb([1, 2.])\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n        # single value\n        result = hz2erb(1.1)\n        self.assertIsInstance(result, float)\n        self.assertEqual(result.dtype, np.float)\n\n    def test_value(self):\n        self.assertTrue(np.allclose(hz2erb(HZ), ERB))\n\n\nclass TestErb2HzFunction(unittest.TestCase):\n\n    def test_types(self):\n        # array\n        result = erb2hz(ERB)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n        # list\n        result = erb2hz([1, 2.])\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n        # single value\n        result = erb2hz(1.1)\n        self.assertIsInstance(result, float)\n        self.assertEqual(result.dtype, np.float)\n\n    def test_value(self):\n        self.assertTrue(np.allclose(erb2hz(ERB), HZ))\n\n\n# helper functions for filter creation\nclass TestFrequencies2BinsFunction(unittest.TestCase):\n\n    freqs = np.asarray([0, 1, 2, 3, 4])\n\n    def test_num_arguments(self):\n        # number of arguments arguments\n        with self.assertRaises(TypeError):\n            frequencies2bins()\n        with self.assertRaises(TypeError):\n            frequencies2bins(1)\n        with self.assertRaises(TypeError):\n            frequencies2bins(1, 2, 3, 4)\n\n    def test_types(self):\n        result = frequencies2bins([0, 1, 2, 3, 4], [0, 1, 2, 3, 4])\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(np.issubdtype(result.dtype, np.integer))\n\n    def test_value(self):\n        # normal frequencies\n        result = frequencies2bins([0, 1, 2, 3, 4], [0, 1, 2, 3, 4])\n        self.assertTrue(np.allclose(result, [0, 1, 2, 3, 4]))\n        # double mapping frequencies\n        result = frequencies2bins([0, 1, 1.1, 1.2, 2, 3, 3.5], [0, 1, 2, 3, 4])\n        self.assertTrue(np.allclose(result, [0, 1, 1, 1, 2, 3, 4]))\n        # higher frequencies should be mapped to the last bin\n        result = frequencies2bins([0, 1, 2, 3, 11], [0, 1, 2, 3, 4])\n        self.assertTrue(np.allclose(result, [0, 1, 2, 3, 4]))\n        # lower frequencies should be mapped to the first bin\n        result = frequencies2bins([-1, 0, 1, 2, 3, 4], [0, 1, 2, 3, 4])\n        self.assertTrue(np.allclose(result, [0, 0, 1, 2, 3, 4]))\n\n    def test_unique_bins(self):\n        # duplicate bins should be kept\n        result = frequencies2bins([0, 1, 2, 3, 4, 5], [0, 2, 4])\n        self.assertTrue(np.allclose(result, [0, 1, 1, 2, 2, 2]))\n        # duplicate bins should be removed\n        result = frequencies2bins([0, 1, 2, 3, 4, 5], [0, 2, 4],\n                                  unique_bins=True)\n        self.assertTrue(np.allclose(result, [0, 1, 2]))\n        # duplicated bins at lower frequencies should be mapped to the first\n        # bin and removed\n        result = frequencies2bins([-1, 0, 1, 2, 3, 4], [0, 1, 2, 3, 4],\n                                  unique_bins=True)\n        self.assertTrue(np.allclose(result, [0, 1, 2, 3, 4]))\n\n\nclass TestBins2FrequenciesFunction(unittest.TestCase):\n\n    def test_num_arguments(self):\n        # number of arguments arguments\n        with self.assertRaises(TypeError):\n            bins2frequencies()\n        with self.assertRaises(TypeError):\n            bins2frequencies(1)\n        with self.assertRaises(TypeError):\n            bins2frequencies(1, 2, 3)\n\n    def test_types(self):\n        result = bins2frequencies([0, 1, 2, 3, 4], [0, 1, 2, 3, 4])\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n\n    def test_value(self):\n        result = bins2frequencies([0, 1, 2, 3, 4], [0, 1, 2, 3, 4])\n        self.assertTrue(np.allclose(result, [0, 1, 2, 3, 4]))\n        result = bins2frequencies([0, 1, 2, 3, 4], [0, 1, 1.1, 1.2, 2, 3, 4])\n        self.assertTrue(np.allclose(result, [0, 1, 1.1, 1.2, 2]))\n        result = bins2frequencies([-1, 0, 1, 2, 3, 4], [0, 1, 2, 3, 4])\n        self.assertTrue(np.allclose(result, [4, 0, 1, 2, 3, 4]))\n\n\n# test classes\nclass TestFilterClass(unittest.TestCase):\n\n    def test_types(self):\n        filt = Filter(np.arange(5))\n        self.assertIsInstance(filt, Filter)\n        self.assertIsInstance(filt.start, int)\n        self.assertIsInstance(filt.stop, int)\n\n    def test_conversion(self):\n        with self.assertRaises(TypeError):\n            Filter([0, 1, 2, 3, 4])\n        with self.assertRaises(TypeError):\n            Filter(0, 1)\n        with self.assertRaises(TypeError):\n            Filter(np.arange(5), [0, 1])\n        with self.assertRaises(NotImplementedError):\n            # TODO: write test when implemented\n            Filter(np.zeros((10, 2)), 1)\n\n    def test_value(self):\n        filt = Filter(np.arange(5))\n        self.assertTrue(np.allclose(filt, [0, 1, 2, 3, 4]))\n        self.assertTrue(filt.start == 0)\n        self.assertTrue(filt.stop == 5)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 4))\n        filt = Filter(np.arange(5), 1)\n        self.assertTrue(np.allclose(filt, [0, 1, 2, 3, 4]))\n        self.assertTrue(filt.start == 1)\n        self.assertTrue(filt.stop == 6)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 4))\n\n    def test_normalization(self):\n        filt = Filter(np.arange(5), norm=True)\n        self.assertTrue(np.allclose(filt, [0, 0.1, 0.2, 0.3, 0.4]))\n        self.assertTrue(filt.start == 0)\n        self.assertTrue(filt.stop == 5)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 0.4))\n\n    def test_filters_method(self):\n        with self.assertRaises(NotImplementedError):\n            # TODO: write test when implemented\n            Filter(np.arange(5)).filters(3, norm=True)\n\n\nclass TestTriangularFilterClass(unittest.TestCase):\n\n    bins = np.asarray([0, 1, 2, 3, 4, 6, 9])\n\n    def test_types(self):\n        filt = TriangularFilter(0, 1, 2)\n        self.assertIsInstance(filt, TriangularFilter)\n        self.assertTrue(filt.dtype == FILTER_DTYPE)\n        self.assertIsInstance(filt.band_bins(np.arange(8)),\n                              types.GeneratorType)\n\n    def test_errors(self):\n        # filter bins ascending order\n        with self.assertRaises(ValueError):\n            TriangularFilter(0, 2, 1)\n\n    def test_values(self):\n        filt = TriangularFilter(0, 1, 2, norm=False)\n        self.assertTrue(np.allclose(filt, [0, 1]))\n        self.assertTrue(filt.start == 0)\n        self.assertTrue(filt.center == 1)\n        self.assertTrue(filt.stop == 2)\n        filt = TriangularFilter(1, 2, 3, norm=True)\n        self.assertTrue(np.allclose(filt, [0, 1]))\n        self.assertTrue(filt.start == 1)\n        self.assertTrue(filt.center == 2)\n        self.assertTrue(filt.stop == 3)\n        filt = TriangularFilter(1, 2, 4, norm=False)\n        self.assertTrue(np.allclose(filt, [0, 1, 0.5]))\n        self.assertTrue(filt.start == 1)\n        self.assertTrue(filt.center == 2)\n        self.assertTrue(filt.stop == 4)\n        filt = TriangularFilter(1, 2, 4, norm=True)\n        self.assertTrue(np.allclose(filt, [0, 0.66667, 0.33333]))\n        self.assertTrue(filt.start == 1)\n        self.assertTrue(filt.center == 2)\n        self.assertTrue(filt.stop == 4)\n        filt = TriangularFilter(4, 6, 9, norm=True)\n        self.assertTrue(np.allclose(filt, [0, 0.2, 0.4, 0.266667, 0.133333]))\n        self.assertTrue(filt.start == 4)\n        self.assertTrue(filt.center == 6)\n        self.assertTrue(filt.stop == 9)\n        # test small filters\n        filt = TriangularFilter(0, 0, 1, norm=True)\n        self.assertTrue(np.allclose(filt, [1]))\n        self.assertTrue(filt.start == 0)\n        self.assertTrue(filt.center == 0)\n        self.assertTrue(filt.stop == 1)\n        filt = TriangularFilter(0, 0, 1, norm=False)\n        self.assertTrue(np.allclose(filt, [1]))\n        self.assertTrue(filt.start == 0)\n        self.assertTrue(filt.center == 0)\n        self.assertTrue(filt.stop == 1)\n\n    def test_band_bins_method_too_few_bins(self):\n        with self.assertRaises(ValueError):\n            list(TriangularFilter.band_bins(np.arange(2)))\n\n    def test_band_bins_method_overlap(self):\n        # test overlapping\n        result = list(TriangularFilter.band_bins(self.bins))\n        self.assertTrue(result == [(0, 1, 2), (1, 2, 3), (2, 3, 4), (3, 4, 6),\n                                   (4, 6, 9)])\n\n    def test_band_bins_method_non_overlap(self):\n        # test non-overlapping\n        result = list(TriangularFilter.band_bins(self.bins, overlap=False))\n        self.assertTrue(result == [(0, 1, 2), (1, 2, 3), (2, 3, 4), (3, 4, 5),\n                                   (5, 6, 8)])\n\n    def test_filters_method_normalized(self):\n        # normalized filters\n        result = TriangularFilter.filters(self.bins, norm=True)\n        filters = np.asarray([[0, 1], [0, 1], [0, 1], [0, 0.66667, 0.33333],\n                              [0, 0.2, 0.4, 0.266667, 0.133333]])\n        starts = [0, 1, 2, 3, 4]\n        stops = [2, 3, 4, 6, 9]\n        # test the values of the filters itself\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res, filters[i]))\n        # test start positions\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res.start, starts[i]))\n        # test stop positions\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res.stop, stops[i]))\n\n    def test_filters_method_non_normalized(self):\n        # non-normalized filters\n        result = TriangularFilter.filters(self.bins, norm=False)\n        filters = np.asarray([[0, 1], [0, 1], [0, 1], [0, 1, 0.5],\n                              [0, 0.5, 1, 0.66667, 0.33333]])\n        starts = [0, 1, 2, 3, 4]\n        stops = [2, 3, 4, 6, 9]\n        # test the values of the filters itself\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res, filters[i]))\n        # test start positions\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res.start, starts[i]))\n        # test stop positions\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res.stop, stops[i]))\n\n\nclass TestRectangularFilterClass(unittest.TestCase):\n\n    bins = np.asarray([0, 1, 2, 3, 4, 6, 9])\n\n    def test_types(self):\n        filt = RectangularFilter(0, 1, False)\n        self.assertIsInstance(filt, RectangularFilter)\n        self.assertTrue(filt.dtype == FILTER_DTYPE)\n        self.assertIsInstance(filt.band_bins(np.arange(8)),\n                              types.GeneratorType)\n\n    def test_errors(self):\n        # TODO: why is this error not raised? it does not really matter, though\n        # # integer bin numbers\n        # with self.assertRaises(ValueError):\n        #     RectangularFilter(0, 1.1, False)\n        # filter bins ascending order\n        with self.assertRaises(ValueError):\n            # stop bigger than start\n            RectangularFilter(2, 1)\n\n    def test_values(self):\n        filt = RectangularFilter(0, 1, norm=False)\n        self.assertTrue(np.allclose(filt, [1]))\n        self.assertTrue(filt.start == 0)\n        self.assertTrue(filt.stop == 1)\n        filt = RectangularFilter(1, 3, norm=True)\n        self.assertTrue(np.allclose(filt, [0.5, 0.5]))\n        self.assertTrue(filt.start == 1)\n        self.assertTrue(filt.stop == 3)\n        filt = RectangularFilter(1, 4, norm=False)\n        self.assertTrue(np.allclose(filt, [1, 1, 1]))\n        self.assertTrue(filt.start == 1)\n        self.assertTrue(filt.stop == 4)\n        filt = RectangularFilter(1, 4, norm=True)\n        self.assertTrue(np.allclose(filt, [0.33333, 0.33333, 0.33333]))\n        self.assertTrue(filt.start == 1)\n        self.assertTrue(filt.stop == 4)\n        filt = RectangularFilter(4, 9, norm=True)\n        self.assertTrue(np.allclose(filt, [0.2, 0.2, 0.2, 0.2, 0.2]))\n        self.assertTrue(filt.start == 4)\n        self.assertTrue(filt.stop == 9)\n\n    def test_band_bins_method_too_few_bins(self):\n        with self.assertRaises(ValueError):\n            list(RectangularFilter.band_bins(np.arange(1)))\n\n    def test_band_bins_method_overlap(self):\n        with self.assertRaises(NotImplementedError):\n            list(RectangularFilter.band_bins(self.bins, overlap=True))\n\n    def test_band_bins_method(self):\n        result = list(RectangularFilter.band_bins(self.bins))\n        self.assertEqual(result, [(0, 1), (1, 2), (2, 3), (3, 4), (4, 6),\n                                  (6, 9)])\n\n    def test_filters_method_normalized(self):\n        # normalized filters\n        # resulting bins: [0, 1, 2, 3, 4, 6, 9]\n        result = RectangularFilter.filters(self.bins, norm=True)\n        filters = np.asarray([[1], [1], [1], [1], [0.5, 0.5],\n                              [0.33333, 0.33333, 0.33333]])\n        starts = [0, 1, 2, 3, 4, 6]\n        stops = [1, 2, 3, 4, 6, 9]\n        # test the values of the filters itself\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res, filters[i]))\n        # test start positions\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res.start, starts[i]))\n        # test stop positions\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res.stop, stops[i]))\n\n    def test_filters_method_non_normalized(self):\n        # non-normalized filters\n        # resulting bins: [0, 0, 1, 1, 2, 3, 4, 6, 9]\n        result = RectangularFilter.filters(self.bins, norm=False)\n        filters = np.asarray([[1], [1], [1], [1], [1, 1], [1, 1, 1]])\n        starts = [0, 1, 2, 3, 4, 6]\n        stops = [1, 2, 3, 4, 6, 9]\n        # test the values of the filters itself\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res, filters[i]))\n        # test start positions\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res.start, starts[i]))\n        # test stop positions\n        for i, res in enumerate(result):\n            self.assertTrue(np.allclose(res.stop, stops[i]))\n\n\nclass TestConstantsClass(unittest.TestCase):\n\n    def test_types(self):\n        self.assertIsInstance(FMIN, float)\n        self.assertIsInstance(FMAX, float)\n        self.assertIsInstance(NUM_BANDS, int)\n        self.assertIsInstance(NORM_FILTERS, bool)\n        self.assertIsInstance(UNIQUE_FILTERS, bool)\n\n    def test_values(self):\n        self.assertEqual(FMIN, 30.)\n        self.assertEqual(FMAX, 17000.)\n        self.assertEqual(NUM_BANDS, 12)\n        self.assertEqual(NORM_FILTERS, True)\n        self.assertEqual(UNIQUE_FILTERS, True)\n\n\nclass TestFilterbankClass(unittest.TestCase):\n\n    rect_filters = [RectangularFilter(0, 10),\n                    RectangularFilter(10, 25),\n                    RectangularFilter(25, 50),\n                    RectangularFilter(50, 100)]\n\n    triang_filters = [TriangularFilter(0, 6, 15),\n                      TriangularFilter(6, 15, 25),\n                      TriangularFilter(15, 25, 50),\n                      TriangularFilter(25, 50, 70)]\n\n    def test_types(self):\n        filt = Filterbank(np.zeros((100, 10)), np.arange(100))\n        self.assertIsInstance(filt, Filterbank)\n        self.assertTrue(filt.dtype == FILTER_DTYPE)\n        self.assertTrue(filt.bin_frequencies.dtype == np.float)\n\n    def test_errors(self):\n        with self.assertRaises(TypeError):\n            Filterbank(np.zeros((100, 10)))\n        with self.assertRaises(TypeError):\n            Filterbank(np.zeros(10), np.arange(10))\n        with self.assertRaises(ValueError):\n            Filterbank(np.zeros((100, 10)), np.arange(10))\n\n    def test_put_filter_function(self):\n        # normal filter placement\n        filt = np.ones(50) * 0.5\n        Filterbank._put_filter(RectangularFilter(10, 25), filt)\n        self.assertTrue(np.allclose(filt[:10], np.ones(10) * 0.5))\n        self.assertTrue(np.allclose(filt[10:25], np.ones(15)))\n        self.assertTrue(np.allclose(filt[25:50], np.ones(25) * 0.5))\n        # out of range end\n        filt = np.zeros(20)\n        Filterbank._put_filter(RectangularFilter(10, 25), filt)\n        self.assertTrue(np.allclose(filt[:10], np.zeros(10)))\n        self.assertTrue(np.allclose(filt[10:], np.ones(10)))\n        # out of range start\n        filt = np.zeros(20)\n        Filterbank._put_filter(RectangularFilter(-5, 10), filt)\n        self.assertTrue(np.allclose(filt[:10], np.ones(10)))\n        self.assertTrue(np.allclose(filt[10:], np.zeros(10)))\n        # non filter placement\n        filt = np.zeros(20)\n        with self.assertRaises(ValueError):\n            Filterbank._put_filter([10], filt)\n\n    def test_from_filters_function(self):\n        # a list of filters\n        filt = Filterbank.from_filters(self.rect_filters, np.arange(100))\n        self.assertIsInstance(filt, Filterbank)\n        self.assertTrue(filt.dtype == FILTER_DTYPE)\n        self.assertTrue(filt.bin_frequencies.dtype == np.float)\n        # a list of list of filters\n        filt = Filterbank.from_filters([self.rect_filters,\n                                        self.triang_filters], np.arange(100))\n        self.assertIsInstance(filt, Filterbank)\n        self.assertTrue(filt.dtype == FILTER_DTYPE)\n        self.assertTrue(filt.bin_frequencies.dtype == np.float)\n\n    def test_values_rectangular(self):\n        filt = Filterbank.from_filters(self.rect_filters, np.arange(100))\n        self.assertTrue(filt.num_bands == 4)\n        self.assertTrue(filt.num_bins == 100)\n        self.assertTrue(filt.fmin == 0)\n        self.assertTrue(filt.fmax == 99)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 1))\n        self.assertTrue(np.allclose(filt.bin_frequencies, np.arange(100)))\n        self.assertTrue(np.allclose(filt.corner_frequencies,\n                                    [[0, 9], [10, 24], [25, 49], [50, 99]]))\n        self.assertTrue(np.allclose(filt.center_frequencies,\n                                    [4, 17, 37, 74]))\n        result = np.zeros((100, 4))\n        result[0:10, 0] = 1\n        result[10:25, 1] = 1\n        result[25:50, 2] = 1\n        result[50:100, 3] = 1\n        self.assertTrue(np.allclose(filt, result))\n\n    def test_values_triangular(self):\n        filt = Filterbank.from_filters(self.triang_filters, np.arange(100))\n        self.assertTrue(filt.num_bands == 4)\n        self.assertTrue(filt.num_bins == 100)\n        self.assertTrue(filt.fmin == 1)\n        self.assertTrue(filt.fmax == 69)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 1))\n        self.assertTrue(np.allclose(filt.bin_frequencies, np.arange(100)))\n        self.assertTrue(np.allclose(filt.corner_frequencies,\n                                    [[1, 14], [7, 24], [16, 49], [26, 69]]))\n        self.assertTrue(np.allclose(filt.center_frequencies,\n                                    [6, 15, 25, 50]))\n\n    def test_values_rectangular_and_triangular(self):\n        # put all triangular filter in a band, always selecting the maximum\n        # ad all rectangular filters in the second band\n        filt = Filterbank.from_filters([self.triang_filters,\n                                        self.rect_filters], np.arange(100))\n        self.assertTrue(filt.num_bands == 2)\n        self.assertTrue(filt.num_bins == 100)\n        self.assertTrue(filt.fmin == 0)\n        self.assertTrue(filt.fmax == 99)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 1))\n        # all triangular filters\n        correct = np.zeros(100)\n        correct[1:70] = [1. / 6, 2. / 6, 3. / 6, 4. / 6, 5. / 6, 1., 8. / 9,\n                         7. / 9, 6. / 9, 5. / 9, 5. / 9, 6. / 9, 7. / 9,\n                         8. / 9, 1., 0.9, 0.8, 0.7, 0.6, 0.5, 0.6, 0.7, 0.8,\n                         0.9, 1., 0.96, 0.92, 0.88, 0.84, 0.8, 0.76, 0.72,\n                         0.68, 0.64, 0.6, 0.56, 0.52, 0.52, 0.56, 0.6, 0.64,\n                         0.68, 0.72, 0.76, 0.8, 0.84, 0.88, 0.92, 0.96, 1.,\n                         0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55,\n                         0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05]\n        self.assertTrue(np.allclose(filt[:, 0], correct))\n        # all rectangular filters are 1\n        self.assertTrue(np.allclose(filt[:, 1], np.ones(100)))\n        self.assertTrue(np.allclose(filt.bin_frequencies, np.arange(100)))\n        self.assertTrue(np.allclose(filt.corner_frequencies,\n                                    [[1, 69], [0, 99]]))\n        self.assertTrue(np.allclose(filt.center_frequencies, [6, 49]))\n\n\nclass TestFilterbankProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = FilterbankProcessor.from_filters(\n            TestFilterbankClass.triang_filters, np.arange(100))\n\n    def test_process(self):\n        result = self.processor.process(np.zeros((20, 100)))\n        self.assertTrue(np.allclose(result, np.zeros((20, 4))))\n\n\nclass TestMelFilterbankClass(unittest.TestCase):\n\n    def test_types(self):\n        filt = MelFilterbank(np.arange(20000))\n        self.assertIsInstance(filt, MelFilterbank)\n        self.assertTrue(filt.dtype == FILTER_DTYPE)\n        self.assertTrue(filt.bin_frequencies.dtype == np.float)\n\n    def test_constant_types(self):\n        self.assertIsInstance(MelFilterbank.FMIN, float)\n        self.assertIsInstance(MelFilterbank.FMAX, float)\n        self.assertIsInstance(MelFilterbank.NUM_BANDS, int)\n        self.assertIsInstance(MelFilterbank.NORM_FILTERS, bool)\n        self.assertIsInstance(MelFilterbank.UNIQUE_FILTERS, bool)\n\n    def test_constant_values(self):\n        self.assertEqual(MelFilterbank.FMIN, 20.)\n        self.assertEqual(MelFilterbank.FMAX, 17000.)\n        self.assertEqual(MelFilterbank.NUM_BANDS, 40)\n        self.assertEqual(MelFilterbank.NORM_FILTERS, True)\n        self.assertEqual(MelFilterbank.UNIQUE_FILTERS, True)\n\n    def test_values(self):\n        filt = MelFilterbank(np.arange(1000) * 20, 10)\n        self.assertTrue(filt.num_bands == 10)\n        self.assertTrue(filt.num_bins == 1000)\n        self.assertTrue(filt.fmin == 40)\n        self.assertTrue(filt.fmax == 16980)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 0.0714286))\n        self.assertTrue(np.allclose(filt.center_frequencies,\n                                    [260, 580, 1020, 1600, 2380, 3420, 4820,\n                                     6700, 9180, 12520]))\n        self.assertTrue(np.allclose(filt.corner_frequencies,\n                                    [[40, 560], [280, 1000], [600, 1580],\n                                     [1040, 2360], [1620, 3400], [2400, 4800],\n                                     [3440, 6680], [4840, 9160], [6720, 12500],\n                                     [9200, 16980]]))\n\n    def test_default_values(self):\n        filt = MelFilterbank(np.fft.fftfreq(2048, 1. / 44100)[:1024])\n        center = [86.132812, 150.732422, 215.332031, 279.931640,\n                  366.064453, 452.197266, 538.330078, 645.996094,\n                  753.662109, 882.861328, 990.527344, 1141.259766,\n                  1291.992187, 1442.724609, 1614.990234, 1808.789063,\n                  2024.121093, 2239.453125, 2476.318359, 2734.716797,\n                  3014.648437, 3316.113281, 3639.111328, 3983.642578,\n                  4371.240234, 4780.371094, 5232.568359, 5706.298828,\n                  6223.095703, 6804.492187, 7407.421875, 8053.417969,\n                  8785.546875, 9539.208984, 10379.003906, 11283.398437,\n                  12252.392578, 13307.519531, 14448.779297, 15676.171875]\n        corner = [[43.066406, 129.199218], [107.666015, 193.798828],\n                  [172.265625, 258.398437], [236.865234, 344.531250],\n                  [301.464843, 430.664062], [387.597656, 516.796875],\n                  [473.730468, 624.462890], [559.863281, 732.128906],\n                  [667.529296, 861.328125], [775.195312, 968.994140],\n                  [904.394531, 1119.72656], [1012.060546, 1270.458984],\n                  [1162.792968, 1421.191406], [1313.525390, 1593.457031],\n                  [1464.257812, 1787.255859], [1636.523437, 2002.587890],\n                  [1830.322265, 2217.919921], [2045.654296, 2454.785156],\n                  [2260.986328, 2713.183593], [2497.851562, 2993.115234],\n                  [2756.250000, 3294.580078], [3036.181640, 3617.578125],\n                  [3337.646484, 3962.109375], [3660.644531, 4349.707031],\n                  [4005.175781, 4758.837890], [4392.773437, 5211.035156],\n                  [4801.904296, 5684.765625], [5254.101562, 6201.562500],\n                  [5727.832031, 6782.958984], [6244.628906, 7385.888671],\n                  [6826.025390, 8031.884765], [7428.955078, 8764.013671],\n                  [8074.951171, 9517.675781], [8807.080078, 10357.470702],\n                  [9560.742187, 11261.865238], [10400.537109, 12230.859375],\n                  [11304.931640, 13285.986328], [12273.925781, 14427.246093],\n                  [13329.052734, 15654.638671], [14470.312500, 16968.164062]]\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 1. / 3))\n        self.assertTrue(np.allclose(filt.center_frequencies, center))\n        self.assertTrue(np.allclose(filt.corner_frequencies, corner))\n\n\nclass TestBarkFilterbankClass(unittest.TestCase):\n\n    def test_types(self):\n        filt = BarkFilterbank(np.arange(20000))\n        self.assertIsInstance(filt, BarkFilterbank)\n        self.assertTrue(filt.dtype == FILTER_DTYPE)\n        self.assertTrue(filt.bin_frequencies.dtype == np.float)\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            BarkFilterbank(np.arange(20000), \'foo\')\n\n    def test_constant_types(self):\n        self.assertIsInstance(BarkFilterbank.FMIN, float)\n        self.assertIsInstance(BarkFilterbank.FMAX, float)\n        self.assertIsInstance(BarkFilterbank.NUM_BANDS, str)\n        self.assertIsInstance(BarkFilterbank.NORM_FILTERS, bool)\n        self.assertIsInstance(BarkFilterbank.UNIQUE_FILTERS, bool)\n\n    def test_constant_values(self):\n        self.assertEqual(BarkFilterbank.FMIN, 20.)\n        self.assertEqual(BarkFilterbank.FMAX, 15500.)\n        self.assertEqual(BarkFilterbank.NUM_BANDS, \'normal\')\n        self.assertEqual(BarkFilterbank.NORM_FILTERS, True)\n        self.assertEqual(BarkFilterbank.UNIQUE_FILTERS, True)\n\n    def test_default_values(self):\n        filt = BarkFilterbank(FFT_FREQS_1024)\n        center = [43.066406, 129.199218, 236.865234, 344.53125, 452.197265,\n                  559.863281, 689.0625, 839.794921, 990.527343, 1162.792968,\n                  1356.591796, 1593.457031, 1851.855468, 2153.320312,\n                  2497.851562, 2906.982421, 3402.246093, 4026.708984,\n                  4823.4375, 5835.498046, 7041.357421, 8591.748046,\n                  10723.535156, 13738.183593]\n        corner = [[21.533203, 86.132812], [107.666015, 172.265625],\n                  [193.798828, 279.931640], [301.464843, 387.597656],\n                  [409.130859, 495.263671], [516.796875, 602.929687],\n                  [624.462890, 753.662109], [775.195312, 904.394531],\n                  [925.927734, 1055.126953], [1076.660156, 1248.925781],\n                  [1270.458984, 1464.257812], [1485.791015, 1701.123046],\n                  [1722.656250, 1981.054687], [2002.587890, 2304.052734],\n                  [2325.585937, 2670.117187], [2691.650390, 3122.314453],\n                  [3143.847656, 3682.177734], [3703.710937, 4371.240234],\n                  [4392.773437, 5275.634765], [5297.167968, 6373.828125],\n                  [6395.361328, 7687.353515], [7708.886718, 9474.609375],\n                  [9496.142578, 11972.460937], [11993.994140, 15482.373046]]\n        self.assertTrue(filt.num_bands == 24)\n        self.assertTrue(filt.num_bins == 1024)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(filt.max() < 1)\n        self.assertTrue(np.allclose(filt.fmin, 21.5332031))\n        self.assertTrue(np.allclose(filt.fmax, 15482.3730468))\n        self.assertTrue(np.allclose(filt.center_frequencies, center))\n        self.assertTrue(np.allclose(filt.corner_frequencies, corner))\n\n    def test_double_values(self):\n        filt = BarkFilterbank(FFT_FREQS_1024, \'double\')\n        center = [21.53320312, 64.59960938, 107.66601562, 150.73242188,\n                  215.33203125, 258.3984375, 301.46484375, 366.06445312,\n                  409.13085938, 473.73046875, 516.796875, 581.39648438,\n                  645.99609375, 732.12890625, 796.72851562, 861.328125,\n                  947.4609375, 1012.06054688, 1098.19335938, 1205.859375,\n                  1313.52539062, 1421.19140625, 1528.85742188, 1636.5234375,\n                  1765.72265625, 1916.45507812, 2067.1875, 2217.91992188,\n                  2390.18554688, 2583.984375, 2777.78320312, 3014.6484375,\n                  3251.51367188, 3531.4453125, 3832.91015625, 4177.44140625,\n                  4586.57226562, 5038.76953125, 5534.03320312, 6072.36328125,\n                  6675.29296875, 7342.82226562, 8096.484375, 8979.34570312,\n                  9991.40625, 11240.33203125, 12726.12304688, 14491.84570312]\n        corner = [[21.53320312, 21.53320312], [43.06640625, 86.1328125],\n                  [107.66601562, 129.19921875], [150.73242188, 172.265625],\n                  [193.79882812, 236.86523438], [258.3984375, 279.93164062],\n                  [301.46484375, 322.99804688], [344.53125, 387.59765625],\n                  [409.13085938, 430.6640625], [452.19726562, 495.26367188],\n                  [516.796875, 538.33007812], [559.86328125, 602.9296875],\n                  [624.46289062, 689.0625], [710.59570312, 753.66210938],\n                  [775.1953125, 818.26171875], [839.79492188, 904.39453125],\n                  [925.92773438, 968.99414062], [990.52734375, 1055.12695312],\n                  [1076.6601563, 1141.2597656], [1162.7929688, 1248.92578125],\n                  [1270.45898438, 1356.59179688], [1378.125, 1464.2578125],\n                  [1485.79101562, 1571.9238281], [1593.45703125, 1701.1230469],\n                  [1722.65625, 1830.32226562], [1851.85546875, 1981.0546875],\n                  [2002.58789062, 2131.7871094], [2153.3203125, 2304.05273438],\n                  [2325.5859375, 2476.31835938], [2497.8515625, 2670.1171875],\n                  [2691.65039062, 2885.44921875], [2906.9824219, 3122.3144531],\n                  [3143.84765625, 3380.7128906], [3402.24609375, 3682.1777344],\n                  [3703.7109375, 3983.64257812], [4005.17578125, 4371.2402344],\n                  [4392.7734375, 4780.37109375], [4801.90429688, 5275.6347656],\n                  [5297.16796875, 5770.8984375], [5792.43164062, 6373.828125],\n                  [6395.36132812, 6976.7578125], [6998.29101562, 7687.3535156],\n                  [7708.88671875, 8484.08203125], [8505.61523438, 9474.609375],\n                  [9496.1425781, 10486.6699219], [10508.203125, 11972.4609375],\n                  [11993.994141, 13479.785156], [13501.318359, 15482.373047]]\n        self.assertTrue(filt.num_bands == 48)\n        self.assertTrue(filt.num_bins == 1024)\n        self.assertTrue(np.allclose(filt.fmin, 21.5332031))\n        self.assertTrue(np.allclose(filt.fmax, 15482.3730468))\n        self.assertTrue(np.allclose(filt.center_frequencies, center))\n        self.assertTrue(np.allclose(filt.corner_frequencies, corner))\n\n\nclass TestLogarithmicFilterbankClass(unittest.TestCase):\n\n    def test_types(self):\n        filt = LogarithmicFilterbank(np.arange(20000))\n        self.assertIsInstance(filt, LogarithmicFilterbank)\n        self.assertTrue(filt.dtype == FILTER_DTYPE)\n        self.assertTrue(filt.bin_frequencies.dtype == np.float)\n\n    def test_errors(self):\n        with self.assertRaises(NotImplementedError):\n            # TODO: write test when implemented\n            LogarithmicFilterbank(np.arange(20000), bands_per_octave=False)\n\n    def test_constant_types(self):\n        # TODO: why can\'t we test the inherited constants? it does not matter\n        # self.assertIsInstance(LogarithmicFilterbank.FMIN, float))\n        # self.assertIsInstance(LogarithmicFilterbank.FMAX, float))\n        self.assertIsInstance(LogarithmicFilterbank.NUM_BANDS_PER_OCTAVE, int)\n        # self.assertIsInstance(LogarithmicFilterbank.NORM_FILTERS, bool))\n        # self.assertIsInstance(LogarithmicFilterbank.UNIQUE_FILTERS, bool))\n\n    def test_constant_values(self):\n        # self.assertEqual(LogarithmicFilterbank.FMIN, 30.)\n        # self.assertEqual(LogarithmicFilterbank.FMAX, 17000.)\n        self.assertEqual(LogarithmicFilterbank.NUM_BANDS_PER_OCTAVE, 12)\n        # self.assertEqual(LogarithmicFilterbank.NORM_FILTERS, True)\n        # self.assertEqual(LogarithmicFilterbank.UNIQUE_FILTERS, False)\n\n    def test_values_unique_filters(self):\n        filt = LogarithmicFilterbank(np.arange(0, 20000, 20), num_bands=12)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 1))\n        self.assertEqual(filt.shape, (1000, 81))\n        filt = LogarithmicFilterbank(np.arange(0, 20000, 20), num_bands=12,\n                                     unique_filters=False)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 1))\n        self.assertEqual(filt.shape, (1000, 108))\n\n    def test_default_values(self):\n        filt = LogarithmicFilterbank(FFT_FREQS_1024)\n\n        self.assertTrue(filt.num_bands == 81)\n        self.assertTrue(filt.num_bands_per_octave == 12)\n        self.assertTrue(filt.num_bins == 1024)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.fmin, 43.066406))\n        self.assertTrue(np.allclose(filt.fmax, 16731.298828))\n        self.assertTrue(np.allclose(filt.center_frequencies,\n                                    LOG_FILTERBANK_CENTER_FREQS))\n        self.assertTrue(np.allclose(filt.corner_frequencies,\n                                    LOG_FILTERBANK_CORNER_FREQS))\n\n\nclass TestRectangularFilterbankClass(unittest.TestCase):\n\n    def test_types(self):\n        filt = RectangularFilterbank(np.arange(20000), [100, 1000])\n        self.assertIsInstance(filt, RectangularFilterbank)\n        self.assertTrue(filt.dtype == FILTER_DTYPE)\n        self.assertTrue(filt.bin_frequencies.dtype == np.float)\n        self.assertTrue(filt.crossover_frequencies.dtype == np.float)\n\n    def test_values(self):\n        filt = RectangularFilterbank(np.arange(0, 2000, 20), [100, 1000],\n                                     norm_filters=False)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 1))\n        self.assertEqual(filt.shape, (100, 3))\n        self.assertTrue(np.allclose(filt.bin_frequencies,\n                                    np.arange(0, 2000, 20)))\n        self.assertTrue(np.allclose(filt.crossover_frequencies, [100, 1000]))\n\n    def test_values_unique_filters(self):\n        filt = RectangularFilterbank(np.arange(0, 2000, 20), [100, 101, 1000],\n                                     unique_filters=False)\n        self.assertTrue(np.allclose(filt.min(), 0))\n        self.assertTrue(np.allclose(filt.max(), 1. / 3))\n        # second band must be 0\n        self.assertTrue(np.allclose(filt[:, 1], np.zeros(100)))\n        self.assertEqual(filt.shape, (100, 4))\n\n\nclass TestSimpleChromaFilterbankClass(unittest.TestCase):\n\n    def test_error(self):\n        with self.assertRaises(NotImplementedError):\n            # TODO: write test when implemented\n            SimpleChromaFilterbank(FFT_FREQS_1024)\n\n\nclass TestHarmonicFilterbankClass(unittest.TestCase):\n\n    def test_error(self):\n        with self.assertRaises(NotImplementedError):\n            # TODO: write test when implemented\n            HarmonicFilterbank()\n\n\nclass TestPitchClassProfileFilterbankClass(unittest.TestCase):\n\n    def test_types(self):\n        filt = PitchClassProfileFilterbank(FFT_FREQS_1024)\n        self.assertIsInstance(filt, PitchClassProfileFilterbank)\n        self.assertTrue(filt.dtype == FILTER_DTYPE)\n        self.assertTrue(filt.bin_frequencies.dtype == np.float)\n\n    def test_constant_types(self):\n        self.assertIsInstance(PitchClassProfileFilterbank.CLASSES, int)\n        self.assertIsInstance(PitchClassProfileFilterbank.FMIN, float)\n        self.assertIsInstance(PitchClassProfileFilterbank.FMAX, float)\n\n    def test_constant_values(self):\n        self.assertEqual(PitchClassProfileFilterbank.CLASSES, 12)\n        self.assertEqual(PitchClassProfileFilterbank.FMIN, 100.)\n        self.assertEqual(PitchClassProfileFilterbank.FMAX, 5000.)\n\n    def test_values(self):\n        filt = PitchClassProfileFilterbank(FFT_FREQS_1024)\n        self.assertTrue(filt.num_bands == 12)\n        self.assertTrue(filt.num_bins == 1024)\n        self.assertTrue(filt.fmin == FFT_FREQS_1024[5])\n        self.assertTrue(filt.fmax == FFT_FREQS_1024[232])\n        self.assertTrue(filt.fref == 440)\n        with self.assertRaises(NotImplementedError):\n            filt.center_frequencies\n        with self.assertRaises(NotImplementedError):\n            filt.corner_frequencies\n\n\nclass TestHarmonicPitchClassProfileFilterbankClass(unittest.TestCase):\n\n    def test_types(self):\n        filt = HarmonicPitchClassProfileFilterbank(FFT_FREQS_1024)\n        self.assertIsInstance(filt, HarmonicPitchClassProfileFilterbank)\n        self.assertTrue(filt.dtype == FILTER_DTYPE)\n        self.assertTrue(filt.bin_frequencies.dtype == np.float)\n\n    def test_constant_types(self):\n        self.assertIsInstance(HarmonicPitchClassProfileFilterbank.CLASSES, int)\n        self.assertIsInstance(HarmonicPitchClassProfileFilterbank.FMIN, float)\n        self.assertIsInstance(HarmonicPitchClassProfileFilterbank.FMAX, float)\n        self.assertIsInstance(HarmonicPitchClassProfileFilterbank.WINDOW, int)\n\n    def test_constant_values(self):\n        self.assertEqual(HarmonicPitchClassProfileFilterbank.CLASSES, 36)\n        self.assertEqual(HarmonicPitchClassProfileFilterbank.FMIN, 100.)\n        self.assertEqual(HarmonicPitchClassProfileFilterbank.FMAX, 5000.)\n        self.assertEqual(HarmonicPitchClassProfileFilterbank.WINDOW, 4)\n\n    def test_values(self):\n        filt = HarmonicPitchClassProfileFilterbank(FFT_FREQS_1024)\n        self.assertTrue(filt.num_bands == 36)\n        self.assertTrue(filt.num_bins == 1024)\n        self.assertTrue(filt.fmin == FFT_FREQS_1024[5])\n        self.assertTrue(filt.fmax == FFT_FREQS_1024[232])\n        self.assertTrue(filt.fref == 440)\n        with self.assertRaises(NotImplementedError):\n            filt.center_frequencies\n        with self.assertRaises(NotImplementedError):\n            filt.corner_frequencies\n\n\nclass TestSemitoneBandpassFilterbank(unittest.TestCase):\n\n    def test_values(self):\n        filt = SemitoneBandpassFilterbank()\n        self.assertTrue(filt.order == 4)\n        self.assertTrue(filt.num_bands == 88)\n        self.assertTrue(np.allclose(filt.fmin, 26.95))\n        self.assertTrue(np.allclose(filt.fmax, 4269.73))\n        self.assertTrue(filt.fref == 440)\n        self.assertTrue(np.allclose(filt.band_sample_rates[38:40],\n                                    np.array([882, 4410])))\n        self.assertTrue(np.allclose(filt.band_sample_rates[74:76],\n                                    np.array([4410, 22050])))\n        # compare filter coefficients with the MATLAB chroma toolbox\n        midi_21 = [np.array([0.00315, -0.02473, 0.08536, -0.16931, 0.21105,\n                             -0.16931, 0.08536, -0.02473, 0.00315]),\n                   np.array([1.00000, -7.83971, 27.04051, -53.59047, 66.74413,\n                             -53.49138, 26.94061, -7.79631, 0.99262])]\n\n        self.assertTrue(np.allclose(midi_21, filt.filters[0], rtol=1e-03))\n        midi_65 = [np.array([0.0031404, -0.0220498, 0.0706113, -0.1340629,\n                             0.1647329, -0.1340629, 0.0706113, -0.0220498,\n                             0.0031404]),\n                   np.array([1.0000000, -7.0134392, 22.4267609, -42.5024913,\n                             52.1127102, -42.3031710, 22.2169086, -6.9152305,\n                             0.9813733])]\n        self.assertTrue(np.allclose(midi_65, filt.filters[44], rtol=1e-03))\n        midi_108 = [np.array([0.0031357, -0.0091928, 0.0224905, -0.0322832,\n                              0.0395297, -0.0322832, 0.0224905, -0.0091928,\n                              0.0031357]),\n                    np.array([1.00000, -2.93573, 7.18487, -10.28654, 12.54224,\n                              -10.17129, 7.02476, -2.83814, 0.95593])]\n        self.assertTrue(np.allclose(midi_108, filt.filters[87], rtol=1e-03))\n'"
tests/test_audio_signal.py,345,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.audio.signal module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport os\nimport sys\nimport tempfile\nimport unittest\nfrom os.path import join as pj\n\nfrom madmom.audio.signal import *\nfrom . import AUDIO_PATH, DATA_PATH\nfrom .test_audio_comb_filters import sig_1d, sig_2d\n\nsample_file = pj(AUDIO_PATH, \'sample.wav\')\nsample_file_22k = pj(AUDIO_PATH, \'sample_22050.wav\')\nstereo_sample_file = pj(AUDIO_PATH, \'stereo_sample.wav\')\ntmp_file = tempfile.NamedTemporaryFile(delete=False).name\n\n\n# test signal functions\nclass TestSmoothFunction(unittest.TestCase):\n\n    def test_types(self):\n        # mono signals\n        result = smooth(sig_1d, None)\n        self.assertTrue(type(result) == type(sig_1d))\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        result = smooth(sig_1d, 3)\n        self.assertTrue(type(result) == type(sig_1d))\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        # multi-channel signals\n        result = smooth(sig_2d, None)\n        self.assertTrue(type(result) == type(sig_2d))\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_2d.shape)\n        result = smooth(sig_2d, 3)\n        self.assertTrue(type(result) == type(sig_2d))\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_2d.shape)\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            smooth(np.zeros(9).reshape(3, 3), -1)\n        with self.assertRaises(ValueError):\n            smooth(np.zeros(9).reshape(3, 3), \'bla\')\n        with self.assertRaises(ValueError):\n            smooth(np.zeros(18).reshape(3, 3, 2), 4)\n\n    def test_values(self):\n        # mono signals\n        result = smooth(sig_1d, None)\n        self.assertTrue(np.allclose(result, sig_1d))\n        result = smooth(sig_1d, 0)\n        self.assertTrue(np.allclose(result, sig_1d))\n        result = smooth(sig_1d, 3)\n        result_3 = [0, 0.08, 1, 0.08, 0.08, 1, 0.08, 0.08, 1]\n        self.assertTrue(np.allclose(result, result_3))\n        result = smooth(sig_1d, 5)\n        result_5 = [0.08, 0.54, 1, 0.62, 0.62, 1, 0.62, 0.62, 1]\n        self.assertTrue(np.allclose(result, result_5))\n        result = smooth(sig_1d, 7)\n        result_7 = [0.31, 0.77, 1.08, 1.08, 1.08, 1.16, 1.08, 1.08, 1.08]\n        self.assertTrue(np.allclose(result, result_7))\n        result = smooth(sig_1d, np.ones(3))\n        result_3_ones = [0, 1, 1, 1, 1, 1, 1, 1, 1]\n        self.assertTrue(np.allclose(result, result_3_ones))\n        result = smooth(sig_1d, np.ones(4))\n        result_4_ones = [0, 1, 1, 1, 2, 1, 1, 2, 1]\n        self.assertTrue(np.allclose(result, result_4_ones))\n        # multi-channel signals\n        result = smooth(sig_2d, None)\n        self.assertTrue(np.allclose(result, sig_2d))\n        result = smooth(sig_2d, 3)\n        result_3 = [[0, 0.08, 1, 0.08, 0.08, 1, 0.08, 0.08, 1],\n                    [1, 0.16, 1, 0.16, 1, 0.16, 1, 0.16, 1]]\n        self.assertTrue(np.allclose(result, np.asarray(result_3).T))\n        result = smooth(sig_2d, 5)\n        result_5 = [[0.08, 0.54, 1, 0.62, 0.62, 1, 0.62, 0.62, 1],\n                    [1.08, 1.08, 1.16, 1.08, 1.16, 1.08, 1.16, 1.08, 1.08]]\n        self.assertTrue(np.allclose(result, np.asarray(result_5).T))\n        result = smooth(sig_2d, 7)\n        result_7 = [[0.31, 0.77, 1.08, 1.08, 1.08, 1.16, 1.08, 1.08, 1.08],\n                    [1.31, 1.62, 1.62, 1.7, 1.62, 1.7, 1.62, 1.62, 1.31]]\n        self.assertTrue(np.allclose(result, np.asarray(result_7).T))\n\n\nclass TestAdjustGainFunction(unittest.TestCase):\n\n    def test_types(self):\n        # mono signals\n        result = adjust_gain(sig_1d, 0)\n        self.assertTrue(type(result) == type(sig_1d))\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        self.assertTrue(result.dtype == sig_1d.dtype)\n        # same with int16 dtype\n        result = adjust_gain(sig_1d.astype(np.int16), 0)\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        self.assertTrue(result.dtype == np.int16)\n        # from file\n        signal = Signal(sample_file)\n        result = adjust_gain(signal, 0)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == signal.dtype)\n        # multi-channel signals\n        result = adjust_gain(sig_2d, 0)\n        self.assertTrue(type(result) == type(sig_2d))\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_2d.shape)\n        self.assertTrue(result.dtype == sig_2d.dtype)\n        # same with int dtype\n        result = adjust_gain(sig_2d.astype(np.int), 0)\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_2d.shape)\n        self.assertTrue(result.dtype == np.int)\n\n    def test_values(self):\n        # mono signals\n        result = adjust_gain(sig_1d, 0)\n        self.assertTrue(np.allclose(result, sig_1d))\n        result = adjust_gain(sig_1d, -10)\n        self.assertTrue(np.allclose(result, 0.31622777 * sig_1d))\n        result = adjust_gain(sig_1d, 10)\n        self.assertTrue(np.allclose(result, 3.1622777 * sig_1d))\n        # same with int dtype\n        result = adjust_gain(sig_1d.astype(np.int), 0)\n        self.assertTrue(np.allclose(result, sig_1d.astype(np.int)))\n        result = adjust_gain(sig_1d.astype(np.int), -5)\n        self.assertTrue(np.allclose(result, 0 * sig_1d))\n        # multi-channel signals\n        result = adjust_gain(sig_2d, 0)\n        self.assertTrue(np.allclose(result, sig_2d))\n        result = adjust_gain(sig_2d, -3)\n        self.assertTrue(np.allclose(result, 0.70794578 * sig_2d))\n        # same with int16 dtype\n        result = adjust_gain(sig_2d.astype(np.int16), 0)\n        self.assertTrue(np.allclose(result, sig_2d))\n        result = adjust_gain(sig_2d.astype(np.int16), -1)\n        self.assertTrue(np.allclose(result, 0 * sig_2d))\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            adjust_gain(sig_2d.astype(np.int16), +60)\n\n\nclass TestAttenuateFunction(unittest.TestCase):\n\n    def test_types(self):\n        # mono signals\n        result = attenuate(sig_1d, 0)\n        self.assertTrue(type(result) == type(sig_1d))\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        self.assertTrue(result.dtype == sig_1d.dtype)\n        # same as int16 dtype\n        result = attenuate(sig_1d.astype(np.int16), 0)\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        self.assertTrue(result.dtype == np.int16)\n        # from file\n        signal = Signal(sample_file)\n        result = attenuate(signal, 0)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int16)\n        # multi-channel signals\n        result = attenuate(sig_2d, 0)\n        self.assertTrue(type(result) == type(sig_2d))\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_2d.shape)\n        self.assertTrue(result.dtype == sig_2d.dtype)\n        # same as int dtype\n        result = attenuate(sig_2d.astype(np.int), 0)\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_2d.shape)\n        self.assertTrue(result.dtype == np.int)\n\n    def test_values(self):\n        # mono signals\n        result = attenuate(sig_1d, 0)\n        self.assertTrue(np.allclose(result, sig_1d))\n        result = attenuate(sig_1d, 10)\n        self.assertTrue(np.allclose(result, 0.31622777 * sig_1d))\n        result = attenuate(sig_1d, -10)\n        self.assertTrue(np.allclose(result, 3.1622777 * sig_1d))\n        # same with int dtype\n        result = attenuate(sig_1d.astype(np.int), 0)\n        self.assertTrue(np.allclose(result, sig_1d.astype(np.int)))\n        result = attenuate(sig_1d.astype(np.int), 5)\n        self.assertTrue(np.allclose(result, 0 * sig_1d))\n        # multi-channel signals\n        result = attenuate(sig_2d, 0)\n        self.assertTrue(np.allclose(result, sig_2d))\n        result = attenuate(sig_2d, 3)\n        self.assertTrue(np.allclose(result, 0.70794578 * sig_2d))\n        # same with int16 dtype\n        result = attenuate(sig_2d.astype(np.int16), 0)\n        self.assertTrue(np.allclose(result, sig_2d))\n        result = attenuate(sig_2d.astype(np.int16), 1)\n        self.assertTrue(np.allclose(result, 0 * sig_2d))\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            attenuate(sig_2d.astype(np.int16), -10)\n\n\nclass TestNormalizeFunction(unittest.TestCase):\n\n    def test_types(self):\n        # mono signals\n        result = normalize(sig_1d)\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        self.assertTrue(result.dtype == sig_1d.dtype)\n        # same as int16 dtype\n        result = normalize(sig_1d.astype(np.int16))\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        self.assertTrue(result.dtype == np.int16)\n        # from file\n        signal = Signal(sample_file)\n        result = normalize(signal)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int16)\n        # multi-channel signals\n        result = normalize(sig_2d)\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_2d.shape)\n        self.assertTrue(result.dtype == sig_2d.dtype)\n        # same as int32 dtype\n        result = normalize(sig_2d.astype(np.int32))\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_2d.shape)\n        self.assertTrue(result.dtype == np.int32)\n\n    def test_values(self):\n        # mono signals\n        result = normalize(sig_1d)\n        self.assertTrue(np.allclose(result, sig_1d))\n        result = normalize(sig_1d * 0.5)\n        self.assertTrue(np.allclose(result, sig_1d))\n        self.assertTrue(np.max(result) == 1)\n        # same as int16 dtype\n        result = normalize(10 * sig_1d.astype(np.int16))\n        self.assertTrue(np.allclose(result, sig_1d * 32767))\n        self.assertTrue(np.max(result) == 32767)\n        # multi-channel signals\n        result = normalize(sig_2d)\n        self.assertTrue(np.allclose(result, sig_2d))\n        self.assertTrue(np.max(result) == 1)\n        # negative values\n        result = normalize(sig_2d * 4 - 2)\n        self.assertTrue(np.allclose(result, sig_2d * 2 - 1))\n        self.assertTrue(result.max() == 1)\n        self.assertTrue(result.min() == -1)\n        # same as int32 dtype\n        result = normalize(3 * sig_2d.astype(np.int32))\n        self.assertTrue(np.allclose(result, sig_2d * 2147483647))\n        self.assertTrue(np.max(result) == 2147483647)\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            normalize(sig_2d.astype(np.int64))\n\n\nclass TestMixFunction(unittest.TestCase):\n\n    mono_2d = np.asarray([0.5, 0, 1, 0, 0.5, 0.5, 0.5, 0, 1], dtype=np.float)\n\n    def test_types(self):\n        # mono signals\n        result = remix(sig_1d, 1)\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        self.assertTrue(result.dtype == sig_1d.dtype)\n        result = remix(sig_1d, 2)\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == (len(sig_1d), 2))\n        self.assertTrue(result.dtype == sig_1d.dtype)\n        result = remix(sig_1d, 3)\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == (len(sig_1d), 3))\n        self.assertTrue(result.dtype == sig_1d.dtype)\n        # same as int dtype\n        result = remix(sig_1d.astype(np.int), 1)\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        self.assertTrue(result.dtype == np.int)\n        result = remix(sig_1d.astype(np.int), 2)\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == (len(sig_1d), 2))\n        self.assertTrue(result.dtype == np.int)\n        # from file\n        signal = Signal(sample_file)\n        result = remix(signal, 1)\n        self.assertTrue(isinstance(result, Signal))\n        self.assertTrue(isinstance(result, np.ndarray))\n        self.assertTrue(result.dtype == np.int16)\n        # multi-channel signals\n        result = remix(sig_2d, 1)\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        self.assertTrue(result.dtype == sig_2d.dtype)\n        result = remix(sig_2d, 2)\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_2d.shape)\n        self.assertTrue(result.dtype == sig_2d.dtype)\n        # from file\n        signal = Signal(stereo_sample_file)\n        result = remix(signal, 1)\n        self.assertTrue(isinstance(result, Signal))\n        self.assertTrue(isinstance(result, np.ndarray))\n        self.assertTrue(result.dtype == np.int16)\n        result = remix(signal, 2)\n        self.assertTrue(isinstance(result, Signal))\n        self.assertTrue(isinstance(result, np.ndarray))\n        self.assertTrue(result.dtype == np.int16)\n        with self.assertRaises(NotImplementedError):\n            remix(sig_2d, 3)\n        # same as int dtype\n        result = remix(sig_2d.astype(np.int), 1)\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        self.assertTrue(result.dtype == np.int)\n        result = remix(sig_2d.astype(np.int), 2)\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_2d.shape)\n        self.assertTrue(result.dtype == np.int)\n\n    def test_channel_selection(self):\n        result = remix(sig_2d, 1, channel=0)\n        self.assertEqual(result.shape, sig_1d.shape)\n        self.assertTrue(np.array_equal(result, sig_1d))\n        result = remix(sig_2d, 1, channel=1)\n        self.assertTrue(np.array_equal(result, sig_2d[:, 1]), 0)\n\n    def test_values(self):\n        # mono signals\n        result = remix(sig_1d, 1)\n        self.assertTrue(np.allclose(result, sig_1d))\n        # same as int dtype\n        result = remix(sig_2d.astype(np.int), 1)\n        self.assertTrue(np.allclose(result, self.mono_2d.astype(np.int)))\n        # multi-channel signals\n        result = remix(sig_2d, 1)\n        self.assertTrue(np.allclose(result, self.mono_2d))\n        # same as int dtype\n        result = remix(2 * sig_2d.astype(np.int), 1)\n        self.assertTrue(np.allclose(result, 2 * self.mono_2d))\n\n\nclass TestResampleFunction(unittest.TestCase):\n\n    def setUp(self):\n        self.signal = Signal(sample_file)\n        self.signal_22k = Signal(sample_file_22k)\n        self.signal_float = Signal(sample_file, dtype=np.float32)\n        self.stereo_signal = Signal(stereo_sample_file)\n        self.float_target = np.array([-0.07537885, -0.077897, -0.08440731,\n                                      -0.07527363, -0.06685895, -0.05827513])\n\n    def test_types(self):\n        # mono signal\n        result = resample(self.signal, 22050)\n        self.assertTrue(isinstance(result, Signal))\n        self.assertTrue(isinstance(result, np.ndarray))\n        self.assertTrue(result.dtype == self.signal.dtype)\n        # stereo signal\n        result = resample(self.stereo_signal, 22050)\n        self.assertTrue(isinstance(result, Signal))\n        self.assertTrue(isinstance(result, np.ndarray))\n        self.assertTrue(result.dtype == self.stereo_signal.dtype)\n\n    def test_values_mono(self):\n        result = resample(self.signal, 22050)\n        self.assertEqual(result.sample_rate, 22050)\n        self.assertEqual(result.num_samples, 61741)\n        self.assertEqual(result.dtype, self.signal.dtype)\n        self.assertEqual(result.num_channels, self.signal.num_channels)\n        self.assertTrue(np.allclose(result.length, self.signal.length))\n        self.assertTrue(np.allclose(result, self.signal_22k))\n\n    def test_values_mono_float(self):\n        result = resample(self.signal_float, 22050)\n        self.assertEqual(result.sample_rate, 22050)\n        self.assertEqual(result.num_samples, 61741)\n        self.assertEqual(result.dtype, self.signal_float.dtype)\n        self.assertEqual(result.num_channels, self.signal_float.num_channels)\n        self.assertTrue(np.allclose(result.length, self.signal_float.length))\n        self.assertTrue(np.allclose(result[:6], self.float_target))\n\n    def test_values_dtype(self):\n        result = resample(self.signal, 22050, dtype=np.float32)\n        self.assertEqual(result.sample_rate, 22050)\n        self.assertEqual(result.num_samples, 61741)\n        self.assertEqual(result.dtype, np.float32)\n        self.assertEqual(result.num_channels, self.signal_float.num_channels)\n        self.assertTrue(np.allclose(result.length, self.signal_float.length))\n        self.assertTrue(np.allclose(result[:6], self.float_target))\n\n    def test_values_stereo(self):\n        result = resample(self.stereo_signal, 22050)\n        self.assertEqual(result.sample_rate, 22050)\n        self.assertEqual(result.num_samples, 91460)\n        self.assertEqual(result.dtype, self.stereo_signal.dtype)\n        self.assertEqual(result.num_channels, self.stereo_signal.num_channels)\n        self.assertTrue(np.allclose(result.length, self.stereo_signal.length))\n        self.assertTrue(np.allclose(result[:6],\n                                    [[34, 38], [32, 33], [37, 31],\n                                     [35, 35], [32, 34], [33, 34]]))\n\n    def test_values_upmixing(self):\n        result = resample(self.signal, 22050, num_channels=2)\n        self.assertEqual(result.sample_rate, 22050)\n        self.assertEqual(result.num_samples, 61741)\n        self.assertEqual(result.dtype, self.signal.dtype)\n        self.assertEqual(result.num_channels, 2)\n        self.assertTrue(np.allclose(result.length, self.signal.length))\n        stereo = np.vstack((self.signal_22k, self.signal_22k)).T / np.sqrt(2)\n        self.assertTrue(np.allclose(result, stereo, atol=np.sqrt(2)))\n\n    def test_values_downmixing(self):\n        result = resample(self.stereo_signal, 22050, num_channels=1)\n        self.assertEqual(result.sample_rate, 22050)\n        self.assertEqual(result.num_samples, 91460)\n        self.assertEqual(result.dtype, self.stereo_signal.dtype)\n        self.assertEqual(result.num_channels, 1)\n        self.assertTrue(np.allclose(result.length, self.stereo_signal.length))\n        self.assertTrue(np.allclose(result[:6], [36, 33, 34, 35, 33, 34]))\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            resample(sig_1d, 2)\n\n\nclass TestRescaleFunction(unittest.TestCase):\n\n    def test_types(self):\n        # mono signals\n        result = rescale(sig_1d, np.float)\n        self.assertTrue(len(result) == len(sig_1d))\n        self.assertTrue(result.shape == sig_1d.shape)\n        self.assertTrue(result.dtype == np.float)\n        # from file\n        signal = Signal(sample_file)\n        result = rescale(signal)\n        self.assertTrue(isinstance(result, Signal))\n        self.assertTrue(isinstance(result, np.ndarray))\n        self.assertTrue(result.dtype == np.float32)\n        # multi-channel signals\n        result = rescale(sig_2d, np.float16)\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.shape == sig_2d.shape)\n        self.assertTrue(result.dtype == np.float16)\n        # from file\n        signal = Signal(stereo_sample_file)\n        result = rescale(signal, np.float)\n        self.assertTrue(isinstance(result, Signal))\n        self.assertTrue(isinstance(result, np.ndarray))\n        self.assertTrue(result.dtype == np.float)\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            rescale(sig_2d, np.complex)\n        with self.assertRaises(ValueError):\n            rescale(sig_2d, np.int)\n        with self.assertRaises(ValueError):\n            rescale(np.ones(10, dtype=np.complex))\n\n    def test_values(self):\n        # mono signals\n        result = rescale(sig_1d, np.float)\n        self.assertTrue(np.allclose(result, sig_1d))\n        # from file\n        signal = Signal(sample_file)\n        result = rescale(signal)\n        self.assertTrue(np.allclose(result[:6],\n                                    [-0.07611316, -0.07660146, -0.07580798,\n                                     -0.08172857, -0.08645894, -0.08212531]))\n        # multi-channel signals\n        result = rescale(sig_2d, np.float16)\n        self.assertTrue(np.allclose(result, sig_2d))\n        # from file\n        signal = Signal(stereo_sample_file)\n        result = rescale(signal, np.float)\n        self.assertTrue(np.allclose(result[:6], [[0.00100711, 0.0011597],\n                                                 [0.00106815, 0.00109867],\n                                                 [0.00088504, 0.00103763],\n                                                 [0.00109867, 0.00094607],\n                                                 [0.00112918, 0.00091556],\n                                                 [0.00109867, 0.00103763]]))\n\n\nclass TestTrimFunction(unittest.TestCase):\n\n    def test_types(self):\n        # mono signals\n        result = trim(sig_1d)\n        self.assertTrue(type(result) == type(sig_1d))\n        self.assertTrue(result.ndim == sig_1d.ndim)\n        self.assertTrue(result.dtype == sig_1d.dtype)\n        signal = Signal(sample_file)\n        result = trim(signal)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.ndim == signal.ndim)\n        self.assertTrue(result.dtype == np.int16)\n        # multi-channel signals\n        result = trim(sig_2d)\n        self.assertTrue(type(result) == type(sig_2d))\n        self.assertTrue(len(result) == len(sig_2d))\n        self.assertTrue(result.ndim == sig_2d.ndim)\n        self.assertTrue(result.dtype == sig_2d.dtype)\n        signal = Signal(stereo_sample_file)\n        result = trim(signal)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.ndim == signal.ndim)\n        self.assertTrue(result.dtype == np.int16)\n\n    def test_values(self):\n        # mono signals\n        result = trim(sig_1d)\n        trimmed_1d = [1, 0, 0, 1, 0, 0, 1]\n        self.assertTrue(np.allclose(result, trimmed_1d))\n        self.assertTrue(len(result) == len(sig_1d) - 2)\n        # multi-channel signals\n        # signal has leading zeros only in one channel\n        result = trim(sig_2d)\n        self.assertTrue(result.shape == sig_2d.shape)\n        signal = Signal(stereo_sample_file)\n        result = trim(signal)\n        self.assertTrue(result.shape == signal.shape)\n        # signal with leading zeros only in both channels\n        signal = np.tile(np.arange(5), 2).reshape(2, 5).T\n        result = trim(signal)\n        self.assertTrue(result.shape == (4, 2))\n        self.assertTrue(np.allclose(result[:, 0], np.arange(1, 5)))\n        self.assertTrue(np.allclose(result[:, 1], np.arange(1, 5)))\n        # zeros at the end\n        result = trim(np.arange(5, 0, -1))\n        self.assertTrue(np.allclose(result, [5, 4, 3, 2, 1]))\n\n\nclass TestEnergyFunction(unittest.TestCase):\n\n    def test_types(self):\n        # mono signals\n        result = energy(sig_1d)\n        self.assertIsInstance(result, float)\n        # multi-channel signals\n        result = energy(sig_2d)\n        self.assertIsInstance(result, float)\n\n    def test_errors(self):\n        with self.assertRaises(TypeError):\n            energy(None)\n\n    def test_values(self):\n        # mono signals\n        result = energy(sig_1d)\n        self.assertTrue(np.allclose(result, 3))\n        result = energy(np.zeros(100))\n        self.assertTrue(np.allclose(result, 0))\n        # multi-channel signals\n        result = energy(sig_2d)\n        self.assertTrue(np.allclose(result, 8))\n        result = energy(np.zeros(100).reshape(-1, 2))\n        self.assertTrue(np.allclose(result, 0))\n\n    def test_frames(self):\n        # mono signals\n        frames = FramedSignal(sig_1d, frame_size=4, hop_size=2)\n        result = energy(frames)\n        self.assertTrue(np.allclose(result, [0, 1, 2, 1, 1]))\n        result = energy(np.zeros(100))\n        self.assertTrue(np.allclose(result, 0))\n        # multi-channel signals\n        frames = FramedSignal(sig_2d, frame_size=4, hop_size=2)\n        result = energy(frames)\n        self.assertTrue(np.allclose(result, [1, 3, 4, 3, 3]))\n        result = energy(np.zeros(100).reshape(-1, 2))\n        self.assertTrue(np.allclose(result, 0))\n\n\nclass TestRootMeanSquareFunction(unittest.TestCase):\n\n    def test_types(self):\n        # mono signals\n        result = root_mean_square(sig_1d)\n        self.assertIsInstance(result, float)\n        # multi-channel signals\n        result = root_mean_square(sig_2d)\n        self.assertIsInstance(result, float)\n\n    def test_values(self):\n        # mono signals\n        result = root_mean_square(sig_1d)\n        self.assertTrue(np.allclose(result, 0.57735026919))\n        result = root_mean_square(np.zeros(100))\n        self.assertTrue(np.allclose(result, 0))\n        # multi-channel signals\n        result = root_mean_square(sig_2d)\n        self.assertTrue(np.allclose(result, 2. / 3))\n        result = root_mean_square(np.zeros(100).reshape(-1, 2))\n        self.assertTrue(np.allclose(result, 0))\n\n    def test_frames(self):\n        # mono signals\n        frames = FramedSignal(sig_1d, frame_size=4, hop_size=2)\n        result = root_mean_square(frames)\n        self.assertTrue(np.allclose(result, [0, 0.5, 0.70710678, 0.5, 0.5]))\n        result = root_mean_square(np.zeros(100))\n        self.assertTrue(np.allclose(result, 0))\n        # multi-channel signals\n        frames = FramedSignal(sig_2d, frame_size=4, hop_size=2)\n        result = root_mean_square(frames)\n        self.assertTrue(np.allclose(result, [0.35355339, 0.61237244,\n                                             0.70710678, 0.61237244,\n                                             0.61237244]))\n        result = root_mean_square(np.zeros(100).reshape(-1, 2))\n        self.assertTrue(np.allclose(result, 0))\n\n\nclass TestSoundPressureLevelFunction(unittest.TestCase):\n\n    def test_types(self):\n        # mono signals\n        result = sound_pressure_level(sig_1d)\n        self.assertIsInstance(result, float)\n        # multi-channel signals\n        result = sound_pressure_level(sig_2d)\n        self.assertIsInstance(result, float)\n\n    def test_values(self):\n        # mono signals\n        result = sound_pressure_level(sig_1d)\n        self.assertTrue(np.allclose(result, -4.7712125472))\n        # silence\n        result = sound_pressure_level(np.zeros(100))\n        self.assertTrue(np.allclose(result, -np.finfo(float).max))\n        # maximum float amplitude, alternating between -1 and 1\n        sinus = np.cos(np.linspace(0, 2 * np.pi * 100, 2 * 100 + 1))\n        result = sound_pressure_level(sinus)\n        self.assertTrue(np.allclose(result, 0.))\n        # maximum int16 amplitude, alternating between -1 and 1\n        sinus_int16 = (sinus * np.iinfo(np.int16).max).astype(np.int16)\n        result = sound_pressure_level(sinus_int16)\n        self.assertTrue(np.allclose(result, 0.))\n\n        # multi-channel signals\n        result = sound_pressure_level(sig_2d)\n        self.assertTrue(np.allclose(result, -3.52182518111))\n        # silence\n        result = sound_pressure_level(np.zeros(100).reshape(-1, 2))\n        self.assertTrue(np.allclose(result, -np.finfo(float).max))\n        # maximum float amplitude, alternating between -1 and 1\n        sig = remix(sinus, 2)\n        result = sound_pressure_level(sig)\n        self.assertTrue(np.allclose(result, 0.))\n        # maximum int16 amplitude, alternating between -1 and 1\n        sig = remix(sinus_int16, 2)\n        result = sound_pressure_level(sig)\n        self.assertTrue(np.allclose(result, 0.))\n\n    def test_frames(self):\n        # mono signals\n        frames = FramedSignal(sig_1d, frame_size=4, hop_size=2)\n        result = sound_pressure_level(frames)\n        self.assertTrue(np.allclose(result, [-np.finfo(float).max, -6.0206,\n                                             -3.0103, -6.0206, -6.0206]))\n        result = sound_pressure_level(np.zeros(100))\n        self.assertTrue(np.allclose(result, -np.finfo(float).max))\n        # multi-channel signals\n        frames = FramedSignal(sig_2d, frame_size=4, hop_size=2)\n        result = sound_pressure_level(frames)\n        self.assertTrue(np.allclose(result, [-9.03089987, -4.25968732,\n                                             -3.01029996, -4.25968732,\n                                             -4.25968732]))\n        result = sound_pressure_level(np.zeros(100).reshape(-1, 2))\n        self.assertTrue(np.allclose(result, -np.finfo(float).max))\n\n\n# signal classes\nclass TestSignalClass(unittest.TestCase):\n\n    def test_types_array(self):\n        result = Signal(sig_1d)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.float)\n        self.assertIsInstance(result.start, type(None))\n        self.assertIsInstance(result.stop, type(None))\n        self.assertIsInstance(result.num_samples, int)\n        self.assertIsInstance(result.sample_rate, type(None))\n        self.assertIsInstance(result.num_channels, int)\n        self.assertIsInstance(result.length, type(None))\n        self.assertIsInstance(result.ndim, int)\n\n    def test_types_array_with_sample_rate(self):\n        result = Signal(sig_1d, 1)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.float)\n        self.assertIsInstance(result.start, type(None))\n        self.assertIsInstance(result.stop, type(None))\n        self.assertIsInstance(result.num_samples, int)\n        self.assertIsInstance(result.sample_rate, int)\n        self.assertIsInstance(result.num_channels, int)\n        self.assertIsInstance(result.length, float)\n        self.assertIsInstance(result.ndim, int)\n\n    def test_types_file(self):\n        result = Signal(sample_file)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int16)\n\n    def test_values_1d(self):\n        result = Signal(sig_1d, 1)\n        self.assertTrue(np.allclose(result, sig_1d))\n        self.assertTrue(len(result) == 9)\n        self.assertTrue(result.num_samples == 9)\n        self.assertTrue(result.sample_rate == 1)\n        self.assertTrue(result.num_channels == 1)\n        self.assertTrue(result.length == 9)\n\n    def test_values_1d_no_sample_rate(self):\n        result = Signal(sig_1d)\n        self.assertTrue(np.allclose(result, sig_1d))\n        self.assertTrue(len(result) == 9)\n        self.assertTrue(result.num_samples == 9)\n        self.assertTrue(result.sample_rate is None)\n        self.assertTrue(result.num_channels == 1)\n        self.assertTrue(result.length is None)\n\n    def test_values_2d(self):\n        result = Signal(sig_2d, 12.3)\n        self.assertTrue(np.allclose(result, sig_2d))\n        self.assertTrue(len(result) == 9)\n        self.assertTrue(result.num_samples == 9)\n        # not officially supported, but Signal can handle float sample rates\n        self.assertTrue(result.sample_rate == 12.3)\n        self.assertTrue(result.num_channels == 2)\n        self.assertTrue(result.length == 9 / 12.3)\n        self.assertTrue(result.ndim == 2)\n\n    def test_num_channels(self):\n        result = Signal(sig_2d, sample_rate=1, num_channels=1)\n        self.assertTrue(result.shape == (9, ))\n        self.assertTrue(np.allclose(result,\n                                    [0.5, 0, 1, 0, 0.5, 0.5, 0.5, 0, 1]))\n\n    def test_values_file(self):\n        result = Signal(sample_file)\n        self.assertTrue(np.allclose(result[:5],\n                                    [-2494, -2510, -2484, -2678, -2833]))\n        self.assertTrue(len(result) == 123481)\n        self.assertTrue(result.num_samples == 123481)\n        self.assertTrue(result.sample_rate == 44100)\n        self.assertTrue(result.num_channels == 1)\n        self.assertTrue(result.ndim == 1)\n        self.assertTrue(np.allclose(result.length, 2.8))\n\n    def test_write_method(self):\n        orig = Signal(sample_file)\n        orig.write(tmp_file)\n        result = Signal(tmp_file)\n        self.assertTrue(np.allclose(orig, result))\n\n    def test_methods(self):\n        # mono signals\n        signal = Signal(sig_1d)\n        self.assertTrue(np.allclose(signal.energy(), 3))\n        self.assertTrue(np.allclose(signal.rms(), 0.57735026919))\n        self.assertTrue(np.allclose(signal.spl(), -4.7712125472))\n        # multi-channel signals\n        signal = Signal(sig_2d)\n        self.assertTrue(np.allclose(signal.energy(), 8))\n        self.assertTrue(np.allclose(signal.root_mean_square(), 2. / 3))\n        self.assertTrue(np.allclose(signal.sound_pressure_level(),\n                                    -3.52182518111))\n\n\nclass TestSignalProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = SignalProcessor()\n\n    def test_types(self):\n        self.assertIsInstance(self.processor, SignalProcessor)\n        self.assertIsInstance(self.processor, Processor)\n        # attributes\n        self.assertTrue(self.processor.sample_rate is None)\n        self.assertTrue(self.processor.num_channels is None)\n        self.assertTrue(self.processor.start is None)\n        self.assertTrue(self.processor.stop is None)\n        self.assertIsInstance(self.processor.norm, bool)\n        self.assertIsInstance(self.processor.gain, float)\n\n    def test_values(self):\n        # attributes\n        self.assertTrue(self.processor.sample_rate is None)\n        self.assertTrue(self.processor.num_channels is None)\n        self.assertTrue(self.processor.start is None)\n        self.assertTrue(self.processor.stop is None)\n        self.assertTrue(self.processor.norm is False)\n        self.assertTrue(self.processor.gain == 0)\n\n    def test_process(self):\n        result = self.processor.process(sample_file)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int16)\n        self.assertTrue(np.allclose(result[:5],\n                                    [-2494, -2510, -2484, -2678, -2833]))\n        self.assertTrue(len(result) == 123481)\n        self.assertTrue(result.min() == -20603)\n        self.assertTrue(result.max() == 17977)\n        self.assertTrue(result.mean() == -172.88385257650975)\n        # attributes\n        self.assertTrue(result.sample_rate == 44100)\n        # properties\n        self.assertTrue(result.num_samples == 123481)\n        self.assertTrue(result.num_channels == 1)\n        self.assertTrue(np.allclose(result.length, 2.8))\n\n    def test_process_stereo(self):\n        self.processor.num_channels = 1\n        self.assertTrue(self.processor.num_channels == 1)\n        result = self.processor.process(stereo_sample_file)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int16)\n\n    def test_process_norm(self):\n        self.processor.norm = True\n        self.assertTrue(self.processor.norm is True)\n        result = self.processor.process(sample_file)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int16)\n        self.assertTrue(np.allclose(result[:5],\n                                    [-3966, -3991, -3950, -4259, -4505]))\n        self.assertTrue(len(result) == 123481)\n        self.assertTrue(result.min() == -32767)\n        self.assertTrue(result.max() == 28590)\n        self.assertTrue(result.mean() == -274.92599671204476)\n        # attributes\n        self.assertTrue(result.sample_rate == 44100)\n        # properties\n        self.assertTrue(result.num_samples == 123481)\n        self.assertTrue(result.num_channels == 1)\n        self.assertTrue(np.allclose(result.length, 2.8))\n\n    def test_process_gain(self):\n        self.processor.gain = -10\n        self.assertTrue(self.processor.gain == -10.)\n        result = self.processor.process(sample_file)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int16)\n        self.assertTrue(np.allclose(result[:5],\n                                    [-788, -793, -785, -846, -895]))\n        self.assertTrue(len(result) == 123481)\n        # attributes\n        self.assertTrue(result.sample_rate == 44100)\n        # properties\n        self.assertTrue(result.num_samples == 123481)\n        self.assertTrue(result.num_channels == 1)\n        self.assertTrue(np.allclose(result.length, 2.8))\n\n    def test_pickle(self):\n        self.processor.dump(tmp_file)\n        processor = SignalProcessor.load(tmp_file)\n        self.assertEqual(type(self.processor), type(processor))\n        self.assertEqual(self.processor.sample_rate,\n                         processor.sample_rate)\n        self.assertEqual(self.processor.num_channels,\n                         processor.num_channels)\n        self.assertEqual(self.processor.start, processor.start)\n        self.assertEqual(self.processor.stop, processor.stop)\n        self.assertEqual(self.processor.norm, processor.norm)\n        self.assertEqual(self.processor.gain, processor.gain)\n\n    @unittest.skipIf(sys.version_info < (3, 2), \'assertWarns needs Python 3.2\')\n    def test_multiprocessing(self):\n        from concurrent.futures import ProcessPoolExecutor\n        sig = Signal(sample_file)\n        pool = ProcessPoolExecutor(max_workers=2)\n        pool.submit(self.processor, sig).result()\n\n\n# framing functions\nclass TestSignalFrameFunction(unittest.TestCase):\n\n    def test_types(self):\n        result = signal_frame(np.arange(10), 0, 4, 2)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int)\n        result = signal_frame(np.arange(10, dtype=np.float), 0, 4, 2)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.float)\n        signal = Signal(sample_file)\n        result = signal_frame(signal, 0, 4, 2)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int16)\n        result = signal_frame(signal, 2000, 400, 200)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int16)\n        result = signal_frame(signal, -10, 400, 200)\n        self.assertIsInstance(result, Signal)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int16)\n\n    def test_short_input_length(self):\n        result = signal_frame(np.arange(4), 0, 10, 5)\n        self.assertTrue(np.allclose(result, [0, 0, 0, 0, 0, 0, 1, 2, 3, 0]))\n        result = signal_frame(np.arange(4), 1, 10, 5)\n        self.assertTrue(np.allclose(result, [0, 1, 2, 3, 0, 0, 0, 0, 0, 0]))\n        result = signal_frame(np.arange(4), 2, 10, 5)\n        self.assertTrue(np.allclose(result, [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n        result = signal_frame(np.arange(4), -2, 10, 5)\n        self.assertTrue(np.allclose(result, [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n\n    def test_values(self):\n        result = signal_frame(np.arange(10), -1, 4, 2)\n        self.assertTrue(np.allclose(result, [0, 0, 0, 0]))\n        result = signal_frame(np.arange(10), 0, 4, 2)\n        self.assertTrue(np.allclose(result, [0, 0, 0, 1]))\n        result = signal_frame(np.arange(10), 1, 4, 2)\n        self.assertTrue(np.allclose(result, [0, 1, 2, 3]))\n        result = signal_frame(np.arange(10), 2, 4, 2)\n        self.assertTrue(np.allclose(result, [2, 3, 4, 5]))\n        result = signal_frame(np.arange(10), 3, 4, 2)\n        self.assertTrue(np.allclose(result, [4, 5, 6, 7]))\n        result = signal_frame(np.arange(10), 4, 4, 2)\n        self.assertTrue(np.allclose(result, [6, 7, 8, 9]))\n        result = signal_frame(np.arange(10), 5, 4, 2)\n        self.assertTrue(np.allclose(result, [8, 9, 0, 0]))\n\n    def test_stereo_values(self):\n        signal = np.tile(np.arange(10)[:, np.newaxis], 2)\n        result = signal_frame(signal, 0, 4, 2)\n        self.assertTrue(np.allclose(result, [[0, 0], [0, 0], [0, 0], [1, 1]]))\n        result = signal_frame(signal, 1, 4, 2)\n        self.assertTrue(np.allclose(result, [[0, 0], [1, 1], [2, 2], [3, 3]]))\n        result = signal_frame(signal, 2, 4, 2)\n        self.assertTrue(np.allclose(result, [[2, 2], [3, 3], [4, 4], [5, 5]]))\n        result = signal_frame(signal, 3, 4, 2)\n        self.assertTrue(np.allclose(result, [[4, 4], [5, 5], [6, 6], [7, 7]]))\n        result = signal_frame(signal, 4, 4, 2)\n        self.assertTrue(np.allclose(result, [[6, 6], [7, 7], [8, 8], [9, 9]]))\n        result = signal_frame(signal, 5, 4, 2)\n        self.assertTrue(np.allclose(result, [[8, 8], [9, 9], [0, 0], [0, 0]]))\n        result = signal_frame(signal, 6, 4, 2)\n        self.assertTrue(np.allclose(result, [[0, 0], [0, 0], [0, 0], [0, 0]]))\n\n    def test_float_hop_size(self):\n        result = signal_frame(np.arange(10), 0, 3.5, 2)\n        self.assertTrue(np.allclose(result, [0, 0, 1]))\n        result = signal_frame(np.arange(10), 1, 3.5, 2)\n        self.assertTrue(np.allclose(result, [1, 2, 3]))\n        result = signal_frame(np.arange(10), 2, 3.5, 2)\n        self.assertTrue(np.allclose(result, [3, 4, 5]))\n\n    def test_origin(self):\n        result = signal_frame(np.arange(10), 0, 4, 2)\n        self.assertTrue(np.allclose(result, [0, 0, 0, 1]))\n        # positive values shift to the left\n        result = signal_frame(np.arange(10), 0, 4, 2, 1)\n        self.assertTrue(np.allclose(result, [0, 0, 0, 0]))\n        # negative values shift to the right\n        result = signal_frame(np.arange(10), 0, 4, 2, -1)\n        self.assertTrue(np.allclose(result, [0, 0, 1, 2]))\n        result = signal_frame(np.arange(10), 0, 4, 2, -2)\n        self.assertTrue(np.allclose(result, [0, 1, 2, 3]))\n        result = signal_frame(np.arange(10), 0, 4, 2, -4)\n        self.assertTrue(np.allclose(result, [2, 3, 4, 5]))\n        # test with float origin with half the size of the frame size\n        result = signal_frame(np.arange(10), 0, 5, 2, -2.5)\n        self.assertTrue(np.allclose(result, [0, 1, 2, 3, 4]))\n\n    def test_pad(self):\n        # 1D signal\n        x = np.arange(10, 20)\n        # pad with a fixed value\n        result = signal_frame(x, 0, frame_size=4, hop_size=2, pad=-1)\n        self.assertTrue(np.allclose(result, [-1, -1, 10, 11]))\n        result = signal_frame(x, 5, frame_size=4, hop_size=2, pad=-1)\n        self.assertTrue(np.allclose(result, [18, 19, -1, -1]))\n        # repeat first value\n        result = signal_frame(x, 0, frame_size=4, hop_size=2, pad=\'repeat\')\n        self.assertTrue(np.allclose(result, [10, 10, 10, 11]))\n        result = signal_frame(x, -10, frame_size=4, hop_size=2, pad=\'repeat\')\n        self.assertTrue(np.allclose(result, [10, 10, 10, 10]))\n        # repeat last value\n        result = signal_frame(x, 0, frame_size=4, hop_size=2, pad=\'repeat\')\n        self.assertTrue(np.allclose(result, [10, 10, 10, 11]))\n        result = signal_frame(x, 20, frame_size=3, hop_size=3, pad=\'repeat\')\n        self.assertTrue(np.allclose(result, [19, 19, 19]))\n\n        # 2D signal\n        x = np.arange(10, 30).reshape((10, 2))\n        # pad with a fixed value\n        result = signal_frame(x, 0, frame_size=4, hop_size=2, pad=-1)\n        self.assertTrue(\n            np.allclose(result, [[-1, -1], [-1, -1], [10, 11], [12, 13]]))\n        result = signal_frame(x, 0, frame_size=4, hop_size=2, pad=[-1, -2])\n        self.assertTrue(\n            np.allclose(result, [[-1, -2], [-1, -2], [10, 11], [12, 13]]))\n        # pad by repeating first/last frame\n        result = signal_frame(x, 0, frame_size=4, hop_size=2, pad=\'repeat\')\n        self.assertTrue(\n            np.allclose(result, [[10, 11], [10, 11], [10, 11], [12, 13]]))\n        result = signal_frame(x, 5, frame_size=4, hop_size=2, pad=\'repeat\')\n        self.assertTrue(\n            np.allclose(result, [[26, 27], [28, 29], [28, 29], [28, 29]]))\n        # requested frame out of signal\n        result = signal_frame(x, -2, frame_size=4, hop_size=2, pad=\'repeat\')\n        self.assertTrue(\n            np.allclose(result, [[10, 11], [10, 11], [10, 11], [10, 11]]))\n        result = signal_frame(x, 7, frame_size=4, hop_size=2, pad=\'repeat\')\n        self.assertTrue(\n            np.allclose(result, [[28, 29], [28, 29], [28, 29], [28, 29]]))\n\n\n# framing classes\nclass TestFramedSignalClass(unittest.TestCase):\n\n    def test_types(self):\n        result = FramedSignal(np.arange(10), 4, 2)\n        self.assertIsInstance(result, FramedSignal)\n        # attributes\n        self.assertIsInstance(result.signal, Signal)\n        self.assertIsInstance(result.frame_size, int)\n        self.assertIsInstance(result.hop_size, float)\n        self.assertIsInstance(result.origin, int)\n        self.assertIsInstance(result.num_frames, int)\n        # get item\n        self.assertIsInstance(result[0], Signal)\n        # get slice\n        self.assertIsInstance(result[:5], FramedSignal)\n        self.assertIsInstance(result[1:2], FramedSignal)\n        # properties\n        self.assertIsInstance(len(result), int)\n        self.assertIsInstance(result.frame_rate, type(None))\n        self.assertIsInstance(result.fps, type(None))\n        self.assertIsInstance(result.overlap_factor, float)\n        self.assertIsInstance(result.shape, tuple)\n        self.assertIsInstance(result.ndim, int)\n\n    def test_types_slice(self):\n        # get a slice of a FramedSignal\n        result = FramedSignal(np.arange(10), 4, 2)[:5]\n        self.assertIsInstance(result, FramedSignal)\n        # attributes\n        self.assertIsInstance(result.signal, Signal)\n        self.assertIsInstance(result.frame_size, int)\n        self.assertIsInstance(result.hop_size, float)\n        self.assertIsInstance(result.origin, int)\n        self.assertIsInstance(result.num_frames, int)\n        # get item\n        self.assertIsInstance(result[0], Signal)\n        # get slice\n        self.assertIsInstance(result[:2], FramedSignal)\n        self.assertIsInstance(result[5:6], FramedSignal)\n        # properties\n        self.assertIsInstance(len(result), int)\n        self.assertIsInstance(result.frame_rate, type(None))\n        self.assertIsInstance(result.fps, type(None))\n        self.assertIsInstance(result.overlap_factor, float)\n        self.assertIsInstance(result.shape, tuple)\n        self.assertIsInstance(result.ndim, int)\n\n    def test_types_with_sample_rate(self):\n        result = FramedSignal(np.arange(10), 4, 2, sample_rate=1)\n        self.assertIsInstance(result, FramedSignal)\n        # attributes\n        self.assertIsInstance(result.signal, Signal)\n        self.assertIsInstance(result.frame_size, int)\n        self.assertIsInstance(result.hop_size, float)\n        self.assertIsInstance(result.origin, int)\n        self.assertIsInstance(result.num_frames, int)\n        self.assertIsInstance(result[0], Signal)\n        # properties\n        self.assertIsInstance(len(result), int)\n        self.assertIsInstance(result.frame_rate, float)\n        self.assertIsInstance(result.fps, float)\n        self.assertIsInstance(result.overlap_factor, float)\n        self.assertIsInstance(result.shape, tuple)\n        self.assertIsInstance(result.ndim, int)\n\n    def test_types_signal(self):\n        signal = Signal(sample_file)\n        result = FramedSignal(signal)\n        self.assertIsInstance(result, FramedSignal)\n        # attributes\n        self.assertIsInstance(result.signal, Signal)\n        self.assertIsInstance(result.frame_size, int)\n        self.assertIsInstance(result.hop_size, float)\n        self.assertIsInstance(result.origin, int)\n        self.assertIsInstance(result.num_frames, int)\n        self.assertIsInstance(result[0], Signal)\n        # properties\n        self.assertIsInstance(len(result), int)\n        self.assertIsInstance(result.frame_rate, float)\n        self.assertIsInstance(result.fps, float)\n        self.assertIsInstance(result.overlap_factor, float)\n        self.assertIsInstance(result.shape, tuple)\n        self.assertIsInstance(result.ndim, int)\n\n    def test_types_file(self):\n        result = FramedSignal(sample_file)\n        self.assertIsInstance(result, FramedSignal)\n        # attributes\n        self.assertIsInstance(result.signal, Signal)\n        self.assertIsInstance(result.frame_size, int)\n        self.assertIsInstance(result.hop_size, float)\n        self.assertIsInstance(result.origin, int)\n        self.assertIsInstance(result.num_frames, int)\n        self.assertIsInstance(result[0], Signal)\n        # properties\n        self.assertIsInstance(len(result), int)\n        self.assertIsInstance(result.frame_rate, float)\n        self.assertIsInstance(result.fps, float)\n        self.assertIsInstance(result.overlap_factor, float)\n        self.assertIsInstance(result.shape, tuple)\n        self.assertIsInstance(result.ndim, int)\n\n    def test_values_array(self):\n        result = FramedSignal(np.arange(10), 4, 2)\n        self.assertTrue(np.allclose(result[0], [0, 0, 0, 1]))\n        # attributes\n        self.assertTrue(result.frame_size == 4)\n        self.assertTrue(result.hop_size == 2.)\n        self.assertTrue(result.origin == 0)\n        self.assertTrue(result.num_frames == 5)\n        # properties\n        self.assertTrue(len(result) == 5)\n        self.assertTrue(result.frame_rate is None)\n        self.assertTrue(result.fps is None)\n        self.assertTrue(result.overlap_factor == 0.5)\n        self.assertTrue(result.shape == (5, 4))\n        self.assertTrue(result.ndim == 2)\n\n    def test_values_array_end(self):\n        result = FramedSignal(np.arange(10), 4, 2)\n        self.assertTrue(result.num_frames == 5)\n        result = FramedSignal(np.arange(10), 4, 2, end=\'extend\')\n        self.assertTrue(result.num_frames == 6)\n\n    def test_values_array_with_sample_rate(self):\n        result = FramedSignal(np.arange(10), 4, 2, sample_rate=4)\n        self.assertTrue(np.allclose(result[0], [0, 0, 0, 1]))\n        self.assertTrue(np.allclose(result[1], [0, 1, 2, 3]))\n        self.assertTrue(np.allclose(result[2], [2, 3, 4, 5]))\n        self.assertTrue(np.allclose(result[3], [4, 5, 6, 7]))\n        self.assertTrue(np.allclose(result[4], [6, 7, 8, 9]))\n        self.assertTrue(np.allclose(result[-1], [6, 7, 8, 9]))\n        with self.assertRaises(IndexError):\n            result[5]\n        # attributes\n        self.assertTrue(result.frame_size == 4)\n        self.assertTrue(result.hop_size == 2.)\n        self.assertTrue(result.origin == 0)\n        self.assertTrue(result.num_frames == 5)\n        # properties\n        self.assertTrue(len(result) == 5)\n        self.assertTrue(result.frame_rate == 2)\n        self.assertTrue(result.fps == 2)\n        self.assertTrue(result.overlap_factor == 0.5)\n        self.assertTrue(result.shape == (5, 4))\n        self.assertTrue(result.ndim == 2)\n\n    def test_values_slicing(self):\n        result = FramedSignal(np.arange(10), 4, 2, sample_rate=4)[1:]\n        self.assertTrue(np.allclose(result[0], [0, 1, 2, 3]))\n        self.assertTrue(np.allclose(result[1], [2, 3, 4, 5]))\n        self.assertTrue(np.allclose(result[2], [4, 5, 6, 7]))\n        self.assertTrue(np.allclose(result[-2], [4, 5, 6, 7]))\n        self.assertTrue(np.allclose(result[3], [6, 7, 8, 9]))\n        self.assertTrue(np.allclose(result[-1], [6, 7, 8, 9]))\n        with self.assertRaises(IndexError):\n            result[4]\n        # attributes\n        self.assertTrue(result.frame_size == 4)\n        self.assertTrue(result.hop_size == 2.)\n        self.assertTrue(result.origin == -2)\n        self.assertTrue(result.num_frames == 4)\n        # properties\n        self.assertTrue(len(result) == 4)\n        self.assertTrue(result.shape == (4, 4))\n        self.assertTrue(result.frame_rate == 2)\n        self.assertTrue(result.fps == 2)\n        self.assertTrue(result.overlap_factor == 0.5)\n        # other slice\n        result = FramedSignal(np.arange(10), 4, 2, sample_rate=4)[2:4]\n        self.assertTrue(result.shape == (2, 4))\n        self.assertTrue(np.allclose(result[0], [2, 3, 4, 5]))\n        self.assertTrue(np.allclose(result[1], [4, 5, 6, 7]))\n        with self.assertRaises(IndexError):\n            result[2]\n        # slices with steps != 1\n        with self.assertRaises(ValueError):\n            FramedSignal(np.arange(10), 4, 2, sample_rate=4)[2:4:2]\n        # only slices with integers should work\n        with self.assertRaises(TypeError):\n            FramedSignal(np.arange(10), 4, 2, sample_rate=4)[\'foo\':\'bar\']\n        # only slices or integers should work\n        with self.assertRaises(TypeError):\n            FramedSignal(np.arange(10), 4, 2, sample_rate=4)[\'bar\']\n\n    def test_values_file(self):\n        signal = Signal(sample_file)\n        result = FramedSignal(sample_file)\n        self.assertTrue(np.allclose(result[0][:5], [0, 0, 0, 0, 0]))\n        # 3rd frame should start at 3 * 441 - 2048 / 2 = 299\n        self.assertTrue(np.allclose(result[3], signal[299: 299 + 2048]))\n        # attributes\n        self.assertTrue(result.frame_size == 2048)\n        self.assertTrue(result.hop_size == 441.)\n        self.assertTrue(result.origin == 0)\n        self.assertTrue(result.num_frames == 281)\n        # properties\n        self.assertTrue(len(result) == 281)\n        self.assertTrue(result.shape == (281, 2048))\n        self.assertTrue(result.frame_rate == 100.)\n        self.assertTrue(result.fps == 100.)\n        self.assertTrue(result.overlap_factor == 0.78466796875)\n        self.assertTrue(result.ndim == 2)\n\n    def test_values_stereo_file(self):\n        signal = Signal(stereo_sample_file)\n        result = FramedSignal(stereo_sample_file)\n        self.assertTrue(np.allclose(result[0][:3], [[0, 0], [0, 0], [0, 0]]))\n        # 3rd frame should start at 3 * 441 - 2048 / 2 = 299\n        self.assertTrue(np.allclose(result[3], signal[299: 299 + 2048]))\n        # attributes\n        self.assertTrue(result.frame_size == 2048)\n        self.assertTrue(result.hop_size == 441.)\n        self.assertTrue(result.origin == 0)\n        self.assertTrue(result.num_frames == 415)\n        # properties\n        self.assertTrue(len(result) == 415)\n        self.assertTrue(result.frame_rate == 100)\n        self.assertTrue(result.fps == 100)\n        self.assertTrue(result.overlap_factor == 0.78466796875)\n        self.assertTrue(result.shape == (415, 2048, 2))\n        self.assertTrue(result.ndim == 3)\n\n    def test_values_file_origin(self):\n        signal = Signal(sample_file)\n        # literal origin\n        result = FramedSignal(sample_file, origin=\'online\')\n        self.assertTrue(result.origin == 1023)\n        self.assertTrue(result.num_frames == 281)\n        # 6th frame should start at 6 * 441 - 2048 + 1 (ref sample) = 599\n        self.assertTrue(np.allclose(result[6], signal[599: 599 + 2048]))\n        # literal left origin\n        result = FramedSignal(sample_file, origin=\'left\')\n        self.assertTrue(result.origin == 1023)\n        # positive origin shifts the window to the left\n        result = FramedSignal(sample_file, origin=10)\n        self.assertTrue(result.origin == 10)\n        # literal offline origin\n        result = FramedSignal(sample_file, origin=\'offline\')\n        self.assertTrue(result.origin == 0)\n        # literal center origin\n        result = FramedSignal(sample_file, origin=\'center\')\n        self.assertTrue(result.origin == 0)\n        # literal right origin\n        result = FramedSignal(sample_file, origin=\'right\')\n        self.assertTrue(result.origin == -1024)\n        # literal future origin\n        result = FramedSignal(sample_file, origin=\'future\')\n        self.assertTrue(result.origin == -1024)\n\n    def test_values_file_start(self):\n        signal = Signal(sample_file)\n        result = FramedSignal(sample_file, origin=-10)\n        # start sample shifted to the right\n        self.assertTrue(result.origin == -10)\n        self.assertTrue(result.num_frames == 281)\n        # 3rd frame should start at 3 * 441 - 2048 / 2 + 10 = 309\n        self.assertTrue(np.allclose(result[3], signal[309: 309 + 2048]))\n\n    def test_values_file_fps(self):\n        result = FramedSignal(sample_file, fps=200)\n        self.assertTrue(result.frame_size == 2048)\n        self.assertTrue(result.hop_size == 220.5)\n        result = FramedSignal(sample_file, fps=50)\n        self.assertTrue(result.frame_size == 2048)\n        self.assertTrue(result.hop_size == 882.)\n\n    def test_methods(self):\n        # mono signals\n        frames = FramedSignal(sig_1d, frame_size=4, hop_size=2)\n        self.assertTrue(np.allclose(frames.energy(), [0, 1, 2, 1, 1]))\n        self.assertTrue(np.allclose(frames.rms(),\n                                    [0, 0.5, 0.70710678, 0.5, 0.5]))\n        self.assertTrue(np.allclose(frames.spl(),\n                                    [-np.finfo(float).max, -6.0206, -3.0103,\n                                     -6.0206, -6.0206]))\n        # multi-channel signals\n        frames = FramedSignal(sig_2d, frame_size=4, hop_size=2)\n        self.assertTrue(np.allclose(frames.energy(), [1, 3, 4, 3, 3]))\n        self.assertTrue(np.allclose(frames.root_mean_square(),\n                                    [0.35355339, 0.61237244, 0.70710678,\n                                     0.61237244, 0.61237244]))\n        self.assertTrue(np.allclose(frames.sound_pressure_level(),\n                                    [-9.03089987, -4.25968732, -3.01029996,\n                                     -4.25968732, -4.25968732]))\n\n    def test_iterating(self):\n        frames = FramedSignal(sig_1d, frame_size=4, hop_size=2)\n        res = frames[range(frames.num_frames)[0]]\n        res = frames[np.arange(frames.num_frames)[0]]\n        res = frames[np.arange(frames.num_frames, dtype=np.long)[0]]\n        if sys.version_info[0] == 2:\n            res = frames[xrange(frames.num_frames)[0]]\n            res = frames[long(range(frames.num_frames)[0])]\n\n\nclass TestFramedSignalProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = FramedSignalProcessor()\n\n    def test_types(self):\n        self.assertIsInstance(self.processor, FramedSignalProcessor)\n        self.assertIsInstance(self.processor, Processor)\n        result = self.processor.process(sample_file)\n        self.assertIsInstance(result, FramedSignal)\n\n    def test_values(self):\n        self.assertTrue(self.processor.frame_size == 2048)\n        self.assertTrue(self.processor.hop_size == 441.)\n        self.assertTrue(self.processor.fps is None)\n        self.assertTrue(self.processor.origin == 0)\n        self.assertTrue(self.processor.end == \'normal\')\n        self.assertTrue(self.processor.num_frames is None)\n\n    def test_process(self):\n        result = self.processor.process(sample_file)\n        self.assertTrue(np.allclose(result[0][:1023], np.zeros(1023)))\n        self.assertTrue(np.allclose(result[0][1024], -2494))\n        # attributes\n        self.assertTrue(result.frame_size == 2048)\n        self.assertTrue(result.hop_size == 441.)\n        self.assertTrue(result.origin == 0)\n        self.assertTrue(result.num_frames == 281)\n        # properties\n        self.assertTrue(len(result) == 281.)\n        self.assertTrue(result.fps == 100.)\n        self.assertTrue(result.frame_rate == 100.)\n        self.assertTrue(result.overlap_factor == 0.78466796875)\n        self.assertTrue(result.shape == (281, 2048))\n        self.assertTrue(result.ndim == 2)\n\n    def test_rewrite_values(self):\n        self.processor.end = \'bogus\'\n        self.assertTrue(self.processor.end == \'bogus\')\n\n    def test_process_online(self):\n        # set online\n        self.processor.origin = \'online\'\n        self.assertEqual(self.processor.origin, \'online\')\n        result = self.processor.process(sample_file)\n        self.assertTrue(np.allclose(result[0][-1], -2494))\n        self.assertTrue(len(result) == 281)\n        self.assertTrue(result.num_frames == 281)\n        # reset online\n        self.processor.online = False\n        self.assertFalse(self.processor.online)\n\n    def test_process_fps(self):\n        # set fps\n        self.processor.fps = 200.\n        self.assertTrue(self.processor.fps == 200)\n        result = self.processor.process(sample_file)\n        self.assertTrue(np.allclose(result[0][:1023], np.zeros(1023)))\n        self.assertTrue(np.allclose(result[0][1024], -2494))\n        self.assertTrue(len(result) == 561)\n        self.assertTrue(result.num_frames == 561)\n        # reset fps\n        self.processor.fps = 100.\n        self.assertTrue(self.processor.fps == 100)\n\n    def test_process_end(self):\n        # set end\n        self.processor.end = \'normal\'\n        self.assertTrue(self.processor.end == \'normal\')\n        # test with a file\n        result = self.processor.process(sample_file)\n        self.assertTrue(np.allclose(result[0][:1023], np.zeros(1023)))\n        self.assertTrue(np.allclose(result[0][1024], -2494))\n        # properties\n        self.assertTrue(result.num_frames == 281)\n        # test with an array\n        self.processor.frame_size = 10\n        self.processor.hop_size = 6\n        result = self.processor.process(np.arange(18))\n        self.assertTrue(len(result) == 3)\n        self.assertTrue(result.num_frames == 3)\n        # rewrite the end\n        self.processor.end = \'extend\'\n        result = self.processor.process(np.arange(18))\n        self.assertTrue(len(result) == 4)\n        self.assertTrue(result.num_frames == 4)\n        # test with incorrect end value\n        with self.assertRaises(ValueError):\n            processor = FramedSignalProcessor(end=\'bla\')\n            processor.process(sample_file)\n        # reset end\n        self.processor.end = \'normal\'\n        self.assertTrue(self.processor.end == \'normal\')\n\n    def test_pickle(self):\n        self.processor.dump(tmp_file)\n        processor = FramedSignalProcessor.load(tmp_file)\n        self.assertEqual(type(self.processor), type(processor))\n        self.assertEqual(self.processor.frame_size, processor.frame_size)\n        self.assertEqual(self.processor.hop_size, processor.hop_size)\n        self.assertEqual(self.processor.fps, processor.fps)\n        self.assertEqual(self.processor.end, processor.end)\n\n\n# clean up\ndef teardown_module():\n    os.unlink(tmp_file)\n'"
tests/test_audio_spectrogram.py,100,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.audio.spectrogram module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join as pj\n\nfrom . import AUDIO_PATH\nfrom .test_audio_filters import FFT_FREQS_1024, LOG_FILTERBANK_CENTER_FREQS\n\nfrom madmom.audio.spectrogram import *\nfrom madmom.audio.filters import (Filterbank, LogarithmicFilterbank,\n                                  MelFilterbank, BarkFilterbank)\nfrom madmom.audio.stft import ShortTimeFourierTransform\nfrom madmom.audio.signal import Signal\n\nsample_file = pj(AUDIO_PATH, \'sample.wav\')\nsample_file_22050 = pj(AUDIO_PATH, \'sample_22050.wav\')\nsample_spec = Spectrogram(sample_file)\n\n\n# test functions\nclass TestDftFunction(unittest.TestCase):\n\n    def test_types(self):\n        self.assertTrue(True)\n\n    def test_values(self):\n        self.assertTrue(True)\n\n\nclass TestStftFunction(unittest.TestCase):\n\n    def test_types(self):\n        self.assertTrue(True)\n\n    def test_value(self):\n        self.assertTrue(True)\n\n\nclass TestSpecFunction(unittest.TestCase):\n\n    def test_types(self):\n        result = spec(np.random.rand(10))\n        self.assertTrue(result.dtype == np.float)\n        self.assertTrue(result.shape == (10, ))\n        result = spec(np.random.rand(10, 2))\n        self.assertTrue(result.dtype == np.float)\n        self.assertTrue(result.shape == (10, 2))\n        # complex data\n        data = np.random.rand(10) + 1j * np.random.rand(10)\n        result = spec(data)\n        self.assertTrue(result.dtype == np.float)\n        self.assertTrue(result.shape == (10, ))\n        data = np.random.rand(10, 2) + 1j * np.random.rand(10, 2)\n        result = spec(data)\n        self.assertTrue(result.dtype == np.float)\n        self.assertTrue(result.shape == (10, 2))\n\n    def test_values(self):\n        data = np.random.rand(10) + 1j * np.random.rand(10)\n        self.assertTrue(np.allclose(np.abs(data), spec(data)))\n        data = np.random.rand(10, 2) + 1j * np.random.rand(10, 2)\n        self.assertTrue(np.allclose(np.abs(data), spec(data)))\n\n\nclass TestSpectrogramClass(unittest.TestCase):\n\n    def test_types(self):\n        result = Spectrogram(sample_file)\n        self.assertIsInstance(result, Spectrogram)\n        # attributes\n        self.assertIsInstance(result.stft, ShortTimeFourierTransform)\n        self.assertIsInstance(result.bin_frequencies, np.ndarray)\n        # properties\n        self.assertIsInstance(result.num_bins, int)\n        self.assertIsInstance(result.num_frames, int)\n\n    def test_values(self):\n        # from file\n        result = Spectrogram(sample_file)\n        self.assertTrue(np.allclose(result[0, :8],\n                                    [3.15249, 4.00272, 5.66156, 6.30141,\n                                     6.02199, 10.84909, 17.83130, 19.44511]))\n        self.assertTrue(np.allclose(result[0, -8:],\n                                    [0.0365325, 0.036513, 0.0364213, 0.0366203,\n                                     0.036737, 0.036423, 0.036335, 0.0367054]))\n        # attributes\n        self.assertTrue(result.shape == (281, 1024))\n        self.assertTrue(np.allclose(result.bin_frequencies, FFT_FREQS_1024))\n        # properties\n        self.assertTrue(result.num_frames == 281)\n        self.assertTrue(result.num_bins == 1024)\n        # from spec\n        self.assertTrue(np.allclose(Spectrogram(result), result))\n        # from stft\n        stft = ShortTimeFourierTransform(sample_file)\n        self.assertTrue(np.allclose(Spectrogram(stft), result))\n\n    def test_methods(self):\n        result = Spectrogram(sample_file)\n        self.assertIsInstance(result.diff(), SpectrogramDifference)\n        self.assertIsInstance(result.filter(), FilteredSpectrogram)\n        self.assertIsInstance(result.log(), LogarithmicSpectrogram)\n\n\nclass TestSpectrogramProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = SpectrogramProcessor()\n\n    def test_types(self):\n        self.assertIsInstance(self.processor, SpectrogramProcessor)\n\n    def test_process(self):\n        result = self.processor.process(sample_file)\n        self.assertIsInstance(result, Spectrogram)\n        # attributes\n        self.assertTrue(result.shape == (281, 1024))\n        self.assertTrue(np.allclose(result.bin_frequencies, FFT_FREQS_1024))\n        # properties\n        self.assertTrue(result.num_frames == 281)\n        self.assertTrue(result.num_bins == 1024)\n\n\nclass TestFilteredSpectrogramClass(unittest.TestCase):\n\n    def test_types(self):\n        result = FilteredSpectrogram(sample_file)\n        self.assertIsInstance(result, FilteredSpectrogram)\n        self.assertIsInstance(result, Spectrogram)\n        # attributes\n        self.assertIsInstance(result.stft, ShortTimeFourierTransform)\n        self.assertIsInstance(result.filterbank, LogarithmicFilterbank)\n        self.assertIsInstance(result.bin_frequencies, np.ndarray)\n        # properties\n        self.assertIsInstance(result.num_bins, int)\n        self.assertIsInstance(result.num_frames, int)\n        # wrong filterbank type\n        with self.assertRaises(TypeError):\n            FilteredSpectrogram(sample_file, filterbank=\'bla\')\n\n    def test_values(self):\n        # from file\n        result = FilteredSpectrogram(sample_file)\n        self.assertTrue(np.allclose(result[0, :8],\n                                    [5.661564, 6.30141, 6.02199, 10.84909,\n                                     17.8313, 19.44511, 17.56456, 21.859523]))\n        self.assertTrue(np.allclose(result[0, -8:],\n                                    [0.123125, 0.119462, 0.137849, 0.1269156,\n                                     0.110888, 0.083526, 0.05426, 0.064614]))\n        # attributes\n        self.assertTrue(result.shape == (281, 81))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    LOG_FILTERBANK_CENTER_FREQS))\n        # properties\n        self.assertTrue(result.num_bins == 81)\n        self.assertTrue(result.num_frames == 281)\n        # with given filterbank\n        result = FilteredSpectrogram(sample_file,\n                                     filterbank=result.filterbank)\n        # attributes\n        self.assertTrue(result.shape == (281, 81))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    LOG_FILTERBANK_CENTER_FREQS))\n        # properties\n        self.assertTrue(result.num_bins == 81)\n        self.assertTrue(result.num_frames == 281)\n\n    def test_filterbanks(self):\n        # with Mel filterbank\n        result = FilteredSpectrogram(sample_file,\n                                     filterbank=MelFilterbank, num_bands=40)\n        self.assertTrue(np.allclose(result[0, :6],\n                                    [8.42887115, 17.98174477, 19.50165367,\n                                     6.48194313, 2.96991181, 4.06280804]))\n        self.assertTrue(result.shape == (281, 40))\n        # with Bark filterbank\n        result = FilteredSpectrogram(sample_file,\n                                     filterbank=BarkFilterbank,\n                                     num_bands=\'normal\')\n        self.assertTrue(np.allclose(result[0, :6],\n                                    [16.42251968, 17.36715126, 2.81979132,\n                                     4.27050114, 3.08699131, 1.50553513]))\n        self.assertTrue(result.shape == (281, 23))\n\n    def test_from_spec(self):\n        spec = Spectrogram(AUDIO_PATH + \'/sample.wav\')\n        result = FilteredSpectrogram(spec)\n        # same results as above\n        self.assertTrue(np.allclose(result[0, :8],\n                                    [5.661564, 6.30141, 6.02199, 10.84909,\n                                     17.8313, 19.44511, 17.56456, 21.859523]))\n        # spec must not be altered\n        self.assertTrue(np.allclose(spec[0, :8],\n                                    [3.15249, 4.00272, 5.66156, 6.30141,\n                                     6.02199, 10.84909, 17.83130, 19.44511]))\n\n    def test_methods(self):\n        result = FilteredSpectrogram(sample_file)\n        self.assertIsInstance(result.diff(), SpectrogramDifference)\n        # TODO: should we return a LogarithmicFilteredSpectrogram?\n        self.assertIsInstance(result.log(), LogarithmicSpectrogram)\n\n\nclass TestFilteredSpectrogramProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = FilteredSpectrogramProcessor()\n\n    def test_types(self):\n        self.assertIsInstance(self.processor, FilteredSpectrogramProcessor)\n        self.assertTrue(issubclass(self.processor.filterbank,\n                                   LogarithmicFilterbank))\n        self.assertIsInstance(self.processor.num_bands, int)\n        self.assertIsInstance(self.processor.fmin, float)\n        self.assertIsInstance(self.processor.fmax, float)\n        self.assertIsInstance(self.processor.fref, float)\n        self.assertIsInstance(self.processor.norm_filters, bool)\n        self.assertIsInstance(self.processor.unique_filters, bool)\n\n    def test_values(self):\n        self.assertTrue(issubclass(self.processor.filterbank,\n                                   LogarithmicFilterbank))\n        self.assertTrue(self.processor.num_bands == 12)\n        self.assertTrue(self.processor.fmin == 30)\n        self.assertTrue(self.processor.fmax == 17000)\n        self.assertTrue(self.processor.fref == 440)\n        self.assertTrue(self.processor.norm_filters is True)\n        self.assertTrue(self.processor.unique_filters is True)\n\n    def test_process(self):\n        # default values\n        result = self.processor.process(sample_file)\n        self.assertIsInstance(result, FilteredSpectrogram)\n        # attributes\n        self.assertTrue(result.shape == (281, 81))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    LOG_FILTERBANK_CENTER_FREQS))\n        # properties\n        self.assertTrue(result.num_bins == 81)\n        self.assertTrue(result.num_frames == 281)\n\n    def test_other_values(self):\n        processor = FilteredSpectrogramProcessor(num_bands=6, fmin=300,\n                                                 fmax=10000)\n        result = processor.process(sample_file)\n        self.assertIsInstance(result, FilteredSpectrogram)\n        # attributes\n        self.assertTrue(result.shape == (281, 29))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    [344.53125, 387.5976562, 430.6640625,\n                                     495.2636718, 559.86328125, 624.4628906,\n                                     689.0625, 775.1953125, 882.8613281,\n                                     990.52734375, 1098.1933593, 1248.9257812,\n                                     1399.6582031, 1571.9238281, 1765.7226562,\n                                     1981.0546875, 2217.9199218, 2497.8515625,\n                                     2799.3164062, 3143.84765625, 3509.912109,\n                                     3940.5761718, 4435.8398437, 4974.1699218,\n                                     5577.09960938, 6266.1621093, 7041.3574218,\n                                     7902.6855468, 8871.6796875]))\n        # properties\n        self.assertTrue(result.num_bins == 29)\n        self.assertTrue(result.num_frames == 281)\n\n\nclass TestLogarithmicSpectrogramClass(unittest.TestCase):\n\n    def test_types(self):\n        result = LogarithmicSpectrogram(sample_file)\n        self.assertIsInstance(result, LogarithmicSpectrogram)\n        self.assertIsInstance(result, Spectrogram)\n        # attributes\n        self.assertIsInstance(result.stft, ShortTimeFourierTransform)\n        self.assertIsInstance(result.bin_frequencies, np.ndarray)\n        self.assertIsInstance(result.mul, float)\n        self.assertIsInstance(result.add, float)\n        # properties\n        self.assertIsInstance(result.num_frames, int)\n        self.assertIsInstance(result.num_bins, int)\n\n    def test_values(self):\n        result = LogarithmicSpectrogram(sample_file)\n        self.assertTrue(np.allclose(result[0, :8],\n                                    [0.618309, 0.699206, 0.823576, 0.86341,\n                                     0.84646, 1.073685, 1.27488, 1.310589]))\n        self.assertTrue(np.allclose(result[0, -8:],\n                                    [0.015583, 0.0155747, 0.0155363, 0.0156197,\n                                     0.0156684, 0.015537, 0.0155003,\n                                     0.01565535]))\n        # attributes\n        self.assertTrue(result.shape == (281, 1024))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    FFT_FREQS_1024))\n        self.assertTrue(result.mul == 1)\n        self.assertTrue(result.add == 1)\n        # properties\n        self.assertTrue(result.num_frames == 281)\n        self.assertTrue(result.num_bins == 1024)\n        # test other values\n        result = LogarithmicSpectrogram(sample_file,\n                                        mul=2, add=2)\n        self.assertTrue(result.mul == 2)\n        self.assertTrue(result.add == 2)\n\n    def test_from_spec(self):\n        spec = Spectrogram(AUDIO_PATH + \'/sample.wav\')\n        result = LogarithmicSpectrogram(spec)\n        # same results as above\n        self.assertTrue(np.allclose(result[0, :8],\n                                    [0.618309, 0.699206, 0.823576, 0.86341,\n                                     0.84646, 1.073685, 1.27488, 1.310589]))\n        # spec must not be altered\n        self.assertTrue(np.allclose(spec[0, :8],\n                                    [3.15249, 4.00272, 5.66156, 6.30141,\n                                     6.02199, 10.84909, 17.83130, 19.44511]))\n\n    def test_methods(self):\n        result = LogarithmicSpectrogram(sample_file)\n        self.assertIsInstance(result.diff(), SpectrogramDifference)\n        self.assertIsInstance(result.filter(), FilteredSpectrogram)\n\n\nclass TestLogarithmicSpectrogramProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = LogarithmicSpectrogramProcessor()\n\n    def test_types(self):\n        self.assertIsInstance(self.processor, LogarithmicSpectrogramProcessor)\n        self.assertIsInstance(self.processor.mul, float)\n        self.assertIsInstance(self.processor.add, float)\n\n    def test_values(self):\n        self.assertTrue(self.processor.mul == 1)\n        self.assertTrue(self.processor.add == 1)\n\n    def test_process(self):\n        result = self.processor.process(sample_file)\n        self.assertIsInstance(result, LogarithmicSpectrogram)\n        self.assertTrue(result.shape == (281, 1024))\n\n\nclass TestLogarithmicFilteredSpectrogramClass(unittest.TestCase):\n\n    def test_types(self):\n        result = LogarithmicFilteredSpectrogram(sample_file)\n        self.assertIsInstance(result, LogarithmicFilteredSpectrogram)\n        self.assertIsInstance(result, Spectrogram)\n        # attributes\n        self.assertIsInstance(result.stft, ShortTimeFourierTransform)\n        self.assertIsInstance(result.filterbank, Filterbank)\n        self.assertIsInstance(result.filterbank, LogarithmicFilterbank)\n        self.assertIsInstance(result.bin_frequencies, np.ndarray)\n        self.assertIsInstance(result.mul, float)\n        self.assertIsInstance(result.add, float)\n        # properties\n        self.assertIsInstance(result.num_frames, int)\n        self.assertIsInstance(result.num_bins, int)\n\n    def test_values(self):\n        result = LogarithmicFilteredSpectrogram(sample_file)\n        self.assertTrue(np.allclose(result[0, :8],\n                                    [0.8235762, 0.863407, 0.8464602, 1.073685,\n                                     1.27488, 1.3105896, 1.2686847, 1.359067]))\n        self.assertTrue(np.allclose(result[0, -8:],\n                                    [0.05042794, 0.0490095, 0.05608485,\n                                     0.05189138, 0.04567042, 0.03483925,\n                                     0.02294769, 0.02719229]))\n        # attributes\n        self.assertTrue(result.shape == (281, 81))\n        self.assertTrue(result.mul == 1)\n        self.assertTrue(result.add == 1)\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    LOG_FILTERBANK_CENTER_FREQS))\n        # properties\n        self.assertTrue(result.num_frames == 281)\n        self.assertTrue(result.num_bins == 81)\n        # test other values\n        result = LogarithmicFilteredSpectrogram(sample_file, mul=2, add=2)\n        self.assertTrue(result.mul == 2)\n        self.assertTrue(result.add == 2)\n\n    def test_from_spec(self):\n        spec = Spectrogram(AUDIO_PATH + \'/sample.wav\')\n        result = LogarithmicFilteredSpectrogram(spec)\n        # same results as above\n        self.assertTrue(result.shape == (281, 81))\n        self.assertTrue(np.allclose(result[0, :8],\n                                    [0.8235762, 0.863407, 0.8464602, 1.073685,\n                                     1.27488, 1.3105896, 1.2686847, 1.359067]))\n        # spec must not be altered\n        self.assertTrue(spec.shape == (281, 1024))\n        self.assertTrue(np.allclose(spec[0, :8],\n                                    [3.15249, 4.00272, 5.66156, 6.30141,\n                                     6.02199, 10.84909, 17.83130, 19.44511]))\n\n\nclass TestLogarithmicFilteredSpectrogramProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = LogarithmicFilteredSpectrogramProcessor()\n\n    def test_types(self):\n\n        self.assertIsInstance(self.processor,\n                              LogarithmicFilteredSpectrogramProcessor)\n        self.assertTrue(self.processor.filterbank == LogarithmicFilterbank)\n        self.assertIsInstance(self.processor.num_bands, int)\n        self.assertIsInstance(self.processor.fmin, float)\n        self.assertIsInstance(self.processor.fmax, float)\n        self.assertIsInstance(self.processor.fref, float)\n        self.assertIsInstance(self.processor.norm_filters, bool)\n        self.assertIsInstance(self.processor.unique_filters, bool)\n        self.assertIsInstance(self.processor.mul, float)\n        self.assertIsInstance(self.processor.add, float)\n\n    def test_values(self):\n        # filter stuff\n        self.assertTrue(issubclass(self.processor.filterbank,\n                                   LogarithmicFilterbank))\n        self.assertTrue(self.processor.num_bands == 12)\n        self.assertTrue(self.processor.fmin == 30)\n        self.assertTrue(self.processor.fmax == 17000)\n        self.assertTrue(self.processor.fref == 440)\n        self.assertTrue(self.processor.norm_filters is True)\n        self.assertTrue(self.processor.unique_filters is True)\n        # log stuff\n        self.assertTrue(self.processor.mul == 1)\n        self.assertTrue(self.processor.add == 1)\n\n    def test_process(self):\n        result = self.processor.process(sample_file)\n        self.assertIsInstance(result, LogarithmicFilteredSpectrogram)\n\n        self.assertTrue(result.shape == (281, 81))\n\n\nclass TestSpectrogramDifferenceClass(unittest.TestCase):\n\n    def test_types(self):\n        result = SpectrogramDifference(sample_file)\n        self.assertIsInstance(result, SpectrogramDifference)\n        self.assertIsInstance(result, Spectrogram)\n        # attributes\n        self.assertIsInstance(result.spectrogram, Spectrogram)\n        self.assertIsInstance(result.bin_frequencies, np.ndarray)\n        self.assertIsInstance(result.diff_ratio, float)\n        self.assertIsInstance(result.diff_frames, int)\n        self.assertTrue(result.diff_max_bins is None)\n        self.assertIsInstance(result.positive_diffs, bool)\n        # properties\n        self.assertIsInstance(result.num_frames, int)\n        self.assertIsInstance(result.num_bins, int)\n\n    def test_values(self):\n        result = SpectrogramDifference(sample_file)\n        self.assertTrue(np.allclose(result[1, :8],\n                                    [1.13179708, -1.1511457, 2.7810955,\n                                     2.39441729, -4.87367058, -0.90269375,\n                                     3.48209763, 11.14723015]))\n        self.assertTrue(np.allclose(result[1, -8:],\n                                    [-0.01463442, -0.01408007, -0.01462659,\n                                     -0.01431422, -0.01404046, -0.01457103,\n                                     -0.01443923, -0.01443416]))\n        # attributes\n        self.assertTrue(result.shape == (281, 1024))\n        self.assertTrue(np.allclose(result.bin_frequencies, FFT_FREQS_1024))\n        self.assertTrue(result.diff_ratio == 0.5)\n        self.assertTrue(result.diff_frames == 1)\n        self.assertTrue(result.diff_max_bins is None)\n        self.assertTrue(result.positive_diffs is False)\n        # properties\n        self.assertTrue(result.num_bins == 1024)\n        self.assertTrue(result.num_frames == 281)\n        # methods\n        self.assertTrue(result.positive_diff().min() == 0)\n\n\nclass TestSpectrogramDifferenceProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = SpectrogramDifferenceProcessor()\n\n    def test_types(self):\n        self.assertIsInstance(self.processor, SpectrogramDifferenceProcessor)\n        self.assertIsInstance(self.processor.diff_ratio, float)\n        self.assertTrue(self.processor.diff_frames is None)\n        self.assertTrue(self.processor.diff_max_bins is None)\n        self.assertIsInstance(self.processor.positive_diffs, bool)\n        self.assertTrue(self.processor.stack_diffs is None)\n\n    def test_values(self):\n        self.assertTrue(self.processor.diff_ratio == 0.5)\n        self.assertTrue(self.processor.diff_frames is None)\n        self.assertTrue(self.processor.diff_max_bins is None)\n        self.assertTrue(self.processor.positive_diffs is False)\n\n    def test_process(self):\n        result = self.processor.process(sample_spec)\n        self.assertTrue(result.shape == (281, 1024))\n        self.assertTrue(np.sum(result[:1]) == 0)\n        self.assertTrue(np.max(result[:2]) > 0)\n        self.assertTrue(np.min(result) < 0)\n        self.assertTrue(np.allclose(result[0], 0))\n        self.assertTrue(np.allclose(result[1:], np.diff(sample_spec, axis=0)))\n        # if called a second time, result must be the exact same\n        result_1 = self.processor.process(sample_spec)\n        self.assertTrue(np.allclose(result, result_1))\n        # result must be the same if processed frame-by-frame\n        self.processor.reset()\n        result_2 = np.vstack([self.processor.process(np.atleast_2d(frame),\n                                                     reset=False)\n                              for frame in sample_spec])\n        self.assertTrue(np.allclose(result_2, result))\n        # result must be different without resetting (first frame != 0)\n        result_3 = np.vstack([self.processor.process(np.atleast_2d(frame),\n                                                     reset=False)\n                              for frame in sample_spec])\n        self.assertFalse(np.allclose(result_3, result))\n        self.assertFalse(np.sum(result_3[0]) == 0)\n\n    def test_diff_frames(self):\n        # re-initialise the processor, because of the buffer\n        self.processor = SpectrogramDifferenceProcessor(diff_frames=2)\n        self.assertTrue(self.processor.diff_frames == 2)\n        result = self.processor.process(sample_spec)\n        self.assertTrue(result.shape == (281, 1024))\n        self.assertTrue(np.sum(result[:2]) == 0)\n        self.assertTrue(np.min(result) < 0)\n        self.assertTrue(result.diff_frames == 2)\n        # if called a second time, result must be the exact same\n        result_1 = self.processor.process(sample_spec)\n        self.assertTrue(np.allclose(result, result_1))\n        # result must be the same if processed frame-by-frame\n        self.processor.reset()\n        self.assertTrue(self.processor.diff_frames == 2)\n        result_2 = np.vstack([self.processor.process(np.atleast_2d(frame),\n                                                     reset=False)\n                              for frame in sample_spec])\n        self.assertTrue(np.allclose(result_2, result))\n        # result must be different without resetting (first 2 frame != 0)\n        result_3 = np.vstack([self.processor.process(np.atleast_2d(frame),\n                                                     reset=False)\n                              for frame in sample_spec])\n        self.assertFalse(np.allclose(result_3, result))\n        self.assertFalse(np.sum(result_3[0]) == 0)\n        self.assertFalse(np.sum(result_3[1]) == 0)\n\n    def test_positive_diffs(self):\n        # re-initialise the processor, because of the buffer\n        self.processor = SpectrogramDifferenceProcessor(diff_frames=2)\n        self.processor.positive_diffs = True\n        result = self.processor.process(sample_spec)\n        self.assertTrue(result.shape == (281, 1024))\n        self.assertTrue(np.sum(result[:2]) == 0)\n        self.assertTrue(np.min(result) >= 0)\n        # change stacking\n        self.processor.stack_diffs = np.hstack\n        result = self.processor.process(sample_spec)\n        self.assertTrue(result.shape == (281, 1024 * 2))\n        self.assertTrue(np.min(result) >= 0)\n        self.processor.stack_diffs = np.vstack\n        result = self.processor.process(sample_spec)\n        self.assertTrue(result.shape == (281 * 2, 1024))\n        self.assertTrue(np.min(result) >= 0)\n        self.processor.stack_diffs = np.dstack\n        result = self.processor.process(sample_spec)\n        self.assertTrue(result.shape == (281, 1024, 2))\n        self.assertTrue(np.min(result) >= 0)\n\n\nclass TestSuperFluxProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = SuperFluxProcessor()\n\n    def test_types(self):\n        self.assertIsInstance(self.processor, SuperFluxProcessor)\n\n    def test_values(self):\n        result = self.processor.process(sample_file)\n        self.assertTrue(np.allclose(result[1, :8],\n                                    [0.11168772, 0.12317812, 0, 0, 0.03797626,\n                                     0.18899226, 0, 0.0903399]))\n        self.assertTrue(np.allclose(result[1, -8:],\n                                    [0, 0, 0.01419619, 0, 0.02666602,\n                                     0.04325962, 0.10899737, 0.06546581]))\n        self.assertIsInstance(result, SpectrogramDifference)\n        self.assertTrue(result.num_bins == 140)\n        self.assertTrue(result.num_frames == 281)\n        self.assertTrue(result.shape == (281, 140))\n        # diff stuff\n        self.assertTrue(result.diff_ratio == 0.5)\n        self.assertTrue(result.diff_max_bins == 3)\n        self.assertTrue(result.positive_diffs is True)\n\n\nclass TestMultiBandSpectrogramClass(unittest.TestCase):\n\n    def test_types(self):\n        result = MultiBandSpectrogram(sample_file, [200, 1000])\n        self.assertIsInstance(result, MultiBandSpectrogram)\n        # attributes\n        self.assertIsInstance(result.bin_frequencies, np.ndarray)\n        self.assertIsInstance(result.crossover_frequencies, list)\n        # properties\n        self.assertIsInstance(result.num_bins, int)\n        self.assertIsInstance(result.num_frames, int)\n\n    def test_values(self):\n        result = MultiBandSpectrogram(sample_file, [200, 1000])\n        self.assertTrue(np.allclose(result[:3],\n                                    [[10.95971966, 4.23556566, 0.19092605],\n                                     [11.38149452, 4.88609695, 0.21491699],\n                                     [13.50860405, 4.48350096, 0.20132662]]))\n        self.assertTrue(isinstance(result.filterbank, Filterbank))\n        # attributes\n        self.assertTrue(result.crossover_frequencies == [200, 1000])\n        self.assertTrue(result.shape == (281, 3))\n        # properties\n        self.assertTrue(result.num_frames == 281)\n        self.assertTrue(result.num_bins == 3)\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    [86.1328125, 581.39648438, 8979.34570312]))\n\n\nclass TestMultiBandSpectrogramProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = MultiBandSpectrogramProcessor([200, 1000])\n\n    def test_types(self):\n        self.assertIsInstance(self.processor, MultiBandSpectrogramProcessor)\n        self.assertIsInstance(self.processor, Processor)\n        self.assertIsInstance(self.processor.crossover_frequencies, np.ndarray)\n        self.assertIsInstance(self.processor.fmin, float)\n        self.assertIsInstance(self.processor.fmax, float)\n        self.assertIsInstance(self.processor.norm_filters, bool)\n        self.assertIsInstance(self.processor.unique_filters, bool)\n\n    def test_values(self):\n        self.assertTrue(np.allclose(self.processor.crossover_frequencies,\n                                    [200, 1000]))\n        self.assertTrue(self.processor.fmin == 30)\n        self.assertTrue(self.processor.fmax == 17000)\n        self.assertTrue(self.processor.norm_filters is True)\n        self.assertTrue(self.processor.unique_filters is True)\n\n    def test_process(self):\n        # default values\n        result = self.processor.process(sample_file)\n        self.assertTrue(np.allclose(result[:3],\n                                    [[10.95971966, 4.23556566, 0.19092605],\n                                     [11.38149452, 4.88609695, 0.21491699],\n                                     [13.50860405, 4.48350096, 0.20132662]]))\n        self.assertIsInstance(result, MultiBandSpectrogram)\n        # attributes\n        self.assertTrue(result.shape == (281, 3))\n        self.assertTrue(np.allclose(result.crossover_frequencies, [200, 1000]))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    [86.1328, 581.3965, 8979.3457]))\n        # properties\n        self.assertTrue(result.num_bins == 3)\n        self.assertTrue(result.num_frames == 281)\n        # test 2 bands\n        self.processor.crossover_frequencies = [500]\n        result = self.processor.process(sample_file)\n        self.assertTrue(np.allclose(result[:3],\n                                    [[9.37507915, 0.23498698],\n                                     [10.4683371, 0.26268598],\n                                     [10.8684139, 0.24078195]]))\n        self.assertIsInstance(result, MultiBandSpectrogram)\n        self.assertTrue(result.shape == (281, 2))\n        self.assertTrue(np.allclose(result.crossover_frequencies, [500]))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    [236.865, 8720.947]))\n        self.assertTrue(np.allclose(np.max(result.filterbank, axis=0),\n                                    [0.04545455, 0.00130548]))\n        # properties\n        self.assertTrue(result.num_bins == 2)\n        self.assertTrue(result.num_frames == 281)\n        # test without normalized filters\n        self.processor.norm_filters = False\n        result = self.processor.process(sample_file)\n        self.assertTrue(np.allclose(result[:3],\n                                    [[206.25172424, 180],\n                                     [230.30342102, 201.21743774],\n                                     [239.10510254, 184.43896484]]))\n        self.assertIsInstance(result, MultiBandSpectrogram)\n        self.assertTrue(result.shape == (281, 2))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    [236.865, 8720.947]))\n        self.assertTrue(np.allclose(np.max(result.filterbank, axis=0), [1, 1]))\n\n\nclass TestSemitoneBandpassSpectrogramClass(unittest.TestCase):\n\n    def setUp(self):\n        self.sbs_50 = SemitoneBandpassSpectrogram(sample_file, fps=50)\n        self.sbs_10 = SemitoneBandpassSpectrogram(sample_file, fps=10)\n        self.sbs_22050 = SemitoneBandpassSpectrogram(\n            sample_file_22050, fps=50, fmin=2637, fmax=4200)\n        data = Signal(sample_file)\n        self.sbs_10_from_signal = SemitoneBandpassSpectrogram(data, fps=10)\n\n    def test_process(self):\n        # test fps = 50\n        self.assertTrue(self.sbs_50.fps == 50)\n        # results\n        self.assertTrue(self.sbs_50.shape == (141, 88))\n        self.assertTrue(self.sbs_50.num_bins == 88)\n        self.assertTrue(np.allclose(self.sbs_50[120:122, 50:55],\n                                    [[0.00056659, 0.00274373, 0.00037994,\n                                      0.00031497, 0.0063823],\n                                     [0.00032294, 0.00285728, 0.00023723,\n                                      0.00010553, 0.0069074]]))\n        self.assertTrue(np.allclose(self.sbs_50[:10, 0],\n                                    [0.00108844, 0.0020613, 0.00187792,\n                                     0.00173228, 0.00163516, 0.00149813,\n                                     0.0013027, 0.0010594, 0.00079916,\n                                     0.00060871], atol=1e-04))\n        self.assertTrue(np.allclose(self.sbs_50[:10, 29],\n                                    [0.05326259, 0.10912816, 0.11616101,\n                                     0.11595627, 0.11979639, 0.12206492,\n                                     0.12836982, 0.12495992, 0.11759637,\n                                     0.10559082]))\n        # test fps = 10\n        self.assertTrue(self.sbs_10.fps == 10)\n        self.assertTrue(self.sbs_10.shape == (29, 88))\n        sbs_10 = [[0.01951193, 0.01638364, 0.00384092, 0.00732366, 0.10310112],\n                  [0.14484727, 0.032042, 0.00719009, 0.02043642, 0.06407038]]\n        self.assertTrue(np.allclose(self.sbs_10[10:12, 50:55], sbs_10))\n        # test computing SemitoneBandpassSpectrogram from signal\n        self.assertTrue(self.sbs_10_from_signal.shape == (29, 88))\n        self.assertTrue(np.allclose(self.sbs_10_from_signal[10:12, 50:55],\n                                    sbs_10))\n        # test 22050 Hz sampling rate. If we use only bands above 2637 Hz,\n        # no resampling is necessary and we can therefore compare with\n        # smaller tolerances.\n        self.assertTrue(self.sbs_22050.shape == (141, 9))\n        tar = [[0.06541425, 0.09758339, 0.09000319, 0.06654418, 0.06468658,\n                0.05898506, 0.03190501, 0.04980498, 0.07482897],\n               [0.07191198, 0.07706247, 0.05581443, 0.03765683, 0.04524021,\n                0.03835757, 0.0295172, 0.04417975, 0.06682143]]\n        self.assertTrue(np.allclose(self.sbs_22050[108:110, :], tar))\n        # check end of signal\n        tar = [9.44913489e-06, 2.15330783e-05, 1.61559697e-05, 3.66821812e-06,\n               7.96367061e-06, 2.01982581e-05, 2.03380816e-06, 5.34317005e-06,\n               4.13617626e-06]\n        self.assertTrue(np.allclose(self.sbs_22050[140, :], tar))\n\n    def test_compare_with_matlab_toolbox(self):\n        # compare the results with the MATLAB chroma toolbox. There are\n        # differences because of different resampling and filtering with\n        # filtfilt, therefore we compare with higher tolerances.\n        self.assertTrue(np.allclose(self.sbs_50[:10, 29],\n                                    [0.054849, 0.114634, 0.115050, 0.119006,\n                                     0.128422, 0.128793, 0.127636, 0.124041,\n                                     0.113962, 0.103785], rtol=1e-01))\n        self.assertTrue(np.allclose(self.sbs_10[10:12, 50:55],\n                                    [[0.01951726, 0.01638535, 0.00384128,\n                                      0.00732471, 0.10306561],\n                                     [0.14487972, 0.03204085, 0.00718818,\n                                      0.02043327, 0.06404668]], rtol=1e-03))\n'"
tests/test_audio_stft.py,63,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.audio.stft module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nimport sys\nfrom os.path import join as pj\n\nfrom . import AUDIO_PATH\nfrom madmom.audio.stft import *\nfrom madmom.audio.spectrogram import Spectrogram\nfrom madmom.audio.signal import FramedSignal\n\nsample_file = pj(AUDIO_PATH, \'sample.wav\')\nsig_2d = np.array([[1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n                   [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n                   [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]])\n\n\nclass TestBinFrequenciesFunction(unittest.TestCase):\n\n    def test_num_arguments(self):\n        # number of arguments arguments\n        with self.assertRaises(TypeError):\n            fft_frequencies()\n        with self.assertRaises(TypeError):\n            fft_frequencies(1)\n        with self.assertRaises(TypeError):\n            fft_frequencies(1, 2, 3)\n\n    def test_types(self):\n        result = fft_frequencies(5, 10)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.float)\n\n    def test_value(self):\n        result = fft_frequencies(5, 10)\n        self.assertTrue(np.allclose(result, [0, 1, 2, 3, 4]))\n\n\nclass TestStftFunction(unittest.TestCase):\n\n    def test_types(self):\n        result = stft(np.arange(10).reshape(5, 2), window=None)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.dtype, np.complex64)\n\n    def test_window_size(self):\n        # window size must match frame size\n        with self.assertRaises(ValueError):\n            stft(np.arange(10).reshape(5, 2), window=[1, 2, 3])\n\n    def test_2d_signal(self):\n        result = stft(sig_2d, window=None)\n        # signal length and FFT size = 12\n        # fft_freqs: 0, 1/12, 2/12, 3/12, 4/12, 5/12\n        # [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] every 4th bin => 3/12\n        res = [3. + 0.j, 0. + 0.j, 0. - 0.j, 3 + 0.j, 0. + 0.j, 0. + 0.j]\n        self.assertTrue(np.allclose(result[0], res))\n        # [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0] every erd bin => 4/12\n        res = [4. + 0.j, 0. + 0.j, 0. + 0.j, 0. + 0.j, 4. + 0.j, 0. + 0.j]\n        self.assertTrue(np.allclose(result[1], res))\n        # [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0] every 2nd bin => 6/12\n        # can\'t resolve any more\n        res = [6. + 0.j, 0. + 0.j, 0. + 0.j, 0. + 0.j, 0. + 0.j, 0. + 0.j]\n        self.assertTrue(np.allclose(result[2], res))\n\n    def test_circular_shift(self):\n        result = stft(sig_2d, window=None, circular_shift=True)\n        # signal length and FFT size = 12\n        # fft_freqs: 0, 1/12, 2/12, 3/12, 4/12, 5/12\n        # [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] every 4th bin => 3/12\n        res = [3. + 0.j, 0. + 0.j, 0. + 0j, -3. + 0.j, 0. + 0.j, 0. + 0.j]\n        self.assertTrue(np.allclose(result[0], res))\n        # [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0] every erd bin => 4/12\n        res = [4. + 0.j, 0. + 0.j, 0. + 0.j, 0. + 0.j, 4. + 0.j, 0. + 0.j]\n        self.assertTrue(np.allclose(result[1], res))\n        # [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0] every 2nd bin => 6/12\n        # can\'t resolve any more\n        res = [6. + 0.j, 0. + 0.j, 0. + 0.j, 0. + 0.j, 0. + 0.j, 0. + 0.j]\n        self.assertTrue(np.allclose(result[2], res))\n\n    def test_nyquist(self):\n        result = stft(sig_2d, window=None, include_nyquist=True)\n        self.assertTrue(result.shape == (3, 7))\n        # test only the last req bin\n        res = [3. + 0.j, 0. + 0.j, 6. + 0.j]\n        self.assertTrue(np.allclose(result[:, -1], res))\n\n    def test_fft_size(self):\n        result = stft(sig_2d, window=None, fft_size=25)\n        self.assertTrue(result.shape == (3, 12))\n        result = stft(sig_2d, window=None, fft_size=25, include_nyquist=True)\n        self.assertTrue(result.shape == (3, 13))\n        # test only the first req bin\n        res = [3. + 0.j, 4. + 0.j, 6. + 0.j]\n        self.assertTrue(np.allclose(result[:, 0], res))\n\n\nclass TestPhaseFunction(unittest.TestCase):\n\n    def test_types(self):\n        result = phase(np.random.rand(10))\n        self.assertTrue(result.dtype == np.float)\n        self.assertTrue(result.shape == (10, ))\n        result = phase(np.random.rand(10, 2))\n        self.assertTrue(result.dtype == np.float)\n        self.assertTrue(result.shape == (10, 2))\n        # complex data\n        data = np.random.rand(10) + 1j * np.random.rand(10)\n        result = phase(data)\n        self.assertTrue(result.dtype == np.float)\n        self.assertTrue(result.shape == (10, ))\n        data = np.random.rand(10, 2) + 1j * np.random.rand(10, 2)\n        result = phase(data)\n        self.assertTrue(result.dtype == np.float)\n        self.assertTrue(result.shape == (10, 2))\n\n    def test_values(self):\n        data = np.random.rand(10) + 1j * np.random.rand(10)\n        self.assertTrue(np.allclose(np.angle(data), phase(data)))\n        data = np.random.rand(10, 2) + 1j * np.random.rand(10, 2)\n        self.assertTrue(np.allclose(np.angle(data), phase(data)))\n\n\nclass TestLocalGroupDelayFunction(unittest.TestCase):\n\n    def test_types(self):\n        result = local_group_delay(np.random.rand(10, 2))\n        self.assertTrue(result.dtype == np.float)\n        self.assertTrue(result.shape == (10, 2))\n        with self.assertRaises(ValueError):\n            local_group_delay(np.arange(10))\n        with self.assertRaises(ValueError):\n            local_group_delay(np.arange(20).reshape(5, 2, 2))\n\n    def test_values(self):\n        data = np.arange(20).reshape(10, 2) * 2\n        correct = np.tile([-2, 0], 10).reshape(10, 2)\n        self.assertTrue(np.allclose(correct, local_group_delay(data)))\n        data = np.arange(20).reshape(10, 2) * 4\n        correct = np.tile([2.28318531, 0], 10).reshape(10, 2)\n        self.assertTrue(np.allclose(correct, local_group_delay(data)))\n\n\n# test classes\nclass ShortTimeFourierTransformClass(unittest.TestCase):\n\n    def test_types(self):\n        result = ShortTimeFourierTransform(sample_file)\n        self.assertIsInstance(result, ShortTimeFourierTransform)\n        self.assertIsInstance(result, np.ndarray)\n        # attributes\n        self.assertIsInstance(result.frames, FramedSignal)\n        self.assertIsInstance(result.bin_frequencies, np.ndarray)\n        self.assertIsInstance(result.window, np.ndarray)\n        self.assertIsInstance(result.fft_window, np.ndarray)\n        self.assertIsInstance(result.fft_size, int)\n        self.assertIsInstance(result.circular_shift, bool)\n        # properties\n        self.assertIsInstance(result.num_bins, int)\n        self.assertIsInstance(result.num_frames, int)\n\n    def test_values(self):\n        result = ShortTimeFourierTransform(sample_file)\n        self.assertTrue(result.shape == (281, 1024))\n        self.assertTrue(result.fft_size == 2048)\n        self.assertTrue(result.circular_shift is False)\n        self.assertTrue(result.include_nyquist is False)\n        self.assertTrue(np.allclose(result.window, np.hanning(2048)))\n        self.assertTrue(np.allclose(result.fft_window,\n                                    np.hanning(2048) / 32767))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    fft_frequencies(1024, 44100)))\n        # properties\n        self.assertTrue(result.num_frames == 281)\n        self.assertTrue(result.num_bins == 1024)\n        # from STFT\n        self.assertTrue(np.allclose(ShortTimeFourierTransform(result), result))\n\n    def test_methods(self):\n        result = ShortTimeFourierTransform(sample_file)\n        self.assertIsInstance(result.spec(), Spectrogram)\n        self.assertIsInstance(result.phase(), Phase)\n\n    def test_fft_window(self):\n        # use a signal\n        from madmom.audio.signal import Signal\n        signal = Signal(sample_file)\n        # scale the signal to float and range -1..1\n        scaling = float(np.iinfo(signal.dtype).max)\n        scaled_signal = signal / scaling\n        # calculate the STFTs of both signals\n        result = ShortTimeFourierTransform(signal)\n        scaled_result = ShortTimeFourierTransform(scaled_signal)\n        # both STFTs must be the same\n        self.assertTrue(np.allclose(result, scaled_result))\n        # if now window is given, a uniformly distributed one should be used\n        result = ShortTimeFourierTransform(signal, window=None)\n        self.assertTrue(np.allclose(result.fft_window,\n                                    np.ones(2048, dtype=float) / scaling))\n        scaled_result = ShortTimeFourierTransform(scaled_signal, window=None)\n        self.assertTrue(scaled_result.fft_window is None)\n\n    def test_nyquist(self):\n        result = ShortTimeFourierTransform(sample_file, include_nyquist=True)\n        self.assertTrue(result.shape == (281, 1025))\n        self.assertTrue(result.fft_size == 2048)\n        self.assertTrue(result.circular_shift is False)\n        self.assertTrue(result.include_nyquist is True)\n        self.assertTrue(np.allclose(result.window, np.hanning(2048)))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    fft_frequencies(1025, 44100)))\n\n\nclass ShortTimeFourierTransformProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = ShortTimeFourierTransformProcessor()\n\n    def test_types(self):\n        self.assertIsInstance(self.processor,\n                              ShortTimeFourierTransformProcessor)\n\n    def test_values(self):\n        self.assertTrue(self.processor.window == np.hanning)\n        self.assertTrue(self.processor.fft_size is None)\n        self.assertTrue(self.processor.circular_shift is False)\n\n    def test_process(self):\n        result = self.processor.process(sample_file)\n        # attributes\n        self.assertTrue(result.shape == (281, 1024))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    fft_frequencies(1024, 44100)))\n        self.assertIsInstance(result, ShortTimeFourierTransform)\n        self.assertTrue(result.fft_size == 2048)\n        self.assertTrue(np.allclose(result.fft_window,\n                                    np.hanning(2048) / 32767))\n\n        # properties\n        self.assertTrue(result.num_bins == 1024)\n        self.assertTrue(result.num_frames == 281)\n\n\nclass PhaseClass(unittest.TestCase):\n\n    def test_types(self):\n        result = Phase(sample_file)\n        self.assertIsInstance(result, Phase)\n        self.assertIsInstance(result, np.ndarray)\n        # attributes\n        self.assertIsInstance(result.stft, ShortTimeFourierTransform)\n        self.assertIsInstance(result.bin_frequencies, np.ndarray)\n        # properties\n        self.assertIsInstance(result.num_bins, int)\n        self.assertIsInstance(result.num_frames, int)\n\n    def test_values(self):\n        result = Phase(sample_file)\n        # attributes\n        self.assertTrue(result.shape == (281, 1024))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    fft_frequencies(1024, 44100)))\n        # properties\n        self.assertTrue(result.num_bins == 1024)\n        self.assertTrue(result.num_frames == 281)\n\n    def test_methods(self):\n        result = Phase(sample_file)\n        self.assertIsInstance(result.local_group_delay(), LocalGroupDelay)\n        self.assertIsInstance(result.lgd(), LocalGroupDelay)\n\n    @unittest.skipIf(sys.version_info < (3, 2), \'assertWarns needs Python 3.2\')\n    def test_warnings(self):\n        with self.assertWarns(RuntimeWarning):\n            Phase(STFT(sample_file))\n\n\nclass LocalGroupDelayClass(unittest.TestCase):\n\n    def test_types(self):\n        result = LocalGroupDelay(sample_file)\n        self.assertIsInstance(result, LocalGroupDelay)\n        self.assertIsInstance(result, np.ndarray)\n        # attributes\n        self.assertIsInstance(result.phase, Phase)\n        self.assertIsInstance(result.stft, ShortTimeFourierTransform)\n        self.assertIsInstance(result.bin_frequencies, np.ndarray)\n        # properties\n        self.assertIsInstance(result.num_bins, int)\n        self.assertIsInstance(result.num_frames, int)\n\n    def test_values(self):\n        result = LocalGroupDelay(sample_file)\n        # attributes\n        self.assertTrue(result.shape == (281, 1024))\n        self.assertTrue(np.allclose(result.bin_frequencies,\n                                    fft_frequencies(1024, 44100)))\n        # properties\n        self.assertTrue(result.num_bins == 1024)\n        self.assertTrue(result.num_frames == 281)\n'"
tests/test_bin.py,215,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the programs in the /bin directory.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport imp\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport unittest\nfrom os.path import join as pj\n\ntry:\n    from cStringIO import StringIO\nexcept ImportError:\n    from io import StringIO\n\nimport numpy as np\n\nfrom madmom.features import Activations\nfrom madmom.evaluation.key import load_key\nfrom madmom.io import load_chords, midi\nfrom madmom.utils import search_files\n\nfrom . import AUDIO_PATH, ACTIVATIONS_PATH, ANNOTATIONS_PATH, DETECTIONS_PATH\n\ntmp_act = tempfile.NamedTemporaryFile(delete=False).name\ntmp_dir = tempfile.mkdtemp()\ntmp_result = tempfile.NamedTemporaryFile(delete=False).name\nsample_file = pj(AUDIO_PATH, \'sample.wav\')\nsample2_file = pj(AUDIO_PATH, \'sample2.wav\')\nsample_file_22050 = pj(AUDIO_PATH, \'sample_22050.wav\')\nsample_beats = pj(ANNOTATIONS_PATH, \'sample.beats\')\nstereo_sample_file = pj(AUDIO_PATH, \'stereo_sample.wav\')\nprogram_path = os.path.dirname(os.path.realpath(__file__)) + \'/../bin/\'\n\n# prevent writing compiled Python files to disk\nsys.dont_write_bytecode = True\n\n\ndef run_program(program):\n    # import module, capture stdout\n    test = imp.load_source(\'test\', program[0])\n    sys.argv = program\n    backup = sys.stdout\n    sys.stdout = StringIO()\n    # run the program\n    data = test.main()\n    # close stdout, restore environment\n    sys.stdout.getvalue()\n    sys.stdout.close()\n    sys.stdout = backup\n    return data\n\n\ndef run_batch(program, infiles, outdir=None, args=None):\n    argv = [program]\n    if args:\n        argv.extend(args)\n    argv.extend([\'batch\', \'-j\', \'1\', \'--shuffle\'])\n    argv.extend(infiles)\n    if outdir:\n        argv.extend([\'-o\', outdir])\n    run_program(argv)\n\n\ndef run_single(program, infile, outfile, online=False, args=None):\n    argv = [program]\n    if args:\n        argv.extend(args)\n    argv.extend([\'single\', \'-j\', \'1\'])\n    if online:\n        argv.append(\'--online\')\n    argv.extend([infile, \'-o\', outfile])\n    run_program(argv)\n\n\ndef run_online(program, infile, outfile):\n    argv = [program, \'online\', \'-j\', \'1\', infile, \'-o\', outfile]\n    run_program(argv)\n\n\ndef run_save(program, infile, outfile, args=None):\n    argv = [program, \'--save\']\n    if args:\n        argv.extend(args)\n    argv.extend([\'single\', \'-j\', \'1\', infile, \'-o\', outfile])\n    run_program(argv)\n\n\ndef run_load(program, infile, outfile, online=False, args=None):\n    argv = [program, \'--load\']\n    if args:\n        argv.extend(args)\n    argv.extend([\'single\', \'-j\', \'1\'])\n    if online:\n        argv.append(\'--online\')\n    argv.extend([infile, \'-o\', outfile])\n    run_program(argv)\n\n\ndef run_help(program):\n    test = imp.load_source(\'test\', program)\n    sys.argv = [program, \'-h\']\n    try:\n        test.main()\n    except SystemExit:\n        return True\n    return False\n\n\n# TODO: parametrize tests, don\'t know how to do with nose, should be simple\n#       with pytest: http://pytest.org/latest/parametrize.html\n\n# TODO: can we speed up these tests?\n\nclass TestDifferentFileFormats(unittest.TestCase):\n\n    def setUp(self):\n        # use SuperFlux since it is fast\n        self.bin = pj(program_path, ""SuperFlux"")\n        self.result = [0.14, 1.57, 2.52, 3.365, 4.14]\n        self.result_file = pj(AUDIO_PATH, \'stereo_sample.onsets.txt\')\n\n    def test_single_wav(self):\n        run_single(self.bin, stereo_sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result))\n\n    def test_single_flac(self):\n        run_single(self.bin, stereo_sample_file[:-3] + \'flac\', tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result))\n\n    def test_single_m4a(self):\n        run_single(self.bin, stereo_sample_file[:-3] + \'m4a\', tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result))\n\n    def test_batch_wav(self):\n        run_batch(self.bin, [stereo_sample_file])\n        result = np.loadtxt(self.result_file)\n        os.unlink(self.result_file)\n        self.assertTrue(np.allclose(result, self.result))\n\n    def test_batch_flac(self):\n        run_batch(self.bin, [stereo_sample_file[:-3] + \'flac\'])\n        result = np.loadtxt(self.result_file)\n        os.unlink(self.result_file)\n        self.assertTrue(np.allclose(result, self.result))\n\n    def test_batch_m4a(self):\n        run_batch(self.bin, [stereo_sample_file[:-3] + \'m4a\'])\n        result = np.loadtxt(self.result_file)\n        os.unlink(self.result_file)\n        self.assertTrue(np.allclose(result, self.result))\n\n\nclass TestBarTrackerProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""BarTracker"")\n        self.act = np.load(pj(ACTIVATIONS_PATH, \'sample.bar_tracker.npz\'))\n        self.beats = [[0.091, 1], [0.8, 2], [1.481, 3], [2.148, 1]]\n        self.downbeats = [0.091, 2.148]\n\n    def test_run(self):\n        # with beat annotations\n        run_single(self.bin, sample_file, tmp_result,\n                   args=[\'--beats\', sample_beats])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.beats))\n        # check 22050 Hz sample rate\n        run_single(self.bin, sample_file_22050, tmp_result,\n                   args=[\'--beats\', sample_beats])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.beats))\n\n    # TODO: investigate why this fails on Windows\n    @unittest.skipIf(sys.platform.startswith(\'win\'), ""fails on Windows"")\n    def test_batch(self):\n        # run using beat detections in batch mode\n        run_batch(self.bin, [sample_file, sample_beats],\n                  args=[\'--beats_suffix\', \'.beats\'])\n        # detections got stored into the audio folder, thus remove that file\n        result_file = pj(AUDIO_PATH, \'sample.beats.txt\')\n        result = np.loadtxt(result_file)\n        os.unlink(result_file)\n        self.assertTrue(np.allclose(result, self.beats))\n\n    def test_output_downbeats(self):\n        run_single(self.bin, sample_file, tmp_result,\n                   args=[\'--down\', \'--beats\', sample_beats])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.downbeats))\n\n    def test_save_load_activations(self):\n        # save RNN bar activations\n        run_save(self.bin, sample_file, tmp_act,\n                 args=[\'--beats\', sample_beats])\n        act = np.load(tmp_act)[\'activations\']\n        self.assertTrue(np.allclose(act, self.act[\'activations\'], rtol=1e-3,\n                                    equal_nan=True))\n        # load RNN bar activations\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.beats))\n\n\nclass TestBeatDetectorProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""BeatDetector"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.beats_blstm.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.beat_detector.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n\nclass TestBeatTrackerProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""BeatTracker"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.beats_blstm.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.beat_tracker.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n\nclass TestCNNChordRecognition(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""CNNChordRecognition"")\n        self.activations = [\n            Activations(pj(ACTIVATIONS_PATH, af))\n            for af in [\'sample.cnn_chord_features.npz\',\n                       \'sample2.cnn_chord_features.npz\']\n        ]\n        self.results = [\n            load_chords(pj(DETECTIONS_PATH, df))\n            for df in [\'sample.cnn_chord_recognition.txt\',\n                       \'sample2.cnn_chord_recognition.txt\']\n        ]\n\n    def _check_results(self, result, true_result):\n        self.assertTrue(np.allclose(result[\'start\'], true_result[\'start\']))\n        self.assertTrue(np.allclose(result[\'end\'], true_result[\'end\']))\n        self.assertTrue((result[\'label\'] == true_result[\'label\']).all())\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        for sf, true_act, true_res in zip([sample_file, sample2_file],\n                                          self.activations, self.results):\n            # save activations as binary file\n            run_save(self.bin, sf, tmp_act)\n            act = Activations(tmp_act)\n            self.assertTrue(np.allclose(act, true_act, atol=1e-5))\n            self.assertEqual(act.fps, true_act.fps)\n            # reload from file\n            run_load(self.bin, tmp_act, tmp_result)\n            self._check_results(load_chords(tmp_result), true_res)\n\n    def test_txt(self):\n        for sf, true_act, true_res in zip([sample_file, sample2_file],\n                                          self.activations, self.results):\n            # save activations as txt file\n            run_save(self.bin, sf, tmp_act, args=[\'--sep\', \' \'])\n            act = Activations(tmp_act, sep=\' \', fps=100)\n            self.assertTrue(np.allclose(act, true_act, atol=1e-5))\n            # reload from file\n            run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n            self._check_results(load_chords(tmp_result), true_res)\n\n    def test_run(self):\n        for sf, true_res in zip([sample_file, sample2_file], self.results):\n            run_single(self.bin, sf, tmp_result)\n            self._check_results(load_chords(tmp_result), true_res)\n\n\nclass TestComplexFluxProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""ComplexFlux"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.complex_flux.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.complex_flux.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n\nclass TestCNNOnsetDetectorProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""CNNOnsetDetector"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.onsets_cnn.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.cnn_onset_detector.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result))\n\n\nclass TestCRFBeatDetectorProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""CRFBeatDetector"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.beats_blstm.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.crf_beat_detector.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n\nclass TestDBNBeatTrackerProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""DBNBeatTracker"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.beats_blstm.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.dbn_beat_tracker.txt""))\n        self.online_results = [0.47, 0.79, 1.48, 2.16, 2.5]\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_online(self):\n        run_online(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.online_results))\n        run_single(self.bin, sample_file, tmp_result, online=True)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.online_results))\n\n\nclass TestDBNDownBeatTrackerProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""DBNDownBeatTracker"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.downbeats_blstm.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.dbn_downbeat_tracker.txt""))\n        self.downbeat_result = self.result[self.result[:, 1] == 1][:, 0]\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run_downbeats(self):\n        run_single(self.bin, sample_file, tmp_result, args=[\'--downbeats\'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.downbeat_result, atol=1e-5))\n\n\nclass TestDCChordRecognition(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""DCChordRecognition"")\n        self.activations = [\n            Activations(pj(ACTIVATIONS_PATH, af))\n            for af in [\'sample.deep_chroma.npz\', \'sample2.deep_chroma.npz\']\n        ]\n        self.results = [\n            load_chords(pj(DETECTIONS_PATH, df))\n            for df in [\'sample.dc_chord_recognition.txt\',\n                       \'sample2.dc_chord_recognition.txt\']\n        ]\n\n    def _check_results(self, result, true_result):\n        self.assertTrue(np.allclose(result[\'start\'], true_result[\'start\']))\n        self.assertTrue(np.allclose(result[\'end\'], true_result[\'end\']))\n        self.assertTrue((result[\'label\'] == true_result[\'label\']).all())\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        for sf, true_act, true_res in zip([sample_file, sample2_file],\n                                          self.activations, self.results):\n            # save activations as binary file\n            run_save(self.bin, sf, tmp_act)\n            act = Activations(tmp_act)\n            self.assertTrue(np.allclose(act, true_act, atol=1e-5))\n            self.assertEqual(act.fps, true_act.fps)\n            # reload from file\n            run_load(self.bin, tmp_act, tmp_result)\n            self._check_results(load_chords(tmp_result), true_res)\n\n    def test_txt(self):\n        for sf, true_act, true_res in zip([sample_file, sample2_file],\n                                          self.activations, self.results):\n            # save activations as txt file\n            run_save(self.bin, sf, tmp_act, args=[\'--sep\', \' \'])\n            act = Activations(tmp_act, sep=\' \', fps=100)\n            self.assertTrue(np.allclose(act, true_act, atol=1e-5))\n            # reload from file\n            run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n            self._check_results(load_chords(tmp_result), true_res)\n\n    def test_run(self):\n        for sf, true_res in zip([sample_file, sample2_file], self.results):\n            run_single(self.bin, sf, tmp_result)\n            self._check_results(load_chords(tmp_result), true_res)\n\n\nclass TestKeyRecognitionProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, \'KeyRecognition\')\n        self.activations = [\n            Activations(pj(ACTIVATIONS_PATH, af))\n            for af in [\'sample.key_cnn.npz\', \'sample2.key_cnn.npz\']\n        ]\n        self.results = [\n            load_key(pj(DETECTIONS_PATH, df))\n            for df in [\'sample.key_recognition.txt\',\n                       \'sample2.key_recognition.txt\']\n        ]\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        for sf, true_act, true_res in zip([sample_file, sample2_file],\n                                          self.activations, self.results):\n            # save activations as binary file\n            run_save(self.bin, sf, tmp_act)\n            act = Activations(tmp_act)\n            self.assertTrue(np.allclose(act, true_act, atol=1e-5))\n            self.assertEqual(act.fps, true_act.fps)\n            # reload from file\n            run_load(self.bin, tmp_act, tmp_result)\n            self.assertEqual(load_key(tmp_result), true_res)\n\n    def test_txt(self):\n        for sf, true_act, true_res in zip([sample_file, sample2_file],\n                                          self.activations, self.results):\n            # save activations as txt file\n            run_save(self.bin, sf, tmp_act, args=[\'--sep\', \' \'])\n            act = Activations(tmp_act, sep=\' \', fps=0)\n            self.assertTrue(np.allclose(act, true_act, atol=1e-5))\n            # reload from file\n            run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n            self.assertEqual(load_key(tmp_result), true_res)\n\n    def test_run(self):\n        for sf, true_res in zip([sample_file, sample2_file], self.results):\n            run_single(self.bin, sf, tmp_result)\n            self.assertEqual(load_key(tmp_result), true_res)\n\n\nclass TestGMMPatternTrackerProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""GMMPatternTracker"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.gmm_pattern_tracker.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.gmm_pattern_tracker.txt""))\n        self.downbeat_result = self.result[self.result[:, 1] == 1][:, 0]\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=50)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run_downbeats(self):\n        run_single(self.bin, sample_file, tmp_result, args=[\'--downbeats\'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.downbeat_result, atol=1e-5))\n\n\nclass TestLogFiltSpecFluxProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""LogFiltSpecFlux"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.log_filt_spec_flux.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.log_filt_spec_flux.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n\nclass TestMMBeatTrackerProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""MMBeatTracker"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.beats_blstm_mm.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.mm_beat_tracker.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n\nclass TestOnsetDetectorProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""OnsetDetector"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.onsets_brnn.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.onset_detector.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n\nclass TestOnsetDetectorLLProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""OnsetDetectorLL"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.onsets_rnn.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.onset_detector_ll.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, online=True)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_online(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result))\n        run_single(self.bin, sample_file, tmp_result, online=True)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result))\n        run_online(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result))\n\n\nclass TestPianoTranscriptorProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""PianoTranscriptor"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""stereo_sample.notes_cnn.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""stereo_sample.piano_transcriptor.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, stereo_sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, stereo_sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_midi(self):\n        run_single(self.bin, stereo_sample_file, tmp_result, args=[\'--midi\'])\n        result = midi.MIDIFile(tmp_result).notes\n        self.assertTrue(np.allclose(result[:, :3], self.result, atol=1e-3))\n\n    def test_mirex(self):\n        run_single(self.bin, stereo_sample_file, tmp_result, args=[\'--mirex\'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result[:, 0], self.result[:, 0]))\n        self.assertTrue(np.allclose(\n            result[:, 1], [1.56, 3.38, 3.5, 3.48, 3.36, 3.4, 4.16, 4.16]))\n        self.assertTrue(np.allclose(\n            result[:, 2], [523.25, 87.31, 698.46, 349.23, 261.63, 207.65,\n                           622.25, 98]))\n\n\nclass TestSpectralOnsetDetectionProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""SpectralOnsetDetection"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.spectral_flux.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.spectral_flux.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n\nclass TestSuperFluxProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""SuperFlux"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.super_flux.npz""))\n        self.result = np.loadtxt(pj(DETECTIONS_PATH, ""sample.super_flux.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=200)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    # TODO: investigate why this fails on Windows\n    @unittest.skipIf(sys.platform.startswith(\'win\'), ""fails on Windows"")\n    def test_batch(self):\n        # test in batch mode with a given output directory\n        run_batch(self.bin, [sample_file, sample_beats, sample2_file],\n                  outdir=tmp_dir)\n        result = search_files(tmp_dir)\n        # result should contain 2 results for the given audio files\n        self.assertEqual(len(result), 2)\n\n\nclass TestSuperFluxNNProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""SuperFluxNN"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.super_flux_nn.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.super_flux_nn.txt""))\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n\nclass TestTempoDetectorProgram(unittest.TestCase):\n\n    def setUp(self):\n        self.bin = pj(program_path, ""TempoDetector"")\n        self.activations = Activations(\n            pj(ACTIVATIONS_PATH, ""sample.beats_blstm.npz""))\n        self.result = np.loadtxt(\n            pj(DETECTIONS_PATH, ""sample.tempo_detector.txt""))\n        self.online_results = np.array([176.47, 88.24, 0.58])\n\n    def test_help(self):\n        self.assertTrue(run_help(self.bin))\n\n    def test_binary(self):\n        # save activations as binary file\n        run_save(self.bin, sample_file, tmp_act)\n        act = Activations(tmp_act)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        self.assertEqual(act.fps, self.activations.fps)\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_txt(self):\n        # save activations as txt file\n        run_save(self.bin, sample_file, tmp_act, args=[\'--sep\', \' \'])\n        act = Activations(tmp_act, sep=\' \', fps=100)\n        self.assertTrue(np.allclose(act, self.activations, atol=1e-5))\n        # reload from file\n        run_load(self.bin, tmp_act, tmp_result, args=[\'--sep\', \' \'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_run(self):\n        run_single(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.result, atol=1e-5))\n\n    def test_online(self):\n        run_online(self.bin, sample_file, tmp_result)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result[-1], self.online_results))\n        run_single(self.bin, sample_file, tmp_result, online=True)\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, self.online_results))\n\n    def test_mirex(self):\n        run_single(self.bin, sample_file, tmp_result, args=[\'--mirex\'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(result, [117.65, 176.47, 0.27]))\n\n    def test_all_tempi(self):\n        run_single(self.bin, sample_file, tmp_result, args=[\'--all\'])\n        result = np.loadtxt(tmp_result)\n        self.assertTrue(np.allclose(\n            result, [[176.47, 0.475], [117.65, 0.177], [240.00, 0.154],\n                     [68.97, 0.099], [82.19, 0.096]]))\n\n\n# clean up\ndef teardown_module():\n    os.unlink(tmp_act)\n    os.unlink(tmp_result)\n    shutil.rmtree(tmp_dir)\n'"
tests/test_bin_evaluate.py,20,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the /bin/evaluate script.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport imp\nimport os\nimport sys\nimport unittest\n\ntry:\n    from cStringIO import StringIO\nexcept ImportError:\n    from io import StringIO\n\nimport numpy as np\n\nfrom . import ANNOTATIONS_PATH, DETECTIONS_PATH\n\neval_script = os.path.dirname(os.path.realpath(__file__)) + \'/../bin/evaluate\'\n\n# prevent writing compiled Python files to disk\nsys.dont_write_bytecode = True\n\n\ndef run_script(task, det_suffix=None, args=None):\n    # import module, capture stdout\n    test = imp.load_source(\'test\', eval_script)\n    sys.argv = [eval_script, task, \'--csv\', DETECTIONS_PATH, ANNOTATIONS_PATH]\n    if det_suffix:\n        sys.argv.extend([\'-d\', det_suffix])\n    if args:\n        sys.argv.extend(args)\n    backup = sys.stdout\n    sys.stdout = StringIO()\n    # run evaluation script\n    test.main()\n    # get data from stdout, restore environment\n    data = sys.stdout.getvalue()\n    sys.stdout.close()\n    sys.stdout = backup\n    return data.splitlines()\n\n\nclass TestEvaluateScript(unittest.TestCase):\n\n    def test_onsets(self):\n        res = run_script(\'onsets\', det_suffix=\'.super_flux.txt\')\n        # second line contains the summed results\n        sum_res = np.fromiter(res[1].split(\',\')[1:], dtype=np.float)\n        self.assertTrue(np.allclose(\n            sum_res, [14, 2, 0, 1, 15, 0.875, 0.933, 0.903, 0.824]))\n        # third line contains the mean results\n        mean_res = np.fromiter(res[2].split(\',\')[1:], dtype=np.float)\n        self.assertTrue(np.allclose(mean_res, sum_res))\n\n    def test_beats(self):\n        res = run_script(\'beats\', det_suffix=\'.beat_detector.txt\')\n        # second line contains the results\n        res = np.fromiter(res[1].split(\',\')[1:], dtype=np.float)\n        self.assertTrue(np.allclose(res, [0.667, 0.5, 0.639, 1, 0, 0,\n                                          0.875, 0.875, 3.322, 3.322]))\n\n    def test_downbeats(self):\n        res = run_script(\'beats\', det_suffix=\'.dbn_downbeat_tracker.txt\',\n                         args=[\'--down\'])\n        # second line contains the results\n        res = np.fromiter(res[1].split(\',\')[1:], dtype=np.float)\n        self.assertTrue(np.allclose(res, [0.667, 0.5, 0.653, 1, 0, 0,\n                                          0.875, 0.875, 3.072, 3.072]))\n\n    def test_chords(self):\n        res = run_script(\'chords\')\n        # second line contains the weighted mean results\n        weighted = np.fromiter(res[1].split(\',\')[1:], dtype=np.float)\n        self.assertTrue(np.allclose(weighted, [0.897, 0.641, 0.462, 0.462,\n                                               0.282, 0.590, 0.590, 0.923]))\n        # third line contains the piecewise mean results\n        piecewise = np.fromiter(res[2].split(\',\')[1:], dtype=np.float)\n        self.assertTrue(np.allclose(weighted, piecewise))\n\n    def test_key(self):\n        res = run_script(\'key\')\n        # second line contains the results\n        res = np.fromiter(res[1].split(\',\')[1:], dtype=np.float)\n        self.assertTrue(np.allclose(res, [0, 0, 1, 0, 0, 0.3]))\n\n    def test_notes(self):\n        res = run_script(\'notes\', det_suffix=\'.piano_transcriptor.txt\',\n                         args=[\'-w\', \'0.05\'])\n        # second line contains the summed results\n        sum_res = np.fromiter(res[1].split(\',\')[1:], dtype=np.float)\n        self.assertTrue(\n            np.allclose(sum_res, [8, 0, 0, 0, 8, 1, 1, 1, 1]))\n        # third line contains the mean results\n        mean_res = np.fromiter(res[2].split(\',\')[1:], dtype=np.float)\n        self.assertTrue(np.allclose(mean_res, sum_res))\n\n    def test_tempo(self):\n        res = run_script(\'tempo\', det_suffix=\'.tempo_detector.txt\',\n                         args=[\'-a\', \'.tempo\'])\n        # second line contains the results\n        res = np.fromiter(res[1].split(\',\')[1:], dtype=np.float)\n        self.assertTrue(\n            np.allclose(res, [0.3, 1, 0, 0, 1]))\n'"
tests/test_evaluation.py,58,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.evaluation module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nimport math\nfrom collections import OrderedDict\n\nfrom madmom.evaluation import *\n\n\nDETECTIONS = np.asarray([0.99, 1.45, 2.01, 2.015, 3.1, 8.1])\nANNOTATIONS = np.asarray([1, 1.5, 2.0, 2.03, 2.05, 2.5, 3])\nMATCHES = np.asarray([0, 1, 2, 3, 6, 6])\n\n\n# test functions\nclass TestFindClosestMatchesFunction(unittest.TestCase):\n\n    def test_types(self):\n        matches = find_closest_matches([], [])\n        self.assertIsInstance(matches, np.ndarray)\n        self.assertEqual(matches.dtype, np.int)\n        self.assertIsInstance(find_closest_matches([], []), np.ndarray)\n\n    def test_value(self):\n        # empty sequences\n        matches = find_closest_matches([], [])\n        self.assertTrue(np.allclose(matches, []))\n        # detections relative to annotations\n        matches = find_closest_matches(DETECTIONS, ANNOTATIONS)\n        self.assertTrue(np.allclose(matches, MATCHES))\n        # annotations relative to detections\n        matches = find_closest_matches(ANNOTATIONS, DETECTIONS)\n        correct = np.asarray([0, 1, 2, 3, 3, 3, 4])\n        self.assertTrue(np.allclose(matches, correct))\n\n\nclass TestCalcErrorsFunction(unittest.TestCase):\n\n    def test_types(self):\n        errors = calc_errors(DETECTIONS, ANNOTATIONS)\n        self.assertIsInstance(errors, np.ndarray)\n        self.assertEqual(errors.dtype, np.float)\n\n    def test_values(self):\n        # empty sequences\n        matches = calc_errors([], [])\n        self.assertTrue(np.allclose(matches, []))\n        # detections relative to annotations\n        errors = calc_errors(DETECTIONS, ANNOTATIONS)\n        correct = np.asarray([-0.01, -0.05, 0.01, -0.015, 0.1, 5.1])\n        self.assertTrue(np.allclose(errors, correct))\n        # same but with matches given\n        errors = calc_errors(DETECTIONS, ANNOTATIONS, MATCHES)\n        self.assertTrue(np.allclose(errors, correct))\n        # annotations relative to detections\n        errors = calc_errors(ANNOTATIONS, DETECTIONS)\n        correct = np.asarray([0.01, 0.05, -0.01, 0.015, 0.035, 0.485, -0.1])\n        self.assertTrue(np.allclose(errors, correct))\n\n\nclass TestCalcAbsoluteErrorsFunction(unittest.TestCase):\n\n    def test_types(self):\n        errors = calc_absolute_errors(DETECTIONS, ANNOTATIONS)\n        self.assertIsInstance(errors, np.ndarray)\n        self.assertEqual(errors.dtype, np.float)\n\n    def test_values(self):\n        # empty sequences\n        errors = calc_absolute_errors([], [])\n        self.assertTrue(np.allclose(errors, []))\n        # detections relative to annotations\n        errors = calc_absolute_errors(DETECTIONS, ANNOTATIONS)\n        correct = np.asarray([0.01, 0.05, 0.01, 0.015, 0.1, 5.1])\n        self.assertTrue(np.allclose(errors, correct))\n        # same but with matches given\n        errors = calc_absolute_errors(DETECTIONS, ANNOTATIONS, MATCHES)\n        self.assertTrue(np.allclose(errors, correct))\n        # annotations relative to detections\n        errors = calc_absolute_errors(ANNOTATIONS, DETECTIONS)\n        correct = np.asarray([0.01, 0.05, 0.01, 0.015, 0.035, 0.485, 0.1])\n        self.assertTrue(np.allclose(errors, correct))\n\n\nclass TestCalcRelativeErrorsFunction(unittest.TestCase):\n\n    def test_types(self):\n        errors = calc_relative_errors(DETECTIONS, ANNOTATIONS)\n        self.assertIsInstance(errors, np.ndarray)\n\n    def test_values(self):\n        # empty sequences\n        errors = calc_relative_errors([], [])\n        self.assertTrue(np.allclose(errors, []))\n        # detections relative to annotations\n        errors = calc_relative_errors(DETECTIONS, ANNOTATIONS)\n        # np.abs(1 - (errors / annotations[matches]))\n        # det: [0.99, 1.45, 2.01, 2.015,            3.1,  8.1])\n        # tar: [1,    1.5,  2.0,  2.03,  2.05, 2.5, 3])\n        correct = np.abs(np.asarray([1 + 0.01 / 1, 1 + 0.05 / 1.5,\n                                     1 - 0.01 / 2, 1 + 0.015 / 2.03,\n                                     1 - 0.1 / 3, 1 - 5.1 / 3]))\n        self.assertTrue(np.allclose(errors, correct))\n        # same but with matches given\n        errors = calc_relative_errors(DETECTIONS, ANNOTATIONS, MATCHES)\n        self.assertTrue(np.allclose(errors, correct))\n        # annotations relative to detections\n        errors = calc_relative_errors(ANNOTATIONS, DETECTIONS)\n        correct = np.abs(np.asarray([1 - 0.01 / 0.99, 1 - 0.05 / 1.45,\n                                     1 + 0.01 / 2.01, 1 - 0.015 / 2.015,\n                                     1 - 0.035 / 2.015, 1 - 0.485 / 2.015,\n                                     1 + 0.1 / 3.1]))\n        self.assertTrue(np.allclose(errors, correct))\n\n\n# test classes\nclass TestSimpleEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = SimpleEvaluation()\n        self.assertIsNone(e.name)\n        self.assertIsInstance(e.num_tp, int)\n        self.assertIsInstance(e.num_fp, int)\n        self.assertIsInstance(e.num_tn, int)\n        self.assertIsInstance(e.num_fn, int)\n        self.assertIsInstance(e.num_annotations, int)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.accuracy, float)\n        self.assertIsInstance(len(e), int)\n        self.assertIsInstance(e.metrics, dict)\n\n    def test_conversion(self):\n        # conversion from float should work\n        e = SimpleEvaluation(float(0), float(0), float(0), float(0))\n        self.assertIsInstance(e.num_tp, int)\n        self.assertIsInstance(e.num_fp, int)\n        self.assertIsInstance(e.num_tn, int)\n        self.assertIsInstance(e.num_fn, int)\n        # conversion from list or dict should fail\n        self.assertRaises(TypeError, SimpleEvaluation, [0], [0], [0], [0])\n        self.assertRaises(TypeError, SimpleEvaluation, {}, {}, {}, {})\n\n    def test_results(self):\n        # empty evaluation object\n        e = SimpleEvaluation()\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.num_annotations, 0)\n        self.assertEqual(len(e), 0)\n        # all correct (none) retrieved\n        self.assertEqual(e.precision, 1)\n        # all retrieved (none) are correct\n        self.assertEqual(e.recall, 1)\n        # 2 * P * R / (P + R)\n        self.assertEqual(e.fmeasure, 1)\n        # (TP + TN) / (TP + FP + TN + FN)\n        self.assertEqual(e.accuracy, 1)\n        # metric dictionary\n        self.assertEqual(list(e.metrics.keys()),\n                         [\'num_tp\', \'num_fp\', \'num_tn\', \'num_fn\',\n                          \'num_annotations\', \'precision\', \'recall\',\n                          \'fmeasure\', \'accuracy\'])\n        correct = OrderedDict([(\'num_tp\', 0), (\'num_fp\', 0), (\'num_tn\', 0),\n                               (\'num_fn\', 0), (\'num_annotations\', 0),\n                               (\'precision\', 1.0), (\'recall\', 1.0),\n                               (\'fmeasure\', 1.0), (\'accuracy\', 1.0)])\n        self.assertEqual(e.metrics, correct)\n\n        # test with other values\n        e = SimpleEvaluation(num_tp=5, num_fp=3, num_tn=4, num_fn=1)\n        self.assertEqual(e.num_tp, 5)\n        self.assertEqual(e.num_fp, 3)\n        self.assertEqual(e.num_tn, 4)\n        self.assertEqual(e.num_fn, 1)\n        self.assertEqual(e.num_annotations, 6)\n        self.assertEqual(len(e), 6)\n        # correct / retrieved\n        self.assertEqual(e.precision, 5. / 8.)\n        # correct / relevant\n        self.assertEqual(e.recall, 5. / 6.)\n        # 2 * P * R / (P + R)\n        f = 2 * (5. / 8.) * (5. / 6.) / ((5. / 8.) + (5. / 6.))\n        self.assertEqual(e.fmeasure, f)\n        # (TP + TN) / (TP + FP + TN + FN)\n        self.assertEqual(e.accuracy, (5. + 4) / (5 + 3 + 4 + 1))\n\n        # test with no true positives/negatives\n        e = SimpleEvaluation(num_tp=0, num_fp=3, num_tn=0, num_fn=1)\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 3)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 1)\n        self.assertEqual(e.num_annotations, 1)\n        self.assertEqual(len(e), 1)\n        self.assertEqual(e.precision, 0)\n        self.assertEqual(e.recall, 0)\n        self.assertEqual(e.fmeasure, 0)\n        self.assertEqual(e.accuracy, 0)\n\n\nclass TestEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = Evaluation()\n        self.assertIsNone(e.name)\n        self.assertIsInstance(e.num_tp, int)\n        self.assertIsInstance(e.num_fp, int)\n        self.assertIsInstance(e.num_tn, int)\n        self.assertIsInstance(e.num_fn, int)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.tp, np.ndarray)\n        self.assertIsInstance(e.fp, np.ndarray)\n        self.assertIsInstance(e.tn, np.ndarray)\n        self.assertIsInstance(e.fn, np.ndarray)\n        self.assertIsInstance(len(e), int)\n        self.assertIsInstance(e.metrics, dict)\n\n    def test_conversion(self):\n        # # conversion from dict should fail\n        # with self.assertRaises(TypeError):\n        #     Evaluation(tp={}, fp={}, tn={}, fn={})\n        # conversion from int or float should fail\n        with self.assertRaises(TypeError):\n            Evaluation(tp=int(0), fp=int(0), tn=int(0), fn=int(0))\n        with self.assertRaises(TypeError):\n            Evaluation(tp=float(0), fp=float(0), tn=float(0), fn=float(0))\n        e = Evaluation(tp={}, fp={}, tn={}, fn={})\n        self.assertIsInstance(e.tp, np.ndarray)\n        self.assertIsInstance(e.fp, np.ndarray)\n        self.assertIsInstance(e.tn, np.ndarray)\n        self.assertIsInstance(e.fn, np.ndarray)\n\n    def test_results(self):\n        # empty evaluation object\n        e = Evaluation()\n        self.assertTrue(np.allclose(e.tp, np.empty(0)))\n        self.assertTrue(np.allclose(e.fp, np.empty(0)))\n        self.assertTrue(np.allclose(e.tn, np.empty(0)))\n        self.assertTrue(np.allclose(e.fn, np.empty(0)))\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        # p: all correct (none) retrieved\n        self.assertEqual(e.precision, 1)\n        # r: all retrieved (none) are correct\n        self.assertEqual(e.recall, 1)\n        # f: 2 * P * R / (P + R)\n        self.assertEqual(e.fmeasure, 1)\n        # acc: (TP + TN) / (TP + FP + TN + FN)\n        self.assertEqual(e.accuracy, 1)\n        # test metric dictionary keys\n        self.assertEqual(list(e.metrics.keys()),\n                         [\'num_tp\', \'num_fp\', \'num_tn\', \'num_fn\',\n                          \'num_annotations\', \'precision\', \'recall\',\n                          \'fmeasure\', \'accuracy\'])\n        # test with other values\n        e = Evaluation(tp=[1, 2, 3.0], fp=[1.5], fn=[0, 3.1])\n        tp = np.asarray([1, 2, 3], dtype=np.float)\n        self.assertTrue(np.allclose(e.tp, tp))\n        fp = np.asarray([1.5], dtype=np.float)\n        self.assertTrue(np.allclose(e.fp, fp))\n        tn = np.asarray([], dtype=np.float)\n        self.assertTrue(np.allclose(e.tn, tn))\n        fn = np.asarray([0, 3.1], dtype=np.float)\n        self.assertTrue(np.allclose(e.fn, fn))\n        self.assertEqual(e.num_tp, 3)\n        self.assertEqual(e.num_fp, 1)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 2)\n        # p: correct / retrieved\n        self.assertEqual(e.precision, 3. / 4.)\n        # r: correct / relevant\n        self.assertEqual(e.recall, 3. / 5.)\n        # f: 2 * P * R / (P + R)\n        f = 2 * (3. / 4.) * (3. / 5.) / ((3. / 4.) + (3. / 5.))\n        self.assertEqual(e.fmeasure, f)\n        # acc: (TP + TN) / (TP + FP + TN + FN)\n        self.assertEqual(e.accuracy, 3. / (3 + 1 + 2))\n\n\nclass TestMultiClassEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = MultiClassEvaluation()\n        self.assertIsNone(e.name)\n        self.assertIsInstance(e.num_tp, int)\n        self.assertIsInstance(e.num_fp, int)\n        self.assertIsInstance(e.num_tn, int)\n        self.assertIsInstance(e.num_fn, int)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.tp, np.ndarray)\n        self.assertIsInstance(e.fp, np.ndarray)\n        self.assertIsInstance(e.tn, np.ndarray)\n        self.assertIsInstance(e.fn, np.ndarray)\n        self.assertEqual(e.tp.shape, (0, 2))\n        self.assertEqual(e.fp.shape, (0, 2))\n        self.assertEqual(e.tn.shape, (0, 2))\n        self.assertEqual(e.fn.shape, (0, 2))\n        self.assertIsInstance(len(e), int)\n        self.assertIsInstance(e.metrics, dict)\n\n\nclass TestSumEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = SumEvaluation([])\n        self.assertIsInstance(e.eval_objects, list)\n        self.assertIsInstance(e.name, str)\n        self.assertIsInstance(e.num_tp, int)\n        self.assertIsInstance(e.num_fp, int)\n        self.assertIsInstance(e.num_tn, int)\n        self.assertIsInstance(e.num_fn, int)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.accuracy, float)\n        self.assertIsInstance(len(e), int)\n        self.assertIsInstance(e.metrics, dict)\n\n    def test_results(self):\n        # empty evaluation\n        e = SumEvaluation([])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertEqual(len(e), 0)\n        # empty SimpleEvaluation\n        e = SumEvaluation([SimpleEvaluation()])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertEqual(len(e), 1)\n        # empty SimpleEvaluation without the list\n        e = SumEvaluation(SimpleEvaluation())\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertEqual(len(e), 1)\n        # empty and real SimpleEvaluation\n        e1 = SimpleEvaluation()\n        e2 = SimpleEvaluation(num_tp=5, num_fp=3, num_tn=4, num_fn=1)\n        e = SumEvaluation([e1, e2])\n        self.assertEqual(e.num_tp, 5)\n        self.assertEqual(e.num_fp, 3)\n        self.assertEqual(e.num_tn, 4)\n        self.assertEqual(e.num_fn, 1)\n        self.assertEqual(e.precision, 5. / 8.)\n        self.assertEqual(e.recall, 5. / 6.)\n        f = 2 * (5. / 8.) * (5. / 6.) / ((5. / 8.) + (5. / 6.))\n        self.assertEqual(e.fmeasure, f)\n        self.assertEqual(e.accuracy, (5. + 4) / (5 + 3 + 4 + 1))\n        self.assertEqual(len(e), 2)\n\n\nclass TestMeanEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = MeanEvaluation([])\n        self.assertIsInstance(e.eval_objects, list)\n        self.assertIsInstance(e.name, str)\n        self.assertIsInstance(e.num_tp, float)\n        self.assertIsInstance(e.num_fp, float)\n        self.assertIsInstance(e.num_tn, float)\n        self.assertIsInstance(e.num_fn, float)\n        self.assertIsInstance(e.num_annotations, float)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.accuracy, float)\n        self.assertIsInstance(len(e), int)\n        self.assertIsInstance(e.metrics, dict)\n\n    def test_results(self):\n        # empty MeanEvaluation\n        e = MeanEvaluation([])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.num_annotations, 0)\n        self.assertTrue(math.isnan(e.precision))\n        self.assertTrue(math.isnan(e.recall))\n        self.assertTrue(math.isnan(e.fmeasure))\n        self.assertTrue(math.isnan(e.accuracy))\n        self.assertEqual(len(e), 0)\n        # empty SimpleEvaluation\n        e = MeanEvaluation([SimpleEvaluation()])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.num_annotations, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertEqual(len(e), 1)\n        # empty SimpleEvaluation without the list\n        e = MeanEvaluation(SimpleEvaluation())\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.num_annotations, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertEqual(len(e), 1)\n        # empty and real SimpleEvaluation\n        e1 = SimpleEvaluation()\n        e2 = SimpleEvaluation(num_tp=5, num_fp=3, num_tn=4, num_fn=1)\n        e = MeanEvaluation([e1, e2])\n        self.assertEqual(e.num_tp, 5 / 2.)\n        self.assertEqual(e.num_fp, 3 / 2.)\n        self.assertEqual(e.num_tn, 4 / 2.)\n        self.assertEqual(e.num_fn, 1 / 2.)\n        self.assertEqual(e.num_annotations, 6 / 2.)\n        self.assertEqual(e.precision, (1 + 5. / 8.) / 2.)\n        self.assertEqual(e.recall, (1 + 5. / 6.) / 2.)\n        f = (1 + 2 * (5. / 8.) * (5. / 6.) / ((5. / 8.) + (5. / 6.))) / 2.\n        self.assertEqual(e.fmeasure, f)\n        self.assertEqual(e.accuracy, (1 + (5. + 4) / (5 + 3 + 4 + 1)) / 2.)\n        self.assertEqual(len(e), 2)\n'"
tests/test_evaluation_beats.py,122,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.evaluation.beats module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport math\nimport unittest\n\nfrom madmom.evaluation.beats import *\nfrom madmom.evaluation.beats import (_entropy, _error_histogram,\n                                     _histogram_bins, _information_gain, )\nfrom . import ANNOTATIONS_PATH, DETECTIONS_PATH\n\nANNOTATIONS = np.asarray([1., 2, 3, 4, 5, 6, 7, 8, 9, 10])\nOFFBEAT_ANNOTATIONS = np.asarray([1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5])\nDOUBLE_ANNOTATIONS = np.asarray([1., 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6,\n                                 6.5, 7, 7.5, 8, 8.5, 9, 9.5, 10])\nTRIPLE_ANNOTATIONS = np.asarray([1, 1.333333, 1.666667, 2, 2.333333, 2.666667,\n                                 3, 3.333333, 3.666667, 4, 4.333333, 4.666667,\n                                 5, 5.333333, 5.666667, 6, 6.333333, 6.666667,\n                                 7, 7.333333, 7.666667, 8, 8.333333, 8.666667,\n                                 9, 9.333333, 9.666667, 10])\nDETECTIONS = np.asarray([1.01, 2, 2.95, 4, 6, 7, 8, 9.1, 10, 11])\nSAMPLE_BEAT_ANNOTATIONS = np.asarray([0.0913, 0.7997, 1.4806, 2.1478])\n\n\n# test functions\nclass TestVariationsFunction(unittest.TestCase):\n\n    def test_types(self):\n        sequences = variations(ANNOTATIONS)\n        self.assertIsInstance(sequences, list)\n\n    def test_values(self):\n        # no variations\n        sequences = variations(ANNOTATIONS)\n        self.assertTrue(len(sequences) == 0)\n        self.assertEqual(sequences, [])\n        # offbeat\n        self.assertTrue(len(sequences) == 0)\n        sequences = variations(ANNOTATIONS, offbeat=True)\n        self.assertTrue(len(sequences) == 1)\n        self.assertTrue(np.allclose(sequences[0], OFFBEAT_ANNOTATIONS))\n        # double\n        sequences = variations(ANNOTATIONS, double=True)\n        self.assertTrue(len(sequences) == 1)\n        self.assertTrue(np.allclose(sequences[0], DOUBLE_ANNOTATIONS))\n        # half tempo (includes starting with 1st or 2nd beat)\n        sequences = variations(ANNOTATIONS, half=True)\n        self.assertTrue(len(sequences) == 2)\n        self.assertTrue(np.allclose(sequences[0], ANNOTATIONS[0::2]))\n        self.assertTrue(np.allclose(sequences[1], ANNOTATIONS[1::2]))\n        # triple\n        sequences = variations(ANNOTATIONS, triple=True)\n        self.assertTrue(len(sequences) == 1)\n        self.assertTrue(np.allclose(sequences[0], TRIPLE_ANNOTATIONS))\n        # third (includes starting with 1st, 2nd or 3rd beat)\n        sequences = variations(ANNOTATIONS, third=True)\n        self.assertTrue(len(sequences) == 3)\n        self.assertTrue(np.allclose(sequences[0], ANNOTATIONS[0::3]))\n        self.assertTrue(np.allclose(sequences[1], ANNOTATIONS[1::3]))\n        self.assertTrue(np.allclose(sequences[2], ANNOTATIONS[2::3]))\n\n    def test_empty_sequence(self):\n        # no variations\n        sequences = variations([])\n        self.assertTrue(len(sequences) == 0)\n        self.assertEqual(sequences, [])\n        # offbeat\n        self.assertTrue(len(sequences) == 0)\n        sequences = variations([], offbeat=True)\n        self.assertTrue(len(sequences) == 1)\n        self.assertTrue(np.allclose(sequences, [[]]))\n        # double\n        sequences = variations([], double=True)\n        self.assertTrue(len(sequences) == 1)\n        self.assertTrue(np.allclose(sequences, [[]]))\n        # half tempo (includes starting with 1st or 2nd beat)\n        sequences = variations([], half=True)\n        self.assertTrue(len(sequences) == 2)\n        self.assertTrue(np.allclose(sequences, [[], []]))\n        # triple\n        sequences = variations([], triple=True)\n        self.assertTrue(len(sequences) == 1)\n        self.assertTrue(np.allclose(sequences, [[], [], []]))\n        # third (includes starting with 1st, 2nd or 3rd beat)\n        sequences = variations([], third=True)\n        self.assertTrue(np.allclose(sequences, [[], [], []]))\n\n\nclass TestCalcIntervalFunction(unittest.TestCase):\n\n    def test_types(self):\n        intervals = calc_intervals(ANNOTATIONS)\n        self.assertIsInstance(intervals, np.ndarray)\n        # events must be correct type\n        intervals = calc_intervals([1, 2])\n        self.assertIsInstance(intervals, np.ndarray)\n\n    def test_errors(self):\n        # empty or length 1 sequences should raise an error\n        with self.assertRaises(BeatIntervalError):\n            calc_intervals([])\n        with self.assertRaises(BeatIntervalError):\n            calc_intervals([1])\n\n    def test_values(self):\n        # test annotations backwards\n        intervals = calc_intervals(ANNOTATIONS)\n        correct = np.asarray([1., 1, 1, 1, 1, 1, 1, 1, 1, 1])\n        self.assertTrue(np.allclose(intervals, correct))\n        # test detections backwards\n        intervals = calc_intervals(DETECTIONS)\n        correct = [0.99, 0.99, 0.95, 1.05, 2, 1, 1, 1.1, 0.9, 1]\n        self.assertTrue(np.allclose(intervals, correct))\n        # test annotations forwards\n        intervals = calc_intervals(ANNOTATIONS, fwd=True)\n        correct = np.asarray([1., 1, 1, 1, 1, 1, 1, 1, 1, 1])\n        self.assertTrue(np.allclose(intervals, correct))\n        # test detections forwards\n        intervals = calc_intervals(DETECTIONS, fwd=True)\n        correct = [0.99, 0.95, 1.05, 2, 1, 1, 1.1, 0.9, 1, 1]\n        self.assertTrue(np.allclose(intervals, correct))\n        # TODO: same tests with matches given\n\n\nclass TestFindClosestIntervalFunction(unittest.TestCase):\n\n    def test_types(self):\n        intervals = find_closest_intervals(DETECTIONS, ANNOTATIONS)\n        self.assertIsInstance(intervals, np.ndarray)\n        # events must be correct type\n        with self.assertRaises(TypeError):\n            find_closest_intervals(None, ANNOTATIONS)\n        with self.assertRaises(TypeError):\n            find_closest_intervals(DETECTIONS, None)\n\n    def test_errors(self):\n        # less than 2 annotations should raise an error\n        with self.assertRaises(BeatIntervalError):\n            find_closest_intervals(DETECTIONS, [])\n        with self.assertRaises(BeatIntervalError):\n            find_closest_intervals(DETECTIONS, [1.])\n\n    def test_values(self):\n        # empty detections should return an empty result\n        intervals = find_closest_intervals([], ANNOTATIONS)\n        self.assertTrue(np.allclose(intervals, []))\n        # test detections w.r.t. annotations\n        intervals = find_closest_intervals(DETECTIONS, ANNOTATIONS)\n        correct = [1., 1, 1, 1, 1, 1, 1, 1, 1, 1]\n        self.assertTrue(np.allclose(intervals, correct))\n        # test annotations w.r.t. detections\n        intervals = find_closest_intervals(ANNOTATIONS, DETECTIONS)\n        correct = [0.99, 0.99, 1.05, 1.05, 2, 2, 1, 1, 1.1, 0.9]\n        self.assertTrue(np.allclose(intervals, correct))\n        # TODO: same tests with matches given\n\n\nclass TestFindLongestContinuousSegmentFunction(unittest.TestCase):\n\n    def test_types(self):\n        length, start = find_longest_continuous_segment(np.asarray([]))\n        self.assertIsInstance(length, int)\n        self.assertIsInstance(start, int)\n        length, start = find_longest_continuous_segment([])\n        self.assertIsInstance(length, int)\n        self.assertIsInstance(start, int)\n\n    def test_errors(self):\n        # events must be correct type\n        with self.assertRaises((IndexError, ValueError)):\n            find_longest_continuous_segment(None)\n        with self.assertRaises((IndexError, ValueError)):\n            find_longest_continuous_segment(1)\n\n    def test_values(self):\n        length, start = find_longest_continuous_segment([])\n        self.assertEqual(length, 0)\n        self.assertEqual(start, 0)\n        length, start = find_longest_continuous_segment([5])\n        self.assertEqual(length, 1)\n        self.assertEqual(start, 0)\n        #\n        length, start = find_longest_continuous_segment([0, 1, 2, 3])\n        self.assertEqual(length, 4)\n        self.assertEqual(start, 0)\n        length, start = find_longest_continuous_segment([0, 2, 3, 5, 6, 7, 9])\n        self.assertEqual(length, 3)\n        self.assertEqual(start, 3)\n\n\nclass TestCalcRelativeErrorsFunction(unittest.TestCase):\n\n    def test_types(self):\n        rel_errors = calc_relative_errors(DETECTIONS, ANNOTATIONS)\n        self.assertIsInstance(rel_errors, np.ndarray)\n        # events must be correct type\n        with self.assertRaises(TypeError):\n            calc_relative_errors(None, ANNOTATIONS)\n        with self.assertRaises(TypeError):\n            calc_relative_errors(DETECTIONS, None)\n\n    def test_errors(self):\n        # less than 2 annotations should raise an error\n        with self.assertRaises(BeatIntervalError):\n            calc_relative_errors(DETECTIONS, [])\n        with self.assertRaises(BeatIntervalError):\n            calc_relative_errors(DETECTIONS, [1.])\n\n    def test_values(self):\n        # empty detections should return an empty result\n        errors = calc_relative_errors([], ANNOTATIONS)\n        self.assertTrue(np.allclose(errors, []))\n        # test detections w.r.t. annotations\n        errors = calc_relative_errors(DETECTIONS, ANNOTATIONS)\n        # det: [1.01, 2, 2.95, 4,    6, 7, 8, 9.1, 10, 11]\n        # tar: [1,    2, 3,    4, 5, 6, 7, 8, 9,   10]\n        correct = [0.01, 0, -0.05, 0, 0, 0, 0, 0.1, 0, 1]\n        # all intervals are 1, so need for division\n        self.assertTrue(np.allclose(errors, correct))\n        # test annotations w.r.t. detections\n        errors = calc_relative_errors(ANNOTATIONS, DETECTIONS)\n        # tar: [1,    2, 3,    4, 5, 6, 7, 8, 9,   10]\n        # det: [1.01, 2, 2.95, 4,    6, 7, 8, 9.1, 10, 11]\n        errors_ = np.asarray([-0.01, 0, 0.05, 0, -1, 0, 0, 0, -0.1, 0])\n        intervals_ = np.asarray([0.99, 0.99, 1.05, 1.05, 2, 2, 1, 1, 1.1, 0.9])\n        self.assertTrue(np.allclose(errors, errors_ / intervals_))\n        # TODO: same tests with matches given\n\n\nclass TestBeatConstantsClass(unittest.TestCase):\n\n    def test_types(self):\n        self.assertIsInstance(FMEASURE_WINDOW, float)\n        self.assertIsInstance(PSCORE_TOLERANCE, float)\n        self.assertIsInstance(CEMGIL_SIGMA, float)\n        self.assertIsInstance(GOTO_THRESHOLD, float)\n        self.assertIsInstance(GOTO_SIGMA, float)\n        self.assertIsInstance(GOTO_MU, float)\n        self.assertIsInstance(CONTINUITY_TEMPO_TOLERANCE, float)\n        self.assertIsInstance(CONTINUITY_PHASE_TOLERANCE, float)\n        self.assertIsInstance(INFORMATION_GAIN_BINS, int)\n\n    def test_values(self):\n        self.assertEqual(FMEASURE_WINDOW, 0.07)\n        self.assertEqual(PSCORE_TOLERANCE, 0.2)\n        self.assertEqual(CEMGIL_SIGMA, 0.04)\n        self.assertEqual(GOTO_THRESHOLD, 0.175)\n        self.assertEqual(GOTO_SIGMA, 0.1)\n        self.assertEqual(GOTO_MU, 0.1)\n        self.assertEqual(CONTINUITY_TEMPO_TOLERANCE, 0.175)\n        self.assertEqual(CONTINUITY_PHASE_TOLERANCE, 0.175)\n        self.assertEqual(INFORMATION_GAIN_BINS, 40)\n\n\nclass TestPscoreFunction(unittest.TestCase):\n\n    def test_types(self):\n        score = pscore(DETECTIONS, ANNOTATIONS, 0.2)\n        self.assertIsInstance(score, float)\n        # detections / annotations must be correct type\n        score = pscore([], [], 0.2)\n        self.assertIsInstance(score, float)\n        # tolerance must be convertible to float\n        score = pscore(DETECTIONS, ANNOTATIONS, int(1.2))\n        self.assertIsInstance(score, float)\n\n    def test_errors(self):\n        # tolerance must be > 0\n        with self.assertRaises(ValueError):\n            pscore(DETECTIONS, ANNOTATIONS, 0)\n        # tolerance must be convertible to float\n        with self.assertRaises(TypeError):\n            pscore(DETECTIONS, ANNOTATIONS, None)\n        with self.assertRaises(TypeError):\n            pscore(DETECTIONS, ANNOTATIONS, [])\n        with self.assertRaises(TypeError):\n            pscore(DETECTIONS, ANNOTATIONS, {})\n        # detections / annotations must be correct type\n        with self.assertRaises(TypeError):\n            pscore(None, ANNOTATIONS, 0.2)\n        with self.assertRaises(TypeError):\n            pscore(DETECTIONS, None, 0.2)\n        # score relies on intervals, hence at least 2 annotations must be given\n        with self.assertRaises(BeatIntervalError):\n            pscore(DETECTIONS, [1], 0.2)\n\n    def test_values(self):\n        # two empty sequences should have a perfect score\n        score = pscore([], [], 0.2)\n        self.assertEqual(score, 1)\n        # if we have no annotations but detections, the score should be 0\n        score = pscore(DETECTIONS, [], 0.2)\n        self.assertEqual(score, 0)\n        # no detections should return 0\n        score = pscore([], ANNOTATIONS, 0.2)\n        self.assertEqual(score, 0)\n        # normal calculation\n        score = pscore(DETECTIONS, ANNOTATIONS, 0.2)\n        self.assertEqual(score, 0.9)\n\n\nclass TestCemgilFunction(unittest.TestCase):\n\n    def test_types(self):\n        score = cemgil(DETECTIONS, ANNOTATIONS, 0.04)\n        self.assertIsInstance(score, float)\n        # detections / annotations must be correct type\n        score = cemgil([], [], 0.04)\n        self.assertIsInstance(score, float)\n        # sigma must be correct type\n        score = cemgil(DETECTIONS, ANNOTATIONS, int(1))\n        self.assertIsInstance(score, float)\n\n    def test_errors(self):\n        # sigma must not be None\n        with self.assertRaises(TypeError):\n            cemgil(DETECTIONS, ANNOTATIONS, None)\n        # sigma must be greater than 0\n        with self.assertRaises(ValueError):\n            cemgil(DETECTIONS, ANNOTATIONS, 0)\n        # detections / annotations must be correct type\n        with self.assertRaises(TypeError):\n            cemgil(None, ANNOTATIONS, 0.04)\n        with self.assertRaises(TypeError):\n            cemgil(DETECTIONS, None, 0.04)\n        # sigma must be correct type\n        with self.assertRaises(TypeError):\n            cemgil(DETECTIONS, ANNOTATIONS, [0.04])\n        with self.assertRaises(TypeError):\n            cemgil(DETECTIONS, ANNOTATIONS, {0: 0.04})\n        with self.assertRaises(TypeError):\n            cemgil(DETECTIONS, ANNOTATIONS, {0.04: 0})\n\n    def test_values(self):\n        # two empty sequences should have a perfect score\n        score = cemgil([], [], 0.04)\n        self.assertEqual(score, 1)\n        # if we have no annotations but detections, the score should be 0\n        score = cemgil(DETECTIONS, [], 0.04)\n        self.assertEqual(score, 0)\n        # score doesn\'t use intervals, thus don\'t check number of annotations\n        # no detections should return 0\n        score = cemgil([], ANNOTATIONS, 0.04)\n        self.assertEqual(score, 0)\n        # normal calculation\n        score = cemgil(DETECTIONS, ANNOTATIONS, 0.04)\n        self.assertEqual(score, 0.74710035298713695)\n\n\nclass TestGotoFunction(unittest.TestCase):\n\n    def test_types(self):\n        score = goto(DETECTIONS, ANNOTATIONS, 0.175, 0.2, 0.2)\n        self.assertIsInstance(score, float)\n        # detections / annotations must be correct type\n        score = goto([], [], 0.175, 0.2, 0.2)\n        self.assertIsInstance(score, float)\n        # parameters must be correct type\n        score = goto(DETECTIONS, ANNOTATIONS, int(1.175), 0.2, 0.2)\n        self.assertIsInstance(score, float)\n        score = goto(DETECTIONS, ANNOTATIONS, 0.175, int(1.2), 0.2)\n        self.assertIsInstance(score, float)\n        score = goto(DETECTIONS, ANNOTATIONS, 0.175, 0.2, int(1.2))\n        self.assertIsInstance(score, float)\n\n    def test_errors(self):\n        # parameters must not be None\n        with self.assertRaises(TypeError):\n            goto(DETECTIONS, ANNOTATIONS, None, 0.2, 0.2)\n        with self.assertRaises(TypeError):\n            goto(DETECTIONS, ANNOTATIONS, 0.175, None, 0.2)\n        with self.assertRaises(TypeError):\n            goto(DETECTIONS, ANNOTATIONS, 0.175, 0.2, None)\n        # parameters must be positive\n        with self.assertRaises(ValueError):\n            goto(DETECTIONS, ANNOTATIONS, -1, 0.2, 0.2)\n        with self.assertRaises(ValueError):\n            goto(DETECTIONS, ANNOTATIONS, 0.175, -1, 0.2)\n        with self.assertRaises(ValueError):\n            goto(DETECTIONS, ANNOTATIONS, 0.175, 0.2, -1)\n        # detections / annotations must be correct type\n        with self.assertRaises(TypeError):\n            goto(None, ANNOTATIONS, 0.175, 0.2, 0.2)\n        with self.assertRaises(TypeError):\n            goto(DETECTIONS, None, 0.175, 0.2, 0.2)\n        # score relies on intervals, hence at least 2 annotations must be given\n        with self.assertRaises(BeatIntervalError):\n            goto(DETECTIONS, [1], 0.175, 0.2, 0.2)\n\n    def test_values(self):\n        # two empty sequences should have a perfect score\n        score = goto([], [], 0.175, 0.2, 0.2)\n        self.assertEqual(score, 1)\n        # if the length of the correct segment is < 0.25 the annotation length\n        score = goto([1], [1, 2, 3, 4, 5], 0.175, 0.2, 0.2)\n        self.assertEqual(score, 0)\n        # if we have no annotations but detections, the score should be 0\n        score = goto(DETECTIONS, [], 0.175, 0.2, 0.2)\n        self.assertEqual(score, 0)\n        # no detections should return 0\n        score = goto([], ANNOTATIONS, 0.175, 0.2, 0.2)\n        self.assertEqual(score, 0)\n        # normal calculation\n        score = goto(DETECTIONS, ANNOTATIONS, 0.175, 0.2, 0.2)\n        self.assertEqual(score, 1)\n        # simple example where the Matlab implementation fails\n        det = np.array([0, 0.5, 1, 1.5, 2, 5, 6, 7, 8, 9])\n        ann = np.arange(10)\n        self.assertEqual(goto(det, ann), 1)\n        self.assertEqual(goto(ann, det), 1)\n\n\nclass TestCmlFunction(unittest.TestCase):\n\n    def test_types(self):\n        cmlc, cmlt = cml(DETECTIONS, ANNOTATIONS, 0.175, 0.175)\n        self.assertIsInstance(cmlc, float)\n        self.assertIsInstance(cmlt, float)\n        # detections / annotations must be correct type\n        cmlc, cmlt = cml([], [], 0.175, 0.175)\n        self.assertIsInstance(cmlc, float)\n        self.assertIsInstance(cmlt, float)\n        # tolerances must be correct type\n        cmlc, cmlt = cml(DETECTIONS, ANNOTATIONS, int(1), int(1))\n        self.assertIsInstance(cmlc, float)\n        self.assertIsInstance(cmlt, float)\n        with self.assertRaises(TypeError):\n            cml(DETECTIONS, ANNOTATIONS, {}, {})\n        with self.assertRaises(TypeError):\n            cml(DETECTIONS, ANNOTATIONS, [0.175], [0.175])\n\n    def test_errors(self):\n        # tolerances must not be None\n        with self.assertRaises(TypeError):\n            cml(DETECTIONS, ANNOTATIONS, 0.1, None)\n        with self.assertRaises(TypeError):\n            cml(DETECTIONS, ANNOTATIONS, None, 0.1)\n        # tolerances must be greater than 0\n        with self.assertRaises(ValueError):\n            cml(DETECTIONS, ANNOTATIONS, 0, 1)\n        with self.assertRaises(ValueError):\n            cml(DETECTIONS, ANNOTATIONS, 1, 0)\n        # detections / annotations must be correct type\n        with self.assertRaises(TypeError):\n            cml(None, ANNOTATIONS, 0.175, 0.175)\n        with self.assertRaises(TypeError):\n            cml(DETECTIONS, None, 0.175, 0.175)\n        # score relies on intervals, hence at least 2 ann/det must be given\n        with self.assertRaises(BeatIntervalError):\n            cml(DETECTIONS, [1.], 0.175, 0.175)\n        with self.assertRaises(BeatIntervalError):\n            cml([1.], ANNOTATIONS, 0.175, 0.175)\n\n    def test_values(self):\n        # two empty sequences should have a perfect score\n        scores = cml([], [], 0.175, 0.175)\n        self.assertEqual(scores, (1, 1))\n        # if we have no annotations but detections, the score should be 0\n        scores = cml(DETECTIONS, [], 0.175, 0.175)\n        self.assertEqual(scores, (0, 0))\n        # no detections should return 0\n        scores = cml([], ANNOTATIONS, 0.175, 0.175)\n        self.assertEqual(scores, (0, 0))\n        # normal calculation\n        scores = cml(DETECTIONS, ANNOTATIONS, 0.175, 0.175)\n        self.assertEqual(scores, (0.4, 0.8))\n\n\nclass TestContinuityFunction(unittest.TestCase):\n\n    def test_types(self):\n        cmlc, cmlt, amlc, amlt = continuity(DETECTIONS, ANNOTATIONS,\n                                            0.175, 0.175)\n        self.assertIsInstance(cmlc, float)\n        self.assertIsInstance(cmlt, float)\n        self.assertIsInstance(amlc, float)\n        self.assertIsInstance(amlt, float)\n        # detections / annotations must be correct type\n        cmlc, cmlt, amlc, amlt = continuity([], [], 0.175, 0.175)\n        self.assertIsInstance(cmlc, float)\n        self.assertIsInstance(cmlt, float)\n        self.assertIsInstance(amlc, float)\n        self.assertIsInstance(amlt, float)\n        # tolerances must be correct type\n        scores = continuity(DETECTIONS, ANNOTATIONS, int(1), int(1))\n        cmlc, cmlt, amlc, amlt = scores\n        self.assertIsInstance(cmlc, float)\n        self.assertIsInstance(cmlt, float)\n        self.assertIsInstance(amlc, float)\n        self.assertIsInstance(amlt, float)\n\n    def test_errors(self):\n        # tolerances must not be None\n        with self.assertRaises(TypeError):\n            continuity(DETECTIONS, ANNOTATIONS, 0.1, None)\n        with self.assertRaises(TypeError):\n            continuity(DETECTIONS, ANNOTATIONS, None, 0.1)\n        # tolerances must be greater than 0\n        with self.assertRaises(ValueError):\n            continuity(DETECTIONS, ANNOTATIONS, 1, 0)\n        with self.assertRaises(ValueError):\n            continuity(DETECTIONS, ANNOTATIONS, 0, 1)\n        # tolerances must be correct type\n        with self.assertRaises(TypeError):\n            continuity(DETECTIONS, ANNOTATIONS, [0.175], 1)\n        with self.assertRaises(TypeError):\n            continuity(DETECTIONS, ANNOTATIONS, 1, [0.175])\n        with self.assertRaises(TypeError):\n            continuity(DETECTIONS, ANNOTATIONS, None, 1)\n        with self.assertRaises(TypeError):\n            continuity(DETECTIONS, ANNOTATIONS, 1, None)\n        with self.assertRaises(TypeError):\n            continuity(DETECTIONS, ANNOTATIONS, {}, 1)\n        with self.assertRaises(TypeError):\n            continuity(DETECTIONS, ANNOTATIONS, 1, {})\n        # detections / annotations must be correct type\n        with self.assertRaises(TypeError):\n            continuity(None, ANNOTATIONS, 0.175, 0.175)\n        with self.assertRaises(TypeError):\n            continuity(DETECTIONS, None, 0.175, 0.175)\n\n    def test_values(self):\n        # two empty sequences should have a perfect score\n        scores = continuity([], [], 0.175, 0.175)\n        self.assertEqual(scores, (1, 1, 1, 1))\n        # if we have no annotations but detections, the score should be 0\n        scores = continuity(DETECTIONS, [], 0.175, 0.175)\n        self.assertEqual(scores, (0, 0, 0, 0))\n        # no detections should return 0\n        scores = continuity([], ANNOTATIONS, 0.175, 0.175)\n        self.assertEqual(scores, (0, 0, 0, 0))\n        # single annotation/detection should return 0\n        scores = continuity(DETECTIONS, [1.], 0.175, 0.175)\n        self.assertEqual(scores, (0, 0, 0, 0))\n        scores = continuity([1.], ANNOTATIONS, 0.175, 0.175)\n        self.assertEqual(scores, (0, 0, 0, 0))\n        # normal calculation\n        scores = continuity(DETECTIONS, ANNOTATIONS, 0.175, 0.175)\n        self.assertEqual(scores, (0.4, 0.8, 0.4, 0.8))\n        # double tempo annotations\n        scores = continuity(DETECTIONS, DOUBLE_ANNOTATIONS, 0.175, 0.175)\n        self.assertEqual(scores, (0., 0., 0.4, 0.8))\n        scores = continuity(DETECTIONS, DOUBLE_ANNOTATIONS, 0.175, 0.175,\n                            double=False, triple=False)\n        self.assertEqual(scores, (0., 0., 0., 0.))\n        scores = continuity(DETECTIONS, DOUBLE_ANNOTATIONS, 0.175, 0.175,\n                            double=True, triple=False)\n        self.assertEqual(scores, (0., 0., 0.4, 0.8))\n        scores = continuity(DETECTIONS, DOUBLE_ANNOTATIONS, 0.175, 0.175,\n                            double=False, triple=True)\n        self.assertEqual(scores, (0., 0., 0., 0.))\n        # half tempo annotations (even beats)\n        scores = continuity(DETECTIONS, ANNOTATIONS[::2], 0.175, 0.175)\n        self.assertEqual(scores, (0., 0., 0.4, 0.7))\n        scores = continuity(DETECTIONS, ANNOTATIONS[::2], 0.175, 0.175,\n                            double=False, triple=False)\n        self.assertEqual(scores, (0., 0., 0.1, 0.1))\n        scores = continuity(DETECTIONS, ANNOTATIONS[::2], 0.175, 0.175,\n                            double=True, triple=False)\n        self.assertEqual(scores, (0., 0., 0.4, 0.7))\n        scores = continuity(DETECTIONS, ANNOTATIONS[::2], 0.175, 0.175,\n                            double=False, triple=True)\n        self.assertEqual(scores, (0., 0., 0.1, 0.1))\n        # half tempo annotations (odd beats)\n        scores = continuity(DETECTIONS, ANNOTATIONS[1::2], 0.175, 0.175)\n        self.assertEqual(scores, (0.1, 0.1, 0.4, 0.7))\n        scores = continuity(DETECTIONS, ANNOTATIONS[1::2], 0.175, 0.175,\n                            double=False, triple=False)\n        self.assertEqual(scores, (0.1, 0.1, 0.1, 0.1))\n        scores = continuity(DETECTIONS, ANNOTATIONS[1::2], 0.175, 0.175,\n                            double=True, triple=False)\n        self.assertEqual(scores, (0.1, 0.1, 0.4, 0.7))\n        scores = continuity(DETECTIONS, ANNOTATIONS[1::2], 0.175, 0.175,\n                            double=False, triple=True)\n        self.assertEqual(scores, (0.1, 0.1, 0.1, 0.1))\n        # triple tempo annotations\n        scores = continuity(DETECTIONS, TRIPLE_ANNOTATIONS, 0.175, 0.175)\n        self.assertEqual(scores, (0., 0., 0.4, 0.8))\n        scores = continuity(DETECTIONS, TRIPLE_ANNOTATIONS, 0.175, 0.175,\n                            double=False, triple=False)\n        self.assertEqual(scores, (0., 0., 0., 0.))\n        scores = continuity(DETECTIONS, TRIPLE_ANNOTATIONS, 0.175, 0.175,\n                            double=True, triple=False)\n        self.assertEqual(scores, (0., 0., 0., 0.))\n        scores = continuity(DETECTIONS, TRIPLE_ANNOTATIONS, 0.175, 0.175,\n                            double=False, triple=True)\n        self.assertEqual(scores, (0., 0., 0.4, 0.8))\n        # third tempo annotations (starting with 1st beat)\n        scores = continuity(DETECTIONS, ANNOTATIONS[::3], 0.175, 0.175)\n        self.assertEqual(scores, (0., 0., 0.4, 0.8))\n        scores = continuity(DETECTIONS, ANNOTATIONS[::3], 0.175, 0.175,\n                            double=False, triple=False)\n        self.assertEqual(scores, (0., 0., 0., 0.))\n        scores = continuity(DETECTIONS, ANNOTATIONS[::3], 0.175, 0.175,\n                            double=True, triple=False)\n        self.assertEqual(scores, (0., 0., 0., 0.))\n        scores = continuity(DETECTIONS, ANNOTATIONS[::3], 0.175, 0.175,\n                            double=False, triple=True)\n        self.assertEqual(scores, (0., 0., 0.4, 0.8))\n        # third tempo annotations (starting with 2nd beat)\n        scores = continuity(DETECTIONS, ANNOTATIONS[1::3], 0.175, 0.175)\n        self.assertEqual(scores, (0., 0., 0.3, 0.5))\n        scores = continuity(DETECTIONS, ANNOTATIONS[1::3], 0.175, 0.175,\n                            double=False, triple=False)\n        self.assertEqual(scores, (0., 0., 0., 0.))\n        scores = continuity(DETECTIONS, ANNOTATIONS[1::3], 0.175, 0.175,\n                            double=True, triple=False)\n        self.assertEqual(scores, (0., 0., 0., 0.))\n        scores = continuity(DETECTIONS, ANNOTATIONS[1::3], 0.175, 0.175,\n                            double=False, triple=True)\n        self.assertEqual(scores, (0., 0., 0.3, 0.5))\n        # third tempo annotations (starting with 3rd beat)\n        scores = continuity(DETECTIONS, ANNOTATIONS[2::3], 0.175, 0.175)\n        self.assertEqual(scores, (0., 0., 0.3, 0.5))\n        scores = continuity(DETECTIONS, ANNOTATIONS[2::3], 0.175, 0.175,\n                            double=False, triple=False)\n        self.assertEqual(scores, (0., 0., 0., 0.))\n        scores = continuity(DETECTIONS, ANNOTATIONS[2::3], 0.175, 0.175,\n                            double=True, triple=False)\n        self.assertEqual(scores, (0., 0., 0., 0.))\n        scores = continuity(DETECTIONS, ANNOTATIONS[2::3], 0.175, 0.175,\n                            double=False, triple=True)\n        self.assertEqual(scores, (0., 0., 0.3, 0.5))\n\n\nclass TestHistogramBinsHelperFunction(unittest.TestCase):\n\n    def test_types(self):\n        bins = _histogram_bins(40)\n        self.assertIsInstance(bins, np.ndarray)\n        self.assertTrue(bins.dtype == np.float)\n\n    def test_errors(self):\n        # bins must be even and greater or equal than 2\n        with self.assertRaises(ValueError):\n            _histogram_bins(1)\n        with self.assertRaises(ValueError):\n            _histogram_bins(2.1)\n        with self.assertRaises(ValueError):\n            _histogram_bins(5)\n\n    def test_values(self):\n        # test some well defined situations\n        bins = _histogram_bins(2)\n        # the bins must be 0.5 wide and centered around 0\n        self.assertTrue(np.allclose(bins, [-0.75, -0.25, 0.25, 0.75]))\n        bins = _histogram_bins(4)\n        # the bins must be 0.25 wide and centered around 0\n        self.assertTrue(np.allclose(bins, [-0.625, -0.375, -0.125, 0.125,\n                                           0.375, 0.625]))\n\n\nclass TestErrorHistogramHelperFunction(unittest.TestCase):\n\n    def test_types(self):\n        bins = _histogram_bins(4)\n        hist = _error_histogram(DETECTIONS, ANNOTATIONS, bins)\n        self.assertIsInstance(hist, np.ndarray)\n        self.assertTrue(hist.dtype == np.float)\n\n    def test_values(self):\n        # first bin maps the \xc2\xb10.5 interval error, the second the 0\n        bins = _histogram_bins(2)\n        ann = np.asarray([0, 1, 2, 3])\n        # A) identical detections map to the 0 error bin\n        hist = _error_histogram(np.asarray([0, 1, 2, 3]), ann, bins)\n        self.assertTrue(np.allclose(hist, [0, 4]))\n        # bins maps the \xc2\xb10.5, -0.25, 0, 0.25 interval errors\n        bins = _histogram_bins(4)\n        # B) identical detections map to the 0 error bin\n        hist = _error_histogram(ann, ann, bins)\n        self.assertTrue(np.allclose(hist, [0, 0, 4, 0]))\n        # C) offbeat detections map to the \xc2\xb10.5 error bin\n        hist = _error_histogram(np.asarray([0.5, 1.5, 2.5, 3.5]), ann, bins)\n        self.assertTrue(np.allclose(hist, [4, 0, 0, 0]))\n        # D) smaller deviations mapping to the 0 and 0.125 error bins\n        hist = _error_histogram(np.asarray([0.125, 0.875, 2.1, 3]), ann, bins)\n        self.assertTrue(np.allclose(hist, [0, 0, 3, 1]))\n        # E) default annotations and detections with 40 bins\n        bins = _histogram_bins(40)\n        hist = _error_histogram(DETECTIONS, ANNOTATIONS, bins)\n        self.assertTrue(np.allclose(hist, [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n                                           0, 0, 0, 0, 0, 0, 1, 0, 8, 0, 0, 0,\n                                           1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n                                           0, 0, 0, 0]))\n\n\nclass TestEntropyHelperFunction(unittest.TestCase):\n\n    def test_types(self):\n        entropy = _entropy(np.ones(6))\n        self.assertIsInstance(entropy, float)\n\n    def test_values(self):\n        # uniform histogram\n        self.assertTrue(_entropy([1, 1, 1]) == np.log2(3))\n        # use the examples of the TestErrorHistogramHelperFunction test above\n        # A)\n        hist = [0, 4]\n        self.assertTrue(_entropy(hist) == 0)\n        # B)\n        hist = [0, 0, 4, 0]\n        self.assertTrue(_entropy(hist) == 0)\n        # C)\n        hist = [4, 0, 0, 0]\n        self.assertTrue(_entropy(hist) == 0)\n        # D)\n        hist = [0, 0, 3, 1]\n        self.assertTrue(np.allclose(_entropy(hist), 0.811278124459))\n        # E)\n        hist = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n                8, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n        self.assertTrue(np.allclose(_entropy(hist), 0.921928094887))\n\n\nclass TestInformationGainHelperFunction(unittest.TestCase):\n\n    def test_types(self):\n        bins = _histogram_bins(4)\n        hist = _error_histogram(DETECTIONS, ANNOTATIONS, bins)\n        ig = _information_gain(hist)\n        self.assertIsInstance(ig, float)\n\n    def test_values(self):\n        # information gain is np.log2(len(histogram)) - entropy(histogram)\n        # histogram with zeros\n        self.assertTrue(_information_gain([0, 0, 0]) == np.log2(3))\n        # uniform histogram\n        self.assertTrue(_information_gain([1, 1, 1]) == 0)\n        # use the examples of the TestErrorHistogramHelperFunction test above\n        # A)\n        hist = [0, 4]\n        self.assertTrue(_information_gain(hist) == np.log2(2))\n        # B)\n        hist = [0, 0, 4, 0]\n        self.assertTrue(_information_gain(hist) == np.log2(4))\n        # C)\n        hist = [4, 0, 0, 0]\n        self.assertTrue(_information_gain(hist) == np.log2(4))\n        # D)\n        hist = [0, 0, 3, 1]\n        self.assertTrue(np.allclose(_information_gain(hist), 1.18872187554))\n        # E)\n        hist = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n                8, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n        self.assertTrue(_information_gain(hist) == 4.4)\n\n\nclass TestInformationGainFunction(unittest.TestCase):\n\n    def test_types(self):\n        ig, histogram = information_gain(DETECTIONS, ANNOTATIONS, 40)\n        self.assertIsInstance(ig, float)\n        self.assertIsInstance(histogram, np.ndarray)\n        # detections / annotations must be correct type\n        ig, histogram = information_gain([], [], 40)\n        self.assertIsInstance(ig, float)\n        self.assertIsInstance(histogram, np.ndarray)\n        # tolerances must be correct type\n        ig, histogram = information_gain(DETECTIONS, ANNOTATIONS, 40)\n        self.assertIsInstance(ig, float)\n        self.assertIsInstance(histogram, np.ndarray)\n        ig, histogram = information_gain(DETECTIONS, ANNOTATIONS, 40)\n        self.assertIsInstance(ig, float)\n        self.assertIsInstance(histogram, np.ndarray)\n\n    def test_errors(self):\n        # num_bins must not be None\n        with self.assertRaises(TypeError):\n            information_gain(DETECTIONS, ANNOTATIONS, None)\n        # num_bins must be correct type\n        with self.assertRaises(TypeError):\n            information_gain(DETECTIONS, ANNOTATIONS, [10])\n        with self.assertRaises(TypeError):\n            information_gain(DETECTIONS, ANNOTATIONS, {10})\n        # detections / annotations must be correct type\n        with self.assertRaises(TypeError):\n            information_gain(None, ANNOTATIONS, 40)\n        with self.assertRaises(TypeError):\n            information_gain(DETECTIONS, None, 40)\n\n    def test_values(self):\n        # empty sequences should return max score and a zero histogram\n        ig, histogram = information_gain([], [], 4)\n        self.assertEqual(ig, np.log2(4))\n        self.assertTrue(np.allclose(histogram, np.zeros(4)))\n        # if any of detections or annotations are empty, a score of 0 and a\n        # uniform histogram should be returned\n        uniform = np.ones(4) * 10. / 4\n        ig, histogram = information_gain([], ANNOTATIONS, 4)\n        self.assertEqual(ig, 0)\n        self.assertTrue(np.allclose(histogram, uniform))\n        ig, histogram = information_gain(DETECTIONS, [], 4)\n        self.assertEqual(ig, 0)\n        self.assertTrue(np.allclose(histogram, uniform))\n        # same if only one annotation/detection is given\n        # single annotation/detection should return 0\n        ig, histogram = information_gain([1.], ANNOTATIONS, 4)\n        self.assertEqual(ig, 0)\n        self.assertTrue(np.allclose(histogram, uniform))\n        ig, histogram = information_gain(DETECTIONS, [1.], 4)\n        self.assertEqual(ig, 0)\n        self.assertTrue(np.allclose(histogram, uniform))\n        # normal calculation\n        ig, histogram = information_gain(DETECTIONS, ANNOTATIONS, 4)\n        # tar: [1,    2, 3,    4, 5, 6, 7, 8, 9,   10]\n        # det: [1.01, 2, 2.95, 4,    6, 7, 8, 9.1, 10, 11]\n        # errors: [-0.01, 0, 0.05, 0, -1, 0, 0, 0, -0.1, 0]\n        # intervals: [0.99, 0.99, 1.05, 1.05, 2, 2, 1, 1, 1.1, 0.9]\n        # rel. err.: [-0.01010101, 0, 0.04761905, 0, -0.5, 0, 0, 0,\n        #             -0.09090909, 0]\n        # bin edges: [-0.625 -0.375 -0.125  0.125  0.375  0.625]\n        # bin count: [1, 0, 9, 0]\n        # normalized histogram: [0.1, 0, 0.9, 0]\n        # well-behaving histogram: [0.1, 1, 0.9, 1]\n        # np.log2 histogram: [-3.32192809, 0, -0.15200309, 0]\n        # entropy: 0.46899559358928122\n        self.assertTrue(np.allclose(histogram, [1, 0, 9, 0]))\n        self.assertEqual(ig, np.log2(4) - 0.46899559358928122)\n\n    def test_few_correct_detections(self):\n        # if only a few beats are correct, ig should be low, too\n        ig, histogram = information_gain([1., 2.], DETECTIONS, 10)\n        self.assertTrue(np.allclose(histogram, [0, 0, 0, 0, 0, 9, 1, 0, 0, 0]))\n        self.assertTrue(np.allclose(ig, 2.8529325))\n        ig, histogram = information_gain(DETECTIONS, [1., 2.], 10)\n        self.assertTrue(np.allclose(histogram, [0, 0, 0, 0, 0, 9, 1, 0, 0, 0]))\n        self.assertTrue(np.allclose(ig, 2.8529325))\n\n\n# test evaluation class\nclass TestBeatEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = BeatEvaluation(DETECTIONS, ANNOTATIONS)\n        # from OnsetEvaluation\n        self.assertIsInstance(e.num_tp, int)\n        self.assertIsInstance(e.num_fp, int)\n        self.assertIsInstance(e.num_tn, int)\n        self.assertIsInstance(e.num_fn, int)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.accuracy, float)\n        self.assertIsInstance(e.errors, np.ndarray)\n        self.assertIsInstance(e.mean_error, float)\n        self.assertIsInstance(e.std_error, float)\n        # additional beat score types\n        self.assertIsInstance(e.pscore, float)\n        self.assertIsInstance(e.cemgil, float)\n        self.assertIsInstance(e.goto, float)\n        self.assertIsInstance(e.cmlc, float)\n        self.assertIsInstance(e.cmlt, float)\n        self.assertIsInstance(e.amlc, float)\n        self.assertIsInstance(e.amlt, float)\n        self.assertIsInstance(e.information_gain, float)\n        self.assertIsInstance(e.global_information_gain, float)\n        self.assertIsInstance(e.error_histogram, np.ndarray)\n\n    def test_conversion(self):\n        # conversion from list should work\n        e = BeatEvaluation([], [])\n        self.assertIsInstance(e.tp, np.ndarray)\n        self.assertIsInstance(e.fp, np.ndarray)\n        self.assertIsInstance(e.tn, np.ndarray)\n        self.assertIsInstance(e.fn, np.ndarray)\n        # conversion from 2D arrays\n        e = BeatEvaluation(np.array([[1, 1], [2, 2]]),\n                           np.array([[1, 1], [2, 2]]))\n        self.assertIsInstance(e.tp, np.ndarray)\n        self.assertIsInstance(e.fp, np.ndarray)\n        self.assertIsInstance(e.tn, np.ndarray)\n        self.assertIsInstance(e.fn, np.ndarray)\n        # conversion from list of lists\n        e = BeatEvaluation([[1, 1], [2, 2]], [[1, 1], [2, 2]])\n        self.assertIsInstance(e.tp, np.ndarray)\n        self.assertIsInstance(e.fp, np.ndarray)\n        self.assertIsInstance(e.tn, np.ndarray)\n        self.assertIsInstance(e.fn, np.ndarray)\n\n    def test_errors(self):\n        # conversion from list of lists\n        with self.assertRaises(BeatIntervalError):\n            e = BeatEvaluation(0, 1.)\n\n    def test_results_empty(self):\n        e = BeatEvaluation([], [])\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.pscore, 1)\n        self.assertEqual(e.cemgil, 1)\n        self.assertEqual(e.goto, 1)\n        self.assertEqual(e.cmlc, 1)\n        self.assertEqual(e.cmlt, 1)\n        self.assertEqual(e.amlc, 1)\n        self.assertEqual(e.amlt, 1)\n        self.assertEqual(e.information_gain, np.log2(40))\n        self.assertEqual(e.global_information_gain, np.log2(40))\n        self.assertTrue(np.allclose(e.error_histogram, np.zeros(40)))\n\n    def test_results(self):\n        e = BeatEvaluation(DETECTIONS, ANNOTATIONS)\n        # tar: [1,    2, 3,    4, 5, 6, 7, 8, 9,   10]\n        # det: [1.01, 2, 2.95, 4,    6, 7, 8, 9.1, 10, 11]\n        # WINDOW = 0.07\n        # TOLERANCE = 0.2\n        # SIGMA = 0.04\n        # TEMPO_TOLERANCE = 0.175\n        # PHASE_TOLERANCE = 0.175\n        # BINS = 40\n        self.assertTrue(np.allclose(e.tp, [1.01, 2, 2.95, 4, 6, 7, 8, 10]))\n        self.assertTrue(np.allclose(e.fp, [9.1, 11]))\n        self.assertTrue(np.allclose(e.tn, []))\n        self.assertTrue(np.allclose(e.fn, [5, 9]))\n        self.assertEqual(e.num_tp, 8)\n        self.assertEqual(e.num_fp, 2)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 2)\n        self.assertEqual(e.precision, 8. / 10.)\n        self.assertEqual(e.recall, 8. / 10.)\n        f = 2 * (8. / 10.) * (8. / 10.) / ((8. / 10.) + (8. / 10.))\n        self.assertEqual(e.fmeasure, f)\n        self.assertEqual(e.accuracy, (8. + 0) / (8 + 2 + 0 + 2))\n        # pscore: delta <= tolerance * median(inter beat interval)\n        self.assertEqual(e.pscore, 9. / 10.)\n        # cemgil:\n        self.assertEqual(e.cemgil, 0.74710035298713695)\n        self.assertEqual(e.goto, 1)\n        self.assertEqual(e.cmlc, 0.4)\n        self.assertEqual(e.cmlt, 0.8)\n        self.assertEqual(e.amlc, 0.4)\n        self.assertEqual(e.amlt, 0.8)\n        self.assertEqual(e.information_gain, 3.965148445440323)\n        self.assertEqual(e.global_information_gain, 3.965148445440323)\n        error_histogram_ = np.zeros(40)\n        error_histogram_[0] = 1\n        error_histogram_[16] = 1\n        error_histogram_[20] = 7\n        error_histogram_[22] = 1\n        self.assertTrue(np.allclose(e.error_histogram, error_histogram_))\n\n    def test_downbeat_results(self):\n        det = [[0.9, 1], [2, 2], [3, 3], [4, 4], [5, 1]]\n        ann = [[1, 1], [2, 2], [3, 3], [4, 4], [5, 1]]\n        e = BeatEvaluation(det, ann)\n        self.assertTrue(np.allclose(e.tp, [2, 3, 4, 5]))\n        e = BeatEvaluation(det, ann, downbeats=True)\n        self.assertTrue(np.allclose(e.tp, [5]))\n        e = BeatEvaluation(det, ann, downbeats=True, fmeasure_window=0.1)\n        self.assertTrue(np.allclose(e.tp, [0.9, 5]))\n\n    def test_tostring(self):\n        print(BeatEvaluation([], []))\n\n\nclass TestBeatMeanEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = BeatMeanEvaluation([])\n        # scores\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.pscore, float)\n        self.assertIsInstance(e.cemgil, float)\n        self.assertIsInstance(e.goto, float)\n        self.assertIsInstance(e.cmlc, float)\n        self.assertIsInstance(e.cmlt, float)\n        self.assertIsInstance(e.amlc, float)\n        self.assertIsInstance(e.amlt, float)\n        self.assertIsInstance(e.information_gain, float)\n        self.assertIsInstance(e.global_information_gain, float)\n        self.assertIsInstance(e.error_histogram, np.ndarray)\n\n    def test_results(self):\n        # empty mean evaluation\n        e = BeatMeanEvaluation([])\n        self.assertTrue(math.isnan(e.fmeasure))\n        self.assertTrue(math.isnan(e.pscore))\n        self.assertTrue(math.isnan(e.cemgil))\n        self.assertTrue(math.isnan(e.goto))\n        self.assertTrue(math.isnan(e.cmlc))\n        self.assertTrue(math.isnan(e.cmlt))\n        self.assertTrue(math.isnan(e.amlc))\n        self.assertTrue(math.isnan(e.amlt))\n        self.assertTrue(math.isnan(e.information_gain))\n        self.assertTrue(np.allclose(e.global_information_gain, 0))\n        self.assertEqual(len(e), 0)\n        # TODO: should this also return nan?\n        self.assertTrue(np.allclose(e.error_histogram, np.zeros(0)))\n\n        # mean evaluation of empty beat evaluation\n        e = BeatMeanEvaluation([BeatEvaluation([], [])])\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.pscore, 1)\n        self.assertEqual(e.cemgil, 1)\n        self.assertEqual(e.goto, 1)\n        self.assertEqual(e.cmlc, 1)\n        self.assertEqual(e.cmlt, 1)\n        self.assertEqual(e.amlc, 1)\n        self.assertEqual(e.amlt, 1)\n        self.assertEqual(e.information_gain, np.log2(40))\n        self.assertTrue(np.allclose(e.global_information_gain, np.log2(40)))\n        self.assertTrue(np.allclose(e.error_histogram, np.zeros(40)))\n        self.assertEqual(len(e), 1)\n\n        # mean evaluation of beat evaluation\n        e = BeatMeanEvaluation([BeatEvaluation(DETECTIONS, ANNOTATIONS)])\n        f = 2 * (8. / 10.) * (8. / 10.) / ((8. / 10.) + (8. / 10.))\n        self.assertEqual(e.fmeasure, f)\n        self.assertEqual(e.pscore, 9. / 10.)\n        self.assertEqual(e.cemgil, 0.74710035298713695)\n        self.assertEqual(e.goto, 1)\n        self.assertEqual(e.cmlc, 0.4)\n        self.assertEqual(e.cmlt, 0.8)\n        self.assertEqual(e.amlc, 0.4)\n        self.assertEqual(e.amlt, 0.8)\n        self.assertEqual(e.information_gain, 3.965148445440323)\n        self.assertEqual(e.global_information_gain, 3.965148445440323)\n        error_histogram_ = np.zeros(40)\n        error_histogram_[0] = 1\n        error_histogram_[16] = 1\n        error_histogram_[20] = 7\n        error_histogram_[22] = 1\n        self.assertTrue(np.allclose(e.error_histogram, error_histogram_))\n        self.assertEqual(len(e), 1)\n        # mean evaluation of empty and beat evaluation\n        e1 = BeatEvaluation([], [])\n        e2 = BeatEvaluation(DETECTIONS, ANNOTATIONS)\n        e = BeatMeanEvaluation([e1, e2])\n        f2 = 2 * (8. / 10.) * (8. / 10.) / ((8. / 10.) + (8. / 10.))\n        self.assertEqual(e.fmeasure, (1 + f2) / 2)\n        self.assertEqual(e.pscore, (1 + 9. / 10.) / 2)\n        self.assertEqual(e.cemgil, (1 + 0.74710035298713695) / 2)\n        self.assertEqual(e.goto, (1 + 1) / 2)\n        self.assertEqual(e.cmlc, (1 + 0.4) / 2)\n        self.assertEqual(e.cmlt, (1 + 0.8) / 2)\n        self.assertEqual(e.amlc, (1 + 0.4) / 2)\n        self.assertEqual(e.amlt, (1 + 0.8) / 2)\n        ig = (np.log2(40) + 3.965148445440323) / 2\n        self.assertEqual(e.information_gain, ig)\n        self.assertEqual(e.global_information_gain, 3.965148445440323)\n        error_histogram_ = np.zeros(40)\n        error_histogram_[0] = 1\n        error_histogram_[16] = 1\n        error_histogram_[20] = 7\n        error_histogram_[22] = 1\n        self.assertTrue(np.allclose(e.error_histogram, error_histogram_))\n        self.assertEqual(len(e), 2)\n\n    def test_tostring(self):\n        print(BeatMeanEvaluation([]))\n\n\nclass TestAddParserFunction(unittest.TestCase):\n\n    def setUp(self):\n        import argparse\n        self.parser = argparse.ArgumentParser()\n        sub_parser = self.parser.add_subparsers()\n        self.sub_parser, self.group = add_parser(sub_parser)\n\n    def test_args(self):\n        args = self.parser.parse_args([\'beats\', ANNOTATIONS_PATH,\n                                       DETECTIONS_PATH])\n        self.assertTrue(args.ann_dir is None)\n        self.assertTrue(args.ann_suffix == \'.beats\')\n        self.assertTrue(args.cemgil_sigma == 0.04)\n        self.assertTrue(args.continuity_phase_tolerance == 0.175)\n        self.assertTrue(args.continuity_tempo_tolerance == 0.175)\n        self.assertTrue(args.det_dir is None)\n        self.assertTrue(args.det_suffix == \'.beats.txt\')\n        self.assertTrue(args.double is True)\n        self.assertTrue(args.downbeats is False)\n        self.assertTrue(args.eval == BeatEvaluation)\n        self.assertTrue(args.files == [ANNOTATIONS_PATH, DETECTIONS_PATH])\n        self.assertTrue(args.fmeasure_window == 0.07)\n        self.assertTrue(args.goto_mu == 0.1)\n        self.assertTrue(args.goto_sigma == 0.1)\n        self.assertTrue(args.goto_threshold == 0.175)\n        self.assertTrue(args.ignore_non_existing is False)\n        self.assertTrue(args.information_gain_bins == 40)\n        self.assertTrue(args.mean_eval == BeatMeanEvaluation)\n        self.assertTrue(args.offbeat is True)\n        # self.assertTrue(args.outfile == StringIO.StringIO)\n        from madmom.evaluation import tostring\n        self.assertTrue(args.output_formatter == tostring)\n        self.assertTrue(args.pscore_tolerance == 0.2)\n        self.assertTrue(args.quiet is False)\n        self.assertTrue(args.skip == 0)\n        self.assertTrue(args.sum_eval is None)\n        self.assertTrue(args.triple is True)\n        self.assertTrue(args.verbose == 0)\n'"
tests/test_evaluation_chords.py,18,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.evaluation.chords module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join\n\nfrom madmom.evaluation.chords import *\nfrom . import ANNOTATIONS_PATH, DETECTIONS_PATH\n\nDUMMY_ANNOTATIONS = np.array(\n    [(0.1, 1.0, (9, 0, [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0])),\n     (1.0, 2.0, (5, 0, [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])),\n     (2.0, 3.0, (0, 0, [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])),\n     (3.0, 4.0, (7, 0, [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]))],\n    dtype=CHORD_ANN_DTYPE\n)\n\nDUMMY_DUPL_ANNOTATIONS = np.array(\n    [(0.1, 1.0, (9, 0, [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0])),\n     (1.0, 2.0, (5, 0, [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])),\n     (2.0, 3.0, (5, 0, [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])),\n     (3.0, 4.0, (5, 1, [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]))],\n    dtype=CHORD_ANN_DTYPE\n)\n\nDUMMY_MERGED_DUPL_ANNOTATIONS = np.array(\n    [(0.1, 1.0, (9, 0, [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0])),\n     (1.0, 3.0, (5, 0, [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])),\n     (3.0, 4.0, (5, 1, [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]))],\n    dtype=CHORD_ANN_DTYPE\n)\n\n\nclass TestChordParsing(unittest.TestCase):\n\n    def test_modify(self):\n        self.assertEqual(modify(0, \'b\'), -1)\n        self.assertEqual(modify(0, \'#\'), 1)\n        self.assertEqual(modify(5, \'b\'), 4)\n        self.assertEqual(modify(10, \'#\'), 11)\n        self.assertEqual(modify(0, \'bb\'), -2)\n        self.assertEqual(modify(0, \'###\'), 3)\n        self.assertEqual(modify(5, \'b#\'), 5)\n        self.assertEqual(modify(10, \'#b\'), 10)\n        self.assertEqual(modify(5, \'b#bb#\'), 4)\n        self.assertRaises(ValueError, modify, 0, \'ab#\')\n\n    def test_pitch(self):\n        # test natural pitches\n        for pn, pid in zip(\'CDEFGAB\', [0, 2, 4, 5, 7, 9, 11]):\n            self.assertEqual(pitch(pn), pid)\n\n        # test modifiers\n        self.assertEqual(pitch(\'C#\'), 1)\n        self.assertEqual(pitch(\'Cb\'), 11)\n        self.assertEqual(pitch(\'E#\'), 5)\n        self.assertEqual(pitch(\'Bb\'), 10)\n\n        # test multiple modifiers\n        self.assertEqual(pitch(\'Bbb\'), 9)\n        self.assertEqual(pitch(\'G#b\'), 7)\n        self.assertEqual(pitch(\'Dbb\'), 0)\n\n    def test_interval(self):\n        # test \'natural\' intervals\n        for int_name, int_id in zip([\'{}\'.format(i) for i in range(1, 14)],\n                                    [i % 12 for i in [0, 2, 4, 5, 7, 9, 11, 12,\n                                                      14, 16, 17, 19, 21]]):\n            self.assertEqual(interval(int_name), int_id)\n\n        # test modifiers\n        self.assertEqual(interval(\'b3\'), 3)\n        self.assertEqual(interval(\'#4\'), 6)\n        self.assertEqual(interval(\'b7\'), 10)\n        self.assertEqual(interval(\'#7\'), 0)\n\n        # test multiple modifiers\n        self.assertEqual(interval(\'##1\'), 2)\n        self.assertEqual(interval(\'#b5\'), 7)\n        self.assertEqual(interval(\'b#b6\'), 8)\n\n    def assertIntervalsEqual(self, i1, i2):\n        self.assertTrue((i1 == i2).all())\n\n    def test_interval_list(self):\n        # test interval creation\n        self.assertIntervalsEqual(\n            interval_list(\'(1,3,5)\'),\n            np.array([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]))\n        self.assertIntervalsEqual(\n            interval_list(\'(1,b3,5)\'),\n            np.array([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0]))\n        self.assertIntervalsEqual(\n            interval_list(\'(1,b3,5,b7)\'),\n            np.array([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0]))\n\n        # test interval subtraction\n        self.assertIntervalsEqual(\n            interval_list(\'(*3)\',\n                          np.array([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])),\n            np.array([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]))\n\n        # test interval addition\n        self.assertIntervalsEqual(\n            interval_list(\'(3, b7)\',\n                          np.array([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])),\n            np.array([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]))\n\n    def test_intervals(self):\n        # test some common interval annotations\n        self.assertIntervalsEqual(chord_intervals(\'maj\'),\n                                  interval_list(\'(1,3,5)\'))\n        self.assertIntervalsEqual(chord_intervals(\'min\'),\n                                  interval_list(\'(1,b3,5)\'))\n        self.assertIntervalsEqual(chord_intervals(\'maj7\'),\n                                  interval_list(\'(1,3,5,7)\'))\n\n        # test addition of intervals\n        self.assertIntervalsEqual(chord_intervals(\'maj(7)\'),\n                                  chord_intervals(\'maj7\'))\n        self.assertIntervalsEqual(chord_intervals(\'dim(bb7)\'),\n                                  chord_intervals(\'dim7\'))\n\n        # test removal of intervals\n        self.assertIntervalsEqual(chord_intervals(\'maj9(*9)\'),\n                                  chord_intervals(\'maj7\'))\n        self.assertIntervalsEqual(chord_intervals(\'min7(*b7)\'),\n                                  chord_intervals(\'min\'))\n\n        # test addition and removal of intervals\n        self.assertIntervalsEqual(chord_intervals(\'maj(*3,2)\'),\n                                  chord_intervals(\'sus2\'))\n        self.assertIntervalsEqual(chord_intervals(\'min(*b3,3,7)\'),\n                                  chord_intervals(\'maj7\'))\n\n    def assertChordEqual(self, c1, c2):\n        self.assertEqual(c1[0], c2[0])\n        self.assertEqual(c1[1], c2[1])\n        self.assertIntervalsEqual(c1[2], c2[2])\n\n    def test_chord(self):\n        # pitch explicit, intervals and bass implicit\n        self.assertChordEqual(chord(\'C\'),\n                              (pitch(\'C\'), 0, chord_intervals(\'maj\')))\n        # pitch and bass explicit, intervals implicit\n        self.assertChordEqual(chord(\'G#b/5\'),\n                              (pitch(\'G\'), interval(\'5\'),\n                               chord_intervals(\'maj\')))\n        # pitch and intervals in shorthand explicit, bass implicit\n        self.assertChordEqual(chord(\'Cb:sus4\'), (pitch(\'Cb\'), 0,\n                                                 chord_intervals(\'sus4\')))\n        # pitch and intervals as list explicit, bass implicit\n        self.assertChordEqual(chord(\'F:(1,3,5,9)\'),\n                              (pitch(\'F\'), 0, chord_intervals(\'(1,3,5,9)\')))\n        # pitch and intervals, both shorthand and list, explicit bass implicit\n        self.assertChordEqual(chord(\'Db:min6(*b3)\'),\n                              (pitch(\'Db\'), 0, chord_intervals(\'(1,5,6)\')))\n        # everything explicit\n        self.assertChordEqual(chord(\'A#:minmaj7/b3\'),\n                              (pitch(\'A#\'), interval(\'b3\'),\n                               chord_intervals(\'minmaj7\')))\n        # test no-chord and unknown-chord\n        self.assertChordEqual(chord(\'N\'), NO_CHORD)\n        self.assertChordEqual(chord(\'X\'), UNKNOWN_CHORD)\n\n    def test_chords(self):\n        # test whether the chords() function creates a proper array of\n        # chords\n        labels = [\'F\', \'C:maj\', \'D:(1,b3,5)\', \'Bb:maj7\']\n        for lbl, crd in zip(labels, chords(labels)):\n            self.assertChordEqual(chord(lbl), crd)\n\n    def test_encode_func(self):\n        crds = encode(\n            load_chords(join(ANNOTATIONS_PATH, \'dummy.chords\')))\n        self.assertTrue((crds == DUMMY_ANNOTATIONS).all())\n\n    def test_merge_func(self):\n        merged_chords = merge_chords(DUMMY_DUPL_ANNOTATIONS)\n        self.assertTrue((merged_chords == DUMMY_MERGED_DUPL_ANNOTATIONS).all())\n\n\nclass TestChordEvaluation(unittest.TestCase):\n\n    def setUp(self):\n        self.ann = encode(\n            load_chords(join(ANNOTATIONS_PATH, \'dummy.chords\')))\n        self.unadjusted_det = encode(\n            load_chords(join(DETECTIONS_PATH, \'dummy.chords.txt\')))\n        self.det = adjust(self.unadjusted_det, self.ann)\n        self.ev_ann, self.ev_det, self.ev_dur = evaluation_pairs(self.det,\n                                                                 self.ann)\n\n    def assertIntervalsEqual(self, i1, i2):\n        self.assertTrue((i1 == i2).all())\n\n    def assertChordEqual(self, c1, c2):\n        self.assertEqual(c1[0], c2[0])\n        self.assertEqual(c1[1], c2[1])\n        self.assertIntervalsEqual(c1[2], c2[2])\n\n    def test_adjust(self):\n        self.assertAlmostEqual(self.det[0][\'start\'], self.ann[0][\'start\'])\n        self.assertAlmostEqual(self.det[-1][\'end\'], self.ann[-1][\'end\'])\n        # the last \'N\' chord should have been removed\n        self.assertChordEqual(self.det[-1][\'chord\'], chord(\'G:aug\'))\n\n        det = self.unadjusted_det.copy()\n        # make detections shorter than annotations\n        det = det[:-2]\n        det[0][\'start\'] = 0.5\n        det = adjust(det, self.ann)\n\n        self.assertAlmostEqual(det[0][\'start\'], self.ann[0][\'start\'])\n        self.assertAlmostEqual(det[-1][\'end\'], self.ann[-1][\'end\'])\n        # should have filled up the chord sequence with a no-chord\n        self.assertChordEqual(det[-1][\'chord\'], chord(\'N\'))\n\n    def test_evaluation_pairs(self):\n        true_ev_ann, true_ev_det, true_ev_dur = zip(*[\n            (chord(\'A:min\'), chord(\'N\'), 0.1),\n            (chord(\'A:min\'), chord(\'A:min\'), 0.6),\n            (chord(\'A:min\'), chord(\'A:min7\'), 0.2),\n            (chord(\'F:maj\'), chord(\'F:dim\'), 0.5),\n            (chord(\'F:maj\'), chord(\'F:maj\'), 0.5),\n            (chord(\'C:maj\'), chord(\'F:maj\'), 0.2),\n            (chord(\'C:maj\'), chord(\'C:maj/3\'), 0.7),\n            (chord(\'C:maj\'), chord(\'G:maj7/7\'), 0.1),\n            (chord(\'G:maj\'), chord(\'G:maj7/7\'), 0.5),\n            (chord(\'G:maj\'), chord(\'G:aug\'), 0.5),\n        ])\n        true_ev_ann = np.array(list(true_ev_ann), dtype=CHORD_DTYPE)\n        true_ev_det = np.array(list(true_ev_det), dtype=CHORD_DTYPE)\n        true_ev_dur = np.array(list(true_ev_dur))\n\n        self.assertTrue((self.ev_ann == true_ev_ann).all())\n        self.assertTrue((self.ev_det == true_ev_det).all())\n        self.assertTrue(np.allclose(self.ev_dur, true_ev_dur))\n\n    def test_score_root(self):\n        score = score_root(self.ev_det, self.ev_ann)\n        self.assertTrue(np.allclose(score, np.array([\n            0., 1., 1., 1., 1., 0., 1., 0., 1., 1.\n        ])))\n\n    def test_score_exact(self):\n        score = score_exact(self.ev_det, self.ev_ann)\n        self.assertTrue(np.allclose(score, np.array([\n            0., 1., 0., 0., 1., 0., 0., 0., 0., 0.\n        ])))\n\n    def test_select_majmin(self):\n        # normally, you would not apply this function to the detected\n        # evaluation  pairs - see evaluation.chords for correct usage.\n        # However, ev_det contains a good variety of chords, so let\'s use it\n        sel = select_majmin(self.ev_det)\n        self.assertTrue((sel == np.array([True, True, False, False, True, True,\n                                          True, False, False, False])).all())\n\n    def test_select_sevenths(self):\n        sel = select_sevenths(self.ev_det)\n        self.assertTrue((sel == np.array([True, True, True, False, True, True,\n                                          True, True, True, False])).all())\n\n    def test_segmentation(self):\n        self.assertAlmostEqual(\n            segmentation(self.ann[\'start\'], self.ann[\'end\'],\n                         self.det[\'start\'], self.det[\'end\']),\n            0.41025641025641025641)\n        self.assertAlmostEqual(\n            segmentation(self.det[\'start\'], self.det[\'end\'],\n                         self.ann[\'start\'], self.ann[\'end\']),\n            0.07692307692307692308)\n\n    def test_reduce_to_triads(self):\n        true_red_wo_bass = chords([\'N\', \'A:min\', \'A:min\', \'F:dim\', \'F:maj\',\n                                   \'C:maj\', \'G:maj\', \'G:aug\'])\n        reduced_wo_bass = reduce_to_triads(self.det[\'chord\'], keep_bass=False)\n        self.assertTrue((reduced_wo_bass == true_red_wo_bass).all())\n\n        true_red_w_bass = chords([\'N\', \'A:min\', \'A:min\', \'F:dim\', \'F:maj\',\n                                  \'C:maj/3\', \'G:maj\', \'G:aug\'])\n        reduced_w_bass = reduce_to_triads(self.det[\'chord\'], keep_bass=True)\n        self.assertTrue((reduced_w_bass == true_red_w_bass).all())\n\n        # test some further mappings\n        src = chords([\'A:hdim7\', \'B:min6/5\', \'C:sus4/4\', \'G:(1,5,b7)\'])\n        trg = chords([\'A:dim\', \'B:min/5\', \'C:sus4/4\', \'G:(1,5)\'])\n        self.assertTrue((reduce_to_triads(src, keep_bass=True) == trg).all())\n\n    def test_reduce_to_tetrads(self):\n        true_red_wo_bass = chords([\'N\', \'A:min\', \'A:min7\', \'F:dim\', \'F:maj\',\n                                   \'C:maj\', \'G:maj7\', \'G:aug\'])\n        reduced_wo_bass = reduce_to_tetrads(self.det[\'chord\'], keep_bass=False)\n        self.assertTrue((reduced_wo_bass == true_red_wo_bass).all())\n\n        reduced_w_bass = reduce_to_tetrads(self.det[\'chord\'], keep_bass=True)\n        self.assertTrue((reduced_w_bass == self.det[\'chord\']).all())\n\n        # test some further mappings\n        src = chords([\'A:maj9\', \'Cb:9\', \'E:min9/9\', \'E:min9/b7\'])\n        trg = chords([\'A:maj7\', \'Cb:7\', \'E:min7\', \'E:min7/b7\'])\n        self.assertTrue((reduce_to_tetrads(src, keep_bass=True) == trg).all())\n\n\nclass TestChordEvaluationClass(unittest.TestCase):\n\n    def test_init(self):\n        eval = ChordEvaluation(\n            load_chords(join(DETECTIONS_PATH, \'dummy.chords.txt\')),\n            load_chords(join(ANNOTATIONS_PATH, \'dummy.chords\')),\n            name=\'TestEval\'\n        )\n        self.assertTrue(eval.name == \'TestEval\')\n        ann = encode(\n            load_chords(join(ANNOTATIONS_PATH, \'dummy.chords\')))\n        det = encode(\n            load_chords(join(DETECTIONS_PATH, \'dummy.chords.txt\')))\n        det = adjust(det, ann)\n        self.assertTrue((eval.ann_chords == ann).all())\n        self.assertTrue((eval.det_chords == det).all())\n        ann, det, dur = evaluation_pairs(eval.det_chords, eval.ann_chords)\n        self.assertTrue((ann == eval.annotations).all())\n        self.assertTrue((det == eval.detections).all())\n        self.assertTrue((dur == eval.durations).all())\n\n    def test_results(self):\n        eval = ChordEvaluation(\n            load_chords(join(DETECTIONS_PATH, \'dummy.chords.txt\')),\n            load_chords(join(ANNOTATIONS_PATH, \'dummy.chords\')),\n            name=\'TestEval\'\n        )\n        self.assertAlmostEqual(eval.length, 3.9)\n        self.assertAlmostEqual(eval.root, 0.8974358974358975)\n        self.assertAlmostEqual(eval.majmin, 0.6410256410256411)\n        self.assertAlmostEqual(eval.majminbass, 0.46153846153846156)\n        self.assertAlmostEqual(eval.sevenths, 0.46153846153846156)\n        self.assertAlmostEqual(eval.seventhsbass, 0.2820512820512821)\n        self.assertAlmostEqual(eval.undersegmentation,\n                               1. - 0.07692307692307692308)\n        self.assertAlmostEqual(eval.oversegmentation,\n                               1. - 0.41025641025641025641)\n        self.assertAlmostEqual(eval.segmentation,\n                               1. - 0.41025641025641025641)\n\n\nclass TestAggregateChordEvaluation(unittest.TestCase):\n\n    def setUp(self):\n        # this one should have a score of 1 everywhere and length 4.3\n        self.eval1 = ChordEvaluation(\n            load_chords(join(DETECTIONS_PATH, \'dummy.chords.txt\')),\n            load_chords(join(DETECTIONS_PATH, \'dummy.chords.txt\')),\n            name=\'TestEval\'\n        )\n        self.eval2 = ChordEvaluation(\n            load_chords(join(DETECTIONS_PATH, \'dummy.chords.txt\')),\n            load_chords(join(ANNOTATIONS_PATH, \'dummy.chords\')),\n            name=\'TestEval\'\n        )\n\n    def test_mean_results(self):\n        mean_eval = ChordMeanEvaluation([self.eval1, self.eval2])\n        self.assertAlmostEqual(mean_eval.root, 0.9487179487179487)\n        self.assertAlmostEqual(mean_eval.majmin, 0.8205128205128205)\n        self.assertAlmostEqual(mean_eval.majminbass, 0.7307692307692308)\n        self.assertAlmostEqual(mean_eval.sevenths, 0.7307692307692308)\n        self.assertAlmostEqual(mean_eval.seventhsbass, 0.6410256410256411)\n        self.assertAlmostEqual(mean_eval.undersegmentation, 0.9615384615384616)\n        self.assertAlmostEqual(mean_eval.oversegmentation, 0.7948717948717949)\n        self.assertAlmostEqual(mean_eval.segmentation, 0.7948717948717949)\n\n    def test_sum_results(self):\n        sum_eval = ChordSumEvaluation([self.eval1, self.eval2])\n        self.assertAlmostEqual(sum_eval.root, 0.951219512195122)\n        self.assertAlmostEqual(sum_eval.majmin, 0.8028169014084507)\n        self.assertAlmostEqual(sum_eval.majminbass, 0.7042253521126761)\n        self.assertAlmostEqual(sum_eval.sevenths, 0.7042253521126761)\n        self.assertAlmostEqual(sum_eval.seventhsbass, 0.6056338028169015)\n        self.assertAlmostEqual(sum_eval.undersegmentation, 0.9634146341463415)\n        self.assertAlmostEqual(sum_eval.oversegmentation, 0.8048780487804879)\n        self.assertAlmostEqual(sum_eval.segmentation, 0.8048780487804879)\n\n\nclass TestAddParserFunction(unittest.TestCase):\n\n    def setUp(self):\n        import argparse\n        self.parser = argparse.ArgumentParser()\n        sub_parser = self.parser.add_subparsers()\n        self.sub_parser = add_parser(sub_parser)\n\n    def test_args(self):\n        args = self.parser.parse_args([\'chords\', ANNOTATIONS_PATH,\n                                       DETECTIONS_PATH])\n        self.assertTrue(args.ann_dir is None)\n        self.assertTrue(args.ann_suffix == \'.chords\')\n        self.assertTrue(args.det_dir is None)\n        self.assertTrue(args.det_suffix == \'.chords.txt\')\n        self.assertTrue(args.eval == ChordEvaluation)\n        self.assertTrue(args.files == [ANNOTATIONS_PATH, DETECTIONS_PATH])\n        self.assertTrue(args.mean_eval == ChordMeanEvaluation)\n        self.assertTrue(args.sum_eval == ChordSumEvaluation)\n        from madmom.evaluation import tostring\n        self.assertTrue(args.output_formatter == tostring)\n'"
tests/test_evaluation_key.py,0,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.evaluation.key module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join\n\nfrom madmom.evaluation.key import *\nfrom . import ANNOTATIONS_PATH, DETECTIONS_PATH\n\n\nclass TestKeyLabelToClassFunction(unittest.TestCase):\n\n    def test_illegal_label(self):\n        with self.assertRaises(ValueError):\n            key_label_to_class(\'Z major\')\n        with self.assertRaises(ValueError):\n            key_label_to_class(\'D mixolydian\')\n        with self.assertRaises(ValueError):\n            key_label_to_class(\'wrongannoation\')\n        with self.assertRaises(ValueError):\n            key_label_to_class(\'C:maj\')\n\n    def test_values(self):\n        self.assertEqual(key_label_to_class(\'C major\'), 0)\n        self.assertEqual(key_label_to_class(\'C# major\'), 1)\n        self.assertEqual(key_label_to_class(\'D major\'), 2)\n        self.assertEqual(key_label_to_class(\'D# major\'), 3)\n        self.assertEqual(key_label_to_class(\'E major\'), 4)\n        self.assertEqual(key_label_to_class(\'F major\'), 5)\n        self.assertEqual(key_label_to_class(\'F# major\'), 6)\n        self.assertEqual(key_label_to_class(\'G major\'), 7)\n        self.assertEqual(key_label_to_class(\'G# major\'), 8)\n        self.assertEqual(key_label_to_class(\'A major\'), 9)\n        self.assertEqual(key_label_to_class(\'A# major\'), 10)\n        self.assertEqual(key_label_to_class(\'B major\'), 11)\n        self.assertEqual(key_label_to_class(\'C minor\'), 0 + 12)\n        self.assertEqual(key_label_to_class(\'C# minor\'), 1 + 12)\n        self.assertEqual(key_label_to_class(\'D minor\'), 2 + 12)\n        self.assertEqual(key_label_to_class(\'D# minor\'), 3 + 12)\n        self.assertEqual(key_label_to_class(\'E minor\'), 4 + 12)\n        self.assertEqual(key_label_to_class(\'F minor\'), 5 + 12)\n        self.assertEqual(key_label_to_class(\'F# minor\'), 6 + 12)\n        self.assertEqual(key_label_to_class(\'G minor\'), 7 + 12)\n        self.assertEqual(key_label_to_class(\'G# minor\'), 8 + 12)\n        self.assertEqual(key_label_to_class(\'A minor\'), 9 + 12)\n        self.assertEqual(key_label_to_class(\'A# minor\'), 10 + 12)\n        self.assertEqual(key_label_to_class(\'B minor\'), 11 + 12)\n        self.assertEqual(key_label_to_class(\'C major\'),\n                         key_label_to_class(\'C maj\'))\n        self.assertEqual(key_label_to_class(\'F minor\'),\n                         key_label_to_class(\'F min\'))\n        self.assertEqual(key_label_to_class(\'gb maj\'),\n                         key_label_to_class(\'F# major\'))\n\n\nclass TestErrorTypeFunction(unittest.TestCase):\n\n    def _compare_scores(self, correct, fifth_strict, fifth_lax, relative,\n                        parallel):\n        for det_key in range(24):\n            score, cat = error_type(det_key, correct)\n            score_st, cat_st = error_type(det_key, correct, strict_fifth=True)\n            if det_key == correct:\n                self.assertEqual(cat, \'correct\')\n                self.assertEqual(score, 1.0)\n                self.assertEqual(cat_st, cat)\n                self.assertEqual(score_st, score)\n            if det_key == fifth_strict:\n                self.assertEqual(cat, \'fifth\')\n                self.assertEqual(score, 0.5)\n                self.assertEqual(cat_st, cat)\n                self.assertEqual(score_st, score)\n            if det_key == fifth_lax:\n                self.assertEqual(cat, \'fifth\')\n                self.assertEqual(score, 0.5)\n                self.assertEqual(cat_st, \'other\')\n                self.assertEqual(score_st, 0.0)\n            if det_key == relative:\n                self.assertEqual(cat, \'relative\')\n                self.assertEqual(score, 0.3)\n                self.assertEqual(cat_st, cat)\n                self.assertEqual(score_st, score)\n            if det_key == parallel:\n                self.assertEqual(cat, \'parallel\')\n                self.assertEqual(score, 0.2)\n                self.assertEqual(cat_st, cat)\n                self.assertEqual(score_st, score)\n\n    def test_values(self):\n        self._compare_scores(\n            correct=key_label_to_class(\'c maj\'),\n            fifth_strict=key_label_to_class(\'g maj\'),\n            fifth_lax=key_label_to_class(\'f maj\'),\n            relative=key_label_to_class(\'a min\'),\n            parallel=key_label_to_class(\'c min\')\n        )\n\n        self._compare_scores(\n            correct=key_label_to_class(\'eb maj\'),\n            fifth_strict=key_label_to_class(\'bb maj\'),\n            fifth_lax=key_label_to_class(\'ab maj\'),\n            relative=key_label_to_class(\'c min\'),\n            parallel=key_label_to_class(\'eb min\')\n        )\n\n        self._compare_scores(\n            correct=key_label_to_class(\'a min\'),\n            fifth_strict=key_label_to_class(\'e min\'),\n            fifth_lax=key_label_to_class(\'d min\'),\n            relative=key_label_to_class(\'c maj\'),\n            parallel=key_label_to_class(\'a maj\')\n        )\n\n        self._compare_scores(\n            correct=key_label_to_class(\'b min\'),\n            fifth_strict=key_label_to_class(\'gb min\'),\n            fifth_lax=key_label_to_class(\'e min\'),\n            relative=key_label_to_class(\'d maj\'),\n            parallel=key_label_to_class(\'b maj\')\n        )\n\n\nclass TestKeyEvaluationClass(unittest.TestCase):\n\n    def setUp(self):\n        self.eval = KeyEvaluation(\n            load_key(join(DETECTIONS_PATH, \'dummy.key.txt\')),\n            load_key(join(ANNOTATIONS_PATH, \'dummy.key\')),\n            name=\'TestEval\'\n        )\n\n    def test_init(self):\n        self.assertTrue(self.eval.name == \'TestEval\')\n        self.assertTrue(self.eval.detection, 9)\n        self.assertTrue(self.eval.annotation, 18)\n\n    def test_results(self):\n        self.assertEqual(self.eval.error_category, \'relative\')\n        self.assertEqual(self.eval.score, 0.3)\n\n\nclass TestKeyMeanEvaluation(unittest.TestCase):\n\n    def setUp(self):\n        # this one should have a score of 1\n        self.eval1 = KeyEvaluation(\n            load_key(join(DETECTIONS_PATH, \'dummy.key.txt\')),\n            load_key(join(DETECTIONS_PATH, \'dummy.key.txt\')),\n            name=\'eval1\'\n        )\n        # this one should have a score of 0.3\n        self.eval2 = KeyEvaluation(\n            load_key(join(DETECTIONS_PATH, \'dummy.key.txt\')),\n            load_key(join(ANNOTATIONS_PATH, \'dummy.key\')),\n            name=\'eval2\'\n        )\n\n    def test_mean_results(self):\n        mean_eval = KeyMeanEvaluation([self.eval1, self.eval2])\n        self.assertAlmostEqual(mean_eval.correct, 0.5)\n        self.assertAlmostEqual(mean_eval.fifth, 0.)\n        self.assertAlmostEqual(mean_eval.relative, 0.5)\n        self.assertAlmostEqual(mean_eval.parallel, 0.0)\n        self.assertAlmostEqual(mean_eval.other, 0.0)\n        self.assertAlmostEqual(mean_eval.weighted, 0.65)\n\n\nclass TestAddParserFunction(unittest.TestCase):\n\n    def setUp(self):\n        import argparse\n        self.parser = argparse.ArgumentParser()\n        sub_parser = self.parser.add_subparsers()\n        self.sub_parser = add_parser(sub_parser)\n\n    def test_args(self):\n        args = self.parser.parse_args([\'key\', ANNOTATIONS_PATH,\n                                       DETECTIONS_PATH])\n        self.assertTrue(args.ann_dir is None)\n        self.assertTrue(args.ann_suffix == \'.key\')\n        self.assertTrue(args.det_dir is None)\n        self.assertTrue(args.det_suffix == \'.key.txt\')\n        self.assertTrue(args.eval == KeyEvaluation)\n        self.assertTrue(args.files == [ANNOTATIONS_PATH, DETECTIONS_PATH])\n        self.assertTrue(args.mean_eval == KeyMeanEvaluation)\n        self.assertTrue(args.sum_eval is None)\n        from madmom.evaluation import tostring\n        self.assertTrue(args.output_formatter == tostring)\n'"
tests/test_evaluation_notes.py,90,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.evaluation.notes module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport math\nimport unittest\n\nfrom madmom.evaluation.notes import *\nfrom . import ANNOTATIONS_PATH, DETECTIONS_PATH\n\nDETECTIONS = np.asarray([[0.147, 72],  # TP\n                         [0.147, 80],  # FP\n                         [0.147, 60],  # FP, octave error\n                         #  [1.567, 41], FN\n                         [2.540, 77],  # 14ms too late\n                         [2.520, 60],  # 29ms too early\n                         #  [2.563, 65], FN\n                         #  [2.577, 57], FN + FP, 1 note off\n                         [3.368, 75],  # 1ms too early\n                         [3.449, 43]])\nANNOTATIONS = np.asarray([[0.147, 72, 3.323, 63],\n                          [1.567, 41, 0.223, 29],\n                          [2.526, 77, 0.930, 72],\n                          [2.549, 60, 0.211, 28],\n                          [2.563, 65, 0.202, 34],\n                          [2.577, 56, 0.234, 31],\n                          [3.369, 75, 0.780, 64],\n                          [3.449, 43, 0.272, 35]])\n\n\n# test functions\nclass TestRemoveDuplicateNotesFunction(unittest.TestCase):\n\n    def test_types(self):\n        notes = remove_duplicate_notes(ANNOTATIONS)\n        self.assertIsInstance(notes, np.ndarray)\n\n    def test_results(self):\n        ann = np.vstack((ANNOTATIONS, ANNOTATIONS[2]))\n        notes = remove_duplicate_notes(ann)\n        self.assertTrue(np.allclose(notes, ANNOTATIONS))\n\n\nclass TestNoteConstantsClass(unittest.TestCase):\n\n    def test_types(self):\n        self.assertIsInstance(WINDOW, float)\n\n    def test_values(self):\n        self.assertEqual(WINDOW, 0.025)\n\n\nclass TestNoteOnsetEvaluationFunction(unittest.TestCase):\n\n    def test_types(self):\n        tp, fp, tn, fn, errors = note_onset_evaluation(DETECTIONS, ANNOTATIONS,\n                                                       0.025)\n        self.assertIsInstance(tp, np.ndarray)\n        self.assertIsInstance(fp, np.ndarray)\n        self.assertIsInstance(tn, np.ndarray)\n        self.assertIsInstance(fn, np.ndarray)\n        self.assertIsInstance(errors, np.ndarray)\n        tp, fp, tn, fn, errors = note_onset_evaluation([[]], [[]], 0.025)\n        self.assertIsInstance(tp, np.ndarray)\n        self.assertIsInstance(fp, np.ndarray)\n        self.assertIsInstance(tn, np.ndarray)\n        self.assertIsInstance(fn, np.ndarray)\n        self.assertIsInstance(errors, np.ndarray)\n        with self.assertRaises(ValueError):\n            note_onset_evaluation([], [], 0.025)\n\n    def test_results(self):\n        # empty detections and annotations\n        tp, fp, tn, fn, errors = note_onset_evaluation([[]], [[]], 0.02)\n        self.assertTrue(np.allclose(tp, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(fp, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(tn, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(fn, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(errors, np.zeros((0, 2))))\n        # empty annotations\n        tp, fp, tn, fn, errors = note_onset_evaluation(DETECTIONS, [[]], 0.02)\n        self.assertTrue(np.allclose(tp, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(fp, DETECTIONS))\n        self.assertTrue(np.allclose(tn, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(fn, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(errors, np.zeros((0, 2))))\n        # empty detections\n        tp, fp, tn, fn, errors = note_onset_evaluation([[]], ANNOTATIONS, 0.02)\n        self.assertTrue(np.allclose(tp, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(fp, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(tn, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(fn, ANNOTATIONS))\n        self.assertTrue(np.allclose(errors, np.zeros((0, 2))))\n        # window = 0.01\n        tp, fp, tn, fn, errors = note_onset_evaluation(DETECTIONS, ANNOTATIONS,\n                                                       0.01)\n        self.assertTrue(np.allclose(tp, [[0.147, 72], [3.368, 75],\n                                         [3.449, 43]]))\n        self.assertTrue(np.allclose(fp, [[0.147, 60], [0.147, 80],\n                                         [2.520, 60], [2.540, 77]]))\n        self.assertTrue(np.allclose(tn, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(fn, [[1.567, 41], [2.526, 77], [2.549, 60],\n                                         [2.563, 65], [2.577, 56]]))\n        self.assertTrue(np.allclose(errors, [[0, 72], [-0.001, 75], [0, 43]]))\n        # default window (= 0.025)\n        tp, fp, tn, fn, errors = note_onset_evaluation(DETECTIONS, ANNOTATIONS)\n        self.assertTrue(np.allclose(tp, [[0.147, 72], [2.540, 77],\n                                         [3.368, 75], [3.449, 43]]))\n        self.assertTrue(np.allclose(fp, [[0.147, 60], [0.147, 80],\n                                         [2.520, 60]]))\n        self.assertTrue(np.allclose(tn, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(fn, [[1.567, 41], [2.549, 60],\n                                         [2.563, 65], [2.577, 56]]))\n        self.assertTrue(np.allclose(errors, [[0, 72], [0.014, 77],\n                                             [-0.001, 75], [0, 43]]))\n        # window = 0.03\n        tp, fp, tn, fn, errors = note_onset_evaluation(DETECTIONS, ANNOTATIONS,\n                                                       0.03)\n        self.assertTrue(np.allclose(tp, [[0.147, 72], [2.520, 60], [2.540, 77],\n                                         [3.368, 75], [3.449, 43]]))\n        self.assertTrue(np.allclose(fp, [[0.147, 60], [0.147, 80]]))\n        self.assertTrue(np.allclose(tn, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(fn, [[1.567, 41], [2.563, 65],\n                                         [2.577, 56]]))\n        self.assertTrue(np.allclose(errors, [[0, 72], [-0.029, 60],\n                                             [0.014, 77], [-0.001, 75],\n                                             [0, 43]]))\n\n\n# test evaluation class\nclass TestNoteEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = NoteEvaluation(DETECTIONS, ANNOTATIONS)\n        self.assertIsInstance(e.num_tp, int)\n        self.assertIsInstance(e.num_fp, int)\n        self.assertIsInstance(e.num_tn, int)\n        self.assertIsInstance(e.num_fn, int)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.accuracy, float)\n        self.assertIsInstance(e.errors, np.ndarray)\n        self.assertIsInstance(e.mean_error, float)\n        self.assertIsInstance(e.std_error, float)\n\n    def test_conversion(self):\n        # conversion from list of lists should work\n        e = NoteEvaluation([[0, 0]], [[0, 0]])\n        self.assertIsInstance(e.tp, np.ndarray)\n        self.assertIsInstance(e.fp, np.ndarray)\n        self.assertIsInstance(e.tn, np.ndarray)\n        self.assertIsInstance(e.fn, np.ndarray)\n\n    def test_results(self):\n        # empty detections / annotations\n        e = NoteEvaluation([[]], [[]])\n        self.assertTrue(np.allclose(e.tp, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(e.fp, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(e.tn, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(e.fn, np.zeros((0, 2))))\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertTrue(np.allclose(e.errors, np.zeros((0, 2))))\n        self.assertTrue(math.isnan(e.mean_error))\n        self.assertTrue(math.isnan(e.std_error))\n\n        # real detections / annotations\n        e = NoteEvaluation(DETECTIONS, ANNOTATIONS)\n        self.assertTrue(np.allclose(e.tp, [[0.147, 72], [2.540, 77],\n                                           [3.368, 75], [3.449, 43]]))\n        self.assertTrue(np.allclose(e.fp, [[0.147, 60], [0.147, 80],\n                                           [2.520, 60]]))\n        self.assertTrue(np.allclose(e.tn, np.zeros((0, 2))))\n        self.assertTrue(np.allclose(e.fn, [[1.567, 41], [2.549, 60],\n                                           [2.563, 65], [2.577, 56]]))\n        self.assertEqual(e.num_tp, 4)\n        self.assertEqual(e.num_fp, 3)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 4)\n        self.assertEqual(e.precision, 4. / 7.)\n        self.assertEqual(e.recall, 4. / 8.)\n        f = 2 * (4. / 7.) * (4. / 8.) / ((4. / 7.) + (4. / 8.))\n        self.assertEqual(e.fmeasure, f)\n        self.assertEqual(e.accuracy, (4. + 0) / (4 + 3 + 0 + 4))\n        # errors\n        # tp =  [[0.147, 72], [2.540, 77], [3.368, 75], [3.449, 43]]\n        # ann = [[0.147, 72], [2.526, 77], [3.369, 75], [3.449, 43]]\n        # err = [[0.   , 72], [0.014, 77], [-0.001, 75], [0.   , 43]]\n        errors = np.asarray([[0., 72], [0.014, 77], [-0.001, 75], [0., 43]])\n        self.assertTrue(np.allclose(e.errors, errors))\n        self.assertTrue(np.allclose(e.mean_error,\n                                    np.mean([0, 0.014, -0.001, 0])))\n        self.assertTrue(np.allclose(e.std_error,\n                                    np.std([0, 0.014, -0.001, 0])))\n\n    def test_tostring(self):\n        print(NoteEvaluation([], []))\n\n\nclass TestNoteSumEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = NoteSumEvaluation([])\n        self.assertIsInstance(e.num_tp, int)\n        self.assertIsInstance(e.num_fp, int)\n        self.assertIsInstance(e.num_tn, int)\n        self.assertIsInstance(e.num_fn, int)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.accuracy, float)\n        self.assertIsInstance(e.errors, np.ndarray)\n        self.assertIsInstance(e.mean_error, float)\n        self.assertIsInstance(e.std_error, float)\n\n    def test_results(self):\n        # empty sum evaluation\n        e = NoteSumEvaluation([])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertTrue(np.allclose(e.errors, np.zeros((0, 2))))\n        self.assertTrue(math.isnan(e.mean_error))\n        self.assertTrue(math.isnan(e.std_error))\n        # sum evaluation of empty note evaluation\n        e1 = NoteEvaluation([], [])\n        e = NoteSumEvaluation([e1])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertTrue(np.allclose(e.errors, np.zeros((0, 2))))\n        self.assertTrue(math.isnan(e.mean_error))\n        self.assertTrue(math.isnan(e.std_error))\n        # sum evaluation of empty and real onset evaluation\n        e2 = NoteEvaluation(DETECTIONS, ANNOTATIONS)\n        e = NoteSumEvaluation([e1, e2])\n        # everything must be the same as e2, since e1 was empty and thus did\n        # not ad anything to the sum evaluation\n        self.assertEqual(e.num_tp, e2.num_tp)\n        self.assertEqual(e.num_fp, e2.num_fp)\n        self.assertEqual(e.num_tn, e2.num_tn)\n        self.assertEqual(e.num_fn, e2.num_fn)\n        self.assertEqual(e.precision, e2.precision)\n        self.assertEqual(e.recall, e2.recall)\n        self.assertEqual(e.fmeasure, e2.fmeasure)\n        self.assertEqual(e.accuracy, e2.accuracy)\n        self.assertTrue(np.allclose(e.errors, e2.errors))\n        self.assertEqual(e.mean_error, e2.mean_error)\n        self.assertEqual(e.std_error, e2.std_error)\n\n    def test_tostring(self):\n        print(NoteSumEvaluation([]))\n\n\nclass TestNoteMeanEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = NoteMeanEvaluation([])\n        self.assertIsInstance(e.num_tp, float)\n        self.assertIsInstance(e.num_fp, float)\n        self.assertIsInstance(e.num_tn, float)\n        self.assertIsInstance(e.num_fn, float)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.accuracy, float)\n        self.assertIsInstance(e.errors, np.ndarray)\n        self.assertIsInstance(e.mean_error, float)\n        self.assertIsInstance(e.std_error, float)\n\n    def test_results(self):\n        # empty mean evaluation\n        e = NoteMeanEvaluation([])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertTrue(math.isnan(e.precision))\n        self.assertTrue(math.isnan(e.recall))\n        self.assertTrue(math.isnan(e.fmeasure))\n        self.assertTrue(math.isnan(e.accuracy))\n        self.assertTrue(np.allclose(e.errors, np.zeros((0, 2))))\n        self.assertTrue(math.isnan(e.mean_error))\n        self.assertTrue(math.isnan(e.std_error))\n\n        # mean evaluation of empty note evaluation\n        e1 = NoteEvaluation([], [])\n        e = NoteMeanEvaluation([e1])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertTrue(np.allclose(e.errors, np.zeros((0, 2))))\n        self.assertTrue(math.isnan(e.mean_error))\n        self.assertTrue(math.isnan(e.std_error))\n\n        # mean evaluation of empty and real note evaluation\n        e2 = NoteEvaluation(DETECTIONS, ANNOTATIONS)\n        e = NoteMeanEvaluation([e1, e2])\n        self.assertTrue(np.allclose(\n            e.num_tp, np.mean([e_.num_tp for e_ in [e1, e2]])))\n        self.assertTrue(np.allclose(\n            e.num_fp, np.mean([e_.num_fp for e_ in [e1, e2]])))\n        self.assertTrue(np.allclose(\n            e.num_tn, np.mean([e_.num_tn for e_ in [e1, e2]])))\n        self.assertTrue(np.allclose(\n            e.num_fn, np.mean([e_.num_fn for e_ in [e1, e2]])))\n        self.assertTrue(np.allclose(\n            e.precision, np.mean([e_.precision for e_ in [e1, e2]])))\n        self.assertTrue(np.allclose(\n            e.recall, np.mean([e_.recall for e_ in [e1, e2]])))\n        self.assertTrue(np.allclose(\n            e.fmeasure, np.mean([e_.fmeasure for e_ in [e1, e2]])))\n        self.assertTrue(np.allclose(\n            e.accuracy, np.mean([e_.accuracy for e_ in [e1, e2]])))\n        self.assertTrue(np.allclose(\n            e.errors, np.concatenate([e_.errors for e_ in [e1, e2]])))\n        # mean and std errors are those of e2, since those of e1 are NaN\n        self.assertEqual(e.mean_error, e2.mean_error)\n        self.assertEqual(e.std_error, e2.std_error)\n\n    def test_tostring(self):\n        print(NoteMeanEvaluation([]))\n\n\nclass TestAddParserFunction(unittest.TestCase):\n\n    def setUp(self):\n        import argparse\n        self.parser = argparse.ArgumentParser()\n        sub_parser = self.parser.add_subparsers()\n        self.sub_parser, self.group = add_parser(sub_parser)\n\n    def test_args(self):\n        args = self.parser.parse_args([\'notes\', ANNOTATIONS_PATH,\n                                       DETECTIONS_PATH])\n        self.assertTrue(args.ann_dir is None)\n        self.assertTrue(args.ann_suffix == \'.notes\')\n        self.assertTrue(args.det_dir is None)\n        self.assertTrue(args.det_suffix == \'.notes.txt\')\n        self.assertTrue(args.eval == NoteEvaluation)\n        self.assertTrue(args.files == [ANNOTATIONS_PATH, DETECTIONS_PATH])\n        self.assertTrue(args.ignore_non_existing is False)\n        self.assertTrue(args.mean_eval == NoteMeanEvaluation)\n        # self.assertTrue(args.outfile == StringIO.StringIO)\n        from madmom.evaluation import tostring\n        self.assertTrue(args.output_formatter == tostring)\n        self.assertTrue(args.quiet is False)\n        self.assertTrue(args.sum_eval == NoteSumEvaluation)\n        self.assertTrue(args.verbose == 0)\n        self.assertTrue(args.window == 0.025)\n'"
tests/test_evaluation_onsets.py,66,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.evaluation.onsets module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport math\nimport unittest\n\nfrom madmom.evaluation.onsets import *\nfrom . import ANNOTATIONS_PATH, DETECTIONS_PATH\n\n# dummy detections/annotations\nDETECTIONS = [0.99999999, 1.02999999, 1.45, 2.01, 2.02, 2.5, 3.025000001]\nANNOTATIONS = [1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3]\n# real detections/annotations\nSAMPLE_DETECTIONS = [0.01, 0.085, 0.275, 0.445, 0.61, 0.795, 0.98, 1.115,\n                     1.365, 1.475, 1.62, 1.795, 2.14, 2.33, 2.485, 2.665]\nSAMPLE_ANNOTATIONS = [0.0943, 0.2844, 0.4528, 0.6160, 0.7630, 0.8025, 0.9847,\n                      1.1233, 1.4820, 1.6276, 1.8032, 2.1486, 2.3351, 2.4918,\n                      2.6710]\n\n\n# loading function\nclass TestOnsetConstantsClass(unittest.TestCase):\n\n    def test_types(self):\n        self.assertIsInstance(WINDOW, float)\n\n    def test_values(self):\n        self.assertEqual(WINDOW, 0.025)\n\n\n# test evaluation function\nclass TestOnsetEvaluationFunction(unittest.TestCase):\n\n    def test_errors(self):\n        # detections / annotations must not be None\n        with self.assertRaises(TypeError):\n            onset_evaluation(None, ANNOTATIONS)\n        with self.assertRaises(TypeError):\n            onset_evaluation(DETECTIONS, None)\n        # tolerance must be > 0\n        with self.assertRaises(ValueError):\n            onset_evaluation(DETECTIONS, ANNOTATIONS, 0)\n        # tolerance must be correct type\n        with self.assertRaises(TypeError):\n            onset_evaluation(DETECTIONS, ANNOTATIONS, None)\n        with self.assertRaises(TypeError):\n            onset_evaluation(DETECTIONS, ANNOTATIONS, [])\n        with self.assertRaises(TypeError):\n            onset_evaluation(DETECTIONS, ANNOTATIONS, {})\n\n    def test_results(self):\n        # default window\n        tp, fp, tn, fn, errors = onset_evaluation(DETECTIONS, ANNOTATIONS)\n        self.assertTrue(np.allclose(tp, [0.999999, 1.029999, 2.01, 2.02, 2.5]))\n        self.assertTrue(np.allclose(fp, [1.45, 3.025000001]))\n        self.assertTrue(np.allclose(tn, []))\n        self.assertTrue(np.allclose(fn, [1.5, 2.05, 3.0]))\n        self.assertTrue(np.allclose(errors, [-0.00000001, 0.00999999, 0.01,\n                                             -0.01, 0]))\n        # window = 0.01\n        tp, fp, tn, fn, errors = onset_evaluation(DETECTIONS, ANNOTATIONS,\n                                                  window=0.01)\n        self.assertTrue(np.allclose(tp, [0.999999, 1.029999, 2.01, 2.02, 2.5]))\n        self.assertTrue(np.allclose(fp, [1.45, 3.025000001]))\n        self.assertTrue(np.allclose(tn, []))\n        self.assertTrue(np.allclose(fn, [1.5, 2.05, 3.0]))\n        self.assertTrue(np.allclose(errors, [-0.00000001, 0.00999999, 0.01,\n                                             -0.01, 0]))\n        # window = 0.04\n        tp, fp, tn, fn, errors = onset_evaluation(DETECTIONS, ANNOTATIONS,\n                                                  window=0.04)\n        self.assertTrue(np.allclose(tp, [0.999999, 1.029999, 2.01, 2.02, 2.5,\n                                         3.025000001]))\n        self.assertTrue(np.allclose(fp, [1.45]))\n        self.assertTrue(np.allclose(tn, []))\n        self.assertTrue(np.allclose(fn, [1.5, 2.05]))\n        self.assertTrue(np.allclose(errors, [-0.00000001, 0.00999999, 0.01,\n                                             -0.01, 0, 0.025]))\n\n\n# test evaluation class\nclass TestOnsetEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = OnsetEvaluation(DETECTIONS, ANNOTATIONS)\n        self.assertIsInstance(e.num_tp, int)\n        self.assertIsInstance(e.num_fp, int)\n        self.assertIsInstance(e.num_tn, int)\n        self.assertIsInstance(e.num_fn, int)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.accuracy, float)\n        self.assertIsInstance(e.errors, np.ndarray)\n        self.assertIsInstance(e.mean_error, float)\n        self.assertIsInstance(e.std_error, float)\n\n    def test_conversion(self):\n        # conversion from list should work\n        e = OnsetEvaluation([0], [0])\n        self.assertIsInstance(e.tp, np.ndarray)\n        self.assertIsInstance(e.fp, np.ndarray)\n        self.assertIsInstance(e.tn, np.ndarray)\n        self.assertIsInstance(e.fn, np.ndarray)\n        self.assertIsInstance(e.errors, np.ndarray)\n        # conversion from single values should work\n        e = OnsetEvaluation(0, 0)\n        self.assertIsInstance(e.tp, np.ndarray)\n        self.assertIsInstance(e.fp, np.ndarray)\n        self.assertIsInstance(e.tn, np.ndarray)\n        self.assertIsInstance(e.fn, np.ndarray)\n        self.assertIsInstance(e.errors, np.ndarray)\n\n    def test_results(self):\n        # empty detections / annotations\n        e = OnsetEvaluation([], [])\n        self.assertTrue(np.allclose(e.tp, []))\n        self.assertTrue(np.allclose(e.fp, []))\n        self.assertTrue(np.allclose(e.tn, []))\n        self.assertTrue(np.allclose(e.fn, []))\n        self.assertTrue(np.allclose(e.errors, []))\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertTrue(np.allclose(e.errors, []))\n        self.assertTrue(math.isnan(e.mean_error))\n        self.assertTrue(math.isnan(e.std_error))\n\n        # real detections / annotations\n        e = OnsetEvaluation(DETECTIONS, ANNOTATIONS)\n        self.assertTrue(np.allclose(e.tp, [0.99999, 1.02999, 2.01, 2.02, 2.5]))\n        self.assertTrue(np.allclose(e.fp, [1.45, 3.025000001]))\n        self.assertTrue(np.allclose(e.tn, []))\n        self.assertTrue(np.allclose(e.fn, [1.5, 2.05, 3.0]))\n        self.assertEqual(e.num_tp, 5)\n        self.assertEqual(e.num_fp, 2)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 3)\n        # p = correct / retrieved\n        self.assertEqual(e.precision, 5. / 7.)\n        # r = correct / relevant\n        self.assertEqual(e.recall, 5. / 8.)\n        # f = 2 * P * R / (P + R)\n        f = 2 * (5. / 7.) * (5. / 8.) / ((5. / 7.) + (5. / 8.))\n        self.assertEqual(e.fmeasure, f)\n        # acc = (TP + TN) / (TP + FP + TN + FN)\n        self.assertEqual(e.accuracy, (5. + 0) / (5 + 2 + 0 + 3))\n        # errors\n        # det 0.99999999, 1.02999999, 1.45, 2.01, 2.02,       2.5, 3.030000001\n        # tar 1,          1.02,       1.5,  2.0,  2.03, 2.05, 2.5, 3\n        errors = [0.99999999 - 1, 1.02999999 - 1.02,  # 1.45 - 1.5,\n                  2.01 - 2, 2.02 - 2.03, 2.5 - 2.5]  # , 3.030000001 - 3\n        self.assertTrue(np.allclose(e.errors, errors))\n        mean = np.mean([0.99999999 - 1, 1.02999999 - 1.02, 2.01 - 2,\n                        2.02 - 2.03, 2.5 - 2.5])\n        self.assertEqual(e.mean_error, mean)\n        std = np.std([0.99999999 - 1, 1.02999999 - 1.02, 2.01 - 2, 2.02 - 2.03,\n                      2.5 - 2.5])\n        self.assertEqual(e.std_error, std)\n\n    def test_tostring(self):\n        print(OnsetEvaluation([], []))\n\n\nclass TestOnsetSumEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = OnsetSumEvaluation([])\n        self.assertIsInstance(e.num_tp, int)\n        self.assertIsInstance(e.num_fp, int)\n        self.assertIsInstance(e.num_tn, int)\n        self.assertIsInstance(e.num_fn, int)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.accuracy, float)\n        self.assertIsInstance(e.errors, np.ndarray)\n        self.assertIsInstance(e.mean_error, float)\n        self.assertIsInstance(e.std_error, float)\n\n    def test_results(self):\n        # empty sum evaluation\n        e = OnsetSumEvaluation([])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertTrue(np.allclose(e.errors, []))\n        self.assertTrue(math.isnan(e.mean_error))\n        self.assertTrue(math.isnan(e.std_error))\n        # sum evaluation of empty onset evaluation\n        e1 = OnsetEvaluation([], [])\n        e = OnsetSumEvaluation([e1])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertTrue(np.allclose(e.errors, []))\n        self.assertTrue(math.isnan(e.mean_error))\n        self.assertTrue(math.isnan(e.std_error))\n        # sum evaluation of empty and real onset evaluation\n        e2 = OnsetEvaluation(DETECTIONS, ANNOTATIONS)\n        e = OnsetSumEvaluation([e1, e2])\n        self.assertEqual(e.num_tp, 5)\n        self.assertEqual(e.num_fp, 2)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 3)\n        # p = correct / retrieved\n        self.assertEqual(e.precision, 5. / 7.)\n        # r = correct / relevant\n        self.assertEqual(e.recall, 5. / 8.)\n        # f = 2 * P * R / (P + R)\n        f = 2 * (5. / 7.) * (5. / 8.) / ((5. / 7.) + (5. / 8.))\n        self.assertEqual(e.fmeasure, f)\n        # acc = (TP + TN) / (TP + FP + TN + FN)\n        self.assertEqual(e.accuracy, (5. + 0) / (5 + 2 + 0 + 3))\n        # errors is just a concatenation of all errors, i.e. those of e2\n        self.assertTrue(np.allclose(e.errors, e2.errors))\n        # thus mean and std of errors is those of e2\n        self.assertEqual(e.mean_error, e2.mean_error)\n        self.assertEqual(e.std_error, e2.std_error)\n\n    def test_tostring(self):\n        print(OnsetSumEvaluation([]))\n\n\nclass TestOnsetMeanEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = OnsetMeanEvaluation([])\n        self.assertIsInstance(e.num_tp, float)\n        self.assertIsInstance(e.num_fp, float)\n        self.assertIsInstance(e.num_tn, float)\n        self.assertIsInstance(e.num_fn, float)\n        self.assertIsInstance(e.precision, float)\n        self.assertIsInstance(e.recall, float)\n        self.assertIsInstance(e.fmeasure, float)\n        self.assertIsInstance(e.accuracy, float)\n        self.assertIsInstance(e.errors, np.ndarray)\n        self.assertIsInstance(e.mean_error, float)\n        self.assertIsInstance(e.std_error, float)\n\n    def test_results(self):\n        # empty mean evaluation\n        e = OnsetMeanEvaluation([])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertTrue(math.isnan(e.precision))\n        self.assertTrue(math.isnan(e.recall))\n        self.assertTrue(math.isnan(e.fmeasure))\n        self.assertTrue(math.isnan(e.accuracy))\n        self.assertTrue(np.allclose(e.errors, []))\n        self.assertTrue(math.isnan(e.mean_error))\n        self.assertTrue(math.isnan(e.std_error))\n\n        # mean evaluation of empty onset evaluation\n        e1 = OnsetEvaluation([], [])\n        e = OnsetMeanEvaluation([e1])\n        self.assertEqual(e.num_tp, 0)\n        self.assertEqual(e.num_fp, 0)\n        self.assertEqual(e.num_tn, 0)\n        self.assertEqual(e.num_fn, 0)\n        self.assertEqual(e.precision, 1)\n        self.assertEqual(e.recall, 1)\n        self.assertEqual(e.fmeasure, 1)\n        self.assertEqual(e.accuracy, 1)\n        self.assertTrue(np.allclose(e.errors, []))\n        self.assertTrue(math.isnan(e.mean_error))\n        self.assertTrue(math.isnan(e.std_error))\n\n        # mean evaluation of empty and real onset evaluation\n        e2 = OnsetEvaluation(DETECTIONS, ANNOTATIONS)\n        e3 = OnsetEvaluation(ANNOTATIONS, DETECTIONS)\n        e = OnsetMeanEvaluation([e1, e2, e3])\n        self.assertTrue(np.allclose(\n            e.num_tp, np.mean([e_.num_tp for e_ in [e1, e2, e3]])))\n        self.assertTrue(np.allclose(\n            e.num_fp, np.mean([e_.num_fp for e_ in [e1, e2, e3]])))\n        self.assertTrue(np.allclose(\n            e.num_tn, np.mean([e_.num_tn for e_ in [e1, e2, e3]])))\n        self.assertTrue(np.allclose(\n            e.num_fn, np.mean([e_.num_fn for e_ in [e1, e2, e3]])))\n        self.assertTrue(np.allclose(\n            e.precision, np.mean([e_.precision for e_ in [e1, e2, e3]])))\n        self.assertTrue(np.allclose(\n            e.recall, np.mean([e_.recall for e_ in [e1, e2, e3]])))\n        self.assertTrue(np.allclose(\n            e.fmeasure, np.mean([e_.fmeasure for e_ in [e1, e2, e3]])))\n        self.assertTrue(np.allclose(\n            e.accuracy, np.mean([e_.accuracy for e_ in [e1, e2, e3]])))\n        # errors is just a concatenation of all errors\n        # (inherited from SumOnsetEvaluation)\n        self.assertTrue(np.allclose(\n            e.errors, np.concatenate([e_.errors for e_ in [e2, e3]])))\n        # mean and std errors are those of e2 and e3, since those of e1 are NaN\n        self.assertEqual(e.mean_error,\n                         np.mean([e_.mean_error for e_ in [e2, e3]]))\n        self.assertEqual(e.std_error,\n                         np.mean([e_.std_error for e_ in [e2, e3]]))\n\n    def test_tostring(self):\n        print(OnsetMeanEvaluation([]))\n\n\nclass TestAddParserFunction(unittest.TestCase):\n\n    def setUp(self):\n        import argparse\n        self.parser = argparse.ArgumentParser()\n        sub_parser = self.parser.add_subparsers()\n        self.sub_parser, self.group = add_parser(sub_parser)\n\n    def test_args(self):\n        args = self.parser.parse_args([\'onsets\', ANNOTATIONS_PATH,\n                                       DETECTIONS_PATH])\n        self.assertTrue(args.ann_dir is None)\n        self.assertTrue(args.ann_suffix == \'.onsets\')\n        self.assertTrue(args.combine == 0.03)\n        self.assertTrue(args.delay == 0.0)\n        self.assertTrue(args.det_dir is None)\n        self.assertTrue(args.det_suffix == \'.onsets.txt\')\n        self.assertTrue(args.eval == OnsetEvaluation)\n        self.assertTrue(args.files == [ANNOTATIONS_PATH, DETECTIONS_PATH])\n        self.assertTrue(args.ignore_non_existing is False)\n        self.assertTrue(args.mean_eval == OnsetMeanEvaluation)\n        # self.assertTrue(args.outfile == StringIO.StringIO)\n        from madmom.evaluation import tostring\n        self.assertTrue(args.output_formatter == tostring)\n        self.assertTrue(args.quiet is False)\n        self.assertTrue(args.sum_eval == OnsetSumEvaluation)\n        self.assertTrue(args.verbose == 0)\n        self.assertTrue(args.window == 0.025)\n'"
tests/test_evaluation_tempo.py,11,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.evaluation.tempo module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport math\nimport unittest\n\nfrom madmom.evaluation.tempo import *\nfrom . import ANNOTATIONS_PATH, DETECTIONS_PATH\n\nANNOTATIONS = np.asarray([[87.5, 0.7], [175, 0.3]])\nANN_TEMPI = np.asarray([87.5, 175])\nANN_STRENGTHS = np.asarray([0.7, 0.3])\nDETECTIONS = np.asarray([[176.47, 0.6], [117.65, 0.4]])\nDET_TEMPI = np.asarray([176.47, 117.65])\nDET_STRENGTHS = np.asarray([0.6, 0.4])\n\n\n# test functions\nclass TestSortTempoFunction(unittest.TestCase):\n\n    def test_sort(self):\n        result = sort_tempo([[100, 0.8], [50, 0.2]])\n        self.assertTrue(np.allclose(result, [[100, 0.8], [50, 0.2]]))\n        result = sort_tempo([[50, 0.2], [100, 0.8]])\n        self.assertTrue(np.allclose(result, [[100, 0.8], [50, 0.2]]))\n        # tempo order of 50 and 100 bpm must be kept\n        result = sort_tempo([[100, 0.2], [50, 0.2], [75, 0.6]])\n        self.assertTrue(np.allclose(result,\n                                    [[75, 0.6], [100, 0.2], [50, 0.2]]))\n\n    def test_error(self):\n        with self.assertRaises(ValueError):\n            sort_tempo([120, 60])\n\n\nclass TestConstantsClass(unittest.TestCase):\n\n    def test_types(self):\n        self.assertIsInstance(TOLERANCE, float)\n        self.assertIsInstance(DOUBLE, bool)\n        self.assertIsInstance(TRIPLE, bool)\n\n    def test_values(self):\n        self.assertEqual(TOLERANCE, 0.04)\n        self.assertEqual(DOUBLE, True)\n        self.assertEqual(TRIPLE, True)\n\n\nclass TestTempoEvaluationFunction(unittest.TestCase):\n\n    def test_types(self):\n        scores = tempo_evaluation(DETECTIONS, ANNOTATIONS)\n        self.assertIsInstance(scores, tuple)\n        # detections / annotations must be correct type\n        scores = tempo_evaluation([], [])\n        self.assertIsInstance(scores, tuple)\n        scores = tempo_evaluation({}, {})\n        self.assertIsInstance(scores, tuple)\n        # tolerance must be correct type\n        scores = tempo_evaluation(DETECTIONS, ANNOTATIONS, int(1.2))\n        self.assertIsInstance(scores, tuple)\n\n    def test_errors(self):\n        # detections / annotations must not be None\n        with self.assertRaises(TypeError):\n            tempo_evaluation(None, ANN_TEMPI)\n        with self.assertRaises(TypeError):\n            tempo_evaluation(DETECTIONS, None)\n        # tolerance must be > 0\n        with self.assertRaises(ValueError):\n            tempo_evaluation(DETECTIONS, ANNOTATIONS, 0)\n        # tolerance must be correct type\n        with self.assertRaises(TypeError):\n            tempo_evaluation(DETECTIONS, ANN_TEMPI, None)\n        with self.assertRaises(TypeError):\n            tempo_evaluation(DETECTIONS, ANN_TEMPI, [])\n        with self.assertRaises(TypeError):\n            tempo_evaluation(DETECTIONS, ANN_TEMPI, {})\n\n    def test_values(self):\n        # no tempi should return perfect score\n        scores = tempo_evaluation([], [])\n        self.assertEqual(scores, (1, True, True))\n        # no detections should return worst score\n        scores = tempo_evaluation([], ANNOTATIONS)\n        self.assertEqual(scores, (0, False, False))\n        # no annotations should return worst score\n        scores = tempo_evaluation(DETECTIONS, np.zeros(0))\n        self.assertEqual(scores, (0, False, False))\n        # normal calculation\n        scores = tempo_evaluation(DETECTIONS, ANNOTATIONS)\n        self.assertEqual(scores, (0.3, True, False))\n        # uniform strength calculation\n        scores = tempo_evaluation(DETECTIONS, ANN_TEMPI)\n        self.assertEqual(scores, (0.5, True, False))\n\n\n# test evaluation class\nclass TestTempoEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = TempoEvaluation(np.zeros(0), np.zeros(0))\n        self.assertIsInstance(e.pscore, float)\n        self.assertIsInstance(e.any, bool)\n        self.assertIsInstance(e.all, bool)\n        self.assertIsInstance(e.acc1, bool)\n        self.assertIsInstance(e.acc2, bool)\n\n    def test_conversion(self):\n        # conversion from list should work\n        e = TempoEvaluation([], [])\n        self.assertIsInstance(e.pscore, float)\n        self.assertIsInstance(e.any, bool)\n        self.assertIsInstance(e.all, bool)\n        self.assertIsInstance(e.acc1, bool)\n        self.assertIsInstance(e.acc2, bool)\n\n    def test_results_empty(self):\n        e = TempoEvaluation([], [])\n        self.assertEqual(e.pscore, 1)\n        self.assertEqual(e.any, True)\n        self.assertEqual(e.all, True)\n        self.assertEqual(e.acc1, True)\n        self.assertEqual(e.acc2, True)\n        self.assertEqual(len(e), 1)\n\n    def test_results(self):\n        # two detections / annotations\n        e = TempoEvaluation([120, 60], [[60, 0.7], [30, 0.3]])\n        self.assertEqual(e.pscore, 0.7)\n        self.assertEqual(e.any, True)\n        self.assertEqual(e.all, False)\n        # consider only first detection / annotation\n        e = TempoEvaluation([120, 60], [[60, 0.7], [30, 0.3]], max_len=1)\n        self.assertEqual(e.pscore, 0)\n        self.assertEqual(e.any, False)\n        self.assertEqual(e.all, False)\n        # only det=120 and ann=60 should be evaluated for acc\n        self.assertEqual(e.acc1, False)\n        self.assertEqual(e.acc2, True)\n\n        # two detections / annotations\n        e = TempoEvaluation([120, 60], [[180, 0.7], [60, 0.3]])\n        self.assertEqual(e.pscore, 0.3)\n        self.assertEqual(e.any, True)\n        self.assertEqual(e.all, False)\n        # only det=120 and ann=180 should be evaluated for acc\n        self.assertEqual(e.acc1, False)\n        self.assertEqual(e.acc2, False)\n        # consider only first detection / annotation\n        e = TempoEvaluation([120, 60], [[180, 0.7], [60, 0.3]], max_len=1)\n        self.assertEqual(e.pscore, 0)\n        self.assertEqual(e.any, False)\n        self.assertEqual(e.all, False)\n\n        # two detections / annotations\n        e = TempoEvaluation([120, 60], [[180, 0.7], [60, 0.3]])\n        self.assertEqual(e.pscore, 0.3)\n        self.assertEqual(e.any, True)\n        self.assertEqual(e.all, False)\n        # only det=120 and ann=180 should be evaluated for acc\n        self.assertEqual(e.acc1, False)\n        self.assertEqual(e.acc2, False)\n\n        # two detections / annotations\n        e = TempoEvaluation([120, 60], [[180, 0.3], [60, 0.7]])\n        self.assertEqual(e.pscore, 0.7)\n        self.assertEqual(e.any, True)\n        self.assertEqual(e.all, False)\n        # only det=120 and ann=60 should be evaluated for acc\n        self.assertEqual(e.acc1, False)\n        self.assertEqual(e.acc2, True)\n        # consider only strongest detection / annotation (sort them)\n        e = TempoEvaluation([60, 120], [[180, 0.3], [60, 0.7]], max_len=1)\n        self.assertEqual(e.pscore, 1)\n        self.assertEqual(e.any, True)\n        self.assertEqual(e.all, True)\n        self.assertEqual(e.acc1, True)\n        self.assertEqual(e.acc2, True)\n        # same, but do not sort them\n        e = TempoEvaluation([60, 120], [[180, 0.3], [60, 0.7]], max_len=1,\n                            sort=False)\n        self.assertEqual(e.pscore, 0)\n        self.assertEqual(e.any, False)\n        self.assertEqual(e.all, False)\n        self.assertEqual(e.acc1, False)\n        self.assertEqual(e.acc2, True)\n\n        # only 1 annotations\n        e = TempoEvaluation([120, 60], [30, 1])\n        self.assertEqual(e.pscore, 0)\n        self.assertEqual(e.any, False)\n        self.assertEqual(e.all, False)\n        # only det=120 and ann=30 should be evaluated for acc\n        self.assertEqual(e.acc1, False)\n        self.assertEqual(e.acc2, False)\n\n        # only 1 annotations\n        e = TempoEvaluation([60, 120], [180, 1])\n        self.assertEqual(e.pscore, 0)\n        self.assertEqual(e.any, False)\n        self.assertEqual(e.all, False)\n        # only det=60 and ann=60 should be evaluated for acc\n        self.assertEqual(e.acc1, False)\n        self.assertEqual(e.acc2, True)\n\n    def test_results_no_double(self):\n        # only 1 annotations\n        e = TempoEvaluation([60], [30], double=False)\n        self.assertEqual(e.pscore, 0)\n        self.assertEqual(e.any, False)\n        self.assertEqual(e.all, False)\n        self.assertEqual(e.acc1, False)\n        self.assertEqual(e.acc2, False)\n        # only 1 annotations\n        e = TempoEvaluation([60], [180], double=False)\n        self.assertEqual(e.pscore, 0)\n        self.assertEqual(e.any, False)\n        self.assertEqual(e.all, False)\n        self.assertEqual(e.acc1, False)\n        self.assertEqual(e.acc2, True)\n\n    def test_results_no_triple(self):\n        # only 1 annotations\n        e = TempoEvaluation([60], [30], triple=False)\n        self.assertEqual(e.pscore, 0)\n        self.assertEqual(e.any, False)\n        self.assertEqual(e.all, False)\n        self.assertEqual(e.acc1, False)\n        self.assertEqual(e.acc2, True)\n        # only 1 annotations\n        e = TempoEvaluation([60], [180], triple=False)\n        self.assertEqual(e.pscore, 0)\n        self.assertEqual(e.any, False)\n        self.assertEqual(e.all, False)\n        self.assertEqual(e.acc1, False)\n        self.assertEqual(e.acc2, False)\n\n    def test_tostring(self):\n        print(TempoEvaluation([], []))\n\n\nclass TestMeanTempoEvaluationClass(unittest.TestCase):\n\n    def test_types(self):\n        e = TempoMeanEvaluation([])\n        self.assertIsInstance(e.pscore, float)\n        self.assertIsInstance(e.any, float)\n        self.assertIsInstance(e.all, float)\n        self.assertIsInstance(e.acc1, float)\n        self.assertIsInstance(e.acc2, float)\n\n    def test_results(self):\n        # empty mean evaluation\n        e = TempoMeanEvaluation([])\n        self.assertTrue(math.isnan(e.pscore))\n        self.assertTrue(math.isnan(e.any))\n        self.assertTrue(math.isnan(e.all))\n        self.assertTrue(math.isnan(e.acc1))\n        self.assertTrue(math.isnan(e.acc2))\n        self.assertEqual(len(e), 0)\n        # mean evaluation with empty evaluation\n        e1 = TempoEvaluation([], [])\n        e = TempoMeanEvaluation([e1])\n        self.assertEqual(e.pscore, 1)\n        self.assertEqual(e.any, 1)\n        self.assertEqual(e.all, 1)\n        self.assertEqual(e.acc1, 1)\n        self.assertEqual(e.acc2, 1)\n        self.assertEqual(len(e), 1)\n        # mean evaluation of empty and real evaluation\n        e2 = TempoEvaluation([120, 60], [[60, 0.7], [30, 0.3]])\n        e = TempoMeanEvaluation([e1, e2])\n        self.assertEqual(e.pscore, (1 + .7) / 2.)\n        self.assertEqual(e.any, (1 + 1) / 2.)\n        self.assertEqual(e.all, (1 + 0) / 2.)\n        self.assertEqual(e.acc1, (1 + 0) / 2.)\n        self.assertEqual(e.acc2, (1 + 1.) / 2.)\n        self.assertEqual(len(e), 2)\n\n    def test_tostring(self):\n        print(TempoMeanEvaluation([]))\n\n\nclass TestAddParserFunction(unittest.TestCase):\n\n    def setUp(self):\n        import argparse\n        self.parser = argparse.ArgumentParser()\n        sub_parser = self.parser.add_subparsers()\n        self.sub_parser, self.group = add_parser(sub_parser)\n\n    def test_args(self):\n        args = self.parser.parse_args([\'tempo\', ANNOTATIONS_PATH,\n                                       DETECTIONS_PATH])\n        self.assertTrue(args.ann_dir is None)\n        self.assertTrue(args.ann_suffix == \'.bpm\')\n        self.assertTrue(args.det_dir is None)\n        self.assertTrue(args.det_suffix == \'.bpm.txt\')\n        self.assertTrue(args.double is True)\n        self.assertTrue(args.eval == TempoEvaluation)\n        self.assertTrue(args.files == [ANNOTATIONS_PATH, DETECTIONS_PATH])\n        self.assertTrue(args.ignore_non_existing is False)\n        self.assertTrue(args.mean_eval == TempoMeanEvaluation)\n        # self.assertTrue(args.outfile == StringIO.StringIO)\n        from madmom.evaluation import tostring\n        self.assertTrue(args.output_formatter == tostring)\n        self.assertTrue(args.quiet is False)\n        self.assertTrue(args.sum_eval is None)\n        self.assertTrue(args.tolerance == 0.04)\n        self.assertTrue(args.triple is True)\n        self.assertTrue(args.verbose == 0)\n'"
tests/test_features_beats.py,27,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.features.beats module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join as pj\n\nfrom . import AUDIO_PATH, ACTIVATIONS_PATH\nfrom madmom.audio.signal import FramedSignal\nfrom madmom.features import Activations\nfrom madmom.features.beats import *\nfrom madmom.features.beats_hmm import *\nfrom madmom.ml.hmm import HiddenMarkovModel\n\nsample_file = pj(AUDIO_PATH, ""sample.wav"")\nsample_lstm_act = Activations(pj(ACTIVATIONS_PATH, ""sample.beats_lstm.npz""))\nsample_blstm_act = Activations(pj(ACTIVATIONS_PATH, ""sample.beats_blstm.npz""))\nsample_downbeat_act = Activations(pj(ACTIVATIONS_PATH,\n                                     ""sample.downbeats_blstm.npz""))\nsample_pattern_features = Activations(pj(ACTIVATIONS_PATH,\n                                         ""sample.gmm_pattern_tracker.npz""))\n\n\nclass TestRNNBeatProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = RNNBeatProcessor()\n\n    def test_process_blstm(self):\n        # load bi-directional RNN models\n        beat_act = self.processor(sample_file)\n        self.assertTrue(np.allclose(beat_act, sample_blstm_act, atol=1e-5))\n\n    def test_process_lstm(self):\n        # load uni-directional RNN models\n        self.processor = RNNBeatProcessor(online=True, origin=\'online\')\n        # process the whole sequence at once\n        result = self.processor(sample_file)\n        self.assertTrue(np.allclose(result, sample_lstm_act, atol=1e-5))\n        # result must be the same if processed a second time\n        result_1 = self.processor(sample_file)\n        self.assertTrue(np.allclose(result, result_1))\n        # result must be the same if processed frame-by-frame\n        frames = FramedSignal(sample_file, origin=\'online\')\n        self.processor = RNNBeatProcessor(online=True, num_frames=1,\n                                          origin=\'future\')\n        result_2 = np.hstack([self.processor(f, reset=False) for f in frames])\n        self.assertTrue(np.allclose(result, result_2))\n        # result must be different without resetting\n        result_3 = np.hstack([self.processor(f, reset=False) for f in frames])\n        self.assertFalse(np.allclose(result, result_3))\n\n\nclass TestBeatTrackingProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = BeatTrackingProcessor(fps=sample_blstm_act.fps)\n\n    def test_process(self):\n        beats = self.processor(sample_blstm_act)\n        self.assertTrue(np.allclose(beats, [0.11, 0.45, 0.79, 1.13, 1.47,\n                                            1.81, 2.15, 2.49]))\n\n\nclass TestBeatDetectionProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = BeatDetectionProcessor(fps=sample_blstm_act.fps)\n\n    def test_process(self):\n        beats = self.processor(sample_blstm_act)\n        self.assertTrue(np.allclose(beats, [0.11, 0.45, 0.79, 1.13, 1.47,\n                                            1.81, 2.15, 2.49]))\n\n\nclass TestCRFBeatDetectionProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = CRFBeatDetectionProcessor(fps=sample_blstm_act.fps)\n\n    def test_process(self):\n        beats = self.processor(sample_blstm_act)\n        self.assertTrue(np.allclose(beats, [0.09, 0.79, 1.49]))\n\n\nclass TestDBNBeatTrackingProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = DBNBeatTrackingProcessor(fps=sample_blstm_act.fps)\n\n    def test_types(self):\n        self.assertIsInstance(self.processor.correct, bool)\n        self.assertIsInstance(self.processor.st, BeatStateSpace)\n        self.assertIsInstance(self.processor.tm, BeatTransitionModel)\n        self.assertIsInstance(self.processor.om,\n                              RNNBeatTrackingObservationModel)\n        self.assertIsInstance(self.processor.hmm, HiddenMarkovModel)\n\n    def test_values(self):\n        self.assertTrue(self.processor.correct)\n        path, prob = self.processor.hmm.viterbi(sample_blstm_act)\n        self.assertTrue(np.allclose(path[:15], [207, 208, 209, 210, 211, 212,\n                                                213, 214, 215, 216, 183, 184,\n                                                185, 186, 187]))\n        self.assertTrue(np.allclose(prob, -758.193327161))\n        positions = self.processor.st.state_positions[path]\n        self.assertTrue(np.allclose(positions[:9],\n                                    [0.70588235, 0.73529412, 0.76470588,\n                                     0.79411765, 0.82352941, 0.85294118,\n                                     0.88235294, 0.91176471, 0.94117647]))\n        intervals = self.processor.st.state_intervals[path]\n        self.assertTrue(np.allclose(intervals[:10], 34))\n\n    def test_process(self):\n        beats = self.processor(sample_blstm_act)\n        self.assertTrue(np.allclose(beats, [0.1, 0.45, 0.8, 1.12, 1.48, 1.8,\n                                            2.15, 2.49]))\n        # test with beats at the first and last frame\n        act = np.zeros(200) + 1e-4\n        act[[0, 49, 99, 149, 199]] = 1\n        beats = self.processor(act)\n        self.assertTrue(np.allclose(beats, [0, 0.49, 0.99, 1.49, 1.99]))\n        # without correcting the beat positions\n        self.processor.correct = False\n        beats = self.processor(sample_blstm_act)\n        self.assertTrue(np.allclose(beats, [0.1, 0.44, 0.78, 1.12, 1.46, 1.8,\n                                            2.14, 2.48]))\n        # set the threshold\n        self.processor.threshold = 0.25\n        beats = self.processor(sample_blstm_act)\n        self.assertTrue(np.allclose(beats, [0.09, 0.43, 0.77, 1.11, 1.45,\n                                            1.79, 2.13]))\n        self.processor.threshold = 1\n        beats = self.processor(sample_blstm_act)\n        self.assertTrue(np.allclose(beats, []))\n\n    def test_process_forward(self):\n        processor = DBNBeatTrackingProcessor(fps=100, online=True)\n        # compute the forward path at once\n        beats = processor.process_forward(sample_lstm_act)\n        self.assertTrue(np.allclose(beats, [0.47, 0.79, 1.48, 2.16, 2.5]))\n        # compute the forward path framewise\n        processor.reset()\n        beats = [processor.process_forward(np.atleast_1d(act), reset=False)\n                 for act in sample_lstm_act]\n        self.assertTrue(np.allclose(np.nonzero(beats),\n                                    [47, 79, 148, 216, 250]))\n        # without resetting results are different\n        beats = [processor.process_forward(np.atleast_1d(act), reset=False)\n                 for act in sample_lstm_act]\n        self.assertTrue(np.allclose(np.nonzero(beats), [3, 79, 149, 216, 252]))\n\n    def test_empty_path(self):\n        # beat activation which leads to an empty path\n        act = np.array([0, 1, 0, 1, 0, 1])\n        self.assertTrue(np.allclose(self.processor(act), []))\n'"
tests/test_features_beats_hmm.py,130,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.features.beats_hmm module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom madmom.ml.hmm import *\nfrom madmom.features.beats_hmm import *\n\n\n# state spaces\nclass TestBeatStateSpaceClass(unittest.TestCase):\n\n    def test_types(self):\n        bss = BeatStateSpace(1, 4)\n        self.assertIsInstance(bss.intervals, np.ndarray)\n        self.assertIsInstance(bss.state_positions, np.ndarray)\n        self.assertIsInstance(bss.state_intervals, np.ndarray)\n        self.assertIsInstance(bss.first_states, np.ndarray)\n        self.assertIsInstance(bss.last_states, np.ndarray)\n        self.assertIsInstance(bss.num_states, int)\n        self.assertIsInstance(bss.num_intervals, int)\n        # dtypes\n        self.assertTrue(bss.intervals.dtype == np.int)\n        self.assertTrue(bss.state_positions.dtype == np.float)\n        self.assertTrue(bss.state_intervals.dtype == np.int)\n        self.assertTrue(bss.first_states.dtype == np.int)\n        self.assertTrue(bss.last_states.dtype == np.int)\n\n    def test_values(self):\n        bss = BeatStateSpace(1, 4)\n        self.assertTrue(np.allclose(bss.intervals, [1, 2, 3, 4]))\n        self.assertTrue(np.allclose(bss.state_positions,\n                                    [0, 0, 0.5, 0, 1. / 3, 2. / 3,\n                                     0, 0.25, 0.5, 0.75]))\n        self.assertTrue(np.allclose(bss.state_intervals,\n                                    [1, 2, 2, 3, 3, 3, 4, 4, 4, 4]))\n        self.assertTrue(np.allclose(bss.first_states, [0, 1, 3, 6]))\n        self.assertTrue(np.allclose(bss.last_states, [0, 2, 5, 9]))\n        self.assertTrue(bss.num_states == 10)\n        self.assertTrue(bss.num_intervals == 4)\n        # other intervals\n        bss = BeatStateSpace(2, 6)\n        self.assertTrue(np.allclose(bss.intervals, [2, 3, 4, 5, 6]))\n        self.assertTrue(np.allclose(bss.state_positions,\n                                    [0, 0.5,\n                                     0, 1. / 3, 2. / 3,\n                                     0, 0.25, 0.5, 0.75,\n                                     0, 0.2, 0.4, 0.6, 0.8,\n                                     0, 1. / 6, 2. / 6, 0.5, 4. / 6, 5. / 6]))\n        self.assertTrue(np.allclose(bss.state_intervals,\n                                    [2, 2, 3, 3, 3, 4, 4, 4, 4,\n                                     5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6]))\n        self.assertTrue(np.allclose(bss.first_states, [0, 2, 5, 9, 14]))\n        self.assertTrue(np.allclose(bss.last_states, [1, 4, 8, 13, 19]))\n        self.assertTrue(bss.num_states == 20)\n        self.assertTrue(bss.num_intervals == 5)\n\n\nclass TestBarStateSpaceClass(unittest.TestCase):\n\n    def test_types(self):\n        bss = BarStateSpace(2, 1, 4)\n        self.assertIsInstance(bss.num_beats, int)\n        self.assertIsInstance(bss.num_states, int)\n        # self.assertIsInstance(bss.intervals, np.ndarray)\n        self.assertIsInstance(bss.state_positions, np.ndarray)\n        self.assertIsInstance(bss.state_intervals, np.ndarray)\n        self.assertIsInstance(bss.first_states, list)\n        self.assertIsInstance(bss.last_states, list)\n        # dtypes\n        self.assertTrue(bss.state_positions.dtype == np.float)\n        self.assertTrue(bss.state_intervals.dtype == np.int)\n\n    def test_values(self):\n        # 2 beats, intervals 1 to 4\n        bss = BarStateSpace(2, 1, 4)\n        self.assertTrue(bss.num_beats == 2)\n        self.assertTrue(bss.num_states == 20)\n        # self.assertTrue(np.allclose(bss.intervals, [1, 2, 3, 4]))\n        self.assertTrue(np.allclose(bss.state_positions,\n                                    [0, 0, 0.5, 0, 1. / 3, 2. / 3,\n                                     0, 0.25, 0.5, 0.75,\n                                     1, 1, 1.5, 1, 4. / 3, 5. / 3,\n                                     1, 1.25, 1.5, 1.75]))\n        self.assertTrue(np.allclose(bss.state_intervals,\n                                    [1, 2, 2, 3, 3, 3, 4, 4, 4, 4,\n                                     1, 2, 2, 3, 3, 3, 4, 4, 4, 4]))\n        self.assertTrue(np.allclose(bss.first_states, [[0, 1, 3, 6],\n                                                       [10, 11, 13, 16]]))\n        self.assertTrue(np.allclose(bss.last_states, [[0, 2, 5, 9],\n                                                      [10, 12, 15, 19]]))\n        # other values: 1 beat, intervals 2 to 6\n        bss = BarStateSpace(1, 2, 6)\n        self.assertTrue(bss.num_beats == 1)\n        self.assertTrue(bss.num_states == 20)\n        # self.assertTrue(np.allclose(bss.intervals, [2, 3, 4, 5, 6]))\n        self.assertTrue(np.allclose(bss.state_positions,\n                                    [0, 0.5,\n                                     0, 1. / 3, 2. / 3,\n                                     0, 0.25, 0.5, 0.75,\n                                     0, 0.2, 0.4, 0.6, 0.8,\n                                     0, 1. / 6, 2. / 6, 0.5, 4. / 6, 5. / 6]))\n        self.assertTrue(np.allclose(bss.state_intervals,\n                                    [2, 2, 3, 3, 3, 4, 4, 4, 4,\n                                     5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6]))\n        self.assertTrue(np.allclose(bss.first_states, [[0, 2, 5, 9, 14]]))\n        self.assertTrue(np.allclose(bss.last_states, [[1, 4, 8, 13, 19]]))\n\n\nclass TestMultiPatternStateSpaceClass(unittest.TestCase):\n\n    def test_types(self):\n        # test with 2 BeatStateSpaces as before\n        # mpss = MultiPatternStateSpace([1, 2], [4, 6])\n        bss1 = BeatStateSpace(1, 4)\n        bss2 = BeatStateSpace(2, 6)\n        mpss = MultiPatternStateSpace([bss1, bss2])\n        self.assertIsInstance(mpss.state_spaces, list)\n        self.assertIsInstance(mpss.state_positions, np.ndarray)\n        self.assertIsInstance(mpss.state_intervals, np.ndarray)\n        self.assertIsInstance(mpss.num_states, int)\n        # self.assertIsInstance(mpss.num_intervals, int)\n        self.assertIsInstance(mpss.num_patterns, int)\n        # dtypes\n        self.assertTrue(mpss.state_positions.dtype == np.float)\n        self.assertTrue(mpss.state_intervals.dtype == np.int)\n\n    def test_values_beat(self):\n        # test with 2 BeatStateSpaces as before\n        # mpss = MultiPatternStateSpace([1, 2], [4, 6])\n        bss1 = BeatStateSpace(1, 4)\n        bss2 = BeatStateSpace(2, 6)\n        mpss = MultiPatternStateSpace([bss1, bss2])\n        self.assertTrue(np.allclose(mpss.state_spaces[0].intervals,\n                                    [1, 2, 3, 4]))\n        self.assertTrue(np.allclose(mpss.state_spaces[1].intervals,\n                                    [2, 3, 4, 5, 6]))\n        self.assertTrue(mpss.num_states == 30)\n        # self.assertTrue(mpss.num_intervals == [4, 5])\n        self.assertTrue(mpss.num_patterns == 2)\n        # first pattern\n        self.assertTrue(np.allclose(mpss.state_positions[:10],\n                                    [0, 0, 0.5, 0, 1. / 3, 2. / 3,\n                                     0, 0.25, 0.5, 0.75]))\n        self.assertTrue(np.allclose(mpss.state_intervals[:10],\n                                    [1, 2, 2, 3, 3, 3, 4, 4, 4, 4]))\n        self.assertTrue(np.allclose(mpss.state_patterns[:10], 0))\n        # second pattern\n        self.assertTrue(np.allclose(mpss.state_positions[10:],\n                                    [0, 0.5,\n                                     0, 1. / 3, 2. / 3,\n                                     0, 0.25, 0.5, 0.75,\n                                     0, 0.2, 0.4, 0.6, 0.8,\n                                     0, 1. / 6, 2. / 6, 0.5, 4. / 6, 5. / 6]))\n        self.assertTrue(np.allclose(mpss.state_intervals[10:],\n                                    [2, 2, 3, 3, 3, 4, 4, 4, 4,\n                                     5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6]))\n        self.assertTrue(np.allclose(mpss.state_patterns[10:], 1))\n\n    def test_values_bar(self):\n        # test with 2 BarStateSpaces\n        bss1 = BarStateSpace(2, 1, 4)\n        bss2 = BarStateSpace(1, 2, 6)\n        mpss = MultiPatternStateSpace([bss1, bss2])\n        # self.assertTrue(np.allclose(mpss.state_spaces[0].intervals,\n        #                             [1, 2, 3, 4]))\n        # self.assertTrue(np.allclose(mpss.state_spaces[1].intervals,\n        #                             [2, 3, 4, 5, 6]))\n        self.assertTrue(mpss.num_states == 40)\n        # self.assertTrue(mpss.num_intervals == [4, 5])\n        self.assertTrue(mpss.num_patterns == 2)\n        # first pattern\n        self.assertTrue(np.allclose(mpss.state_positions[:20],\n                                    [0, 0, 0.5, 0, 1. / 3, 2. / 3,\n                                     0, 0.25, 0.5, 0.75,\n                                     1, 1, 1.5, 1, 4. / 3, 5. / 3,\n                                     1, 1.25, 1.5, 1.75]))\n        self.assertTrue(np.allclose(mpss.state_intervals[:20],\n                                    [1, 2, 2, 3, 3, 3, 4, 4, 4, 4,\n                                     1, 2, 2, 3, 3, 3, 4, 4, 4, 4]))\n        self.assertTrue(np.allclose(mpss.state_patterns[:20], 0))\n        # self.assertTrue(np.allclose(mpss.first_states[0],\n        #                             [[0, 1, 3, 6], [10, 11, 13, 16]]))\n        # self.assertTrue(np.allclose(mpss.last_states[0],\n        #                             [[0, 2, 5, 9], [10, 12, 15, 19]]))\n        # second pattern\n        self.assertTrue(np.allclose(mpss.state_positions[20:],\n                                    [0, 0.5,\n                                     0, 1. / 3, 2. / 3,\n                                     0, 0.25, 0.5, 0.75,\n                                     0, 0.2, 0.4, 0.6, 0.8,\n                                     0, 1. / 6, 2. / 6, 0.5, 4. / 6, 5. / 6]))\n        self.assertTrue(np.allclose(mpss.state_intervals[20:],\n                                    [2, 2, 3, 3, 3, 4, 4, 4, 4,\n                                     5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6]))\n        self.assertTrue(np.allclose(mpss.state_patterns[20:], 1))\n        # self.assertTrue(np.allclose(mpss.first_states[1],\n        #                             [[0, 2, 5, 9, 14]]))\n        # self.assertTrue(np.allclose(mpss.last_states[1],\n        #                             [[1, 4, 8, 13, 19]]))\n\n\n# transition models\nclass TestBeatTransitionModelClass(unittest.TestCase):\n\n    def test_types(self):\n        bss = BeatStateSpace(1, 4)\n        tm = BeatTransitionModel(bss, 100)\n        self.assertIsInstance(tm, BeatTransitionModel)\n        self.assertIsInstance(tm, TransitionModel)\n        self.assertIsInstance(tm.state_space, BeatStateSpace)\n        self.assertIsInstance(tm.transition_lambda, float)\n        self.assertIsInstance(tm.states, np.ndarray)\n        self.assertIsInstance(tm.pointers, np.ndarray)\n        self.assertIsInstance(tm.probabilities, np.ndarray)\n        self.assertIsInstance(tm.log_probabilities, np.ndarray)\n        self.assertIsInstance(tm.num_states, int)\n        self.assertIsInstance(tm.num_transitions, int)\n        self.assertTrue(tm.states.dtype == np.uint32)\n        self.assertTrue(tm.pointers.dtype == np.uint32)\n        self.assertTrue(tm.probabilities.dtype == np.float)\n        self.assertTrue(tm.log_probabilities.dtype == np.float)\n\n    def test_values(self):\n        bss = BeatStateSpace(1, 4)\n        tm = BeatTransitionModel(bss, 100)\n        self.assertTrue(np.allclose(tm.states,\n                                    [0, 2, 5, 1, 5, 9, 3, 4, 5, 9, 6, 7, 8]))\n        self.assertTrue(np.allclose(tm.pointers,\n                                    [0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 13]))\n        self.assertTrue(np.allclose(tm.probabilities,\n                                    [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1]))\n        self.assertTrue(np.allclose(tm.log_probabilities,\n                                    [0, 0, -33.33333, 0, 0, -25,\n                                     0, 0, -33.33333, 0, 0, 0, 0]))\n        self.assertTrue(tm.num_states == 10)\n        self.assertTrue(tm.num_transitions == 13)\n\n\nclass TestBarTransitionModelClass(unittest.TestCase):\n\n    def test_types(self):\n        bss = BarStateSpace(2, 1, 4)\n        tm = BarTransitionModel(bss, 100)\n        self.assertIsInstance(tm, BarTransitionModel)\n        self.assertIsInstance(tm, TransitionModel)\n        self.assertIsInstance(tm.state_space, BarStateSpace)\n        self.assertIsInstance(tm.transition_lambda, list)\n        self.assertIsInstance(tm.states, np.ndarray)\n        self.assertIsInstance(tm.pointers, np.ndarray)\n        self.assertIsInstance(tm.probabilities, np.ndarray)\n        self.assertIsInstance(tm.log_probabilities, np.ndarray)\n        self.assertIsInstance(tm.num_states, int)\n        self.assertIsInstance(tm.num_transitions, int)\n        self.assertTrue(tm.states.dtype == np.uint32)\n        self.assertTrue(tm.pointers.dtype == np.uint32)\n        self.assertTrue(tm.probabilities.dtype == np.float)\n        self.assertTrue(tm.log_probabilities.dtype == np.float)\n\n    def test_values(self):\n        bss = BarStateSpace(2, 1, 4)\n        tm = BarTransitionModel(bss, 100)\n        self.assertTrue(np.allclose(tm.states,\n                                    [10, 12, 15, 1, 15, 19, 3, 4, 15, 19, 6, 7,\n                                     8, 0, 2, 5, 11, 5, 9, 13, 14, 5, 9, 16,\n                                     17, 18]))\n        self.assertTrue(np.allclose(tm.pointers,\n                                    [0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14,\n                                     16, 17, 19, 20, 21, 23, 24, 25, 26]))\n        self.assertTrue(np.allclose(tm.probabilities,\n                                    [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n                                     1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1]))\n        self.assertTrue(np.allclose(tm.log_probabilities,\n                                    [0, 0, -33.33333, 0, 0, -25,\n                                     0, 0, -33.33333, 0, 0, 0, 0,\n                                     0, 0, -33.33333, 0, 0, -25,\n                                     0, 0, -33.33333, 0, 0, 0, 0]))\n        self.assertTrue(tm.num_states == 20)\n        self.assertTrue(tm.num_transitions == 26)\n\n\nclass TestMultiPatternTransitionModelClass(unittest.TestCase):\n\n    def test_types(self):\n        bss1 = BeatStateSpace(1, 4)\n        bss2 = BeatStateSpace(2, 6)\n        btm1 = BeatTransitionModel(bss1, 100)\n        btm2 = BeatTransitionModel(bss2, 100)\n        tm = MultiPatternTransitionModel([btm1, btm2])\n        self.assertIsInstance(tm, MultiPatternTransitionModel)\n        self.assertIsInstance(tm, TransitionModel)\n        self.assertIsInstance(tm.transition_models, list)\n        self.assertIsNone(tm.transition_prob)\n        self.assertIsInstance(tm.states, np.ndarray)\n        self.assertIsInstance(tm.pointers, np.ndarray)\n        self.assertIsInstance(tm.probabilities, np.ndarray)\n        self.assertIsInstance(tm.log_probabilities, np.ndarray)\n        self.assertIsInstance(tm.num_states, int)\n        self.assertIsInstance(tm.num_transitions, int)\n        self.assertTrue(tm.states.dtype == np.uint32)\n        self.assertTrue(tm.pointers.dtype == np.uint32)\n        self.assertTrue(tm.probabilities.dtype == np.float)\n        self.assertTrue(tm.log_probabilities.dtype == np.float)\n\n    def test_values_beat(self):\n        # test with 2 BeatStateSpaces\n        bss1 = BeatStateSpace(1, 4)\n        bss2 = BeatStateSpace(2, 6)\n        btm1 = BeatTransitionModel(bss1, 100)\n        btm2 = BeatTransitionModel(bss2, 100)\n        tm = MultiPatternTransitionModel([btm1, btm2])\n\n        self.assertTrue(tm.num_states == 10 + 20)\n        self.assertTrue(tm.num_transitions == 13 + 28)\n        # the first pattern has 13 transitions\n        self.assertTrue(np.allclose(tm.states[:13],\n                                    [0, 2, 5, 1, 5, 9, 3, 4, 5, 9, 6, 7, 8]))\n        # the second 28\n        self.assertTrue(np.allclose(tm.states[13:],\n                                    [11, 14, 10, 14, 18, 12, 13, 14, 18, 23,\n                                     29, 15, 16, 17, 18, 23, 29, 19, 20, 21,\n                                     22, 23, 29, 24, 25, 26, 27, 28]))\n        # the first pattern has 10 states (pointers has one more element)\n        self.assertTrue(np.allclose(tm.pointers[:11],\n                                    [0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 13]))\n        # the second has 20\n        self.assertTrue(np.allclose(tm.pointers[11:],\n                                    [15, 16, 18, 19, 20, 24, 25, 26, 27, 30,\n                                     31, 32, 33, 34, 36, 37, 38, 39, 40, 41]))\n        # transition probabilities\n        self.assertTrue(np.allclose(tm.probabilities,\n                                    [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n                                     0, 1, 1, 0, 1, 1, 0, 1, 2.06e-09, 0, 1, 1,\n                                     1, 0, 1, 5.78e-08, 1, 1, 1, 1, 2.06e-09,\n                                     1, 1, 1, 1, 1, 1]))\n        self.assertTrue(np.allclose(tm.log_probabilities,\n                                    [0, 0, -33.33333, 0, 0, -25, 0, 0,\n                                     -33.33333, 0, 0, 0, 0, 0,\n                                     -33.33333, 0, 0, -25, 0, 0,\n                                     -33.33333, 0, -20, -33.33333, 0, 0,\n                                     0, -25, -4.1e-09, -16.6666, 0, 0, 0,\n                                     0, -20, -5.78e-08, 0, 0, 0, 0, 0]))\n\n    def test_values_bar(self):\n        # test with 2 BarStateSpaces\n        bss1 = BarStateSpace(2, 1, 4)\n        bss2 = BarStateSpace(1, 2, 6)\n        btm1 = BarTransitionModel(bss1, 100)\n        btm2 = BarTransitionModel(bss2, 100)\n        tm = MultiPatternTransitionModel([btm1, btm2])\n        self.assertTrue(tm.num_states == 20 + 20)\n        self.assertTrue(tm.num_transitions == 26 + 28)\n        # the first pattern has 26 transitions\n        self.assertTrue(np.allclose(tm.states[:26],\n                                    [10, 12, 15, 1, 15, 19, 3, 4, 15, 19, 6, 7,\n                                     8, 0, 2, 5, 11, 5, 9, 13, 14, 5, 9, 16,\n                                     17, 18]))\n        # the second 28\n        self.assertTrue(np.allclose(tm.states[26:],\n                                    [21, 24, 20, 24, 28, 22, 23, 24, 28, 33,\n                                     39, 25, 26, 27, 28, 33, 39, 29, 30, 31,\n                                     32, 33, 39, 34, 35, 36, 37, 38]))\n        # the first pattern has 20 states (pointers has one more element)\n        self.assertTrue(np.allclose(tm.pointers[:21],\n                                    [0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14,\n                                     16, 17, 19, 20, 21, 23, 24, 25, 26]))\n        # the second has 20\n        self.assertTrue(np.allclose(tm.pointers[21:],\n                                    [28, 29, 31, 32, 33, 37, 38, 39, 40, 43,\n                                     44, 45, 46, 47, 49, 50, 51, 52, 53, 54]))\n        # transition probabilities\n        self.assertTrue(np.allclose(tm.probabilities,\n                                    [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n                                     1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n                                     1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n                                     0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1],\n                                    atol=1e-7))\n        self.assertTrue(np.allclose(tm.log_probabilities,\n                                    [0, 0, -33.33333, 0, 0, -25,\n                                     0, 0, -33.33333, 0, 0, 0, 0,\n                                     0, 0, -33.33333, 0, 0, -25,\n                                     0, 0, -33.33333, 0, 0, 0,\n                                     0, 0, -33.33333, 0, 0, -25,\n                                     0, 0, -33.33333, 0, -20, -33.33333, 0,\n                                     0, 0, -25, 0, -16.6666, 0, 0,\n                                     0, 0, -20, -5.78e-08, 0, 0, 0, 0, 0]))\n\n    def test_values_meter_transition(self):\n        # test with 2 BarStateSpaces\n        bss1 = BarStateSpace(2, 1, 1)  # states 01\n        bss2 = BarStateSpace(3, 1, 1)  # states 234\n        btm1 = BarTransitionModel(bss1, 100)\n        btm2 = BarTransitionModel(bss2, 100)\n        tm = MultiPatternTransitionModel([btm1, btm2], transition_prob=0.25)\n        self.assertIsInstance(tm.transition_prob, np.ndarray)\n        self.assertTrue(tm.num_states == 5)\n        self.assertTrue(tm.num_transitions == 7)\n        self.assertTrue(np.allclose(tm.states, [1, 4, 0, 1, 4, 2, 3]))\n        self.assertTrue(np.allclose(tm.pointers, [0, 2, 3, 5, 6, 7]))\n        self.assertTrue(np.allclose(tm.probabilities,\n                                    [0.75, 0.25, 1, 0.25, 0.75, 1, 1]))\n        states, prev_states, probs = tm.make_dense(tm.states, tm.pointers,\n                                                   tm.probabilities)\n        self.assertTrue(np.allclose(prev_states, [1, 4, 0, 1, 4, 2, 3]))\n        self.assertTrue(np.allclose(states, [0, 0, 1, 2, 2, 3, 4]))\n        self.assertTrue(np.allclose(probs, [0.75, 0.25, 1, 0.25, 0.75, 1, 1]))\n        # same with 3 bar lengths\n        bss3 = BarStateSpace(4, 1, 1)  # states 5678\n        btm3 = BarTransitionModel(bss3, 100)\n        trans = np.array([[0.6, 0.3, 0.25],\n                          [0.15, 0.6, 0.15],\n                          [0.25, 0.1, 0.6]])\n        tm = MultiPatternTransitionModel([btm1, btm2, btm3],\n                                         transition_prob=trans)\n        self.assertIsInstance(tm.transition_prob, np.ndarray)\n        self.assertTrue(tm.num_states == 9)\n        self.assertTrue(tm.num_transitions == 15)\n        self.assertTrue(np.allclose(tm.states, [1, 4, 8, 0, 1, 4, 8, 2, 3, 1,\n                                                4, 8, 5, 6, 7]))\n        self.assertTrue(np.allclose(tm.pointers, [0, 3, 4, 7, 8, 9, 12, 13,\n                                                  14, 15]))\n        self.assertTrue(np.allclose(tm.probabilities,\n                                    [0.6, 0.3, 0.25, 1, 0.15, 0.6, 0.15, 1, 1,\n                                     0.25, 0.1, 0.6, 1, 1, 1]))\n        states, prev_states, probs = tm.make_dense(tm.states, tm.pointers,\n                                                   tm.probabilities)\n        self.assertTrue(np.allclose(prev_states, [1, 4, 8, 0, 1, 4, 8, 2, 3,\n                                                  1, 4, 8, 5, 6, 7]))\n        self.assertTrue(np.allclose(states, [0, 0, 0, 1, 2, 2, 2, 3, 4,\n                                             5, 5, 5, 6, 7, 8]))\n        self.assertTrue(np.allclose(probs, [0.6, 0.3, 0.25, 1, 0.15, 0.6, 0.15,\n                                            1, 1, 0.25, 0.1, 0.6, 1, 1, 1]))\n        # test with 2 BarStateSpaces with more tempi\n        bss1 = BarStateSpace(2, 2, 5)\n        bss2 = BarStateSpace(3, 2, 4)\n        btm1 = BarTransitionModel(bss1, 100)\n        btm2 = BarTransitionModel(bss2, 100)\n        tm = MultiPatternTransitionModel([btm1, btm2])\n        self.assertTrue(tm.num_states == 55)\n        self.assertTrue(tm.num_transitions == 74)\n        with self.assertRaises(ValueError):\n            MultiPatternTransitionModel([btm1, btm2], transition_prob=0.25)\n        # same with same number of tempi\n        bss1 = BarStateSpace(2, 2, 4)\n        bss2 = BarStateSpace(3, 2, 4)\n        btm1 = BarTransitionModel(bss1, 100)\n        btm2 = BarTransitionModel(bss2, 100)\n        tm = MultiPatternTransitionModel([btm1, btm2], transition_prob=0.25)\n        self.assertTrue(tm.num_states == 45)\n        self.assertTrue(tm.num_transitions == 72)\n\n\n# observation models\nclass TestRNNBeatTrackingObservationModelClass(unittest.TestCase):\n\n    def setUp(self):\n        btss = BeatStateSpace(1, 4)\n        self.om = RNNBeatTrackingObservationModel(btss, 4)\n        self.obs = np.asarray([1, 0.1, 0.01, 0], dtype=np.float32)\n\n    def test_types(self):\n        self.assertIsInstance(self.om.pointers, np.ndarray)\n        self.assertIsInstance(self.om.densities(self.obs), np.ndarray)\n        self.assertIsInstance(self.om.log_densities(self.obs), np.ndarray)\n        self.assertTrue(self.om.pointers.dtype == np.uint32)\n        self.assertTrue(self.om.densities(self.obs).dtype == np.float)\n        self.assertTrue(self.om.log_densities(self.obs).dtype == np.float)\n\n    def test_values(self):\n        self.assertTrue(np.allclose(self.om.pointers,\n                                    [1, 1, 0, 1, 0, 0, 1, 0, 0, 0]))\n        self.assertTrue(np.allclose(self.om.densities(self.obs),\n                                    [[0, 1], [0.3, 0.1],\n                                     [0.33, 0.01], [1. / 3, 0]]))\n        self.assertTrue(np.allclose(self.om.log_densities(self.obs),\n                                    [[-np.inf, 0], [-1.20397281, -2.30258508],\n                                     [-1.10866262, -4.60517021],\n                                     [-1.09861229, -np.inf]]))\n'"
tests/test_features_chords.py,7,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.features.chords module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join as pj\n\nfrom madmom.features import Activations\nfrom madmom.features.chords import *\nfrom madmom.io import load_chords\nfrom . import ACTIVATIONS_PATH, AUDIO_PATH, DETECTIONS_PATH\n\nsample_files = [pj(AUDIO_PATH, sf) for sf in [\'sample.wav\', \'sample2.wav\']]\n\nsample_cnn_acts = [Activations(pj(ACTIVATIONS_PATH, af))\n                   for af in [\'sample.cnn_chord_features.npz\',\n                              \'sample2.cnn_chord_features.npz\']]\n\nsample_cnn_labels = [load_chords(pj(DETECTIONS_PATH, df))\n                     for df in [\'sample.cnn_chord_recognition.txt\',\n                                \'sample2.cnn_chord_recognition.txt\']]\n\nsample_deep_chroma_acts = [Activations(pj(ACTIVATIONS_PATH, af))\n                           for af in [\'sample.deep_chroma.npz\',\n                                      \'sample2.deep_chroma.npz\']]\n\nsample_deep_chroma_labels = [load_chords(pj(DETECTIONS_PATH, df))\n                             for df in [\'sample.dc_chord_recognition.txt\',\n                                        \'sample2.dc_chord_recognition.txt\']]\n\n\ndef _compare_labels(test_case, labels, reference_labels):\n    test_case.assertTrue(\n        np.allclose(labels[\'start\'], reference_labels[\'start\']))\n    test_case.assertTrue(np.allclose(labels[\'end\'], reference_labels[\'end\']))\n    test_case.assertTrue((labels[\'label\'] == reference_labels[\'label\']).all())\n\n\nclass TestParseChords(unittest.TestCase):\n\n    def test_read_chord_annotations(self):\n        chords = load_chords(pj(DETECTIONS_PATH,\n                             \'sample2.dc_chord_recognition.txt\'))\n        _compare_labels(self, chords,\n                        np.array([(0.0, 1.6, \'F:maj\'),\n                                  (1.6, 2.5, \'A:maj\'),\n                                  (2.5, 4.1, \'D:maj\')],\n                                 dtype=SEGMENT_DTYPE))\n\n        chords = load_chords(pj(DETECTIONS_PATH,\n                             \'sample.dc_chord_recognition.txt\'))\n        _compare_labels(self, chords,\n                        np.array([(0.0, 2.9, \'G#:maj\')],\n                                 dtype=SEGMENT_DTYPE))\n\n\nclass TestMajMinTargetsToChordLabelsFunction(unittest.TestCase):\n    def test_all_labels(self):\n        fps = 10.\n        targets = range(25)\n        target_labels = np.array([(0.0, 0.1, \'A:maj\'),\n                                  (0.1, 0.2, \'A#:maj\'),\n                                  (0.2, 0.3, \'B:maj\'),\n                                  (0.3, 0.4, \'C:maj\'),\n                                  (0.4, 0.5, \'C#:maj\'),\n                                  (0.5, 0.6, \'D:maj\'),\n                                  (0.6, 0.7, \'D#:maj\'),\n                                  (0.7, 0.8, \'E:maj\'),\n                                  (0.8, 0.9, \'F:maj\'),\n                                  (0.9, 1.0, \'F#:maj\'),\n                                  (1.0, 1.1, \'G:maj\'),\n                                  (1.1, 1.2, \'G#:maj\'),\n                                  (1.2, 1.3, \'A:min\'),\n                                  (1.3, 1.4, \'A#:min\'),\n                                  (1.4, 1.5, \'B:min\'),\n                                  (1.5, 1.6, \'C:min\'),\n                                  (1.6, 1.7, \'C#:min\'),\n                                  (1.7, 1.8, \'D:min\'),\n                                  (1.8, 1.9, \'D#:min\'),\n                                  (1.9, 2.0, \'E:min\'),\n                                  (2.0, 2.1, \'F:min\'),\n                                  (2.1, 2.2, \'F#:min\'),\n                                  (2.2, 2.3, \'G:min\'),\n                                  (2.3, 2.4, \'G#:min\'),\n                                  (2.4, 2.5, \'N\')],\n                                 dtype=SEGMENT_DTYPE)\n\n        labels = majmin_targets_to_chord_labels(targets, fps)\n        _compare_labels(self, labels, target_labels)\n\n    def test_frame_join(self):\n        fps = 10.\n        targets = [0, 0, 4, 4, 4, 4, 24, 8, 8]\n        target_labels = np.array([(0.0, 0.2, \'A:maj\'),\n                                  (0.2, 0.6, \'C#:maj\'),\n                                  (0.6, 0.7, \'N\'),\n                                  (0.7, 0.9, \'F:maj\')],\n                                 dtype=SEGMENT_DTYPE)\n        labels = majmin_targets_to_chord_labels(targets, fps)\n        _compare_labels(self, labels, target_labels)\n\n\nclass TestCNNChordFeatureProcessorClass(unittest.TestCase):\n    def setUp(self):\n        self.processor = CNNChordFeatureProcessor()\n\n    def test_process(self):\n        for audio_file, true_activation in zip(sample_files, sample_cnn_acts):\n            act = self.processor(audio_file)\n            self.assertTrue(np.allclose(act, true_activation, rtol=1e-4))\n\n\nclass TestCRFChordRecognitionProcessorClass(unittest.TestCase):\n    def setUp(self):\n        self.processor = CRFChordRecognitionProcessor()\n\n    def test_process(self):\n        for activation, true_labels in zip(sample_cnn_acts, sample_cnn_labels):\n            labels = self.processor(activation)\n            _compare_labels(self, labels, true_labels)\n\n\nclass TestDeepChromaChordRecognitionProcessorClass(unittest.TestCase):\n    def setUp(self):\n        self.processor = DeepChromaChordRecognitionProcessor()\n\n    def test_process(self):\n        for activation, true_labels in zip(sample_deep_chroma_acts,\n                                           sample_deep_chroma_labels):\n            labels = self.processor(activation)\n            _compare_labels(self, labels, true_labels)\n'"
tests/test_features_downbeats.py,33,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.features.downbeats module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join as pj\n\nfrom madmom.ml.hmm import HiddenMarkovModel\n\nfrom madmom.audio.chroma import CLPChroma\nfrom madmom.features import Activations\nfrom madmom.features.downbeats import *\nfrom madmom.models import PATTERNS_BALLROOM\nfrom . import ACTIVATIONS_PATH, ANNOTATIONS_PATH, AUDIO_PATH, DETECTIONS_PATH\nfrom .test_utils import DETECTION_FILES\n\nsample_file = pj(AUDIO_PATH, ""sample.wav"")\nsample_beats = np.loadtxt(pj(ANNOTATIONS_PATH, ""sample.beats""))\nsample_det_file = pj(DETECTIONS_PATH, \'sample.dbn_beat_tracker.txt\')\nsample_beat_det = np.loadtxt(sample_det_file)\nsample_bar_act = Activations(pj(ACTIVATIONS_PATH, ""sample.bar_tracker.npz""))\nsample_downbeat_act = Activations(pj(ACTIVATIONS_PATH,\n                                     ""sample.downbeats_blstm.npz""))\nsample_pattern_features = Activations(pj(ACTIVATIONS_PATH,\n                                         ""sample.gmm_pattern_tracker.npz""))\n\n\nclass TestRNNDownBeatProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = RNNDownBeatProcessor()\n\n    def test_process(self):\n        downbeat_act = self.processor(sample_file)\n        self.assertTrue(np.allclose(downbeat_act, sample_downbeat_act,\n                                    atol=1e-5))\n\n\nclass TestDBNDownBeatTrackingProcessorClass(unittest.TestCase):\n    def setUp(self):\n        self.processor = DBNDownBeatTrackingProcessor(\n            [3, 4], fps=sample_downbeat_act.fps)\n\n    def test_types(self):\n        self.assertIsInstance(self.processor.correct, bool)\n        # self.assertIsInstance(self.processor.st, BarStateSpace)\n        # the bar lengths are modelled with individual HMMs\n        self.assertIsInstance(self.processor.hmms, list)\n        self.assertIsInstance(self.processor.hmms[0], HiddenMarkovModel)\n        self.assertIsInstance(self.processor.hmms[0].transition_model,\n                              BarTransitionModel)\n        self.assertIsInstance(self.processor.hmms[0].observation_model,\n                              RNNDownBeatTrackingObservationModel)\n\n    def test_values(self):\n        self.assertTrue(self.processor.correct)\n        # we have to test each bar length individually\n        path, prob = self.processor.hmms[0].viterbi(sample_downbeat_act)\n        self.assertTrue(np.allclose(path[:13],\n                                    [7682, 7683, 7684, 7685, 7686, 7687, 7688,\n                                     7689, 217, 218, 219, 220, 221]))\n        self.assertTrue(np.allclose(prob, -764.586595603))\n        tm = self.processor.hmms[0].transition_model\n        positions = tm.state_space.state_positions[path]\n        self.assertTrue(np.allclose(positions[:10],\n                                    [2.77142857, 2.8, 2.82857143, 2.85714286,\n                                     2.88571429, 2.91428571, 2.94285714,\n                                     2.97142857, 0, 0.02857143]))\n        intervals = tm.state_space.state_intervals[path]\n        self.assertTrue(np.allclose(intervals[:10], 35))\n\n    def test_process(self):\n        downbeats = self.processor(sample_downbeat_act)\n        self.assertTrue(np.allclose(downbeats, [[0.09, 1], [0.45, 2],\n                                                [0.79, 3], [1.12, 4],\n                                                [1.47, 1], [1.8, 2],\n                                                [2.14, 3], [2.49, 4]]))\n        # test with beats at the first and last frame\n        act = np.zeros((200, 2)) + 1e-4\n        act[[0, 199], 1] = 1  # downbeats\n        act[[49, 99, 149], 0] = 1  # beats\n        downbeats = self.processor(act)\n        self.assertTrue(np.allclose(downbeats, [[0, 1], [0.49, 2], [0.99, 3],\n                                                [1.49, 4], [1.99, 1]]))\n        # without correcting the beat positions\n        self.processor.correct = False\n        downbeats = self.processor(sample_downbeat_act)\n        correct = np.array([[0.08, 1], [0.43, 2], [0.77, 3], [1.11, 4],\n                            [1.45, 1], [1.79, 2], [2.13, 3], [2.47, 4]])\n        self.assertTrue(np.allclose(downbeats, correct))\n        # test threshold\n        self.processor.threshold = 0.5\n        downbeats = self.processor(sample_downbeat_act)\n        self.assertTrue(np.allclose(downbeats, correct[1:-1]))\n        self.processor.threshold = 1\n        downbeats = self.processor(sample_downbeat_act)\n        self.assertTrue(np.allclose(downbeats, np.empty((0, 2))))\n\n\nclass TestPatternTrackingProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = PatternTrackingProcessor(\n            PATTERNS_BALLROOM, fps=sample_pattern_features.fps)\n\n    def test_types(self):\n        self.assertIsInstance(self.processor.num_beats, list)\n        self.assertIsInstance(self.processor.st, MultiPatternStateSpace)\n        self.assertIsInstance(self.processor.tm, MultiPatternTransitionModel)\n        self.assertIsInstance(self.processor.om,\n                              GMMPatternTrackingObservationModel)\n        self.assertIsInstance(self.processor.hmm, HiddenMarkovModel)\n\n    def test_values(self):\n        self.assertTrue(self.processor.fps == 50)\n        self.assertTrue(np.allclose(self.processor.num_beats, [3, 4]))\n        path, prob = self.processor.hmm.viterbi(sample_pattern_features)\n        self.assertTrue(np.allclose(path[:12], [5573, 5574, 5575, 5576, 6757,\n                                                6758, 6759, 6760, 6761, 6762,\n                                                6763, 6764]))\n        self.assertTrue(np.allclose(prob, -468.8014))\n        patterns = self.processor.st.state_patterns[path]\n        self.assertTrue(np.allclose(patterns,\n                                    np.ones(len(sample_pattern_features))))\n        positions = self.processor.st.state_positions[path]\n        self.assertTrue(np.allclose(positions[:6], [1.76470588, 1.82352944,\n                                                    1.88235296, 1.94117648,\n                                                    2, 2.0588236]))\n\n    def test_process(self):\n        beats = self.processor(sample_pattern_features)\n        self.assertTrue(np.allclose(beats, [[0.08, 3], [0.42, 4], [0.76, 1],\n                                            [1.1, 2], [1.44, 3], [1.78, 4],\n                                            [2.12, 1], [2.46, 2], [2.8, 3]]))\n\n\nclass TestLoadBeatsProcessorClass(unittest.TestCase):\n\n    def test_single(self):\n        proc = LoadBeatsProcessor(sample_det_file)\n        self.assertTrue(proc.mode == \'single\')\n        result = proc()\n        self.assertTrue(np.allclose(result, sample_beat_det))\n\n    def test_batch(self):\n        proc = LoadBeatsProcessor(None, files=DETECTION_FILES,\n                                  beats_suffix=\'.dbn_beat_tracker.txt\')\n        self.assertTrue(proc.mode == \'batch\')\n        result = proc(sample_file)\n        self.assertTrue(np.allclose(result, sample_beat_det))\n\n\nclass TestSyncronizeFeaturesProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = SyncronizeFeaturesProcessor(beat_subdivisions=2,\n                                                     fps=100)\n\n    def test_process(self):\n        data = [CLPChroma(sample_file, fps=100), sample_beats]\n        feat_sync = self.processor(data)\n        target = [[0.28231065, 0.14807641, 0.22790557, 0.41458403, 0.15966462,\n                   0.22294236, 0.1429988, 0.16661506, 0.5978227, 0.24039252,\n                   0.23444982, 0.21910049],\n                  [0.25676728, 0.13382165, 0.19957431, 0.47225753, 0.18936998,\n                   0.17014103, 0.14079712, 0.18317944, 0.60692955, 0.20016842,\n                   0.17619181, 0.24408179]]\n        self.assertTrue(np.allclose(feat_sync[0, :], target, rtol=1e-3))\n\n    def test_corner_cases(self):\n        feat_sync = self.processor([np.arange(100), np.array([])])\n        self.assertTrue(np.allclose(feat_sync, [[], []]))\n        feat_sync = self.processor([np.arange(100), np.array([0, 0.5, 1.5])])\n        self.assertTrue(np.allclose(feat_sync, [[[11.], [33.5]]]))\n\n\nclass TestRNNBarProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = RNNBarProcessor(fps=100)\n\n    def test_process(self):\n        act = self.processor((sample_file, sample_beats[:, 0]))\n        self.assertTrue(np.allclose(act, sample_bar_act, rtol=1e-3,\n                                    equal_nan=True))\n\n\nclass TestDBNBarTrackingProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = DBNBarTrackingProcessor()\n\n    def test_dbn(self):\n        # check DBN output\n        path, log = self.processor.hmm.viterbi(sample_bar_act[:-1, 1])\n        self.assertTrue(np.allclose(path, [0, 1, 2]))\n        self.assertTrue(np.allclose(log, -12.2217575073))\n\n    def test_process(self):\n        beats = self.processor(sample_bar_act)\n        self.assertTrue(np.allclose(beats, [[0.0913, 1.], [0.7997, 2.],\n                                            [1.4806, 3.], [2.1478, 1.]]))\n\n    def test_single_bar_length(self):\n        processor = DBNBarTrackingProcessor(beats_per_bar=3)\n        beats = processor(sample_bar_act)\n        self.assertTrue(np.allclose(beats, [[0.0913, 1.], [0.7997, 2.],\n                                            [1.4806, 3.], [2.1478, 1.]]))\n'"
tests/test_features_key.py,6,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.features.key module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join as pj\n\nfrom madmom.features import Activations\nfrom madmom.features.key import *\nfrom . import AUDIO_PATH, ACTIVATIONS_PATH\n\nsample_file = pj(AUDIO_PATH, \'sample.wav\')\nsample2_file = pj(AUDIO_PATH, \'sample2.wav\')\nsample_key_act = Activations(pj(ACTIVATIONS_PATH, \'sample.key_cnn.npz\'))\nsample2_key_act = Activations(pj(ACTIVATIONS_PATH, \'sample2.key_cnn.npz\'))\n\n\nclass TestHelperFunctions(unittest.TestCase):\n\n    def test_key_prediction_to_label_function(self):\n        self.assertEqual(key_prediction_to_label(sample_key_act), \'Ab major\')\n        self.assertEqual(\n            key_prediction_to_label(sample_key_act[0]), \'Ab major\')\n        self.assertEqual(\n            key_prediction_to_label(np.roll(sample_key_act[0], 1)), \'A minor\')\n        self.assertEqual(\n            key_prediction_to_label(np.roll(sample_key_act[0], -3)), \'F major\')\n\n        self.assertEqual(key_prediction_to_label(sample2_key_act), \'A minor\')\n        self.assertEqual(\n            key_prediction_to_label(sample2_key_act[0]), \'A minor\')\n        self.assertEqual(\n            key_prediction_to_label(np.roll(sample2_key_act[0], 1)),\n            \'Bb minor\')\n        self.assertEqual(\n            key_prediction_to_label(np.roll(sample2_key_act[0], -3)),\n            \'F# major\')\n\n\nclass TestCNNKeyRecognitionProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = CNNKeyRecognitionProcessor()\n\n    def test_process(self):\n        act = self.processor(sample_file)\n        self.assertTrue(np.allclose(act, sample_key_act))\n\n        act = self.processor(sample2_file)\n        self.assertTrue(np.allclose(act, sample2_key_act))\n'"
tests/test_features_notes.py,14,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.features.notes module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join as pj\n\nfrom madmom.features import Activations\nfrom madmom.features.notes import *\nfrom madmom.io import load_notes\nfrom . import ACTIVATIONS_PATH, AUDIO_PATH, DETECTIONS_PATH\n\nsample_file = pj(AUDIO_PATH, ""stereo_sample.wav"")\nsample_act_rnn = Activations(pj(ACTIVATIONS_PATH,\n                                ""stereo_sample.notes_brnn.npz""))\nsample_act_cnn = Activations(pj(ACTIVATIONS_PATH,\n                                ""stereo_sample.notes_cnn.npz""))\nsample_det = load_notes(pj(DETECTIONS_PATH,\n                           ""stereo_sample.piano_transcriptor.txt""))\n\n\nclass TestRNNOnsetProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = RNNPianoNoteProcessor()\n\n    def test_process(self):\n        act = self.processor(sample_file)\n        self.assertTrue(np.allclose(act, sample_act_rnn, atol=1e-6))\n\n\nclass TestNoteOnsetPeakPickingProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = NoteOnsetPeakPickingProcessor(\n            threshold=0.35, smooth=0.09, combine=0.05, pre_max=0.01,\n            post_max=0.01, pitch_offset=21, fps=100)\n        self.result = np.array([[0.14, 72], [1.56, 41],\n                                [2.52, 77], [3.37, 75]])\n\n    def test_process(self):\n        notes = self.processor(sample_act_rnn)\n        self.assertTrue(np.allclose(notes, self.result))\n        self.processor.threshold = 2\n        notes = self.processor(sample_act_rnn)\n        self.assertTrue(np.allclose(notes, np.zeros((0, 2))))\n\n    def test_delay(self):\n        self.processor.delay = 1\n        notes = self.processor(sample_act_rnn)\n        self.assertTrue(np.allclose(notes[:, 0] - 1, self.result[:, 0]))\n        self.assertTrue(np.allclose(notes[:, 1], self.result[:, 1]))\n\n\nclass TestCNNPianoNoteProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = CNNPianoNoteProcessor()\n\n    def test_process(self):\n        act = self.processor(sample_file)\n        self.assertTrue(np.allclose(act, sample_act_cnn, atol=1e-6))\n\n\nclass TestADSRNoteTrackingProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = ADSRNoteTrackingProcessor()\n\n    def test_process(self):\n        notes = self.processor(sample_act_cnn)\n        self.assertTrue(np.allclose(notes, sample_det))\n        self.assertTrue(np.allclose(notes.shape, (8, 3)))\n        # do not enforce complete notes (same result, though)\n        self.processor.complete = False\n        notes = self.processor(sample_act_cnn)\n        self.assertTrue(np.allclose(notes.shape, (8, 3)))\n        # try various thresholds\n        self.processor.onset_threshold = 0.75\n        notes = self.processor(sample_act_cnn)\n        self.assertTrue(np.allclose(notes.shape, (6, 3)))\n        self.processor.note_threshold = 0.99\n        notes = self.processor(sample_act_cnn)\n        self.assertTrue(np.allclose(notes.shape, (5, 3)))\n        self.processor.complete = False\n        notes = self.processor(sample_act_cnn)\n        self.assertTrue(np.allclose(notes.shape, (5, 3)))\n        self.processor.onset_threshold = 1\n        notes = self.processor(sample_act_cnn)\n        self.assertTrue(np.allclose(notes.shape, (0, 3)))\n'"
tests/test_features_onsets.py,29,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.features.onsets module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join as pj\n\nfrom . import AUDIO_PATH, ACTIVATIONS_PATH\n\nfrom madmom.audio.signal import SignalProcessor, FramedSignalProcessor\nfrom madmom.audio.filters import LogarithmicFilterbank\nfrom madmom.audio.stft import ShortTimeFourierTransformProcessor\nfrom madmom.audio.spectrogram import (Spectrogram, SpectrogramProcessor,\n                                      FilteredSpectrogramProcessor,\n                                      LogarithmicFilteredSpectrogram,\n                                      LogarithmicSpectrogramProcessor)\nfrom madmom.features import Activations\nfrom madmom.features.onsets import *\n\nsample_file = pj(AUDIO_PATH, \'sample.wav\')\nsample_spec = Spectrogram(sample_file, circular_shift=True)\nsample_log_filt_spec = LogarithmicFilteredSpectrogram(\n    sample_spec, num_bands=24, mul=1, add=1)\nsample_cnn_act = Activations(pj(ACTIVATIONS_PATH, \'sample.onsets_cnn.npz\'))\nsample_rnn_act = Activations(pj(ACTIVATIONS_PATH, \'sample.onsets_rnn.npz\'))\nsample_brnn_act = Activations(pj(ACTIVATIONS_PATH, \'sample.onsets_brnn.npz\'))\nsample_superflux_act = Activations(pj(ACTIVATIONS_PATH,\n                                      \'sample.super_flux.npz\'))\n\n\nclass TestHighFrequencyContentFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = high_frequency_content(sample_log_filt_spec)\n        self.assertTrue(np.allclose(odf[:6], [8.97001563, 9.36399107,\n                                              8.64144536, 8.34977449,\n                                              8.21097918, 8.40412515]))\n\n\nclass TestFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = high_frequency_content(sample_log_filt_spec)\n        self.assertTrue(np.allclose(odf[:6], [8.97001563, 9.36399107,\n                                              8.64144536, 8.34977449,\n                                              8.21097918, 8.40412515]))\n\n\nclass TestSpectralDiffFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = spectral_diff(sample_log_filt_spec)\n        self.assertTrue(np.allclose(odf[:6], [0, 0.55715936, 0.64004618,\n                                              0.0810971, 0.295396,\n                                              0.16324584]))\n\n\nclass TestSpectralFluxFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = spectral_flux(sample_log_filt_spec)\n        self.assertTrue(np.allclose(odf[:6], [0, 3.91207361, 2.91675663,\n                                              1.38361311, 2.59582925,\n                                              2.16986609]))\n\n\nclass TestSuperfluxFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = superflux(sample_log_filt_spec)\n        self.assertTrue(np.allclose(odf[:6], [0, 2.08680153, 0.6411702,\n                                              0.38634294, 0.40202433,\n                                              0.63349575]))\n\n\nclass TestComplexFluxFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = complex_flux(sample_log_filt_spec)\n        self.assertTrue(np.allclose(odf[:6], [0, 0.476213485, 0.0877621323,\n                                              0.0593151376, 0.0654867291,\n                                              0.0954693183]))\n\n\nclass TestModifiedKullbackLeiblerFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = modified_kullback_leibler(sample_log_filt_spec)\n        self.assertTrue(np.allclose(odf[:6], [0, 0.71910584, 0.6664055,\n                                              0.68092251, 0.69984031,\n                                              0.71744561]))\n\n\nclass TestPhaseDeviationFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = phase_deviation(sample_log_filt_spec)\n        self.assertTrue(np.allclose(odf[:6], [0, 0, 0.71957183, 0.91994524,\n                                              0.9418999, 0.86083585]))\n\n\nclass TestWeightedPhaseDeviationFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = weighted_phase_deviation(sample_spec)\n        self.assertTrue(np.allclose(odf[:6], [0, 0, 0.19568817, 0.20483065,\n                                              0.17890805, 0.16970603]))\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            weighted_phase_deviation(sample_log_filt_spec)\n\n\nclass TestNormalizesWeightedPhaseDeviationFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = normalized_weighted_phase_deviation(sample_spec)\n        self.assertTrue(np.allclose(odf[:6], [0, 0, 0.46018526, 0.50193471,\n                                              0.42031503, 0.40806249]))\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            normalized_weighted_phase_deviation(sample_log_filt_spec)\n\n\nclass TestComplexDomainFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = complex_domain(sample_spec)\n        self.assertTrue(np.allclose(odf[:6], [399.29980469, 585.9564209,\n                                              262.08010864, 225.84718323,\n                                              196.88954163, 200.32469177]))\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            complex_domain(sample_log_filt_spec)\n\n\nclass TestRectifiedComplexDomainFunction(unittest.TestCase):\n\n    def test_values(self):\n        odf = rectified_complex_domain(sample_spec)\n        self.assertTrue(np.allclose(odf[:6], [0, 394.165222, 119.79425,\n                                              96.70564, 122.52311, 92.61698]))\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            rectified_complex_domain(sample_log_filt_spec)\n\n\nclass TestSpectralOnsetProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = SpectralOnsetProcessor()\n\n    def test_processors(self):\n        proc = SpectralOnsetProcessor()\n        self.assertIsInstance(proc.processors[0], SignalProcessor)\n        self.assertIsInstance(proc.processors[1], FramedSignalProcessor)\n        self.assertIsInstance(proc.processors[2],\n                              ShortTimeFourierTransformProcessor)\n        self.assertIsInstance(proc.processors[3], SpectrogramProcessor)\n        self.assertEqual(proc.processors[4], spectral_flux)\n\n    def test_filterbank(self):\n        # with filtering\n        proc = SpectralOnsetProcessor(filterbank=LogarithmicFilterbank)\n        self.assertIsInstance(proc.processors[4], FilteredSpectrogramProcessor)\n        self.assertEqual(proc.processors[5], spectral_flux)\n\n    def test_scaling(self):\n        # with logarithmic scaling\n        proc = SpectralOnsetProcessor(log=np.log10)\n        self.assertIsInstance(proc.processors[4],\n                              LogarithmicSpectrogramProcessor)\n        self.assertEqual(proc.processors[5], spectral_flux)\n\n    def test_filtered_scaling(self):\n        # with both filtering and logarithmic scaling\n        proc = SpectralOnsetProcessor(filterbank=LogarithmicFilterbank,\n                                      log=np.log10)\n        self.assertIsInstance(proc.processors[4], FilteredSpectrogramProcessor)\n        self.assertIsInstance(proc.processors[5],\n                              LogarithmicSpectrogramProcessor)\n        self.assertEqual(proc.processors[6], spectral_flux)\n\n    def test_circular_shift(self):\n        # circular shift\n        proc = SpectralOnsetProcessor(onset_method=\'phase_deviation\')\n        self.assertIsInstance(proc.processors[2],\n                              ShortTimeFourierTransformProcessor)\n        self.assertTrue(proc.processors[2].circular_shift)\n        self.assertEqual(proc.processors[4], phase_deviation)\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            SpectralOnsetProcessor(onset_method=\'nonexistent\')\n\n    def test_process(self):\n        odf = self.processor(sample_file)\n        self.assertTrue(np.allclose(odf[:6], [0., 100.90120697, 74.44419861,\n                                              40.277565, 57.95736313,\n                                              46.15561295]))\n\n\nclass TestRNNOnsetProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = RNNOnsetProcessor()\n        self.online_processor = RNNOnsetProcessor(online=True, origin=\'online\')\n\n    def test_process(self):\n        act = self.processor(sample_file)\n        self.assertTrue(np.allclose(act, sample_brnn_act))\n        act = self.online_processor(sample_file, reset=False)\n        self.assertTrue(np.allclose(act, sample_rnn_act))\n\n\nclass TestCNNOnsetProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = CNNOnsetProcessor()\n\n    def test_process(self):\n        act = self.processor(sample_file)\n        self.assertTrue(np.allclose(act, sample_cnn_act))\n\n\nclass TestPeakPickingFunction(unittest.TestCase):\n\n    def test_values(self):\n        onsets = peak_picking(sample_superflux_act, 1.1)\n        self.assertTrue(np.allclose(onsets[:6], [2, 10, 17, 48, 55, 80]))\n        self.assertTrue(len(onsets) == 35)\n        # smooth\n        onsets = peak_picking(sample_superflux_act, 1.1, smooth=3)\n        self.assertTrue(np.allclose(onsets[:6], [2, 10, 17, 24, 48, 55]))\n        # default values\n        onsets = peak_picking(sample_superflux_act, 1.1, pre_max=2,\n                              post_max=10, pre_avg=30)\n        self.assertTrue(np.allclose(onsets[:6], [2, 17, 55, 89, 122, 159]))\n\n    def test_online(self):\n        onsets = peak_picking(sample_rnn_act, threshold=0.23, post_max=0)\n        self.assertTrue(np.allclose(onsets,\n                                    [1, 3, 10, 12, 29, 46, 62, 63, 77, 79,\n                                     81, 99, 100, 113, 115, 148, 149, 164,\n                                     181, 183, 216, 234, 250, 268]))\n        self.assertTrue(len(onsets) == 24)\n\n\nclass TestOnsetPeakPickingProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = OnsetPeakPickingProcessor(\n            threshold=1.1, pre_max=0.01, post_max=0.05, pre_avg=0.15,\n            post_avg=0, combine=0.03, delay=0, fps=sample_superflux_act.fps)\n        self.sample_superflux_result = [0.01, 0.085, 0.275, 0.445, 0.61, 0.795,\n                                        0.98, 1.115, 1.365, 1.475, 1.62,\n                                        1.795, 2.14, 2.33, 2.485, 2.665]\n        self.online_processor = OnsetPeakPickingProcessor(\n            threshold=0.23, online=True, fps=sample_rnn_act.fps)\n        self.sample_rnn_result = [0.01, 0.1, 0.29, 0.46, 0.62, 0.77, 0.81,\n                                  0.99, 1.13, 1.48, 1.64, 1.81, 2.16, 2.34,\n                                  2.5, 2.68]\n\n    def test_online_parameters(self):\n        self.assertEqual(self.online_processor.smooth, 0)\n        self.assertEqual(self.online_processor.post_avg, 0)\n        self.assertEqual(self.online_processor.post_max, 0)\n\n    def test_process(self):\n        onsets = self.processor(sample_superflux_act)\n        self.assertTrue(np.allclose(onsets, self.sample_superflux_result))\n\n    def test_process_online(self):\n        # process everything at once\n        onsets = self.online_processor(sample_rnn_act)\n        self.assertTrue(np.allclose(onsets, self.sample_rnn_result))\n        # results must be the same if processed a second time\n        onsets_1 = self.online_processor(sample_rnn_act)\n        self.assertTrue(np.allclose(onsets_1, self.sample_rnn_result))\n        # process frame by frame\n        self.online_processor.reset()\n        onsets_2 = np.hstack(\n            [self.online_processor(np.atleast_1d(f), reset=False)\n             for f in sample_rnn_act])\n        self.assertTrue(np.allclose(onsets_2, self.sample_rnn_result))\n\n    def test_delay(self):\n        self.processor.delay = 1\n        onsets = self.processor(sample_superflux_act)\n        self.assertTrue(np.allclose(onsets - 1, self.sample_superflux_result))\n'"
tests/test_features_tempo.py,113,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.features.tempo module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join as pj\n\nfrom madmom.features.tempo import *\nfrom madmom.io import write_tempo, load_tempo\nfrom . import ACTIVATIONS_PATH\n\nact_file = np.load(pj(ACTIVATIONS_PATH, ""sample.beats_blstm.npz""))\nact = act_file[\'activations\'].astype(np.float)\nfps = float(act_file[\'fps\'])\n\nCOMB_TEMPI = np.array([[176.470, 0.475], [117.647, 0.177],\n                       [240.0, 0.154], [68.966, 0.099], [82.192, 0.096]])\nCOMB_TEMPI_ONLINE = [[176.470588, 0.289414003], [115.384615, 0.124638601],\n                     [230.769231, 0.0918372569], [84.5070423, 0.0903815502],\n                     [75.0000000, 0.0713704506], [53.5714286, 0.0701783497],\n                     [65.9340659, 0.0696296514], [49.1803279, 0.0676349815],\n                     [61.2244898, 0.0646209647], [40.8163265, 0.0602941909]]\nACF_TEMPI = np.array([[176.470, 0.246], [86.956, 0.226], [58.823, 0.181],\n                      [43.795, 0.137], [115.384, 0.081], [70.588, 0.067],\n                      [50.847, 0.058]])\nACF_TEMPI_ONLINE = [[176.470588, 0.253116038], [88.2352941, 0.231203195],\n                    [58.8235294, 0.187827698], [43.7956204, 0.139373027],\n                    [115.384615, 0.0749783568], [69.7674419, 0.0599632291],\n                    [50.4201681, 0.0535384559]]\nDBN_TEMPI = np.array([[176.470, 1]])\nDBN_TEMPI_ONLINE = [[176.470588, 0.580877380], [86.9565217, 0.244729904],\n                    [74.0740741, 0.127887992], [40.8163265, 0.0232523621],\n                    [250.000000, 0.0232523621]]\nHIST = interval_histogram_comb(act, 0.79, min_tau=24, max_tau=150)\n\n\nclass TestIntervalHistogramAcfFunction(unittest.TestCase):\n\n    def test_values(self):\n        hist = interval_histogram_acf(act, min_tau=24, max_tau=150)\n        self.assertTrue(np.allclose(hist[0][:6], [0.10034907, 0.10061631,\n                                                  0.11078519, 0.13461014,\n                                                  0.17694432, 0.24372872]))\n        self.assertTrue(np.allclose(hist[1], np.arange(24, 151)))\n\n\nclass TestIntervalHistogramCombFunction(unittest.TestCase):\n\n    def setUp(self):\n        self.hist_0_6 = np.array([3.16024358, 2.00690881, 2.52592621,\n                                  2.00221429, 1.73527979, 1.47528936])\n\n    def test_values(self):\n        hist = interval_histogram_comb(act, 0.79, min_tau=24, max_tau=150)\n        self.assertTrue(np.allclose(hist[0][:6], self.hist_0_6))\n        self.assertTrue(np.allclose(hist[1], np.arange(24, 151)))\n\n    def test_values_2d(self):\n        act_2d = np.vstack((act, act)).T\n        hist = interval_histogram_comb(act_2d, 0.79, min_tau=24, max_tau=150)\n        # test both channels individually\n        self.assertTrue(np.allclose(hist[0][0, :6], self.hist_0_6))\n        # 2nd channel is the same\n        self.assertTrue(np.allclose(hist[0][1, :6], self.hist_0_6))\n        self.assertTrue(np.allclose(hist[1], np.arange(24, 151)))\n\n\nclass TestSmoothHistogramFunction(unittest.TestCase):\n\n    def test_values(self):\n        hist = smooth_histogram(HIST, 3)\n        self.assertTrue(np.allclose(hist[0][:6], [3.32079628, 2.46180239,\n                                                  2.84665606, 2.34311077,\n                                                  2.01348008, 1.73241048]))\n        self.assertTrue(np.allclose(hist[1], HIST[1]))\n\n\nclass TestDominantIntervalFunction(unittest.TestCase):\n\n    def test_values(self):\n        result = dominant_interval(HIST)\n        self.assertTrue(result == 34)\n\n\nclass TestDetectTempoFunction(unittest.TestCase):\n\n    def test_values(self):\n        result = detect_tempo(HIST, fps)\n        self.assertTrue(np.allclose(result[:5], [[176.47, 0.169],\n                                                 [117.65, 0.064],\n                                                 [250.0, 0.051],\n                                                 [230.77, 0.041],\n                                                 [105.26, 0.040]], atol=0.1))\n\n\nclass TestTempoEstimationProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = TempoEstimationProcessor(fps=fps)\n        self.online_processor = TempoEstimationProcessor(fps=fps, online=True)\n\n    def test_types(self):\n        self.assertIsInstance(self.processor.method, str)\n        self.assertIsInstance(self.processor.min_bpm, float)\n        self.assertIsInstance(self.processor.max_bpm, float)\n        self.assertIsInstance(self.processor.act_smooth, float)\n        self.assertIsInstance(self.processor.hist_smooth, int)\n        self.assertIsInstance(self.processor.fps, float)\n        self.assertIsInstance(self.processor.histogram_processor,\n                              TempoHistogramProcessor)\n\n    def test_values(self):\n        self.assertTrue(self.processor.method == \'comb\')\n        self.assertTrue(self.processor.min_bpm == 40)\n        self.assertTrue(self.processor.max_bpm == 250)\n        self.assertTrue(self.processor.act_smooth == 0.14)\n        self.assertTrue(self.processor.hist_smooth == 9)\n        self.assertTrue(self.processor.fps == 100)\n        # test default values of the histogram processor\n        self.assertTrue(self.processor.histogram_processor.alpha == 0.79)\n        self.assertTrue(self.processor.histogram_processor.min_interval == 24)\n        self.assertTrue(self.processor.histogram_processor.max_interval == 150)\n\n    def test_process(self):\n        tempi = self.processor(act)\n        self.assertTrue(np.allclose(tempi, COMB_TEMPI, atol=0.01))\n\n    def test_process_online(self):\n        # process all activations at once\n        tempi = self.online_processor(act, reset=False)\n        self.assertTrue(np.allclose(tempi, COMB_TEMPI_ONLINE))\n        # process frame by frame; with resetting results are the same\n        self.online_processor.reset()\n        tempi = [self.online_processor(np.atleast_1d(a), reset=False)\n                 for a in act]\n        self.assertTrue(np.allclose(tempi[-1], COMB_TEMPI_ONLINE))\n        # without resetting results are different\n        tempi = [self.online_processor(np.atleast_1d(a), reset=False)\n                 for a in act]\n        self.assertTrue(np.allclose(tempi[-1][:3], [[176.470588, 0.31322337],\n                                                    [85.7142857, 0.11437361],\n                                                    [115.384615, 0.10919612]]))\n\n\nclass TestCombFilterTempoHistogramProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = CombFilterTempoHistogramProcessor(fps=fps)\n        self.online_processor = CombFilterTempoHistogramProcessor(fps=fps,\n                                                                  online=True)\n\n    def test_types(self):\n        self.assertIsInstance(self.processor.min_bpm, float)\n        self.assertIsInstance(self.processor.max_bpm, float)\n        self.assertIsInstance(self.processor.alpha, float)\n        self.assertIsInstance(self.processor.fps, float)\n        # properties\n        self.assertIsInstance(self.processor.min_interval, int)\n        self.assertIsInstance(self.processor.max_interval, int)\n\n    def test_values(self):\n        self.assertTrue(self.processor.min_bpm == 40)\n        self.assertTrue(self.processor.max_bpm == 250)\n        self.assertTrue(self.processor.alpha == 0.79)\n        self.assertTrue(self.processor.fps == 100)\n        self.assertTrue(self.processor.min_interval == 24)\n        self.assertTrue(self.processor.max_interval == 150)\n\n    def test_tempo(self):\n        tempo_processor = TempoEstimationProcessor(\n            histogram_processor=self.processor, fps=fps)\n        tempi = tempo_processor(act)\n        self.assertTrue(np.allclose(tempi, COMB_TEMPI, atol=0.01))\n\n    def test_tempo_online(self):\n        tempo_processor = TempoEstimationProcessor(\n            histogram_processor=self.online_processor, fps=fps, online=True)\n        # process all activations at once\n        tempi = tempo_processor(act, reset=False)\n        self.assertTrue(np.allclose(tempi, COMB_TEMPI_ONLINE))\n        # process frame by frame; with resetting results are the same\n        tempo_processor.reset()\n        tempi = [tempo_processor(np.atleast_1d(a), reset=False) for a in act]\n        self.assertTrue(np.allclose(tempi[-1], COMB_TEMPI_ONLINE))\n        # without resetting results are different\n        tempi = [tempo_processor(np.atleast_1d(a), reset=False) for a in act]\n        self.assertTrue(np.allclose(tempi[-1][:3], [[176.470588, 0.31322337],\n                                                    [85.7142857, 0.11437361],\n                                                    [115.384615, 0.10919612]]))\n\n    def test_process(self):\n        hist, delays = self.processor(act)\n        self.assertTrue(np.allclose(delays, np.arange(24, 151)))\n        self.assertTrue(np.allclose(hist.max(), 10.5064280455))\n        self.assertTrue(np.allclose(hist.min(), 1.23250838113))\n        self.assertTrue(np.allclose(hist.argmax(), 10))\n        self.assertTrue(np.allclose(hist.argmin(), 44))\n        self.assertTrue(np.allclose(np.sum(hist), 231.568316445))\n        self.assertTrue(np.allclose(np.mean(hist), 1.82337257043))\n        self.assertTrue(np.allclose(np.median(hist), 1.48112542203))\n\n    def test_process_online(self):\n        # offline results\n        hist_offline, delays_offline = self.processor(act)\n        # calling with all activations at once\n        hist, delays = self.online_processor(act)\n        # result must be the same as for offline processing\n        self.assertTrue(np.allclose(hist, hist_offline))\n        self.assertTrue(np.allclose(delays, delays_offline))\n        # calling frame by frame after resetting\n        self.online_processor.reset()\n        result = [self.online_processor(np.atleast_1d(a), reset=False)\n                  for a in act]\n        # the final result must be the same as for offline processing\n        hist, delays = result[-1]\n        hist_, delays_ = self.processor(act)\n        self.assertTrue(np.allclose(hist, hist_))\n        self.assertTrue(np.allclose(delays, delays_))\n        # result after 100 frames\n        hist, delays = result[99]\n        self.assertTrue(np.allclose(hist.max(), 2.03108930086))\n        self.assertTrue(np.allclose(hist.min(), 1.23250838113))\n        self.assertTrue(np.allclose(hist.argmax(), 12))\n        self.assertTrue(np.allclose(hist.argmin(), 44))\n        self.assertTrue(np.allclose(np.sum(hist), 175.034206851))\n        self.assertTrue(np.allclose(np.mean(hist), 1.37822210119))\n        self.assertTrue(np.allclose(np.median(hist), 1.23250838113))\n        # the final result must be the same as for offline processing\n        hist, delays = result[-1]\n        self.assertTrue(np.allclose(hist, hist_offline))\n        self.assertTrue(np.allclose(delays, delays_offline))\n        # results must be different without resetting\n        result = [self.online_processor(np.atleast_1d(a), reset=False)\n                  for a in act]\n        hist, delays = result[-1]\n        self.assertTrue(np.allclose(hist.max(), 18.1385269354))\n        self.assertTrue(np.allclose(hist.min(), 1.23250838113))\n        self.assertTrue(np.allclose(hist.argmax(), 11))\n        self.assertTrue(np.allclose(hist.argmin(), 72))\n        self.assertTrue(np.allclose(np.sum(hist), 332.668525522))\n        self.assertTrue(np.allclose(np.mean(hist), 2.61943720884))\n        self.assertTrue(np.allclose(np.median(hist), 1.96220625848))\n\n\nclass TestACFTempoHistogramProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = ACFTempoHistogramProcessor(fps=fps)\n        self.online_processor = ACFTempoHistogramProcessor(fps=fps,\n                                                           online=True)\n\n    def test_types(self):\n        self.assertIsInstance(self.processor.min_bpm, float)\n        self.assertIsInstance(self.processor.max_bpm, float)\n        self.assertIsInstance(self.processor.fps, float)\n        # properties\n        self.assertIsInstance(self.processor.min_interval, int)\n        self.assertIsInstance(self.processor.max_interval, int)\n\n    def test_values(self):\n        self.assertTrue(self.processor.min_bpm == 40)\n        self.assertTrue(self.processor.max_bpm == 250)\n        self.assertTrue(self.processor.fps == 100)\n        self.assertTrue(self.processor.min_interval == 24)\n        self.assertTrue(self.processor.max_interval == 150)\n\n    def test_tempo(self):\n        tempo_processor = TempoEstimationProcessor(\n            histogram_processor=self.processor, fps=fps)\n        tempi = tempo_processor(act)\n        self.assertTrue(np.allclose(tempi, ACF_TEMPI, atol=0.01))\n\n    def test_tempo_online(self):\n        tempo_processor = TempoEstimationProcessor(\n            histogram_processor=self.online_processor, fps=fps, online=True)\n        # process all activations at once\n        tempi = tempo_processor(act, reset=False)\n        self.assertTrue(np.allclose(tempi, ACF_TEMPI_ONLINE))\n        # process frame by frame; with resetting results are the same\n        tempo_processor.reset()\n        tempi = [tempo_processor(np.atleast_1d(a), reset=False) for a in act]\n        self.assertTrue(np.allclose(tempi[-1], ACF_TEMPI_ONLINE))\n        # without resetting results are different\n        tempi = [tempo_processor(np.atleast_1d(a), reset=False) for a in act]\n        self.assertTrue(np.allclose(tempi[-1][:3], [[176.4705882, 0.2414368],\n                                                    [86.95652174, 0.2248635],\n                                                    [58.25242718, 0.1878183]]))\n\n    def test_process(self):\n        hist, delays = self.processor(act)\n        self.assertTrue(np.allclose(delays, np.arange(24, 151)))\n        self.assertTrue(np.allclose(hist.max(), 0.772242703961))\n        self.assertTrue(np.allclose(hist.min(), 0.0550745515184))\n        self.assertTrue(np.allclose(hist.argmax(), 11))\n        self.assertTrue(np.allclose(hist.argmin(), 103))\n        self.assertTrue(np.allclose(np.sum(hist), 28.4273056042))\n        self.assertTrue(np.allclose(np.mean(hist), 0.223837052001))\n        self.assertTrue(np.allclose(np.median(hist), 0.147368463433))\n\n    def test_process_online(self):\n        # offline results\n        hist_offline, delays_offline = self.processor(act)\n        # calling with all activations at once\n        hist, delays = self.online_processor(act)\n        # result must be the same as for offline processing\n        self.assertTrue(np.allclose(hist, hist_offline))\n        self.assertTrue(np.allclose(delays, delays_offline))\n        # calling frame by frame after resetting\n        self.online_processor.reset()\n        result = [self.online_processor(np.atleast_1d(a), reset=False)\n                  for a in act]\n        # the final result must be the same as for offline processing\n        hist, delays = result[-1]\n        hist_, delays_ = self.processor(act)\n        self.assertTrue(np.allclose(hist, hist_))\n        self.assertTrue(np.allclose(delays, delays_))\n        # result after 100 frames\n        hist, delays = result[99]\n        self.assertTrue(np.allclose(hist.max(), 0.19544739526))\n        self.assertTrue(np.allclose(hist.min(), 0))\n        self.assertTrue(np.allclose(hist.argmax(), 46))\n        self.assertTrue(np.allclose(hist.argmin(), 76))\n        self.assertTrue(np.allclose(np.sum(hist), 3.58546628975))\n        self.assertTrue(np.allclose(np.mean(hist), 0.0282320180295))\n        self.assertTrue(np.allclose(np.median(hist), 0.00471735456373))\n        # the final result must be the same as for offline processing\n        hist, delays = result[-1]\n        self.assertTrue(np.allclose(hist, hist_offline))\n        self.assertTrue(np.allclose(delays, delays_offline))\n\n\nclass TestDBNTempoHistogramProcessorClass(unittest.TestCase):\n\n    def setUp(self):\n        self.processor = DBNTempoHistogramProcessor(fps=fps)\n        self.online_processor = DBNTempoHistogramProcessor(fps=fps,\n                                                           online=True)\n\n    def test_types(self):\n        self.assertIsInstance(self.processor.min_bpm, float)\n        self.assertIsInstance(self.processor.max_bpm, float)\n        self.assertIsInstance(self.processor.fps, float)\n        # properties\n        self.assertIsInstance(self.processor.min_interval, int)\n        self.assertIsInstance(self.processor.max_interval, int)\n\n    def test_values(self):\n        self.assertTrue(self.processor.min_bpm == 40)\n        self.assertTrue(self.processor.max_bpm == 250)\n        self.assertTrue(self.processor.fps == 100)\n        self.assertTrue(self.processor.min_interval == 24)\n        self.assertTrue(self.processor.max_interval == 150)\n\n    def test_tempo(self):\n        tempo_processor = TempoEstimationProcessor(\n            histogram_processor=self.processor, fps=fps)\n        tempi = tempo_processor(act)\n        self.assertTrue(np.allclose(tempi, DBN_TEMPI, atol=0.01))\n\n    def test_tempo_online(self):\n        tempo_processor = TempoEstimationProcessor(\n            histogram_processor=self.online_processor, fps=fps, online=True)\n        # process all activations at once\n        tempi = tempo_processor(act, reset=False)\n        self.assertTrue(np.allclose(tempi, DBN_TEMPI_ONLINE))\n        # process frame by frame; with resetting results are the same\n        tempo_processor.reset()\n        tempo_processor.reset()\n        tempi = [tempo_processor(np.atleast_1d(a), reset=False) for a in act]\n        self.assertTrue(np.allclose(tempi[-1], DBN_TEMPI_ONLINE))\n        # without resetting results are different\n        tempi = [tempo_processor(np.atleast_1d(a), reset=False) for a in act]\n        self.assertTrue(np.allclose(tempi[-1][:3],\n                                    [[176.4705882, 0.472499032],\n                                     [84.5070423, 0.432130320],\n                                     [74.0740741, 0.0699384753]]))\n\n    def test_process(self):\n        hist, delays = self.processor(act)\n        self.assertTrue(np.allclose(delays, np.arange(24, 151)))\n        self.assertTrue(np.allclose(hist.max(), 281))\n        self.assertTrue(np.allclose(hist.min(), 0))\n        self.assertTrue(np.allclose(hist.argmax(), 10))\n        self.assertTrue(np.allclose(hist.argmin(), 0))\n        self.assertTrue(np.allclose(np.sum(hist), 281))\n        self.assertTrue(np.allclose(np.mean(hist), 2.2125984252))\n        self.assertTrue(np.allclose(np.median(hist), 0))\n\n    def test_process_online(self):\n        hist, delays = self.online_processor(act)\n        self.assertTrue(np.allclose(delays, np.arange(24, 151)))\n        self.assertTrue(np.allclose(hist.max(), 106))\n        self.assertTrue(np.allclose(hist.min(), 0))\n        self.assertTrue(np.allclose(hist.argmax(), 10))\n        self.assertTrue(np.allclose(hist.argmin(), 1))\n        self.assertTrue(np.allclose(np.sum(hist), 281))\n        self.assertTrue(np.allclose(np.mean(hist), 2.2125984252))\n        self.assertTrue(np.allclose(np.median(hist), 0))\n\n\nclass TestWriteTempoFunction(unittest.TestCase):\n\n    def setUp(self):\n        import tempfile\n        self.out_file = tempfile.NamedTemporaryFile(delete=False).name\n\n    def test_types(self):\n        # must work with 2d arrays\n        write_tempo(COMB_TEMPI[:1], self.out_file)\n        # but also with 1d arrays\n        write_tempo(COMB_TEMPI[0], self.out_file)\n\n    def test_values(self):\n        # only one tempo given (>68 bpm)\n        write_tempo(COMB_TEMPI[0], self.out_file)\n        result = load_tempo(self.out_file)\n        self.assertTrue(np.allclose(result, [[176.47, 1]],\n                                    atol=1e-4, equal_nan=True))\n        # only one tempo given (<68 bpm)\n        write_tempo(COMB_TEMPI[3] / 2, self.out_file)\n        result = load_tempo(self.out_file)\n        self.assertTrue(np.allclose(result, [[34.48, 1]],\n                                    atol=1e-4, equal_nan=True))\n        # multiple tempi given\n        write_tempo(COMB_TEMPI, self.out_file)\n        result = load_tempo(self.out_file)\n        self.assertTrue(np.allclose(result, [[176.47, 0.73],\n                                             [117.65, 0.27]], atol=1e-4))\n\n    def test_values_mirex(self):\n        # multiple tempi given\n        write_tempo(COMB_TEMPI, self.out_file, mirex=True)\n        result = load_tempo(self.out_file)\n        self.assertTrue(np.allclose(result, [[117.65, 0.27],\n                                             [176.47, 0.73]], atol=1e-4))\n\n    def tearDown(self):\n        import os\n        os.unlink(self.out_file)\n'"
tests/test_io.py,24,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains test functions for the madmom.io module.\n\nPlease note that most loading functions are tested from within the respective\nevaluation module tests, because the expected values are defined in these\ntests.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join as pj, join\n\nfrom madmom.io import *\nfrom madmom.io import load_beats, load_key, load_notes, load_onsets, load_tempo\nfrom tests import ANNOTATIONS_PATH, DETECTIONS_PATH\nfrom . import DATA_PATH\n\nEVENTS = [1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3]\n\n\nclass TestLoadEventsFunction(unittest.TestCase):\n\n    def test_read_events_from_file(self):\n        events = load_events(pj(DATA_PATH, \'events.txt\'))\n        self.assertIsInstance(events, np.ndarray)\n\n    def test_read_events_from_file_handle(self):\n        file_handle = open(pj(DATA_PATH, \'events.txt\'))\n        events = load_events(file_handle)\n        self.assertIsInstance(events, np.ndarray)\n        file_handle.close()\n\n    def test_load_file_with_comments_and_empty_lines(self):\n        events = load_events(pj(DATA_PATH, \'commented_txt\'))\n        self.assertTrue(np.allclose(events, [1.1, 2.1]))\n\n\nclass TestWriteEventsFunction(unittest.TestCase):\n\n    def test_write_events_to_file(self):\n        write_events(EVENTS, pj(DATA_PATH, \'events.txt\'))\n        annotations = load_events(pj(DATA_PATH, \'events.txt\'))\n        self.assertTrue(np.allclose(annotations, EVENTS))\n\n    def test_write_events_to_file_handle(self):\n        file_handle = open(pj(DATA_PATH, \'events.txt\'), \'wb\')\n        write_events(EVENTS, file_handle)\n        file_handle.close()\n        annotations = load_events(pj(DATA_PATH, \'events.txt\'))\n        self.assertTrue(np.allclose(annotations, EVENTS))\n\n    def test_write_and_read_events(self):\n        write_events(EVENTS, pj(DATA_PATH, \'events.txt\'))\n        annotations = load_events(pj(DATA_PATH, \'events.txt\'))\n        self.assertTrue(np.allclose(annotations, EVENTS))\n\n\nclass TestLoadBeatsFunction(unittest.TestCase):\n\n    def test_load_beats_from_file(self):\n        beats = load_beats(pj(ANNOTATIONS_PATH, \'sample.beats\'))\n        from tests.test_evaluation_beats import SAMPLE_BEAT_ANNOTATIONS\n        self.assertTrue(np.allclose(beats, SAMPLE_BEAT_ANNOTATIONS))\n\n    def test_load_downbeats_from_file(self):\n        downbeats = load_beats(pj(ANNOTATIONS_PATH, \'sample.beats\'),\n                               downbeats=True)\n        self.assertTrue(np.allclose(downbeats, 0.0913))\n\n\nclass TestLoadChordsFunction(unittest.TestCase):\n\n    def test_read_chords_from_file(self):\n        chords = load_chords(pj(DETECTIONS_PATH,\n                             \'sample.dc_chord_recognition.txt\'))\n        self.assertIsInstance(chords, np.ndarray)\n        self.assertEqual(chords[0][0], 0.0)\n        self.assertEqual(chords[0][1], 2.9)\n        self.assertEqual(chords[0][2], \'G#:maj\')\n\n    def test_read_chords_from_file_handle(self):\n        with open(pj(DETECTIONS_PATH,\n                     \'sample.dc_chord_recognition.txt\')) as file_handle:\n            chords = load_chords(file_handle)\n            self.assertIsInstance(chords, np.ndarray)\n            self.assertEqual(chords[0][0], 0.0)\n            self.assertEqual(chords[0][1], 2.9)\n            self.assertEqual(chords[0][2], \'G#:maj\')\n\n\nclass TestLoadKeyFunction(unittest.TestCase):\n\n    def test_load_key_from_file(self):\n        key = load_key(join(ANNOTATIONS_PATH, \'dummy.key\'))\n        self.assertEqual(key, \'F# minor\')\n        key = load_key(join(DETECTIONS_PATH, \'dummy.key.txt\'))\n        self.assertEqual(key, \'a maj\')\n        key = load_key(open(join(ANNOTATIONS_PATH, \'dummy.key\')))\n        self.assertEqual(key, \'F# minor\')\n        key = load_key(open(join(DETECTIONS_PATH, \'dummy.key.txt\')))\n        self.assertEqual(key, \'a maj\')\n\n\nclass TestLoadNotesFunction(unittest.TestCase):\n\n    def test_load_notes_from_file(self):\n        annotations = load_notes(pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'))\n        self.assertIsInstance(annotations, np.ndarray)\n\n    def test_load_notes_from_file_handle(self):\n        file_handle = open(pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'))\n        annotations = load_notes(file_handle)\n        self.assertIsInstance(annotations, np.ndarray)\n        file_handle.close()\n\n    def test_load_notes_annotations(self):\n        from tests.test_evaluation_notes import ANNOTATIONS\n        annotations = load_notes(pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'))\n        self.assertIsInstance(annotations, np.ndarray)\n        self.assertEqual(annotations.shape, (8, 4))\n        self.assertTrue(np.allclose(annotations, ANNOTATIONS))\n\n\nclass TestWriteNotesFunction(unittest.TestCase):\n\n    def test_values(self):\n        from tests.test_evaluation_notes import ANNOTATIONS\n        header = ""MIDI notes for the stereo_sample.[flac|wav] file""\n        write_notes(ANNOTATIONS,\n                    pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'), header=header)\n\n\nclass TestLoadOnsetsFunction(unittest.TestCase):\n\n    def test_load_onsets(self):\n        from tests.test_evaluation_onsets import SAMPLE_ANNOTATIONS\n        events = load_onsets(pj(ANNOTATIONS_PATH, \'sample.onsets\'))\n        self.assertTrue(np.allclose(events, SAMPLE_ANNOTATIONS))\n\n    def test_load_onsets_without_comments(self):\n        from tests.test_evaluation_onsets import SAMPLE_DETECTIONS\n\n        events = load_onsets(pj(DETECTIONS_PATH, \'sample.super_flux.txt\'))\n        self.assertTrue(np.allclose(events, SAMPLE_DETECTIONS))\n\n    def test_onsets_with_comments_and_empty_lines(self):\n        events = load_onsets(pj(DATA_PATH, \'commented_txt\'))\n        self.assertTrue(np.allclose(events, [1.1, 2.1]))\n\n    def test_load_timestamps_only(self):\n        events = load_onsets(pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'))\n        self.assertTrue(np.allclose(events, [0.147, 1.567, 2.526, 2.549, 2.563,\n                                             2.577, 3.369, 3.449]))\n\n\nclass TestLoadTempoFunction(unittest.TestCase):\n\n    def test_load_tempo_from_file(self):\n        annotations = load_tempo(pj(ANNOTATIONS_PATH, \'sample.tempo\'))\n        self.assertIsInstance(annotations, np.ndarray)\n\n    def test_load_tempo_from_file_handle(self):\n        file_handle = open(pj(ANNOTATIONS_PATH, \'sample.tempo\'))\n        annotations = load_tempo(file_handle)\n        self.assertIsInstance(annotations, np.ndarray)\n        file_handle.close()\n\n    def test_load_tempo_annotations(self):\n        from tests.test_evaluation_tempo import (ANNOTATIONS, ANN_TEMPI,\n                                                 ANN_STRENGTHS)\n        annotations = load_tempo(pj(ANNOTATIONS_PATH, \'sample.tempo\'))\n        self.assertIsInstance(annotations, np.ndarray)\n        self.assertEqual(annotations.shape, (2, 2))\n        self.assertTrue(np.allclose(annotations, ANNOTATIONS))\n        self.assertTrue(np.allclose(annotations[:, 0], ANN_TEMPI))\n        self.assertTrue(np.allclose(annotations[:, 1], ANN_STRENGTHS))\n'"
tests/test_io_audio.py,43,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.audio.signal module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join as pj\nimport io\n\nfrom madmom.io.audio import *\nfrom . import AUDIO_PATH, DATA_PATH\n\nsample_file = pj(AUDIO_PATH, \'sample.wav\')\nsample_file_22k = pj(AUDIO_PATH, \'sample_22050.wav\')\nstereo_sample_file = pj(AUDIO_PATH, \'stereo_sample.wav\')\nflac_file = pj(AUDIO_PATH, \'stereo_sample.flac\')\nm4a_file = pj(AUDIO_PATH, \'stereo_sample.m4a\')\nrg_flac_file = pj(AUDIO_PATH, \'stereo_sample_rg.flac\')\nloud_rg_flac_file = pj(AUDIO_PATH, \'stereo_chirp_rg.flac\')\n\ntmp_file = tempfile.NamedTemporaryFile(delete=False).name\n\n\nclass TestLoadWaveFileFunction(unittest.TestCase):\n\n    def test_types(self):\n        signal, sample_rate = load_wave_file(sample_file)\n        self.assertIsInstance(signal, np.ndarray)\n        self.assertTrue(signal.dtype == np.int16)\n        self.assertTrue(type(sample_rate) == int)\n\n    def test_file_handle(self):\n        # open file handle\n        with open(sample_file, \'rb\') as file_handle:\n            signal, sample_rate = load_wave_file(file_handle)\n        self.assertIsInstance(signal, np.ndarray)\n        self.assertTrue(signal.dtype == np.int16)\n        self.assertTrue(type(sample_rate) == int)\n\n    def test_values(self):\n        # test wave loader\n        signal, sample_rate = load_wave_file(sample_file)\n        self.assertTrue(np.allclose(signal[:5],\n                                    [-2494, -2510, -2484, -2678, -2833]))\n        self.assertTrue(len(signal) == 123481)\n        self.assertTrue(sample_rate == 44100)\n        self.assertTrue(signal.shape == (123481,))\n        # stereo\n        signal, sample_rate = load_wave_file(stereo_sample_file)\n        self.assertTrue(np.allclose(signal[:4],\n                                    [[33, 38], [35, 36], [29, 34], [36, 31]]))\n        self.assertTrue(len(signal) == 182919)\n        self.assertTrue(sample_rate == 44100)\n        self.assertTrue(signal.shape == (182919, 2))\n\n    def test_start_stop(self):\n        # test wave loader\n        signal, sample_rate = load_wave_file(sample_file, start=1. / 44100,\n                                             stop=5. / 44100)\n        self.assertTrue(np.allclose(signal, [-2510, -2484, -2678, -2833]))\n        self.assertTrue(len(signal) == 4)\n        self.assertTrue(sample_rate == 44100)\n\n    def test_downmix(self):\n        # test wave loader\n        signal, sample_rate = load_wave_file(stereo_sample_file,\n                                             num_channels=1)\n        self.assertTrue(np.allclose(signal[:5], [35, 35, 31, 33, 33]))\n\n        self.assertTrue(len(signal) == 182919)\n        self.assertTrue(sample_rate == 44100)\n        self.assertTrue(signal.shape == (182919,))\n\n    def test_channel_choice(self):\n        signal, sample_rate = load_wave_file(stereo_sample_file, channel=0)\n        self.assertTrue(signal.shape == (182919,))\n        self.assertTrue(np.allclose(signal[:4], [33, 35, 29, 36]))\n        signal, sample_rate = load_wave_file(stereo_sample_file, channel=1)\n        self.assertTrue(np.allclose(signal[:4], [38, 36, 34, 31]))\n\n    def test_upmix(self):\n        signal, sample_rate = load_wave_file(sample_file, num_channels=2)\n        self.assertTrue(np.allclose(signal[:5],\n                                    [[-2494, -2494], [-2510, -2510],\n                                     [-2484, -2484], [-2678, -2678],\n                                     [-2833, -2833]]))\n        self.assertTrue(len(signal) == 123481)\n        self.assertTrue(sample_rate == 44100)\n        self.assertTrue(signal.shape == (123481, 2))\n\n    def test_errors(self):\n        # resampling of wav not supported\n        with self.assertRaises(ValueError):\n            load_wave_file(sample_file, sample_rate=22050)\n        # resampling of wav not supported\n        with self.assertRaises(ValueError):\n            load_wave_file(sample_file, dtype=np.float)\n        # file not found\n        with self.assertRaises(IOError):\n            load_wave_file(pj(AUDIO_PATH, \'foo_bar.wav\'))\n        # not an audio file\n        with self.assertRaises(ValueError):\n            load_wave_file(pj(DATA_PATH, \'README\'))\n        # closed file handle\n        with self.assertRaises(ValueError):\n            file_handle = open(sample_file, \'rb\')\n            file_handle.close()\n            load_wave_file(file_handle)\n\n\nclass TestWriteWaveFileFunction(unittest.TestCase):\n\n    def setUp(self):\n        self.signal = Signal(sample_file)\n        write_wave_file(self.signal, tmp_file)\n        self.result = Signal(sample_file)\n\n    def test_types(self):\n        self.assertIsInstance(self.result, Signal)\n        self.assertIsInstance(self.result, np.ndarray)\n        self.assertTrue(self.result.dtype == np.int16)\n        self.assertTrue(type(self.result.sample_rate) == int)\n\n    def test_values(self):\n        # test wave loader\n        self.assertTrue(np.allclose(self.signal, self.result))\n        self.assertTrue(self.result.sample_rate == 44100)\n        self.assertTrue(self.result.shape == (123481,))\n\n\nclass TestLoadAudioFileFunction(unittest.TestCase):\n\n    # this tests both madmom.io.audio.load_wave_file() and\n    # madmom.io.audio.load_ffmpeg_file() functions via the universal\n    # load_audio_file() function\n\n    def test_types(self):\n        # test wave loader\n        signal, sample_rate = load_audio_file(sample_file)\n        self.assertIsInstance(signal, np.ndarray)\n        self.assertTrue(signal.dtype == np.int16)\n        self.assertTrue(type(sample_rate) == int)\n        # test ffmpeg loader\n        signal, sample_rate = load_audio_file(stereo_sample_file)\n        self.assertIsInstance(signal, np.ndarray)\n        self.assertTrue(signal.dtype == np.int16)\n        self.assertTrue(type(sample_rate) == int)\n        if sys.version_info[0] == 2:\n            # test unicode string type (Python 2 only)\n            signal, sample_rate = load_audio_file(unicode(sample_file))\n\n    def test_file_handle(self):\n        # test wave loader\n        with open(sample_file, \'rb\') as file_handle:\n            signal, sample_rate = load_audio_file(file_handle)\n        self.assertIsInstance(signal, np.ndarray)\n        self.assertTrue(signal.dtype == np.int16)\n        self.assertTrue(type(sample_rate) == int)\n        # test ffmpeg loader\n        with open(sample_file, \'rb\') as file_handle:\n            signal, sample_rate = load_audio_file(file_handle)\n        self.assertIsInstance(signal, np.ndarray)\n        self.assertTrue(signal.dtype == np.int16)\n        self.assertTrue(type(sample_rate) == int)\n\n    def test_values(self):\n        # test wave loader\n        signal, sample_rate = load_audio_file(sample_file)\n        self.assertTrue(np.allclose(signal[:5],\n                                    [-2494, -2510, -2484, -2678, -2833]))\n        self.assertTrue(len(signal) == 123481)\n        self.assertTrue(sample_rate == 44100)\n        self.assertTrue(signal.shape == (123481,))\n        # stereo\n        signal, sample_rate = load_audio_file(stereo_sample_file)\n        self.assertTrue(np.allclose(signal[:4],\n                                    [[33, 38], [35, 36], [29, 34], [36, 31]]))\n        self.assertTrue(len(signal) == 182919)\n        self.assertTrue(sample_rate == 44100)\n        self.assertTrue(signal.shape == (182919, 2))\n        # test ffmpeg loader\n        signal, sample_rate = load_audio_file(stereo_sample_file)\n        self.assertTrue(np.allclose(signal[:4],\n                                    [[33, 38], [35, 36], [29, 34], [36, 31]]))\n        self.assertTrue(len(signal) == 182919)\n        self.assertTrue(sample_rate == 44100)\n        self.assertTrue(signal.shape == (182919, 2))\n\n    def test_wave_channel_selection(self):\n        signal, sample_rate = load_audio_file(stereo_sample_file, channel=1)\n        self.assertTrue(signal.shape == (182919,))\n        self.assertTrue(np.allclose(signal[:4], [38, 36, 34, 31]))\n\n    def test_start_stop(self):\n        # test wave loader\n        signal, sample_rate = load_audio_file(sample_file, start=1. / 44100,\n                                              stop=5. / 44100)\n        self.assertTrue(np.allclose(signal, [-2510, -2484, -2678, -2833]))\n        self.assertTrue(len(signal) == 4)\n        self.assertTrue(sample_rate == 44100)\n        # test ffmpeg loader\n        signal, sample_rate = load_audio_file(stereo_sample_file,\n                                              start=1. / 44100,\n                                              stop=4. / 44100)\n        self.assertTrue(np.allclose(signal, [[35, 36], [29, 34], [36, 31]]))\n        self.assertTrue(len(signal) == 3)\n        self.assertTrue(sample_rate == 44100)\n\n    def test_downmix(self):\n        # test wave loader\n        signal, sample_rate = load_audio_file(stereo_sample_file,\n                                              num_channels=1)\n        self.assertTrue(np.allclose(signal[:5],\n                                    [35, 35, 31, 33, 33]))\n        self.assertTrue(len(signal) == 182919)\n        self.assertTrue(sample_rate == 44100)\n        self.assertTrue(signal.shape == (182919,))\n        # test ffmpeg loader\n        signal, sample_rate = load_audio_file(stereo_sample_file,\n                                              num_channels=1)\n        # results are rounded differently, thus allow atol=1\n        self.assertTrue(np.allclose(signal[:5], [35, 35, 31, 33, 33], atol=1))\n        # avconv results in a different length of 182909 samples\n        self.assertTrue(np.allclose(len(signal), 182919, atol=10))\n        self.assertTrue(sample_rate == 44100)\n        # test clipping\n        f = pj(AUDIO_PATH, \'stereo_chirp.wav\')\n        signal, _ = load_audio_file(f, num_channels=1)\n        signal_stereo, _ = load_audio_file(f)\n        # sanity checks\n        self.assertTrue(np.allclose(signal_stereo[:, 0], signal_stereo[:, 1]))\n        self.assertTrue(np.allclose(signal_stereo.mean(axis=1),\n                                    signal_stereo[:, 0]))\n        # check clipping\n        self.assertTrue(np.allclose(signal, signal_stereo[:, 1]))\n\n    def test_upmix(self):\n        signal, sample_rate = load_audio_file(sample_file, num_channels=2)\n        self.assertTrue(np.allclose(signal[:5],\n                                    [[-2494, -2494], [-2510, -2510],\n                                     [-2484, -2484], [-2678, -2678],\n                                     [-2833, -2833]]))\n        self.assertTrue(len(signal) == 123481)\n        self.assertTrue(sample_rate == 44100)\n        self.assertTrue(signal.shape == (123481, 2))\n\n    def test_resample(self):\n        # method must chose ffmpeg loader\n        signal, sample_rate = load_audio_file(stereo_sample_file,\n                                              sample_rate=22050)\n        self.assertTrue(sample_rate == 22050)\n        # avconv does round differently, thus allow atol=1\n        # result: [[33, 38], [33, 33], [36, 31], [35, 35], [32, 35]]\n        self.assertTrue(np.allclose(signal[:5], [[34, 38], [32, 33], [37, 31],\n                                                 [35, 35], [32, 34]], atol=1))\n        # also downmix\n        signal, sample_rate = load_audio_file(stereo_sample_file,\n                                              sample_rate=22050,\n                                              num_channels=1)\n        self.assertTrue(np.allclose(signal[:5], [36, 33, 34, 35, 33], atol=1))\n        # avconv results in a different length of 91450 samples\n        self.assertTrue(np.allclose(len(signal), 91460, atol=10))\n\n    def test_choose_channel(self):\n        signal, sample_rate = load_audio_file(flac_file,\n                                              sample_rate=22050,\n                                              num_channels=1, channel=0)\n        # avconv results in a different length of 91450 samples\n        self.assertTrue(np.allclose(len(signal), 91460, atol=10))\n        self.assertTrue(np.allclose(signal[:5], [34, 32, 37, 35, 32], atol=1))\n\n    def test_replaygain_disabled(self):\n        original = load_signal(flac_file)\n        signal = load_signal(rg_flac_file, replaygain_mode=None)\n        self.assertEqual(signal.spl(), original.spl())\n\n    def test_replaygain_track(self):\n        original = load_signal(flac_file)\n        data, sample_rate = load_audio_file(rg_flac_file,\n                                            replaygain_mode=\'track\')\n        signal = Signal(data)\n        self.assertEqual(sample_rate, 44100)\n        # The FLAC file has an RG track gain of +8.39\n        self.assertAlmostEqual(signal.spl() - original.spl(), 8.39, places=3)\n\n    def test_replaygain_album(self):\n        original = load_signal(flac_file)\n        signal = load_signal(rg_flac_file, replaygain_mode=\'album\')\n        # The FLAC file has an RG album gain of -8.12 (the other track is loud)\n        self.assertAlmostEqual(signal.spl() - original.spl(), -8.12, places=3)\n\n    def test_replaygain_preamp(self):\n        signal = load_signal(loud_rg_flac_file)\n        base_spl = signal.spl()\n        rg_sig = load_signal(loud_rg_flac_file, replaygain_mode=\'track\')\n        # Remember, ffmpeg will limit gain to avoid clipping,\n        # so the SPL difference is non-obvious here.\n        self.assertTrue(base_spl > rg_sig.spl())\n        # Preamp on a file with track RG at -12.44 should happily go to -6.44dB\n        pre_rg_sig = load_signal(loud_rg_flac_file,\n                                 replaygain_mode=\'track\',\n                                 replaygain_preamp=+6.0)\n        self.assertAlmostEqual(rg_sig.spl() + 6.0, pre_rg_sig.spl(), places=3)\n\n    def test_errors(self):\n        # file not found\n        with self.assertRaises(IOError):\n            load_audio_file(pj(AUDIO_PATH, \'sample.flac\'))\n        # not an audio file\n        with self.assertRaises(LoadAudioFileError):\n            load_audio_file(pj(DATA_PATH, \'README\'))\n\n\ndef load_signal(fn, *args, **kwargs):\n    return Signal(load_audio_file(fn, *args, **kwargs)[0])\n\n\nclass TestDecodeToDisk(unittest.TestCase):\n    def test_write_to_temp(self):\n        outfile = decode_to_disk(stereo_sample_file, tmp_suffix=\'.raw\')\n        self.assertTrue(os.path.exists(outfile))\n        self.assertGreater(os.stat(outfile).st_size, 100 * 1024)\n\n    def test_write_with_replaygain(self):\n        outfile = decode_to_disk(loud_rg_flac_file, tmp_suffix=\'.raw\')\n        outfile_rg = decode_to_disk(loud_rg_flac_file, tmp_suffix=\'.raw\',\n                                    replaygain_mode=\'track\')\n        with open(outfile, \'rb\') as f:\n            data = np.frombuffer(f.read(), dtype=np.int16).reshape((-1, 2))\n            orig_spl = Signal(data).spl()\n        with open(outfile_rg, \'rb\') as f:\n            data = np.frombuffer(f.read(), dtype=np.int16).reshape((-1, 2))\n            adjusted_spl = Signal(data).spl()\n        self.assertGreater(orig_spl, adjusted_spl)\n\n\nclass TestLoadAudioFromFileObject(unittest.TestCase):\n\n    def test_file_object(self):\n        for file_path in [sample_file, flac_file, m4a_file]:\n            disk_signal = Signal(file_path)\n            with open(file_path, \'rb\') as file_handle:\n                memory_signal = Signal(io.BytesIO(file_handle.read()))\n            self.assertTrue((disk_signal == memory_signal).all)\n\n\n# clean up\ndef teardown_module():\n    os.unlink(tmp_file)\n'"
tests/test_io_midi.py,20,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains test functions for the madmom.utils.midi module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport os\nimport unittest\nimport tempfile\nfrom os.path import join as pj\n\nfrom madmom.io.midi import *\n\nfrom . import ANNOTATIONS_PATH\n\ntmp_file = tempfile.NamedTemporaryFile(delete=False).name\n\n\nclass TestMIDIFileClass(unittest.TestCase):\n\n    def test_notes(self):\n        # read a MIDI file\n        midi = MIDIFile(pj(ANNOTATIONS_PATH, \'stereo_sample.mid\'))\n        notes = np.loadtxt(pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'))\n        self.assertTrue(np.allclose(notes, midi.notes[:, :4], atol=1e-3))\n\n    def test_recreate_midi(self):\n        notes = np.loadtxt(pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'))\n        # create a MIDI file from the notes\n        midi = MIDIFile.from_notes(notes, tempo=120)\n        self.assertTrue(np.allclose(notes, midi.notes[:, :4], atol=1e-3))\n        # write to a temporary file\n        midi.save(tmp_file)\n        tmp_midi = MIDIFile(tmp_file)\n        self.assertTrue(np.allclose(notes, tmp_midi.notes[:, :4], atol=1e-3))\n\n    def test_notes_in_beats(self):\n        # read a MIDI file\n        midi = MIDIFile(pj(ANNOTATIONS_PATH, \'piano_sample.mid\'))\n        midi.unit = \'b\'\n        notes = np.loadtxt(pj(ANNOTATIONS_PATH, \'piano_sample.notes_in_beats\'))\n        self.assertTrue(np.allclose(notes, midi.notes[:, :4]))\n\n    def test_notes_in_ticks(self):\n        # read a MIDI file\n        midi = MIDIFile(pj(ANNOTATIONS_PATH, \'piano_sample.mid\'))\n        midi.unit = \'t\'\n        note_times = [0, 240, 480, 720, 960, 1200, 1440, 1680, 1920, 2160,\n                      2400, 2640, 2880, 3120, 3360, 3600, 3840, 3840, 3840,\n                      4320, 4800, 4800, 5280]\n        self.assertTrue(np.allclose(note_times, midi.notes[:, 0]))\n\n    def test_multitrack(self):\n        # read a multi-track MIDI file\n        midi = MIDIFile(pj(ANNOTATIONS_PATH, \'multitrack.mid\'))\n        self.assertTrue(np.allclose(midi.notes[:4],\n                                    [[0, 60, 0.2272725, 90, 2],\n                                     [0, 72, 0.90814303, 90, 1],\n                                     [0.2272725, 67, 0.22632553, 90, 2],\n                                     [0.45359803, 64, 0.22821947, 90, 2]]))\n        midi.unit = \'b\'\n        self.assertTrue(np.allclose(midi.notes[:4], [[0, 60, 0.5, 90, 2],\n                                                     [0, 72, 2, 90, 1],\n                                                     [0.5, 67, 0.5, 90, 2],\n                                                     [1, 64, 0.5, 90, 2]],\n                                    atol=1e-2))\n\n    def test_sustain(self):\n        # use an existing file as a start\n        midi = MIDIFile(pj(ANNOTATIONS_PATH, \'stereo_sample_sustained.mid\'))\n        # obtain all sustain messages from that file\n        sustain_msgs = []\n        for msg in midi:\n            if msg.type == \'control_change\' and msg.control == 64:\n                sustain_msgs.append(msg)\n        # there\'s only a single sustain message\n        self.assertTrue(len(sustain_msgs) == 4)\n        # the logic adds a another sustain OFF message (i.e. value of 0)\n        self.assertTrue(len(midi.sustain_messages) == 5)\n        self.assertTrue(midi.sustain_messages[-1].value == 0)\n        self.assertTrue(midi.sustain_messages[0] == sustain_msgs[0])\n        # check notes with and without sustain information\n        self.assertTrue(np.allclose(midi.notes,\n                                    [[0.146875, 72., 3.32291667, 63., 0.],\n                                     [1.56666667, 41., 0.22291667, 29., 0.],\n                                     [2.525, 77., 0.93020833, 72., 0.],\n                                     [2.54895833, 60., 0.21041667, 28., 0.],\n                                     [2.5625, 65., 0.20208333, 34., 0.],\n                                     [2.57604167, 56., 0.234375, 31., 0.],\n                                     [3.36875, 75., 0.78020833, 64., 0.],\n                                     [3.44895833, 43., 0.271875, 35., 0.]]))\n        self.assertTrue(np.allclose(midi.sustained_notes,\n                                    [[0.146875, 72., 4.00208333, 63., 0.],\n                                     [1.56666667, 41., 0.22291667, 29., 0.],\n                                     [2.525, 77., 1.62395833, 72., 0.],\n                                     [2.54895833, 60., 0.21041667, 28., 0.],\n                                     [2.5625, 65., 0.20208333, 34., 0.],\n                                     [2.57604167, 56., 0.234375, 31., 0.],\n                                     [3.36875, 75., 0.78020833, 64., 0.],\n                                     [3.44895833, 43., 0.7, 35., 0.]]))\n\n    def test_time_signature(self):\n        midi = MIDIFile(pj(ANNOTATIONS_PATH, \'stereo_sample.mid\'))\n        self.assertTrue(np.allclose(midi.time_signatures, [[0, 4, 4]]))\n\n    def test_tempi(self):\n        midi = MIDIFile(pj(ANNOTATIONS_PATH, \'stereo_sample.mid\'))\n        self.assertTrue(np.allclose(midi.tempi, [[0, 500000]]))\n\n\nclass TestWriteMidiFunction(unittest.TestCase):\n\n    def test_write_midi(self):\n        notes = np.loadtxt(pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'))\n        # write to a temporary file\n        write_midi(notes, tmp_file)\n        # read in that file and compare notes\n        tmp_midi = MIDIFile(tmp_file)\n        self.assertTrue(np.allclose(notes, tmp_midi.notes[:, :4], atol=1e-3))\n\n\nclass TestLoadMidiFunction(unittest.TestCase):\n\n    def test_load_midi(self):\n        notes = load_midi(pj(ANNOTATIONS_PATH, \'stereo_sample.mid\'))\n        notes_txt = np.loadtxt(pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'))\n        self.assertTrue(np.allclose(notes[:, :4], notes_txt, atol=1e-3))\n\n    def test_load_midi_sustained(self):\n        notes = load_midi(pj(ANNOTATIONS_PATH, \'stereo_sample_sustained.mid\'))\n        self.assertTrue(np.allclose(notes[0, 2], 3.32291667))\n        notes = load_midi(pj(ANNOTATIONS_PATH, \'stereo_sample_sustained.mid\'),\n                          sustain=True)\n        self.assertTrue(np.allclose(notes[0, 2], 4.00208333))\n\n\n# clean up\ndef teardown_module():\n    os.unlink(tmp_file)\n'"
tests/test_ml_crf.py,12,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains test for the madmom.ml.crf module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom madmom.ml.crf import *\n\neta = 0.000000000000001  # numerical stability\nPI = np.log(np.array([0.6, 0.2, 0.1, 0.1], dtype=np.float64))\nTAU = np.log(np.ones(4, dtype=np.float64))\nC = np.log(np.ones(4, dtype=np.float64))\n\nA = np.log(np.array([[0.8, 0.2, 0.0, 0.0],\n                     [0.1, 0.6, 0.3, 0.0],\n                     [0.0, 0.2, 0.7, 0.1],\n                     [0.0, 0.0, 0.4, 0.6]]) + eta).astype(np.float64)\n\nW = np.log(np.array([[0.7, 0.1, 0.2, 0.3],\n                     [0.15, 0.4, 0.7, 0.1],\n                     [0.15, 0.5, 0.1, 0.6]]) + eta).astype(np.float64)\n\n\ndef _to_onehot(seq, num_states):\n    oh = np.zeros((len(seq), num_states))\n    oh[range(len(seq)), seq] = 1\n    return oh\n\nOBS_SEQ_1 = _to_onehot(np.array([0, 0, 1, 0, 0, 2, 1, 0, 2, 1, 0, 1, 1, 1, 0,\n                                 2, 0, 2, 0, 1, 1, 2, 0, 0, 0, 1]), 3)\nOBS_SEQ_2 = _to_onehot(np.array([2, 2, 2, 2, 1, 0, 2, 0, 0, 0, 1, 1, 1, 2, 0,\n                                 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1]), 3)\n\n\nclass TestConditionalRandomFieldClass(unittest.TestCase):\n\n    def setUp(self):\n        self.crf = ConditionalRandomField(PI, TAU, C, A, W)\n\n    def test_decode(self):\n        correct_state_seq1 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2,\n                                       2, 3, 3, 3, 3, 3, 2, 2, 1, 0, 0, 0, 0])\n        # correct_p_seq1 = -36.94762254\n        correct_state_seq2 = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2,\n                                       3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2])\n        # correct_p_seq2 = -34.03217714\n\n        state_seq = self.crf.process(OBS_SEQ_1)\n        self.assertTrue((state_seq == correct_state_seq1).all())\n\n        state_seq = self.crf.process(OBS_SEQ_2)\n        self.assertTrue((state_seq == correct_state_seq2).all())\n'"
tests/test_ml_hmm.py,44,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.ml.hmm module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport sys\nimport unittest\nfrom madmom.ml.hmm import *\n\n\nPRIOR = np.array([0.6, 0.2, 0.2])\n\nTRANSITIONS = [(0, 0, 0.7),\n               (0, 1, 0.3),\n               (1, 0, 0.1),\n               (1, 1, 0.6),\n               (1, 2, 0.3),\n               (2, 1, 0.3),\n               (2, 2, 0.7)]\n\nOBS_PROB = np.array([[0.7, 0.15, 0.15],\n                     [0.3, 0.5, 0.2],\n                     [0.2, 0.4, 0.4]])\n\nOBS_SEQ = np.array([0, 2, 2, 0, 0, 1, 1, 2, 0, 2, 1, 1,\n                    1, 2, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n\nCORRECT_FWD = np.array([[0.6754386, 0.23684211, 0.0877193],\n                        [0.369291, 0.36798608, 0.26272292],\n                        [0.18146746, 0.33625874, 0.4822738],\n                        [0.35097423, 0.37533682, 0.27368895],\n                        [0.51780506, 0.32329768, 0.15889725],\n                        [0.17366244, 0.58209473, 0.24424283],\n                        [0.06699296, 0.58957189, 0.34343515],\n                        [0.05708114, 0.3428725, 0.60004636],\n                        [0.18734426, 0.43567034, 0.3769854],\n                        [0.09699435, 0.31882203, 0.58418362],\n                        [0.03609747, 0.47711943, 0.4867831],\n                        [0.02569311, 0.52002881, 0.45427808],\n                        [0.02452257, 0.53259115, 0.44288628],\n                        [0.03637171, 0.31660931, 0.64701899],\n                        [0.02015006, 0.46444741, 0.51540253],\n                        [0.02118133, 0.51228818, 0.46653049],\n                        [0.16609052, 0.48889238, 0.3450171],\n                        [0.06141349, 0.55365814, 0.38492837],\n                        [0.2327641, 0.47273564, 0.29450026],\n                        [0.42127593, 0.37947727, 0.1992468],\n                        [0.57132392, 0.30444215, 0.12423393],\n                        [0.66310201, 0.25840843, 0.07848956],\n                        [0.23315472, 0.59876843, 0.16807684],\n                        [0.43437318, 0.40024174, 0.16538507],\n                        [0.58171672, 0.30436365, 0.11391962]])\n\n\nclass TestTransitionModelClass(unittest.TestCase):\n\n    def setUp(self):\n        frm, to, prob = list(zip(*TRANSITIONS))\n        self.tm = TransitionModel.from_dense(to, frm, prob)\n\n    def test_types(self):\n        self.assertIsInstance(self.tm.states, np.ndarray)\n        self.assertIsInstance(self.tm.pointers, np.ndarray)\n        self.assertIsInstance(self.tm.probabilities, np.ndarray)\n        self.assertIsInstance(self.tm.log_probabilities, np.ndarray)\n        self.assertIsInstance(self.tm.num_states, int)\n        self.assertIsInstance(self.tm.num_transitions, int)\n        self.assertTrue(self.tm.states.dtype == np.uint32)\n        self.assertTrue(self.tm.pointers.dtype == np.uint32)\n        self.assertTrue(self.tm.probabilities.dtype == np.float)\n        self.assertTrue(self.tm.log_probabilities.dtype == np.float)\n\n    def test_values(self):\n        self.assertTrue(np.allclose(self.tm.states, [0, 1, 0, 1, 2, 1, 2]))\n        self.assertTrue(np.allclose(self.tm.pointers, [0, 2, 5, 7]))\n        self.assertTrue(np.allclose(self.tm.probabilities,\n                                    [0.7, 0.1, 0.3, 0.6, 0.3, 0.3, 0.7]))\n        log_prob = [-0.35667494, -2.30258509, -1.2039728, -0.51082562,\n                    -1.2039728, -1.2039728, -0.35667494]\n        self.assertTrue(np.allclose(self.tm.log_probabilities, log_prob))\n        self.assertTrue(self.tm.num_states == 3)\n        self.assertTrue(self.tm.num_transitions == 7)\n\n    def test_num_states_unreachable(self):\n        for r in range(3):\n            trans = np.array([[.5, .5, .0],\n                              [.5, .5, .0],\n                              [.5, .5, .0]])\n            trans = np.roll(trans, shift=r, axis=1)\n            frm, to = trans.nonzero()\n            tm = TransitionModel.from_dense(to, frm, trans[frm, to])\n            self.assertTrue(tm.num_states == 3)\n\n\nclass TestDiscreteObservationModelClass(unittest.TestCase):\n\n    def setUp(self):\n        self.om = DiscreteObservationModel(OBS_PROB)\n\n    def test_types(self):\n        self.assertIsInstance(self.om.pointers, np.ndarray)\n        self.assertIsInstance(self.om.densities(OBS_SEQ), np.ndarray)\n        self.assertIsInstance(self.om.log_densities(OBS_SEQ), np.ndarray)\n        self.assertTrue(self.om.pointers.dtype == np.uint32)\n        self.assertTrue(self.om.densities(OBS_SEQ).dtype == np.float)\n        self.assertTrue(self.om.log_densities(OBS_SEQ).dtype == np.float)\n\n    def test_values(self):\n        self.assertTrue(np.allclose(self.om.pointers, [0, 1, 2]))\n        self.assertTrue(np.allclose(self.om.observation_probabilities,\n                                    OBS_PROB))\n        self.assertTrue(np.allclose(self.om.densities(OBS_SEQ),\n                                    OBS_PROB[:, OBS_SEQ].T))\n        self.assertTrue(np.allclose(self.om.log_densities(OBS_SEQ),\n                                    np.log(OBS_PROB[:, OBS_SEQ].T)))\n\n\nclass TestHiddenMarkovModelClass(unittest.TestCase):\n\n    def setUp(self):\n        frm, to, prob = list(zip(*TRANSITIONS))\n        tm = TransitionModel.from_dense(to, frm, prob)\n        om = DiscreteObservationModel(OBS_PROB)\n        self.hmm = HiddenMarkovModel(tm, om, PRIOR)\n\n    def test_viterbi(self):\n        correct_state_seq = np.array([0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2,\n                                      2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n        correct_log_p = -35.2104311327\n        state_seq, log_p = self.hmm.viterbi(OBS_SEQ)\n        self.assertTrue((state_seq == correct_state_seq).all())\n        self.assertAlmostEqual(log_p, correct_log_p)\n\n    def test_forward(self):\n        fwd = self.hmm.forward(OBS_SEQ)\n        self.assertTrue(np.allclose(fwd, CORRECT_FWD))\n        # two runs must yield identical results\n        fwd = self.hmm.forward(OBS_SEQ)\n        self.assertTrue(np.allclose(fwd, CORRECT_FWD))\n        # after resetting the HMM, it must produce the same output as before\n        self.hmm.reset()\n        fwd = np.vstack([self.hmm.forward(np.atleast_1d(o), reset=False)\n                         for o in OBS_SEQ])\n        self.assertTrue(np.allclose(fwd, CORRECT_FWD))\n        # without resetting it produces different results\n        fwd = np.vstack([self.hmm.forward(np.atleast_1d(o), reset=False)\n                         for o in OBS_SEQ])\n        self.assertFalse(np.allclose(fwd, CORRECT_FWD))\n        # after resetting it must yield the correct result again\n        self.hmm.reset()\n        fwd = np.vstack([self.hmm.forward(np.atleast_1d(o), reset=False)\n                         for o in OBS_SEQ])\n        self.assertTrue(np.allclose(fwd, CORRECT_FWD))\n        # initialisation must not change\n        self.assertTrue(np.allclose(self.hmm.initial_distribution, PRIOR))\n\n    def test_forward_generator(self):\n        fwd = np.vstack(self.hmm.forward_generator(OBS_SEQ, block_size=5))\n        self.assertTrue(np.allclose(fwd, CORRECT_FWD))\n\n    def test_invalid_sequence(self):\n        transitions = [(0, 0, 0.1), (0, 1, 0.9), (0, 2, 0),\n                       (1, 0, 0), (1, 1, 1), (1, 2, 0),\n                       (2, 0, 0), (2, 1, 0), (2, 2, 1)]\n        frm, to, prob = list(zip(*transitions))\n        tm = TransitionModel.from_dense(to, frm, prob)\n        obs_prob = np.array([[0.7, 0.3, 0],\n                             [0.3, 0.7, 0],\n                             [0, 0, 1]])\n        om = DiscreteObservationModel(obs_prob)\n        hmm = HiddenMarkovModel(tm, om)\n        state_seq, log_p = hmm.viterbi([0, 1, 0, 2])\n        self.assertTrue(np.allclose(state_seq, []))\n        self.assertAlmostEqual(log_p, -np.inf)\n        # TODO: assertWarns exist only for Python 3.2+, test in all versions\n        if sys.version_info >= (3, 2):\n            with self.assertWarns(RuntimeWarning):\n                hmm.viterbi([0, 1, 0, 2])\n        state_seq, log_p = hmm.viterbi([0, 0, 1, 1])\n        self.assertTrue((state_seq == [1, 1, 1, 1]).all())\n        self.assertAlmostEqual(log_p, -4.219907785197447)\n'"
tests/test_ml_nn.py,124,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.ml.nn module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\n\nfrom madmom.models import *\nfrom madmom.ml.nn import *\nfrom madmom.ml.nn.layers import *\n\n\nclass TestRNNClass(unittest.TestCase):\n\n    def setUp(self):\n        # uni-directional RNN\n        self.rnn = NeuralNetwork.load(ONSETS_RNN[0])\n        self.data = np.zeros((4, self.rnn.layers[0].weights.shape[0]))\n        self.data[1] = 1.\n        self.result = [1.78801871e-04, 8.00144131e-01,\n                       3.30476369e-05, 1.36037513e-04]\n\n    def test_process(self):\n        # process the whole sequence at once\n        result = self.rnn.process(self.data)\n        self.assertTrue(np.allclose(result, self.result))\n        # two runs must produce the same output\n        result_1 = self.rnn.process(self.data)\n        self.assertTrue(np.allclose(result_1, self.result))\n        # after resetting the RNN, it must produce the same output as before\n        self.rnn.reset()\n        result_2 = [self.rnn.process(np.atleast_2d(d), reset=False)\n                    for d in self.data]\n        self.assertTrue(np.allclose(np.hstack(result_2), self.result))\n        # without resetting it produces different results\n        result_3 = [self.rnn.process(np.atleast_2d(d), reset=False)\n                    for d in self.data]\n        self.assertTrue(np.allclose(np.hstack(result_3),\n                                    [9.15636891e-04, 9.74331021e-01,\n                                     4.83996118e-05, 2.72355013e-04]))\n\n\nclass TestLSTMClass(unittest.TestCase):\n    def setUp(self):\n        # uni-directional LSTM-RNN\n        self.rnn = NeuralNetwork.load(BEATS_LSTM[0])\n        self.data = np.zeros((4, self.rnn.layers[0].cell.weights.shape[0]))\n        self.data[1] = 1.\n        self.result = [0.00126955, 0.03134079, 0.01535073, 0.00207471]\n\n    def test_process(self):\n        # process the whole sequence at once\n        result = self.rnn.process(self.data)\n        self.assertTrue(np.allclose(result, self.result))\n        # two runs must produce the same output\n        result_1 = self.rnn.process(self.data)\n        self.assertTrue(np.allclose(result_1, self.result))\n        # after resetting the RNN, it must produce the same output\n        self.rnn.reset()\n        result_2 = [self.rnn.process(np.atleast_2d(d), reset=False)\n                    for d in self.data]\n        self.assertTrue(np.allclose(np.hstack(result_2), self.result))\n        # without resetting it produces different output\n        result_3 = [self.rnn.process(np.atleast_2d(d), reset=False)\n                    for d in self.data]\n        self.assertTrue(np.allclose(np.hstack(result_3),\n                                    [0.00054101, 0.05323271,\n                                     0.0548761, 0.00785541]))\n\n\n# class for testing all other (offline-only) networks\nclass TestNeuralNetworkClass(unittest.TestCase):\n\n    def test_brnn(self):\n        rnn = NeuralNetwork.load(ONSETS_BRNN[0])\n        input_size = rnn.layers[0].fwd_layer.weights.shape[0]\n        data = np.zeros((4, input_size))\n        data[1] = 1.\n        result = rnn.process(data)\n        self.assertTrue(np.allclose(result, [0.00461393, 0.46032878,\n                                             0.04824624, 0.00083493]))\n\n    def test_brnn_pp(self):\n        rnn = NeuralNetwork.load(ONSETS_BRNN_PP[0])\n        input_size = rnn.layers[0].fwd_layer.weights.shape[0]\n        data = np.zeros((4, input_size))\n        data[1] = 1.\n        result = rnn.process(data)\n        self.assertTrue(np.allclose(result,\n                                    [3.88076517e-03, 1.67354920e-03,\n                                     1.14450835e-03, 5.01533471e-05]))\n\n    def test_brnn_regression(self):\n        rnn = NeuralNetwork.load(NOTES_BRNN[0])\n        input_size = rnn.layers[0].fwd_layer.weights.shape[0]\n        data = np.zeros((4, input_size))\n        data[1] = 1.\n        result = rnn.process(data)\n        self.assertEqual(result.shape, (4, 88))\n        self.assertTrue(np.allclose(result[:, :2],\n                                    [[6.50841586e-05, 4.06891153e-04],\n                                     [-9.74552809e-04, -3.86762259e-03],\n                                     [1.09878686e-04, 1.54044293e-04],\n                                     [-8.16427571e-04, 4.62550714e-04]]))\n\n    def test_blstm(self):\n        rnn = NeuralNetwork.load(BEATS_BLSTM[0])\n        input_size = rnn.layers[0].fwd_layer.cell.weights.shape[0]\n        data = np.zeros((4, input_size))\n        data[1] = 1.\n        result = rnn.process(data)\n        self.assertTrue(np.allclose(result, [0.0815198, 0.24451593,\n                                             0.08786312, 0.01776425]))\n\n    def test_cnn(self):\n        cnn = NeuralNetwork.load(ONSETS_CNN[0])\n        data = np.zeros((19, 80, 3))\n        data[10] = 1.\n        result = cnn.process(data)\n        self.assertTrue(np.allclose(result, [0.0021432, 0.02647826, 0.92750794,\n                                             0.84207922, 0.21631248]))\n\n\nclass TestFeedForwardLayerClass(unittest.TestCase):\n\n    def setUp(self):\n        # borrow an FeedForwardLayer from an existing network\n        rnn = NeuralNetwork.load(ONSETS_RNN[0])\n        self.layer = rnn.layers[-1]\n        input_size = self.layer.weights.shape[0]\n        self.data = np.zeros((4, input_size))\n        self.data[1] = 1.\n        self.result = np.array([[0.16283005], [0.14362903],\n                                [0.16283005], [0.16283005]])\n\n    def test_types(self):\n        self.assertTrue(isinstance(self.layer, FeedForwardLayer))\n        self.assertTrue(self.layer.activation_fn == sigmoid)\n\n    def test_init(self):\n        self.assertFalse(hasattr(self.layer, \'init\'))\n        self.assertFalse(hasattr(self.layer, \'_prev\'))\n\n    def test_activate(self):\n        # test result\n        result_1 = self.layer(self.data)\n        self.assertTrue(np.allclose(result_1, self.result))\n        # two runs must yield identical results\n        result_2 = self.layer(self.data)\n        self.assertTrue(np.allclose(result_1, result_2))\n        # calling frame-by-frame must yield identical results\n        result_3 = [self.layer.activate(d) for d in self.data]\n        self.assertTrue(np.allclose(result_3, self.result))\n        # calling frame-by-frame without resetting also\n        result_4 = [self.layer.activate(d, reset=False) for d in self.data]\n        self.assertTrue(np.allclose(result_4, self.result))\n\n\nclass TestRecurrentLayerClass(unittest.TestCase):\n\n    def setUp(self):\n        # borrow an RecurrentLayer from an existing network\n        rnn = NeuralNetwork.load(ONSETS_RNN[0])\n        self.layer = rnn.layers[0]\n        input_size = self.layer.weights.shape[0]\n        self.data = np.zeros((4, input_size))\n        self.data[1] = 1.\n\n    def test_types(self):\n        self.assertTrue(isinstance(self.layer, RecurrentLayer))\n        self.assertTrue(self.layer.activation_fn == tanh)\n\n    def test_init(self):\n        self.assertTrue(hasattr(self.layer, \'init\'))\n        self.assertTrue(hasattr(self.layer, \'_prev\'))\n\n    def test_activate(self):\n        # test result\n        result_1 = self.layer(self.data)\n        self.assertTrue(np.allclose(result_1[0, :2],\n                                    [-0.33919713, -0.02091585]))\n        self.assertTrue(np.allclose(result_1[-1, -2:],\n                                    [0.4419672, -0.261151]))\n        # two runs must yield identical results\n        result_2 = self.layer(self.data)\n        self.assertTrue(np.allclose(result_2, result_1))\n        # last step must be preserved\n        self.assertTrue(np.allclose(self.layer._prev, result_2[-1]))\n        # initialisation must not change\n        self.assertTrue(np.allclose(self.layer.init, np.zeros(25)))\n        # reset layer, activate framewise must yield the same result\n        self.layer.reset()\n        result_3 = [self.layer.activate(np.atleast_2d(d), reset=False)\n                    for d in self.data]\n        result_3 = np.vstack(result_3)\n        self.assertTrue(np.allclose(result_3, result_1))\n        self.assertTrue(np.allclose(self.layer._prev, result_3[-1]))\n        # activate framewise without resetting must yield a different result\n        result_4 = [self.layer.activate(np.atleast_2d(d), reset=False)\n                    for d in self.data]\n        result_4 = np.vstack(result_4)\n        self.assertFalse(np.allclose(result_4, result_1))\n        self.assertTrue(np.allclose(result_4[0, :2],\n                                    [-3.14807342e-01, -2.22700375e-01]))\n        self.assertTrue(np.allclose(result_4[-1, -2:],\n                                    [4.40259654e-01, -2.59141315e-01]))\n        # last step must be preserved\n        self.assertTrue(np.allclose(self.layer._prev, result_4[-1]))\n        # initialisation must not change\n        self.assertTrue(np.allclose(self.layer.init, np.zeros(25)))\n\n\nclass TestLSTMLayerClass(unittest.TestCase):\n\n    def setUp(self):\n        # borrow an LSTMLayer from an existing network\n        rnn = NeuralNetwork.load(BEATS_BLSTM[0])\n        self.layer = rnn.layers[0].fwd_layer\n        input_size = self.layer.cell.weights.shape[0]\n        self.data = np.zeros((4, input_size))\n        self.data[1] = 1.\n\n    def test_types(self):\n        self.assertTrue(isinstance(self.layer, LSTMLayer))\n        self.assertTrue(isinstance(self.layer.input_gate, Gate))\n        self.assertTrue(isinstance(self.layer.forget_gate, Gate))\n        self.assertTrue(isinstance(self.layer.cell, Cell))\n        self.assertTrue(isinstance(self.layer.output_gate, Gate))\n        self.assertTrue(self.layer.activation_fn == tanh)\n        self.assertTrue(self.layer.input_gate.activation_fn == sigmoid)\n        self.assertTrue(self.layer.forget_gate.activation_fn == sigmoid)\n        self.assertTrue(self.layer.cell.activation_fn == tanh)\n        self.assertTrue(self.layer.output_gate.activation_fn == sigmoid)\n\n    def test_init(self):\n        self.assertTrue(hasattr(self.layer, \'init\'))\n        self.assertTrue(hasattr(self.layer, \'_prev\'))\n\n    def test_activate(self):\n        # test result\n        result_1 = self.layer(self.data)\n        self.assertTrue(np.allclose(result_1[0, :2],\n                                    [8.15829188e-02, 1.14209838e-02]))\n        self.assertTrue(np.allclose(result_1[-1, -2:],\n                                    [-1.81968838e-01, -2.32963227e-02]))\n        # two runs must yield identical results\n        result_2 = self.layer(self.data)\n        self.assertTrue(np.allclose(result_2, result_1))\n        # last step must be preserved\n        self.assertTrue(np.allclose(self.layer._prev, result_2[-1]))\n        # reset layer, activate framewise must yield the same result\n        self.layer.reset()\n        result_3 = [self.layer.activate(np.atleast_2d(d), reset=False)\n                    for d in self.data]\n        self.assertTrue(np.allclose(np.vstack(result_3), result_1))\n        # activate framewise without resetting must yield a different result\n        result_4 = [self.layer.activate(np.atleast_2d(d), reset=False)\n                    for d in self.data]\n        result_4 = np.vstack(result_4)\n        self.assertFalse(np.allclose(result_4, result_1))\n        self.assertTrue(np.allclose(result_4[0, :2],\n                                    [2.34878659e-01, -1.26488507e-03]))\n        self.assertTrue(np.allclose(result_4[-1, -2:],\n                                    [-2.45573238e-01, -2.92062219e-02]))\n        # last step must be preserved\n        self.assertTrue(np.allclose(self.layer._prev, result_4[-1]))\n        # initialisation must not change\n        self.assertTrue(np.allclose(self.layer.init, np.zeros(25)))\n\n\nclass TestGRUClass(unittest.TestCase):\n\n    W_xr = np.array([[-0.42948743, -1.29989187],\n                     [0.77213901, 0.86070993],\n                     [1.13791823, -0.87066225]])\n    W_xu = np.array([[0.44875312, 0.07172084],\n                     [-0.24292999, 1.318794],\n                     [1.0270179, 0.16293946]])\n    W_xhu = np.array([[0.8812559, 1.35859991],\n                      [1.04311944, -0.25449358],\n                      [-1.09539597, 1.19808424]])\n    W_hr = np.array([[0.96696973, 0.1384294],\n                     [-0.09561655, -1.23413809]])\n    W_hu = np.array([[0.04664641, 0.59561686],\n                     [1.00325841, -0.11574791]])\n    W_hhu = np.array([[1.19742848, 1.07850016],\n                      [0.35234964, -1.45348681]])\n    b_r = np.array([1.41851288, -0.39743243])\n    b_u = np.array([-0.78729095, 0.83385797])\n    b_hu = np.array([1.25143065, -0.97715625])\n\n    IN = np.array([[0.91298812, -1.47626202, -1.08667502],\n                   [0.49814883, -0.0104938, 0.93869008],\n                   [-1.12282135, 0.3780883, 1.42017503],\n                   [0.62669439, 0.89438929, -0.69354132],\n                   [0.16162221, -1.00166208, 0.23579985]])\n    OUT = np.array([[0.22772433, -0.13181415],\n                    [0.49479958, 0.51224858],\n                    [0.08539771, -0.56119639],\n                    [0.1946809, -0.50421363],\n                    [0.17403202, -0.27258521]])\n    H = np.array([0.02345737, 0.34454183])\n\n    def setUp(self):\n        self.reset_gate = layers.Gate(\n            TestGRUClass.W_xr, TestGRUClass.b_r, TestGRUClass.W_hr,\n            activation_fn=activations.sigmoid)\n        self.update_gate = layers.Gate(\n            TestGRUClass.W_xu, TestGRUClass.b_u, TestGRUClass.W_hu,\n            activation_fn=activations.sigmoid)\n        self.gru_cell = layers.GRUCell(\n            TestGRUClass.W_xhu, TestGRUClass.b_hu, TestGRUClass.W_hhu)\n        self.gru_1 = layers.GRULayer(self.reset_gate, self.update_gate,\n                                     self.gru_cell)\n        self.gru_2 = layers.GRULayer(self.reset_gate, self.update_gate,\n                                     self.gru_cell, init=TestGRUClass.H)\n\n    def test_activate(self):\n        self.assertTrue(\n            np.allclose(self.reset_gate.activate(TestGRUClass.IN[0, :],\n                        TestGRUClass.H), np.array([0.20419282, 0.08861294])))\n        self.assertTrue(\n            np.allclose(self.update_gate.activate(TestGRUClass.IN[0, :],\n                        TestGRUClass.H), np.array([0.31254834, 0.2226105])))\n        self.assertTrue(\n            np.allclose(self.gru_cell.activate(TestGRUClass.IN[0, :],\n                        TestGRUClass.H, TestGRUClass.H),\n                        np.array([0.9366396, -0.67876764])))\n        # activating the layer normally\n        self.assertTrue(np.allclose(self.gru_1.activate(TestGRUClass.IN),\n                                    TestGRUClass.OUT))\n        # activating the layer a second time must give the same results\n        self.assertTrue(np.allclose(self.gru_1.activate(TestGRUClass.IN),\n                                    TestGRUClass.OUT))\n        # activating the other layer\n        self.assertTrue(\n            np.allclose(self.gru_2.activate(TestGRUClass.IN),\n                        np.array([[0.30988133, 0.13258138],\n                                  [0.60639685, 0.55714613],\n                                  [0.21366976, -0.55568963],\n                                  [0.30860096, -0.43686554],\n                                  [0.28866628, -0.23025239]])))\n        # reset layer, activate framewise must yield the same result\n        self.gru_1.reset()\n        result_1 = [self.gru_1.activate(np.atleast_2d(d), reset=False)\n                    for d in self.IN]\n        self.assertTrue(np.allclose(np.vstack(result_1), self.OUT))\n        # the previous state must be the last output\n        self.assertTrue(np.allclose(self.gru_1._prev, self.OUT[-1]))\n        # activate with same data without resetting\n        result_2 = [self.gru_1.activate(np.atleast_2d(d), reset=False)\n                    for d in self.IN]\n        # results must differ\n        self.assertFalse(np.allclose(result_1, result_2))\n        self.assertTrue(np.allclose(np.vstack(result_2),\n                                    [[0.3254016, -0.33195618],\n                                     [0.53048187, 0.51293057],\n                                     [0.12495148, -0.559039],\n                                     [0.22988503, -0.48455557],\n                                     [0.20934506, -0.25959042]]))\n        # the previous state must be the last output\n        self.assertTrue(np.allclose(self.gru_1._prev,\n                                    [0.20934506, -0.25959042]))\n        # initialisation must not change\n        self.assertTrue(np.allclose(self.gru_1.init, [0, 0]))\n\n\nclass TestBatchNormLayerClass(unittest.TestCase):\n\n    IN = np.array([[[0.32400414, 0.31483042],\n                    [0.38269293, 0.04822304],\n                    [0.03791266, 0.34776369]],\n                   [[0.87113619, 0.62172854],\n                    [0.87353969, 0.92837042],\n                    [0.70359915, 0.49917081]],\n                   [[0.42643583, 0.74653631],\n                    [0.08519834, 0.35423595],\n                    [0.34863797, 0.44895086]]])\n\n    BN_PARAMS = [np.array([-0.00098404, 0.00185387]),\n                 np.array([-0.0068268, 0.0068859]),\n                 np.array([-0.00289366, 0.00742069]),\n                 np.array([-0.00177374, -0.00444383])]\n\n    OUT = np.array([[[-0.00098008, 0.00184446],\n                     [-0.00097937, 0.00185262],\n                     [-0.00098355, 0.00184345]],\n                    [[-0.00097346, 0.00183507],\n                     [-0.00097343, 0.00182569],\n                     [-0.00097549, 0.00183882]],\n                    [[-0.00097884, 0.00183125],\n                     [-0.00098297, 0.00184326],\n                     [-0.00097978, 0.00184036]]])\n\n    def test_batch_norm(self):\n        params = TestBatchNormLayerClass.BN_PARAMS\n        x = TestBatchNormLayerClass.IN\n        y_true = TestBatchNormLayerClass.OUT\n        bnl = layers.BatchNormLayer(\n            params[0], params[1], params[2], params[3], activations.linear)\n\n        y = bnl.activate(x)\n\n        self.assertTrue(np.allclose(y, y_true))\n\n\nclass TestAverageLayerClass(unittest.TestCase):\n\n    IN = np.array([[[0.32400414, 0.31483042],\n                    [0.38269293, 0.04822304],\n                    [0.03791266, 0.34776369]],\n                   [[0.87113619, 0.62172854],\n                    [0.87353969, 0.92837042],\n                    [0.70359915, 0.49917081]],\n                   [[0.42643583, 0.74653631],\n                    [0.08519834, 0.35423595],\n                    [0.34863797, 0.44895086]]])\n\n    OUT_AVG = 0.46460927444444444\n    OUT_02 = np.array([0.55077857, 0.44537673, 0.39767252])\n    OUT_02_KD = np.array([[[0.55077857], [0.44537673], [0.39767252]]])\n\n    def test_average_layer(self):\n        al = layers.AverageLayer()\n        out = al(TestAverageLayerClass.IN)\n        self.assertAlmostEqual(out, TestAverageLayerClass.OUT_AVG)\n\n        al = layers.AverageLayer(axis=(0, 2))\n        out = al(TestAverageLayerClass.IN)\n        self.assertEqual(out.shape, (3,))\n        self.assertTrue(np.allclose(out, TestAverageLayerClass.OUT_02))\n\n        al = layers.AverageLayer(axis=(0, 2), keepdims=True)\n        out = al(TestAverageLayerClass.IN)\n        self.assertEqual(out.shape, (1, 3, 1))\n        self.assertTrue(np.allclose(out, TestAverageLayerClass.OUT_02_KD))\n\n        al = layers.AverageLayer(axis=(0, 2), dtype=np.float32)\n        out = al(TestAverageLayerClass.IN)\n        self.assertEqual(out.dtype, np.float32)\n\n\nclass TestReshapeLayerClass(unittest.TestCase):\n\n    IN = np.random.random((2, 3, 4))\n\n    def test_reshape_layer(self):\n        rl = layers.ReshapeLayer(newshape=(3, 4, 2))\n        self.assertEqual(rl(TestReshapeLayerClass.IN).shape, (3, 4, 2))\n        rl = layers.ReshapeLayer(newshape=(3, -1, 2))\n        self.assertEqual(rl(TestReshapeLayerClass.IN).shape, (3, 4, 2))\n        rl = layers.ReshapeLayer(newshape=(-1,))\n        self.assertEqual(rl(TestReshapeLayerClass.IN).shape, (24,))\n\n        with self.assertRaises(ValueError):\n            rl = layers.ReshapeLayer(newshape=(3, 2, 2))\n            rl(TestReshapeLayerClass.IN)\n\n\nclass TestTransposeLayerClass(unittest.TestCase):\n\n    IN = np.random.random((2, 3, 4, 5))\n\n    def test_transpose_layer(self):\n        tl = layers.TransposeLayer()\n        self.assertEqual(tl(TestTransposeLayerClass.IN).shape, (5, 4, 3, 2))\n\n        tl = layers.TransposeLayer(axes=(2, 0, 1, 3))\n        self.assertEqual(tl(TestTransposeLayerClass.IN).shape, (4, 2, 3, 5))\n\n        with self.assertRaises(ValueError):\n            tl = layers.TransposeLayer(axes=(0, 1, 3))\n            tl(TestTransposeLayerClass.IN)\n\n        with self.assertRaises(ValueError):\n            tl = layers.TransposeLayer(axes=(0, 1, 2, 3, 4))\n            tl(TestTransposeLayerClass.IN)\n\n        with self.assertRaises(ValueError):\n            tl = layers.TransposeLayer(axes=(0, 1, 1, 2))\n            tl(TestTransposeLayerClass.IN)\n\n\nclass TestPadLayerClass(unittest.TestCase):\n\n    def test_constant_padding(self):\n        pl = layers.PadLayer(width=2, axes=(0, 1), value=10.)\n        data = np.arange(40).reshape(5, 4, 2).astype(np.float)\n        out = pl(data)\n\n        self.assertEqual(out.shape, (9, 8, 2))\n        self.assertTrue(np.allclose(out[2:-2, 2:-2, :], data))\n        self.assertTrue(np.allclose(out[:2, :, :], 10.))\n        self.assertTrue(np.allclose(out[-2:, :, :], 10.))\n        self.assertTrue(np.allclose(out[:, :2, :], 10.))\n        self.assertTrue(np.allclose(out[:, -2:, :], 10.))\n\n        pl = layers.PadLayer(width=3, axes=(2,), value=2.2)\n        out = pl(data)\n\n        self.assertEqual(out.shape, (5, 4, 8))\n        self.assertTrue(np.allclose(out[:, :, 3:-3], data))\n        self.assertTrue(np.allclose(out[:, :, :3], 2.2))\n        self.assertTrue(np.allclose(out[:, :, -3:], 2.2))\n\n\nclass ConvolutionalLayerClassTest(unittest.TestCase):\n\n    W1 = np.array([[[[0.69557322]],\n                    [[0.45649655]],\n                    [[0.58179561]]],\n                   [[[0.20438251]],\n                    [[0.17404747]],\n                    [[0.41624290]]]])\n\n    W3 = np.array([[[[0.57353216, 0.72422232, 0.15716315],\n                     [0.82000373, 0.26902348, 0.69203708],\n                     [0.45564084, 0.89265194, 0.98080186]],\n                    [[0.44920649, 0.52442715, 0.33103038],\n                     [0.24536095, 0.49307102, 0.28850389],\n                     [0.38324254, 0.46965330, 0.76865911]],\n                    [[0.44225901, 0.34989312, 0.92381997],\n                     [0.32123710, 0.04856574, 0.87387125],\n                     [0.70175767, 0.38149251, 0.40178089]]],\n                   [[[0.28197446, 0.35315104, 0.53862099],\n                     [0.01224023, 0.94672135, 0.87194315],\n                     [0.69193064, 0.27611521, 0.51076897]],\n                    [[0.22228372, 0.58605351, 0.17730248],\n                     [0.10949298, 0.43124835, 0.71336330],\n                     [0.57694486, 0.44623928, 0.11774881]],\n                    [[0.76850363, 0.46740177, 0.76900027],\n                     [0.61551742, 0.62841514, 0.05235070],\n                     [0.01321052, 0.93591818, 0.61256317]]]])\n\n    B = np.array([0.27614033, 0.87995416, 0.23540803])\n\n    O1 = np.array([[[0.97171354, 1.33645070, 0.81720366],\n                    [0.27614033, 0.87995416, 0.23540803],\n                    [0.27614033, 0.87995416, 0.23540803],\n                    [0.27614033, 0.87995416, 0.23540803],\n                    [0.48052284, 1.05400163, 0.65165093]],\n                   [[0.27614033, 0.87995416, 0.23540803],\n                    [0.97171354, 1.33645070, 0.81720366],\n                    [0.27614033, 0.87995416, 0.23540803],\n                    [0.48052284, 1.05400163, 0.65165093],\n                    [0.27614033, 0.87995416, 0.23540803]],\n                   [[0.27614033, 0.87995416, 0.23540803],\n                    [0.27614033, 0.87995416, 0.23540803],\n                    [1.17609602, 1.51049817, 1.23344656],\n                    [0.27614033, 0.87995416, 0.23540803],\n                    [0.27614033, 0.87995416, 0.23540803]],\n                   [[0.27614033, 0.87995416, 0.23540803],\n                    [0.48052284, 1.05400163, 0.65165093],\n                    [0.27614033, 0.87995416, 0.23540803],\n                    [0.97171354, 1.33645070, 0.81720366],\n                    [0.27614033, 0.87995416, 0.23540803]],\n                   [[0.48052284, 1.05400163, 0.65165093],\n                    [0.27614033, 0.87995416, 0.23540803],\n                    [0.27614033, 0.87995416, 0.23540803],\n                    [0.27614033, 0.87995416, 0.23540803],\n                    [0.97171354, 1.33645070, 0.81720366]]])\n\n    O3 = np.array([[[2.38147223, 2.81317455, 1.89651736],\n                    [2.05779099, 2.38843173, 2.54209157],\n                    [2.61057651, 2.39648026, 2.56985398]],\n                   [[2.35418737, 2.29051489, 2.02105685],\n                    [4.27677071, 3.77638656, 2.53863951],\n                    [2.84045803, 2.85248774, 2.44744130]],\n                   [[2.90905416, 2.44869238, 2.34779163],\n                    [3.13685429, 2.75457102, 1.92640647],\n                    [2.61026680, 2.70863968, 1.74057683]]])\n\n    def setUp(self):\n        self.layer1x1 = ConvolutionalLayer(ConvolutionalLayerClassTest.W1,\n                                           ConvolutionalLayerClassTest.B)\n        self.layer3x3 = ConvolutionalLayer(ConvolutionalLayerClassTest.W3,\n                                           ConvolutionalLayerClassTest.B)\n        self.data = np.stack([np.eye(5), np.eye(5)[:, ::-1]], axis=-1)\n\n    def test_activate(self):\n        out1 = self.layer1x1.activate(self.data)\n        self.assertTrue(np.allclose(out1, ConvolutionalLayerClassTest.O1))\n        out3 = self.layer3x3.activate(self.data)\n        self.assertTrue(np.allclose(out3, ConvolutionalLayerClassTest.O3))\n'"
tests/test_processors.py,36,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains tests for the madmom.processors module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\nimport tempfile\nimport unittest\n\nfrom madmom.processors import *\nfrom madmom.models import *\nfrom madmom.ml.nn import NeuralNetwork\n\ntmp_file = tempfile.NamedTemporaryFile(delete=False).name\n\n\nclass TestProcessor(unittest.TestCase):\n\n    def test_unicode(self):\n        if sys.version_info[0] == 2:\n            # load from unicode string\n            rnn = NeuralNetwork.load(unicode(ONSETS_RNN[0]))\n            # save to unicode string\n            rnn.dump(unicode(tmp_file))\n\n\nclass TestBufferProcessor(unittest.TestCase):\n\n    def test_1d(self):\n        buffer = BufferProcessor(5, init=np.zeros(5))\n        self.assertTrue(np.allclose(buffer.data, 0))\n        # shift in two new values\n        result = buffer(np.arange(2))\n        self.assertTrue(np.allclose(result, [0, 0, 0, 0, 1]))\n        result = buffer(np.arange(2, 4))\n        self.assertTrue(np.allclose(result, [0, 0, 1, 2, 3]))\n        result = buffer(np.arange(4, 6))\n        self.assertTrue(np.allclose(result, [1, 2, 3, 4, 5]))\n        # shift in three new values\n        result = buffer(np.arange(6, 9))\n        self.assertTrue(np.allclose(result, [4, 5, 6, 7, 8]))\n        # shift in six new values (bigger than buffer)\n        result = buffer(np.arange(9, 15))\n        self.assertTrue(np.allclose(result, [10, 11, 12, 13, 14]))\n\n    def test_2d(self):\n        buffer = BufferProcessor((5, 2), init=np.zeros((5, 2)))\n        self.assertTrue(buffer.data.shape == (5, 2))\n        self.assertTrue(np.allclose(buffer.data, 0))\n        # shift in new values\n        result = buffer(np.arange(2).reshape((1, -1)))\n        self.assertTrue(result.shape == (5, 2))\n        self.assertTrue(np.allclose(result[:4], 0))\n        self.assertTrue(np.allclose(result[-1], [0, 1]))\n        result = buffer(np.arange(2, 4).reshape((1, -1)))\n        self.assertTrue(result.shape == (5, 2))\n        self.assertTrue(np.allclose(result[:3], 0))\n        self.assertTrue(np.allclose(result[-2], [0, 1]))\n        self.assertTrue(np.allclose(result[-1], [2, 3]))\n        # shift in two new values\n        result = buffer(np.arange(4, 8).reshape((2, -1)))\n        self.assertTrue(result.shape == (5, 2))\n        self.assertTrue(np.allclose(result[0], 0))\n        self.assertTrue(np.allclose(result[1], [0, 1]))\n        self.assertTrue(np.allclose(result[2], [2, 3]))\n        self.assertTrue(np.allclose(result[3], [4, 5]))\n        self.assertTrue(np.allclose(result[4], [6, 7]))\n        # shift in three new values\n        result = buffer(np.arange(8, 14).reshape((3, -1)))\n        self.assertTrue(result.shape == (5, 2))\n        self.assertTrue(np.allclose(result.ravel(), np.arange(4, 14)))\n        # shift in six new values (bigger than buffer)\n        result = buffer(np.arange(14, 26).reshape((6, -1)))\n        self.assertTrue(result.shape == (5, 2))\n        self.assertTrue(np.allclose(result.ravel(), np.arange(16, 26)))\n\n    def test_reset(self):\n        buffer = BufferProcessor(5, init=np.ones(5))\n        self.assertTrue(np.allclose(buffer.data, 1))\n        result = buffer(np.arange(2))\n        self.assertTrue(np.allclose(result, [1, 1, 1, 0, 1]))\n        buffer.reset()\n        self.assertTrue(np.allclose(buffer.data, 1))\n\n\n# clean up\ndef teardown_module():\n    import os\n    os.unlink(tmp_file)\n'"
tests/test_utils.py,119,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains test functions for the madmom.utils module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport unittest\nfrom os.path import join as pj\n\nfrom madmom.utils import *\nfrom . import (ACTIVATIONS_PATH, ANNOTATIONS_PATH, AUDIO_PATH, DATA_PATH,\n               DETECTIONS_PATH)\nfrom .test_evaluation_notes import ANNOTATIONS as NOTES\n\nFILE_LIST = [pj(DATA_PATH, \'README\'),\n             pj(DATA_PATH, \'commented_txt\'),\n             pj(DATA_PATH, \'events.txt\')]\n\nAUDIO_FILES = [pj(AUDIO_PATH, \'sample.wav\'),\n               pj(AUDIO_PATH, \'sample2.wav\'),\n               pj(AUDIO_PATH, \'sample_22050.wav\'),\n               pj(AUDIO_PATH, \'stereo_chirp.wav\'),\n               pj(AUDIO_PATH, \'stereo_chirp_rg.flac\'),\n               pj(AUDIO_PATH, \'stereo_sample.flac\'),\n               pj(AUDIO_PATH, \'stereo_sample.m4a\'),\n               pj(AUDIO_PATH, \'stereo_sample_rg.flac\'),\n               pj(AUDIO_PATH, \'stereo_sample.wav\')]\n\nACTIVATION_FILES = [pj(ACTIVATIONS_PATH, \'sample.bar_tracker.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.beats_blstm.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.beats_blstm_mm.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.beats_lstm.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.cnn_chord_features.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.downbeats_blstm.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.deep_chroma.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.complex_flux.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.gmm_pattern_tracker.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.key_cnn.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample2.key_cnn.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.log_filt_spec_flux.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.onsets_cnn.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.onsets_brnn.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.onsets_rnn.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.spectral_flux.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.super_flux.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample.super_flux_nn.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample2.cnn_chord_features.npz\'),\n                    pj(ACTIVATIONS_PATH, \'sample2.deep_chroma.npz\'),\n                    pj(ACTIVATIONS_PATH, \'stereo_sample.notes_brnn.npz\'),\n                    pj(ACTIVATIONS_PATH, \'stereo_sample.notes_cnn.npz\')]\n\nANNOTATION_FILES = [pj(ANNOTATIONS_PATH, \'dummy.chords\'),\n                    pj(ANNOTATIONS_PATH, \'sample.beats\'),\n                    pj(ANNOTATIONS_PATH, \'dummy.key\'),\n                    pj(ANNOTATIONS_PATH, \'sample.onsets\'),\n                    pj(ANNOTATIONS_PATH, \'sample.sv\'),\n                    pj(ANNOTATIONS_PATH, \'sample.tempo\'),\n                    pj(ANNOTATIONS_PATH, \'stereo_sample.mid\'),\n                    pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'),\n                    pj(ANNOTATIONS_PATH, \'stereo_sample.notes.mirex\'),\n                    pj(ANNOTATIONS_PATH, \'stereo_sample.sv\'),\n                    pj(ANNOTATIONS_PATH, \'stereo_sample_sustained.mid\'),\n                    pj(ANNOTATIONS_PATH, \'multitrack.mid\'),\n                    pj(ANNOTATIONS_PATH, \'piano_sample.mid\'),\n                    pj(ANNOTATIONS_PATH, \'piano_sample.notes_in_beats\')]\n\nDETECTION_FILES = [pj(DETECTIONS_PATH, \'dummy.chords.txt\'),\n                   pj(DETECTIONS_PATH, \'dummy.key.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.beat_detector.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.beat_tracker.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.cnn_chord_recognition.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.cnn_onset_detector.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.complex_flux.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.crf_beat_detector.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.dbn_beat_tracker.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.dbn_downbeat_tracker.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.dc_chord_recognition.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.gmm_pattern_tracker.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.key_recognition.txt\'),\n                   pj(DETECTIONS_PATH, \'sample2.key_recognition.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.log_filt_spec_flux.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.mm_beat_tracker.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.onset_detector.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.onset_detector_ll.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.spectral_flux.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.super_flux.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.super_flux_nn.txt\'),\n                   pj(DETECTIONS_PATH, \'sample.tempo_detector.txt\'),\n                   pj(DETECTIONS_PATH, \'sample2.cnn_chord_recognition.txt\'),\n                   pj(DETECTIONS_PATH, \'sample2.dc_chord_recognition.txt\'),\n                   pj(DETECTIONS_PATH, \'stereo_sample.piano_transcriptor.txt\')]\n\nEVENTS = [1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3]\n\nONSET_ANNOTATIONS = [0.0943, 0.2844, 0.4528, 0.6160, 0.7630, 0.8025, 0.9847,\n                     1.1233, 1.4820, 1.6276, 1.8032, 2.1486, 2.3351, 2.4918,\n                     2.6710]\nONSET_DETECTIONS = [0.01, 0.085, 0.275, 0.445, 0.61, 0.795, 0.98, 1.115, 1.365,\n                    1.475, 1.62, 1.795, 2.14, 2.33, 2.485, 2.665]\n\n\nclass TestFilterFilesFunction(unittest.TestCase):\n\n    def test_single_file(self):\n        # no suffix\n        result = filter_files(pj(DATA_PATH, \'README\'), None)\n        self.assertEqual(result, [pj(DATA_PATH, \'README\')])\n        # single suffix\n        result = filter_files(pj(DATA_PATH, \'README\'), suffix=\'.txt\')\n        self.assertEqual(result, [])\n        # suffix list\n        result = filter_files(pj(DATA_PATH, \'events.txt\'),\n                              suffix=[\'.txt\', None])\n        self.assertEqual(result, [pj(DATA_PATH, \'events.txt\')])\n\n    def test_file_list(self):\n        # no suffix\n        result = filter_files(FILE_LIST, None)\n        self.assertEqual(result, FILE_LIST)\n        # single suffix\n        result = filter_files(FILE_LIST, suffix=\'txt\')\n        self.assertEqual(result, [pj(DATA_PATH, \'commented_txt\'),\n                                  pj(DATA_PATH, \'events.txt\')])\n        # suffix list\n        result = filter_files(FILE_LIST, suffix=[\'.txt\'])\n        self.assertEqual(result, [pj(DATA_PATH, \'events.txt\')])\n\n\nclass TestSearchPathFunction(unittest.TestCase):\n\n    def test_path(self):\n        result = search_path(DATA_PATH)\n        self.assertEqual(result, FILE_LIST)\n\n    def test_recursion(self):\n        result = search_path(DATA_PATH, 1)\n        all_files = (FILE_LIST + AUDIO_FILES + ANNOTATION_FILES +\n                     DETECTION_FILES + ACTIVATION_FILES)\n        self.assertEqual(result, sorted(all_files))\n\n    def test_errors(self):\n        with self.assertRaises(IOError):\n            search_path(pj(DATA_PATH, \'README\'))\n\n\nclass TestSearchFilesFunction(unittest.TestCase):\n\n    def test_file(self):\n        # no suffix\n        result = search_files(pj(DATA_PATH, \'README\'))\n        self.assertEqual(result, [pj(DATA_PATH, \'README\')])\n        # single suffix\n        result = search_files(pj(DATA_PATH, \'README\'), suffix=\'.txt\')\n        self.assertEqual(result, [])\n        # suffix list\n        result = search_files(pj(DATA_PATH, \'README\'), suffix=[\'.txt\', \'txt\'])\n        self.assertEqual(result, [])\n        # non-existing file\n        with self.assertRaises(IOError):\n            search_files(pj(DATA_PATH, \'non_existing\'))\n\n    def test_path(self):\n        # no suffix\n        result = search_files(DATA_PATH)\n        self.assertEqual(result, sorted(FILE_LIST))\n        # single suffix\n        result = search_files(DATA_PATH, suffix=\'txt\')\n        file_list = [pj(DATA_PATH, \'commented_txt\'),\n                     pj(DATA_PATH, \'events.txt\')]\n        self.assertEqual(result, sorted(file_list))\n        # another suffix\n        result = search_files(DATA_PATH, suffix=\'.txt\')\n        file_list = [pj(DATA_PATH, \'events.txt\')]\n        self.assertEqual(result, sorted(file_list))\n        # suffix list\n        result = search_files(DATA_PATH, suffix=[\'.txt\', \'txt\'])\n        file_list = [pj(DATA_PATH, \'commented_txt\'),\n                     pj(DATA_PATH, \'events.txt\')]\n        self.assertEqual(result, sorted(file_list))\n\n    def test_file_list(self):\n        # no suffix\n        result = search_files(FILE_LIST)\n        self.assertEqual(result, sorted(FILE_LIST))\n        # single suffix\n        result = search_files(FILE_LIST, suffix=\'.txt\')\n        self.assertEqual(result, [pj(DATA_PATH, \'events.txt\')])\n        # suffix list\n        result = search_files(FILE_LIST, suffix=[\'.txt\', \'txt\'])\n        self.assertEqual(result, [pj(DATA_PATH, \'commented_txt\'),\n                                  pj(DATA_PATH, \'events.txt\')])\n\n\nclass TestStripSuffixFunction(unittest.TestCase):\n    # tests for strip_suffix(filename, ext=None)\n    def test_strip_txt_suffix(self):\n        self.assertEqual(strip_suffix(\'file.txt\', \'txt\'), \'file.\')\n        self.assertEqual(strip_suffix(\'/path/file.txt\', \'txt\'), \'/path/file.\')\n\n    def test_strip_dot_txt_suffix(self):\n        self.assertEqual(strip_suffix(\'file.txt\', \'.txt\'), \'file\')\n        self.assertEqual(strip_suffix(\'/path/file.txt\', \'.txt\'), \'/path/file\')\n\n\nclass TestMatchFileFunction(unittest.TestCase):\n    # test for match_file(filename, match_list, ext=None, match_suffix=None)\n    def test_match_dot_txt_suffix(self):\n        match_list = [\'file.txt\', \'/path/file.txt\', \'/path/file.txt.other\']\n        result = match_file(\'file.txt\', match_list)\n        self.assertEqual(result, [\'file.txt\', \'/path/file.txt\'])\n        result = match_file(\'file.txt\', match_list, match_exactly=False)\n        self.assertEqual(result, [\'file.txt\', \'/path/file.txt\'])\n\n    def test_match_other_suffix(self):\n        match_list = [\'file.txt\', \'/path/file.txt\', \'/path/file.txt.other\']\n        result = match_file(\'file.txt\', match_list, match_suffix=\'other\')\n        self.assertEqual(result, [])\n        result = match_file(\'file.txt\', match_list, match_suffix=\'other\',\n                            match_exactly=False)\n        self.assertEqual(result, [\'/path/file.txt.other\'])\n\n    def test_match_dot_other_suffix(self):\n        match_list = [\'file.txt\', \'/path/file.txt\', \'/path/file.txt.other\']\n        result = match_file(\'file.txt\', match_list, match_suffix=\'.other\')\n        self.assertEqual(result, [\'/path/file.txt.other\'])\n        result = match_file(\'txt\', match_list, match_suffix=\'.other\',\n                            match_exactly=False)\n        self.assertEqual(result, [\'/path/file.txt.other\'])\n        result = match_file(\'other\', match_list, match_exactly=False)\n        self.assertEqual(result, [\'/path/file.txt.other\'])\n\n    def test_match_any_suffix(self):\n        match_list = [\'file.txt\', \'/path/file.txt\', \'/path/file.txt.other\']\n        result = match_file(\'file.txt\', match_list, match_suffix=\'*\')\n        self.assertEqual(result, [\'file.txt\', \'/path/file.txt\'])\n        result = match_file(\'file.txt\', match_list, match_suffix=\'*\',\n                            match_exactly=False)\n        self.assertEqual(result, match_list)\n\n\nclass TestCombineEventsFunction(unittest.TestCase):\n\n    def test_combine_mean(self):\n        # EVENTS =           [1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3]\n        comb = combine_events(EVENTS, 0.)\n        correct = np.asarray([1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events(EVENTS, 0.01)\n        correct = np.asarray([1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events(EVENTS, 0.03)\n        correct = np.asarray([1.01, 1.5, 2.015, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events(EVENTS, 0.035)\n        correct = np.asarray([1.01, 1.5, 2.0325, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events([1], 0.035)\n        correct = np.asarray([1])\n        self.assertTrue(np.allclose(comb, correct))\n\n    def test_combine_left(self):\n        # EVENTS =           [1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3]\n        comb = combine_events(EVENTS, 0., \'left\')\n        correct = np.asarray([1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events(EVENTS, 0.01, \'left\')\n        correct = np.asarray([1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events(EVENTS, 0.03, \'left\')\n        correct = np.asarray([1, 1.5, 2, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events(EVENTS, 0.035, \'left\')\n        correct = np.asarray([1, 1.5, 2, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events(EVENTS, 0.05, \'left\')\n        correct = np.asarray([1, 1.5, 2, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n\n    def test_combine_right(self):\n        # EVENTS =           [1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3]\n        comb = combine_events(EVENTS, 0., \'right\')\n        correct = np.asarray([1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events(EVENTS, 0.01, \'right\')\n        correct = np.asarray([1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events(EVENTS, 0.03, \'right\')\n        correct = np.asarray([1.02, 1.5, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events(EVENTS, 0.035, \'right\')\n        correct = np.asarray([1.02, 1.5, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n        comb = combine_events(EVENTS, 0.05, \'right\')\n        correct = np.asarray([1.02, 1.5, 2.05, 2.5, 3])\n        self.assertTrue(np.allclose(comb, correct))\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            combine_events(np.arange(6).reshape((2, 3)), 0.5)\n        with self.assertRaises(ValueError):\n            combine_events(EVENTS, 0.5, \'foo\')\n\n\nclass TestQuantizeEventsFunction(unittest.TestCase):\n\n    def test_fps(self):\n        # 10 FPS\n        quantized = quantize_events(EVENTS, 10)\n        idx = np.nonzero(quantized)[0]\n        # tar: [1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3]\n        self.assertTrue(np.allclose(idx, [10, 15, 20, 25, 30]))\n        # 100 FPS with numpy arrays (array must not be changed)\n        events = np.array(EVENTS)\n        events_ = np.copy(events)\n        quantized = quantize_events(events, 100)\n        idx = np.nonzero(quantized)[0]\n        # tar: [1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3]\n        correct = [100, 102, 150, 200, 203, 205, 250, 300]\n        self.assertTrue(np.allclose(idx, correct))\n        self.assertTrue(np.allclose(events, events_))\n\n    def test_length(self):\n        # length = 280\n        quantized = quantize_events(EVENTS, 100, length=280)\n        idx = np.nonzero(quantized)[0]\n        # targets: [1, 1.02, 1.5, 2.0, 2.03, 2.05, 2.5, 3]\n        self.assertTrue(np.allclose(idx, [100, 102, 150, 200, 203, 205, 250]))\n\n    def test_rounding(self):\n        # without length\n        quantized = quantize_events([3.95], 10)\n        idx = np.nonzero(quantized)[0]\n        self.assertTrue(np.allclose(idx, [40]))\n        # with length\n        quantized = quantize_events([3.95], 10, length=39)\n        idx = np.nonzero(quantized)[0]\n        self.assertTrue(np.allclose(idx, []))\n        # round down with length\n        quantized = quantize_events([3.9499999], 10, length=40)\n        idx = np.nonzero(quantized)[0]\n        self.assertTrue(np.allclose(idx, [39]))\n\n    def test_shift(self):\n        # no length\n        quantized = quantize_events(EVENTS, 10, shift=1)\n        idx = np.nonzero(quantized)[0]\n        self.assertTrue(np.allclose(idx, [20, 25, 30, 35, 40]))\n        # limited length\n        quantized = quantize_events(EVENTS, 10, shift=1, length=35)\n        idx = np.nonzero(quantized)[0]\n        correct = [20, 25, 30]\n        self.assertTrue(np.allclose(idx, correct))\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            quantize_events(1, fps=100)\n        with self.assertRaises(ValueError):\n            quantize_events([[0], [1], [2]], fps=100)\n        with self.assertRaises(ValueError):\n            quantize_events(np.arange(9).reshape((3, 3, 3)), fps=100)\n\n\nclass TestQuantizeNotesFunction(unittest.TestCase):\n\n    def test_fps(self):\n        # 10 FPS\n        fps = 10\n        quantized = quantize_notes(NOTES, fps=fps)\n        self.assertTrue(quantized.shape == (42, 78))\n        idx = np.nonzero(quantized)\n        correct = np.arange(np.round(NOTES[0, 0] * fps),\n                            np.round((NOTES[0, 0] + NOTES[0, 2]) * fps) + 1)\n        self.assertTrue(np.allclose(idx[0][idx[1] == 72], correct))\n        # 100 FPS with numpy arrays (array must not be changed)\n        fps = 100\n        notes = np.array(NOTES)\n        notes_ = np.copy(notes)\n        quantized = quantize_notes(notes, fps=fps)\n        self.assertTrue(quantized.shape == (416, 78))\n        idx = np.nonzero(quantized)\n        correct = np.arange(np.round(NOTES[1, 0] * fps),\n                            np.round((NOTES[1, 0] + NOTES[1, 2]) * fps) + 1)\n        self.assertTrue(np.allclose(idx[0][idx[1] == 41], correct))\n        self.assertTrue(np.allclose(notes, notes_))\n\n    def test_length(self):\n        fps = 100\n        length = 280\n        quantized = quantize_notes(NOTES, fps=fps, length=length)\n        self.assertTrue(quantized.shape == (280, 78))\n        idx = np.nonzero(quantized)\n        correct = np.arange(np.round(NOTES[0, 0] * fps), length)\n        self.assertTrue(np.allclose(idx[0][idx[1] == 72], correct))\n\n    def test_rounding(self):\n        # rounding towards next even number\n        quantized = quantize_notes([[0.95, 0], [1.95, 1]], fps=10)\n        self.assertTrue(np.allclose(np.nonzero(quantized), [[10, 20], [0, 1]]))\n        quantized = quantize_notes([[0.85, 0], [1.85, 1]], fps=10)\n        self.assertTrue(np.allclose(np.nonzero(quantized), [[8, 18], [0, 1]]))\n        # round down\n        quantized = quantize_notes([[0.9499999, 0]], fps=10)\n        self.assertTrue(np.allclose(np.nonzero(quantized), [[9], [0]]))\n        # with length\n        quantized = quantize_notes([[0.95, 0], [1.95, 1]], fps=10, length=15)\n        self.assertTrue(np.allclose(np.nonzero(quantized), [[10], [0]]))\n\n    def test_num_notes(self):\n        fps = 10\n        num_pitches = 73\n        quantized = quantize_notes(NOTES, fps=fps, num_pitches=num_pitches)\n        self.assertTrue(quantized.shape == (42, 73))\n        idx = np.nonzero(quantized)\n        correct = np.arange(np.round(NOTES[0, 0] * fps),\n                            np.round((NOTES[0, 0] + NOTES[0, 2]) * fps) + 1)\n        self.assertTrue(np.allclose(idx[0][idx[1] == 72], correct))\n        num_pitches = 72\n        quantized = quantize_notes(NOTES, fps=fps, num_pitches=num_pitches),\n        idx = np.nonzero(quantized)\n        self.assertTrue(np.allclose(idx[0][idx[1] == 72], []))\n\n    def test_velocity(self):\n        fps = 10\n        quantized = quantize_notes(NOTES, fps=fps)\n        self.assertTrue(quantized.shape == (42, 78))\n        self.assertTrue(np.max(quantized) == 72)\n        self.assertTrue(np.allclose(quantized[:, 72][0], 0))\n        self.assertTrue(np.allclose(quantized[:, 72][1: 36], 63))\n        self.assertTrue(np.allclose(quantized[:, 72][36:], 0))\n        # set velocity\n        quantized = quantize_notes(NOTES, fps=fps, velocity=1.5)\n        self.assertTrue(np.max(quantized) == 1.5)\n        # default velocity if not given by the notes\n        quantized = quantize_notes([[0.95, 0], [1.95, 1]], fps=10)\n        self.assertTrue(np.allclose(quantized[np.nonzero(quantized)], 1))\n        quantized = quantize_notes([[0.95, 0], [1.95, 1]], fps=10, velocity=5)\n        self.assertTrue(np.allclose(quantized[np.nonzero(quantized)], 5))\n\n    def test_errors(self):\n        with self.assertRaises(ValueError):\n            quantize_notes([0, 1, 2], fps=100)\n        with self.assertRaises(ValueError):\n            quantize_notes([[0], [1], [2]], fps=100)\n        with self.assertRaises(ValueError):\n            quantize_notes(np.arange(8).reshape((2, 2, 2)), fps=100)\n\n\nclass TestExpandNotesFunction(unittest.TestCase):\n\n    def test_values(self):\n        # only onset and note number given\n        result = expand_notes(NOTES[:, :2])\n        self.assertTrue(np.allclose(result[:, :2], NOTES[:, :2]))\n        self.assertTrue(np.allclose(result[:, 2], 0.6))\n        self.assertTrue(np.allclose(result[:, 3], 100))\n        # also duration given\n        result = expand_notes(NOTES[:, :3], velocity=66)\n        self.assertTrue(np.allclose(result[:, :3], NOTES[:, :3]))\n        self.assertTrue(np.allclose(result[:, 3], 66))\n        # also velocity given\n        result = expand_notes(NOTES)\n        self.assertTrue(np.allclose(result, NOTES))\n\n\nclass TestSegmentAxisFunction(unittest.TestCase):\n\n    def test_types(self):\n        result = segment_axis(np.arange(10), 4, 2)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int)\n        result = segment_axis(np.arange(10, dtype=np.float), 4, 2)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.float)\n        # test with a Signal\n        from madmom.audio.signal import Signal\n        signal = Signal(pj(AUDIO_PATH, \'sample.wav\'))\n        result = segment_axis(signal, 4, 2)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue(result.dtype == np.int16)\n\n    def test_errors(self):\n        # test wrong axis\n        with self.assertRaises(ValueError):\n            segment_axis(np.arange(10), 4, 2, axis=1)\n        # testing 0 frame_size\n        with self.assertRaises(ValueError):\n            segment_axis(np.arange(10), 0, 2)\n        # testing 0 hop_size\n        with self.assertRaises(ValueError):\n            segment_axis(np.arange(10), 4, 0)\n        with self.assertRaises(ValueError):\n            # not enough data points for frame length\n            segment_axis(np.arange(3), 4, 2)\n\n    def test_values(self):\n        result = segment_axis(np.arange(10), 4, 2)\n        self.assertTrue(np.allclose(result, [[0, 1, 2, 3], [2, 3, 4, 5],\n                                             [4, 5, 6, 7], [6, 7, 8, 9]]))\n        result = segment_axis(np.arange(10), 4, 3, end=\'pad\')\n        self.assertTrue(np.allclose(result, [[0, 1, 2, 3], [3, 4, 5, 6],\n                                             [6, 7, 8, 9]]))\n        result = segment_axis(np.arange(11), 4, 3, end=\'pad\')\n        self.assertTrue(np.allclose(result, [[0, 1, 2, 3], [3, 4, 5, 6],\n                                             [6, 7, 8, 9], [9, 10, 0, 0]]))\n        result = segment_axis(np.arange(11), 4, 3, end=\'pad\', end_value=1)\n        self.assertTrue(np.allclose(result, [[0, 1, 2, 3], [3, 4, 5, 6],\n                                             [6, 7, 8, 9], [9, 10, 1, 1]]))\n        result = segment_axis(np.arange(11), 4, 3, end=\'wrap\')\n        self.assertTrue(np.allclose(result, [[0, 1, 2, 3], [3, 4, 5, 6],\n                                             [6, 7, 8, 9], [9, 10, 0, 1]]))\n        result = segment_axis(np.arange(11), 4, 3, end=\'cut\')\n        self.assertTrue(np.allclose(result, [[0, 1, 2, 3], [3, 4, 5, 6],\n                                             [6, 7, 8, 9]]))\n        result = segment_axis(np.arange(11), 4, 3, axis=0)\n        self.assertTrue(np.allclose(result, [[0, 1, 2, 3], [3, 4, 5, 6],\n                                             [6, 7, 8, 9]]))\n        result = segment_axis(np.arange(3), 4, 2, end=\'wrap\')\n        self.assertTrue(np.allclose(result, [[0, 1, 2, 0]]))\n        result = segment_axis(np.arange(3), 4, 2, end=\'pad\', end_value=9)\n        self.assertTrue(np.allclose(result, [[0, 1, 2, 9]]))\n'"
tests/test_utils_midi.py,9,"b'# encoding: utf-8\n# pylint: skip-file\n""""""\nThis file contains test functions for the madmom.utils.midi module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport os\nimport unittest\nimport tempfile\nfrom os.path import join as pj\n\nfrom madmom.utils.midi import *\n\nfrom . import ANNOTATIONS_PATH\n\ntmp_file = tempfile.NamedTemporaryFile(delete=False).name\n\n\nclass TestEventsClass(unittest.TestCase):\n\n    def setUp(self):\n        self.e1 = NoteOnEvent(tick=100, pitch=50, velocity=60)\n        self.e2 = NoteOffEvent(tick=300, pitch=50)\n        self.e3 = NoteOffEvent(tick=200, pitch=50)\n        self.e4 = NoteOnEvent(tick=300, pitch=50, velocity=60)\n\n    def test_equality(self):\n        self.assertEqual(\n            self.e1, NoteOnEvent(tick=100, pitch=50, velocity=60))\n        self.assertNotEqual(\n            self.e1, NoteOnEvent(tick=101, pitch=50, velocity=60))\n        self.assertNotEqual(\n            self.e1, NoteOnEvent(tick=100, pitch=51, velocity=60))\n        self.assertNotEqual(\n            self.e1, NoteOnEvent(tick=100, pitch=50, velocity=61))\n        self.assertNotEqual(\n            self.e1, NoteOnEvent(tick=100, pitch=50, velocity=60, channel=1))\n        self.assertNotEqual(\n            self.e1, NoteOffEvent(tick=100, pitch=50))\n\n    def test_comparison(self):\n        self.assertTrue(self.e1 < self.e2)\n        self.assertTrue(self.e1 < self.e3)\n        self.assertTrue(self.e1 < self.e4)\n        self.assertTrue(self.e4 < self.e2)\n\n    def test_sort_events(self):\n        events = sorted([self.e1, self.e2, self.e3, self.e4])\n        self.assertTrue(events == [self.e1, self.e3, self.e4, self.e2])\n        # MIDITrack should sort the events before writing the MIDI file\n        track = MIDITrack([self.e1, self.e2, self.e3, self.e4])\n        midi = MIDIFile(track)\n        midi.write(tmp_file)\n        events = MIDIFile.from_file(tmp_file).tracks[0].events\n        self.assertTrue(events == [self.e1, self.e3, self.e4, self.e2])\n\n\nclass TestMIDIFileClass(unittest.TestCase):\n\n    def test_notes(self):\n        # read a MIDI file\n        midi = MIDIFile.from_file(pj(ANNOTATIONS_PATH, \'stereo_sample.mid\'))\n        notes = np.loadtxt(pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'))\n        notes_ = midi.notes()[:, :4]\n        self.assertTrue(np.allclose(notes, notes_, atol=1e-3))\n\n    def test_recreate_midi(self):\n        notes = np.loadtxt(pj(ANNOTATIONS_PATH, \'stereo_sample.notes\'))\n        # create a MIDI file from the notes\n        midi = MIDIFile.from_notes(notes)\n        notes_ = midi.notes()[:, :4]\n        self.assertTrue(np.allclose(notes, notes_, atol=1e-3))\n        # write to a temporary file\n        midi.write(tmp_file)\n        # FIXME: re-read this file and compare the notes\n        tmp_midi = MIDIFile.from_file(tmp_file)\n        notes_ = tmp_midi.notes()[:, :4]\n        self.assertTrue(np.allclose(notes, notes_, atol=1e-3))\n\n    def test_notes_in_beats(self):\n        # read a MIDI file\n        midi = MIDIFile.from_file(pj(ANNOTATIONS_PATH, \'piano_sample.mid\'))\n        notes = np.loadtxt(pj(ANNOTATIONS_PATH, \'piano_sample.notes_in_beats\'))\n        notes_ = midi.notes(unit=\'b\')[:, :4]\n        self.assertTrue(np.allclose(notes, notes_))\n\n    def test_multitrack(self):\n        # read a multi-track MIDI file\n        midi = MIDIFile.from_file(pj(ANNOTATIONS_PATH, \'multitrack.mid\'))\n        notes = midi.notes(unit=\'b\')\n        self.assertTrue(np.allclose(notes[:4], [[0, 60, 0.5, 90, 2],\n                                                [0, 72, 2, 90, 1],\n                                                [0.5, 67, 0.5, 90, 2],\n                                                [1, 64, 0.5, 90, 2]],\n                                    atol=1e-2))\n        notes = midi.notes(unit=\'s\')\n        self.assertTrue(np.allclose(notes[:4],\n                                    [[0, 60, 0.2272725, 90, 2],\n                                     [0, 72, 0.90814303, 90, 1],\n                                     [0.2272725, 67, 0.22632553, 90, 2],\n                                     [0.45359803, 64, 0.22821947, 90, 2]]))\n\n\n# clean up\ndef teardown_module():\n    os.unlink(tmp_file)\n'"
madmom/audio/__init__.py,0,"b'# encoding: utf-8\n""""""\nThis package includes audio handling functionality and low-level features.\nThe definition of ""low"" may vary, but all ""high""-level features (e.g. beats,\nonsets, etc. -- basically everything you want to evaluate) should be in the\n`madmom.features` package.\n\nNotes\n-----\nAlmost all functionality blocks are split into two classes:\n\n1) A data class: instances are signal dependent, i.e. they operate directly on\n   the signal and show different values for different signals.\n2) A processor class: for every data class there should be a processor class\n   with the exact same name and a ""Processor"" suffix. This class must inherit\n   from madmom.Processor and define a process() method which returns a data\n   class or inherit from madmom.SequentialProcessor or ParallelProcessor.\n\nThe data classes should be either sub-classed from numpy arrays or be indexable\nand iterable. This way they can be used identically to numpy arrays.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\n# import the submodules\nfrom . import comb_filters, filters, signal, spectrogram, stft\n# import classes used often\nfrom .chroma import DeepChromaProcessor\nfrom .signal import (FramedSignal, FramedSignalProcessor, Signal,\n                     SignalProcessor, )\nfrom .spectrogram import (FilteredSpectrogram, FilteredSpectrogramProcessor,\n                          LogarithmicFilteredSpectrogram,\n                          LogarithmicFilteredSpectrogramProcessor,\n                          LogarithmicSpectrogram,\n                          LogarithmicSpectrogramProcessor,\n                          MultiBandSpectrogramProcessor, Spectrogram,\n                          SpectrogramDifference,\n                          SpectrogramDifferenceProcessor,\n                          SpectrogramProcessor, )\nfrom .stft import ShortTimeFourierTransform, ShortTimeFourierTransformProcessor\n'"
madmom/audio/cepstrogram.py,5,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains all cepstrogram related functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\nfrom scipy.fftpack import dct\n\nfrom ..processors import Processor\nfrom .filters import MelFilterbank\nfrom .spectrogram import Spectrogram\n\n\nclass Cepstrogram(np.ndarray):\n    """"""\n    The Cepstrogram class represents a transformed Spectrogram. This generic\n    class applies some transformation (usually a DCT) on a spectrogram.\n\n    Parameters\n    ----------\n    spectrogram : :class:`.audio.spectrogram.Spectrogram` instance\n        Spectrogram.\n    transform : numpy ufunc\n        Transformation applied to the `spectrogram`.\n    kwargs : dict\n        If no :class:`.audio.spectrogram.Spectrogram` instance was given,\n        one is instantiated with these additional keyword arguments.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, spectrogram, transform=dct, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, spectrogram, transform=dct, **kwargs):\n        # instantiate a Spectrogram if needed\n        if not isinstance(spectrogram, Spectrogram):\n            # try to instantiate a Spectrogram object\n            spectrogram = Spectrogram(spectrogram, **kwargs)\n\n        # apply the transformation to the spectrogram\n        data = transform(spectrogram)\n        # cast as Cepstrogram\n        obj = np.asarray(data).view(cls)\n        # save additional attributes\n        obj.spectrogram = spectrogram\n        # TODO: what are the frequencies of the bins?\n        # obj.bin_frequencies = ???\n        obj.transform = transform\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views\n        self.spectrogram = getattr(obj, \'spectrogram\', None)\n        self.bin_frequencies = getattr(obj, \'bin_frequencies\', None)\n        self.transform = getattr(obj, \'transform\', None)\n\n    @property\n    def num_frames(self):\n        """"""Number of frames.""""""\n        return len(self)\n\n    @property\n    def num_bins(self):\n        """"""Number of bins.""""""\n        return int(self.shape[1])\n\n\nclass CepstrogramProcessor(Processor):\n    """"""\n    Cepstrogram processor class.\n\n    Parameters\n    ----------\n    transform : numpy ufunc\n        Transformation applied during processing.\n\n    """"""\n\n    def __init__(self, transform=dct, **kwargs):\n        # pylint: disable=unused-argument\n        self.transform = transform\n\n    def process(self, data):\n        """"""\n        Return a Cepstrogram of the given data.\n\n        Parameters\n        ----------\n        data : numpy array\n            Data to be processed (usually a spectrogram).\n\n        Returns\n        -------\n        :class:`Cepstrogram` instance\n            Cepstrogram.\n\n        """"""\n        return Cepstrogram(data, transform=self.transform)\n\n\nMFCC_BANDS = 30\nMFCC_FMIN = 40.\nMFCC_FMAX = 15000.\nMFCC_NORM_FILTERS = True\nMFCC_MUL = 1.\nMFCC_ADD = 0.\n\n\nclass MFCC(Cepstrogram):\n    """"""\n    MFCC class.\n\n    Parameters\n    ----------\n    spectrogram : :class:`.audio.spectrogram.Spectrogram` instance\n        Spectrogram.\n    transform : numpy ufunc, optional\n        Transformation applied to the `spectrogram`.\n    filterbank : :class:`.audio.filters.Filterbank` type or instance, optional\n        Filterbank used to filter the `spectrogram`; if a\n        :class:`.audio.filters.Filterbank` type (i.e. class) is given\n        (rather than an instance), one will be created with the given type\n        and following parameters:\n    num_bands : int, optional\n        Number of filter bands (per octave, depending on the type of the\n        filterbank).\n    fmin : float, optional\n        The minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        The maximum frequency of the filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filters to area 1.\n    mul : float, optional\n        Multiply the magnitude spectrogram with this factor before taking the\n        logarithm.\n    add : float, optional\n        Add this value before taking the logarithm of the magnitudes.\n    kwargs : dict\n        If no :class:`.audio.spectrogram.Spectrogram` instance was given, one\n        is instantiated and these keyword arguments are passed.\n\n    Notes\n    -----\n\n    If a filtered or scaled Spectrogram is given, a new unfiltered and unscaled\n    Spectrogram will be computed and then the given filter and scaling will be\n    applied accordingly.\n\n    From https://en.wikipedia.org/wiki/Mel-frequency_cepstrum:\n\n    MFCCs are commonly derived as follows:\n\n    1) Take the Fourier transform of (a windowed excerpt of) a signal.\n    2) Map the powers of the spectrum obtained above onto the mel scale,\n       using triangular overlapping windows.\n    3) Take the logs of the powers at each of the mel frequencies.\n    4) Take the discrete cosine transform of the list of mel log powers,\n       as if it were a signal.\n    5) The MFCCs are the amplitudes of the resulting spectrum\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, spectrogram, transform=dct, filterbank=MelFilterbank,\n                 num_bands=MFCC_BANDS, fmin=MFCC_FMIN, fmax=MFCC_FMAX,\n                 norm_filters=MFCC_NORM_FILTERS, mul=MFCC_MUL, add=MFCC_ADD,\n                 **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, spectrogram, transform=dct, filterbank=MelFilterbank,\n                num_bands=MFCC_BANDS, fmin=MFCC_FMIN, fmax=MFCC_FMAX,\n                norm_filters=MFCC_NORM_FILTERS, mul=MFCC_MUL, add=MFCC_ADD,\n                **kwargs):\n        # for signature documentation see __init__()\n        from .filters import Filterbank\n        # instantiate a Spectrogram if needed\n        if not isinstance(spectrogram, Spectrogram):\n            # try to instantiate a Spectrogram object\n            spectrogram = Spectrogram(spectrogram, **kwargs)\n\n        # recalculate the spec if it is filtered or scaled already\n        if (spectrogram.filterbank is not None or\n                spectrogram.mul is not None or\n                spectrogram.add is not None):\n            import warnings\n            warnings.warn(\'Spectrogram was filtered or scaled already, redo \'\n                          \'calculation!\')\n            spectrogram = Spectrogram(spectrogram.stft)\n\n        # instantiate a Filterbank if needed\n        if issubclass(filterbank, Filterbank):\n            # create a filterbank of the given type\n            filterbank = filterbank(spectrogram.bin_frequencies,\n                                    num_bands=num_bands, fmin=fmin, fmax=fmax,\n                                    norm_filters=norm_filters,\n                                    duplicate_filters=False)\n        if not isinstance(filterbank, Filterbank):\n            raise ValueError(\'not a Filterbank type or instance: %s\' %\n                             filterbank)\n        # filter the spectrogram\n        data = np.dot(spectrogram, filterbank)\n        # logarithmically scale the magnitudes\n        np.log10(mul * data + add, out=data)\n        # apply the transformation\n        data = transform(data)\n        # cast as MFCC\n        obj = np.asarray(data).view(cls)\n        # save additional attributes\n        obj.transform = transform\n        obj.spectrogram = spectrogram\n        obj.filterbank = filterbank\n        obj.mul = mul\n        obj.add = add\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views\n        self.filterbank = getattr(obj, \'filterbank\', None)\n        self.mul = getattr(obj, \'mul\', MFCC_MUL)\n        self.add = getattr(obj, \'add\', MFCC_ADD)\n        super(MFCC, self).__array_finalize__(obj)\n\n\nclass MFCCProcessor(Processor):\n    """"""\n    MFCCProcessor is CepstrogramProcessor which filters the magnitude\n    spectrogram of the spectrogram with a Mel filterbank, takes the logarithm\n    and performs a discrete cosine transform afterwards.\n\n    Parameters\n    ----------\n    num_bands : int, optional\n        Number of Mel filter bands.\n    fmin : float, optional\n        Minimum frequency of the Mel filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the Mel filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filters to area 1.\n    mul : float, optional\n        Multiply the magnitude spectrogram with this factor before taking the\n        logarithm.\n    add : float, optional\n        Add this value before taking the logarithm of the magnitudes.\n    transform : numpy ufunc\n        Transformation applied to the Mel filtered spectrogram.\n\n    """"""\n\n    def __init__(self, num_bands=MFCC_BANDS, fmin=MFCC_FMIN, fmax=MFCC_FMAX,\n                 norm_filters=MFCC_NORM_FILTERS, mul=MFCC_MUL, add=MFCC_ADD,\n                 transform=dct, **kwargs):\n        # pylint: disable=unused-argument\n        self.num_bands = num_bands\n        self.fmin = fmin\n        self.fmax = fmax\n        self.norm_filters = norm_filters\n        self.mul = mul\n        self.add = add\n        self.transform = transform\n\n    def process(self, data):\n        """"""\n        Process the data and return the MFCCs of it.\n\n        Parameters\n        ----------\n        data : numpy array\n            Data to be processed (usually a spectrogram).\n\n        Returns\n        -------\n        :class:`MFCC` instance\n            MFCCs of the data.\n\n        """"""\n        return MFCC(data, num_bands=self.num_bands, fmin=self.fmin,\n                    fmax=self.fmax, norm_filters=self.norm_filters,\n                    mul=self.mul, add=self.add)\n'"
madmom/audio/chroma.py,14,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains chroma related functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport warnings\nimport numpy as np\n\nfrom madmom.audio.spectrogram import (Spectrogram, FilteredSpectrogram,\n                                      SemitoneBandpassSpectrogram)\nfrom madmom.audio.filters import (A4, Filterbank,\n                                  PitchClassProfileFilterbank as PCP,\n                                  HarmonicPitchClassProfileFilterbank as HPCP)\nfrom madmom.processors import SequentialProcessor, Processor\n\n\n# inherit from FilteredSpectrogram, since this class is closest related\nclass PitchClassProfile(FilteredSpectrogram):\n    """"""\n    Simple class for extracting pitch class profiles (PCP), i.e. chroma\n    vectors from a spectrogram.\n\n    Parameters\n    ----------\n    spectrogram : :class:`.audio.spectrogram.Spectrogram` instance\n        :class:`.audio.spectrogram.Spectrogram` instance.\n    filterbank : :class:`.audio.filters.Filterbank` class or instance\n        :class:`.audio.filters.Filterbank` class or instance.\n    num_classes : int, optional\n        Number of pitch classes.\n    fmin : float, optional\n        Minimum frequency of the PCP filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the PCP filterbank [Hz].\n    fref : float, optional\n        Reference frequency for the first PCP bin [Hz].\n    kwargs : dict, optional\n        If no :class:`.audio.spectrogram.Spectrogram` instance was given,\n        one is instantiated with these additional keyword arguments.\n\n    Notes\n    -----\n    If `fref` is \'None\', the reference frequency is estimated from the given\n    spectrogram.\n\n    References\n    ----------\n    .. [1] T. Fujishima,\n           ""Realtime chord recognition of musical sound: a system using Common\n           Lisp Music"",\n           Proceedings of the International Computer Music Conference (ICMC),\n           1999.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, spectrogram, filterbank=PCP, num_classes=PCP.CLASSES,\n                 fmin=PCP.FMIN, fmax=PCP.FMAX, fref=A4, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, spectrogram, filterbank=PCP, num_classes=PCP.CLASSES,\n                fmin=PCP.FMIN, fmax=PCP.FMAX, fref=A4, **kwargs):\n        # check spectrogram type\n        if not isinstance(spectrogram, Spectrogram):\n            spectrogram = Spectrogram(spectrogram, **kwargs)\n        # spectrogram should not be filtered\n        if hasattr(spectrogram, \'filterbank\'):\n            warnings.warn(\'Spectrogram should not be filtered.\',\n                          RuntimeWarning)\n        # reference frequency for the filterbank\n        if fref is None:\n            fref = spectrogram.tuning_frequency()\n\n        # set filterbank\n        if issubclass(filterbank, Filterbank):\n            filterbank = filterbank(spectrogram.bin_frequencies,\n                                    num_classes=num_classes, fmin=fmin,\n                                    fmax=fmax, fref=fref)\n        if not isinstance(filterbank, Filterbank):\n            raise ValueError(\'not a Filterbank type or instance: %s\' %\n                             filterbank)\n        # filter the spectrogram\n        data = np.dot(spectrogram, filterbank)\n        # cast as PitchClassProfile\n        obj = np.asarray(data).view(cls)\n        # save additional attributes\n        obj.filterbank = filterbank\n        obj.spectrogram = spectrogram\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views\n        self.filterbank = getattr(obj, \'filterbank\', None)\n        self.spectrogram = getattr(obj, \'spectrogram\', None)\n\n\nclass HarmonicPitchClassProfile(PitchClassProfile):\n    """"""\n    Class for extracting harmonic pitch class profiles (HPCP) from a\n    spectrogram.\n\n    Parameters\n    ----------\n    spectrogram : :class:`.audio.spectrogram.Spectrogram` instance\n        :class:`.audio.spectrogram.Spectrogram` instance.\n    filterbank : :class:`.audio.filters.Filterbank` class or instance\n        Filterbank class or instance.\n    num_classes : int, optional\n        Number of harmonic pitch classes.\n    fmin : float, optional\n        Minimum frequency of the HPCP filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the HPCP filterbank [Hz].\n    fref : float, optional\n        Reference frequency for the first HPCP bin [Hz].\n    window : int, optional\n        Length of the weighting window [bins].\n    kwargs : dict, optional\n        If no :class:`.audio.spectrogram.Spectrogram` instance was given,\n        one is instantiated with these additional keyword arguments.\n\n    Notes\n    -----\n    If `fref` is \'None\', the reference frequency is estimated from the given\n    spectrogram.\n\n    References\n    ----------\n    .. [1] Emilia G\xc3\xb3mez,\n           ""Tonal Description of Music Audio Signals"",\n           PhD thesis, Universitat Pompeu Fabra, Barcelona, Spain, 2006.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, spectrogram, filterbank=HPCP, num_classes=HPCP.CLASSES,\n                 fmin=HPCP.FMIN, fmax=HPCP.FMAX, fref=A4, window=HPCP.WINDOW,\n                 **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, spectrogram, filterbank=HPCP, num_classes=HPCP.CLASSES,\n                fmin=HPCP.FMIN, fmax=HPCP.FMAX, fref=A4, window=HPCP.WINDOW,\n                **kwargs):\n        # check spectrogram type\n        if not isinstance(spectrogram, Spectrogram):\n            spectrogram = Spectrogram(spectrogram, **kwargs)\n        # spectrogram should not be filtered\n        if hasattr(spectrogram, \'filterbank\'):\n            warnings.warn(\'Spectrogram should not be filtered.\',\n                          RuntimeWarning)\n        # reference frequency for the filterbank\n        if fref is None:\n            fref = spectrogram.tuning_frequency()\n\n        # set filterbank\n        if issubclass(filterbank, Filterbank):\n            filterbank = filterbank(spectrogram.bin_frequencies,\n                                    num_classes=num_classes, fmin=fmin,\n                                    fmax=fmax, fref=fref, window=window)\n        if not isinstance(filterbank, Filterbank):\n            raise ValueError(\'not a Filterbank type or instance: %s\' %\n                             filterbank)\n        # filter the spectrogram\n        data = np.dot(spectrogram, filterbank)\n        # cast as PitchClassProfile\n        obj = np.asarray(data).view(cls)\n        # save additional attributes\n        obj.filterbank = filterbank\n        obj.spectrogram = spectrogram\n        # return the object\n        return obj\n\n\ndef _dcp_flatten(fs):\n    """"""Flatten spectrograms for DeepChromaProcessor. Needs to be outside\n       of the class in order to be picklable for multiprocessing.\n    """"""\n    return np.concatenate(fs).reshape(len(fs), -1)\n\n\nclass DeepChromaProcessor(SequentialProcessor):\n    """"""\n    Compute chroma vectors from an audio file using a deep neural network\n    that focuses on harmonically relevant spectral content.\n\n    Parameters\n    ----------\n    fmin : int, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    unique_filters : bool, optional\n        Indicate if the filterbank should contain only unique filters, i.e.\n        remove duplicate filters resulting from insufficient resolution at\n        low frequencies.\n    models : list of filenames, optional\n        List of model filenames.\n\n    Notes\n    -----\n    Provided model files must be compatible with the processing pipeline and\n    the values of `fmin`, `fmax`, and `unique_filters`. The\n    general use case for the `models` parameter is to use a specific\n    model instead of an ensemble of all models.\n\n    The models shipped with madmom differ slightly from those presented in the\n    paper (less hidden units, narrower frequency band for spectrogram), but\n    achieve similar results.\n\n    References\n    ----------\n    .. [1] Filip Korzeniowski and Gerhard Widmer,\n           ""Feature Learning for Chord Recognition: The Deep Chroma Extractor"",\n           Proceedings of the 17th International Society for Music Information\n           Retrieval Conference (ISMIR), 2016.\n\n    Examples\n    --------\n    Extract a chroma vector using the deep chroma extractor:\n\n    >>> dcp = DeepChromaProcessor()\n    >>> chroma = dcp(\'tests/data/audio/sample2.wav\')\n    >>> chroma  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    array([[0.01317, 0.00721, ..., 0.00546, 0.00943],\n           [0.36809, 0.01314, ..., 0.02213, 0.01838],\n           ...,\n           [0.1534 , 0.06475, ..., 0.00896, 0.05789],\n           [0.17513, 0.0729 , ..., 0.00945, 0.06913]], dtype=float32)\n    >>> chroma.shape\n    (41, 12)\n\n    """"""\n\n    def __init__(self, fmin=65, fmax=2100, unique_filters=True, models=None,\n                 **kwargs):\n        from ..models import CHROMA_DNN\n        from ..audio.signal import SignalProcessor, FramedSignalProcessor\n        from ..audio.stft import ShortTimeFourierTransformProcessor\n        from ..audio.spectrogram import LogarithmicFilteredSpectrogramProcessor\n        from madmom.ml.nn import NeuralNetworkEnsemble\n        # signal pre-processing\n        sig = SignalProcessor(num_channels=1, sample_rate=44100)\n        frames = FramedSignalProcessor(frame_size=8192, fps=10)\n        stft = ShortTimeFourierTransformProcessor()  # caching FFT window\n        spec = LogarithmicFilteredSpectrogramProcessor(\n            num_bands=24, fmin=fmin, fmax=fmax, unique_filters=unique_filters)\n        # split the spectrogram into overlapping frames\n        spec_signal = SignalProcessor(sample_rate=10)\n        spec_frames = FramedSignalProcessor(frame_size=15, hop_size=1, fps=10)\n        # predict chroma bins with a DNN\n        nn = NeuralNetworkEnsemble.load(models or CHROMA_DNN, **kwargs)\n        # instantiate a SequentialProcessor\n        super(DeepChromaProcessor, self).__init__([\n            sig, frames, stft, spec, spec_signal, spec_frames, _dcp_flatten, nn\n        ])\n\n\n# Compressed Log Pitch (CLP) chroma stuff\nCLP_FPS = 50\nCLP_FMIN = 27.5\nCLP_FMAX = 4200.\nCLP_COMPRESSION_FACTOR = 100\nCLP_NORM = True\nCLP_THRESHOLD = 0.001\n\n\nclass CLPChroma(np.ndarray):\n    """"""\n    Compressed Log Pitch (CLP) chroma as proposed in [1]_ and [2]_.\n\n    Parameters\n    ----------\n    data : str, Signal, or SemitoneBandpassSpectrogram\n        Input data.\n    fps : int, optional\n        Desired frame rate of the signal [Hz].\n    fmin : float, optional\n        Lowest frequency of the spectrogram [Hz].\n    fmax : float, optional\n        Highest frequency of the spectrogram [Hz].\n    compression_factor : float, optional\n        Factor for compression of the energy.\n    norm : bool, optional\n        Normalize the energy of each frame to one (divide by the L2 norm).\n    threshold : float, optional\n        If the energy of a frame is below a threshold, the energy is equally\n        distributed among all chroma bins.\n\n    Notes\n    -----\n    The resulting chromagrams differ slightly from those obtained by the\n    MATLAB chroma toolbox [2]_ because of different resampling and filter\n    methods.\n\n    References\n    ----------\n    .. [1] Meinard M\xc3\xbcller,\n           ""Information retrieval for music and motion"", Springer, 2007.\n\n    .. [2] Meinard M\xc3\xbcller and Sebastian Ewert,\n           ""Chroma Toolbox: MATLAB Implementations for Extracting Variants of\n           Chroma-Based Audio Features"",\n           Proceedings of the International Conference on Music Information\n           Retrieval (ISMIR), 2011.\n\n    """"""\n\n    def __init__(self, data, fps=CLP_FPS, fmin=CLP_FMIN, fmax=CLP_FMAX,\n                 compression_factor=CLP_COMPRESSION_FACTOR, norm=CLP_NORM,\n                 threshold=CLP_THRESHOLD, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, data, fps=CLP_FPS, fmin=CLP_FMIN, fmax=CLP_FMAX,\n                compression_factor=CLP_COMPRESSION_FACTOR, norm=CLP_NORM,\n                threshold=CLP_THRESHOLD, **kwargs):\n        from madmom.audio.filters import hz2midi\n        # check input type\n        if not isinstance(data, SemitoneBandpassSpectrogram):\n            # compute SemitoneBandpassSpectrogram\n            data = SemitoneBandpassSpectrogram(data, fps=fps, fmin=fmin,\n                                               fmax=fmax)\n        # apply log compression\n        log_pitch_energy = np.log10(data * compression_factor + 1)\n        # compute chroma by adding up bins that correspond to the same\n        # pitch class\n        obj = np.zeros((log_pitch_energy.shape[0], 12)).view(cls)\n        midi_min = int(np.round(hz2midi(data.bin_frequencies[0])))\n        for p in range(log_pitch_energy.shape[1]):\n            # make sure that p maps to the correct bin_label (midi_min=12\n            # corresponds to a C and therefore chroma_idx=0)\n            chroma_idx = np.mod(midi_min + p, 12)\n            obj[:, chroma_idx] += log_pitch_energy[:, p]\n        obj.bin_labels = [\'C\', \'C#\', \'D\', \'D#\', \'E\', \'F\', \'F#\', \'G\',\n                          \'G#\', \'A\', \'A#\', \'B\']\n        obj.fps = fps\n        if norm:\n            # normalise the vectors according to the l2 norm\n            mean_energy = np.sqrt((obj ** 2).sum(axis=1))\n            idx_below_threshold = np.where(mean_energy < threshold)\n            obj /= mean_energy[:, np.newaxis]\n            obj[idx_below_threshold, :] = np.ones((1, 12)) / np.sqrt(12)\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here\n        self.fps = getattr(obj, \'fps\', None)\n        self.bin_labels = getattr(obj, \'bin_labels\', None)\n\n\nclass CLPChromaProcessor(Processor):\n    """"""\n    Compressed Log Pitch (CLP) Chroma Processor.\n\n    Parameters\n    ----------\n    fps : int, optional\n        Desired frame rate of the signal [Hz].\n    fmin : float, optional\n        Lowest frequency of the spectrogram [Hz].\n    fmax : float, optional\n        Highest frequency of the spectrogram [Hz].\n    compression_factor : float, optional\n        Factor for compression of the energy.\n    norm : bool, optional\n        Normalize the energy of each frame to one (divide by the L2 norm).\n    threshold : float, optional\n        If the energy of a frame is below a threshold, the energy is equally\n        distributed among all chroma bins.\n\n    """"""\n\n    def __init__(self, fps=CLP_FPS, fmin=CLP_FMIN, fmax=CLP_FMAX,\n                 compression_factor=CLP_COMPRESSION_FACTOR, norm=CLP_NORM,\n                 threshold=CLP_THRESHOLD, **kwargs):\n        # pylint: disable=unused-argument\n        self.fps = fps\n        self.fmin = fmin\n        self.fmax = fmax\n        self.compression_factor = compression_factor\n        self.norm = norm\n        self.threshold = threshold\n\n    def process(self, data, **kwargs):\n        """"""\n        Create a CLPChroma from the given data.\n\n        Parameters\n        ----------\n        data : Signal instance or filename\n            Data to be processed.\n\n        Returns\n        -------\n        clp : :class:`CLPChroma` instance\n            CLPChroma.\n\n        """"""\n        # update arguments passed to CLPChroma\n        args = dict(fps=self.fps, fmin=self.fmin, fmax=self.fmax,\n                    compression_factor=self.compression_factor,\n                    norm=self.norm, threshold=self.threshold)\n        args.update(kwargs)\n        # instantiate a CLPChroma\n        return CLPChroma(data, **args)\n'"
madmom/audio/filters.py,72,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains filter and filterbank related functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\nfrom ..processors import Processor\n\nFILTER_DTYPE = np.float32\nA4 = 440.\n\n\n# Mel frequency scale\ndef hz2mel(f):\n    """"""\n    Convert Hz frequencies to Mel.\n\n    Parameters\n    ----------\n    f : numpy array\n        Input frequencies [Hz].\n\n    Returns\n    -------\n    m : numpy array\n        Frequencies in Mel [Mel].\n\n    """"""\n    return 1127.01048 * np.log(np.asarray(f) / 700. + 1.)\n\n\ndef mel2hz(m):\n    """"""\n    Convert Mel frequencies to Hz.\n\n    Parameters\n    ----------\n    m : numpy array\n        Input frequencies [Mel].\n\n    Returns\n    -------\n    f: numpy array\n        Frequencies in Hz [Hz].\n\n    """"""\n    return 700. * (np.exp(np.asarray(m) / 1127.01048) - 1.)\n\n\ndef mel_frequencies(num_bands, fmin, fmax):\n    """"""\n    Returns frequencies aligned on the Mel scale.\n\n    Parameters\n    ----------\n    num_bands : int\n        Number of bands.\n    fmin : float\n        Minimum frequency [Hz].\n    fmax : float\n        Maximum frequency [Hz].\n\n    Returns\n    -------\n    mel_frequencies: numpy array\n        Frequencies with Mel spacing [Hz].\n\n    """"""\n    # convert fmin and fmax to the Mel scale and return an array of frequencies\n    return mel2hz(np.linspace(hz2mel(fmin), hz2mel(fmax), num_bands))\n\n\n# Bark frequency scale\ndef hz2bark(f):\n    """"""\n    Convert Hz frequencies to Bark.\n\n    Parameters\n    ----------\n    f : numpy array\n        Input frequencies [Hz].\n\n    Returns\n    -------\n    z : numpy array\n        Frequencies in Bark [Bark].\n\n    """"""\n    raise NotImplementedError(\'please check this function, it produces \'\n                              \'negative values\')\n    # TODO: use Zwicker\'s formula?\n    #       return 13 * arctan(0.00076 * f) + 3.5 * arctan((f / 7500.) ** 2)\n    return (26.81 / (1. + 1960. / np.asarray(f))) - 0.53\n\n\ndef bark2hz(z):\n    """"""\n    Convert Bark frequencies to Hz.\n\n    Parameters\n    ----------\n    z : numpy array\n        Input frequencies [Bark].\n\n    Returns\n    -------\n    f : numpy array\n        Frequencies in Hz [Hz].\n\n    """"""\n    raise NotImplementedError(\'please check this function, it produces weird \'\n                              \'values\')\n    # TODO: use Zwicker\'s formula? what\'s the inverse of the above?\n    return 1960. / (26.81 / (np.asarray(z) + 0.53) - 1.)\n\n\ndef bark_frequencies(fmin=20., fmax=15500.):\n    """"""\n    Returns frequencies aligned on the Bark scale.\n\n    Parameters\n    ----------\n    fmin : float\n        Minimum frequency [Hz].\n    fmax : float\n        Maximum frequency [Hz].\n\n    Returns\n    -------\n    bark_frequencies : numpy array\n        Frequencies with Bark spacing [Hz].\n\n    """"""\n    # frequencies aligned to the Bark-scale\n    frequencies = np.array([20, 100, 200, 300, 400, 510, 630, 770, 920, 1080,\n                            1270, 1480, 1720, 2000, 2320, 2700, 3150, 3700,\n                            4400, 5300, 6400, 7700, 9500, 12000, 15500])\n    # filter frequencies\n    frequencies = frequencies[np.searchsorted(frequencies, fmin):]\n    frequencies = frequencies[:np.searchsorted(frequencies, fmax, \'right\')]\n    # return\n    return frequencies\n\n\ndef bark_double_frequencies(fmin=20., fmax=15500.):\n    """"""\n    Returns frequencies aligned on the Bark-scale.\n\n    The list also includes center frequencies between the corner frequencies.\n\n    Parameters\n    ----------\n    fmin : float\n        Minimum frequency [Hz].\n    fmax : float\n        Maximum frequency [Hz].\n\n    Returns\n    -------\n    bark_frequencies : numpy array\n        Frequencies with Bark spacing [Hz].\n\n    """"""\n    # frequencies aligned to the Bark-scale, also includes center frequencies\n    frequencies = np.array([20, 50, 100, 150, 200, 250, 300, 350, 400, 450,\n                            510, 570, 630, 700, 770, 840, 920, 1000, 1080,\n                            1170, 1270, 1370, 1480, 1600, 1720, 1850, 2000,\n                            2150, 2320, 2500, 2700, 2900, 3150, 3400, 3700,\n                            4000, 4400, 4800, 5300, 5800, 6400, 7000, 7700,\n                            8500, 9500, 10500, 12000, 13500, 15500])\n    # filter frequencies\n    frequencies = frequencies[np.searchsorted(frequencies, fmin):]\n    frequencies = frequencies[:np.searchsorted(frequencies, fmax, \'right\')]\n    # return\n    return frequencies\n\n\n# logarithmic frequency scale\ndef log_frequencies(bands_per_octave, fmin, fmax, fref=A4):\n    """"""\n    Returns frequencies aligned on a logarithmic frequency scale.\n\n    Parameters\n    ----------\n    bands_per_octave : int\n        Number of filter bands per octave.\n    fmin : float\n        Minimum frequency [Hz].\n    fmax : float\n        Maximum frequency [Hz].\n    fref : float, optional\n        Tuning frequency [Hz].\n\n    Returns\n    -------\n    log_frequencies : numpy array\n        Logarithmically spaced frequencies [Hz].\n\n    Notes\n    -----\n    If `bands_per_octave` = 12 and `fref` = 440 are used, the frequencies are\n    equivalent to MIDI notes.\n\n    """"""\n    # get the range\n    left = np.floor(np.log2(float(fmin) / fref) * bands_per_octave)\n    right = np.ceil(np.log2(float(fmax) / fref) * bands_per_octave)\n    # generate frequencies\n    frequencies = fref * 2. ** (np.arange(left, right) /\n                                float(bands_per_octave))\n    # filter frequencies\n    # needed, because range might be bigger because of the use of floor/ceil\n    frequencies = frequencies[np.searchsorted(frequencies, fmin):]\n    frequencies = frequencies[:np.searchsorted(frequencies, fmax, \'right\')]\n    # return\n    return frequencies\n\n\ndef semitone_frequencies(fmin, fmax, fref=A4):\n    """"""\n    Returns frequencies separated by semitones.\n\n    Parameters\n    ----------\n    fmin : float\n        Minimum frequency [Hz].\n    fmax : float\n        Maximum frequency [Hz].\n    fref : float, optional\n        Tuning frequency of A4 [Hz].\n\n    Returns\n    -------\n    semitone_frequencies : numpy array\n        Semitone frequencies [Hz].\n\n    """"""\n    # return MIDI frequencies\n    return log_frequencies(12, fmin, fmax, fref)\n\n\n# MIDI\ndef hz2midi(f, fref=A4):\n    """"""\n    Convert frequencies to the corresponding MIDI notes.\n\n    Parameters\n    ----------\n    f : numpy array\n        Input frequencies [Hz].\n    fref : float, optional\n        Tuning frequency of A4 [Hz].\n\n    Returns\n    -------\n    m : numpy array\n        MIDI notes\n\n    Notes\n    -----\n    For details see: at http://www.phys.unsw.edu.au/jw/notes.html\n    This function does not necessarily return a valid MIDI Note, you may need\n    to round it to the nearest integer.\n\n    """"""\n    return (12. * np.log2(np.asarray(f, dtype=np.float) / fref)) + 69.\n\n\ndef midi2hz(m, fref=A4):\n    """"""\n    Convert MIDI notes to corresponding frequencies.\n\n    Parameters\n    ----------\n    m : numpy array\n        Input MIDI notes.\n    fref : float, optional\n        Tuning frequency of A4 [Hz].\n\n    Returns\n    -------\n    f : numpy array\n        Corresponding frequencies [Hz].\n\n    """"""\n    return 2. ** ((np.asarray(m, dtype=np.float) - 69.) / 12.) * fref\n\n\n# provide an alias to semitone_frequencies\nmidi_frequencies = semitone_frequencies\n\n\n# ERB frequency scale\ndef hz2erb(f):\n    """"""\n    Convert Hz to ERB.\n\n    Parameters\n    ----------\n    f : numpy array\n        Input frequencies [Hz].\n\n    Returns\n    -------\n    e : numpy array\n        Frequencies in ERB [ERB].\n\n    Notes\n    -----\n    Information about the ERB scale can be found at:\n    https://ccrma.stanford.edu/~jos/bbt/Equivalent_Rectangular_Bandwidth.html\n\n    """"""\n    return 21.4 * np.log10(1 + 4.37 * np.asarray(f) / 1000.)\n\n\ndef erb2hz(e):\n    """"""\n    Convert ERB scaled frequencies to Hz.\n\n    Parameters\n    ----------\n    e : numpy array\n        Input frequencies [ERB].\n\n    Returns\n    -------\n    f : numpy array\n        Frequencies in Hz [Hz].\n\n    Notes\n    -----\n    Information about the ERB scale can be found at:\n    https://ccrma.stanford.edu/~jos/bbt/Equivalent_Rectangular_Bandwidth.html\n\n    """"""\n    return (10. ** (np.asarray(e) / 21.4) - 1.) * 1000. / 4.37\n\n\n# helper functions for filter creation\ndef frequencies2bins(frequencies, bin_frequencies, unique_bins=False):\n    """"""\n    Map frequencies to the closest corresponding bins.\n\n    Parameters\n    ----------\n    frequencies : numpy array\n        Input frequencies [Hz].\n    bin_frequencies : numpy array\n        Frequencies of the (FFT) bins [Hz].\n    unique_bins : bool, optional\n        Return only unique bins, i.e. remove all duplicate bins resulting from\n        insufficient resolution at low frequencies.\n\n    Returns\n    -------\n    bins : numpy array\n        Corresponding (unique) bins.\n\n    Notes\n    -----\n    It can be important to return only unique bins, otherwise the lower\n    frequency bins can be given too much weight if all bins are simply summed\n    up (as in the spectral flux onset detection).\n\n    """"""\n    # cast as numpy arrays\n    frequencies = np.asarray(frequencies)\n    bin_frequencies = np.asarray(bin_frequencies)\n    # map the frequencies to the closest bins\n    # solution found at: http://stackoverflow.com/questions/8914491/\n    indices = bin_frequencies.searchsorted(frequencies)\n    indices = np.clip(indices, 1, len(bin_frequencies) - 1)\n    left = bin_frequencies[indices - 1]\n    right = bin_frequencies[indices]\n    indices -= frequencies - left < right - frequencies\n    # only keep unique bins if requested\n    if unique_bins:\n        indices = np.unique(indices)\n    # return the (unique) bin indices of the closest matches\n    return indices\n\n\ndef bins2frequencies(bins, bin_frequencies):\n    """"""\n    Convert bins to the corresponding frequencies.\n\n    Parameters\n    ----------\n    bins : numpy array\n        Bins (e.g. FFT bins).\n    bin_frequencies : numpy array\n        Frequencies of the (FFT) bins [Hz].\n\n    Returns\n    -------\n    f : numpy array\n        Corresponding frequencies [Hz].\n\n    """"""\n    # map the frequencies to spectrogram bins\n    return np.asarray(bin_frequencies, dtype=np.float)[np.asarray(bins)]\n\n\n# filter classes\nclass Filter(np.ndarray):\n    """"""\n    Generic Filter class.\n\n    Parameters\n    ----------\n    data : 1D numpy array\n        Filter data.\n    start : int, optional\n        Start position (see notes).\n    norm : bool, optional\n        Normalize the filter area to 1.\n\n    Notes\n    -----\n    The start position is mandatory if a Filter should be used for the creation\n    of a Filterbank.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, data, start=0, norm=False):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, data, start=0, norm=False):\n        # input is an numpy ndarray instance\n        if isinstance(data, np.ndarray):\n            # cast as Filter\n            obj = np.asarray(data, dtype=FILTER_DTYPE).view(cls)\n        else:\n            raise TypeError(\'wrong input data for Filter, must be np.ndarray\')\n        # right now, allow only 1D\n        if obj.ndim != 1:\n            raise NotImplementedError(\'please add multi-dimension support\')\n        # normalize\n        if norm:\n            obj /= np.sum(obj)\n        # set attributes\n        obj.start = int(start)\n        obj.stop = int(start + len(data))\n        # return the object\n        return obj\n\n    @classmethod\n    def band_bins(cls, bins, **kwargs):\n        """"""\n        Must yield the center/crossover bins needed for filter creation.\n\n        Parameters\n        ----------\n        bins : numpy array\n            Center/crossover bins used for the creation of filters.\n        kwargs : dict, optional\n            Additional parameters for for the creation of filters\n            (e.g. if the filters should overlap or not).\n\n        """"""\n        raise NotImplementedError(\'needs to be implemented by sub-classes\')\n\n    @classmethod\n    def filters(cls, bins, norm, **kwargs):\n        """"""\n        Create a list with filters for the given bins.\n\n        Parameters\n        ----------\n        bins : list or numpy array\n            Center/crossover bins of the filters.\n        norm : bool\n            Normalize the area of the filter(s) to 1.\n        kwargs : dict, optional\n            Additional parameters passed to :func:`band_bins`\n            (e.g. if the filters should overlap or not).\n\n        Returns\n        -------\n        filters : list\n            Filter(s) for the given bins.\n\n        """"""\n        # generate a list of filters for the given center/crossover bins\n        filters = []\n        for filter_args in cls.band_bins(bins, **kwargs):\n            # create a filter and append it to the list\n            filters.append(cls(*filter_args, norm=norm))\n        # return the filters\n        return filters\n\n\nclass TriangularFilter(Filter):\n    """"""\n    Triangular filter class.\n\n    Create a triangular shaped filter with length `stop`, height 1 (unless\n    normalized) with indices <= `start` set to 0.\n\n    Parameters\n    ----------\n    start : int\n        Start bin of the filter.\n    center : int\n        Center bin of the filter.\n    stop : int\n        Stop bin of the filter.\n    norm : bool, optional\n        Normalize the area of the filter to 1.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, start, center, stop, norm=False):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, start, center, stop, norm=False):\n        # pylint: disable=arguments-differ\n        # center must be between start & stop\n        if not start <= center < stop:\n            raise ValueError(\'`center` must be between `start` and `stop`\')\n        # cast variables to int\n        center = int(center)\n        start = int(start)\n        stop = int(stop)\n        # make center and stop relative\n        center -= start\n        stop -= start\n        # create filter\n        data = np.zeros(stop)\n        # rising edge (without the center)\n        data[:center] = np.linspace(0, 1, center, endpoint=False)\n        # falling edge (including the center, but without the last bin)\n        data[center:] = np.linspace(1, 0, stop - center, endpoint=False)\n        # cast to TriangularFilter\n        obj = Filter.__new__(cls, data, start, norm)\n        # set the center bin\n        obj.center = start + center\n        # return the filter\n        return obj\n\n    @classmethod\n    def band_bins(cls, bins, overlap=True):\n        """"""\n        Yields start, center and stop bins for creation of triangular filters.\n\n        Parameters\n        ----------\n        bins : list or numpy array\n            Center bins of filters.\n        overlap : bool, optional\n            Filters should overlap (see notes).\n\n        Yields\n        ------\n        start : int\n            Start bin of the filter.\n        center : int\n            Center bin of the filter.\n        stop : int\n            Stop bin of the filter.\n\n        Notes\n        -----\n        If `overlap` is \'False\', the `start` and `stop` bins of the filters\n        are interpolated between the centre bins, normal rounding applies.\n\n        """"""\n        # pylint: disable=arguments-differ\n        # make sure enough bins are given\n        if len(bins) < 3:\n            raise ValueError(\'not enough bins to create a TriangularFilter\')\n        # yield the bins\n        index = 0\n        while index + 3 <= len(bins):\n            # get start, center and stop bins\n            start, center, stop = bins[index: index + 3]\n            # create non-overlapping filters\n            if not overlap:\n                # re-arrange the start and stop positions\n                start = int(np.floor((center + start) / 2.))\n                stop = int(np.ceil((center + stop) / 2.))\n            # consistently handle too-small filters\n            if stop - start < 2:\n                center = start\n                stop = start + 1\n            # yield the bins and continue\n            yield start, center, stop\n            # increase counter\n            index += 1\n\n\nclass RectangularFilter(Filter):\n    """"""\n    Rectangular filter class.\n\n    Create a rectangular shaped filter with length `stop`, height 1 (unless\n    normalized) with indices < `start` set to 0.\n\n    Parameters\n    ----------\n    start : int\n        Start bin of the filter.\n    stop : int\n        Stop bin of the filter.\n    norm : bool, optional\n        Normalize the area of the filter to 1.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, start, stop, norm=False):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, start, stop, norm=False):\n        # pylint: disable=signature-differs\n        # start must be smaller than stop\n        if start >= stop:\n            raise ValueError(\'`start` must be smaller than `stop`\')\n        # length of the filter\n        length = stop - start\n        # create filter\n        data = np.ones(length, dtype=np.float)\n        # cast to RectangularFilter and return it\n        return Filter.__new__(cls, data, start, norm)\n\n    @classmethod\n    def band_bins(cls, bins, overlap=False):\n        """"""\n        Yields start and stop bins and normalization info for creation of\n        rectangular filters.\n\n        Parameters\n        ----------\n        bins : list or numpy array\n            Crossover bins of filters.\n        overlap : bool, optional\n            Filters should overlap.\n\n        Yields\n        ------\n        start : int\n            Start bin of the filter.\n        stop : int\n            Stop bin of the filter.\n\n        """"""\n        # pylint: disable=arguments-differ\n        # make sure enough bins are given\n        if len(bins) < 2:\n            raise ValueError(\'not enough bins to create a RectangularFilter\')\n        # overlapping filters?\n        if overlap:\n            raise NotImplementedError(\'please implement if needed!\')\n        # yield the bins\n        index = 0\n        while index + 2 <= len(bins):\n            # get start and stop bins\n            start, stop = bins[index: index + 2]\n            # yield the bins and continue\n            yield start, stop\n            # increase counter\n            index += 1\n\n\n# default values for filter banks\nFMIN = 30.\nFMAX = 17000.\nNUM_BANDS = 12\nNORM_FILTERS = True\nUNIQUE_FILTERS = True\n\n\nclass Filterbank(np.ndarray):\n    """"""\n    Generic filterbank class.\n\n    A Filterbank is a simple numpy array enhanced with several additional\n    attributes, e.g. number of bands.\n\n    A Filterbank has a shape of (num_bins, num_bands) and can be used to\n    filter a spectrogram of shape (num_frames, num_bins) to (num_frames,\n    num_bands).\n\n    Parameters\n    ----------\n    data : numpy array, shape (num_bins, num_bands)\n        Data of the filterbank .\n    bin_frequencies : numpy array, shape (num_bins, )\n        Frequencies of the bins [Hz].\n\n    Notes\n    -----\n    The length of `bin_frequencies` must be equal to the first dimension\n    of the given `data` array.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, data, bin_frequencies):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, data, bin_frequencies):\n        # input is an numpy ndarray instance\n        if isinstance(data, np.ndarray) and data.ndim == 2:\n            # cast as Filterbank\n            obj = np.asarray(data, dtype=FILTER_DTYPE).view(cls)\n        else:\n            raise TypeError(\'wrong input data for Filterbank, must be a 2D \'\n                            \'np.ndarray\')\n        # set bin frequencies\n        if len(bin_frequencies) != obj.shape[0]:\n            raise ValueError(\'`bin_frequencies` must have the same length as \'\n                             \'the first dimension of `data`.\')\n        obj.bin_frequencies = np.asarray(bin_frequencies, dtype=np.float)\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here\n        self.bin_frequencies = getattr(obj, \'bin_frequencies\', None)\n\n    @classmethod\n    def _put_filter(cls, filt, band):\n        """"""\n        Puts a filter in the band, internal helper function.\n\n        Parameters\n        ----------\n        filt : :class:`Filter` instance\n            Filter to be put into the band.\n        band : numpy array\n            Band in which the filter should be put.\n\n        Notes\n        -----\n        The `band` must be an existing numpy array where the filter `filt` is\n        put in, given the position of the filter. Out of range filters are\n        truncated. If there are non-zero values in the filter band at the\n        respective positions, the maximum value of the `band` and the filter\n        `filt` is used.\n\n        """"""\n        if not isinstance(filt, Filter):\n            raise ValueError(\'unable to determine start position of Filter\')\n        # determine start and stop positions\n        start = filt.start\n        stop = start + len(filt)\n        # truncate the filter if it starts before the 0th band bin\n        if start < 0:\n            filt = filt[-start:]\n            start = 0\n        # truncate the filter if it ends after the last band bin\n        if stop > len(band):\n            filt = filt[:-(stop - len(band))]\n            stop = len(band)\n        # put the filter in place\n        filter_position = band[start:stop]\n        # TODO: if needed, allow other handling (like summing values)\n        np.maximum(filt, filter_position, out=filter_position)\n\n    @classmethod\n    def from_filters(cls, filters, bin_frequencies):\n        """"""\n        Create a filterbank with possibly multiple filters per band.\n\n        Parameters\n        ----------\n        filters : list (of lists) of Filters\n            List of Filters (per band); if multiple filters per band are\n            desired, they should be also contained in a list, resulting in a\n            list of lists of Filters.\n        bin_frequencies : numpy array\n            Frequencies of the bins (needed to determine the expected size of\n            the filterbank).\n\n        Returns\n        -------\n        filterbank : :class:`Filterbank` instance\n            Filterbank with respective filter elements.\n\n        """"""\n        # create filterbank\n        fb = np.zeros((len(bin_frequencies), len(filters)))\n        # iterate over all filters\n        for band_id, band_filter in enumerate(filters):\n            # get the band\'s corresponding slice of the filterbank\n            band = fb[:, band_id]\n            # if there\'s a list of filters for the current band, put them all\n            # into this band\n            if isinstance(band_filter, list):\n                for filt in band_filter:\n                    cls._put_filter(filt, band)\n            # otherwise put this filter into that band\n            else:\n                cls._put_filter(band_filter, band)\n        # create Filterbank and cast as class where this method was called from\n        return Filterbank.__new__(cls, fb, bin_frequencies)\n\n    @property\n    def num_bins(self):\n        """"""Number of bins.""""""\n        return self.shape[0]\n\n    @property\n    def num_bands(self):\n        """"""Number of bands.""""""\n        return self.shape[1]\n\n    @property\n    def corner_frequencies(self):\n        """"""Corner frequencies of the filter bands.""""""\n        freqs = []\n        for band in range(self.num_bands):\n            # get the non-zero bins per band\n            bins = np.nonzero(self[:, band])[0]\n            # append the lowest and highest bin\n            freqs.append([np.min(bins), np.max(bins)])\n        # map to frequencies\n        return bins2frequencies(freqs, self.bin_frequencies)\n\n    @property\n    def center_frequencies(self):\n        """"""Center frequencies of the filter bands.""""""\n        freqs = []\n        for band in range(self.num_bands):\n            # get the non-zero bins per band\n            bins = np.nonzero(self[:, band])[0]\n            min_bin = np.min(bins)\n            max_bin = np.max(bins)\n            # if we have a uniform filter, use the center bin\n            if self[min_bin, band] == self[max_bin, band]:\n                center = int(min_bin + (max_bin - min_bin) / 2.)\n            # if we have a filter with a peak, use the peak bin\n            else:\n                center = min_bin + np.argmax(self[min_bin: max_bin, band])\n            freqs.append(center)\n        # map to frequencies\n        return bins2frequencies(freqs, self.bin_frequencies)\n\n    @property\n    def fmin(self):\n        """"""Minimum frequency of the filterbank.""""""\n        return self.bin_frequencies[np.nonzero(self)[0][0]]\n\n    @property\n    def fmax(self):\n        """"""Maximum frequency of the filterbank.""""""\n        return self.bin_frequencies[np.nonzero(self)[0][-1]]\n\n\nclass FilterbankProcessor(Processor, Filterbank):\n    """"""\n    Generic filterbank processor class.\n\n    A FilterbankProcessor is a simple wrapper for Filterbank which adds a\n    process() method.\n\n    See Also\n    --------\n    :class:`Filterbank`\n\n    """"""\n    # Note: this class is only for consistency of the naming scheme. Basically\n    #       the process()\n\n    def process(self, data):\n        """"""\n        Filter the given data with the Filterbank.\n\n        Parameters\n        ----------\n        data : 2D numpy array\n            Data to be filtered.\n        Returns\n        -------\n        filt_data : numpy array\n            Filtered data.\n\n        Notes\n        -----\n        This method makes the :class:`Filterbank` act as a :class:`Processor`.\n\n        """"""\n        # Note: we do not inherit from Processor, since instantiation gets\n        #       messed up\n        return np.dot(data, self)\n\n    @staticmethod\n    def add_arguments(parser, filterbank=None, num_bands=None,\n                      crossover_frequencies=None, fmin=None, fmax=None,\n                      norm_filters=None, unique_filters=None):\n        """"""\n        Add filterbank related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        filterbank : :class:`.audio.filters.Filterbank`, optional\n            Use a filterbank of that type.\n        num_bands : int or list, optional\n            Number of bands (per octave).\n        crossover_frequencies : list or numpy array, optional\n            List of crossover frequencies at which the `spectrogram` is split\n            into bands.\n        fmin : float, optional\n            Minimum frequency of the filterbank [Hz].\n        fmax : float, optional\n            Maximum frequency of the filterbank [Hz].\n        norm_filters : bool, optional\n            Normalize the filters of the filterbank to area 1.\n        unique_filters : bool, optional\n            Indicate if the filterbank should contain only unique filters,\n            i.e. remove duplicate filters resulting from insufficient\n            resolution at low frequencies.\n\n        Returns\n        -------\n        argparse argument group\n            Filterbank argument parser group.\n\n        Notes\n        -----\n        Parameters are included in the group only if they are not \'None\'.\n        Depending on the type of the `filterbank`, either `num_bands` or\n        `crossover_frequencies` should be used.\n\n        """"""\n        from madmom.utils import OverrideDefaultListAction\n        # add filterbank related options to the existing parser\n        g = parser.add_argument_group(\'filterbank arguments\')\n        # filterbank\n        # TODO: add a list with filterbank options?\n        if filterbank is not None:\n            if issubclass(filterbank, Filterbank):\n                g.add_argument(\'--no_filter\', dest=\'filterbank\',\n                               action=\'store_false\', default=filterbank,\n                               help=\'do not filter the spectrogram with a \'\n                                    \'filterbank [default=%(default)s]\')\n            else:\n                g.add_argument(\'--filterbank\', action=\'store_true\',\n                               default=None,\n                               help=\'filter the spectrogram with a filterbank \'\n                                    \'of this type\')\n        # number of bands\n        # TODO: add a second argument with num_bands_per_octave and rename the\n        #       option at the relevant filterbanks accordingly?\n        # depending on the type of num_bands, use different options\n        if isinstance(num_bands, int):\n            g.add_argument(\'--num_bands\', action=\'store\', type=int,\n                           default=num_bands,\n                           help=\'number of filter bands (per octave) \'\n                                \'[default=%(default)i]\')\n        elif isinstance(num_bands, list):\n            # Note: this option can be used in conjunction with stacked\n            #       spectrograms with different frame sizes to have different\n            #       number of bands per frame size\n            g.add_argument(\'--num_bands\', type=int, default=num_bands,\n                           action=OverrideDefaultListAction, sep=\',\',\n                           help=\'(comma separated list of) number of filter \'\n                                \'bands (per octave) [default=%(default)s]\')\n        # crossover frequencies\n        if crossover_frequencies is not None:\n            g.add_argument(\'--crossover_frequencies\', type=float, sep=\',\',\n                           action=OverrideDefaultListAction,\n                           default=crossover_frequencies,\n                           help=\'(comma separated) list with crossover \'\n                                \'frequencies [Hz, default=%(default)s]\')\n        # minimum frequency\n        if fmin is not None:\n            g.add_argument(\'--fmin\', action=\'store\', type=float,\n                           default=fmin,\n                           help=\'minimum frequency of the filterbank \'\n                                \'[Hz, default=%(default).1f]\')\n        # maximum frequency\n        if fmax is not None:\n            g.add_argument(\'--fmax\', action=\'store\', type=float,\n                           default=fmax,\n                           help=\'maximum frequency of the filterbank \'\n                                \'[Hz, default=%(default).1f]\')\n        # normalize filters\n        if norm_filters is True:\n            g.add_argument(\'--no_norm_filters\', dest=\'norm_filters\',\n                           action=\'store_false\', default=norm_filters,\n                           help=\'do not normalize the filters to area 1 \'\n                                \'[default=True]\')\n        elif norm_filters is False:\n            g.add_argument(\'--norm_filters\', dest=\'norm_filters\',\n                           action=\'store_true\', default=norm_filters,\n                           help=\'normalize the filters to area 1 \'\n                                \'[default=False]\')\n        # unique or duplicate filters\n        if unique_filters is True:\n            # add option to keep the duplicate filters\n            g.add_argument(\'--duplicate_filters\', dest=\'unique_filters\',\n                           action=\'store_false\', default=unique_filters,\n                           help=\'keep duplicate filters resulting from \'\n                                \'insufficient resolution at low frequencies \'\n                                \'[default=only unique filters are kept]\')\n        elif unique_filters is False:\n            g.add_argument(\'--unique_filters\', action=\'store_true\',\n                           default=unique_filters,\n                           help=\'keep only unique filters, i.e. remove \'\n                                \'duplicate filters resulting from \'\n                                \'insufficient resolution at low frequencies \'\n                                \'[default=duplicate filters are kept]\')\n        # return the group\n        return g\n\n\nclass MelFilterbank(Filterbank):\n    """"""\n    Mel filterbank class.\n\n    Parameters\n    ----------\n    bin_frequencies : numpy array\n        Frequencies of the bins [Hz].\n    num_bands : int, optional\n        Number of filter bands.\n    fmin : float, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filters to area 1.\n    unique_filters : bool, optional\n        Keep only unique filters, i.e. remove duplicate filters resulting\n        from insufficient resolution at low frequencies.\n\n    Notes\n    -----\n    Because of rounding and mapping of frequencies to bins and back to\n    frequencies, the actual minimum, maximum and center frequencies do not\n    necessarily match the parameters given.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    NUM_BANDS = 40\n    FMIN = 20.\n    FMAX = 17000.\n    NORM_FILTERS = True\n    UNIQUE_FILTERS = True\n\n    def __init__(self, bin_frequencies, num_bands=NUM_BANDS, fmin=FMIN,\n                 fmax=FMAX, norm_filters=NORM_FILTERS,\n                 unique_filters=UNIQUE_FILTERS, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, bin_frequencies, num_bands=NUM_BANDS, fmin=FMIN,\n                fmax=FMAX, norm_filters=NORM_FILTERS,\n                unique_filters=UNIQUE_FILTERS, **kwargs):\n        # pylint: disable=arguments-differ\n        # get a list of frequencies aligned on the Mel scale\n        # request 2 more bands, because these are the edge frequencies\n        frequencies = mel_frequencies(num_bands + 2, fmin, fmax)\n        # convert to bins\n        bins = frequencies2bins(frequencies, bin_frequencies,\n                                unique_bins=unique_filters)\n        # get overlapping triangular filters\n        filters = TriangularFilter.filters(bins, norm=norm_filters,\n                                           overlap=True)\n        # create a MelFilterbank from the filters\n        return cls.from_filters(filters, bin_frequencies)\n\n\nclass BarkFilterbank(Filterbank):\n    """"""\n    Bark filterbank class.\n\n    Parameters\n    ----------\n    bin_frequencies : numpy array\n        Frequencies of the bins [Hz].\n    num_bands : {\'normal\', \'double\'}, optional\n        Number of filter bands.\n    fmin : float, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filters to area 1.\n    unique_filters : bool, optional\n        Keep only unique filters, i.e. remove duplicate filters resulting\n        from insufficient resolution at low frequencies.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    FMIN = 20.\n    FMAX = 15500.\n    NUM_BANDS = \'normal\'\n    NORM_FILTERS = True\n    UNIQUE_FILTERS = True\n\n    def __init__(self, bin_frequencies, num_bands=NUM_BANDS, fmin=FMIN,\n                 fmax=FMAX, norm_filters=NORM_FILTERS,\n                 unique_filters=UNIQUE_FILTERS, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, bin_frequencies, num_bands=NUM_BANDS, fmin=FMIN,\n                fmax=FMAX, norm_filters=NORM_FILTERS,\n                unique_filters=UNIQUE_FILTERS, **kwargs):\n        # pylint: disable=arguments-differ\n        # get a list of frequencies\n        if num_bands == \'normal\':\n            frequencies = bark_frequencies(fmin, fmax)\n        elif num_bands == \'double\':\n            frequencies = bark_double_frequencies(fmin, fmax)\n        else:\n            raise ValueError(""`num_bands` must be {\'normal\', \'double\'}"")\n        # convert to bins\n        bins = frequencies2bins(frequencies, bin_frequencies,\n                                unique_bins=not unique_filters)\n        # get non-overlapping rectangular filters\n        filters = RectangularFilter.filters(bins, norm=norm_filters,\n                                            overlap=False)\n        # create a BarkFilterbank from the filters\n        return cls.from_filters(filters, bin_frequencies)\n\n\nclass LogarithmicFilterbank(Filterbank):\n    """"""\n    Logarithmic filterbank class.\n\n    Parameters\n    ----------\n    bin_frequencies : numpy array\n        Frequencies of the bins [Hz].\n    num_bands : int, optional\n        Number of filter bands (per octave).\n    fmin : float, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    fref : float, optional\n        Tuning frequency of the filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filters to area 1.\n    unique_filters : bool, optional\n        Keep only unique filters, i.e. remove duplicate filters resulting\n        from insufficient resolution at low frequencies.\n    bands_per_octave : bool, optional\n        Indicates whether `num_bands` is given as number of bands per octave\n        (\'True\', default) or as an absolute number of bands (\'False\').\n\n    Notes\n    -----\n    `num_bands` sets either the number of bands per octave or the total number\n    of bands, depending on the setting of `bands_per_octave`. `num_bands` is\n    used to set also the number of bands per octave to keep the argument for\n    all classes the same. If 12 bands per octave are used, a filterbank with\n    semitone spacing is created.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    NUM_BANDS_PER_OCTAVE = 12\n\n    def __init__(self, bin_frequencies, num_bands=NUM_BANDS_PER_OCTAVE,\n                 fmin=FMIN, fmax=FMAX, fref=A4, norm_filters=NORM_FILTERS,\n                 unique_filters=UNIQUE_FILTERS, bands_per_octave=True):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, bin_frequencies, num_bands=NUM_BANDS_PER_OCTAVE,\n                fmin=FMIN, fmax=FMAX, fref=A4, norm_filters=NORM_FILTERS,\n                unique_filters=UNIQUE_FILTERS, bands_per_octave=True):\n        # pylint: disable=arguments-differ\n        # decide whether num_bands is bands per octave or total number of bands\n        if bands_per_octave:\n            num_bands_per_octave = num_bands\n            # get a list of frequencies with logarithmic scaling\n            frequencies = log_frequencies(num_bands, fmin, fmax, fref)\n            # convert to bins\n            bins = frequencies2bins(frequencies, bin_frequencies,\n                                    unique_bins=unique_filters)\n        else:\n            # iteratively get the number of bands\n            raise NotImplementedError(""please implement `num_bands` with ""\n                                      ""`bands_per_octave` set to \'False\' for ""\n                                      ""LogarithmicFilterbank"")\n        # get overlapping triangular filters\n        filters = TriangularFilter.filters(bins, norm=norm_filters,\n                                           overlap=True)\n        # create a LogarithmicFilterbank from the filters\n        obj = cls.from_filters(filters, bin_frequencies)\n        # set additional attributes\n        obj.fref = fref\n        obj.num_bands_per_octave = num_bands_per_octave\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here\n        self.num_bands_per_octave = getattr(obj, \'num_bands_per_octave\',\n                                            self.NUM_BANDS_PER_OCTAVE)\n        self.fref = getattr(obj, \'fref\', A4)\n\n\n# alias\nLogFilterbank = LogarithmicFilterbank\n\n\nclass RectangularFilterbank(Filterbank):\n    """"""\n    Rectangular filterbank class.\n\n    Parameters\n    ----------\n    bin_frequencies : numpy array\n        Frequencies of the bins [Hz].\n    crossover_frequencies : list or numpy array\n        Crossover frequencies of the bands [Hz].\n    fmin : float, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filters to area 1.\n    unique_filters : bool, optional\n        Keep only unique filters, i.e. remove duplicate filters resulting\n        from insufficient resolution at low frequencies.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, bin_frequencies, crossover_frequencies, fmin=FMIN,\n                 fmax=FMAX, norm_filters=NORM_FILTERS,\n                 unique_filters=UNIQUE_FILTERS):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, bin_frequencies, crossover_frequencies, fmin=FMIN,\n                fmax=FMAX, norm_filters=NORM_FILTERS,\n                unique_filters=UNIQUE_FILTERS):\n        # pylint: disable=arguments-differ\n        # create an empty filterbank\n        fb = np.zeros((len(bin_frequencies), len(crossover_frequencies) + 1),\n                      dtype=FILTER_DTYPE)\n        corner_frequencies = np.r_[fmin, crossover_frequencies, fmax]\n        # get the corner bins\n        corner_bins = frequencies2bins(corner_frequencies, bin_frequencies,\n                                       unique_bins=unique_filters)\n        # map the bins to the filterbank bands\n        for i in range(len(corner_bins) - 1):\n            fb[corner_bins[i]:corner_bins[i + 1], i] = 1\n        # normalize the filterbank\n        if norm_filters:\n            # if the sum over a band is zero, do not normalize this band\n            band_sum = np.sum(fb, axis=0)\n            band_sum[band_sum == 0] = 1\n            fb /= band_sum\n        # create Filterbank and cast as RectangularFilterbank\n        obj = Filterbank.__new__(cls, fb, bin_frequencies)\n        # set additional attributes\n        obj.crossover_frequencies = bins2frequencies(corner_bins[1:-1],\n                                                     bin_frequencies)\n        # return the object\n        return obj\n\n\n# chroma / harmonic filterbanks\nclass SimpleChromaFilterbank(Filterbank):\n    """"""\n    A simple chroma filterbank based on a (semitone) filterbank.\n\n    Parameters\n    ----------\n    bin_frequencies : numpy array\n        Frequencies of the bins [Hz].\n    num_bands : int, optional\n        Number of filter bands per octave.\n    fmin : float, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    fref : float, optional\n        Tuning frequency of the filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filters to area 1.\n    unique_filters : bool, optional\n        Keep only unique filters, i.e. remove duplicate filters resulting\n        from insufficient resolution at low frequencies.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    NUM_BANDS = 12\n\n    def __init__(self, bin_frequencies, num_bands=NUM_BANDS, fmin=FMIN,\n                 fmax=FMAX, fref=A4, norm_filters=NORM_FILTERS,\n                 unique_filters=UNIQUE_FILTERS):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, bin_frequencies, num_bands=NUM_BANDS, fmin=FMIN,\n                fmax=FMAX, fref=A4, norm_filters=NORM_FILTERS,\n                unique_filters=UNIQUE_FILTERS):\n        # pylint: disable=arguments-differ\n        raise NotImplementedError(""please check if produces correct/expected ""\n                                  ""results and enable if yes."")\n        # TODO: add comments!\n        stf = LogFilterbank(bin_frequencies, num_bands=num_bands, fmin=fmin,\n                            fmax=fmax, fref=fref, norm_filters=norm_filters,\n                            unique_filters=unique_filters)\n        # create an empty filterbank\n        fb = np.empty((stf.shape[0], 12))\n        spacing = np.arange(8) * 12\n        for i in range(12):\n            cur_spacing = spacing + i\n            cur_spacing = cur_spacing[cur_spacing < stf.shape[1]]\n            fb[:, i] = stf[:, cur_spacing].sum(1)\n        # TODO: check if this should depend on the norm_filters parameter\n        fb /= fb.sum(0)\n        # cast to Filterbank\n        obj = Filterbank.__new__(cls, fb, bin_frequencies)\n        # set additional attributes\n        obj.fref = fref\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here\n        self.fref = getattr(obj, \'fref\', A4)\n\n\nclass HarmonicFilterbank(Filterbank):\n    """"""\n    Harmonic filterbank class.\n\n    """"""\n    # Note: old code: https://jobim.ofai.at/gitlab/madmom/madmom/snippets/1\n    # pylint: disable=no-init\n\n    def __new__(cls):\n        # pylint: disable=arguments-differ\n        raise NotImplementedError(\'please implement if needed!\')\n\n\nclass PitchClassProfileFilterbank(Filterbank):\n    """"""\n    Filterbank for extracting pitch class profiles (PCP).\n\n    Parameters\n    ----------\n    bin_frequencies : numpy array\n        Frequencies of the bins [Hz].\n    num_classes : int, optional\n        Number of pitch classes.\n    fmin : float, optional\n        Minimum frequency [Hz].\n    fmax : float, optional\n        Maximum frequency [Hz].\n    fref : float, optional\n        Reference frequency for the first PCP bin [Hz].\n\n    References\n    ----------\n    .. [1] T. Fujishima,\n           ""Realtime chord recognition of musical sound: a system using Common\n           Lisp Music"",\n           Proceedings of the International Computer Music Conference (ICMC),\n           1999.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    CLASSES = 12\n    FMIN = 100.\n    FMAX = 5000.\n\n    def __init__(self, bin_frequencies, num_classes=CLASSES, fmin=FMIN,\n                 fmax=FMAX, fref=A4):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, bin_frequencies, num_classes=CLASSES, fmin=FMIN,\n                fmax=FMAX, fref=A4):\n        # pylint: disable=arguments-differ\n\n        # init a filterbank\n        fb = np.zeros((len(bin_frequencies), num_classes))\n        # use only positive bin frequencies\n        pos_bin_frequencies = bin_frequencies > 0\n        # log deviation from the reference frequency\n        log_dev = np.log2(bin_frequencies[pos_bin_frequencies] / fref)\n        # map the log deviation to the closest pitch class profiles\n        num_class = np.round(num_classes * log_dev) % num_classes\n        # define the pitch class profile filterbank, skip all bins which were 0\n        fb[pos_bin_frequencies, num_class.astype(int)] = 1\n        # set all bins outside the allowed frequency range to 0\n        fb[np.searchsorted(bin_frequencies, fmax, \'right\'):] = 0\n        fb[:np.searchsorted(bin_frequencies, fmin)] = 0\n        # cast to Filterbank\n        obj = Filterbank.__new__(cls, fb, bin_frequencies)\n        # set additional attributes\n        obj.fref = fref\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here\n        self.fref = getattr(obj, \'fref\', A4)\n\n    @property\n    def corner_frequencies(self):\n        # TODO: property should return multiple corner frequencies\n        raise NotImplementedError(\'please implement if needed\')\n\n    @property\n    def center_frequencies(self):\n        # TODO: property should return multiple center frequencies\n        raise NotImplementedError(\'please implement if needed\')\n\n\nclass HarmonicPitchClassProfileFilterbank(PitchClassProfileFilterbank):\n    """"""\n    Filterbank for extracting harmonic pitch class profiles (HPCP).\n\n    Parameters\n    ----------\n    bin_frequencies : numpy array\n        Frequencies of the bins [Hz].\n    num_classes : int, optional\n        Number of pitch classes.\n    fmin : float, optional\n        Minimum frequency [Hz].\n    fmax : float, optional\n        Maximum frequency [Hz].\n    fref : float, optional\n        Reference frequency for the first HPCP bin [Hz].\n    window : int, optional\n        Length of the weighting window [bins].\n\n    References\n    ----------\n    .. [1] Emilia G\xc3\xb3mez,\n           ""Tonal Description of Music Audio Signals"",\n           PhD thesis, Universitat Pompeu Fabra, Barcelona, Spain, 2006.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    CLASSES = 36\n    FMIN = 100.\n    FMAX = 5000.\n    WINDOW = 4\n\n    def __init__(self, bin_frequencies, num_classes=CLASSES, fmin=FMIN,\n                 fmax=FMAX, fref=A4, window=WINDOW):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, bin_frequencies, num_classes=CLASSES, fmin=FMIN,\n                fmax=FMAX, fref=A4, window=WINDOW):\n        # pylint: disable=arguments-differ\n        # init a filterbank\n        fb = np.zeros((len(bin_frequencies), num_classes))\n        # use only positive bin frequencies\n        pos_bin_frequencies = np.nonzero(bin_frequencies > 0)[0]\n        # log deviation from the reference frequency\n        log_dev = np.log2(bin_frequencies[pos_bin_frequencies] / fref)\n        # map the log deviation to pitch class profiles\n        num_class = (num_classes * log_dev) % num_classes\n        # weight the bins\n        for c in range(num_classes):\n            # calculate the distance of the bins to the current class\n            distance = num_class - c\n            # unwrap\n            distance[distance < -num_classes / 2.] += num_classes\n            distance[distance > num_classes / 2.] -= num_classes\n            # get all bins which are within the defined window\n            idx = np.abs(distance) < window / 2.\n            # apply the weighting function\n            filt = np.cos((num_class[idx] - c) * np.pi / window) ** 2.\n            # map these indices to the positive bin frequencies\n            fb[pos_bin_frequencies[idx], c] = filt\n        # set all bins outside the allowed frequency range to 0\n        fb[np.searchsorted(bin_frequencies, fmax, \'right\'):] = 0\n        fb[:np.searchsorted(bin_frequencies, fmin)] = 0\n        # cast to Filterbank\n        obj = Filterbank.__new__(cls, fb, bin_frequencies)\n        # set additional attributes\n        obj.fref = fref\n        obj.window = window\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here\n        self.fref = getattr(obj, \'fref\', A4)\n        self.window = getattr(obj, \'window\', self.WINDOW)\n\n\nclass SemitoneBandpassFilterbank(object):\n    """"""\n    Time domain semitone filterbank of elliptic filters as proposed in [1]_.\n\n    Parameters\n    ----------\n    order : int, optional\n        Order of elliptic filters.\n    passband_ripple : float, optional\n        Maximum ripple allowed below unity gain in the passband [dB].\n    stopband_rejection : float, optional\n        Minimum attenuation required in the stop band [dB].\n    q_factor : int, optional\n        Q-factor of the filters.\n    fmin : float, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    fref : float, optional\n        Reference frequency for the first bandpass filter [Hz].\n\n    References\n    ----------\n    .. [1] Meinard M\xc3\xbcller,\n           ""Information retrieval for music and motion"", Springer, 2007.\n\n    Notes\n    -----\n    This is a time domain filterbank, thus it cannot be used as the other\n    time-frequency filterbanks of this module. Instead of ``np.dot()`` use\n    ``scipy.signal.filtfilt()`` to filter a signal.\n\n    """"""\n\n    def __init__(self, order=4, passband_ripple=1, stopband_rejection=50,\n                 q_factor=25, fmin=27.5, fmax=4200., fref=A4):\n        from scipy.signal import ellip\n        self.order = order\n        self.passband_ripple = passband_ripple\n        self.stopband_rejection = stopband_rejection\n        self.q_factor = q_factor\n        self.fref = fref\n        self.center_frequencies = semitone_frequencies(fmin, fmax, fref=fref)\n        # use different sample rates for the individual bands\n        self.band_sample_rates = np.ones_like(self.center_frequencies) * 4410\n        self.band_sample_rates[self.center_frequencies > 2000] = 22050\n        self.band_sample_rates[self.center_frequencies < 250] = 882\n        self.filters = []\n        for freq, sample_rate in zip(self.center_frequencies,\n                                     self.band_sample_rates):\n            freqs = [(freq - freq / q_factor / 2.) * 2. / sample_rate,\n                     (freq + freq / q_factor / 2.) * 2. / sample_rate]\n            self.filters.append(ellip(order, passband_ripple,\n                                      stopband_rejection, freqs,\n                                      btype=\'bandpass\'))\n\n    @property\n    def num_bands(self):\n        """"""Number of bands.""""""\n        return len(self.center_frequencies)\n\n    @property\n    def fmin(self):\n        """"""Minimum frequency of the filterbank.""""""\n        f = self.center_frequencies[0]\n        return f - f / self.q_factor / 2.\n\n    @property\n    def fmax(self):\n        """"""Maximum frequency of the filterbank.""""""\n        f = self.center_frequencies[-1]\n        return f + f / self.q_factor / 2.\n'"
madmom/audio/hpss.py,3,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains all harmonic/percussive source separation functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\nfrom madmom.processors import Processor\n\n# TODO: keep this as Processors or should it be done as np.ndarray classes?\n\n\nclass HarmonicPercussiveSourceSeparation(Processor):\n    """"""\n    HarmonicPercussiveSourceSeparation is a Processor which separates the\n    magnitude spectrogram into its harmonic and percussive components with\n    median filters.\n\n    Parameters\n    ----------\n    masking : float or str\n        Can be either the literal \'binary\' or any float coefficient resulting\n        in a soft mask. \'None\' translates to a binary mask, too.\n    harmonic_filter : tuple of ints\n        Tuple with harmonic filter size (frames, bins).\n    percussive_filter : tuple of ints\n        Tuple with percussive filter size (frames, bins).\n\n    References\n    ----------\n    .. [1] Derry FitzGerald,\n           ""Harmonic/percussive separation using median filtering."",\n           Proceedings of the 13th International Conference on Digital Audio\n           Effects (DAFx), Graz, Austria, 2010.\n\n    """"""\n    MASKING = \'binary\'\n    HARMONIC_FILTER = (15, 1)\n    PERCUSSIVE_FILTER = (1, 15)\n\n    def __init__(self, masking=MASKING, harmonic_filter=HARMONIC_FILTER,\n                 percussive_filter=PERCUSSIVE_FILTER):\n        # set the parameters, so they get used for computation\n        self.masking = masking\n        self.harmonic_filter = np.asarray(harmonic_filter, dtype=int)\n        self.percussive_filter = np.asarray(percussive_filter, dtype=int)\n\n    def slices(self, data):\n        """"""\n        Returns the harmonic and percussive slices of the data.\n\n        Parameters\n        ----------\n        data : numpy array\n            Data to be sliced (usually a magnitude spectrogram).\n\n        Returns\n        -------\n        harmonic_slice : numpy array\n            Harmonic slice.\n        percussive_slice : numpy array\n            Percussive slice.\n\n        """"""\n        from scipy.ndimage.filters import median_filter\n        # compute the harmonic and percussive slices\n        harmonic_slice = median_filter(data, self.harmonic_filter)\n        percussive_slice = median_filter(data, self.percussive_filter)\n        # return the slices\n        return harmonic_slice, percussive_slice\n\n    def masks(self, harmonic_slice, percussive_slice):\n        """"""\n        Returns the masks given the harmonic and percussive slices.\n\n        Parameters\n        ----------\n        harmonic_slice : numpy array\n            Harmonic slice.\n        percussive_slice : numpy array\n            Percussive slice.\n\n        Returns\n        -------\n        harmonic_mask : numpy array\n            Harmonic mask.\n        percussive_mask : numpy array\n            Percussive mask.\n\n        """"""\n        # compute the masks\n        if self.masking in (None, \'binary\'):\n            # return binary masks\n            harmonic_mask = harmonic_slice > percussive_slice\n            percussive_mask = percussive_slice >= harmonic_slice\n        else:\n            # return soft masks\n            p = float(self.masking)\n            harmonic_slice_ = harmonic_slice ** p\n            percussive_slice_ = percussive_slice ** p\n            slice_sum_ = harmonic_slice_ + percussive_slice_\n            harmonic_mask = harmonic_slice_ / slice_sum_\n            percussive_mask = percussive_slice_ / slice_sum_\n        # return the masks\n        return harmonic_mask, percussive_mask\n\n    def process(self, data):\n        """"""\n        Returns the harmonic and percussive components of the given data.\n\n        Parameters\n        ----------\n        data : numpy array\n            Data to be split into harmonic and percussive components.\n\n        Returns\n        -------\n        harmonic components : numpy array\n            Harmonic components.\n        percussive components : numpy array\n            Percussive components.\n\n        """"""\n        from .spectrogram import Spectrogram\n        # data must be in the right format\n        if isinstance(data, Spectrogram):\n            # use the magnitude spectrogram of the Spectrogram\n            spectrogram = data.spec\n        # compute the harmonic and percussive slices\n        slices = self.slices(spectrogram)\n        # compute the corresponding masks\n        harmonic_mask, percussive_mask = self.masks(*slices)\n        # filter the data\n        harmonic = spectrogram * harmonic_mask\n        percussive = spectrogram * percussive_mask\n        # and return it\n        return harmonic, percussive\n\n    @staticmethod\n    def add_arguments(parser, masking=None, harmonic_filter=None,\n                      percussive_filter=None):\n        """"""\n        Add harmonic/percussive source separation related arguments to an\n        existing parser object.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        masking : float, optional\n            Masking; if \'None\', binary masking is used.\n        harmonic_filter : tuple, optional\n            Harmonic filter (frames, bins).\n        percussive_filter : tuple, optional\n            Percussive filter (frames, bins).\n\n        Returns\n        -------\n        argparse argument group\n            Harmonic/percussive source separation argument parser group.\n\n        Notes\n        -----\n        Parameters are included in the group only if they are not \'None\'.\n\n        """"""\n        # add harmonic/percussive related options to the existing parser\n        g = parser.add_argument_group(\'harmonic/percussive source separation \'\n                                      \'related arguments\')\n        if masking is not None:\n            g.add_argument(\'--filter_type\', action=\'store\', type=float,\n                           default=masking,\n                           help=\'masking coefficient [default=%(default).2f]\')\n        if harmonic_filter is not None:\n            g.add_argument(\'--harmonic_filter\', action=\'store\',\n                           default=harmonic_filter,\n                           help=\'harmonic filter size (frames, bins) \'\n                                \'[default=%(default)s]\')\n        if percussive_filter is not None:\n            g.add_argument(\'--percussive_filter\', action=\'store\',\n                           default=percussive_filter,\n                           help=\'percussive filter size (frames, bins) \'\n                                \'[default=%(default)s]\')\n        # return the argument group so it can be modified if needed\n        return g\n\n\n# alias\nHPSS = HarmonicPercussiveSourceSeparation\n'"
madmom/audio/signal.py,57,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains basic signal processing functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport warnings\nimport numpy as np\n\nfrom ..processors import BufferProcessor, Processor\nfrom ..utils import integer_types\n\n\n# signal functions\ndef smooth(signal, kernel):\n    """"""\n    Smooth the signal along its first axis.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal to be smoothed.\n    kernel : numpy array or int\n        Smoothing kernel (size).\n\n    Returns\n    -------\n    numpy array\n        Smoothed signal.\n\n    Notes\n    -----\n    If `kernel` is an integer, a Hamming window of that length will be used\n    as a smoothing kernel.\n\n    """"""\n    # check if a kernel is given\n    if kernel is None:\n        return signal\n    # size for the smoothing kernel is given\n    elif isinstance(kernel, integer_types):\n        if kernel == 0:\n            return signal\n        elif kernel > 1:\n            # use a Hamming window of given length\n            kernel = np.hamming(kernel)\n        else:\n            raise ValueError(""can\'t create a smoothing kernel of size %d"" %\n                             kernel)\n    # otherwise use the given smoothing kernel directly\n    elif isinstance(kernel, np.ndarray):\n        kernel = kernel\n    else:\n        raise ValueError(""can\'t smooth signal with %s"" % kernel)\n    # convolve with the kernel and return\n    if signal.ndim == 1:\n        return np.convolve(signal, kernel, \'same\')\n    elif signal.ndim == 2:\n        from scipy.signal import convolve2d\n        return convolve2d(signal, kernel[:, np.newaxis], \'same\')\n    else:\n        raise ValueError(\'signal must be either 1D or 2D\')\n\n\ndef adjust_gain(signal, gain):\n    """"""""\n    Adjust the gain of the signal.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal to be adjusted.\n    gain : float\n        Gain adjustment level [dB].\n\n    Returns\n    -------\n    numpy array\n        Signal with adjusted gain.\n\n    Notes\n    -----\n    The signal is returned with the same dtype, thus rounding errors may occur\n    with integer dtypes.\n\n    `gain` values > 0 amplify the signal and are only supported for signals\n    with float dtype to prevent clipping and integer overflows.\n\n    """"""\n    # convert the gain in dB to a scaling factor\n    gain = np.power(np.sqrt(10.), 0.1 * gain)\n    # prevent overflow and clipping\n    if gain > 1 and np.issubdtype(signal.dtype, np.integer):\n        raise ValueError(\'positive gain adjustments are only supported for \'\n                         \'float dtypes.\')\n    # Note: np.asanyarray returns the signal\'s ndarray subclass\n    return np.asanyarray(signal * gain, dtype=signal.dtype)\n\n\ndef attenuate(signal, attenuation):\n    """"""\n    Attenuate the signal.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal to be attenuated.\n    attenuation :  float\n        Attenuation level [dB].\n\n    Returns\n    -------\n    numpy array\n        Attenuated signal (same dtype as `signal`).\n\n    Notes\n    -----\n    The signal is returned with the same dtype, thus rounding errors may occur\n    with integer dtypes.\n\n    """"""\n    # return the signal unaltered if no attenuation is given\n    if attenuation == 0:\n        return signal\n    return adjust_gain(signal, -attenuation)\n\n\ndef normalize(signal):\n    """"""\n    Normalize the signal to have maximum amplitude.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal to be normalized.\n\n    Returns\n    -------\n    numpy array\n        Normalized signal.\n\n    Notes\n    -----\n    Signals with float dtypes cover the range [-1, +1], signals with integer\n    dtypes will cover the maximally possible range, e.g. [-32768, 32767] for\n    np.int16.\n\n    The signal is returned with the same dtype, thus rounding errors may occur\n    with integer dtypes.\n\n    """"""\n    # scaling factor to be applied\n    scaling = float(np.max(np.abs(signal)))\n    if np.issubdtype(signal.dtype, np.integer):\n        if signal.dtype in (np.int16, np.int32):\n            scaling /= np.iinfo(signal.dtype).max\n        else:\n            raise ValueError(\'only float and np.int16/32 dtypes supported, \'\n                             \'not %s.\' % signal.dtype)\n    # Note: np.asanyarray returns the signal\'s ndarray subclass\n    return np.asanyarray(signal / scaling, dtype=signal.dtype)\n\n\ndef remix(signal, num_channels, channel=None):\n    """"""\n    Remix the signal to have the desired number of channels.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal to be remixed.\n    num_channels : int\n        Number of channels.\n    channel : int, optional\n        When reducing a signal to `num_channels` of 1, use this channel,\n        or \'None\' to return the average across all channels.\n\n    Returns\n    -------\n    numpy array\n        Remixed signal (same dtype as `signal`).\n\n    Notes\n    -----\n    This function does not support arbitrary channel number conversions.\n    Only down-mixing to and up-mixing from mono signals is supported.\n\n    The signal is returned with the same dtype, thus rounding errors may occur\n    with integer dtypes.\n\n    If the signal should be down-mixed to mono and has an integer dtype, it\n    will be converted to float internally and then back to the original dtype\n    to prevent clipping of the signal. To avoid this double conversion,\n    convert the dtype first.\n\n    """"""\n    if num_channels == signal.ndim or num_channels is None:\n        # return as many channels as there are.\n        return signal\n    elif num_channels == 1 and signal.ndim > 1:\n        if channel is None:\n            # down-mix to mono\n            # Note: to prevent clipping, the signal is converted to float first\n            #       and then converted back to the original dtype\n            # TODO: add weighted mixing\n            return np.mean(signal, axis=-1).astype(signal.dtype)\n        else:\n            # Use the requested channel verbatim\n            return signal[:, channel]\n    elif num_channels > 1 and signal.ndim == 1:\n        # up-mix a mono signal simply by copying channels\n        return np.tile(signal[:, np.newaxis], num_channels)\n    else:\n        # any other channel conversion is not supported\n        raise NotImplementedError(""Requested %d channels, but got %d channels ""\n                                  ""and channel conversion is not implemented.""\n                                  % (num_channels, signal.shape[1]))\n\n\ndef resample(signal, sample_rate, **kwargs):\n    """"""\n    Resample the signal.\n\n    Parameters\n    ----------\n    signal : numpy array or Signal\n        Signal to be resampled.\n    sample_rate : int\n        Sample rate of the signal.\n    kwargs : dict, optional\n        Keyword arguments passed to :func:`load_ffmpeg_file`.\n\n    Returns\n    -------\n    numpy array or Signal\n        Resampled signal.\n\n    Notes\n    -----\n    This function uses ``ffmpeg`` to resample the signal.\n\n    """"""\n    from ..io.audio import load_ffmpeg_file\n    # is the given signal a Signal?\n    if not isinstance(signal, Signal):\n        raise ValueError(\'only Signals can resampled, not %s\' % type(signal))\n    if signal.sample_rate == sample_rate:\n        return signal\n    # per default use the signal\'s dtype and num_channels\n    dtype = kwargs.get(\'dtype\', signal.dtype)\n    num_channels = kwargs.get(\'num_channels\', signal.num_channels)\n    # resample the signal\n    signal, sample_rate = load_ffmpeg_file(signal, sample_rate=sample_rate,\n                                           num_channels=num_channels,\n                                           dtype=dtype)\n    # return it\n    return Signal(signal, sample_rate=sample_rate)\n\n\ndef rescale(signal, dtype=np.float32):\n    """"""\n    Rescale the signal to range [-1, 1] and return as float dtype.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal to be remixed.\n    dtype : numpy dtype\n        Data type of the signal.\n\n    Returns\n    -------\n    numpy array\n        Signal rescaled to range [-1, 1].\n\n    """"""\n    # allow only float dtypes\n    if not np.issubdtype(dtype, np.floating):\n        raise ValueError(\'only float dtypes are supported, not %s.\' % dtype)\n    # float signals don\'t need rescaling\n    if np.issubdtype(signal.dtype, np.floating):\n        return signal.astype(dtype)\n    elif np.issubdtype(signal.dtype, np.integer):\n        return signal.astype(dtype) / np.iinfo(signal.dtype).max\n    else:\n        raise ValueError(\'unsupported signal dtype: %s.\' % signal.dtype)\n\n\ndef trim(signal, where=\'fb\'):\n    """"""\n    Trim leading and trailing zeros of the signal.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal to be trimmed.\n    where : str, optional\n        A string with \'f\' representing trim from front and \'b\' to trim from\n        back. Default is \'fb\', trim zeros from both ends of the signal.\n\n    Returns\n    -------\n    numpy array\n        Trimmed signal.\n\n    """"""\n    # code borrowed from np.trim_zeros()\n    first = 0\n    where = where.upper()\n    if \'F\' in where:\n        for i in signal:\n            if np.sum(i) != 0.:\n                break\n            else:\n                first += 1\n    last = len(signal)\n    if \'B\' in where:\n        for i in signal[::-1]:\n            if np.sum(i) != 0.:\n                break\n            else:\n                last -= 1\n    return signal[first:last]\n\n\ndef energy(signal):\n    """"""\n    Compute the energy of a (framed) signal.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal.\n\n    Returns\n    -------\n    energy : float\n        Energy of the signal.\n\n    Notes\n    -----\n    If `signal` is a `FramedSignal`, the energy is computed for each frame\n    individually.\n\n    """"""\n    # compute the energy for every frame of the signal\n    if isinstance(signal, FramedSignal):\n        return np.array([energy(frame) for frame in signal])\n    # make sure the signal is a numpy array\n    if not isinstance(signal, np.ndarray):\n        raise TypeError(""Invalid type for signal, must be a numpy array."")\n    # take the abs if the signal is complex\n    if np.iscomplex(signal).any():\n        signal = np.abs(signal)\n    # Note: type conversion needed because of integer overflows\n    if signal.dtype != np.float:\n        signal = signal.astype(np.float)\n    # return energy\n    return np.dot(signal.flatten(), signal.flatten())\n\n\ndef root_mean_square(signal):\n    """"""\n    Compute the root mean square of a (framed) signal. This can be used as a\n    measurement of power.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal.\n\n    Returns\n    -------\n    rms : float\n        Root mean square of the signal.\n\n    Notes\n    -----\n    If `signal` is a `FramedSignal`, the root mean square is computed for each\n    frame individually.\n\n    """"""\n    # compute the root mean square for every frame of the signal\n    if isinstance(signal, FramedSignal):\n        return np.array([root_mean_square(frame) for frame in signal])\n    return np.sqrt(energy(signal) / signal.size)\n\n\ndef sound_pressure_level(signal, p_ref=None):\n    """"""\n    Compute the sound pressure level of a (framed) signal.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal.\n    p_ref : float, optional\n        Reference sound pressure level; if \'None\', take the max amplitude\n        value for the data-type, if the data-type is float, assume amplitudes\n        are between -1 and +1.\n\n    Returns\n    -------\n    spl : float\n        Sound pressure level of the signal [dB].\n\n    Notes\n    -----\n    From http://en.wikipedia.org/wiki/Sound_pressure: Sound pressure level\n    (SPL) or sound level is a logarithmic measure of the effective sound\n    pressure of a sound relative to a reference value. It is measured in\n    decibels (dB) above a standard reference level.\n\n    If `signal` is a `FramedSignal`, the sound pressure level is computed for\n    each frame individually.\n\n    """"""\n    # compute the sound pressure level for every frame of the signal\n    if isinstance(signal, FramedSignal):\n        return np.array([sound_pressure_level(frame) for frame in signal])\n    # compute the RMS\n    rms = root_mean_square(signal)\n    # find a reasonable default reference value if None is given\n    if p_ref is None:\n        if np.issubdtype(signal.dtype, np.integer):\n            p_ref = float(np.iinfo(signal.dtype).max)\n        else:\n            p_ref = 1.0\n    # normal SPL computation. ignore warnings when taking the log of 0,\n    # then replace the resulting -inf values with the smallest finite number\n    with np.errstate(divide=\'ignore\'):\n        return np.nan_to_num(20.0 * np.log10(rms / p_ref))\n\n\n# functions to load / write audio files\nclass LoadAudioFileError(Exception):\n    """"""\n    Deprecated as of version 0.16. Please use\n    madmom.io.audio.LoadAudioFileError instead. Will be removed in version\n    0.18.\n\n    """"""\n    # pylint: disable=super-init-not-called\n\n    def __init__(self, value=None):\n        warnings.warn(LoadAudioFileError.__doc__)\n        if value is None:\n            value = \'Could not load audio file.\'\n        self.value = value\n\n\ndef load_wave_file(*args, **kwargs):\n    """"""\n    Deprecated as of version 0.16. Please use madmom.io.audio.load_wave_file\n    instead. Will be removed in version 0.18.\n\n    """"""\n    warnings.warn(\'Deprecated as of version 0.16. Please use madmom.io.audio.\'\n                  \'load_wave_file instead. Will be removed in version 0.18.\')\n    from ..io.audio import load_wave_file\n    return load_wave_file(*args, **kwargs)\n\n\ndef write_wave_file(*args, **kwargs):\n    """"""\n    Deprecated as of version 0.16. Please use madmom.io.audio.write_wave_file\n    instead. Will be removed in version 0.18.\n\n    """"""\n    warnings.warn(\'Deprecated as of version 0.16. Please use madmom.io.audio.\'\n                  \'write_wave_file instead. Will be removed in version 0.18.\')\n    from ..io.audio import write_wave_file\n    return write_wave_file(*args, **kwargs)\n\n\n# function for automatically determining how to open audio files\ndef load_audio_file(*args, **kwargs):\n    """"""\n    Deprecated as of version 0.16. Please use madmom.io.audio.load_audio_file\n    instead. Will be removed in version 0.18.\n\n    """"""\n    warnings.warn(\'Deprecated as of version 0.16. Please use madmom.io.audio.\'\n                  \'load_audio_file instead. Will be removed in version 0.18.\')\n    from ..io.audio import load_audio_file\n    return load_audio_file(*args, **kwargs)\n\n\n# signal classes\nSAMPLE_RATE = None\nNUM_CHANNELS = None\nCHANNEL = None\nSTART = None\nSTOP = None\nNORM = False\nGAIN = 0.\nDTYPE = None\n\n\nclass Signal(np.ndarray):\n    """"""\n    The :class:`Signal` class represents a signal as a (memory-mapped) numpy\n    array and enhances it with a number of attributes.\n\n    Parameters\n    ----------\n    data : numpy array, str or file handle\n        Signal data or file name or file handle.\n    sample_rate : int, optional\n        Desired sample rate of the signal [Hz], or \'None\' to return the\n        signal in its original rate.\n    num_channels : int, optional\n        Reduce or expand the signal to `num_channels` channels, or \'None\'\n        to return the signal with its original channels.\n    channel : int, optional\n        When reducing a signal to `num_channels` of 1, use this channel,\n        or \'None\' to return the average across all channels.\n    start : float, optional\n        Start position [seconds].\n    stop : float, optional\n        Stop position [seconds].\n    norm : bool, optional\n        Normalize the signal to maximum range of the data type.\n    gain : float, optional\n        Adjust the gain of the signal [dB].\n    dtype : numpy data type, optional\n        The data is returned with the given dtype. If \'None\', it is returned\n        with its original dtype, otherwise the signal gets rescaled. Integer\n        dtypes use the complete value range, float dtypes the range [-1, +1].\n\n    Notes\n    -----\n    `sample_rate` or `num_channels` can be used to set the desired sample rate\n    and number of channels if the audio is read from file. If set to \'None\'\n    the audio signal is used as is, i.e. the sample rate and number of channels\n    are determined directly from the audio file.\n\n    If the `data` is a numpy array, the `sample_rate` is set to the given value\n    and `num_channels` is set to the number of columns of the array.\n\n    The `gain` can be used to adjust the level of the signal.\n\n    If both `norm` and `gain` are set, the signal is first normalized and then\n    the gain is applied afterwards.\n\n    If `norm` or `gain` is set, the selected part of the signal is loaded into\n    memory completely, i.e. .wav files are not memory-mapped any more.\n\n    Examples\n    --------\n    Load a mono audio file:\n\n    >>> sig = Signal(\'tests/data/audio/sample.wav\')\n    >>> sig\n    Signal([-2494, -2510, ...,   655,   639], dtype=int16)\n    >>> sig.sample_rate\n    44100\n\n    Load a stereo audio file, down-mix it to mono:\n\n    >>> sig = Signal(\'tests/data/audio/stereo_sample.flac\', num_channels=1)\n    >>> sig\n    Signal([ 36,  36, ..., 524, 495], dtype=int16)\n    >>> sig.num_channels\n    1\n\n    Load and re-sample an audio file:\n\n    >>> sig = Signal(\'tests/data/audio/sample.wav\', sample_rate=22050)\n    >>> sig\n    Signal([-2470, -2553, ...,   517,   677], dtype=int16)\n    >>> sig.sample_rate\n    22050\n\n    Load an audio file with `float32` data type (i.e. rescale it to [-1, 1]):\n\n    >>> sig = Signal(\'tests/data/audio/sample.wav\', dtype=np.float32)\n    >>> sig\n    Signal([-0.07611, -0.0766 , ...,  0.01999,  0.0195 ], dtype=float32)\n    >>> sig.dtype\n    dtype(\'float32\')\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, data, sample_rate=SAMPLE_RATE,\n                 num_channels=NUM_CHANNELS, channel=CHANNEL, start=START,\n                 stop=STOP, norm=NORM, gain=GAIN, dtype=DTYPE, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, data, sample_rate=SAMPLE_RATE, num_channels=NUM_CHANNELS,\n                channel=CHANNEL, start=START, stop=STOP, norm=NORM, gain=GAIN,\n                dtype=DTYPE, **kwargs):\n        from ..io.audio import load_audio_file\n        # try to load an audio file if the data is not a numpy array\n        if not isinstance(data, np.ndarray):\n            data, sample_rate = load_audio_file(data, sample_rate=sample_rate,\n                                                num_channels=num_channels,\n                                                start=start, stop=stop,\n                                                dtype=dtype)\n        # cast as Signal if needed\n        if not isinstance(data, Signal):\n            data = np.asarray(data).view(cls)\n            data.sample_rate = sample_rate\n        # remix to desired number of channels\n        if num_channels:\n            data = remix(data, num_channels, channel)\n        # normalize signal if needed\n        if norm:\n            data = normalize(data)\n        # adjust the gain if needed\n        if gain is not None and gain != 0:\n            data = adjust_gain(data, gain)\n        # resample if needed\n        if sample_rate != data.sample_rate:\n            data = resample(data, sample_rate)\n        # save start and stop position\n        if start is not None:\n            # FIXME: start and stop settings are not checked\n            data.start = start\n            data.stop = start + float(len(data)) / sample_rate\n        # return the object\n        return data\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views of the Signal\n        self.sample_rate = getattr(obj, \'sample_rate\', None)\n        self.start = getattr(obj, \'start\', None)\n        self.stop = getattr(obj, \'stop\', None)\n\n    def __reduce__(self):\n        # Get the parent\'s __reduce__ tuple\n        state = super(Signal, self).__reduce__()\n        # Create our own tuple to pass to __setstate__, but append the\n        # __dict__ rather than individual members\n        new_state = state[2] + (self.__dict__,)\n        # Return a tuple that replaces the parent\'s __setstate__ tuple with\n        # our own\n        return state[0], state[1], new_state\n\n    def __setstate__(self, state):\n        # Update the internal dict from state\n        self.__dict__.update(state[-1])\n        # Call the parent\'s __setstate__ with the other tuple elements\n        super(Signal, self).__setstate__(state[:-1])\n\n    @property\n    def num_samples(self):\n        """"""Number of samples.""""""\n        return len(self)\n\n    @property\n    def num_channels(self):\n        """"""Number of channels.""""""\n        # mono file\n        if self.ndim == 1:\n            return 1\n        # multi channel file\n        return np.shape(self)[1]\n\n    @property\n    def length(self):\n        """"""Length of signal in seconds.""""""\n        # n/a if the signal has no sample rate\n        if self.sample_rate is None:\n            return None\n        return float(self.num_samples) / self.sample_rate\n\n    def write(self, filename):\n        """"""\n        Write the signal to disk as a .wav file.\n\n        Parameters\n        ----------\n        filename : str\n            Name of the file.\n\n        Returns\n        -------\n        filename : str\n            Name of the written file.\n\n        """"""\n        return write_wave_file(self, filename)\n\n    def energy(self):\n        """"""Energy of signal.""""""\n        return energy(self)\n\n    def root_mean_square(self):\n        """"""Root mean square of signal.""""""\n        return root_mean_square(self)\n\n    rms = root_mean_square\n\n    def sound_pressure_level(self):\n        """"""Sound pressure level of signal.""""""\n        return sound_pressure_level(self)\n\n    spl = sound_pressure_level\n\n\nclass SignalProcessor(Processor):\n    """"""\n    The :class:`SignalProcessor` class is a basic signal processor.\n\n    Parameters\n    ----------\n    sample_rate : int, optional\n        Sample rate of the signal [Hz]; if set the signal will be re-sampled\n        to that sample rate; if \'None\' the sample rate of the audio file will\n        be used.\n    num_channels : int, optional\n        Number of channels of the signal; if set, the signal will be reduced\n        to that number of channels; if \'None\' as many channels as present in\n        the audio file are returned.\n    start : float, optional\n        Start position [seconds].\n    stop : float, optional\n        Stop position [seconds].\n    norm : bool, optional\n        Normalize the signal to the range [-1, +1].\n    gain : float, optional\n        Adjust the gain of the signal [dB].\n    dtype : numpy data type, optional\n        The data is returned with the given dtype. If \'None\', it is returned\n        with its original dtype, otherwise the signal gets rescaled. Integer\n        dtypes use the complete value range, float dtypes the range [-1, +1].\n\n    Examples\n    --------\n    Processor for loading the first two seconds of an audio file, re-sampling\n    it to 22.05 kHz and down-mixing it to mono:\n\n    >>> proc = SignalProcessor(sample_rate=22050, num_channels=1, stop=2)\n    >>> sig = proc(\'tests/data/audio/sample.wav\')\n    >>> sig\n    Signal([-2470, -2553, ...,  -173,  -265], dtype=int16)\n    >>> sig.sample_rate\n    22050\n    >>> sig.num_channels\n    1\n    >>> sig.length\n    2.0\n\n    """"""\n\n    def __init__(self, sample_rate=SAMPLE_RATE, num_channels=NUM_CHANNELS,\n                 start=START, stop=STOP, norm=NORM, gain=GAIN, dtype=DTYPE,\n                 **kwargs):\n        # pylint: disable=unused-argument\n        self.sample_rate = sample_rate\n        self.num_channels = num_channels\n        self.start = start\n        self.stop = stop\n        self.norm = norm\n        self.gain = gain\n        self.dtype = dtype\n\n    def process(self, data, **kwargs):\n        """"""\n        Processes the given audio file.\n\n        Parameters\n        ----------\n        data : numpy array, str or file handle\n            Data to be processed.\n        kwargs : dict, optional\n            Keyword arguments passed to :class:`Signal`.\n\n        Returns\n        -------\n        signal : :class:`Signal` instance\n            :class:`Signal` instance.\n\n        """"""\n        # pylint: disable=unused-argument\n        # update arguments passed to FramedSignal\n        args = dict(sample_rate=self.sample_rate,\n                    num_channels=self.num_channels, start=self.start,\n                    stop=self.stop, norm=self.norm, gain=self.gain,\n                    dtype=self.dtype)\n        args.update(kwargs)\n        # instantiate a Signal and return it\n        return Signal(data, **args)\n\n    @staticmethod\n    def add_arguments(parser, sample_rate=None, mono=None, start=None,\n                      stop=None, norm=None, gain=None):\n        """"""\n        Add signal processing related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        sample_rate : int, optional\n            Re-sample the signal to this sample rate [Hz].\n        mono : bool, optional\n            Down-mix the signal to mono.\n        start : float, optional\n            Start position [seconds].\n        stop : float, optional\n            Stop position [seconds].\n        norm : bool, optional\n            Normalize the signal to the range [-1, +1].\n        gain : float, optional\n            Adjust the gain of the signal [dB].\n\n        Returns\n        -------\n        argparse argument group\n            Signal processing argument parser group.\n\n        Notes\n        -----\n        Parameters are included in the group only if they are not \'None\'. To\n        include `start` and `stop` arguments with a default value of \'None\',\n        i.e. do not set any start or stop time, they can be set to \'True\'.\n\n        """"""\n        # add signal processing options to the existing parser\n        g = parser.add_argument_group(\'signal processing arguments\')\n        if sample_rate is not None:\n            g.add_argument(\'--sample_rate\', action=\'store\', type=int,\n                           default=sample_rate, help=\'re-sample the signal to \'\n                                                     \'this sample rate [Hz]\')\n        if mono is not None:\n            g.add_argument(\'--mono\', dest=\'num_channels\', action=\'store_const\',\n                           const=1, help=\'down-mix the signal to mono\')\n        if start is not None:\n            g.add_argument(\'--start\', action=\'store\', type=float,\n                           help=\'start position of the signal [seconds]\')\n        if stop is not None:\n            g.add_argument(\'--stop\', action=\'store\', type=float,\n                           help=\'stop position of the signal [seconds]\')\n        if norm is not None:\n            g.add_argument(\'--norm\', action=\'store_true\', default=norm,\n                           help=\'normalize the signal [default=%(default)s]\')\n        if gain is not None:\n            g.add_argument(\'--gain\', action=\'store\', type=float, default=gain,\n                           help=\'adjust the gain of the signal \'\n                                \'[dB, default=%(default).1f]\')\n        # return the argument group so it can be modified if needed\n        return g\n\n\n# functions for splitting a signal into frames\ndef signal_frame(signal, index, frame_size, hop_size, origin=0, pad=0):\n    """"""\n    This function returns frame at `index` of the `signal`.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal.\n    index : int\n        Index of the frame to return.\n    frame_size : int\n        Size of each frame in samples.\n    hop_size : float\n        Hop size in samples between adjacent frames.\n    origin : int\n        Location of the window center relative to the signal position.\n    pad : int, float or str, optional\n        Pad parts of the frame not covered by the signal with this value.\n        The literal \'repeat\' can be used to indicate that the first/last value\n        should be repeated.\n\n    Returns\n    -------\n    frame : numpy array\n        Requested frame of the signal.\n\n    Notes\n    -----\n    The reference sample of the first frame (index == 0) refers to the first\n    sample of the `signal`, and each following frame is placed `hop_size`\n    samples after the previous one.\n\n    The window is always centered around this reference sample. Its location\n    relative to the reference sample can be set with the `origin` parameter.\n    Arbitrary integer values can be given:\n\n    - zero centers the window on its reference sample\n    - negative values shift the window to the right\n    - positive values shift the window to the left\n\n    An `origin` of half the size of the `frame_size` results in windows located\n    to the left of the reference sample, i.e. the first frame starts at the\n    first sample of the signal.\n\n    The part of the frame which is not covered by the signal is padded with\n    zeros.\n\n    This function is totally independent of the length of the signal. Thus,\n    contrary to common indexing, the index \'-1\' refers NOT to the last frame\n    of the signal, but instead the frame left of the first frame is returned.\n\n    """"""\n    # cast variables to int\n    frame_size = int(frame_size)\n    # length of the signal\n    num_samples = len(signal)\n    # seek to the correct position in the audio signal\n    ref_sample = int(index * hop_size)\n    # position the window\n    start = ref_sample - frame_size // 2 - int(origin)\n    stop = start + frame_size\n    # return the requested portion of the signal\n    # Note: use NumPy\'s advanced indexing (i.e. trailing comma) in order to\n    #       avoid a memory leak (issue #321). This returns a copy of the data,\n    #       however, returning a simple copy of the relevant portion of the\n    #       signal also leaks memory\n    # Update: removing this hack again, since it seems that it is not needed\n    #         any more with recent NumPy versions\n    if start >= 0 and stop <= num_samples:\n        # normal read operation, return appropriate section\n        return signal[start:stop]\n\n    # part of the frame falls outside the signal, padding needed\n    # Note: np.pad(signal[from: to], (pad_left, pad_right), mode=\'constant\')\n    #       always returns a ndarray, not the subclass (and is slower);\n    #       usually np.zeros_like(signal[:frame_size]) is exactly what we want\n    #       (i.e. zeros of frame_size length and the same type/class as the\n    #       signal and not just the dtype), but since we have no guarantee that\n    #       the signal is that long, we have to use the np.repeat workaround\n    frame = np.repeat(signal[:1], frame_size, axis=0)\n\n    # determine how many samples need to be padded from left/right\n    left, right = 0, 0\n    if start < 0:\n        left = min(stop, 0) - start\n        # repeat beginning of signal\n        frame[:left] = np.repeat(signal[:1], left, axis=0)\n        if pad != \'repeat\':\n            frame[:left] = pad\n        start = 0\n    if stop > num_samples:\n        right = stop - max(start, num_samples)\n        # repeat end of signal\n        frame[-right:] = np.repeat(signal[-1:], right, axis=0)\n        if pad != \'repeat\':\n            frame[-right:] = pad\n        stop = num_samples\n\n    # position signal inside frame\n    frame[left:frame_size - right] = signal[min(start, num_samples):\n                                            max(stop, 0)]\n    # return the frame\n    return frame\n\n\nFRAME_SIZE = 2048\nHOP_SIZE = 441.\nFPS = None\nORIGIN = 0\nEND_OF_SIGNAL = \'normal\'\nNUM_FRAMES = None\n\n\n# classes for splitting a signal into frames\nclass FramedSignal(object):\n    """"""\n    The :class:`FramedSignal` splits a :class:`Signal` into frames and makes it\n    iterable and indexable.\n\n    Parameters\n    ----------\n    signal : :class:`Signal` instance\n        Signal to be split into frames.\n    frame_size : int, optional\n        Size of one frame [samples].\n    hop_size : float, optional\n        Progress `hop_size` samples between adjacent frames.\n    fps : float, optional\n        Use given frames per second; if set, this computes and overwrites the\n        given `hop_size` value.\n    origin : int, optional\n        Location of the window relative to the reference sample of a frame.\n    end : int or str, optional\n        End of signal handling (see notes below).\n    num_frames : int, optional\n        Number of frames to return.\n    kwargs : dict, optional\n        If no :class:`Signal` instance was given, one is instantiated with\n        these additional keyword arguments.\n\n    Notes\n    -----\n    The :class:`FramedSignal` class is implemented as an iterator. It splits\n    the given `signal` automatically into frames of `frame_size` length with\n    `hop_size` samples (can be float, normal rounding applies) between the\n    frames. The reference sample of the first frame refers to the first sample\n    of the `signal`.\n\n    The location of the window relative to the reference sample of a frame can\n    be set with the `origin` parameter (with the same behaviour as used by\n    ``scipy.ndimage`` filters). Arbitrary integer values can be given:\n\n    - zero centers the window on its reference sample,\n    - negative values shift the window to the right,\n    - positive values shift the window to the left.\n\n    Additionally, it can have the following literal values:\n\n    - \'center\', \'offline\': the window is centered on its reference sample,\n    - \'left\', \'past\', \'online\': the window is located to the left of its\n      reference sample (including the reference sample),\n    - \'right\', \'future\', \'stream\': the window is located to the right of its\n      reference sample.\n\n    The `end` parameter is used to handle the end of signal behaviour and\n    can have these values:\n\n    - \'normal\': stop as soon as the whole signal got covered by at least one\n      frame (i.e. pad maximally one frame),\n    - \'extend\': frames are returned as long as part of the frame overlaps\n      with the signal to cover the whole signal.\n\n    Alternatively, `num_frames` can be used to retrieve a fixed number of\n    frames.\n\n    In order to be able to stack multiple frames obtained with different frame\n    sizes, the number of frames to be returned must be independent from the set\n    `frame_size`. It is not guaranteed that every sample of the signal is\n    returned in a frame unless the `origin` is either \'right\' or \'future\'.\n\n    If used in online real-time mode the parameters `origin` and `num_frames`\n    should be set to \'stream\' and 1, respectively.\n\n    Examples\n    --------\n    To chop a :class:`Signal` (or anything a :class:`Signal` can be\n    instantiated from) into overlapping frames of size 2048 with adjacent\n    frames being 441 samples apart:\n\n    >>> sig = Signal(\'tests/data/audio/sample.wav\')\n    >>> sig\n    Signal([-2494, -2510, ...,   655,   639], dtype=int16)\n    >>> frames = FramedSignal(sig, frame_size=2048, hop_size=441)\n    >>> frames  # doctest: +ELLIPSIS\n    <madmom.audio.signal.FramedSignal object at 0x...>\n    >>> frames[0]\n    Signal([    0,     0, ..., -4666, -4589], dtype=int16)\n    >>> frames[10]\n    Signal([-6156, -5645, ...,  -253,   671], dtype=int16)\n    >>> frames.fps\n    100.0\n\n    Instead of passing a :class:`Signal` instance as the first argument,\n    anything a :class:`Signal` can be instantiated from (e.g. a file name) can\n    be used. We can also set the frames per second (`fps`) instead, they get\n    converted to `hop_size` based on the `sample_rate` of the signal:\n\n    >>> frames = FramedSignal(\'tests/data/audio/sample.wav\', fps=100)\n    >>> frames  # doctest: +ELLIPSIS\n    <madmom.audio.signal.FramedSignal object at 0x...>\n    >>> frames[0]\n    Signal([    0,     0, ..., -4666, -4589], dtype=int16)\n    >>> frames.frame_size, frames.hop_size\n    (2048, 441.0)\n\n    When trying to access an out of range frame, an IndexError is raised. Thus\n    the FramedSignal can be used the same way as a numpy array or any other\n    iterable.\n\n    >>> frames = FramedSignal(\'tests/data/audio/sample.wav\')\n    >>> frames.num_frames\n    281\n    >>> frames[281]\n    Traceback (most recent call last):\n    IndexError: end of signal reached\n    >>> frames.shape\n    (281, 2048)\n\n    Slices are FramedSignals itself:\n\n    >>> frames[:4]  # doctest: +ELLIPSIS\n    <madmom.audio.signal.FramedSignal object at 0x...>\n\n    To obtain a numpy array from a FramedSignal, simply use np.array() on the\n    full FramedSignal or a slice of it. Please note, that this requires a full\n    memory copy.\n\n    >>> np.array(frames[2:4])\n    array([[    0,     0, ..., -5316, -5405],\n           [ 2215,  2281, ...,   561,   653]], dtype=int16)\n\n    """"""\n\n    def __init__(self, signal, frame_size=FRAME_SIZE, hop_size=HOP_SIZE,\n                 fps=FPS, origin=ORIGIN, end=END_OF_SIGNAL,\n                 num_frames=NUM_FRAMES, **kwargs):\n\n        # signal handling\n        if not isinstance(signal, Signal):\n            # try to instantiate a Signal\n            signal = Signal(signal, **kwargs)\n\n        # save the signal\n        self.signal = signal\n\n        # arguments for splitting the signal into frames\n        if frame_size:\n            self.frame_size = int(frame_size)\n        if hop_size:\n            self.hop_size = float(hop_size)\n        # use fps instead of hop_size\n        if fps:\n            # overwrite the hop_size\n            self.hop_size = self.signal.sample_rate / float(fps)\n\n        # translate literal window location values to numeric origin\n        if origin in (\'center\', \'offline\'):\n            # window centered around the origin\n            origin = 0\n        elif origin in (\'left\', \'past\', \'online\'):\n            # origin is the right edge of the frame, i.e. window to the left\n            # Note: used when simulating online mode, where only past\n            #       information of the audio signal can be used\n            origin = (frame_size - 1) / 2\n        elif origin in (\'right\', \'future\', \'stream\'):\n            # origin is the left edge of the frame, i.e. window to the right\n            # Note: used when operating on live audio streams where we want\n            #       to retrieve a single frame. Instead of using \'online\', we\n            #       ""fake"" the origin in order to retrieve the complete frame\n            #       provided by FramedSignalProcessor. This is a workaround to\n            #       be able to use the same processing chain in different modes\n            origin = -(frame_size / 2)\n        self.origin = int(origin)\n\n        # number of frames determination\n        if num_frames is None:\n            if end == \'extend\':\n                # return frames as long as a frame covers any signal\n                num_frames = np.floor(len(self.signal) /\n                                      float(self.hop_size) + 1)\n            elif end == \'normal\':\n                # return frames as long as the origin sample covers the signal\n                num_frames = np.ceil(len(self.signal) / float(self.hop_size))\n            else:\n                raise ValueError(""end of signal handling \'%s\' unknown"" %\n                                 end)\n        self.num_frames = int(num_frames)\n\n    # make the object indexable / iterable\n    def __getitem__(self, index):\n        """"""\n        This makes the :class:`FramedSignal` class indexable and/or iterable.\n\n        The signal is split into frames (of length `frame_size`) automatically.\n        Two frames are located `hop_size` samples apart. If `hop_size` is a\n        float, normal rounding applies.\n\n        """"""\n        # a single index is given\n        if isinstance(index, integer_types):\n            # negative indices\n            if index < 0:\n                index += self.num_frames\n            # return the frame at the given index\n            if index < self.num_frames:\n                return signal_frame(self.signal, index,\n                                    frame_size=self.frame_size,\n                                    hop_size=self.hop_size, origin=self.origin)\n            # otherwise raise an error to indicate the end of signal\n            raise IndexError(""end of signal reached"")\n        # a slice is given\n        elif isinstance(index, slice):\n            # determine the frames to return (limited to the number of frames)\n            start, stop, step = index.indices(self.num_frames)\n            # allow only normal steps\n            if step != 1:\n                raise ValueError(\'only slices with a step size of 1 supported\')\n            # determine the number of frames\n            num_frames = stop - start\n            # determine the new origin, i.e. start position\n            origin = self.origin - self.hop_size * start\n            # return a new FramedSignal instance covering the requested frames\n            return FramedSignal(self.signal, frame_size=self.frame_size,\n                                hop_size=self.hop_size, origin=origin,\n                                num_frames=num_frames)\n        # other index types are invalid\n        else:\n            raise TypeError(""frame indices must be slices or integers"")\n\n    # len() returns the number of frames, consistent with __getitem__()\n    def __len__(self):\n        return self.num_frames\n\n    @property\n    def frame_rate(self):\n        """"""Frame rate (same as fps).""""""\n        # n/a if the signal has no sample rate\n        if self.signal.sample_rate is None:\n            return None\n        return float(self.signal.sample_rate) / self.hop_size\n\n    @property\n    def fps(self):\n        """"""Frames per second.""""""\n        return self.frame_rate\n\n    @property\n    def overlap_factor(self):\n        """"""Overlapping factor of two adjacent frames.""""""\n        return 1.0 - self.hop_size / self.frame_size\n\n    @property\n    def shape(self):\n        """"""\n        Shape of the FramedSignal (num_frames, frame_size[, num_channels]).\n\n        """"""\n        shape = self.num_frames, self.frame_size\n        if self.signal.num_channels != 1:\n            shape += (self.signal.num_channels, )\n        return shape\n\n    @property\n    def ndim(self):\n        """"""Dimensionality of the FramedSignal.""""""\n        return len(self.shape)\n\n    def energy(self):\n        """"""Energy of the individual frames.""""""\n        return energy(self)\n\n    def root_mean_square(self):\n        """"""Root mean square of the individual frames.""""""\n        return root_mean_square(self)\n\n    rms = root_mean_square\n\n    def sound_pressure_level(self):\n        """"""Sound pressure level of the individual frames.""""""\n        return sound_pressure_level(self)\n\n    spl = sound_pressure_level\n\n\nclass FramedSignalProcessor(Processor):\n    """"""\n    Slice a Signal into frames.\n\n    Parameters\n    ----------\n    frame_size : int, optional\n        Size of one frame [samples].\n    hop_size : float, optional\n        Progress `hop_size` samples between adjacent frames.\n    fps : float, optional\n        Use given frames per second; if set, this computes and overwrites the\n        given `hop_size` value.\n    origin : int, optional\n        Location of the window relative to the reference sample of a frame.\n    end : int or str, optional\n        End of signal handling (see :class:`FramedSignal`).\n    num_frames : int, optional\n        Number of frames to return.\n\n    Notes\n    -----\n    When operating on live audio signals, `origin` must be set to \'stream\' in\n    order to retrieve always the last `frame_size` samples.\n\n    Examples\n    --------\n    Processor for chopping a :class:`Signal` (or anything a :class:`Signal` can\n    be instantiated from) into overlapping frames of size 2048, and a frame\n    rate of 100 frames per second:\n\n    >>> proc = FramedSignalProcessor(frame_size=2048, fps=100)\n    >>> frames = proc(\'tests/data/audio/sample.wav\')\n    >>> frames  # doctest: +ELLIPSIS\n    <madmom.audio.signal.FramedSignal object at 0x...>\n    >>> frames[0]\n    Signal([    0,     0, ..., -4666, -4589], dtype=int16)\n    >>> frames[10]\n    Signal([-6156, -5645, ...,  -253,   671], dtype=int16)\n    >>> frames.hop_size\n    441.0\n\n    """"""\n\n    def __init__(self, frame_size=FRAME_SIZE, hop_size=HOP_SIZE, fps=FPS,\n                 origin=ORIGIN, end=END_OF_SIGNAL, num_frames=NUM_FRAMES,\n                 **kwargs):\n        # pylint: disable=unused-argument\n        self.frame_size = frame_size\n        self.hop_size = hop_size\n        self.fps = fps  # do not convert here, pass it to FramedSignal\n        self.origin = origin\n        self.end = end\n        self.num_frames = num_frames\n\n    def process(self, data, **kwargs):\n        """"""\n        Slice the signal into (overlapping) frames.\n\n        Parameters\n        ----------\n        data : :class:`Signal` instance\n            Signal to be sliced into frames.\n        kwargs : dict, optional\n            Keyword arguments passed to :class:`FramedSignal`.\n\n        Returns\n        -------\n        frames : :class:`FramedSignal` instance\n            FramedSignal instance\n\n        """"""\n        # update arguments passed to FramedSignal\n        args = dict(frame_size=self.frame_size, hop_size=self.hop_size,\n                    fps=self.fps, origin=self.origin, end=self.end,\n                    num_frames=self.num_frames)\n        args.update(kwargs)\n        # always use the last `frame_size` samples if we operate on a live\n        # audio stream, otherwise we get the wrong portion of the signal\n        if self.origin == \'stream\':\n            data = data[-self.frame_size:]\n        # instantiate a FramedSignal from the data and return it\n        return FramedSignal(data, **args)\n\n    @staticmethod\n    def add_arguments(parser, frame_size=FRAME_SIZE, fps=FPS,\n                      online=None):\n        """"""\n        Add signal framing related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        frame_size : int, optional\n            Size of one frame in samples.\n        fps : float, optional\n            Frames per second.\n        online : bool, optional\n            Online mode (use only past signal information, i.e. align the\n            window to the left of the reference sample).\n\n        Returns\n        -------\n        argparse argument group\n            Signal framing argument parser group.\n\n        Notes\n        -----\n        Parameters are included in the group only if they are not \'None\'.\n\n        """"""\n        # add signal framing options to the existing parser\n        g = parser.add_argument_group(\'signal framing arguments\')\n        # depending on the type of frame_size, use different options\n        if isinstance(frame_size, integer_types):\n            g.add_argument(\'--frame_size\', action=\'store\', type=int,\n                           default=frame_size,\n                           help=\'frame size [samples, default=%(default)i]\')\n        elif isinstance(frame_size, list):\n            # Note: this option can be used to stack multiple spectrograms\n            #       with different frame sizes\n            from ..utils import OverrideDefaultListAction\n            g.add_argument(\'--frame_size\', type=int, default=frame_size,\n                           action=OverrideDefaultListAction, sep=\',\',\n                           help=\'(comma separated list of) frame size(s) to \'\n                                \'use [samples, default=%(default)s]\')\n        if fps is not None:\n            g.add_argument(\'--fps\', action=\'store\', type=float, default=fps,\n                           help=\'frames per second [default=%(default).1f]\')\n        if online is False:\n            g.add_argument(\'--online\', dest=\'origin\', action=\'store_const\',\n                           const=\'online\', default=\'offline\',\n                           help=\'operate in online mode [default=offline]\')\n        elif online is True:\n            g.add_argument(\'--offline\', dest=\'origin\', action=\'store_const\',\n                           const=\'offline\', default=\'online\',\n                           help=\'operate in offline mode [default=online]\')\n        # return the argument group so it can be modified if needed\n        return g\n\n\n# class for online processing\nclass Stream(object):\n    """"""\n    A Stream handles live (i.e. online, real-time) audio input via PyAudio.\n\n    Parameters\n    ----------\n    sample_rate : int\n        Sample rate of the signal.\n    num_channels : int, optional\n        Number of channels.\n    dtype : numpy dtype, optional\n        Data type for the signal.\n    frame_size : int, optional\n        Size of one frame [samples].\n    hop_size : int, optional\n        Progress `hop_size` samples between adjacent frames.\n    fps : float, optional\n        Use given frames per second; if set, this computes and overwrites the\n        given `hop_size` value (the resulting `hop_size` must be an integer).\n    stream_input_device : int, optional\n        PyAudio device index of the desired input device.\n    queue_size : int\n        Size of the FIFO (first in first out) queue. If the queue is full and\n        new audio samples arrive, the oldest item in the queue will be dropped.\n\n    Notes\n    -----\n    Stream is implemented as an iterable which blocks until enough new data is\n    available.\n\n    """"""\n\n    def __init__(self, sample_rate=SAMPLE_RATE, num_channels=NUM_CHANNELS,\n                 dtype=np.float32, frame_size=FRAME_SIZE, hop_size=HOP_SIZE,\n                 fps=FPS, stream_input_device=None, **kwargs):\n        # import PyAudio here and not at the module level\n        import pyaudio\n        # set attributes\n        self.sample_rate = sample_rate\n        self.num_channels = 1 if num_channels is None else num_channels\n        self.dtype = dtype\n        if frame_size:\n            self.frame_size = int(frame_size)\n        if fps:\n            # use fps instead of hop_size\n            hop_size = self.sample_rate / float(fps)\n        if int(hop_size) != hop_size:\n            raise ValueError(\n                \'only integer `hop_size` supported, not %s\' % hop_size)\n        self.hop_size = int(hop_size)\n        self.stream_input_device = stream_input_device\n        # init PyAudio\n        self.pa = pyaudio.PyAudio()\n        # init a stream to read audio samples from\n        self.stream = self.pa.open(rate=self.sample_rate,\n                                   channels=self.num_channels,\n                                   format=pyaudio.paFloat32, input=True,\n                                   frames_per_buffer=self.hop_size,\n                                   input_device_index=self.stream_input_device,\n                                   start=True)\n        # create a buffer\n        self.buffer = BufferProcessor(self.frame_size)\n        # frame index counter\n        self.frame_idx = 0\n        # PyAudio flags\n        self.paComplete = pyaudio.paComplete\n        self.paContinue = pyaudio.paContinue\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        # get the desired number of samples (block until all are present)\n        data = self.stream.read(self.hop_size, exception_on_overflow=False)\n        # convert it to a numpy array\n        data = np.fromstring(data, \'float32\').astype(self.dtype, copy=False)\n        # buffer the data (i.e. append hop_size samples and rotate)\n        data = self.buffer(data)\n        # wrap the last frame_size samples as a Signal\n        # TODO: check float / int hop size; theoretically a float hop size\n        #       can be accomplished by making the buffer N samples bigger and\n        #       take the correct portion of the buffer\n        start = (self.frame_idx * float(self.hop_size) / self.sample_rate)\n        signal = Signal(data[-self.frame_size:], sample_rate=self.sample_rate,\n                        dtype=self.dtype, num_channels=self.num_channels,\n                        start=start)\n        # increment the frame index\n        self.frame_idx += 1\n        return signal\n\n    next = __next__\n\n    def is_running(self):\n        return self.stream.is_active()\n\n    def close(self):\n        self.stream.close()\n        # TODO: is this the correct place to terminate PyAudio?\n        self.pa.terminate()\n\n    @property\n    def shape(self):\n        """"""Shape of the Stream (None, frame_size[, num_channels]).""""""\n        shape = None, self.frame_size\n        if self.signal.num_channels != 1:\n            shape += (self.signal.num_channels,)\n        return shape\n'"
madmom/audio/spectrogram.py,37,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains spectrogram related functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport inspect\nimport numpy as np\n\nfrom ..processors import Processor, SequentialProcessor, BufferProcessor\nfrom .filters import (Filterbank, LogarithmicFilterbank, NUM_BANDS, FMIN, FMAX,\n                      A4, NORM_FILTERS, UNIQUE_FILTERS)\n\n\ndef spec(stft):\n    """"""\n    Computes the magnitudes of the complex Short Time Fourier Transform of a\n    signal.\n\n    Parameters\n    ----------\n    stft : numpy array\n        Complex STFT of a signal.\n\n    Returns\n    -------\n    spec : numpy array\n        Magnitude spectrogram.\n\n    """"""\n    return np.abs(stft)\n\n\ndef tuning_frequency(spectrogram, bin_frequencies, num_hist_bins=15, fref=A4):\n    """"""\n    Determines the tuning frequency of the audio signal based on the given\n    magnitude spectrogram.\n\n    To determine the tuning frequency, a weighted histogram of relative\n    deviations of the spectrogram bins towards the closest semitones is built.\n\n    Parameters\n    ----------\n    spectrogram : numpy array\n        Magnitude spectrogram.\n    bin_frequencies : numpy array\n        Frequencies of the spectrogram bins [Hz].\n    num_hist_bins : int, optional\n        Number of histogram bins.\n    fref : float, optional\n        Reference tuning frequency [Hz].\n\n    Returns\n    -------\n    tuning_frequency : float\n        Tuning frequency [Hz].\n\n    """"""\n    from .filters import hz2midi\n    # interval of spectral bins from the reference frequency in semitones\n    semitone_int = hz2midi(bin_frequencies, fref=fref)\n    # deviation from the next semitone\n    semitone_dev = semitone_int - np.round(semitone_int)\n    # np.histogram accepts bin edges, so we need to apply an offset and use 1\n    # more bin than given to build a histogram\n    offset = 0.5 / num_hist_bins\n    hist_bins = np.linspace(-0.5 - offset, 0.5 + offset, num_hist_bins + 1)\n    histogram = np.histogram(semitone_dev, weights=np.sum(spectrogram, axis=0),\n                             bins=hist_bins)\n    # deviation of the bins (centre of the bins)\n    dev_bins = (histogram[1][:-1] + histogram[1][1:]) / 2.\n    # dominant deviation\n    dev = dev_bins[np.argmax(histogram[0])]\n    # calculate the tuning frequency\n    return fref * 2. ** (dev / 12.)\n\n\n# magnitude spectrogram of STFT\nclass Spectrogram(np.ndarray):\n    """"""\n    A :class:`Spectrogram` represents the magnitude spectrogram of a\n    :class:`.audio.stft.ShortTimeFourierTransform`.\n\n    Parameters\n    ----------\n    stft : :class:`.audio.stft.ShortTimeFourierTransform` instance\n        Short Time Fourier Transform.\n    kwargs : dict, optional\n        If no :class:`.audio.stft.ShortTimeFourierTransform` instance was\n        given, one is instantiated with these additional keyword arguments.\n\n    Examples\n    --------\n    Create a :class:`Spectrogram` from a\n    :class:`.audio.stft.ShortTimeFourierTransform` (or anything it can be\n    instantiated from:\n\n    >>> spec = Spectrogram(\'tests/data/audio/sample.wav\')\n    >>> spec  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    Spectrogram([[ 3.15249,  4.00272, ...,  0.03634,  0.03671],\n                 [ 4.28429,  2.85158, ...,  0.0219 ,  0.02227],\n                 ...,\n                 [ 4.92274, 10.27775, ...,  0.00607,  0.00593],\n                 [ 9.22709,  9.6387 , ...,  0.00981,  0.00984]], dtype=float32)\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, stft, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, stft, **kwargs):\n        from .stft import ShortTimeFourierTransform\n        # check stft type\n        if isinstance(stft, Spectrogram):\n            # already a Spectrogram\n            data = stft\n        elif isinstance(stft, ShortTimeFourierTransform):\n            # take the abs of the STFT\n            data = np.abs(stft)\n        else:\n            # try to instantiate a ShortTimeFourierTransform\n            stft = ShortTimeFourierTransform(stft, **kwargs)\n            # take the abs of the STFT\n            data = np.abs(stft)\n        # cast as Spectrogram\n        obj = np.asarray(data).view(cls)\n        # save additional attributes\n        obj.stft = stft\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views\n        self.stft = getattr(obj, \'stft\', None)\n\n    @property\n    def num_frames(self):\n        """"""Number of frames.""""""\n        return len(self)\n\n    @property\n    def num_bins(self):\n        """"""Number of bins.""""""\n        return int(self.shape[1])\n\n    @property\n    def bin_frequencies(self):\n        """"""Bin frequencies.""""""\n        return self.stft.bin_frequencies\n\n    def diff(self, **kwargs):\n        """"""\n        Return the difference of the magnitude spectrogram.\n\n        Parameters\n        ----------\n        kwargs : dict\n            Keyword arguments passed to :class:`SpectrogramDifference`.\n\n        Returns\n        -------\n        diff : :class:`SpectrogramDifference` instance\n            The differences of the magnitude spectrogram.\n\n        """"""\n        return SpectrogramDifference(self, **kwargs)\n\n    def filter(self, **kwargs):\n        """"""\n        Return a filtered version of the magnitude spectrogram.\n\n        Parameters\n        ----------\n        kwargs : dict\n            Keyword arguments passed to :class:`FilteredSpectrogram`.\n\n        Returns\n        -------\n        filt_spec : :class:`FilteredSpectrogram` instance\n            Filtered version of the magnitude spectrogram.\n\n        """"""\n        return FilteredSpectrogram(self, **kwargs)\n\n    def log(self, **kwargs):\n        """"""\n        Return a logarithmically scaled version of the magnitude spectrogram.\n\n        Parameters\n        ----------\n        kwargs : dict\n            Keyword arguments passed to :class:`LogarithmicSpectrogram`.\n\n        Returns\n        -------\n        log_spec : :class:`LogarithmicSpectrogram` instance\n            Logarithmically scaled version of the magnitude spectrogram.\n\n        """"""\n        return LogarithmicSpectrogram(self, **kwargs)\n\n    def tuning_frequency(self, **kwargs):\n        """"""\n        Return the tuning frequency of the audio signal based on peaks of the\n        spectrogram.\n\n        Parameters\n        ----------\n        kwargs : dict\n            Keyword arguments passed to :func:`tuning_frequency`.\n\n        Returns\n        -------\n        tuning_frequency : float\n            Tuning frequency of the spectrogram.\n\n        """"""\n        from scipy.ndimage.filters import maximum_filter\n        # widen the spectrogram in frequency dimension\n        max_spec = maximum_filter(self, size=[1, 3])\n        # get the peaks of the spectrogram\n        max_spec = self * (self == max_spec)\n        # determine the tuning frequency\n        return tuning_frequency(max_spec, self.bin_frequencies, **kwargs)\n\n\nclass SpectrogramProcessor(Processor):\n    """"""\n    SpectrogramProcessor class.\n\n    """"""\n    def __init__(self, **kwargs):\n        pass\n\n    def process(self, data, **kwargs):\n        """"""\n        Create a Spectrogram from the given data.\n\n        Parameters\n        ----------\n        data : numpy array\n            Data to be processed.\n        kwargs : dict\n            Keyword arguments passed to :class:`Spectrogram`.\n\n        Returns\n        -------\n        spec : :class:`Spectrogram` instance\n            Spectrogram.\n\n        """"""\n        return Spectrogram(data, **kwargs)\n\n\n# filtered spectrogram stuff\nFILTERBANK = LogarithmicFilterbank\n\n\nclass FilteredSpectrogram(Spectrogram):\n    """"""\n    FilteredSpectrogram class.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        Spectrogram.\n    filterbank : :class:`.audio.filters.Filterbank`, optional\n        Filterbank class or instance; if a class is given (rather than an\n        instance), one will be created with the given type and parameters.\n    num_bands : int, optional\n        Number of filter bands (per octave, depending on the type of the\n        `filterbank`).\n    fmin : float, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    fref : float, optional\n        Tuning frequency of the filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filter bands of the filterbank to area 1.\n    unique_filters : bool, optional\n        Indicate if the filterbank should contain only unique filters, i.e.\n        remove duplicate filters resulting from insufficient resolution at\n        low frequencies.\n    kwargs : dict, optional\n        If no :class:`Spectrogram` instance was given, one is instantiated\n        with these additional keyword arguments.\n\n    Examples\n    --------\n    Create a :class:`FilteredSpectrogram` from a :class:`Spectrogram` (or\n    anything it can be instantiated from. Per default a\n    :class:`.madmom.audio.filters.LogarithmicFilterbank` with 12 bands per\n    octave is used.\n\n    >>> spec = FilteredSpectrogram(\'tests/data/audio/sample.wav\')\n    >>> spec  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    FilteredSpectrogram([[ 5.66156, 6.30141, ..., 0.05426, 0.06461],\n                         [ 8.44266, 8.69582, ..., 0.07703, 0.0902 ],\n                         ...,\n                         [10.04626, 1.12018, ..., 0.0487 , 0.04282],\n                         [ 8.60186, 6.81195, ..., 0.03721, 0.03371]],\n                        dtype=float32)\n\n    The resulting spectrogram has fewer frequency bins, with the centers of\n    the bins aligned logarithmically (lower frequency bins still have a linear\n    spacing due to the coarse resolution of the DFT at low frequencies):\n\n    >>> spec.shape\n    (281, 81)\n    >>> spec.num_bins\n    81\n    >>> spec.bin_frequencies  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    array([    43.06641,    64.59961,    86.13281,   107.66602,\n              129.19922,   150.73242,   172.26562,   193.79883, ...,\n            10551.26953, 11175.73242, 11843.26172, 12553.85742,\n            13285.98633, 14082.71484, 14922.50977, 15805.37109])\n\n    The filterbank used to filter the spectrogram is saved as an attribute:\n\n    >>> spec.filterbank  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    LogarithmicFilterbank([[0., 0., ..., 0., 0.],\n                           [0., 0., ..., 0., 0.],\n                           ...,\n                           [0., 0., ..., 0., 0.],\n                           [0., 0., ..., 0., 0.]], dtype=float32)\n    >>> spec.filterbank.num_bands\n    81\n\n    The filterbank can be chosen at instantiation time:\n\n    >>> from madmom.audio.filters import MelFilterbank\n    >>> spec = FilteredSpectrogram(\'tests/data/audio/sample.wav\', \\\n    filterbank=MelFilterbank, num_bands=40)\n    >>> type(spec.filterbank)\n    <class \'madmom.audio.filters.MelFilterbank\'>\n    >>> spec.shape\n    (281, 40)\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, spectrogram, filterbank=FILTERBANK, num_bands=NUM_BANDS,\n                 fmin=FMIN, fmax=FMAX, fref=A4, norm_filters=NORM_FILTERS,\n                 unique_filters=UNIQUE_FILTERS, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, spectrogram, filterbank=FILTERBANK, num_bands=NUM_BANDS,\n                fmin=FMIN, fmax=FMAX, fref=A4, norm_filters=NORM_FILTERS,\n                unique_filters=UNIQUE_FILTERS, **kwargs):\n        # pylint: disable=unused-argument\n        # instantiate a Spectrogram if needed\n        if not isinstance(spectrogram, Spectrogram):\n            # try to instantiate a Spectrogram object\n            spectrogram = Spectrogram(spectrogram, **kwargs)\n        # instantiate a Filterbank if needed\n        if inspect.isclass(filterbank) and issubclass(filterbank, Filterbank):\n            # a Filterbank class is given, create a filterbank of this type\n            filterbank = filterbank(spectrogram.bin_frequencies,\n                                    num_bands=num_bands, fmin=fmin, fmax=fmax,\n                                    fref=fref, norm_filters=norm_filters,\n                                    unique_filters=unique_filters)\n        if not isinstance(filterbank, Filterbank):\n            raise TypeError(\'not a Filterbank type or instance: %s\' %\n                            filterbank)\n        # filter the spectrogram\n        data = np.dot(spectrogram, filterbank)\n        # cast as FilteredSpectrogram\n        obj = np.asarray(data).view(cls)\n        # save additional attributes\n        obj.filterbank = filterbank\n        # and those from the given spectrogram\n        obj.stft = spectrogram.stft\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views\n        self.stft = getattr(obj, \'stft\', None)\n        self.filterbank = getattr(obj, \'filterbank\', None)\n\n    @property\n    def bin_frequencies(self):\n        """"""Bin frequencies.""""""\n        # use the center frequencies of the filterbank as bin_frequencies\n        return self.filterbank.center_frequencies\n\n\nclass FilteredSpectrogramProcessor(Processor):\n    """"""\n    FilteredSpectrogramProcessor class.\n\n    Parameters\n    ----------\n    filterbank : :class:`.audio.filters.Filterbank`\n        Filterbank used to filter a spectrogram.\n    num_bands : int\n        Number of bands (per octave).\n    fmin : float, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    fref : float, optional\n        Tuning frequency of the filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filter of the filterbank to area 1.\n    unique_filters : bool, optional\n        Indicate if the filterbank should contain only unique filters, i.e.\n        remove duplicate filters resulting from insufficient resolution at\n        low frequencies.\n\n    """"""\n\n    def __init__(self, filterbank=FILTERBANK, num_bands=NUM_BANDS, fmin=FMIN,\n                 fmax=FMAX, fref=A4, norm_filters=NORM_FILTERS,\n                 unique_filters=UNIQUE_FILTERS, **kwargs):\n        # pylint: disable=unused-argument\n        self.filterbank = filterbank\n        self.num_bands = num_bands\n        self.fmin = fmin\n        self.fmax = fmax\n        self.fref = fref\n        self.norm_filters = norm_filters\n        self.unique_filters = unique_filters\n\n    def process(self, data, **kwargs):\n        """"""\n        Create a FilteredSpectrogram from the given data.\n\n        Parameters\n        ----------\n        data : numpy array\n            Data to be processed.\n        kwargs : dict\n            Keyword arguments passed to :class:`FilteredSpectrogram`.\n\n        Returns\n        -------\n        filt_spec : :class:`FilteredSpectrogram` instance\n            Filtered spectrogram.\n\n        """"""\n        # update arguments passed to FilteredSpectrogram\n        args = dict(filterbank=self.filterbank, num_bands=self.num_bands,\n                    fmin=self.fmin, fmax=self.fmax, fref=self.fref,\n                    norm_filters=self.norm_filters,\n                    unique_filters=self.unique_filters)\n        args.update(kwargs)\n        # instantiate a FilteredSpectrogram and return it\n        data = FilteredSpectrogram(data, **args)\n        # cache the filterbank\n        self.filterbank = data.filterbank\n        return data\n\n\n# logarithmic spectrogram stuff\nLOG = np.log10\nMUL = 1.\nADD = 1.\n\n\nclass LogarithmicSpectrogram(Spectrogram):\n    """"""\n    LogarithmicSpectrogram class.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        Spectrogram.\n    log : numpy ufunc, optional\n        Logarithmic scaling function to apply.\n    mul : float, optional\n        Multiply the magnitude spectrogram with this factor before taking\n        the logarithm.\n    add : float, optional\n        Add this value before taking the logarithm of the magnitudes.\n    kwargs : dict, optional\n        If no :class:`Spectrogram` instance was given, one is instantiated\n        with these additional keyword arguments.\n\n    Examples\n    --------\n    Create a :class:`LogarithmicSpectrogram` from a :class:`Spectrogram` (or\n    anything it can be instantiated from. Per default `np.log10` is used as\n    the scaling function and a value of 1 is added to avoid negative values.\n\n    >>> spec = LogarithmicSpectrogram(\'tests/data/audio/sample.wav\')\n    >>> spec  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    LogarithmicSpectrogram([[...]], dtype=float32)\n    >>> spec.min()\n    LogarithmicSpectrogram(0., dtype=float32)\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, spectrogram, log=LOG, mul=MUL, add=ADD, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, spectrogram, log=LOG, mul=MUL, add=ADD, **kwargs):\n        # instantiate a Spectrogram if needed\n        if not isinstance(spectrogram, Spectrogram):\n            # try to instantiate a Spectrogram object\n            spectrogram = Spectrogram(spectrogram, **kwargs)\n            data = spectrogram\n        else:\n            # make a copy of the spectrogram\n            data = spectrogram.copy()\n        # scale the spectrogram\n        if mul is not None:\n            data *= mul\n        if add is not None:\n            data += add\n        if log is not None:\n            log(data, data)\n        # cast as FilteredSpectrogram\n        obj = np.asarray(data).view(cls)\n        # save additional attributes\n        obj.mul = mul\n        obj.add = add\n        # and those from the given spectrogram\n        obj.stft = spectrogram.stft\n        obj.spectrogram = spectrogram\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views\n        self.stft = getattr(obj, \'stft\', None)\n        self.spectrogram = getattr(obj, \'spectrogram\', None)\n        self.mul = getattr(obj, \'mul\', MUL)\n        self.add = getattr(obj, \'add\', ADD)\n\n    @property\n    def filterbank(self):\n        """"""Filterbank.""""""\n        return self.spectrogram.filterbank\n\n    @property\n    def bin_frequencies(self):\n        """"""Bin frequencies.""""""\n        return self.spectrogram.bin_frequencies\n\n\nclass LogarithmicSpectrogramProcessor(Processor):\n    """"""\n    Logarithmic Spectrogram Processor class.\n\n    Parameters\n    ----------\n    log : numpy ufunc, optional\n        Loagrithmic scaling function to apply.\n    mul : float, optional\n        Multiply the magnitude spectrogram with this factor before taking the\n        logarithm.\n    add : float, optional\n        Add this value before taking the logarithm of the magnitudes.\n\n    """"""\n\n    def __init__(self, log=LOG, mul=MUL, add=ADD, **kwargs):\n        # pylint: disable=unused-argument\n        self.log = log\n        self.mul = mul\n        self.add = add\n\n    def process(self, data, **kwargs):\n        """"""\n        Perform logarithmic scaling of a spectrogram.\n\n        Parameters\n        ----------\n        data : numpy array\n            Data to be processed.\n        kwargs : dict\n            Keyword arguments passed to :class:`LogarithmicSpectrogram`.\n\n        Returns\n        -------\n        log_spec : :class:`LogarithmicSpectrogram` instance\n            Logarithmically scaled spectrogram.\n\n        """"""\n        # update arguments passed to LogarithmicSpectrogram\n        args = dict(log=self.log, mul=self.mul, add=self.add)\n        args.update(kwargs)\n        # instantiate a LogarithmicSpectrogram\n        return LogarithmicSpectrogram(data, **args)\n\n    @staticmethod\n    def add_arguments(parser, log=None, mul=None, add=None):\n        """"""\n        Add spectrogram scaling related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        log : bool, optional\n            Take the logarithm of the spectrogram.\n        mul : float, optional\n            Multiply the magnitude spectrogram with this factor before taking\n            the logarithm.\n        add : float, optional\n            Add this value before taking the logarithm of the magnitudes.\n\n        Returns\n        -------\n        argparse argument group\n            Spectrogram scaling argument parser group.\n\n        Notes\n        -----\n        Parameters are included in the group only if they are not \'None\'.\n\n        """"""\n        # add log related options to the existing parser\n        g = parser.add_argument_group(\'magnitude scaling arguments\')\n        # log\n        if log is True:\n            g.add_argument(\'--linear\', dest=\'log\', action=\'store_const\',\n                           const=None, default=LOG,\n                           help=\'linear magnitudes [default=logarithmic]\')\n        elif log is False:\n            g.add_argument(\'--log\', action=\'store_const\',\n                           const=LOG, default=None,\n                           help=\'logarithmic magnitudes [default=linear]\')\n        # mul\n        if mul is not None:\n            g.add_argument(\'--mul\', action=\'store\', type=float,\n                           default=mul, help=\'multiplier (before taking \'\n                           \'the log) [default=%(default).1f]\')\n        # add\n        if add is not None:\n            g.add_argument(\'--add\', action=\'store\', type=float,\n                           default=add, help=\'value added (before taking \'\n                           \'the log) [default=%(default).1f]\')\n        # return the group\n        return g\n\n\n# logarithmic filtered spectrogram class\nclass LogarithmicFilteredSpectrogram(LogarithmicSpectrogram,\n                                     FilteredSpectrogram):\n    """"""\n    LogarithmicFilteredSpectrogram class.\n\n    Parameters\n    ----------\n    spectrogram : :class:`FilteredSpectrogram` instance\n        Filtered spectrogram.\n    kwargs : dict, optional\n        If no :class:`FilteredSpectrogram` instance was given, one is\n        instantiated with these additional keyword arguments and\n        logarithmically scaled afterwards, i.e. passed to\n        :class:`LogarithmicSpectrogram`.\n\n    Notes\n    -----\n    For the filtering and scaling parameters, please refer to\n    :class:`FilteredSpectrogram` and :class:`LogarithmicSpectrogram`.\n\n    See Also\n    --------\n    :class:`FilteredSpectrogram`\n    :class:`LogarithmicSpectrogram`\n\n    Examples\n    --------\n    Create a :class:`LogarithmicFilteredSpectrogram` from a\n    :class:`Spectrogram` (or anything it can be instantiated from. This is\n    mainly a convenience class which first filters the spectrogram and then\n    scales it logarithmically.\n\n    >>> spec = LogarithmicFilteredSpectrogram(\'tests/data/audio/sample.wav\')\n    >>> spec  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    LogarithmicFilteredSpectrogram([[0.82358, 0.86341, ..., 0.02295, 0.02719],\n                                    [0.97509, 0.98658, ..., 0.03223, 0.0375 ],\n                                    ...,\n                                    [1.04322, 0.32637, ..., 0.02065, 0.01821],\n                                    [0.98236, 0.89276, ..., 0.01587, 0.0144 ]],\n                                    dtype=float32)\n    >>> spec.shape\n    (281, 81)\n    >>> spec.filterbank  # doctest: +ELLIPSIS\n    LogarithmicFilterbank([[...]], dtype=float32)\n    >>> spec.min()  # doctest: +ELLIPSIS\n    LogarithmicFilteredSpectrogram(0.00831, dtype=float32)\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, spectrogram, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, spectrogram, **kwargs):\n        # get the log args\n        mul = kwargs.pop(\'mul\', MUL)\n        add = kwargs.pop(\'add\', ADD)\n        # instantiate a FilteredSpectrogram if needed\n        if not isinstance(spectrogram, FilteredSpectrogram):\n            spectrogram = FilteredSpectrogram(spectrogram, **kwargs)\n        # take the logarithm\n        data = LogarithmicSpectrogram(spectrogram, mul=mul, add=add, **kwargs)\n        # cast as LogarithmicFilteredSpectrogram\n        obj = np.asarray(data).view(cls)\n        # save additional attributes\n        obj.mul = data.mul\n        obj.add = data.add\n        # and those from the given spectrogram\n        obj.stft = spectrogram.stft\n        obj.spectrogram = spectrogram\n        # return the object\n        return obj\n\n    @property\n    def filterbank(self):\n        """"""Filterbank.""""""\n        return self.spectrogram.filterbank\n\n    @property\n    def bin_frequencies(self):\n        """"""Bin frequencies.""""""\n        return self.filterbank.center_frequencies\n\n\nclass LogarithmicFilteredSpectrogramProcessor(Processor):\n    """"""\n    Logarithmic Filtered Spectrogram Processor class.\n\n    Parameters\n    ----------\n    filterbank : :class:`.audio.filters.Filterbank`\n        Filterbank used to filter a spectrogram.\n    num_bands : int\n        Number of bands (per octave).\n    fmin : float, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    fref : float, optional\n        Tuning frequency of the filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filter of the filterbank to area 1.\n    unique_filters : bool, optional\n        Indicate if the filterbank should contain only unique filters, i.e.\n        remove duplicate filters resulting from insufficient resolution at\n        low frequencies.\n    mul : float, optional\n        Multiply the magnitude spectrogram with this factor before taking the\n        logarithm.\n    add : float, optional\n        Add this value before taking the logarithm of the magnitudes.\n\n    """"""\n\n    def __init__(self, filterbank=FILTERBANK, num_bands=NUM_BANDS, fmin=FMIN,\n                 fmax=FMAX, fref=A4, norm_filters=NORM_FILTERS,\n                 unique_filters=UNIQUE_FILTERS, mul=MUL, add=ADD, **kwargs):\n        # pylint: disable=unused-argument\n        self.filterbank = filterbank\n        self.num_bands = num_bands\n        self.fmin = fmin\n        self.fmax = fmax\n        self.fref = fref\n        self.norm_filters = norm_filters\n        self.unique_filters = unique_filters\n        self.mul = mul\n        self.add = add\n\n    def process(self, data, **kwargs):\n        """"""\n        Perform filtering and logarithmic scaling of a spectrogram.\n\n        Parameters\n        ----------\n        data : numpy array\n            Data to be processed.\n        kwargs : dict\n            Keyword arguments passed to\n            :class:`LogarithmicFilteredSpectrogram`.\n\n        Returns\n        -------\n        log_filt_spec : :class:`LogarithmicFilteredSpectrogram` instance\n            Logarithmically scaled filtered spectrogram.\n\n        """"""\n        # update arguments passed to LogarithmicFilteredSpectrogram\n        args = dict(filterbank=self.filterbank, num_bands=self.num_bands,\n                    fmin=self.fmin, fmax=self.fmax, fref=self.fref,\n                    norm_filters=self.norm_filters,\n                    unique_filters=self.unique_filters, mul=self.mul,\n                    add=self.add)\n        args.update(kwargs)\n        # instantiate a LogarithmicFilteredSpectrogram\n        data = LogarithmicFilteredSpectrogram(data, **args)\n        # cache the filterbank\n        self.filterbank = data.filterbank\n        return data\n\n\n# spectrogram difference stuff\nDIFF_RATIO = 0.5\nDIFF_FRAMES = None\nDIFF_MAX_BINS = None\nPOSITIVE_DIFFS = False\n\n\ndef _diff_frames(diff_ratio, hop_size, frame_size, window=np.hanning):\n    """"""\n    Compute the number of `diff_frames` for the given ratio of overlap.\n\n    Parameters\n    ----------\n    diff_ratio : float\n        Ratio of overlap of windows of two consecutive STFT frames.\n    hop_size : int\n        Samples between two adjacent frames.\n    frame_size : int\n        Size of one frames in samples.\n    window : numpy ufunc or array\n        Window function.\n\n    Returns\n    -------\n    diff_frames : int\n        Number of frames to calculate the difference to.\n\n    """"""\n    # calculate the number of diff frames on basis of the diff_ratio\n    # first sample of the window with a higher magnitude than given ratio\n    if hasattr(window, \'__call__\'):\n        # Note: if only a window function is given (default in audio.stft),\n        #       generate a window of size `frame_size` with the given shape\n        window = window(frame_size)\n    sample = np.argmax(window > float(diff_ratio) * max(window))\n    diff_samples = len(window) / 2 - sample\n    # convert to frames, must be at least 1\n    return int(max(1, round(diff_samples / hop_size)))\n\n\nclass SpectrogramDifference(Spectrogram):\n    """"""\n    SpectrogramDifference class.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        Spectrogram.\n    diff_ratio : float, optional\n        Calculate the difference to the frame at which the window used for the\n        STFT yields this ratio of the maximum height.\n    diff_frames : int, optional\n        Calculate the difference to the `diff_frames`-th previous frame (if\n        set, this overrides the value calculated from the `diff_ratio`)\n    diff_max_bins : int, optional\n        Apply a maximum filter with this width (in bins in frequency dimension)\n        to the spectrogram the difference is calculated to.\n    positive_diffs : bool, optional\n        Keep only the positive differences, i.e. set all diff values < 0 to 0.\n    keep_dims : bool, optional\n        Indicate if the dimensions (i.e. shape) of the spectrogram should be\n        kept.\n    kwargs : dict, optional\n        If no :class:`Spectrogram` instance was given, one is instantiated with\n        these additional keyword arguments.\n\n    Notes\n    -----\n    The first `diff_frames` frames will have a value of 0.\n\n    If `keep_dims` is \'True\' the returned difference has the same shape as the\n    spectrogram. This is needed if the diffs should be stacked on top of it.\n    If set to \'False\', the length will be `diff_frames` frames shorter (mostly\n    used by the SpectrogramDifferenceProcessor which first buffers that many\n    frames.\n\n    The SuperFlux algorithm [1]_ uses a maximum filtered spectrogram with 3\n    `diff_max_bins` together with a 24 band logarithmic filterbank to calculate\n    the difference spectrogram with a `diff_ratio` of 0.5.\n\n    The effect of this maximum filter applied to the spectrogram is that the\n    magnitudes are ""widened"" in frequency direction, i.e. the following\n    difference calculation is less sensitive against frequency fluctuations.\n    This effect is exploited to suppress false positive energy fragments\n    originating from vibrato.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck and Gerhard Widmer\n           ""Maximum Filter Vibrato Suppression for Onset Detection""\n           Proceedings of the 16th International Conference on Digital Audio\n           Effects (DAFx), 2013.\n\n    Examples\n    --------\n    To obtain the SuperFlux feature as described above first create a filtered\n    and logarithmically spaced spectrogram:\n\n    >>> spec = LogarithmicFilteredSpectrogram(\'tests/data/audio/sample.wav\', \\\n                                              num_bands=24, fps=200)\n    >>> spec  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    LogarithmicFilteredSpectrogram([[0.82358, 0.86341, ..., 0.02809, 0.02672],\n                                    [0.92514, 0.93211, ..., 0.03607, 0.0317 ],\n                                    ...,\n                                    [1.03826, 0.767  , ..., 0.01814, 0.01138],\n                                    [0.98236, 0.89276, ..., 0.01669, 0.00919]],\n                                    dtype=float32)\n    >>> spec.shape\n    (561, 140)\n\n    Then use the temporal first order difference and apply a maximum filter\n    with 3 bands, keeping only the positive differences (i.e. rise in energy):\n\n    >>> superflux = SpectrogramDifference(spec, diff_max_bins=3, \\\n                                          positive_diffs=True)\n    >>> superflux  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    SpectrogramDifference([[0.     , 0. , ...,  0. ,  0. ],\n                           [0.     , 0. , ...,  0. ,  0. ],\n                           ...,\n                           [0.01941, 0. , ...,  0. ,  0. ],\n                           [0.     , 0. , ...,  0. ,  0. ]], dtype=float32)\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, spectrogram, diff_ratio=DIFF_RATIO,\n                 diff_frames=DIFF_FRAMES, diff_max_bins=DIFF_MAX_BINS,\n                 positive_diffs=POSITIVE_DIFFS, keep_dims=True, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, spectrogram, diff_ratio=DIFF_RATIO,\n                diff_frames=DIFF_FRAMES, diff_max_bins=DIFF_MAX_BINS,\n                positive_diffs=POSITIVE_DIFFS, keep_dims=True, **kwargs):\n        # instantiate a Spectrogram if needed\n        if not isinstance(spectrogram, Spectrogram):\n            # try to instantiate a Spectrogram object\n            spectrogram = Spectrogram(spectrogram, **kwargs)\n\n        # calculate the number of diff frames to use\n        if diff_frames is None:\n            diff_frames = _diff_frames(\n                diff_ratio, hop_size=spectrogram.stft.frames.hop_size,\n                frame_size=spectrogram.stft.frames.frame_size,\n                window=spectrogram.stft.window)\n\n        # apply a maximum filter to diff_spec if needed\n        if diff_max_bins is not None and diff_max_bins > 1:\n            from scipy.ndimage.filters import maximum_filter\n            # widen the spectrogram in frequency dimension\n            size = (1, int(diff_max_bins))\n            diff_spec = maximum_filter(spectrogram, size=size)\n        else:\n            diff_spec = spectrogram\n\n        # calculate the diff\n        if keep_dims:\n            diff = np.zeros_like(spectrogram)\n            diff[diff_frames:] = (spectrogram[diff_frames:] -\n                                  diff_spec[:-diff_frames])\n        else:\n            diff = spectrogram[diff_frames:] - diff_spec[:-diff_frames]\n\n        # positive differences only?\n        if positive_diffs:\n            np.maximum(diff, 0, out=diff)\n\n        # cast as FilteredSpectrogram\n        obj = np.asarray(diff).view(cls)\n        # save additional attributes\n        obj.spectrogram = spectrogram\n        obj.diff_ratio = diff_ratio\n        obj.diff_frames = diff_frames\n        obj.diff_max_bins = diff_max_bins\n        obj.positive_diffs = positive_diffs\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views\n        self.diff_ratio = getattr(obj, \'diff_ratio\', 0.5)\n        self.diff_frames = getattr(obj, \'diff_frames\', None)\n        self.diff_max_bins = getattr(obj, \'diff_max_bins\', None)\n        self.positive_diffs = getattr(obj, \'positive_diffs\', False)\n\n    @property\n    def bin_frequencies(self):\n        """"""Bin frequencies.""""""\n        return self.spectrogram.bin_frequencies\n\n    def positive_diff(self):\n        """"""Positive diff.""""""\n        return np.maximum(self, 0)\n\n\nclass SpectrogramDifferenceProcessor(Processor):\n    """"""\n    Difference Spectrogram Processor class.\n\n    Parameters\n    ----------\n    diff_ratio : float, optional\n        Calculate the difference to the frame at which the window used for the\n        STFT yields this ratio of the maximum height.\n    diff_frames : int, optional\n        Calculate the difference to the `diff_frames`-th previous frame (if\n        set, this overrides the value calculated from the `diff_ratio`)\n    diff_max_bins : int, optional\n        Apply a maximum filter with this width (in bins in frequency dimension)\n        to the spectrogram the difference is calculated to.\n    positive_diffs : bool, optional\n        Keep only the positive differences, i.e. set all diff values < 0 to 0.\n    stack_diffs : numpy stacking function, optional\n        If \'None\', only the differences are returned. If set, the diffs are\n        stacked with the underlying spectrogram data according to the `stack`\n        function:\n\n        - ``np.vstack``\n          the differences and spectrogram are stacked vertically, i.e. in time\n          direction,\n        - ``np.hstack``\n          the differences and spectrogram are stacked horizontally, i.e. in\n          frequency direction,\n        - ``np.dstack``\n          the differences and spectrogram are stacked in depth, i.e. return\n          them as a 3D representation with depth as the third dimension.\n\n    """"""\n\n    def __init__(self, diff_ratio=DIFF_RATIO, diff_frames=DIFF_FRAMES,\n                 diff_max_bins=DIFF_MAX_BINS, positive_diffs=POSITIVE_DIFFS,\n                 stack_diffs=None, **kwargs):\n        # pylint: disable=unused-argument\n        self.diff_ratio = diff_ratio\n        self.diff_frames = diff_frames\n        self.diff_max_bins = diff_max_bins\n        self.positive_diffs = positive_diffs\n        self.stack_diffs = stack_diffs\n        # attributes needed for stateful processing\n        # Note: do not init the buffer here, since it depends on the data\n        self._buffer = None\n\n    def __getstate__(self):\n        # copy everything to a picklable object\n        state = self.__dict__.copy()\n        # do not pickle attributes needed for stateful processing\n        state.pop(\'_buffer\', None)\n        return state\n\n    def __setstate__(self, state):\n        # restore pickled instance attributes\n        self.__dict__.update(state)\n        # add non-pickled attributes needed for stateful processing\n        self._buffer = None\n\n    def process(self, data, reset=True, **kwargs):\n        """"""\n        Perform a temporal difference calculation on the given data.\n\n        Parameters\n        ----------\n        data : numpy array\n            Data to be processed.\n        reset : bool, optional\n            Reset the spectrogram buffer before computing the difference.\n        kwargs : dict\n            Keyword arguments passed to :class:`SpectrogramDifference`.\n\n        Returns\n        -------\n        diff : :class:`SpectrogramDifference` instance\n            Spectrogram difference.\n\n        Notes\n        -----\n        If `reset` is \'True\', the first `diff_frames` differences will be 0.\n\n        """"""\n        # update arguments passed to SpectrogramDifference\n        args = dict(diff_ratio=self.diff_ratio, diff_frames=self.diff_frames,\n                    diff_max_bins=self.diff_max_bins,\n                    positive_diffs=self.positive_diffs)\n        args.update(kwargs)\n        # calculate the number of diff frames\n        if self.diff_frames is None:\n            # Note: use diff_ration from args, not self.diff_ratio\n            self.diff_frames = _diff_frames(\n                args[\'diff_ratio\'], frame_size=data.stft.frames.frame_size,\n                hop_size=data.stft.frames.hop_size, window=data.stft.window)\n        # init buffer or shift it\n        if self._buffer is None or reset:\n            # put diff_frames infs before the data (will be replaced by 0s)\n            init = np.empty((self.diff_frames, data.shape[1]))\n            init[:] = np.inf\n            data = np.insert(data, 0, init, axis=0)\n            # use the data for the buffer\n            self._buffer = BufferProcessor(init=data)\n        else:\n            # shift buffer by length of data and put new data at end of buffer\n            data = self._buffer(data)\n        # compute difference based on this data (reduce 1st dimension)\n        diff = SpectrogramDifference(data, keep_dims=False, **args)\n        # set all inf-diffs to 0\n        diff[np.isinf(diff)] = 0\n        # stack the diff and the data if needed\n        if self.stack_diffs is None:\n            return diff\n        # Note: don\'t use `data` directly, because it could be a str\n        #       we ave to access diff.spectrogram (i.e. converted data)\n        return self.stack_diffs((diff.spectrogram[self.diff_frames:], diff))\n\n    def reset(self):\n        """"""Reset the SpectrogramDifferenceProcessor.""""""\n        # reset cached spectrogram data\n        self._buffer = None\n\n    @staticmethod\n    def add_arguments(parser, diff=None, diff_ratio=None, diff_frames=None,\n                      diff_max_bins=None, positive_diffs=None):\n        """"""\n        Add spectrogram difference related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        diff : bool, optional\n            Take the difference of the spectrogram.\n        diff_ratio : float, optional\n            Calculate the difference to the frame at which the window used for\n            the STFT yields this ratio of the maximum height.\n        diff_frames : int, optional\n            Calculate the difference to the `diff_frames`-th previous frame (if\n            set, this overrides the value calculated from the `diff_ratio`)\n        diff_max_bins : int, optional\n            Apply a maximum filter with this width (in bins in frequency\n            dimension) to the spectrogram the difference is calculated to.\n        positive_diffs : bool, optional\n            Keep only the positive differences, i.e. set all diff values < 0\n            to 0.\n\n        Returns\n        -------\n        argparse argument group\n            Spectrogram difference argument parser group.\n\n        Notes\n        -----\n        Parameters are included in the group only if they are not \'None\'.\n\n        Only the `diff_frames` parameter behaves differently, it is included\n        if either the `diff_ratio` is set or a value != \'None\' is given.\n\n        """"""\n        # add diff related options to the existing parser\n        g = parser.add_argument_group(\'spectrogram difference arguments\')\n        # diff\n        if diff is True:\n            g.add_argument(\'--no_diff\', dest=\'diff\', action=\'store_false\',\n                           help=\'use the spectrogram [default=differences \'\n                                \'of the spectrogram]\')\n        elif diff is False:\n            g.add_argument(\'--diff\', action=\'store_true\',\n                           help=\'use the differences of the spectrogram \'\n                                \'[default=spectrogram]\')\n        # diff ratio\n        if diff_ratio is not None:\n            g.add_argument(\'--diff_ratio\', action=\'store\', type=float,\n                           default=diff_ratio,\n                           help=\'calculate the difference to the frame at \'\n                                \'which the window of the STFT have this ratio \'\n                                \'of the maximum height \'\n                                \'[default=%(default).1f]\')\n        # diff frames\n        if diff_ratio is not None or diff_frames:\n            g.add_argument(\'--diff_frames\', action=\'store\', type=int,\n                           default=diff_frames,\n                           help=\'calculate the difference to the N-th previous\'\n                                \' frame (this overrides the value calculated \'\n                                \'with `diff_ratio`) [default=%(default)s]\')\n        # positive diffs\n        if positive_diffs is True:\n            g.add_argument(\'--all_diffs\', dest=\'positive_diffs\',\n                           action=\'store_false\',\n                           help=\'keep both positive and negative diffs \'\n                                \'[default=only the positive diffs]\')\n        elif positive_diffs is False:\n            g.add_argument(\'--positive_diffs\', action=\'store_true\',\n                           help=\'keep only positive diffs \'\n                                \'[default=positive and negative diffs]\')\n        # add maximum filter related options to the existing parser\n        if diff_max_bins is not None:\n            g.add_argument(\'--max_bins\', action=\'store\', type=int,\n                           dest=\'diff_max_bins\', default=diff_max_bins,\n                           help=\'apply a maximum filter with this width (in \'\n                                \'frequency bins) [default=%(default)d]\')\n        # return the group\n        return g\n\n\nclass SuperFluxProcessor(SequentialProcessor):\n    """"""\n    Spectrogram processor which sets the default values suitable for the\n    SuperFlux algorithm.\n\n    """"""\n    # pylint: disable=too-many-ancestors\n\n    def __init__(self, **kwargs):\n        from .stft import ShortTimeFourierTransformProcessor\n        # set the default values (can be overwritten if set)\n        # we need an un-normalized LogarithmicFilterbank with 24 bands\n        filterbank = kwargs.pop(\'filterbank\', FILTERBANK)\n        num_bands = kwargs.pop(\'num_bands\', 24)\n        norm_filters = kwargs.pop(\'norm_filters\', False)\n        # we want max filtered diffs\n        diff_ratio = kwargs.pop(\'diff_ratio\', 0.5)\n        diff_max_bins = kwargs.pop(\'diff_max_bins\', 3)\n        positive_diffs = kwargs.pop(\'positive_diffs\', True)\n        # processing chain\n        stft = ShortTimeFourierTransformProcessor(**kwargs)\n        spec = SpectrogramProcessor(**kwargs)\n        filt = FilteredSpectrogramProcessor(filterbank=filterbank,\n                                            num_bands=num_bands,\n                                            norm_filters=norm_filters,\n                                            **kwargs)\n        log = LogarithmicSpectrogramProcessor(**kwargs)\n        diff = SpectrogramDifferenceProcessor(diff_ratio=diff_ratio,\n                                              diff_max_bins=diff_max_bins,\n                                              positive_diffs=positive_diffs,\n                                              **kwargs)\n        # sequentially process everything\n        super(SuperFluxProcessor, self).__init__([stft, spec, filt, log, diff])\n\n\nclass MultiBandSpectrogram(FilteredSpectrogram):\n    """"""\n    MultiBandSpectrogram class.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        Spectrogram.\n    crossover_frequencies : list or numpy array\n        List of crossover frequencies at which the `spectrogram` is split\n        into multiple bands.\n    fmin : float, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filter bands of the filterbank to area 1.\n    unique_filters : bool, optional\n        Indicate if the filterbank should contain only unique filters, i.e.\n        remove duplicate filters resulting from insufficient resolution at\n        low frequencies.\n    kwargs : dict, optional\n        If no :class:`Spectrogram` instance was given, one is instantiated\n        with these additional keyword arguments.\n\n    Notes\n    -----\n    The MultiBandSpectrogram is implemented as a :class:`Spectrogram` which\n    uses a :class:`.audio.filters.RectangularFilterbank` to combine multiple\n    frequency bins.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, spectrogram, crossover_frequencies, fmin=FMIN,\n                 fmax=FMAX, norm_filters=NORM_FILTERS,\n                 unique_filters=UNIQUE_FILTERS, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, spectrogram, crossover_frequencies, fmin=FMIN, fmax=FMAX,\n                norm_filters=NORM_FILTERS, unique_filters=UNIQUE_FILTERS,\n                **kwargs):\n        from .filters import RectangularFilterbank\n        # instantiate a Spectrogram if needed\n        if not isinstance(spectrogram, Spectrogram):\n            spectrogram = Spectrogram(spectrogram, **kwargs)\n        # create a rectangular filterbank\n        filterbank = RectangularFilterbank(spectrogram.bin_frequencies,\n                                           crossover_frequencies,\n                                           fmin=fmin, fmax=fmax,\n                                           norm_filters=norm_filters,\n                                           unique_filters=unique_filters)\n        # filter the spectrogram\n        data = np.dot(spectrogram, filterbank)\n        # cast as FilteredSpectrogram\n        obj = np.asarray(data).view(cls)\n        # save additional attributes\n        obj.spectrogram = spectrogram\n        obj.filterbank = filterbank\n        obj.crossover_frequencies = crossover_frequencies\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views\n        self.spectrogram = getattr(obj, \'spectrogram\', None)\n        self.filterbank = getattr(obj, \'filterbank\', None)\n        self.crossover_frequencies = getattr(obj, \'crossover_frequencies\',\n                                             None)\n\n\nclass MultiBandSpectrogramProcessor(Processor):\n    """"""\n    Spectrogram processor which combines the spectrogram magnitudes into\n    multiple bands.\n\n    Parameters\n    ----------\n    crossover_frequencies : list or numpy array\n        List of crossover frequencies at which a spectrogram is split into\n        the individual bands.\n    fmin : float, optional\n        Minimum frequency of the filterbank [Hz].\n    fmax : float, optional\n        Maximum frequency of the filterbank [Hz].\n    norm_filters : bool, optional\n        Normalize the filter bands of the filterbank to area 1.\n    unique_filters : bool, optional\n        Indicate if the filterbank should contain only unique filters, i.e.\n        remove duplicate filters resulting from insufficient resolution at\n        low frequencies.\n\n    """"""\n\n    def __init__(self, crossover_frequencies, fmin=FMIN, fmax=FMAX,\n                 norm_filters=NORM_FILTERS, unique_filters=UNIQUE_FILTERS,\n                 **kwargs):\n        # pylint: disable=unused-argument\n        self.crossover_frequencies = np.array(crossover_frequencies)\n        self.fmin = fmin\n        self.fmax = fmax\n        self.norm_filters = norm_filters\n        self.unique_filters = unique_filters\n\n    def process(self, data, **kwargs):\n        """"""\n        Return the a multi-band representation of the given data.\n\n        Parameters\n        ----------\n        data : numpy array\n            Data to be processed.\n        kwargs : dict\n            Keyword arguments passed to :class:`MultiBandSpectrogram`.\n\n        Returns\n        -------\n        multi_band_spec : :class:`MultiBandSpectrogram` instance\n            Spectrogram split into multiple bands.\n\n        """"""\n        # update arguments passed to MultiBandSpectrogram\n        args = dict(crossover_frequencies=self.crossover_frequencies,\n                    fmin=self.fmin, fmax=self.fmax,\n                    norm_filters=self.norm_filters,\n                    unique_filters=self.unique_filters)\n        args.update(kwargs)\n        # instantiate a MultiBandSpectrogram\n        return MultiBandSpectrogram(data, **args)\n\n\nclass SemitoneBandpassSpectrogram(FilteredSpectrogram):\n    """"""\n    Construct a semitone spectrogram by using a time domain filterbank of\n    bandpass filters as described in [1]_.\n\n    Parameters\n    ----------\n    signal : Signal\n        Signal instance.\n    fps : float, optional\n        Frame rate of the spectrogram [Hz].\n    fmin : float, optional\n        Lowest frequency of the spectrogram [Hz].\n    fmax : float, optional\n        Highest frequency of the spectrogram [Hz].\n\n    References\n    ----------\n    .. [1] Meinard M\xc3\xbcller,\n           ""Information retrieval for music and motion"", Springer, 2007.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, signal, fps=50., fmin=27.5, fmax=4200.):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, signal, fps=50., fmin=27.5, fmax=4200.):\n        from scipy.signal import filtfilt\n        from .filters import SemitoneBandpassFilterbank\n        from .signal import FramedSignal, Signal, resample\n        # check if we got a mono Signal\n        if not isinstance(signal, Signal) or signal.num_channels != 1:\n            signal = Signal(signal, num_channels=1)\n        sample_rate = float(signal.sample_rate)\n        # keep a reference to the original signal\n        signal_ = signal\n        # determine how many frames the filtered signal will have\n        num_frames = np.round(len(signal) * fps / sample_rate) + 1\n        # compute the energy of the frames of the bandpass filtered signal\n        filterbank = SemitoneBandpassFilterbank(fmin=fmin, fmax=fmax)\n        bands = []\n        for filt, band_sample_rate in zip(filterbank.filters,\n                                          filterbank.band_sample_rates):\n            # frames should overlap 50%\n            frame_size = np.round(2 * band_sample_rate / float(fps))\n            # down-sample audio if needed\n            if band_sample_rate != signal.sample_rate:\n                signal = resample(signal_, band_sample_rate)\n            # filter the signal\n            b, a = filt\n            filtered_signal = filtfilt(b, a, signal)\n            # normalise the signal if it has an integer dtype\n            try:\n                filtered_signal /= np.iinfo(signal.dtype).max\n            except ValueError:\n                pass\n            # compute the energy of the filtered signal\n            # Note: 1) the energy of the signal is computed with respect to the\n            #          reference sampling rate as in the MATLAB chroma toolbox\n            #       2) we do not sum here, but rather after splitting the\n            #          signal into overlapping frames to avoid doubled\n            #          computation due to the overlapping frames\n            filtered_signal = filtered_signal ** 2 / band_sample_rate * 22050.\n            # split into overlapping frames\n            frames = FramedSignal(filtered_signal, frame_size=frame_size,\n                                  fps=fps, sample_rate=band_sample_rate,\n                                  num_frames=num_frames)\n            # finally sum the energy of all frames\n            bands.append(np.sum(frames, axis=1))\n        # cast as SemitoneBandpassSpectrogram\n        obj = np.vstack(bands).T.view(cls)\n        # save additional attributes\n        obj.filterbank = filterbank\n        obj.fps = fps\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here\n        self.filterbank = getattr(obj, \'filterbank\', None)\n        self.fps = getattr(obj, \'fps\', None)\n'"
madmom/audio/stft.py,22,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains Short-Time Fourier Transform (STFT) related functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport warnings\n\nimport numpy as np\nimport scipy.fftpack as fftpack\n\ntry:\n    from pyfftw.builders import rfft as rfft_builder\nexcept ImportError:\n    def rfft_builder(*args, **kwargs):\n        return None\n\nfrom ..processors import Processor\nfrom .signal import Signal, FramedSignal\n\nSTFT_DTYPE = np.complex64\n\n\ndef fft_frequencies(num_fft_bins, sample_rate):\n    """"""\n    Frequencies of the FFT bins.\n\n    Parameters\n    ----------\n    num_fft_bins : int\n        Number of FFT bins (i.e. half the FFT length).\n    sample_rate : float\n        Sample rate of the signal.\n\n    Returns\n    -------\n    fft_frequencies : numpy array\n        Frequencies of the FFT bins [Hz].\n\n    """"""\n    return np.fft.fftfreq(num_fft_bins * 2, 1. / sample_rate)[:num_fft_bins]\n\n\ndef stft(frames, window, fft_size=None, circular_shift=False,\n         include_nyquist=False, fftw=None):\n    """"""\n    Calculates the complex Short-Time Fourier Transform (STFT) of the given\n    framed signal.\n\n    Parameters\n    ----------\n    frames : numpy array or iterable, shape (num_frames, frame_size)\n        Framed signal (e.g. :class:`FramedSignal` instance)\n    window : numpy array, shape (frame_size,)\n        Window (function).\n    fft_size : int, optional\n        FFT size (should be a power of 2); if \'None\', the \'frame_size\' given\n        by `frames` is used; if the given `fft_size` is greater than the\n        \'frame_size\', the frames are zero-padded, if smaller truncated.\n    circular_shift : bool, optional\n        Circular shift the individual frames before performing the FFT;\n        needed for correct phase.\n    include_nyquist : bool, optional\n        Include the Nyquist frequency bin (sample rate / 2) in returned STFT.\n    fftw : :class:`pyfftw.FFTW` instance, optional\n        If a :class:`pyfftw.FFTW` object is given it is used to compute the\n        STFT with the FFTW library. Requires \'pyfftw\'.\n\n    Returns\n    -------\n    stft : numpy array, shape (num_frames, frame_size)\n        The complex STFT of the framed signal.\n\n    """"""\n    # check for correct shape of input\n    if frames.ndim != 2:\n        # TODO: add multi-channel support\n        raise ValueError(\'frames must be a 2D array or iterable, got %s with \'\n                         \'shape %s.\' % (type(frames), frames.shape))\n\n    # shape of the frames\n    num_frames, frame_size = frames.shape\n\n    # FFT size to use\n    if fft_size is None:\n        fft_size = frame_size\n    # number of FFT bins to return\n    num_fft_bins = fft_size >> 1\n    if include_nyquist:\n        num_fft_bins += 1\n\n    # size of the FFT circular shift (needed for correct phase)\n    if circular_shift:\n        fft_shift = frame_size >> 1\n\n    # init objects\n    data = np.empty((num_frames, num_fft_bins), STFT_DTYPE)\n\n    # iterate over all frames\n    for f, frame in enumerate(frames):\n        if circular_shift:\n            # if we need to circular shift the signal for correct phase, we\n            # first multiply the signal frame with the window (or just use it\n            # as it is if no window function is given)\n            if window is not None:\n                signal = np.multiply(frame, window)\n            else:\n                signal = frame\n            # then swap the two halves of the windowed signal; if the FFT size\n            # is bigger than the frame size, we need to pad the (windowed)\n            # signal with additional zeros in between the two halves\n            fft_signal = np.zeros(fft_size)\n            fft_signal[:fft_shift] = signal[fft_shift:]\n            fft_signal[-fft_shift:] = signal[:fft_shift]\n        else:\n            # multiply the signal frame with the window and or save it directly\n            # to fft_signal (i.e. bypass the additional copying step above)\n            if window is not None:\n                fft_signal = np.multiply(frame, window)\n            else:\n                fft_signal = frame\n        # perform DFT\n        if fftw:\n            data[f] = fftw(fft_signal)[:num_fft_bins]\n        else:\n            data[f] = fftpack.fft(fft_signal, fft_size, axis=0)[:num_fft_bins]\n    # return STFT\n    return data\n\n\ndef phase(stft):\n    """"""\n    Returns the phase of the complex STFT of a signal.\n\n    Parameters\n    ----------\n    stft : numpy array, shape (num_frames, frame_size)\n        The complex STFT of a signal.\n\n    Returns\n    -------\n    phase : numpy array\n        Phase of the STFT.\n\n    """"""\n    return np.angle(stft)\n\n\ndef local_group_delay(phase):\n    """"""\n    Returns the local group delay of the phase of a signal.\n\n    Parameters\n    ----------\n    phase : numpy array, shape (num_frames, frame_size)\n        Phase of the STFT of a signal.\n\n    Returns\n    -------\n    lgd : numpy array\n        Local group delay of the phase.\n\n    """"""\n    # check for correct shape of input\n    if phase.ndim != 2:\n        raise ValueError(\'phase must be a 2D array\')\n    # unwrap phase\n    unwrapped_phase = np.unwrap(phase)\n    # local group delay is the derivative over frequency\n    unwrapped_phase[:, :-1] -= unwrapped_phase[:, 1:]\n    # set the highest frequency to 0\n    unwrapped_phase[:, -1] = 0\n    # return the local group delay\n    return unwrapped_phase\n\n\n# alias\nlgd = local_group_delay\n\n\n# mixin providing `num_frames` & `num_bins` properties\nclass _PropertyMixin(object):\n    # pylint: disable=missing-docstring\n\n    @property\n    def num_frames(self):\n        """"""Number of frames.""""""\n        return len(self)\n\n    @property\n    def num_bins(self):\n        """"""Number of bins.""""""\n        return int(self.shape[1])\n\n\n# short-time Fourier transform class\nclass ShortTimeFourierTransform(_PropertyMixin, np.ndarray):\n    """"""\n    ShortTimeFourierTransform class.\n\n    Parameters\n    ----------\n    frames : :class:`.audio.signal.FramedSignal` instance\n        Framed signal.\n    window : numpy ufunc or numpy array, optional\n        Window (function); if a function (e.g. `np.hanning`) is given, a window\n        with the frame size of `frames` and the given shape is created.\n    fft_size : int, optional\n        FFT size (should be a power of 2); if \'None\', the `frame_size` given by\n        `frames` is used, if the given `fft_size` is greater than the\n        `frame_size`, the frames are zero-padded accordingly.\n    circular_shift : bool, optional\n        Circular shift the individual frames before performing the FFT;\n        needed for correct phase.\n    include_nyquist : bool, optional\n        Include the Nyquist frequency bin (sample rate / 2).\n    fftw : :class:`pyfftw.FFTW` instance, optional\n        If a :class:`pyfftw.FFTW` object is given it is used to compute the\n        STFT with the FFTW library. If \'None\', a new :class:`pyfftw.FFTW`\n        object is built. Requires \'pyfftw\'.\n    kwargs : dict, optional\n        If no :class:`.audio.signal.FramedSignal` instance was given, one is\n        instantiated with these additional keyword arguments.\n\n    Notes\n    -----\n    If the :class:`Signal` (wrapped in the :class:`FramedSignal`) has an\n    integer dtype, the `window` is automatically scaled as if the `signal` had\n    a float dtype with the values being in the range [-1, 1]. This results in\n    same valued STFTs independently of the dtype of the signal. On the other\n    hand, this prevents extra memory consumption since the data-type of the\n    signal does not need to be converted (and if no decoding is needed, the\n    audio signal can be memory-mapped).\n\n    Examples\n    --------\n    Create a :class:`ShortTimeFourierTransform` from a :class:`Signal` or\n    :class:`FramedSignal`:\n\n    >>> sig = Signal(\'tests/data/audio/sample.wav\')\n    >>> sig\n    Signal([-2494, -2510, ...,   655,   639], dtype=int16)\n    >>> frames = FramedSignal(sig, frame_size=2048, hop_size=441)\n    >>> frames  # doctest: +ELLIPSIS\n    <madmom.audio.signal.FramedSignal object at 0x...>\n    >>> stft = ShortTimeFourierTransform(frames)\n    >>> stft  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS +NORMALIZE_FFT\n    ShortTimeFourierTransform([[-3.15249+0.j     ,  2.62216-3.02425j, ...,\n                                -0.03634-0.00005j,  0.0367 +0.00029j],\n                               [-4.28429+0.j     ,  2.02009+2.01264j, ...,\n                                -0.01981-0.00933j, -0.00536+0.02162j],\n                               ...,\n                               [-4.92274+0.j     ,  4.09839-9.42525j, ...,\n                                 0.0055 -0.00257j,  0.00137+0.00577j],\n                               [-9.22709+0.j     ,  8.76929+4.0005j , ...,\n                                 0.00981-0.00014j, -0.00984+0.00006j]],\n                              dtype=complex64)\n\n    A ShortTimeFourierTransform can be instantiated directly from a file name:\n\n    >>> stft = ShortTimeFourierTransform(\'tests/data/audio/sample.wav\')\n    >>> stft  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    ShortTimeFourierTransform([[...]], dtype=complex64)\n\n    Doing the same with a Signal of float data-type will result in a STFT of\n    same value range (rounding errors will occur of course):\n\n    >>> sig = Signal(\'tests/data/audio/sample.wav\', dtype=np.float)\n    >>> sig  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    Signal([-0.07611, -0.0766 , ...,  0.01999,  0.0195 ])\n    >>> frames = FramedSignal(sig, frame_size=2048, hop_size=441)\n    >>> frames  # doctest: +ELLIPSIS\n    <madmom.audio.signal.FramedSignal object at 0x...>\n    >>> stft = ShortTimeFourierTransform(frames)\n    >>> stft  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS +NORMALIZE_FFT\n    ShortTimeFourierTransform([[-3.1524 +0.j     ,  2.62208-3.02415j, ...,\n                                -0.03633-0.00005j,  0.0367 +0.00029j],\n                               [-4.28416+0.j     ,  2.02003+2.01257j, ...,\n                                -0.01981-0.00933j, -0.00536+0.02162j],\n                               ...,\n                               [-4.92259+0.j     ,  4.09827-9.42496j, ...,\n                                 0.0055 -0.00257j,  0.00137+0.00577j],\n                               [-9.22681+0.j     ,  8.76902+4.00038j, ...,\n                                 0.00981-0.00014j, -0.00984+0.00006j]],\n                              dtype=complex64)\n\n    Additional arguments are passed to :class:`FramedSignal` and\n    :class:`Signal` respectively:\n\n    >>> stft = ShortTimeFourierTransform(\'tests/data/audio/sample.wav\', \\\nframe_size=2048, fps=100, sample_rate=22050)\n    >>> stft.frames  # doctest: +ELLIPSIS\n    <madmom.audio.signal.FramedSignal object at 0x...>\n    >>> stft.frames.frame_size\n    2048\n    >>> stft.frames.hop_size\n    220.5\n    >>> stft.frames.signal.sample_rate\n    22050\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, frames, window=np.hanning, fft_size=None,\n                 circular_shift=False, include_nyquist=False, fft_window=None,\n                 fftw=None, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, frames, window=np.hanning, fft_size=None,\n                circular_shift=False, include_nyquist=False, fft_window=None,\n                fftw=None, **kwargs):\n        # pylint: disable=unused-argument\n        if isinstance(frames, ShortTimeFourierTransform):\n            # already a STFT, use the frames thereof\n            frames = frames.frames\n        # instantiate a FramedSignal if needed\n        if not isinstance(frames, FramedSignal):\n            frames = FramedSignal(frames, **kwargs)\n\n        # size of the frames\n        frame_size = frames.shape[1]\n\n        if fft_window is None:\n            # if a callable window function is given, use the frame size to\n            # create a window of this size\n            if hasattr(window, \'__call__\'):\n                window = window(frame_size)\n            # window used for FFT\n            try:\n                # if the signal is not scaled, scale the window accordingly\n                max_range = float(np.iinfo(frames.signal.dtype).max)\n                try:\n                    # scale the window by the max_range\n                    fft_window = window / max_range\n                except TypeError:\n                    # if the window is None we can\'t scale it, thus create a\n                    # uniform window and scale it accordingly\n                    fft_window = np.ones(frame_size) / max_range\n            except ValueError:\n                # no scaling needed, use the window as is (can also be None)\n                fft_window = window\n\n        # use FFTW to speed up STFT\n        try:\n            # Note: use fft_window instead of a frame because it has already\n            #       the correct dtype (frames are multiplied with this window)\n            fftw = rfft_builder(fft_window, fft_size, axis=0)\n        except AttributeError:\n            pass\n        # calculate the STFT\n        data = stft(frames, fft_window, fft_size=fft_size,\n                    circular_shift=circular_shift,\n                    include_nyquist=include_nyquist, fftw=fftw)\n\n        # cast as ShortTimeFourierTransform\n        obj = np.asarray(data).view(cls)\n        # save the other parameters\n        obj.frames = frames\n        obj.window = window\n        obj.fft_window = fft_window\n        obj.fft_size = fft_size if fft_size else frame_size\n        obj.circular_shift = circular_shift\n        obj.include_nyquist = include_nyquist\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views\n        self.frames = getattr(obj, \'frames\', None)\n        self.window = getattr(obj, \'window\', np.hanning)\n        self.fft_window = getattr(obj, \'fft_window\', None)\n        self.fftw = getattr(obj, \'fftw\', None)\n        self.fft_size = getattr(obj, \'fft_size\', None)\n        self.circular_shift = getattr(obj, \'circular_shift\', False)\n\n    @property\n    def bin_frequencies(self):\n        """"""Bin frequencies.""""""\n        return fft_frequencies(self.num_bins, self.frames.signal.sample_rate)\n\n    def spec(self, **kwargs):\n        """"""\n        Returns the magnitude spectrogram of the STFT.\n\n        Parameters\n        ----------\n        kwargs : dict, optional\n            Keyword arguments passed to\n            :class:`.audio.spectrogram.Spectrogram`.\n\n        Returns\n        -------\n        spec : :class:`.audio.spectrogram.Spectrogram`\n            :class:`.audio.spectrogram.Spectrogram` instance.\n\n        """"""\n        # import Spectrogram here, otherwise we have circular imports\n        from .spectrogram import Spectrogram\n        return Spectrogram(self, **kwargs)\n\n    def phase(self, **kwargs):\n        """"""\n        Returns the phase of the STFT.\n\n        Parameters\n        ----------\n        kwargs : dict, optional\n            keyword arguments passed to :class:`Phase`.\n\n        Returns\n        -------\n        phase : :class:`Phase`\n            :class:`Phase` instance.\n\n        """"""\n        return Phase(self, **kwargs)\n\n\nSTFT = ShortTimeFourierTransform\n\n\nclass ShortTimeFourierTransformProcessor(Processor):\n    """"""\n    ShortTimeFourierTransformProcessor class.\n\n    Parameters\n    ----------\n    window : numpy ufunc, optional\n        Window function.\n    fft_size : int, optional\n        FFT size (should be a power of 2); if \'None\', it is determined by the\n        size of the frames; if is greater than the frame size, the frames are\n        zero-padded accordingly.\n    circular_shift : bool, optional\n        Circular shift the individual frames before performing the FFT;\n        needed for correct phase.\n    include_nyquist : bool, optional\n        Include the Nyquist frequency bin (sample rate / 2).\n\n    Examples\n    --------\n    Create a :class:`ShortTimeFourierTransformProcessor` and call it with\n    either a file name or a the output of a (Framed-)SignalProcessor to obtain\n    a :class:`ShortTimeFourierTransform` instance.\n\n    >>> proc = ShortTimeFourierTransformProcessor()\n    >>> stft = proc(\'tests/data/audio/sample.wav\')\n    >>> stft  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS +NORMALIZE_FFT\n    ShortTimeFourierTransform([[-3.15249+0.j     ,  2.62216-3.02425j, ...,\n                                -0.03634-0.00005j,  0.0367 +0.00029j],\n                               [-4.28429+0.j     ,  2.02009+2.01264j, ...,\n                                -0.01981-0.00933j, -0.00536+0.02162j],\n                               ...,\n                               [-4.92274+0.j     ,  4.09839-9.42525j, ...,\n                                 0.0055 -0.00257j,  0.00137+0.00577j],\n                               [-9.22709+0.j     ,  8.76929+4.0005j , ...,\n                                 0.00981-0.00014j, -0.00984+0.00006j]],\n                              dtype=complex64)\n\n    """"""\n\n    def __init__(self, window=np.hanning, fft_size=None, circular_shift=False,\n                 include_nyquist=False, **kwargs):\n        # pylint: disable=unused-argument\n        self.window = window\n        self.fft_size = fft_size\n        self.circular_shift = circular_shift\n        self.include_nyquist = include_nyquist\n        # caching only, not intended for general use\n        self.fft_window = None\n        self.fftw = None\n\n    def process(self, data, **kwargs):\n        """"""\n        Perform FFT on a framed signal and return the STFT.\n\n        Parameters\n        ----------\n        data : numpy array\n            Data to be processed.\n        kwargs : dict, optional\n            Keyword arguments passed to :class:`ShortTimeFourierTransform`.\n\n        Returns\n        -------\n        stft : :class:`ShortTimeFourierTransform`\n            :class:`ShortTimeFourierTransform` instance.\n\n        """"""\n        # instantiate a STFT\n        data = ShortTimeFourierTransform(data, window=self.window,\n                                         fft_size=self.fft_size,\n                                         circular_shift=self.circular_shift,\n                                         include_nyquist=self.include_nyquist,\n                                         fft_window=self.fft_window,\n                                         fftw=self.fftw, **kwargs)\n        # cache the window used for FFT\n        # Note: depending on the signal this may be scaled already\n        self.fft_window = data.fft_window\n        self.fftw = data.fftw\n        return data\n\n    @staticmethod\n    def add_arguments(parser, window=None, fft_size=None):\n        """"""\n        Add STFT related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser.\n        window : numpy ufunc, optional\n            Window function.\n        fft_size : int, optional\n            Use this size for FFT (should be a power of 2).\n\n        Returns\n        -------\n        argparse argument group\n            STFT argument parser group.\n\n        Notes\n        -----\n        Parameters are included in the group only if they are not \'None\'.\n\n        """"""\n        # add filterbank related options to the existing parser\n        g = parser.add_argument_group(\'short-time Fourier transform arguments\')\n        if window is not None:\n            g.add_argument(\'--window\', dest=\'window\',\n                           action=\'store\', default=window,\n                           help=\'window function to use for FFT\')\n        if fft_size is not None:\n            g.add_argument(\'--fft_size\', action=\'store\', type=int,\n                           default=fft_size,\n                           help=\'use this size for FFT (should be a power of \'\n                                \'2) [default=%(default)i]\')\n        # return the group\n        return g\n\n\nSTFTProcessor = ShortTimeFourierTransformProcessor\n\n\n# phase of STFT\nclass Phase(_PropertyMixin, np.ndarray):\n    """"""\n    Phase class.\n\n    Parameters\n    ----------\n    stft : :class:`ShortTimeFourierTransform` instance\n         :class:`ShortTimeFourierTransform` instance.\n    kwargs : dict, optional\n        If no :class:`ShortTimeFourierTransform` instance was given, one is\n        instantiated with these additional keyword arguments.\n\n    Examples\n    --------\n    Create a :class:`Phase` from a :class:`ShortTimeFourierTransform` (or\n    anything it can be instantiated from:\n\n    >>> stft = ShortTimeFourierTransform(\'tests/data/audio/sample.wav\')\n    >>> phase = Phase(stft)\n    >>> phase  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS +NORMALIZE_FFT\n    Phase([[ 3.14159, -0.85649, ..., -3.14016,  0.00779],\n           [ 3.14159,  0.78355, ..., -2.70136,  1.81393],\n           ...,\n           [ 3.14159, -1.16063, ..., -0.4373 ,  1.33774],\n           [ 3.14159,  0.42799, ..., -0.0142 ,  3.13592]], dtype=float32)\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, stft, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, stft, **kwargs):\n        # pylint: disable=unused-argument\n        # if a Phase object is given use its STFT\n        if isinstance(stft, Phase):\n            stft = stft.stft\n        # instantiate a ShortTimeFourierTransform object if needed\n        if not isinstance(stft, ShortTimeFourierTransform):\n            # set circular_shift if it was not disables explicitly\n            circular_shift = kwargs.pop(\'circular_shift\', True)\n            stft = ShortTimeFourierTransform(stft,\n                                             circular_shift=circular_shift,\n                                             **kwargs)\n        # TODO: just recalculate with circular_shift set?\n        if not stft.circular_shift:\n            warnings.warn(""`circular_shift` of the STFT must be set to \'True\' ""\n                          ""for correct phase"", RuntimeWarning)\n        # process the STFT and cast the result as Phase\n        obj = np.asarray(phase(stft)).view(cls)\n        # save additional attributes\n        obj.stft = stft\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views\n        self.stft = getattr(obj, \'stft\', None)\n\n    @property\n    def bin_frequencies(self):\n        """"""Bin frequencies.""""""\n        return self.stft.bin_frequencies\n\n    def local_group_delay(self, **kwargs):\n        """"""\n        Returns the local group delay of the phase.\n\n        Parameters\n        ----------\n        kwargs : dict, optional\n            Keyword arguments passed to :class:`LocalGroupDelay`.\n\n        Returns\n        -------\n        lgd : :class:`LocalGroupDelay` instance\n            :class:`LocalGroupDelay` instance.\n\n        """"""\n        return LocalGroupDelay(self, **kwargs)\n\n    lgd = local_group_delay\n\n\n# local group delay of STFT\nclass LocalGroupDelay(_PropertyMixin, np.ndarray):\n    """"""\n    Local Group Delay class.\n\n    Parameters\n    ----------\n    stft : :class:`Phase` instance\n         :class:`Phase` instance.\n    kwargs : dict, optional\n        If no :class:`Phase` instance was given, one is instantiated with\n        these additional keyword arguments.\n\n    Examples\n    --------\n    Create a :class:`LocalGroupDelay` from a :class:`ShortTimeFourierTransform`\n    (or anything it can be instantiated from:\n\n    >>> stft = ShortTimeFourierTransform(\'tests/data/audio/sample.wav\')\n    >>> lgd = LocalGroupDelay(stft)\n    >>> lgd  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    LocalGroupDelay([[-2.2851 , -2.25605, ...,  3.13525,  0. ],\n                     [ 2.35804,  2.53786, ...,  1.76788,  0. ],\n                     ...,\n                     [-1.98..., -2.93039, ..., -1.77505,  0. ],\n                     [ 2.7136 ,  2.60925, ...,  3.13318,  0. ]])\n\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, phase, **kwargs):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, phase, **kwargs):\n        # pylint: disable=unused-argument\n        # try to instantiate a Phase object\n        if not isinstance(stft, Phase):\n            phase = Phase(phase, circular_shift=True, **kwargs)\n        if not phase.stft.circular_shift:\n            warnings.warn(""`circular_shift` of the STFT must be set to \'True\' ""\n                          ""for correct local group delay"")\n        # process the phase and cast the result as LocalGroupDelay\n        obj = np.asarray(local_group_delay(phase)).view(cls)\n        # save additional attributes\n        obj.phase = phase\n        obj.stft = phase.stft\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here, also needed for views\n        self.phase = getattr(obj, \'phase\', None)\n        self.stft = getattr(obj, \'stft\', None)\n\n    @property\n    def bin_frequencies(self):\n        """"""Bin frequencies.""""""\n        return self.stft.bin_frequencies\n\n\nLGD = LocalGroupDelay\n'"
madmom/evaluation/__init__.py,44,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n# pylint: disable=wrong-import-position\n""""""\nEvaluation package.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\n\n# evaluation helper functions\ndef find_closest_matches(detections, annotations):\n    """"""\n    Find the closest annotation for each detection.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected events.\n    annotations : list or numpy array\n        Annotated events.\n\n    Returns\n    -------\n    indices : numpy array\n        Indices of the closest matches.\n\n    Notes\n    -----\n    The sequences must be ordered.\n\n    """"""\n    # make sure the arrays have the correct types\n    detections = np.asarray(detections, dtype=np.float)\n    annotations = np.asarray(annotations, dtype=np.float)\n    # TODO: right now, it only works with 1D arrays\n    if detections.ndim > 1 or annotations.ndim > 1:\n        raise NotImplementedError(\'please implement multi-dim support\')\n    # if no detections or annotations are given\n    if len(detections) == 0 or len(annotations) == 0:\n        # return a empty array\n        return np.zeros(0, dtype=np.int)\n    # if only a single annotation is given\n    if len(annotations) == 1:\n        # return an array as long as the detections with indices 0\n        return np.zeros(len(detections), dtype=np.int)\n    # solution found at: http://stackoverflow.com/questions/8914491/\n    indices = annotations.searchsorted(detections)\n    indices = np.clip(indices, 1, len(annotations) - 1)\n    left = annotations[indices - 1]\n    right = annotations[indices]\n    indices -= detections - left < right - detections\n    # return the indices of the closest matches\n    return indices\n\n\ndef calc_errors(detections, annotations, matches=None):\n    """"""\n    Errors of the detections to the closest annotations.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected events.\n    annotations : list or numpy array\n        Annotated events.\n    matches : list or numpy array\n        Indices of the closest events.\n\n    Returns\n    -------\n    errors : numpy array\n        Errors.\n\n    Notes\n    -----\n    The sequences must be ordered. To speed up the calculation, a list of\n    pre-computed indices of the closest matches can be used.\n\n    """"""\n    # make sure the arrays have the correct types\n    detections = np.asarray(detections, dtype=np.float)\n    annotations = np.asarray(annotations, dtype=np.float)\n    if matches is not None:\n        matches = np.asarray(matches, dtype=np.int)\n    # TODO: right now, it only works with 1D arrays\n    if detections.ndim > 1 or annotations.ndim > 1:\n        raise NotImplementedError(\'please implement multi-dim support\')\n    # if no detections or annotations are given\n    if len(detections) == 0 or len(annotations) == 0:\n        # return a empty array\n        return np.zeros(0, dtype=np.float)\n    # determine the closest annotations\n    if matches is None:\n        matches = find_closest_matches(detections, annotations)\n    # calc error relative to those annotations\n    errors = detections - annotations[matches]\n    # return the errors\n    return errors\n\n\ndef calc_absolute_errors(detections, annotations, matches=None):\n    """"""\n    Absolute errors of the detections to the closest annotations.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected events.\n    annotations : list or numpy array\n        Annotated events.\n    matches : list or numpy array\n        Indices of the closest events.\n\n    Returns\n    -------\n    errors : numpy array\n        Absolute errors.\n\n    Notes\n    -----\n    The sequences must be ordered. To speed up the calculation, a list of\n    pre-computed indices of the closest matches can be used.\n\n    """"""\n    # make sure the arrays have the correct types\n    detections = np.asarray(detections, dtype=np.float)\n    annotations = np.asarray(annotations, dtype=np.float)\n    if matches is not None:\n        matches = np.asarray(matches, dtype=np.int)\n    # TODO: right now, it only works with 1D arrays\n    if detections.ndim > 1 or annotations.ndim > 1:\n        raise NotImplementedError(\'please implement multi-dim support\')\n    # return the errors\n    return np.abs(calc_errors(detections, annotations, matches))\n\n\ndef calc_relative_errors(detections, annotations, matches=None):\n    """"""\n    Relative errors of the detections to the closest annotations.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected events.\n    annotations : list or numpy array\n        Annotated events.\n    matches : list or numpy array\n        Indices of the closest events.\n\n    Returns\n    -------\n    errors : numpy array\n        Relative errors.\n\n    Notes\n    -----\n    The sequences must be ordered. To speed up the calculation, a list of\n    pre-computed indices of the closest matches can be used.\n\n    """"""\n    # make sure the arrays have the correct types\n    detections = np.asarray(detections, dtype=np.float)\n    annotations = np.asarray(annotations, dtype=np.float)\n    if matches is not None:\n        matches = np.asarray(matches, dtype=np.int)\n    # TODO: right now, it only works with 1D arrays\n    if detections.ndim > 1 or annotations.ndim > 1:\n        raise NotImplementedError(\'please implement multi-dim support\')\n    # if no detections or annotations are given\n    if len(detections) == 0 or len(annotations) == 0:\n        # return a empty array\n        return np.zeros(0, dtype=np.float)\n    # determine the closest annotations\n    if matches is None:\n        matches = find_closest_matches(detections, annotations)\n    # calculate the absolute errors\n    errors = calc_errors(detections, annotations, matches)\n    # return the relative errors\n    return np.abs(1 - (errors / annotations[matches]))\n\n\n# abstract evaluation base class\nclass EvaluationMixin(object):\n    """"""\n    Evaluation mixin class.\n\n    This class has a `name` attribute which is used for display purposes and\n    defaults to \'None\'.\n\n    `METRIC_NAMES` is a list of tuples, containing the attribute\'s name and the\n    corresponding label, e.g.:\n\n    The attributes defined in `METRIC_NAMES` will be provided as an ordered\n    dictionary as the `metrics` property unless the subclass overwrites the\n    property.\n\n    `FLOAT_FORMAT` is used to format floats.\n\n    """"""\n\n    # Example:\n    # METRIC_NAMES = [\n    #     (\'precision\', \'Precision\'),\n    #     (\'recall\', \'Recall\'),\n    #     (\'fmeasure\', \'F-measure\'),\n    # ]\n    name = None\n    METRIC_NAMES = []\n    FLOAT_FORMAT = \'{:.3f}\'\n\n    @property\n    def metrics(self):\n        """"""Metrics as a dictionary.""""""\n        from collections import OrderedDict\n        metrics = OrderedDict()\n        # metrics = {}\n        for metric in [m[0] for m in self.METRIC_NAMES]:\n            metrics[metric] = getattr(self, metric)\n        return metrics\n\n    def __len__(self):\n        """"""Length of the evaluation object.""""""\n        raise NotImplementedError(\'must be implemented by subclass.\')\n\n    def tostring(self, **kwargs):\n        """"""\n        Format the evaluation metrics as a human readable string.\n\n        Returns\n        -------\n        str\n            Evaluation metrics formatted as a human readable string.\n\n        Notes\n        -----\n        This is a fallback method formatting the `metrics` dictionary in a\n        human readable way. Classes inheriting from this mixin class should\n        provide a method better suitable.\n\n        """"""\n        # pylint: disable=unused-argument\n        import pprint\n        return pprint.pformat(dict(self.metrics), indent=4)\n\n\n# evaluation classes\nclass SimpleEvaluation(EvaluationMixin):\n    """"""\n    Simple Precision, Recall, F-measure and Accuracy evaluation based on the\n    numbers of true/false positive/negative detections.\n\n    Parameters\n    ----------\n    num_tp : int\n        Number of true positive detections.\n    num_fp : int\n        Number of false positive detections.\n    num_tn : int\n        Number of true negative detections.\n    num_fn : int\n        Number of false negative detections.\n    name : str\n        Name to be displayed.\n\n    Notes\n    -----\n    This class is only suitable for a 1-class evaluation problem.\n\n    """"""\n\n    METRIC_NAMES = [\n        (\'num_tp\', \'No. of true positives\'),\n        (\'num_fp\', \'No. of false positives\'),\n        (\'num_tn\', \'No. of true negatives\'),\n        (\'num_fn\', \'No. of false negatives\'),\n        (\'num_annotations\', \'No. Annotations\'),\n        (\'precision\', \'Precision\'),\n        (\'recall\', \'Recall\'),\n        (\'fmeasure\', \'F-measure\'),\n        (\'accuracy\', \'Accuracy\'),\n    ]\n\n    def __init__(self, num_tp=0, num_fp=0, num_tn=0, num_fn=0, name=None,\n                 **kwargs):\n        # pylint: disable=unused-argument\n        # hidden variables, to be able to overwrite them in subclasses\n        self._num_tp = int(num_tp)\n        self._num_fp = int(num_fp)\n        self._num_tn = int(num_tn)\n        self._num_fn = int(num_fn)\n        # name of the evaluation\n        self.name = name\n\n    @property\n    def num_tp(self):\n        """"""Number of true positive detections.""""""\n        return self._num_tp\n\n    @property\n    def num_fp(self):\n        """"""Number of false positive detections.""""""\n        return self._num_fp\n\n    @property\n    def num_tn(self):\n        """"""Number of true negative detections.""""""\n        return self._num_tn\n\n    @property\n    def num_fn(self):\n        """"""Number of false negative detections.""""""\n        return self._num_fn\n\n    @property\n    def num_annotations(self):\n        """"""Number of annotations.""""""\n        return self.num_tp + self.num_fn\n\n    def __len__(self):\n        # the length equals the number of annotations\n        return self.num_annotations\n\n    @property\n    def precision(self):\n        """"""Precision.""""""\n        # correct / retrieved\n        retrieved = float(self.num_tp + self.num_fp)\n        # if there are no positive predictions, none of them are wrong\n        if retrieved == 0:\n            return 1.\n        return self.num_tp / retrieved\n\n    @property\n    def recall(self):\n        """"""Recall.""""""\n        # correct / relevant\n        relevant = float(self.num_tp + self.num_fn)\n        # if there are no positive annotations, we recalled all of them\n        if relevant == 0:\n            return 1.\n        return self.num_tp / relevant\n\n    @property\n    def fmeasure(self):\n        """"""F-measure.""""""\n        # 2pr / (p+r)\n        numerator = 2. * self.precision * self.recall\n        if numerator == 0:\n            return 0.\n        return numerator / (self.precision + self.recall)\n\n    @property\n    def accuracy(self):\n        """"""Accuracy.""""""\n        # acc: (TP + TN) / (TP + FP + TN + FN)\n        denominator = self.num_fp + self.num_fn + self.num_tp + self.num_tn\n        if denominator == 0:\n            return 1.\n        numerator = float(self.num_tp + self.num_tn)\n        if numerator == 0:\n            return 0.\n        return numerator / denominator\n\n    def tostring(self, **kwargs):\n        """"""\n        Format the evaluation metrics as a human readable string.\n\n        Returns\n        -------\n        str\n            Evaluation metrics formatted as a human readable string.\n\n\n        """"""\n        ret = \'\'\n        if self.name is not None:\n            ret += \'%s\\n  \' % self.name\n        ret += \'Annotations: %5d TP: %5d FP: %5d FN: %5d \' \\\n               \'Precision: %.3f Recall: %.3f F-measure: %.3f Acc: %.3f\' % \\\n               (self.num_annotations, self.num_tp, self.num_fp, self.num_fn,\n                self.precision, self.recall, self.fmeasure, self.accuracy)\n        return ret\n\n    def __str__(self):\n        return self.tostring()\n\n\n# evaluate Precision, Recall, F-measure and Accuracy with lists or numpy arrays\nclass Evaluation(SimpleEvaluation):\n    """"""\n    Evaluation class for measuring Precision, Recall and F-measure based on\n    numpy arrays or lists with true/false positive/negative detections.\n\n    Parameters\n    ----------\n    tp : list or numpy array\n        True positive detections.\n    fp : list or numpy array\n        False positive detections.\n    tn : list or numpy array\n        True negative detections.\n    fn : list or numpy array\n        False negative detections.\n    name : str\n        Name to be displayed.\n\n    """"""\n\n    def __init__(self, tp=None, fp=None, tn=None, fn=None, **kwargs):\n        # set default values\n        if tp is None:\n            tp = []\n        if fp is None:\n            fp = []\n        if tn is None:\n            tn = []\n        if fn is None:\n            fn = []\n        # instantiate a SimpleEvaluation object\n        super(Evaluation, self).__init__(**kwargs)\n        # convert everything to numpy arrays and save them\n        self.tp = np.asarray(list(tp), dtype=np.float)\n        self.fp = np.asarray(list(fp), dtype=np.float)\n        self.tn = np.asarray(list(tn), dtype=np.float)\n        self.fn = np.asarray(list(fn), dtype=np.float)\n\n    @property\n    def num_tp(self):\n        """"""Number of true positive detections.""""""\n        return len(self.tp)\n\n    @property\n    def num_fp(self):\n        """"""Number of false positive detections.""""""\n        return len(self.fp)\n\n    @property\n    def num_tn(self):\n        """"""Number of true negative detections.""""""\n        return len(self.tn)\n\n    @property\n    def num_fn(self):\n        """"""Number of false negative detections.""""""\n        return len(self.fn)\n\n\n# class for evaluation of Precision, Recall, F-measure with 2D arrays\nclass MultiClassEvaluation(Evaluation):\n    """"""\n    Evaluation class for measuring Precision, Recall and F-measure based on\n    2D numpy arrays with true/false positive/negative detections.\n\n    Parameters\n    ----------\n    tp : list of tuples or numpy array, shape (num_tp, 2)\n        True positive detections.\n    fp : list of tuples or numpy array, shape (num_fp, 2)\n        False positive detections.\n    tn : list of tuples or numpy array, shape (num_tn, 2)\n        True negative detections.\n    fn : list of tuples or numpy array, shape (num_fn, 2)\n        False negative detections.\n    name : str\n        Name to be displayed.\n\n    Notes\n    -----\n    The second item of the tuples or the second column of the arrays denote\n    the class the detection belongs to.\n\n    """"""\n    def __init__(self, tp=None, fp=None, tn=None, fn=None, **kwargs):\n        # set default values\n        if tp is None:\n            tp = np.zeros((0, 2))\n        if fp is None:\n            fp = np.zeros((0, 2))\n        if tn is None:\n            tn = np.zeros((0, 2))\n        if fn is None:\n            fn = np.zeros((0, 2))\n        super(MultiClassEvaluation, self).__init__(**kwargs)\n        self.tp = np.asarray(tp, dtype=np.float)\n        self.fp = np.asarray(fp, dtype=np.float)\n        self.tn = np.asarray(tn, dtype=np.float)\n        self.fn = np.asarray(fn, dtype=np.float)\n\n    def tostring(self, verbose=False, **kwargs):\n        """"""\n        Format the evaluation metrics as a human readable string.\n\n        Parameters\n        ----------\n        verbose : bool\n            Add evaluation for individual classes.\n\n        Returns\n        -------\n        str\n            Evaluation metrics formatted as a human readable string.\n\n        """"""\n        ret = \'\'\n\n        if verbose:\n            # extract all classes\n            classes = []\n            if self.tp.any():\n                classes = np.append(classes, np.unique(self.tp[:, 1]))\n            if self.fp.any():\n                classes = np.append(classes, np.unique(self.fp[:, 1]))\n            if self.tn.any():\n                classes = np.append(classes, np.unique(self.tn[:, 1]))\n            if self.fn.any():\n                classes = np.append(classes, np.unique(self.fn[:, 1]))\n            for cls in sorted(np.unique(classes)):\n                # extract the TP, FP, TN and FN of this class\n                tp = self.tp[self.tp[:, 1] == cls]\n                fp = self.fp[self.fp[:, 1] == cls]\n                tn = self.tn[self.tn[:, 1] == cls]\n                fn = self.fn[self.fn[:, 1] == cls]\n                # evaluate them\n                e = Evaluation(tp, fp, tn, fn, name=\'Class %s\' % cls)\n                # append to the output string\n                ret += \'  %s\\n\' % e.tostring(verbose=False)\n        # normal formatting\n        ret += \'Annotations: %5d TP: %5d FP: %4d FN: %4d \' \\\n               \'Precision: %.3f Recall: %.3f F-measure: %.3f Acc: %.3f\' % \\\n               (self.num_annotations, self.num_tp, self.num_fp, self.num_fn,\n                self.precision, self.recall, self.fmeasure, self.accuracy)\n        # return\n        return ret\n\n\n# class for summing Evaluations\nclass SumEvaluation(SimpleEvaluation):\n    """"""\n    Simple class for summing evaluations.\n\n    Parameters\n    ----------\n    eval_objects : list\n        Evaluation objects.\n    name : str\n        Name to be displayed.\n\n    """"""\n\n    def __init__(self, eval_objects, name=None):\n        # pylint: disable=super-init-not-called\n        # Note: we want to inherit the evaluation functions/properties, no need\n        #       to call __super__, but we need to take care of \'name\'\n        if not isinstance(eval_objects, list):\n            # wrap the given eval_object in a list\n            eval_objects = [eval_objects]\n        self.eval_objects = eval_objects\n        self.name = name or \'sum for %d files\' % len(self)\n\n    def __len__(self):\n        # just use the length of the evaluation objects\n        return len(self.eval_objects)\n\n    # redefine the counters (number of TP, FP, TN, FN & number of annotations)\n\n    @property\n    def num_tp(self):\n        """"""Number of true positive detections.""""""\n        return sum(e.num_tp for e in self.eval_objects)\n\n    @property\n    def num_fp(self):\n        """"""Number of false positive detections.""""""\n        return sum(e.num_fp for e in self.eval_objects)\n\n    @property\n    def num_tn(self):\n        """"""Number of true negative detections.""""""\n        return sum(e.num_tn for e in self.eval_objects)\n\n    @property\n    def num_fn(self):\n        """"""Number of false negative detections.""""""\n        return sum(e.num_fn for e in self.eval_objects)\n\n    @property\n    def num_annotations(self):\n        """"""Number of annotations.""""""\n        return sum(e.num_annotations for e in self.eval_objects)\n\n\n# class for averaging Evaluations\nclass MeanEvaluation(SumEvaluation):\n    """"""\n    Simple class for averaging evaluation.\n\n    Parameters\n    ----------\n    eval_objects : list\n        Evaluation objects.\n    name : str\n        Name to be displayed.\n\n    """"""\n\n    def __init__(self, eval_objects, name=None, **kwargs):\n        super(MeanEvaluation, self).__init__(eval_objects, **kwargs)\n        # handle the \'name\' here to be able to set a different default value\n        self.name = name or \'mean for %d files\' % len(self)\n\n    # overwrite the properties to calculate the mean instead of the sum\n\n    @property\n    def num_tp(self):\n        """"""Number of true positive detections.""""""\n        if not self.eval_objects:\n            return 0.\n        return np.nanmean([e.num_tp for e in self.eval_objects])\n\n    @property\n    def num_fp(self):\n        """"""Number of false positive detections.""""""\n        if not self.eval_objects:\n            return 0.\n        return np.nanmean([e.num_fp for e in self.eval_objects])\n\n    @property\n    def num_tn(self):\n        """"""Number of true negative detections.""""""\n        if not self.eval_objects:\n            return 0.\n        return np.nanmean([e.num_tn for e in self.eval_objects])\n\n    @property\n    def num_fn(self):\n        """"""Number of false negative detections.""""""\n        if not self.eval_objects:\n            return 0.\n        return np.nanmean([e.num_fn for e in self.eval_objects])\n\n    @property\n    def num_annotations(self):\n        """"""Number of annotations.""""""\n        if not self.eval_objects:\n            return 0.\n        return np.nanmean([e.num_annotations for e in self.eval_objects])\n\n    @property\n    def precision(self):\n        """"""Precision.""""""\n        return np.nanmean([e.precision for e in self.eval_objects])\n\n    @property\n    def recall(self):\n        """"""Recall.""""""\n        return np.nanmean([e.recall for e in self.eval_objects])\n\n    @property\n    def fmeasure(self):\n        """"""F-measure.""""""\n        return np.nanmean([e.fmeasure for e in self.eval_objects])\n\n    @property\n    def accuracy(self):\n        """"""Accuracy.""""""\n        return np.nanmean([e.accuracy for e in self.eval_objects])\n\n    def tostring(self, **kwargs):\n        """"""\n        Format the evaluation metrics as a human readable string.\n\n        Returns\n        -------\n        str\n            Evaluation metrics formatted as a human readable string.\n\n        """"""\n        ret = \'\'\n        if self.name is not None:\n            ret += \'%s\\n  \' % self.name\n        # TODO: unify this with SimpleEvaluation but\n        #       add option to provide field formatters (e.g. 3d or 5.2f)\n        # format with floats instead of integers\n        ret += \'Annotations: %5.2f TP: %5.2f FP: %5.2f FN: %5.2f \' \\\n               \'Precision: %.3f Recall: %.3f F-measure: %.3f Acc: %.3f\' % \\\n               (self.num_annotations, self.num_tp, self.num_fp, self.num_fn,\n                self.precision, self.recall, self.fmeasure, self.accuracy)\n        return ret\n\n\ndef tostring(eval_objects, **kwargs):\n    """"""\n    Format the given evaluation objects as human readable strings.\n\n    Parameters\n    ----------\n    eval_objects : list\n        Evaluation objects.\n\n    Returns\n    -------\n    str\n        Evaluation metrics formatted as a human readable string.\n\n    """"""\n    # pylint: disable=unused-argument\n    return \'\\n\'.join([e.tostring() for e in eval_objects])\n\n\ndef tocsv(eval_objects, metric_names=None, float_format=\'{:.3f}\', **kwargs):\n    """"""\n    Format the given evaluation objects as a CSV table.\n\n    Parameters\n    ----------\n    eval_objects : list\n        Evaluation objects.\n    metric_names : list of tuples, optional\n        List of tuples defining the name of the property corresponding to the\n        metric, and the metric label e.g. (\'fp\', \'False Positives\').\n    float_format : str, optional\n        How to format the metrics.\n\n    Returns\n    -------\n    str\n        CSV table representation of the evaluation objects.\n\n    Notes\n    -----\n    If no `metric_names` are given, they will be extracted from the first\n    evaluation object.\n\n    """"""\n    # pylint: disable=unused-argument\n\n    if metric_names is None:\n        # get the evaluation metrics from the first evaluation object\n        metric_names = eval_objects[0].METRIC_NAMES\n    metric_names, metric_labels = list(zip(*metric_names))\n    # add header\n    lines = [\'Name,\' + \',\'.join(metric_labels)]\n    # TODO: use e.metrics dict?\n    # add the evaluation objects\n    for e in eval_objects:\n        values = [float_format.format(getattr(e, mn)) for mn in metric_names]\n        lines.append(e.name + \',\' + \',\'.join(values))\n    # return everything\n    return \'\\n\'.join(lines)\n\n\ndef totex(eval_objects, metric_names=None, float_format=\'{:.3f}\', **kwargs):\n    """"""\n    Format the given evaluation objects as a LaTeX table.\n\n    Parameters\n    ----------\n    eval_objects : list\n        Evaluation objects.\n    metric_names : list of tuples, optional\n        List of tuples defining the name of the property corresponding to the\n        metric, and the metric label e.g. (\'fp\', \'False Positives\').\n    float_format : str, optional\n        How to format the metrics.\n\n    Returns\n    -------\n    str\n        LaTeX table representation of the evaluation objects.\n\n    Notes\n    -----\n    If no `metric_names` are given, they will be extracted from the first\n    evaluation object.\n\n    """"""\n    # pylint: disable=unused-argument\n\n    if metric_names is None:\n        # get the evaluation metrics from the first evaluation object\n        metric_names = eval_objects[0].METRIC_NAMES\n    metric_names, metric_labels = list(zip(*metric_names))\n    # add header\n    lines = [\'Name & \' + \' & \'.join(metric_labels) + \'\\\\\\\\\']\n    # TODO: use e.metrics dict\n    # TODO: add a generic totable() function which accepts columns separator,\n    #       newline stuff (e.g. tex \\\\\\\\) and others\n    # add the evaluation objects\n    for e in eval_objects:\n        values = [float_format.format(getattr(e, mn)) for mn in metric_names]\n        lines.append(e.name + \' & \' + \' & \'.join(values) + \'\\\\\\\\\')\n    # return everything\n    return \'\\n\'.join(lines)\n\n\ndef evaluation_io(parser, ann_suffix, det_suffix, ann_dir=None, det_dir=None):\n    """"""\n    Add evaluation input/output and formatting related arguments to an existing\n    parser object.\n\n    Parameters\n    ----------\n    parser : argparse parser instance\n        Existing argparse parser object.\n    ann_suffix : str\n        Suffix of the annotation files.\n    det_suffix : str\n        Suffix of the detection files.\n    ann_dir : str, optional\n        Use only annotations from this folder (and sub-folders).\n    det_dir : str, optional\n        Use only detections from this folder (and sub-folders).\n\n    Returns\n    -------\n    io_group : argparse argument group\n        Evaluation input / output argument group.\n    formatter_group : argparse argument group\n        Evaluation formatter argument group.\n\n    """"""\n    import sys\n    import argparse\n    # general input output file handling\n    parser.add_argument(\'files\', nargs=\'*\',\n                        help=\'files (or folders) to be evaluated\')\n    parser.add_argument(\'-o\', dest=\'outfile\', type=argparse.FileType(\'w\'),\n                        default=sys.stdout,\n                        help=\'output file [default: STDOUT]\')\n    # file suffixes used for evaluation\n    g = parser.add_argument_group(\'file/folder/suffix arguments\')\n    g.add_argument(\'-a\', dest=\'ann_suffix\', action=\'store\', default=ann_suffix,\n                   help=\'suffix of the annotation files \'\n                        \'[default: %(default)s]\')\n    g.add_argument(\'--ann_dir\', action=\'store\', default=ann_dir,\n                   help=\'search only this directory (recursively) for \'\n                        \'annotation files [default: %(default)s]\')\n    g.add_argument(\'-d\', dest=\'det_suffix\', action=\'store\', default=det_suffix,\n                   help=\'suffix of the detection files [default: %(default)s]\')\n    g.add_argument(\'--det_dir\', action=\'store\', default=det_dir,\n                   help=\'search only this directory (recursively) for \'\n                        \'detection files [default: %(default)s]\')\n    # option to ignore non-existing detections\n    g.add_argument(\'-i\', \'--ignore_non_existing\', action=\'store_true\',\n                   help=\'ignore non-existing detections [default: raise a \'\n                        \'warning and assume empty detections]\')\n    # verbose\n    parser.add_argument(\'-v\', \'--verbose\', action=\'count\', default=0,\n                        help=\'increase verbosity level\')\n    # option to suppress warnings\n    parser.add_argument(\'-q\', \'--quiet\', action=\'store_true\',\n                        help=\'suppress any warnings\')\n    # output format options\n    parser.set_defaults(output_formatter=tostring)\n    f = parser.add_argument_group(\'formatting arguments\')\n    formats = f.add_mutually_exclusive_group()\n    formats.add_argument(\'--tex\', dest=\'output_formatter\',\n                         action=\'store_const\', const=totex,\n                         help=\'format output to be used in .tex files\')\n    formats.add_argument(\'--csv\', dest=\'output_formatter\',\n                         action=\'store_const\', const=tocsv,\n                         help=\'format output to be used in .csv files\')\n    # return the output formatting group so the caller can add more options\n    return g, f\n\n\n# finally import the submodules\nfrom . import chords, beats, notes, onsets, tempo\n\n# import often used classes\nfrom .beats import BeatEvaluation, BeatMeanEvaluation\nfrom .chords import ChordEvaluation, ChordMeanEvaluation, ChordSumEvaluation\nfrom .key import KeyEvaluation, KeyMeanEvaluation\nfrom .notes import NoteEvaluation, NoteMeanEvaluation, NoteSumEvaluation\nfrom .onsets import OnsetEvaluation, OnsetMeanEvaluation, OnsetSumEvaluation\nfrom .tempo import TempoEvaluation, TempoMeanEvaluation\n'"
madmom/evaluation/beats.py,58,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains beat evaluation functionality.\n\nThe measures are described in [1]_, a Matlab implementation exists here:\nhttp://code.soundsoftware.ac.uk/projects/beat-evaluation/repository\n\nNotes\n-----\nPlease note that this is a complete re-implementation, which took some other\ndesign decisions. For example, the beat detections and annotations are not\nquantised before being evaluated with F-measure, P-score and other metrics.\nHence these evaluation functions DO NOT report the exact same results/scores.\nThis approach was chosen, because it is simpler and produces more accurate\nresults.\n\nReferences\n----------\n.. [1] Matthew E. P. Davies, Norberto Degara, and Mark D. Plumbley,\n       ""Evaluation Methods for Musical Audio Beat Tracking Algorithms"",\n       Technical Report C4DM-TR-09-06,\n       Centre for Digital Music, Queen Mary University of London, 2009.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nfrom functools import wraps\nimport warnings\n\nimport numpy as np\n\nfrom . import (MeanEvaluation, calc_absolute_errors, calc_errors,\n               evaluation_io, find_closest_matches)\nfrom .onsets import OnsetEvaluation\nfrom ..io import load_beats\n\n\n# exceptions\nclass BeatIntervalError(Exception):\n    """"""\n    Exception to be raised whenever an interval cannot be computed.\n\n    """"""\n    # pylint: disable=super-init-not-called\n\n    def __init__(self, value=None):\n        if value is None:\n            value = ""At least two beats must be present to be able to "" \\\n                    ""calculate an interval.""\n        self.value = value\n\n    def __str__(self):\n        return repr(self.value)\n\n\n# decorators\ndef array(metric):\n    """"""\n    Decorate metric to convert annotations and detections to numpy arrays.\n\n    """"""\n\n    @wraps(metric)\n    def float_array(detections, annotations, *args, **kwargs):\n        """"""Warp detections and annotations as numpy arrays.""""""\n        # make sure the annotations and detections have a float dtype\n        detections = np.asarray(detections, dtype=np.float)\n        annotations = np.asarray(annotations, dtype=np.float)\n        return metric(detections, annotations, *args, **kwargs)\n\n    return float_array\n\n\ndef _score_decorator(perfect_score, zero_score):\n    """"""\n    Decorate metric with evaluation results for perfect and zero score.\n\n    Parameters\n    ----------\n    perfect_score : float or tuple\n    zero_score : float or tuple\n\n    Returns\n    -------\n    metric\n        Decorated metric.\n\n    """"""\n\n    def wrap(metric):\n        """"""Metric to decorate""""""\n\n        @wraps(metric)\n        def score(detections, annotations, *args, **kwargs):\n            """"""\n            Return perfect/zero score if neither/either detections and\n            annotations are given, respectively.\n\n            """"""\n            # neither detections nor annotations are given, perfect score\n            if len(detections) == 0 and len(annotations) == 0:\n                return perfect_score\n            # either beat detections or annotations are empty, score 0\n            elif (len(detections) == 0) != (len(annotations) == 0):\n                return zero_score\n            # normal scoring\n            return metric(detections, annotations, *args, **kwargs)\n\n        return score\n\n    return wrap\n\n\nscore_10 = _score_decorator(1., 0.)\nscore_1100 = _score_decorator((1., 1.), (0., 0.))\n\n\n# function for sequence variations generation\ndef variations(sequence, offbeat=False, double=False, half=False,\n               triple=False, third=False):\n    """"""\n    Create variations of the given beat sequence.\n\n    Parameters\n    ----------\n    sequence : numpy array\n        Beat sequence.\n    offbeat : bool, optional\n        Create an offbeat sequence.\n    double : bool, optional\n        Create a double tempo sequence.\n    half : bool, optional\n        Create half tempo sequences (includes offbeat version).\n    triple : bool, optional\n        Create triple tempo sequence.\n    third : bool, optional\n        Create third tempo sequences (includes offbeat versions).\n\n    Returns\n    -------\n    list\n        Beat sequence variations.\n\n    """"""\n    # create different variants of the annotations\n    sequences = []\n    # double/half and offbeat variation\n    if double or offbeat:\n        if len(sequence) == 0:\n            # if we have an empty sequence, there\'s nothing to interpolate\n            double_sequence = []\n        else:\n            # create a sequence with double tempo\n            same = np.arange(0, len(sequence))\n            # request one item less, otherwise we would extrapolate\n            shifted = np.arange(0, len(sequence), 0.5)[:-1]\n            double_sequence = np.interp(shifted, same, sequence)\n        # same tempo, half tempo off\n        if offbeat:\n            sequences.append(double_sequence[1::2])\n        # double/half tempo variations\n        if double:\n            # double tempo\n            sequences.append(double_sequence)\n    if half:\n        # half tempo odd beats (i.e. 1,3,1,3,..)\n        sequences.append(sequence[0::2])\n        # half tempo even beats (i.e. 2,4,2,4,..)\n        sequences.append(sequence[1::2])\n    # triple/third tempo variations\n    if triple:\n        if len(sequence) == 0:\n            # if we have an empty sequence, there\'s nothing to interpolate\n            triple_sequence = []\n        else:\n            # create a annotation sequence with triple tempo\n            same = np.arange(0, len(sequence))\n            # request two items less, otherwise we would extrapolate\n            shifted = np.arange(0, len(sequence), 1. / 3)[:-2]\n            triple_sequence = np.interp(shifted, same, sequence)\n        # triple tempo\n        sequences.append(triple_sequence)\n    if third:\n        # third tempo 1st beat (1,4,3,2,..)\n        sequences.append(sequence[0::3])\n        # third tempo 2nd beat (2,1,4,3,..)\n        sequences.append(sequence[1::3])\n        # third tempo 3rd beat (3,2,1,4,..)\n        sequences.append(sequence[2::3])\n    # return\n    return sequences\n\n\n# helper functions for beat evaluation\ndef calc_intervals(events, fwd=False):\n    """"""\n    Calculate the intervals of all events to the previous/next event.\n\n    Parameters\n    ----------\n    events : numpy array\n        Beat sequence.\n    fwd : bool, optional\n        Calculate the intervals towards the next event (instead of previous).\n\n    Returns\n    -------\n    numpy array\n        Beat intervals.\n\n    Notes\n    -----\n    The sequence must be ordered. The first (last) interval will be set to\n    the same value as the second (second to last) interval (when used in\n    `fwd` mode).\n\n    """"""\n    # at least 2 events must be given to calculate an interval\n    if len(events) < 2:\n        raise BeatIntervalError\n    interval = np.zeros_like(events)\n    if fwd:\n        interval[:-1] = np.diff(events)\n        # set the last interval to the same value as the second last\n        interval[-1] = interval[-2]\n    else:\n        interval[1:] = np.diff(events)\n        # set the first interval to the same value as the second\n        interval[0] = interval[1]\n    # return\n    return interval\n\n\ndef find_closest_intervals(detections, annotations, matches=None):\n    """"""\n    Find the closest annotated interval to each beat detection.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected beats.\n    annotations : list or numpy array\n        Annotated beats.\n    matches : list or numpy array\n        Indices of the closest beats.\n\n    Returns\n    -------\n    numpy array\n        Closest annotated beat intervals.\n\n    Notes\n    -----\n    The sequences must be ordered. To speed up the calculation, a list of\n    pre-computed indices of the closest matches can be used.\n\n    The function does NOT test if each detection has a surrounding interval,\n    it always returns the closest interval.\n\n    """"""\n    # if no detection are given, return an empty interval array\n    if len(detections) == 0:\n        return np.zeros(0, dtype=np.float)\n    # at least annotations must be given\n    if len(annotations) < 2:\n        raise BeatIntervalError\n    # init array\n    closest_interval = np.ones_like(detections)\n    # intervals\n    # Note: it is faster if we combine the forward and backward intervals,\n    #       but we need to take care of the sizes; intervals to the next\n    #       annotation are always the same as those at the next index\n    intervals = np.zeros(len(annotations) + 1)\n    # intervals to previous annotation\n    intervals[1:-1] = np.diff(annotations)\n    # interval of the first annotation to the left is the same as to the right\n    intervals[0] = intervals[1]\n    # interval of the last annotation to the right is the same as to the left\n    intervals[-1] = intervals[-2]\n    # determine the closest annotations\n    if matches is None:\n        matches = find_closest_matches(detections, annotations)\n    # calculate the absolute errors\n    errors = calc_errors(detections, annotations, matches)\n    # if the errors are positive, the detection is after the annotation\n    # thus use the interval towards the next annotation\n    closest_interval[errors > 0] = intervals[matches[errors > 0] + 1]\n    # if the errors are 0 or negative, the detection is before the annotation\n    # or at the same position; thus use the interval to previous annotation\n    closest_interval[errors <= 0] = intervals[matches[errors <= 0]]\n    # return the closest interval\n    return closest_interval\n\n\ndef find_longest_continuous_segment(sequence_indices):\n    """"""\n    ind the longest consecutive segment in the given sequence.\n\n    Parameters\n    ----------\n    sequence_indices : numpy array\n        Indices of the beats\n\n    Returns\n    -------\n    length : int\n        Length of the longest consecutive segment.\n    start : int\n        Start position of the longest continuous segment.\n\n    """"""\n    # continuous segments have consecutive indices, i.e. diffs =! 1 are\n    # boundaries between continuous segments; add 1 to get the correct index\n    boundaries = np.nonzero(np.diff(sequence_indices) != 1)[0] + 1\n    # add a start (index 0) and stop (length of correct detections) to the\n    # segment boundary indices\n    boundaries = np.concatenate(([0], boundaries, [len(sequence_indices)]))\n    # lengths of the individual segments\n    segment_lengths = np.diff(boundaries)\n    # return the length and start position of the longest continuous segment\n    length = int(np.max(segment_lengths))\n    start_pos = int(boundaries[np.argmax(segment_lengths)])\n    return length, start_pos\n\n\n@array\ndef calc_relative_errors(detections, annotations, matches=None):\n    """"""\n    Errors of the detections relative to the closest annotated interval.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected beats.\n    annotations : list or numpy array\n        Annotated beats.\n    matches : list or numpy array\n        Indices of the closest beats.\n\n    Returns\n    -------\n    numpy array\n        Errors relative to the closest annotated beat interval.\n\n    Notes\n    -----\n    The sequences must be ordered! To speed up the calculation, a list of\n    pre-computed indices of the closest matches can be used.\n\n    """"""\n    # if no detection are given, return an empty interval array\n    if len(detections) == 0:\n        return np.zeros(0, dtype=np.float)\n    # at least annotations must be given\n    if len(annotations) < 2:\n        raise BeatIntervalError\n    # determine the closest annotations\n    if matches is None:\n        matches = find_closest_matches(detections, annotations)\n    # calculate the absolute errors\n    errors = calc_errors(detections, annotations, matches)\n    # get the closest intervals\n    intervals = find_closest_intervals(detections, annotations, matches)\n    # return the relative errors\n    return errors / intervals\n\n\n# default beat evaluation parameter values\nFMEASURE_WINDOW = 0.07\nPSCORE_TOLERANCE = 0.2\nCEMGIL_SIGMA = 0.04\nGOTO_THRESHOLD = 0.175\nGOTO_SIGMA = 0.1\nGOTO_MU = 0.1\nCONTINUITY_TEMPO_TOLERANCE = 0.175\nCONTINUITY_PHASE_TOLERANCE = 0.175\nINFORMATION_GAIN_BINS = 40\n\n\n# evaluation functions for beat detection\n@array\n@score_10\ndef pscore(detections, annotations, tolerance=PSCORE_TOLERANCE):\n    """"""\n    Calculate the P-score accuracy for the given detections and annotations.\n\n    The P-score is determined by taking the sum of the cross-correlation\n    between two impulse trains, representing the detections and annotations\n    allowing for a tolerance of 20% of the median annotated interval [1]_.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected beats.\n    annotations : list or numpy array\n        Annotated beats.\n    tolerance : float, optional\n        Evaluation tolerance (fraction of the median beat interval).\n\n    Returns\n    -------\n    pscore : float\n        P-Score.\n\n    Notes\n    -----\n    Contrary to the original implementation which samples the two impulse\n    trains with 100Hz, we do not quantise the annotations and detections but\n    rather count all detections falling withing the defined tolerance window.\n\n    References\n    ----------\n    .. [1] M. McKinney, D. Moelants, M. Davies and A. Klapuri,\n           ""Evaluation of audio beat tracking and music tempo extraction\n           algorithms"",\n           Journal of New Music Research, vol. 36, no. 1, 2007.\n\n    """"""\n    # at least 2 annotations must be given to calculate an interval\n    if len(annotations) < 2:\n        raise BeatIntervalError(""At least 2 annotations are needed for""\n                                ""P-Score."")\n    # tolerance must be greater than 0\n    if float(tolerance) <= 0:\n        raise ValueError(""`tolerance` must be greater than 0."")\n    # the error window is the given fraction of the median beat interval\n    window = tolerance * np.median(np.diff(annotations))\n    # errors\n    errors = calc_absolute_errors(detections, annotations)\n    # count the instances where the error is smaller or equal than the window\n    p = len(detections[errors <= window])\n    # normalize by the max number of detections/annotations\n    p /= float(max(len(detections), len(annotations)))\n    # return p-score\n    return p\n\n\n@array\n@score_10\ndef cemgil(detections, annotations, sigma=CEMGIL_SIGMA):\n    """"""\n    Calculate the Cemgil accuracy for the given detections and annotations.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected beats.\n    annotations : list or numpy array\n        Annotated beats.\n    sigma : float, optional\n        Sigma for Gaussian error function.\n\n    Returns\n    -------\n    cemgil : float\n        Cemgil beat tracking accuracy.\n\n    References\n    ----------\n    .. [1] A.T. Cemgil, B. Kappen, P. Desain, and H. Honing,\n           ""On tempo tracking: Tempogram representation and Kalman filtering"",\n           Journal Of New Music Research, vol. 28, no. 4, 2001.\n\n    """"""\n    # sigma must be greater than 0\n    if float(sigma) <= 0:\n        raise ValueError(""`sigma` must be greater than 0."")\n    # determine the abs. errors of the detections to the closest annotations\n    # Note: the original implementation searches for the closest matches of\n    #       detections given the annotations. Since absolute errors > a usual\n    #       beat interval produce high errors (and thus in turn add negligible\n    #       values to the accuracy), it is safe to swap those two.\n    errors = calc_absolute_errors(detections, annotations)\n    # apply a Gaussian error function with the given std. dev. on the errors\n    acc = np.exp(-(errors ** 2.) / (2. * (sigma ** 2.)))\n    # and sum up the accuracy\n    acc = np.sum(acc)\n    # normalized by the mean of the number of detections and annotations\n    acc /= 0.5 * (len(annotations) + len(detections))\n    # return accuracy\n    return acc\n\n\n@array\n@score_10\ndef goto(detections, annotations, threshold=GOTO_THRESHOLD, sigma=GOTO_SIGMA,\n         mu=GOTO_MU):\n    """"""\n    Calculate the Goto and Muraoka accuracy for the given detections and\n    annotations.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected beats.\n    annotations : list or numpy array\n        Annotated beats.\n    threshold : float, optional\n        Threshold.\n    sigma : float, optional\n        Allowed std. dev. of the errors in the longest segment.\n    mu : float, optional\n        Allowed mean. of the errors in the longest segment.\n\n    Returns\n    -------\n    goto : float\n        Goto beat tracking accuracy.\n\n    Notes\n    -----\n    [1]_ requires that the first correct beat detection must occur within the\n    first 3/4 of the excerpt. In order to be able to deal with audio with\n    varying tempo, this was altered that the length of the longest continuously\n    tracked segment must be at least 1/4 of the total length [2]_.\n\n    References\n    ----------\n    .. [1] M. Goto and Y. Muraoka,\n           ""Issues in evaluating beat tracking systems"",\n           Working Notes of the IJCAI-97 Workshop on Issues in AI and Music -\n           Evaluation and Assessment, 1997.\n    .. [2] Matthew E. P. Davies, Norberto Degara, and Mark D. Plumbley,\n           ""Evaluation Methods for Musical Audio Beat Tracking Algorithms"",\n           Technical Report C4DM-TR-09-06,\n           Centre for Digital Music, Queen Mary University of London, 2009.\n\n    """"""\n    # at least 2 annotations must be given to calculate an interval\n    if len(annotations) < 2:\n        raise BeatIntervalError(""At least 2 annotations are needed for Goto\'s ""\n                                ""score."")\n    # threshold, sigma and mu must be greater than 0\n    if float(threshold) <= 0 or float(sigma) <= 0 or float(mu) <= 0:\n        raise ValueError(""Threshold, sigma and mu must be positive."")\n    # get the indices of the closest detections to the annotations to determine\n    # the longest continuous segment\n    closest = find_closest_matches(annotations, detections)\n    # keep only those which have abs(errors) <= threshold\n    # Note: both the original paper and the Matlab implementation normalize by\n    #       half a beat interval, thus our threshold is halved (same applies to\n    #       sigma and mu)\n    # errors of the detections relative to the surrounding annotation interval\n    errors = calc_relative_errors(detections, annotations)\n    # the absolute error must be smaller than the given threshold\n    closest = closest[np.abs(errors[closest]) <= threshold]\n    # get the length and start position of the longest continuous segment\n    length, start = find_longest_continuous_segment(closest)\n    # three conditions must be met to identify the segment as correct\n    # 1) the length of the segment must be at least 1/4 of the total length\n    # Note: the original paper requires that the first element must occur\n    #       within the first 3/4 of the excerpt, but this was altered in the\n    #       Matlab implementation to the above condition to be able to deal\n    #       with audio with varying tempo\n    if length < 0.25 * len(annotations):\n        return 0.\n    # errors of the longest segment\n    segment_errors = errors[closest[start: start + length]]\n    # 2) mean of the errors must not exceed mu\n    if np.mean(np.abs(segment_errors)) > mu:\n        return 0.\n    # 3) std deviation of the errors must not exceed sigma\n    # Note: contrary to the original paper and in line with the Matlab code,\n    #       we calculate the std. deviation based on the raw errors and not on\n    #       their absolute values.\n    if np.std(segment_errors) > sigma:\n        return 0.\n    # otherwise return 1\n    return 1.\n\n\n@array\n@score_1100\ndef cml(detections, annotations, phase_tolerance=CONTINUITY_PHASE_TOLERANCE,\n        tempo_tolerance=CONTINUITY_TEMPO_TOLERANCE):\n    """"""\n    Calculate the cmlc and cmlt scores for the given detections and\n    annotations.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected beats.\n    annotations : list or numpy array\n        Annotated beats.\n    phase_tolerance : float, optional\n        Allowed phase tolerance.\n    tempo_tolerance : float, optional\n        Allowed tempo tolerance.\n\n    Returns\n    -------\n    cmlc : float\n        Longest continuous segment of correct detections normalized by the\n        maximum length of both sequences (detection and annotations).\n    cmlt : float\n        Same as cmlc, but no continuity required.\n\n    References\n    ----------\n    .. [1] S. Hainsworth,\n           ""Techniques for the automated analysis of musical audio"",\n           PhD. dissertation, Department of Engineering, Cambridge University,\n           2004.\n    .. [2] A.P. Klapuri, A. Eronen, and J. Astola,\n           ""Analysis of the meter of acoustic musical signals"",\n           IEEE Transactions on Audio, Speech and Language Processing, vol. 14,\n           no. 1, 2006.\n\n    """"""\n    # at least 2 annotations must be given to calculate an interval\n    if len(annotations) < 2:\n        raise BeatIntervalError(""At least 2 annotations are needed for ""\n                                ""continuity scores, %s given."" % annotations)\n    # TODO: remove this, see TODO below\n    if len(detections) < 2:\n        raise BeatIntervalError(""At least 2 detections are needed for ""\n                                ""continuity scores, %s given."" % detections)\n    # tolerances must be greater than 0\n    if float(tempo_tolerance) <= 0 or float(phase_tolerance) <= 0:\n        raise ValueError(""Tempo and phase tolerances must be greater than 0"")\n    # determine closest annotations to detections\n    closest = find_closest_matches(detections, annotations)\n    # errors of the detections wrt. to the annotations\n    errors = calc_absolute_errors(detections, annotations, closest)\n    # detection intervals\n    det_interval = calc_intervals(detections)\n    # annotation intervals (get those intervals at the correct positions)\n    ann_interval = calc_intervals(annotations)[closest]\n    # a detection is correct, if it fulfills 2 conditions:\n    # 1) must match an annotation within a certain tolerance window, i.e. the\n    #    phase must be correct\n    correct_phase = detections[errors <= ann_interval * phase_tolerance]\n    # Note: the initially cited technical report has an additional condition\n    #       ii) on page 5 which requires the same condition to be true for the\n    #       previous detection / annotation combination. We do not enforce\n    #       this, since a) this condition is kind of pointless: why shouldn\'t\n    #       we count a correct beat just because its predecessor is not? and\n    #       b) the original Matlab implementation does not enforce it either\n    # 2) the tempo, i.e. the intervals, must be within the tempo tolerance\n    # TODO: as agreed with Matthew, this should only be enforced from the 2nd\n    #       beat onwards.\n    correct_tempo = detections[abs(1 - (det_interval / ann_interval)) <=\n                               tempo_tolerance]\n    # combine the conditions\n    correct = np.intersect1d(correct_phase, correct_tempo)\n    # convert to indices\n    correct_idx = np.searchsorted(detections, correct)\n    # cmlc: longest continuous segment of detections normalized by the max.\n    #       length of both sequences (detection and annotations)\n    length = float(max(len(detections), len(annotations)))\n    longest, _ = find_longest_continuous_segment(correct_idx)\n    cmlc = longest / length\n    # cmlt: same but for all detections (no need for continuity)\n    cmlt = len(correct) / length\n    # return a tuple\n    return cmlc, cmlt\n\n\n@array\ndef continuity(detections, annotations,\n               phase_tolerance=CONTINUITY_PHASE_TOLERANCE,\n               tempo_tolerance=CONTINUITY_TEMPO_TOLERANCE,\n               offbeat=True, double=True, triple=True):\n    """"""\n    Calculate the cmlc, cmlt, amlc and amlt scores for the given detections and\n    annotations.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected beats.\n    annotations : list or numpy array\n        Annotated beats.\n    phase_tolerance : float, optional\n        Allowed phase tolerance.\n    tempo_tolerance : float, optional\n        Allowed tempo tolerance.\n    offbeat : bool, optional\n        Include offbeat variation.\n    double  : bool, optional\n        Include double and half tempo variations (and offbeat thereof).\n    triple  : bool, optional\n        Include triple and third tempo variations (and offbeats thereof).\n\n    Returns\n    -------\n    cmlc : float\n        Tracking accuracy, continuity at the correct metrical level required.\n    cmlt : float\n        Same as cmlc, continuity at the correct metrical level not required.\n    amlc : float\n        Same as cmlc, alternate metrical levels allowed.\n    amlt : float\n        Same as cmlt, alternate metrical levels allowed.\n\n    See Also\n    --------\n    :func:`cml`\n\n    """"""\n    # neither detections nor annotations are given\n    if len(detections) == 0 and len(annotations) == 0:\n        return 1., 1., 1., 1.\n    # either a single beat detections or annotations given, score 0\n    if len(detections) <= 1 or len(annotations) <= 1:\n        return 0., 0., 0., 0.\n    # evaluate the correct tempo\n    cmlc, cmlt = cml(detections, annotations, tempo_tolerance, phase_tolerance)\n    amlc = cmlc\n    amlt = cmlt\n    # speed up calculation by skipping other metrical levels if the score is\n    # higher than 0.5 already. We must have tested the correct metrical level\n    # already, otherwise the cmlc score would be lower.\n    if cmlc > 0.5:\n        return cmlc, cmlt, amlc, amlt\n    # create different variants of the annotations:\n    # Note: double also includes half as does triple third, respectively\n    sequences = variations(annotations, offbeat=offbeat, double=double,\n                           half=double, triple=triple, third=triple)\n    # evaluate these metrical variants\n    for sequence in sequences:\n        # if other metrical levels achieve higher accuracies, take these values\n        try:\n            # Note: catch the IntervalError here, because the beat variants\n            #       could be too short for valid interval calculation;\n            #       ok, since we already have valid values for amlc & amlt\n            c, t = cml(detections, sequence, tempo_tolerance, phase_tolerance)\n        except BeatIntervalError:\n            c, t = np.nan, np.nan\n        amlc = max(amlc, c)\n        amlt = max(amlt, t)\n    # return a tuple\n    return cmlc, cmlt, amlc, amlt\n\n\ndef _histogram_bins(num_bins):\n    """"""\n    Helper function to generate the histogram bins used to calculate the error\n    histogram of the information gain.\n\n    Parameters\n    ----------\n    num_bins : int\n        Number of histogram bins.\n    Returns\n    -------\n    numpy array\n        Histogram bin edges.\n\n    Notes\n    -----\n    This functions returns the bin edges for a histogram with one more bin than\n    the requested number of bins, because the fist and last bins are added\n    together (to make the histogram circular) later on. Because of the same\n    reason, the first and the last bin are only half as wide as the others.\n\n    """"""\n    # allow only even numbers and require at least 2 bins\n    if num_bins % 2 != 0 or num_bins < 2:\n        # Note: because of the implementation details of the histogram, the\n        #       easiest way to make sure the an error of 0 is always mapped\n        #       to the centre bin is to enforce an even number of bins\n        raise ValueError(""Number of error histogram bins must be even and ""\n                         ""greater than 0"")\n    # since np.histogram accepts a sequence of bin edges we just increase the\n    # number of bins by 1, but we need to apply offset\n    offset = 0.5 / num_bins\n    # because the histogram is made circular by adding the last bin to the\n    # first one before being removed, increase the number of bins by 2\n    return np.linspace(-0.5 - offset, 0.5 + offset, num_bins + 2)\n\n\ndef _error_histogram(detections, annotations, histogram_bins):\n    """"""\n    Helper function to calculate the relative errors of the given detections\n    and annotations and map them to an histogram with the given bins edges.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected beats.\n    annotations : list or numpy array\n        Annotated beats.\n    histogram_bins : numpy array\n        Beat error histogram bin edges.\n\n    Returns\n    -------\n    error_histogram : numpy array\n        Beat error histogram.\n\n    Notes\n    -----\n    The returned error histogram is circular, i.e. it contains 1 bin less than\n    a histogram built normally with the given histogram bin edges. The values\n    of the last and first bin are summed and mapped to the first bin.\n\n    """"""\n    # get the relative errors of the detections to the annotations\n    errors = calc_relative_errors(detections, annotations)\n    # map the relative beat errors to the range of -0.5..0.5\n    errors = np.mod(errors + 0.5, -1) + 0.5\n    # get bin counts for the given errors over the distribution\n    histogram = np.histogram(errors, histogram_bins)[0].astype(np.float)\n    # make the histogram circular by adding the last bin to the first one\n    histogram[0] += histogram[-1]\n    # return the histogram without the last bin\n    return histogram[:-1]\n\n\ndef _entropy(error_histogram):\n    """"""\n    Helper function to calculate the entropy of the given error histogram.\n\n    Parameters\n    ----------\n    error_histogram : numpy array\n        Error histogram.\n\n    Returns\n    -------\n    entropy : float\n        Entropy of the error histogram.\n\n    """"""\n    # copy the error_histogram, because it must not be altered\n    histogram = np.copy(error_histogram).astype(np.float)\n    # normalize the histogram\n    histogram /= np.sum(histogram)\n    # set all 0 values to 1 to make entropy calculation well-behaved\n    histogram[histogram == 0] = 1.\n    # calculate entropy\n    return - np.sum(histogram * np.log2(histogram))\n\n\ndef _information_gain(error_histogram):\n    """"""\n    Helper function to calculate the information gain of the given error\n    histogram.\n\n    Parameters\n    ----------\n    error_histogram : numpy array\n        Error histogram.\n\n    Returns\n    -------\n    information_gain : float\n        Information gain.\n\n    """"""\n    # calculate the entropy of th error histogram\n    if np.asarray(error_histogram).any():\n        entropy = _entropy(error_histogram)\n    else:\n        # an empty error histogram has an entropy of 0\n        entropy = 0.\n    # return information gain\n    return np.log2(len(error_histogram)) - entropy\n\n\n@array\ndef information_gain(detections, annotations, num_bins=INFORMATION_GAIN_BINS):\n    """"""\n    Calculate information gain for the given detections and annotations.\n\n    Parameters\n    ----------\n    detections : list or numpy array\n        Detected beats.\n    annotations : list or numpy array\n        Annotated beats.\n    num_bins : int, optional\n        Number of bins for the beat error histogram.\n\n    Returns\n    -------\n    information_gain : float\n        Information gain.\n    error_histogram : numpy array\n        Error histogram.\n\n    References\n    ----------\n    .. [1] M. E.P. Davies, N. Degara and M. D. Plumbley,\n           ""Measuring the performance of beat tracking algorithms algorithms\n           using a beat error histogram"",\n           IEEE Signal Processing Letters, vol. 18, vo. 3, 2011.\n\n    """"""\n    # neither detections nor annotations are given, perfect score\n    if len(detections) == 0 and len(annotations) == 0:\n        # return a max. information gain and an empty error histogram\n        return np.log2(num_bins), np.zeros(num_bins)\n    # either beat detections or annotations are empty, score 0\n    # Note: use ""or"" here since we test both the detections against the\n    #       annotations and vice versa during the evaluation process\n    if len(detections) <= 1 or len(annotations) <= 1:\n        # return an information gain of 0 and a uniform beat error histogram\n        # Note: because swapped detections and annotations should return the\n        #       same uniform histogram, the maximum length of the detections\n        #       and annotations is chosen (instead of just the length of the\n        #       annotations as in the Matlab implementation).\n        max_length = max(len(detections), len(annotations))\n        return 0., np.ones(num_bins) * max_length / float(num_bins)\n    # at least 2 annotations must be given to calculate an interval\n    if len(detections) < 2 or len(annotations) < 2:\n        raise BeatIntervalError(""At least 2 annotations and 2 detections are""\n                                ""needed for Information gain."")\n    # check if there are enough beat annotations for the number of bins\n    if num_bins > len(annotations):\n        warnings.warn(""Not enough beat annotations (%d) for %d histogram bins.""\n                      % (len(annotations), num_bins))\n    # create bins edges for the error histogram\n    histogram_bins = _histogram_bins(num_bins)\n    # evaluate detections against annotations\n    fwd_histogram = _error_histogram(detections, annotations, histogram_bins)\n    fwd_ig = _information_gain(fwd_histogram)\n    # if only a few (but correct) beats are detected, the errors could be small\n    # thus evaluate also the annotations against the detections, i.e. simulate\n    # a lot of false positive detections\n    bwd_histogram = _error_histogram(annotations, detections, histogram_bins)\n    bwd_ig = _information_gain(bwd_histogram)\n    # only use the lower information gain\n    if fwd_ig < bwd_ig:\n        return fwd_ig, fwd_histogram\n    return bwd_ig, bwd_histogram\n\n\n# human readable output\ndef tostring(obj):\n    """"""\n    Format the evaluation metrics as a human readable string.\n\n    Returns\n    -------\n    str\n        Evaluation metrics formatted as a human readable string.\n\n    """"""\n    ret = \'\'\n    if obj.name is not None:\n        ret += \'%s\\n  \' % obj.name\n    ret += \'F-measure: %.3f P-score: %.3f Cemgil: %.3f Goto: %.3f CMLc: \' \\\n           \'%.3f CMLt: %.3f AMLc: %.3f AMLt: %.3f D: %.3f Dg: %.3f\' % \\\n           (obj.fmeasure, obj.pscore, obj.cemgil, obj.goto, obj.cmlc,\n            obj.cmlt, obj.amlc, obj.amlt, obj.information_gain,\n            obj.global_information_gain)\n    return ret\n\n\n# beat evaluation class\nclass BeatEvaluation(OnsetEvaluation):\n    # this class inherits from OnsetEvaluation the Precision, Recall, and\n    # F-measure evaluation stuff but uses a different evaluation window\n    """"""\n    Beat evaluation class.\n\n    Parameters\n    ----------\n    detections : str, list or numpy array\n        Detected beats.\n    annotations : str, list or numpy array\n        Annotated ground truth beats.\n    fmeasure_window : float, optional\n        F-measure evaluation window [seconds]\n    pscore_tolerance : float, optional\n        P-Score tolerance [fraction of the median beat interval].\n    cemgil_sigma : float, optional\n        Sigma of Gaussian window for Cemgil accuracy.\n    goto_threshold : float, optional\n        Threshold for Goto error.\n    goto_sigma : float, optional\n        Sigma for Goto error.\n    goto_mu : float, optional\n        Mu for Goto error.\n    continuity_phase_tolerance : float, optional\n        Continuity phase tolerance.\n    continuity_tempo_tolerance : float, optional\n        Continuity tempo tolerance.\n    information_gain_bins : int, optional\n        Number of bins for for the information gain beat error histogram.\n    offbeat : bool, optional\n        Include offbeat variation.\n    double : bool, optional\n        Include double and half tempo variations (and offbeat thereof).\n    triple : bool, optional\n        Include triple and third tempo variations (and offbeats thereof).\n    skip : float, optional\n        Skip the first `skip` seconds for evaluation.\n    downbeats : bool, optional\n        Evaluate downbeats instead of beats.\n\n    Notes\n    -----\n    The `offbeat`, `double`, and `triple` variations of the beat sequences are\n    used only for AMLc/AMLt.\n\n    """"""\n    METRIC_NAMES = [\n        (\'fmeasure\', \'F-measure\'),\n        (\'pscore\', \'P-score\'),\n        (\'cemgil\', \'Cemgil\'),\n        (\'goto\', \'Goto\'),\n        (\'cmlc\', \'CMLc\'),\n        (\'cmlt\', \'CMLt\'),\n        (\'amlc\', \'AMLc\'),\n        (\'amlt\', \'AMLt\'),\n        (\'information_gain\', \'D\'),\n        (\'global_information_gain\', \'Dg\')\n    ]\n\n    def __init__(self, detections, annotations,\n                 fmeasure_window=FMEASURE_WINDOW,\n                 pscore_tolerance=PSCORE_TOLERANCE,\n                 cemgil_sigma=CEMGIL_SIGMA, goto_threshold=GOTO_THRESHOLD,\n                 goto_sigma=GOTO_SIGMA, goto_mu=GOTO_MU,\n                 continuity_phase_tolerance=CONTINUITY_PHASE_TOLERANCE,\n                 continuity_tempo_tolerance=CONTINUITY_TEMPO_TOLERANCE,\n                 information_gain_bins=INFORMATION_GAIN_BINS,\n                 offbeat=True, double=True, triple=True, skip=0,\n                 downbeats=False, **kwargs):\n        # convert to numpy array\n        detections = np.array(detections, dtype=np.float, ndmin=1)\n        annotations = np.array(annotations, dtype=np.float, ndmin=1)\n        # use only the first column (i.e. the time stamp) or extract the\n        # downbeats if these are 2D\n        if detections.ndim > 1:\n            if downbeats:\n                detections = detections[detections[:, 1] == 1][:, 0]\n            else:\n                detections = detections[:, 0]\n        if annotations.ndim > 1:\n            if downbeats:\n                annotations = annotations[annotations[:, 1] == 1][:, 0]\n            else:\n                annotations = annotations[:, 0]\n        # sort them\n        detections = np.sort(detections)\n        annotations = np.sort(annotations)\n        # remove detections and annotations that are within the first N seconds\n        # Note: skipping the first few seconds alters the results!\n        if skip > 0:\n            start_idx = np.searchsorted(detections, skip, \'right\')\n            detections = detections[start_idx:]\n            start_idx = np.searchsorted(annotations, skip, \'right\')\n            annotations = annotations[start_idx:]\n\n        # perform onset evaluation with the appropriate fmeasure_window\n        super(BeatEvaluation, self).__init__(detections, annotations,\n                                             window=fmeasure_window, **kwargs)\n        # other scores\n        self.pscore = pscore(detections, annotations, pscore_tolerance)\n        self.cemgil = cemgil(detections, annotations, cemgil_sigma)\n        self.goto = goto(detections, annotations, goto_threshold,\n                         goto_sigma, goto_mu)\n        # continuity scores\n        scores = continuity(detections, annotations,\n                            continuity_tempo_tolerance,\n                            continuity_phase_tolerance,\n                            offbeat, double, triple)\n        self.cmlc, self.cmlt, self.amlc, self.amlt = scores\n        # information gain stuff\n        scores = information_gain(detections, annotations,\n                                  information_gain_bins)\n        self.information_gain, self.error_histogram = scores\n\n    @property\n    def global_information_gain(self):\n        """"""Global information gain.""""""\n        # Note: if only 1 file is evaluated, it is the same as information gain\n        return self.information_gain\n\n    def tostring(self, **kwargs):\n        return tostring(self)\n\n\nclass BeatMeanEvaluation(MeanEvaluation):\n    """"""\n    Class for averaging beat evaluation scores.\n\n    """"""\n    METRIC_NAMES = BeatEvaluation.METRIC_NAMES\n\n    @property\n    def fmeasure(self):\n        """"""F-measure.""""""\n        return np.nanmean([e.fmeasure for e in self.eval_objects])\n\n    @property\n    def pscore(self):\n        """"""P-score.""""""\n        return np.nanmean([e.pscore for e in self.eval_objects])\n\n    @property\n    def cemgil(self):\n        """"""Cemgil accuracy.""""""\n        return np.nanmean([e.cemgil for e in self.eval_objects])\n\n    @property\n    def goto(self):\n        """"""Goto accuracy.""""""\n        return np.nanmean([e.goto for e in self.eval_objects])\n\n    @property\n    def cmlc(self):\n        """"""CMLc.""""""\n        return np.nanmean([e.cmlc for e in self.eval_objects])\n\n    @property\n    def cmlt(self):\n        """"""CMLt.""""""\n        return np.nanmean([e.cmlt for e in self.eval_objects])\n\n    @property\n    def amlc(self):\n        """"""AMLc.""""""\n        return np.nanmean([e.amlc for e in self.eval_objects])\n\n    @property\n    def amlt(self):\n        """"""AMLt.""""""\n        return np.nanmean([e.amlt for e in self.eval_objects])\n\n    @property\n    def information_gain(self):\n        """"""Information gain.""""""\n        return np.nanmean([e.information_gain for e in self.eval_objects])\n\n    @property\n    def error_histogram(self):\n        """"""Error histogram.""""""\n        if not self.eval_objects:\n            # return an empty error histogram of length 0\n            return np.zeros(0)\n        # sum all error histograms to gather a global one\n        return np.sum([e.error_histogram for e in self.eval_objects], axis=0)\n\n    @property\n    def global_information_gain(self):\n        """"""Global information gain.""""""\n        if len(self.error_histogram) == 0:\n            # if the error histogram has length 0, the information gain is 0\n            return 0.\n        # calculate the information gain from the (global) error histogram\n        return _information_gain(self.error_histogram)\n\n    def tostring(self, **kwargs):\n        return tostring(self)\n\n\ndef add_parser(parser):\n    """"""\n    Add a beat evaluation sub-parser to an existing parser.\n\n    Parameters\n    ----------\n    parser : argparse parser instance\n        Existing argparse parser object.\n\n    Returns\n    -------\n    sub_parser : argparse sub-parser instance\n        Beat evaluation sub-parser.\n    parser_group : argparse argument group\n        Beat evaluation argument group.\n\n    """"""\n    import argparse\n    # add beat evaluation sub-parser to the existing parser\n    p = parser.add_parser(\n        \'beats\', help=\'beat evaluation\',\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        description=\'\'\'\n    This program evaluates pairs of files containing the beat annotations and\n    detections. Suffixes can be given to filter them from the list of files.\n\n    Each line represents a beat and must have the following format with values\n    being separated by whitespace [brackets indicate optional values]:\n    `beat_time [beat_inside_bar]`\n\n    Lines starting with # are treated as comments and are ignored.\n\n    To maintain compatibility with the original Matlab implementation, use the\n    arguments \'--skip 5 --no_triple\'. Please note, that the results can still\n    differ, because of the different implementation approach.\n\n    \'\'\')\n    # set defaults\n    p.set_defaults(eval=BeatEvaluation, sum_eval=None,\n                   mean_eval=BeatMeanEvaluation, load_fn=load_beats)\n    # file I/O\n    evaluation_io(p, ann_suffix=\'.beats\', det_suffix=\'.beats.txt\')\n    # parameters for sequence variants\n    s = p.add_argument_group(\'sequence manipulation arguments\')\n    s.add_argument(\'--no_offbeat\', dest=\'offbeat\', action=\'store_false\',\n                   help=\'do not include offbeat evaluation\')\n    s.add_argument(\'--no_double\', dest=\'double\', action=\'store_false\',\n                   help=\'do not include double/half tempo evaluation\')\n    s.add_argument(\'--no_triple\', dest=\'triple\', action=\'store_false\',\n                   help=\'do not include triple/third tempo evaluation\')\n    s.add_argument(\'--skip\', action=\'store\', type=float, default=0,\n                   help=\'skip first N seconds for evaluation \'\n                        \'[default=%(default).3f]\')\n    s.add_argument(\'--downbeats\', action=\'store_true\',\n                   help=\'evaluate only downbeats\')\n    # evaluation parameters\n    g = p.add_argument_group(\'beat evaluation arguments\')\n    g.add_argument(\'--window\', dest=\'fmeasure_window\', action=\'store\',\n                   type=float, default=FMEASURE_WINDOW,\n                   help=\'evaluation window for F-measure \'\n                        \'[seconds, default=%(default).3f]\')\n    g.add_argument(\'--tolerance\', dest=\'pscore_tolerance\', action=\'store\',\n                   type=float, default=PSCORE_TOLERANCE,\n                   help=\'evaluation tolerance for P-score \'\n                        \'[default=%(default).3f]\')\n    g.add_argument(\'--sigma\', dest=\'cemgil_sigma\', action=\'store\', type=float,\n                   default=CEMGIL_SIGMA,\n                   help=\'sigma for Cemgil accuracy [default=%(default).3f]\')\n    g.add_argument(\'--goto_threshold\', action=\'store\', type=float,\n                   default=GOTO_THRESHOLD,\n                   help=\'threshold for Goto error [default=%(default).3f]\')\n    g.add_argument(\'--goto_sigma\', action=\'store\', type=float,\n                   default=GOTO_SIGMA,\n                   help=\'sigma for Goto error [default=%(default).3f]\')\n    g.add_argument(\'--goto_mu\', action=\'store\', type=float,\n                   default=GOTO_MU,\n                   help=\'\xc2\xb5 for Goto error [default=%(default).3f]\')\n    g.add_argument(\'--phase_tolerance\', dest=\'continuity_phase_tolerance\',\n                   action=\'store\', type=float,\n                   default=CONTINUITY_PHASE_TOLERANCE,\n                   help=\'phase tolerance window for continuity accuracies \'\n                        \'[default=%(default).3f]\')\n    g.add_argument(\'--tempo_tolerance\', dest=\'continuity_tempo_tolerance\',\n                   action=\'store\', type=float,\n                   default=CONTINUITY_TEMPO_TOLERANCE,\n                   help=\'tempo tolerance window for continuity accuracies \'\n                        \'[default=%(default).3f]\')\n    g.add_argument(\'--bins\', dest=\'information_gain_bins\', action=\'store\',\n                   type=int, default=INFORMATION_GAIN_BINS,\n                   help=\'number of histogram bins for information gain \'\n                        \'[default=%(default)i]\')\n    # return the sub-parser and evaluation argument group\n    return p, g\n'"
madmom/evaluation/chords.py,44,"b'# encoding: utf-8\n""""""\nThis module contains chord evaluation functionality.\n\nIt provides the evaluation measures used for the MIREX ACE task, and\ntries to follow [1]_ and [2]_ as closely as possible.\n\nNotes\n-----\nThis implementation tries to follow the references and their implementation\n(e.g., https://github.com/jpauwels/MusOOEvaluator for [2]_). However, there\nare some known (and possibly some unknown) differences. If you find one not\nlisted in the following, please file an issue:\n\n - Detected chord segments are adjusted to fit the length of the annotations.\n   In particular, this means that, if necessary, filler segments of \'no chord\'\n   are added at beginnings and ends. This can result in different segmentation\n   scores compared to the original implementation.\n\nReferences\n----------\n.. [1] Christopher Harte, ""Towards Automatic Extraction of Harmony Information\n       from Music Signals."" Dissertation,\n       Department for Electronic Engineering, Queen Mary University of London,\n       2010.\n.. [2] Johan Pauwels and Geoffroy Peeters.\n       ""Evaluating Automatically Estimated Chord Sequences.""\n       In Proceedings of ICASSP 2013, Vancouver, Canada, 2013.\n\n""""""\n\nimport numpy as np\n\nfrom . import evaluation_io, EvaluationMixin\nfrom ..io import load_chords\n\n\nCHORD_DTYPE = [(\'root\', np.int),\n               (\'bass\', np.int),\n               (\'intervals\', np.int, (12,))]\n\nCHORD_ANN_DTYPE = [(\'start\', np.float),\n                   (\'end\', np.float),\n                   (\'chord\', CHORD_DTYPE)]\n\nNO_CHORD = (-1, -1, np.zeros(12, dtype=np.int))\nUNKNOWN_CHORD = (-1, -1, np.ones(12, dtype=np.int) * -1)\n\n\ndef encode(chord_labels):\n    """"""\n    Encodes chord labels to numeric interval representations.\n\n    Parameters\n    ----------\n    chord_labels : numpy structured array\n        Chord segments in `madmom.io.SEGMENT_DTYPE` format\n\n    Returns\n    -------\n    encoded_chords : numpy structured array\n        Chords in `CHORD_ANN_DTYPE` format\n\n    """"""\n    encoded_chords = np.zeros(len(chord_labels), dtype=CHORD_ANN_DTYPE)\n    encoded_chords[\'start\'] = chord_labels[\'start\']\n    encoded_chords[\'end\'] = chord_labels[\'end\']\n    encoded_chords[\'chord\'] = chords(chord_labels[\'label\'])\n    return encoded_chords\n\n\ndef chords(labels):\n    """"""\n    Transform a list of chord labels into an array of internal numeric\n    representations.\n\n    Parameters\n    ----------\n    labels : list\n        List of chord labels (str).\n\n    Returns\n    -------\n    chords : numpy.array\n        Structured array with columns \'root\', \'bass\', and \'intervals\',\n        containing a numeric representation of chords (`CHORD_DTYPE`).\n\n    """"""\n    crds = np.zeros(len(labels), dtype=CHORD_DTYPE)\n    cache = {}\n    for i, lbl in enumerate(labels):\n        cv = cache.get(lbl, None)\n        if cv is None:\n            cv = chord(lbl)\n            cache[lbl] = cv\n        crds[i] = cv\n    return crds\n\n\ndef chord(label):\n    """"""\n    Transform a chord label into the internal numeric representation of\n    (root, bass, intervals array) as defined by `CHORD_DTYPE`.\n\n    Parameters\n    ----------\n    label : str\n        Chord label.\n\n    Returns\n    -------\n    chord : tuple\n        Numeric representation of the chord: (root, bass, intervals array).\n\n    """"""\n    if label == \'N\':\n        return NO_CHORD\n    if label == \'X\':\n        return UNKNOWN_CHORD\n\n    c_idx = label.find(\':\')\n    s_idx = label.find(\'/\')\n\n    if c_idx == -1:\n        quality_str = \'maj\'\n        if s_idx == -1:\n            root_str = label\n            bass_str = \'\'\n        else:\n            root_str = label[:s_idx]\n            bass_str = label[s_idx + 1:]\n    else:\n        root_str = label[:c_idx]\n        if s_idx == -1:\n            quality_str = label[c_idx + 1:]\n            bass_str = \'\'\n        else:\n            quality_str = label[c_idx + 1:s_idx]\n            bass_str = label[s_idx + 1:]\n\n    root = pitch(root_str)\n    bass = interval(bass_str) if bass_str else 0\n    ivs = chord_intervals(quality_str)\n    ivs[bass] = 1\n\n    return root, bass, ivs\n\n\n_l = [0, 1, 1, 0, 1, 1, 1]\n_chroma_id = (np.arange(len(_l) * 2) + 1) + np.array(_l + _l).cumsum() - 1\n\n\ndef modify(base_pitch, modifier):\n    """"""\n    Modify a pitch class in integer representation by a given modifier string.\n\n    A modifier string can be any sequence of \'b\' (one semitone down)\n    and \'#\' (one semitone up).\n\n    Parameters\n    ----------\n    base_pitch : int\n        Pitch class as integer.\n    modifier : str\n        String of modifiers (\'b\' or \'#\').\n\n    Returns\n    -------\n    modified_pitch : int\n        Modified root note.\n\n    """"""\n    for m in modifier:\n        if m == \'b\':\n            base_pitch -= 1\n        elif m == \'#\':\n            base_pitch += 1\n        else:\n            raise ValueError(\'Unknown modifier: {}\'.format(m))\n    return base_pitch\n\n\ndef pitch(pitch_str):\n    """"""\n    Convert a string representation of a pitch class (consisting of root\n    note and modifiers) to an integer representation.\n\n    Parameters\n    ----------\n    pitch_str : str\n        String representation of a pitch class.\n\n    Returns\n    -------\n    pitch : int\n        Integer representation of a pitch class.\n\n    """"""\n    return modify(_chroma_id[(ord(pitch_str[0]) - ord(\'C\')) % 7],\n                  pitch_str[1:]) % 12\n\n\ndef interval(interval_str):\n    """"""\n    Convert a string representation of a musical interval into a pitch class\n    (e.g. a minor seventh \'b7\' into 10, because it is 10 semitones above its\n    base note).\n\n    Parameters\n    ----------\n    interval_str : str\n        Musical interval.\n\n    Returns\n    -------\n    pitch_class : int\n        Number of semitones to base note of interval.\n\n    """"""\n    for i, c in enumerate(interval_str):\n        if c.isdigit():\n            return modify(_chroma_id[int(interval_str[i:]) - 1],\n                          interval_str[:i]) % 12\n\n\ndef interval_list(intervals_str, given_pitch_classes=None):\n    """"""\n    Convert a list of intervals given as string to a binary pitch class\n    representation. For example, \'b3, 5\' would become\n    [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0].\n\n    Parameters\n    ----------\n    intervals_str : str\n        List of intervals as comma-separated string (e.g. \'b3, 5\').\n    given_pitch_classes : None or numpy array\n        If None, start with empty pitch class array, if numpy array of length\n        12, this array will be modified.\n\n    Returns\n    -------\n    pitch_classes : numpy array\n        Binary pitch class representation of intervals.\n\n    """"""\n    if given_pitch_classes is None:\n        given_pitch_classes = np.zeros(12, dtype=np.int)\n    for int_def in intervals_str[1:-1].split(\',\'):\n        int_def = int_def.strip()\n        if int_def[0] == \'*\':\n            given_pitch_classes[interval(int_def[1:])] = 0\n        else:\n            given_pitch_classes[interval(int_def)] = 1\n    return given_pitch_classes\n\n\n# mapping of shorthand interval notations to the actual interval representation\n_shorthands = {\n    \'maj\': interval_list(\'(1,3,5)\'),\n    \'min\': interval_list(\'(1,b3,5)\'),\n    \'dim\': interval_list(\'(1,b3,b5)\'),\n    \'aug\': interval_list(\'(1,3,#5)\'),\n    \'maj7\': interval_list(\'(1,3,5,7)\'),\n    \'min7\': interval_list(\'(1,b3,5,b7)\'),\n    \'7\': interval_list(\'(1,3,5,b7)\'),\n    \'5\': interval_list(\'(1,5)\'),\n    \'1\': interval_list(\'(1)\'),\n    \'dim7\': interval_list(\'(1,b3,b5,bb7)\'),\n    \'hdim7\': interval_list(\'(1,b3,b5,b7)\'),\n    \'minmaj7\': interval_list(\'(1,b3,5,7)\'),\n    \'maj6\': interval_list(\'(1,3,5,6)\'),\n    \'min6\': interval_list(\'(1,b3,5,6)\'),\n    \'9\': interval_list(\'(1,3,5,b7,9)\'),\n    \'maj9\': interval_list(\'(1,3,5,7,9)\'),\n    \'min9\': interval_list(\'(1,b3,5,b7,9)\'),\n    \'sus2\': interval_list(\'(1,2,5)\'),\n    \'sus4\': interval_list(\'(1,4,5)\'),\n    \'11\': interval_list(\'(1,3,5,b7,9,11)\'),\n    \'min11\': interval_list(\'(1,b3,5,b7,9,11)\'),\n    \'13\': interval_list(\'(1,3,5,b7,13)\'),\n    \'maj13\': interval_list(\'(1,3,5,7,13)\'),\n    \'min13\': interval_list(\'(1,b3,5,b7,13)\')\n}\n\n\ndef chord_intervals(quality_str):\n    """"""\n    Convert a chord quality string to a pitch class representation. For\n    example, \'maj\' becomes [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0].\n\n    Parameters\n    ----------\n    quality_str : str\n        String defining the chord quality.\n\n    Returns\n    -------\n    pitch_classes : numpy array\n        Binary pitch class representation of chord quality.\n\n    """"""\n    list_idx = quality_str.find(\'(\')\n    if list_idx == -1:\n        return _shorthands[quality_str].copy()\n    if list_idx != 0:\n        ivs = _shorthands[quality_str[:list_idx]].copy()\n    else:\n        ivs = np.zeros(12, dtype=np.int)\n\n    return interval_list(quality_str[list_idx:], ivs)\n\n\ndef merge_chords(chords):\n    """"""\n    Merge consecutive chord annotations if they represent the same chord.\n\n    Parameters\n    ----------\n    chords : numpy structured arrray\n        Chord annotations to be merged, in `CHORD_ANN_DTYPE` format.\n\n    Returns\n    -------\n    merged_chords : numpy structured array\n        Merged chord annotations, in `CHORD_ANN_DTYPE` format.\n\n    """"""\n    merged_starts = []\n    merged_ends = []\n    merged_chords = []\n    prev_chord = None\n    for start, end, chord in chords:\n        if chord != prev_chord:\n            prev_chord = chord\n            merged_starts.append(start)\n            merged_ends.append(end)\n            merged_chords.append(chord)\n        else:\n            # prolong the previous chord\n            merged_ends[-1] = end\n\n    crds = np.zeros(len(merged_chords), dtype=CHORD_ANN_DTYPE)\n    crds[\'start\'] = merged_starts\n    crds[\'end\'] = merged_ends\n    crds[\'chord\'] = merged_chords\n    return crds\n\n\ndef evaluation_pairs(det_chords, ann_chords):\n    """"""\n    Match detected with annotated chords and create paired label segments\n    for evaluation.\n\n    Parameters\n    ----------\n    det_chords : numpy structured array\n        Chord detections with \'start\' and \'end\' fields.\n    ann_chords : numpy structured array\n        Chord annotations with \'start\' and \'end\' fields.\n\n    Returns\n    -------\n    annotations : numpy structured array\n        Annotated chords of evaluation segments.\n    detections : numpy structured array\n        Detected chords of evaluation segments.\n    durations : numpy array\n        Durations of evaluation segments.\n\n    """"""\n    times = np.unique(np.hstack([ann_chords[\'start\'], ann_chords[\'end\'],\n                                 det_chords[\'start\'], det_chords[\'end\']]))\n\n    durations = times[1:] - times[:-1]\n    annotations = ann_chords[\'chord\'][\n        np.searchsorted(ann_chords[\'start\'], times[:-1], side=\'right\') - 1]\n    detections = det_chords[\'chord\'][\n        np.searchsorted(det_chords[\'start\'], times[:-1], side=\'right\') - 1]\n\n    return annotations, detections, durations\n\n\ndef score_root(det_chords, ann_chords):\n    """"""\n    Score similarity of chords based on only the root, i.e. returns a score of\n    1 if roots match, 0 otherwise.\n\n    Parameters\n    ----------\n    det_chords : numpy structured array\n        Detected chords.\n    ann_chords : numpy structured array\n        Annotated chords.\n\n    Returns\n    -------\n    scores : numpy array\n        Similarity score for each chord.\n\n    """"""\n    return (ann_chords[\'root\'] == det_chords[\'root\']).astype(np.float)\n\n\ndef score_exact(det_chords, ann_chords):\n    """"""\n    Score similarity of chords. Returns 1 if all chord information (root,\n    bass, and intervals) match exactly.\n\n    Parameters\n    ----------\n    det_chords : numpy structured array\n        Detected chords.\n    ann_chords : numpy structured array\n        Annotated chords.\n\n    Returns\n    -------\n    scores : numpy array\n        Similarity score for each chord.\n\n    """"""\n    return ((ann_chords[\'root\'] == det_chords[\'root\']) &\n            (ann_chords[\'bass\'] == det_chords[\'bass\']) &\n            ((ann_chords[\'intervals\'] == det_chords[\'intervals\']).all(axis=1))\n            ).astype(np.float)\n\n\ndef reduce_to_triads(chords, keep_bass=False):\n    """"""\n    Reduce chords to triads.\n\n    The function follows the reduction rules implemented in [1]_. If a chord\n    chord does not contain a third, major second or fourth, it is reduced to\n    a power chord. If it does not contain neither a third nor a fifth, it is\n    reduced to a single note ""chord"".\n\n    Parameters\n    ----------\n    chords : numpy structured array\n        Chords to be reduced.\n    keep_bass : bool\n        Indicates whether to keep the bass note or set it to 0.\n\n    Returns\n    -------\n    reduced_chords : numpy structured array\n        Chords reduced to triads.\n\n    References\n    ----------\n    .. [1] Johan Pauwels and Geoffroy Peeters.\n           ""Evaluating Automatically Estimated Chord Sequences.""\n           In Proceedings of ICASSP 2013, Vancouver, Canada, 2013.\n\n    """"""\n    unison = chords[\'intervals\'][:, 0].astype(bool)\n    maj_sec = chords[\'intervals\'][:, 2].astype(bool)\n    min_third = chords[\'intervals\'][:, 3].astype(bool)\n    maj_third = chords[\'intervals\'][:, 4].astype(bool)\n    perf_fourth = chords[\'intervals\'][:, 5].astype(bool)\n    dim_fifth = chords[\'intervals\'][:, 6].astype(bool)\n    perf_fifth = chords[\'intervals\'][:, 7].astype(bool)\n    aug_fifth = chords[\'intervals\'][:, 8].astype(bool)\n    no_chord = (chords[\'intervals\'] == NO_CHORD[-1]).all(axis=1)\n\n    reduced_chords = chords.copy()\n    ivs = reduced_chords[\'intervals\']\n\n    ivs[~no_chord] = interval_list(\'(1)\')\n    ivs[unison & perf_fifth] = interval_list(\'(1,5)\')\n    ivs[~perf_fourth & maj_sec] = _shorthands[\'sus2\']\n    ivs[perf_fourth & ~maj_sec] = _shorthands[\'sus4\']\n\n    ivs[min_third] = _shorthands[\'min\']\n    ivs[min_third & aug_fifth & ~perf_fifth] = interval_list(\'(1,b3,#5)\')\n    ivs[min_third & dim_fifth & ~perf_fifth] = _shorthands[\'dim\']\n\n    ivs[maj_third] = _shorthands[\'maj\']\n    ivs[maj_third & dim_fifth & ~perf_fifth] = interval_list(\'(1,3,b5)\')\n    ivs[maj_third & aug_fifth & ~perf_fifth] = _shorthands[\'aug\']\n\n    if not keep_bass:\n        reduced_chords[\'bass\'] = 0\n    else:\n        # remove bass notes if they are not part of the intervals anymore\n        reduced_chords[\'bass\'] *= ivs[range(len(reduced_chords)),\n                                      reduced_chords[\'bass\']]\n    # keep -1 in bass for no chords\n    reduced_chords[\'bass\'][no_chord] = -1\n\n    return reduced_chords\n\n\ndef reduce_to_tetrads(chords, keep_bass=False):\n    """"""\n    Reduce chords to tetrads.\n\n    The function follows the reduction rules implemented in [1]_. If a chord\n    does not contain a third, major second or fourth, it is reduced to a power\n    chord. If it does not contain neither a third nor a fifth, it is reduced\n    to a single note ""chord"".\n\n    Parameters\n    ----------\n    chords : numpy structured array\n        Chords to be reduced.\n    keep_bass : bool\n        Indicates whether to keep the bass note or set it to 0.\n\n    Returns\n    -------\n    reduced_chords : numpy structured array\n        Chords reduced to tetrads.\n\n    References\n    ----------\n    .. [1] Johan Pauwels and Geoffroy Peeters.\n           ""Evaluating Automatically Estimated Chord Sequences.""\n           In Proceedings of ICASSP 2013, Vancouver, Canada, 2013.\n\n    """"""\n    unison = chords[\'intervals\'][:, 0].astype(bool)\n    maj_sec = chords[\'intervals\'][:, 2].astype(bool)\n    min_third = chords[\'intervals\'][:, 3].astype(bool)\n    maj_third = chords[\'intervals\'][:, 4].astype(bool)\n    perf_fourth = chords[\'intervals\'][:, 5].astype(bool)\n    dim_fifth = chords[\'intervals\'][:, 6].astype(bool)\n    perf_fifth = chords[\'intervals\'][:, 7].astype(bool)\n    aug_fifth = chords[\'intervals\'][:, 8].astype(bool)\n    maj_sixth = chords[\'intervals\'][:, 9].astype(bool)\n    dim_seventh = maj_sixth\n    min_seventh = chords[\'intervals\'][:, 10].astype(bool)\n    maj_seventh = chords[\'intervals\'][:, 11].astype(bool)\n    no_chord = (chords[\'intervals\'] == NO_CHORD[-1]).all(axis=1)\n\n    reduced_chords = chords.copy()\n    ivs = reduced_chords[\'intervals\']\n\n    ivs[~no_chord] = interval_list(\'(1)\')\n    ivs[unison & perf_fifth] = interval_list(\'(1,5)\')\n\n    sus2 = ~perf_fourth & maj_sec\n    sus2_ivs = _shorthands[\'sus2\']\n    ivs[sus2] = sus2_ivs\n    ivs[sus2 & maj_sixth] = interval_list(\'(6)\', sus2_ivs.copy())\n    ivs[sus2 & maj_seventh] = interval_list(\'(7)\', sus2_ivs.copy())\n    ivs[sus2 & min_seventh] = interval_list(\'(b7)\', sus2_ivs.copy())\n\n    sus4 = perf_fourth & ~maj_sec\n    sus4_ivs = _shorthands[\'sus4\']\n    ivs[sus4] = sus4_ivs\n    ivs[sus4 & maj_sixth] = interval_list(\'(6)\', sus4_ivs.copy())\n    ivs[sus4 & maj_seventh] = interval_list(\'(7)\', sus4_ivs.copy())\n    ivs[sus4 & min_seventh] = interval_list(\'(b7)\', sus4_ivs.copy())\n\n    ivs[min_third] = _shorthands[\'min\']\n    ivs[min_third & maj_sixth] = _shorthands[\'min6\']\n    ivs[min_third & maj_seventh] = _shorthands[\'minmaj7\']\n    ivs[min_third & min_seventh] = _shorthands[\'min7\']\n    minaugfifth = min_third & ~perf_fifth & aug_fifth\n    ivs[minaugfifth] = interval_list(\'(1,b3,#5)\')\n    ivs[minaugfifth & maj_seventh] = interval_list(\'(1,b3,#5,7)\')\n    ivs[minaugfifth & min_seventh] = interval_list(\'(1,b3,#5,b7)\')\n    mindimfifth = min_third & ~perf_fifth & dim_fifth\n    ivs[mindimfifth] = _shorthands[\'dim\']\n    ivs[mindimfifth & dim_seventh] = _shorthands[\'dim7\']\n    ivs[mindimfifth & min_seventh] = _shorthands[\'hdim7\']\n\n    ivs[maj_third] = _shorthands[\'maj\']\n    ivs[maj_third & maj_sixth] = _shorthands[\'maj6\']\n    ivs[maj_third & maj_seventh] = _shorthands[\'maj7\']\n    ivs[maj_third & min_seventh] = _shorthands[\'7\']\n    majdimfifth = maj_third & ~perf_fifth & dim_fifth\n    ivs[majdimfifth] = interval_list(\'(1,3,b5)\')\n    ivs[majdimfifth & maj_seventh] = interval_list(\'(1,3,b5,7)\')\n    ivs[majdimfifth & min_seventh] = interval_list(\'(1,3,b5,b7)\')\n    majaugfifth = maj_third & ~perf_fifth & aug_fifth\n    aug_ivs = _shorthands[\'aug\']\n    ivs[majaugfifth] = _shorthands[\'aug\']\n    ivs[majaugfifth & maj_seventh] = interval_list(\'(7)\', aug_ivs.copy())\n    ivs[majaugfifth & min_seventh] = interval_list(\'(b7)\', aug_ivs.copy())\n\n    if not keep_bass:\n        reduced_chords[\'bass\'] = 0\n    else:\n        # remove bass notes if they are not part of the intervals anymore\n        reduced_chords[\'bass\'] *= ivs[range(len(reduced_chords)),\n                                      reduced_chords[\'bass\']]\n    # keep -1 in bass for no chords\n    reduced_chords[\'bass\'][no_chord] = -1\n\n    return reduced_chords\n\n\ndef select_majmin(chords):\n    """"""\n    Compute a mask that selects all major, minor, and\n    ""no chords"" with a 1, and all other chords with a 0.\n\n    Parameters\n    ----------\n    chords : numpy structured array\n        Chords to compute the mask for.\n\n    Returns\n    -------\n    mask : numpy array (boolean)\n        Selection mask for major, minor, and ""no chords"".\n\n    """"""\n    return ((chords[\'intervals\'] == _shorthands[\'maj\']).all(axis=1) |\n            (chords[\'intervals\'] == _shorthands[\'min\']).all(axis=1) |\n            (chords[\'intervals\'] == NO_CHORD[-1]).all(axis=1))\n\n\ndef select_sevenths(chords):\n    """"""\n    Compute a mask that selects all major, minor, seventh, and\n    ""no chords"" with a 1, and all other chords with a 0.\n\n    Parameters\n    ----------\n    chords : numpy structured array\n        Chords to compute the mask for.\n\n    Returns\n    -------\n    mask : numpy array (boolean)\n        Selection mask for major, minor, seventh, and ""no chords"".\n\n    """"""\n    return (select_majmin(chords) |\n            (chords[\'intervals\'] == _shorthands[\'7\']).all(axis=1) |\n            (chords[\'intervals\'] == _shorthands[\'min7\']).all(axis=1) |\n            (chords[\'intervals\'] == _shorthands[\'maj7\']).all(axis=1))\n\n\ndef adjust(det_chords, ann_chords):\n    """"""\n    Adjust the length of detected chord segments to the annotation\n    length.\n\n    Discard detected chords that start after the annotation ended,\n    and shorten the last detection to fit the last annotation;\n    discared detected chords that end before the annotation begins,\n    and shorten the first detection to match the first annotation.\n\n    Parameters\n    ----------\n    det_chords : numpy structured array\n        Detected chord segments.\n    ann_chords : numpy structured array\n        Annotated chord segments.\n\n    Returns\n    -------\n    det_chords : numpy structured array\n        Adjusted detected chord segments.\n\n    """"""\n    det_start = det_chords[0][\'start\']\n    ann_start = ann_chords[0][\'start\']\n    if det_start > ann_start:\n        filler = np.array((ann_start, det_start, chord(\'N\')),\n                          dtype=CHORD_ANN_DTYPE)\n        det_chords = np.hstack([filler, det_chords])\n    elif det_start < ann_start:\n        det_chords = det_chords[det_chords[\'end\'] > ann_start]\n        det_chords[0][\'start\'] = ann_start\n\n    det_end = det_chords[-1][\'end\']\n    ann_end = ann_chords[-1][\'end\']\n    if det_end < ann_end:\n        filler = np.array((det_end, ann_end, chord(\'N\')),\n                          dtype=CHORD_ANN_DTYPE)\n        det_chords = np.hstack([det_chords, filler])\n    elif det_end > ann_end:\n        det_chords = det_chords[det_chords[\'start\'] < ann_end]\n        det_chords[-1][\'end\'] = ann_chords[-1][\'end\']\n\n    return det_chords\n\n\ndef segmentation(ann_starts, ann_ends, det_starts, det_ends):\n    """"""\n    Compute the normalized Hamming divergence between chord\n    segmentations as defined in [1]_ (Eqs. 8.37 and 8.38).\n\n    Parameters\n    ----------\n    ann_starts : list or numpy array\n        Start times of annotated chord segments.\n    ann_ends : list or numpy array\n        End times of annotated chord segments.\n    det_starts : list or numpy array\n        Start times of detected chord segments.\n    det_ends : list or numpy array\n        End times of detected chord segments.\n\n    Returns\n    -------\n    distance : float\n        Normalised Hamming divergence between annotated and\n        detected chord segments.\n\n    References\n    ----------\n    .. [1] Christopher Harte, ""Towards Automatic Extraction of Harmony\n           Information from Music Signals."" Dissertation,\n           Department for Electronic Engineering, Queen Mary University of\n           London, 2010.\n\n    """"""\n    est_ts = np.unique(np.hstack([det_starts, det_ends]))\n    seg = 0.\n    for start, end in zip(ann_starts, ann_ends):\n        dur = end - start\n        seg_ts = np.hstack([\n            start, est_ts[(est_ts > start) & (est_ts < end)], end])\n        seg += dur - np.diff(seg_ts).max()\n\n    return seg / (ann_ends[-1] - ann_starts[0])\n\n\nclass ChordEvaluation(EvaluationMixin):\n    """"""\n    Provide various chord evaluation scores.\n\n    Parameters\n    ----------\n    detections : str\n        File containing chords detections.\n    annotations : str\n        File containing chord annotations.\n    name : str, optional\n        Name of the evaluation object (e.g., the name of the song).\n\n    """"""\n\n    METRIC_NAMES = [\n        (\'root\', \'Root\'),\n        (\'majmin\', \'MajMin\'),\n        (\'majminbass\', \'MajMinBass\'),\n        (\'sevenths\', \'Sevenths\'),\n        (\'seventhsbass\', \'SeventhsBass\'),\n        (\'segmentation\', \'Segmentation\'),\n        (\'oversegmentation\', \'OverSegmentation\'),\n        (\'undersegmentation\', \'UnderSegmentation\'),\n    ]\n\n    def __init__(self, detections, annotations, name=None, **kwargs):\n        self.name = name or \'\'\n        self.ann_chords = merge_chords(encode(annotations))\n        self.det_chords = merge_chords(adjust(encode(detections),\n                                              self.ann_chords))\n        self.annotations, self.detections, self.durations = evaluation_pairs(\n            self.det_chords, self.ann_chords)\n        self._underseg = None\n        self._overseg = None\n\n    @property\n    def length(self):\n        """"""Length of annotations.""""""\n        return self.ann_chords[\'end\'][-1] - self.ann_chords[\'start\'][0]\n\n    @property\n    def root(self):\n        """"""Fraction of correctly detected chord roots.""""""\n        return np.average(score_root(self.detections, self.annotations),\n                          weights=self.durations)\n\n    @property\n    def majmin(self):\n        """"""\n        Fraction of correctly detected chords that can be reduced to major\n        or minor triads (plus no-chord). Ignores the bass pitch class.\n        """"""\n        det_triads = reduce_to_triads(self.detections)\n        ann_triads = reduce_to_triads(self.annotations)\n        majmin_sel = select_majmin(ann_triads)\n        return np.average(score_exact(det_triads, ann_triads),\n                          weights=self.durations * majmin_sel)\n\n    @property\n    def majminbass(self):\n        """"""\n        Fraction of correctly detected chords that can be reduced to major\n        or minor triads (plus no-chord). Considers the bass pitch class.\n        """"""\n        det_triads = reduce_to_triads(self.detections, keep_bass=True)\n        ann_triads = reduce_to_triads(self.annotations, keep_bass=True)\n        majmin_sel = select_majmin(ann_triads)\n        return np.average(score_exact(det_triads, ann_triads),\n                          weights=self.durations * majmin_sel)\n\n    @property\n    def sevenths(self):\n        """"""\n        Fraction of correctly detected chords that can be reduced to a seventh\n        tetrad (plus no-chord). Ignores the bass pitch class.\n        """"""\n        det_tetrads = reduce_to_tetrads(self.detections)\n        ann_tetrads = reduce_to_tetrads(self.annotations)\n        sevenths_sel = select_sevenths(ann_tetrads)\n        return np.average(score_exact(det_tetrads, ann_tetrads),\n                          weights=self.durations * sevenths_sel)\n\n    @property\n    def seventhsbass(self):\n        """"""\n        Fraction of correctly detected chords that can be reduced to a seventh\n        tetrad (plus no-chord). Considers the bass pitch class.\n        """"""\n        det_tetrads = reduce_to_tetrads(self.detections, keep_bass=True)\n        ann_tetrads = reduce_to_tetrads(self.annotations, keep_bass=True)\n        sevenths_sel = select_sevenths(ann_tetrads)\n        return np.average(score_exact(det_tetrads, ann_tetrads),\n                          weights=self.durations * sevenths_sel)\n\n    @property\n    def undersegmentation(self):\n        """"""\n        Normalized Hamming divergence (directional) between annotations and\n        detections. Captures missed chord segments.\n        """"""\n        if self._underseg is None:\n            self._underseg = 1 - segmentation(\n                self.det_chords[\'start\'], self.det_chords[\'end\'],\n                self.ann_chords[\'start\'], self.ann_chords[\'end\'],\n            )\n        return self._underseg\n\n    @property\n    def oversegmentation(self):\n        """"""\n        Normalized Hamming divergence (directional) between detections and\n        annotations. Captures how fragmented the detected chord segments are.\n        """"""\n        if self._overseg is None:\n            self._overseg = 1 - segmentation(\n                self.ann_chords[\'start\'], self.ann_chords[\'end\'],\n                self.det_chords[\'start\'], self.det_chords[\'end\'],\n            )\n        return self._overseg\n\n    @property\n    def segmentation(self):\n        """"""Minimum of `oversegmentation` and `undersegmentation`.""""""\n        return min(self.undersegmentation, self.oversegmentation)\n\n    def tostring(self, **kwargs):\n        """"""\n        Format the evaluation metrics as a human readable string.\n\n        Returns\n        -------\n        eval_string : str\n            Evaluation metrics formatted as a human readable string.\n\n        """"""\n        ret = (\n            \'{}\\n\'\n            \'  Root: {:5.2f} MajMin: {:5.2f} MajMinBass: {:5.2f} \'\n            \'Sevenths: {:5.2f} SeventhsBass: {:5.2f}\\n\'\n            \'  Seg: {:5.2f} UnderSeg: {:5.2f} OverSeg: {:5.2f}\'.format(\n                self.name,\n                self.root * 100, self.majmin * 100, self.majminbass * 100,\n                self.sevenths * 100, self.seventhsbass * 100,\n                self.segmentation * 100, self.undersegmentation * 100,\n                self.oversegmentation * 100)\n        )\n        return ret\n\n\nclass ChordSumEvaluation(ChordEvaluation):\n    """"""\n    Class for averaging Chord evaluation scores, considering the lengths\n    of the pieces. For a detailed description of the available metrics,\n    refer to ChordEvaluation.\n\n    Parameters\n    ----------\n    eval_objects : list\n        Evaluation objects.\n    name : str, optional\n        Name to be displayed.\n\n    """"""\n    # pylint: disable=super-init-not-called\n\n    def __init__(self, eval_objects, name=None):\n        self.name = name or \'weighted mean for %d files\' % len(eval_objects)\n\n        self.annotations = np.hstack([e.annotations for e in eval_objects])\n        self.detections = np.hstack([e.detections for e in eval_objects])\n        self.durations = np.hstack([e.durations for e in eval_objects])\n\n        un_segs = [e.undersegmentation for e in eval_objects]\n        over_segs = [e.oversegmentation for e in eval_objects]\n        segs = [e.segmentation for e in eval_objects]\n        lens = [e.length for e in eval_objects]\n\n        self._underseg = np.average(un_segs, weights=lens)\n        self._overseg = np.average(over_segs, weights=lens)\n        self._seg = np.average(segs, weights=lens)\n        self._length = sum(lens)\n\n    def length(self):\n        """"""Length of all evaluation objects.""""""\n        return self._length\n\n    @property\n    def segmentation(self):\n        return self._seg\n\n\nclass ChordMeanEvaluation(ChordEvaluation):\n    """"""\n    Class for averaging chord evaluation scores, averaging piecewise (i.e.\n    ignoring the lengths of the pieces). For a detailed description of the\n    available metrics, refer to ChordEvaluation.\n\n    Parameters\n    ----------\n    eval_objects : list\n        Evaluation objects.\n    name : str, optional\n        Name to be displayed.\n\n    """"""\n    # pylint: disable=super-init-not-called\n\n    def __init__(self, eval_objects, name=None):\n        self.name = name or \'piecewise mean for %d files\' % len(eval_objects)\n        self.eval_objects = eval_objects\n\n    def length(self):\n        """"""Number of evaluation objects.""""""\n        return len(self.eval_objects)\n\n    @property\n    def root(self):\n        return np.mean([e.root for e in self.eval_objects])\n\n    @property\n    def majmin(self):\n        return np.mean([e.majmin for e in self.eval_objects])\n\n    @property\n    def majminbass(self):\n        return np.mean([e.majminbass for e in self.eval_objects])\n\n    @property\n    def sevenths(self):\n        return np.mean([e.sevenths for e in self.eval_objects])\n\n    @property\n    def seventhsbass(self):\n        return np.mean([e.seventhsbass for e in self.eval_objects])\n\n    @property\n    def undersegmentation(self):\n        return np.mean([e.undersegmentation for e in self.eval_objects])\n\n    @property\n    def oversegmentation(self):\n        return np.mean([e.oversegmentation for e in self.eval_objects])\n\n    @property\n    def segmentation(self):\n        return np.mean([e.segmentation for e in self.eval_objects])\n\n\ndef add_parser(parser):\n    """"""\n    Add a chord evaluation sub-parser to an existing parser.\n\n    Parameters\n    ----------\n    parser : argparse parser instance\n        Existing argparse parser object.\n\n    Returns\n    -------\n    sub_parser : argparse sub-parser instance\n        Chord evaluation sub-parser.\n\n    """"""\n    import argparse\n    # add chord evaluation sub-parser to the existing parser\n    p = parser.add_parser(\n        \'chords\', help=\'chord evaluation\',\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        description=\'\'\'\n    This program evaluates pairs of files containing the chord annotations and\n    predictions. Suffixes can be given to filter them from the list of files.\n\n    Each line represents a chord and must have the following format with values\n    being separated by whitespace (chord_label follows the syntax as defined\n    by Harte 2010):\n    `start_time end_time chord_label`\n    \'\'\')\n    # set defaults\n    p.set_defaults(eval=ChordEvaluation, sum_eval=ChordSumEvaluation,\n                   mean_eval=ChordMeanEvaluation, load_fn=load_chords)\n    # file I/O\n    evaluation_io(p, ann_suffix=\'.chords\', det_suffix=\'.chords.txt\')\n    # return the sub-parser and evaluation argument group\n    return p\n'"
madmom/evaluation/key.py,0,"b'# encoding: utf-8\n""""""\nThis module contains key evaluation functionality.\n\n""""""\n\nfrom collections import Counter\n\nfrom . import EvaluationMixin, evaluation_io\nfrom ..io import load_key\n\n\n_KEY_TO_SEMITONE = {\'c\': 0, \'c#\': 1, \'db\': 1, \'d\': 2, \'d#\': 3, \'eb\': 3, \'e\': 4,\n                    \'f\': 5, \'f#\': 6, \'gb\': 6, \'g\': 7, \'g#\': 8, \'ab\': 8, \'a\': 9,\n                    \'a#\': 10, \'bb\': 10, \'b\': 11, \'cb\': 11}\n\n\ndef key_label_to_class(key_label):\n    """"""\n    Convert key label to key class number.\n\n    The key label must follow the MIREX syntax defined at\n    http://music-ir.org/mirex/wiki/2017:Audio_Key_Detection:\n    `tonic mode`, where tonic is in {C, C#, Db, ... Cb} and mode in {\'major\',\n    \'maj\', \'minor\', \'min\'}. The label will be converted into a class id based\n    on the root pitch id (c .. 0, c# .. 1, ..., cb ... 11) plus 12 if in minor\n    mode.\n\n    Parameters\n    ----------\n    key_label : str\n        Key label.\n\n    Returns\n    -------\n    key_class : int\n        Key class.\n\n    Examples\n    --------\n    >>> from madmom.evaluation.key import key_label_to_class\n    >>> key_label_to_class(\'D major\')\n    2\n\n    >>> key_label_to_class(\'D minor\')\n    14\n\n    """"""\n    tonic, mode = key_label.split()\n    if tonic.lower() not in _KEY_TO_SEMITONE.keys():\n        raise ValueError(\'Unknown tonic: {}\'.format(tonic))\n    key_class = _KEY_TO_SEMITONE[tonic.lower()]\n    if mode in [\'minor\', \'min\']:\n        key_class += 12\n    elif mode in [\'major\', \'maj\']:\n        key_class += 0\n    else:\n        raise ValueError(\'Unknown mode: {}\'.format(mode))\n    return key_class\n\n\ndef error_type(det_key, ann_key, strict_fifth=False):\n    """"""\n    Compute the evaluation score and error category for a predicted key\n    compared to the annotated key.\n\n    Categories and evaluation scores follow the evaluation strategy used\n    for MIREX (see http://music-ir.org/mirex/wiki/2017:Audio_Key_Detection).\n    There are two evaluation modes for the \'fifth\' category: by default,\n    a detection falls into the \'fifth\' category if it is the fifth of the\n    annotation, or the annotation is the fifth of the detection.\n    If `strict_fifth` is `True`, only the former case is considered. This is\n    the mode used for MIREX.\n\n    Parameters\n    ----------\n    det_key : int\n        Detected key class.\n    ann_key : int\n        Annotated key class.\n    strict_fifth: bool\n        Use strict interpretation of the \'fifth\' category, as in MIREX.\n\n    Returns\n    -------\n    score, category : float, str\n        Evaluation score and error category.\n\n    """"""\n    ann_root = ann_key % 12\n    ann_mode = ann_key // 12\n    det_root = det_key % 12\n    det_mode = det_key // 12\n    major, minor = 0, 1\n\n    if det_root == ann_root and det_mode == ann_mode:\n        return 1.0, \'correct\'\n    if det_mode == ann_mode and ((det_root - ann_root) % 12 == 7):\n        return 0.5, \'fifth\'\n    if not strict_fifth and (det_mode == ann_mode and\n                             ((det_root - ann_root) % 12 == 5)):\n        return 0.5, \'fifth\'\n    if (ann_mode == major and det_mode != ann_mode and (\n            (det_root - ann_root) % 12 == 9)):\n        return 0.3, \'relative\'\n    if (ann_mode == minor and det_mode != ann_mode and (\n            (det_root - ann_root) % 12 == 3)):\n        return 0.3, \'relative\'\n    if det_mode != ann_mode and det_root == ann_root:\n        return 0.2, \'parallel\'\n    else:\n        return 0.0, \'other\'\n\n\nclass KeyEvaluation(EvaluationMixin):\n    """"""\n    Provide the key evaluation score.\n\n    Parameters\n    ----------\n    detection : str\n        File containing detected key\n    annotation : str\n        File containing annotated key\n    strict_fifth : bool, optional\n        Use strict interpretation of the \'fifth\' category, as in MIREX.\n    name : str, optional\n        Name of the evaluation object (e.g., the name of the song).\n\n    """"""\n\n    METRIC_NAMES = [\n        (\'score\', \'Score\'),\n        (\'error_category\', \'Error Category\')\n    ]\n\n    def __init__(self, detection, annotation, strict_fifth=False, name=None,\n                 **kwargs):\n        self.name = name or \'\'\n        self.detection = key_label_to_class(detection)\n        self.annotation = key_label_to_class(annotation)\n        self.score, self.error_category = error_type(\n            self.detection, self.annotation, strict_fifth\n        )\n\n    def tostring(self, **kwargs):\n        """"""\n        Format the evaluation as a human readable string.\n\n        Returns\n        -------\n        str\n            Evaluation score and category as a human readable string.\n\n        """"""\n        ret = \'{}: \'.format(self.name) if self.name else \'\'\n        ret += \'{:3.1f}, {}\'.format(self.score, self.error_category)\n        return ret\n\n\nclass KeyMeanEvaluation(EvaluationMixin):\n    """"""\n    Class for averaging key evaluations.\n\n    Parameters\n    ----------\n    eval_objects : list\n        Key evaluation objects.\n    name : str, optional\n        Name to be displayed.\n\n    """"""\n\n    METRIC_NAMES = [\n        (\'correct\', \'Correct\'),\n        (\'fifth\', \'Fifth\'),\n        (\'relative\', \'Relative\'),\n        (\'parallel\', \'Parallel\'),\n        (\'other\', \'Other\'),\n        (\'weighted\', \'Weighted\'),\n    ]\n\n    def __init__(self, eval_objects, name=None):\n        self.name = name or \'mean for {:d} files\'.format(len(eval_objects))\n\n        n = len(eval_objects)\n        c = Counter(e.error_category for e in eval_objects)\n\n        self.correct = float(c[\'correct\']) / n\n        self.fifth = float(c[\'fifth\']) / n\n        self.relative = float(c[\'relative\']) / n\n        self.parallel = float(c[\'parallel\']) / n\n        self.other = float(c[\'other\']) / n\n        self.weighted = sum(e.score for e in eval_objects) / n\n\n    def tostring(self, **kwargs):\n        return (\'{}\\n  Weighted: {:.3f}  Correct: {:.3f}  Fifth: {:.3f}  \'\n                \'Relative: {:.3f}  Parallel: {:.3f}  Other: {:.3f}\'.format(\n                    self.name, self.weighted, self.correct, self.fifth,\n                    self.relative, self.parallel, self.other))\n\n\ndef add_parser(parser):\n    """"""\n    Add a key evaluation sub-parser to an existing parser.\n\n    Parameters\n    ----------\n    parser : argparse parser instance\n        Existing argparse parser object.\n\n    Returns\n    -------\n    sub_parser : argparse sub-parser instance\n        Key evaluation sub-parser.\n\n    """"""\n    import argparse\n    # add key evaluation sub-parser to the existing parser\n    p = parser.add_parser(\n        \'key\', help=\'key evaluation\',\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        description=\'\'\'\n    This program evaluates pairs of files containing global key annotations\n    and predictions. Suffixes can be given to filter them from the list of\n    files.\n\n    Each file must contain only the global key and follow the syntax outlined\n    in http://music-ir.org/mirex/wiki/2017:Audio_Key_Detection:\n    `tonic mode`, where tonic is in {C, C#, Db, ... Cb} and mode in {\'major\',\n    \'maj\', \'minor\', \'min\'}.\n\n    To maintain compatibility with MIREX evaluation scores, use the\n    --strict_fifth flag.\n    \'\'\')\n    # set defaults\n    p.set_defaults(eval=KeyEvaluation, mean_eval=KeyMeanEvaluation,\n                   sum_eval=None, load_fn=load_key)\n    # file I/O\n    evaluation_io(p, ann_suffix=\'.key\', det_suffix=\'.key.txt\')\n    p.add_argument(\'--strict_fifth\', dest=\'strict_fifth\', action=\'store_true\',\n                   help=\'Strict interpretation of the \\""fifth\\"" category.\')\n    # return the sub-parser and evaluation argument group\n    return p\n'"
madmom/evaluation/notes.py,32,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains note evaluation functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport warnings\nimport numpy as np\n\nfrom . import (evaluation_io, MultiClassEvaluation, SumEvaluation,\n               MeanEvaluation)\nfrom .onsets import onset_evaluation, OnsetEvaluation\nfrom ..io import load_notes\n\n\n# default note evaluation values\nWINDOW = 0.025\n\n\ndef remove_duplicate_notes(data):\n    """"""\n    Remove duplicate rows from the array.\n\n    Parameters\n    ----------\n    data : numpy array\n        Data.\n\n    Returns\n    -------\n    numpy array\n        Data array with duplicate rows removed.\n\n    Notes\n    -----\n    This function removes only exact duplicates.\n\n    """"""\n    if data.size == 0:\n        return data\n    # found here: http://stackoverflow.com/questions/2828059/\n    # find the unique rows\n    order = np.ascontiguousarray(data).view(\n        np.dtype((np.void, data.dtype.itemsize * data.shape[1])))\n    unique = np.unique(order, return_index=True)[1]\n    # only use the unique rows\n    data = data[unique]\n    # sort them by the first column and return them\n    return data[data[:, 0].argsort()]\n\n\n# note onset evaluation function\ndef note_onset_evaluation(detections, annotations, window=WINDOW):\n    """"""\n    Determine the true/false positive/negative note onset detections.\n\n    Parameters\n    ----------\n    detections : numpy array\n        Detected notes.\n    annotations : numpy array\n        Annotated ground truth notes.\n    window : float, optional\n        Evaluation window [seconds].\n\n    Returns\n    -------\n    tp : numpy array, shape (num_tp, 2)\n        True positive detections.\n    fp : numpy array, shape (num_fp, 2)\n        False positive detections.\n    tn : numpy array, shape (0, 2)\n        True negative detections (empty, see notes).\n    fn : numpy array, shape (num_fn, 2)\n        False negative detections.\n    errors : numpy array, shape (num_tp, 2)\n        Errors of the true positive detections wrt. the annotations.\n\n    Notes\n    -----\n    The expected note row format is:\n\n    \'note_time\' \'MIDI_note\' [\'duration\' [\'MIDI_velocity\']]\n\n    The returned true negative array is empty, because we are not interested\n    in this class, since it is magnitudes bigger than true positives array.\n\n    """"""\n    # make sure the arrays have the correct types and dimensions\n    detections = np.asarray(detections, dtype=np.float)\n    annotations = np.asarray(annotations, dtype=np.float)\n    # check dimensions\n    if detections.ndim != 2 or annotations.ndim != 2:\n        raise ValueError(\'detections and annotations must be 2D arrays\')\n\n    # init TP, FP, TN and FN lists\n    tp = np.zeros((0, 2))\n    fp = np.zeros((0, 2))\n    tn = np.zeros((0, 2))  # this will not be altered\n    fn = np.zeros((0, 2))\n    errors = np.zeros((0, 2))\n    # if neither detections nor annotations are given\n    if detections.size == 0 and annotations.size == 0:\n        # return the arrays as is\n        return tp, fp, tn, fn, errors\n    # if only detections are given\n    elif annotations.size == 0:\n        # all detections are FP\n        return tp, detections, tn, fn, errors\n    # if only annotations are given\n    elif detections.size == 0:\n        # all annotations are FN\n        return tp, tp, tn, annotations, errors\n\n    # TODO: extend to also evaluate the duration and velocity of notes\n    # for onset evaluation use only the onset time and midi note number\n    detections = detections[:, :2]\n    annotations = annotations[:, :2]\n\n    # get a list of all notes detected / annotated\n    notes = np.unique(np.concatenate((detections[:, 1],\n                                      annotations[:, 1]))).tolist()\n    # iterate over all notes\n    for note in notes:\n        # perform normal onset detection on each note\n        det = detections[detections[:, 1] == note]\n        ann = annotations[annotations[:, 1] == note]\n        tp_, fp_, _, fn_, err_ = onset_evaluation(det[:, 0], ann[:, 0], window)\n        # convert returned arrays to lists and append the detections and\n        # annotations to the correct lists\n        tp = np.vstack((tp, det[np.in1d(det[:, 0], tp_)]))\n        fp = np.vstack((fp, det[np.in1d(det[:, 0], fp_)]))\n        fn = np.vstack((fn, ann[np.in1d(ann[:, 0], fn_)]))\n        # append the note number to the errors\n        err_ = np.vstack((np.array(err_),\n                          np.repeat(np.asarray([note]), len(err_)))).T\n        errors = np.vstack((errors, err_))\n    # check calculations\n    if len(tp) + len(fp) != len(detections):\n        raise AssertionError(\'bad TP / FP calculation\')\n    if len(tp) + len(fn) != len(annotations):\n        raise AssertionError(\'bad FN calculation\')\n    if len(tp) != len(errors):\n        raise AssertionError(\'bad errors calculation\')\n    # sort the arrays\n    # Note: The errors must have the same sorting order as the TPs, so they\n    #       must be done first (before the TPs get sorted)\n    errors = errors[tp[:, 0].argsort()]\n    tp = tp[tp[:, 0].argsort()]\n    fp = fp[fp[:, 0].argsort()]\n    fn = fn[fn[:, 0].argsort()]\n    # return the arrays\n    return tp, fp, tn, fn, errors\n\n\n# for note evaluation with Precision, Recall, F-measure use the Evaluation\n# class and just define the evaluation function\n# TODO: extend to also report the measures without octave errors\nclass NoteEvaluation(MultiClassEvaluation):\n    """"""\n    Evaluation class for measuring Precision, Recall and F-measure of notes.\n\n    Parameters\n    ----------\n    detections : str, list or numpy array\n        Detected notes.\n    annotations : str, list or numpy array\n        Annotated ground truth notes.\n    window : float, optional\n        F-measure evaluation window [seconds]\n    delay : float, optional\n        Delay the detections `delay` seconds for evaluation.\n\n    """"""\n\n    def __init__(self, detections, annotations, window=WINDOW, delay=0,\n                 **kwargs):\n        # convert to numpy array\n        detections = np.array(detections, dtype=np.float, ndmin=2)\n        annotations = np.array(annotations, dtype=np.float, ndmin=2)\n        # shift the detections if needed\n        if delay != 0:\n            detections[:, 0] += delay\n        # evaluate\n        numbers = note_onset_evaluation(detections, annotations, window)\n        tp, fp, tn, fn, errors = numbers\n        super(NoteEvaluation, self).__init__(tp, fp, tn, fn, **kwargs)\n        self.errors = errors\n        # save them for the individual note evaluation\n        self.detections = detections\n        self.annotations = annotations\n        self.window = window\n\n    @property\n    def mean_error(self):\n        """"""Mean of the errors.""""""\n        warnings.warn(\'mean_error is given for all notes, this will change!\')\n        if len(self.errors) == 0:\n            return np.nan\n        return np.mean(self.errors[:, 0])\n\n    @property\n    def std_error(self):\n        """"""Standard deviation of the errors.""""""\n        warnings.warn(\'std_error is given for all notes, this will change!\')\n        if len(self.errors) == 0:\n            return np.nan\n        return np.std(self.errors[:, 0])\n\n    def tostring(self, notes=False, **kwargs):\n        """"""\n\n        Parameters\n        ----------\n        notes : bool, optional\n            Display detailed output for all individual notes.\n\n        Returns\n        -------\n        str\n            Evaluation metrics formatted as a human readable string.\n\n        """"""\n        ret = \'\'\n        if self.name is not None:\n            ret += \'%s\\n  \' % self.name\n        # add statistics for the individual note\n        if notes:\n            # determine which notes are present\n            notes = []\n            if self.tp.any():\n                notes = np.append(notes, np.unique(self.tp[:, 1]))\n            if self.fp.any():\n                notes = np.append(notes, np.unique(self.fp[:, 1]))\n            if self.tn.any():\n                notes = np.append(notes, np.unique(self.tn[:, 1]))\n            if self.fn.any():\n                notes = np.append(notes, np.unique(self.fn[:, 1]))\n            # evaluate them individually\n            for note in sorted(np.unique(notes)):\n                # detections and annotations for this note (only onset times)\n                det = self.detections[self.detections[:, 1] == note][:, 0]\n                ann = self.annotations[self.annotations[:, 1] == note][:, 0]\n                name = \'MIDI note %s\' % note\n                e = OnsetEvaluation(det, ann, self.window, name=name)\n                # append to the output string\n                ret += \'  %s\\n\' % e.tostring(notes=False)\n        # normal formatting\n        ret += \'Notes: %5d TP: %5d FP: %4d FN: %4d \' \\\n               \'Precision: %.3f Recall: %.3f F-measure: %.3f \' \\\n               \'Acc: %.3f mean: %5.1f ms std: %5.1f ms\' % \\\n               (self.num_annotations, self.num_tp, self.num_fp, self.num_fn,\n                self.precision, self.recall, self.fmeasure, self.accuracy,\n                self.mean_error * 1000., self.std_error * 1000.)\n        # return\n        return ret\n\n\nclass NoteSumEvaluation(SumEvaluation, NoteEvaluation):\n    """"""\n    Class for summing note evaluations.\n\n    """"""\n\n    @property\n    def errors(self):\n        """"""Errors of the true positive detections wrt. the ground truth.""""""\n        if not self.eval_objects:\n            # return empty array\n            return np.zeros((0, 2))\n        return np.concatenate([e.errors for e in self.eval_objects])\n\n\nclass NoteMeanEvaluation(MeanEvaluation, NoteSumEvaluation):\n    """"""\n    Class for averaging note evaluations.\n\n    """"""\n\n    @property\n    def mean_error(self):\n        """"""Mean of the errors.""""""\n        warnings.warn(\'mean_error is given for all notes, this will change!\')\n        return np.nanmean([e.mean_error for e in self.eval_objects])\n\n    @property\n    def std_error(self):\n        """"""Standard deviation of the errors.""""""\n        warnings.warn(\'std_error is given for all notes, this will change!\')\n        return np.nanmean([e.std_error for e in self.eval_objects])\n\n    def tostring(self, **kwargs):\n        """"""\n        Format the evaluation metrics as a human readable string.\n\n        Returns\n        -------\n        str\n            Evaluation metrics formatted as a human readable string.\n\n        """"""\n        # format with floats instead of integers\n        ret = \'\'\n        if self.name is not None:\n            ret += \'%s\\n  \' % self.name\n        ret += \'Notes: %5.2f TP: %5.2f FP: %5.2f FN: %5.2f \' \\\n               \'Precision: %.3f Recall: %.3f F-measure: %.3f \' \\\n               \'Acc: %.3f mean: %5.1f ms std: %5.1f ms\' % \\\n               (self.num_annotations, self.num_tp, self.num_fp, self.num_fn,\n                self.precision, self.recall, self.fmeasure, self.accuracy,\n                self.mean_error * 1000., self.std_error * 1000.)\n        return ret\n\n\ndef add_parser(parser):\n    """"""\n    Add a note evaluation sub-parser to an existing parser.\n\n    Parameters\n    ----------\n    parser : argparse parser instance\n        Existing argparse parser object.\n\n    Returns\n    -------\n    sub_parser : argparse sub-parser instance\n        Note evaluation sub-parser.\n    parser_group : argparse argument group\n        Note evaluation argument group.\n\n    """"""\n    import argparse\n    # add tempo evaluation sub-parser to the existing parser\n    p = parser.add_parser(\n        \'notes\', help=\'note evaluation\',\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        description=\'\'\'\n    This program evaluates pairs of files containing the note annotations and\n    detections. Suffixes can be given to filter them from the list of files.\n\n    Each line represents a note and must have the following format with values\n    being separated by whitespace [brackets indicate optional values]:\n    `onset_time MIDI_note [duration [velocity]]`\n\n    Lines starting with # are treated as comments and are ignored.\n\n    \'\'\')\n    # set defaults\n    p.set_defaults(eval=NoteEvaluation, sum_eval=NoteSumEvaluation,\n                   mean_eval=NoteMeanEvaluation, load_fn=load_notes)\n    # file I/O\n    evaluation_io(p, ann_suffix=\'.notes\', det_suffix=\'.notes.txt\')\n    # evaluation parameters\n    g = p.add_argument_group(\'note evaluation arguments\')\n    g.add_argument(\'-w\', dest=\'window\', action=\'store\', type=float,\n                   default=0.025,\n                   help=\'evaluation window (+/- the given size) \'\n                        \'[seconds, default=%(default)s]\')\n    g.add_argument(\'--delay\', action=\'store\', type=float, default=0.,\n                   help=\'add given delay to all detections [seconds]\')\n    # return the sub-parser and evaluation argument group\n    return p, g\n'"
madmom/evaluation/onsets.py,26,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains onset evaluation functionality described in [1]_:\n\nReferences\n----------\n.. [1] Sebastian B\xc3\xb6ck, Florian Krebs and Markus Schedl,\n       ""Evaluating the Online Capabilities of Onset Detection Methods"",\n       Proceedings of the 13th International Society for Music Information\n       Retrieval Conference (ISMIR), 2012.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\nfrom . import Evaluation, MeanEvaluation, SumEvaluation, evaluation_io\nfrom ..io import load_onsets\nfrom ..utils import combine_events\n\n# default onset evaluation values\nWINDOW = 0.025\nCOMBINE = 0.03\n\n\n# onset evaluation function\ndef onset_evaluation(detections, annotations, window=WINDOW):\n    """"""\n    Determine the true/false positive/negative detections.\n\n    Parameters\n    ----------\n    detections : numpy array\n        Detected notes.\n    annotations : numpy array\n        Annotated ground truth notes.\n    window : float, optional\n        Evaluation window [seconds].\n\n    Returns\n    -------\n    tp : numpy array, shape (num_tp,)\n        True positive detections.\n    fp : numpy array, shape (num_fp,)\n        False positive detections.\n    tn : numpy array, shape (0,)\n        True negative detections (empty, see notes).\n    fn : numpy array, shape (num_fn,)\n        False negative detections.\n    errors : numpy array, shape (num_tp,)\n        Errors of the true positive detections wrt. the annotations.\n\n    Notes\n    -----\n    The returned true negative array is empty, because we are not interested\n    in this class, since it is magnitudes bigger than true positives array.\n\n    """"""\n    # make sure the arrays have the correct types and dimensions\n    detections = np.asarray(detections, dtype=np.float)\n    annotations = np.asarray(annotations, dtype=np.float)\n    # TODO: right now, it only works with 1D arrays\n    if detections.ndim > 1 or annotations.ndim > 1:\n        raise NotImplementedError(\'please implement multi-dim support\')\n\n    # init TP, FP, FN and errors\n    tp = np.zeros(0)\n    fp = np.zeros(0)\n    tn = np.zeros(0)  # we will not alter this array\n    fn = np.zeros(0)\n    errors = np.zeros(0)\n\n    # if neither detections nor annotations are given\n    if len(detections) == 0 and len(annotations) == 0:\n        # return the arrays as is\n        return tp, fp, tn, fn, errors\n    # if only detections are given\n    elif len(annotations) == 0:\n        # all detections are FP\n        return tp, detections, tn, fn, errors\n    # if only annotations are given\n    elif len(detections) == 0:\n        # all annotations are FN\n        return tp, fp, tn, annotations, errors\n\n    # window must be greater than 0\n    if float(window) <= 0:\n        raise ValueError(\'window must be greater than 0\')\n\n    # sort the detections and annotations\n    det = np.sort(detections)\n    ann = np.sort(annotations)\n    # cache variables\n    det_length = len(detections)\n    ann_length = len(annotations)\n    det_index = 0\n    ann_index = 0\n    # iterate over all detections and annotations\n    while det_index < det_length and ann_index < ann_length:\n        # fetch the first detection\n        d = det[det_index]\n        # fetch the first annotation\n        a = ann[ann_index]\n        # compare them\n        if abs(d - a) <= window:\n            # TP detection\n            tp = np.append(tp, d)\n            # append the error to the array\n            errors = np.append(errors, d - a)\n            # increase the detection and annotation index\n            det_index += 1\n            ann_index += 1\n        elif d < a:\n            # FP detection\n            fp = np.append(fp, d)\n            # increase the detection index\n            det_index += 1\n            # do not increase the annotation index\n        elif d > a:\n            # we missed a annotation: FN\n            fn = np.append(fn, a)\n            # do not increase the detection index\n            # increase the annotation index\n            ann_index += 1\n        else:\n            # can\'t match detected with annotated onset\n            raise AssertionError(\'can not match % with %\', d, a)\n    # the remaining detections are FP\n    fp = np.append(fp, det[det_index:])\n    # the remaining annotations are FN\n    fn = np.append(fn, ann[ann_index:])\n    # check calculations\n    if len(tp) + len(fp) != len(detections):\n        raise AssertionError(\'bad TP / FP calculation\')\n    if len(tp) + len(fn) != len(annotations):\n        raise AssertionError(\'bad FN calculation\')\n    if len(tp) != len(errors):\n        raise AssertionError(\'bad errors calculation\')\n    # convert to numpy arrays and return them\n    return np.array(tp), np.array(fp), tn, np.array(fn), np.array(errors)\n\n\n# for onset evaluation with Precision, Recall, F-measure use the Evaluation\n# class and just define the evaluation and error functions\nclass OnsetEvaluation(Evaluation):\n    """"""\n    Evaluation class for measuring Precision, Recall and F-measure of onsets.\n\n    Parameters\n    ----------\n    detections : str, list or numpy array\n        Detected notes.\n    annotations : str, list or numpy array\n        Annotated ground truth notes.\n    window : float, optional\n        F-measure evaluation window [seconds]\n    combine : float, optional\n        Combine all annotated onsets within `combine` seconds.\n    delay : float, optional\n        Delay the detections `delay` seconds for evaluation.\n\n    """"""\n\n    def __init__(self, detections, annotations, window=WINDOW, combine=0,\n                 delay=0, **kwargs):\n        # convert to numpy array\n        detections = np.array(detections, dtype=np.float, ndmin=1)\n        annotations = np.array(annotations, dtype=np.float, ndmin=1)\n        # combine the annotations if needed\n        if combine > 0:\n            annotations = combine_events(annotations, combine)\n        # shift the detections if needed\n        if delay != 0:\n            detections += delay\n        # evaluate\n        tp, fp, tn, fn, errors = onset_evaluation(detections, annotations,\n                                                  window)\n        # instantiate a Evaluation object\n        super(OnsetEvaluation, self).__init__(tp, fp, tn, fn, **kwargs)\n        # add the errors\n        self.errors = errors\n\n    @property\n    def mean_error(self):\n        """"""Mean of the errors.""""""\n        if len(self.errors) == 0:\n            return np.nan\n        return np.mean(self.errors)\n\n    @property\n    def std_error(self):\n        """"""Standard deviation of the errors.""""""\n        if len(self.errors) == 0:\n            return np.nan\n        return np.std(self.errors)\n\n    def tostring(self, **kwargs):\n        """"""\n        Format the evaluation metrics as a human readable string.\n\n        Returns\n        -------\n        str\n            Evaluation metrics formatted as a human readable string.\n\n        """"""\n        ret = \'\'\n        if self.name is not None:\n            ret += \'%s\\n  \' % self.name\n        ret += \'Onsets: %5d TP: %5d FP: %5d FN: %5d Precision: %.3f \' \\\n               \'Recall: %.3f F-measure: %.3f mean: %5.1f ms std: %5.1f ms\' % \\\n               (self.num_annotations, self.num_tp, self.num_fp, self.num_fn,\n                self.precision, self.recall, self.fmeasure,\n                self.mean_error * 1000., self.std_error * 1000.)\n        return ret\n\n    def __str__(self):\n        return self.tostring()\n\n\nclass OnsetSumEvaluation(SumEvaluation, OnsetEvaluation):\n    """"""\n    Class for summing onset evaluations.\n\n    """"""\n\n    @property\n    def errors(self):\n        """"""Errors of the true positive detections wrt. the ground truth.""""""\n        if not self.eval_objects:\n            # return empty array\n            return np.zeros(0)\n        return np.concatenate([e.errors for e in self.eval_objects])\n\n\nclass OnsetMeanEvaluation(MeanEvaluation, OnsetSumEvaluation):\n    """"""\n    Class for averaging onset evaluations.\n\n    """"""\n\n    @property\n    def mean_error(self):\n        """"""Mean of the errors.""""""\n        return np.nanmean([e.mean_error for e in self.eval_objects])\n\n    @property\n    def std_error(self):\n        """"""Standard deviation of the errors.""""""\n        return np.nanmean([e.std_error for e in self.eval_objects])\n\n    def tostring(self, **kwargs):\n        """"""\n        Format the evaluation metrics as a human readable string.\n\n        Returns\n        -------\n        str\n            Evaluation metrics formatted as a human readable string.\n\n        """"""\n        # format with floats instead of integers\n        ret = \'\'\n        if self.name is not None:\n            ret += \'%s\\n  \' % self.name\n        ret += \'Onsets: %5.2f TP: %5.2f FP: %5.2f FN: %5.2f \' \\\n               \'Precision: %.3f Recall: %.3f F-measure: %.3f \' \\\n               \'mean: %5.1f ms std: %5.1f ms\' % \\\n               (self.num_annotations, self.num_tp, self.num_fp, self.num_fn,\n                self.precision, self.recall, self.fmeasure,\n                self.mean_error * 1000., self.std_error * 1000.)\n        return ret\n\n\ndef add_parser(parser):\n    """"""\n    Add an onset evaluation sub-parser to an existing parser.\n\n    Parameters\n    ----------\n    parser : argparse parser instance\n        Existing argparse parser object.\n\n    Returns\n    -------\n    sub_parser : argparse sub-parser instance\n        Onset evaluation sub-parser.\n    parser_group : argparse argument group\n        Onset evaluation argument group.\n\n    """"""\n    import argparse\n    # add beat evaluation sub-parser to the existing parser\n    p = parser.add_parser(\n        \'onsets\', help=\'onset evaluation\',\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        description=\'\'\'\n    This program evaluates pairs of files containing the onset annotations and\n    detections. Suffixes can be given to filter them from the list of files.\n\n    Each line represents an onset and must have the following format:\n    `onset_time`.\n\n    Lines starting with # are treated as comments and are ignored.\n\n    \'\'\')\n    # set defaults\n    p.set_defaults(eval=OnsetEvaluation, sum_eval=OnsetSumEvaluation,\n                   mean_eval=OnsetMeanEvaluation, load_fn=load_onsets)\n    # file I/O\n    evaluation_io(p, ann_suffix=\'.onsets\', det_suffix=\'.onsets.txt\')\n    # evaluation parameters\n    g = p.add_argument_group(\'onset evaluation arguments\')\n    g.add_argument(\'-w\', dest=\'window\', action=\'store\', type=float,\n                   default=WINDOW,\n                   help=\'evaluation window (+/- the given size) \'\n                        \'[seconds, default=%(default).3f]\')\n    g.add_argument(\'-c\', dest=\'combine\', action=\'store\', type=float,\n                   default=COMBINE,\n                   help=\'combine annotation events within this range \'\n                        \'[seconds, default=%(default).3f]\')\n    g.add_argument(\'--delay\', action=\'store\', type=float, default=0.,\n                   help=\'add given delay to all detections [seconds]\')\n    # return the sub-parser and evaluation argument group\n    return p, g\n'"
madmom/evaluation/tempo.py,18,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains tempo evaluation functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport warnings\nimport numpy as np\n\nfrom . import EvaluationMixin, MeanEvaluation, evaluation_io\nfrom ..io import load_tempo\n\n# default tempo evaluation values\nTOLERANCE = 0.04\nDOUBLE = True\nTRIPLE = True\n\n\n# function to sort tempi\ndef sort_tempo(tempo):\n    """"""\n    Sort tempi according to their strengths.\n\n    Parameters\n    ----------\n    tempo : numpy array, shape (num_tempi, 2)\n        Tempi (first column) and their relative strength (second column).\n\n    Returns\n    -------\n    tempi : numpy array, shape (num_tempi, 2)\n        Tempi sorted according to their strength.\n\n    """"""\n    tempo = np.array(tempo, copy=False, ndmin=1)\n    if tempo.ndim != 2:\n        raise ValueError(\'`tempo` has no strength information, cannot sort \'\n                         \'them.\')\n    tempi = tempo[:, 0]\n    strengths = tempo[:, 1]\n    # Note: use \'mergesort\', because we want a stable sorting algorithm\n    #       which keeps the order of the keys in case of duplicate keys\n    #       but we need to apply this (-strengths) trick because we want\n    #       tempi with uniformly distributed strengths to keep their order\n    sort_idx = (-strengths).argsort(kind=\'mergesort\')\n    tempi = tempi[sort_idx]\n    strengths = strengths[sort_idx]\n    return np.vstack((tempi, strengths)).T\n\n\n# this evaluation function can evaluate multiple tempi simultaneously\ndef tempo_evaluation(detections, annotations, tolerance=TOLERANCE):\n    """"""\n    Calculate the tempo P-Score, at least one and all tempi correct.\n\n    Parameters\n    ----------\n    detections : list of tuples or numpy array\n        Detected tempi (rows, first column) and their relative strengths\n        (second column).\n    annotations : list or numpy array\n        Annotated tempi (rows, first column) and their relative strengths\n        (second column).\n    tolerance : float, optional\n        Evaluation tolerance (max. allowed deviation).\n\n    Returns\n    -------\n    pscore : float\n        P-Score.\n    at_least_one : bool\n        At least one tempo correctly identified.\n    all : bool\n        All tempi correctly identified.\n\n    Notes\n    -----\n    All given detections are evaluated against all annotations according to the\n    relative strengths given. If no strengths are given, evenly distributed\n    strengths are assumed. If the strengths do not sum to 1, they will be\n    normalized.\n\n    References\n    ----------\n    .. [1] M. McKinney, D. Moelants, M. Davies and A. Klapuri,\n           ""Evaluation of audio beat tracking and music tempo extraction\n           algorithms"",\n           Journal of New Music Research, vol. 36, no. 1, 2007.\n\n    """"""\n    # neither detections nor annotations are given\n    if len(detections) == 0 and len(annotations) == 0:\n        # perfect result\n        return 1., True, True\n    # either detections or annotations are empty\n    if len(detections) == 0 or len(annotations) == 0:\n        # worst result\n        return 0., False, False\n    # tolerance must be greater than 0\n    if float(tolerance) <= 0:\n        raise ValueError(\'tolerance must be greater than 0\')\n    # make sure the annotations and detections have a float dtype\n    detections = np.array(detections, dtype=np.float, ndmin=1)\n    annotations = np.array(annotations, dtype=np.float, ndmin=1)\n    # extract the detected tempi, ignore the strengths\n    if detections.ndim == 2:\n        detections = detections[:, 0]\n    # extract the annotated tempi and strengths\n    strengths = []\n    if annotations.ndim == 2:\n        # Note: extract the strength before using only the tempo annotations\n        strengths = annotations[:, 1]\n        annotations = annotations[:, 0]\n    # strengths must sum up to 1\n    strengths_sum = np.sum(strengths)\n    if strengths_sum == 0:\n        # uniformly distribute strengths\n        warnings.warn(\'no annotated tempo strengths given, assuming a uniform \'\n                      \'distribution\')\n        strengths = np.ones_like(annotations) / float(len(annotations))\n    elif strengths_sum != 1:\n        # normalize strengths\n        warnings.warn(\'annotated tempo strengths do not sum to 1, normalizing\')\n        strengths /= float(strengths_sum)\n    # test all detected tempi against all annotated tempi\n    errors = np.abs(1 - (detections[:, np.newaxis] / annotations))\n    # correctly identified annotation tempi\n    correct = np.asarray(np.sum(errors <= tolerance, axis=0), np.bool)\n    # the P-Score is the sum of the strengths of the correctly identified tempi\n    pscore = np.sum(strengths[correct])\n    # return the scores\n    # TODO: also return the errors?\n    return pscore, correct.any(), correct.all()\n\n\n# basic tempo evaluation\nclass TempoEvaluation(EvaluationMixin):\n    """"""\n    Tempo evaluation class.\n\n    Parameters\n    ----------\n    detections : str, list of tuples or numpy array\n        Detected tempi (rows) and their strengths (columns).\n        If a file name is given, load them from this file.\n    annotations : str, list or numpy array\n        Annotated ground truth tempi (rows) and their strengths (columns).\n        If a file name is given, load them from this file.\n    tolerance : float, optional\n        Evaluation tolerance (max. allowed deviation).\n    double : bool, optional\n        Include double and half tempo variations.\n    triple : bool, optional\n        Include triple and third tempo variations.\n    sort : bool, optional\n        Sort the tempi by their strengths (descending order).\n    max_len : bool, optional\n        Evaluate at most `max_len` tempi.\n    name : str, optional\n        Name of the evaluation to be displayed.\n\n    Notes\n    -----\n    For P-Score, the number of detected tempi will be limited to the number\n    of annotations (if not further limited by `max_len`).\n    For Accuracy 1 & 2 only one detected tempo is used. Depending on `sort`,\n    this can be either the first or the strongest one.\n\n    """"""\n    METRIC_NAMES = [\n        (\'pscore\', \'P-score\'),\n        (\'any\', \'one tempo correct\'),\n        (\'all\', \'both tempi correct\'),\n        (\'acc1\', \'Accuracy 1\'),\n        (\'acc2\', \'Accuracy 2\')\n    ]\n\n    def __init__(self, detections, annotations, tolerance=TOLERANCE,\n                 double=DOUBLE, triple=TRIPLE, sort=True, max_len=None,\n                 name=None, **kwargs):\n        # pylint: disable=unused-argument\n        # convert to numpy array\n        detections = np.array(detections, dtype=np.float, ndmin=1)\n        annotations = np.array(annotations, dtype=np.float, ndmin=1)\n        if sort and detections.ndim == 2:\n            detections = sort_tempo(detections)\n        if sort and annotations.ndim == 2:\n            annotations = sort_tempo(annotations)\n        # truncate detections and detections to the same length\n        if max_len:\n            detections = detections[:max_len]\n            annotations = annotations[:max_len]\n        # evaluate P-score with all tempo annotations\n        self.pscore, self.any, self.all = tempo_evaluation(\n            detections, annotations, tolerance)\n        # evaluate accuracies only with the strongest/first tempo\n        # Note: the strengths are irrelevant or acc1 & acc2 calculation\n        #       the accuracies correspond to either any or all tempi\n        # evaluate acc1 (i.e. any of the annotated tempi)\n        self.acc1 = tempo_evaluation(\n            detections[:1], annotations[:1], tolerance)[1]\n        # evaluate acc2 like acc1 but include double/half & triple/third tempi\n        try:\n            tempi = annotations[:1, 0].copy()\n        except IndexError:\n            tempi = annotations[:1].copy()\n        tempi_ = tempi.copy()\n        if double:\n            tempi_ = np.hstack((tempi_, tempi * 2., tempi / 2.))\n        if triple:\n            tempi_ = np.hstack((tempi_, tempi * 3., tempi / 3.))\n        self.acc2 = tempo_evaluation(detections[:1], tempi_, tolerance)[1]\n        # save the name\n        self.name = name\n\n    def __len__(self):\n        return 1\n\n    def tostring(self, **kwargs):\n        """"""\n        Format the evaluation metrics as a human readable string.\n\n        Returns\n        -------\n        str\n            Evaluation metrics formatted as a human readable string.\n\n        """"""\n        # pylint: disable=unused-argument\n\n        ret = \'\'\n        if self.name is not None:\n            ret += \'%s\\n  \' % self.name\n        ret += \'pscore=%.3f (one tempo: %.3f, all tempi: %.3f) \' \\\n               \'acc1=%.3f acc2=%.3f\' % \\\n               (self.pscore, self.any, self.all, self.acc1, self.acc2)\n        return ret\n\n    def __str__(self):\n        return self.tostring()\n\n\nclass TempoMeanEvaluation(MeanEvaluation):\n    """"""\n    Class for averaging tempo evaluation scores.\n\n    """"""\n    METRIC_NAMES = TempoEvaluation.METRIC_NAMES\n\n    @property\n    def pscore(self):\n        """"""P-Score.""""""\n        return np.nanmean([e.pscore for e in self.eval_objects])\n\n    @property\n    def any(self):\n        """"""At least one tempo correct.""""""\n        return np.nanmean([e.any for e in self.eval_objects])\n\n    @property\n    def all(self):\n        """"""All tempi correct.""""""\n        return np.nanmean([e.all for e in self.eval_objects])\n\n    @property\n    def acc1(self):\n        """"""Accuracy 1.""""""\n        return np.nanmean([e.acc1 for e in self.eval_objects])\n\n    @property\n    def acc2(self):\n        """"""Accuracy 2.""""""\n        return np.nanmean([e.acc2 for e in self.eval_objects])\n\n    def tostring(self, **kwargs):\n        """"""\n        Format the evaluation metrics as a human readable string.\n\n        Returns\n        -------\n        str\n            Evaluation metrics formatted as a human readable string.\n\n        """"""\n        ret = \'\'\n        if self.name is not None:\n            ret += \'%s\\n  \' % self.name\n        ret += \'pscore=%.3f (one tempo: %.3f, all tempi: %.3f) \' \\\n               \'acc1=%.3f acc2=%.3f\' % \\\n               (self.pscore, self.any, self.all, self.acc1, self.acc2)\n        return ret\n\n    def __str__(self):\n        return self.tostring()\n\n\ndef add_parser(parser):\n    """"""\n    Add a tempo evaluation sub-parser to an existing parser.\n\n    Parameters\n    ----------\n    parser : argparse parser instance\n        Existing argparse parser object.\n\n    Returns\n    -------\n    sub_parser : argparse sub-parser instance\n        Tempo evaluation sub-parser.\n    parser_group : argparse argument group\n        Tempo evaluation argument group.\n\n    """"""\n    import argparse\n    # add tempo evaluation sub-parser to the existing parser\n    p = parser.add_parser(\n        \'tempo\', help=\'tempo evaluation\',\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        description=\'\'\'\n    This program evaluates pairs of files containing the tempo annotations and\n    detections. Suffixes can be given to filter them from the list of files.\n\n    A single line represents the tempi and their relative strength and must\n    have the following format with values being separated by whitespace:\n    `tempo_one tempo_two relative_strength`\n\n    Lines starting with # are treated as comments and are ignored.\n\n    For P-Score evaluation as many tempi detections are used as tempo\n    annotations are given.\n\n    For Accuracy 1 & 2 evaluation, only the strongest (if strengths are given)\n    or the first tempo is used.\n\n    \'\'\')\n    # set defaults\n    p.set_defaults(eval=TempoEvaluation, mean_eval=TempoMeanEvaluation,\n                   sum_eval=None, load_fn=load_tempo)\n    # file I/O\n    evaluation_io(p, ann_suffix=\'.bpm\', det_suffix=\'.bpm.txt\')\n    # evaluation parameters\n    g = p.add_argument_group(\'tempo manipulation arguments\')\n    g.add_argument(\'--tolerance\', type=float, action=\'store\',\n                   default=TOLERANCE,\n                   help=\'tolerance for tempo detection \'\n                        \'[default=%(default).3f]\')\n    g.add_argument(\'--no_double\', dest=\'double\', action=\'store_false\',\n                   help=\'do not include double/half tempo evaluation\')\n    g.add_argument(\'--no_triple\', dest=\'triple\', action=\'store_false\',\n                   help=\'do not include triple/third tempo evaluation\')\n    # how many and which of the tempi should be evaluated?\n    g.add_argument(\'--no_sort\', dest=\'sort\', action=\'store_false\',\n                   help=\'do not sort the tempi by strength [default: sort \'\n                        \'them by strength]\')\n    # TODO: add option to evaluate any other than the default number of tempi?\n    # g.add_argument(\'--num\', dest=\'max_len\', action=\'store\', type=int,\n    #                help=\'evaluate NUM tempi [default: evaluate only the \'\n    #                     \'first (after sorting them)]\')\n    # return the sub-parser and evaluation argument group\n    return p, g\n'"
madmom/features/__init__.py,10,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n# pylint: disable=wrong-import-position\n""""""\nThis package includes high-level features. Your definition of ""high"" may\nvary, but we define high-level features as the ones you want to evaluate (e.g.\nonsets, beats, etc.). All lower-level features can be found the `madmom.audio`\npackage.\n\nNotes\n-----\nAll features should be implemented as classes which inherit from Processor\n(or provide a XYZProcessor(Processor) variant). This way, multiple Processor\nobjects can be chained/combined to achieve the wanted functionality.\n\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\nfrom ..processors import Processor\n\n\nclass Activations(np.ndarray):\n    """"""\n    The Activations class extends a numpy ndarray with a frame rate (fps)\n    attribute.\n\n    Parameters\n    ----------\n    data : str, file handle or numpy array\n        Either file name/handle to read the data from or array.\n    fps : float, optional\n        Frames per second (must be set if `data` is given as an array).\n    sep : str, optional\n        Separator between activation values (if read from file).\n    dtype : numpy dtype\n        Data-type the activations are stored/saved/kept.\n\n    Attributes\n    ----------\n    fps : float\n        Frames per second.\n\n    Notes\n    -----\n    If a filename or file handle is given, an undefined or empty separator\n    means that the file should be treated as a numpy binary file.\n    Only binary files can store the frame rate of the activations.\n    Text files should not be used for anything else but manual inspection\n    or I/O with other programs.\n\n    """"""\n    # pylint: disable=super-on-old-class\n    # pylint: disable=super-init-not-called\n    # pylint: disable=attribute-defined-outside-init\n\n    def __init__(self, data, fps=None, sep=None, dtype=np.float32):\n        # this method is for documentation purposes only\n        pass\n\n    def __new__(cls, data, fps=None, sep=None, dtype=np.float32):\n        import io\n\n        # check the type of the given data\n        if isinstance(data, np.ndarray):\n            # cast to Activations\n            obj = np.asarray(data, dtype=dtype).view(cls)\n            obj.fps = fps\n        elif isinstance(data, (str, io.IOBase)):\n            # read from file or file handle\n            obj = cls.load(data, fps, sep)\n        else:\n            raise TypeError(""wrong input data for Activations"")\n        # frame rate must be set\n        if obj.fps is None:\n            raise TypeError(""frame rate for Activations must be set"")\n        # return the object\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        # set default values here\n        self.fps = getattr(obj, \'fps\', None)\n\n    @classmethod\n    def load(cls, infile, fps=None, sep=None):\n        """"""\n        Load the activations from a file.\n\n        Parameters\n        ----------\n        infile : str or file handle\n            Input file name or file handle.\n        fps : float, optional\n            Frames per second; if set, it overwrites the saved frame rate.\n        sep : str, optional\n            Separator between activation values.\n\n        Returns\n        -------\n        :class:`Activations` instance\n            :class:`Activations` instance.\n\n        Notes\n        -----\n        An undefined or empty separator means that the file should be treated\n        as a numpy binary file.\n        Only binary files can store the frame rate of the activations.\n        Text files should not be used for anything else but manual inspection\n        or I/O with other programs.\n\n        """"""\n        # load the activations\n        if sep in [None, \'\']:\n            # numpy binary format\n            data = np.load(infile)\n            if isinstance(data, np.lib.npyio.NpzFile):\n                # .npz file, set the frame rate if none is given\n                if fps is None:\n                    fps = float(data[\'fps\'])\n                # and overwrite the data\n                data = data[\'activations\']\n        else:\n            # simple text format\n            data = np.loadtxt(infile, delimiter=sep)\n        if data.ndim > 1 and data.shape[1] == 1:\n            # flatten the array if it has only 1 real dimension\n            data = data.flatten()\n        # instantiate a new object\n        return cls(data, fps)\n\n    def save(self, outfile, sep=None, fmt=\'%.5f\'):\n        """"""\n        Save the activations to a file.\n\n        Parameters\n        ----------\n        outfile : str or file handle\n            Output file name or file handle.\n        sep : str, optional\n            Separator between activation values if saved as text file.\n        fmt : str, optional\n            Format of the values if saved as text file.\n\n        Notes\n        -----\n        An undefined or empty separator means that the file should be treated\n        as a numpy binary file.\n        Only binary files can store the frame rate of the activations.\n        Text files should not be used for anything else but manual inspection\n        or I/O with other programs.\n\n        If the activations are a 1D array, its values are interpreted as\n        features of a single time step, i.e. all values are printed in a single\n        line. If you want each value to appear in an individual line, use \'\\\\n\'\n        as a separator.\n\n        If the activations are a 2D array, the first axis corresponds to the\n        time dimension, i.e. the features are separated by `sep` and the time\n        steps are printed in separate lines. If you like to swap the\n        dimensions, please use the `T` attribute.\n\n        """"""\n\n        # save the activations\n        if sep in [None, \'\']:\n            # numpy binary format\n            npz = {\'activations\': self,\n                   \'fps\': self.fps}\n            np.savez(outfile, **npz)\n        else:\n            if self.ndim > 2:\n                raise ValueError(\'Only 1D and 2D activations can be saved in \'\n                                 \'human readable text format.\')\n            # simple text format\n            header = ""FPS:%f"" % self.fps\n            np.savetxt(outfile, np.atleast_2d(self), fmt=fmt, delimiter=sep,\n                       header=header)\n        # TODO: check if closing the file is really the best option to avoid\n        #       fails in tests/test_bin.py\n        try:\n            outfile.close()\n        except AttributeError:\n            # a string filename cannot be closed\n            pass\n\n\nclass ActivationsProcessor(Processor):\n    """"""\n    ActivationsProcessor processes a file and returns an Activations instance.\n\n    Parameters\n    ----------\n    mode : {\'r\', \'w\', \'in\', \'out\', \'load\', \'save\'}\n        Mode of the Processor: read/write.\n    fps : float, optional\n        Frame rate of the activations (if set, it overwrites the saved frame\n        rate).\n    sep : str, optional\n        Separator between activation values if saved as text file.\n\n    Notes\n    -----\n    An undefined or empty (\xe2\x80\x9c\xe2\x80\x9d) separator means that the file should be treated\n    as a numpy binary file. Only binary files can store the frame rate of the\n    activations.\n\n    """"""\n\n    def __init__(self, mode, fps=None, sep=None, **kwargs):\n        # pylint: disable=unused-argument\n        self.mode = mode\n        self.fps = fps\n        self.sep = sep\n\n    def process(self, data, output=None, **kwargs):\n        """"""\n        Depending on the mode, either loads the data stored in the given file\n        and returns it as an Activations instance or save the data to the given\n        output.\n\n        Parameters\n        ----------\n        data : str, file handle or numpy array\n            Data or file to be loaded (if `mode` is \'r\') or data to be saved\n            to file (if `mode` is \'w\').\n        output : str or file handle, optional\n            output file (only in write-mode)\n\n        Returns\n        -------\n        :class:`Activations` instance\n            :class:`Activations` instance (only in read-mode)\n\n        """"""\n        # pylint: disable=arguments-differ\n\n        if self.mode in (\'r\', \'in\', \'load\'):\n            return Activations.load(data, fps=self.fps, sep=self.sep)\n        if self.mode in (\'w\', \'out\', \'save\'):\n            # TODO: should we return the data or the Activations instance?\n            Activations(data, fps=self.fps).save(output, sep=self.sep)\n        else:\n            raise ValueError(""wrong mode %s; choose {\'r\', \'w\', \'in\', \'out\', ""\n                             ""\'load\', \'save\'}"")\n        return data\n\n    @staticmethod\n    def add_arguments(parser):\n        """"""\n        Add options to save/load activations to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser.\n\n        Returns\n        -------\n        parser_group : argparse argument group\n            Input/output argument parser group.\n\n        """"""\n        # add onset detection related options to the existing parser\n        g = parser.add_argument_group(\'save/load the activations\')\n        # add options for saving and loading the activations\n        g.add_argument(\'--save\', action=\'store_true\', default=False,\n                       help=\'save the activations to file\')\n        g.add_argument(\'--load\', action=\'store_true\', default=False,\n                       help=\'load the activations from file\')\n        g.add_argument(\'--sep\', action=\'store\', default=None,\n                       help=\'separator for saving/loading the activations \'\n                            \'[default: None, i.e. numpy binary format]\')\n        # return the argument group so it can be modified if needed\n        return g\n\n\n# finally import the submodules\nfrom . import beats, chords, downbeats, key, notes, onsets, tempo\n\n# import often used classes\nfrom .beats import (BeatDetectionProcessor, BeatTrackingProcessor,\n                    CRFBeatDetectionProcessor, DBNBeatTrackingProcessor,\n                    MultiModelSelectionProcessor, RNNBeatProcessor)\nfrom .chords import (CNNChordFeatureProcessor, CRFChordRecognitionProcessor,\n                     DeepChromaChordRecognitionProcessor)\nfrom .downbeats import (RNNDownBeatProcessor, DBNDownBeatTrackingProcessor,\n                        PatternTrackingProcessor, RNNBarProcessor,\n                        DBNBarTrackingProcessor)\nfrom .key import CNNKeyRecognitionProcessor\nfrom .notes import (CNNPianoNoteProcessor, ADSRNoteTrackingProcessor,\n                    NoteOnsetPeakPickingProcessor, NotePeakPickingProcessor,\n                    RNNPianoNoteProcessor)\nfrom .onsets import (CNNOnsetProcessor, OnsetPeakPickingProcessor,\n                     RNNOnsetProcessor, SpectralOnsetProcessor)\nfrom .tempo import TempoEstimationProcessor\n'"
madmom/features/beats.py,32,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains beat tracking related functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport sys\n\nimport numpy as np\n\nfrom ..audio.signal import signal_frame, smooth as smooth_signal\nfrom ..ml.nn import average_predictions\nfrom ..processors import (OnlineProcessor, ParallelProcessor, Processor,\n                          SequentialProcessor)\n\n\n# classes for tracking (down-)beats with RNNs\nclass RNNBeatProcessor(SequentialProcessor):\n    """"""\n    Processor to get a beat activation function from multiple RNNs.\n\n    Parameters\n    ----------\n    post_processor : Processor, optional\n        Post-processor, default is to average the predictions.\n    online : bool, optional\n        Use signal processing parameters and RNN models suitable for online\n        mode.\n    nn_files : list, optional\n        List with trained RNN model files. Per default (\'None\'), an ensemble\n        of networks will be used.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck and Markus Schedl,\n           ""Enhanced Beat Tracking with Context-Aware Neural Networks"",\n           Proceedings of the 14th International Conference on Digital Audio\n           Effects (DAFx), 2011.\n\n    Examples\n    --------\n    Create a RNNBeatProcessor and pass a file through the processor.\n    The returned 1d array represents the probability of a beat at each frame,\n    sampled at 100 frames per second.\n\n    >>> proc = RNNBeatProcessor()\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.beats.RNNBeatProcessor object at 0x...>\n    >>> proc(\'tests/data/audio/sample.wav\')  # doctest: +ELLIPSIS\n    array([0.00479, 0.00603, 0.00927, 0.01419, ... 0.02725], dtype=float32)\n\n    For online processing, `online` must be set to \'True\'. If processing power\n    is limited, fewer number of RNN models can be defined via `nn_files`. The\n    audio signal is then processed frame by frame.\n\n    >>> from madmom.models import BEATS_LSTM\n    >>> proc = RNNBeatProcessor(online=True, nn_files=[BEATS_LSTM[0]])\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.beats.RNNBeatProcessor object at 0x...>\n    >>> proc(\'tests/data/audio/sample.wav\')  # doctest: +ELLIPSIS\n    array([0.03887, 0.02619, 0.00747, 0.00218, ... 0.04825], dtype=float32)\n\n    """"""\n\n    def __init__(self, post_processor=average_predictions, online=False,\n                 nn_files=None, **kwargs):\n        # pylint: disable=unused-argument\n        from ..audio.signal import SignalProcessor, FramedSignalProcessor\n        from ..audio.stft import ShortTimeFourierTransformProcessor\n        from ..audio.spectrogram import (\n            FilteredSpectrogramProcessor, LogarithmicSpectrogramProcessor,\n            SpectrogramDifferenceProcessor)\n        from ..ml.nn import NeuralNetworkEnsemble\n        from ..models import BEATS_LSTM, BEATS_BLSTM\n        # choose the appropriate models and set frame sizes accordingly\n        if online:\n            if nn_files is None:\n                nn_files = BEATS_LSTM\n            frame_sizes = [2048]\n            num_bands = 12\n        else:\n            if nn_files is None:\n                nn_files = BEATS_BLSTM\n            frame_sizes = [1024, 2048, 4096]\n            num_bands = 6\n        # define pre-processing chain\n        sig = SignalProcessor(num_channels=1, sample_rate=44100)\n        # process the multi-resolution spec & diff in parallel\n        multi = ParallelProcessor([])\n        for frame_size in frame_sizes:\n            frames = FramedSignalProcessor(frame_size=frame_size, **kwargs)\n            stft = ShortTimeFourierTransformProcessor()  # caching FFT window\n            filt = FilteredSpectrogramProcessor(num_bands=num_bands, fmin=30,\n                                                fmax=17000, norm_filters=True)\n            spec = LogarithmicSpectrogramProcessor(mul=1, add=1)\n            diff = SpectrogramDifferenceProcessor(\n                diff_ratio=0.5, positive_diffs=True, stack_diffs=np.hstack)\n            # process each frame size with spec and diff sequentially\n            multi.append(SequentialProcessor((frames, stft, filt, spec, diff)))\n        # stack the features and processes everything sequentially\n        pre_processor = SequentialProcessor((sig, multi, np.hstack))\n        # process the pre-processed signal with a NN ensemble and the given\n        # post_processor\n        nn = NeuralNetworkEnsemble.load(nn_files,\n                                        ensemble_fn=post_processor, **kwargs)\n        # instantiate a SequentialProcessor\n        super(RNNBeatProcessor, self).__init__((pre_processor, nn))\n\n\n# class for selecting a certain beat activation functions from (multiple) NNs\nclass MultiModelSelectionProcessor(Processor):\n    """"""\n    Processor for selecting the most suitable model (i.e. the predictions\n    thereof) from a multiple models/predictions.\n\n    Parameters\n    ----------\n    num_ref_predictions : int\n        Number of reference predictions (see below).\n\n    Notes\n    -----\n    This processor selects the most suitable prediction from multiple models by\n    comparing them to the predictions of a reference model. The one with the\n    smallest mean squared error is chosen.\n\n    If `num_ref_predictions` is 0 or None, an averaged prediction is computed\n    from the given predictions and used as reference.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck, Florian Krebs and Gerhard Widmer,\n           ""A Multi-Model Approach to Beat Tracking Considering Heterogeneous\n           Music Styles"",\n           Proceedings of the 15th International Society for Music Information\n           Retrieval Conference (ISMIR), 2014.\n\n    Examples\n    --------\n    The MultiModelSelectionProcessor takes a list of model predictions as it\'s\n    call argument. Thus, `post_processor` of `RNNBeatProcessor` hast to be set\n    to \'None\' in order to get the predictions of all models.\n\n    >>> proc = RNNBeatProcessor(post_processor=None)\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.beats.RNNBeatProcessor object at 0x...>\n\n    When passing a file through the processor, a list with predictions, one for\n    each model tested, is returned.\n\n    >>> predictions = proc(\'tests/data/audio/sample.wav\')\n    >>> predictions  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    [array([0.00535, 0.00774, ..., 0.02343, 0.04931], dtype=float32),\n     array([0.0022 , 0.00282, ..., 0.00825, 0.0152 ], dtype=float32),\n     ...,\n     array([0.005  , 0.0052 , ..., 0.00472, 0.01524], dtype=float32),\n     array([0.00319, 0.0044 , ..., 0.0081 , 0.01498], dtype=float32)]\n\n    We can feed these predictions to the MultiModelSelectionProcessor.\n    Since we do not have a dedicated reference prediction (which had to be the\n    first element of the list and `num_ref_predictions` set to 1), we simply\n    set `num_ref_predictions` to \'None\'. MultiModelSelectionProcessor averages\n    all predictions to obtain a reference prediction it compares all others to.\n\n    >>> mm_proc = MultiModelSelectionProcessor(num_ref_predictions=None)\n    >>> mm_proc(predictions)  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    array([0.00759, 0.00901, ..., 0.00843, 0.01834], dtype=float32)\n\n    """"""\n\n    def __init__(self, num_ref_predictions, **kwargs):\n        # pylint: disable=unused-argument\n\n        self.num_ref_predictions = num_ref_predictions\n\n    def process(self, predictions, **kwargs):\n        """"""\n        Selects the most appropriate predictions form the list of predictions.\n\n        Parameters\n        ----------\n        predictions : list\n            Predictions (beat activation functions) of multiple models.\n\n        Returns\n        -------\n        numpy array\n            Most suitable prediction.\n\n        Notes\n        -----\n        The reference beat activation function must be the first one in the\n        list of given predictions.\n\n        """"""\n        # TODO: right now we only have 1D predictions, what to do with\n        #       multi-dim?\n        num_refs = self.num_ref_predictions\n        # determine the reference prediction\n        if num_refs in (None, 0):\n            # just average all predictions to simulate a reference network\n            reference = average_predictions(predictions)\n        elif num_refs > 0:\n            # average the reference predictions\n            reference = average_predictions(predictions[:num_refs])\n        else:\n            raise ValueError(\'`num_ref_predictions` must be positive or None, \'\n                             \'%s given\' % num_refs)\n        # init the error with the max. possible value (i.e. prediction length)\n        best_error = len(reference)\n        # init the best_prediction with an empty array\n        best_prediction = np.empty(0)\n        # compare the (remaining) predictions with the reference prediction\n        for prediction in predictions[num_refs:]:\n            # calculate the squared error w.r.t. the reference prediction\n            error = np.sum((prediction - reference) ** 2.)\n            # chose the best activation\n            if error < best_error:\n                best_prediction = prediction\n                best_error = error\n        # return the best prediction\n        return best_prediction.ravel()\n\n\n# function for detecting the beats based on the given dominant interval\ndef detect_beats(activations, interval, look_aside=0.2):\n    """"""\n    Detects the beats in the given activation function as in [1]_.\n\n    Parameters\n    ----------\n    activations : numpy array\n        Beat activations.\n    interval : int\n        Look for the next beat each `interval` frames.\n    look_aside : float\n        Look this fraction of the `interval` to each side to detect the beats.\n\n    Returns\n    -------\n    numpy array\n        Beat positions [frames].\n\n    Notes\n    -----\n    A Hamming window of 2 * `look_aside` * `interval` is applied around the\n    position where the beat is expected to prefer beats closer to the centre.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck and Markus Schedl,\n           ""Enhanced Beat Tracking with Context-Aware Neural Networks"",\n           Proceedings of the 14th International Conference on Digital Audio\n           Effects (DAFx), 2011.\n\n    """"""\n    # TODO: make this faster!\n    sys.setrecursionlimit(len(activations))\n    # always look at least 1 frame to each side\n    frames_look_aside = max(1, int(interval * look_aside))\n    win = np.hamming(2 * frames_look_aside)\n\n    # list to be filled with beat positions from inside the recursive function\n    positions = []\n\n    def recursive(position):\n        """"""\n        Recursively detect the next beat.\n\n        Parameters\n        ----------\n        position : int\n            Start at this position.\n\n        """"""\n        # detect the nearest beat around the actual position\n        act = signal_frame(activations, position, frames_look_aside * 2, 1)\n        # apply a filtering window to prefer beats closer to the centre\n        act = np.multiply(act, win)\n        # search max\n        if np.argmax(act) > 0:\n            # maximum found, take that position\n            position = np.argmax(act) + position - frames_look_aside\n        # add the found position\n        positions.append(position)\n        # go to the next beat, until end is reached\n        if position + interval < len(activations):\n            recursive(position + interval)\n        else:\n            return\n\n    # calculate the beats for each start position (up to the interval length)\n    sums = np.zeros(interval)\n    for i in range(interval):\n        positions = []\n        # detect the beats for this start position\n        recursive(i)\n        # calculate the sum of the activations at the beat positions\n        sums[i] = np.sum(activations[positions])\n    # take the winning start position\n    start_position = np.argmax(sums)\n    # and calc the beats for this start position\n    positions = []\n    recursive(start_position)\n    # return indices\n    return np.array(positions)\n\n\n# classes for detecting/tracking of beat inside a beat activation function\nclass BeatTrackingProcessor(Processor):\n    """"""\n    Track the beats according to previously determined (local) tempo by\n    iteratively aligning them around the estimated position [1]_.\n\n    Parameters\n    ----------\n    look_aside : float, optional\n        Look this fraction of the estimated beat interval to each side of the\n        assumed next beat position to look for the most likely position of the\n        next beat.\n    look_ahead : float, optional\n        Look `look_ahead` seconds in both directions to determine the local\n        tempo and align the beats accordingly.\n    tempo_estimator : :class:`TempoEstimationProcessor`, optional\n        Use this processor to estimate the (local) tempo. If \'None\' a default\n        tempo estimator will be created and used.\n    fps : float, optional\n        Frames per second.\n    kwargs : dict, optional\n        Keyword arguments passed to\n        :class:`madmom.features.tempo.TempoEstimationProcessor` if no\n        `tempo_estimator` was given.\n\n    Notes\n    -----\n    If `look_ahead` is not set, a constant tempo throughout the whole piece\n    is assumed. If `look_ahead` is set, the local tempo (in a range +/-\n    `look_ahead` seconds around the actual position) is estimated and then\n    the next beat is tracked accordingly. This procedure is repeated from\n    the new position to the end of the piece.\n\n    Instead of the auto-correlation based method for tempo estimation proposed\n    in [1]_, it uses a comb filter based method [2]_ per default. The behaviour\n    can be controlled with the `tempo_method` parameter.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck and Markus Schedl,\n           ""Enhanced Beat Tracking with Context-Aware Neural Networks"",\n           Proceedings of the 14th International Conference on Digital Audio\n           Effects (DAFx), 2011.\n    .. [2] Sebastian B\xc3\xb6ck, Florian Krebs and Gerhard Widmer,\n           ""Accurate Tempo Estimation based on Recurrent Neural Networks and\n           Resonating Comb Filters"",\n           Proceedings of the 16th International Society for Music Information\n           Retrieval Conference (ISMIR), 2015.\n\n    Examples\n    --------\n    Create a BeatTrackingProcessor. The returned array represents the positions\n    of the beats in seconds, thus the expected sampling rate has to be given.\n\n    >>> proc = BeatTrackingProcessor(fps=100)\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.beats.BeatTrackingProcessor object at 0x...>\n\n    Call this BeatTrackingProcessor with the beat activation function returned\n    by RNNBeatProcessor to obtain the beat positions.\n\n    >>> act = RNNBeatProcessor()(\'tests/data/audio/sample.wav\')\n    >>> proc(act)\n    array([0.11, 0.45, 0.79, 1.13, 1.47, 1.81, 2.15, 2.49])\n\n    """"""\n    LOOK_ASIDE = 0.2\n    LOOK_AHEAD = 10.\n\n    def __init__(self, look_aside=LOOK_ASIDE, look_ahead=LOOK_AHEAD, fps=None,\n                 tempo_estimator=None, **kwargs):\n        # save variables\n        self.look_aside = look_aside\n        self.look_ahead = look_ahead\n        self.fps = fps\n        # tempo estimator\n        if tempo_estimator is None:\n            # import the TempoEstimation here otherwise we have a loop\n            from .tempo import TempoEstimationProcessor\n            # create default tempo estimator\n            tempo_estimator = TempoEstimationProcessor(fps=fps, **kwargs)\n        self.tempo_estimator = tempo_estimator\n\n    def process(self, activations, **kwargs):\n        """"""\n        Detect the beats in the given activation function.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Beat activation function.\n\n        Returns\n        -------\n        beats : numpy array\n            Detected beat positions [seconds].\n\n        """"""\n        # smooth activations\n        act_smooth = int(self.fps * self.tempo_estimator.act_smooth)\n        activations = smooth_signal(activations, act_smooth)\n        # TODO: refactor interval stuff to use TempoEstimation\n        # if look_ahead is not defined, assume a global tempo\n        if self.look_ahead is None:\n            # create a interval histogram\n            histogram = self.tempo_estimator.interval_histogram(activations)\n            # get the dominant interval\n            interval = self.tempo_estimator.dominant_interval(histogram)\n            # detect beats based on this interval\n            detections = detect_beats(activations, interval, self.look_aside)\n        else:\n            # allow varying tempo\n            look_ahead_frames = int(self.look_ahead * self.fps)\n            # detect the beats\n            detections = []\n            pos = 0\n            # TODO: make this _much_ faster!\n            while pos < len(activations):\n                # look N frames around the actual position\n                act = signal_frame(activations, pos, look_ahead_frames * 2, 1)\n                # create a interval histogram\n                histogram = self.tempo_estimator.interval_histogram(act)\n                # get the dominant interval\n                interval = self.tempo_estimator.dominant_interval(histogram)\n                # add the offset (i.e. the new detected start position)\n                positions = detect_beats(act, interval, self.look_aside)\n                # correct the beat positions\n                positions += pos - look_ahead_frames\n                # remove all positions < already detected beats + min_interval\n                next_pos = (detections[-1] + self.tempo_estimator.min_interval\n                            if detections else 0)\n                positions = positions[positions >= next_pos]\n                # search the closest beat to the predicted beat position\n                pos = positions[(np.abs(positions - pos)).argmin()]\n                # append to the beats\n                detections.append(pos)\n                pos += interval\n\n        # convert detected beats to a list of timestamps\n        detections = np.array(detections) / float(self.fps)\n        # remove beats with negative times and return them\n        return detections[np.searchsorted(detections, 0):]\n\n    @staticmethod\n    def add_arguments(parser, look_aside=LOOK_ASIDE,\n                      look_ahead=LOOK_AHEAD):\n        """"""\n        Add beat tracking related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        look_aside : float, optional\n            Look this fraction of the estimated beat interval to each side of\n            the assumed next beat position to look for the most likely position\n            of the next beat.\n        look_ahead : float, optional\n            Look `look_ahead` seconds in both directions to determine the local\n            tempo and align the beats accordingly.\n\n        Returns\n        -------\n        parser_group : argparse argument group\n            Beat tracking argument parser group.\n\n        Notes\n        -----\n        Parameters are included in the group only if they are not \'None\'.\n\n        """"""\n        # add beat detection related options to the existing parser\n        g = parser.add_argument_group(\'beat detection arguments\')\n        # TODO: unify look_aside with CRFBeatDetection\'s interval_sigma\n        if look_aside is not None:\n            g.add_argument(\'--look_aside\', action=\'store\', type=float,\n                           default=look_aside,\n                           help=\'look this fraction of a beat interval to \'\n                                \'each side of the assumed next beat position \'\n                                \'to look for the most likely position of the \'\n                                \'next beat [default=%(default).2f]\')\n        if look_ahead is not None:\n            g.add_argument(\'--look_ahead\', action=\'store\', type=float,\n                           default=look_ahead,\n                           help=\'look this many seconds in both directions \'\n                                \'to determine the local tempo and align the \'\n                                \'beats accordingly [default=%(default).2f]\')\n        # return the argument group so it can be modified if needed\n        return g\n\n\nclass BeatDetectionProcessor(BeatTrackingProcessor):\n    """"""\n    Class for detecting beats according to the previously determined global\n    tempo by iteratively aligning them around the estimated position [1]_.\n\n    Parameters\n    ----------\n    look_aside : float\n        Look this fraction of the estimated beat interval to each side of the\n        assumed next beat position to look for the most likely position of the\n        next beat.\n    fps : float, optional\n        Frames per second.\n\n    Notes\n    -----\n    A constant tempo throughout the whole piece is assumed.\n\n    Instead of the auto-correlation based method for tempo estimation proposed\n    in [1]_, it uses a comb filter based method [2]_ per default. The behaviour\n    can be controlled with the `tempo_method` parameter.\n\n    See Also\n    --------\n    :class:`BeatTrackingProcessor`\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck and Markus Schedl,\n           ""Enhanced Beat Tracking with Context-Aware Neural Networks"",\n           Proceedings of the 14th International Conference on Digital Audio\n           Effects (DAFx), 2011.\n    .. [2] Sebastian B\xc3\xb6ck, Florian Krebs and Gerhard Widmer,\n           ""Accurate Tempo Estimation based on Recurrent Neural Networks and\n           Resonating Comb Filters"",\n           Proceedings of the 16th International Society for Music Information\n           Retrieval Conference (ISMIR), 2015.\n\n    Examples\n    --------\n    Create a BeatDetectionProcessor. The returned array represents the\n    positions of the beats in seconds, thus the expected sampling rate has to\n    be given.\n\n    >>> proc = BeatDetectionProcessor(fps=100)\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.beats.BeatDetectionProcessor object at 0x...>\n\n    Call this BeatDetectionProcessor with the beat activation function returned\n    by RNNBeatProcessor to obtain the beat positions.\n\n    >>> act = RNNBeatProcessor()(\'tests/data/audio/sample.wav\')\n    >>> proc(act)\n    array([0.11, 0.45, 0.79, 1.13, 1.47, 1.81, 2.15, 2.49])\n\n    """"""\n    LOOK_ASIDE = 0.2\n\n    def __init__(self, look_aside=LOOK_ASIDE, fps=None, **kwargs):\n        super(BeatDetectionProcessor, self).__init__(look_aside=look_aside,\n                                                     look_ahead=None, fps=fps,\n                                                     **kwargs)\n\n\ndef _process_crf(process_tuple):\n    """"""\n    Extract the best beat sequence for a piece.\n\n    This proxy function is necessary to process different intervals in parallel\n    using the multiprocessing module.\n\n    Parameters\n    ----------\n    process_tuple : tuple\n        Tuple with (activations, dominant_interval, allowed deviation from the\n        dominant interval per beat).\n\n    Returns\n    -------\n    beats : numpy array\n        Extracted beat positions [frames].\n    log_prob : float\n        Log probability of the beat sequence.\n\n    """"""\n    # pylint: disable=no-name-in-module\n    from .beats_crf import best_sequence\n    # activations, dominant_interval, interval_sigma = process_tuple\n    return best_sequence(*process_tuple)\n\n\nclass CRFBeatDetectionProcessor(BeatTrackingProcessor):\n    """"""\n    Conditional Random Field Beat Detection.\n\n    Tracks the beats according to the previously determined global tempo using\n    a conditional random field (CRF) model.\n\n    Parameters\n    ----------\n    interval_sigma : float, optional\n        Allowed deviation from the dominant beat interval per beat.\n    use_factors : bool, optional\n        Use dominant interval multiplied by factors instead of intervals\n        estimated by tempo estimator.\n    num_intervals : int, optional\n        Maximum number of estimated intervals to try.\n    factors : list or numpy array, optional\n        Factors of the dominant interval to try.\n\n    References\n    ----------\n    .. [1] Filip Korzeniowski, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""Probabilistic Extraction of Beat Positions from a Beat Activation\n           Function"",\n           Proceedings of the 15th International Society for Music Information\n           Retrieval Conference (ISMIR), 2014.\n\n    Examples\n    --------\n    Create a CRFBeatDetectionProcessor. The returned array represents the\n    positions of the beats in seconds, thus the expected sampling rate has to\n    be given.\n\n    >>> proc = CRFBeatDetectionProcessor(fps=100)\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.beats.CRFBeatDetectionProcessor object at 0x...>\n\n    Call this BeatDetectionProcessor with the beat activation function returned\n    by RNNBeatProcessor to obtain the beat positions.\n\n    >>> act = RNNBeatProcessor()(\'tests/data/audio/sample.wav\')\n    >>> proc(act)\n    array([0.09, 0.79, 1.49])\n\n    """"""\n    INTERVAL_SIGMA = 0.18\n    USE_FACTORS = False\n    FACTORS = np.array([0.5, 0.67, 1.0, 1.5, 2.0])\n    NUM_INTERVALS = 5\n    # tempo defaults\n    MIN_BPM = 20\n    MAX_BPM = 240\n    ACT_SMOOTH = 0.09\n    HIST_SMOOTH = 7\n\n    def __init__(self, interval_sigma=INTERVAL_SIGMA, use_factors=USE_FACTORS,\n                 num_intervals=NUM_INTERVALS, factors=FACTORS, **kwargs):\n        super(CRFBeatDetectionProcessor, self).__init__(**kwargs)\n        # save parameters\n        self.interval_sigma = interval_sigma\n        self.use_factors = use_factors\n        self.num_intervals = num_intervals\n        self.factors = factors\n        # get num_threads from kwargs\n        num_threads = min(len(factors) if use_factors else num_intervals,\n                          kwargs.get(\'num_threads\', 1))\n        # init a pool of workers (if needed)\n        self.map = map\n        if num_threads != 1:\n            import multiprocessing as mp\n            self.map = mp.Pool(num_threads).map\n\n    def process(self, activations, **kwargs):\n        """"""\n        Detect the beats in the given activation function.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Beat activation function.\n\n        Returns\n        -------\n        numpy array\n            Detected beat positions [seconds].\n\n        """"""\n        import itertools as it\n        # estimate the tempo\n        tempi = self.tempo_estimator.process(activations)\n        intervals = self.fps * 60. / tempi[:, 0]\n\n        # compute possible intervals\n        if self.use_factors:\n            # use the dominant interval with different factors\n            possible_intervals = [int(intervals[0] * f) for f in self.factors]\n            possible_intervals = [i for i in possible_intervals if\n                                  self.tempo_estimator.max_interval >= i >=\n                                  self.tempo_estimator.min_interval]\n        else:\n            # take the top n intervals from the tempo estimator\n            possible_intervals = intervals[:self.num_intervals]\n\n        # sort and start from the greatest interval\n        possible_intervals.sort()\n        possible_intervals = [int(i) for i in possible_intervals[::-1]]\n\n        # smooth activations\n        act_smooth = int(self.fps * self.tempo_estimator.act_smooth)\n        activations = smooth_signal(activations, act_smooth)\n\n        # since the cython code uses memory views, we need to make sure that\n        # the activations are C-contiguous and of C-type float (np.float32)\n        contiguous_act = np.ascontiguousarray(activations, dtype=np.float32)\n        results = list(self.map(\n            _process_crf, zip(it.repeat(contiguous_act), possible_intervals,\n                              it.repeat(self.interval_sigma))))\n\n        # normalize their probabilities\n        normalized_seq_probabilities = np.array([r[1] / r[0].shape[0]\n                                                 for r in results])\n        # pick the best one\n        best_seq = results[normalized_seq_probabilities.argmax()][0]\n\n        # convert the detected beat positions to seconds and return them\n        return best_seq.astype(np.float) / self.fps\n\n    @staticmethod\n    def add_arguments(parser, interval_sigma=INTERVAL_SIGMA,\n                      use_factors=USE_FACTORS, num_intervals=NUM_INTERVALS,\n                      factors=FACTORS):\n        """"""\n        Add CRFBeatDetection related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        interval_sigma : float, optional\n            allowed deviation from the dominant beat interval per beat\n        use_factors : bool, optional\n            use dominant interval multiplied by factors instead of intervals\n            estimated by tempo estimator\n        num_intervals : int, optional\n            max number of estimated intervals to try\n        factors : list or numpy array, optional\n            factors of the dominant interval to try\n\n        Returns\n        -------\n        parser_group : argparse argument group\n            CRF beat tracking argument parser group.\n\n        """"""\n        # pylint: disable=arguments-differ\n        from ..utils import OverrideDefaultListAction\n        # add CRF related arguments\n        g = parser.add_argument_group(\'conditional random field arguments\')\n        g.add_argument(\'--interval_sigma\', action=\'store\', type=float,\n                       default=interval_sigma,\n                       help=\'allowed deviation from the dominant interval \'\n                            \'[default=%(default).2f]\')\n        g.add_argument(\'--use_factors\', action=\'store_true\',\n                       default=use_factors,\n                       help=\'use dominant interval multiplied with factors \'\n                            \'instead of multiple estimated intervals \'\n                            \'[default=%(default)s]\')\n        g.add_argument(\'--num_intervals\', action=\'store\', type=int,\n                       default=num_intervals, dest=\'num_intervals\',\n                       help=\'number of estimated intervals to try \'\n                            \'[default=%(default)s]\')\n        g.add_argument(\'--factors\', action=OverrideDefaultListAction,\n                       default=factors, type=float, sep=\',\',\n                       help=\'(comma separated) list with factors of dominant \'\n                            \'interval to try [default=%(default)s]\')\n        return g\n\n\ndef threshold_activations(activations, threshold):\n    """"""\n    Threshold activations to include only the main segment exceeding the given\n    threshold (i.e. first to last time/index exceeding the threshold).\n\n    Parameters\n    ----------\n    activations : numpy array\n        Activations to be thresholded.\n    threshold : float\n        Threshold value.\n\n    Returns\n    -------\n    activations : numpy array\n        Thresholded activations\n    start : int\n        Index of the first activation exceeding the threshold.\n\n    Notes\n    -----\n\n    This function can be used to extract the main segment of beat activations\n    to track only the beats where the activations exceed the threshold.\n\n    """"""\n    first = last = 0\n    # use only the activations > threshold\n    idx = np.nonzero(activations >= threshold)[0]\n    if idx.any():\n        first = max(first, np.min(idx))\n        last = min(len(activations), np.max(idx) + 1)\n    # return thresholded activations segment and first index\n    return activations[first:last], first\n\n\nclass DBNBeatTrackingProcessor(OnlineProcessor):\n    """"""\n    Beat tracking with RNNs and a dynamic Bayesian network (DBN) approximated\n    by a Hidden Markov Model (HMM).\n\n    Parameters\n    ----------\n    min_bpm : float, optional\n        Minimum tempo used for beat tracking [bpm].\n    max_bpm : float, optional\n        Maximum tempo used for beat tracking [bpm].\n    num_tempi : int, optional\n        Number of tempi to model; if set, limit the number of tempi and use a\n        log spacing, otherwise a linear spacing.\n    transition_lambda : float, optional\n        Lambda for the exponential tempo change distribution (higher values\n        prefer a constant tempo from one beat to the next one).\n    observation_lambda : int, optional\n        Split one beat period into `observation_lambda` parts, the first\n        representing beat states and the remaining non-beat states.\n    threshold : float, optional\n        Threshold the observations before Viterbi decoding.\n    correct : bool, optional\n        Correct the beats (i.e. align them to the nearest peak of the beat\n        activation function).\n    fps : float, optional\n        Frames per second.\n    online : bool, optional\n        Use the forward algorithm (instead of Viterbi) to decode the beats.\n\n    Notes\n    -----\n    Instead of the originally proposed state space and transition model for\n    the DBN [1]_, the more efficient version proposed in [2]_ is used.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck, Florian Krebs and Gerhard Widmer,\n           ""A Multi-Model Approach to Beat Tracking Considering Heterogeneous\n           Music Styles"",\n           Proceedings of the 15th International Society for Music Information\n           Retrieval Conference (ISMIR), 2014.\n    .. [2] Florian Krebs, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""An Efficient State Space Model for Joint Tempo and Meter Tracking"",\n           Proceedings of the 16th International Society for Music Information\n           Retrieval Conference (ISMIR), 2015.\n\n    Examples\n    --------\n    Create a DBNBeatTrackingProcessor. The returned array represents the\n    positions of the beats in seconds, thus the expected sampling rate has to\n    be given.\n\n    >>> proc = DBNBeatTrackingProcessor(fps=100)\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.beats.DBNBeatTrackingProcessor object at 0x...>\n\n    Call this DBNBeatTrackingProcessor with the beat activation function\n    returned by RNNBeatProcessor to obtain the beat positions.\n\n    >>> act = RNNBeatProcessor()(\'tests/data/audio/sample.wav\')\n    >>> proc(act)\n    array([0.1 , 0.45, 0.8 , 1.12, 1.48, 1.8 , 2.15, 2.49])\n\n    """"""\n    MIN_BPM = 55.\n    MAX_BPM = 215.\n    NUM_TEMPI = None\n    TRANSITION_LAMBDA = 100\n    OBSERVATION_LAMBDA = 16\n    THRESHOLD = 0\n    CORRECT = True\n\n    def __init__(self, min_bpm=MIN_BPM, max_bpm=MAX_BPM, num_tempi=NUM_TEMPI,\n                 transition_lambda=TRANSITION_LAMBDA,\n                 observation_lambda=OBSERVATION_LAMBDA, correct=CORRECT,\n                 threshold=THRESHOLD, fps=None, online=False, **kwargs):\n        # pylint: disable=unused-argument\n        # pylint: disable=no-name-in-module\n        from .beats_hmm import (BeatStateSpace, BeatTransitionModel,\n                                RNNBeatTrackingObservationModel)\n        from ..ml.hmm import HiddenMarkovModel\n        # convert timing information to construct a beat state space\n        min_interval = 60. * fps / max_bpm\n        max_interval = 60. * fps / min_bpm\n        self.st = BeatStateSpace(min_interval, max_interval, num_tempi)\n        # transition model\n        self.tm = BeatTransitionModel(self.st, transition_lambda)\n        # observation model\n        self.om = RNNBeatTrackingObservationModel(self.st, observation_lambda)\n        # instantiate a HMM\n        self.hmm = HiddenMarkovModel(self.tm, self.om, None)\n        # save variables\n        self.correct = correct\n        self.threshold = threshold\n        self.fps = fps\n        self.min_bpm = min_bpm\n        self.max_bpm = max_bpm\n        # keep state in online mode\n        self.online = online\n        # TODO: refactor the visualisation stuff\n        if self.online:\n            self.visualize = kwargs.get(\'verbose\', False)\n            self.counter = 0\n            self.beat_counter = 0\n            self.strength = 0\n            self.last_beat = 0\n            self.tempo = 0\n\n    def reset(self):\n        """"""Reset the DBNBeatTrackingProcessor.""""""\n        # pylint: disable=attribute-defined-outside-init\n        # reset the HMM\n        self.hmm.reset()\n        # reset other variables\n        self.counter = 0\n        self.beat_counter = 0\n        self.strength = 0\n        self.last_beat = 0\n        self.tempo = 0\n\n    def process_offline(self, activations, **kwargs):\n        """"""\n        Detect the beats in the given activation function with Viterbi\n        decoding.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Beat activation function.\n\n        Returns\n        -------\n        beats : numpy array\n            Detected beat positions [seconds].\n\n        """"""\n        # init the beats to return and the offset\n        beats = np.empty(0, dtype=np.int)\n        first = 0\n        # use only the activations > threshold\n        if self.threshold:\n            activations, first = threshold_activations(activations,\n                                                       self.threshold)\n        # return no beats if no activations given / remain after thresholding\n        if not activations.any():\n            return beats\n        # get the best state path by calling the viterbi algorithm\n        path, _ = self.hmm.viterbi(activations)\n        # also return no beats if no path was found\n        if not path.any():\n            return beats\n        # correct the beat positions if needed\n        if self.correct:\n            # for each detection determine the ""beat range"", i.e. states where\n            # the pointers of the observation model are 1\n            beat_range = self.om.pointers[path]\n            # get all change points between True and False\n            idx = np.nonzero(np.diff(beat_range))[0] + 1\n            # if the first frame is in the beat range, add a change at frame 0\n            if beat_range[0]:\n                idx = np.r_[0, idx]\n            # if the last frame is in the beat range, append the length of the\n            # array\n            if beat_range[-1]:\n                idx = np.r_[idx, beat_range.size]\n            # iterate over all regions\n            if idx.any():\n                for left, right in idx.reshape((-1, 2)):\n                    # pick the frame with the highest activations value\n                    peak = np.argmax(activations[left:right]) + left\n                    beats = np.hstack((beats, peak))\n        else:\n            # just take the frames with the smallest beat state values\n            from scipy.signal import argrelmin\n            beats = argrelmin(self.st.state_positions[path], mode=\'wrap\')[0]\n            # recheck if they are within the ""beat range"", i.e. the pointers\n            # of the observation model for that state must be 1\n            # Note: interpolation and alignment of the beats to be at state 0\n            #       does not improve results over this simple method\n            beats = beats[self.om.pointers[path[beats]] == 1]\n        # convert the detected beats to seconds and return them\n        return (beats + first) / float(self.fps)\n\n    def process_online(self, activations, reset=True, **kwargs):\n        """"""\n        Detect the beats in the given activation function with the forward\n        algorithm.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Beat activation for a single frame.\n        reset : bool, optional\n            Reset the DBNBeatTrackingProcessor to its initial state before\n            processing.\n\n        Returns\n        -------\n        beats : numpy array\n            Detected beat position [seconds].\n\n        """"""\n        # reset to initial state\n        if reset:\n            self.reset()\n        # use forward path to get best state\n        fwd = self.hmm.forward(activations, reset=reset)\n        # choose the best state for each step\n        states = np.argmax(fwd, axis=1)\n        # decide which time steps are beats\n        beats = self.om.pointers[states] == 1\n        # the positions inside the beats\n        positions = self.st.state_positions[states]\n        # visualisation stuff (only when called frame by frame)\n        if self.visualize and len(activations) == 1:\n            beat_length = 80\n            display = [\' \'] * beat_length\n            display[int(positions * beat_length)] = \'*\'\n            # activation strength indicator\n            strength_length = 10\n            self.strength = int(max(self.strength, activations * 10))\n            display.append(\'| \')\n            display.extend([\'*\'] * self.strength)\n            display.extend([\' \'] * (strength_length - self.strength))\n            # reduce the displayed strength every couple of frames\n            if self.counter % 5 == 0:\n                self.strength -= 1\n            # beat indicator\n            if beats:\n                self.beat_counter = 3\n            if self.beat_counter > 0:\n                display.append(\'| X \')\n            else:\n                display.append(\'|   \')\n            self.beat_counter -= 1\n            # display tempo\n            display.append(\'| %5.1f | \' % self.tempo)\n            sys.stderr.write(\'\\r%s\' % \'\'.join(display))\n            sys.stderr.flush()\n        # forward path often reports multiple beats close together, thus report\n        # only beats more than the minimum interval apart\n        beats_ = []\n        for frame in np.nonzero(beats)[0]:\n            cur_beat = (frame + self.counter) / float(self.fps)\n            next_beat = self.last_beat + 60. / self.max_bpm\n            # FIXME: this skips the first beat, but maybe this has a positive\n            #        effect on the overall beat tracking accuracy\n            if cur_beat >= next_beat:\n                # update tempo\n                self.tempo = 60. / (cur_beat - self.last_beat)\n                # update last beat\n                self.last_beat = cur_beat\n                # append to beats\n                beats_.append(cur_beat)\n        # increase counter\n        self.counter += len(activations)\n        # return beat(s)\n        return np.array(beats_)\n\n    process_forward = process_online\n\n    process_viterbi = process_offline\n\n    @staticmethod\n    def add_arguments(parser, min_bpm=MIN_BPM, max_bpm=MAX_BPM,\n                      num_tempi=NUM_TEMPI, transition_lambda=TRANSITION_LAMBDA,\n                      observation_lambda=OBSERVATION_LAMBDA,\n                      threshold=THRESHOLD, correct=CORRECT):\n        """"""\n        Add DBN related arguments to an existing parser object.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        min_bpm : float, optional\n            Minimum tempo used for beat tracking [bpm].\n        max_bpm : float, optional\n            Maximum tempo used for beat tracking [bpm].\n        num_tempi : int, optional\n            Number of tempi to model; if set, limit the number of tempi and use\n            a log spacing, otherwise a linear spacing.\n        transition_lambda : float, optional\n            Lambda for the exponential tempo change distribution (higher values\n            prefer a constant tempo over a tempo change from one beat to the\n            next one).\n        observation_lambda : float, optional\n            Split one beat period into `observation_lambda` parts, the first\n            representing beat states and the remaining non-beat states.\n        threshold : float, optional\n            Threshold the observations before Viterbi decoding.\n        correct : bool, optional\n            Correct the beats (i.e. align them to the nearest peak of the beat\n            activation function).\n\n        Returns\n        -------\n        parser_group : argparse argument group\n            DBN beat tracking argument parser group\n\n        """"""\n        # pylint: disable=arguments-differ\n        # add DBN parser group\n        g = parser.add_argument_group(\'dynamic Bayesian Network arguments\')\n        # add a transition parameters\n        g.add_argument(\'--min_bpm\', action=\'store\', type=float,\n                       default=min_bpm,\n                       help=\'minimum tempo [bpm, default=%(default).2f]\')\n        g.add_argument(\'--max_bpm\', action=\'store\', type=float,\n                       default=max_bpm,\n                       help=\'maximum tempo [bpm,  default=%(default).2f]\')\n        g.add_argument(\'--num_tempi\', action=\'store\', type=int,\n                       default=num_tempi,\n                       help=\'limit the number of tempi; if set, align the \'\n                            \'tempi with a log spacing, otherwise linearly\')\n        g.add_argument(\'--transition_lambda\', action=\'store\', type=float,\n                       default=transition_lambda,\n                       help=\'lambda of the tempo transition distribution; \'\n                            \'higher values prefer a constant tempo over a \'\n                            \'tempo change from one beat to the next one \'\n                            \'[default=%(default).1f]\')\n        # observation model stuff\n        g.add_argument(\'--observation_lambda\', action=\'store\', type=float,\n                       default=observation_lambda,\n                       help=\'split one beat period into N parts, the first \'\n                            \'representing beat states and the remaining \'\n                            \'non-beat states [default=%(default)i]\')\n        g.add_argument(\'-t\', dest=\'threshold\', action=\'store\', type=float,\n                       default=threshold,\n                       help=\'threshold the observations before Viterbi \'\n                            \'decoding [default=%(default).2f]\')\n        # option to correct the beat positions\n        if correct:\n            g.add_argument(\'--no_correct\', dest=\'correct\',\n                           action=\'store_false\', default=correct,\n                           help=\'do not correct the beat positions (i.e. do \'\n                                \'not align them to the nearest peak of the \'\n                                \'beat activation function)\')\n        else:\n            g.add_argument(\'--correct\', dest=\'correct\',\n                           action=\'store_true\', default=correct,\n                           help=\'correct the beat positions (i.e. align them \'\n                                \'to the nearest peak of the beat activation\'\n                                \'function)\')\n        # return the argument group so it can be modified if needed\n        return g\n'"
madmom/features/beats_hmm.py,72,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains HMM state spaces, transition and observation models used\nfor beat, downbeat and pattern tracking.\n\nNotes\n-----\nPlease note that (almost) everything within this module is discretised to\ninteger values because of performance reasons.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\nfrom madmom.ml.hmm import ObservationModel, TransitionModel\n\n\n# state spaces\nclass BeatStateSpace(object):\n    """"""\n    State space for beat tracking with a HMM.\n\n    Parameters\n    ----------\n    min_interval : float\n        Minimum interval to model.\n    max_interval : float\n        Maximum interval to model.\n    num_intervals : int, optional\n        Number of intervals to model; if set, limit the number of intervals\n        and use a log spacing instead of the default linear spacing.\n\n    Attributes\n    ----------\n    num_states : int\n        Number of states.\n    intervals : numpy array\n        Modeled intervals.\n    num_intervals : int\n        Number of intervals.\n    state_positions : numpy array\n        Positions of the states (i.e. 0...1).\n    state_intervals : numpy array\n        Intervals of the states (i.e. 1 / tempo).\n    first_states : numpy array\n        First state of each interval.\n    last_states : numpy array\n        Last state of each interval.\n\n    References\n    ----------\n    .. [1] Florian Krebs, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""An Efficient State Space Model for Joint Tempo and Meter Tracking"",\n           Proceedings of the 16th International Society for Music Information\n           Retrieval Conference (ISMIR), 2015.\n\n    """"""\n\n    def __init__(self, min_interval, max_interval, num_intervals=None):\n        # per default, use a linear spacing of the tempi\n        intervals = np.arange(np.round(min_interval),\n                              np.round(max_interval) + 1)\n        # if num_intervals is given (and smaller than the length of the linear\n        # spacing of the intervals) use a log spacing and limit the number of\n        # intervals to the given value\n        if num_intervals is not None and num_intervals < len(intervals):\n            # we must approach the number of intervals iteratively\n            num_log_intervals = num_intervals\n            intervals = []\n            while len(intervals) < num_intervals:\n                intervals = np.logspace(np.log2(min_interval),\n                                        np.log2(max_interval),\n                                        num_log_intervals, base=2)\n                # quantize to integer intervals\n                intervals = np.unique(np.round(intervals))\n                num_log_intervals += 1\n        # save the intervals\n        self.intervals = np.ascontiguousarray(intervals, dtype=np.int)\n        # number of states and intervals\n        self.num_states = int(np.sum(intervals))\n        self.num_intervals = len(intervals)\n        # define first and last states\n        first_states = np.cumsum(np.r_[0, self.intervals[:-1]])\n        self.first_states = first_states.astype(np.int)\n        self.last_states = np.cumsum(self.intervals) - 1\n        # define the positions and intervals of the states\n        self.state_positions = np.empty(self.num_states)\n        self.state_intervals = np.empty(self.num_states, dtype=np.int)\n        # Note: having an index counter is faster than ndenumerate\n        idx = 0\n        for i in self.intervals:\n            self.state_positions[idx: idx + i] = np.linspace(0, 1, i,\n                                                             endpoint=False)\n            self.state_intervals[idx: idx + i] = i\n            idx += i\n\n\nclass BarStateSpace(object):\n    """"""\n    State space for bar tracking with a HMM.\n\n    Model `num_beat` identical beats with the given arguments in a single state\n    space.\n\n    Parameters\n    ----------\n    num_beats : int\n        Number of beats to form a bar.\n    min_interval : float\n        Minimum beat interval to model.\n    max_interval : float\n        Maximum beat interval to model.\n    num_intervals : int, optional\n        Number of beat intervals to model; if set, limit the number of\n        intervals and use a log spacing instead of the default linear spacing.\n\n    Attributes\n    ----------\n    num_beats : int\n        Number of beats.\n    num_states : int\n        Number of states.\n    num_intervals : int\n        Number of intervals.\n    state_positions : numpy array\n        Positions of the states.\n    state_intervals : numpy array\n        Intervals of the states.\n    first_states : list\n        First states of each beat.\n    last_states : list\n        Last states of each beat.\n\n    References\n    ----------\n    .. [1] Florian Krebs, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""An Efficient State Space Model for Joint Tempo and Meter Tracking"",\n           Proceedings of the 16th International Society for Music Information\n           Retrieval Conference (ISMIR), 2015.\n\n    """"""\n\n    def __init__(self, num_beats, min_interval, max_interval,\n                 num_intervals=None):\n        # model N beats as a bar\n        self.num_beats = int(num_beats)\n        self.state_positions = np.empty(0)\n        self.state_intervals = np.empty(0, dtype=np.int)\n        self.num_states = 0\n        # save the first and last states of the individual beats in a list\n        self.first_states = []\n        self.last_states = []\n        # create a BeatStateSpace and stack it `num_beats` times\n        bss = BeatStateSpace(min_interval, max_interval, num_intervals)\n        for b in range(self.num_beats):\n            # define position (add beat counter) and interval states\n            self.state_positions = np.hstack((self.state_positions,\n                                              bss.state_positions + b))\n            self.state_intervals = np.hstack((self.state_intervals,\n                                              bss.state_intervals))\n            # add the current number of states as offset\n            self.first_states.append(bss.first_states + self.num_states)\n            self.last_states.append(bss.last_states + self.num_states)\n            # finally increase the number of states\n            self.num_states += bss.num_states\n\n\nclass MultiPatternStateSpace(object):\n    """"""\n    State space for rhythmic pattern tracking with a HMM.\n\n    Model a joint state space with the given `state_spaces` by stacking the\n    individual state spaces.\n\n    Parameters\n    ----------\n    state_spaces : list\n        List with state spaces to model.\n\n    References\n    ----------\n    .. [1] Florian Krebs, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""An Efficient State Space Model for Joint Tempo and Meter Tracking"",\n           Proceedings of the 16th International Society for Music Information\n           Retrieval Conference (ISMIR), 2015.\n\n    """"""\n\n    def __init__(self, state_spaces):\n        # combine the given state spaces in a single state space\n        self.num_patterns = len(state_spaces)\n        self.state_spaces = state_spaces\n        self.state_positions = np.empty(0)\n        self.state_intervals = np.empty(0, dtype=np.int)\n        self.state_patterns = np.empty(0, dtype=np.int)\n        self.num_states = 0\n        # save the first and last states of the individual patterns in a list\n        self.first_states = []\n        self.last_states = []\n        # stack the individual state spaces\n        for p, pss in enumerate(state_spaces):\n            # define position, interval and pattern states\n            self.state_positions = np.hstack((self.state_positions,\n                                              pss.state_positions))\n            self.state_intervals = np.hstack((self.state_intervals,\n                                              pss.state_intervals))\n            self.state_patterns = np.hstack((self.state_patterns,\n                                             np.repeat(p, pss.num_states)))\n            # append the first and last states of each pattern\n            self.first_states.append(pss.first_states[0] + self.num_states)\n            self.last_states.append(pss.last_states[-1] + self.num_states)\n            # finally increase the number of states\n            self.num_states += pss.num_states\n\n\n# transition distributions\ndef exponential_transition(from_intervals, to_intervals, transition_lambda,\n                           threshold=np.spacing(1), norm=True):\n    """"""\n    Exponential tempo transition.\n\n    Parameters\n    ----------\n    from_intervals : numpy array\n        Intervals where the transitions originate from.\n    to_intervals :  : numpy array\n        Intervals where the transitions terminate.\n    transition_lambda : float\n        Lambda for the exponential tempo change distribution (higher values\n        prefer a constant tempo from one beat/bar to the next one). If None,\n        allow only transitions from/to the same interval.\n    threshold : float, optional\n        Set transition probabilities below this threshold to zero.\n    norm : bool, optional\n        Normalize the emission probabilities to sum 1.\n\n    Returns\n    -------\n    probabilities : numpy array, shape (num_from_intervals, num_to_intervals)\n        Probability of each transition from an interval to another.\n\n    References\n    ----------\n    .. [1] Florian Krebs, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""An Efficient State Space Model for Joint Tempo and Meter Tracking"",\n           Proceedings of the 16th International Society for Music Information\n           Retrieval Conference (ISMIR), 2015.\n\n    """"""\n    # no transition lambda\n    if transition_lambda is None:\n        # return a diagonal matrix\n        return np.diag(np.diag(np.ones((len(from_intervals),\n                                        len(to_intervals)))))\n    # compute the transition probabilities\n    ratio = (to_intervals.astype(np.float) /\n             from_intervals.astype(np.float)[:, np.newaxis])\n    prob = np.exp(-transition_lambda * abs(ratio - 1.))\n    # set values below threshold to 0\n    prob[prob <= threshold] = 0\n    # normalize the emission probabilities\n    if norm:\n        prob /= np.sum(prob, axis=1)[:, np.newaxis]\n    return prob\n\n\n# transition models\nclass BeatTransitionModel(TransitionModel):\n    """"""\n    Transition model for beat tracking with a HMM.\n\n    Within the beat the tempo stays the same; at beat boundaries transitions\n    from one tempo (i.e. interval) to another are allowed, following an\n    exponential distribution.\n\n    Parameters\n    ----------\n    state_space : :class:`BeatStateSpace` instance\n        BeatStateSpace instance.\n    transition_lambda : float\n        Lambda for the exponential tempo change distribution (higher values\n        prefer a constant tempo from one beat to the next one).\n\n    References\n    ----------\n    .. [1] Florian Krebs, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""An Efficient State Space Model for Joint Tempo and Meter Tracking"",\n           Proceedings of the 16th International Society for Music Information\n           Retrieval Conference (ISMIR), 2015.\n\n    """"""\n\n    def __init__(self, state_space, transition_lambda):\n        # save attributes\n        self.state_space = state_space\n        self.transition_lambda = float(transition_lambda)\n        # same tempo transitions probabilities within the state space is 1\n        # Note: use all states, but remove all first states because there are\n        #       no same tempo transitions into them\n        states = np.arange(state_space.num_states, dtype=np.uint32)\n        states = np.setdiff1d(states, state_space.first_states)\n        prev_states = states - 1\n        probabilities = np.ones_like(states, dtype=np.float)\n        # tempo transitions occur at the boundary between beats\n        # Note: connect the beat state space with itself, the transitions from\n        #       the last states to the first states follow an exponential tempo\n        #       transition (with the tempi given as intervals)\n        to_states = state_space.first_states\n        from_states = state_space.last_states\n        from_int = state_space.state_intervals[from_states]\n        to_int = state_space.state_intervals[to_states]\n        prob = exponential_transition(from_int, to_int, self.transition_lambda)\n        # use only the states with transitions to/from != 0\n        from_prob, to_prob = np.nonzero(prob)\n        states = np.hstack((states, to_states[to_prob]))\n        prev_states = np.hstack((prev_states, from_states[from_prob]))\n        probabilities = np.hstack((probabilities, prob[prob != 0]))\n        # make the transitions sparse\n        transitions = self.make_sparse(states, prev_states, probabilities)\n        # instantiate a TransitionModel\n        super(BeatTransitionModel, self).__init__(*transitions)\n\n\nclass BarTransitionModel(TransitionModel):\n    """"""\n    Transition model for bar tracking with a HMM.\n\n    Within the beats of the bar the tempo stays the same; at beat boundaries\n    transitions from one tempo (i.e. interval) to another following an\n    exponential distribution are allowed.\n\n    Parameters\n    ----------\n    state_space : :class:`BarStateSpace` instance\n        BarStateSpace instance.\n    transition_lambda : float or list\n        Lambda for the exponential tempo change distribution (higher values\n        prefer a constant tempo from one beat to the next one).\n        None can be used to set the tempo change probability to 0.\n        If a list is given, the individual values represent the lambdas for\n        each transition into the beat at this index position.\n\n    Notes\n    -----\n    Bars performing tempo changes only at bar boundaries (and not at the beat\n    boundaries) must have set all but the first `transition_lambda` values to\n    None, e.g. [100, None, None] for a bar with 3 beats.\n\n    References\n    ----------\n    .. [1] Florian Krebs, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""An Efficient State Space Model for Joint Tempo and Meter Tracking"",\n           Proceedings of the 16th International Society for Music Information\n           Retrieval Conference (ISMIR), 2015.\n\n    """"""\n\n    def __init__(self, state_space, transition_lambda):\n        # expand transition_lambda to a list if a single value is given\n        if not isinstance(transition_lambda, list):\n            transition_lambda = [transition_lambda] * state_space.num_beats\n        if state_space.num_beats != len(transition_lambda):\n            raise ValueError(\'length of `transition_lambda` must be equal to \'\n                             \'`num_beats` of `state_space`.\')\n        # save attributes\n        self.state_space = state_space\n        self.transition_lambda = transition_lambda\n        # TODO: this could be unified with the BeatTransitionModel\n        # same tempo transitions probabilities within the state space is 1\n        # Note: use all states, but remove all first states of the individual\n        #       beats, because there are no same tempo transitions into them\n        states = np.arange(state_space.num_states, dtype=np.uint32)\n        states = np.setdiff1d(states, state_space.first_states)\n        prev_states = states - 1\n        probabilities = np.ones_like(states, dtype=np.float)\n        # tempo transitions occur at the boundary between beats (unless the\n        # corresponding transition_lambda is set to None)\n        for beat in range(state_space.num_beats):\n            # connect to the first states of the actual beat\n            to_states = state_space.first_states[beat]\n            # connect from the last states of the previous beat\n            from_states = state_space.last_states[beat - 1]\n            # transition follow an exponential tempo distribution\n            from_int = state_space.state_intervals[from_states]\n            to_int = state_space.state_intervals[to_states]\n            prob = exponential_transition(from_int, to_int,\n                                          transition_lambda[beat])\n            # use only the states with transitions to/from != 0\n            from_prob, to_prob = np.nonzero(prob)\n            states = np.hstack((states, to_states[to_prob]))\n            prev_states = np.hstack((prev_states, from_states[from_prob]))\n            probabilities = np.hstack((probabilities, prob[prob != 0]))\n        # make the transitions sparse\n        transitions = self.make_sparse(states, prev_states, probabilities)\n        # instantiate a TransitionModel\n        super(BarTransitionModel, self).__init__(*transitions)\n\n\nclass MultiPatternTransitionModel(TransitionModel):\n    """"""\n    Transition model for pattern tracking with a HMM.\n\n    Add transitions with the given probability between the individual\n    transition models. These transition models must correspond to the state\n    spaces forming a :class:`MultiPatternStateSpace`.\n\n    Parameters\n    ----------\n    transition_models : list\n        List with :class:`TransitionModel` instances.\n    transition_prob : numpy array or float, optional\n        Probabilities to change the pattern at pattern boundaries. If an array\n        is given, the first dimension corresponds to the origin pattern, the\n        second to the destination pattern. If a single value is given, a\n        uniform transition distribution to all other patterns is assumed. Set\n        to None to stay within the same pattern.\n\n    """"""\n\n    def __init__(self, transition_models, transition_prob=None):\n        # save attributes\n        self.transition_models = transition_models\n        self.transition_prob = transition_prob\n        num_patterns = len(transition_models)\n        # first stack all transition models\n        first_states = []\n        last_states = []\n        for p, tm in enumerate(self.transition_models):\n            # set/update the probabilities, states and pointers\n            offset = 0\n            if p == 0:\n                # for the first pattern, just use the TM arrays\n                states = tm.states\n                pointers = tm.pointers\n                probabilities = tm.probabilities\n            else:\n                # for all consecutive patterns, stack the TM arrays after\n                # applying an offset\n                # Note: len(pointers) = len(states) + 1, because of the CSR\n                #       format of the TM (please see ml.hmm.TransitionModel)\n                offset = len(pointers) - 1\n                # states: offset = length of the pointers - 1\n                states = np.hstack((states, tm.states + len(pointers) - 1))\n                # pointers: offset = current maximum of the pointers\n                #           start = tm.pointers[1:]\n                pointers = np.hstack((pointers, tm.pointers[1:] +\n                                      max(pointers)))\n                # probabilities: just stack them\n                probabilities = np.hstack((probabilities, tm.probabilities))\n            # save the first/last states\n            first_states.append(tm.state_space.first_states[0] + offset)\n            last_states.append(tm.state_space.last_states[-1] + offset)\n        # retrieve a dense representation in order to add transitions\n        # TODO: operate directly on the sparse representation?\n        states, prev_states, probabilities = self.make_dense(states, pointers,\n                                                             probabilities)\n        # translate float transition_prob value to transition_prob matrix\n        if isinstance(transition_prob, float) and transition_prob:\n            # create a pattern transition probability matrix\n            self.transition_prob = np.ones((num_patterns, num_patterns))\n            # if there is more than 1 pattern, create transitions between them\n            if num_patterns > 1:\n                # transition to other patterns\n                self.transition_prob *= transition_prob / (num_patterns - 1)\n                # transition to same pattern\n                diag = np.diag_indices_from(self.transition_prob)\n                self.transition_prob[diag] = 1. - transition_prob\n        else:\n            self.transition_prob = transition_prob\n        # update/add transitions between patterns\n        if self.transition_prob is not None and num_patterns > 1:\n            new_states = []\n            new_prev_states = []\n            new_probabilities = []\n            for p in range(num_patterns):\n                # indices of states/prev_states/probabilities\n                idx = np.logical_and(np.in1d(prev_states, last_states[p]),\n                                     np.in1d(states, first_states[p]))\n                # transition probability\n                prob = probabilities[idx]\n                # update transitions to same pattern with new probability\n                probabilities[idx] *= self.transition_prob[p, p]\n                # distribute that part among all other patterns\n                for p_ in np.setdiff1d(range(num_patterns), p):\n                    idx_ = np.logical_and(\n                        np.in1d(prev_states, last_states[p_]),\n                        np.in1d(states, first_states[p_]))\n                    # make sure idx and idx_ have same length\n                    if len(np.nonzero(idx)[0]) != len(np.nonzero(idx_)[0]):\n                        raise ValueError(\'Cannot add transition between \'\n                                         \'patterns with different number of \'\n                                         \'entering/exiting states.\')\n                    # use idx for the states and idx_ for prev_states\n                    new_states.extend(states[idx])\n                    new_prev_states.extend(prev_states[idx_])\n                    new_probabilities.extend(prob *\n                                             self.transition_prob[p, p_])\n            # extend the arrays by these new transitions\n            states = np.append(states, new_states)\n            prev_states = np.append(prev_states, new_prev_states)\n            probabilities = np.append(probabilities, new_probabilities)\n        # make the transitions sparse\n        transitions = self.make_sparse(states, prev_states, probabilities)\n        # instantiate a TransitionModel\n        super(MultiPatternTransitionModel, self).__init__(*transitions)\n\n\n# observation models\nclass RNNBeatTrackingObservationModel(ObservationModel):\n    """"""\n    Observation model for beat tracking with a HMM.\n\n    Parameters\n    ----------\n    state_space : :class:`BeatStateSpace` instance\n        BeatStateSpace instance.\n    observation_lambda : int\n        Split one beat period into `observation_lambda` parts, the first\n        representing beat states and the remaining non-beat states.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck, Florian Krebs and Gerhard Widmer,\n           ""A Multi-Model Approach to Beat Tracking Considering Heterogeneous\n           Music Styles"",\n           Proceedings of the 15th International Society for Music Information\n           Retrieval Conference (ISMIR), 2014.\n\n    """"""\n\n    def __init__(self, state_space, observation_lambda):\n        self.observation_lambda = observation_lambda\n        # compute observation pointers\n        # always point to the non-beat densities\n        pointers = np.zeros(state_space.num_states, dtype=np.uint32)\n        # unless they are in the beat range of the state space\n        border = 1. / observation_lambda\n        pointers[state_space.state_positions < border] = 1\n        # instantiate a ObservationModel with the pointers\n        super(RNNBeatTrackingObservationModel, self).__init__(pointers)\n\n    def log_densities(self, observations):\n        """"""\n        Compute the log densities of the observations.\n\n        Parameters\n        ----------\n        observations : numpy array, shape (N, )\n            Observations (i.e. 1D beat activations of the RNN).\n\n        Returns\n        -------\n        numpy array, shape (N, 2)\n            Log densities of the observations, the columns represent the\n            observation log probability densities for no-beats and beats.\n\n        """"""\n        # init densities\n        log_densities = np.empty((len(observations), 2), dtype=np.float)\n        # Note: it\'s faster to call np.log 2 times instead of once on the\n        #       whole 2d array\n        log_densities[:, 0] = np.log((1. - observations) /\n                                     (self.observation_lambda - 1))\n        log_densities[:, 1] = np.log(observations)\n        # return the densities\n        return log_densities\n\n\nclass RNNDownBeatTrackingObservationModel(ObservationModel):\n    """"""\n    Observation model for downbeat tracking with a HMM.\n\n    Parameters\n    ----------\n    state_space : :class:`BarStateSpace` instance\n        BarStateSpace instance.\n    observation_lambda : int\n        Split each (down-)beat period into `observation_lambda` parts, the\n        first representing (down-)beat states and the remaining non-beat\n        states.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck, Florian Krebs and Gerhard Widmer,\n           ""Joint Beat and Downbeat Tracking with Recurrent Neural Networks""\n           Proceedings of the 17th International Society for Music Information\n           Retrieval Conference (ISMIR), 2016.\n\n    """"""\n\n    def __init__(self, state_space, observation_lambda):\n        self.observation_lambda = observation_lambda\n        # compute observation pointers\n        # always point to the non-beat densities\n        pointers = np.zeros(state_space.num_states, dtype=np.uint32)\n        # unless they are in the beat range of the state space\n        border = 1. / observation_lambda\n        pointers[state_space.state_positions % 1 < border] = 1\n        # the downbeat (i.e. the first beat range) points to density column 2\n        pointers[state_space.state_positions < border] = 2\n        # instantiate a ObservationModel with the pointers\n        super(RNNDownBeatTrackingObservationModel, self).__init__(pointers)\n\n    def log_densities(self, observations):\n        """"""\n        Compute the log densities of the observations.\n\n        Parameters\n        ----------\n        observations : numpy array, shape (N, 2)\n            Observations (i.e. 2D activations of a RNN, the columns represent\n            \'beat\' and \'downbeat\' probabilities)\n\n        Returns\n        -------\n        numpy array, shape (N, 3)\n            Log densities of the observations, the columns represent the\n            observation log probability densities for no-beats, beats and\n            downbeats.\n\n        """"""\n        # init densities\n        log_densities = np.empty((len(observations), 3), dtype=np.float)\n        # Note: it\'s faster to call np.log multiple times instead of once on\n        #       the whole 2d array\n        log_densities[:, 0] = np.log((1. - np.sum(observations, axis=1)) /\n                                     (self.observation_lambda - 1))\n        log_densities[:, 1] = np.log(observations[:, 0])\n        log_densities[:, 2] = np.log(observations[:, 1])\n        # return the densities\n        return log_densities\n\n\nclass GMMPatternTrackingObservationModel(ObservationModel):\n    """"""\n    Observation model for GMM based beat tracking with a HMM.\n\n    Parameters\n    ----------\n    pattern_files : list\n        List with files representing the rhythmic patterns, one entry per\n        pattern; each pattern being a list with fitted GMMs.\n    state_space : :class:`MultiPatternStateSpace` instance\n        Multi pattern state space.\n\n    References\n    ----------\n    .. [1] Florian Krebs, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""Rhythmic Pattern Modeling for Beat and Downbeat Tracking in Musical\n           Audio"",\n           Proceedings of the 14th International Society for Music Information\n           Retrieval Conference (ISMIR), 2013.\n\n    """"""\n\n    def __init__(self, pattern_files, state_space):\n        # save the parameters\n        self.pattern_files = pattern_files\n        self.state_space = state_space\n        # define the pointers of the log densities\n        pointers = np.zeros(state_space.num_states, dtype=np.uint32)\n        patterns = self.state_space.state_patterns\n        positions = self.state_space.state_positions\n        # Note: the densities of all GMMs are just stacked on top of each\n        #       other, so we have to to keep track of the total number of GMMs\n        densities_idx_offset = 0\n        for p, gmms in enumerate(pattern_files):\n            # number of fitted GMMs for this pattern\n            num_gmms = len(gmms)\n            # number of beats in this pattern\n            # TODO: save the number of beats in the pattern files so we don\'t\n            #       need to save references to all state spaces\n            num_beats = self.state_space.state_spaces[p].num_beats\n            # distribute the observation densities defined by the GMMs\n            # uniformly across the entire state space (for this pattern)\n            # since the densities are just stacked, add the offset\n            # Note: we have to divide by the number of beats, since the\n            #       positions range is [0, num_beats]\n            pointers[patterns == p] = (positions[patterns == p] * num_gmms /\n                                       num_beats + densities_idx_offset)\n            # increase the offset by the number of GMMs\n            densities_idx_offset += num_gmms\n        # instantiate a ObservationModel with the pointers\n        super(GMMPatternTrackingObservationModel, self).__init__(pointers)\n\n    def log_densities(self, observations):\n        """"""\n        Compute the log densities of the observations using (a) GMM(s).\n\n        Parameters\n        ----------\n        observations : numpy array\n            Observations (i.e. multi-band spectral flux features).\n\n        Returns\n        -------\n        numpy array, shape (N, num_gmms)\n            Log densities of the observations, the columns represent the\n            observation log probability densities for the individual GMMs.\n\n        """"""\n        # number of GMMs of all patterns\n        num_gmms = sum([len(pattern) for pattern in self.pattern_files])\n        # init the densities\n        log_densities = np.empty((len(observations), num_gmms), dtype=np.float)\n        # define the observation densities\n        i = 0\n        for pattern in self.pattern_files:\n            for gmm in pattern:\n                # get the predictions of each GMM for the observations\n                log_densities[:, i] = gmm.score(observations)\n                i += 1\n        # return the densities\n        return log_densities\n'"
madmom/features/chords.py,3,"b'# encoding: utf-8\n""""""\nThis module contains chord recognition related functionality.\n\n""""""\nfrom __future__ import absolute_import, division, print_function\n\nfrom functools import partial\n\nimport numpy as np\n\nfrom ..io import SEGMENT_DTYPE\nfrom ..processors import SequentialProcessor\n\n\ndef majmin_targets_to_chord_labels(targets, fps):\n    """"""\n    Converts a series of major/minor chord targets to human readable chord\n    labels. Targets are assumed to be spaced equidistant in time as defined\n    by the `fps` parameter (each target represents one \'frame\').\n\n    Ids 0-11 encode major chords starting with root \'A\', 12-23 minor chords.\n    Id 24 represents \'N\', the no-chord class.\n\n    Parameters\n    ----------\n    targets : iterable\n        Iterable containing chord class ids.\n    fps : float\n        Frames per second. Consecutive class\n\n    Returns\n    -------\n    chord labels : list\n        List of tuples of the form (start time, end time, chord label)\n\n    """"""\n    # create a map of semitone index to semitone name (e.g. 0 -> A, 1 -> A#)\n    pitch_class_to_label = [\'A\', \'A#\', \'B\', \'C\', \'C#\', \'D\', \'D#\', \'E\', \'F\',\n                            \'F#\', \'G\', \'G#\']\n\n    def pred_to_cl(pred):\n        """"""\n        Map a class id to a chord label.\n        0..11 major chords, 12..23 minor chords, 24 no chord\n        """"""\n        if pred == 24:\n            return \'N\'\n        return \'{}:{}\'.format(pitch_class_to_label[pred % 12],\n                              \'maj\' if pred < 12 else \'min\')\n\n    # get labels per frame\n    spf = 1. / fps\n    labels = [(i * spf, pred_to_cl(p)) for i, p in enumerate(targets)]\n\n    # join same consecutive predictions\n    prev_label = (None, None)\n    uniq_labels = []\n\n    for label in labels:\n        if label[1] != prev_label[1]:\n            uniq_labels.append(label)\n            prev_label = label\n\n    # end time of last label is one frame duration after\n    # the last prediction time\n    start_times, chord_labels = zip(*uniq_labels)\n    end_times = start_times[1:] + (labels[-1][0] + spf,)\n\n    return np.array(list(zip(start_times, end_times, chord_labels)),\n                    dtype=SEGMENT_DTYPE)\n\n\nclass DeepChromaChordRecognitionProcessor(SequentialProcessor):\n    """"""\n    Recognise major and minor chords from deep chroma vectors [1]_ using a\n    Conditional Random Field.\n\n    Parameters\n    ----------\n    model : str\n        File containing the CRF model. If None, use the model supplied with\n        madmom.\n    fps : float\n        Frames per second. Must correspond to the fps of the incoming\n        activations and the model.\n\n    References\n    ----------\n    .. [1] Filip Korzeniowski and Gerhard Widmer,\n           ""Feature Learning for Chord Recognition: The Deep Chroma Extractor"",\n           Proceedings of the 17th International Society for Music Information\n           Retrieval Conference (ISMIR), 2016.\n\n    Examples\n    --------\n    To recognise chords in an audio file using the\n    DeepChromaChordRecognitionProcessor you first need to create a\n    madmom.audio.chroma.DeepChromaProcessor to extract the appropriate chroma\n    vectors.\n\n    >>> from madmom.audio.chroma import DeepChromaProcessor\n    >>> dcp = DeepChromaProcessor()\n    >>> dcp  # doctest: +ELLIPSIS\n    <madmom.audio.chroma.DeepChromaProcessor object at ...>\n\n    Then, create the DeepChromaChordRecognitionProcessor to decode a chord\n    sequence from the extracted chromas:\n\n    >>> decode = DeepChromaChordRecognitionProcessor()\n    >>> decode  # doctest: +ELLIPSIS\n    <madmom.features.chords.DeepChromaChordRecognitionProcessor object at ...>\n\n    To transcribe the chords, you can either manually call the processors\n    one after another,\n\n    >>> chroma = dcp(\'tests/data/audio/sample2.wav\')\n    >>> decode(chroma)\n    ... # doctest: +NORMALIZE_WHITESPACE +NORMALIZE_ARRAYS\n    array([(0. , 1.6, \'F:maj\'), (1.6, 2.5, \'A:maj\'), (2.5, 4.1, \'D:maj\')],\n          dtype=[(\'start\', \'<f8\'), (\'end\', \'<f8\'), (\'label\', \'O\')])\n\n    or create a `SequentialProcessor` that connects them:\n\n    >>> from madmom.processors import SequentialProcessor\n    >>> chordrec = SequentialProcessor([dcp, decode])\n    >>> chordrec(\'tests/data/audio/sample2.wav\')\n    ... # doctest: +NORMALIZE_WHITESPACE +NORMALIZE_ARRAYS\n    array([(0. , 1.6, \'F:maj\'), (1.6, 2.5, \'A:maj\'), (2.5, 4.1, \'D:maj\')],\n          dtype=[(\'start\', \'<f8\'), (\'end\', \'<f8\'), (\'label\', \'O\')])\n    """"""\n\n    def __init__(self, model=None, fps=10, **kwargs):\n        from ..ml.crf import ConditionalRandomField\n        from ..models import CHORDS_DCCRF\n        crf = ConditionalRandomField.load(model or CHORDS_DCCRF[0])\n        lbl = partial(majmin_targets_to_chord_labels, fps=fps)\n        super(DeepChromaChordRecognitionProcessor, self).__init__((crf, lbl))\n\n\n# functions necessary for CNNChordFeatureProcessor - they need to\n# be outside of the class so the processor stays picklable\ndef _cnncfp_pad(data):\n    """"""Pad the input""""""\n    pad_data = np.zeros((11, 113))\n    return np.vstack([pad_data, data, pad_data])\n\n\ndef _cnncfp_superframes(data):\n    """"""Segment input into superframes""""""\n    from ..utils import segment_axis\n    return segment_axis(data, 3, 1, axis=0)\n\n\ndef _cnncfp_avg(data):\n    """"""Global average pool""""""\n    return data.mean((1, 2))\n\n\nclass CNNChordFeatureProcessor(SequentialProcessor):\n    """"""\n    Extract learned features for chord recognition, as described in [1]_.\n\n    References\n    ----------\n    .. [1] Filip Korzeniowski and Gerhard Widmer,\n           ""A Fully Convolutional Deep Auditory Model for Musical Chord\n           Recognition"",\n           Proceedings of IEEE International Workshop on Machine Learning for\n           Signal Processing (MLSP), 2016.\n\n    Examples\n    --------\n    >>> proc = CNNChordFeatureProcessor()\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.chords.CNNChordFeatureProcessor object at 0x...>\n    >>> features = proc(\'tests/data/audio/sample2.wav\')\n    >>> features.shape\n    (41, 128)\n    >>> features # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    array([[0.05798, 0.     , ..., 0.02757, 0.014  ],\n           [0.06604, 0.     , ..., 0.02898, 0.00886],\n           ...,\n           [0.00655, 0.1166 , ..., 0.00651, 0.     ],\n           [0.01476, 0.11185, ..., 0.00287, 0.     ]])\n    """"""\n\n    def __init__(self, **kwargs):\n        from ..audio.signal import SignalProcessor, FramedSignalProcessor\n        from ..audio.stft import ShortTimeFourierTransformProcessor\n        from ..audio.spectrogram import LogarithmicFilteredSpectrogramProcessor\n        from ..ml.nn import NeuralNetwork\n        from ..models import CHORDS_CNN_FEAT\n\n        # spectrogram computation\n        sig = SignalProcessor(num_channels=1, sample_rate=44100)\n        frames = FramedSignalProcessor(frame_size=8192, fps=10)\n        stft = ShortTimeFourierTransformProcessor()  # caching FFT window\n        spec = LogarithmicFilteredSpectrogramProcessor(\n            num_bands=24, fmin=60, fmax=2600, unique_filters=True\n        )\n\n        # padding, neural network and global average pooling\n        pad = _cnncfp_pad\n        nn = NeuralNetwork.load(CHORDS_CNN_FEAT[0])\n        superframes = _cnncfp_superframes\n        avg = _cnncfp_avg\n\n        # create processing pipeline\n        super(CNNChordFeatureProcessor, self).__init__([\n            sig, frames, stft, spec, pad, nn, superframes, avg\n        ])\n\n\nclass CRFChordRecognitionProcessor(SequentialProcessor):\n    """"""\n    Recognise major and minor chords from learned features extracted by\n    a convolutional neural network, as described in [1]_.\n\n    Parameters\n    ----------\n    model : str\n        File containing the CRF model. If None, use the model supplied with\n        madmom.\n    fps : float\n        Frames per second. Must correspond to the fps of the incoming\n        activations and the model.\n\n    References\n    ----------\n    .. [1] Filip Korzeniowski and Gerhard Widmer,\n           ""A Fully Convolutional Deep Auditory Model for Musical Chord\n           Recognition"",\n           Proceedings of IEEE International Workshop on Machine Learning for\n           Signal Processing (MLSP), 2016.\n\n    Examples\n    --------\n    To recognise chords using the CRFChordRecognitionProcessor, you first need\n    to extract features using the CNNChordFeatureProcessor.\n\n    >>> featproc = CNNChordFeatureProcessor()\n    >>> featproc  # doctest: +ELLIPSIS\n    <madmom.features.chords.CNNChordFeatureProcessor object at 0x...>\n\n    Then, create the CRFChordRecognitionProcessor to decode a chord sequence\n    from the extracted features:\n\n    >>> decode = CRFChordRecognitionProcessor()\n    >>> decode  # doctest: +ELLIPSIS\n    <madmom.features.chords.CRFChordRecognitionProcessor object at 0x...>\n\n    To transcribe the chords, you can either manually call the processors\n    one after another,\n\n    >>> feats = featproc(\'tests/data/audio/sample2.wav\')\n    >>> decode(feats)\n    ... # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS +NORMALIZE_ARRAYS\n    array([(0. , 0.2, \'N\'), (0.2, 1.6, \'F:maj\'),\n           (1.6, 2.4..., \'A:maj\'), (2.4..., 4.1, \'D:min\')],\n          dtype=[(\'start\', \'<f8\'), (\'end\', \'<f8\'), (\'label\', \'O\')])\n\n    or create a `madmom.processors.SequentialProcessor` that connects them:\n\n    >>> from madmom.processors import SequentialProcessor\n    >>> chordrec = SequentialProcessor([featproc, decode])\n    >>> chordrec(\'tests/data/audio/sample2.wav\')\n    ... # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS +NORMALIZE_ARRAYS\n    array([(0. , 0.2, \'N\'), (0.2, 1.6, \'F:maj\'),\n           (1.6, 2.4..., \'A:maj\'), (2.4..., 4.1, \'D:min\')],\n          dtype=[(\'start\', \'<f8\'), (\'end\', \'<f8\'), (\'label\', \'O\')])\n    """"""\n    def __init__(self, model=None, fps=10, **kwargs):\n        from ..ml.crf import ConditionalRandomField\n        from ..models import CHORDS_CFCRF\n        crf = ConditionalRandomField.load(model or CHORDS_CFCRF[0])\n        lbl = partial(majmin_targets_to_chord_labels, fps=fps)\n        super(CRFChordRecognitionProcessor, self).__init__((crf, lbl))\n'"
madmom/features/downbeats.py,54,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains downbeat and bar tracking related functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport sys\nimport warnings\n\nimport numpy as np\n\nfrom .beats import threshold_activations\nfrom .beats_hmm import (BarStateSpace, BarTransitionModel,\n                        GMMPatternTrackingObservationModel,\n                        MultiPatternStateSpace,\n                        MultiPatternTransitionModel,\n                        RNNBeatTrackingObservationModel,\n                        RNNDownBeatTrackingObservationModel, )\nfrom ..ml.hmm import HiddenMarkovModel\nfrom ..processors import ParallelProcessor, Processor, SequentialProcessor\nfrom ..utils import string_types\n\n\n# downbeat tracking, i.e. track beats and downbeats directly from signal\nclass RNNDownBeatProcessor(SequentialProcessor):\n    """"""\n    Processor to get a joint beat and downbeat activation function from\n    multiple RNNs.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck, Florian Krebs and Gerhard Widmer,\n           ""Joint Beat and Downbeat Tracking with Recurrent Neural Networks""\n           Proceedings of the 17th International Society for Music Information\n           Retrieval Conference (ISMIR), 2016.\n\n    Examples\n    --------\n    Create a RNNDownBeatProcessor and pass a file through the processor.\n    The returned 2d array represents the probabilities at each frame, sampled\n    at 100 frames per second. The columns represent \'beat\' and \'downbeat\'.\n\n    >>> proc = RNNDownBeatProcessor()\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.downbeats.RNNDownBeatProcessor object at 0x...>\n    >>> proc(\'tests/data/audio/sample.wav\')\n    ... # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    array([[0.00011, 0.00037],\n           [0.00008, 0.00043],\n           ...,\n           [0.00791, 0.00169],\n           [0.03425, 0.00494]], dtype=float32)\n\n    """"""\n\n    def __init__(self, **kwargs):\n        # pylint: disable=unused-argument\n        from functools import partial\n        from ..audio.signal import SignalProcessor, FramedSignalProcessor\n        from ..audio.stft import ShortTimeFourierTransformProcessor\n        from ..audio.spectrogram import (\n            FilteredSpectrogramProcessor, LogarithmicSpectrogramProcessor,\n            SpectrogramDifferenceProcessor)\n        from ..ml.nn import NeuralNetworkEnsemble\n        from ..models import DOWNBEATS_BLSTM\n\n        # define pre-processing chain\n        sig = SignalProcessor(num_channels=1, sample_rate=44100)\n        # process the multi-resolution spec & diff in parallel\n        multi = ParallelProcessor([])\n        frame_sizes = [1024, 2048, 4096]\n        num_bands = [3, 6, 12]\n        for frame_size, num_bands in zip(frame_sizes, num_bands):\n            frames = FramedSignalProcessor(frame_size=frame_size, fps=100)\n            stft = ShortTimeFourierTransformProcessor()  # caching FFT window\n            filt = FilteredSpectrogramProcessor(\n                num_bands=num_bands, fmin=30, fmax=17000, norm_filters=True)\n            spec = LogarithmicSpectrogramProcessor(mul=1, add=1)\n            diff = SpectrogramDifferenceProcessor(\n                diff_ratio=0.5, positive_diffs=True, stack_diffs=np.hstack)\n            # process each frame size with spec and diff sequentially\n            multi.append(SequentialProcessor((frames, stft, filt, spec, diff)))\n        # stack the features and processes everything sequentially\n        pre_processor = SequentialProcessor((sig, multi, np.hstack))\n        # process the pre-processed signal with a NN ensemble\n        nn = NeuralNetworkEnsemble.load(DOWNBEATS_BLSTM, **kwargs)\n        # use only the beat & downbeat (i.e. remove non-beat) activations\n        act = partial(np.delete, obj=0, axis=1)\n        # instantiate a SequentialProcessor\n        super(RNNDownBeatProcessor, self).__init__((pre_processor, nn, act))\n\n\ndef _process_dbn(process_tuple):\n    """"""\n    Extract the best path through the state space in an observation sequence.\n\n    This proxy function is necessary to process different sequences in parallel\n    using the multiprocessing module.\n\n    Parameters\n    ----------\n    process_tuple : tuple\n        Tuple with (HMM, observations).\n\n    Returns\n    -------\n    path : numpy array\n        Best path through the state space.\n    log_prob : float\n        Log probability of the path.\n\n    """"""\n    # pylint: disable=no-name-in-module\n    return process_tuple[0].viterbi(process_tuple[1])\n\n\nclass DBNDownBeatTrackingProcessor(Processor):\n    """"""\n    Downbeat tracking with RNNs and a dynamic Bayesian network (DBN)\n    approximated by a Hidden Markov Model (HMM).\n\n    Parameters\n    ----------\n    beats_per_bar : int or list\n        Number of beats per bar to be modeled. Can be either a single number\n        or a list or array with bar lengths (in beats).\n    min_bpm : float or list, optional\n        Minimum tempo used for beat tracking [bpm]. If a list is given, each\n        item corresponds to the number of beats per bar at the same position.\n    max_bpm : float or list, optional\n        Maximum tempo used for beat tracking [bpm]. If a list is given, each\n        item corresponds to the number of beats per bar at the same position.\n    num_tempi : int or list, optional\n        Number of tempi to model; if set, limit the number of tempi and use a\n        log spacing, otherwise a linear spacing. If a list is given, each\n        item corresponds to the number of beats per bar at the same position.\n    transition_lambda : float or list, optional\n        Lambda for the exponential tempo change distribution (higher values\n        prefer a constant tempo from one beat to the next one).  If a list is\n        given, each item corresponds to the number of beats per bar at the\n        same position.\n    observation_lambda : int, optional\n        Split one (down-)beat period into `observation_lambda` parts, the first\n        representing (down-)beat states and the remaining non-beat states.\n    threshold : float, optional\n        Threshold the RNN (down-)beat activations before Viterbi decoding.\n    correct : bool, optional\n        Correct the beats (i.e. align them to the nearest peak of the\n        (down-)beat activation function).\n    fps : float, optional\n        Frames per second.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck, Florian Krebs and Gerhard Widmer,\n           ""Joint Beat and Downbeat Tracking with Recurrent Neural Networks""\n           Proceedings of the 17th International Society for Music Information\n           Retrieval Conference (ISMIR), 2016.\n\n    Examples\n    --------\n    Create a DBNDownBeatTrackingProcessor. The returned array represents the\n    positions of the beats and their position inside the bar. The position is\n    given in seconds, thus the expected sampling rate is needed. The position\n    inside the bar follows the natural counting and starts at 1.\n\n    The number of beats per bar which should be modelled must be given, all\n    other parameters (e.g. tempo range) are optional but must have the same\n    length as `beats_per_bar`, i.e. must be given for each bar length.\n\n    >>> proc = DBNDownBeatTrackingProcessor(beats_per_bar=[3, 4], fps=100)\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.downbeats.DBNDownBeatTrackingProcessor object at 0x...>\n\n    Call this DBNDownBeatTrackingProcessor with the beat activation function\n    returned by RNNDownBeatProcessor to obtain the beat positions.\n\n    >>> act = RNNDownBeatProcessor()(\'tests/data/audio/sample.wav\')\n    >>> proc(act)  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n    array([[0.09, 1. ],\n           [0.45, 2. ],\n           ...,\n           [2.14, 3. ],\n           [2.49, 4. ]])\n\n    """"""\n\n    MIN_BPM = 55.\n    MAX_BPM = 215.\n    NUM_TEMPI = 60\n    TRANSITION_LAMBDA = 100\n    OBSERVATION_LAMBDA = 16\n    THRESHOLD = 0.05\n    CORRECT = True\n\n    def __init__(self, beats_per_bar, min_bpm=MIN_BPM, max_bpm=MAX_BPM,\n                 num_tempi=NUM_TEMPI, transition_lambda=TRANSITION_LAMBDA,\n                 observation_lambda=OBSERVATION_LAMBDA, threshold=THRESHOLD,\n                 correct=CORRECT, fps=None, **kwargs):\n        # pylint: disable=unused-argument\n        # pylint: disable=no-name-in-module\n        # expand arguments to arrays\n        beats_per_bar = np.array(beats_per_bar, ndmin=1)\n        min_bpm = np.array(min_bpm, ndmin=1)\n        max_bpm = np.array(max_bpm, ndmin=1)\n        num_tempi = np.array(num_tempi, ndmin=1)\n        transition_lambda = np.array(transition_lambda, ndmin=1)\n        # make sure the other arguments are long enough by repeating them\n        # TODO: check if they are of length 1?\n        if len(min_bpm) != len(beats_per_bar):\n            min_bpm = np.repeat(min_bpm, len(beats_per_bar))\n        if len(max_bpm) != len(beats_per_bar):\n            max_bpm = np.repeat(max_bpm, len(beats_per_bar))\n        if len(num_tempi) != len(beats_per_bar):\n            num_tempi = np.repeat(num_tempi, len(beats_per_bar))\n        if len(transition_lambda) != len(beats_per_bar):\n            transition_lambda = np.repeat(transition_lambda,\n                                          len(beats_per_bar))\n        if not (len(min_bpm) == len(max_bpm) == len(num_tempi) ==\n                len(beats_per_bar) == len(transition_lambda)):\n            raise ValueError(\'`min_bpm`, `max_bpm`, `num_tempi`, `num_beats` \'\n                             \'and `transition_lambda` must all have the same \'\n                             \'length.\')\n        # get num_threads from kwargs\n        num_threads = min(len(beats_per_bar), kwargs.get(\'num_threads\', 1))\n        # init a pool of workers (if needed)\n        self.map = map\n        if num_threads != 1:\n            import multiprocessing as mp\n            self.map = mp.Pool(num_threads).map\n        # convert timing information to construct a beat state space\n        min_interval = 60. * fps / max_bpm\n        max_interval = 60. * fps / min_bpm\n        # model the different bar lengths\n        self.hmms = []\n        for b, beats in enumerate(beats_per_bar):\n            st = BarStateSpace(beats, min_interval[b], max_interval[b],\n                               num_tempi[b])\n            tm = BarTransitionModel(st, transition_lambda[b])\n            om = RNNDownBeatTrackingObservationModel(st, observation_lambda)\n            self.hmms.append(HiddenMarkovModel(tm, om))\n        # save variables\n        self.beats_per_bar = beats_per_bar\n        self.threshold = threshold\n        self.correct = correct\n        self.fps = fps\n\n    def process(self, activations, **kwargs):\n        """"""\n        Detect the (down-)beats in the given activation function.\n\n        Parameters\n        ----------\n        activations : numpy array, shape (num_frames, 2)\n            Activation function with probabilities corresponding to beats\n            and downbeats given in the first and second column, respectively.\n\n        Returns\n        -------\n        beats : numpy array, shape (num_beats, 2)\n            Detected (down-)beat positions [seconds] and beat numbers.\n\n        """"""\n        # pylint: disable=arguments-differ\n        import itertools as it\n        # use only the activations > threshold (init offset to be added later)\n        first = 0\n        if self.threshold:\n            activations, first = threshold_activations(activations,\n                                                       self.threshold)\n        # return no beats if no activations given / remain after thresholding\n        if not activations.any():\n            return np.empty((0, 2))\n        # (parallel) decoding of the activations with HMM\n        results = list(self.map(_process_dbn, zip(self.hmms,\n                                                  it.repeat(activations))))\n        # choose the best HMM (highest log probability)\n        best = np.argmax(np.asarray(results)[:, 1])\n        # the best path through the state space\n        path, _ = results[best]\n        # the state space and observation model of the best HMM\n        st = self.hmms[best].transition_model.state_space\n        om = self.hmms[best].observation_model\n        # the positions inside the pattern (0..num_beats)\n        positions = st.state_positions[path]\n        # corresponding beats (add 1 for natural counting)\n        beat_numbers = positions.astype(int) + 1\n        if self.correct:\n            beats = np.empty(0, dtype=np.int)\n            # for each detection determine the ""beat range"", i.e. states where\n            # the pointers of the observation model are >= 1\n            beat_range = om.pointers[path] >= 1\n            # get all change points between True and False (cast to int before)\n            idx = np.nonzero(np.diff(beat_range.astype(np.int)))[0] + 1\n            # if the first frame is in the beat range, add a change at frame 0\n            if beat_range[0]:\n                idx = np.r_[0, idx]\n            # if the last frame is in the beat range, append the length of the\n            # array\n            if beat_range[-1]:\n                idx = np.r_[idx, beat_range.size]\n            # iterate over all regions\n            if idx.any():\n                for left, right in idx.reshape((-1, 2)):\n                    # pick the frame with the highest activations value\n                    # Note: we look for both beats and down-beat activations;\n                    #       since np.argmax works on the flattened array, we\n                    #       need to divide by 2\n                    peak = np.argmax(activations[left:right]) // 2 + left\n                    beats = np.hstack((beats, peak))\n        else:\n            # transitions are the points where the beat numbers change\n            # FIXME: we might miss the first or last beat!\n            #        we could calculate the interval towards the beginning/end\n            #        to decide whether to include these points\n            beats = np.nonzero(np.diff(beat_numbers))[0] + 1\n        # return the beat positions (converted to seconds) and beat numbers\n        return np.vstack(((beats + first) / float(self.fps),\n                          beat_numbers[beats])).T\n\n    @staticmethod\n    def add_arguments(parser, beats_per_bar, min_bpm=MIN_BPM, max_bpm=MAX_BPM,\n                      num_tempi=NUM_TEMPI, transition_lambda=TRANSITION_LAMBDA,\n                      observation_lambda=OBSERVATION_LAMBDA,\n                      threshold=THRESHOLD, correct=CORRECT):\n        """"""\n        Add DBN downbeat tracking related arguments to an existing parser\n        object.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        beats_per_bar : int or list, optional\n            Number of beats per bar to be modeled. Can be either a single\n            number or a list with bar lengths (in beats).\n        min_bpm : float or list, optional\n            Minimum tempo used for beat tracking [bpm]. If a list is given,\n            each item corresponds to the number of beats per bar at the same\n            position.\n        max_bpm : float or list, optional\n            Maximum tempo used for beat tracking [bpm]. If a list is given,\n            each item corresponds to the number of beats per bar at the same\n            position.\n        num_tempi : int or list, optional\n            Number of tempi to model; if set, limit the number of tempi and use\n            a log spacing, otherwise a linear spacing. If a list is given,\n            each item corresponds to the number of beats per bar at the same\n            position.\n        transition_lambda : float or list, optional\n            Lambda for the exponential tempo change distribution (higher values\n            prefer a constant tempo over a tempo change from one beat to the\n            next one). If a list is given, each item corresponds to the number\n            of beats per bar at the same position.\n        observation_lambda : float, optional\n            Split one (down-)beat period into `observation_lambda` parts, the\n            first representing (down-)beat states and the remaining non-beat\n            states.\n        threshold : float, optional\n            Threshold the RNN (down-)beat activations before Viterbi decoding.\n        correct : bool, optional\n            Correct the beats (i.e. align them to the nearest peak of the\n            (down-)beat activation function).\n\n        Returns\n        -------\n        parser_group : argparse argument group\n            DBN downbeat tracking argument parser group\n\n        """"""\n        # pylint: disable=arguments-differ\n        from ..utils import OverrideDefaultListAction\n\n        # add DBN parser group\n        g = parser.add_argument_group(\'dynamic Bayesian Network arguments\')\n        # add a transition parameters\n        g.add_argument(\'--beats_per_bar\', action=OverrideDefaultListAction,\n                       default=beats_per_bar, type=int, sep=\',\',\n                       help=\'number of beats per bar to be modeled (comma \'\n                            \'separated list of bar length in beats) \'\n                            \'[default=%(default)s]\')\n        g.add_argument(\'--min_bpm\', action=OverrideDefaultListAction,\n                       default=min_bpm, type=float, sep=\',\',\n                       help=\'minimum tempo (comma separated list with one \'\n                            \'value per bar length) [bpm, default=%(default)s]\')\n        g.add_argument(\'--max_bpm\', action=OverrideDefaultListAction,\n                       default=max_bpm, type=float, sep=\',\',\n                       help=\'maximum tempo (comma separated list with one \'\n                            \'value per bar length) [bpm, default=%(default)s]\')\n        g.add_argument(\'--num_tempi\', action=OverrideDefaultListAction,\n                       default=num_tempi, type=int, sep=\',\',\n                       help=\'limit the number of tempi; if set, align the \'\n                            \'tempi with log spacings, otherwise linearly \'\n                            \'(comma separated list with one value per bar \'\n                            \'length) [default=%(default)s]\')\n        g.add_argument(\'--transition_lambda\',\n                       action=OverrideDefaultListAction,\n                       default=transition_lambda, type=float, sep=\',\',\n                       help=\'lambda of the tempo transition distribution; \'\n                            \'higher values prefer a constant tempo over a \'\n                            \'tempo change from one beat to the next one (\'\n                            \'comma separated list with one value per bar \'\n                            \'length) [default=%(default)s]\')\n        # observation model stuff\n        g.add_argument(\'--observation_lambda\', action=\'store\', type=float,\n                       default=observation_lambda,\n                       help=\'split one (down-)beat period into N parts, the \'\n                            \'first representing beat states and the remaining \'\n                            \'non-beat states [default=%(default)i]\')\n        g.add_argument(\'-t\', dest=\'threshold\', action=\'store\', type=float,\n                       default=threshold,\n                       help=\'threshold the observations before Viterbi \'\n                            \'decoding [default=%(default).2f]\')\n        # option to correct the beat positions\n        if correct is True:\n            g.add_argument(\'--no_correct\', dest=\'correct\',\n                           action=\'store_false\', default=correct,\n                           help=\'do not correct the (down-)beat positions \'\n                                \'(i.e. do not align them to the nearest peak \'\n                                \'of the (down-)beat activation function)\')\n        elif correct is False:\n            g.add_argument(\'--correct\', dest=\'correct\',\n                           action=\'store_true\', default=correct,\n                           help=\'correct the (down-)beat positions (i.e. \'\n                                \'align them to the nearest peak of the \'\n                                \'(down-)beat  activation function)\')\n        # add output format stuff\n        g = parser.add_argument_group(\'output arguments\')\n        g.add_argument(\'--downbeats\', action=\'store_true\', default=False,\n                       help=\'output only the downbeats\')\n        # return the argument group so it can be modified if needed\n        return g\n\n\nclass PatternTrackingProcessor(Processor):\n    """"""\n    Pattern tracking with a dynamic Bayesian network (DBN) approximated by a\n    Hidden Markov Model (HMM).\n\n    Parameters\n    ----------\n    pattern_files : list\n        List of files with the patterns (including the fitted GMMs and\n        information about the number of beats).\n    min_bpm : list, optional\n        Minimum tempi used for pattern tracking [bpm].\n    max_bpm : list, optional\n        Maximum tempi used for pattern tracking [bpm].\n    num_tempi : int or list, optional\n        Number of tempi to model; if set, limit the number of tempi and use a\n        log spacings, otherwise a linear spacings.\n    transition_lambda : float or list, optional\n        Lambdas for the exponential tempo change distributions (higher values\n        prefer constant tempi from one beat to the next one).\n    fps : float, optional\n        Frames per second.\n\n    Notes\n    -----\n    `min_bpm`, `max_bpm`, `num_tempo_states`, and `transition_lambda` must\n    contain as many items as rhythmic patterns are modeled (i.e. length of\n    `pattern_files`).\n    If a single value is given for `num_tempo_states` and `transition_lambda`,\n    this value is used for all rhythmic patterns.\n\n    Instead of the originally proposed state space and transition model for\n    the DBN [1]_, the more efficient version proposed in [2]_ is used.\n\n    References\n    ----------\n    .. [1] Florian Krebs, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""Rhythmic Pattern Modeling for Beat and Downbeat Tracking in Musical\n           Audio"",\n           Proceedings of the 15th International Society for Music Information\n           Retrieval Conference (ISMIR), 2013.\n    .. [2] Florian Krebs, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""An Efficient State Space Model for Joint Tempo and Meter Tracking"",\n           Proceedings of the 16th International Society for Music Information\n           Retrieval Conference (ISMIR), 2015.\n\n    Examples\n    --------\n    Create a PatternTrackingProcessor from the given pattern files. These\n    pattern files include fitted GMMs for the observation model of the HMM.\n    The returned array represents the positions of the beats and their position\n    inside the bar. The position is given in seconds, thus the expected\n    sampling rate is needed. The position inside the bar follows the natural\n    counting and starts at 1.\n\n    >>> from madmom.models import PATTERNS_BALLROOM\n    >>> proc = PatternTrackingProcessor(PATTERNS_BALLROOM, fps=50)\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.downbeats.PatternTrackingProcessor object at 0x...>\n\n    Call this PatternTrackingProcessor with a multi-band spectrogram to obtain\n    the beat and downbeat positions. The parameters of the spectrogram have to\n    correspond to those used to fit the GMMs.\n\n    >>> from madmom.audio.spectrogram import LogarithmicSpectrogramProcessor, \\\nSpectrogramDifferenceProcessor, MultiBandSpectrogramProcessor\n    >>> from madmom.processors import SequentialProcessor\n    >>> log = LogarithmicSpectrogramProcessor()\n    >>> diff = SpectrogramDifferenceProcessor(positive_diffs=True)\n    >>> mb = MultiBandSpectrogramProcessor(crossover_frequencies=[270])\n    >>> pre_proc = SequentialProcessor([log, diff, mb])\n\n    >>> act = pre_proc(\'tests/data/audio/sample.wav\')\n    >>> proc(act)  # doctest: +ELLIPSIS\n    array([[0.82, 4.  ],\n           [1.78, 1.  ],\n           ...,\n           [3.7 , 3.  ],\n           [4.66, 4.  ]])\n    """"""\n    MIN_BPM = (55, 60)\n    MAX_BPM = (205, 225)\n    NUM_TEMPI = None\n    # Note: if multiple values are given, the individual values represent the\n    #       lambdas for each transition into the beat at this index position\n    TRANSITION_LAMBDA = 100\n\n    def __init__(self, pattern_files, min_bpm=MIN_BPM, max_bpm=MAX_BPM,\n                 num_tempi=NUM_TEMPI, transition_lambda=TRANSITION_LAMBDA,\n                 fps=None, **kwargs):\n        # pylint: disable=unused-argument\n        # pylint: disable=no-name-in-module\n        import pickle\n        min_bpm = np.array(min_bpm, ndmin=1)\n        max_bpm = np.array(max_bpm, ndmin=1)\n        num_tempi = np.array(num_tempi, ndmin=1)\n        transition_lambda = np.array(transition_lambda, ndmin=1)\n        # make sure arguments are given for each pattern (expand if needed)\n        if len(min_bpm) != len(pattern_files):\n            min_bpm = np.repeat(min_bpm, len(pattern_files))\n        if len(max_bpm) != len(pattern_files):\n            max_bpm = np.repeat(max_bpm, len(pattern_files))\n        if len(num_tempi) != len(pattern_files):\n            num_tempi = np.repeat(num_tempi, len(pattern_files))\n        if len(transition_lambda) != len(pattern_files):\n            transition_lambda = np.repeat(transition_lambda,\n                                          len(pattern_files))\n        # check if all lists have the same length\n        if not (len(min_bpm) == len(max_bpm) == len(num_tempi) ==\n                len(transition_lambda) == len(pattern_files)):\n            raise ValueError(\'`min_bpm`, `max_bpm`, `num_tempi` and \'\n                             \'`transition_lambda` must have the same length \'\n                             \'as number of patterns.\')\n        # save some variables\n        self.fps = fps\n        self.num_beats = []\n        # convert timing information to construct a state space\n        min_interval = 60. * self.fps / np.asarray(max_bpm)\n        max_interval = 60. * self.fps / np.asarray(min_bpm)\n        # collect beat/bar state spaces, transition models, and GMMs\n        state_spaces = []\n        transition_models = []\n        gmms = []\n        # check that at least one pattern is given\n        if not pattern_files:\n            raise ValueError(\'at least one rhythmical pattern must be given.\')\n        # load the patterns\n        for p, pattern_file in enumerate(pattern_files):\n            with open(pattern_file, \'rb\') as f:\n                # Python 2 and 3 behave differently\n                try:\n                    # Python 3\n                    pattern = pickle.load(f, encoding=\'latin1\')\n                except TypeError:\n                    # Python 2 doesn\'t have/need the encoding\n                    pattern = pickle.load(f)\n            # get the fitted GMMs and number of beats\n            gmms.append(pattern[\'gmms\'])\n            num_beats = pattern[\'num_beats\']\n            self.num_beats.append(num_beats)\n            # model each rhythmic pattern as a bar\n            state_space = BarStateSpace(num_beats, min_interval[p],\n                                        max_interval[p], num_tempi[p])\n            transition_model = BarTransitionModel(state_space,\n                                                  transition_lambda[p])\n            state_spaces.append(state_space)\n            transition_models.append(transition_model)\n        # create multi pattern state space, transition and observation model\n        self.st = MultiPatternStateSpace(state_spaces)\n        self.tm = MultiPatternTransitionModel(transition_models)\n        self.om = GMMPatternTrackingObservationModel(gmms, self.st)\n        # instantiate a HMM\n        self.hmm = HiddenMarkovModel(self.tm, self.om, None)\n\n    def process(self, features, **kwargs):\n        """"""\n        Detect the (down-)beats given the features.\n\n        Parameters\n        ----------\n        features : numpy array\n            Multi-band spectral features.\n\n        Returns\n        -------\n        beats : numpy array, shape (num_beats, 2)\n            Detected (down-)beat positions [seconds] and beat numbers.\n\n        """"""\n        # pylint: disable=arguments-differ\n        # get the best state path by calling the viterbi algorithm\n        path, _ = self.hmm.viterbi(features)\n        # the positions inside the pattern (0..num_beats)\n        positions = self.st.state_positions[path]\n        # corresponding beats (add 1 for natural counting)\n        beat_numbers = positions.astype(int) + 1\n        # transitions are the points where the beat numbers change\n        # FIXME: we might miss the first or last beat!\n        #        we could calculate the interval towards the beginning/end to\n        #        decide whether to include these points\n        beat_positions = np.nonzero(np.diff(beat_numbers))[0] + 1\n        # return the beat positions (converted to seconds) and beat numbers\n        return np.vstack((beat_positions / float(self.fps),\n                          beat_numbers[beat_positions])).T\n\n    @staticmethod\n    def add_arguments(parser, pattern_files=None, min_bpm=MIN_BPM,\n                      max_bpm=MAX_BPM, num_tempi=NUM_TEMPI,\n                      transition_lambda=TRANSITION_LAMBDA):\n        """"""\n        Add DBN related arguments for pattern tracking to an existing parser\n        object.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        pattern_files : list\n            Load the patterns from these files.\n        min_bpm : list, optional\n            Minimum tempi used for beat tracking [bpm].\n        max_bpm : list, optional\n            Maximum tempi used for beat tracking [bpm].\n        num_tempi : int or list, optional\n            Number of tempi to model; if set, limit the number of states and\n            use log spacings, otherwise a linear spacings.\n        transition_lambda : float or list, optional\n            Lambdas for the exponential tempo change distribution (higher\n            values prefer constant tempi from one beat to the next one).\n\n        Returns\n        -------\n        parser_group : argparse argument group\n            Pattern tracking argument parser group\n\n        Notes\n        -----\n        `pattern_files`, `min_bpm`, `max_bpm`, `num_tempi`, and\n        `transition_lambda` must have the same number of items.\n\n        """"""\n        from ..utils import OverrideDefaultListAction\n        # add GMM options\n        if pattern_files is not None:\n            g = parser.add_argument_group(\'GMM arguments\')\n            g.add_argument(\'--pattern_files\', action=OverrideDefaultListAction,\n                           default=pattern_files,\n                           help=\'load the patterns (with the fitted GMMs) \'\n                                \'from these files (comma separated list)\')\n        # add HMM parser group\n        g = parser.add_argument_group(\'dynamic Bayesian Network arguments\')\n        g.add_argument(\'--min_bpm\', action=OverrideDefaultListAction,\n                       default=min_bpm, type=float, sep=\',\',\n                       help=\'minimum tempo (comma separated list with one \'\n                            \'value per pattern) [bpm, default=%(default)s]\')\n        g.add_argument(\'--max_bpm\', action=OverrideDefaultListAction,\n                       default=max_bpm, type=float, sep=\',\',\n                       help=\'maximum tempo (comma separated list with one \'\n                            \'value per pattern) [bpm, default=%(default)s]\')\n        g.add_argument(\'--num_tempi\', action=OverrideDefaultListAction,\n                       default=num_tempi, type=int, sep=\',\',\n                       help=\'limit the number of tempi; if set, align the \'\n                            \'tempi with log spacings, otherwise linearly \'\n                            \'(comma separated list with one value per pattern)\'\n                            \' [default=%(default)s]\')\n        g.add_argument(\'--transition_lambda\', action=OverrideDefaultListAction,\n                       default=transition_lambda, type=float, sep=\',\',\n                       help=\'lambda of the tempo transition distribution; \'\n                            \'higher values prefer a constant tempo over a \'\n                            \'tempo change from one bar to the next one (comma \'\n                            \'separated list with one value per pattern) \'\n                            \'[default=%(default)s]\')\n        # add output format stuff\n        g = parser.add_argument_group(\'output arguments\')\n        g.add_argument(\'--downbeats\', action=\'store_true\', default=False,\n                       help=\'output only the downbeats\')\n        # return the argument group so it can be modified if needed\n        return g\n\n\n# bar tracking, i.e. track downbeats from signal given beat positions\nclass LoadBeatsProcessor(Processor):\n    """"""\n    Load beat times from file or handle.\n\n    """"""\n    def __init__(self, beats, files=None, beats_suffix=None, **kwargs):\n        # pylint: disable=unused-argument\n        from ..utils import search_files\n        if isinstance(files, list) and beats_suffix is not None:\n            # overwrite beats with the files matching the suffix\n            beats = search_files(files, suffix=beats_suffix)\n            self.mode = \'batch\'\n        else:\n            self.mode = \'single\'\n        self.beats = beats\n        self.beats_suffix = beats_suffix\n\n    def process(self, data=None, **kwargs):\n        """"""\n        Load the beats from file (handle) or read them from STDIN.\n\n        """"""\n        # pylint: disable=unused-argument\n        if self.mode == \'single\':\n            return self.process_single()\n        elif self.mode == \'batch\':\n            return self.process_batch(data)\n        else:\n            raise ValueError(""don\'t know how to obtain the beats"")\n\n    def process_single(self):\n        """"""\n        Load the beats in bulk-mode (i.e. all at once) from the input stream\n        or file.\n\n        Returns\n        -------\n        beats : numpy array\n            Beat positions [seconds].\n\n        """"""\n        # pylint: disable=unused-argument\n        from ..io import load_events\n        return load_events(self.beats)\n\n    def process_batch(self, filename):\n        """"""\n        Load beat times from file.\n\n        First match the given input filename to the beat filenames, then load\n        the beats.\n\n        Parameters\n        ----------\n        filename : str\n            Input file name.\n\n        Returns\n        -------\n        beats : numpy array\n            Beat positions [seconds].\n\n        Notes\n        -----\n        Both the file names to search for the beats as well as the suffix to\n        determine the beat files must be given at instantiation time.\n\n        """"""\n        import os\n        from ..utils import match_file\n\n        if not isinstance(filename, string_types):\n            raise SystemExit(\'Please supply a filename, not %s.\' % filename)\n        # select the matching beat file to a given input file from all files\n        basename, ext = os.path.splitext(os.path.basename(filename))\n        matches = match_file(basename, self.beats, suffix=ext,\n                             match_suffix=self.beats_suffix)\n        if not matches:\n            raise SystemExit(""can\'t find a beat file for %s"" % filename)\n        # load the beats and return them\n        # TODO: Use load_beats function\n        beats = np.loadtxt(matches[0])\n        if beats.ndim == 2:\n            # only use beat times, omit the beat positions inside the bar\n            beats = beats[:, 0]\n        return beats\n\n    @staticmethod\n    def add_arguments(parser, beats=sys.stdin, beats_suffix=\'.beats.txt\'):\n        """"""\n        Add beat loading related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        beats : FileType, optional\n            Where to read the beats from (\'single\' mode).\n        beats_suffix : str, optional\n            Suffix of beat files (\'batch\' mode)\n\n        Returns\n        -------\n        argparse argument group\n            Beat loading argument parser group.\n\n        """"""\n        import argparse\n        # add beat loading options to the existing parser\n        g = parser.add_argument_group(\'beat loading arguments\')\n        g.add_argument(\'--beats\', type=argparse.FileType(\'rb\'), default=beats,\n                       help=\'where/how to read the beat positions from \'\n                            \'[default: single: STDIN]\')\n        g.add_argument(\'--beats_suffix\', type=str, default=beats_suffix,\n                       help=\'file suffix of the beat files [default: \'\n                            \'%(default)s]\')\n        # return the argument group so it can be modified if needed\n        return g\n\n\nclass SyncronizeFeaturesProcessor(Processor):\n    """"""\n    Synchronize features to beats.\n\n    First, divide a beat interval into `beat_subdivision` divisions. Then\n    summarise all features that fall into one subdivision. If no feature value\n    for a subdivision is found, it is set to 0.\n\n    Parameters\n    ----------\n    beat_subdivisions : int\n        Number of subdivisions a beat is divided into.\n    fps : float\n        Frames per second.\n\n    """"""\n    def __init__(self, beat_subdivisions, fps, **kwargs):\n        # pylint: disable=unused-argument\n        self.beat_subdivisions = beat_subdivisions\n        self.fps = fps\n\n    def process(self, data, **kwargs):\n        """"""\n        Synchronize features to beats.\n\n        Average all feature values that fall into a window of beat duration /\n        beat subdivisions, centered on the beat positions or interpolated\n        subdivisions, starting with the first beat.\n\n        Parameters\n        ----------\n        data : tuple (features, beats)\n            Tuple of two numpy arrays, the first containing features to be\n            synchronized and second the beat times.\n\n        Returns\n        -------\n        numpy array (num beats - 1, beat subdivisions, features dim.)\n            Beat synchronous features.\n\n        """"""\n        features, beats = data\n        # no beats, return immediately\n        if beats.size == 0:\n            return np.array([]), np.array([])\n        # beats can be 1D (only beat times) or 2D (times, position inside bar)\n        if beats.ndim > 1:\n            beats = beats[:, 0]\n        # trim beat sequence\n        while (float(len(features)) / self.fps) < beats[-1]:\n            beats = beats[:-1]\n            warnings.warn(\'Beat sequence too long compared to features.\')\n        # number of beats\n        num_beats = len(beats)\n        # feature dimension (make sure features are 2D)\n        features = np.array(features.T, copy=False, ndmin=2).T\n        feat_dim = features.shape[-1]\n        # init a 3D feature aggregation array\n        beat_features = np.zeros(\n            (num_beats - 1, self.beat_subdivisions, feat_dim))\n        # start first beat 20ms before actual annotation\n        beat_start = int(max(0, np.floor((beats[0] - 0.02) * self.fps)))\n        # TODO: speed this up, could probably be done without a loop\n        for i in range(num_beats - 1):\n            # aggregate all feature values that fall into a window of\n            # length = beat_duration / beat_subdivisions, centered on the beat\n            # annotations or interpolated subdivisions\n            beat_duration = beats[i + 1] - beats[i]\n            offset = 0.5 * beat_duration / self.beat_subdivisions\n            # offset should be < 50 ms\n            offset = np.min([offset, 0.05])\n            # last frame of beat\n            beat_end = int(np.floor((beats[i + 1] - offset) * self.fps))\n            # we need to put each feature frame into its corresponding\n            # beat subdivison; linearly align the subdivisions up to the\n            # length of the beat\n            subdiv = np.floor(np.linspace(0, self.beat_subdivisions,\n                                          beat_end - beat_start,\n                                          endpoint=False))\n            beat = features[beat_start:beat_end]\n            # group features by beat subdivisions and aggregate them\n            subdiv_features = [beat[subdiv == div] for div in\n                               range(self.beat_subdivisions)]\n            beat_features[i, :, :] = np.array([np.mean(x, axis=0) for x in\n                                               subdiv_features])\n            # progress to next beat\n            beat_start = beat_end\n        # return beats and beat-synchronous features\n        return beat_features\n\n\nclass RNNBarProcessor(Processor):\n    """"""\n    Retrieve a downbeat activation function from a signal and pre-determined\n    beat positions by obtaining beat-synchronous harmonic and percussive\n    features which are processed with a GRU-RNN.\n\n    Parameters\n    ----------\n    beat_subdivisions : tuple, optional\n        Number of beat subdivisions for the percussive and harmonic feature.\n\n    References\n    ----------\n    .. [1] Florian Krebs, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""Downbeat Tracking Using Beat-Synchronous Features and Recurrent\n           Networks"",\n           Proceedings of the 17th International Society for Music Information\n           Retrieval Conference (ISMIR), 2016.\n\n    Examples\n    --------\n    Create an RNNBarProcessor and pass an audio file and pre-determined (or\n    given) beat positions through the processor. The returned tuple contains\n    the beats positions and the probability to be a downbeat.\n\n    >>> proc = RNNBarProcessor()\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.downbeats.RNNBarProcessor object at 0x...>\n    >>> beats = np.loadtxt(\'tests/data/detections/sample.dbn_beat_tracker.txt\')\n    >>> downbeat_prob = proc((\'tests/data/audio/sample.wav\', beats))\n    >>> np.around(downbeat_prob, decimals=3)\n    ... # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS +NORMALIZE_ARRAYS\n    array([[0.1  , 0.378],\n           [0.45 , 0.19 ],\n           [0.8  , 0.112],\n           [1.12 , 0.328],\n           [1.48 , 0.27 ],\n           [1.8  , 0.181],\n           [2.15 , 0.162],\n           [2.49 ,   nan]])\n\n    """"""\n\n    def __init__(self, beat_subdivisions=(4, 2), fps=100, **kwargs):\n        # pylint: disable=unused-argument\n        from ..audio.signal import SignalProcessor, FramedSignalProcessor\n        from ..audio.stft import ShortTimeFourierTransformProcessor\n        from ..audio.spectrogram import (\n            FilteredSpectrogramProcessor, LogarithmicSpectrogramProcessor,\n            SpectrogramDifferenceProcessor)\n        from ..audio.chroma import CLPChromaProcessor\n        from ..ml.nn import NeuralNetworkEnsemble\n        from ..models import DOWNBEATS_BGRU\n        # define percussive feature\n        sig = SignalProcessor(num_channels=1, sample_rate=44100)\n        frames = FramedSignalProcessor(frame_size=2048, fps=fps)\n        stft = ShortTimeFourierTransformProcessor()  # caching FFT window\n        spec = FilteredSpectrogramProcessor(\n            num_bands=6, fmin=30., fmax=17000., norm_filters=True)\n        log_spec = LogarithmicSpectrogramProcessor(mul=1, add=1)\n        diff = SpectrogramDifferenceProcessor(\n            diff_ratio=0.5, positive_diffs=True)\n        self.perc_feat = SequentialProcessor(\n            (sig, frames, stft, spec, log_spec, diff))\n        # define harmonic feature\n        self.harm_feat = CLPChromaProcessor(\n            fps=fps, fmin=27.5, fmax=4200., compression_factor=100,\n            norm=True, threshold=0.001)\n        # sync features to the beats\n        # TODO: can beat_subdivisions extracted from somewhere?\n        self.perc_beat_sync = SyncronizeFeaturesProcessor(\n            beat_subdivisions[0], fps=fps, **kwargs)\n        self.harm_beat_sync = SyncronizeFeaturesProcessor(\n            beat_subdivisions[1], fps=fps, **kwargs)\n        # NN ensembles to process beat-synchronous features\n        self.perc_nn = NeuralNetworkEnsemble.load(DOWNBEATS_BGRU[0], **kwargs)\n        self.harm_nn = NeuralNetworkEnsemble.load(DOWNBEATS_BGRU[1], **kwargs)\n\n    def process(self, data, **kwargs):\n        """"""\n        Retrieve a downbeat activation function from a signal and beat\n        positions.\n\n        Parameters\n        ----------\n        data : tuple\n            Tuple containing a signal or file (handle) and corresponding beat\n            times [seconds].\n\n        Returns\n        -------\n        numpy array, shape (num_beats, 2)\n            Array containing the beat positions (first column) and the\n            corresponding downbeat activations, i.e. the probability that a\n            beat is a downbeat (second column).\n\n        Notes\n        -----\n        Since features are synchronized to the beats, and the probability of\n        being a downbeat depends on a whole beat duration, only num_beats-1\n        activations can be computed and the last value is filled with \'NaN\'.\n\n        """"""\n        # pylint: disable=unused-argument\n        # split the input data\n        signal, beats = data\n        # process the signal\n        perc = self.perc_feat(signal)\n        harm = self.harm_feat(signal)\n        # sync to the beats\n        perc_synced = self.perc_beat_sync((perc, beats))\n        harm_synced = self.harm_beat_sync((harm, beats))\n        # process with NNs and average the predictions\n        # Note: reshape the NN input to length of synced features\n        perc = self.perc_nn(perc_synced.reshape((len(perc_synced), -1)))\n        harm = self.harm_nn(harm_synced.reshape((len(harm_synced), -1)))\n        # since the synchronized features contain 1 value less than the number\n        # of beats, append an artificial value\n        act = np.mean([perc, harm], axis=0)\n        act = np.append(act, np.ones(1) * np.nan)\n        return np.vstack((beats, act)).T\n\n\nclass DBNBarTrackingProcessor(Processor):\n    """"""\n    Bar tracking with a dynamic Bayesian network (DBN) approximated by a\n    Hidden Markov Model (HMM).\n\n    Parameters\n    ----------\n    beats_per_bar : int or list\n        Number of beats per bar to be modeled. Can be either a single number\n        or a list or array with bar lengths (in beats).\n    observation_weight : int, optional\n        Weight for the downbeat activations.\n    meter_change_prob : float, optional\n        Probability to change meter at bar boundaries.\n\n    Examples\n    --------\n    Create a DBNBarTrackingProcessor. The returned array represents the\n    positions of the beats and their position inside the bar. The position\n    inside the bar follows the natural counting and starts at 1.\n\n    The number of beats per bar which should be modelled must be given, all\n    other parameters (e.g. probability to change the meter at bar boundaries)\n    are optional but must have the same length as `beats_per_bar`.\n\n    >>> proc = DBNBarTrackingProcessor(beats_per_bar=[3, 4])\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.downbeats.DBNBarTrackingProcessor object at 0x...>\n\n    Call this DBNDownBeatTrackingProcessor with beat positions and downbeat\n    activation function returned by RNNBarProcessor to obtain the positions.\n\n    >>> beats = np.loadtxt(\'tests/data/detections/sample.dbn_beat_tracker.txt\')\n    >>> act = RNNBarProcessor()((\'tests/data/audio/sample.wav\', beats))\n    >>> proc(act)  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n    array([[0.1 , 1. ],\n           [0.45, 2. ],\n           [0.8 , 3. ],\n           [1.12, 1. ],\n           [1.48, 2. ],\n           [1.8 , 3. ],\n           [2.15, 1. ],\n           [2.49, 2. ]])\n\n    """"""\n\n    OBSERVATION_WEIGHT = 100\n    METER_CHANGE_PROB = 1e-7\n\n    def __init__(self, beats_per_bar=(3, 4),\n                 observation_weight=OBSERVATION_WEIGHT,\n                 meter_change_prob=METER_CHANGE_PROB, **kwargs):\n        # pylint: disable=unused-argument\n        from madmom.utils import integer_types\n        if isinstance(beats_per_bar, integer_types):\n            beats_per_bar = (beats_per_bar, )\n        self.beats_per_bar = beats_per_bar\n        # state space & transition model for each bar length\n        state_spaces = []\n        transition_models = []\n        for beats in self.beats_per_bar:\n            # Note: tempo and transition_lambda is not relevant\n            st = BarStateSpace(beats, min_interval=1, max_interval=1)\n            tm = BarTransitionModel(st, transition_lambda=1)\n            state_spaces.append(st)\n            transition_models.append(tm)\n        # Note: treat different bar lengths as different patterns and use the\n        #       existing MultiPatternStateSpace and MultiPatternTransitionModel\n        self.st = MultiPatternStateSpace(state_spaces)\n        self.tm = MultiPatternTransitionModel(\n            transition_models, transition_prob=meter_change_prob)\n        # observation model\n        self.om = RNNBeatTrackingObservationModel(self.st, observation_weight)\n        # instantiate a HMM\n        self.hmm = HiddenMarkovModel(self.tm, self.om, None)\n\n    def process(self, data, **kwargs):\n        """"""\n        Detect downbeats from the given beats and activation function with\n        Viterbi decoding.\n\n        Parameters\n        ----------\n        data : numpy array, shape (num_beats, 2)\n            Array containing beat positions (first column) and corresponding\n            downbeat activations (second column).\n\n        Returns\n        -------\n        numpy array, shape (num_beats, 2)\n            Decoded (down-)beat positions and beat numbers.\n\n        Notes\n        -----\n        The position of the last beat is not decoded, but rather extrapolated\n        based on the position and meter of the second to last beat.\n\n        """"""\n        # pylint: disable=unused-argument\n        beats = data[:, 0]\n        activations = data[:, 1]\n        # remove unsynchronised (usually the last) values\n        activations = activations[:-1]\n        # TODO: expand to generic extrapolation of values? e.g.:\n        #       activations = activations[~np.isnan(activations)]\n        # Viterbi decoding\n        path, _ = self.hmm.viterbi(activations)\n        # get the position inside the bar\n        position = self.st.state_positions[path]\n        # the beat numbers are the counters + 1 at the transition points\n        beat_numbers = position.astype(int) + 1\n        # add the last beat (which has no activation function value)\n        meter = self.beats_per_bar[self.st.state_patterns[path[-1]]]\n        last_beat_number = np.mod(beat_numbers[-1], meter) + 1\n        beat_numbers = np.append(beat_numbers, last_beat_number)\n        # return beats and their beat numbers\n        return np.vstack((beats, beat_numbers)).T\n\n    @classmethod\n    def add_arguments(cls, parser, beats_per_bar,\n                      observation_weight=OBSERVATION_WEIGHT,\n                      meter_change_prob=METER_CHANGE_PROB):\n        """"""\n        Add DBN related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        beats_per_bar : int or list, optional\n            Number of beats per bar to be modeled. Can be either a single\n            number or a list with bar lengths (in beats).\n        observation_weight : float, optional\n            Weight for the activations at downbeat times.\n        meter_change_prob : float, optional\n            Probability to change meter at bar boundaries.\n\n        Returns\n        -------\n        parser_group : argparse argument group\n            DBN bar tracking argument parser group\n\n        """"""\n        # pylint: disable=arguments-differ\n        from ..utils import OverrideDefaultListAction\n        # add DBN parser group\n        g = parser.add_argument_group(\'dynamic Bayesian Network arguments\')\n        g.add_argument(\'--beats_per_bar\', action=OverrideDefaultListAction,\n                       default=beats_per_bar, type=int, sep=\',\',\n                       help=\'number of beats per bar to be modeled (comma \'\n                            \'separated list of bar length in beats) \'\n                            \'[default=%(default)s]\')\n        g.add_argument(\'--observation_weight\', action=\'store\', type=float,\n                       default=observation_weight,\n                       help=\'weight for the downbeat activations \'\n                            \'[default=%(default)i]\')\n        g.add_argument(\'--meter_change_prob\', action=\'store\', type=float,\n                       default=meter_change_prob,\n                       help=\'meter change probability [default=%(default).g]\')\n        # add output format stuff\n        parser = parser.add_argument_group(\'output arguments\')\n        parser.add_argument(\'--downbeats\', action=\'store_true\', default=False,\n                            help=\'output only the downbeats\')\n        # return the argument group so it can be modified if needed\n        return parser\n'"
madmom/features/key.py,2,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains key recognition related functionality.\n\n""""""\n\nimport numpy as np\n\nfrom ..processors import SequentialProcessor\n\n\nKEY_LABELS = [\'A major\', \'Bb major\', \'B major\', \'C major\', \'Db major\',\n              \'D major\', \'Eb major\', \'E major\', \'F major\', \'F# major\',\n              \'G major\', \'Ab major\', \'A minor\', \'Bb minor\', \'B minor\',\n              \'C minor\', \'C# minor\', \'D minor\', \'D# minor\', \'E minor\',\n              \'F minor\', \'F# minor\', \'G minor\', \'G# minor\']\n\n\ndef key_prediction_to_label(prediction):\n    """"""\n    Convert key class id to a human-readable key name.\n\n    Parameters\n    ----------\n    prediction : numpy array\n        Array containing the probabilities of each key class.\n\n    Returns\n    -------\n    str\n        Human-readable key name.\n\n    """"""\n    prediction = np.atleast_2d(prediction)\n    return KEY_LABELS[prediction[0].argmax()]\n\n\ndef add_axis(x):\n    return x[np.newaxis, ...]\n\n\nclass CNNKeyRecognitionProcessor(SequentialProcessor):\n    """"""\n    Recognise the global key of a musical piece using a Convolutional Neural\n    Network as described in [1]_.\n\n    Parameters\n    ----------\n    nn_files : list, optional\n        List with trained CNN model files. Per default (\'None\'), an ensemble\n        of networks will be used.\n\n    References\n    ----------\n    .. [1] Filip Korzeniowski and Gerhard Widmer,\n           ""Genre-Agnostic Key Classification with Convolutional Neural\n           Networks"", In Proceedings of the 19th International Society for\n           Music Information Retrieval Conference (ISMIR), Paris, France, 2018.\n\n    Examples\n    --------\n    Create a CNNKeyRecognitionProcessor and pass a file through it.\n    The returned array represents the probability of each key class.\n\n    >>> proc = CNNKeyRecognitionProcessor()\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.key.CNNKeyRecognitionProcessor object at 0x...>\n    >>> proc(\'tests/data/audio/sample.wav\')  # doctest: +NORMALIZE_WHITESPACE\n    array([[0.03426, 0.0331 , 0.02979, 0.04423, 0.04215, 0.0311 , 0.05225,\n            0.04263, 0.04141, 0.02907, 0.03755, 0.09546, 0.0431 , 0.02792,\n            0.02138, 0.05589, 0.03276, 0.02786, 0.02415, 0.04608, 0.05329,\n            0.02804, 0.03868, 0.08786]])\n    """"""\n\n    def __init__(self, nn_files=None, **kwargs):\n        from ..audio.signal import SignalProcessor, FramedSignalProcessor\n        from ..audio.stft import ShortTimeFourierTransformProcessor\n        from ..audio.spectrogram import LogarithmicFilteredSpectrogramProcessor\n        from ..ml.nn import NeuralNetworkEnsemble\n        from ..ml.nn.activations import softmax\n        from ..models import KEY_CNN\n\n        # spectrogram computation\n        sig = SignalProcessor(num_channels=1, sample_rate=44100)\n        frames = FramedSignalProcessor(frame_size=8192, fps=5)\n        stft = ShortTimeFourierTransformProcessor()  # caching FFT window\n        spec = LogarithmicFilteredSpectrogramProcessor(\n            num_bands=24, fmin=65, fmax=2100, unique_filters=True\n        )\n\n        # neural network\n        nn_files = nn_files or KEY_CNN\n        nn = NeuralNetworkEnsemble.load(nn_files)\n\n        # create processing pipeline\n        super(CNNKeyRecognitionProcessor, self).__init__([\n            sig, frames, stft, spec, nn, add_axis, softmax\n        ])\n'"
madmom/features/notes.py,19,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains note transcription related functionality.\n\nNotes are stored as numpy arrays with the following column definition:\n\n\'note_time\' \'MIDI_note\' [\'duration\' [\'MIDI_velocity\']]\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\nfrom .onsets import OnsetPeakPickingProcessor, peak_picking\nfrom ..processors import ParallelProcessor, Processor, SequentialProcessor\nfrom ..utils import combine_events\n\n\n# class for detecting notes with a RNN\nclass RNNPianoNoteProcessor(SequentialProcessor):\n    """"""\n    Processor to get a (piano) note onset activation function from a RNN.\n\n    References\n    ----------\n\n    .. [1] Sebastian B\xc3\xb6ck and Markus Schedl,\n           ""Polyphonic Piano Note Transcription with Recurrent Neural Networks""\n           Proceedings of the 37th International Conference on Acoustics,\n           Speech and Signal Processing (ICASSP), 2012.\n\n    Examples\n    --------\n    Create a RNNPianoNoteProcessor and pass a file through the processor to\n    obtain a note onset activation function (sampled with 100 frames per\n    second).\n\n    >>> proc = RNNPianoNoteProcessor()\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.notes.RNNPianoNoteProcessor object at 0x...>\n    >>> act = proc(\'tests/data/audio/sample.wav\')\n    >>> act.shape\n    (281, 88)\n    >>> act  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    array([[-0.00014,  0.0002 , ..., -0.     ,  0.     ],\n           [ 0.00008,  0.0001 , ...,  0.00006, -0.00001],\n           ...,\n           [-0.00005, -0.00011, ...,  0.00005, -0.00001],\n           [-0.00017,  0.00002, ...,  0.00009, -0.00009]], dtype=float32)\n\n    """"""\n\n    def __init__(self, **kwargs):\n        # pylint: disable=unused-argument\n        from ..audio.signal import SignalProcessor, FramedSignalProcessor\n        from ..audio.stft import ShortTimeFourierTransformProcessor\n        from ..audio.spectrogram import (\n            FilteredSpectrogramProcessor, LogarithmicSpectrogramProcessor,\n            SpectrogramDifferenceProcessor)\n        from ..models import NOTES_BRNN\n        from ..ml.nn import NeuralNetwork\n\n        # define pre-processing chain\n        sig = SignalProcessor(num_channels=1, sample_rate=44100)\n        # process the multi-resolution spec & diff in parallel\n        multi = ParallelProcessor([])\n        for frame_size in [1024, 2048, 4096]:\n            frames = FramedSignalProcessor(frame_size=frame_size, fps=100)\n            stft = ShortTimeFourierTransformProcessor()  # caching FFT window\n            filt = FilteredSpectrogramProcessor(\n                num_bands=12, fmin=30, fmax=17000, norm_filters=True)\n            spec = LogarithmicSpectrogramProcessor(mul=5, add=1)\n            diff = SpectrogramDifferenceProcessor(\n                diff_ratio=0.5, positive_diffs=True, stack_diffs=np.hstack)\n            # process each frame size with spec and diff sequentially\n            multi.append(SequentialProcessor((frames, stft, filt, spec, diff)))\n        # stack the features and processes everything sequentially\n        pre_processor = SequentialProcessor((sig, multi, np.hstack))\n\n        # process the pre-processed signal with a NN\n        nn = NeuralNetwork.load(NOTES_BRNN[0])\n\n        # instantiate a SequentialProcessor\n        super(RNNPianoNoteProcessor, self).__init__((pre_processor, nn))\n\n\nclass NoteOnsetPeakPickingProcessor(OnsetPeakPickingProcessor):\n    """"""\n    This class implements the note onset peak-picking functionality.\n\n    Parameters\n    ----------\n    threshold : float\n        Threshold for peak-picking.\n    smooth : float, optional\n        Smooth the activation function over `smooth` seconds.\n    pre_avg : float, optional\n        Use `pre_avg` seconds past information for moving average.\n    post_avg : float, optional\n        Use `post_avg` seconds future information for moving average.\n    pre_max : float, optional\n        Use `pre_max` seconds past information for moving maximum.\n    post_max : float, optional\n        Use `post_max` seconds future information for moving maximum.\n    combine : float, optional\n        Only report one note per pitch within `combine` seconds.\n    delay : float, optional\n        Report the detected notes `delay` seconds delayed.\n    online : bool, optional\n        Use online peak-picking, i.e. no future information.\n    fps : float, optional\n        Frames per second used for conversion of timings.\n\n    Returns\n    -------\n    notes : numpy array\n        Detected notes [seconds, pitch].\n\n    Notes\n    -----\n    If no moving average is needed (e.g. the activations are independent of\n    the signal\'s level as for neural network activations), `pre_avg` and\n    `post_avg` should be set to 0.\n    For peak picking of local maxima, set `pre_max` >= 1. / `fps` and\n    `post_max` >= 1. / `fps`.\n    For online peak picking, all `post_` parameters are set to 0.\n\n    Examples\n    --------\n    Create a NoteOnsetPeakPickingProcessor. The returned array represents the\n    positions of the onsets in seconds, thus the frame rate has to be given.\n    To obtain piano MIDI note numbers, the pitch offset must be set to 21.\n\n    >>> proc = NoteOnsetPeakPickingProcessor(fps=100, pitch_offset=21)\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.notes.NoteOnsetPeakPickingProcessor object at 0x...>\n\n    Call this NoteOnsetPeakPickingProcessor with the note activations from an\n    RNNPianoNoteProcessor.\n\n    >>> act = RNNPianoNoteProcessor()(\'tests/data/audio/stereo_sample.wav\')\n    >>> proc(act)  # doctest: +ELLIPSIS\n    array([[ 0.14, 72.  ],\n           [ 1.56, 41.  ],\n           [ 3.37, 75.  ]])\n\n    """"""\n    THRESHOLD = 0.5  # binary threshold\n    SMOOTH = 0.\n    PRE_AVG = 0.\n    POST_AVG = 0.\n    PRE_MAX = 0.\n    POST_MAX = 0.\n    COMBINE = 0.03\n    DELAY = 0.\n\n    def __init__(self, threshold=THRESHOLD, smooth=SMOOTH, pre_avg=PRE_AVG,\n                 post_avg=POST_AVG, pre_max=PRE_MAX, post_max=POST_MAX,\n                 combine=COMBINE, delay=DELAY, fps=None, pitch_offset=0,\n                 **kwargs):\n        # pylint: disable=unused-argument\n        super(NoteOnsetPeakPickingProcessor, self).__init__(\n            threshold=threshold, smooth=smooth, pre_avg=pre_avg,\n            post_avg=post_avg, pre_max=pre_max, post_max=post_max,\n            combine=combine, delay=delay, fps=fps)\n        self.pitch_offset = pitch_offset\n\n    def process(self, activations, **kwargs):\n        """"""\n        Detect the notes in the given activation function.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Note activation function.\n\n        Returns\n        -------\n        onsets : numpy array\n            Detected notes [seconds, pitches].\n\n        """"""\n        # convert timing information to frames and set default values\n        # TODO: use at least 1 frame if any of these values are > 0?\n        timings = np.array([self.smooth, self.pre_avg, self.post_avg,\n                            self.pre_max, self.post_max]) * self.fps\n        timings = np.round(timings).astype(int)\n        # detect the peaks (function returns int indices)\n        onsets, pitches = peak_picking(activations, self.threshold, *timings)\n        # if no note onsets are detected, return empty array\n        if not onsets.any():\n            return np.empty((0, 2))\n        # convert onset timing and apply pitch offset\n        onsets = onsets.astype(np.float) / self.fps\n        pitches += self.pitch_offset\n        # shift if necessary\n        if self.delay:\n            onsets += self.delay\n        # combine notes\n        if self.combine > 0:\n            notes = []\n            # iterate over each detected note pitch separately\n            for pitch in np.unique(pitches):\n                # get all onsets for this pitch\n                onsets_ = onsets[pitches == pitch]\n                # combine onsets\n                onsets_ = combine_events(onsets_, self.combine, \'left\')\n                # zip onsets and pitches and add them to list of detections\n                notes.extend(list(zip(onsets_, [pitch] * len(onsets_))))\n        else:\n            # just zip all detected notes\n            notes = list(zip(onsets, pitches))\n        # sort the detections and return as numpy array\n        return np.array(sorted(notes))\n\n\nclass NotePeakPickingProcessor(NoteOnsetPeakPickingProcessor):\n    """"""\n    Deprecated as of version 0.17. Will be removed in version 0.19. Use\n    :class:`NoteOnsetPeakPickingProcessor` instead and set `fps` and\n    `pitch_offset` accordingly.\n\n    """"""\n\n    def __init__(self, fps=100, pitch_offset=21, **kwargs):\n        # pylint: disable=unused-argument\n        super(NotePeakPickingProcessor, self).__init__(\n            fps=fps, pitch_offset=pitch_offset, **kwargs)\n\n\ndef _cnn_pad(data):\n    """"""Pad the data by repeating the first and last frame 5 times.""""""\n    pad_start = np.repeat(data[:1], 5, axis=0)\n    pad_stop = np.repeat(data[-1:], 5, axis=0)\n    return np.concatenate((pad_start, data, pad_stop))\n\n\nclass CNNPianoNoteProcessor(SequentialProcessor):\n    """"""\n    Processor to get piano note activations from a CNN in a multi-task fashion\n    which simultaneously detects onsets and intermediate note features.\n\n    References\n    ----------\n\n    .. [1] Rainer Kelz, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""Deep Polyphonic ADSR Piano Note Transcription"",\n           Proceedings of the 44th International Conference on Acoustics,\n           Speech and Signal Processing (ICASSP), 2019.\n\n    Examples\n    --------\n    Create a CNNPianoNoteProcessor and pass a file through the processor\n    to obtain a note activation function (sampled with 50 frames per second).\n\n    >>> proc = CNNPianoNoteProcessor()\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.notes.CNNPianoNoteProcessor object at 0x...>\n    >>> act = proc(\'tests/data/audio/stereo_sample.wav\')\n\n    The activations are returned as a 3-dimensional array, the first axis\n    representing time, the second the MIDI notes, and the third dimension\n    contains the (sounding) note and onset activations (first and second value,\n    respectively).\n\n    >>> act.shape\n    (208, 88, 3)\n\n    Sounding notes,\n\n    >>> act[..., 0]  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    array([[0., 0., ..., 0., 0.],\n           [0., 0., ..., 0., 0.],\n           ...,\n           [0., 0., ..., 0., 0.],\n           [0., 0., ..., 0., 0.]], dtype=float32)\n\n    and onset activations.\n\n    >>> act[..., 1]  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    array([[0.     , 0.00001, ..., 0.     , 0.     ],\n           [0.     , 0.00002, ..., 0.     , 0.     ],\n           ...,\n           [0.     , 0.     , ..., 0.     , 0.     ],\n           [0.     , 0.     , ..., 0.     , 0.     ]], dtype=float32)\n\n    """"""\n\n    def __init__(self, **kwargs):\n        from ..audio.signal import SignalProcessor, FramedSignalProcessor\n        from ..audio.stft import ShortTimeFourierTransformProcessor\n        from ..audio.spectrogram import (FilteredSpectrogramProcessor,\n                                         LogarithmicSpectrogramProcessor)\n        from ..models import NOTES_CNN\n        from ..ml.nn import NeuralNetworkEnsemble\n        # define pre-processing chain\n        sig = SignalProcessor(num_channels=1, sample_rate=44100)\n        frames = FramedSignalProcessor(frame_size=4096, fps=50)\n        stft = ShortTimeFourierTransformProcessor()  # caching FFT window\n        filt = FilteredSpectrogramProcessor(num_bands=24, fmin=30, fmax=10000)\n        spec = LogarithmicSpectrogramProcessor(add=1)\n        # pre-processes everything sequentially\n        pre_processor = SequentialProcessor(\n            (sig, frames, stft, filt, spec, _cnn_pad))\n        # process the pre-processed signal with a NN\n        nn = NeuralNetworkEnsemble.load(NOTES_CNN)\n        # instantiate a SequentialProcessor\n        super(CNNPianoNoteProcessor, self).__init__((pre_processor, nn))\n\n\nclass ADSRNoteTrackingProcessor(Processor):\n    """"""\n    Track the notes with an HMM based on a model of attack, decay, sustain,\n    release (ADSR) envelopes.\n\n    Parameters\n    ----------\n    onset_prob : float, optional\n        Transition probability to enter an onset state.\n    note_prob : float, optional\n        Transition probability to enter a sounding note state.\n    offset_prob : float, optional\n        Transition probability to enter an offset state.\n    attack_length : float, optional\n        Minimum required attack (i.e. onset activation required) length.\n    decay_length : float, optional\n        Minimum required decay (i.e. note activation required) length.\n    release_length : float, optional\n        Minimum required release (i.e. note activation required) length.\n    complete : bool, optional\n        Require notes to transition all states (i.e. discard incomplete notes).\n    onset_threshold : float, optional\n        Require notes to have an onset activation greater or equal this\n        threshold.\n    note_threshold : float, optional\n        Require notes to have a note activation greater equal this threshold.\n    fps : float, optional\n        Frames per second.\n    pitch_offset : int, optional\n        Pitch offset for the detected notes.\n\n    References\n    ----------\n\n    .. [1] Rainer Kelz, Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""Deep Polyphonic ADSR Piano Note Transcription"",\n           Proceedings of the 44th International Conference on Acoustics,\n           Speech and Signal Processing (ICASSP), 2019.\n\n    Examples\n    --------\n    Create a CNNPianoNoteProcessor and pass a file through the processor\n    to obtain a note activation function (sampled with 50 frames per second).\n\n    >>> proc = CNNPianoNoteProcessor()\n    >>> act = proc(\'tests/data/audio/stereo_sample.wav\')\n\n    Track the notes by means on ADSR note tracking:\n    >>> adsr = ADSRNoteTrackingProcessor()\n    >>> adsr(act)  # doctest: +NORMALIZE_WHITESPACE\n    array([[ 0.12, 72. , 1.44],\n           [ 1.54, 41. , 1.84],\n           [ 2.5 , 77. , 1.  ],\n           [ 2.52, 65. , 0.96],\n           [ 2.54, 60. , 0.82],\n           [ 2.58, 56. , 0.82],\n           [ 3.34, 75. , 0.82],\n           [ 3.42, 43. , 0.74]])\n    """"""\n\n    def __init__(self, onset_prob=0.8, note_prob=0.8, offset_prob=0.5,\n                 attack_length=0.04, decay_length=0.04, release_length=0.02,\n                 complete=True, onset_threshold=0.5, note_threshold=0.5,\n                 fps=50, pitch_offset=21, **kwargs):\n        from .notes_hmm import (ADSRStateSpace, ADSRTransitionModel,\n                                ADSRObservationModel)\n        from ..ml.hmm import HiddenMarkovModel\n        # state space\n        self.st = ADSRStateSpace(attack_length=int(attack_length * fps),\n                                 decay_length=int(decay_length * fps),\n                                 release_length=int(release_length * fps))\n        # transition model\n        self.tm = ADSRTransitionModel(self.st, onset_prob=onset_prob,\n                                      note_prob=note_prob,\n                                      offset_prob=offset_prob)\n        # observation model\n        self.om = ADSRObservationModel(self.st)\n        # instantiate a HMM\n        self.hmm = HiddenMarkovModel(self.tm, self.om, None)\n        # save variables\n        self.complete = complete\n        self.onset_threshold = onset_threshold\n        self.note_threshold = note_threshold\n        self.pitch_offset = pitch_offset\n        self.fps = fps\n\n    def process(self, activations, **kwargs):\n        """"""\n        Detect the notes in the given activation function.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Combined note and onset activation function.\n\n        Returns\n        -------\n        notes : numpy array\n            Detected notes [seconds, pitches, duration].\n\n        """"""\n        notes = []\n        note_path = np.arange(self.st.attack, self.st.release)\n        # process each pitch individually\n        for pitch in range(activations.shape[1]):\n            # decode activations for this pitch with HMM\n            with np.errstate(divide=\'ignore\'):\n                # ignore warnings when taking the log of 0\n                path, _ = self.hmm.viterbi(activations[:, pitch, :])\n            # extract HMM note segments\n            segments = np.logical_and(path > self.st.attack,\n                                      path < self.st.release)\n            # extract start and end positions (transition points)\n            idx = np.nonzero(np.diff(segments.astype(np.int)))[0]\n            # add end if needed\n            if len(idx) % 2 != 0:\n                idx = np.append(idx, [len(activations)])\n            # all sounding frames\n            frames = activations[:, pitch, 0]\n            # all frames with onset activations\n            onsets = activations[:, pitch, 1]\n            # iterate over all segments to decide which to keep\n            for onset, offset in idx.reshape((-1, 2)):\n                # extract note segment\n                segment = path[onset:offset]\n                # discard segment which do not contain the complete note path\n                if self.complete and np.setdiff1d(note_path, segment).any():\n                    continue\n                # discard segments without a real note\n                if frames[onset:offset].max() < self.note_threshold:\n                    continue\n                # discard segments without a real onset\n                if onsets[onset:offset].max() < self.onset_threshold:\n                    continue\n                # append segment as note\n                notes.append([onset / self.fps, pitch + self.pitch_offset,\n                              (offset - onset) / self.fps])\n        # if no note notes are detected, return empty array\n        if len(notes) == 0:\n            return np.empty((0, 3))\n        # sort the notes, convert timing information and return them\n        return np.array(sorted(notes), ndmin=2)\n'"
madmom/features/notes_hmm.py,5,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains HMM state spaces, transition and observation models used\nfor note transcription.\n\nNotes\n-----\nPlease note that (almost) everything within this module is discretised to\ninteger values because of performance reasons.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\nfrom madmom.ml.hmm import TransitionModel, ObservationModel\n\n\nclass ADSRStateSpace(object):\n    """"""\n    Map state numbers to actual states.\n\n    State 0 refers to silence, the ADSR states (attack, decay, sustain,\n    release) are numbered from 1 onwards.\n\n    Parameters\n    ----------\n    attack_length : int, optional\n        Length of the attack phase.\n    decay_length : int, optional\n        Length of the decay phase.\n    release_length : int, optional\n        Length of the release phase.\n\n    Sustain phase has no specific minimum length, since self-transitions from\n    this state are used to model the note length.\n\n    """"""\n\n    def __init__(self, attack_length=1, decay_length=1, release_length=1):\n\n        # define note with states which must be transitioned\n        self.silence = 0\n        self.attack = 1\n        self.decay = self.attack + attack_length\n        self.sustain = self.decay + decay_length\n        self.release = self.sustain + release_length\n\n    @property\n    def num_states(self):\n        return self.release + 1\n\n\nclass ADSRTransitionModel(TransitionModel):\n    """"""\n    Transition model for note transcription with a HMM.\n\n    Parameters\n    ----------\n    state_space : :class:`ADSRStateSpace` instance\n        ADSRStateSpace which maps state numbers to states.\n    onset_prob : float, optional\n        Probability to enter/stay in the attack and decay phase. When entering\n        this phase from a previously sounding note, this probability will be\n        divided by the sum of `onset_prob`, `note_prob`, and `offset_prob`.\n    note_prob : float, optional\n        Probability to enter the sustain phase. Notes can stay in the sustain\n        phase given by this probability divided by the sum of `onset_prob`,\n        `note_prob`, and `offset_prob`.\n    offset_prob : float, optional\n        Probability to enter/stay in the release phase.\n    end_prob : float, optional\n        Probability to go back from release to silence.\n\n    """"""\n\n    def __init__(self, state_space, onset_prob=0.8, note_prob=0.8,\n                 offset_prob=0.2, end_prob=1.):\n        # save attributes\n        self.state_space = state_space\n        # states\n        silence = state_space.silence\n        attack = state_space.attack\n        decay = state_space.decay\n        sustain = state_space.sustain\n        release = state_space.release\n        # transitions = [(from_state, to_state, prob), ...]\n        # onset phase & min_onset_length\n        t = [(silence, silence, 1. - onset_prob),\n             (silence, attack, onset_prob)]\n        for s in range(attack, decay):\n            t.append((s, silence, 1. - onset_prob))\n            t.append((s, s + 1, onset_prob))\n        # transition to note & min_note_duration\n        for s in range(decay, sustain):\n            t.append((s, silence, 1. - note_prob))\n            t.append((s, s + 1, note_prob))\n        # 3 possibilities to continue note\n        prob_sum = onset_prob + note_prob + offset_prob\n        # 1) sustain note (keep sounding)\n        t.append((sustain, sustain, note_prob / prob_sum))\n        # 2) new note\n        t.append((sustain, attack, onset_prob / prob_sum))\n        # 3) release note (end note)\n        t.append((sustain, sustain + 1, offset_prob / prob_sum))\n        # release phase\n        for s in range(sustain + 1, release):\n            t.append((s, sustain, offset_prob))\n            t.append((s, s + 1, 1. - offset_prob))\n        # after releasing a note, go back to silence or start new note\n        t.append((release, silence, end_prob))\n        t.append((release, release, 1. - end_prob))\n        t = np.array(t)\n        # make the transitions sparse\n        t = self.make_sparse(t[:, 1].astype(np.int), t[:, 0].astype(np.int),\n                             t[:, 2])\n        # instantiate a TransitionModel\n        super(ADSRTransitionModel, self).__init__(*t)\n\n\nclass ADSRObservationModel(ObservationModel):\n    """"""\n    Observation model for note transcription tracking with a HMM.\n\n    Parameters\n    ----------\n    state_space : :class:`ADSRStateSpace` instance\n        ADSRStateSpace instance.\n\n    The observed probabilities for note onsets, sounding notes, and offsets are\n    mapped to the states defined in the state space. The observation for\n    \'silence\' is defined as 1 - p(onset), \'onset\' as p(onset), \'decay\' and\n    \'sustain\' as p(note) and \'offset\' as p(offset).\n\n    """"""\n\n    def __init__(self, state_space):\n        # define observation pointers\n        pointers = np.zeros(state_space.num_states, dtype=np.uint32)\n        # map from densities to states\n        pointers[state_space.silence:] = 0\n        pointers[state_space.attack:] = 1\n        pointers[state_space.decay:] = 2\n        # Note: sustain uses the same observations as decay\n        pointers[state_space.release:] = 3\n        # instantiate a ObservationModel with the pointers\n        super(ADSRObservationModel, self).__init__(pointers)\n\n    def log_densities(self, observations):\n        """"""\n        Computes the log densities of the observations.\n\n        Parameters\n        ----------\n        observations : tuple with two numpy arrays\n            Observations (i.e. 3d activations of the CNN).\n\n        Returns\n        -------\n        numpy array\n            Log densities of the observations.\n\n        """"""\n        # observations: notes, onsets, offsets\n        densities = np.ones((len(observations), 4), dtype=np.float)\n        # silence (not onset)\n        densities[:, 0] = 1. - observations[:, 1]\n        # attack: onset\n        densities[:, 1] = observations[:, 1]\n        # decay + sustain: note\n        densities[:, 2] = observations[:, 0]\n        # release: offset\n        densities[:, 3] = observations[:, 2]\n        # return the log densities\n        return np.log(densities)\n'"
madmom/features/onsets.py,58,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains onset detection related functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\nfrom scipy.ndimage import uniform_filter\nfrom scipy.ndimage.filters import maximum_filter, minimum_filter\n\nfrom ..audio.signal import smooth as smooth_signal\nfrom ..processors import (BufferProcessor, OnlineProcessor, ParallelProcessor,\n                          Processor, SequentialProcessor, )\nfrom ..utils import combine_events\n\nEPSILON = np.spacing(1)\n\n\n# onset detection helper functions\ndef wrap_to_pi(phase):\n    """"""\n    Wrap the phase information to the range -\xcf\x80...\xcf\x80.\n\n    Parameters\n    ----------\n    phase : numpy array\n        Phase of the STFT.\n\n    Returns\n    -------\n    wrapped_phase : numpy array\n        Wrapped phase.\n\n    """"""\n    return np.mod(phase + np.pi, 2.0 * np.pi) - np.pi\n\n\ndef correlation_diff(spec, diff_frames=1, pos=False, diff_bins=1):\n    """"""\n    Calculates the difference of the magnitude spectrogram relative to the\n    N-th previous frame shifted in frequency to achieve the highest\n    correlation between these two frames.\n\n    Parameters\n    ----------\n    spec : numpy array\n        Magnitude spectrogram.\n    diff_frames : int, optional\n        Calculate the difference to the `diff_frames`-th previous frame.\n    pos : bool, optional\n        Keep only positive values.\n    diff_bins : int, optional\n        Maximum number of bins shifted for correlation calculation.\n\n    Returns\n    -------\n    correlation_diff : numpy array\n        (Positive) magnitude spectrogram differences.\n\n    Notes\n    -----\n    This function is only because of completeness, it is not intended to be\n    actually used, since it is extremely slow. Please consider the superflux()\n    function, since if performs equally well but much faster.\n\n    """"""\n    # init diff matrix\n    diff_spec = np.zeros_like(spec)\n    if diff_frames < 1:\n        raise ValueError(""number of `diff_frames` must be >= 1"")\n    # calculate the diff\n    frames, bins = diff_spec.shape\n    corr = np.zeros((frames, diff_bins * 2 + 1))\n    for f in range(diff_frames, frames):\n        # correlate the frame with the previous one\n        # resulting size = bins * 2 - 1\n        c = np.correlate(spec[f], spec[f - diff_frames], mode=\'full\')\n        # save the middle part\n        centre = len(c) / 2\n        corr[f] = c[centre - diff_bins: centre + diff_bins + 1]\n        # shift the frame for difference calculation according to the\n        # highest peak in correlation\n        bin_offset = diff_bins - np.argmax(corr[f])\n        bin_start = diff_bins + bin_offset\n        bin_stop = bins - 2 * diff_bins + bin_start\n        diff_spec[f, diff_bins:-diff_bins] = spec[f, diff_bins:-diff_bins] - \\\n            spec[f - diff_frames, bin_start:bin_stop]\n    # keep only positive values\n    if pos:\n        np.maximum(diff_spec, 0, diff_spec)\n    return np.asarray(diff_spec)\n\n\n# onset detection functions pluggable into SpectralOnsetDetection\n# Note: all functions here expect a Spectrogram object as their sole argument\n#       thus it is not enforced that the algorithm does exactly what it is\n#       supposed to do, but new configurations can be built easily\ndef high_frequency_content(spectrogram):\n    """"""\n    High Frequency Content.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        Spectrogram instance.\n\n    Returns\n    -------\n    high_frequency_content : numpy array\n        High frequency content onset detection function.\n\n    References\n    ----------\n    .. [1] Paul Masri,\n           ""Computer Modeling of Sound for Transformation and Synthesis of\n           Musical Signals"",\n           PhD thesis, University of Bristol, 1996.\n\n    """"""\n    # HFC emphasizes high frequencies by weighting the magnitude spectrogram\n    # bins by their respective ""number"" (starting at low frequencies)\n    hfc = spectrogram * np.arange(spectrogram.num_bins)\n    return np.asarray(np.mean(hfc, axis=1))\n\n\ndef spectral_diff(spectrogram, diff_frames=None):\n    """"""\n    Spectral Diff.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        Spectrogram instance.\n    diff_frames : int, optional\n        Number of frames to calculate the diff to.\n\n    Returns\n    -------\n    spectral_diff : numpy array\n        Spectral diff onset detection function.\n\n    References\n    ----------\n    .. [1] Chris Duxbury, Mark Sandler and Matthew Davis,\n           ""A hybrid approach to musical note onset detection"",\n           Proceedings of the 5th International Conference on Digital Audio\n           Effects (DAFx), 2002.\n\n    """"""\n    from madmom.audio.spectrogram import SpectrogramDifference\n    # if the diff of a spectrogram is given, do not calculate the diff twice\n    if not isinstance(spectrogram, SpectrogramDifference):\n        spectrogram = spectrogram.diff(diff_frames=diff_frames,\n                                       positive_diffs=True)\n    # Spectral diff is the sum of all squared positive 1st order differences\n    return np.asarray(np.sum(spectrogram ** 2, axis=1))\n\n\ndef spectral_flux(spectrogram, diff_frames=None):\n    """"""\n    Spectral Flux.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        Spectrogram instance.\n    diff_frames : int, optional\n        Number of frames to calculate the diff to.\n\n    Returns\n    -------\n    spectral_flux : numpy array\n        Spectral flux onset detection function.\n\n    References\n    ----------\n    .. [1] Paul Masri,\n           ""Computer Modeling of Sound for Transformation and Synthesis of\n           Musical Signals"",\n           PhD thesis, University of Bristol, 1996.\n\n    """"""\n    from madmom.audio.spectrogram import SpectrogramDifference\n    # if the diff of a spectrogram is given, do not calculate the diff twice\n    if not isinstance(spectrogram, SpectrogramDifference):\n        spectrogram = spectrogram.diff(diff_frames=diff_frames,\n                                       positive_diffs=True)\n    # Spectral flux is the sum of all positive 1st order differences\n    return np.asarray(np.sum(spectrogram, axis=1))\n\n\ndef superflux(spectrogram, diff_frames=None, diff_max_bins=3):\n    """"""\n    SuperFlux method with a maximum filter vibrato suppression stage.\n\n    Calculates the difference of bin k of the magnitude spectrogram relative to\n    the N-th previous frame with the maximum filtered spectrogram.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        Spectrogram instance.\n    diff_frames : int, optional\n        Number of frames to calculate the diff to.\n    diff_max_bins : int, optional\n        Number of bins used for maximum filter.\n\n    Returns\n    -------\n    superflux : numpy array\n        SuperFlux onset detection function.\n\n    Notes\n    -----\n    This method works only properly, if the spectrogram is filtered with a\n    filterbank of the right frequency spacing. Filter banks with 24 bands per\n    octave (i.e. quarter-tone resolution) usually yield good results. With\n    `max_bins` = 3, the maximum of the bins k-1, k, k+1 of the frame\n    `diff_frames` to the left is used for the calculation of the difference.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""Maximum Filter Vibrato Suppression for Onset Detection"",\n           Proceedings of the 16th International Conference on Digital Audio\n           Effects (DAFx), 2013.\n\n    """"""\n    from madmom.audio.spectrogram import SpectrogramDifference\n    # if the diff of a spectrogram is given, do not calculate the diff twice\n    if not isinstance(spectrogram, SpectrogramDifference):\n        spectrogram = spectrogram.diff(diff_frames=diff_frames,\n                                       diff_max_bins=diff_max_bins,\n                                       positive_diffs=True)\n    # SuperFlux is the sum of all positive 1st order max. filtered differences\n    return np.asarray(np.sum(spectrogram, axis=1))\n\n\n# TODO: should this be its own class so that we can set the filter\n#       sizes in seconds instead of frames?\ndef complex_flux(spectrogram, diff_frames=None, diff_max_bins=3,\n                 temporal_filter=3, temporal_origin=0):\n    """"""\n    ComplexFlux.\n\n    ComplexFlux is based on the SuperFlux, but adds an additional local group\n    delay based tremolo suppression.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        :class:`Spectrogram` instance.\n    diff_frames : int, optional\n        Number of frames to calculate the diff to.\n    diff_max_bins : int, optional\n        Number of bins used for maximum filter.\n    temporal_filter : int, optional\n        Temporal maximum filtering of the local group delay [frames].\n    temporal_origin : int, optional\n        Origin of the temporal maximum filter.\n\n    Returns\n    -------\n    complex_flux : numpy array\n        ComplexFlux onset detection function.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""Local group delay based vibrato and tremolo suppression for onset\n           detection"",\n           Proceedings of the 14th International Society for Music Information\n           Retrieval Conference (ISMIR), 2013.\n\n    """"""\n    # create a mask based on the local group delay information\n    # take only absolute values of the local group delay and normalize them\n    lgd = np.abs(spectrogram.stft.phase().lgd()) / np.pi\n    # maximum filter along the temporal axis\n    # TODO: use HPSS instead of simple temporal filtering\n    if temporal_filter > 0:\n        lgd = maximum_filter(lgd, size=[temporal_filter, 1],\n                             origin=temporal_origin)\n    # lgd = uniform_filter(lgd, size=[1, 3])  # better for percussive onsets\n    # create the weighting mask\n    try:\n        # if the magnitude spectrogram was filtered, use the minimum local\n        # group delay value of each filterbank (expanded by one frequency\n        # bin in both directions) as the mask\n        mask = np.zeros_like(spectrogram)\n        num_bins = lgd.shape[1]\n        for b in range(mask.shape[1]):\n            # determine the corner bins for the mask\n            corner_bins = np.nonzero(spectrogram.filterbank[:, b])[0]\n            # always expand to the next neighbour\n            start_bin = corner_bins[0] - 1\n            stop_bin = corner_bins[-1] + 2\n            # constrain the range\n            if start_bin < 0:\n                start_bin = 0\n            if stop_bin > num_bins:\n                stop_bin = num_bins\n            # set mask\n            mask[:, b] = np.amin(lgd[:, start_bin: stop_bin], axis=1)\n    except AttributeError:\n        # if the spectrogram is not filtered, use a simple minimum filter\n        # covering only the current bin and its neighbours\n        mask = minimum_filter(lgd, size=[1, 3])\n    # sum all positive 1st order max. filtered and weighted differences\n    diff = spectrogram.diff(diff_frames=diff_frames,\n                            diff_max_bins=diff_max_bins,\n                            positive_diffs=True)\n    return np.asarray(np.sum(diff * mask, axis=1))\n\n\ndef modified_kullback_leibler(spectrogram, diff_frames=1, epsilon=EPSILON):\n    """"""\n    Modified Kullback-Leibler.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        :class:`Spectrogram` instance.\n    diff_frames : int, optional\n        Number of frames to calculate the diff to.\n    epsilon : float, optional\n        Add `epsilon` to the `spectrogram` avoid division by 0.\n\n    Returns\n    -------\n    modified_kullback_leibler : numpy array\n         MKL onset detection function.\n\n    Notes\n    -----\n    The implementation presented in [1]_ is used instead of the original work\n    presented in [2]_.\n\n    References\n    ----------\n    .. [1] Paul Brossier,\n           ""Automatic Annotation of Musical Audio for Interactive\n           Applications"",\n           PhD thesis, Queen Mary University of London, 2006.\n    .. [2] Stephen Hainsworth and Malcolm Macleod,\n           ""Onset Detection in Musical Audio Signals"",\n           Proceedings of the International Computer Music Conference (ICMC),\n           2003.\n\n    """"""\n    if epsilon <= 0:\n        raise ValueError(""a positive value must be added before division"")\n    mkl = np.zeros_like(spectrogram)\n    mkl[diff_frames:] = (spectrogram[diff_frames:] /\n                         (spectrogram[:-diff_frames] + epsilon))\n    # note: the original MKL uses sum instead of mean,\n    # but the range of mean is much more suitable\n    return np.asarray(np.mean(np.log(1 + mkl), axis=1))\n\n\ndef _phase_deviation(phase):\n    """"""\n    Helper function used by phase_deviation() & weighted_phase_deviation().\n\n    Parameters\n    ----------\n    phase : numpy array\n        Phase of the STFT.\n\n    Returns\n    -------\n    numpy array\n        Phase deviation.\n\n    """"""\n    pd = np.zeros_like(phase)\n    # instantaneous frequency is given by the first difference\n    # \xcf\x88\xe2\x80\xb2(n, k) = \xcf\x88(n, k) \xe2\x88\x92 \xcf\x88(n \xe2\x88\x92 1, k)\n    # change in instantaneous frequency is given by the second order difference\n    # \xcf\x88\xe2\x80\xb2\xe2\x80\xb2(n, k) = \xcf\x88\xe2\x80\xb2(n, k) \xe2\x88\x92 \xcf\x88\xe2\x80\xb2(n \xe2\x88\x92 1, k)\n    pd[2:] = phase[2:] - 2 * phase[1:-1] + phase[:-2]\n    # map to the range -pi..pi\n    return np.asarray(wrap_to_pi(pd))\n\n\ndef phase_deviation(spectrogram):\n    """"""\n    Phase Deviation.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        :class:`Spectrogram` instance.\n\n    Returns\n    -------\n    phase_deviation : numpy array\n        Phase deviation onset detection function.\n\n    References\n    ----------\n    .. [1] Juan Pablo Bello, Chris Duxbury, Matthew Davies and Mark Sandler,\n           ""On the use of phase and energy for musical onset detection in the\n           complex domain"",\n           IEEE Signal Processing Letters, Volume 11, Number 6, 2004.\n\n    """"""\n    # absolute phase changes in instantaneous frequency\n    pd = np.abs(_phase_deviation(spectrogram.stft.phase()))\n    return np.asarray(np.mean(pd, axis=1))\n\n\ndef weighted_phase_deviation(spectrogram):\n    """"""\n    Weighted Phase Deviation.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        :class:`Spectrogram` instance.\n\n    Returns\n    -------\n    weighted_phase_deviation : numpy array\n        Weighted phase deviation onset detection function.\n\n    References\n    ----------\n    .. [1] Simon Dixon,\n           ""Onset Detection Revisited"",\n           Proceedings of the 9th International Conference on Digital Audio\n           Effects (DAFx), 2006.\n\n    """"""\n    # cache phase\n    phase = spectrogram.stft.phase()\n    # make sure the spectrogram is not filtered before\n    if np.shape(phase) != np.shape(spectrogram):\n        raise ValueError(\'spectrogram and phase must be of same shape\')\n    # weighted_phase_deviation = spectrogram * phase_deviation\n    wpd = np.abs(_phase_deviation(phase) * spectrogram)\n    return np.asarray(np.mean(wpd, axis=1))\n\n\ndef normalized_weighted_phase_deviation(spectrogram, epsilon=EPSILON):\n    """"""\n    Normalized Weighted Phase Deviation.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        :class:`Spectrogram` instance.\n    epsilon : float, optional\n        Add `epsilon` to the `spectrogram` avoid division by 0.\n\n    Returns\n    -------\n    normalized_weighted_phase_deviation : numpy array\n        Normalized weighted phase deviation onset detection function.\n\n    References\n    ----------\n    .. [1] Simon Dixon,\n           ""Onset Detection Revisited"",\n           Proceedings of the 9th International Conference on Digital Audio\n           Effects (DAFx), 2006.\n\n    """"""\n    if epsilon <= 0:\n        raise ValueError(""a positive value must be added before division"")\n    # normalize WPD by the sum of the spectrogram\n    # (add a small epsilon so that we don\'t divide by 0)\n    norm = np.add(np.mean(spectrogram, axis=1), epsilon)\n    return np.asarray(weighted_phase_deviation(spectrogram) / norm)\n\n\ndef _complex_domain(spectrogram):\n    """"""\n    Helper method used by complex_domain() & rectified_complex_domain().\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        :class:`Spectrogram` instance.\n\n    Returns\n    -------\n    numpy array\n        Complex domain onset detection function.\n\n    Notes\n    -----\n    We use the simple implementation presented in [1]_.\n\n    References\n    ----------\n    .. [1] Simon Dixon,\n           ""Onset Detection Revisited"",\n           Proceedings of the 9th International Conference on Digital Audio\n           Effects (DAFx), 2006.\n\n    """"""\n    # cache phase\n    phase = spectrogram.stft.phase()\n    # make sure the spectrogram is not filtered before\n    if np.shape(phase) != np.shape(spectrogram):\n        raise ValueError(\'spectrogram and phase must be of same shape\')\n    # expected spectrogram\n    cd_target = np.zeros_like(phase)\n    # assume constant phase change\n    cd_target[1:] = 2 * phase[1:] - phase[:-1]\n    # add magnitude\n    cd_target = spectrogram * np.exp(1j * cd_target)\n    # create complex spectrogram\n    cd = spectrogram * np.exp(1j * phase)\n    # subtract the target values\n    cd[1:] -= cd_target[:-1]\n    return np.asarray(cd)\n\n\ndef complex_domain(spectrogram):\n    """"""\n    Complex Domain.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        :class:`Spectrogram` instance.\n\n    Returns\n    -------\n    complex_domain : numpy array\n        Complex domain onset detection function.\n\n    References\n    ----------\n    .. [1] Juan Pablo Bello, Chris Duxbury, Matthew Davies and Mark Sandler,\n           ""On the use of phase and energy for musical onset detection in the\n           complex domain"",\n           IEEE Signal Processing Letters, Volume 11, Number 6, 2004.\n\n    """"""\n    # take the sum of the absolute changes\n    return np.asarray(np.sum(np.abs(_complex_domain(spectrogram)), axis=1))\n\n\ndef rectified_complex_domain(spectrogram, diff_frames=None):\n    """"""\n    Rectified Complex Domain.\n\n    Parameters\n    ----------\n    spectrogram : :class:`Spectrogram` instance\n        :class:`Spectrogram` instance.\n    diff_frames : int, optional\n        Number of frames to calculate the diff to.\n\n    Returns\n    -------\n    rectified_complex_domain : numpy array\n        Rectified complex domain onset detection function.\n\n    References\n    ----------\n    .. [1] Simon Dixon,\n           ""Onset Detection Revisited"",\n           Proceedings of the 9th International Conference on Digital Audio\n           Effects (DAFx), 2006.\n\n    """"""\n    # rectified complex domain\n    rcd = _complex_domain(spectrogram)\n    # only keep values where the magnitude rises\n    pos_diff = spectrogram.diff(diff_frames=diff_frames, positive_diffs=True)\n    rcd *= pos_diff.astype(bool)\n    # take the sum of the absolute changes\n    return np.asarray(np.sum(np.abs(rcd), axis=1))\n\n\nclass SpectralOnsetProcessor(SequentialProcessor):\n    """"""\n    The SpectralOnsetProcessor class implements most of the common onset\n    detection functions based on the magnitude or phase information of a\n    spectrogram.\n\n    Parameters\n    ----------\n    onset_method : str, optional\n        Onset detection function. See `METHODS` for possible values.\n    kwargs : dict, optional\n        Keyword arguments passed to the pre-processing chain to obtain a\n        spectral representation of the signal.\n\n    Notes\n    -----\n    If the spectrogram should be filtered, the `filterbank` parameter must\n    contain a valid Filterbank, if it should be scaled logarithmically, `log`\n    must be set accordingly.\n\n    References\n    ----------\n    .. [1] Paul Masri,\n           ""Computer Modeling of Sound for Transformation and Synthesis of\n           Musical Signals"",\n           PhD thesis, University of Bristol, 1996.\n    .. [2] Sebastian B\xc3\xb6ck and Gerhard Widmer,\n           ""Maximum Filter Vibrato Suppression for Onset Detection"",\n           Proceedings of the 16th International Conference on Digital Audio\n           Effects (DAFx), 2013.\n\n    Examples\n    --------\n\n    Create a SpectralOnsetProcessor and pass a file through the processor to\n    obtain an onset detection function. Per default the spectral flux [1]_ is\n    computed on a simple Spectrogram.\n\n    >>> sodf = SpectralOnsetProcessor()\n    >>> sodf  # doctest: +ELLIPSIS\n    <madmom.features.onsets.SpectralOnsetProcessor object at 0x...>\n    >>> sodf.processors[-1]  # doctest: +ELLIPSIS\n    <function spectral_flux at 0x...>\n    >>> sodf(\'tests/data/audio/sample.wav\')\n    ... # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    array([ 0. , 100.90121, ..., 26.30577, 20.94439], dtype=float32)\n\n    The parameters passed to the signal pre-processing chain can be set when\n    creating the SpectralOnsetProcessor. E.g. to obtain the SuperFlux [2]_\n    onset detection function set these parameters:\n\n    >>> from madmom.audio.filters import LogarithmicFilterbank\n    >>> sodf = SpectralOnsetProcessor(onset_method=\'superflux\', fps=200,\n    ...                               filterbank=LogarithmicFilterbank,\n    ...                               num_bands=24, log=np.log10)\n    >>> sodf(\'tests/data/audio/sample.wav\')\n    ... # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    array([ 0. , 0. , 2.0868 , 1.02404, ..., 0.29888, 0.12122], dtype=float32)\n\n    """"""\n\n    METHODS = [\'superflux\', \'complex_flux\', \'high_frequency_content\',\n               \'spectral_diff\', \'spectral_flux\', \'modified_kullback_leibler\',\n               \'phase_deviation\', \'weighted_phase_deviation\',\n               \'normalized_weighted_phase_deviation\', \'complex_domain\',\n               \'rectified_complex_domain\']\n\n    def __init__(self, onset_method=\'spectral_flux\', **kwargs):\n        import inspect\n        from ..audio.signal import SignalProcessor, FramedSignalProcessor\n        from ..audio.stft import ShortTimeFourierTransformProcessor\n        from ..audio.spectrogram import (SpectrogramProcessor,\n                                         FilteredSpectrogramProcessor,\n                                         LogarithmicSpectrogramProcessor)\n        # for certain methods we need to circular shift the signal before STFT\n        if any(odf in onset_method for odf in (\'phase\', \'complex\')):\n            kwargs[\'circular_shift\'] = True\n        # always use mono signals\n        kwargs[\'num_channels\'] = 1\n        # define processing chain\n        sig = SignalProcessor(**kwargs)\n        frames = FramedSignalProcessor(**kwargs)\n        stft = ShortTimeFourierTransformProcessor(**kwargs)\n        spec = SpectrogramProcessor(**kwargs)\n        processors = [sig, frames, stft, spec]\n        # filtering needed?\n        if \'filterbank\' in kwargs.keys() and kwargs[\'filterbank\'] is not None:\n            processors.append(FilteredSpectrogramProcessor(**kwargs))\n        # scaling needed?\n        if \'log\' in kwargs.keys() and kwargs[\'log\'] is not None:\n            processors.append(LogarithmicSpectrogramProcessor(**kwargs))\n        # odf function\n        if not inspect.isfunction(onset_method):\n            try:\n                onset_method = globals()[onset_method]\n            except KeyError:\n                raise ValueError(\'%s not a valid onset detection function, \'\n                                 \'choose %s.\' % (onset_method, self.METHODS))\n            processors.append(onset_method)\n        # instantiate a SequentialProcessor\n        super(SpectralOnsetProcessor, self).__init__(processors)\n\n    @classmethod\n    def add_arguments(cls, parser, onset_method=None):\n        """"""\n        Add spectral onset detection arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        onset_method : str, optional\n            Default onset detection method.\n\n        Returns\n        -------\n        parser_group : argparse argument group\n            Spectral onset detection argument parser group.\n\n        """"""\n        # add onset detection method arguments to the existing parser\n        g = parser.add_argument_group(\'spectral onset detection arguments\')\n        if onset_method is not None:\n            g.add_argument(\'--odf\', dest=\'onset_method\',\n                           default=onset_method, choices=cls.METHODS,\n                           help=\'use this onset detection function \'\n                                \'[default=%(default)s]\')\n        # return the argument group so it can be modified if needed\n        return g\n\n\n# classes for detecting onsets with NNs\nclass RNNOnsetProcessor(SequentialProcessor):\n    """"""\n    Processor to get a onset activation function from multiple RNNs.\n\n    Parameters\n    ----------\n    online : bool, optional\n        Choose networks suitable for online onset detection, i.e. use\n        unidirectional RNNs.\n\n    Notes\n    -----\n    This class uses either uni- or bi-directional RNNs. Contrary to [1], it\n    uses simple tanh units as in [2]. Also the input representations changed\n    to use logarithmically filtered and scaled spectrograms.\n\n    References\n    ----------\n    .. [1] ""Universal Onset Detection with bidirectional Long Short-Term Memory\n           Neural Networks""\n           Florian Eyben, Sebastian B\xc3\xb6ck, Bj\xc3\xb6rn Schuller and Alex Graves.\n           Proceedings of the 11th International Society for Music Information\n           Retrieval Conference (ISMIR), 2010.\n    .. [2] ""Online Real-time Onset Detection with Recurrent Neural Networks""\n           Sebastian B\xc3\xb6ck, Andreas Arzt, Florian Krebs and Markus Schedl.\n           Proceedings of the 15th International Conference on Digital Audio\n           Effects (DAFx), 2012.\n\n    Examples\n    --------\n    Create a RNNOnsetProcessor and pass a file through the processor to obtain\n    an onset detection function (sampled with 100 frames per second).\n\n    >>> proc = RNNOnsetProcessor()\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.onsets.RNNOnsetProcessor object at 0x...>\n    >>> proc(\'tests/data/audio/sample.wav\') # doctest: +ELLIPSIS\n    array([0.08313, 0.0024 , ... 0.00527], dtype=float32)\n\n    """"""\n\n    def __init__(self, **kwargs):\n        # pylint: disable=unused-argument\n        from ..audio.signal import SignalProcessor, FramedSignalProcessor\n        from ..audio.stft import ShortTimeFourierTransformProcessor\n        from ..audio.spectrogram import (\n            FilteredSpectrogramProcessor, LogarithmicSpectrogramProcessor,\n            SpectrogramDifferenceProcessor)\n        from ..models import ONSETS_RNN, ONSETS_BRNN\n        from ..ml.nn import NeuralNetworkEnsemble\n\n        # choose the appropriate models and set frame sizes accordingly\n        if kwargs.get(\'online\'):\n            nn_files = ONSETS_RNN\n            frame_sizes = [512, 1024, 2048]\n        else:\n            nn_files = ONSETS_BRNN\n            frame_sizes = [1024, 2048, 4096]\n\n        # define pre-processing chain\n        sig = SignalProcessor(num_channels=1, sample_rate=44100)\n        # process the multi-resolution spec & diff in parallel\n        multi = ParallelProcessor([])\n        for frame_size in frame_sizes:\n            # pass **kwargs in order to be able to process in online mode\n            frames = FramedSignalProcessor(frame_size=frame_size, **kwargs)\n            stft = ShortTimeFourierTransformProcessor()  # caching FFT window\n            filt = FilteredSpectrogramProcessor(\n                num_bands=6, fmin=30, fmax=17000, norm_filters=True)\n            spec = LogarithmicSpectrogramProcessor(mul=5, add=1)\n            diff = SpectrogramDifferenceProcessor(\n                diff_ratio=0.25, positive_diffs=True, stack_diffs=np.hstack)\n            # process each frame size with spec and diff sequentially\n            multi.append(SequentialProcessor((frames, stft, filt, spec, diff)))\n        # stack the features and processes everything sequentially\n        pre_processor = SequentialProcessor((sig, multi, np.hstack))\n\n        # process the pre-processed signal with a NN ensemble\n        nn = NeuralNetworkEnsemble.load(nn_files, **kwargs)\n\n        # instantiate a SequentialProcessor\n        super(RNNOnsetProcessor, self).__init__((pre_processor, nn))\n\n\n# must be a top-level function to be pickle-able\ndef _cnn_onset_processor_pad(data):\n    """"""Pad the data by repeating the first and last frame 7 times.""""""\n    pad_start = np.repeat(data[:1], 7, axis=0)\n    pad_stop = np.repeat(data[-1:], 7, axis=0)\n    return np.concatenate((pad_start, data, pad_stop))\n\n\nclass CNNOnsetProcessor(SequentialProcessor):\n    """"""\n    Processor to get a onset activation function from a CNN.\n\n    References\n    ----------\n    .. [1] ""Musical Onset Detection with Convolutional Neural Networks""\n           Jan Schl\xc3\xbcter and Sebastian B\xc3\xb6ck.\n           Proceedings of the 6th International Workshop on Machine Learning\n           and Music, 2013.\n\n    Notes\n    -----\n    The implementation follows as closely as possible the original one, but\n    part of the signal pre-processing differs in minor aspects, so results can\n    differ slightly, too.\n\n    Examples\n    --------\n    Create a CNNOnsetProcessor and pass a file through the processor to obtain\n    an onset detection function (sampled with 100 frames per second).\n\n    >>> proc = CNNOnsetProcessor()\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.onsets.CNNOnsetProcessor object at 0x...>\n    >>> proc(\'tests/data/audio/sample.wav\')  # doctest: +ELLIPSIS\n    array([0.05369, 0.04205, ... 0.00014], dtype=float32)\n\n    """"""\n\n    def __init__(self, **kwargs):\n        # pylint: disable=unused-argument\n        from ..audio.signal import SignalProcessor, FramedSignalProcessor\n        from ..audio.stft import ShortTimeFourierTransformProcessor\n        from ..audio.filters import MelFilterbank\n        from ..audio.spectrogram import (FilteredSpectrogramProcessor,\n                                         LogarithmicSpectrogramProcessor)\n        from ..models import ONSETS_CNN\n        from ..ml.nn import NeuralNetwork\n\n        # define pre-processing chain\n        sig = SignalProcessor(num_channels=1, sample_rate=44100)\n        # process the multi-resolution spec in parallel\n        multi = ParallelProcessor([])\n        for frame_size in [2048, 1024, 4096]:\n            frames = FramedSignalProcessor(frame_size=frame_size, fps=100)\n            stft = ShortTimeFourierTransformProcessor()  # caching FFT window\n            filt = FilteredSpectrogramProcessor(\n                filterbank=MelFilterbank, num_bands=80, fmin=27.5, fmax=16000,\n                norm_filters=True, unique_filters=False)\n            spec = LogarithmicSpectrogramProcessor(log=np.log, add=EPSILON)\n            # process each frame size with spec and diff sequentially\n            multi.append(SequentialProcessor((frames, stft, filt, spec)))\n        # stack the features (in depth) and pad at beginning and end\n        stack = np.dstack\n        pad = _cnn_onset_processor_pad\n        # pre-processes everything sequentially\n        pre_processor = SequentialProcessor((sig, multi, stack, pad))\n\n        # process the pre-processed signal with a NN ensemble\n        nn = NeuralNetwork.load(ONSETS_CNN[0])\n\n        # instantiate a SequentialProcessor\n        super(CNNOnsetProcessor, self).__init__((pre_processor, nn))\n\n\n# universal peak-picking method\ndef peak_picking(activations, threshold, smooth=None, pre_avg=0, post_avg=0,\n                 pre_max=1, post_max=1):\n    """"""\n    Perform thresholding and peak-picking on the given activation function.\n\n    Parameters\n    ----------\n    activations : numpy array\n        Activation function.\n    threshold : float\n        Threshold for peak-picking\n    smooth : int or numpy array, optional\n        Smooth the activation function with the kernel (size).\n    pre_avg : int, optional\n        Use `pre_avg` frames past information for moving average.\n    post_avg : int, optional\n        Use `post_avg` frames future information for moving average.\n    pre_max : int, optional\n        Use `pre_max` frames past information for moving maximum.\n    post_max : int, optional\n        Use `post_max` frames future information for moving maximum.\n\n    Returns\n    -------\n    peak_idx : numpy array\n        Indices of the detected peaks.\n\n    See Also\n    --------\n    :func:`smooth`\n\n    Notes\n    -----\n    If no moving average is needed (e.g. the activations are independent of\n    the signal\'s level as for neural network activations), set `pre_avg` and\n    `post_avg` to 0.\n    For peak picking of local maxima, set `pre_max` and  `post_max` to 1.\n    For online peak picking, set all `post_` parameters to 0.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck, Florian Krebs and Markus Schedl,\n           ""Evaluating the Online Capabilities of Onset Detection Methods"",\n           Proceedings of the 13th International Society for Music Information\n           Retrieval Conference (ISMIR), 2012.\n\n    """"""\n    # smooth activations\n    activations = smooth_signal(activations, smooth)\n    # compute a moving average\n    avg_length = pre_avg + post_avg + 1\n    if avg_length > 1:\n        # TODO: make the averaging function exchangeable (mean/median/etc.)\n        avg_origin = int(np.floor((pre_avg - post_avg) / 2))\n        if activations.ndim == 1:\n            filter_size = avg_length\n        elif activations.ndim == 2:\n            filter_size = [avg_length, 1]\n        else:\n            raise ValueError(\'`activations` must be either 1D or 2D\')\n        mov_avg = uniform_filter(activations, filter_size, mode=\'constant\',\n                                 origin=avg_origin)\n    else:\n        # do not use a moving average\n        mov_avg = 0\n    # detections are those activations above the moving average + the threshold\n    detections = activations * (activations >= mov_avg + threshold)\n    # peak-picking\n    max_length = pre_max + post_max + 1\n    if max_length > 1:\n        # compute a moving maximum\n        max_origin = int(np.floor((pre_max - post_max) / 2))\n        if activations.ndim == 1:\n            filter_size = max_length\n        elif activations.ndim == 2:\n            filter_size = [max_length, 1]\n        else:\n            raise ValueError(\'`activations` must be either 1D or 2D\')\n        mov_max = maximum_filter(detections, filter_size, mode=\'constant\',\n                                 origin=max_origin)\n        # detections are peak positions\n        detections *= (detections == mov_max)\n    # return indices\n    if activations.ndim == 1:\n        return np.nonzero(detections)[0]\n    elif activations.ndim == 2:\n        return np.nonzero(detections)\n    else:\n        raise ValueError(\'`activations` must be either 1D or 2D\')\n\n\nclass OnsetPeakPickingProcessor(OnlineProcessor):\n    """"""\n    This class implements the onset peak-picking functionality.\n    It transparently converts the chosen values from seconds to frames.\n\n    Parameters\n    ----------\n    threshold : float\n        Threshold for peak-picking.\n    smooth : float, optional\n        Smooth the activation function over `smooth` seconds.\n    pre_avg : float, optional\n        Use `pre_avg` seconds past information for moving average.\n    post_avg : float, optional\n        Use `post_avg` seconds future information for moving average.\n    pre_max : float, optional\n        Use `pre_max` seconds past information for moving maximum.\n    post_max : float, optional\n        Use `post_max` seconds future information for moving maximum.\n    combine : float, optional\n        Only report one onset within `combine` seconds.\n    delay : float, optional\n        Report the detected onsets `delay` seconds delayed.\n    online : bool, optional\n        Use online peak-picking, i.e. no future information.\n    fps : float, optional\n        Frames per second used for conversion of timings.\n\n    Returns\n    -------\n    onsets : numpy array\n        Detected onsets [seconds].\n\n    Notes\n    -----\n    If no moving average is needed (e.g. the activations are independent of\n    the signal\'s level as for neural network activations), `pre_avg` and\n    `post_avg` should be set to 0.\n    For peak picking of local maxima, set `pre_max` >= 1. / `fps` and\n    `post_max` >= 1. / `fps`.\n    For online peak picking, all `post_` parameters are set to 0.\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck, Florian Krebs and Markus Schedl,\n           ""Evaluating the Online Capabilities of Onset Detection Methods"",\n           Proceedings of the 13th International Society for Music Information\n           Retrieval Conference (ISMIR), 2012.\n\n    Examples\n    --------\n    Create a PeakPickingProcessor. The returned array represents the positions\n    of the onsets in seconds, thus the expected sampling rate has to be given.\n\n    >>> proc = OnsetPeakPickingProcessor(fps=100)\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.onsets.OnsetPeakPickingProcessor object at 0x...>\n\n    Call this OnsetPeakPickingProcessor with the onset activation function from\n    an RNNOnsetProcessor to obtain the onset positions.\n\n    >>> act = RNNOnsetProcessor()(\'tests/data/audio/sample.wav\')\n    >>> proc(act)  # doctest: +ELLIPSIS\n    array([0.09, 0.29, 0.45, ..., 2.34, 2.49, 2.67])\n\n    """"""\n    FPS = 100\n    THRESHOLD = 0.5  # binary threshold\n    SMOOTH = 0.\n    PRE_AVG = 0.\n    POST_AVG = 0.\n    PRE_MAX = 0.\n    POST_MAX = 0.\n    COMBINE = 0.03\n    DELAY = 0.\n    ONLINE = False\n\n    def __init__(self, threshold=THRESHOLD, smooth=SMOOTH, pre_avg=PRE_AVG,\n                 post_avg=POST_AVG, pre_max=PRE_MAX, post_max=POST_MAX,\n                 combine=COMBINE, delay=DELAY, online=ONLINE, fps=FPS,\n                 **kwargs):\n        # pylint: disable=unused-argument\n        # instantiate OnlineProcessor\n        super(OnsetPeakPickingProcessor, self).__init__(online=online)\n        if self.online:\n            # set some parameters to 0 (i.e. no future information available)\n            smooth = 0\n            post_avg = 0\n            post_max = 0\n            # init buffer\n            self.buffer = None\n            self.counter = 0\n            self.last_onset = None\n        # save parameters\n        self.threshold = threshold\n        self.smooth = smooth\n        self.pre_avg = pre_avg\n        self.post_avg = post_avg\n        self.pre_max = pre_max\n        self.post_max = post_max\n        self.combine = combine\n        self.delay = delay\n        self.fps = fps\n\n    def reset(self):\n        """"""Reset OnsetPeakPickingProcessor.""""""\n        self.buffer = None\n        self.counter = 0\n        self.last_onset = None\n\n    def process_offline(self, activations, **kwargs):\n        """"""\n        Detect the onsets in the given activation function.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Onset activation function.\n\n        Returns\n        -------\n        onsets : numpy array\n            Detected onsets [seconds].\n\n        """"""\n        # convert timing information to frames and set default values\n        # TODO: use at least 1 frame if any of these values are > 0?\n        timings = np.array([self.smooth, self.pre_avg, self.post_avg,\n                            self.pre_max, self.post_max]) * self.fps\n        timings = np.round(timings).astype(int)\n        # detect the peaks (function returns int indices)\n        onsets = peak_picking(activations, self.threshold, *timings)\n        # convert to timestamps\n        onsets = onsets.astype(np.float) / self.fps\n        # shift if necessary\n        if self.delay:\n            onsets += self.delay\n        # combine onsets\n        if self.combine:\n            onsets = combine_events(onsets, self.combine, \'left\')\n        # return the onsets\n        return np.asarray(onsets)\n\n    def process_online(self, activations, reset=True, **kwargs):\n        """"""\n        Detect the onsets in the given activation function.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Onset activation function.\n        reset : bool, optional\n            Reset the processor to its initial state before processing.\n\n        Returns\n        -------\n        onsets : numpy array\n            Detected onsets [seconds].\n\n        """"""\n        # buffer data\n        if self.buffer is None or reset:\n            # reset the processor\n            self.reset()\n            # put 0s in front (depending on context given by pre_max\n            init = np.zeros(int(np.round(self.pre_max * self.fps)))\n            buffer = np.insert(activations, 0, init, axis=0)\n            # offset the counter, because we buffer the activations\n            self.counter = -len(init)\n            # use the data for the buffer\n            self.buffer = BufferProcessor(init=buffer)\n        else:\n            buffer = self.buffer(activations)\n        # convert timing information to frames and set default values\n        # TODO: use at least 1 frame if any of these values are > 0?\n        timings = np.array([self.smooth, self.pre_avg, self.post_avg,\n                            self.pre_max, self.post_max]) * self.fps\n        timings = np.round(timings).astype(int)\n        # detect the peaks (function returns int indices)\n        peaks = peak_picking(buffer, self.threshold, *timings)\n        # convert to onset timings\n        onsets = (self.counter + peaks) / float(self.fps)\n        # increase counter\n        self.counter += len(activations)\n        # shift if necessary\n        if self.delay:\n            raise ValueError(\'delay not supported yet in online mode\')\n        # report only if there was no onset within the last combine seconds\n        if self.combine and onsets.any():\n            # prepend the last onset to be able to combine them correctly\n            start = 0\n            if self.last_onset is not None:\n                onsets = np.append(self.last_onset, onsets)\n                start = 1\n            # combine the onsets\n            onsets = combine_events(onsets, self.combine, \'left\')\n            # use only if the last onsets differ\n            if onsets[-1] != self.last_onset:\n                self.last_onset = onsets[-1]\n                # remove the first onset if we added it previously\n                onsets = onsets[start:]\n            else:\n                # don\'t report an onset\n                onsets = np.empty(0)\n        # return the onsets\n        return onsets\n\n    process_sequence = process_offline\n\n    @staticmethod\n    def add_arguments(parser, threshold=THRESHOLD, smooth=None, pre_avg=None,\n                      post_avg=None, pre_max=None, post_max=None,\n                      combine=COMBINE, delay=DELAY):\n        """"""\n        Add onset peak-picking related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        threshold : float\n            Threshold for peak-picking.\n        smooth : float, optional\n            Smooth the activation function over `smooth` seconds.\n        pre_avg : float, optional\n            Use `pre_avg` seconds past information for moving average.\n        post_avg : float, optional\n            Use `post_avg` seconds future information for moving average.\n        pre_max : float, optional\n            Use `pre_max` seconds past information for moving maximum.\n        post_max : float, optional\n            Use `post_max` seconds future information for moving maximum.\n        combine : float, optional\n            Only report one onset within `combine` seconds.\n        delay : float, optional\n            Report the detected onsets `delay` seconds delayed.\n\n        Returns\n        -------\n        parser_group : argparse argument group\n            Onset peak-picking argument parser group.\n\n        Notes\n        -----\n        Parameters are included in the group only if they are not \'None\'.\n\n        """"""\n        # add onset peak-picking related options to the existing parser\n        g = parser.add_argument_group(\'peak-picking arguments\')\n        g.add_argument(\'-t\', dest=\'threshold\', action=\'store\', type=float,\n                       default=threshold,\n                       help=\'detection threshold [default=%(default).2f]\')\n        if smooth is not None:\n            g.add_argument(\'--smooth\', action=\'store\', type=float,\n                           default=smooth,\n                           help=\'smooth the activation function over N \'\n                                \'seconds [default=%(default).2f]\')\n        if pre_avg is not None:\n            g.add_argument(\'--pre_avg\', action=\'store\', type=float,\n                           default=pre_avg,\n                           help=\'build average over N previous seconds \'\n                                \'[default=%(default).2f]\')\n        if post_avg is not None:\n            g.add_argument(\'--post_avg\', action=\'store\', type=float,\n                           default=post_avg,\n                           help=\'build average over N following seconds \'\n                                \'[default=%(default).2f]\')\n        if pre_max is not None:\n            g.add_argument(\'--pre_max\', action=\'store\', type=float,\n                           default=pre_max,\n                           help=\'search maximum over N previous seconds \'\n                                \'[default=%(default).2f]\')\n        if post_max is not None:\n            g.add_argument(\'--post_max\', action=\'store\', type=float,\n                           default=post_max,\n                           help=\'search maximum over N following seconds \'\n                                \'[default=%(default).2f]\')\n        if combine is not None:\n            g.add_argument(\'--combine\', action=\'store\', type=float,\n                           default=combine,\n                           help=\'combine events within N seconds \'\n                                \'[default=%(default).2f]\')\n        if delay is not None:\n            g.add_argument(\'--delay\', action=\'store\', type=float,\n                           default=delay,\n                           help=\'report the events N seconds delayed \'\n                                \'[default=%(default)i]\')\n        # return the argument group so it can be modified if needed\n        return g\n'"
madmom/features/tempo.py,29,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains tempo related functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport sys\n\nimport numpy as np\n\nfrom ..audio.signal import smooth as smooth_signal\nfrom ..processors import BufferProcessor, OnlineProcessor\n\nMETHOD = \'comb\'\nALPHA = 0.79\nMIN_BPM = 40.\nMAX_BPM = 250.\nACT_SMOOTH = 0.14\nHIST_SMOOTH = 9\nHIST_BUFFER = 10.\nNO_TEMPO = np.nan\n\n\n# helper functions\ndef smooth_histogram(histogram, smooth):\n    """"""\n    Smooth the given histogram.\n\n    Parameters\n    ----------\n    histogram : tuple\n        Histogram (tuple of 2 numpy arrays, the first giving the strengths of\n        the bins and the second corresponding delay values).\n    smooth : int or numpy array\n        Smoothing kernel (size).\n\n    Returns\n    -------\n    histogram_bins : numpy array\n        Bins of the smoothed histogram.\n    histogram_delays : numpy array\n        Corresponding delays.\n\n    Notes\n    -----\n    If `smooth` is an integer, a Hamming window of that length will be used as\n    a smoothing kernel.\n\n    """"""\n    # smooth only the histogram bins, not the corresponding delays\n    return smooth_signal(histogram[0], smooth), histogram[1]\n\n\n# interval detection\ndef interval_histogram_acf(activations, min_tau=1, max_tau=None):\n    """"""\n    Compute the interval histogram of the given (beat) activation function via\n    auto-correlation as in [1]_.\n\n    Parameters\n    ----------\n    activations : numpy array\n        Beat activation function.\n    min_tau : int, optional\n        Minimal delay for the auto-correlation function [frames].\n    max_tau : int, optional\n        Maximal delay for the auto-correlation function [frames].\n\n    Returns\n    -------\n    histogram_bins : numpy array\n        Bins of the tempo histogram.\n    histogram_delays : numpy array\n        Corresponding delays [frames].\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck and Markus Schedl,\n           ""Enhanced Beat Tracking with Context-Aware Neural Networks"",\n           Proceedings of the 14th International Conference on Digital Audio\n           Effects (DAFx), 2011.\n\n    """"""\n    if activations.ndim != 1:\n        raise NotImplementedError(\'too many dimensions for autocorrelation \'\n                                  \'interval histogram calculation.\')\n    # set the maximum delay\n    if max_tau is None:\n        max_tau = len(activations) - min_tau\n    # test all possible delays\n    taus = list(range(min_tau, max_tau + 1))\n    bins = []\n    # Note: this is faster than:\n    #   corr = np.correlate(activations, activations, mode=\'full\')\n    #   bins = corr[len(activations) + min_tau - 1: len(activations) + max_tau]\n    for tau in taus:\n        bins.append(np.sum(np.abs(activations[tau:] * activations[0:-tau])))\n    # return histogram\n    return np.array(bins), np.array(taus)\n\n\ndef interval_histogram_comb(activations, alpha, min_tau=1, max_tau=None):\n    """"""\n    Compute the interval histogram of the given (beat) activation function via\n    a bank of resonating comb filters as in [1]_.\n\n    Parameters\n    ----------\n    activations : numpy array\n        Beat activation function.\n    alpha : float or numpy array\n        Scaling factor for the comb filter; if only a single value is given,\n        the same scaling factor for all delays is assumed.\n    min_tau : int, optional\n        Minimal delay for the comb filter [frames].\n    max_tau : int, optional\n        Maximal delta for comb filter [frames].\n\n    Returns\n    -------\n    histogram_bins : numpy array\n        Bins of the tempo histogram.\n    histogram_delays : numpy array\n        Corresponding delays [frames].\n\n    References\n    ----------\n    .. [1] Sebastian B\xc3\xb6ck, Florian Krebs and Gerhard Widmer,\n           ""Accurate Tempo Estimation based on Recurrent Neural Networks and\n           Resonating Comb Filters"",\n           Proceedings of the 16th International Society for Music Information\n           Retrieval Conference (ISMIR), 2015.\n\n    """"""\n    # import comb filter\n    from madmom.audio.comb_filters import CombFilterbankProcessor\n    # set the maximum delay\n    if max_tau is None:\n        max_tau = len(activations) - min_tau\n    # get the range of taus\n    taus = np.arange(min_tau, max_tau + 1)\n    # create a comb filter bank instance\n    cfb = CombFilterbankProcessor(\'backward\', taus, alpha)\n    if activations.ndim in (1, 2):\n        # apply a bank of comb filters\n        act = cfb.process(activations)\n        # determine the tau with the highest value for each time step\n        act_max = act == np.max(act, axis=-1)[..., np.newaxis]\n        # sum up these maxima weighted by the activation value to yield the\n        # histogram bin values\n        histogram_bins = np.sum(act * act_max, axis=0)\n    else:\n        raise NotImplementedError(\'too many dimensions for comb filter \'\n                                  \'interval histogram calculation.\')\n    # return the histogram\n    return histogram_bins, taus\n\n\n# helper functions\ndef dominant_interval(histogram, smooth=None):\n    """"""\n    Extract the dominant interval of the given histogram.\n\n    Parameters\n    ----------\n    histogram : tuple\n        Histogram (tuple of 2 numpy arrays, the first giving the strengths of\n        the bins and the second corresponding delay values).\n    smooth : int or numpy array, optional\n        Smooth the histogram with the given kernel (size).\n\n    Returns\n    -------\n    interval : int\n        Dominant interval.\n\n    Notes\n    -----\n    If `smooth` is an integer, a Hamming window of that length will be used as\n    a smoothing kernel.\n\n    """"""\n    # smooth the histogram bins\n    if smooth:\n        histogram = smooth_histogram(histogram, smooth)\n    # return the dominant interval\n    return histogram[1][np.argmax(histogram[0])]\n\n\n# extract the tempo from a histogram\ndef detect_tempo(histogram, fps):\n    """"""\n    Extract the tempo from the given histogram.\n\n    Parameters\n    ----------\n    histogram : tuple\n        Histogram (tuple of 2 numpy arrays, the first giving the strengths of\n        the bins and the second corresponding delay values).\n    fps : float\n        Frames per second.\n\n    Returns\n    -------\n    tempi : numpy array\n        Numpy array with the dominant tempi [bpm] (first column) and their\n        relative strengths (second column).\n\n    """"""\n    from scipy.signal import argrelmax\n    # histogram of IBIs\n    bins = histogram[0]\n    # convert the histogram bin delays to tempi in beats per minute\n    tempi = 60.0 * fps / histogram[1]\n    # to get the two dominant tempi, just keep the peaks\n    # use \'wrap\' mode to also get peaks at the borders\n    peaks = argrelmax(bins, mode=\'wrap\')[0]\n    # we need more than 1 peak to report multiple tempi\n    if len(peaks) == 0:\n        # a flat histogram has no peaks, use the center bin\n        if len(bins):\n            ret = np.asarray([tempi[len(bins) // 2], 1.])\n        else:\n            # otherwise: no peaks, no tempo\n            ret = np.asarray([NO_TEMPO, 0.])\n    elif len(peaks) == 1:\n        # report only the strongest tempo\n        ret = np.asarray([tempi[peaks[0]], 1.])\n    else:\n        # sort the peaks in descending order of bin heights\n        sorted_peaks = peaks[np.argsort(bins[peaks])[::-1]]\n        # normalize their strengths\n        strengths = bins[sorted_peaks]\n        strengths /= np.sum(strengths)\n        # return the tempi and their normalized strengths\n        ret = np.asarray(list(zip(tempi[sorted_peaks], strengths)))\n    # return the tempi\n    return np.atleast_2d(ret)\n\n\n# tempo histogram processor classes\nclass TempoHistogramProcessor(OnlineProcessor):\n    """"""\n    Tempo Histogram Processor class.\n\n    Parameters\n    ----------\n    min_bpm : float\n        Minimum tempo to detect [bpm].\n    max_bpm : float\n        Maximum tempo to detect [bpm].\n    hist_buffer : float\n        Aggregate the tempo histogram over `hist_buffer` seconds.\n    fps : float, optional\n        Frames per second.\n\n    Notes\n    -----\n    This abstract class provides the basic tempo histogram functionality.\n    Please use one of the following implementations:\n\n    - :class:`CombFilterTempoHistogramProcessor`,\n    - :class:`ACFTempoHistogramProcessor` or\n    - :class:`DBNTempoHistogramProcessor`.\n\n    """"""\n\n    def __init__(self, min_bpm, max_bpm, hist_buffer=HIST_BUFFER, fps=None,\n                 online=False, **kwargs):\n        # pylint: disable=unused-argument\n        super(TempoHistogramProcessor, self).__init__(online=online)\n        self.min_bpm = min_bpm\n        self.max_bpm = max_bpm\n        self.hist_buffer = hist_buffer\n        self.fps = fps\n        if self.online:\n            self._hist_buffer = BufferProcessor((int(hist_buffer * self.fps),\n                                                 len(self.intervals)))\n\n    @property\n    def min_interval(self):\n        """"""Minimum beat interval [frames].""""""\n        return int(np.floor(60. * self.fps / self.max_bpm))\n\n    @property\n    def max_interval(self):\n        """"""Maximum beat interval [frames].""""""\n        return int(np.ceil(60. * self.fps / self.min_bpm))\n\n    @property\n    def intervals(self):\n        """"""Beat intervals [frames].""""""\n        return np.arange(self.min_interval, self.max_interval + 1)\n\n    def reset(self):\n        """"""Reset the tempo histogram aggregation buffer.""""""\n        self._hist_buffer.reset()\n\n\nclass CombFilterTempoHistogramProcessor(TempoHistogramProcessor):\n    """"""\n    Create a tempo histogram with a bank of resonating comb filters.\n\n    Parameters\n    ----------\n    min_bpm : float, optional\n        Minimum tempo to detect [bpm].\n    max_bpm : float, optional\n        Maximum tempo to detect [bpm].\n    alpha : float, optional\n        Scaling factor for the comb filter.\n    hist_buffer : float\n        Aggregate the tempo histogram over `hist_buffer` seconds.\n    fps : float, optional\n        Frames per second.\n    online : bool, optional\n        Operate in online (i.e. causal) mode.\n\n    """"""\n\n    def __init__(self, min_bpm=MIN_BPM, max_bpm=MAX_BPM, alpha=ALPHA,\n                 hist_buffer=HIST_BUFFER, fps=None, online=False, **kwargs):\n        # pylint: disable=unused-argument\n        super(CombFilterTempoHistogramProcessor, self).__init__(\n            min_bpm=min_bpm, max_bpm=max_bpm, hist_buffer=hist_buffer, fps=fps,\n            online=online, **kwargs)\n        self.alpha = alpha\n        if self.online:\n            self._comb_buffer = BufferProcessor((self.max_interval + 1,\n                                                 len(self.intervals)))\n\n    def reset(self):\n        """"""Reset to initial state.""""""\n        super(CombFilterTempoHistogramProcessor, self).reset()\n        self._comb_buffer.reset()\n\n    def process_offline(self, activations, **kwargs):\n        """"""\n        Compute the histogram of the beat intervals with a bank of resonating\n        comb filters.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Beat activation function.\n\n        Returns\n        -------\n        histogram_bins : numpy array\n            Bins of the beat interval histogram.\n        histogram_delays : numpy array\n            Corresponding delays [frames].\n\n        """"""\n        return interval_histogram_comb(activations, self.alpha,\n                                       self.min_interval, self.max_interval)\n\n    def process_online(self, activations, reset=True, **kwargs):\n        """"""\n        Compute the histogram of the beat intervals with a bank of resonating\n        comb filters in online mode.\n\n        Parameters\n        ----------\n        activations : numpy float\n            Beat activation function.\n        reset : bool, optional\n            Reset to initial state before processing.\n\n        Returns\n        -------\n        histogram_bins : numpy array\n            Bins of the tempo histogram.\n        histogram_delays : numpy array\n            Corresponding delays [frames].\n\n        """"""\n        # reset to initial state\n        if reset:\n            self.reset()\n        # indices at which to retrieve y[n - \xcf\x84]\n        idx = [-self.intervals, np.arange(len(self.intervals))]\n        # iterate over all activations\n        for act in activations:\n            # online feed backward comb filter (y[n] = x[n] + \xce\xb1 * y[n - \xcf\x84])\n            y_n = act + self.alpha * self._comb_buffer[idx]\n            # shift output buffer with new value\n            self._comb_buffer(y_n)\n            # determine the tau with the highest value\n            act_max = y_n == np.max(y_n, axis=-1)[..., np.newaxis]\n            # compute the max bins\n            bins = y_n * act_max\n            # use a buffer to only keep a certain number of bins\n            # shift buffer and put new bins at end of buffer\n            bins = self._hist_buffer(bins)\n        # build a histogram together with the intervals and return it\n        return np.sum(bins, axis=0), self.intervals\n\n\nclass ACFTempoHistogramProcessor(TempoHistogramProcessor):\n    """"""\n    Create a tempo histogram with autocorrelation.\n\n    Parameters\n    ----------\n    min_bpm : float, optional\n        Minimum tempo to detect [bpm].\n    max_bpm : float, optional\n        Maximum tempo to detect [bpm].\n    hist_buffer : float\n        Aggregate the tempo histogram over `hist_buffer` seconds.\n    fps : float, optional\n        Frames per second.\n    online : bool, optional\n        Operate in online (i.e. causal) mode.\n\n    """"""\n\n    def __init__(self, min_bpm=MIN_BPM, max_bpm=MAX_BPM,\n                 hist_buffer=HIST_BUFFER, fps=None, online=False, **kwargs):\n        # pylint: disable=unused-argument\n        super(ACFTempoHistogramProcessor, self).__init__(\n            min_bpm=min_bpm, max_bpm=max_bpm, hist_buffer=hist_buffer, fps=fps,\n            online=online, **kwargs)\n        if self.online:\n            self._act_buffer = BufferProcessor((self.max_interval + 1, 1))\n\n    def reset(self):\n        """"""Reset to initial state.""""""\n        super(ACFTempoHistogramProcessor, self).reset()\n        self._act_buffer.reset()\n\n    def process_offline(self, activations, **kwargs):\n        """"""\n        Compute the histogram of the beat intervals with the autocorrelation\n        function.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Beat activation function.\n\n        Returns\n        -------\n        histogram_bins : numpy array\n            Bins of the beat interval histogram.\n        histogram_delays : numpy array\n            Corresponding delays [frames].\n\n        """"""\n        # build the tempo (i.e. inter beat interval) histogram and return it\n        return interval_histogram_acf(activations, self.min_interval,\n                                      self.max_interval)\n\n    def process_online(self, activations, reset=True, **kwargs):\n        """"""\n        Compute the histogram of the beat intervals with the autocorrelation\n        function in online mode.\n\n        Parameters\n        ----------\n        activations : numpy float\n            Beat activation function.\n        reset : bool, optional\n            Reset to initial state before processing.\n\n        Returns\n        -------\n        histogram_bins : numpy array\n            Bins of the tempo histogram.\n        histogram_delays : numpy array\n            Corresponding delays [frames].\n\n        """"""\n        # reset to initial state\n        if reset:\n            self.reset()\n        # iterate over all activations\n        # TODO: speed this up!\n        for act in activations:\n            # online ACF (y[n] = x[n] * x[n - \xcf\x84])\n            bins = act * self._act_buffer[-self.intervals].T\n            # shift activation buffer with new value\n            self._act_buffer(act)\n            # use a buffer to only keep a certain number of bins\n            # shift buffer and put new bins at end of buffer\n            bins = self._hist_buffer(bins)\n        # build a histogram together with the intervals and return it\n        return np.sum(bins, axis=0), self.intervals\n\n\nclass DBNTempoHistogramProcessor(TempoHistogramProcessor):\n    """"""\n    Create a tempo histogram with a dynamic Bayesian network (DBN).\n\n    Parameters\n    ----------\n    min_bpm : float, optional\n        Minimum tempo to detect [bpm].\n    max_bpm : float, optional\n        Maximum tempo to detect [bpm].\n    hist_buffer : float\n        Aggregate the tempo histogram over `hist_buffer` seconds.\n    fps : float, optional\n        Frames per second.\n    online : bool, optional\n        Operate in online (i.e. causal) mode.\n\n    """"""\n\n    def __init__(self, min_bpm=MIN_BPM, max_bpm=MAX_BPM,\n                 hist_buffer=HIST_BUFFER, fps=None, online=False, **kwargs):\n        # pylint: disable=unused-argument\n        super(DBNTempoHistogramProcessor, self).__init__(\n            min_bpm=min_bpm, max_bpm=max_bpm, hist_buffer=hist_buffer, fps=fps,\n            online=online, **kwargs)\n        from .beats import DBNBeatTrackingProcessor\n        self.dbn = DBNBeatTrackingProcessor(\n            min_bpm=self.min_bpm, max_bpm=self.max_bpm, fps=self.fps,\n            online=online, **kwargs)\n\n    def reset(self):\n        """"""Reset DBN to initial state.""""""\n        super(DBNTempoHistogramProcessor, self).reset()\n        self.dbn.hmm.reset()\n\n    def process_offline(self, activations, **kwargs):\n        """"""\n        Compute the histogram of the beat intervals with a DBN.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Beat activation function.\n\n        Returns\n        -------\n        histogram_bins : numpy array\n            Bins of the beat interval histogram.\n        histogram_delays : numpy array\n            Corresponding delays [frames].\n\n        """"""\n        # get the best state path by calling the viterbi algorithm\n        path, _ = self.dbn.hmm.viterbi(activations.astype(np.float32))\n        intervals = self.dbn.st.state_intervals[path]\n        # get the counts of the bins\n        bins = np.bincount(intervals,\n                           minlength=self.dbn.st.intervals.max() + 1)\n        # truncate everything below the minimum interval of the state space\n        bins = bins[self.dbn.st.intervals.min():]\n        # build a histogram together with the intervals and return it\n        return bins, self.dbn.st.intervals\n\n    def process_online(self, activations, reset=True, **kwargs):\n        """"""\n        Compute the histogram of the beat intervals with a DBN using the\n        forward algorithm.\n\n        Parameters\n        ----------\n        activations : numpy float\n            Beat activation function.\n        reset : bool, optional\n            Reset DBN to initial state before processing.\n\n        Returns\n        -------\n        histogram_bins : numpy array\n           Bins of the tempo histogram.\n        histogram_delays : numpy array\n           Corresponding delays [frames].\n\n        """"""\n        # reset to initial state\n        if reset:\n            self.reset()\n        # use forward path to get best state\n        fwd = self.dbn.hmm.forward(activations, reset=reset)\n        # choose the best state for each step\n        states = np.argmax(fwd, axis=1)\n        intervals = self.dbn.st.state_intervals[states]\n        # convert intervals to bins\n        bins = np.zeros((len(activations), len(self.intervals)))\n        bins[np.arange(len(activations)), intervals - self.min_interval] = 1\n        # shift buffer and put new bins at end of buffer\n        bins = self._hist_buffer(bins)\n        # build a histogram together with the intervals and return it\n        return np.sum(bins, axis=0), self.intervals\n\n\nclass TempoEstimationProcessor(OnlineProcessor):\n    """"""\n    Tempo Estimation Processor class.\n\n    Parameters\n    ----------\n    method : {\'comb\', \'acf\', \'dbn\'}\n        Method used for tempo estimation.\n    min_bpm : float, optional\n        Minimum tempo to detect [bpm].\n    max_bpm : float, optional\n        Maximum tempo to detect [bpm].\n    act_smooth : float, optional (default: 0.14)\n        Smooth the activation function over `act_smooth` seconds.\n    hist_smooth : int, optional (default: 7)\n        Smooth the tempo histogram over `hist_smooth` bins.\n    alpha : float, optional\n        Scaling factor for the comb filter.\n    fps : float, optional\n        Frames per second.\n    histogram_processor : :class:`TempoHistogramProcessor`, optional\n        Processor used to create a tempo histogram. If \'None\', a default\n        combfilter histogram processor will be created and used.\n    kwargs : dict, optional\n        Keyword arguments passed to :class:`CombFilterTempoHistogramProcessor`\n        if no `histogram_processor` was given.\n\n    Examples\n    --------\n    Create a TempoEstimationProcessor. The returned array represents the\n    estimated tempi (given in beats per minute) and their relative strength.\n\n    >>> proc = TempoEstimationProcessor(fps=100)\n    >>> proc  # doctest: +ELLIPSIS\n    <madmom.features.tempo.TempoEstimationProcessor object at 0x...>\n\n    Call this TempoEstimationProcessor with the beat activation function\n    obtained by RNNBeatProcessor to estimate the tempi.\n\n    >>> from madmom.features.beats import RNNBeatProcessor\n    >>> act = RNNBeatProcessor()(\'tests/data/audio/sample.wav\')\n    >>> proc(act)  # doctest: +NORMALIZE_WHITESPACE\n    array([[176.47059,  0.47469],\n           [117.64706,  0.17667],\n           [240.     ,  0.15371],\n           [ 68.96552,  0.09864],\n           [ 82.19178,  0.09629]])\n\n    """"""\n\n    def __init__(self, method=METHOD, min_bpm=MIN_BPM, max_bpm=MAX_BPM,\n                 act_smooth=ACT_SMOOTH, hist_smooth=HIST_SMOOTH, fps=None,\n                 online=False, histogram_processor=None, **kwargs):\n        # pylint: disable=unused-argument\n        super(TempoEstimationProcessor, self).__init__(online=online)\n        self.method = method\n        self.act_smooth = act_smooth\n        self.hist_smooth = hist_smooth\n        self.fps = fps\n        if self.online:\n            self.visualize = kwargs.get(\'verbose\', False)\n        if histogram_processor is None:\n            if method == \'acf\':\n                histogram_processor = ACFTempoHistogramProcessor\n            elif method == \'comb\':\n                histogram_processor = CombFilterTempoHistogramProcessor\n            elif method == \'dbn\':\n                histogram_processor = DBNTempoHistogramProcessor\n                # do not smooth the activations for the DBN\n                self.act_smooth = None\n            else:\n                raise ValueError(\'tempo histogram method unknown.\')\n            # instantiate histogram processor\n            histogram_processor = histogram_processor(\n                min_bpm=min_bpm, max_bpm=max_bpm, fps=fps, online=online,\n                **kwargs)\n        self.histogram_processor = histogram_processor\n\n    @property\n    def min_bpm(self):\n        """"""Minimum tempo [bpm].""""""\n        return self.histogram_processor.min_bpm\n\n    @property\n    def max_bpm(self):\n        """"""Maximum  tempo [bpm].""""""\n        return self.histogram_processor.max_bpm\n\n    @property\n    def intervals(self):\n        """"""Beat intervals [frames].""""""\n        return self.histogram_processor.intervals\n\n    @property\n    def min_interval(self):\n        """"""Minimum beat interval [frames].""""""\n        return self.histogram_processor.min_interval\n\n    @property\n    def max_interval(self):\n        """"""Maximum beat interval [frames].""""""\n        return self.histogram_processor.max_interval\n\n    def reset(self):\n        """"""Reset to initial state.""""""\n        self.histogram_processor.reset()\n\n    def process_offline(self, activations, **kwargs):\n        """"""\n        Detect the tempi from the (beat) activations.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Beat activation function.\n\n        Returns\n        -------\n        tempi : numpy array\n            Array with the dominant tempi [bpm] (first column) and their\n            relative strengths (second column).\n\n        """"""\n        # smooth the activations if needed\n        if self.act_smooth is not None:\n            act_smooth = int(round(self.fps * self.act_smooth))\n            activations = smooth_signal(activations, act_smooth)\n        # generate a histogram of beat intervals\n        histogram = self.interval_histogram(activations.astype(np.float))\n        # smooth the histogram\n        histogram = smooth_histogram(histogram, self.hist_smooth)\n        # detect the tempi and return them\n        return detect_tempo(histogram, self.fps)\n\n    def process_online(self, activations, reset=True, **kwargs):\n        """"""\n        Detect the tempi from the (beat) activations in online mode.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Beat activation function processed frame by frame.\n        reset : bool, optional\n            Reset the TempoEstimationProcessor to its initial state before\n            processing.\n\n        Returns\n        -------\n        tempi : numpy array\n            Array with the dominant tempi [bpm] (first column) and their\n            relative strengths (second column).\n\n        """"""\n        # build the tempo histogram depending on the chosen method\n        histogram = self.interval_histogram(activations, reset=reset)\n        # smooth the histogram\n        histogram = smooth_histogram(histogram, self.hist_smooth)\n        # detect the tempo and append it to the found tempi\n        tempo = detect_tempo(histogram, self.fps)\n        # visualize tempo\n        if self.visualize:\n            display = \'\'\n            # display the 3 most likely tempi and their strengths\n            for i, display_tempo in enumerate(tempo[:3], start=1):\n                # display tempo\n                display += \'| \' + str(round(display_tempo[0], 1)) + \' \'\n                # display strength\n                display += min(int(display_tempo[1] * 50), 18) * \'*\'\n                # fill up the rest with spaces\n                display = display.ljust(i * 26)\n            # print the tempi\n            sys.stderr.write(\'\\r%s\' % \'\'.join(display) + \'|\')\n            sys.stderr.flush()\n        # return tempo\n        return tempo\n\n    def interval_histogram(self, activations, **kwargs):\n        """"""\n        Compute the histogram of the beat intervals.\n\n        Parameters\n        ----------\n        activations : numpy array\n            Beat activation function.\n\n        Returns\n        -------\n        histogram_bins : numpy array\n            Bins of the beat interval histogram.\n        histogram_delays : numpy array\n            Corresponding delays [frames].\n\n        """"""\n        return self.histogram_processor(activations, **kwargs)\n\n    def dominant_interval(self, histogram):\n        """"""\n        Extract the dominant interval of the given histogram.\n\n        Parameters\n        ----------\n        histogram : tuple\n            Histogram (tuple of 2 numpy arrays, the first giving the strengths\n            of the bins and the second corresponding delay values).\n\n        Returns\n        -------\n        interval : int\n            Dominant interval.\n\n        """"""\n        # return the dominant interval\n        return dominant_interval(histogram, self.hist_smooth)\n\n    @staticmethod\n    def add_arguments(parser, method=None, min_bpm=None, max_bpm=None,\n                      act_smooth=None, hist_smooth=None, hist_buffer=None,\n                      alpha=None):\n        """"""\n        Add tempo estimation related arguments to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser.\n        method : {\'comb\', \'acf\', \'dbn\'}\n            Method used for tempo estimation.\n        min_bpm : float, optional\n            Minimum tempo to detect [bpm].\n        max_bpm : float, optional\n            Maximum tempo to detect [bpm].\n        act_smooth : float, optional\n            Smooth the activation function over `act_smooth` seconds.\n        hist_smooth : int, optional\n            Smooth the tempo histogram over `hist_smooth` bins.\n        hist_buffer : float, optional\n            Aggregate the tempo histogram over `hist_buffer` seconds.\n        alpha : float, optional\n            Scaling factor for the comb filter.\n\n        Returns\n        -------\n        parser_group : argparse argument group\n            Tempo argument parser group.\n\n        Notes\n        -----\n        Parameters are included in the group only if they are not \'None\'.\n\n        """"""\n        # add tempo estimation related options to the existing parser\n        g = parser.add_argument_group(\'tempo estimation arguments\')\n        if method is not None:\n            g.add_argument(\'--method\', action=\'store\', type=str,\n                           default=method, choices=[\'acf\', \'comb\', \'dbn\'],\n                           help=""which method to use [default=%(default)s]"")\n        if min_bpm is not None:\n            g.add_argument(\'--min_bpm\', action=\'store\', type=float,\n                           default=min_bpm,\n                           help=\'minimum tempo [bpm, default=%(default).2f]\')\n        if max_bpm is not None:\n            g.add_argument(\'--max_bpm\', action=\'store\', type=float,\n                           default=max_bpm,\n                           help=\'maximum tempo [bpm, default=%(default).2f]\')\n        if act_smooth is not None:\n            g.add_argument(\'--act_smooth\', action=\'store\', type=float,\n                           default=act_smooth,\n                           help=\'smooth the activations over N seconds \'\n                                \'[default=%(default).2f]\')\n        if hist_smooth is not None:\n            g.add_argument(\'--hist_smooth\', action=\'store\', type=int,\n                           default=hist_smooth,\n                           help=\'smooth the tempo histogram over N bins \'\n                                \'[default=%(default)d]\')\n        if hist_buffer is not None:\n            g.add_argument(\'--hist_buffer\', action=\'store\', type=float,\n                           default=hist_buffer,\n                           help=\'aggregate the tempo histogram over N seconds \'\n                                \'[default=%(default).2f]\')\n        if alpha is not None:\n            g.add_argument(\'--alpha\', action=\'store\', type=float,\n                           default=alpha,\n                           help=\'alpha for comb filter tempo estimation \'\n                                \'[default=%(default).2f]\')\n        # return the argument group so it can be modified if needed\n        return g\n'"
madmom/io/__init__.py,15,"b'# encoding: utf-8\n""""""\nInput/output package.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport io as _io\nimport contextlib\n\nimport numpy as np\n\nfrom .audio import load_audio_file\nfrom .midi import load_midi, write_midi\nfrom ..utils import suppress_warnings, string_types\n\nENCODING = \'utf8\'\n\n# dtype for numpy structured arrays that contain labelled segments\n# \'label\' needs to be castable to str\nSEGMENT_DTYPE = [(\'start\', np.float), (\'end\', np.float), (\'label\', object)]\n\n\n# overwrite the built-in open() to transparently apply some magic file handling\n@contextlib.contextmanager\ndef open_file(filename, mode=\'r\'):\n    """"""\n    Context manager which yields an open file or handle with the given mode\n    and closes it if needed afterwards.\n\n    Parameters\n    ----------\n    filename : str or file handle\n        File (handle) to open.\n    mode: {\'r\', \'w\'}\n        Specifies the mode in which the file is opened.\n\n    Yields\n    ------\n        Open file (handle).\n\n    """"""\n    # check if we need to open the file\n    if isinstance(filename, string_types):\n        f = fid = _io.open(filename, mode)\n    else:\n        f = filename\n        fid = None\n    # yield an open file handle\n    yield f\n    # close the file if needed\n    if fid:\n        fid.close()\n\n\n@suppress_warnings\ndef load_events(filename):\n    """"""\n    Load a events from a text file, one floating point number per line.\n\n    Parameters\n    ----------\n    filename : str or file handle\n        File to load the events from.\n\n    Returns\n    -------\n    numpy array\n        Events.\n\n    Notes\n    -----\n    Comments (lines starting with \'#\') and additional columns are ignored,\n    i.e. only the first column is returned.\n\n    """"""\n    # read in the events, one per line\n    events = np.loadtxt(filename, ndmin=2)\n    # 1st column is the event\'s time, the rest is ignored\n    return events[:, 0]\n\n\ndef write_events(events, filename, fmt=\'%.3f\', delimiter=\'\\t\', header=None):\n    """"""\n    Write the events to a file, one event per line.\n\n    Parameters\n    ----------\n    events : numpy array\n        Events to be written to file.\n    filename : str or file handle\n        File to write the events to.\n    fmt : str or sequence of strs, optional\n        A single format (e.g. \'%.3f\'), a sequence of formats, or a multi-format\n        string (e.g. \'%.3f %.3f\'), in which case `delimiter` is ignored.\n    delimiter : str, optional\n        String or character separating columns.\n    header : str, optional\n        String that will be written at the beginning of the file as comment.\n\n    """"""\n    events = np.array(events)\n    # reformat fmt to be a single string if needed\n    if isinstance(fmt, (list, tuple)):\n        fmt = delimiter.join(fmt)\n    # write output\n    with open_file(filename, \'wb\') as f:\n        # write header\n        if header is not None:\n            f.write(bytes((\'# \' + header + \'\\n\').encode(ENCODING)))\n        # write events\n        for e in events:\n            try:\n                string = fmt % tuple(e.tolist())\n            except AttributeError:\n                string = e\n            except TypeError:\n                string = fmt % e\n            f.write(bytes((string + \'\\n\').encode(ENCODING)))\n            f.flush()\n\n\nload_onsets = load_events\nwrite_onsets = write_events\n\n\n@suppress_warnings\ndef load_beats(filename, downbeats=False):\n    """"""\n    Load the beats from the given file, one beat per line of format\n    \'beat_time\' [\'beat_number\'].\n\n    Parameters\n    ----------\n    filename : str or file handle\n        File to load the beats from.\n    downbeats : bool, optional\n        Load only downbeats instead of beats.\n\n    Returns\n    -------\n    numpy array\n        Beats.\n\n    """"""\n    values = np.loadtxt(filename, ndmin=1)\n    if values.ndim > 1:\n        if downbeats:\n            # rows with a ""1"" in the 2nd column are downbeats\n            return values[values[:, 1] == 1][:, 0]\n        else:\n            # 1st column is the beat time, the rest is ignored\n            return values[:, 0]\n    return values\n\n\ndef write_beats(beats, filename, fmt=None, delimiter=\'\\t\', header=None):\n    """"""\n    Write the beats to a file.\n\n    Parameters\n    ----------\n    beats : numpy array\n        Beats to be written to file.\n    filename : str or file handle\n        File to write the beats to.\n    fmt : str or sequence of strs, optional\n        A single format (e.g. \'%.3f\'), a sequence of formats (e.g.\n        [\'%.3f\', \'%d\']), or a multi-format string (e.g. \'%.3f %d\'), in which\n        case `delimiter` is ignored.\n    delimiter : str, optional\n        String or character separating columns.\n    header : str, optional\n        String that will be written at the beginning of the file as comment.\n\n    """"""\n    if fmt is None and beats.ndim == 2:\n        fmt = [\'%.3f\', \'%d\']\n    elif fmt is None:\n        fmt = \'%.3f\'\n    write_events(beats, filename, fmt, delimiter, header)\n\n\ndef load_downbeats(filename):\n    """"""\n    Load the downbeats from the given file.\n\n    Parameters\n    ----------\n    filename : str or file handle\n        File to load the downbeats from.\n\n    Returns\n    -------\n    numpy array\n        Downbeats.\n\n    """"""\n    return load_beats(filename, downbeats=True)\n\n\ndef write_downbeats(beats, filename, fmt=None, delimiter=\'\\t\', header=None):\n    """"""\n    Write the downbeats to a file.\n\n    Parameters\n    ----------\n    beats : numpy array\n        Beats or downbeats to be written to file.\n    filename : str or file handle\n        File to write the beats to.\n    fmt : str or sequence of strs, optional\n        A single format (e.g. \'%.3f\'), a sequence of formats (e.g.\n        [\'%.3f\', \'%d\']), or a multi-format string (e.g. \'%.3f %d\'), in which\n        case `delimiter` is ignored.\n    delimiter : str, optional\n        String or character separating columns.\n    header : str, optional\n        String that will be written at the beginning of the file as comment.\n\n    Notes\n    -----\n    If `beats` contains both time and number of the beats, they are filtered\n    to contain only the downbeats (i.e. only the times of those beats with a\n    beat number of 1).\n\n    """"""\n    if beats.ndim == 2:\n        beats = beats[beats[:, 1] == 1][:, 0]\n    if fmt is None:\n        fmt = \'%.3f\'\n    write_events(beats, filename, fmt, delimiter, header)\n\n\n@suppress_warnings\ndef load_notes(filename):\n    """"""\n    Load the notes from the given file, one note per line of format\n    \'onset_time\' \'note_number\' [\'duration\' [\'velocity\']].\n\n    Parameters\n    ----------\n    filename: str or file handle\n        File to load the notes from.\n\n    Returns\n    -------\n    numpy array\n        Notes.\n\n    """"""\n    return np.loadtxt(filename, ndmin=2)\n\n\ndef write_notes(notes, filename, fmt=None, delimiter=\'\\t\', header=None):\n    """"""\n    Write the notes to a file.\n\n    Parameters\n    ----------\n    notes : numpy array, shape (num_notes, 2)\n        Notes, row format \'onset_time\' \'note_number\' [\'duration\' [\'velocity\']].\n    filename : str or file handle\n        File to write the notes to.\n    fmt : str or sequence of strs, optional\n        A sequence of formats (e.g. [\'%.3f\', \'%d\', \'%.3f\', \'%d\']), or a\n        multi-format string, e.g. \'%.3f %d %.3f %d\', in which case `delimiter`\n        is ignored.\n    delimiter : str, optional\n        String or character separating columns.\n    header : str, optional\n        String that will be written at the beginning of the file as comment.\n\n    Returns\n    -------\n    numpy array\n        Notes.\n\n    """"""\n    # set default format\n    if fmt is None:\n        fmt = [\'%.3f\', \'%d\', \'%.3f\', \'%d\']\n    if not notes.ndim == 2:\n        raise ValueError(\'unknown format for `notes`\')\n    # truncate format to the number of columns given\n    fmt = delimiter.join(fmt[:notes.shape[1]])\n    # write the notes\n    write_events(notes, filename, fmt=fmt, delimiter=delimiter, header=header)\n\n\ndef load_segments(filename):\n    """"""\n    Load labelled segments from file, one segment per line. Each segment is of\n    form <start> <end> <label>, where <start> and <end> are floating point\n    numbers, and <label> is a string.\n\n    Parameters\n    ----------\n    filename : str or file handle\n        File to read the labelled segments from.\n\n    Returns\n    -------\n    segments : numpy structured array\n        Structured array with columns \'start\', \'end\', and \'label\',\n        containing the beginning, end, and label of segments.\n\n    """"""\n    start, end, label = [], [], []\n\n    with open_file(filename) as f:\n        for line in f:\n            s, e, l = line.split()\n            start.append(float(s))\n            end.append(float(e))\n            label.append(l)\n\n    segments = np.zeros(len(start), dtype=SEGMENT_DTYPE)\n    segments[\'start\'] = start\n    segments[\'end\'] = end\n    segments[\'label\'] = label\n    return segments\n\n\ndef write_segments(segments, filename, fmt=None, delimiter=\'\\t\', header=None):\n    """"""\n    Write labelled segments to a file.\n\n    Parameters\n    ----------\n    segments : numpy structured array\n        Labelled segments, one per row (column definition see SEGMENT_DTYPE).\n    filename : str or file handle\n        Output filename or handle.\n    fmt : str or sequence of strs, optional\n        A sequence of formats (e.g. [\'%.3f\', \'%.3f\', \'%s\']), or a multi-format\n        string (e.g. \'%.3f %.3f %s\'), in which case `delimiter` is ignored.\n    delimiter : str, optional\n        String or character separating columns.\n    header : str, optional\n        String that will be written at the beginning of the file as comment.\n\n    Returns\n    -------\n    numpy structured array\n        Labelled segments\n\n    Notes\n    -----\n    Labelled segments are represented as numpy structured array with three\n    named columns: \'start\' contains the start position (e.g. seconds),\n    \'end\' the end position, and \'label\' the segment label.\n\n    """"""\n    if fmt is None:\n        fmt = [\'%.3f\', \'%.3f\', \'%s\']\n    write_events(segments, filename, fmt=fmt, delimiter=delimiter,\n                 header=header)\n\n\nload_chords = load_segments\nwrite_chords = write_segments\n\n\ndef load_key(filename):\n    """"""\n    Load the key from the given file.\n\n    Parameters\n    ----------\n    filename : str or file handle\n        File to read key information from.\n\n    Returns\n    -------\n    str\n        Key.\n\n    """"""\n    with open_file(filename) as f:\n        return f.read().strip()\n\n\ndef write_key(key, filename, header=None):\n    """"""\n    Write key string to a file.\n\n    Parameters\n    ----------\n    key : str\n        Key name.\n    filename : str or file handle\n        Output file.\n    header : str, optional\n        String that will be written at the beginning of the file as comment.\n\n    Returns\n    -------\n    key : str\n        Key name.\n\n    """"""\n    write_events([key], filename, fmt=\'%s\', header=header)\n\n\ndef load_tempo(filename, split_value=1., sort=None, norm_strengths=None,\n               max_len=None):\n    """"""\n    Load tempo information from the given file.\n\n    Tempo information must have the following format:\n    \'main tempo\' [\'secondary tempo\' [\'relative_strength\']]\n\n    Parameters\n    ----------\n    filename : str or file handle\n        File to load the tempo from.\n    split_value : float, optional\n        Value to distinguish between tempi and strengths.\n        `values` > `split_value` are interpreted as tempi [bpm],\n        `values` <= `split_value` are interpreted as strengths.\n    sort : bool, deprecated\n        Sort the tempi by their strength.\n    norm_strengths : bool, deprecated\n        Normalize the strengths to sum 1.\n    max_len : int, deprecated\n        Return at most `max_len` tempi.\n\n    Returns\n    -------\n    tempi : numpy array, shape (num_tempi[, 2])\n        Array with tempi. If no strength is parsed, a 1-dimensional array of\n        length \'num_tempi\' is returned. If strengths are given, a 2D array\n        with tempi (first column) and their relative strengths (second column)\n        is returned.\n\n\n    """"""\n    # try to load the data from file\n    values = np.loadtxt(filename, ndmin=1)\n    # split the filename according to their filename into tempi and strengths\n    # TODO: this is kind of hack-ish, find a better solution\n    tempi = values[values > split_value]\n    strengths = values[values <= split_value]\n    # make the strengths behave properly\n    strength_sum = np.sum(strengths)\n    # relative strengths are given (one less than tempi)\n    if len(tempi) - len(strengths) == 1:\n        strengths = np.append(strengths, 1. - strength_sum)\n        if np.any(strengths < 0):\n            raise AssertionError(\'strengths must be positive\')\n    # no strength is given, assume an evenly distributed one\n    if strength_sum == 0:\n        strengths = np.ones_like(tempi) / float(len(tempi))\n    # normalize the strengths\n    if norm_strengths is not None:\n        import warnings\n        warnings.warn(\'`norm_strengths` is deprecated as of version 0.16 and \'\n                      \'will be removed in 0.18. Please normalize strengths \'\n                      \'separately.\')\n        strengths /= float(strength_sum)\n    # tempi and strengths must have same length\n    if len(tempi) != len(strengths):\n        raise AssertionError(\'tempi and strengths must have same length\')\n    # order the tempi according to their strengths\n    if sort:\n        import warnings\n        warnings.warn(\'`sort` is deprecated as of version 0.16 and will be \'\n                      \'removed in 0.18. Please sort the returned array \'\n                      \'separately.\')\n        # Note: use \'mergesort\', because we want a stable sorting algorithm\n        #       which keeps the order of the keys in case of duplicate keys\n        #       but we need to apply this \'(-strengths)\' trick because we want\n        #       tempi with uniformly distributed strengths to keep their order\n        sort_idx = (-strengths).argsort(kind=\'mergesort\')\n        tempi = tempi[sort_idx]\n        strengths = strengths[sort_idx]\n    # return at most \'max_len\' tempi and their relative strength\n    if max_len is not None:\n        import warnings\n        warnings.warn(\'`max_len` is deprecated as of version 0.16 and will be \'\n                      \'removed in 0.18. Please truncate the returned array \'\n                      \'separately.\')\n    return np.vstack((tempi[:max_len], strengths[:max_len])).T\n\n\ndef write_tempo(tempi, filename, delimiter=\'\\t\', header=None, mirex=None):\n    """"""\n    Write the most dominant tempi and the relative strength to a file.\n\n    Parameters\n    ----------\n    tempi : numpy array\n        Array with the detected tempi (first column) and their strengths\n        (second column).\n    filename : str or file handle\n        Output file.\n    delimiter : str, optional\n        String or character separating columns.\n    header : str, optional\n        String that will be written at the beginning of the file as comment.\n    mirex : bool, deprecated\n        Report the lower tempo first (as required by MIREX).\n\n    Returns\n    -------\n    tempo_1 : float\n        The most dominant tempo.\n    tempo_2 : float\n        The second most dominant tempo.\n    strength : float\n        Their relative strength.\n\n    """"""\n    # make the given tempi a 2d array\n    tempi = np.array(tempi, ndmin=2)\n    # default values\n    t1 = t2 = strength = np.nan\n    # only one tempo was detected\n    if len(tempi) == 1:\n        t1 = tempi[0][0]\n        strength = 1.\n    # consider only the two strongest tempi and strengths\n    elif len(tempi) > 1:\n        t1, t2 = tempi[:2, 0]\n        strength = tempi[0, 1] / sum(tempi[:2, 1])\n    # for MIREX, the lower tempo must be given first\n    if mirex is not None:\n        import warnings\n        warnings.warn(\'`mirex` argument is deprecated as of version 0.16 \'\n                      \'and will be removed in version 0.17. Please sort the \'\n                      \'tempi manually\')\n        if t1 > t2:\n            t1, t2, strength = t2, t1, 1. - strength\n    # format as a numpy array and write to output\n    out = np.array([t1, t2, strength], ndmin=2)\n    write_events(out, filename, fmt=[\'%.2f\', \'%.2f\', \'%.2f\'],\n                 delimiter=delimiter, header=header)\n'"
madmom/io/audio.py,6,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains audio input/output functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport errno\nimport os\nimport subprocess\nimport sys\nimport tempfile\n\nimport numpy as np\n\nfrom ..utils import string_types, file_types\nfrom ..audio.signal import Signal\n\n\n# error classes\nclass LoadAudioFileError(Exception):\n    """"""\n    Exception to be raised whenever an audio file could not be loaded.\n\n    """"""\n    # pylint: disable=super-init-not-called\n\n    def __init__(self, value=None):\n        if value is None:\n            value = \'Could not load audio file.\'\n        self.value = value\n\n    def __str__(self):\n        return repr(self.value)\n\n\n# functions for loading audio files with ffmpeg\ndef _ffmpeg_fmt(dtype):\n    """"""\n    Convert numpy dtypes to format strings understood by ffmpeg.\n\n    Parameters\n    ----------\n    dtype : numpy dtype\n        Data type to be converted.\n\n    Returns\n    -------\n    str\n        ffmpeg format string.\n\n    """"""\n    # convert dtype to sample type\n    dtype = np.dtype(dtype)\n    # Note: list with all ffmpeg PCM sample types: ffmpeg -formats | grep PCM\n    # - unsigned int, signed int, floating point:\n    fmt = {\'u\': \'u\', \'i\': \'s\', \'f\': \'f\'}.get(dtype.kind)\n    # - sample size in bits:\n    fmt += str(8 * dtype.itemsize)\n    # - little endian or big endian:\n    if dtype.byteorder == \'=\':\n        fmt += sys.byteorder[0] + \'e\'\n    else:\n        fmt += {\'|\': \'\', \'<\': \'le\', \'>\': \'be\'}.get(dtype.byteorder)\n    return str(fmt)\n\n\ndef _ffmpeg_call(infile, output, fmt=\'f32le\', sample_rate=None, num_channels=1,\n                 channel=None, skip=None, max_len=None, cmd=\'ffmpeg\',\n                 replaygain_mode=None, replaygain_preamp=0.0):\n    """"""\n    Create a sequence of strings indicating ffmpeg how to be called as well as\n    the parameters necessary to decode the given input (file) to the given\n    format, at the given offset and for the given length to the given output.\n\n    Parameters\n    ----------\n    infile : str\n        Name of the audio sound file to decode.\n    output : str\n        Where to decode to.\n    fmt : {\'f32le\', \'s16le\'}, optional\n        Format of the samples:\n        - \'f32le\' for float32, little-endian,\n        - \'s16le\' for signed 16-bit int, little-endian.\n    sample_rate : int, optional\n        Sample rate to re-sample the signal to (if set) [Hz].\n    num_channels : int, optional\n        Number of channels to reduce the signal to.\n        If \'None\', return the signal with its original channels,\n        or whatever is selected by `channel`.\n    channel : int, optional\n        When reducing a signal to `num_channels` of 1, use this channel,\n        or \'None\' to return the average across all channels.\n    skip : float, optional\n        Number of seconds to skip at beginning of file.\n    max_len : float, optional\n        Maximum length in seconds to decode.\n    cmd : {\'ffmpeg\',\'avconv\'}, optional\n        Decoding command (defaults to ffmpeg, alternatively supports avconv).\n    replaygain_mode : {None, \'track\',\'album\'}, optional\n        Specify the ReplayGain volume-levelling mode (None to disable).\n    replaygain_preamp : float, optional\n        ReplayGain preamp volume change level (in dB).\n\n    Returns\n    -------\n    list\n        ffmpeg call.\n\n    Notes\n    -----\n    \'avconv\' rounds decoding positions and decodes in blocks of 4096 length\n    resulting in incorrect start and stop positions. Thus it should only be\n    used to decode complete files.\n\n    """"""\n    # Note: avconv rounds decoding positions and decodes in blocks of 4096\n    #       length resulting in incorrect start and stop positions\n    if cmd == \'avconv\' and skip is not None and max_len is not None:\n        raise RuntimeError(\'avconv has a bug, which results in wrong audio \'\n                           \'slices! Decode the audio files to .wav first or \'\n                           \'use ffmpeg.\')\n    # general options\n    call = [cmd, ""-v"", ""quiet"", ""-y""]\n    # input options\n    if skip:\n        # use ""%f"" to avoid scientific float notation\n        call.extend([""-ss"", ""%f"" % float(skip)])\n    # if we decode from STDIN, the format must be specified\n    if isinstance(infile, Signal):\n        in_fmt = _ffmpeg_fmt(infile.dtype)\n        in_ac = str(int(infile.num_channels))\n        in_ar = str(int(infile.sample_rate))\n        infile = ""pipe:0""\n        call.extend([""-f"", in_fmt, ""-ac"", in_ac, ""-ar"", in_ar])\n    elif isinstance(infile, file_types):\n        infile = ""pipe:0""\n    else:\n        infile = str(infile)\n    call.extend([""-i"", infile])\n    if replaygain_mode:\n        audio_filter = (""volume=replaygain=%s:replaygain_preamp=%.1f""\n                        % (replaygain_mode, replaygain_preamp))\n        call.extend([""-af"", audio_filter])\n    # output options\n    call.extend([""-f"", str(fmt)])\n    if max_len:\n        # use ""%f"" to avoid scientific float notation\n        call.extend([""-t"", ""%f"" % float(max_len)])\n    # output options\n    if num_channels:\n        call.extend([""-ac"", str(int(num_channels))])\n    if channel is not None and (num_channels == 1 or num_channels is None):\n        # Calling with channel=x and num_channels\n        call.extend([""-af"", ""pan=mono|c0=c%d"" % int(channel)])\n    if sample_rate:\n        call.extend([""-ar"", str(int(sample_rate))])\n    call.append(output)\n    return call\n\n\ndef decode_to_disk(infile, fmt=\'f32le\', sample_rate=None, num_channels=1,\n                   channel=None, skip=None, max_len=None, outfile=None,\n                   tmp_dir=None, tmp_suffix=None, cmd=\'ffmpeg\',\n                   replaygain_mode=None, replaygain_preamp=0.0):\n    """"""\n    Decode the given audio file to another file.\n\n    Parameters\n    ----------\n    infile : str\n        Name of the audio sound file to decode.\n    fmt : {\'f32le\', \'s16le\'}, optional\n        Format of the samples:\n        - \'f32le\' for float32, little-endian,\n        - \'s16le\' for signed 16-bit int, little-endian.\n    sample_rate : int, optional\n        Sample rate to re-sample the signal to (if set) [Hz].\n    num_channels : int, optional\n        Number of channels to reduce the signal to.\n        If \'None\', return the signal with its original channels,\n        or whatever is selected by `channel`.\n    channel : int, optional\n        When reducing a signal to `num_channels` of 1, use this channel,\n        or \'None\' to return the average across all channels.\n    skip : float, optional\n        Number of seconds to skip at beginning of file.\n    max_len : float, optional\n        Maximum length in seconds to decode.\n    outfile : str, optional\n        The file to decode the sound file to; if not given, a temporary file\n        will be created.\n    tmp_dir : str, optional\n        The directory to create the temporary file in (if no `outfile` is\n        given).\n    tmp_suffix : str, optional\n        The file suffix for the temporary file if no `outfile` is given; e.g.\n        "".pcm"" (including the dot).\n    cmd : {\'ffmpeg\', \'avconv\'}, optional\n        Decoding command (defaults to ffmpeg, alternatively supports avconv).\n    replaygain_mode : {None, \'track\',\'album\'}, optional\n        Specify the ReplayGain volume-levelling mode (None to disable).\n    replaygain_preamp : float, optional\n        ReplayGain preamp volume change level (in dB).\n\n    Returns\n    -------\n    outfile : str\n        The output file name.\n\n    """"""\n    # check input file type\n    if not isinstance(infile, string_types):\n        raise ValueError(""only file names are supported as `infile`, not %s.""\n                         % infile)\n    # create temp file if no outfile is given\n    if outfile is None:\n        # looks stupid, but is recommended over tempfile.mktemp()\n        f = tempfile.NamedTemporaryFile(delete=False, dir=tmp_dir,\n                                        suffix=tmp_suffix)\n        f.close()\n        outfile = f.name\n        delete_on_fail = True\n    else:\n        delete_on_fail = False\n    # check output file type\n    if not isinstance(outfile, string_types):\n        raise ValueError(""only file names are supported as `outfile`, not %s.""\n                         % outfile)\n    # call ffmpeg (throws exception on error)\n    try:\n        call = _ffmpeg_call(infile, outfile, fmt, sample_rate, num_channels,\n                            channel, skip, max_len, cmd,\n                            replaygain_mode=replaygain_mode,\n                            replaygain_preamp=replaygain_preamp)\n        subprocess.check_call(call)\n    except Exception:\n        if delete_on_fail:\n            os.unlink(outfile)\n        raise\n    return outfile\n\n\ndef decode_to_pipe(infile, fmt=\'f32le\', sample_rate=None, num_channels=1,\n                   channel=None, skip=None, max_len=None, buf_size=-1,\n                   cmd=\'ffmpeg\', replaygain_mode=None, replaygain_preamp=0.0):\n    """"""\n    Decode the given audio and return a file-like object for reading the\n    samples, as well as a process object.\n\n    Parameters\n    ----------\n    infile : str\n        Name of the audio sound file to decode.\n    fmt : {\'f32le\', \'s16le\'}, optional\n        Format of the samples:\n        - \'f32le\' for float32, little-endian,\n        - \'s16le\' for signed 16-bit int, little-endian.\n    sample_rate : int, optional\n        Sample rate to re-sample the signal to (if set) [Hz].\n    num_channels : int, optional\n        Number of channels to reduce the signal to.\n        If \'None\', return the signal with its original channels,\n        or whatever is selected by `channel`.\n    channel : int, optional\n        When reducing a signal to `num_channels` of 1, use this channel,\n        or \'None\' to return the average across all channels.\n    skip : float, optional\n        Number of seconds to skip at beginning of file.\n    max_len : float, optional\n        Maximum length in seconds to decode.\n    buf_size : int, optional\n        Size of buffer for the file-like object:\n        - \'-1\' means OS default (default),\n        - \'0\' means unbuffered,\n        - \'1\' means line-buffered, any other value is the buffer size in bytes.\n    cmd : {\'ffmpeg\',\'avconv\'}, optional\n        Decoding command (defaults to ffmpeg, alternatively supports avconv).\n    replaygain_mode : {None, \'track\',\'album\'}, optional\n        Specify the ReplayGain volume-levelling mode (None to disable).\n    replaygain_preamp : float, optional\n        ReplayGain preamp volume change level (in dB).\n\n    Returns\n    -------\n    pipe : file-like object\n        File-like object for reading the decoded samples.\n    proc : process object\n        Process object for the decoding process.\n\n    Notes\n    -----\n    To stop decoding the file, call close() on the returned file-like object,\n    then call wait() on the returned process object.\n\n    """"""\n    # check input file type\n    if not isinstance(infile, (string_types, file_types, Signal)):\n        raise ValueError(""only file names, file objects or Signal instances ""\n                         ""are supported as `infile`, not %s."" % infile)\n    # Note: closing the file-like object only stops decoding because ffmpeg\n    #       reacts on that. A cleaner solution would be calling proc.terminate\n    #       explicitly, but this is only available in Python 2.6+. proc.wait\n    #       needs to be called in any case.\n    call = _ffmpeg_call(infile, ""pipe:1"", fmt, sample_rate, num_channels,\n                        channel, skip, max_len, cmd,\n                        replaygain_mode=replaygain_mode,\n                        replaygain_preamp=replaygain_preamp)\n    # redirect stdout to a pipe and buffer as requested\n    if isinstance(infile, (Signal, file_types)):\n        proc = subprocess.Popen(call, stdin=subprocess.PIPE,\n                                stdout=subprocess.PIPE, bufsize=buf_size)\n    else:\n        proc = subprocess.Popen(call, stdout=subprocess.PIPE, bufsize=buf_size)\n    return proc.stdout, proc\n\n\ndef nonstreamable_mp4_file_object(infile, cmd=""ffprobe""):\n    """"""\n    Test if the given audio file object is a non-streamable MPEG4 container.\n    Decode the given audio and return a file-like object for reading the\n    samples, as well as a process object.\n\n    Parameters\n    ----------\n    infile : file_types\n        File object to decode.\n    cmd : {\'ffprobe\', \'avprobe\'}, optional\n        Probing command (defaults to ffprobe, alternatively supports avprobe).\n\n    Returns\n    -------\n    boolean\n        True when audio is non-streamable container, False otherwise.\n\n    """"""\n    call = [cmd, ""-v"", ""debug"", ""-hide_banner"",\n            ""-show_entries"", ""format=format_name"",\n            ""-print_format"", ""default=nokey=1:noprint_wrappers=1"",\n            ""pipe:0""]\n    proc = subprocess.Popen(call, stdin=subprocess.PIPE,\n                            stdout=subprocess.PIPE,\n                            stderr=subprocess.PIPE)\n    out, err = proc.communicate(infile.read())\n    retcode = proc.poll()\n    infile.seek(0)\n    if retcode:\n        raise subprocess.CalledProcessError(retcode, call, output=err)\n    container_format = out.decode().strip()\n    partial_file = ""partial file"" in err.decode()\n    if container_format == ""mov,mp4,m4a,3gp,3g2,mj2"" and partial_file:\n        return True\n    else:\n        return False\n\n\ndef decode_to_memory(infile, fmt=\'f32le\', sample_rate=None, num_channels=1,\n                     channel=None, skip=None, max_len=None,\n                     cmd_decode=\'ffmpeg\', cmd_probe=\'ffprobe\',\n                     replaygain_mode=None, replaygain_preamp=0.0):\n    """"""\n    Decode the given audio and return it as a binary string representation.\n\n    Parameters\n    ----------\n    infile : str\n        Name of the audio sound file to decode.\n    fmt : {\'f32le\', \'s16le\'}, optional\n        Format of the samples:\n        - \'f32le\' for float32, little-endian,\n        - \'s16le\' for signed 16-bit int, little-endian.\n    sample_rate : int, optional\n        Sample rate to re-sample the signal to (if set) [Hz].\n    num_channels : int, optional\n        Number of channels to reduce the signal to.\n        If \'None\', return the signal with its original channels,\n        or whatever is selected by `channel`.\n    channel : int, optional\n        When reducing a signal to `num_channels` of 1, use this channel,\n        or \'None\' to return the average across all channels.\n    skip : float, optional\n        Number of seconds to skip at beginning of file.\n    max_len : float, optional\n        Maximum length in seconds to decode.\n    cmd_decode : {\'ffmpeg\', \'avconv\'}, optional\n        Decoding command (defaults to ffmpeg, alternatively supports avconv).\n    cmd_probe : {\'ffprobe\', \'avprobe\'}, optional\n        Probing command (defaults to ffprobe, alternatively supports avprobe).\n    replaygain_mode : {None, \'track\',\'album\'}, optional\n        Specify the ReplayGain volume-levelling mode (None to disable).\n    replaygain_preamp : float, optional\n        ReplayGain preamp volume change level (in dB).\n\n    Returns\n    -------\n    samples : str\n        Binary string representation of the audio samples.\n\n    """"""\n    # check input file type\n    if not isinstance(infile, (string_types, file_types, Signal)):\n        raise ValueError(""only file names, file objects or Signal instances ""\n                         ""are supported as `infile`, not %s."" % infile)\n    # prepare decoding to pipe\n    _, proc = decode_to_pipe(infile, fmt=fmt, sample_rate=sample_rate,\n                             num_channels=num_channels, channel=channel,\n                             skip=skip, max_len=max_len, cmd=cmd_decode,\n                             replaygain_mode=replaygain_mode,\n                             replaygain_preamp=replaygain_preamp)\n    # decode the input to memory\n    if isinstance(infile, Signal):\n        # Note: np.getbuffer was removed in Python 3, but Python 2 memoryviews\n        #       do not have the cast() method\n        try:\n            signal, _ = proc.communicate(np.getbuffer(infile))\n        except AttributeError:\n            mv = memoryview(infile)\n            signal, _ = proc.communicate(mv.cast(\'b\'))\n    elif isinstance(infile, file_types):\n        signal, _ = proc.communicate(infile.read())\n        infile.seek(0)\n        # handle non-streamable MP4 container, which silently returns an empty\n        # signal\n        if not signal and nonstreamable_mp4_file_object(infile, cmd_probe):\n            try:\n                delete_file = False\n                try:\n                    # pass its path if the file exists on disk\n                    path = infile.name\n                except AttributeError:\n                    # otherwise store it as a temporary file\n                    with tempfile.NamedTemporaryFile(mode=""wb"", delete=False,\n                                                     suffix="".mp4"") as f:\n                        f.write(infile.read())\n                    infile.seek(0)\n                    path = f.name\n                    delete_file = True\n                # retry by passing a path to ffmpeg instead of piping the\n                # audio to stdin (allows multiple reading passes)\n                signal = decode_to_memory(path, fmt, sample_rate, num_channels,\n                                          channel, skip, max_len, cmd_decode,\n                                          cmd_probe, replaygain_mode,\n                                          replaygain_preamp)\n            finally:\n                if delete_file:\n                    os.remove(path)\n    else:\n        signal, _ = proc.communicate()\n    if proc.returncode != 0:\n        raise subprocess.CalledProcessError(proc.returncode, cmd_decode)\n    return signal\n\n\ndef get_file_info(infile, cmd=\'ffprobe\'):\n    """"""\n    Extract and return information about audio files.\n\n    Parameters\n    ----------\n    infile : str\n        Name of the audio file.\n    cmd : {\'ffprobe\', \'avprobe\'}, optional\n        Probing command (defaults to ffprobe, alternatively supports avprobe).\n\n    Returns\n    -------\n    dict\n        Audio file information.\n\n    """"""\n    # init dictionary\n    info = {\'num_channels\': None, \'sample_rate\': None}\n    if isinstance(infile, Signal):\n        info[\'num_channels\'] = infile.num_channels\n        info[\'sample_rate\'] = infile.sample_rate\n    else:\n        # call ffprobe\n        if isinstance(infile, file_types):\n            call = [cmd, ""-v"", ""quiet"", ""-show_streams"", ""pipe:0""]\n            proc = subprocess.Popen(call, stdin=subprocess.PIPE,\n                                    stdout=subprocess.PIPE)\n            output, _ = proc.communicate(infile.read())\n            retcode = proc.poll()\n            infile.seek(0)\n            if retcode:\n                raise subprocess.CalledProcessError(retcode, call,\n                                                    output=output)\n        else:\n            output = subprocess.check_output([cmd, ""-v"", ""quiet"",\n                                              ""-show_streams"", infile])\n        # parse information\n        for line in output.split():\n            if line.startswith(b\'channels=\'):\n                info[\'num_channels\'] = int(line[len(\'channels=\'):])\n            if line.startswith(b\'sample_rate=\'):\n                # the int(float(...)) conversion is necessary because\n                # avprobe returns sample_rate as floating point number\n                # which int() can\'t handle.\n                info[\'sample_rate\'] = int(float(line[len(\'sample_rate=\'):]))\n    # return the dictionary\n    return info\n\n\ndef load_ffmpeg_file(filename, sample_rate=None, num_channels=None,\n                     channel=None, start=None, stop=None, dtype=None,\n                     cmd_decode=\'ffmpeg\', cmd_probe=\'ffprobe\',\n                     replaygain_mode=None, replaygain_preamp=0.0):\n    """"""\n    Load the audio data from the given file and return it as a numpy array.\n\n    This uses ffmpeg (or avconv) and thus supports a lot of different file\n    formats, resampling and channel conversions. The file will be fully decoded\n    into memory if no start and stop positions are given.\n\n    Parameters\n    ----------\n    filename : str\n        Name of the audio sound file to load.\n    sample_rate : int, optional\n        Sample rate to re-sample the signal to [Hz]; \'None\' returns the signal\n        in its original rate.\n    num_channels : int, optional\n        Reduce or expand the signal to `num_channels` channels.\n        If \'None\', return the signal with its original channels,\n        or whatever is selected by `channel`.\n    channel : int, optional\n        When reducing a signal to `num_channels` of 1, use this channel,\n        or \'None\' to return the average across all channels.\n    start : float, optional\n        Start position [seconds].\n    stop : float, optional\n        Stop position [seconds].\n    dtype : numpy dtype, optional\n        Numpy dtype to return the signal in (supports signed and unsigned\n        8/16/32-bit integers, and single and double precision floats,\n        each in little or big endian). If \'None\', np.int16 is used.\n    cmd_decode : {\'ffmpeg\', \'avconv\'}, optional\n        Decoding command (defaults to ffmpeg, alternatively supports avconv).\n    cmd_probe : {\'ffprobe\', \'avprobe\'}, optional\n        Probing command (defaults to ffprobe, alternatively supports avprobe).\n    replaygain_mode : {None, \'track\',\'album\'}, optional\n        Specify the ReplayGain volume-levelling mode (None to disable).\n    replaygain_preamp : float, optional\n        ReplayGain preamp volume change level (in dB).\n\n    Returns\n    -------\n    signal : numpy array\n        Audio samples.\n    sample_rate : int\n        Sample rate of the audio samples.\n\n    """"""\n    # set default dtype\n    if dtype is None:\n        dtype = np.int16\n    # ffmpeg output format\n    fmt = _ffmpeg_fmt(dtype)\n    # start and stop position\n    if start is None:\n        start = 0\n    max_len = None\n    if stop is not None:\n        max_len = stop - start\n    # convert the audio signal using ffmpeg\n    signal = np.frombuffer(\n        decode_to_memory(filename, fmt=fmt, sample_rate=sample_rate,\n                         num_channels=num_channels, channel=channel,\n                         skip=start, max_len=max_len,\n                         cmd_decode=cmd_decode, cmd_probe=cmd_probe,\n                         replaygain_mode=replaygain_mode,\n                         replaygain_preamp=replaygain_preamp\n                         ),\n        dtype=dtype)\n    # get the needed information from the file\n    if sample_rate is None or num_channels is None:\n        info = get_file_info(filename, cmd=cmd_probe)\n        if sample_rate is None:\n            sample_rate = info[\'sample_rate\']\n        if num_channels is None:\n            num_channels = info[\'num_channels\']\n    # reshape the audio signal\n    if num_channels > 1:\n        signal = signal.reshape((-1, num_channels))\n    return signal, sample_rate\n\n\n# functions for loading/saving wave files\ndef load_wave_file(filename, sample_rate=None, num_channels=None, channel=None,\n                   start=None, stop=None, dtype=None):\n    """"""\n    Load the audio data from the given file and return it as a numpy array.\n\n    Only supports wave files, does not support re-sampling or arbitrary\n    channel number conversions. Reads the data as a memory-mapped file with\n    copy-on-write semantics to defer I/O costs until needed.\n\n    Parameters\n    ----------\n    filename : str\n        Name of the file.\n    sample_rate : int, optional\n        Desired sample rate of the signal [Hz], or \'None\' to return the\n        signal in its original rate.\n    num_channels : int, optional\n        Reduce or expand the signal to `num_channels` channels\n        If \'None\', return the signal with its original channels,\n        or whichever is selected by `channel`.\n    channel : int, optional\n        When reducing a signal to `num_channels` of 1, use this channel,\n        or \'None\' to return the average across all channels.\n    start : float, optional\n        Start position [seconds].\n    stop : float, optional\n        Stop position [seconds].\n    dtype : numpy data type, optional\n        The data is returned with the given dtype. If \'None\', it is returned\n        with its original dtype, otherwise the signal gets rescaled. Integer\n        dtypes use the complete value range, float dtypes the range [-1, +1].\n\n\n    Returns\n    -------\n    signal : numpy array\n        Audio signal.\n    sample_rate : int\n        Sample rate of the signal [Hz].\n\n    Notes\n    -----\n    The `start` and `stop` positions are rounded to the closest sample; the\n    sample corresponding to the `stop` value is not returned, thus consecutive\n    segment starting with the previous `stop` can be concatenated to obtain\n    the original signal without gaps or overlaps.\n\n    """"""\n    from scipy.io import wavfile\n    file_sample_rate, signal = wavfile.read(filename, mmap=True)\n    # if the sample rate is not the desired one, raise exception\n    if sample_rate is not None and sample_rate != file_sample_rate:\n        raise ValueError(\'Requested sample rate of %f Hz, but got %f Hz and \'\n                         \'re-sampling is not implemented.\' %\n                         (sample_rate, file_sample_rate))\n    # same for the data type\n    if dtype is not None and signal.dtype != dtype:\n        raise ValueError(\'Requested dtype %s, but got %s and re-scaling is \'\n                         \'not implemented.\' % (dtype, signal.dtype))\n    # only request the desired part of the signal\n    if start is not None:\n        start = int(start * file_sample_rate)\n    if stop is not None:\n        stop = min(len(signal), int(stop * file_sample_rate))\n    if start is not None or stop is not None:\n        signal = signal[start: stop]\n    if channel is not None and num_channels is None:\n        # It\'s clear what the caller means here\n        num_channels = 1\n    if num_channels is not None:\n        from ..audio.signal import remix\n        signal = remix(signal, num_channels, channel)\n    # return the signal\n    return signal, file_sample_rate\n\n\ndef write_wave_file(signal, filename, sample_rate=None):\n    """"""\n    Write the signal to disk as a .wav file.\n\n    Parameters\n    ----------\n    signal : numpy array or Signal\n        The signal to be written to file.\n    filename : str\n        Name of the file.\n    sample_rate : int, optional\n        Sample rate of the signal [Hz].\n\n    Returns\n    -------\n    filename : str\n        Name of the file.\n\n    Notes\n    -----\n    `sample_rate` can be \'None\' if `signal` is a :class:`Signal` instance. If\n    set, the given `sample_rate` is used instead of the signal\'s sample rate.\n    Must be given if `signal` is a ndarray.\n\n    """"""\n    from scipy.io import wavfile\n    if isinstance(signal, Signal) and sample_rate is None:\n        sample_rate = int(signal.sample_rate)\n    wavfile.write(filename, rate=sample_rate, data=signal)\n    return filename\n\n\n# function for automatically determining how to open audio files\ndef load_audio_file(filename, sample_rate=None, num_channels=None,\n                    channel=None, start=None, stop=None, dtype=None,\n                    replaygain_mode=None, replaygain_preamp=0.0):\n    """"""\n    Load the audio data from the given file and return it as a numpy array.\n    This tries load_wave_file() load_ffmpeg_file() (for ffmpeg and avconv).\n\n    Parameters\n    ----------\n    filename : str or file handle\n        Name of the file or file handle.\n    sample_rate : int, optional\n        Desired sample rate of the signal [Hz], or \'None\' to return the\n        signal in its original rate.\n    num_channels : int, optional\n        Reduce or expand the signal to `num_channels` channels.\n        If \'None\', return the signal with its original channels,\n        or whatever is selected by `channel`.\n    channel : int, optional\n        When reducing a signal to `num_channels` of 1, use this channel,\n        or \'None\' to return the average across all channels.\n    start : float, optional\n        Start position [seconds].\n    stop : float, optional\n        Stop position [seconds].\n    dtype : numpy data type, optional\n        The data is returned with the given dtype. If \'None\', it is returned\n        with its original dtype, otherwise the signal gets rescaled. Integer\n        dtypes use the complete value range, float dtypes the range [-1, +1].\n    replaygain_mode : {None, \'track\',\'album\'}, optional\n        Specify the ReplayGain volume-levelling mode (None to disable).\n    replaygain_preamp : float, optional\n        ReplayGain preamp volume change level (in dB).\n\n    Returns\n    -------\n    signal : numpy array\n        Audio signal.\n    sample_rate : int\n        Sample rate of the signal [Hz].\n\n    Notes\n    -----\n    For wave files, the `start` and `stop` positions are rounded to the closest\n    sample; the sample corresponding to the `stop` value is not returned, thus\n    consecutive segment starting with the previous `stop` can be concatenated\n    to obtain the original signal without gaps or overlaps.\n    For all other audio files, this can not be guaranteed.\n\n    """"""\n    # try reading as a wave file\n    error = ""All attempts to load audio file %r failed."" % filename\n    try:\n        return load_wave_file(filename, sample_rate=sample_rate,\n                              num_channels=num_channels, channel=channel,\n                              start=start, stop=stop, dtype=dtype)\n    except ValueError:\n        pass\n    # not a wave file (or other sample rate requested), try ffmpeg\n    try:\n        return load_ffmpeg_file(filename, sample_rate=sample_rate,\n                                num_channels=num_channels, channel=channel,\n                                start=start, stop=stop, dtype=dtype,\n                                replaygain_mode=replaygain_mode,\n                                replaygain_preamp=replaygain_preamp)\n    except OSError as e:\n        # if it\'s not a file not found error, raise it!\n        if e.errno != errno.ENOENT:\n            raise\n\n        # ffmpeg is not present, try avconv\n        try:\n            return load_ffmpeg_file(filename, sample_rate=sample_rate,\n                                    num_channels=num_channels, channel=channel,\n                                    start=start, stop=stop, dtype=dtype,\n                                    cmd_decode=\'avconv\', cmd_probe=\'avprobe\',\n                                    replaygain_mode=replaygain_mode,\n                                    replaygain_preamp=replaygain_preamp)\n        except OSError as e:\n            if e.errno == errno.ENOENT:\n                error += "" Try installing ffmpeg (or avconv on Ubuntu Linux).""\n            else:\n                raise\n        except subprocess.CalledProcessError:\n            pass\n    except subprocess.CalledProcessError:\n        pass\n    raise LoadAudioFileError(error)\n'"
madmom/io/midi.py,11,"b'# encoding: utf-8\n# pylint: disable=no-member\n""""""\nThis module contains MIDI functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\nimport mido\nimport warnings\n\nDEFAULT_TEMPO = 500000  # microseconds per quarter note (i.e. 120 bpm in 4/4)\nDEFAULT_TICKS_PER_BEAT = 480  # ticks per quarter note\nDEFAULT_TIME_SIGNATURE = (4, 4)\n\n\n# TODO: remove these unit conversion functions after upstream PR is merged\n#       https://github.com/olemb/mido/pull/114\ndef tick2second(tick, ticks_per_beat=DEFAULT_TICKS_PER_BEAT,\n                tempo=DEFAULT_TEMPO):\n    """"""\n    Convert absolute time in ticks to seconds.\n\n    Returns absolute time in seconds for a chosen MIDI file time resolution\n    (ticks/pulses per quarter note, also called PPQN) and tempo (microseconds\n    per quarter note).\n\n    """"""\n    # Note: both tempo (microseconds) and ticks are per quarter note\n    #       thus the time signature is irrelevant\n    scale = tempo * 1e-6 / ticks_per_beat\n    return tick * scale\n\n\ndef second2tick(second, ticks_per_beat=DEFAULT_TICKS_PER_BEAT,\n                tempo=DEFAULT_TEMPO):\n    """"""\n    Convert absolute time in seconds to ticks.\n\n    Returns absolute time in ticks for a chosen MIDI file time resolution\n    (ticks/pulses per quarter note, also called PPQN) and tempo (microseconds\n    per quarter note).\n\n    """"""\n    # Note: both tempo (microseconds) and ticks are per quarter note\n    #       thus the time signature is irrelevant\n    scale = tempo * 1e-6 / ticks_per_beat\n    return int(round(second / scale))\n\n\ndef bpm2tempo(bpm, time_signature=DEFAULT_TIME_SIGNATURE):\n    """"""\n    Convert BPM (beats per minute) to MIDI file tempo (microseconds per\n    quarter note).\n\n    Depending on the chosen time signature a bar contains a different number of\n    beats. These beats are multiples/fractions of a quarter note, thus the\n    returned BPM depend on the time signature.\n\n    """"""\n    return int(round(60 * 1e6 / bpm * time_signature[1] / 4.))\n\n\ndef tempo2bpm(tempo, time_signature=DEFAULT_TIME_SIGNATURE):\n    """"""\n    Convert MIDI file tempo (microseconds per quarter note) to BPM (beats per\n    minute).\n\n    Depending on the chosen time signature a bar contains a different number of\n    beats. These beats are multiples/fractions of a quarter note, thus the\n    returned tempo depends on the time signature.\n\n    """"""\n    return 60 * 1e6 / tempo * time_signature[1] / 4.\n\n\ndef tick2beat(tick, ticks_per_beat=DEFAULT_TICKS_PER_BEAT,\n              time_signature=DEFAULT_TIME_SIGNATURE):\n    """"""\n    Convert ticks to beats.\n\n    Returns beats for a chosen MIDI file time resolution (ticks/pulses per\n    quarter note, also called PPQN) and time signature.\n\n    """"""\n    return tick / (4. * ticks_per_beat / time_signature[1])\n\n\ndef beat2tick(beat, ticks_per_beat=DEFAULT_TICKS_PER_BEAT,\n              time_signature=DEFAULT_TIME_SIGNATURE):\n    """"""\n    Convert beats to ticks.\n\n    Returns ticks for a chosen MIDI file time resolution (ticks/pulses per\n    quarter note, also called PPQN) and time signature.\n\n    """"""\n    return int(round(beat * 4. * ticks_per_beat / time_signature[1]))\n\n\nclass MIDIFile(mido.MidiFile):\n    """"""\n    MIDI File.\n\n    Parameters\n    ----------\n    filename : str\n        MIDI file name.\n    file_format : int, optional\n        MIDI file format (0, 1, 2).\n    ticks_per_beat : int, optional\n        Resolution (i.e. ticks per quarter note) of the MIDI file.\n    unit : str, optional\n        Unit of all MIDI messages, can be one of the following:\n\n        - \'ticks\', \'t\': use native MIDI ticks as unit,\n        - \'seconds\', \'s\': use seconds as unit,\n        - \'beats\', \'b\' : use beats as unit.\n\n    timing : str, optional\n        Timing of all MIDI messages, can be one of the following:\n\n        - \'absolute\', \'abs\', \'a\': use absolute timing.\n        - \'relative\', \'rel\', \'r\': use relative timing, i.e. delta to\n          previous message.\n\n    Examples\n    --------\n    Create a MIDI file from an array with notes. The format of the note array\n    is: \'onset time\', \'pitch\', \'duration\', \'velocity\', \'channel\'. The last\n    column can be omitted, assuming channel 0.\n\n    >>> notes = np.array([[0, 50, 1, 60], [0.5, 62, 0.5, 90]])\n    >>> m = MIDIFile.from_notes(notes)\n    >>> m  # doctest: +ELLIPSIS\n    <madmom.io.midi.MIDIFile object at 0x...>\n\n    The notes can be accessed as a numpy array in various formats (default is\n    seconds):\n\n    >>> m.notes\n    array([[ 0. , 50. ,  1. , 60. ,  0. ],\n           [ 0.5, 62. ,  0.5, 90. ,  0. ]])\n    >>> m.unit =\'ticks\'\n    >>> m.notes\n    array([[  0.,  50., 960.,  60.,   0.],\n           [480.,  62., 480.,  90.,   0.]])\n    >>> m.unit = \'seconds\'\n    >>> m.notes\n    array([[ 0. , 50. ,  1. , 60. ,  0. ],\n           [ 0.5, 62. ,  0.5, 90. ,  0. ]])\n    >>> m.unit = \'beats\'\n    >>> m.notes\n    array([[ 0., 50.,  2., 60.,  0.],\n           [ 1., 62.,  1., 90.,  0.]])\n\n    >>> m = MIDIFile.from_notes(notes, tempo=60)\n    >>> m.notes\n    array([[ 0. , 50. ,  1. , 60. ,  0. ],\n           [ 0.5, 62. ,  0.5, 90. ,  0. ]])\n    >>> m.unit = \'ticks\'\n    >>> m.notes\n    array([[  0.,  50., 480.,  60.,   0.],\n           [240.,  62., 240.,  90.,   0.]])\n    >>> m.unit = \'beats\'\n    >>> m.notes\n    array([[ 0. , 50. ,  1. , 60. ,  0. ],\n           [ 0.5, 62. ,  0.5, 90. ,  0. ]])\n\n    >>> m = MIDIFile.from_notes(notes, time_signature=(2, 2))\n    >>> m.notes\n    array([[ 0. , 50. ,  1. , 60. ,  0. ],\n           [ 0.5, 62. ,  0.5, 90. ,  0. ]])\n    >>> m.unit = \'ticks\'\n    >>> m.notes\n    array([[   0.,   50., 1920.,   60.,    0.],\n           [ 960.,   62.,  960.,   90.,    0.]])\n    >>> m.unit = \'beats\'\n    >>> m.notes\n    array([[ 0., 50.,  2., 60.,  0.],\n           [ 1., 62.,  1., 90.,  0.]])\n\n    >>> m = MIDIFile.from_notes(notes, tempo=60, time_signature=(2, 2))\n    >>> m.notes\n    array([[ 0. , 50. ,  1. , 60. ,  0. ],\n           [ 0.5, 62. ,  0.5, 90. ,  0. ]])\n    >>> m.unit = \'ticks\'\n    >>> m.notes\n    array([[  0.,  50., 960.,  60.,   0.],\n           [480.,  62., 480.,  90.,   0.]])\n    >>> m.unit = \'beats\'\n    >>> m.notes\n    array([[ 0. , 50. ,  1. , 60. ,  0. ],\n           [ 0.5, 62. ,  0.5, 90. ,  0. ]])\n\n    >>> m = MIDIFile.from_notes(notes, tempo=240, time_signature=(3, 8))\n    >>> m.notes\n    array([[ 0. , 50. ,  1. , 60. ,  0. ],\n           [ 0.5, 62. ,  0.5, 90. ,  0. ]])\n    >>> m.unit = \'ticks\'\n    >>> m.notes\n    array([[  0.,  50., 960.,  60.,   0.],\n           [480.,  62., 480.,  90.,   0.]])\n    >>> m.unit = \'beats\'\n    >>> m.notes\n    array([[ 0., 50.,  4., 60.,  0.],\n           [ 2., 62.,  2., 90.,  0.]])\n\n    """"""\n\n    def __init__(self, filename=None, file_format=0,\n                 ticks_per_beat=DEFAULT_TICKS_PER_BEAT, unit=\'seconds\',\n                 timing=\'absolute\', **kwargs):\n        # instantiate a MIDIFile\n        super(MIDIFile, self).__init__(filename=filename, type=file_format,\n                                       ticks_per_beat=ticks_per_beat, **kwargs)\n        # add attributes for unit conversion\n        self.unit = unit\n        self.timing = timing\n\n    # TODO: remove this method after upstream PR is merged\n    #       https://github.com/olemb/mido/pull/115\n    def __iter__(self):\n        # The tracks of type 2 files are not in sync, so they can\n        # not be played back like this.\n        if self.type == 2:\n            raise TypeError(""can\'t merge tracks in type 2 (asynchronous) file"")\n\n        tempo = DEFAULT_TEMPO\n        time_signature = DEFAULT_TIME_SIGNATURE\n        cum_delta = 0\n        for msg in mido.merge_tracks(self.tracks):\n            # Convert relative message time to desired unit\n            if msg.time > 0:\n                if self.unit.lower() in (\'t\', \'ticks\'):\n                    delta = msg.time\n                elif self.unit.lower() in (\'s\', \'sec\', \'seconds\'):\n                    delta = tick2second(msg.time, self.ticks_per_beat, tempo)\n                elif self.unit.lower() in (\'b\', \'beats\'):\n                    delta = tick2beat(msg.time, self.ticks_per_beat,\n                                      time_signature)\n                else:\n                    raise ValueError(""`unit` must be either \'ticks\', \'t\', ""\n                                     ""\'seconds\', \'s\', \'beats\', \'b\', not %s."" %\n                                     self.unit)\n            else:\n                delta = 0\n            # Convert relative time to absolute values if needed\n            if self.timing.lower() in (\'a\', \'abs\', \'absolute\'):\n                cum_delta += delta\n            elif self.timing.lower() in (\'r\', \'rel\', \'relative\'):\n                cum_delta = delta\n            else:\n                raise ValueError(""`timing` must be either \'relative\', \'rel\', ""\n                                 ""\'r\', or \'absolute\', \'abs\', \'a\', not %s."" %\n                                 self.timing)\n\n            yield msg.copy(time=cum_delta)\n\n            if msg.type == \'set_tempo\':\n                tempo = msg.tempo\n            elif msg.type == \'time_signature\':\n                time_signature = (msg.numerator, msg.denominator)\n\n    def __repr__(self):\n        return object.__repr__(self)\n\n    @property\n    def tempi(self):\n        """"""\n        Tempi (microseconds per quarter note) of the MIDI file.\n\n        Returns\n        -------\n        tempi : numpy array\n            Array with tempi (time, tempo).\n\n        Notes\n        -----\n        The time will be given in the unit set by `unit`.\n\n        """"""\n        # list for all tempi\n        tempi = []\n        # process all events\n        for msg in self:\n            if msg.type == \'set_tempo\':\n                tempi.append((msg.time, msg.tempo))\n        # make sure a tempo is set (and occurs at time 0)\n        if not tempi or tempi[0][0] > 0:\n            tempi.insert(0, (0, DEFAULT_TEMPO))\n        # tempo is given in microseconds per quarter note\n        # TODO: add option to return in BPM\n        return np.asarray(tempi, np.float)\n\n    @property\n    def time_signatures(self):\n        """"""\n        Time signatures of the MIDI file.\n\n        Returns\n        -------\n        time_signatures : numpy array\n            Array with time signatures (time, numerator, denominator).\n\n        Notes\n        -----\n        The time will be given in the unit set by `unit`.\n\n        """"""\n        # list for all time signature\n        signatures = []\n        # process all events\n        for msg in self:\n            if msg.type == \'time_signature\':\n                signatures.append((msg.time, msg.numerator, msg.denominator))\n        # make sure a signatures is set (and occurs at time 0)\n        if not signatures or signatures[0][0] > 0:\n            signatures.insert(0, (0, DEFAULT_TIME_SIGNATURE[0],\n                                  DEFAULT_TIME_SIGNATURE[1]))\n        # return time signatures\n        return np.asarray(signatures, dtype=np.float)\n\n    @property\n    def notes(self):\n        """"""\n        Notes of the MIDI file.\n\n        Returns\n        -------\n        notes : numpy array\n            Array with notes (onset time, pitch, duration, velocity, channel).\n\n        """"""\n        # lists to collect notes and sustain messages\n        notes = []\n        # dictionary for storing the last onset time and velocity for each\n        # individual note (i.e. same pitch and channel)\n        sounding_notes = {}\n\n        # as key for the dict use channel * 128 (max number of pitches) + pitch\n        def note_hash(channel, pitch):\n            """"""Generate a note hash.""""""\n            return channel * 128 + pitch\n\n        # process all events\n        for msg in self:\n            # use only note on or note off events\n            note_on = msg.type == \'note_on\'\n            note_off = msg.type == \'note_off\'\n            if not (note_on or note_off):\n                continue\n            # hash sounding note\n            note = note_hash(msg.channel, msg.note)\n            # start note if it\'s a \'note on\' event with velocity > 0\n            if note_on and msg.velocity > 0:\n                # save the onset time and velocity\n                sounding_notes[note] = (msg.time, msg.velocity)\n            # end note if it\'s a \'note off\' event or \'note on\' with velocity 0\n            elif note_off or (note_on and msg.velocity == 0):\n                if note not in sounding_notes:\n                    warnings.warn(\'ignoring MIDI message %s\' % msg)\n                    continue\n                # append the note to the list\n                notes.append((sounding_notes[note][0], msg.note,\n                              msg.time - sounding_notes[note][0],\n                              sounding_notes[note][1], msg.channel))\n                # remove hash from dict\n                del sounding_notes[note]\n\n        # sort the notes and convert to numpy array\n        return np.asarray(sorted(notes), dtype=np.float)\n\n    @property\n    def sustain_messages(self):\n        """"""\n        Sustain messages of the MIDI file.\n\n        Returns\n        -------\n        sustain_messages : list\n            List with MIDI sustain messages.\n\n        Notes\n        -----\n        If the last sustain message is a \'sustain on\' message (i.e. it has a\n        value >= 64), an artificial sustain message with a value of 0 and the\n        timing of the last MIDI message is appended to the list.\n\n        """"""\n        sustain_msgs = []\n        last_msg_time = None\n        for msg in self:\n            last_msg_time = msg.time\n            # keep track of sustain information\n            if msg.type == \'control_change\' and msg.control == 64:\n                sustain_msgs.append(msg)\n        # if the last sustain message is \'sustain on\', append a fake sustain\n        # message to end sustain with the last note\n        if sustain_msgs and sustain_msgs[-1].value >= 64:\n            msg = sustain_msgs[-1].copy()\n            msg.time = last_msg_time\n            msg.value = 0\n            sustain_msgs.append(msg)\n        return sustain_msgs\n\n    @property\n    def sustained_notes(self):\n        """"""\n        Notes of the MIDI file with applied sustain information.\n\n        Returns\n        -------\n        notes : numpy array\n            Array with notes (onset time, pitch, duration, velocity, channel).\n\n        """"""\n        notes = np.copy(self.notes)\n        # apply sustain information\n        # keep track of sustain start times (channel = key)\n        sustain_starts = {}\n        note_offsets = notes[:, 0] + notes[:, 2]\n        for msg in self.sustain_messages:\n            # remember sustain start\n            if msg.value >= 64:\n                if msg.channel in sustain_starts:\n                    # sustain is ON already, ignoring\n                    continue\n                sustain_starts[msg.channel] = msg.time\n            # expand all notes in this channel until sustain end\n            else:\n                if msg.channel not in sustain_starts:\n                    # sustain is OFF already, ignoring\n                    continue\n                # end all notes with i) offsets between sustain start and end\n                sustained = np.logical_and(\n                    note_offsets >= sustain_starts[msg.channel],\n                    note_offsets <= msg.time)\n                # and ii) same channel\n                sustained = np.logical_and(sustained,\n                                           notes[:, 4] == msg.channel)\n                # update duration of notes (sustain end time - onset time)\n                notes[sustained, 2] = msg.time - notes[sustained, 0]\n                # remove sustain start time for this channel\n                del sustain_starts[msg.channel]\n        # end all notes latest when next note (of same pitch) starts\n        for pitch in np.unique(notes[:, 1]):\n            note_idx = np.nonzero(notes[:, 1] == pitch)[0]\n            max_duration = np.diff(notes[note_idx, 0])\n            notes[note_idx[:-1], 2] = np.minimum(notes[note_idx[:-1], 2],\n                                                 max_duration)\n        # finally return notes\n        return notes\n\n    @classmethod\n    def from_notes(cls, notes, unit=\'seconds\', tempo=DEFAULT_TEMPO,\n                   time_signature=DEFAULT_TIME_SIGNATURE,\n                   ticks_per_beat=DEFAULT_TICKS_PER_BEAT):\n        """"""\n        Create a MIDIFile from the given notes.\n\n        Parameters\n        ----------\n        notes : numpy array\n            Array with notes, one per row. The columns are defined as:\n            (onset time, pitch, duration, velocity, [channel]).\n        unit : str, optional\n            Unit of `notes`, can be one of the following:\n\n            - \'seconds\', \'s\': use seconds as unit,\n            - \'ticks\', \'t\': use native MIDI ticks as unit,\n            - \'beats\', \'b\' : use beats as unit.\n\n        tempo : float, optional\n            Tempo of the MIDI track, given in bpm or microseconds per quarter\n            note. The unit is determined automatically by the value:\n\n            - `tempo` <= 1000: bpm\n            - `tempo` > 1000: microseconds per quarter note\n\n        time_signature : tuple, optional\n            Time signature of the track, e.g. (4, 4) for 4/4.\n        ticks_per_beat : int, optional\n            Resolution (i.e. ticks per quarter note) of the MIDI file.\n\n        Returns\n        -------\n        :class:`MIDIFile` instance\n            :class:`MIDIFile` instance with all notes collected in one track.\n\n        Notes\n        -----\n        All note events (including the generated tempo and time signature\n        events) are written into a single track (i.e. MIDI file format 0).\n\n        """"""\n        # create new MIDI file\n        midi_file = cls(file_format=0, ticks_per_beat=ticks_per_beat,\n                        unit=unit, timing=\'absolute\')\n        # convert tempo\n        if tempo <= 1000:\n            # convert from bpm to tempo\n            tempo = bpm2tempo(tempo, time_signature)\n        else:\n            # tempo given in ticks per quarter note\n            # i.e. we have to adjust according to the time signature\n            tempo = int(tempo * time_signature[1] / 4)\n        # create new track and add tempo and time signature information\n        track = midi_file.add_track()\n        track.append(mido.MetaMessage(\'set_tempo\', tempo=tempo))\n        track.append(mido.MetaMessage(\'time_signature\',\n                                      numerator=time_signature[0],\n                                      denominator=time_signature[1]))\n        # create note on/off messages with absolute timing\n        messages = []\n        for note in notes:\n            try:\n                onset, pitch, duration, velocity, channel = note\n            except ValueError:\n                onset, pitch, duration, velocity = note\n                channel = 0\n            pitch = int(pitch)\n            velocity = int(velocity)\n            channel = int(channel)\n            offset = onset + duration\n            # create MIDI messages\n            onset = second2tick(onset, ticks_per_beat, tempo)\n            note_on = mido.Message(\'note_on\', time=onset, note=pitch,\n                                   velocity=velocity, channel=channel)\n            offset = second2tick(offset, ticks_per_beat, tempo)\n            note_off = mido.Message(\'note_off\', time=offset, note=pitch,\n                                    channel=channel)\n            # append to list\n            messages.extend([note_on, note_off])\n        # sort them, convert to relative timing and append to track\n        messages.sort(key=lambda msg: msg.time)\n        messages = mido.midifiles.tracks._to_reltime(messages)\n        track.extend(messages)\n        # return MIDI file\n        return midi_file\n\n    def save(self, filename):\n        """"""\n        Save to MIDI file.\n\n        Parameters\n        ----------\n        filename : str or open file handle\n            The MIDI file name.\n\n        """"""\n        from . import open_file\n        # write the MIDI stream\n        with open_file(filename, \'wb\') as f:\n            self._save(f)\n\n\ndef load_midi(filename, sustain=False):\n    """"""\n    Load notes from a MIDI file.\n\n    Parameters\n    ----------\n    filename : str\n        MIDI file.\n    sustain : bool, optional\n        Apply sustain information to the notes.\n\n    Returns\n    -------\n    numpy array\n        Notes (\'onset time\' \'note number\' \'duration\' \'velocity\' \'channel\')\n\n    """"""\n    if sustain:\n        return MIDIFile(filename).sustained_notes\n    return MIDIFile(filename).notes\n\n\ndef write_midi(notes, filename, duration=0.6, velocity=100):\n    """"""\n    Write notes to a MIDI file.\n\n    Parameters\n    ----------\n    notes : numpy array, shape (num_notes, 2)\n        Notes, one per row (column definition see notes).\n    filename : str\n        Output MIDI file.\n    duration : float, optional\n        Note duration if not defined by `notes`.\n    velocity : int, optional\n        Note velocity if not defined by `notes`.\n\n    Returns\n    -------\n    numpy array\n        Notes (including note length, velocity and channel).\n\n    Notes\n    -----\n    The note columns format must be (duration, velocity and channel optional):\n\n    \'onset time\' \'note number\' [\'duration\' [\'velocity\' [\'channel\']]]\n\n    """"""\n    from ..utils import expand_notes\n    # expand the array to have a default duration and velocity\n    notes = expand_notes(notes, duration, velocity)\n    # write the notes to the file and return them\n    MIDIFile.from_notes(notes).save(filename)\n'"
madmom/ml/__init__.py,0,"b'# encoding: utf-8\n""""""\nMachine learning package.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\n# import the submodules\nfrom . import nn, hmm, gmm, crf\n'"
madmom/ml/crf.py,14,"b'# encoding: utf-8\n""""""\nThis module contains an implementation of Conditional Random Fields (CRFs)\n""""""\n# pylint: disable=no-member\n# pylint: disable=invalid-name\nimport numpy as np\n\nfrom ..processors import Processor\n\n\nclass ConditionalRandomField(Processor):\n    """"""\n    Implements a linear-chain Conditional Random Field using a\n    matrix-based definition:\n\n    .. math::\n        P(Y|X) = exp[E(Y,X)] / \xce\xa3_{Y\'}[E(Y\', X)]\n\n        E(Y,X) = \xce\xa3_{i=1}^{N} [y_{n-1}^T  A  y_n + y_n^T c + x_n^T W y_n ] +\n                y_0^T \xcf\x80 + y_N^T \xcf\x84,\n\n    where Y is a sequence of labels in one-hot encoding and X are the observed\n    features.\n\n    Parameters\n    ----------\n    initial : numpy array\n        Initial potential (\xcf\x80) of the CRF. Also defines the number of states.\n    final : numpy array\n        Potential (\xcf\x84) of the last variable of the CRF.\n    bias : numpy array\n        Label bias potential (c).\n    transition : numpy array\n        Matrix defining the transition potentials (A), where the rows are the\n        \'from\' dimension, and columns the \'to\' dimension.\n    observation : numpy array\n        Matrix defining the observation potentials (W), where the rows are the\n        \'observation\' dimension, and columns the \'state\' dimension.\n\n    Examples\n    --------\n    Create a CRF that emulates a simple hidden markov model. This means that\n    the bias and final potential will be constant and thus have no effect\n    on the predictions.\n\n    >>> eta = np.spacing(1)  # for numerical stability\n    >>> initial = np.log(np.array([0.7, 0.2, 0.1]) + eta)\n    >>> final = np.ones(3)\n    >>> bias = np.ones(3)\n    >>> transition = np.log(np.array([[0.6, 0.2, 0.2],\n    ...                               [0.1, 0.7, 0.2],\n    ...                               [0.1, 0.1, 0.8]]) + eta)\n    >>> observation = np.log(np.array([[0.9, 0.5, 0.1],\n    ...                                [0.1, 0.5, 0.1]]) + eta)\n    >>> crf = ConditionalRandomField(initial, final, bias,\n    ...                              transition, observation)\n    >>> crf  # doctest: +ELLIPSIS\n    <madmom.ml.crf.ConditionalRandomField object at 0x...>\n\n    We can now decode the most probable state sequence given an observation\n    sequence. Since we are emulating a discrete HMM, the observation sequence\n    needs to be observation ids in one-hot encoding.\n\n    The following observation sequence corresponds to ""0, 0, 1, 0, 1, 1"":\n\n    >>> obs = np.array([[1, 0], [1, 0], [0, 1], [1, 0], [0, 1], [0, 1]])\n\n    Now we can find the most likely state sequence:\n\n    >>> crf.process(obs)\n    array([0, 0, 1, 1, 1, 1], dtype=uint32)\n\n    """"""\n\n    def __init__(self, initial, final, bias, transition, observation):\n        self.pi = initial\n        self.tau = final\n        self.c = bias\n        self.A = transition\n        self.W = observation\n\n    def process(self, observations, **kwargs):\n        """"""\n        Determine the most probable configuration of Y given the state\n        sequence x:\n\n        .. math::\n            y^* = argmax_y P(Y=y|X=x)\n\n        Parameters\n        ----------\n        observations : numpy array\n            Observations (x) to decode the most probable state sequence for.\n\n        Returns\n        -------\n        y_star : numpy array\n            Most probable state sequence.\n        """"""\n        num_observations = len(observations)\n        num_states = len(self.pi)\n        bt_pointers = np.empty((num_observations, num_states), dtype=np.uint32)\n        viterbi = self.pi.copy()\n        y_star = np.empty(num_observations, dtype=np.uint32)\n\n        for i in range(num_observations):\n            all_trans = self.A + viterbi[:, np.newaxis]\n            best_trans = np.max(all_trans, axis=0)\n            bt_pointers[i] = np.argmax(all_trans, axis=0)\n            viterbi = self.c + np.dot(observations[i], self.W) + best_trans\n\n        viterbi += self.tau\n\n        y_star[-1] = np.argmax(viterbi)\n        for i in range(len(y_star) - 1)[::-1]:\n            y_star[i] = bt_pointers[i + 1, y_star[i + 1]]\n\n        return y_star\n'"
madmom/ml/gmm.py,25,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains functionality needed for fitting and scoring Gaussian\nMixture Models (GMMs) (needed e.g. in madmom.features.beats).\n\nThe needed functionality is taken from sklearn.mixture.GMM which is released\nunder the BSD license and was written by these authors:\n\n- Ron Weiss <ronweiss@gmail.com>\n- Fabian Pedregosa <fabian.pedregosa@inria.fr>\n- Bertrand Thirion <bertrand.thirion@inria.fr>\n\nThis version works with sklearn v0.16 (and hopefully onwards).\nAll commits until 0650d5502e01e6b4245ce99729fc8e7a71aacff3 are incorporated.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\nfrom scipy import linalg\n\n\n# the following code is copied from sklearn\ndef logsumexp(arr, axis=0):\n    """"""\n    Computes the sum of arr assuming arr is in the log domain.\n\n    Parameters\n    ----------\n    arr : numpy array\n        Input data [log domain].\n    axis : int, optional\n        Axis to operate on.\n\n    Returns\n    -------\n    numpy array\n        log(sum(exp(arr))) while minimizing the possibility of over/underflow.\n\n    Notes\n    -----\n    Function copied from sklearn.utils.extmath.\n\n    """"""\n    arr = np.rollaxis(arr, axis)\n    # Use the max to normalize, as with the log this is what accumulates\n    # the less errors\n    vmax = arr.max(axis=0)\n    out = np.log(np.sum(np.exp(arr - vmax), axis=0))\n    out += vmax\n    return out\n\n\ndef pinvh(a, cond=None, rcond=None, lower=True):\n    """"""\n    Compute the (Moore-Penrose) pseudo-inverse of a hermetian matrix.\n\n    Calculate a generalized inverse of a symmetric matrix using its\n    eigenvalue decomposition and including all \'large\' eigenvalues.\n\n    Parameters\n    ----------\n    a : array, shape (N, N)\n        Real symmetric or complex hermetian matrix to be pseudo-inverted.\n    cond, rcond : float or None\n        Cutoff for \'small\' eigenvalues. Singular values smaller than rcond *\n        largest_eigenvalue are considered zero.\n        If None or -1, suitable machine precision is used.\n    lower : boolean\n        Whether the pertinent array data is taken from the lower or upper\n        triangle of `a`.\n\n    Returns\n    -------\n    B : array, shape (N, N)\n\n    Raises\n    ------\n    LinAlgError\n        If eigenvalue does not converge\n\n    Notes\n    -----\n    Function copied from sklearn.utils.extmath.\n\n    """"""\n    a = np.asarray_chkfinite(a)\n    s, u = linalg.eigh(a, lower=lower)\n\n    if rcond is not None:\n        cond = rcond\n    if cond in [None, -1]:\n        t = u.dtype.char.lower()\n        factor = {\'f\': 1E3, \'d\': 1E6}\n        cond = factor[t] * np.finfo(t).eps\n\n    # unlike svd case, eigh can lead to negative eigenvalues\n    above_cutoff = (abs(s) > cond * np.max(abs(s)))\n    psigma_diag = np.zeros_like(s)\n    psigma_diag[above_cutoff] = 1.0 / s[above_cutoff]\n\n    return np.dot(u * psigma_diag, np.conjugate(u).T)\n\n\ndef log_multivariate_normal_density(x, means, covars, covariance_type=\'diag\'):\n    """"""\n    Compute the log probability under a multivariate Gaussian distribution.\n\n    Parameters\n    ----------\n    x : array_like, shape (n_samples, n_features)\n        List of n_features-dimensional data points.  Each row corresponds to a\n        single data point.\n    means : array_like, shape (n_components, n_features)\n        List of n_features-dimensional mean vectors for n_components Gaussians.\n        Each row corresponds to a single mean vector.\n    covars : array_like\n        List of n_components covariance parameters for each Gaussian. The shape\n        depends on `covariance_type`:\n\n        - (n_components, n_features)             if \'spherical\',\n        - (n_features, n_features)               if \'tied\',\n        - (n_components, n_features)             if \'diag\',\n        - (n_components, n_features, n_features) if \'full\'.\n\n    covariance_type : {\'diag\', \'spherical\', \'tied\', \'full\'}\n        Type of the covariance parameters. Defaults to \'diag\'.\n\n    Returns\n    -------\n    lpr : array_like, shape (n_samples, n_components)\n        Array containing the log probabilities of each data point in `x`\n        under each of the n_components multivariate Gaussian distributions.\n\n    """"""\n    log_multivariate_normal_density_dict = {\n        \'spherical\': _log_multivariate_normal_density_spherical,\n        \'tied\': _log_multivariate_normal_density_tied,\n        \'diag\': _log_multivariate_normal_density_diag,\n        \'full\': _log_multivariate_normal_density_full}\n    return log_multivariate_normal_density_dict[covariance_type](\n        x, means, covars)\n\n\ndef _log_multivariate_normal_density_diag(x, means, covars):\n    """"""Compute Gaussian log-density at x for a diagonal model.""""""\n    _, n_dim = x.shape\n    lpr = -0.5 * (n_dim * np.log(2 * np.pi) + np.sum(np.log(covars), 1) +\n                  np.sum((means ** 2) / covars, 1) -\n                  2 * np.dot(x, (means / covars).T) +\n                  np.dot(x ** 2, (1.0 / covars).T))\n    return lpr\n\n\ndef _log_multivariate_normal_density_spherical(x, means, covars):\n    """"""Compute Gaussian log-density at x for a spherical model.""""""\n    cv = covars.copy()\n    if covars.ndim == 1:\n        cv = cv[:, np.newaxis]\n    if covars.shape[1] == 1:\n        cv = np.tile(cv, (1, x.shape[-1]))\n    return _log_multivariate_normal_density_diag(x, means, cv)\n\n\ndef _log_multivariate_normal_density_tied(x, means, covars):\n    """"""Compute Gaussian log-density at X for a tied model""""""\n    cv = np.tile(covars, (means.shape[0], 1, 1))\n    return _log_multivariate_normal_density_full(x, means, cv)\n\n\ndef _log_multivariate_normal_density_full(x, means, covars, min_covar=1.e-7):\n    """"""Log probability for full covariance matrices.""""""\n    n_samples, n_dim = x.shape\n    nmix = len(means)\n    log_prob = np.empty((n_samples, nmix))\n    for c, (mu, cv) in enumerate(zip(means, covars)):\n        try:\n            cv_chol = linalg.cholesky(cv, lower=True)\n        except linalg.LinAlgError:\n            # The model is most probably stuck in a component with too\n            # few observations, we need to reinitialize this components\n            try:\n                cv_chol = linalg.cholesky(cv + min_covar * np.eye(n_dim),\n                                          lower=True)\n            except linalg.LinAlgError:\n                raise ValueError(""\'covars\' must be symmetric, ""\n                                 ""positive-definite"")\n\n        cv_log_det = 2 * np.sum(np.log(np.diagonal(cv_chol)))\n        cv_sol = linalg.solve_triangular(cv_chol, (x - mu).T, lower=True).T\n        log_prob[:, c] = - .5 * (np.sum(cv_sol ** 2, axis=1) +\n                                 n_dim * np.log(2 * np.pi) + cv_log_det)\n\n    return log_prob\n\n\n# provide a basic GMM implementation which has the score() method implemented\nclass GMM(object):\n    """"""\n    Gaussian Mixture Model\n\n    Representation of a Gaussian mixture model probability distribution.\n    This class allows for easy evaluation of, sampling from, and\n    maximum-likelihood estimation of the parameters of a GMM distribution.\n\n    Initializes parameters such that every mixture component has zero\n    mean and identity covariance.\n\n    Parameters\n    ----------\n    n_components : int, optional\n        Number of mixture components. Defaults to 1.\n    covariance_type : {\'diag\', \'spherical\', \'tied\', \'full\'}\n        String describing the type of covariance parameters to\n        use. Defaults to \'diag\'.\n\n    Attributes\n    ----------\n    `weights_` : array, shape (n_components,)\n        This attribute stores the mixing weights for each mixture component.\n    `means_` : array, shape (n_components, n_features)\n        Mean parameters for each mixture component.\n    `covars_` : array\n        Covariance parameters for each mixture component. The shape\n        depends on `covariance_type`.::\n\n        - (n_components, n_features)             if \'spherical\',\n        - (n_features, n_features)               if \'tied\',\n        - (n_components, n_features)             if \'diag\',\n        - (n_components, n_features, n_features) if \'full\'.\n\n    `converged_` : bool\n        True when convergence was reached in fit(), False otherwise.\n\n    See Also\n    --------\n    sklearn.mixture.GMM\n\n    """"""\n\n    def __init__(self, n_components=1, covariance_type=\'full\'):\n\n        if covariance_type not in [\'spherical\', \'tied\', \'diag\', \'full\']:\n            raise ValueError(\'Invalid value for covariance_type: %s\' %\n                             covariance_type)\n        # save parameters\n        self.n_components = n_components\n        self.covariance_type = covariance_type\n        # init variables\n        self.weights = np.ones(self.n_components) / self.n_components\n        self.means = None\n        self.covars = None\n\n    def __setstate__(self, state):\n        # TODO: old models have underscores at some variable names, thus rename\n        #       them; remove this unpickling code after updating all models\n        try:\n            import warnings\n            warnings.warn(\'Please update your GMM models by loading them and \'\n                          \'saving them again. Loading old models will not \'\n                          \'work from version 0.16 onwards.\')\n            state[\'weights\'] = state.pop(\'weights_\')\n            state[\'means\'] = state.pop(\'means_\')\n            state[\'covars\'] = state.pop(\'covars_\')\n        except KeyError:\n            pass\n        # restore pickled instance attributes\n        self.__dict__.update(state)\n\n    def score_samples(self, x):\n        """"""\n        Return the per-sample likelihood of the data under the model.\n\n        Compute the log probability of x under the model and\n        return the posterior distribution (responsibilities) of each\n        mixture component for each element of x.\n\n        Parameters\n        ----------\n        x: array_like, shape (n_samples, n_features)\n            List of n_features-dimensional data points. Each row corresponds\n            to a single data point.\n\n        Returns\n        -------\n        log_prob : array_like, shape (n_samples,)\n            Log probabilities of each data point in `x`.\n\n        responsibilities : array_like, shape (n_samples, n_components)\n            Posterior probabilities of each mixture component for each\n            observation.\n\n        """"""\n        x = np.asarray(x)\n        if x.ndim == 1:\n            x = x[:, np.newaxis]\n        if x.size == 0:\n            return np.array([]), np.empty((0, self.n_components))\n        if x.shape[1] != self.means.shape[1]:\n            raise ValueError(\'The shape of x is not compatible with self\')\n\n        lpr = (log_multivariate_normal_density(x, self.means, self.covars,\n                                               self.covariance_type) +\n               np.log(self.weights))\n        log_prob = logsumexp(lpr, axis=1)\n        responsibilities = np.exp(lpr - log_prob[:, np.newaxis])\n        return log_prob, responsibilities\n\n    def score(self, x):\n        """"""\n        Compute the log probability under the model.\n\n        Parameters\n        ----------\n        x : array_like, shape (n_samples, n_features)\n            List of n_features-dimensional data points.  Each row\n            corresponds to a single data point.\n\n        Returns\n        -------\n        log_prob : array_like, shape (n_samples,)\n            Log probabilities of each data point in `x`.\n\n        """"""\n        log_prob, _ = self.score_samples(x)\n        return log_prob\n\n    def fit(self, x, random_state=None, tol=1e-3, min_covar=1e-3,\n            n_iter=100, n_init=1, params=\'wmc\', init_params=\'wmc\'):\n        """"""\n        Estimate model parameters with the expectation-maximization algorithm.\n\n        A initialization step is performed before entering the em\n        algorithm. If you want to avoid this step, set the keyword\n        argument init_params to the empty string \'\' when creating the\n        GMM object. Likewise, if you would like just to do an\n        initialization, set n_iter=0.\n\n        Parameters\n        ----------\n        x : array_like, shape (n, n_features)\n            List of n_features-dimensional data points.  Each row corresponds\n            to a single data point.\n        random_state: RandomState or an int seed (0 by default)\n            A random number generator instance.\n        min_covar : float, optional\n            Floor on the diagonal of the covariance matrix to prevent\n            overfitting.\n        tol : float, optional\n            Convergence threshold. EM iterations will stop when average\n            gain in log-likelihood is below this threshold.\n        n_iter : int, optional\n            Number of EM iterations to perform.\n        n_init : int, optional\n            Number of initializations to perform, the best results is kept.\n        params : str, optional\n            Controls which parameters are updated in the training process.\n            Can contain any combination of \'w\' for weights, \'m\' for means,\n            and \'c\' for covars.\n        init_params : str, optional\n            Controls which parameters are updated in the initialization\n            process.  Can contain any combination of \'w\' for weights,\n            \'m\' for means, and \'c\' for covars.\n\n        """"""\n        import sklearn.mixture\n        # first initialise a sklearn.mixture.GMM object\n        gmm = sklearn.mixture.GMM(n_components=self.n_components,\n                                  covariance_type=self.covariance_type,\n                                  random_state=random_state, tol=tol,\n                                  min_covar=min_covar, n_iter=n_iter,\n                                  n_init=n_init, params=params,\n                                  init_params=init_params)\n        # fit this GMM\n        gmm.fit(x)\n        # copy the needed information\n        self.covars = gmm.covars_\n        self.means = gmm.means_\n        self.weights = gmm.weights_\n        # and return self\n        return self\n'"
madmom/utils/__init__.py,27,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n# pylint: disable=wrong-import-position\n""""""\nUtility package.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport io\nimport argparse\nimport contextlib\n\nimport numpy as np\n\n\n# Python 2/3 string compatibility (like six does it)\ntry:\n    string_types = basestring\n    integer_types = (int, long, np.integer)\nexcept NameError:\n    string_types = str\n    integer_types = (int, np.integer)\n\n\n# Python 2/3 file compatibility\ntry:\n    file_types = (io.IOBase, file)\nexcept NameError:\n    file_types = io.IOBase\n\n\n# decorator to suppress warnings\ndef suppress_warnings(function):\n    """"""\n    Decorate the given function to suppress any warnings.\n\n    Parameters\n    ----------\n    function : function\n        Function to be decorated.\n\n    Returns\n    -------\n    decorated function\n        Decorated function.\n\n    """"""\n    # needed to preserve docstring of the decorated function\n    from functools import wraps\n\n    @wraps(function)\n    def decorator_function(*args, **kwargs):\n        """"""\n        Decorator function to suppress warnings.\n\n        Parameters\n        ----------\n        args : arguments, optional\n            Arguments passed to function to be decorated.\n        kwargs : keyword arguments, optional\n            Keyword arguments passed to function to be decorated.\n\n        Returns\n        -------\n        decorated function\n            Decorated function.\n\n        """"""\n        import warnings\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"")\n            return function(*args, **kwargs)\n\n    return decorator_function\n\n\n# file handling routines\ndef filter_files(files, suffix):\n    """"""\n    Filter the list to contain only files matching the given `suffix`.\n\n    Parameters\n    ----------\n    files : list\n        List of files to be filtered.\n    suffix : str\n        Return only files matching this suffix.\n\n    Returns\n    -------\n    list\n        List of files.\n\n    """"""\n    import fnmatch\n    # make sure files is a list\n    if not isinstance(files, list):\n        files = [files]\n    # no suffix given, return the list unaltered\n    if suffix is None:\n        return files\n    # filter the files with the given suffix\n    file_list = []\n    if isinstance(suffix, list):\n        # a list of suffices is given\n        for s in suffix:\n            file_list.extend(fnmatch.filter(files, ""*%s"" % s))\n    else:\n        # a single suffix is given\n        file_list.extend(fnmatch.filter(files, ""*%s"" % suffix))\n    # return the filtered list\n    return file_list\n\n\ndef search_path(path, recursion_depth=0):\n    """"""\n    Returns a list of files in a directory (recursively).\n\n    Parameters\n    ----------\n    path : str or list\n        Directory to be searched.\n    recursion_depth : int, optional\n        Recursively search sub-directories up to this depth.\n\n    Returns\n    -------\n    list\n        List of files.\n\n    """"""\n    # adapted from http://stackoverflow.com/a/234329\n    import os\n    # remove the rightmost path separator (needed for recursion depth count)\n    path = path.rstrip(os.path.sep)\n    # we can only handle directories\n    if not os.path.isdir(path):\n        raise IOError(""%s is not a directory."" % path)\n    # files to be returned\n    file_list = []\n    # keep track of the initial recursion depth\n    initial_depth = path.count(os.path.sep)\n    for root, dirs, files in os.walk(path):\n        # add all files of this directory to the list\n        for f in files:\n            file_list.append(os.path.join(root, f))\n        # remove all sub directories exceeding the wanted recursion depth\n        if initial_depth + recursion_depth <= root.count(os.path.sep):\n            del dirs[:]\n    # return the sorted file list\n    return sorted(file_list)\n\n\ndef search_files(files, suffix=None, recursion_depth=0):\n    """"""\n    Returns the files matching the given `suffix`.\n\n    Parameters\n    ----------\n    files : str or list\n        File, path or a list thereof to be searched / filtered.\n    suffix : str, optional\n        Return only files matching this suffix.\n    recursion_depth : int, optional\n        Recursively search sub-directories up to this depth.\n\n    Returns\n    -------\n    list\n        List of files.\n\n    Notes\n    -----\n    The list of returned files is sorted.\n\n    """"""\n    import os\n    file_list = []\n    # determine the files\n    if isinstance(files, list):\n        # a list is given, recursively call the function on each element\n        for f in files:\n            file_list.extend(search_files(f))\n    elif os.path.isdir(files):\n        # add all files in the given path (up to the given recursion depth)\n        file_list.extend(search_path(files, recursion_depth))\n    elif os.path.isfile(files):\n        # add the given file\n        file_list.append(files)\n    else:\n        raise IOError(""%s does not exist."" % files)\n    # filter with the given suffix\n    if suffix is not None:\n        file_list = filter_files(file_list, suffix)\n    # remove duplicates\n    file_list = list(set(file_list))\n    # return the sorted file list\n    return sorted(file_list)\n\n\ndef strip_suffix(filename, suffix=None):\n    """"""\n    Strip off the suffix of the given filename or string.\n\n    Parameters\n    ----------\n    filename : str\n        Filename or string to strip.\n    suffix : str, optional\n        Suffix to be stripped off (e.g. \'.txt\' including the dot).\n\n    Returns\n    -------\n    str\n        Filename or string without suffix.\n\n    """"""\n    if suffix is not None and filename.endswith(suffix):\n        return filename[:-len(suffix)]\n    return filename\n\n\ndef match_file(filename, match_list, suffix=None, match_suffix=None,\n               match_exactly=True):\n    """"""\n    Match a filename or string against a list of other filenames or strings.\n\n    Parameters\n    ----------\n    filename : str\n        Filename or string to match.\n    match_list : list\n        Match to this list of filenames or strings.\n    suffix : str, optional\n        Suffix of `filename` to be ignored.\n    match_suffix : str, optional\n        Match only files from `match_list` with this suffix.\n    match_exactly : bool, optional\n        Matches must be exact, i.e. have the same base name.\n\n    Returns\n    -------\n    list\n        List of matched files.\n\n    Notes\n    -----\n    Asterisks ""*"" can be used to match any string or suffix.\n\n    """"""\n    import os\n    import fnmatch\n\n    # get the base name without the path\n    basename = os.path.basename(strip_suffix(filename, suffix))\n    # init return list\n    matches = []\n    # look for files with the same base name in the files_list\n    if match_suffix is not None:\n        pattern = ""*%s*%s"" % (basename, match_suffix)\n    else:\n        pattern = ""*%s"" % basename\n    for match in fnmatch.filter(match_list, pattern):\n        # base names must match exactly if indicated\n        if (not match_exactly) or (basename == os.path.basename(\n                strip_suffix(match, match_suffix))):\n            matches.append(match)\n    # return the matches\n    return matches\n\n\ndef combine_events(events, delta, combine=\'mean\'):\n    """"""\n    Combine all events within a certain range.\n\n    Parameters\n    ----------\n    events : list or numpy array\n        Events to be combined.\n    delta : float\n        Combination delta. All events within this `delta` are combined.\n    combine : {\'mean\', \'left\', \'right\'}\n        How to combine two adjacent events:\n\n            - \'mean\': replace by the mean of the two events\n            - \'left\': replace by the left of the two events\n            - \'right\': replace by the right of the two events\n\n    Returns\n    -------\n    numpy array\n        Combined events.\n\n    """"""\n    # add a small value to delta, otherwise we end up in floating point hell\n    delta += 1e-12\n    # return immediately if possible\n    if len(events) <= 1:\n        return events\n    # convert to numpy array or create a copy if needed\n    events = np.array(events, dtype=np.float)\n    # can handle only 1D events\n    if events.ndim > 1:\n        raise ValueError(\'only 1-dimensional events supported.\')\n    # set start position\n    idx = 0\n    # get first event\n    left = events[idx]\n    # iterate over all remaining events\n    for right in events[1:]:\n        if right - left <= delta:\n            # combine the two events\n            if combine == \'mean\':\n                left = events[idx] = 0.5 * (right + left)\n            elif combine == \'left\':\n                left = events[idx] = left\n            elif combine == \'right\':\n                left = events[idx] = right\n            else:\n                raise ValueError(""don\'t know how to combine two events with ""\n                                 ""%s"" % combine)\n        else:\n            # move forward\n            idx += 1\n            left = events[idx] = right\n    # return the combined events\n    return events[:idx + 1]\n\n\ndef quantize_events(events, fps, length=None, shift=None):\n    """"""\n    Quantize the events with the given resolution.\n\n    Parameters\n    ----------\n    events : list or numpy array\n        Events to be quantized.\n    fps : float\n        Quantize with `fps` frames per second.\n    length : int, optional\n        Length of the returned array. If \'None\', the length will be set\n        according to the latest event.\n    shift : float, optional\n        Shift the events by `shift` seconds before quantization.\n\n    Returns\n    -------\n    numpy array\n        Quantized events.\n\n    """"""\n    # convert to numpy array or create a copy if needed\n    events = np.array(events, dtype=np.float)\n    # can handle only 1D events\n    if events.ndim != 1:\n        raise ValueError(\'only 1-dimensional events supported.\')\n    # shift all events if needed\n    if shift is not None:\n        import warnings\n        warnings.warn(\'`shift` parameter is deprecated as of version 0.16 and \'\n                      \'will be removed in version 0.18. Please shift the \'\n                      \'events manually before calling this function.\')\n        events += shift\n    # determine the length for the quantized array\n    if length is None:\n        # set the length to be long enough to cover all events\n        length = int(round(np.max(events) * float(fps))) + 1\n    else:\n        # else filter all events which do not fit in the array\n        # since we apply rounding later, we need to subtract half a bin\n        events = events[:np.searchsorted(events, float(length - 0.5) / fps)]\n    # init array\n    quantized = np.zeros(length)\n    # quantize\n    events *= fps\n    # indices to be set in the quantized array\n    idx = np.unique(np.round(events).astype(np.int))\n    quantized[idx] = 1\n    # return the quantized array\n    return quantized\n\n\ndef quantize_notes(notes, fps, length=None, num_pitches=None, velocity=None):\n    """"""\n    Quantize the notes with the given resolution.\n\n    Create a sparse 2D array with rows corresponding to points in time\n    (according to `fps` and `length`), and columns to note pitches (according\n    to `num_pitches`). The values of the array correspond to the velocity of a\n    sounding note at a given point in time (based on the note pitch, onset,\n    duration and velocity). If no values for `length` and `num_pitches` are\n    given, they are inferred from `notes`.\n\n    Parameters\n    ----------\n    notes : 2D numpy array\n        Notes to be quantized. Expected columns:\n        \'note_time\' \'note_number\' [\'duration\' [\'velocity\']]\n        If `notes` contains no \'duration\' column, only the frame of the\n        onset will be set. If `notes` has no velocity column, a velocity\n        of 1 is assumed.\n    fps : float\n        Quantize with `fps` frames per second.\n    length : int, optional\n        Length of the returned array. If \'None\', the length will be set\n        according to the latest sounding note.\n    num_pitches : int, optional\n        Number of pitches of the returned array. If \'None\', the number of\n        pitches will be based on the highest pitch in the `notes` array.\n    velocity : float, optional\n        Use this velocity for all quantized notes. If set, the last column of\n        `notes` (if present) will be ignored.\n\n    Returns\n    -------\n    numpy array\n        Quantized notes.\n\n    """"""\n    # convert to numpy array or create a copy if needed\n    notes = np.array(np.array(notes).T, dtype=np.float, ndmin=2).T\n    # check supported dims and shapes\n    if notes.ndim != 2:\n        raise ValueError(\'only 2-dimensional notes supported.\')\n    if notes.shape[1] < 2:\n        raise ValueError(\'notes must have at least 2 columns.\')\n    # split the notes into columns\n    note_onsets = notes[:, 0]\n    note_numbers = notes[:, 1].astype(np.int)\n    note_offsets = np.copy(note_onsets)\n    if notes.shape[1] > 2:\n        note_offsets += notes[:, 2]\n    if notes.shape[1] > 3 and velocity is None:\n        note_velocities = notes[:, 3]\n    else:\n        velocity = velocity or 1\n        note_velocities = np.ones(len(notes)) * velocity\n    # determine length and width of quantized array\n    if length is None:\n        # set the length to be long enough to cover all notes\n        length = int(round(np.max(note_offsets) * float(fps))) + 1\n    if num_pitches is None:\n        num_pitches = int(np.max(note_numbers)) + 1\n    # init array\n    quantized = np.zeros((length, num_pitches))\n    # quantize onsets and offsets\n    note_onsets = np.round((note_onsets * fps)).astype(np.int)\n    note_offsets = np.round((note_offsets * fps)).astype(np.int) + 1\n    # iterate over all notes\n    for n, note in enumerate(notes):\n        # use only the notes which fit in the array and note number >= 0\n        if num_pitches > note_numbers[n] >= 0:\n            quantized[note_onsets[n]:note_offsets[n], note_numbers[n]] = \\\n                note_velocities[n]\n    # return quantized array\n    return quantized\n\n\ndef expand_notes(notes, duration=0.6, velocity=100):\n    """"""\n    Expand notes to include duration and velocity.\n\n    The given duration and velocity is only used if they are not set already.\n\n    Parameters\n    ----------\n    notes : numpy array, shape (num_notes, 2)\n        Notes, one per row. Expected columns:\n        \'note_time\' \'note_number\' [\'duration\' [\'velocity\']]\n    duration : float, optional\n        Note duration if not defined by `notes`.\n    velocity : int, optional\n        Note velocity if not defined by `notes`.\n\n    Returns\n    -------\n    notes : numpy array, shape (num_notes, 2)\n        Notes (including note duration and velocity).\n\n    """"""\n    notes = np.array(notes, ndmin=2)\n    rows, columns = notes.shape\n    if columns >= 4:\n        return notes\n    elif columns == 3:\n        new_columns = np.ones((rows, 1)) * velocity\n    elif columns == 2:\n        new_columns = np.ones((rows, 2)) * velocity\n        new_columns[:, 0] = duration\n    else:\n        raise ValueError(\'unable to handle `notes` with %d columns\' % columns)\n    # return the notes\n    notes = np.hstack((notes, new_columns))\n    return notes\n\n\n# argparse action to set and overwrite default lists\nclass OverrideDefaultListAction(argparse.Action):\n    """"""\n    OverrideDefaultListAction\n\n    An argparse action that works similarly to the regular \'append\' action.\n    The default value is deleted when a new value is specified. The \'append\'\n    action would append the new value to the default.\n\n    Parameters\n    ----------\n    sep : str, optional\n        Separator to be used if multiple values should be parsed from a list.\n\n    """"""\n    def __init__(self, sep=None, *args, **kwargs):\n        super(OverrideDefaultListAction, self).__init__(*args, **kwargs)\n        self.set_to_default = True\n        # save the type as the type for the list\n        self.list_type = self.type\n        if sep is not None:\n            # if multiple values (separated by the given separator) should be\n            # parsed we need to fake the type of the argument to be a string\n            self.type = str\n        self.sep = sep\n\n    def __call__(self, parser, namespace, value, option_string=None):\n        # if this Action is called for the first time, remove the defaults\n        if self.set_to_default:\n            setattr(namespace, self.dest, [])\n            self.set_to_default = False\n        # get the current values\n        cur_values = getattr(namespace, self.dest)\n        # convert to correct type and append the newly parsed values\n        try:\n            cur_values.extend([self.list_type(v)\n                               for v in value.split(self.sep)])\n        except ValueError as e:\n            raise argparse.ArgumentError(self, str(e) + value)\n\n\n# taken from: http://www.scipy.org/Cookbook/SegmentAxis\ndef segment_axis(signal, frame_size, hop_size, axis=None, end=\'cut\',\n                 end_value=0):\n    """"""\n    Generate a new array that chops the given array along the given axis into\n    (overlapping) frames.\n\n    Parameters\n    ----------\n    signal : numpy array\n        Signal.\n    frame_size : int\n        Size of each frame [samples].\n    hop_size : int\n        Hop size between adjacent frames [samples].\n    axis : int, optional\n        Axis to operate on; if \'None\', operate on the flattened array.\n    end : {\'cut\', \'wrap\', \'pad\'}, optional\n        What to do with the last frame, if the array is not evenly divisible\n        into pieces; possible values:\n\n        - \'cut\'\n          simply discard the extra values,\n        - \'wrap\'\n          copy values from the beginning of the array,\n        - \'pad\'\n          pad with a constant value.\n\n    end_value : float, optional\n        Value used to pad if `end` is \'pad\'.\n\n    Returns\n    -------\n    numpy array, shape (num_frames, frame_size)\n        Array with overlapping frames\n\n    Notes\n    -----\n    The array is not copied unless necessary (either because it is unevenly\n    strided and being flattened or because end is set to \'pad\' or \'wrap\').\n\n    The returned array is always of type np.ndarray.\n\n    Examples\n    --------\n    >>> segment_axis(np.arange(10), 4, 2)\n    array([[0, 1, 2, 3],\n           [2, 3, 4, 5],\n           [4, 5, 6, 7],\n           [6, 7, 8, 9]])\n\n    """"""\n    # make sure that both frame_size and hop_size are integers\n    frame_size = int(frame_size)\n    hop_size = int(hop_size)\n    # TODO: add comments!\n    if axis is None:\n        signal = np.ravel(signal)  # may copy\n        axis = 0\n    if axis != 0:\n        raise ValueError(\'please check if the resulting array is correct.\')\n\n    length = signal.shape[axis]\n\n    if hop_size <= 0:\n        raise ValueError(""hop_size must be positive."")\n    if frame_size <= 0:\n        raise ValueError(""frame_size must be positive."")\n\n    if length < frame_size or (length - frame_size) % hop_size:\n        if length > frame_size:\n            round_up = (frame_size + (1 + (length - frame_size) // hop_size) *\n                        hop_size)\n            round_down = (frame_size + ((length - frame_size) // hop_size) *\n                          hop_size)\n        else:\n            round_up = frame_size\n            round_down = 0\n        assert round_down < length < round_up\n        assert round_up == round_down + hop_size or (round_up == frame_size and\n                                                     round_down == 0)\n        signal = signal.swapaxes(-1, axis)\n\n        if end == \'cut\':\n            signal = signal[..., :round_down]\n        elif end in [\'pad\', \'wrap\']:\n            # need to copy\n            s = list(signal.shape)\n            s[-1] = round_up\n            y = np.empty(s, dtype=signal.dtype)\n            y[..., :length] = signal\n            if end == \'pad\':\n                y[..., length:] = end_value\n            elif end == \'wrap\':\n                y[..., length:] = signal[..., :round_up - length]\n            signal = y\n\n        signal = signal.swapaxes(-1, axis)\n\n    length = signal.shape[axis]\n    if length == 0:\n        raise ValueError(""Not enough data points to segment array in \'cut\' ""\n                         ""mode; try end=\'pad\' or end=\'wrap\'"")\n    assert length >= frame_size\n    assert (length - frame_size) % hop_size == 0\n    n = 1 + (length - frame_size) // hop_size\n    s = signal.strides[axis]\n    new_shape = (signal.shape[:axis] + (n, frame_size) +\n                 signal.shape[axis + 1:])\n    new_strides = (signal.strides[:axis] + (hop_size * s, s) +\n                   signal.strides[axis + 1:])\n\n    try:\n        return np.ndarray.__new__(np.ndarray, strides=new_strides,\n                                  shape=new_shape, buffer=signal,\n                                  dtype=signal.dtype)\n    except TypeError:\n        # TODO: remove warning?\n        import warnings\n        warnings.warn(""Problem with ndarray creation forces copy."")\n        signal = signal.copy()\n        # shape doesn\'t change but strides does\n        new_strides = (signal.strides[:axis] + (hop_size * s, s) +\n                       signal.strides[axis + 1:])\n        return np.ndarray.__new__(np.ndarray, strides=new_strides,\n                                  shape=new_shape, buffer=signal,\n                                  dtype=signal.dtype)\n\n\n# keep namespace clean\ndel contextlib\n'"
madmom/utils/midi.py,11,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n# pylint: disable=too-few-public-methods\n""""""\nThis module contains MIDI functionality, but is deprecated as of version 0.16.\nPlease use madmom.io.midi instead. This module will be removed in version 0.18.\n\nAlmost all code is taken from Giles Hall\'s python-midi package:\nhttps://github.com/vishnubob/python-midi\n\nIt combines the complete package in a single file, to make it easier to\ndistribute. Most notable changes are `MIDITrack` and `MIDIFile` classes which\nhandle all data i/o and provide a interface which allows to read/display all\nnotes as simple numpy arrays. Also, the EventRegistry is handled differently.\n\nThe last merged commit is 3053fefe.\n\nSince then the following commits have been added functionality-wise:\n\n- 0964c0b (prevent multiple tick conversions)\n- c43bf37 (add pitch and value properties to AfterTouchEvent)\n- 40111c6 (add 0x08 MetaEvent: ProgramNameEvent)\n- 43de818 (handle unknown MIDI meta events gracefully)\n\nAdditionally, the module has been updated to work with Python3.\n\nThe MIT License (MIT)\nCopyright (c) 2013 Giles F. Hall\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the ""Software""), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\nof the Software, and to permit persons to whom the Software is furnished to do\nso, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport sys\nimport math\nimport struct\nimport numpy as np\nimport warnings\n\n\n# constants\nOCTAVE_MAX_VALUE = 12\nOCTAVE_VALUES = list(range(OCTAVE_MAX_VALUE))\n\nNOTE_NAMES = [\'C\', \'Cs\', \'D\', \'Ds\', \'E\', \'F\', \'Fs\', \'G\', \'Gs\', \'A\', \'As\', \'B\']\nWHITE_KEYS = [0, 2, 4, 5, 7, 9, 11]\nBLACK_KEYS = [1, 3, 6, 8, 10]\nNOTE_PER_OCTAVE = len(NOTE_NAMES)\nNOTE_VALUES = list(range(OCTAVE_MAX_VALUE * NOTE_PER_OCTAVE))\nNOTE_NAME_MAP_FLAT = {}\nNOTE_VALUE_MAP_FLAT = []\nNOTE_NAME_MAP_SHARP = {}\nNOTE_VALUE_MAP_SHARP = []\n\nfor index in range(128):\n    note_idx = index % NOTE_PER_OCTAVE\n    oct_idx = index / OCTAVE_MAX_VALUE\n    note_name = NOTE_NAMES[note_idx]\n    if len(note_name) == 2:\n        # sharp note\n        flat = NOTE_NAMES[note_idx + 1] + \'b\'\n        NOTE_NAME_MAP_FLAT[\'%s_%d\' % (flat, oct_idx)] = index\n        NOTE_NAME_MAP_SHARP[\'%s_%d\' % (note_name, oct_idx)] = index\n        NOTE_VALUE_MAP_FLAT.append(\'%s_%d\' % (flat, oct_idx))\n        NOTE_VALUE_MAP_SHARP.append(\'%s_%d\' % (note_name, oct_idx))\n        globals()[\'%s_%d\' % (note_name[0] + \'s\', oct_idx)] = index\n        globals()[\'%s_%d\' % (flat, oct_idx)] = index\n    else:\n        NOTE_NAME_MAP_FLAT[\'%s_%d\' % (note_name, oct_idx)] = index\n        NOTE_NAME_MAP_SHARP[\'%s_%d\' % (note_name, oct_idx)] = index\n        NOTE_VALUE_MAP_FLAT.append(\'%s_%d\' % (note_name, oct_idx))\n        NOTE_VALUE_MAP_SHARP.append(\'%s_%d\' % (note_name, oct_idx))\n        globals()[\'%s_%d\' % (note_name, oct_idx)] = index\n\nBEAT_NAMES = [\'whole\', \'half\', \'quarter\', \'eighth\', \'sixteenth\',\n              \'thirty-second\', \'sixty-fourth\']\nBEAT_VALUES = [4, 2, 1, .5, .25, .125, .0625]\nWHOLE = 0\nHALF = 1\nQUARTER = 2\nEIGHTH = 3\nSIXTEENTH = 4\nTHIRTY_SECOND = 5\nSIXTY_FOURTH = 6\n\nHEADER_SIZE = 14\n\nRESOLUTION = 480  # ticks per quarter note\nTEMPO = 120\nTIME_SIGNATURE_NUMERATOR = 4\nTIME_SIGNATURE_DENOMINATOR = 4\nTIME_SIGNATURE = (TIME_SIGNATURE_NUMERATOR, TIME_SIGNATURE_DENOMINATOR)\nSECONDS_PER_QUARTER_NOTE = 60. / TEMPO\nSECONDS_PER_TICK = SECONDS_PER_QUARTER_NOTE / RESOLUTION\n\nwarnings.warn(\'Deprecated as of version 0.16. Please use madmom.io.midi \'\n              \'instead. This module will be removed in version 0.18.\')\n\n# Ensure Python2/3 compatibility when reading bytes from MIDI files\nif sys.version_info[0] == 2:\n    int2byte = chr\n\n    def byte2int(byte):\n        """"""Convert a byte-character to an integer.""""""\n        return ord(byte)\nelse:\n    int2byte = struct.Struct("">B"").pack\n\n    def byte2int(byte):\n        """"""Convert a byte-character to an integer.""""""\n        return byte\n\n\n# functions for packing / unpacking variable length data\ndef read_variable_length(data):\n    """"""\n    Read a variable length variable from the given data.\n\n    Parameters\n    ----------\n    data : bytearray\n        Data of variable length.\n\n    Returns\n    -------\n    length : int\n        Length in bytes.\n\n    """"""\n    next_byte = 1\n    value = 0\n    while next_byte:\n        next_value = byte2int(next(data))\n        # is the hi-bit set?\n        if not next_value & 0x80:\n            # no next BYTE\n            next_byte = 0\n            # mask out the 8th bit\n        next_value &= 0x7f\n        # shift last value up 7 bits\n        value <<= 7\n        # add new value\n        value += next_value\n    return value\n\n\ndef write_variable_length(value):\n    """"""\n    Write a variable length variable.\n\n    Parameters\n    ----------\n    value : bytearray\n        Value to be encoded as a variable of variable length.\n\n    Returns\n    -------\n    bytearray\n        Variable with variable length.\n\n    """"""\n    result = bytearray()\n    result.insert(0, value & 0x7F)\n    value >>= 7\n    if value:\n        result.insert(0, (value & 0x7F) | 0x80)\n        value >>= 7\n        if value:\n            result.insert(0, (value & 0x7F) | 0x80)\n            value >>= 7\n            if value:\n                result.insert(0, (value & 0x7F) | 0x80)\n    return result\n\n\n# class for dynamically registering event classes\nclass EventRegistry(object):\n    """"""\n    Class for registering Events.\n\n    Event classes should be registered manually by calling\n    EventRegistry.register_event(EventClass) after the class definition.\n\n    Normal events are registered in the `events` dictionary and use the event\'s\n    `status_msg` as a key; meta events are registered in the `meta_events`\n    dictionary and use their `meta_command` as key.\n\n    """"""\n    events = {}\n    meta_events = {}\n\n    @classmethod\n    def register_event(cls, event):\n        """"""\n        Registers an event in the registry.\n\n        Parameters\n        ----------\n        event : :class:`Event` instance\n            Event to be registered.\n\n        """"""\n        # normal events\n        if any(b in (Event, ChannelEvent, NoteEvent) for b in event.__bases__):\n            # raise an error if the event class is registered already\n            if event.status_msg in cls.events:\n                raise AssertionError(""Event %s already registered"" %\n                                     event.name)\n            # register the Event\n            cls.events[event.status_msg] = event\n        # meta events\n        elif any(b in (MetaEvent, MetaEventWithText) for b in event.__bases__):\n            # raise an error if the meta event class is registered already\n            if event.meta_command in EventRegistry.meta_events:\n                raise AssertionError(""Event %s already registered"" %\n                                     event.name)\n            # register the MetaEvent\n            cls.meta_events[event.meta_command] = event\n        # unknown events\n        else:\n            # raise an error\n            raise AssertionError(""Unknown base class in event type: %s"" %\n                                 event.__bases__)\n\n\nclass Event(object):\n    """"""\n    Generic MIDI Event.\n\n    """"""\n    name = ""Generic MIDI Event""\n    length = 0\n    status_msg = 0x0\n    # sort is a float value used for sorting events occurring at the same tick\n    sort = 0.\n\n    def __init__(self, **kwargs):\n        if isinstance(self.length, int):\n            data = [0] * self.length\n        else:\n            data = []\n        self.tick = 0\n        self.data = data\n        for key in kwargs:\n            setattr(self, key, kwargs[key])\n\n    def __eq__(self, other):\n        return (\n            self.tick == other.tick and self.data == other.data and\n            self.status_msg == other.status_msg)\n\n    def __ne__(self, other):\n        return not self == other\n\n    def __lt__(self, other):\n        if self.tick < other.tick:\n            return True\n        elif self.tick == other.tick and self.sort < other.sort:\n            return True\n        return False\n\n    def __le__(self, other):\n        return NotImplementedError\n\n    def __gt__(self, other):\n        if self.tick > other.tick:\n            return True\n        elif self.tick == other.tick and self.sort > other.sort:\n            return True\n        return False\n\n    def __ge__(self, other):\n        return NotImplementedError\n\n    def __str__(self):\n        return ""%s: tick: %s data: %s"" % (\n            self.__class__.__name__, self.tick, self.data)\n\n\nclass ChannelEvent(Event):\n    """"""\n    Event with a channel number.\n\n    """"""\n    name = \'ChannelEvent\'\n\n    def __init__(self, **kwargs):\n        super(ChannelEvent, self).__init__(**kwargs)\n        self.channel = kwargs.get(\'channel\', 0)\n\n    def __eq__(self, other):\n        return (\n            self.tick == other.tick and self.channel == other.channel and\n            self.data == other.data and self.status_msg == other.status_msg)\n\n    def __str__(self):\n        return ""%s: tick: %s channel: %s data: %s"" % (\n            self.__class__.__name__, self.tick, self.channel, self.data)\n\n\nclass NoteEvent(ChannelEvent):\n    """"""\n    NoteEvent is a special subclass of Event that is not meant to be used as a\n    concrete class. It defines the generalities of NoteOn and NoteOff events.\n\n    """"""\n    length = 2\n\n    def __str__(self):\n        return ""%s: tick: %s channel: %s pitch: %s velocity: %s"" % (\n            self.__class__.__name__, self.tick, self.channel, self.pitch,\n            self.velocity)\n\n    @property\n    def pitch(self):\n        """"""\n        Pitch of the note event.\n\n        """"""\n        return self.data[0]\n\n    @pitch.setter\n    def pitch(self, pitch):\n        """"""\n        Set the pitch of the note event.\n\n        Parameters\n        ----------\n        pitch : int\n            Pitch of the note.\n\n        """"""\n        self.data[0] = pitch\n\n    @property\n    def velocity(self):\n        """"""\n        Velocity of the note event.\n\n        """"""\n        return self.data[1]\n\n    @velocity.setter\n    def velocity(self, velocity):\n        """"""\n        Set the velocity of the note event.\n\n        Parameters\n        ----------\n        velocity : int\n            Velocity of the note.\n\n        """"""\n        self.data[1] = velocity\n\n\nclass NoteOnEvent(NoteEvent):\n    """"""\n    Note On Event.\n\n    """"""\n    status_msg = 0x90\n    name = \'Note On\'\n    sort = .1  # make sure it is sorted before NoteOffEvent\n\nEventRegistry.register_event(NoteOnEvent)\n\n\nclass NoteOffEvent(NoteEvent):\n    """"""\n    Note Off Event.\n\n    """"""\n    status_msg = 0x80\n    name = \'Note Off\'\n    sort = .2  # make sure it is sorted after NoteOnEvent\n\nEventRegistry.register_event(NoteOffEvent)\n\n\nclass AfterTouchEvent(ChannelEvent):\n    """"""\n    After Touch Event.\n\n    """"""\n    status_msg = 0xA0\n    length = 2\n    name = \'After Touch\'\n\n    def __str__(self):\n        return ""%s: tick: %s channel: %s pitch: %s value: %s"" % (\n            self.__class__.__name__, self.tick, self.channel, self.pitch,\n            self.value)\n\n    @property\n    def pitch(self):\n        """"""\n        Pitch of the after touch event.\n\n        """"""\n        return self.data[0]\n\n    @pitch.setter\n    def pitch(self, pitch):\n        """"""\n        Set the pitch of the after touch event.\n\n        Parameters\n        ----------\n        pitch : int\n            Pitch of the after touch event.\n\n        """"""\n        self.data[0] = pitch\n\n    @property\n    def value(self):\n        """"""\n        Value of the after touch event.\n\n        """"""\n        return self.data[1]\n\n    @value.setter\n    def value(self, value):\n        """"""\n        Set the value of the after touch event.\n\n        Parameters\n        ----------\n        value : int\n            Value of the after touch event.\n\n        """"""\n        self.data[1] = value\n\nEventRegistry.register_event(AfterTouchEvent)\n\n\nclass ControlChangeEvent(ChannelEvent):\n    """"""\n    Control Change Event.\n\n    """"""\n    status_msg = 0xB0\n    length = 2\n    name = \'Control Change\'\n\n    def __str__(self):\n        return ""%s: tick: %s channel: %s control: %s value: %s"" % (\n            self.__class__.__name__, self.tick, self.channel, self.control,\n            self.value)\n\n    @property\n    def control(self):\n        """"""\n        Control ID.\n\n        """"""\n        return self.data[0]\n\n    @control.setter\n    def control(self, control):\n        """"""\n        Set control ID.\n\n        Parameters\n        ----------\n        control : int\n            Control ID.\n\n        """"""\n        self.data[0] = control\n\n    @property\n    def value(self):\n        """"""\n        Value of the controller.\n\n        """"""\n        return self.data[1]\n\n    @value.setter\n    def value(self, value):\n        """"""\n        Set the value of the controller.\n\n        Parameters\n        ----------\n        value : int\n            Value of the controller.\n\n        """"""\n        self.data[1] = value\n\nEventRegistry.register_event(ControlChangeEvent)\n\n\nclass ProgramChangeEvent(ChannelEvent):\n    """"""\n    Program Change Event.\n\n    """"""\n    status_msg = 0xC0\n    length = 1\n    name = \'Program Change\'\n\n    def __str__(self):\n        return ""%s: tick: %s channel: %s value: %s"" % (\n            self.__class__.__name__, self.tick, self.channel, self.value)\n\n    @property\n    def value(self):\n        """"""\n        Value of the Program Change Event.\n\n        """"""\n        return self.data[0]\n\n    @value.setter\n    def value(self, value):\n        """"""\n        Set the value of the Program Change Event.\n\n        Parameters\n        ----------\n        value : int\n            Value of the Program Change Event.\n\n        """"""\n        self.data[0] = value\n\nEventRegistry.register_event(ProgramChangeEvent)\n\n\nclass ChannelAfterTouchEvent(ChannelEvent):\n    """"""\n    Channel After Touch Event.\n\n    """"""\n    status_msg = 0xD0\n    length = 1\n    name = \'Channel After Touch\'\n\n    def __str__(self):\n        return ""%s: tick: %s channel: %s value: %s"" % (\n            self.__class__.__name__, self.tick, self.channel, self.value)\n\n    @property\n    def value(self):\n        """"""\n        Value of the Channel After Touch Event.\n\n        """"""\n        return self.data[0]\n\n    @value.setter\n    def value(self, value):\n        """"""\n        Set the value of the Channel After Touch Event.\n\n        Parameters\n        ----------\n        value : int\n            Value of the Channel After Touch Event.\n\n        """"""\n        self.data[0] = value\n\nEventRegistry.register_event(ChannelAfterTouchEvent)\n\n\nclass PitchWheelEvent(ChannelEvent):\n    """"""\n    Pitch Wheel Event.\n\n    """"""\n    status_msg = 0xE0\n    length = 2\n    name = \'Pitch Wheel\'\n\n    @property\n    def pitch(self):\n        """"""\n        Pitch of the Pitch Wheel Event.\n\n        """"""\n        return ((self.data[1] << 7) | self.data[0]) - 0x2000\n\n    @pitch.setter\n    def pitch(self, pitch):\n        """"""\n        Set the pitch of the Pitch Wheel Event.\n\n        Parameters\n        ----------\n        pitch : int\n            Pitch of the Pitch Wheel Event.\n\n        """"""\n        value = pitch + 0x2000\n        self.data[0] = value & 0x7F\n        self.data[1] = (value >> 7) & 0x7F\n\nEventRegistry.register_event(PitchWheelEvent)\n\n\nclass SysExEvent(Event):\n    """"""\n    System Exclusive Event.\n\n    """"""\n    status_msg = 0xF0\n    length = \'variable\'\n    name = \'SysEx\'\n\nEventRegistry.register_event(SysExEvent)\n\n\nclass MetaEvent(Event):\n    """"""\n    MetaEvent is a special subclass of Event that is not meant to be used as a\n    concrete class. It defines a subset of Events known as the Meta events.\n\n    """"""\n    status_msg = 0xFF\n    meta_command = 0x0\n    name = \'Meta Event\'\n\n    def __eq__(self, other):\n        return (\n            self.tick == other.tick and self.data == other.data and\n            self.status_msg == other.status_msg and\n            self.meta_command == other.meta_command)\n\n\nclass MetaEventWithText(MetaEvent):\n    """"""\n    Meta Event With Text.\n\n    """"""\n    def __init__(self, **kwargs):\n        super(MetaEventWithText, self).__init__(**kwargs)\n        if \'text\' not in kwargs:\n            self.text = \'\'.join(chr(datum) for datum in self.data)\n\n    def __str__(self):\n        return ""%s: %s"" % (self.__class__.__name__, self.text)\n\n\nclass SequenceNumberMetaEvent(MetaEvent):\n    """"""\n    Sequence Number Meta Event.\n\n    """"""\n    meta_command = 0x00\n    length = 2\n    name = \'Sequence Number\'\n\nEventRegistry.register_event(SequenceNumberMetaEvent)\n\n\nclass TextMetaEvent(MetaEventWithText):\n    """"""\n    Text Meta Event.\n\n    """"""\n    meta_command = 0x01\n    length = \'variable\'\n    name = \'Text\'\n\nEventRegistry.register_event(TextMetaEvent)\n\n\nclass CopyrightMetaEvent(MetaEventWithText):\n    """"""\n    Copyright Meta Event.\n\n    """"""\n    meta_command = 0x02\n    length = \'variable\'\n    name = \'Copyright Notice\'\n\nEventRegistry.register_event(CopyrightMetaEvent)\n\n\nclass TrackNameEvent(MetaEventWithText):\n    """"""\n    Track Name Event.\n\n    """"""\n    meta_command = 0x03\n    length = \'variable\'\n    name = \'Track Name\'\n\nEventRegistry.register_event(TrackNameEvent)\n\n\nclass InstrumentNameEvent(MetaEventWithText):\n    """"""\n    Instrument Name Event.\n\n    """"""\n    meta_command = 0x04\n    length = \'variable\'\n    name = \'Instrument Name\'\n\nEventRegistry.register_event(InstrumentNameEvent)\n\n\nclass LyricsEvent(MetaEventWithText):\n    """"""\n    Lyrics Event.\n\n    """"""\n    meta_command = 0x05\n    length = \'variable\'\n    name = \'Lyrics\'\n\nEventRegistry.register_event(LyricsEvent)\n\n\nclass MarkerEvent(MetaEventWithText):\n    """"""\n    Marker Event.\n\n    """"""\n    meta_command = 0x06\n    length = \'variable\'\n    name = \'Marker\'\n\nEventRegistry.register_event(MarkerEvent)\n\n\nclass CuePointEvent(MetaEventWithText):\n    """"""\n    Cue Point Event.\n\n    """"""\n    meta_command = 0x07\n    length = \'variable\'\n    name = \'Cue Point\'\n\nEventRegistry.register_event(CuePointEvent)\n\n\nclass ProgramNameEvent(MetaEventWithText):\n    """"""\n    Program Name Event.\n\n    """"""\n    meta_command = 0x08\n    length = \'variable\'\n    name = \'Program Name\'\n\nEventRegistry.register_event(ProgramNameEvent)\n\n\nclass UnknownMetaEvent(MetaEvent):\n    """"""\n    Unknown Meta Event.\n\n    Parameters\n    ----------\n    meta_command : int\n        Value of the meta command.\n\n    """"""\n    meta_command = None\n    name = \'Unknown\'\n\n    def __init__(self, **kwargs):\n        super(UnknownMetaEvent, self).__init__(**kwargs)\n        # TODO: is this needed, should be handled by Event already\n        self.meta_command = kwargs[\'meta_command\']\n\nEventRegistry.register_event(UnknownMetaEvent)\n\n\nclass ChannelPrefixEvent(MetaEvent):\n    """"""\n    Channel Prefix Event.\n\n    """"""\n    meta_command = 0x20\n    length = 1\n    name = \'Channel Prefix\'\n\nEventRegistry.register_event(ChannelPrefixEvent)\n\n\nclass PortEvent(MetaEvent):\n    """"""\n    Port Event.\n\n    """"""\n    meta_command = 0x21\n    name = \'MIDI Port/Cable\'\n\nEventRegistry.register_event(PortEvent)\n\n\nclass TrackLoopEvent(MetaEvent):\n    """"""\n    Track Loop Event.\n\n    """"""\n    meta_command = 0x2E\n    name = \'Track Loop\'\n\nEventRegistry.register_event(TrackLoopEvent)\n\n\nclass EndOfTrackEvent(MetaEvent):\n    """"""\n    End Of Track Event.\n\n    """"""\n    meta_command = 0x2F\n    name = \'End of Track\'\n    sort = .99  # should always come last\n\nEventRegistry.register_event(EndOfTrackEvent)\n\n\nclass SetTempoEvent(MetaEvent):\n    """"""\n    Set Tempo Event.\n\n    """"""\n    meta_command = 0x51\n    length = 3\n    name = \'Set Tempo\'\n\n    def __str__(self):\n        return ""%s: tick: %s microseconds per quarter note: %s"" % (\n            self.__class__.__name__, self.tick,\n            self.microseconds_per_quarter_note)\n\n    @property\n    def microseconds_per_quarter_note(self):\n        """"""\n        Microseconds per quarter note.\n\n        """"""\n        assert len(self.data) == 3\n        values = [self.data[x] << (16 - (8 * x)) for x in range(3)]\n        return sum(values)\n\n    @microseconds_per_quarter_note.setter\n    def microseconds_per_quarter_note(self, microseconds):\n        """"""\n        Set microseconds per quarter note.\n\n        Parameters\n        ----------\n        microseconds : int\n            Microseconds per quarter note.\n\n        """"""\n        self.data = [(microseconds >> (16 - (8 * x)) & 0xFF) for x in range(3)]\n\nEventRegistry.register_event(SetTempoEvent)\n\n\nclass SmpteOffsetEvent(MetaEvent):\n    """"""\n    SMPTE Offset Event.\n\n    """"""\n    meta_command = 0x54\n    name = \'SMPTE Offset\'\n\nEventRegistry.register_event(SmpteOffsetEvent)\n\n\nclass TimeSignatureEvent(MetaEvent):\n    """"""\n    Time Signature Event.\n\n    """"""\n    meta_command = 0x58\n    length = 4\n    name = \'Time Signature\'\n\n    @property\n    def numerator(self):\n        """"""\n        Numerator of the time signature.\n\n        """"""\n        return self.data[0]\n\n    @numerator.setter\n    def numerator(self, numerator):\n        """"""\n        Set numerator of the time signature.\n\n        Parameters\n        ----------\n        numerator : int\n            Numerator of the time signature.\n        """"""\n        self.data[0] = numerator\n\n    @property\n    def denominator(self):\n        """"""\n        Denominator of the time signature.\n\n        """"""\n        return 2 ** self.data[1]\n\n    @denominator.setter\n    def denominator(self, denominator):\n        """"""\n        Set denominator of the time signature.\n\n        Parameters\n        ----------\n        denominator : int\n            Denominator of the time signature.\n\n        """"""\n        self.data[1] = int(math.log(denominator, 2))\n\n    @property\n    def metronome(self):\n        """"""\n        Metronome.\n\n        """"""\n        return self.data[2]\n\n    @metronome.setter\n    def metronome(self, metronome):\n        """"""\n        Set metronome of the time signature.\n\n        Parameters\n        ----------\n        metronome : int\n            Metronome of the time signature.\n\n        """"""\n        self.data[2] = metronome\n\n    @property\n    def thirty_seconds(self):\n        """"""\n        Thirty-seconds of the time signature.\n\n        """"""\n        return self.data[3]\n\n    @thirty_seconds.setter\n    def thirty_seconds(self, thirty_seconds):\n        """"""\n        Set thirty-seconds of the time signature.\n\n        Parameters\n        ----------\n        thirty_seconds : int\n            Thirty-seconds of the time signature.\n\n        """"""\n        self.data[3] = thirty_seconds\n\nEventRegistry.register_event(TimeSignatureEvent)\n\n\nclass KeySignatureEvent(MetaEvent):\n    """"""\n    Key Signature Event.\n\n    """"""\n    meta_command = 0x59\n    length = 2\n    name = \'Key Signature\'\n\n    @property\n    def alternatives(self):\n        """"""\n        Alternatives of the key signature.\n\n        """"""\n        return self.data[0] - 256 if self.data[0] > 127 else self.data[0]\n\n    @alternatives.setter\n    def alternatives(self, alternatives):\n        """"""\n        Set alternatives of the key signature.\n\n        Parameters\n        ----------\n        alternatives : int\n            Alternatives of the key signature.\n\n        """"""\n        self.data[0] = 256 + alternatives if alternatives < 0 else alternatives\n\n    @property\n    def minor(self):\n        """"""\n        Major / minor.\n\n        """"""\n        return self.data[1]\n\n    @minor.setter\n    def minor(self, val):\n        """"""\n        Set major / minor.\n\n        Parameters\n        ----------\n        val : int\n            Major / minor.\n\n        """"""\n        self.data[1] = val\n\nEventRegistry.register_event(KeySignatureEvent)\n\n\nclass SequencerSpecificEvent(MetaEvent):\n    """"""\n    Sequencer Specific Event.\n\n    """"""\n    meta_command = 0x7F\n    name = \'Sequencer Specific\'\n\nEventRegistry.register_event(SequencerSpecificEvent)\n\n\ndef _add_channel(notes, channel=0):\n    """"""\n    Adds a default channel to the notes if missing.\n\n    Parameters\n    ----------\n    notes : numpy array, shape (num_notes, 2)\n        Notes, one per row (column definition see notes).\n    channel : int, optional\n        Note channel if not defined by `notes`.\n\n    Returns\n    -------\n    numpy array\n        Notes (including note channel).\n\n    Notes\n    -----\n    The note columns format must be (channel being optional):\n\n    \'onset\' \'pitch\' \'duration\' \'velocity\' [\'channel\']\n\n    """"""\n    if not notes.ndim == 2:\n        raise ValueError(\'unknown format for `notes`\')\n    rows, columns = notes.shape\n    if columns == 5:\n        return notes\n    elif columns == 4:\n        channels = np.ones((rows, 1)) * channel\n        return np.hstack((notes, channels))\n    raise ValueError(\'unable to handle `notes` with %d columns\' % columns)\n\n\n# MIDI Track\nclass MIDITrack(object):\n    """"""\n    MIDI Track.\n\n    Parameters\n    ----------\n    events : list\n        MIDI events.\n\n    Notes\n    -----\n    All events are stored with timing information in absolute ticks.\n    The events must be sorted. Consider using `from_notes()` method.\n\n    Examples\n    --------\n\n    Create a MIDI track from a list of events. Please note that the events must\n    be sorted.\n\n    >>> e1 = NoteOnEvent(tick=100, pitch=50, velocity=60)\n    >>> e2 = NoteOffEvent(tick=300, pitch=50)\n    >>> e3 = NoteOnEvent(tick=200, pitch=62, velocity=90)\n    >>> e4 = NoteOffEvent(tick=600, pitch=62)\n    >>> t = MIDITrack(sorted([e1, e2, e3, e4]))\n    >>> t  # doctest: +ELLIPSIS\n    <madmom.utils.midi.MIDITrack object at 0x...>\n    >>> t.events  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    [<madmom.utils.midi.NoteOnEvent object at 0x...>,\n     <madmom.utils.midi.NoteOnEvent object at 0x...>,\n     <madmom.utils.midi.NoteOffEvent object at 0x...>,\n     <madmom.utils.midi.NoteOffEvent object at 0x...>]\n\n    It can also be created from an array containing the notes. The `from_notes`\n    method also takes care of creating tempo and time signature events.\n\n    >>> notes = np.array([[0.1, 50, 0.3, 60], [0.2, 62, 0.4, 90]])\n    >>> t = MIDITrack.from_notes(notes)\n    >>> t  # doctest: +ELLIPSIS\n    <madmom.utils.midi.MIDITrack object at 0x...>\n    >>> t.events  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    [<madmom.utils.midi.SetTempoEvent object at 0x...>,\n     <madmom.utils.midi.TimeSignatureEvent object at 0...>,\n     <madmom.utils.midi.NoteOnEvent object at 0x...>,\n     <madmom.utils.midi.NoteOnEvent object at 0x...>,\n     <madmom.utils.midi.NoteOffEvent object at 0x...>,\n     <madmom.utils.midi.NoteOffEvent object at 0x...>]\n\n    """"""\n\n    def __init__(self, events=None):\n        if events is None:\n            self.events = []\n        else:\n            # do not sort the events, since they can have relative timing!\n            self.events = events\n\n    def _make_ticks_abs(self):\n        """"""Make the track\'s events timing information absolute.""""""\n        running_tick = 0\n        for event in self.events:\n            event.tick += running_tick\n            running_tick = event.tick\n\n    def _make_ticks_rel(self):\n        """"""Make the track\'s events timing information relative.""""""\n        running_tick = 0\n        for event in self.events:\n            event.tick -= running_tick\n            running_tick += event.tick\n\n    @property\n    def data_stream(self):\n        """"""\n        MIDI data stream representation of the track.\n\n        """"""\n        # sort the events\n        self.events.sort()\n        # first make sure the timing information is relative\n        self._make_ticks_rel()\n        # and unset the status message\n        status = None\n        # then encode all events of the track\n        track_data = bytearray()\n        for event in self.events:\n            # encode the event data, first the timing information\n            track_data.extend(write_variable_length(event.tick))\n            # is the event a MetaEvent?\n            if isinstance(event, MetaEvent):\n                track_data.append(event.status_msg)\n                track_data.append(event.meta_command)\n                track_data.extend(write_variable_length(len(event.data)))\n                track_data.extend(event.data)\n            # is this event a SysEx Event?\n            elif isinstance(event, SysExEvent):\n                track_data.append(0xF0)\n                track_data.extend(event.data)\n                track_data.append(0xF7)\n            # not a meta or SysEx event, must be a general message\n            elif isinstance(event, Event):\n                if not status or status.status_msg != event.status_msg or \\\n                        status.channel != event.channel:\n                    status = event\n                    track_data.append(event.status_msg | event.channel)\n                track_data.extend(event.data)\n            else:\n                raise ValueError(""Unknown MIDI Event: "" + str(event))\n        # TODO: should we add a EndOfTrackEvent?\n        # convert events back to absolute ticks\n        self._make_ticks_abs()\n        # prepare the data\n        data = bytearray()\n        # generate a MIDI header\n        data.extend(b\'MTrk\')\n        data.extend(struct.pack("">L"", len(track_data)))\n        # append the track data\n        data.extend(track_data)\n        # return the track data\n        return data\n\n    @classmethod\n    def from_stream(cls, midi_stream):\n        """"""\n        Create a MIDI track by reading the data from a stream.\n\n        Parameters\n        ----------\n        midi_stream : open file handle\n            MIDI file stream (e.g. open MIDI file handle)\n\n        Returns\n        -------\n        :class:`MIDITrack` instance\n            :class:`MIDITrack` instance\n\n        """"""\n        events = []\n        # reset the status\n        status = None\n        # first four bytes are Track header\n        chunk = midi_stream.read(4)\n        if chunk != b\'MTrk\':\n            raise TypeError(""Bad track header in MIDI file: %s"" % chunk)\n        # next four bytes are track size\n        track_size = struct.unpack("">L"", midi_stream.read(4))[0]\n        track_data = iter(midi_stream.read(track_size))\n        # read in all events\n        while True:\n            try:\n                # first datum is variable length representing the delta-time\n                tick = read_variable_length(track_data)\n                # next byte is status message\n                status_msg = byte2int(next(track_data))\n                # is the event a MetaEvent?\n                if MetaEvent.status_msg == status_msg:\n                    meta_cmd = byte2int(next(track_data))\n                    if meta_cmd not in EventRegistry.meta_events:\n                        import warnings\n                        warnings.warn(""Unknown Meta MIDI Event: %s"" % meta_cmd)\n                        event_cls = UnknownMetaEvent\n                    else:\n                        event_cls = EventRegistry.meta_events[meta_cmd]\n                    data_len = read_variable_length(track_data)\n                    data = [byte2int(next(track_data)) for _ in\n                            range(data_len)]\n                    # create an event and append it to the list\n                    events.append(event_cls(tick=tick, data=data,\n                                            meta_command=meta_cmd))\n                # is this event a SysEx Event?\n                elif SysExEvent.status_msg == status_msg:\n                    data = []\n                    while True:\n                        datum = byte2int(next(track_data))\n                        if datum == 0xF7:\n                            break\n                        data.append(datum)\n                    # create an event and append it to the list\n                    events.append(SysExEvent(tick=tick, data=data))\n                # not a meta or SysEx event, must be a general MIDI event\n                else:\n                    key = status_msg & 0xF0\n                    if key not in EventRegistry.events:\n                        assert status, ""Bad byte value""\n                        data = []\n                        key = status & 0xF0\n                        event_cls = EventRegistry.events[key]\n                        channel = status & 0x0F\n                        data.append(status_msg)\n                        data += [byte2int(next(track_data)) for _ in\n                                 range(event_cls.length - 1)]\n                        # create an event and append it to the list\n                        events.append(event_cls(tick=tick, channel=channel,\n                                                data=data))\n                    else:\n                        status = status_msg\n                        event_cls = EventRegistry.events[key]\n                        channel = status & 0x0F\n                        data = [byte2int(next(track_data)) for _ in\n                                range(event_cls.length)]\n                        # create an event and append it to the list\n                        events.append(event_cls(tick=tick, channel=channel,\n                                                data=data))\n            # no more events to be processed\n            except StopIteration:\n                break\n        # create a new track\n        track = cls(events)\n        # make the timing of the events (i.e. the ticks) absolute\n        track._make_ticks_abs()\n        # return this track\n        return track\n\n    @classmethod\n    def from_notes(cls, notes, tempo=TEMPO, time_signature=TIME_SIGNATURE,\n                   resolution=RESOLUTION):\n        """"""\n        Create a MIDI track from the given notes.\n\n        Parameters\n        ----------\n        notes : numpy array\n            Array with the notes, one per row. The columns must be:\n            (onset time, pitch, duration, velocity, [channel]).\n        tempo : float, optional\n            Tempo of the MIDI track, given in beats per minute (bpm).\n        time_signature : tuple, optional\n            Time signature of the track, e.g. (4, 4) for 4/4.\n        resolution : int\n            Resolution (i.e. ticks per quarter note) of the MIDI track.\n\n        Returns\n        -------\n        :class:`MIDITrack` instance\n            :class:`MIDITrack` instance\n\n        Notes\n        -----\n        All events including the generated tempo and time signature events is\n        included in the returned track (i.e. as defined in MIDI format 0).\n\n        """"""\n        # add a default channel if needed\n        notes = _add_channel(notes)\n\n        # set time signature\n        sig = TimeSignatureEvent(tick=0)\n        sig.numerator, sig.denominator = time_signature\n\n        # length of a quarter note (seconds)\n        quarter_note_length = 60. / tempo * sig.denominator / 4\n        # quarter notes per second\n        quarter_notes_per_second = 1 / quarter_note_length\n        # ticks per second\n        ticks_per_second = resolution * quarter_notes_per_second\n\n        # set tempo\n        tempo = SetTempoEvent(tick=0)\n        tempo.microseconds_per_quarter_note = int(quarter_note_length * 1e6)\n\n        # list for events (ticks in absolute timing)\n        events = []\n\n        # add the notes\n        for note in notes:\n            onset, pitch, duration, velocity, channel = note\n            # add NoteOn\n            e_on = NoteOnEvent()\n            e_on.tick = int(onset * ticks_per_second)\n            e_on.pitch = int(pitch)\n            e_on.velocity = int(velocity)\n            e_on.channel = int(channel)\n            # and NoteOff\n            e_off = NoteOffEvent()\n            e_off.tick = int((onset + duration) * ticks_per_second)\n            e_off.pitch = int(pitch)\n            e_off.channel = int(channel)\n            events.append(e_on)\n            events.append(e_off)\n        # sort the events and prepend the tempo and time signature events\n        events = sorted(events)\n        events.insert(0, sig)\n        events.insert(0, tempo)\n        # create a track from the events\n        return cls(events)\n\n\n# File I/O classes\nclass MIDIFile(object):\n    """"""\n    MIDI File.\n\n    Parameters\n    ----------\n    tracks : list\n        List of :class:`MIDITrack` instances.\n    resolution : int, optional\n        Resolution (i.e. microseconds per quarter note).\n    file_format : int, optional\n        Format of the MIDI file.\n\n    Notes\n    -----\n    Writing a MIDI file assumes a tempo of 120 beats per minute (bpm) and a 4/4\n    time signature and writes all events into a single track (i.e. MIDI format\n    0).\n\n    Examples\n    --------\n    Create a MIDI file from an array with notes. The format of the note array\n    is: \'onset time\', \'pitch\', \'duration\', \'velocity\', \'channel\'. The last\n    column can be omitted, assuming channel 0.\n\n    >>> notes = np.array([[0, 50, 1, 60], [0.5, 62, 0.5, 90]])\n    >>> m = MIDIFile.from_notes(notes)\n    >>> m  # doctest: +ELLIPSIS\n    <madmom.utils.midi.MIDIFile object at 0x...>\n\n    The notes can be accessed as a numpy array in various formats (default is\n    seconds):\n\n    >>> m.notes()\n    array([[ 0. , 50. ,  1. , 60. ,  0. ],\n           [ 0.5, 62. ,  0.5, 90. ,  0. ]])\n    >>> m.notes(unit=\'ticks\')\n    array([[  0.,  50., 960.,  60.,   0.],\n           [480.,  62., 480.,  90.,   0.]])\n    >>> m.notes(unit=\'beats\')\n    array([[ 0., 50.,  2., 60.,  0.],\n           [ 1., 62.,  1., 90.,  0.]])\n\n    >>> m = MIDIFile.from_notes(notes, tempo=60)\n    >>> m.notes(unit=\'ticks\')\n    array([[  0.,  50., 480.,  60.,   0.],\n           [240.,  62., 240.,  90.,   0.]])\n    >>> m.notes(unit=\'beats\')\n    array([[ 0. , 50. ,  1. , 60. ,  0. ],\n           [ 0.5, 62. ,  0.5, 90. ,  0. ]])\n\n    >>> m = MIDIFile.from_notes(notes, tempo=60, time_signature=(2, 2))\n    >>> m.notes(unit=\'ticks\')\n    array([[  0.,  50., 960.,  60.,   0.],\n           [480.,  62., 480.,  90.,   0.]])\n    >>> m.notes(unit=\'beats\')\n    array([[ 0. , 50. ,  1. , 60. ,  0. ],\n           [ 0.5, 62. ,  0.5, 90. ,  0. ]])\n\n    >>> m = MIDIFile.from_notes(notes, tempo=240, time_signature=(3, 8))\n    >>> m.notes(unit=\'ticks\')\n    array([[  0.,  50., 960.,  60.,   0.],\n           [480.,  62., 480.,  90.,   0.]])\n    >>> m.notes(unit=\'beats\')\n    array([[ 0., 50.,  4., 60.,  0.],\n           [ 2., 62.,  2., 90.,  0.]])\n\n    """"""\n\n    def __init__(self, tracks=None, resolution=RESOLUTION, file_format=0):\n        # init variables\n        if tracks is None:\n            self.tracks = []\n        elif isinstance(tracks, MIDITrack):\n            self.tracks = [tracks]\n        elif isinstance(tracks, list):\n            # TODO: test if the items of the list are of type MIDITrack\n            self.tracks = tracks\n        else:\n            raise ValueError(\'file_format of `tracks` not supported.\')\n        self.resolution = resolution  # i.e. ticks per quarter note\n        # format 0 stores all information in 1 track\n        # format 1 has multiple tracks but plays them back simultaneously\n        # TODO: format 2 has multiple tracks but plays them back one after\n        #       another. This type is not supported (yet).\n        if file_format > 1:\n            raise ValueError(\'Only MIDI file formats 0 and 1 supported.\')\n        self.format = file_format\n\n    @property\n    def ticks_per_quarter_note(self):\n        """"""\n        Number of ticks per quarter note.\n\n        """"""\n        return self.resolution\n\n    def tempi(self, suppress_warnings=False):\n        """"""\n        Tempi of the MIDI file.\n\n        Returns\n        -------\n        tempi : numpy array\n            Array with tempi (tick, seconds per tick, cumulative time).\n\n        """"""\n        if not suppress_warnings:\n            import warnings\n            warnings.warn(\'this method will be removed soon, do not rely on \'\n                          \'its output, rather fix issue #192 ;)\')\n        # create an empty tempo list\n        tempo_events = []\n        for i, track in enumerate(self.tracks):\n            # get a list with tempo events\n            track_tempo_events = [e for e in track.events if\n                                  isinstance(e, SetTempoEvent)]\n            # tempo events should be only in the first track of a MIDI file\n            if track_tempo_events and i > 0:\n                raise ValueError(\'SetTempoEvents should be only in the first \'\n                                 \'track of a MIDI file.\')\n            tempo_events.extend(track_tempo_events)\n\n        # convert to desired format (tick, microseconds per tick)\n        tempi = [(e.tick, e.microseconds_per_quarter_note /\n                  (1e6 * self.resolution)) for e in tempo_events]\n        # make sure a tempo is set and the first tempo occurs at tick 0\n        if not tempi or tempi[0][0] > 0:\n            tempi.insert(0, (0, SECONDS_PER_TICK))\n        # sort (just to be sure)\n        tempi.sort()\n        # re-iterate over the list to calculate the cumulative time\n        for i, _ in enumerate(tempi):\n            if i == 0:\n                tempi[i] = (tempi[i][0], tempi[i][1], 0)\n            else:\n                ticks = tempi[i][0] - tempi[i - 1][0]\n                cum_time = tempi[i - 1][2] + ticks * tempi[i - 1][1]\n                tempi[i] = (tempi[i][0], tempi[i][1], cum_time)\n        # return tempo\n        return np.asarray(tempi, np.float)\n\n    def time_signatures(self, suppress_warnings=False):\n        """"""\n        Time signatures of the MIDI file.\n\n        Returns\n        -------\n        time_signatures : numpy array\n            Array with time signatures (tick, numerator, denominator).\n\n        """"""\n        if not suppress_warnings:\n            import warnings\n            warnings.warn(\'this method will be removed soon, do not rely on \'\n                          \'its output, rather fix issue #192 ;)\')\n        signatures = None\n        for track in self.tracks:\n            # get a list with time signature events\n            time_signature_events = [e for e in track.events if\n                                     isinstance(e, TimeSignatureEvent)]\n            if signatures is None and len(time_signature_events) > 0:\n                # convert to desired format\n                signatures = [(e.tick, e.numerator, e.denominator)\n                              for e in time_signature_events]\n            elif signatures is not None and len(time_signature_events) > 0:\n                # time signature events should be contained only in the first\n                # track of a MIDI file, thus raise an error\n                raise ValueError(\'TimeSignatureEvent should be only in the \'\n                                 \'first track of a MIDI file.\')\n        # make sure a time signature is set and the first one occurs at tick 0\n        if signatures is None:\n            signatures = [(0, TIME_SIGNATURE)]\n        if signatures[0][0] > 0:\n            signatures.insert(0, (0, TIME_SIGNATURE))\n        # return time signatures\n        return np.asarray(signatures, dtype=np.float)\n\n    def notes(self, unit=\'s\'):\n        """"""\n        Notes of the MIDI file.\n\n        Parameters\n        ----------\n        unit : {\'s\', \'seconds\', \'b\', \'beats\', \'t\', \'ticks\'}\n            Time unit for notes, seconds (\'s\') beats (\'b\') or ticks (\'t\')\n\n        Returns\n        -------\n        notes : numpy array\n            Array with notes (onset time, pitch, duration, velocity, channel).\n\n        """"""\n        # list for all notes\n        notes = []\n        # dictionary for storing the last onset and velocity for each\n        # individual note (i.e. same pitch and channel)\n        sounding_notes = {}\n\n        # as key for the dict use channel * 128 (max number of pitches) + pitch\n        def note_hash(channel, pitch):\n            """"""Generate a note hash.""""""\n            return channel * 128 + pitch\n\n        for track in self.tracks:\n            # get a list with note events\n            note_events = [e for e in track.events if isinstance(e, NoteEvent)]\n            # process all events\n            tick = 0\n            for e in note_events:\n                if tick > e.tick:\n                    raise AssertionError(\'note events must be sorted!\')\n                n = note_hash(e.channel, e.pitch)\n                is_note_on = isinstance(e, NoteOnEvent)\n                is_note_off = isinstance(e, NoteOffEvent)\n                # if it\'s a note on event with a velocity > 0,\n                if is_note_on and e.velocity > 0:\n                    # save the onset time and velocity\n                    sounding_notes[n] = (e.tick, e.velocity)\n                # if it\'s a note off event or a note on with a velocity of 0,\n                elif is_note_off or (is_note_on and e.velocity == 0):\n                    if n not in sounding_notes:\n                        import warnings\n                        warnings.warn(""ignoring %s"" % e)\n                        continue\n                    if sounding_notes[n][0] > e.tick:\n                        raise AssertionError(\'note duration must be positive\')\n                    if sounding_notes[n][1] <= 0:\n                        raise AssertionError(\'note velocity must be positive\')\n                    # append the note to the list\n                    notes.append((sounding_notes[n][0], e.pitch,\n                                  e.tick - sounding_notes[n][0],\n                                  sounding_notes[n][1], e.channel))\n                    # remove hash from dict\n                    del sounding_notes[n]\n                else:\n                    raise TypeError(\'unexpected NoteEvent\', e)\n                tick = e.tick\n\n        # sort the notes and convert to numpy array\n        notes = np.asarray(sorted(notes), dtype=np.float)\n\n        # convert onset times and durations from ticks to the requested unit\n        # and return the notes\n        if unit.lower() in (\'t\', \'ticks\'):\n            return notes\n        elif unit.lower() in (\'s\', \'seconds\'):\n            return self._notes_in_seconds(notes)\n        elif unit.lower() in (\'b\', \'beats\'):\n            return self._notes_in_beats(notes)\n        else:\n            raise ValueError(""`unit` must be either \'seconds\', \'s\', \'beats\', ""\n                             ""\'b\', \'ticks\', or \'t\' not %s."" % unit)\n\n    def _notes_in_beats(self, notes):\n        """"""\n        Converts onsets and offsets of notes from ticks to beats.\n\n        Parameters\n        ----------\n        notes : numpy array or list of tuples\n            Notes (onset, pitch, offset, velocity).\n\n        Returns\n        -------\n        notes : numpy array\n            Notes with onsets and offsets in beats.\n\n        """"""\n        tpq = self.ticks_per_quarter_note\n        time_signatures = self.time_signatures(suppress_warnings=True)\n\n        # change the second column of time_signatures to beat position of the\n        # signature change, the first column is now the tick position, the\n        # second column the beat position and the third column the new beat\n        # unit after the signature change\n        time_signatures[0, 1] = 0\n\n        # quarter notes between time signature changes\n        qnbtsc = np.diff(time_signatures[:, 0]) / tpq\n        # beats between time signature changes\n        bbtsc = qnbtsc * (time_signatures[:-1, 2] / 4.0)\n        # compute beat position of each time signature change\n        time_signatures[1:, 1] = bbtsc.cumsum()\n\n        # iterate over all notes\n        for note in notes:\n            onset, _, offset, _, _ = note\n            # get info about last time signature change\n            tsc = time_signatures[np.argmax(time_signatures[:, 0] > onset) - 1]\n            # adjust onset\n            onset_ticks_since_tsc = onset - tsc[0]\n            note[0] = tsc[1] + (onset_ticks_since_tsc / tpq) * (tsc[2] / 4.)\n            # adjust offsets\n            offset_ticks_since_tsc = offset - tsc[0]\n            note[2] = tsc[1] + (offset_ticks_since_tsc / tpq) * (tsc[2] / 4.)\n        # return notes\n        return notes\n\n    def _notes_in_seconds(self, notes):\n        """"""\n        Converts onsets and offsets of notes from ticks to seconds.\n\n        Parameters\n        ----------\n        notes : numpy array or list of tuples\n            Notes (onset, pitch, offset, velocity).\n\n        Returns\n        -------\n        notes : numpy array\n            Notes with onset and offset times in seconds.\n\n        """"""\n        # cache tempo\n        tempi = self.tempi(suppress_warnings=True)\n        # iterate over all notes\n        for note in notes:\n            onset, _, offset, _, _ = note\n            # get last tempo for the onset and offset\n            t_on = tempi[np.argmax(tempi[:, 0] > onset) - 1]\n            t_off = tempi[np.argmax(tempi[:, 0] > offset) - 1]\n            # adjust the note onset and offset\n            note[0] = (onset - t_on[0]) * t_on[1] + t_on[2]\n            note[2] = (offset - t_off[0]) * t_off[1] + t_off[2]\n        # return notes\n        return notes\n\n    # methods for writing MIDI stuff\n    @property\n    def data_stream(self):\n        """"""\n        MIDI data stream representation of the MIDI file.\n\n        """"""\n        # prepare data\n        data = bytearray()\n        # generate a MIDI header\n        data.extend(b\'MThd\')\n        data.extend(struct.pack("">LHHH"", 6, self.format, len(self.tracks),\n                                self.resolution))\n        # append the tracks\n        for track in self.tracks:\n            data.extend(track.data_stream)\n        # return the data\n        return data\n\n    def write(self, midi_file):\n        """"""\n        Write a MIDI file.\n\n        Parameters\n        ----------\n        midi_file : str\n            The MIDI file name.\n\n        """"""\n        # if we get a filename, open the file\n        if not hasattr(midi_file, \'write\'):\n            midi_file = open(midi_file, \'wb\')\n        # write the MIDI stream\n        midi_file.write(self.data_stream)\n        # close the file\n        midi_file.close()\n\n    @classmethod\n    def from_file(cls, midi_file):\n        """"""\n        Create a MIDI file instance from a .mid file.\n\n        Parameters\n        ----------\n        midi_file : str\n            Name of the .mid file to load.\n\n        Returns\n        -------\n        :class:`MIDIFile` instance\n            :class:`MIDIFile` instance\n\n        """"""\n        tracks = []\n        resolution = None\n        midi_format = None\n        with open(midi_file, \'rb\') as midi_file:\n            # read in file header\n            # first four bytes are MIDI header\n            chunk = midi_file.read(4)\n            if chunk != b\'MThd\':\n                raise TypeError(""Bad header in MIDI file: %s"", chunk)\n            # next four bytes are header size\n            # next two bytes specify the format version\n            # next two bytes specify the number of tracks\n            # next two bytes specify the resolution/PPQ/Parts Per Quarter\n            # (in other words, how many ticks per quarter note)\n            data = struct.unpack("">LHHH"", midi_file.read(10))\n            header_size = data[0]\n            midi_format = data[1]\n            num_tracks = data[2]\n            resolution = data[3]\n            # if the top bit of the resolution word is 0, the following 15 bits\n            # describe the time division in ticks per beat\n            if resolution & 0x8000 == 0:\n                resolution = resolution\n            # otherwise the following 15 bits describe the time division in\n            # frames per second\n            else:\n                # from http://www.sonicspot.com/guide/midifiles.html:\n                # Frames per second is defined by breaking the remaining 15\n                # bytes into two values. The top 7 bits (bit mask 0x7F00)\n                # define a value for the number of SMPTE frames and can be\n                # 24, 25, 29 (for 29.97 fps) or 30. The remaining byte\n                # (bit mask 0x00FF) defines how many clock ticks or track delta\n                # positions there are per frame. So a time division example of\n                # 0x9978 could be broken down into it\'s three parts: the top\n                # bit is one, so it is in SMPTE frames per second format, the\n                # following 7 bits have a value of 25 (0x19) and the bottom\n                # byte has a value of 120 (0x78). This means the example plays\n                # at 24(?) frames per second SMPTE time and has 120 ticks per\n                # frame.\n                raise NotImplementedError(""SMPTE resolution not implemented."")\n            # skip the remaining part of the header\n            if header_size > HEADER_SIZE:\n                midi_file.read(header_size - HEADER_SIZE)\n            # read in all tracks\n            for _ in range(num_tracks):\n                # read in one track and append it to the tracks list\n                track = MIDITrack.from_stream(midi_file)\n                tracks.append(track)\n        if resolution is None or midi_format is None:\n            raise IOError(\'unable to read MIDI file %s.\' % midi_file)\n        # return a newly created object\n        return cls(tracks=tracks, resolution=resolution,\n                   file_format=midi_format)\n\n    @classmethod\n    def from_notes(cls, notes, tempo=TEMPO, time_signature=TIME_SIGNATURE,\n                   resolution=RESOLUTION):\n        """"""\n        Create a MIDIFile from the given notes.\n\n        Parameters\n        ----------\n        notes : numpy array\n            Array with the notes, one per row. The columns must be:\n            (onset time, pitch, duration, velocity, [channel]).\n        tempo : float, optional\n            Tempo of the MIDI track, given in beats per minute (bpm).\n        time_signature : tuple, optional\n            Time signature of the track, e.g. (4, 4) for 4/4.\n        resolution : int\n            Resolution (i.e. ticks per quarter note) of the MIDI track.\n\n        Returns\n        -------\n        :class:`MIDIFile` instance\n            :class:`MIDIFile` instance with all notes collected in one track.\n\n        Notes\n        -----\n        All note events (including the generated tempo and time signature\n        events) are written into a single track (i.e. MIDI file format 0).\n\n        """"""\n        # create a new track from the notes and then a MIDIFile instance\n        return cls(MIDITrack.from_notes(notes, tempo, time_signature,\n                                        resolution))\n\n    @staticmethod\n    def add_arguments(parser, length=None, velocity=None, channel=None):\n        """"""\n        Add MIDI related arguments to an existing parser object.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        length : float, optional\n            Default length of the notes [seconds].\n        velocity : int, optional\n            Default velocity of the notes.\n        channel : int, optional\n            Default channel of the notes.\n\n        Returns\n        -------\n        argparse argument group\n            MIDI argument parser group object.\n\n        """"""\n        # add MIDI related options to the existing parser\n        g = parser.add_argument_group(\'MIDI arguments\')\n        g.add_argument(\'--midi\', action=\'store_true\', help=\'save as MIDI\')\n        if length is not None:\n            g.add_argument(\'--note_length\', action=\'store\', type=float,\n                           default=length,\n                           help=\'set the note length [default=%(default).2f]\')\n        if velocity is not None:\n            g.add_argument(\'--note_velocity\', action=\'store\', type=int,\n                           default=velocity,\n                           help=\'set the note velocity [default=%(default)i]\')\n        if channel is not None:\n            g.add_argument(\'--note_channel\', action=\'store\', type=int,\n                           default=channel,\n                           help=\'set the note channel [default=%(default)i]\')\n        # return the argument group so it can be modified if needed\n        return g\n\n\ndef process_notes(data, output=None):\n    """"""\n    This is a simple processing function. It either loads the notes from a MIDI\n    file and or writes the notes to a file.\n\n    The behaviour depends on the presence of the `output` argument, if \'None\'\n    is given, the notes are read, otherwise the notes are written to file.\n\n    Parameters\n    ----------\n    data : str or numpy array\n        MIDI file to be loaded (if `output` is \'None\') / notes to be written.\n    output : str, optional\n        Output file name. If set, the notes given by `data` are written.\n\n    Returns\n    -------\n    notes : numpy array\n        Notes read/written.\n\n    """"""\n    if output is None:\n        # load the notes\n        return MIDIFile.from_file(data).notes()\n    MIDIFile.from_notes(data).write(output)\n    return data\n'"
madmom/utils/stats.py,6,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n""""""\nThis module contains some statistical functionality.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\n\ndef mcnemar_test(test_1, test_2, significance=0.01):\n    """"""\n    Perform McNemar\'s statistical test.\n\n    Parameters\n    ----------\n    test_1 : numpy array\n        Test 1 sample(s).\n    test_2 : numpy array\n        Test 2 sample(s).\n    significance : float, optional\n        Significance level.\n\n    Returns\n    -------\n    significance : int\n        Significance {-1, 0, +1}.\n    p_value : float\n        P-value.\n\n    Notes\n    -----\n    Please see: http://en.wikipedia.org/wiki/McNemar%27s_test\n\n    +-----------------+-----------------+-----------------+-----------+\n    |                 | Test 2 positive | Test 2 negative | Row total |\n    +-----------------+-----------------+-----------------+-----------+\n    | Test 1 positive |        a        |        b        |   a + b   |\n    | Test 1 negative |        c        |        d        |   c + d   |\n    +-----------------+-----------------+-----------------+-----------+\n    | Column total    |      a + c      |      b + d      |     n     |\n    +-----------------+-----------------+-----------------+-----------+\n\n    """"""\n    from scipy.stats import chi2\n    # convert the tests to numpy arrays\n    test_1 = np.asarray(test_1)\n    test_2 = np.asarray(test_2)\n    # both test must have the same length\n    if not (test_1.size == test_2.size and test_1.shape == test_2.shape):\n        raise ValueError(""Both tests must have the same size and shape."")\n    # calculate a, b, c, d\n    # a = np.sum(test_1 * test_2)\n    b = np.sum(test_1 > test_2)\n    c = np.sum(test_1 < test_2)\n    # d = np.sum(-test_1 * -test_2)\n    # is the approximation ok?\n    if b + c < 25:\n        raise NotImplementedError(""implement correct binomial distribution or ""\n                                  ""use bigger sample sizes (b + c > 25)"")\n    # statistical test\n    stat = (b - c) ** 2 / float(b + c)\n    # test under chi square distribution\n    p = chi2(1).sf(stat)\n    # direction of significance\n    sig = 0\n    if p < significance:\n        sig = 1 if b > c else -1\n    return sig, p\n'"
madmom/ml/nn/__init__.py,7,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n# pylint: disable=too-few-public-methods\n""""""\nNeural Network package.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\nfrom . import layers, activations\nfrom ...processors import Processor, ParallelProcessor, SequentialProcessor\n\n\ndef average_predictions(predictions):\n    """"""\n    Returns the average of all predictions.\n\n    Parameters\n    ----------\n    predictions : list\n        Predictions (i.e. NN activation functions).\n\n    Returns\n    -------\n    numpy array\n        Averaged prediction.\n\n    """"""\n    # average predictions if needed\n    if len(predictions) > 1:\n        # average the predictions\n        predictions = sum(predictions) / len(predictions)\n    else:\n        # nothing to average since we have only one prediction\n        predictions = predictions[0]\n    # return the (averaged) predictions\n    return predictions\n\n\nclass NeuralNetwork(Processor):\n    """"""\n    Neural Network class.\n\n    Parameters\n    ----------\n    layers : list\n        Layers of the Neural Network.\n\n    Examples\n    --------\n    Create a NeuralNetwork from the given layers.\n\n    >>> from madmom.ml.nn.layers import FeedForwardLayer\n    >>> from madmom.ml.nn.activations import tanh, sigmoid\n    >>> l1_weights = np.array([[0.5, -1., -0.3 , -0.2]])\n    >>> l1_bias = np.array([0.05, 0., 0.8, -0.5])\n    >>> l1 = FeedForwardLayer(l1_weights, l1_bias, activation_fn=tanh)\n    >>> l2_weights = np.array([-1, 0.9, -0.2 , 0.4])\n    >>> l2_bias = np.array([0.5])\n    >>> l2 = FeedForwardLayer(l2_weights, l2_bias, activation_fn=sigmoid)\n    >>> nn = NeuralNetwork([l1, l2])\n    >>> nn  # doctest: +ELLIPSIS\n    <madmom.ml.nn.NeuralNetwork object at 0x...>\n    >>> nn(np.array([[0], [0.5], [1], [0], [1], [2], [0]]))\n    ... # doctest: +NORMALIZE_WHITESPACE\n    array([0.53305, 0.36903, 0.265 , 0.53305, 0.265 , 0.18612, 0.53305])\n\n    """"""\n\n    def __init__(self, layers):\n        self.layers = layers\n\n    def process(self, data, reset=True, **kwargs):\n        """"""\n        Process the given data with the neural network.\n\n        Parameters\n        ----------\n        data : numpy array, shape (num_frames, num_inputs)\n            Activate the network with this data.\n        reset : bool, optional\n            Reset the network to its initial state before activating it.\n\n        Returns\n        -------\n        numpy array, shape (num_frames, num_outputs)\n            Network predictions for this data.\n\n        """"""\n        # make data at least 2d (required by NN-layers)\n        if data.ndim < 2:\n            data = np.array(data, subok=True, copy=False, ndmin=2)\n        # loop over all layers\n        for layer in self.layers:\n            # activate the layer and feed the output into the next one\n            data = layer.activate(data, reset=reset)\n        # ravel the predictions if needed\n        if data.ndim == 2 and data.shape[1] == 1:\n            data = data.ravel()\n        return data\n\n    def reset(self):\n        """"""\n        Reset the neural network to its initial state.\n\n        """"""\n        for layer in self.layers:\n            layer.reset()\n\n\nclass NeuralNetworkEnsemble(SequentialProcessor):\n    """"""\n    Neural Network ensemble class.\n\n    Parameters\n    ----------\n    networks : list\n        List of the Neural Networks.\n    ensemble_fn : function or callable, optional\n        Ensemble function to be applied to the predictions of the neural\n        network ensemble (default: average predictions).\n    num_threads : int, optional\n        Number of parallel working threads.\n\n    Notes\n    -----\n    If `ensemble_fn` is set to \'None\', the predictions are returned as a list\n    with the same length as the number of networks given.\n\n    Examples\n    --------\n    Create a NeuralNetworkEnsemble from the networks. Instead of supplying\n    the neural networks as parameter, they can also be loaded from file:\n\n    >>> from madmom.models import ONSETS_BRNN_PP\n    >>> nn = NeuralNetworkEnsemble.load(ONSETS_BRNN_PP)\n    >>> nn  # doctest: +ELLIPSIS\n    <madmom.ml.nn.NeuralNetworkEnsemble object at 0x...>\n    >>> nn(np.array([[0], [0.5], [1], [0], [1], [2], [0]]))\n    ... # doctest: +NORMALIZE_WHITESPACE\n    array([0.00116, 0.00213, 0.01428, 0.00729, 0.0088 , 0.21965, 0.00532])\n\n    """"""\n\n    def __init__(self, networks, ensemble_fn=average_predictions,\n                 num_threads=None, **kwargs):\n        networks_processor = ParallelProcessor(networks,\n                                               num_threads=num_threads)\n        super(NeuralNetworkEnsemble, self).__init__((networks_processor,\n                                                     ensemble_fn))\n\n    @classmethod\n    def load(cls, nn_files, **kwargs):\n        """"""\n        Instantiate a new Neural Network ensemble from a list of files.\n\n        Parameters\n        ----------\n        nn_files : list\n            List of neural network model file names.\n        kwargs : dict, optional\n            Keyword arguments passed to NeuralNetworkEnsemble.\n\n        Returns\n        -------\n        NeuralNetworkEnsemble\n            NeuralNetworkEnsemble instance.\n\n        """"""\n        networks = [NeuralNetwork.load(f) for f in nn_files]\n        return cls(networks, **kwargs)\n\n    @staticmethod\n    def add_arguments(parser, nn_files):\n        """"""\n        Add neural network options to an existing parser.\n\n        Parameters\n        ----------\n        parser : argparse parser instance\n            Existing argparse parser object.\n        nn_files : list\n            Neural network model files.\n\n        Returns\n        -------\n        argparse argument group\n            Neural network argument parser group.\n\n        """"""\n        # pylint: disable=signature-differs\n        from madmom.utils import OverrideDefaultListAction\n        # add neural network options\n        g = parser.add_argument_group(\'neural network arguments\')\n        g.add_argument(\'--nn_files\', action=OverrideDefaultListAction,\n                       type=str, default=nn_files,\n                       help=\'average the predictions of these pre-trained \'\n                            \'neural networks (multiple files can be given, \'\n                            \'one file per argument)\')\n        # return the argument group so it can be modified if needed\n        return g\n'"
madmom/ml/nn/activations.py,11,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n""""""\nThis module contains neural network activation functions for the ml.nn module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\n\ndef linear(x, out=None):\n    """"""\n    Linear function.\n\n    Parameters\n    ----------\n    x : numpy array\n        Input data.\n    out : numpy array, optional\n        Array to hold the output data.\n\n    Returns\n    -------\n    numpy array\n        Unaltered input data.\n\n    """"""\n    if out is None or x is out:\n        return x\n    out[:] = x\n    return out\n\n\ndef tanh(x, out=None):\n    """"""\n    Hyperbolic tangent function.\n\n    Parameters\n    ----------\n    x : numpy array\n        Input data.\n    out : numpy array, optional\n        Array to hold the output data.\n\n    Returns\n    -------\n    numpy array\n        Hyperbolic tangent of input data.\n\n    """"""\n    # Note: define a wrapper around np.tanh so we just have the dependency on\n    #       madmom when pickling objects\n    return np.tanh(x, out)\n\n\ntry:\n    # pylint: disable=no-name-in-module\n    # pylint: disable=wrong-import-order\n    # pylint: disable=wrong-import-position\n\n    # try to use a faster sigmoid function\n    from distutils.version import LooseVersion\n    from scipy.version import version as scipy_version\n    # we need a recent version of scipy, older have a bug in expit\n    # https://github.com/scipy/scipy/issues/3385\n    if LooseVersion(scipy_version) < LooseVersion(""0.14""):\n        # Note: Raising an AttributeError might not be the best idea ever\n        #       (i.e. ImportError would be more appropriate), but older\n        #       versions of scipy not having the expit function raise the same\n        #       error. In some cases this check fails, don\'t know why...\n        raise AttributeError\n    from scipy.special import expit as _sigmoid\nexcept AttributeError:\n    # define a fallback function\n    def _sigmoid(x, out=None):\n        """"""\n        Logistic sigmoid function.\n\n        Parameters\n        ----------\n        x : numpy array\n            Input data.\n        out : numpy array, optional\n            Array to hold the output data.\n\n        Returns\n        -------\n        numpy array\n            Logistic sigmoid of input data.\n\n        """"""\n        # sigmoid = 0.5 * (1. + np.tanh(0.5 * x))\n        if out is None:\n            out = np.asarray(.5 * x)\n        else:\n            if out is not x:\n                out[:] = x\n            out *= .5\n        np.tanh(out, out=out)\n        out += 1\n        out *= .5\n        return out\n\n\ndef sigmoid(x, out=None):\n    """"""\n    Logistic sigmoid function.\n\n    Parameters\n    ----------\n    x : numpy array\n        Input data.\n    out : numpy array, optional\n        Array to hold the output data.\n\n    Returns\n    -------\n    numpy array\n        Logistic sigmoid of input data.\n\n    """"""\n    # Note: define a wrapper around _sigmoid so we just have the dependency on\n    #       madmom when pickling objects, not on scipy.special which may\n    #       contain the bug mentioned above\n    return _sigmoid(x, out)\n\n\ndef relu(x, out=None):\n    """"""\n    Rectified linear (unit) transfer function.\n\n    Parameters\n    ----------\n    x : numpy array\n        Input data.\n    out : numpy array, optional\n        Array to hold the output data.\n\n    Returns\n    -------\n    numpy array\n        Rectified linear of input data.\n\n    """"""\n    return np.maximum(x, 0, out)\n\n\ndef elu(x, out=None):\n    """"""\n    Exponential linear (unit) transfer function.\n\n    Parameters\n    ----------\n    x : numpy array\n        Input data.\n    out : numpy array, optional\n        Array to hold the output data.\n\n    Returns\n    -------\n    numpy array\n        Exponential linear of input data\n\n    References\n    ----------\n    .. [1] Djork-Arn\xc3\xa9 Clevert, Thomas Unterthiner, Sepp Hochreiter (2015):\n       Fast and Accurate Deep Network Learning by Exponential Linear Units\n       (ELUs), http://arxiv.org/abs/1511.07289\n    """"""\n    if out is None:\n        out = x.copy()\n    elif out is not x:\n        out[:] = x[:]\n    m = x < 0\n    out[m] = np.exp(x[m]) - 1\n    return out\n\n\ndef softmax(x, out=None):\n    """"""\n    Softmax transfer function.\n\n    Parameters\n    ----------\n    x : numpy array\n        Input data.\n    out : numpy array, optional\n        Array to hold the output data.\n\n    Returns\n    -------\n    numpy array\n        Softmax of input data.\n\n    """"""\n    # determine maximum (over classes)\n    tmp = np.amax(x, axis=1, keepdims=True)\n    # exp of the input minus the max\n    if out is None:\n        out = np.exp(x - tmp)\n    else:\n        np.exp(x - tmp, out=out)\n    # normalize by the sum (reusing the tmp variable)\n    np.sum(out, axis=1, keepdims=True, out=tmp)\n    out /= tmp\n    return out\n'"
madmom/ml/nn/layers.py,28,"b'# encoding: utf-8\n# pylint: disable=no-member\n# pylint: disable=invalid-name\n# pylint: disable=too-many-arguments\n# pylint: disable=too-few-public-methods\n""""""\nThis module contains neural network layers for the ml.nn module.\n\n""""""\n\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\n\nfrom .activations import linear, sigmoid, tanh\n\nNN_DTYPE = np.float32\n\n\nclass Layer(object):\n    """"""\n    Generic callable network layer.\n\n    """"""\n\n    def __call__(self, *args, **kwargs):\n        # this magic method makes a Layer callable\n        return self.activate(*args, **kwargs)\n\n    def activate(self, data):\n        """"""\n        Activate the layer.\n\n        Parameters\n        ----------\n        data : numpy array\n            Activate with this data.\n\n        Returns\n        -------\n        numpy array\n            Activations for this data.\n\n        """"""\n        raise NotImplementedError(\'must be implemented by subclass.\')\n\n    def reset(self):\n        """"""\n        Reset the layer to its initial state.\n\n        """"""\n        return None\n\n\nclass FeedForwardLayer(Layer):\n    """"""\n    Feed-forward network layer.\n\n    Parameters\n    ----------\n    weights : numpy array, shape (num_inputs, num_hiddens)\n        Weights.\n    bias : scalar or numpy array, shape (num_hiddens,)\n        Bias.\n    activation_fn : numpy ufunc\n        Activation function.\n\n    """"""\n\n    def __init__(self, weights, bias, activation_fn):\n        self.weights = weights\n        self.bias = bias.flatten()\n        self.activation_fn = activation_fn\n\n    def activate(self, data, **kwargs):\n        """"""\n        Activate the layer.\n\n        Parameters\n        ----------\n        data : numpy array, shape (num_frames, num_inputs)\n            Activate with this data.\n\n        Returns\n        -------\n        numpy array, shape (num_frames, num_hiddens)\n            Activations for this data.\n\n        """"""\n        # weight input, add bias and apply activations function\n        out = np.dot(data, self.weights) + self.bias\n        return self.activation_fn(out)\n\n\nclass RecurrentLayer(FeedForwardLayer):\n    """"""\n    Recurrent network layer.\n\n    Parameters\n    ----------\n    weights : numpy array, shape (num_inputs, num_hiddens)\n        Weights.\n    bias : scalar or numpy array, shape (num_hiddens,)\n        Bias.\n    recurrent_weights : numpy array, shape (num_hiddens, num_hiddens)\n        Recurrent weights.\n    activation_fn : numpy ufunc\n        Activation function.\n    init : numpy array, shape (num_hiddens,), optional\n        Initial state of hidden units.\n\n    """"""\n\n    def __init__(self, weights, bias, recurrent_weights, activation_fn,\n                 init=None):\n        super(RecurrentLayer, self).__init__(weights, bias, activation_fn)\n        self.recurrent_weights = recurrent_weights\n        if init is None:\n            init = np.zeros(self.bias.size, dtype=NN_DTYPE)\n        self.init = init\n        # attributes needed for stateful processing\n        self._prev = self.init\n\n    def __getstate__(self):\n        # copy everything to a picklable object\n        state = self.__dict__.copy()\n        # do not pickle attributes needed for stateful processing\n        state.pop(\'_prev\', None)\n        return state\n\n    def __setstate__(self, state):\n        # restore pickled instance attributes\n        self.__dict__.update(state)\n        # TODO: old models do not have the init attribute, thus create it\n        #       remove this initialisation code after updating the models\n        if not hasattr(self, \'init\'):\n            self.init = np.zeros(self.bias.size, dtype=NN_DTYPE)\n        # add non-pickled attributes needed for stateful processing\n        self._prev = self.init\n\n    def reset(self, init=None):\n        """"""\n        Reset the layer to its initial state.\n\n        Parameters\n        ----------\n        init : numpy array, shape (num_hiddens,), optional\n            Reset the hidden units to this initial state.\n\n        """"""\n        # reset previous time step to initial value\n        self._prev = init if init is not None else self.init\n\n    def activate(self, data, reset=True):\n        """"""\n        Activate the layer.\n\n        Parameters\n        ----------\n        data : numpy array, shape (num_frames, num_inputs)\n            Activate with this data.\n        reset : bool, optional\n            Reset the layer to its initial state before activating it.\n\n        Returns\n        -------\n        numpy array, shape (num_frames, num_hiddens)\n            Activations for this data.\n\n        """"""\n        # reset layer to initial state\n        if reset:\n            self.reset()\n        # weight input and add bias\n        out = np.dot(data, self.weights) + self.bias\n        # loop through all time steps\n        for i in range(len(data)):\n            # add weighted previous step\n            out[i] += np.dot(self._prev, self.recurrent_weights)\n            # apply activation function\n            out[i] = self.activation_fn(out[i])\n            # set reference to current output\n            self._prev = out[i]\n        # return\n        return out\n\n\nclass BidirectionalLayer(Layer):\n    """"""\n    Bidirectional network layer.\n\n    Parameters\n    ----------\n    fwd_layer : Layer instance\n        Forward layer.\n    bwd_layer : Layer instance\n        Backward layer.\n\n    """"""\n\n    def __init__(self, fwd_layer, bwd_layer):\n        self.fwd_layer = fwd_layer\n        self.bwd_layer = bwd_layer\n\n    def activate(self, data, **kwargs):\n        """"""\n        Activate the layer.\n\n        After activating the `fwd_layer` with the data and the `bwd_layer` with\n        the data in reverse temporal order, the two activations are stacked and\n        returned.\n\n        Parameters\n        ----------\n        data : numpy array, shape (num_frames, num_inputs)\n            Activate with this data.\n\n        Returns\n        -------\n        numpy array, shape (num_frames, num_hiddens)\n            Activations for this data.\n\n        """"""\n        # activate in forward direction\n        fwd = self.fwd_layer(data, **kwargs)\n        # also activate with reverse input\n        bwd = self.bwd_layer(data[::-1], **kwargs)\n        # stack data\n        return np.hstack((fwd, bwd[::-1]))\n\n\n# LSTM stuff\nclass Gate(RecurrentLayer):\n    """"""\n    Gate as used by LSTM layers.\n\n    Parameters\n    ----------\n    weights : numpy array, shape (num_inputs, num_hiddens)\n        Weights.\n    bias : scalar or numpy array, shape (num_hiddens,)\n        Bias.\n    recurrent_weights : numpy array, shape (num_hiddens, num_hiddens)\n        Recurrent weights.\n    peephole_weights : numpy array, shape (num_hiddens,), optional\n        Peephole weights.\n    activation_fn : numpy ufunc, optional\n        Activation function.\n\n    Notes\n    -----\n    Gate should not be used directly, only inside an LSTMLayer.\n\n    """"""\n\n    def __init__(self, weights, bias, recurrent_weights, peephole_weights=None,\n                 activation_fn=sigmoid):\n        super(Gate, self).__init__(weights, bias, recurrent_weights,\n                                   activation_fn=activation_fn)\n        if peephole_weights is not None:\n            peephole_weights = peephole_weights.flatten()\n        self.peephole_weights = peephole_weights\n\n    def activate(self, data, prev, state=None):\n        """"""\n        Activate the gate with the given data, state (if peephole connections\n        are used) and the previous output (if recurrent connections are used).\n\n        Parameters\n        ----------\n        data : scalar or numpy array, shape (num_hiddens,)\n            Input data for the cell.\n        prev : scalar or numpy array, shape (num_hiddens,)\n            Output data of the previous time step.\n        state : scalar or numpy array, shape (num_hiddens,)\n            State data of the {current | previous} time step.\n\n        Returns\n        -------\n        numpy array, shape (num_hiddens,)\n            Activations of the gate for this data.\n\n        """"""\n        # weight input and add bias\n        out = np.dot(data, self.weights) + self.bias\n        # add the previous state weighted by the peephole\n        if self.peephole_weights is not None:\n            out += state * self.peephole_weights\n        # add recurrent connection\n        out += np.dot(prev, self.recurrent_weights)\n        # apply activation function and return it\n        return self.activation_fn(out)\n\n\nclass Cell(Gate):\n    """"""\n    Cell as used by LSTM layers.\n\n    Parameters\n    ----------\n    weights : numpy array, shape (num_inputs, num_hiddens)\n        Weights.\n    bias : scalar or numpy array, shape (num_hiddens,)\n        Bias.\n    recurrent_weights : numpy array, shape (num_hiddens, num_hiddens)\n        Recurrent weights.\n    activation_fn : numpy ufunc, optional\n        Activation function.\n\n    Notes\n    -----\n    A Cell is the same as a Gate except it misses peephole connections and\n    has a `tanh` activation function. It should not be used directly, only\n    inside an LSTMLayer.\n\n    """"""\n\n    def __init__(self, weights, bias, recurrent_weights, activation_fn=tanh):\n        super(Cell, self).__init__(weights, bias, recurrent_weights,\n                                   activation_fn=activation_fn)\n\n\nclass LSTMLayer(RecurrentLayer):\n    """"""\n    Recurrent network layer with Long Short-Term Memory units.\n\n    Parameters\n    ----------\n    input_gate : :class:`Gate`\n        Input gate.\n    forget_gate : :class:`Gate`\n        Forget gate.\n    cell : :class:`Cell`\n        Cell (i.e. a Gate without peephole connections).\n    output_gate : :class:`Gate`\n        Output gate.\n    activation_fn : numpy ufunc, optional\n        Activation function.\n    init : numpy array, shape (num_hiddens, ), optional\n        Initial state of the layer.\n    cell_init : numpy array, shape (num_hiddens, ), optional\n        Initial state of the cell.\n\n    """"""\n\n    def __init__(self, input_gate, forget_gate, cell, output_gate,\n                 activation_fn=tanh, init=None, cell_init=None):\n        self.input_gate = input_gate\n        self.forget_gate = forget_gate\n        self.cell = cell\n        self.output_gate = output_gate\n        self.activation_fn = activation_fn\n        # keep the state of the layer and cell\n        if init is None:\n            init = np.zeros(self.cell.bias.size, dtype=NN_DTYPE)\n        self.init = init\n        self._prev = self.init\n        if cell_init is None:\n            cell_init = np.zeros(self.cell.bias.size, dtype=NN_DTYPE)\n        self.cell_init = cell_init\n        self._state = self.cell_init\n\n    def __getstate__(self):\n        # copy everything to a picklable object\n        state = self.__dict__.copy()\n        # do not pickle attributes needed for stateful processing\n        state.pop(\'_prev\', None)\n        state.pop(\'_state\', None)\n        return state\n\n    def __setstate__(self, state):\n        # restore pickled instance attributes\n        self.__dict__.update(state)\n        # TODO: old models do not have the init attributes, thus create them\n        #       remove this initialisation code after updating the models\n        if not hasattr(self, \'init\'):\n            self.init = np.zeros(self.cell.bias.size, dtype=NN_DTYPE)\n        if not hasattr(self, \'cell_init\'):\n            self.cell_init = np.zeros(self.cell.bias.size, dtype=NN_DTYPE)\n        # add non-pickled attributes needed for stateful processing\n        self._prev = self.init\n        self._state = self.cell_init\n\n    def reset(self, init=None, cell_init=None):\n        """"""\n        Reset the layer to its initial state.\n\n        Parameters\n        ----------\n        init : numpy array, shape (num_hiddens,), optional\n            Reset the hidden units to this initial state.\n        cell_init : numpy array, shape (num_hiddens,), optional\n            Reset the cells to this initial state.\n\n        """"""\n        # reset previous time step and state to initial value\n        self._prev = init if init is not None else self.init\n        self._state = cell_init if cell_init is not None else self.cell_init\n\n    def activate(self, data, reset=True):\n        """"""\n        Activate the LSTM layer.\n\n        Parameters\n        ----------\n        data : numpy array, shape (num_frames, num_inputs)\n            Activate with this data.\n        reset : bool, optional\n            Reset the layer to its initial state before activating it.\n\n        Returns\n        -------\n        numpy array, shape (num_frames, num_hiddens)\n            Activations for this data.\n\n        """"""\n        # reset layer\n        if reset:\n            self.reset()\n        # init arrays\n        size = len(data)\n        # output matrix for the whole sequence\n        out = np.zeros((size, self.cell.bias.size), dtype=NN_DTYPE)\n        # process the input data\n        for i in range(size):\n            # cache input data\n            data_ = data[i]\n            # input gate:\n            # operate on current data, previous output and state\n            ig = self.input_gate.activate(data_, self._prev, self._state)\n            # forget gate:\n            # operate on current data, previous output and state\n            fg = self.forget_gate.activate(data_, self._prev, self._state)\n            # cell:\n            # operate on current data and previous output\n            cell = self.cell.activate(data_, self._prev)\n            # internal state:\n            # weight the cell with the input gate\n            # and add the previous state weighted by the forget gate\n            self._state = cell * ig + self._state * fg\n            # output gate:\n            # operate on current data, previous output and current state\n            og = self.output_gate.activate(data_, self._prev, self._state)\n            # output:\n            # apply activation function to state and weight by output gate\n            out[i] = self.activation_fn(self._state) * og\n            # set reference to current output\n            self._prev = out[i]\n        return out\n\n\nclass GRUCell(Cell):\n    """"""\n    Cell as used by GRU layers proposed in [1]_. The cell output is computed by\n\n    .. math::\n        h = tanh(W_{xh} * x_t + W_{hh} * h_{t-1} + b).\n\n    Parameters\n    ----------\n    weights : numpy array, shape (num_inputs, num_hiddens)\n        Weights of the connections between inputs and cell.\n    bias : scalar or numpy array, shape (num_hiddens,)\n        Bias.\n    recurrent_weights : numpy array, shape (num_hiddens, num_hiddens)\n        Weights of the connections between cell and cell output of the\n        previous time step.\n    activation_fn : numpy ufunc, optional\n        Activation function.\n\n    References\n    ----------\n    .. [1] Kyunghyun Cho, Bart Van Merrienboer, Dzmitry Bahdanau, and Yoshua\n           Bengio,\n           ""On the properties of neural machine translation: Encoder-decoder\n           approaches"", http://arxiv.org/abs/1409.1259, 2014.\n\n    Notes\n    -----\n    There are two formulations of the GRUCell in the literature. Here,\n    we adopted the (slightly older) one proposed in [1]_, which is also\n    implemented in the Lasagne toolbox.\n\n    It should not be used directly, only inside a GRULayer.\n\n    """"""\n\n    def __init__(self, weights, bias, recurrent_weights, activation_fn=tanh):\n        super(GRUCell, self).__init__(weights, bias, recurrent_weights,\n                                      activation_fn)\n\n    def activate(self, data, prev, reset_gate):\n        """"""\n        Activate the cell with the given input, previous output and reset gate.\n\n        Parameters\n        ----------\n        data : numpy array, shape (num_inputs,)\n            Input data for the cell.\n        prev : numpy array, shape (num_hiddens,)\n            Output of the previous time step.\n        reset_gate : numpy array, shape (num_hiddens,)\n            Activation of the reset gate.\n\n        Returns\n        -------\n        numpy array, shape (num_hiddens,)\n            Activations of the cell for this data.\n\n        """"""\n        # weight input and add bias\n        out = np.dot(data, self.weights) + self.bias\n        # weight previous cell output and reset gate\n        out += reset_gate * np.dot(prev, self.recurrent_weights)\n        # apply activation function and return it\n        return self.activation_fn(out)\n\n\nclass GRULayer(RecurrentLayer):\n    """"""\n    Recurrent network layer with Gated Recurrent Units (GRU) as proposed in\n    [1]_.\n\n    Parameters\n    ----------\n    reset_gate : :class:`Gate`\n        Reset gate.\n    update_gate : :class:`Gate`\n        Update gate.\n    cell : :class:`GRUCell`\n        GRU cell.\n    init : numpy array, shape (num_hiddens,), optional\n        Initial state of hidden units.\n\n    References\n    ----------\n    .. [1] Kyunghyun Cho, Bart van Merri\xc3\xabnboer, Dzmitry Bahdanau, and Yoshua\n           Bengio,\n           ""On the properties of neural machine translation: Encoder-decoder\n           approaches"",\n           http://arxiv.org/abs/1409.1259, 2014.\n\n    Notes\n    -----\n    There are two formulations of the GRUCell in the literature. Here,\n    we adopted the (slightly older) one proposed in [1], which is also\n    implemented in the Lasagne toolbox.\n\n    """"""\n\n    def __init__(self, reset_gate, update_gate, cell, init=None):\n        # init the gates\n        self.reset_gate = reset_gate\n        self.update_gate = update_gate\n        self.cell = cell\n        # keep the state of the layer\n        if init is None:\n            init = np.zeros(self.cell.bias.size, dtype=NN_DTYPE)\n        self.init = init\n        # keep the state of the layer\n        self._prev = self.init\n\n    def __getstate__(self):\n        # copy everything to a picklable object\n        state = self.__dict__.copy()\n        # do not pickle attributes needed for stateful processing\n        state.pop(\'_prev\', None)\n        return state\n\n    def __setstate__(self, state):\n        # TODO: old models have a \'hid_init\' instead of an \'init\' attribute\n        #       remove this unpickling code after updating all models\n        try:\n            import warnings\n            warnings.warn(\'Please update your GRU models by loading them and \'\n                          \'saving them again. Loading old models will not work\'\n                          \' from version 0.18 onwards.\', RuntimeWarning)\n            state[\'init\'] = state.pop(\'hid_init\')\n        except KeyError:\n            pass\n        # restore pickled instance attributes\n        self.__dict__.update(state)\n        # TODO: old models do not have the init attributes, thus create them\n        #       remove this initialisation code after updating the models\n        if not hasattr(self, \'init\'):\n            self.init = np.zeros(self.cell.bias.size, dtype=NN_DTYPE)\n        # add non-pickled attributes needed for stateful processing\n        self._prev = self.init\n\n    def reset(self, init=None):\n        """"""\n        Reset the layer to its initial state.\n\n        Parameters\n        ----------\n        init : numpy array, shape (num_hiddens,), optional\n            Reset the hidden units to this initial state.\n\n        """"""\n        # reset previous time step and state to initial value\n        self._prev = init or self.init\n\n    def activate(self, data, reset=True):\n        """"""\n        Activate the GRU layer.\n\n        Parameters\n        ----------\n        data : numpy array, shape (num_frames, num_inputs)\n            Activate with this data.\n        reset : bool, optional\n            Reset the layer to its initial state before activating it.\n\n        Returns\n        -------\n        numpy array, shape (num_frames, num_hiddens)\n            Activations for this data.\n\n        """"""\n        # reset layer\n        if reset:\n            self.reset()\n        # init arrays\n        size = len(data)\n        # output matrix for the whole sequence\n        out = np.zeros((size, self.cell.bias.size), dtype=NN_DTYPE)\n        # process the input data\n        for i in range(size):\n            # cache input data\n            data_ = data[i]\n            # reset gate:\n            # operate on current data and previous output\n            rg = self.reset_gate.activate(data_, self._prev)\n            # update gate:\n            # operate on current data and previous output\n            ug = self.update_gate.activate(data_, self._prev)\n            # cell (implemented as in [1]):\n            # operate on current data, previous output and reset gate\n            cell = self.cell.activate(data_, self._prev, rg)\n            # output:\n            out[i] = ug * cell + (1 - ug) * self._prev\n            # set reference to current output\n            self._prev = out[i]\n        return out\n\n\ndef _kernel_margins(kernel_shape, margin_shift):\n    """"""\n    Determine the margin that needs to be cut off when doing a ""valid""\n    convolution.\n\n    Parameters\n    ----------\n    kernel_shape : tuple\n        Shape of the convolution kernel to determine the margins for\n    margin_shift : bool\n        Shift the borders by one pixel if kernel is of even size\n\n    Returns\n    -------\n    start_x, end_x, start_y, end_y : tuple\n        Indices determining the valid part of the convolution output.\n    """"""\n\n    start_x = int(np.floor(kernel_shape[0] / 2.))\n    start_y = int(np.floor(kernel_shape[1] / 2.))\n\n    margin_shift = -1 if margin_shift else 0\n    if kernel_shape[0] % 2 == 0:\n        end_x = start_x - 1\n        start_x += margin_shift\n        end_x -= margin_shift\n    else:\n        end_x = start_x\n    start_x = start_x if start_x > 0 else None\n    end_x = -end_x if end_x > 0 else None\n\n    if kernel_shape[1] % 2 == 0:\n        end_y = start_y - 1\n        start_y += margin_shift\n        end_y -= margin_shift\n    else:\n        end_y = start_y\n    start_y = start_y if start_y > 0 else None\n    end_y = -end_y if end_y > 0 else None\n\n    return start_x, end_x, start_y, end_y\n\n\ntry:\n    # pylint: disable=no-name-in-module\n    # pylint: disable=wrong-import-order\n    # pylint: disable=wrong-import-position\n\n    # if opencv is installed, use their convolution function, because\n    # it is much faster\n    from cv2 import filter2D as _do_convolve\n\n    def _convolve(x, k):\n        sx, ex, sy, ey = _kernel_margins(k.shape, margin_shift=False)\n        return _do_convolve(x, -1, k[::-1, ::-1])[sx:ex, sy:ey]\n\nexcept ImportError:\n    # scipy.ndimage.convolution behaves slightly differently with\n    # even-sized kernels. If it is used, we need to shift the margins\n    from scipy.ndimage import convolve as _do_convolve\n\n    def _convolve(x, k):\n        sx, ex, sy, ey = _kernel_margins(k.shape, margin_shift=True)\n        return _do_convolve(x, k)[sx:ex, sy:ey]\n\n\ndef convolve(data, kernel):\n    """"""\n    Convolve the data with the kernel in \'valid\' mode, i.e. only where\n    kernel and data fully overlaps.\n\n    Parameters\n    ----------\n    data : numpy array\n        Data to be convolved.\n    kernel : numpy array\n        Convolution kernel\n\n    Returns\n    -------\n    numpy array\n        Convolved data\n\n    """"""\n    return _convolve(data, kernel)\n\n\nclass ConvolutionalLayer(FeedForwardLayer):\n    """"""\n    Convolutional network layer.\n\n    Parameters\n    ----------\n    weights : numpy array, shape (num_feature_maps, num_channels, <kernel>)\n        Weights.\n    bias : scalar or numpy array, shape (num_filters,)\n        Bias.\n    stride : int, optional\n        Stride of the convolution.\n    pad : {\'valid\', \'same\', \'full\'}\n        A string indicating the size of the output:\n\n        - full\n            The output is the full discrete linear convolution of the inputs.\n        - valid\n            The output consists only of those elements that do not rely on the\n            zero-padding.\n        - same\n            The output is the same size as the input, centered with respect to\n            the \xe2\x80\x98full\xe2\x80\x99 output.\n\n    activation_fn : numpy ufunc\n        Activation function.\n\n    """"""\n\n    def __init__(self, weights, bias, stride=1, pad=\'valid\',\n                 activation_fn=linear):\n        super(ConvolutionalLayer, self).__init__(weights, bias, activation_fn)\n        if stride != 1:\n            raise NotImplementedError(\'only `stride` == 1 implemented.\')\n        self.stride = stride\n        if pad != \'valid\':\n            raise NotImplementedError(\'only `pad` == ""valid"" implemented.\')\n        self.pad = pad\n\n    def activate(self, data, **kwargs):\n        """"""\n        Activate the layer.\n\n        Parameters\n        ----------\n        data : numpy array (num_frames, num_bins, num_channels)\n            Activate with this data.\n\n        Returns\n        -------\n        numpy array\n            Activations for this data.\n\n        """"""\n        # if no channel dimension given, assume 1 channel\n        if len(data.shape) == 2:\n            data = data.reshape(data.shape + (1,))\n\n        # determine output shape and allocate memory\n        num_frames, num_bins, num_channels = data.shape\n        num_channels_w, num_features, size_time, size_freq = self.weights.shape\n        if num_channels_w != num_channels:\n            raise ValueError(\'Number of channels in weight vector different \'\n                             \'from number of channels of input data!\')\n        # adjust the output number of frames and bins depending on `pad`\n        # TODO: this works only with pad=\'valid\'\n        num_frames -= (size_time - 1)\n        num_bins -= (size_freq - 1)\n        # init the output array with Fortran ordering (column major)\n        out = np.zeros((num_frames, num_bins, num_features),\n                       dtype=NN_DTYPE, order=\'F\')\n        # iterate over all channels\n        for c in range(num_channels):\n            channel = data[:, :, c]\n            # convolve each channel separately with each filter\n            for w, weights in enumerate(self.weights[c]):\n                conv = convolve(channel, weights)\n                out[:, :, w] += conv\n        # add bias to each feature map and apply activation function\n        return self.activation_fn(out + self.bias)\n\n\nclass StrideLayer(Layer):\n    """"""\n    Stride network layer.\n\n    Parameters\n    ----------\n    block_size : int\n        Re-arrange (stride) the data in blocks of given size.\n\n    """"""\n\n    def __init__(self, block_size):\n        self.block_size = block_size\n\n    def activate(self, data, **kwargs):\n        """"""\n        Activate the layer.\n\n        Parameters\n        ----------\n        data : numpy array\n            Activate with this data.\n\n        Returns\n        -------\n        numpy array\n            Strided data.\n\n        """"""\n        # re-arrange the data for the following dense layer\n        from ...utils import segment_axis\n        data = segment_axis(data, self.block_size, 1, axis=0, end=\'cut\')\n        return data.reshape(len(data), -1)\n\n\nclass MaxPoolLayer(Layer):\n    """"""\n    2D max-pooling network layer.\n\n    Parameters\n    ----------\n    size : tuple\n        The size of the pooling region in each dimension.\n    stride : tuple, optional\n        The strides between successive pooling regions in each dimension.\n        If None `stride` = `size`.\n\n    """"""\n\n    def __init__(self, size, stride=None):\n        self.size = size\n        if stride is None:\n            stride = size\n        self.stride = stride\n\n    def activate(self, data, **kwargs):\n        """"""\n        Activate the layer.\n\n        Parameters\n        ----------\n        data : numpy array\n            Activate with this data.\n\n        Returns\n        -------\n        numpy array\n            Max pooled data.\n\n        """"""\n        from scipy.ndimage.filters import maximum_filter\n        # define which part of the maximum filtered data to return\n        slice_dim_1 = slice(self.size[0] // 2, None, self.stride[0])\n        slice_dim_2 = slice(self.size[1] // 2, None, self.stride[1])\n        # TODO: is constant mode the most appropriate?\n        data = [maximum_filter(data[:, :, c], self.size, mode=\'constant\')\n                [slice_dim_1, slice_dim_2] for c in range(data.shape[2])]\n        # join channels and return as array\n        return np.dstack(data)\n\n\nclass BatchNormLayer(Layer):\n    """"""\n    Batch normalization layer with activation function. The previous layer\n    is usually linear with no bias - the BatchNormLayer\'s beta parameter\n    replaces it. See [1]_ for a detailed understanding of the parameters.\n\n    Parameters\n    ----------\n    beta : numpy array\n        Values for the `beta` parameter. Must be broadcastable to the incoming\n        shape.\n    gamma : numpy array\n        Values for the `gamma` parameter. Must be broadcastable to the incoming\n        shape.\n    mean : numpy array\n        Mean values of incoming data. Must be broadcastable to the incoming\n        shape.\n    inv_std : numpy array\n        Inverse standard deviation of incoming data. Must be broadcastable to\n        the incoming shape.\n    activation_fn : numpy ufunc\n        Activation function.\n\n    References\n    ----------\n    .. [1] ""Batch Normalization: Accelerating Deep Network Training by Reducing\n           Internal Covariate Shift""\n           Sergey Ioffe and Christian Szegedy.\n           http://arxiv.org/abs/1502.03167, 2015.\n\n    """"""\n\n    def __init__(self, beta, gamma, mean, inv_std, activation_fn):\n        self.beta = beta\n        self.gamma = gamma\n        self.mean = mean\n        self.inv_std = inv_std\n        self.activation_fn = activation_fn\n\n    def activate(self, data, **kwargs):\n        """"""\n        Activate the layer.\n\n        Parameters\n        ----------\n        data : numpy array\n            Activate with this data.\n\n        Returns\n        -------\n        numpy array\n            Normalized data.\n\n        """"""\n        return self.activation_fn(\n            (data - self.mean) * (self.gamma * self.inv_std) + self.beta\n        )\n\n\nclass TransposeLayer(Layer):\n    """"""\n    Transpose layer.\n\n    Parameters\n    ----------\n    axes : list of ints, optional\n        By default, reverse the dimensions of the input, otherwise permute the\n        axes of the input according to the values given.\n\n    """"""\n\n    def __init__(self, axes=None):\n        self.axes = axes\n\n    def activate(self, data, **kwargs):\n        """"""\n        Activate the layer.\n\n        Parameters\n        ----------\n        data : numpy array\n            Activate with this data.\n\n        Returns\n        -------\n        numpy array\n            Transposed data.\n\n        """"""\n        return np.transpose(data, self.axes)\n\n\nclass ReshapeLayer(Layer):\n    """"""\n    Reshape Layer.\n\n    Parameters\n    ----------\n    newshape : int or tuple of ints\n        The new shape should be compatible with the original shape. If\n        an integer, then the result will be a 1-D array of that length.\n        One shape dimension can be -1. In this case, the value is\n        inferred from the length of the array and remaining dimensions.\n    order : {\'C\', \'F\', \'A\'}, optional\n        Index order or the input. See np.reshape for a detailed description.\n\n    """"""\n\n    def __init__(self, newshape, order=\'C\'):\n        self.newshape = newshape\n        self.order = order\n\n    def activate(self, data, **kwargs):\n        """"""\n        Activate the layer.\n\n        Parameters\n        ----------\n        data : numpy array\n            Activate with this data.\n\n        Returns\n        -------\n        numpy array\n            Reshaped data.\n\n        """"""\n        return np.reshape(data, self.newshape, self.order)\n\n\nclass AverageLayer(Layer):\n    """"""\n    Average layer.\n\n    Parameters\n    ----------\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which the means are computed. The default is to\n        compute the mean of the flattened array.\n    dtype : data-type, optional\n        Type to use in computing the mean.  For integer inputs, the default\n        is `float64`; for floating point inputs, it is the same as the\n        input dtype.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one.\n\n    """"""\n\n    def __init__(self, axis=None, dtype=None, keepdims=False):\n        self.axis = axis\n        self.dtype = dtype\n        self.keepdims = keepdims\n\n    def activate(self, data, **kwargs):\n        """"""\n        Activate the layer.\n\n        Parameters\n        ----------\n        data : numpy array\n            Activate with this data.\n\n        Returns\n        -------\n        numpy array\n            Averaged data.\n\n        """"""\n        return np.mean(data, axis=self.axis, dtype=self.dtype,\n                       keepdims=self.keepdims)\n\n\nclass PadLayer(Layer):\n    """"""\n    Padding layer that pads the input with a constant value.\n\n    Parameters\n    ----------\n    width : int\n        Width of the padding (only one value for all dimensions)\n    axes : iterable\n        Indices of axes to be padded\n    value : float\n        Value to be used for padding.\n\n    """"""\n\n    def __init__(self, width, axes, value=0.):\n        self.width = width\n        self.axes = axes\n        self.value = value\n\n    def activate(self, data, **kwargs):\n        """"""\n        Activate the layer.\n\n        Parameters\n        ----------\n        data : numpy array\n            Activate with this data.\n\n        Returns\n        -------\n        numpy array\n            Padded data.\n\n        """"""\n        shape = list(data.shape)\n        data_idxs = [slice(None) for _ in range(len(shape))]\n        for a in self.axes:\n            shape[a] += self.width * 2\n            data_idxs[a] = slice(self.width, -self.width)\n        data_padded = np.full(tuple(shape), self.value)\n        data_padded[tuple(data_idxs)] = data\n        return data_padded\n'"
