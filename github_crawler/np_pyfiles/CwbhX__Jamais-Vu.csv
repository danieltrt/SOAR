file_path,api_count,code
JMV_Test.py,0,"b'from jamaisvu import Jamaisvu\nfrom jamaisvu.recognize import FileRecognizer, MicrophoneRecognizer\nimport sys\nimport yaml\n\n\ndef main(config, testfile):\n    filestream = open(config, ""rt"")\n    config_information = yaml.load(filestream)\n    filestream.close()\n\n    print(""Config info: %s"" % config_information)\n    jmv = Jamaisvu(config_information)\n    jmv.fingerprint_file(testfile)\n\n    recognizer = FileRecognizer(jmv)\n    returned_song = recognizer.recognize_file(filename=testfile)\n    # returned_song = jmv.recognize(FileRecognizer, testfile)\n    print(""Result:"")\n    for key in returned_song:\n        print(str(key) + "" : "" + str(returned_song[key]))\n\n\nif __name__ == \'__main__\':\n    config = sys.argv[1]\n    print(""Config file: %s"" % config)\n    testfile = sys.argv[2]\n    print(""Testfile: %s"" % testfile)\n    main(config, testfile)\n    print("""")\n'"
jamaisvu/SDF_Test.py,0,"b'from songdata import SongDataFinder\nimport sys\n\n\ndef main(acoustid_apikey, file):\n    sdf = SongDataFinder(acoustid_apikey)\n    songdata = sdf.matchFile(file)\n\n    if(songdata != None):\n        print(""Spotify Data:"")\n        print(""Song Name: %s"" % songdata.getName())\n        print(""Song Artist: %s"" % songdata.getMainArtist())\n        print(""Song Album: %s"" % songdata.getAlbum())\n        print(""Song Genre: %s"" % songdata.getMainArtistGenre())\n        print(""Song Explicit: %s"" % songdata.getExplicitRating())\n        print(""Song Length: %s"" % songdata.getLength())\n\n    else:\n        print(""Could not identify the song with AcoustID/MusicBrains"")\n\nif __name__ == \'__main__\':\n    apikey = sys.argv[1]\n    testfile = sys.argv[2]\n    main(apikey, testfile)\n'"
jamaisvu/__init__.py,0,"b'from jamaisvu.database import get_database, Database\nfrom songdata import SongDataFinder\nimport jamaisvu.decoder as decoder\nimport fingerprint\n\n\nclass Jamaisvu(object):\n\n    SONG_ID = ""song_id""\n    SONG_NAME = \'song_name\'\n\n    SONG_ARTIST = ""song_artist""\n    SONG_ALBUM = ""song_album""\n    SONG_GENRE = ""song_genre""\n    SONG_EXPLICIT = ""song_explicit""\n    SONG_LENGTH = ""song_length""\n\n    CONFIDENCE = \'confidence\'\n    MATCH_TIME = \'match_time\'\n    OFFSET = \'offset\'\n    OFFSET_SECS = \'offset_seconds\'\n\n    def __init__(self, config):\n        super(Jamaisvu, self).__init__()\n\n        self.config = config\n\n        # initialize db\n        db_cls = get_database(config.get(""database_type"", None))\n\n        self.db = db_cls(**config.get(""database"", {}))\n        self.db.setup()  # Change this with an if condition\n\n        # if we should limit seconds fingerprinted,\n        # None|-1 means use entire track\n        self.limit = self.config.get(""fingerprint_limit"", None)\n        if self.limit == -1:  # for JSON compatibility\n            self.limit = None\n\n        self.songdatafinder = SongDataFinder(self.config.get(""acoustid_apikey""))\n\n        self.get_fingerprinted_songs()\n\n    def get_fingerprinted_songs(self):\n        # get songs previously indexed\n        self.songs = self.db.get_songs()\n        self.songhashes_set = set()  # to know which ones we\'ve computed before\n        for song in self.songs:\n            song_hash = song[Database.FIELD_FILE_SHA1]\n            self.songhashes_set.add(song_hash)\n\n    def fingerprint_file(self, filepath):\n        song_hash = decoder.unique_hash(filepath)  # Generate song file hash\n\n        # Don\'t refingerprint already fingerprinted files or try to find data\n        if song_hash in self.songhashes_set:\n            print ""%s has already been fingerprinted."" % song_hash\n\n            return False\n        else:\n            songdata = self.songdatafinder.matchFile(filepath)\n            if songdata == None:  # Exit like the previous condition, if we disabled userinput\n                print(""Could not ID song"")\n                return False\n\n            song_name = songdata.getName()\n            song_artist = songdata.getMainArtist()\n            song_album = songdata.getAlbum()\n            song_artist_genre = songdata.getMainArtistGenre()\n            song_explicit = songdata.getExplicitRating()\n            song_length = songdata.getLength()\n\n            hashes, file_hash = _fingerprint_worker(filepath, self.limit)\n            # Insert our song data into the songs table and return its location\n            sid = self.db.insert_song(song_name,\n                                      song_artist,\n                                      song_album,\n                                      song_artist_genre,\n                                      song_explicit,\n                                      song_length,\n                                      file_hash)\n\n            self.db.insert_hashes(sid, hashes)\n            self.db.set_song_fingerprinted(sid)\n            self.get_fingerprinted_songs() # Why is this being run after every call... with two nested for loops\n\n            return True\n\n    def fingerprint_directory(self, path, extensions):\n        # TODO: Make this use the fingerprint_file, can\'t do multiple processes due to API limits\n        # This shouldn\'t be an issue once gpu acceleration is implemented\n\n        filenames_to_fingerprint = []\n        for filename, _ in decoder.find_files(path, extensions):\n            # don\'t refingerprint already fingerprinted files\n            if decoder.unique_hash(filename) in self.songhashes_set:\n                print ""%s already fingerprinted, continuing..."" % filename\n            else:\n                filenames_to_fingerprint.append(filename)\n\n        print(filenames_to_fingerprint)\n\n        for filename in filenames_to_fingerprint:\n            self.fingerprint_file(filename)\n\n        return True\n\n    def find_matches(self, samples, Fs=fingerprint.DEFAULT_FS):\n        hashes = fingerprint.fingerprint(samples, Fs=Fs)\n        return self.db.return_matches(hashes)\n\n    def align_matches(self, matches):\n        """"""\n            Finds hash matches that align in time with other matches and finds\n            consensus about which hashes are ""true"" signal from the audio.\n\n            Returns a dictionary with match information.\n        """"""\n        # align by diffs\n        diff_counter = {}\n        largest = 0\n        largest_count = 0\n        song_id = -1\n        for tup in matches:\n            sid, diff = tup\n            if diff not in diff_counter:\n                diff_counter[diff] = {}\n            if sid not in diff_counter[diff]:\n                diff_counter[diff][sid] = 0\n            diff_counter[diff][sid] += 1\n\n            if diff_counter[diff][sid] > largest_count:\n                largest = diff\n                largest_count = diff_counter[diff][sid]\n                song_id = sid\n\n        # extract idenfication\n        song = self.db.get_song_by_id(song_id)\n        if song:\n            # TODO: Clarify what `get_song_by_id` should return.\n            songname = song.get(Jamaisvu.SONG_NAME, None)\n            songartist = song.get(Jamaisvu.SONG_ARTIST, None)\n            songalbum = song.get(Jamaisvu.SONG_ALBUM, None)\n            songgenre = song.get(Jamaisvu.SONG_GENRE, None)\n            songexplicit = song.get(Jamaisvu.SONG_EXPLICIT, True)  # Default to yes to explicit if there is no data, we don\'t want explicit songs on air\n            songlength = song.get(Jamaisvu.SONG_LENGTH, 0)\n        else:\n            return None\n\n        # return match info\n        nseconds = round(float(largest) / fingerprint.DEFAULT_FS *\n                         fingerprint.DEFAULT_WINDOW_SIZE *\n                         fingerprint.DEFAULT_OVERLAP_RATIO, 5)\n        song = {  # TODO: Replace this variable...\n            Jamaisvu.SONG_ID: song_id,\n            Jamaisvu.SONG_NAME: songname,\n            Jamaisvu.SONG_ARTIST: songartist,\n            Jamaisvu.SONG_ALBUM: songalbum,\n            Jamaisvu.SONG_GENRE: songgenre,\n            Jamaisvu.SONG_EXPLICIT: songexplicit,\n            Jamaisvu.SONG_LENGTH: songlength,\n\n            Jamaisvu.CONFIDENCE: largest_count,\n            Jamaisvu.OFFSET: int(largest),\n            Jamaisvu.OFFSET_SECS: nseconds,\n            Database.FIELD_FILE_SHA1: song.get(Database.FIELD_FILE_SHA1, None)\n            }\n\n        return song\n\n    def recognize(self, recognizer, *options, **kwoptions):\n        r = recognizer(self)\n        return r.recognize(*options, **kwoptions)\n\n\ndef _fingerprint_worker(filename, limit=None):\n    # I only want the hashes. This function should not has any songdata otherwise\n    try:\n        filename, limit = filename\n    except ValueError:\n        pass\n\n    channels, Fs, file_hash = decoder.read(filename, limit)\n    result = set()\n    channel_amount = len(channels)\n\n    for channeln, channel in enumerate(channels):\n        # TODO: Remove prints or change them into optional logging.\n        print(""Fingerprinting channel %d/%d for %s"" % (channeln + 1,\n                                                       channel_amount,\n                                                       filename))\n        hashes = fingerprint.fingerprint(channel, Fs=Fs)\n        print(""Finished channel %d/%d for %s"" % (channeln + 1, channel_amount,\n                                                 filename))\n        result |= set(hashes)\n\n    return result, file_hash\n\n\ndef chunkify(lst, n):\n    """"""\n    Splits a list into roughly n equal parts.\n    http://stackoverflow.com/questions/2130016/splitting-a-list-of-arbitrary-size-into-only-roughly-n-equal-parts\n    """"""\n    return [lst[i::n] for i in xrange(n)]\n'"
jamaisvu/database.py,0,"b'from __future__ import absolute_import\nimport abc\n\n\nclass Database(object):\n    __metaclass__ = abc.ABCMeta\n\n    FIELD_FILE_SHA1 = \'file_sha1\'\n    FIELD_SONG_ID = \'song_id\'\n    FIELD_SONGNAME = \'song_name\'\n\n    # Additional Song Details\n    FIELD_ARTIST = ""song_artist""\n    FIELD_ALBUM = ""song_album""\n    FIELD_GENRE = ""song_genre""\n    FIELD_EXPLICIT = ""song_explicit""\n    FIELD_LENGTH = ""song_length""\n    FIELD_IDENTIFIED = ""song_identified""\n\n    FIELD_OFFSET = \'offset\'\n    FIELD_HASH = \'hash\'\n\n    # Name of your Database subclass, this is used in configuration\n    # to refer to your class\n    type = None\n\n    def __init__(self):\n        super(Database, self).__init__()\n\n    def before_fork(self):\n        """"""\n        Called before the database instance is given to the new process\n        """"""\n        pass\n\n    def after_fork(self):\n        """"""\n        Called after the database instance has been given to the new process\n\n        This will be called in the new process.\n        """"""\n        pass\n\n    def setup(self):\n        """"""\n        Called on creation or shortly afterwards.\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def empty(self):\n        """"""\n        Called when the database should be cleared of all data.\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def delete_unfingerprinted_songs(self):\n        """"""\n        Called to remove any song entries that do not have any fingerprints\n        associated with them.\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def get_num_songs(self):\n        """"""\n        Returns the amount of songs in the database.\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def get_num_fingerprints(self):\n        """"""\n        Returns the number of fingerprints in the database.\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def set_song_fingerprinted(self, sid):\n        """"""\n        Sets a specific song as having all fingerprints in the database.\n\n        sid: Song identifier\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def get_songs(self):\n        """"""\n        Returns all fully fingerprinted songs in the database.\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def get_song_by_id(self, sid):\n        """"""\n        Return a song by its identifier\n\n        sid: Song identifier\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def insert(self, hash, sid, offset):\n        """"""\n        Inserts a single fingerprint into the database.\n\n          hash: Part of a sha1 hash, in hexadecimal format\n           sid: Song identifier this fingerprint is off\n        offset: The offset this hash is from\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def insert_song(self, song_name):\n        """"""\n        Inserts a song name into the database, returns the new\n        identifier of the song.\n\n        song_name: The name of the song.\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def query(self, hash):\n        """"""\n        Returns all matching fingerprint entries associated with\n        the given hash as parameter.\n\n        hash: Part of a sha1 hash, in hexadecimal format\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def get_iterable_kv_pairs(self):\n        """"""\n        Returns all fingerprints in the database.\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def insert_hashes(self, sid, hashes):\n        """"""\n        Insert a multitude of fingerprints.\n\n           sid: Song identifier the fingerprints belong to\n        hashes: A sequence of tuples in the format (hash, offset)\n        -   hash: Part of a sha1 hash, in hexadecimal format\n        - offset: Offset this hash was created from/at.\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def return_matches(self, hashes):\n        """"""\n        Searches the database for pairs of (hash, offset) values.\n\n        hashes: A sequence of tuples in the format (hash, offset)\n        -   hash: Part of a sha1 hash, in hexadecimal format\n        - offset: Offset this hash was created from/at.\n\n        Returns a sequence of (sid, offset_difference) tuples.\n\n                      sid: Song identifier\n        offset_difference: (offset - database_offset)\n        """"""\n        pass\n\n\ndef get_database(database_type=None):\n    # Default to using the mysql database\n    database_type = database_type or ""mysql""\n    # Lower all the input.\n    database_type = database_type.lower()\n\n    for db_cls in Database.__subclasses__():\n        if db_cls.type == database_type:\n            return db_cls\n\n    raise TypeError(""Unsupported database type supplied."")\n\n\n# Import our default database handler\nimport jamaisvu.database_sql\n'"
jamaisvu/database_sql.py,0,"b'from __future__ import absolute_import\nfrom itertools import izip_longest\nimport Queue\n\nimport MySQLdb as mysql\nfrom MySQLdb.cursors import DictCursor\n\nfrom jamaisvu.database import Database\n\n\nclass SQLDatabase(Database):\n    """"""\n    Queries:\n\n    1) Find duplicates (shouldn\'t be any, though):\n\n        select `hash`, `song_id`, `offset`, count(*) cnt\n        from fingerprints\n        group by `hash`, `song_id`, `offset`\n        having cnt > 1\n        order by cnt asc;\n\n    2) Get number of hashes by song:\n\n        select song_id, song_name, count(song_id) as num\n        from fingerprints\n        natural join songs\n        group by song_id\n        order by count(song_id) desc;\n\n    3) get hashes with highest number of collisions\n\n        select\n            hash,\n            count(distinct song_id) as n\n        from fingerprints\n        group by `hash`\n        order by n DESC;\n\n    => 26 different songs with same fingerprint (392 times):\n\n        select songs.song_name, fingerprints.offset\n        from fingerprints natural join songs\n        where fingerprints.hash = ""08d3c833b71c60a7b620322ac0c0aba7bf5a3e73"";\n    """"""\n\n    type = ""mysql""\n\n    # tables\n    FINGERPRINTS_TABLENAME = ""fingerprints""\n    SONGS_TABLENAME = ""songs""\n\n    # fields\n    FIELD_FINGERPRINTED = ""fingerprinted""\n\n    # creates\n    CREATE_FINGERPRINTS_TABLE = """"""\n        CREATE TABLE IF NOT EXISTS `%s` (\n             `%s` binary(10) not null,\n             `%s` mediumint unsigned not null,\n             `%s` int unsigned not null,\n         INDEX (%s),\n         UNIQUE KEY `unique_constraint` (%s, %s, %s),\n         FOREIGN KEY (%s) REFERENCES %s(%s) ON DELETE CASCADE\n    ) ENGINE=INNODB;"""""" % (\n        FINGERPRINTS_TABLENAME, Database.FIELD_HASH,\n        Database.FIELD_SONG_ID, Database.FIELD_OFFSET, Database.FIELD_HASH,\n        Database.FIELD_SONG_ID, Database.FIELD_OFFSET, Database.FIELD_HASH,\n        Database.FIELD_SONG_ID, SONGS_TABLENAME, Database.FIELD_SONG_ID\n    )\n\n\t# Completed Additions - Clement\n    CREATE_SONGS_TABLE = """"""\n        CREATE TABLE IF NOT EXISTS `%s` (\n            `%s` mediumint unsigned not null auto_increment,\n            `%s` varchar(250) not null,\n\t\t\t`%s` varchar(250) not null,\n\t\t\t`%s` varchar(250) not null,\n\t\t\t`%s` varchar(250) not null,\n            `%s` boolean default null,\n\t\t\t`%s` mediumint unsigned not null,\n            `%s` tinyint default 0,\n            `%s` binary(20) not null,\n        PRIMARY KEY (`%s`),\n        UNIQUE KEY `%s` (`%s`)\n    ) ENGINE=INNODB;"""""" % (\n        SONGS_TABLENAME, Database.FIELD_SONG_ID, Database.FIELD_SONGNAME, Database.FIELD_ARTIST, Database.FIELD_ALBUM, Database.FIELD_GENRE, Database.FIELD_EXPLICIT, Database.FIELD_LENGTH, FIELD_FINGERPRINTED,\n        Database.FIELD_FILE_SHA1,\n        Database.FIELD_SONG_ID, Database.FIELD_SONG_ID, Database.FIELD_SONG_ID,\n    )\n\n    # inserts (ignores duplicates)\n    INSERT_FINGERPRINT = """"""\n        INSERT IGNORE INTO %s (%s, %s, %s) values\n            (UNHEX(%%s), %%s, %%s);\n    """""" % (FINGERPRINTS_TABLENAME, Database.FIELD_HASH, Database.FIELD_SONG_ID, Database.FIELD_OFFSET)\n\n    ##                             Name, Artist, Album, Genre, Length, SHA1\n    INSERT_SONG = ""INSERT INTO %s (%s, %s, %s, %s, %s, %s, %s) values (%%s, %%s, %%s, %%s, %%s, %%s, UNHEX(%%s));"" % (\n        SONGS_TABLENAME, Database.FIELD_SONGNAME, Database.FIELD_ARTIST, Database.FIELD_ALBUM, Database.FIELD_GENRE, Database.FIELD_EXPLICIT, Database.FIELD_LENGTH, Database.FIELD_FILE_SHA1)\n\n    # selects\n    SELECT = """"""\n        SELECT %s, %s FROM %s WHERE %s = UNHEX(%%s);\n    """""" % (Database.FIELD_SONG_ID, Database.FIELD_OFFSET, FINGERPRINTS_TABLENAME, Database.FIELD_HASH)\n\n    SELECT_MULTIPLE = """"""\n        SELECT HEX(%s), %s, %s FROM %s WHERE %s IN (%%s);\n    """""" % (Database.FIELD_HASH, Database.FIELD_SONG_ID, Database.FIELD_OFFSET,\n           FINGERPRINTS_TABLENAME, Database.FIELD_HASH)\n\n    SELECT_ALL = """"""\n        SELECT %s, %s FROM %s;\n    """""" % (Database.FIELD_SONG_ID, Database.FIELD_OFFSET, FINGERPRINTS_TABLENAME)\n\n    SELECT_SONG = """"""\n        SELECT %s, %s, %s, %s, %s, %s, HEX(%s) as %s FROM %s WHERE %s = %%s;\n    """""" % (Database.FIELD_SONGNAME, Database.FIELD_ARTIST, Database.FIELD_ALBUM, Database.FIELD_GENRE, Database.FIELD_EXPLICIT, Database.FIELD_LENGTH, Database.FIELD_FILE_SHA1,\n            Database.FIELD_FILE_SHA1, SONGS_TABLENAME, Database.FIELD_SONG_ID)\n\n    SELECT_NUM_FINGERPRINTS = """"""\n        SELECT COUNT(*) as n FROM %s\n    """""" % (FINGERPRINTS_TABLENAME)\n\n    SELECT_UNIQUE_SONG_IDS = """"""\n        SELECT COUNT(DISTINCT %s) as n FROM %s WHERE %s = 1;\n    """""" % (Database.FIELD_SONG_ID, SONGS_TABLENAME, FIELD_FINGERPRINTED)\n\n    SELECT_SONGS = """"""\n        SELECT %s, %s, HEX(%s) as %s FROM %s WHERE %s = 1;\n    """""" % (Database.FIELD_SONG_ID, Database.FIELD_SONGNAME, Database.FIELD_FILE_SHA1, Database.FIELD_FILE_SHA1,\n           SONGS_TABLENAME, FIELD_FINGERPRINTED)\n\n    # drops\n    DROP_FINGERPRINTS = ""DROP TABLE IF EXISTS %s;"" % FINGERPRINTS_TABLENAME\n    DROP_SONGS = ""DROP TABLE IF EXISTS %s;"" % SONGS_TABLENAME\n\n    # update\n    UPDATE_SONG_FINGERPRINTED = """"""\n        UPDATE %s SET %s = 1 WHERE %s = %%s\n    """""" % (SONGS_TABLENAME, FIELD_FINGERPRINTED, Database.FIELD_SONG_ID)\n\n    # delete\n    DELETE_UNFINGERPRINTED = """"""\n        DELETE FROM %s WHERE %s = 0;\n    """""" % (SONGS_TABLENAME, FIELD_FINGERPRINTED)\n\n    def __init__(self, **options):\n        super(SQLDatabase, self).__init__()\n        self.cursor = cursor_factory(**options)\n        self._options = options\n\n    def after_fork(self):\n        # Clear the cursor cache, we don\'t want any stale connections from\n        # the previous process.\n        Cursor.clear_cache()\n\n    def setup(self):\n        """"""\n        Creates any non-existing tables required for jamaisvu to function.\n\n        This also removes all songs that have been added but have no\n        fingerprints associated with them.\n        """"""\n        with self.cursor() as cur:\n            cur.execute(self.CREATE_SONGS_TABLE)\n            cur.execute(self.CREATE_FINGERPRINTS_TABLE)\n            cur.execute(self.DELETE_UNFINGERPRINTED)\n\n    def empty(self):\n        """"""\n        Drops tables created by jamaisvu and then creates them again\n        by calling `SQLDatabase.setup`.\n\n        .. warning:\n            This will result in a loss of data\n        """"""\n        with self.cursor() as cur:\n            cur.execute(self.DROP_FINGERPRINTS)\n            cur.execute(self.DROP_SONGS)\n\n        self.setup()\n\n    def delete_unfingerprinted_songs(self):\n        """"""\n        Removes all songs that have no fingerprints associated with them.\n        """"""\n        with self.cursor() as cur:\n            cur.execute(self.DELETE_UNFINGERPRINTED)\n\n    def get_num_songs(self):\n        """"""\n        Returns number of songs the database has fingerprinted.\n        """"""\n        with self.cursor() as cur:\n            cur.execute(self.SELECT_UNIQUE_SONG_IDS)\n\n            for count, in cur:\n                return count\n            return 0\n\n    def get_num_fingerprints(self):\n        """"""\n        Returns number of fingerprints the database has fingerprinted.\n        """"""\n        with self.cursor() as cur:\n            cur.execute(self.SELECT_NUM_FINGERPRINTS)\n\n            for count, in cur:\n                return count\n            return 0\n\n    def set_song_fingerprinted(self, sid):\n        """"""\n        Set the fingerprinted flag to TRUE (1) once a song has been completely\n        fingerprinted in the database.\n        """"""\n        with self.cursor() as cur:\n            cur.execute(self.UPDATE_SONG_FINGERPRINTED, (sid,))\n\n    def get_songs(self):\n        """"""\n        Return songs that have the fingerprinted flag set TRUE (1).\n        """"""\n        with self.cursor(cursor_type=DictCursor) as cur:\n            cur.execute(self.SELECT_SONGS)\n            for row in cur:\n                yield row\n\n    def get_song_by_id(self, sid):\n        """"""\n        Returns song by its ID.\n        """"""\n        with self.cursor(cursor_type=DictCursor) as cur:\n            cur.execute(self.SELECT_SONG, (sid,))\n            return cur.fetchone()\n\n    def insert(self, hash, sid, offset):\n        """"""\n        Insert a (sha1, song_id, offset) row into database.\n        """"""\n        with self.cursor() as cur:\n            cur.execute(self.INSERT_FINGERPRINT, (hash, sid, offset))\n\n    def insert_song(self, songname, artist, album, genre, explicit, length, file_hash):\n        """"""\n        Inserts song in the database and returns the ID of the inserted record.\n        """"""\n        with self.cursor() as cur:\n            cur.execute(self.INSERT_SONG, (songname, artist, album, genre, explicit, length, file_hash))\n            return cur.lastrowid\n\n    def query(self, hash):\n        """"""\n        Return all tuples associated with hash.\n\n        If hash is None, returns all entries in the\n        database (be careful with that one!).\n        """"""\n        # select all if no key\n        query = self.SELECT_ALL if hash is None else self.SELECT\n\n        with self.cursor() as cur:\n            cur.execute(query)\n            for sid, offset in cur:\n                yield (sid, offset)\n\n    def get_iterable_kv_pairs(self):\n        """"""\n        Returns all tuples in database.\n        """"""\n        return self.query(None)\n\n    def insert_hashes(self, sid, hashes):\n        """"""\n        Insert series of hash => song_id, offset\n        values into the database.\n        """"""\n        values = []\n        for hash, offset in hashes:\n            values.append((hash, sid, offset))\n\n        with self.cursor() as cur:\n            for split_values in grouper(values, 1000):\n                cur.executemany(self.INSERT_FINGERPRINT, split_values)\n\n    def return_matches(self, hashes):\n        """"""\n        Return the (song_id, offset_diff) tuples associated with\n        a list of (sha1, sample_offset) values.\n        """"""\n        # Create a dictionary of hash => offset pairs for later lookups\n        mapper = {}\n        for hash, offset in hashes:\n            mapper[hash.upper()] = offset\n\n        # Get an iteratable of all the hashes we need\n        values = mapper.keys()\n\n        with self.cursor() as cur:\n            for split_values in grouper(values, 1000):\n                # Create our IN part of the query\n                query = self.SELECT_MULTIPLE\n                query = query % \', \'.join([\'UNHEX(%s)\'] * len(split_values))\n\n                cur.execute(query, split_values)\n\n                for hash, sid, offset in cur:\n                    # (sid, db_offset - song_sampled_offset)\n                    yield (sid, offset - mapper[hash])\n\n    def __getstate__(self):\n        return (self._options,)\n\n    def __setstate__(self, state):\n        self._options, = state\n        self.cursor = cursor_factory(**self._options)\n\n\ndef grouper(iterable, n, fillvalue=None):\n    args = [iter(iterable)] * n\n    return (filter(None, values) for values\n            in izip_longest(fillvalue=fillvalue, *args))\n\n\ndef cursor_factory(**factory_options):\n    def cursor(**options):\n        options.update(factory_options)\n        return Cursor(**options)\n    return cursor\n\n\nclass Cursor(object):\n    """"""\n    Establishes a connection to the database and returns an open cursor.\n\n\n    ```python\n    # Use as context manager\n    with Cursor() as cur:\n        cur.execute(query)\n    ```\n    """"""\n    _cache = Queue.Queue(maxsize=5)\n\n    def __init__(self, cursor_type=mysql.cursors.Cursor, **options):\n        super(Cursor, self).__init__()\n\n        try:\n            conn = self._cache.get_nowait()\n        except Queue.Empty:\n            conn = mysql.connect(**options)\n        else:\n            # Ping the connection before using it from the cache.\n            conn.ping(True)\n\n        self.conn = conn\n        self.conn.autocommit(False)\n        self.cursor_type = cursor_type\n\n    @classmethod\n    def clear_cache(cls):\n        cls._cache = Queue.Queue(maxsize=5)\n\n    def __enter__(self):\n        self.cursor = self.conn.cursor(self.cursor_type)\n        return self.cursor\n\n    def __exit__(self, extype, exvalue, traceback):\n        # if we had a MySQL related error we try to rollback the cursor.\n        if extype is mysql.MySQLError:\n            self.cursor.rollback()\n\n        self.cursor.close()\n        self.conn.commit()\n\n        # Put it back on the queue\n        try:\n            self._cache.put_nowait(self.conn)\n        except Queue.Full:\n            self.conn.close()\n'"
jamaisvu/decoder.py,2,"b'import os\nimport fnmatch\nimport numpy as np\nfrom pydub import AudioSegment\nfrom pydub.utils import audioop\nimport wavio\nfrom hashlib import sha1\n\ndef unique_hash(filepath, blocksize=2**20):\n    """""" Small function to generate a hash to uniquely generate\n    a file. Inspired by MD5 version here:\n    http://stackoverflow.com/a/1131255/712997\n\n    Works with large files. \n    """"""\n    s = sha1()\n    with open(filepath , ""rb"") as f:\n        while True:\n            buf = f.read(blocksize)\n            if not buf:\n                break\n            s.update(buf)\n    return s.hexdigest().upper()\n\n\ndef find_files(path, extensions):\n    # Allow both with "".mp3"" and without ""mp3"" to be used for extensions\n    extensions = [e.replace(""."", """") for e in extensions]\n\n    for dirpath, dirnames, files in os.walk(path):\n        for extension in extensions:\n            for f in fnmatch.filter(files, ""*.%s"" % extension):\n                p = os.path.join(dirpath, f)\n                yield (p, extension)\n\n\ndef read(filename, limit=None):\n    """"""\n    Reads any file supported by pydub (ffmpeg) and returns the data contained\n    within. If file reading fails due to input being a 24-bit wav file,\n    wavio is used as a backup.\n\n    Can be optionally limited to a certain amount of seconds from the start\n    of the file by specifying the `limit` parameter. This is the amount of\n    seconds from the start of the file.\n\n    returns: (channels, samplerate)\n    """"""\n    # pydub does not support 24-bit wav files, use wavio when this occurs\n    try:\n        audiofile = AudioSegment.from_file(filename)\n\n        if limit:\n            audiofile = audiofile[:limit * 1000]\n\n        data = np.fromstring(audiofile._data, np.int16)\n\n        channels = []\n        for chn in xrange(audiofile.channels):\n            channels.append(data[chn::audiofile.channels])\n\n        fs = audiofile.frame_rate\n    except audioop.error:\n        fs, _, audiofile = wavio.readwav(filename)\n\n        if limit:\n            audiofile = audiofile[:limit * 1000]\n\n        audiofile = audiofile.T\n        audiofile = audiofile.astype(np.int16)\n\n        channels = []\n        for chn in audiofile:\n            channels.append(chn)\n\n    return channels, audiofile.frame_rate, unique_hash(filename)\n\n\ndef path_to_songname(path):\n    """"""\n    Extracts song name from a filepath. Used to identify which songs\n    have already been fingerprinted on disk.\n    """"""\n    return os.path.splitext(os.path.basename(path))[0]\n'"
jamaisvu/fingerprint.py,0,"b'import numpy\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage.filters import maximum_filter\nfrom scipy.ndimage.morphology import (generate_binary_structure,\n                                      iterate_structure, binary_erosion)\nimport hashlib, time\nfrom operator import itemgetter\n\nfrom reikna.cluda import any_api\nfrom gpu import maximum_filter_2d, Spectrogram\n\nIDX_FREQ_I = 0\nIDX_TIME_J = 1\n\n######################################################################\n# Sampling rate, related to the Nyquist conditions, which affects\n# the range frequencies we can detect.\nDEFAULT_FS = 44100\n\n######################################################################\n# Size of the FFT window, affects frequency granularity\nDEFAULT_WINDOW_SIZE = 4096\n\n######################################################################\n# Ratio by which each sequential window overlaps the last and the\n# next window. Higher overlap will allow a higher granularity of offset\n# matching, but potentially more fingerprints.\nDEFAULT_OVERLAP_RATIO = 0.5\n\n######################################################################\n# Degree to which a fingerprint can be paired with its neighbors --\n# higher will cause more fingerprints, but potentially better accuracy.\nDEFAULT_FAN_VALUE = 15\n\n######################################################################\n# Minimum amplitude in spectrogram in order to be considered a peak.\n# This can be raised to reduce number of fingerprints, but can negatively\n# affect accuracy.\nDEFAULT_AMP_MIN = 10\n\n######################################################################\n# Number of cells around an amplitude peak in the spectrogram in order\n# for Jamaisvu to consider it a spectral peak. Higher values mean less\n# fingerprints and faster matching, but can potentially affect accuracy.\nPEAK_NEIGHBORHOOD_SIZE = 20\n\n######################################################################\n# Thresholds on how close or far fingerprints can be in time in order\n# to be paired as a fingerprint. If your max is too low, higher values of\n# DEFAULT_FAN_VALUE may not perform as expected.\nMIN_HASH_TIME_DELTA = 0\nMAX_HASH_TIME_DELTA = 200\n\n######################################################################\n# If True, will sort peaks temporally for fingerprinting;\n# not sorting will cut down number of fingerprints, but potentially\n# affect performance.\nPEAK_SORT = True\n\n######################################################################\n# Number of bits to throw away from the front of the SHA1 hash in the\n# fingerprint calculation. The more you throw away, the less storage, but\n# potentially higher collisions and misclassifications when identifying songs.\nFINGERPRINT_REDUCTION = 20\n\ndef fingerprint(channel_samples, Fs=DEFAULT_FS,\n                wsize=DEFAULT_WINDOW_SIZE,\n                wratio=DEFAULT_OVERLAP_RATIO,\n                fan_value=DEFAULT_FAN_VALUE,\n                amp_min=DEFAULT_AMP_MIN,\n                debug=False):\n    """"""\n    FFT the channel, log transform output, find local maxima, then return\n    locally sensitive hashes.\n    """"""\n    # FFT the signal and extract frequency components\n    channel_samples = channel_samples.astype(""float32"") # Import for the GPU\n\n\n\n    t1 = time.time()\n    # Reikna setup for Spectrogram generation\n    api = any_api()\n    thr = api.Thread.create()\n    specgram_reikna = Spectrogram(channel_samples, NFFT=wsize, noverlap=int(wsize * wratio), pad_to=wsize).compile(thr)\n    x_dev = thr.to_device(channel_samples)\n    spectre_dev = thr.empty_like(specgram_reikna.parameter.output)\n    specgram_reikna(spectre_dev, x_dev)\n\n    arr2D = spectre_dev.get() ## Get spectrogram\n    specttime = time.time()-t1\n\n    # Apply log transform since specgram() returns linear array\n    t1 = time.time()\n    with numpy.errstate(divide=\'ignore\'):\n        arr2D = 10 * numpy.log10(arr2D)\n    arr2D[arr2D == -numpy.inf] = 0  # Replace infs with zeros\n    logtime = time.time()-t1\n\n    t1 = time.time()\n    # Find local maxima\n    local_maxima = get_2D_peaks(arr2D, plot=False, amp_min=amp_min)\n    peaktime = time.time()-t1\n\n    if debug == True:\n        print(""Time to calculate Spectrogram: %s"" % specttime)\n        print(""Time to apply log transform: %s"" % logtime)\n        print(""Time to calculate Peaks: %s"" % peaktime)\n\n    # return hashes\n    return generate_hashes(local_maxima, fan_value=fan_value)\n\n\ndef get_2D_peaks(arr2D, plot=False, amp_min=DEFAULT_AMP_MIN):\n    # http://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.morphology.iterate_structure.html#scipy.ndimage.morphology.iterate_structure\n    struct = generate_binary_structure(2, 1)\n    neighborhood = iterate_structure(struct, PEAK_NEIGHBORHOOD_SIZE).astype(numpy.int32) # Set out footprint but with 1s and 0s for True/False\n\n    # Find local maxima using our fliter shape\n    local_max = maximum_filter_2d(arr2D, footprint=neighborhood) == arr2D # Use our Cuda Kernel to compute\n    background = (arr2D == 0)\n    eroded_background = binary_erosion(background, structure=neighborhood,\n                                       border_value=1)\n\n    # Boolean mask of arr2D with True at peaks\n    detected_peaks = local_max ^ eroded_background # Use ^ now instead of -, since - has been deprecated!\n\n    # Extract peaks\n    amps = arr2D[detected_peaks]\n    j, i = numpy.where(detected_peaks)\n\n    # Filter peaks\n    amps = amps.flatten()\n    peaks = zip(i, j, amps)\n    peaks_filtered = [x for x in peaks if x[2] > amp_min]  # freq, time, amp\n\n    # Get indices for frequency and time\n    frequency_idx = [x[1] for x in peaks_filtered]\n    time_idx = [x[0] for x in peaks_filtered]\n\n    if plot:\n        # Scatter of the peaks\n        ax = plt.subplots()\n        ax.imshow(arr2D)\n        ax.scatter(time_idx, frequency_idx)\n        ax.set_xlabel(\'Time\')\n        ax.set_ylabel(\'Frequency\')\n        ax.set_title(""Spectrogram"")\n        plt.gca().invert_yaxis()\n        plt.show()\n\n    return zip(frequency_idx, time_idx)\n\n\ndef generate_hashes(peaks, fan_value=DEFAULT_FAN_VALUE):\n    """"""\n    Hash list structure:\n       sha1_hash[0:20]    time_offset\n    [(e05b341a9b77a51fd26, 32), ... ]\n    """"""\n    if PEAK_SORT:\n        peaks.sort(key=itemgetter(1))\n\n    for i in range(len(peaks)):\n        for j in range(1, fan_value):\n            if (i + j) < len(peaks):\n\n                freq1 = peaks[i][IDX_FREQ_I]\n                freq2 = peaks[i + j][IDX_FREQ_I]\n                t1 = peaks[i][IDX_TIME_J]\n                t2 = peaks[i + j][IDX_TIME_J]\n                t_delta = t2 - t1\n\n                if t_delta >= MIN_HASH_TIME_DELTA and t_delta <= MAX_HASH_TIME_DELTA:\n                    h = hashlib.sha1(\n                        ""%s|%s|%s"" % (str(freq1), str(freq2), str(t_delta)))\n                    yield (h.hexdigest()[0:FINGERPRINT_REDUCTION], t1)\n'"
jamaisvu/gpu.py,0,"b'import numpy, math, os\nimport pycuda.driver as cuda\nimport pycuda.autoinit\nfrom pycuda.compiler import SourceModule\n\nfrom reikna.cluda import dtypes, functions\nfrom reikna.core import Computation, Transformation, Parameter, Annotation, Type\nfrom reikna.fft import FFT\nfrom reikna.algorithms import Transpose\nimport reikna.transformations as transformations\n\ndef hanning_window(arr, NFFT):\n    """"""\n    Applies the von Hann window to the rows of a 2D array.\n    To account for zero padding (which we do not want to window), NFFT is provided separately.\n    """"""\n    if dtypes.is_complex(arr.dtype):\n        coeff_dtype = dtypes.real_for(arr.dtype)\n    else:\n        coeff_dtype = arr.dtype\n    return Transformation(\n        [\n            Parameter(\'output\', Annotation(arr, \'o\')),\n            Parameter(\'input\', Annotation(arr, \'i\')),\n        ],\n        """"""\n        ${dtypes.ctype(coeff_dtype)} coeff;\n        %if NFFT != output.shape[0]:\n        if (${idxs[1]} >= ${NFFT})\n        {\n            coeff = 1;\n        }\n        else\n        %endif\n        {\n            coeff = 0.5 * (1 - cos(2 * ${numpy.pi} * ${idxs[-1]} / (${NFFT} - 1)));\n        }\n        ${output.store_same}(${mul}(${input.load_same}, coeff));\n        """""",\n        render_kwds=dict(\n            coeff_dtype=coeff_dtype, NFFT=NFFT,\n            mul=functions.mul(arr.dtype, coeff_dtype)))\n\ndef rolling_frame(arr, NFFT, noverlap, pad_to):\n    """"""\n    Transforms a 1D array to a 2D array whose rows are\n    partially overlapped parts of the initial array.\n    """"""\n\n    frame_step = NFFT - noverlap\n    frame_num = (arr.size - noverlap) // frame_step\n    frame_size = NFFT if pad_to is None else pad_to\n\n    result_arr = Type(arr.dtype, (frame_num, frame_size))\n\n    return Transformation(\n        [\n            Parameter(\'output\', Annotation(result_arr, \'o\')),\n            Parameter(\'input\', Annotation(arr, \'i\')),\n        ],\n        """"""\n        %if NFFT != output.shape[1]:\n        if (${idxs[1]} >= ${NFFT})\n        {\n            ${output.store_same}(0);\n        }\n        else\n        %endif\n        {\n            ${output.store_same}(${input.load_idx}(${idxs[0]} * ${frame_step} + ${idxs[1]}));\n        }\n        """""",\n        render_kwds=dict(frame_step=frame_step, NFFT=NFFT),\n        # note that only the ""store_same""-using argument can serve as a connector!\n        connectors=[\'output\'])\n\ndef crop_frequencies(arr):\n    """"""\n    Crop a 2D array whose columns represent frequencies to only leave the frequencies with\n    different absolute values.\n    """"""\n    result_arr = Type(arr.dtype, (arr.shape[0], arr.shape[1] // 2 + 1))\n    return Transformation(\n        [\n            Parameter(\'output\', Annotation(result_arr, \'o\')),\n            Parameter(\'input\', Annotation(arr, \'i\')),\n        ],\n        """"""\n        if (${idxs[1]} < ${input.shape[1] // 2 + 1})\n            ${output.store_idx}(${idxs[0]}, ${idxs[1]}, ${input.load_same});\n        """""",\n        # note that only the ""load_same""-using argument can serve as a connector!\n        connectors=[\'input\'])\n\ndef getGridSize(blockDim, arrayDim):\n\tblockSize = 1\n\tarraySize = 1\n\t\n\tfor dim in blockDim:\n\t\tblockSize *= dim\n\t\n\tfor dim in arrayDim:\n\t\tarraySize *= dim\n\t\n\tgrid1dim = int(math.ceil(math.sqrt(arraySize/blockSize)))\n\tif grid1dim < 1: # Prevent issue where we have a small array size\n\t\tgrid1dim = 1\n\t\n\treturn (grid1dim, grid1dim)\n\ndef maximum_filter_2d(arr2D, footprint): ## Make sure arr2D is our datatype float32 and footprint of int32\n    arr2DMaxed = numpy.empty_like(arr2D)\n    head, tail = os.path.split(os.path.abspath(__file__)) # Used so that we can always get the kernel which should be in the same directory as this file\n\n    maxFunction = open(head + ""/2DSlidingMaxFootprintKernel.c"", ""rt"")\n    maxFunction = SourceModule(maxFunction.read())\n    slidingMaxKernel = maxFunction.get_function(""slidingMaxiumum2D"")\n\n    blockSize = [16, 16] # To-do: Add a variable to this, can affect performance based on GPU\n    gridSize = getGridSize(blockSize, arr2D.shape) # Get the size of our grid based on the size of a grid (blocksize)\n\n\n    slidingMaxKernel(cuda.In(arr2D),                   # Input\n                    cuda.Out(arr2DMaxed),              # Output\n                    numpy.int32(footprint.shape[1]),   # Kernel Size\n                    numpy.int32(arr2D.shape[1]),       # Row Stride\n                    numpy.int32(1),                    # Column Stride\n                    numpy.int32(int(arr2D.shape[1])),  # Array Column Count\n                    numpy.int32(int(arr2D.shape[0])),  # Array Row Count\n                    cuda.In(footprint),\n                    block=(blockSize[0],blockSize[1],1),\n                    grid=(gridSize[0],gridSize[1],1)\n    )\n\n    return arr2DMaxed\n\nclass Spectrogram(Computation):\n\n    def __init__(self, x, NFFT=256, noverlap=128, pad_to=None, window=hanning_window):\n\n        # print(""x Data type = %s"" % x.dtype)\n        # print(""Is Real = %s"" % dtypes.is_real(x.dtype))\n        # print(""dim = %s"" % x.ndim)\n        assert dtypes.is_real(x.dtype)\n        assert x.ndim == 1\n\n        rolling_frame_trf = rolling_frame(x, NFFT, noverlap, pad_to)\n\n        complex_dtype = dtypes.complex_for(x.dtype)\n        fft_arr = Type(complex_dtype, rolling_frame_trf.output.shape)\n        real_fft_arr = Type(x.dtype, rolling_frame_trf.output.shape)\n\n        window_trf = window(real_fft_arr, NFFT)\n        broadcast_zero_trf = transformations.broadcast_const(real_fft_arr, 0)\n        to_complex_trf = transformations.combine_complex(fft_arr)\n        amplitude_trf = transformations.norm_const(fft_arr, 1)\n        crop_trf = crop_frequencies(amplitude_trf.output)\n\n        fft = FFT(fft_arr, axes=(1,))\n        fft.parameter.input.connect(\n            to_complex_trf, to_complex_trf.output,\n            input_real=to_complex_trf.real, input_imag=to_complex_trf.imag)\n        fft.parameter.input_imag.connect(\n            broadcast_zero_trf, broadcast_zero_trf.output)\n        fft.parameter.input_real.connect(\n            window_trf, window_trf.output, unwindowed_input=window_trf.input)\n        fft.parameter.unwindowed_input.connect(\n            rolling_frame_trf, rolling_frame_trf.output, flat_input=rolling_frame_trf.input)\n        fft.parameter.output.connect(\n            amplitude_trf, amplitude_trf.input, amplitude=amplitude_trf.output)\n        fft.parameter.amplitude.connect(\n            crop_trf, crop_trf.input, cropped_amplitude=crop_trf.output)\n\n        self._fft = fft\n\n        self._transpose = Transpose(fft.parameter.cropped_amplitude)\n\n        Computation.__init__(self,\n            [Parameter(\'output\', Annotation(self._transpose.parameter.output, \'o\')),\n            Parameter(\'input\', Annotation(fft.parameter.flat_input, \'i\'))])\n\n    def _build_plan(self, plan_factory, device_params, output, input_):\n        plan = plan_factory()\n        temp = plan.temp_array_like(self._fft.parameter.cropped_amplitude)\n        plan.computation_call(self._fft, temp, input_)\n        plan.computation_call(self._transpose, output, temp)\n        return plan'"
jamaisvu/recognize.py,1,"b'import jamaisvu.fingerprint as fingerprint\nimport jamaisvu.decoder as decoder\nimport numpy as np\nimport pyaudio\nimport time\n\n\nclass BaseRecognizer(object):\n\n    def __init__(self, jamaisvu):\n        self.jamaisvu = jamaisvu\n        self.Fs = fingerprint.DEFAULT_FS\n\n    def _recognize(self, *data):\n        matches = []\n        for d in data:\n            matches.extend(self.jamaisvu.find_matches(d, Fs=self.Fs))\n        return self.jamaisvu.align_matches(matches)\n\n    def recognize(self):\n        pass  # base class does nothing\n\n\nclass FileRecognizer(BaseRecognizer):\n    def __init__(self, jamaisvu):\n        super(FileRecognizer, self).__init__(jamaisvu)\n\n    def recognize_file(self, filename):\n        frames, self.Fs, file_hash = decoder.read(filename, self.jamaisvu.limit)\n\n        t = time.time()\n        match = self._recognize(*frames)\n        t = time.time() - t\n\n        if match:\n            match[\'match_time\'] = t\n\n        return match\n\n    def recognize(self, filename):\n        return self.recognize_file(filename)\n\n\nclass MicrophoneRecognizer(BaseRecognizer):\n    default_chunksize   = 8192\n    default_format      = pyaudio.paInt16\n    default_channels    = 2\n    default_samplerate  = 44100\n\n    def __init__(self, jamaisvu):\n        super(MicrophoneRecognizer, self).__init__(jamaisvu)\n        self.audio = pyaudio.PyAudio()\n        self.stream = None\n        self.data = []\n        self.channels = MicrophoneRecognizer.default_channels\n        self.chunksize = MicrophoneRecognizer.default_chunksize\n        self.samplerate = MicrophoneRecognizer.default_samplerate\n        self.recorded = False\n\n    def start_recording(self, channels=default_channels,\n                        samplerate=default_samplerate,\n                        chunksize=default_chunksize):\n        self.chunksize = chunksize\n        self.channels = channels\n        self.recorded = False\n        self.samplerate = samplerate\n\n        if self.stream:\n            self.stream.stop_stream()\n            self.stream.close()\n\n        self.stream = self.audio.open(\n            format=self.default_format,\n            channels=channels,\n            rate=samplerate,\n            input=True,\n            frames_per_buffer=chunksize,\n        )\n\n        self.data = [[] for i in range(channels)]\n\n    def process_recording(self):\n        data = self.stream.read(self.chunksize)\n        nums = np.fromstring(data, np.int16)\n        for c in range(self.channels):\n            self.data[c].extend(nums[c::self.channels])\n\n    def stop_recording(self):\n        self.stream.stop_stream()\n        self.stream.close()\n        self.stream = None\n        self.recorded = True\n\n    def recognize_recording(self):\n        if not self.recorded:\n            raise NoRecordingError(""Recording was not complete/begun"")\n        return self._recognize(*self.data)\n\n    def get_recorded_time(self):\n        return len(self.data[0]) / self.rate\n\n    def recognize(self, seconds=10):\n        self.start_recording()\n        for i in range(0, int(self.samplerate / self.chunksize\n                              * seconds)):\n            self.process_recording()\n        self.stop_recording()\n        return self.recognize_recording()\n\n\nclass NoRecordingError(Exception):\n    pass\n'"
jamaisvu/songdata.py,0,"b'import acoustid\nimport spotipy\nimport pymsgbox\nfrom spotipy.oauth2 import SpotifyClientCredentials\n\n\nclass SongDataFinder(object):\n\n    def __init__(self, acoustid_apikey):\n        self.acoustid_apikey = acoustid_apikey\n        self.spotifysearch = SpotifySearch()\n\n    def _topresult(self, filename):  # Use acoustID Webservice for basic information\n        results = acoustid.match(self.acoustid_apikey, filename)\n        try:\n            for score, recording_id, title, artist in results:\n                return (title, artist, score)\n        except TypeError:  # If we could not identify a match with MusicBrains\n            return None\n\n    # TODO: Match spotify results with artist and song name to improve results\n    def matchFile(self, filename, userInput=True):\n        try:\n            title, artist, score = self._topresult(filename)\n            print("""")\n            print(""AcoustID Name: %s"" % title)\n            print(""AcoustID Artist: %s"" % artist)\n            print("""")\n            self.spotifysearch.search(""%s - %s"" % (title, artist))  # Plug back in our acoustID results into spotify search\n\n            return self.spotifysearch.selectResult(0)  # Return the resulting spotify track\n\n        except TypeError:  # Again, If we could not identify a match\n            # TODO: Work on the userInput exception handling... e.g. skip None Songs\n            if userInput == True:\n                pymsgbox.alert(text=\'Could not identify song automatically\', title=\'Song ID Error\', button=\'OK\')\n                userSongName = pymsgbox.prompt(text=\'Song Name\', title=\'Enter Song Name\')\n                userSongArtist = pymsgbox.prompt(text=\'Artist\', title=\'Enter Artist Name\')\n\n                self.spotifysearch.search(""%s - %s"" % (userSongName, userSongArtist))  # Search spotify with user entered values\n                return self.spotifysearch.selectResult(0)  # Return the resulting spotify track\n            else:\n                return None\n\n\nclass SpotifySearch(object):\n\n    def __init__(self):\n        self.client_credentials_manager = SpotifyClientCredentials()\n        self.spotify = spotipy.Spotify(client_credentials_manager=self.client_credentials_manager)\n\n    def search(self, query):\n        self.results = self.spotify.search(query)\n\n    def selectResult(self, index):\n        if index < self.getNumberOfResults():\n            return SpotifyTrack(self.results[""tracks""][""items""][index])\n        else:\n            print(""Index is too high"")\n            return None\n\n    def getNumberOfResults(self):\n        return len(self.results[""tracks""][""items""])\n\n    def getTrackNames(self):\n        trackNames = []\n        for track in self.results[""tracks""][""items""]:\n            trackNames.append(track[name])\n\n        return trackNames\n\n    def getTrackAlbums(self):\n        trackAlbums = []\n        for track in self.results[""tracks""][""items""]:\n            trackAlbums.append(track[""album""][""name""])\n\n        return trackAlbums\n\n    def getTrackArtists(self):\n        trackArtists = []\n        for track in self.results[""tracks""][""items""]:\n            trackArtists.append(track[""artists""][""name""][0])  # There might be more than one artist, figure how to handle this\n\n        return trackArtists\n\n    def getExplicitRatings(self):\n        explicitRatings = []\n        for track in self.results[""tracks""][""items""]:\n            explicitRatings.append[track[""explicit""]]\n\n        return explicitRatings\n\n    def getTrackIDs(self):\n        trackIDs = []\n        for track in self.results[""tracks""][""items""]:\n            trackIDs.append(track[""id""])\n\nclass SpotifyTrack(object):\n\n    def __init__(self, trackJSON):\n        self.trackdata = trackJSON\n\n    def getName(self):\n        return self.trackdata[""name""]\n\n    def getAlbum(self):\n        return self.trackdata[""album""][""name""]\n\n    def getAlbumArt(self):\n        return self.trackdata[""album""][""images""][0][""url""]\n\n    def getArtists(self):\n        return self.trackdata[""artists""]\n\n    def getMainArtist(self):\n        return self.trackdata[""artists""][0][""name""]\n\n    def getMainArtistGenre(self):\n        uri = self.trackdata[""artists""][0][""uri""]\n        client_credentials_manager = SpotifyClientCredentials()\n        spotify = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n        artistdata = spotify.artist(uri)\n        try:\n            return artistdata[""genres""][0]\n        except IndexError:\n            return None\n\n    def getTrackNumber(self):\n        return self.trackdata[""track_number""]\n\n    def getLength(self):\n        return self.trackdata[""duration_ms""]\n\n    def getExplicitRating(self):\n        return bool(self.trackdata[""explicit""])\n\n    def getSpotifyID(self):\n        return self.trackdata[""id""]\n'"
jamaisvu/testing.py,1,"b'from __future__ import division\nfrom pydub import AudioSegment\nfrom jamaisvu.decoder import path_to_songname\nfrom jamaisvu import Jamaisvu\nfrom jamaisvu.fingerprint import *\nimport traceback\nimport fnmatch\nimport os, re, ast\nimport subprocess\nimport random\nimport logging\n\ndef set_seed(seed=None):\n    """"""\n    `seed` as None means that the sampling will be random.\n\n    Setting your own seed means that you can produce the\n    same experiment over and over.\n    """"""\n    if seed != None:\n        random.seed(seed)\n\ndef get_files_recursive(src, fmt):\n    """"""\n    `src` is the source directory.\n    `fmt` is the extension, ie "".mp3"" or ""mp3"", etc.\n    """"""\n    for root, dirnames, filenames in os.walk(src):\n        for filename in fnmatch.filter(filenames, \'*\' + fmt):\n            yield os.path.join(root, filename)\n\ndef get_length_audio(audiopath, extension):\n    """"""\n    Returns length of audio in seconds.\n    Returns None if format isn\'t supported or in case of error.\n    """"""\n    try:\n        audio = AudioSegment.from_file(audiopath, extension.replace(""."", """"))\n    except:\n        print ""Error in get_length_audio(): %s"" % traceback.format_exc()\n        return None\n    return int(len(audio) / 1000.0)\n\ndef get_starttime(length, nseconds, padding):\n    """"""\n    `length` is total audio length in seconds\n    `nseconds` is amount of time to sample in seconds\n    `padding` is off-limits seconds at beginning and ending\n    """"""\n    maximum = length - padding - nseconds\n    if padding > maximum:\n        return 0\n    return random.randint(padding, maximum)\n\ndef generate_test_files(src, dest, nseconds, fmts=["".mp3"", "".wav""], padding=10):\n    """"""\n    Generates a test file for each file recursively in `src` directory\n    of given format using `nseconds` sampled from the audio file.\n\n    Results are written to `dest` directory.\n\n    `padding` is the number of off-limit seconds and the beginning and\n    end of a track that won\'t be sampled in testing. Often you want to\n    avoid silence, etc.\n    """"""\n    # create directories if necessary\n    for directory in [src, dest]:\n        try:\n            os.stat(directory)\n        except:\n            os.mkdir(directory)\n\n    # find files recursively of a given file format\n    for fmt in fmts:\n        testsources = get_files_recursive(src, fmt)\n        for audiosource in testsources:\n\n            print ""audiosource:"", audiosource\n\n            filename, extension = os.path.splitext(os.path.basename(audiosource))\n            length = get_length_audio(audiosource, extension)\n            starttime = get_starttime(length, nseconds, padding)\n\n            test_file_name = ""%s_%s_%ssec.%s"" % (\n                os.path.join(dest, filename), starttime,\n                nseconds, extension.replace(""."", """"))\n\n            subprocess.check_output([\n                ""ffmpeg"", ""-y"",\n                ""-ss"", ""%d"" % starttime,\n                \'-t\' , ""%d"" % nseconds,\n                ""-i"", audiosource,\n                test_file_name])\n\ndef log_msg(msg, log=True, silent=False):\n    if log:\n        logging.debug(msg)\n    if not silent:\n        print msg\n\ndef autolabel(rects, ax):\n    # attach some text labels\n    for rect in rects:\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width() / 2., 1.05 * height,\n            \'%d\' % int(height), ha=\'center\', va=\'bottom\')\n\ndef autolabeldoubles(rects, ax):\n    # attach some text labels\n    for rect in rects:\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width() / 2., 1.05 * height,\n            \'%s\' % round(float(height), 3), ha=\'center\', va=\'bottom\')\n\nclass JamaisvuTest(object):\n    def __init__(self, folder, seconds):\n        super(JamaisvuTest, self).__init__()\n\n        self.test_folder = folder\n        self.test_seconds = seconds\n        self.test_songs = []\n\n        print ""test_seconds"", self.test_seconds\n\n        self.test_files = [\n            f for f in os.listdir(self.test_folder)\n            if os.path.isfile(os.path.join(self.test_folder, f))\n            and re.findall(""[0-9]*sec"", f)[0] in self.test_seconds]\n\n        print ""test_files"", self.test_files\n\n        self.n_columns = len(self.test_seconds)\n        self.n_lines = int(len(self.test_files) / self.n_columns)\n\n        print ""columns:"", self.n_columns\n        print ""length of test files:"", len(self.test_files)\n        print ""lines:"", self.n_lines\n\n        # variable match results (yes, no, invalid)\n        self.result_match = [[0 for x in xrange(self.n_columns)] for x in xrange(self.n_lines)]\n\n        print ""result_match matrix:"", self.result_match\n\n        # variable match precision (if matched in the corrected time)\n        self.result_matching_times = [[0 for x in xrange(self.n_columns)] for x in xrange(self.n_lines)]\n\n        # variable mahing time (query time)\n        self.result_query_duration = [[0 for x in xrange(self.n_columns)] for x in xrange(self.n_lines)]\n\n        # variable confidence\n        self.result_match_confidence = [[0 for x in xrange(self.n_columns)] for x in xrange(self.n_lines)]\n\n        self.begin()\n\n    def get_column_id (self, secs):\n        for i, sec in enumerate(self.test_seconds):\n            if secs == sec:\n                return i\n\n    def get_line_id (self, song):\n        for i, s in enumerate(self.test_songs):\n            if song == s:\n                return i\n        self.test_songs.append(song)\n        return len(self.test_songs) - 1\n\n    def create_plots(self, name, results, results_folder):\n        for sec in range(0, len(self.test_seconds)):\n            ind = np.arange(self.n_lines) #\n            width = 0.25       # the width of the bars\n\n            fig = plt.figure()\n            ax = fig.add_subplot(111)\n            ax.set_xlim([-1 * width, 2 * width])\n\n            means_dvj = [x[0] for x in results[sec]]\n            rects1 = ax.bar(ind, means_dvj, width, color=\'r\')\n\n            # add some\n            ax.set_ylabel(name)\n            ax.set_title(""%s %s Results"" % (self.test_seconds[sec], name))\n            ax.set_xticks(ind + width)\n\n            labels = [0 for x in range(0, self.n_lines)]\n            for x in range(0, self.n_lines):\n                labels[x] = ""song %s"" % (x+1)\n            ax.set_xticklabels(labels)\n\n            box = ax.get_position()\n            ax.set_position([box.x0, box.y0, box.width * 0.75, box.height])\n\n            #ax.legend( (rects1[0]), (\'Jamaisvu\'), loc=\'center left\', bbox_to_anchor=(1, 0.5))\n\n            if name == \'Confidence\':\n                autolabel(rects1, ax)\n            else:\n                autolabeldoubles(rects1, ax)\n\n            plt.grid()\n\n            fig_name = os.path.join(results_folder, ""%s_%s.png"" % (name, self.test_seconds[sec]))\n            fig.savefig(fig_name)\n\n    def begin(self):\n        for f in self.test_files:\n            log_msg(\'--------------------------------------------------\')\n            log_msg(\'file: %s\' % f)\n\n            # get column\n            col = self.get_column_id(re.findall(""[0-9]*sec"", f)[0])\n            # format: XXXX_offset_length.mp3\n            song = path_to_songname(f).split(""_"")[0]\n            line = self.get_line_id(song)\n            result = subprocess.check_output([\n                ""python"",\n                ""jamaisvu.py"",\n                \'-r\',\n                \'file\',\n                self.test_folder + ""/"" + f])\n\n            if result.strip() == ""None"":\n                log_msg(\'No match\')\n                self.result_match[line][col] = \'no\'\n                self.result_matching_times[line][col] = 0\n                self.result_query_duration[line][col] = 0\n                self.result_match_confidence[line][col] = 0\n\n            else:\n                result = result.strip()\n                result = result.replace("" \\\'"", \' ""\')\n                result = result.replace(""{\\\'"", \'{""\')\n                result = result.replace(""\\\':"", \'"":\')\n                result = result.replace(""\\\',"", \'"",\')\n\n                # which song did we predict?\n                result = ast.literal_eval(result)\n                song_result = result[""song_name""]\n                log_msg(\'song: %s\' % song)\n                log_msg(\'song_result: %s\' % song_result)\n\n                if song_result != song:\n                    log_msg(\'invalid match\')\n                    self.result_match[line][col] = \'invalid\'\n                    self.result_matching_times[line][col] = 0\n                    self.result_query_duration[line][col] = 0\n                    self.result_match_confidence[line][col] = 0\n                else:\n                    log_msg(\'correct match\')\n                    print self.result_match\n                    self.result_match[line][col] = \'yes\'\n                    self.result_query_duration[line][col] = round(result[Jamaisvu.MATCH_TIME],3)\n                    self.result_match_confidence[line][col] = result[Jamaisvu.CONFIDENCE]\n\n                    song_start_time = re.findall(""\\_[^\\_]+"",f)\n                    song_start_time = song_start_time[0].lstrip(""_ "")\n\n                    result_start_time = round((result[Jamaisvu.OFFSET] * DEFAULT_WINDOW_SIZE *\n                        DEFAULT_OVERLAP_RATIO) / (DEFAULT_FS), 0)\n\n                    self.result_matching_times[line][col] = int(result_start_time) - int(song_start_time)\n                    if (abs(self.result_matching_times[line][col]) == 1):\n                        self.result_matching_times[line][col] = 0\n\n                    log_msg(\'query duration: %s\' % round(result[Jamaisvu.MATCH_TIME],3))\n                    log_msg(\'confidence: %s\' % result[Jamaisvu.CONFIDENCE])\n                    log_msg(\'song start_time: %s\' % song_start_time)\n                    log_msg(\'result start time: %s\' % result_start_time)\n                    if (self.result_matching_times[line][col] == 0):\n                        log_msg(\'accurate match\')\n                    else:\n                        log_msg(\'inaccurate match\')\n            log_msg(\'--------------------------------------------------\\n\')\n'"
jamaisvu/wavio.py,8,"b'# wavio.py\n# Author: Warren Weckesser\n# License: BSD 3-Clause (http://opensource.org/licenses/BSD-3-Clause)\n# Synopsis: A Python module for reading and writing 24 bit WAV files.\n# Github: github.com/WarrenWeckesser/wavio\n\nimport wave as _wave\nimport numpy as _np\n\n\ndef _wav2array(nchannels, sampwidth, data):\n    """"""data must be the string containing the bytes from the wav file.""""""\n    num_samples, remainder = divmod(len(data), sampwidth * nchannels)\n    if remainder > 0:\n        raise ValueError(\'The length of data is not a multiple of \'\n                         \'sampwidth * num_channels.\')\n    if sampwidth > 4:\n        raise ValueError(""sampwidth must not be greater than 4."")\n\n    if sampwidth == 3:\n        a = _np.empty((num_samples, nchannels, 4), dtype=_np.uint8)\n        raw_bytes = _np.fromstring(data, dtype=_np.uint8)\n        a[:, :, :sampwidth] = raw_bytes.reshape(-1, nchannels, sampwidth)\n        a[:, :, sampwidth:] = (a[:, :, sampwidth - 1:sampwidth] >> 7) * 255\n        result = a.view(\'<i4\').reshape(a.shape[:-1])\n    else:\n        # 8 bit samples are stored as unsigned ints; others as signed ints.\n        dt_char = \'u\' if sampwidth == 1 else \'i\'\n        a = _np.fromstring(data, dtype=\'<%s%d\' % (dt_char, sampwidth))\n        result = a.reshape(-1, nchannels)\n    return result\n\n\ndef readwav(file):\n    """"""\n    Read a WAV file.\n\n    Parameters\n    ----------\n    file : string or file object\n        Either the name of a file or an open file pointer.\n\n    Return Values\n    -------------\n    rate : float\n        The sampling frequency (i.e. frame rate)\n    sampwidth : float\n        The sample width, in bytes.  E.g. for a 24 bit WAV file,\n        sampwidth is 3.\n    data : numpy array\n        The array containing the data.  The shape of the array is\n        (num_samples, num_channels).  num_channels is the number of\n        audio channels (1 for mono, 2 for stereo).\n\n    Notes\n    -----\n    This function uses the `wave` module of the Python standard libary\n    to read the WAV file, so it has the same limitations as that library.\n    In particular, the function does not read compressed WAV files.\n\n    """"""\n    wav = _wave.open(file)\n    rate = wav.getframerate()\n    nchannels = wav.getnchannels()\n    sampwidth = wav.getsampwidth()\n    nframes = wav.getnframes()\n    data = wav.readframes(nframes)\n    wav.close()\n    array = _wav2array(nchannels, sampwidth, data)\n    return rate, sampwidth, array\n\n\ndef writewav24(filename, rate, data):\n    """"""\n    Create a 24 bit wav file.\n\n    Parameters\n    ----------\n    filename : string\n        Name of the file to create.\n    rate : float\n        The sampling frequency (i.e. frame rate) of the data.\n    data : array-like collection of integer or floating point values\n        data must be ""array-like"", either 1- or 2-dimensional.  If it\n        is 2-d, the rows are the frames (i.e. samples) and the columns\n        are the channels.\n\n    Notes\n    -----\n    The data is assumed to be signed, and the values are assumed to be\n    within the range of a 24 bit integer.  Floating point values are\n    converted to integers.  The data is not rescaled or normalized before\n    writing it to the file.\n\n    Example\n    -------\n    Create a 3 second 440 Hz sine wave.\n\n    >>> rate = 22050  # samples per second\n    >>> T = 3         # sample duration (seconds)\n    >>> f = 440.0     # sound frequency (Hz)\n    >>> t = np.linspace(0, T, T*rate, endpoint=False)\n    >>> x = (2**23 - 1) * np.sin(2 * np.pi * f * t)\n    >>> writewav24(""sine24.wav"", rate, x)\n\n    """"""\n    a32 = _np.asarray(data, dtype=_np.int32)\n    if a32.ndim == 1:\n        # Convert to a 2D array with a single column.\n        a32.shape = a32.shape + (1,)\n    # By shifting first 0 bits, then 8, then 16, the resulting output\n    # is 24 bit little-endian.\n    a8 = (a32.reshape(a32.shape + (1,)) >> _np.array([0, 8, 16])) & 255\n    wavdata = a8.astype(_np.uint8).tostring()\n\n    w = _wave.open(filename, \'wb\')\n    w.setnchannels(a32.shape[1])\n    w.setsampwidth(3)\n    w.setframerate(rate)\n    w.writeframes(wavdata)\n    w.close()\n'"
