file_path,api_count,code
src/adversarial_attacks.py,0,"b'import tensorflow as tf\nfrom math import pi\n\ndef rotate_op(rot):\n    point = tf.constant([1, 0, 0])\n    point = point[:, tf.newaxis]\n\n    pitch = rot[0][0]\n    yaw = rot[0][1]\n\n    pitch_mat = tf.stack([\n        1, 0, 0,\n        0, tf.cos(pitch), -tf.sin(pitch),\n        0, tf.sin(pitch), tf.cos(pitch)\n    ])\n    pitch_mat = tf.reshape(pitch_mat, [3, 3])\n    yaw_mat = tf.stack([\n        tf.cos(yaw), -tf.sin(yaw), 0,\n        tf.sin(yaw), tf.cos(yaw), 0,\n        0, 0, 1\n    ])\n    yaw_mat = tf.reshape(yaw_mat, [3, 3])\n\n    return tf.reshape(tf.matmul(yaw_mat, tf.matmul(pitch_mat, point)), [1, -1])\n\ndef view_op(x_pl, model_loss_fn, t_pl = None, one_hot = True, iter = 10, eps = 1):\n    targeted = t_pl is not None\n    alpha = eps / float(iter)\n\n    # use the prediction class to prevent label leaking\n    if not targeted:\n        logits, _ = model_loss_fn(x_pl, None)\n        t_pl = tf.argmax(logits, axis = 1)\n        if one_hot:\n            t_pl = tf.one_hot(t_pl, tf.shape(logits)[1])\n        t_pl = tf.stop_gradient(t_pl)\n    \n    rot = tf.random_uniform([1, 2], maxval = pi * 2)\n    for _ in range(iter):\n        point = rotate_op(rot)\n        dists = tf.linalg.norm(x_pl - point[:, tf.newaxis], axis = 2)\n        min_dist = tf.reduce_min(dists, axis = 1)\n        avg_dist = tf.reduce_mean(dists, axis = 1)\n        dists = (dists - avg_dist[:, tf.newaxis]) / (avg_dist[:, tf.newaxis] - min_dist[:, tf.newaxis])\n        dists = 1.0 - tf.sigmoid(dists * 6.0)\n        x_adv = dists[:, :, tf.newaxis] * x_pl\n\n        _, loss = model_loss_fn(x_adv, t_pl)\n        grad = tf.gradients(loss, rot)[0]\n        if targeted:\n            rot = rot - alpha * grad\n        else:\n            rot = rot + alpha * grad\n        rot = tf.stop_gradient(rot)\n    \n    remove = dists < 0.4\n    idx = tf.argmin(tf.to_float(remove), axis = 1)\n    one_hot = tf.one_hot(idx, tf.shape(x_adv)[1])\n    replace = tf.reduce_sum(x_adv * one_hot[:, :, tf.newaxis], axis = 1, keep_dims = True)\n    x_adv = tf.where(remove[:, :, tf.newaxis] & tf.fill(tf.shape(x_adv), True), replace + tf.zeros_like(x_adv), x_adv)\n    x_adv = tf.stop_gradient(x_adv)\n\n    return x_adv\n\ndef sort_op(x_pl, model_loss_fn, t_pl = None, faces = None, one_hot = True, iter = 10):\n    targeted = t_pl is not None\n\n    # use the prediction class to prevent label leaking\n    if not targeted:\n        logits, _ = model_loss_fn(x_pl, None)\n        t_pl = tf.argmax(logits, axis = 1)\n        if one_hot:\n            t_pl = tf.one_hot(t_pl, tf.shape(logits)[1])\n        t_pl = tf.stop_gradient(t_pl)\n\n    if faces is not None:\n        normal = tf.cross(faces[:, :, 1] - faces[:, :, 0], faces[:, :, 2] - faces[:, :, 1])\n        normal = normal / tf.linalg.norm(normal, axis = 2, keep_dims = True)\n\n    x_adv = x_pl\n    var = tf.Variable(x_adv, trainable = False, collections = [""not_in_checkpoint""])\n    with tf.control_dependencies([tf.variables_initializer([var])]):\n        for _ in range(iter):\n            _, loss = model_loss_fn(x_adv, t_pl)\n            grad = tf.reduce_mean(tf.gradients(loss, x_adv)[0], axis = 2)\n            #grad_sorted = tf.contrib.framework.argsort(grad, axis = 1)\n            \n            #idx = tf.tile(tf.range(tf.shape(x_adv)[0])[:, tf.newaxis], multiples = [1, iter])\n            #lower = grad_sorted[:, :iter]\n            #higher = grad_sorted[:, -iter:][:, ::-1]\n            idx = tf.range(tf.shape(x_adv)[0])[:, tf.newaxis]\n            lower = tf.to_int32(tf.argmin(grad, axis = 1)[:, tf.newaxis])\n            higher = tf.to_int32(tf.argmax(grad, axis = 1)[:, tf.newaxis])\n            lower = tf.reshape(tf.stack([idx, lower], axis = 2), shape = [-1, 2])\n            higher = tf.reshape(tf.stack([idx, higher], axis = 2), shape = [-1, 2])\n\n            if targeted:\n                # replace higher with lower\n                x_adv = tf.scatter_nd_update(var, higher, tf.gather_nd(x_adv, lower) + 1e-3)\n            else:\n                # replace lower with higher\n                x_adv = tf.scatter_nd_update(var, lower, tf.gather_nd(x_adv, higher) + 1e-3)\n            \n            x_adv = tf.assign(var, x_adv)\n            x_adv = tf.stop_gradient(x_adv)\n    \n    return x_adv\n\ndef iter_grad_op(x_pl, model_loss_fn, t_pl = None, faces = None, one_hot = True, iter = 10, eps = 0.01, restrict = False, ord = ""inf"", clip_min = None, clip_max = None, clip_norm = None, min_norm = 0.0):\n    targeted = t_pl is not None\n    alpha = eps / float(iter)\n    if clip_norm is not None:\n        dists = x_pl[:, tf.newaxis] - x_pl[:, :, tf.newaxis]\n        dists = tf.linalg.norm(dists, axis = 3)\n\n        diag = tf.eye(tf.shape(x_pl)[1], batch_shape = [tf.shape(x_pl)[0]])\n        dists = tf.where(diag > 0.0, tf.fill(tf.shape(dists), float(""inf"")), dists)\n        \n        dists = tf.reduce_min(dists, axis = 2)\n        avg, var = tf.nn.moments(dists, axes = [1], keep_dims = True)\n        std = clip_norm * tf.sqrt(var)\n        clip_norm = avg + std # set clip_norm to be the actual clip value\n        \n        clip_norm = clip_norm / float(iter)\n    min_norm = min_norm / float(iter)\n\n    # use the prediction class to prevent label leaking\n    if not targeted:\n        logits, _ = model_loss_fn(x_pl, None)\n        t_pl = tf.argmax(logits, axis = 1)\n        if one_hot:\n            t_pl = tf.one_hot(t_pl, tf.shape(logits)[1])\n        t_pl = tf.stop_gradient(t_pl)\n\n    if faces is not None:\n        normal = tf.cross(faces[:, :, 1] - faces[:, :, 0], faces[:, :, 2] - faces[:, :, 1])\n        normal = normal / tf.linalg.norm(normal, axis = 2, keep_dims = True)\n\n    if ord == ""inf"":\n        ord_fn = tf.sign\n    elif ord == ""1"":\n        ord_fn = lambda x: x / tf.reduce_sum(tf.abs(x), axis = list(range(1, x.shape.ndims)), keep_dims = True)\n    elif ord == ""2"":\n        ord_fn = lambda x: x / tf.sqrt(tf.reduce_sum(x ** 2, axis = list(range(1, x.shape.ndims)), keep_dims = True))\n    elif ord == ""2.5"":\n        def ord_fn(x):\n            norm = tf.linalg.norm(x, axis = -1, keep_dims = True)\n            return tf.where(tf.equal(norm, 0.0) & tf.fill(tf.shape(x), True), tf.zeros_like(x), x / norm)\n    else:\n        raise ValueError(""Only L-inf, L1, L2, and normalized L2 norms are supported!"")\n\n    x_adv = x_pl\n    for _ in range(iter):\n        _, loss = model_loss_fn(x_adv, t_pl)\n\n        x_original = x_adv\n\n        perturb = alpha * ord_fn(tf.gradients(loss, x_adv)[0])\n        perturb_norm = tf.linalg.norm(perturb, axis = -1, keep_dims = True)\n        if clip_norm is not None:\n            clip = perturb_norm > clip_norm[..., tf.newaxis]\n            perturb = tf.where(clip & tf.fill(tf.shape(perturb), True), perturb * clip_norm[..., tf.newaxis] / perturb_norm, perturb)\n        perturb = perturb * tf.to_float(perturb_norm >= min_norm)\n\n        if targeted:\n            x_adv = x_adv - perturb\n        else:\n            x_adv = x_adv + perturb\n\n        if faces is not None:\n            # constrain perturbations for each point to its corresponding plane\n            x_adv = x_adv - normal * tf.reduce_sum(normal * (x_adv - faces[:, :, 0]), axis = 2, keep_dims = True)\n            # clip perturbations that goes outside each triangle\n            if restrict:\n                x_adv = triangle_border_intersections_op(x_original, x_adv, faces)\n\n        if clip_min is not None and clip_max is not None:\n            x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n        \n        x_adv = tf.stop_gradient(x_adv)\n    \n    return x_adv\n\ndef momentum_grad_op(x_pl, model_loss_fn, t_pl = None, faces = None, one_hot = True, iter = 10, eps = 0.01, momentum = 1.0, restrict = False, ord = ""inf"", clip_min = None, clip_max = None, clip_norm = None, min_norm = 0.0):\n    targeted = t_pl is not None\n    alpha = eps / float(iter)\n    if clip_norm is not None:\n        dists = x_pl[:, tf.newaxis] - x_pl[:, :, tf.newaxis]\n        dists = tf.linalg.norm(dists, axis = 3)\n\n        diag = tf.eye(tf.shape(x_pl)[1], batch_shape = [tf.shape(x_pl)[0]])\n        dists = tf.where(diag > 0.0, tf.fill(tf.shape(dists), float(""inf"")), dists)\n        \n        dists = tf.reduce_min(dists, axis = 2)\n        avg, var = tf.nn.moments(dists, axes = [1], keep_dims = True)\n        std = clip_norm * tf.sqrt(var)\n        clip_norm = avg + std # set clip_norm to be the actual clip value\n\n        clip_norm = clip_norm / float(iter)\n    min_norm = min_norm / float(iter)\n\n    # use the prediction class to prevent label leaking\n    if not targeted:\n        logits, _ = model_loss_fn(x_pl, None)\n        t_pl = tf.argmax(logits, axis = 1)\n        if one_hot:\n            t_pl = tf.one_hot(t_pl, tf.shape(logits)[1])\n        t_pl = tf.stop_gradient(t_pl)\n\n    if faces is not None:\n        normal = tf.cross(faces[:, :, 1] - faces[:, :, 0], faces[:, :, 2] - faces[:, :, 1])\n        normal = normal / tf.linalg.norm(normal, axis = 2, keep_dims = True)\n\n    if ord == ""inf"":\n        ord_fn = tf.sign\n    elif ord == ""1"":\n        ord_fn = lambda x: x / tf.reduce_sum(tf.abs(x), axis = list(range(1, x.shape.ndims)), keep_dims = True)\n    elif ord == ""2"":\n        ord_fn = lambda x: x / tf.sqrt(tf.reduce_sum(x ** 2, axis = list(range(1, x.shape.ndims)), keep_dims = True))\n    elif ord == ""2.5"":\n        def ord_fn(x):\n            norm = tf.linalg.norm(x, axis = -1, keep_dims = True)\n            return tf.where(tf.equal(norm, 0.0) & tf.fill(tf.shape(x), True), tf.zeros_like(x), x / norm)\n    else:\n        raise ValueError(""Only L-inf, L1, L2, and normalized L2 norms are supported!"")\n\n    x_adv = x_pl\n    prev_grad = tf.zeros_like(x_pl)\n    for _ in range(iter):\n        _, loss = model_loss_fn(x_adv, t_pl)\n\n        grad = tf.gradients(loss, x_adv)[0]\n        grad = grad / tf.reduce_mean(tf.abs(grad), axis = list(range(1, x_pl.shape.ndims)), keep_dims = True)\n        grad = momentum * prev_grad + grad\n        prev_grad = grad\n\n        x_original = x_adv\n\n        perturb = alpha * ord_fn(grad)\n        perturb_norm = tf.linalg.norm(perturb, axis = -1, keep_dims = True)\n        if clip_norm is not None:\n            clip = perturb_norm > clip_norm[..., tf.newaxis]\n            perturb = tf.where(clip & tf.fill(tf.shape(perturb), True), perturb * clip_norm[..., tf.newaxis] / perturb_norm, perturb)\n        perturb = perturb * tf.to_float(perturb_norm >= min_norm)\n\n        if targeted:\n            x_adv = x_adv - perturb\n        else:\n            x_adv = x_adv + perturb\n\n        if faces is not None:\n            # constrain perturbations for each point to its corresponding plane\n            x_adv = x_adv - normal * tf.reduce_sum(normal * (x_adv - faces[:, :, 0]), axis = 2, keep_dims = True)\n            # clip perturbations that goes outside each triangle\n            if restrict:\n                x_adv = triangle_border_intersections_op(x_original, x_adv, faces)\n\n        if clip_min is not None and clip_max is not None:\n            x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n        \n        x_adv = tf.stop_gradient(x_adv)\n    \n    return x_adv\n\ndef jacobian_saliency_map_points_op(x_pl, model_loss_fn, t_pl = None, faces = None, one_hot = True, iter = 10, eps = 0.01, restrict = False, clip_min = None, clip_max = None):\n    targeted = t_pl is not None\n    \n    # use the prediction class to prevent label leaking\n    if not targeted:\n        logits, _ = model_loss_fn(x_pl, None)\n        t_pl = tf.argmax(logits, axis = 1)\n        t_pl = tf.stop_gradient(t_pl)\n    \n    if targeted and one_hot:\n        t_pl = tf.argmax(t_pl, axis = 1)\n        t_pl = tf.stop_gradient(t_pl)\n\n    if faces is not None:\n        normal = tf.cross(faces[:, :, 1] - faces[:, :, 0], faces[:, :, 2] - faces[:, :, 1])\n        normal = normal / tf.linalg.norm(normal, axis = 2, keep_dims = True)\n\n    x_adv = x_pl\n    unused = tf.fill(tf.shape(x_adv)[:2], True)\n    for _ in range(iter):\n        logits, _ = model_loss_fn(x_adv, None)\n\n        total_grad = tf.gradients(logits, x_adv)[0]\n        target_grad = tf.gradients(tf.reduce_sum(tf.stop_gradient(tf.one_hot(t_pl, tf.shape(logits)[1])) * logits, axis = 1), x_adv)[0]\n        other_grad = total_grad - target_grad\n\n        saliency = tf.abs(target_grad) * tf.abs(other_grad)\n        increase = (target_grad >= 0.0) & (other_grad <= 0.0) & unused[:, :, tf.newaxis]\n        decrease = (target_grad <= 0.0) & (other_grad >= 0.0) & unused[:, :, tf.newaxis]\n        saliency = saliency * tf.to_float(increase | decrease)\n        saliency = tf.reduce_sum(saliency, axis = 2)\n\n        idx = tf.argmax(saliency, axis = 1)\n        one_hot = tf.one_hot(idx, tf.shape(saliency)[1], on_value = True, off_value = False)\n        increase = increase & one_hot[:, :, tf.newaxis]\n        decrease = decrease & one_hot[:, :, tf.newaxis]\n        unused = unused & ~one_hot\n\n        x_original = x_adv\n\n        perturb = tf.to_float(increase) * tf.fill(tf.shape(x_adv), -eps) + tf.to_float(decrease) * tf.fill(tf.shape(x_adv), eps)\n\n        if targeted:\n            x_adv = x_adv - perturb\n        else:\n            x_adv = x_adv + perturb\n\n        if faces is not None:\n            # constrain perturbations for each point to its corresponding plane\n            x_adv = x_adv - normal * tf.reduce_sum(normal * (x_adv - faces[:, :, 0]), axis = 2, keep_dims = True)\n            # clip perturbations that goes outside each triangle\n            if restrict:\n                x_adv = triangle_border_intersections_op(x_original, x_adv, faces)\n\n        if clip_min is not None and clip_max is not None:\n            x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n\n        x_adv = tf.stop_gradient(x_adv)\n    \n    return x_adv\n\ndef jacobian_saliency_map_pair_op(x_pl, model_loss_fn, t_pl = None, faces = None, one_hot = True, iter = 10, eps = 0.01, restrict = False, clip_min = None, clip_max = None):\n    targeted = t_pl is not None\n    \n    # use the prediction class to prevent label leaking\n    if not targeted:\n        logits, _ = model_loss_fn(x_pl, None)\n        t_pl = tf.argmax(logits, axis = 1)\n        t_pl = tf.stop_gradient(t_pl)\n    \n    if targeted and one_hot:\n        t_pl = tf.argmax(t_pl, axis = 1)\n        t_pl = tf.stop_gradient(t_pl)\n\n    if faces is not None:\n        normal = tf.cross(faces[:, :, 1] - faces[:, :, 0], faces[:, :, 2] - faces[:, :, 1])\n        normal = normal / tf.linalg.norm(normal, axis = 2, keep_dims = True)\n\n    x_adv = x_pl\n    size = tf.reduce_prod(tf.shape(x_adv)[1:])\n    unused = tf.fill([tf.shape(x_adv)[0], size], True)\n    for _ in range(iter):\n        logits, _ = model_loss_fn(x_adv, None)\n\n        total_grad = tf.gradients(logits, x_adv)[0]\n        target_grad = tf.gradients(tf.reduce_sum(tf.stop_gradient(tf.one_hot(t_pl, tf.shape(logits)[1])) * logits, axis = 1), x_adv)[0]\n        other_grad = total_grad - target_grad\n\n        saliency = tf.abs(target_grad) * tf.abs(other_grad)\n        saliency = tf.reshape(saliency, [-1, size])\n        saliency = saliency[:, tf.newaxis, :] + saliency[:, :, tf.newaxis]\n        target_grad = tf.reshape(target_grad, [-1, size])\n        other_grad = tf.reshape(other_grad, [-1, size])\n        target_grad = target_grad[:, tf.newaxis, :] + target_grad[:, :, tf.newaxis]\n        other_grad = other_grad[:, tf.newaxis, :] + other_grad[:, :, tf.newaxis]\n\n        if targeted:\n            # target should increase, others should decrease\n            cond = unused[:, tf.newaxis, :] & unused[:, :, tf.newaxis] & (target_grad >= 0.0) & (other_grad <= 0.0)\n        else:\n            # others should increase, target should decrease\n            cond = unused[:, tf.newaxis, :] & unused[:, :, tf.newaxis] & (target_grad <= 0.0) & (other_grad >= 0.0)\n\n        diag_zeros = tf.ones([size, size])\n        diag_zeros = tf.linalg.set_diag(diag_zeros, tf.zeros(size))\n\n        idx_both = tf.argmax(tf.reshape(tf.to_float(cond) * diag_zeros[tf.newaxis, :, :] * saliency, [-1, size * size]), axis = 1)\n        i = tf.to_int64(idx_both / tf.to_int64(size))\n        j = tf.to_int64(idx_both % tf.to_int64(size))\n        perturb = tf.one_hot(i, size, on_value = eps, off_value = 0.0) + tf.one_hot(j, size, on_value = eps, off_value = 0.0)\n        perturb = tf.reshape(perturb, tf.shape(x_adv))\n        unused = unused & tf.one_hot(i, size, on_value = False, off_value = True) & tf.one_hot(j, size, on_value = False, off_value = True)\n\n        x_original = x_adv\n        x_adv = x_adv + perturb\n\n        if faces is not None:\n            # constrain perturbations for each point to its corresponding plane\n            x_adv = x_adv - normal * tf.reduce_sum(normal * (x_adv - faces[:, :, 0]), axis = 2, keep_dims = True)\n            # clip perturbations that goes outside each triangle\n            if restrict:\n                x_adv = triangle_border_intersections_op(x_original, x_adv, faces)\n\n        if clip_min is not None and clip_max is not None:\n            x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n\n        x_adv = tf.stop_gradient(x_adv)\n    \n    return x_adv\n\ninf = float(""inf"")\nfloat_epsilon = 1e-4 # to handle floating point inaccuracies\n\ndef triangle_border_intersections_op(p1, p2, triangles):\n    p = p1\n    d = p2 - p1\n\n    triangle_normals = tf.cross(triangles[:, :, 1] - triangles[:, :, 0], triangles[:, :, 2] - triangles[:, :, 1])\n\n    side_normals = tf.stack([\n        tf.cross(triangles[:, :, 1] - triangles[:, :, 0], triangles[:, :, 1] - triangles[:, :, 0] + triangle_normals),\n        tf.cross(triangles[:, :, 2] - triangles[:, :, 1], triangles[:, :, 2] - triangles[:, :, 1] + triangle_normals),\n        tf.cross(triangles[:, :, 0] - triangles[:, :, 2], triangles[:, :, 0] - triangles[:, :, 2] + triangle_normals)\n    ], axis = 2)\n\n    # intersection between line and triangle sides as planes\n    dot = tf.reduce_sum(side_normals * d[:, :, tf.newaxis, :], axis = 3)\n    zero_mask = tf.equal(dot, 0.0)\n    dot = tf.where(zero_mask, tf.ones_like(dot), dot) # prevent division by zero\n    a = p[:, :, tf.newaxis, :] - triangles\n    b = -tf.reduce_sum(side_normals * a, axis = 3) / dot\n    dir = d[:, :, tf.newaxis, :] * b[:, :, :, tf.newaxis]\n    # intersections not in the same direction as d have b < 0\n    mask = tf.logical_or(zero_mask, b < -float_epsilon)[:, :, :, tf.newaxis] & tf.fill(tf.shape(dir), True)\n    dir = tf.where(mask, tf.fill(tf.shape(dir), inf), dir)\n\n    # only use closest intersection\n    dists = tf.linalg.norm(dir, axis = 3)\n    min_idx = tf.argmin(dists, axis = 2)\n    closest_mask = tf.one_hot(min_idx, 3, on_value = True, off_value = False)[:, :, :, tf.newaxis] & tf.fill(tf.shape(dir), True)\n    dir = tf.where(closest_mask, dir, tf.zeros_like(dir))\n    dir = tf.reduce_sum(dir, axis = 2)\n    # either use the intersection point or d\n    dists = tf.linalg.norm(dir, axis = 2)\n    norm_d = tf.linalg.norm(d, axis = 2)\n    closest_mask = (norm_d < dists)[:, :, tf.newaxis] & tf.fill(tf.shape(dir), True)\n    dir = tf.where(closest_mask, d, dir)\n\n    return p + dir'"
src/adversarial_defenses.py,0,"b'import tensorflow as tf\n\ndef remove_outliers_fn(x, model_loss_fn, top_k = 10, num_std = 1.0):\n    dists = x[:, tf.newaxis] - x[:, :, tf.newaxis]\n    dists = tf.linalg.norm(dists, axis = 3)\n    \n    diag = tf.eye(tf.shape(x)[1], batch_shape = [tf.shape(x)[0]])\n    dists = tf.where(diag > 0.0, tf.fill(tf.shape(dists), float(""inf"")), dists)\n    dists = tf.nn.top_k(dists * -1.0, k = top_k, sorted = False)[0] * -1.0\n    \n    dists = tf.reduce_mean(dists, axis = 2)\n    avg, var = tf.nn.moments(dists, axes = [1], keep_dims = True)\n    std = num_std * tf.sqrt(var)\n    \n    remove = dists > avg + std\n    idx = tf.argmin(tf.to_float(remove), axis = 1)\n    one_hot = tf.one_hot(idx, tf.shape(x)[1])\n    replace = tf.reduce_sum(x * one_hot[:, :, tf.newaxis], axis = 1, keep_dims = True)\n    x = tf.where(remove[:, :, tf.newaxis] & tf.fill(tf.shape(x), True), replace + tf.zeros_like(x), x)\n\n    return tf.stop_gradient(x)\n\ndef remove_salient_points_fn(x, model_loss_fn, top_k = 100):\n    logits, _ = model_loss_fn(x, None)\n    grads = []\n    for i in range(logits.shape[1]):\n        grads.append(tf.gradients(logits[:, i], x)[0])\n    grads = tf.stack(grads, axis = 0)\n\n    norms = tf.linalg.norm(grads, axis = 3)\n    norms = tf.reduce_max(norms, axis = 0)\n    _, remove = tf.nn.top_k(norms, k = top_k, sorted = False)\n    remove = tf.one_hot(remove, tf.shape(x)[1], on_value = True, off_value = False)\n    remove = tf.reduce_any(remove, axis = 1)\n\n    idx = tf.argmin(tf.to_float(remove), axis = 1)\n    one_hot = tf.one_hot(idx, tf.shape(x)[1])\n    replace = tf.reduce_sum(x * one_hot[:, :, tf.newaxis], axis = 1, keep_dims = True)\n    x = tf.where(remove[:, :, tf.newaxis] & tf.fill(tf.shape(x), True), replace + tf.zeros_like(x), x)\n\n    return tf.stop_gradient(x)'"
src/adversarial_pointnet.py,8,"b'import numpy as np\nimport tensorflow as tf\nimport scipy\nimport adversarial_utils\nimport adversarial_defenses\nimport os\nimport sys\nimport argparse\nimport importlib\nworking_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.join(working_dir, ""models""))\nsys.path.append(os.path.join(working_dir, ""utils""))\nimport provider\nimport pc_util\n\nparser = argparse.ArgumentParser(description = ""Adversarial attacks on PointNet used for classification."", formatter_class = argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(""--checkpoint"", default = ""log/model.ckpt"", help = ""Path to the model\'s checkpoint file."")\nparser.add_argument(""--output"", default = ""adversarial"", help = ""Output directory."")\nparser.add_argument(""--data"", default = ""data/modelnet40_ply_hdf5_2048/test_files.txt"", help = ""Input data. Either a Numpy file or a text file containing a list of HDF5 files."")\nparser.add_argument(""--class-names"", default = ""data/modelnet40_ply_hdf5_2048/shape_names.txt"", help = ""Text file containing a list of class names."")\nparser.add_argument(""--num-points"", type = int, default = 1024, help = ""Number of points to use."")\nparser.add_argument(""--num-objects"", type = int, default = 1000000000, help = ""Number of correctly classified objects to use. Specify a very large number to use all correctly classified objects."")\nparser.add_argument(""--targeted"", action = ""store_true"", help = ""Run targeted attack."")\nparser.add_argument(""--iter"", type = int, default = 10, help = ""Number of iterations for iterative gradient sign."")\nparser.add_argument(""--eps"", nargs = ""+"", type = float, default = [1], help = ""List of epsilon values for iterative gradient sign."")\nparser.add_argument(""--mode"", choices = [""iterative"", ""momentum"", ""saliency"", ""sort"", ""view""], default = ""iterative"", help = ""Which algorithm to use when perturbing points."")\nparser.add_argument(""--defense"", choices = [""none"", ""outliers"", ""saliency""], default = ""none"", help = ""Which algorithm to use for postprocessing points as a defense."")\nparser.add_argument(""--projection"", action = ""store_true"", help = ""Project the gradient vectors onto each point\'s corresponding triangle."")\nparser.add_argument(""--restrict"", action = ""store_true"", help = ""Restrict the gradient vectors to be inside each point\'s corresponding triangle."")\nparser.add_argument(""--norm"", default = ""inf"", help = ""Norm used for gradient sign."")\nparser.add_argument(""--clip-norm"", type = float, default = None, help = ""Value to clip L2 norm by."")\nparser.add_argument(""--min-norm"", type = float, default = 0.0, help = ""Ignore perturbations with a smaller L2 norm than this."")\nargs = parser.parse_args()\nprint(args)\n\nmodel = importlib.import_module(""pointnet_cls"")\nclass_names = [line.rstrip() for line in open(args.class_names)]\n\nnp.random.seed(0) # fixed seed for consistency\n\nnumpy_file = args.data.endswith("".npz"")\n\nif numpy_file:\n    with np.load(args.data) as file:\n        data_x = file[""points""][:, :args.num_points, :]\n        if args.projection:\n            data_f = file[""faces""][:, :args.num_points, :3, :]\n        else:\n            data_f = None\n        data_t = file[""labels""]\nelse:\n    test_files = provider.getDataFiles(args.data)\n\n    data_x = []\n    data_t = []\n    for file in test_files:\n        curr_x, curr_t = provider.loadDataFile(file)\n        data_x.append(curr_x[:, :args.num_points, :])\n        data_t.append(np.squeeze(curr_t))\n\n    data_x = np.concatenate(data_x)\n    data_f = None\n    data_t = np.concatenate(data_t)\n\ndefense_dict = {\n    ""none"": None,\n    ""outliers"": adversarial_defenses.remove_outliers_fn,\n    ""saliency"": adversarial_defenses.remove_salient_points_fn\n}\n\nx_pl, t_pl = model.placeholder_inputs(1, args.num_points)\n\nis_training = tf.placeholder(tf.bool, shape = [])\n\ndef model_loss_fn(x, t):\n    with tf.variable_scope(tf.get_variable_scope(), reuse = tf.AUTO_REUSE):\n        y, end_points = model.get_model(x, is_training, num_classes = len(class_names))\n    if t is None:\n        loss = None\n    else:\n        loss = model.get_loss(y, t, end_points)\n    return y, loss\n\nif args.targeted:\n    res = adversarial_utils.targeted_attack(args.checkpoint, args.output, x_pl, t_pl, model_loss_fn, data_x, data_t, args.num_objects, class_names, data_f = data_f, restrict = args.restrict, iter = args.iter, eps_list = args.eps, norm = args.norm, mode = args.mode, one_hot = False, clip_norm = args.clip_norm, min_norm = args.min_norm, postprocess_fn = defense_dict[args.defense], extra_feed_dict = {is_training: False})\n    if data_f is None:\n        x_original, target, x_adv = res\n    else:\n        x_original, target, x_adv, faces = res\n\n    for eps_idx in range(len(args.eps)):\n        class_idx = np.random.choice(len(class_names), size = len(class_names), replace = False)\n        for i in class_idx:\n            idx = np.random.choice(len(x_original[eps_idx][i]), size = min(3, len(x_original[eps_idx][i])), replace = False)\n            for j in idx:\n                img_file = ""%d_%s_original.jpg"" % (j, class_names[target[eps_idx][i][j]])\n                img_file = os.path.join(args.output, img_file)\n                img = pc_util.point_cloud_three_views(x_original[eps_idx][i][j])\n                scipy.misc.imsave(img_file, img)\n\n                eps_str = str(args.eps[eps_idx]).replace(""."", ""_"")\n                img_file = ""%d_%s_adv_target_%s_eps_%s.jpg"" % (j, class_names[target[eps_idx][i][j]], class_names[i], eps_str)\n                img_file = os.path.join(args.output, img_file)\n                img = pc_util.point_cloud_three_views(x_adv[eps_idx][i][j])\n                scipy.misc.imsave(img_file, img)\nelse:\n    res = adversarial_utils.untargeted_attack(args.checkpoint, args.output, x_pl, t_pl, model_loss_fn, data_x, data_t, args.num_objects, class_names, data_f = data_f, restrict = args.restrict, iter = args.iter, eps_list = args.eps, norm = args.norm, mode = args.mode, one_hot = False, clip_norm = args.clip_norm, min_norm = args.min_norm, postprocess_fn = defense_dict[args.defense], extra_feed_dict = {is_training: False})\n    if data_f is None:\n        x_original, target, x_adv, pred_adv = res\n    else:\n        x_original, target, x_adv, pred_adv, faces = res\n\n    for eps_idx in range(len(args.eps)):\n        idx = np.random.choice(len(x_original[eps_idx]), size = min(3, len(x_original[eps_idx])), replace = False)\n        for i in idx:\n            img_file = ""%d_%s_original.jpg"" % (i, class_names[target[eps_idx][i]])\n            img_file = os.path.join(args.output, img_file)\n            img = pc_util.point_cloud_three_views(x_original[eps_idx][i])\n            scipy.misc.imsave(img_file, img)\n\n            eps_str = str(args.eps[eps_idx]).replace(""."", ""_"")\n            img_file = ""%d_%s_adv_pred_%s_eps_%s.jpg"" % (i, class_names[target[eps_idx][i]], class_names[pred_adv[eps_idx][i]], eps_str)\n            img_file = os.path.join(args.output, img_file)\n            img = pc_util.point_cloud_three_views(x_adv[eps_idx][i])\n            scipy.misc.imsave(img_file, img)'"
src/adversarial_pointnet2.py,8,"b'import numpy as np\nimport tensorflow as tf\nimport scipy\nimport adversarial_utils\nimport adversarial_defenses\nimport os\nimport sys\nimport argparse\nimport importlib\nworking_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.join(working_dir, ""models""))\nsys.path.append(os.path.join(working_dir, ""utils""))\nimport provider\nimport pc_util\n\nparser = argparse.ArgumentParser(description = ""Adversarial attacks on PointNet++ used for classification."", formatter_class = argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(""--checkpoint"", default = ""log/model.ckpt"", help = ""Path to the model\'s checkpoint file."")\nparser.add_argument(""--output"", default = ""adversarial"", help = ""Output directory."")\nparser.add_argument(""--data"", default = ""data/modelnet40_ply_hdf5_2048/test_files.txt"", help = ""Input data. Either a Numpy file or a text file containing a list of HDF5 files."")\nparser.add_argument(""--class-names"", default = ""data/modelnet40_ply_hdf5_2048/shape_names.txt"", help = ""Text file containing a list of class names."")\nparser.add_argument(""--num-points"", type = int, default = 1024, help = ""Number of points to use."")\nparser.add_argument(""--num-objects"", type = int, default = 1000000000, help = ""Number of correctly classified objects to use. Specify a very large number to use all correctly classified objects."")\nparser.add_argument(""--targeted"", action = ""store_true"", help = ""Run targeted attack."")\nparser.add_argument(""--iter"", type = int, default = 10, help = ""Number of iterations for iterative gradient sign."")\nparser.add_argument(""--eps"", nargs = ""+"", type = float, default = [1], help = ""List of epsilon values for iterative gradient sign."")\nparser.add_argument(""--mode"", choices = [""iterative"", ""momentum"", ""saliency"", ""sort"", ""view""], default = ""iterative"", help = ""Which algorithm to use when perturbing points."")\nparser.add_argument(""--defense"", choices = [""none"", ""outliers"", ""saliency""], default = ""none"", help = ""Which algorithm to use for postprocessing points as a defense."")\nparser.add_argument(""--projection"", action = ""store_true"", help = ""Project the gradient vectors onto each point\'s corresponding triangle."")\nparser.add_argument(""--restrict"", action = ""store_true"", help = ""Restrict the gradient vectors to be inside each point\'s corresponding triangle."")\nparser.add_argument(""--norm"", default = ""inf"", help = ""Norm used for gradient sign."")\nparser.add_argument(""--clip-norm"", type = float, default = None, help = ""Value to clip L2 norm by."")\nparser.add_argument(""--min-norm"", type = float, default = 0.0, help = ""Ignore perturbations with a smaller L2 norm than this."")\nargs = parser.parse_args()\nprint(args)\n\nmodel = importlib.import_module(""pointnet2_cls_ssg"")\nclass_names = [line.rstrip() for line in open(args.class_names)]\n\nnp.random.seed(0) # fixed seed for consistency\n\nnumpy_file = args.data.endswith("".npz"")\n\nif numpy_file:\n    with np.load(args.data) as file:\n        data_x = file[""points""][:, :args.num_points, :]\n        if args.projection:\n            data_f = file[""faces""][:, :args.num_points, :3, :]\n        else:\n            data_f = None\n        data_t = file[""labels""]\nelse:\n    test_files = provider.getDataFiles(args.data)\n\n    data_x = []\n    data_t = []\n    for file in test_files:\n        curr_x, curr_t = provider.loadDataFile(file)\n        data_x.append(curr_x[:, :args.num_points, :])\n        data_t.append(np.squeeze(curr_t))\n\n    data_x = np.concatenate(data_x)\n    data_f = None\n    data_t = np.concatenate(data_t)\n\ndefense_dict = {\n    ""none"": None,\n    ""outliers"": adversarial_defenses.remove_outliers_fn,\n    ""saliency"": adversarial_defenses.remove_salient_points_fn\n}\n\nx_pl, t_pl = model.placeholder_inputs(1, args.num_points)\n\nis_training = tf.placeholder(tf.bool, shape = [])\n\ndef model_loss_fn(x, t):\n    with tf.variable_scope(tf.get_variable_scope(), reuse = tf.AUTO_REUSE):\n        y, end_points = model.get_model(x, is_training, num_classes = len(class_names))\n    if t is None:\n        loss = None\n    else:\n        loss = model.get_loss(y, t, end_points)\n    return y, loss\n\nif args.targeted:\n    res = adversarial_utils.targeted_attack(args.checkpoint, args.output, x_pl, t_pl, model_loss_fn, data_x, data_t, args.num_objects, class_names, data_f = data_f, restrict = args.restrict, iter = args.iter, eps_list = args.eps, norm = args.norm, mode = args.mode, one_hot = False, clip_norm = args.clip_norm, min_norm = args.min_norm, postprocess_fn = defense_dict[args.defense], extra_feed_dict = {is_training: False})\n    if data_f is None:\n        x_original, target, x_adv = res\n    else:\n        x_original, target, x_adv, faces = res\n\n    for eps_idx in range(len(args.eps)):\n        class_idx = np.random.choice(len(class_names), size = len(class_names), replace = False)\n        for i in class_idx:\n            idx = np.random.choice(len(x_original[eps_idx][i]), size = min(3, len(x_original[eps_idx][i])), replace = False)\n            for j in idx:\n                img_file = ""%d_%s_original.jpg"" % (j, class_names[target[eps_idx][i][j]])\n                img_file = os.path.join(args.output, img_file)\n                img = pc_util.point_cloud_three_views(x_original[eps_idx][i][j])\n                scipy.misc.imsave(img_file, img)\n\n                eps_str = str(args.eps[eps_idx]).replace(""."", ""_"")\n                img_file = ""%d_%s_adv_target_%s_eps_%s.jpg"" % (j, class_names[target[eps_idx][i][j]], class_names[i], eps_str)\n                img_file = os.path.join(args.output, img_file)\n                img = pc_util.point_cloud_three_views(x_adv[eps_idx][i][j])\n                scipy.misc.imsave(img_file, img)\nelse:\n    res = adversarial_utils.untargeted_attack(args.checkpoint, args.output, x_pl, t_pl, model_loss_fn, data_x, data_t, args.num_objects, class_names, data_f = data_f, restrict = args.restrict, iter = args.iter, eps_list = args.eps, norm = args.norm, mode = args.mode, one_hot = False, clip_norm = args.clip_norm, min_norm = args.min_norm, postprocess_fn = defense_dict[args.defense], extra_feed_dict = {is_training: False})\n    if data_f is None:\n        x_original, target, x_adv, pred_adv = res\n    else:\n        x_original, target, x_adv, pred_adv, faces = res\n\n    for eps_idx in range(len(args.eps)):\n        idx = np.random.choice(len(x_original[eps_idx]), size = min(3, len(x_original[eps_idx])), replace = False)\n        for i in idx:\n            img_file = ""%d_%s_original.jpg"" % (i, class_names[target[eps_idx][i]])\n            img_file = os.path.join(args.output, img_file)\n            img = pc_util.point_cloud_three_views(x_original[eps_idx][i])\n            scipy.misc.imsave(img_file, img)\n\n            eps_str = str(args.eps[eps_idx]).replace(""."", ""_"")\n            img_file = ""%d_%s_adv_pred_%s_eps_%s.jpg"" % (i, class_names[target[eps_idx][i]], class_names[pred_adv[eps_idx][i]], eps_str)\n            img_file = os.path.join(args.output, img_file)\n            img = pc_util.point_cloud_three_views(x_adv[eps_idx][i])\n            scipy.misc.imsave(img_file, img)'"
src/adversarial_stats.py,22,"b'import numpy as np\nimport visualization_utils\nfrom collections import defaultdict\n\npaths = [\n    ""point_clouds/pointnet/saliency_untargeted_iter_l2/succeeded_point_clouds_eps_1_0.npz""\n]\n\nfiles = visualization_utils.read_npz_files(paths)\n\nfor i, file in enumerate(files):\n    print(""File %d"" % (i + 1))\n    if ""x_adv"" in file:\n        print(""%d objects total"" % file[""x_original""].shape[0])\n        print(""%d points per object"" % file[""x_original""].shape[1])\n\n        perturbed = ~np.isclose(file[""x_original""], file[""x_adv""])\n        perturbed = np.any(perturbed, axis = 2)\n        perturbed = np.sum(perturbed, axis = 1)\n        print(""%d points perturbed minimum"" % np.min(perturbed))\n        print(""%d points perturbed maximum"" % np.max(perturbed))\n        print(""%d points perturbed on average"" % np.mean(perturbed))\n\n        norm = np.linalg.norm(file[""x_adv""], axis = 2)\n        print(""Min L2 norm: %.3f"" % np.min(norm))\n        print(""Max L2 norm: %.3f"" % np.max(norm))\n        print(""Avg L2 norm: %.3f"" % np.mean(norm))\n\n        same_pos = []\n        for obj in file[""x_adv""]:\n            count = defaultdict(int)\n            res = 0\n            for point in obj:\n                count[point.tobytes()] += 1\n            for key in count:\n                if count[key] > 1:\n                    res += count[key] - 1\n            same_pos.append(res)\n        same_pos = np.array(same_pos)\n\n        print(""Min number of duplicate points: %.3f"" % np.min(same_pos))\n        print(""Max number of duplicate points: %.3f"" % np.max(same_pos))\n        print(""Avg number of duplicate points: %.3f"" % np.mean(same_pos))\n    elif ""saliency"" in file:\n        print(""%d objects total"" % file[""points""].shape[0])\n        print(""%d points per object"" % file[""points""].shape[1])\n\n        dist = np.abs(np.max(file[""saliency""], axis = 0) - np.min(file[""saliency""], axis = 0))\n        print(""Avg number of equal saliency gradients: %d"" % np.mean(np.sum(np.all(dist < 1e-4, axis = 2), axis = 1)))\n        \n        norm = np.linalg.norm(file[""saliency""], axis = 3)\n        dist = np.abs(np.max(norm, axis = 0) - np.min(norm, axis = 0))\n        print(""Avg number of equal saliency norms: %d"" % np.mean(np.sum(dist < 1e-4, axis = 1)))\n        print(""Min saliency norm: %.3f"" % np.min(norm))\n        print(""Max saliency norm: %.3f"" % np.max(norm))\n        print(""Avg saliency norm: %.3f"" % np.mean(norm))'"
src/adversarial_utils.py,101,"b'import numpy as np\nimport tensorflow as tf\nimport matplotlib\nmatplotlib.use(""Agg"")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport adversarial_attacks\nimport os\nimport errno\n\nnp.random.seed(0) # fixed seed for consistency\n\ndef confusion_heatmap(data, path, class_names = None, percentages = True, annotate = True):\n    data = np.array(data)\n    \n    if percentages:\n        total = np.sum(data, axis = 1, keepdims = True)\n        total[total == 0] = 1 # handle division by zero\n        data = data.astype(float) / total\n\n    heatmap(data, path, ""Labels"", ""Predicted Classes"", class_names = class_names, percentages = percentages, annotate = annotate)\n\ndef class_change_heatmap(data, path, class_names = None, percentages = True, annotate = True):\n    data = np.array(data)\n    \n    if percentages:\n        total = np.sum(data, axis = 1, keepdims = True)\n        total[total == 0] = 1 # handle division by zero\n        data = data.astype(float) / total\n\n    heatmap(data, path, ""Original Classes"", ""Classes After Adversarial Attack"", class_names = class_names, percentages = percentages, annotate = annotate)\n\ndef transfer_heatmap(data, path, class_names = None, percentages = True, annotate = True):\n    data = np.array(data)\n    \n    if percentages:\n        total = np.sum(data, axis = 1, keepdims = True)\n        total[total == 0] = 1 # handle division by zero\n        data = data.astype(float) / total\n\n    heatmap(data, path, ""Predictions of the Original Model"", ""Predictions of This Model"", class_names = class_names, percentages = percentages, annotate = annotate)\n\ndef targeted_success_rate_heatmap(data, path, total = None, class_names = None, annotate = True):\n    data = np.array(data)\n    percentages = total is not None\n\n    if percentages:\n        total = np.array(total)\n        total[total == 0] = 1 # handle division by zero\n        data = data.astype(float) / total\n    \n    heatmap(data, path, ""Original Classes"", ""Adversarial Attack Target Classes"", class_names = class_names, percentages = percentages, annotate = annotate)\n\ndef heatmap(data, path, x_label, y_label, class_names = None, percentages = True, annotate = True):\n    data = np.array(data)\n\n    if class_names is None:\n        class_names = list(range(len(data)))\n    \n    if percentages:\n        vmin = 0\n        vmax = 1\n        fmt = "".2g""\n    else:\n        vmin = None\n        vmax = None\n        fmt = ""d""\n    \n    fig_size = len(class_names) // 10 * 7 + 3\n    plt.figure(figsize = (fig_size, fig_size))\n    ax = sns.heatmap(data.T, annot = annotate, xticklabels = class_names, yticklabels = class_names, vmin = vmin, vmax = vmax, fmt = fmt, linewidths = 2)\n    ax.invert_yaxis()\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(y_label)\n\n    plt.savefig(path)\n    plt.close()\n\ndef untargeted_attack(model_path, out_dir, x_pl, t_pl, model_loss_fn, data_x, data_t, num_objects, class_names, iter, eps_list, norm = ""inf"", data_f = None, restrict = False, one_hot = True, mode = ""iterative"", momentum = 1.0, clip_min = None, clip_max = None, clip_norm = None, min_norm = 0.0, postprocess_fn = None, extra_feed_dict = None):\n    if postprocess_fn is None:\n        postprocess_fn = lambda x, y: x\n    if extra_feed_dict is None:\n        extra_feed_dict = {}\n    try:\n        os.makedirs(out_dir)\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n    \n    def_logits_op, def_loss_op = model_loss_fn(postprocess_fn(x_pl, model_loss_fn), t_pl)\n    def_probs_op = tf.nn.softmax(def_logits_op)\n\n    logits_op, loss_op = model_loss_fn(x_pl, t_pl)\n    probs_op = tf.nn.softmax(logits_op)\n\n    data_x = np.array(data_x)\n    data_t = np.array(data_t)\n    if data_f is not None:\n        data_f = np.array(data_f)\n    eps_list = np.array(eps_list)\n\n    shuffle_idx = np.random.permutation(len(data_x))\n    data_x = data_x[shuffle_idx]\n    data_t = data_t[shuffle_idx]\n    if data_f is not None:\n        data_f = data_f[shuffle_idx]\n\n    eps = tf.placeholder(tf.float32, shape = [])\n    if data_f is None:\n        faces = None\n    else:\n        faces = tf.placeholder(tf.float32, shape = [1, None, 3, 3])\n\n    if mode == ""iterative"":\n        x_adv_op = postprocess_fn(adversarial_attacks.iter_grad_op(x_pl, model_loss_fn, faces = faces, one_hot = one_hot, iter = iter, eps = eps, ord = norm, restrict = restrict, clip_min = clip_min, clip_max = clip_max, clip_norm = clip_norm, min_norm = min_norm), model_loss_fn)\n    elif mode == ""momentum"":\n        x_adv_op = postprocess_fn(adversarial_attacks.momentum_grad_op(x_pl, model_loss_fn, faces = faces, one_hot = one_hot, iter = iter, eps = eps, ord = norm, momentum = momentum, restrict = restrict, clip_min = clip_min, clip_max = clip_max, clip_norm = clip_norm, min_norm = min_norm), model_loss_fn)\n    elif mode == ""saliency"":\n        x_adv_op = postprocess_fn(adversarial_attacks.jacobian_saliency_map_points_op(x_pl, model_loss_fn, faces = faces, one_hot = one_hot, iter = iter, eps = eps, restrict = restrict, clip_min = clip_min, clip_max = clip_max), model_loss_fn)\n    elif mode == ""sort"":\n        x_adv_op = postprocess_fn(adversarial_attacks.sort_op(x_pl, model_loss_fn, faces = faces, one_hot = one_hot, iter = iter), model_loss_fn)\n    elif mode == ""view"":\n        x_adv_op = postprocess_fn(adversarial_attacks.view_op(x_pl, model_loss_fn, one_hot = one_hot, iter = iter, eps = eps), model_loss_fn)\n    else:\n        raise ValueError(""Only iterative, momentum, saliency, sort, and view modes are supported!"")\n    \n    saver = tf.train.Saver()\n\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    with tf.Session(config = config) as sess:\n        saver.restore(sess, model_path)\n        print(""Restored model!"")\n\n        succeeded_x_original = []\n        succeeded_target = []\n        succeeded_x_adv = []\n        succeeded_pred_adv = []\n        if data_f is not None:\n            succeeded_faces = []\n\n        total = len(data_x)\n\n        logits = []\n        losses = []\n        preds = []\n        probs = []\n        for i in range(total):\n            feed_dict = {\n                x_pl: [data_x[i]],\n                t_pl: [data_t[i]]\n            }\n            feed_dict.update(extra_feed_dict)\n            curr_logit, curr_loss, curr_prob = sess.run([def_logits_op, def_loss_op, def_probs_op], feed_dict = feed_dict)\n            curr_pred = np.argmax(curr_logit, axis = 1)\n            logits.append(curr_logit)\n            losses.append(curr_loss)\n            preds.append(curr_pred)\n            probs.append(curr_prob)\n        \n        logits = np.concatenate(logits)\n        losses = np.array(losses)\n        preds = np.concatenate(preds)\n        probs = np.concatenate(probs)\n\n        if one_hot:\n            sparse_t = np.argmax(data_t, axis = 1)\n        else:\n            sparse_t = data_t\n        \n        correct_idx = preds == sparse_t\n        logits = logits[correct_idx][:num_objects]\n        preds = preds[correct_idx][:num_objects]\n        losses = losses[correct_idx][:num_objects]\n        probs = probs[correct_idx][:num_objects]\n        data_x = data_x[correct_idx][:num_objects]\n        data_t = data_t[correct_idx][:num_objects]\n        if data_f is not None:\n            data_f = data_f[correct_idx][:num_objects]\n\n        correct = len(data_x)\n\n        class_totals = np.zeros(shape = len(class_names), dtype = int)\n        np.add.at(class_totals, sparse_t, 1)\n        class_correct = np.zeros(shape = len(class_names), dtype = int)\n        np.add.at(class_correct, preds, 1)\n\n        print(""Evaluated model!"")\n        print(""Generating adversarial inputs..."")\n\n        for curr_eps in eps_list:\n            print(""Current eps: %s"" % curr_eps)\n\n            x_adv = []\n            for i in range(correct):\n                feed_dict = {\n                    x_pl: [data_x[i]],\n                    eps: curr_eps\n                }\n                if data_f is not None:\n                    feed_dict[faces] = [data_f[i]]\n                feed_dict.update(extra_feed_dict)\n                curr_x_adv = sess.run(x_adv_op, feed_dict = feed_dict)\n                x_adv.append(curr_x_adv)\n            \n            x_adv = np.concatenate(x_adv)\n\n            logits_adv = []\n            losses_adv = []\n            preds_adv = []\n            probs_adv = []\n            for i in range(correct):\n                feed_dict = {\n                    x_pl: [x_adv[i]],\n                    t_pl: [data_t[i]]\n                }\n                feed_dict.update(extra_feed_dict)\n                curr_logit_adv, curr_loss_adv, curr_prob_adv = sess.run([logits_op, loss_op, probs_op], feed_dict = feed_dict)\n                curr_pred_adv = np.argmax(curr_logit_adv, axis = 1)\n                logits_adv.append(curr_logit_adv)\n                losses_adv.append(curr_loss_adv)\n                preds_adv.append(curr_pred_adv)\n                probs_adv.append(curr_prob_adv)\n            \n            logits_adv = np.concatenate(logits_adv)\n            losses_adv = np.array(losses_adv)\n            preds_adv = np.concatenate(preds_adv)\n            probs_adv = np.concatenate(probs_adv)\n\n            succeeded_idx = preds_adv != preds\n            succeeded = np.sum(succeeded_idx)\n            succeeded_x_original.append(data_x[succeeded_idx])\n            succeeded_target.append(data_t[succeeded_idx])\n            succeeded_x_adv.append(x_adv[succeeded_idx])\n            succeeded_pred_adv.append(preds_adv[succeeded_idx])\n            if data_f is not None:\n                succeeded_faces.append(data_f[succeeded_idx])\n            \n            class_changes = np.zeros(shape = (len(class_names), len(class_names)), dtype = int)\n            np.add.at(class_changes, [preds, preds_adv], 1)\n\n            eps_str = str(curr_eps).replace(""."", ""_"")\n            class_change_heatmap(class_changes, os.path.join(out_dir, ""class_changes_eps_%s.eps"" % eps_str), class_names = class_names, percentages = False)\n            class_change_heatmap(class_changes, os.path.join(out_dir, ""percent_class_changes_eps_%s.eps"" % eps_str), class_names = class_names, annotate = False)\n\n            class_succeeded = np.zeros(shape = len(class_names), dtype = int)\n            np.add.at(class_succeeded, preds[succeeded_idx], 1)\n\n            with open(os.path.join(out_dir, ""class_stats_eps_%s.csv"" % eps_str), ""w"") as f:\n                f.write(""Average confidence for correct predictions: %.3f\\n"" % np.mean(probs[range(correct), preds]))\n                f.write(""Average confidence for successful adversarial predictions: %.3f\\n"" % np.mean(probs_adv[succeeded_idx][range(succeeded), preds_adv[succeeded_idx]]))\n                f.write(""Average confidence for unsuccessful adversarial predictions: %.3f\\n"" % np.mean(probs_adv[~succeeded_idx][range(correct - succeeded), preds_adv[~succeeded_idx]]))\n                f.write(""Index, Original Class, Total, Correct, Attacks Succeeded, Succeeded / Correct\\n"")\n\n                for i in range(len(class_names)):\n                    percent = 0 if class_correct[i] == 0 else float(class_succeeded[i]) / class_correct[i]\n                    f.write(""%d, %s, %d, %d, %d, %.3f\\n"" % (i, class_names[i], class_totals[i], class_correct[i], class_succeeded[i], percent))\n                \n                percent = 0 if correct == 0 else float(succeeded) / correct\n                f.write(""Total, Total, %d, %d, %d, %.3f\\n"" % (total, correct, succeeded, percent))\n\n            if data_f is None:\n                np.savez_compressed(os.path.join(out_dir, ""succeeded_point_clouds_eps_%s.npz"" % eps_str), x_original = succeeded_x_original[-1], labels = succeeded_target[-1], x_adv = succeeded_x_adv[-1], pred_adv = succeeded_pred_adv[-1])\n            else:\n                np.savez_compressed(os.path.join(out_dir, ""succeeded_point_clouds_eps_%s.npz"" % eps_str), x_original = succeeded_x_original[-1], labels = succeeded_target[-1], x_adv = succeeded_x_adv[-1], pred_adv = succeeded_pred_adv[-1], faces = succeeded_faces[-1])\n\n    print(""Done!"")\n\n    if data_f is None:\n        return succeeded_x_original, succeeded_target, succeeded_x_adv, succeeded_pred_adv\n    else:\n        return succeeded_x_original, succeeded_target, succeeded_x_adv, succeeded_pred_adv, succeeded_faces\n\ndef targeted_attack(model_path, out_dir, x_pl, t_pl, model_loss_fn, data_x, data_t, num_objects, class_names, iter, eps_list, norm = ""inf"", data_f = None, restrict = False, one_hot = True, mode = ""iterative"", momentum = 1.0, clip_min = None, clip_max = None, clip_norm = None, min_norm = 0.0, postprocess_fn = None, extra_feed_dict = None):\n    if postprocess_fn is None:\n        postprocess_fn = lambda x, y: x\n    if extra_feed_dict is None:\n        extra_feed_dict = {}\n    try:\n        os.makedirs(out_dir)\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n    \n    def_logits_op, def_loss_op = model_loss_fn(postprocess_fn(x_pl, model_loss_fn), t_pl)\n    def_probs_op = tf.nn.softmax(def_logits_op)\n\n    logits_op, loss_op = model_loss_fn(x_pl, t_pl)\n    probs_op = tf.nn.softmax(logits_op)\n\n    data_x = np.array(data_x)\n    data_t = np.array(data_t)\n    if data_f is not None:\n        data_f = np.array(data_f)\n    eps_list = np.array(eps_list)\n\n    shuffle_idx = np.random.permutation(len(data_x))\n    data_x = data_x[shuffle_idx]\n    data_t = data_t[shuffle_idx]\n    if data_f is not None:\n        data_f = data_f[shuffle_idx]\n\n    eps = tf.placeholder(tf.float32, shape = [])\n    if one_hot:\n        target = tf.placeholder(tf.float32, shape = [1, len(class_names)])\n    else:\n        target = tf.placeholder(tf.int32, [1])\n    if data_f is None:\n        faces = None\n    else:\n        faces = tf.placeholder(tf.float32, shape = [1, None, 3, 3])\n    \n    if mode == ""iterative"":\n        x_adv_op = postprocess_fn(adversarial_attacks.iter_grad_op(x_pl, model_loss_fn, t_pl = target, faces = faces, one_hot = one_hot, iter = iter, eps = eps, ord = norm, restrict = restrict, clip_min = clip_min, clip_max = clip_max, clip_norm = clip_norm, min_norm = min_norm), model_loss_fn)\n    elif mode == ""momentum"":\n        x_adv_op = postprocess_fn(adversarial_attacks.momentum_grad_op(x_pl, model_loss_fn, t_pl = target, faces = faces, one_hot = one_hot, iter = iter, eps = eps, ord = norm, momentum = momentum, restrict = restrict, clip_min = clip_min, clip_max = clip_max, clip_norm = clip_norm, min_norm = min_norm), model_loss_fn)\n    elif mode == ""saliency"":\n        x_adv_op = postprocess_fn(adversarial_attacks.jacobian_saliency_map_points_op(x_pl, model_loss_fn, t_pl = target, faces = faces, one_hot = one_hot, iter = iter, eps = eps, restrict = restrict, clip_min = clip_min, clip_max = clip_max), model_loss_fn)\n    else:\n        raise ValueError(""Only iterative, momentum, and saliency modes are supported!"")\n    \n    saver = tf.train.Saver()\n\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    with tf.Session(config = config) as sess:\n        saver.restore(sess, model_path)\n        print(""Model restored!"")\n        \n        succeeded_x_original = []\n        succeeded_target = []\n        succeeded_x_adv = []\n        if data_f is not None:\n            succeeded_faces = []\n\n        total = len(data_x)\n\n        logits = []\n        losses = []\n        preds = []\n        probs = []\n        for i in range(total):\n            feed_dict = {\n                x_pl: [data_x[i]],\n                t_pl: [data_t[i]]\n            }\n            feed_dict.update(extra_feed_dict)\n            curr_logit, curr_loss, curr_prob = sess.run([def_logits_op, def_loss_op, def_probs_op], feed_dict = feed_dict)\n            curr_pred = np.argmax(curr_logit, axis = 1)\n            logits.append(curr_logit)\n            losses.append(curr_loss)\n            preds.append(curr_pred)\n            probs.append(curr_prob)\n        \n        logits = np.concatenate(logits)\n        losses = np.array(losses)\n        preds = np.concatenate(preds)\n        probs = np.concatenate(probs)\n\n        if one_hot:\n            sparse_t = np.argmax(data_t, axis = 1)\n        else:\n            sparse_t = data_t\n        \n        correct_idx = preds == sparse_t\n        logits = logits[correct_idx][:num_objects]\n        preds = preds[correct_idx][:num_objects]\n        losses = losses[correct_idx][:num_objects]\n        probs = probs[correct_idx][:num_objects]\n        data_x = data_x[correct_idx][:num_objects]\n        data_t = data_t[correct_idx][:num_objects]\n        if data_f is not None:\n            data_f = data_f[correct_idx][:num_objects]\n\n        correct = len(data_x)\n\n        class_totals = np.zeros(shape = len(class_names), dtype = int)\n        np.add.at(class_totals, sparse_t, 1)\n        class_correct = np.zeros(shape = len(class_names), dtype = int)\n        np.add.at(class_correct, preds, 1)\n        heatmap_totals = np.tile(class_correct, (len(class_names), 1)).T\n\n        print(""Model evaluated!"")\n        print(""Generating adversarial inputs..."")\n\n        for curr_eps in eps_list:\n            print(""Current eps: %s"" % curr_eps)\n\n            curr_succeeded_x_original = []\n            curr_succeeded_target = []\n            curr_succeeded_x_adv = []\n            if data_f is not None:\n                curr_succeeded_faces = []\n            success_counts = np.zeros(shape = (len(class_names), len(class_names)), dtype = int)\n            total_succeeded = 0\n            total_successful_confidence = 0\n            total_unsuccessful_confidence = 0\n            eps_str = str(curr_eps).replace(""."", ""_"")\n\n            for curr_target in range(len(class_names)):\n                print(""Current target: %s"" % class_names[curr_target])\n\n                if one_hot:\n                    adv_target = np.zeros(shape = len(class_names))\n                    adv_target[curr_target] = 1\n                else:\n                    adv_target = curr_target\n                \n                x_adv = []\n                for i in range(correct):\n                    feed_dict = {\n                        x_pl: [data_x[i]],\n                        eps: curr_eps,\n                        target: [adv_target]\n                    }\n                    if data_f is not None:\n                        feed_dict[faces] = [data_f[i]]\n                    feed_dict.update(extra_feed_dict)\n                    curr_x_adv = sess.run(x_adv_op, feed_dict = feed_dict)\n                    x_adv.append(curr_x_adv)\n                \n                x_adv = np.concatenate(x_adv)\n\n                logits_adv = []\n                losses_adv = []\n                preds_adv = []\n                probs_adv = []\n                for i in range(correct):\n                    feed_dict = {\n                        x_pl: [x_adv[i]],\n                        t_pl: [data_t[i]]\n                    }\n                    feed_dict.update(extra_feed_dict)\n                    curr_logit_adv, curr_loss_adv, curr_prob_adv = sess.run([logits_op, loss_op, probs_op], feed_dict = feed_dict)\n                    curr_pred_adv = np.argmax(curr_logit_adv, axis = 1)\n                    logits_adv.append(curr_logit_adv)\n                    losses_adv.append(curr_loss_adv)\n                    preds_adv.append(curr_pred_adv)\n                    probs_adv.append(curr_prob_adv)\n                \n                logits_adv = np.concatenate(logits_adv)\n                losses_adv = np.array(losses_adv)\n                preds_adv = np.concatenate(preds_adv)\n                probs_adv = np.concatenate(probs_adv)\n\n                succeeded_idx = (preds != curr_target) & (preds_adv == curr_target)\n                succeeded = np.sum(succeeded_idx)\n                total_succeeded += succeeded\n                curr_succeeded_x_original.append(data_x[succeeded_idx])\n                curr_succeeded_target.append(data_t[succeeded_idx])\n                curr_succeeded_x_adv.append(x_adv[succeeded_idx])\n                if data_f is not None:\n                    curr_succeeded_faces.append(data_f[succeeded_idx])\n                \n                total_successful_confidence += np.mean(probs_adv[succeeded_idx][range(succeeded), preds_adv[succeeded_idx]])\n                total_unsuccessful_confidence += np.mean(probs_adv[~succeeded_idx][range(correct - succeeded), preds_adv[~succeeded_idx]])\n\n                np.add.at(success_counts, [preds[succeeded_idx], preds_adv[succeeded_idx]], 1)\n\n                if data_f is None:\n                    np.savez_compressed(os.path.join(out_dir, ""succeeded_point_clouds_target_%s_eps_%s.npz"" % (class_names[curr_target], eps_str)), x_original = curr_succeeded_x_original[-1], labels = curr_succeeded_target[-1], x_adv = curr_succeeded_x_adv[-1])\n                else:\n                    np.savez_compressed(os.path.join(out_dir, ""succeeded_point_clouds_target_%s_eps_%s.npz"" % (class_names[curr_target], eps_str)), x_original = curr_succeeded_x_original[-1], labels = curr_succeeded_target[-1], x_adv = curr_succeeded_x_adv[-1], faces = curr_succeeded_faces[-1])\n\n            targeted_success_rate_heatmap(success_counts, os.path.join(out_dir, ""success_count_eps_%s.eps"" % eps_str), class_names = class_names)\n            targeted_success_rate_heatmap(success_counts, os.path.join(out_dir, ""success_rate_eps_%s.eps"" % eps_str), total = heatmap_totals, class_names = class_names)\n\n            total_succeeded /= float(len(class_names))\n            total_successful_confidence /= float(len(class_names))\n            total_unsuccessful_confidence /= float(len(class_names))\n\n            with open(os.path.join(out_dir, ""targeted_stats_eps_%s.csv"" % eps_str), ""w"") as f:\n                f.write(""Average confidence for correct predictions: %.3f\\n"" % np.mean(probs[range(correct), preds]))\n                f.write(""Average confidence for successful adversarial predictions: %.3f\\n"" % total_successful_confidence)\n                f.write(""Average confidence for unsuccessful adversarial predictions: %.3f\\n"" % total_unsuccessful_confidence)\n                \n                percent = 0 if correct == 0 else float(total_succeeded) / correct\n                f.write(""Total %d, Correct %d, Average Attacks Succeeded For All Target Classes %d, Average Succeeded / Correct %.3f\\n"" % (total, correct, total_succeeded, percent))\n            \n            succeeded_x_original.append(curr_succeeded_x_original)\n            succeeded_target.append(curr_succeeded_target)\n            succeeded_x_adv.append(curr_succeeded_x_adv)\n            if data_f is not None:\n                succeeded_faces.append(curr_succeeded_faces)\n\n    print(""Done!"")\n\n    if data_f is None:\n        return succeeded_x_original, succeeded_target, succeeded_x_adv\n    else:\n        return succeeded_x_original, succeeded_target, succeeded_x_adv, succeeded_faces\n\ndef evaluate(model_path, out_dir, x_pl, t_pl, model_loss_fn, data_x, data_t, class_names, data_p = None, one_hot = True, extra_feed_dict = None):\n    if extra_feed_dict is None:\n        extra_feed_dict = {}\n    try:\n        os.makedirs(out_dir)\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n    \n    logits_op, loss_op = model_loss_fn(x_pl, t_pl)\n    probs_op = tf.nn.softmax(logits_op)\n\n    data_x = np.array(data_x)\n    data_t = np.array(data_t)\n    if data_p is not None:\n        data_p = np.array(data_p)\n\n    saver = tf.train.Saver()\n\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    with tf.Session(config = config) as sess:\n        saver.restore(sess, model_path)\n        print(""Model restored!"")\n\n        logits = []\n        losses = []\n        preds = []\n        probs = []\n        for i in range(len(data_x)):\n            feed_dict = {\n                x_pl: [data_x[i]],\n                t_pl: [data_t[i]]\n            }\n            feed_dict.update(extra_feed_dict)\n            curr_logit, curr_loss, curr_prob = sess.run([logits_op, loss_op, probs_op], feed_dict = feed_dict)\n            curr_pred = np.argmax(curr_logit, axis = 1)\n            logits.append(curr_logit)\n            losses.append(curr_loss)\n            preds.append(curr_pred)\n            probs.append(curr_prob)\n        \n        logits = np.concatenate(logits)\n        losses = np.array(losses)\n        preds = np.concatenate(preds)\n        probs = np.concatenate(probs)\n\n        if one_hot:\n            sparse_t = np.argmax(data_t, axis = 1)\n            if data_p is not None:\n                sparse_p = np.argmax(data_p, axis = 1)\n        else:\n            sparse_t = data_t\n            sparse_p = data_p\n        \n        idx = preds == sparse_t\n        correct = np.sum(idx)\n        if data_p is not None:\n            idx = preds == sparse_p\n            match = np.sum(idx)\n            avg_correct_confidence = np.mean(probs[idx][range(match), preds[idx]])\n            avg_wrong_confidence = np.mean(probs[~idx][range(len(data_x) - match), preds[~idx]])\n        else:\n            avg_correct_confidence = np.mean(probs[idx][range(correct), preds[idx]])\n            avg_wrong_confidence = np.mean(probs[~idx][range(len(data_x) - correct), preds[~idx]])\n\n        target_vs_preds = np.zeros(shape = (len(class_names), len(class_names)), dtype = int)\n        np.add.at(target_vs_preds, [sparse_t, preds], 1)\n        if data_p is not None:\n            preds_vs_preds = np.zeros(shape = (len(class_names), len(class_names)), dtype = int)\n            np.add.at(preds_vs_preds, [sparse_p, preds], 1)\n\n        if data_p is None:\n            confusion_heatmap(target_vs_preds, os.path.join(out_dir, ""labels_vs_preds.eps""), class_names = class_names, percentages = False)\n            confusion_heatmap(target_vs_preds, os.path.join(out_dir, ""percent_labels_vs_preds.eps""), class_names = class_names, annotate = False)\n        else:\n            class_change_heatmap(target_vs_preds, os.path.join(out_dir, ""labels_vs_preds.eps""), class_names = class_names, percentages = False)\n            class_change_heatmap(target_vs_preds, os.path.join(out_dir, ""percent_labels_vs_preds.eps""), class_names = class_names, annotate = False)\n            transfer_heatmap(preds_vs_preds, os.path.join(out_dir, ""preds_vs_preds.eps""), class_names = class_names, percentages = False)\n            transfer_heatmap(preds_vs_preds, os.path.join(out_dir, ""percent_preds_vs_preds.eps""), class_names = class_names, annotate = False)\n\n        print(""Total: %d"" % len(data_x))\n        if data_p is None:\n            print(""Correct: %d"" % correct)\n            print(""Correct / Total: %.3f"" % (float(correct) / len(data_x)))\n        else:\n            print(""Attacks Succeeded: %d"" % (len(data_x) - correct))\n            print(""Succeeded / Total: %.3f"" % (float(len(data_x) - correct) / len(data_x)))\n            print(""Transfers With Matching Predictions: %d"" % match)\n            print(""Matching / Succeeded: %.3f"" % (float(match) / (len(data_x) - correct)))\n        print(""Average confidence of correct or matching predictions: %.3f\\n"" % avg_correct_confidence)\n        print(""Average confidence of wrong predictions: %.3f\\n"" % avg_wrong_confidence)\n\n    print(""Done!"")\n\ndef get_feature_vectors(model_path, x_pl, model_loss_fn, data_x_original, data_x_adv, class_names, extra_feed_dict = None):\n    if extra_feed_dict is None:\n        extra_feed_dict = {}\n    \n    model_loss_fn(x_pl, None)\n    features_op = tf.get_default_graph().get_tensor_by_name(""feature_vector:0"")\n    idx = tf.placeholder(tf.int32, [1])\n    mask = tf.one_hot(idx, tf.shape(features_op)[1])\n    mask = tf.stop_gradient(mask)\n    grad_op = tf.gradients(mask * features_op, x_pl)[0]\n\n    data_x_original = np.array(data_x_original)\n    data_x_adv = np.array(data_x_adv)\n\n    saver = tf.train.Saver()\n\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config = config)\n    saver.restore(sess, model_path)\n    print(""Model restored!"")\n\n    features_original = []\n    features_adv = []\n    for i in range(len(data_x_original)):\n        feed_dict = {\n            x_pl: [data_x_original[i]]\n        }\n        feed_dict.update(extra_feed_dict)\n        features = sess.run(features_op, feed_dict = feed_dict)\n        features_original.append(features)\n\n        feed_dict = {\n            x_pl: [data_x_adv[i]]\n        }\n        feed_dict.update(extra_feed_dict)\n        features = sess.run(features_op, feed_dict = feed_dict)\n        features_adv.append(features)\n    \n    features_original = np.concatenate(features_original)\n    features_adv = np.concatenate(features_adv)\n\n    def feature_grad_fn(diff, k, adv):\n        grads = [[] for _ in range(k)]\n        max_idx = np.argsort(np.abs(diff), axis = 1)[:, -k:]\n        for i in range(len(data_x_original)):\n            feed_dict = {}\n            feed_dict[x_pl] = [data_x_adv[i]] if adv else [data_x_original[i]]\n            feed_dict.update(extra_feed_dict)\n            for j in range(k):\n                feed_dict[idx] = [max_idx[i][j]]\n                res_grads = sess.run(grad_op, feed_dict = feed_dict)\n                for grad in res_grads:\n                    grads[j].append(grad)\n        \n        return np.array(grads), max_idx.T\n\n    print(""Done!"")\n\n    return features_original, features_adv, feature_grad_fn, lambda: sess.close()\n\ndef saliency(model_path, x_pl, model_loss_fn, data_x, class_names, t_pl = None, data_t = None, saliency_class = None, extra_feed_dict = None):\n    if extra_feed_dict is None:\n        extra_feed_dict = {}\n    \n    if saliency_class is None: # loss wrt input\n        _, loss_op = model_loss_fn(x_pl, t_pl)\n        grad_op = tf.gradients(loss_op, x_pl)[0]\n    else: # saliency_class wrt input\n        logits_op, _ = model_loss_fn(x_pl, None)\n        mask = tf.one_hot(saliency_class, tf.shape(logits_op)[1])\n        mask = tf.stop_gradient(mask)\n        grad_op = tf.gradients(mask * logits_op, x_pl)[0]\n\n    data_x = np.array(data_x)\n    if data_t is not None:\n        data_t = np.array(data_t)\n\n    saver = tf.train.Saver()\n\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config = config)\n    saver.restore(sess, model_path)\n    print(""Model restored!"")\n\n    saliency = []\n    for i in range(len(data_x)):\n        feed_dict = {\n            x_pl: [data_x[i]]\n        }\n        if data_t is not None:\n            feed_dict[t_pl] = [data_t[i]]\n        feed_dict.update(extra_feed_dict)\n        grad = sess.run(grad_op, feed_dict = feed_dict)\n        saliency.append(grad)\n    \n    saliency = np.concatenate(saliency)\n\n    print(""Done!"")\n\n    return saliency'"
src/evaluate_pointnet.py,5,"b'import numpy as np\nimport tensorflow as tf\nimport adversarial_utils\nimport os\nimport sys\nimport argparse\nimport importlib\nworking_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.join(working_dir, ""models""))\nsys.path.append(os.path.join(working_dir, ""utils""))\nimport provider\n\nparser = argparse.ArgumentParser(description = ""Evaluates PointNet on classification."", formatter_class = argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(""--checkpoint"", default = ""log/model.ckpt"", help = ""Path to the model\'s checkpoint file."")\nparser.add_argument(""--output"", default = ""evaluate"", help = ""Output directory."")\nparser.add_argument(""--data"", default = ""data/modelnet40_ply_hdf5_2048/test_files.txt"", help = ""Input data. Either a Numpy file or a text file containing a list of HDF5 files."")\nparser.add_argument(""--class-names"", default = ""data/modelnet40_ply_hdf5_2048/shape_names.txt"", help = ""Text file containing a list of class names."")\nparser.add_argument(""--num-points"", type = int, default = 1024, help = ""Number of points to use."")\nparser.add_argument(""--sparse-target"", type = int, default = None, help = ""Sparse adversarial attack target."")\nparser.add_argument(""--num-objects"", type = int, default = 1000000000, help = ""Use the first few objects. Specify a very large number to use all objects."")\nargs = parser.parse_args()\nprint(args)\n\nmodel = importlib.import_module(""pointnet_cls"")\nclass_names = [line.rstrip() for line in open(args.class_names)]\n\nnumpy_file = args.data.endswith("".npz"")\n\ndata_p = None\n\nif numpy_file:\n    with np.load(args.data) as file:\n        if ""x_adv"" in file:\n            data_x = file[""x_adv""]\n            data_t = file[""labels""]\n            if ""pred_adv"" in file:\n                data_p = file[""pred_adv""]\n            elif args.sparse_target is not None:\n                data_p = np.repeat(args.sparse_target, repeats = len(data_x))\n        else:\n            data_x = file[""points""][:, :args.num_points, :]\n            data_t = file[""labels""]\nelse:\n    test_files = provider.getDataFiles(args.data)\n\n    data_x = []\n    data_t = []\n    for file in test_files:\n        curr_x, curr_t = provider.loadDataFile(file)\n        data_x.append(curr_x[:, :args.num_points, :])\n        data_t.append(np.squeeze(curr_t))\n\n    data_x = np.concatenate(data_x)\n    data_t = np.concatenate(data_t)\n\ndata_x = data_x[:args.num_objects]\ndata_t = data_t[:args.num_objects]\nif data_p is not None:\n    data_p = data_p[:args.num_objects]\n\nx_pl, t_pl = model.placeholder_inputs(1, args.num_points)\n\nis_training = tf.placeholder(tf.bool, shape = [])\n\ndef model_loss_fn(x, t):\n    with tf.variable_scope(tf.get_variable_scope(), reuse = tf.AUTO_REUSE):\n        y, end_points = model.get_model(x, is_training, num_classes = len(class_names))\n    if t is None:\n        loss = None\n    else:\n        loss = model.get_loss(y, t, end_points)\n    return y, loss\n\nadversarial_utils.evaluate(args.checkpoint, args.output, x_pl, t_pl, model_loss_fn, data_x, data_t, class_names, data_p = data_p, one_hot = False, extra_feed_dict = {is_training: False})'"
src/evaluate_pointnet2.py,5,"b'import numpy as np\nimport tensorflow as tf\nimport adversarial_utils\nimport os\nimport sys\nimport argparse\nimport importlib\nworking_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.join(working_dir, ""models""))\nsys.path.append(os.path.join(working_dir, ""utils""))\nimport provider\n\nparser = argparse.ArgumentParser(description = ""Evaluates PointNet++ on classification."", formatter_class = argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(""--checkpoint"", default = ""log/model.ckpt"", help = ""Path to the model\'s checkpoint file."")\nparser.add_argument(""--output"", default = ""evaluate"", help = ""Output directory."")\nparser.add_argument(""--data"", default = ""data/modelnet40_ply_hdf5_2048/test_files.txt"", help = ""Input data. Either a Numpy file or a text file containing a list of HDF5 files."")\nparser.add_argument(""--class-names"", default = ""data/modelnet40_ply_hdf5_2048/shape_names.txt"", help = ""Text file containing a list of class names."")\nparser.add_argument(""--num-points"", type = int, default = 1024, help = ""Number of points to use."")\nparser.add_argument(""--sparse-target"", type = int, default = None, help = ""Sparse adversarial attack target."")\nparser.add_argument(""--num-objects"", type = int, default = 1000000000, help = ""Use the first few objects. Specify a very large number to use all objects."")\nargs = parser.parse_args()\nprint(args)\n\nmodel = importlib.import_module(""pointnet2_cls_ssg"")\nclass_names = [line.rstrip() for line in open(args.class_names)]\n\nnumpy_file = args.data.endswith("".npz"")\n\ndata_p = None\n\nif numpy_file:\n    with np.load(args.data) as file:\n        if ""x_adv"" in file:\n            data_x = file[""x_adv""]\n            data_t = file[""labels""]\n            if ""pred_adv"" in file:\n                data_p = file[""pred_adv""]\n            elif args.sparse_target is not None:\n                data_p = np.repeat(args.sparse_target, repeats = len(data_x))\n        else:\n            data_x = file[""points""][:, :args.num_points, :]\n            data_t = file[""labels""]\nelse:\n    test_files = provider.getDataFiles(args.data)\n\n    data_x = []\n    data_t = []\n    for file in test_files:\n        curr_x, curr_t = provider.loadDataFile(file)\n        data_x.append(curr_x[:, :args.num_points, :])\n        data_t.append(np.squeeze(curr_t))\n\n    data_x = np.concatenate(data_x)\n    data_t = np.concatenate(data_t)\n\ndata_x = data_x[:args.num_objects]\ndata_t = data_t[:args.num_objects]\nif data_p is not None:\n    data_p = data_p[:args.num_objects]\n\nx_pl, t_pl = model.placeholder_inputs(1, args.num_points)\n\nis_training = tf.placeholder(tf.bool, shape = [])\n\ndef model_loss_fn(x, t):\n    with tf.variable_scope(tf.get_variable_scope(), reuse = tf.AUTO_REUSE):\n        y, end_points = model.get_model(x, is_training, num_classes = len(class_names))\n    if t is None:\n        loss = None\n    else:\n        loss = model.get_loss(y, t, end_points)\n    return y, loss\n\nadversarial_utils.evaluate(args.checkpoint, args.output, x_pl, t_pl, model_loss_fn, data_x, data_t, class_names, data_p = data_p, one_hot = False, extra_feed_dict = {is_training: False})'"
src/feature_vectors_pointnet.py,55,"b'import numpy as np\nimport tensorflow as tf\nimport adversarial_utils\nimport os\nimport sys\nimport errno\nimport argparse\nimport importlib\nworking_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.join(working_dir, ""models""))\nsys.path.append(os.path.join(working_dir, ""utils""))\nfrom collections import defaultdict\n\nparser = argparse.ArgumentParser(description = ""Gets the feature vector for PointNet."", formatter_class = argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(""--checkpoint"", default = ""log/model.ckpt"", help = ""Path to the model\'s checkpoint file."")\nparser.add_argument(""--data"", help = ""Input data, a Numpy file."")\nparser.add_argument(""--output"", default = ""feature_vectors"", help = ""Output path."")\nparser.add_argument(""--class-names"", default = ""data/modelnet40_ply_hdf5_2048/shape_names.txt"", help = ""Text file containing a list of class names."")\nparser.add_argument(""--num-objects"", type = int, default = 1000000000, help = ""Use the first few objects. Specify a very large number to use all objects."")\nargs = parser.parse_args()\nprint(args)\n\nmodel = importlib.import_module(""pointnet_cls"")\nclass_names = [line.rstrip() for line in open(args.class_names)]\n\nwith np.load(args.data) as file:\n    data_x_original = file[""x_original""][:args.num_objects]\n    data_x_adv = file[""x_adv""][:args.num_objects]\n    labels = file[""labels""][:args.num_objects]\n    pred_adv = file[""pred_adv""][:args.num_objects]\n\nx_pl, _ = model.placeholder_inputs(1, data_x_original.shape[1])\n\nis_training = tf.placeholder(tf.bool, shape = [])\n\ndef model_loss_fn(x, t):\n    with tf.variable_scope(tf.get_variable_scope(), reuse = tf.AUTO_REUSE):\n        y, end_points = model.get_model(x, is_training, num_classes = len(class_names))\n    if t is None:\n        loss = None\n    else:\n        loss = model.get_loss(y, t, end_points)\n    return y, loss\n\nfeatures_original, features_adv, feature_grad_fn, sess_close = adversarial_utils.get_feature_vectors(args.checkpoint, x_pl, model_loss_fn, data_x_original, data_x_adv, class_names, extra_feed_dict = {is_training: False})\n\nprint(features_original.shape)\nprint(""Average norm of perturbation: %.3f"" % np.mean(np.sqrt(np.sum((data_x_adv - data_x_original) ** 2, axis = (1, 2)))))\n\navg_ratio = 0.0\nratio_count = 0\nfor i in range(len(labels)):\n    diff_norm = np.linalg.norm(features_adv[i] - features_original[i])\n    avg_dist = 0.0\n    dist_count = 0\n    for j in range(len(labels)):\n        if labels[j] == pred_adv[i]:\n            dist = np.linalg.norm(features_original[i] - features_original[j])\n            avg_dist += dist\n            dist_count += 1\n    if dist_count == 0:\n        continue\n    avg_dist /= float(dist_count)\n    ratio = diff_norm / avg_dist\n    avg_ratio += ratio\n    ratio_count += 1\n\nprint(""Average ratio of difference norms to average class differences: %.3f"" % (avg_ratio / float(ratio_count)))\n\ndef print_per_class(per_class):\n    for i, val in enumerate(per_class):\n        print(""%d, %s: %.3f"" % (i, class_names[i], val))\n\ncounts = np.zeros(len(class_names))\nnp.add.at(counts, labels, 1)\nzero = counts == 0.0\ncounts[zero] = 1.0\n\ndiff = features_adv - features_original\ndiff_norm = np.linalg.norm(diff, axis = 1)\n\nprint(""Average L2 norms of feature vector changes: %.3f"" % np.mean(diff_norm))\n\nper_class = np.zeros(len(class_names))\nnp.add.at(per_class, labels, diff_norm)\nper_class[zero] = 0.0\nper_class = per_class / counts\n\nprint(""Average L2 norms of feature vector changes per class:"")\nprint_per_class(per_class)\n\nnorm_diff = np.linalg.norm(features_adv, axis = 1) - np.linalg.norm(features_original, axis = 1)\n\nprint(""Average difference between L2 norms: %.3f"" % np.mean(norm_diff))\nprint(""Min difference between L2 norms: %.3f"" % np.min(norm_diff))\nprint(""Max difference between L2 norms: %.3f"" % np.max(norm_diff))\n\nper_class = np.zeros(len(class_names))\nnp.add.at(per_class, labels, norm_diff)\nper_class[zero] = 0.0\nper_class = per_class / counts\n\nprint(""Average difference between L2 norms per class:"")\nprint_per_class(per_class)\n\npercent_pos = np.sum(diff > 0.0, axis = 1) / float(diff.shape[1])\npercent_neg = np.sum(diff < 0.0, axis = 1) / float(diff.shape[1])\n\nprint(""Average %% positive change: %.3f"" % np.mean(percent_pos))\nprint(""Average %% negative change: %.3f"" % np.mean(percent_neg))\n\nper_class_pos = np.zeros(len(class_names))\nnp.add.at(per_class_pos, labels, percent_pos)\nper_class_pos[zero] = 0.0\nper_class_pos = per_class_pos / counts\n\nper_class_neg = np.zeros(len(class_names))\nnp.add.at(per_class_neg, labels, percent_neg)\nper_class_neg[zero] = 0.0\nper_class_neg = per_class_neg / counts\n\nprint(""Average % positive change per class:"")\nprint_per_class(per_class_pos)\n\nprint(""Average % negative change per class:"")\nprint_per_class(per_class_neg)\n\nprint(""Average dimension change %.3f"" % np.mean(diff))\n\nper_class = np.zeros(len(class_names))\nnp.add.at(per_class, labels, np.mean(diff, axis = 1))\nper_class[zero] = 0.0\nper_class = per_class / counts\n\nprint(""Average dimension change per class:"")\nprint_per_class(per_class)\n\nprint(""Average absolute dimension change %.3f"" % np.mean(np.abs(diff)))\nprint(""Avg min absolute dimension change %.3f"" % np.min(np.mean(np.abs(diff), axis = 1)))\nprint(""Avg max absolute dimension change %.3f"" % np.max(np.mean(np.abs(diff), axis = 1)))\n\nper_class = np.zeros(len(class_names))\nnp.add.at(per_class, labels, np.mean(np.abs(diff), axis = 1))\nper_class[zero] = 0.0\nper_class = per_class / counts\n\nprint(""Average absolute dimension change per class:"")\nprint_per_class(per_class)\n\navg_diff = np.mean(diff, axis = 0)\nprint(""Average change per dimension, min %.3f, max %.3f"" % (np.min(avg_diff), np.max(avg_diff)))\n\npair_dist_original = np.zeros((len(class_names), len(class_names)))\npair_dist_adv = np.zeros((len(class_names), len(class_names)))\npair_dist_pred_adv_original = np.zeros((len(class_names), len(class_names)))\npair_dist_pred_adv = np.zeros((len(class_names), len(class_names)))\npair_counts = np.zeros((len(class_names), len(class_names)))\npair_counts_pred_adv = np.zeros((len(class_names), len(class_names)))\nmask = np.zeros((len(class_names), len(class_names)))\nfor i in range(len(labels)):\n    for j in range(len(labels)):\n        pair_dist_original[labels[i]][labels[j]] += np.linalg.norm(features_original[i] - features_original[j])\n        pair_dist_adv[labels[i]][labels[j]] += np.linalg.norm(features_adv[i] - features_original[j])\n        pair_dist_pred_adv_original[pred_adv[i]][labels[j]] += np.linalg.norm(features_original[i] - features_original[j])\n        pair_dist_pred_adv[pred_adv[i]][labels[j]] += np.linalg.norm(features_adv[i] - features_original[j])\n        pair_counts[labels[i]][labels[j]] += 1\n        pair_counts_pred_adv[pred_adv[i]][labels[j]] += 1\n\npair_dist_original = np.array(pair_dist_original)\npair_dist_adv = np.array(pair_dist_adv)\npair_counts = np.array(pair_counts)\npair_dist_pred_adv_original = np.array(pair_dist_pred_adv_original)\npair_dist_pred_adv = np.array(pair_dist_pred_adv)\npair_counts_pred_adv = np.array(pair_counts_pred_adv)\nmask[labels, pred_adv] = 1.0\n\npair_dist_original[pair_counts == 0.0] = 0.0\npair_dist_adv[pair_counts == 0.0] = 0.0\npair_dist_pred_adv_original[pair_counts_pred_adv == 0.0] = 0.0\npair_dist_pred_adv[pair_counts_pred_adv == 0.0] = 0.0\npair_counts[pair_counts == 0.0] = 1.0\npair_counts_pred_adv[pair_counts_pred_adv == 0.0] = 1.0\n\npair_dist_original = pair_dist_original / pair_counts\npair_dist_adv = pair_dist_adv / pair_counts\npair_dist_pred_adv_original = pair_dist_pred_adv_original / pair_counts_pred_adv\npair_dist_pred_adv = pair_dist_pred_adv / pair_counts_pred_adv\n\ntry:\n    os.makedirs(args.output)\nexcept OSError as e:\n    if e.errno != errno.EEXIST:\n        raise\n\nadversarial_utils.heatmap(pair_dist_original, os.path.join(args.output, ""original_dist.png""), ""Original"", ""Original"", class_names = class_names, percentages = False, annotate = False)\nadversarial_utils.heatmap(pair_dist_adv, os.path.join(args.output, ""adversarial_dist.png""), ""Adversarial"", ""Original"", class_names = class_names, percentages = False, annotate = False)\nadversarial_utils.heatmap(pair_dist_adv - pair_dist_original, os.path.join(args.output, ""adversarial_dist_change.png""), ""Adversarial"", ""Original"", class_names = class_names, percentages = False, annotate = False)\nadversarial_utils.heatmap((pair_dist_adv - pair_dist_original) * mask, os.path.join(args.output, ""adversarial_dist_relevant_change.png""), ""Adversarial"", ""Original"", class_names = class_names, percentages = False, annotate = False)\n\nadversarial_utils.heatmap(pair_dist_pred_adv_original, os.path.join(args.output, ""original_pred_adv_dist.png""), ""Original"", ""Original"", class_names = class_names, percentages = False, annotate = False)\nadversarial_utils.heatmap(pair_dist_pred_adv, os.path.join(args.output, ""adversarial_pred_adv_dist.png""), ""Adversarial"", ""Original"", class_names = class_names, percentages = False, annotate = False)\nadversarial_utils.heatmap(pair_dist_pred_adv - pair_dist_pred_adv_original, os.path.join(args.output, ""adversarial_pred_adv_dist_change.png""), ""Adversarial"", ""Original"", class_names = class_names, percentages = False, annotate = False)\n\ndef top_k_freq(a, k):\n    res = defaultdict(int)\n    max_idx = np.argsort(np.abs(a), axis = 1)[:, -k:]\n    for idx in max_idx:\n        for i in idx:\n            res[i] += 1\n    return sorted(res.items(), key = lambda x: x[1], reverse = True)\n\ndef top_k_freq_per_class(a, k):\n    res = [defaultdict(int) for _ in class_names]\n    max_idx = np.argsort(np.abs(a), axis = 1)[:, -k:]\n    for i in range(len(max_idx)):\n        for j in max_idx[i]:\n            res[labels[i]][j] += 1\n    return [sorted(dict.items(), key = lambda x: x[1], reverse = True) for dict in res]\n\nprint(""Dimensions that changed the most (dimension, count):"")\nfreq = top_k_freq(diff, 5)[:5]\nprint(freq)\n\nfreq_per_class = top_k_freq_per_class(diff, 5)\n\nprint(""Number of different dimensions that changed the most per class:"")\nprint_per_class([len(x) for x in freq_per_class])\n\nprint(""Dimensions that changed the most per class (dimension, count):"")\nfor i in range(len(class_names)):\n    curr_idx = freq_per_class[i][:5]\n    print(""%d, %s: %s"" % (i, class_names[i], curr_idx))\n\ngrads_adv, top_adv = feature_grad_fn(diff, k = 5, adv = True)\ngrads_original, top_original = feature_grad_fn(diff, k = 5, adv = False)\nsess_close()\n\nnp.savez_compressed(os.path.join(args.output, ""feature_vector_saliency_adv.npz""), feature_vectors = features_adv, points = data_x_adv, labels = labels, pred_adv = pred_adv, saliency = grads_adv, top_k = top_adv)\nnp.savez_compressed(os.path.join(args.output, ""feature_vector_saliency_original.npz""), feature_vectors = features_original, points = data_x_original, labels = labels, saliency = grads_original, top_k = top_original)'"
src/feature_vectors_pointnet2.py,55,"b'import numpy as np\nimport tensorflow as tf\nimport adversarial_utils\nimport os\nimport sys\nimport errno\nimport argparse\nimport importlib\nworking_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.join(working_dir, ""models""))\nsys.path.append(os.path.join(working_dir, ""utils""))\nfrom collections import defaultdict\n\nparser = argparse.ArgumentParser(description = ""Gets the feature vector for PointNet++."", formatter_class = argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(""--checkpoint"", default = ""log/model.ckpt"", help = ""Path to the model\'s checkpoint file."")\nparser.add_argument(""--data"", help = ""Input data, a Numpy file."")\nparser.add_argument(""--output"", default = ""feature_vectors"", help = ""Output path."")\nparser.add_argument(""--class-names"", default = ""data/modelnet40_ply_hdf5_2048/shape_names.txt"", help = ""Text file containing a list of class names."")\nparser.add_argument(""--num-objects"", type = int, default = 1000000000, help = ""Use the first few objects. Specify a very large number to use all objects."")\nargs = parser.parse_args()\nprint(args)\n\nmodel = importlib.import_module(""pointnet2_cls_ssg"")\nclass_names = [line.rstrip() for line in open(args.class_names)]\n\nwith np.load(args.data) as file:\n    data_x_original = file[""x_original""][:args.num_objects]\n    data_x_adv = file[""x_adv""][:args.num_objects]\n    labels = file[""labels""][:args.num_objects]\n    pred_adv = file[""pred_adv""][:args.num_objects]\n\nx_pl, _ = model.placeholder_inputs(1, data_x_original.shape[1])\n\nis_training = tf.placeholder(tf.bool, shape = [])\n\ndef model_loss_fn(x, t):\n    with tf.variable_scope(tf.get_variable_scope(), reuse = tf.AUTO_REUSE):\n        y, end_points = model.get_model(x, is_training, num_classes = len(class_names))\n    if t is None:\n        loss = None\n    else:\n        loss = model.get_loss(y, t, end_points)\n    return y, loss\n\nfeatures_original, features_adv, feature_grad_fn, sess_close = adversarial_utils.get_feature_vectors(args.checkpoint, x_pl, model_loss_fn, data_x_original, data_x_adv, class_names, extra_feed_dict = {is_training: False})\n\nprint(features_original.shape)\nprint(""Average norm of perturbation: %.3f"" % np.mean(np.sqrt(np.sum((data_x_adv - data_x_original) ** 2, axis = (1, 2)))))\n\navg_ratio = 0.0\nratio_count = 0\nfor i in range(len(labels)):\n    diff_norm = np.linalg.norm(features_adv[i] - features_original[i])\n    avg_dist = 0.0\n    dist_count = 0\n    for j in range(len(labels)):\n        if labels[j] == pred_adv[i]:\n            dist = np.linalg.norm(features_original[i] - features_original[j])\n            avg_dist += dist\n            dist_count += 1\n    if dist_count == 0:\n        continue\n    avg_dist /= float(dist_count)\n    ratio = diff_norm / avg_dist\n    avg_ratio += ratio\n    ratio_count += 1\n\nprint(""Average ratio of difference norms to average class differences: %.3f"" % (avg_ratio / float(ratio_count)))\n\ndef print_per_class(per_class):\n    for i, val in enumerate(per_class):\n        print(""%d, %s: %.3f"" % (i, class_names[i], val))\n\ncounts = np.zeros(len(class_names))\nnp.add.at(counts, labels, 1)\nzero = counts == 0.0\ncounts[zero] = 1.0\n\ndiff = features_adv - features_original\ndiff_norm = np.linalg.norm(diff, axis = 1)\n\nprint(""Average L2 norms of feature vector changes: %.3f"" % np.mean(diff_norm))\n\nper_class = np.zeros(len(class_names))\nnp.add.at(per_class, labels, diff_norm)\nper_class[zero] = 0.0\nper_class = per_class / counts\n\nprint(""Average L2 norms of feature vector changes per class:"")\nprint_per_class(per_class)\n\nnorm_diff = np.linalg.norm(features_adv, axis = 1) - np.linalg.norm(features_original, axis = 1)\n\nprint(""Average difference between L2 norms: %.3f"" % np.mean(norm_diff))\nprint(""Min difference between L2 norms: %.3f"" % np.min(norm_diff))\nprint(""Max difference between L2 norms: %.3f"" % np.max(norm_diff))\n\nper_class = np.zeros(len(class_names))\nnp.add.at(per_class, labels, norm_diff)\nper_class[zero] = 0.0\nper_class = per_class / counts\n\nprint(""Average difference between L2 norms per class:"")\nprint_per_class(per_class)\n\npercent_pos = np.sum(diff > 0.0, axis = 1) / float(diff.shape[1])\npercent_neg = np.sum(diff < 0.0, axis = 1) / float(diff.shape[1])\n\nprint(""Average %% positive change: %.3f"" % np.mean(percent_pos))\nprint(""Average %% negative change: %.3f"" % np.mean(percent_neg))\n\nper_class_pos = np.zeros(len(class_names))\nnp.add.at(per_class_pos, labels, percent_pos)\nper_class_pos[zero] = 0.0\nper_class_pos = per_class_pos / counts\n\nper_class_neg = np.zeros(len(class_names))\nnp.add.at(per_class_neg, labels, percent_neg)\nper_class_neg[zero] = 0.0\nper_class_neg = per_class_neg / counts\n\nprint(""Average % positive change per class:"")\nprint_per_class(per_class_pos)\n\nprint(""Average % negative change per class:"")\nprint_per_class(per_class_neg)\n\nprint(""Average dimension change %.3f"" % np.mean(diff))\n\nper_class = np.zeros(len(class_names))\nnp.add.at(per_class, labels, np.mean(diff, axis = 1))\nper_class[zero] = 0.0\nper_class = per_class / counts\n\nprint(""Average dimension change per class:"")\nprint_per_class(per_class)\n\nprint(""Average absolute dimension change %.3f"" % np.mean(np.abs(diff)))\nprint(""Avg min absolute dimension change %.3f"" % np.min(np.mean(np.abs(diff), axis = 1)))\nprint(""Avg max absolute dimension change %.3f"" % np.max(np.mean(np.abs(diff), axis = 1)))\n\nper_class = np.zeros(len(class_names))\nnp.add.at(per_class, labels, np.mean(np.abs(diff), axis = 1))\nper_class[zero] = 0.0\nper_class = per_class / counts\n\nprint(""Average absolute dimension change per class:"")\nprint_per_class(per_class)\n\navg_diff = np.mean(diff, axis = 0)\nprint(""Average change per dimension, min %.3f, max %.3f"" % (np.min(avg_diff), np.max(avg_diff)))\n\npair_dist_original = np.zeros((len(class_names), len(class_names)))\npair_dist_adv = np.zeros((len(class_names), len(class_names)))\npair_dist_pred_adv_original = np.zeros((len(class_names), len(class_names)))\npair_dist_pred_adv = np.zeros((len(class_names), len(class_names)))\npair_counts = np.zeros((len(class_names), len(class_names)))\npair_counts_pred_adv = np.zeros((len(class_names), len(class_names)))\nmask = np.zeros((len(class_names), len(class_names)))\nfor i in range(len(labels)):\n    for j in range(len(labels)):\n        pair_dist_original[labels[i]][labels[j]] += np.linalg.norm(features_original[i] - features_original[j])\n        pair_dist_adv[labels[i]][labels[j]] += np.linalg.norm(features_adv[i] - features_original[j])\n        pair_dist_pred_adv_original[pred_adv[i]][labels[j]] += np.linalg.norm(features_original[i] - features_original[j])\n        pair_dist_pred_adv[pred_adv[i]][labels[j]] += np.linalg.norm(features_adv[i] - features_original[j])\n        pair_counts[labels[i]][labels[j]] += 1\n        pair_counts_pred_adv[pred_adv[i]][labels[j]] += 1\n\npair_dist_original = np.array(pair_dist_original)\npair_dist_adv = np.array(pair_dist_adv)\npair_counts = np.array(pair_counts)\npair_dist_pred_adv_original = np.array(pair_dist_pred_adv_original)\npair_dist_pred_adv = np.array(pair_dist_pred_adv)\npair_counts_pred_adv = np.array(pair_counts_pred_adv)\nmask[labels, pred_adv] = 1.0\n\npair_dist_original[pair_counts == 0.0] = 0.0\npair_dist_adv[pair_counts == 0.0] = 0.0\npair_dist_pred_adv_original[pair_counts_pred_adv == 0.0] = 0.0\npair_dist_pred_adv[pair_counts_pred_adv == 0.0] = 0.0\npair_counts[pair_counts == 0.0] = 1.0\npair_counts_pred_adv[pair_counts_pred_adv == 0.0] = 1.0\n\npair_dist_original = pair_dist_original / pair_counts\npair_dist_adv = pair_dist_adv / pair_counts\npair_dist_pred_adv_original = pair_dist_pred_adv_original / pair_counts_pred_adv\npair_dist_pred_adv = pair_dist_pred_adv / pair_counts_pred_adv\n\ntry:\n    os.makedirs(args.output)\nexcept OSError as e:\n    if e.errno != errno.EEXIST:\n        raise\n\nadversarial_utils.heatmap(pair_dist_original, os.path.join(args.output, ""original_dist.png""), ""Original"", ""Original"", class_names = class_names, percentages = False, annotate = False)\nadversarial_utils.heatmap(pair_dist_adv, os.path.join(args.output, ""adversarial_dist.png""), ""Adversarial"", ""Original"", class_names = class_names, percentages = False, annotate = False)\nadversarial_utils.heatmap(pair_dist_adv - pair_dist_original, os.path.join(args.output, ""adversarial_dist_change.png""), ""Adversarial"", ""Original"", class_names = class_names, percentages = False, annotate = False)\nadversarial_utils.heatmap((pair_dist_adv - pair_dist_original) * mask, os.path.join(args.output, ""adversarial_dist_relevant_change.png""), ""Adversarial"", ""Original"", class_names = class_names, percentages = False, annotate = False)\n\nadversarial_utils.heatmap(pair_dist_pred_adv_original, os.path.join(args.output, ""original_pred_adv_dist.png""), ""Original"", ""Original"", class_names = class_names, percentages = False, annotate = False)\nadversarial_utils.heatmap(pair_dist_pred_adv, os.path.join(args.output, ""adversarial_pred_adv_dist.png""), ""Adversarial"", ""Original"", class_names = class_names, percentages = False, annotate = False)\nadversarial_utils.heatmap(pair_dist_pred_adv - pair_dist_pred_adv_original, os.path.join(args.output, ""adversarial_pred_adv_dist_change.png""), ""Adversarial"", ""Original"", class_names = class_names, percentages = False, annotate = False)\n\ndef top_k_freq(a, k):\n    res = defaultdict(int)\n    max_idx = np.argsort(np.abs(a), axis = 1)[:, -k:]\n    for idx in max_idx:\n        for i in idx:\n            res[i] += 1\n    return sorted(res.items(), key = lambda x: x[1], reverse = True)\n\ndef top_k_freq_per_class(a, k):\n    res = [defaultdict(int) for _ in class_names]\n    max_idx = np.argsort(np.abs(a), axis = 1)[:, -k:]\n    for i in range(len(max_idx)):\n        for j in max_idx[i]:\n            res[labels[i]][j] += 1\n    return [sorted(dict.items(), key = lambda x: x[1], reverse = True) for dict in res]\n\nprint(""Dimensions that changed the most (dimension, count):"")\nfreq = top_k_freq(diff, 5)[:5]\nprint(freq)\n\nfreq_per_class = top_k_freq_per_class(diff, 5)\n\nprint(""Number of different dimensions that changed the most per class:"")\nprint_per_class([len(x) for x in freq_per_class])\n\nprint(""Dimensions that changed the most per class (dimension, count):"")\nfor i in range(len(class_names)):\n    curr_idx = freq_per_class[i][:5]\n    print(""%d, %s: %s"" % (i, class_names[i], curr_idx))\n\ngrads_adv, top_adv = feature_grad_fn(diff, k = 5, adv = True)\ngrads_original, top_original = feature_grad_fn(diff, k = 5, adv = False)\nsess_close()\n\nnp.savez_compressed(os.path.join(args.output, ""feature_vector_saliency_adv.npz""), feature_vectors = features_adv, points = data_x_adv, labels = labels, pred_adv = pred_adv, saliency = grads_adv, top_k = top_adv)\nnp.savez_compressed(os.path.join(args.output, ""feature_vector_saliency_original.npz""), feature_vectors = features_original, points = data_x_original, labels = labels, saliency = grads_original, top_k = top_original)'"
src/point_cloud_utils.py,22,"b'import glob\nimport os\nimport numpy as np\nimport bisect\n\ndef read_off_files(globPath, label_names = None):\n    if label_names is not None:\n        label_names = {label_names[i]: i for i in range(len(label_names))}\n\n    objects = []\n    labels = []\n    for path in glob.glob(globPath):\n        with open(path) as file:\n            line = file.readline()\n            if len(line) > 4:\n                line = line[3:] # exclude \'OFF\'\n            else:\n                line = file.readline()\n            num_vertices, num_faces, _ = [int(x) for x in line.split()]\n\n            vertices = []\n            for _ in range(num_vertices):\n                vertices.append([float(x) for x in file.readline().split()])\n            \n            faces = []\n            for _ in range(num_faces):\n                curr_face = []\n                idx = [int(x) for x in file.readline().split()]\n                idx = idx[1:]\n                for i in idx:\n                    curr_face.append(vertices[i])\n                faces.append(curr_face)\n            \n            faces = np.array(faces) # the shape should be (num_faces, 3, 3)\n            if tuple(faces.shape) == (num_faces, 3, 3):\n                name = os.path.basename(path)\n                name = name[:name.rindex(""_"")]\n                if label_names is None or name in label_names:\n                    if label_names is not None:\n                        name = label_names[name]\n                    objects.append(faces[:, :, [0, 2, 1]])\n                    labels.append(name)\n                else:\n                    raise ValueError(""A label does not exist in label names!"")\n            else:\n                raise ValueError(""A 3D object\'s array has incorrect shape!"")\n    \n    return objects, np.array(labels)\n\ndef sample_points(objects, num_points):\n    points = []\n    triangles = []\n\n    for obj in objects:\n        curr_points = []\n        curr_triangles = []\n\n        areas = np.cross(obj[:, 1] - obj[:, 0], obj[:, 2] - obj[:, 0])\n        areas = np.linalg.norm(areas, axis = 1) / 2.0\n        prefix_sum = np.cumsum(areas)\n        total_area = prefix_sum[-1]\n        \n        for _ in range(num_points):\n            # pick random triangle based on area\n            rand = np.random.uniform(high = total_area)\n            if rand >= total_area:\n                idx = len(obj) - 1 # can happen due to floating point rounding\n            else:\n                idx = bisect.bisect_right(prefix_sum, rand)\n            \n            # pick random point in triangle\n            a, b, c = obj[idx]\n            r1 = np.random.random()\n            r2 = np.random.random()\n            if r1 + r2 >= 1.0:\n                r1 = 1 - r1\n                r2 = 1 - r2\n            p = a + r1 * (b - a) + r2 * (c - a)\n\n            curr_points.append(p)\n            curr_triangles.append(obj[idx])\n\n        points.append(curr_points)\n        triangles.append(curr_triangles)\n    \n    points = np.array(points)\n    triangles = np.array(triangles)\n\n    return points, triangles\n\ndef farthest_points_normalized(points, faces, num_points):\n    res_points = []\n    res_faces = []\n\n    for obj_points, obj_faces in zip(points, faces):\n        first = np.random.randint(len(obj_points))\n        selected = [first]\n        dists = np.full(shape = len(obj_points), fill_value = np.inf)\n\n        for _ in range(num_points - 1):\n            dists = np.minimum(dists, np.linalg.norm(obj_points - obj_points[selected[-1]][np.newaxis, :], axis = 1))\n            selected.append(np.argmax(dists))\n        \n        res_points.append(obj_points[selected])\n        res_faces.append(obj_faces[selected])\n    \n    res_points = np.array(res_points)\n    res_faces = np.array(res_faces)\n\n    # normalize the points and faces\n    avg = np.average(np.transpose(res_points, axes = (0, 2, 1)), axis = 2)\n    res_points = res_points - avg[:, np.newaxis, :]\n    res_faces = res_faces - avg[:, np.newaxis, np.newaxis, :]\n    dists = np.max(np.linalg.norm(res_points, axis = 2), axis = 1)\n    res_points = res_points / dists[:, np.newaxis, np.newaxis]\n    res_faces = res_faces / dists[:, np.newaxis, np.newaxis, np.newaxis]\n\n    return res_points, res_faces'"
src/saliency_pointnet.py,2,"b'import numpy as np\nimport tensorflow as tf\nimport adversarial_utils\nimport os\nimport sys\nimport importlib\nworking_dir = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.join(working_dir, ""models""))\nsys.path.append(os.path.join(working_dir, ""utils""))\n\nloss_saliency = True\nsaliency_class = 8\nnum_points = 1024\nmodel_path = ""log/model.ckpt""\nout_dir = ""saliency""\npath = ""point_clouds.npz""\n\nmodel = importlib.import_module(""pointnet_cls"")\nclass_names = [line.rstrip() for line in open(""data/modelnet40_ply_hdf5_2048/shape_names.txt"")]\n\nwith np.load(path) as file:\n    if ""points"" in file:\n        data_x = file[""points""][:, :num_points, :]\n        data_t = file[""labels""]\n    else:\n        data_x = file[""x_adv""]\n        data_t = file[""labels""]\n\nx_pl, t_pl = model.placeholder_inputs(1, num_points)\n\nis_training = tf.placeholder(tf.bool, shape = [])\n\ndef model_loss_fn(x, t):\n    with tf.variable_scope(tf.get_variable_scope(), reuse = tf.AUTO_REUSE):\n        y, end_points = model.get_model(x, is_training, num_classes = len(class_names))\n    if t is None:\n        loss = None\n    else:\n        loss = model.get_loss(y, t, end_points)\n    return y, loss\n\nif loss_saliency:\n    saliency = adversarial_utils.saliency(model_path, x_pl, model_loss_fn, data_x, class_names, t_pl = t_pl, data_t = data_t, extra_feed_dict = {is_training: False})\nelse:\n    saliency = adversarial_utils.saliency(model_path, x_pl, model_loss_fn, data_x, class_names, saliency_class = saliency_class, extra_feed_dict = {is_training: False})\n\nnp.savez_compressed(os.path.join(out_dir, ""saliency.npz""), points = data_x, labels = data_t, saliency = saliency)'"
src/sample_point_clouds.py,1,"b'import point_cloud_utils\nimport numpy as np\n\nclass_names = [line.rstrip() for line in open(""shape_names.txt"")]\nobjects, labels = point_cloud_utils.read_off_files(""objects/*/test/*.off"", class_names)\npoints, faces = point_cloud_utils.sample_points(objects, 10000)\npoints, faces = point_cloud_utils.farthest_points_normalized(points, faces, 2048)\n\nnp.savez_compressed(""point_clouds.npz"", points = points, faces = faces, labels = labels)'"
src/unique_points_stats.py,6,"b'import numpy as np\nfrom collections import defaultdict\n\nfile1 = np.load(""point_clouds/saliency_original.npz"")\nfile2 = np.load(""point_clouds/saliency_adv.npz"")\n\np1 = file1[""saliency""][0]\np2 = file2[""saliency""][0]\n\nl1 = file1[""points""][0]\nl2 = file2[""points""][0]\n\nprint(p1.shape)\n\ns1 = defaultdict(list)\ns2 = defaultdict(list)\ns3 = []\nfor i in range(len(l1)):\n    s1[l1[i].tobytes()] += [p1[i]]\n    s2[l2[i].tobytes()] += [p2[i]]\n    if np.any(~np.isclose(l1[i], l2[i])):\n        s3.append(p2[i])\n\nprint(s3)\nprint(len(s3))\n\nprint(len(s1))\nprint(len(s2))\n\nprint(np.sum(np.all(p1 == 0, axis = 1)))\n\ndup = []\nfor _, val in s2.items():\n    if len(val) > 1:\n        dup.append(val)\n        print(val)\nprint(len(dup))\n\nidx1 = np.argsort(np.mean(p1, axis = 1))\nprint(p1[idx1][:10])\n\nidx2 = np.argsort(np.mean(p2, axis = 1))\nprint(p2[idx2][:10])'"
src/visualization_utils.py,1,"b'import numpy as np\n\ndef read_npz_files(paths):\n    files = []\n    for path in paths:\n        files.append(np.load(path))\n    return files\n\ndef files_to_dicts(files):\n    dicts = []\n    for file in files:\n        dict = {}\n        for i, x in enumerate(file[""x_original""]):\n            dict[x.tobytes()] = i\n        dicts.append(dict)\n    return dicts\n\ndef get_intersection(data):\n    keys = data[0].keys()\n    for i in range(1, len(data)):\n        keys &= data[i].keys()\n    return keys\n\ndef get_common_labels(files, data, common, class_names):\n    res = []\n    for key in common:\n        res.append(class_names[files[0][""labels""][data[0][key]]])\n    return res\n\ndef get_object(files, data, key):\n    dicts = []\n    for file, curr_data in zip(files, data):\n        dicts.append({k: file[k][curr_data[key]] for k in file.keys()})\n    return dicts'"
src/visualize_adv_attacks.py,10,"b'import numpy as np\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport visualization_utils\nimport os\n\nclass_str = ""car""\ncamera = (0, 0)\n\nnames = [\n    ""fast_l2"",\n    ""iter_l2"",\n    ""iter_l2_norm"",\n    ""iter_l2_proj"",\n    ""fast_l2_normalized"",\n    ""iter_l2_normalized""\n]\n\npointnet_paths = [\n    ""point_clouds/pointnet/untargeted_16_final/untargeted_16_fast_l2/succeeded_point_clouds_eps_1_0.npz"",\n    #""point_clouds/pointnet/unique/untargeted_fast_sign/succeeded_point_clouds_eps_0_05.npz"",\n    ""point_clouds/pointnet/untargeted_16_final/untargeted_16_iter_l2/succeeded_point_clouds_eps_1_0.npz"",\n    ""point_clouds/pointnet/untargeted_16_final/untargeted_16_iter_l2_norm/succeeded_point_clouds_eps_1_0.npz"",\n    #""point_clouds/pointnet/unique/untargeted_iter_l2_min_norm/succeeded_point_clouds_eps_10_0.npz"",\n    ""point_clouds/pointnet/untargeted_16_final/untargeted_16_iter_l2_proj/succeeded_point_clouds_eps_1_0.npz"",\n    ""point_clouds/pointnet/untargeted_16_final/untargeted_16_fast_l2_normalized/succeeded_point_clouds_eps_0_05.npz"",\n    ""point_clouds/pointnet/untargeted_16_final/untargeted_16_iter_l2_normalized/succeeded_point_clouds_eps_0_05.npz""\n    #""point_clouds/pointnet/unique/untargeted_saliency/succeeded_point_clouds_eps_2_0.npz""\n]\n\npointnet2_paths = [\n    ""point_clouds/pointnet2/untargeted_fast_l2/succeeded_point_clouds_eps_1_0.npz"",\n    ""point_clouds/pointnet2/untargeted_fast_sign/succeeded_point_clouds_eps_0_05.npz"",\n    ""point_clouds/pointnet2/untargeted_iter_l2/succeeded_point_clouds_eps_1_0.npz"",\n    ""point_clouds/pointnet2/untargeted_iter_l2_clip_norm/succeeded_point_clouds_eps_5_0.npz"",\n    ""point_clouds/pointnet2/untargeted_iter_l2_min_norm/succeeded_point_clouds_eps_5_0.npz"",\n    ""point_clouds/pointnet2/untargeted_iter_l2_proj/succeeded_point_clouds_eps_5_0.npz"",\n    ""point_clouds/pointnet2/untargeted_saliency/succeeded_point_clouds_eps_2_0.npz""\n]\n\nshow_both = False\nshow_title = False\nshow_axis_numbers = False\nclass_names = [line.rstrip() for line in open(""shape_names_unique.txt"")]\n\npointnet_files = visualization_utils.read_npz_files(pointnet_paths)\nif show_both:\n    pointnet2_files = visualization_utils.read_npz_files(pointnet2_paths)\npointnet_data = visualization_utils.files_to_dicts(pointnet_files)\nif show_both:\n    pointnet2_data = visualization_utils.files_to_dicts(pointnet2_files)\n\ncommon = visualization_utils.get_intersection(pointnet_data)\nif show_both:\n    common = common & visualization_utils.get_intersection(pointnet2_data)\ncommon = list(common)\nprint(""Number of objects in common: %d"" % len(common))\n\npointnet_labels = visualization_utils.get_common_labels(pointnet_files, pointnet_data, common, class_names)\nif show_both:\n    pointnet2_labels = visualization_utils.get_common_labels(pointnet2_files, pointnet2_data, common, class_names)\n    assert pointnet_labels == pointnet2_labels\nprint(""Common object labels: %s"" % pointnet_labels)\n\nchosen_idx = pointnet_labels.index(class_str)\npointnet_object = visualization_utils.get_object(pointnet_files, pointnet_data, common[chosen_idx])\nif show_both:\n    pointnet2_object = visualization_utils.get_object(pointnet2_files, pointnet2_data, common[chosen_idx])\nprint(""Chosen label: %s"" % class_names[pointnet_object[0][""labels""]])\n\nos.makedirs(""point_clouds/images/%s"" % class_str, exist_ok = True)\n\nplt.figure(figsize = (12, 7))\nplt.subplot(111, projection = ""3d"")\nif show_title:\n    plt.title(""Original"")\nplt.gca().scatter(*pointnet_object[0][""x_original""].T, zdir = ""y"", c = ""C0"", s = 5)\nplt.axis(""scaled"")\nmin = np.min(pointnet_object[0][""x_original""]) - 0.1\nmax = np.max(pointnet_object[0][""x_original""]) + 0.1\nplt.gca().set_xlim(min, max)\nplt.gca().set_ylim(min, max)\nplt.gca().set_zlim(min, max)\nplt.gca().view_init(*camera)\nif not show_axis_numbers:\n    plt.gca().set_xticklabels([])\n    plt.gca().set_yticklabels([])\n    plt.gca().set_zticklabels([])\nplt.subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, wspace = 0, hspace = 0)\nplt.savefig(""point_clouds/images/%s/original_%s.eps"" % (class_str, class_str))\n#plt.show()\nplt.close()\n\nif show_both:\n    arr = zip(pointnet_object, pointnet2_object)\nelse:\n    arr = pointnet_object\nfor i, p in enumerate(arr):\n    if show_both:\n        p1, p2 = p\n    else:\n        p1 = p\n    plt.figure(figsize = (12, 7))\n\n    if show_both:\n        plt.subplot(121, projection = ""3d"")\n    else:\n        plt.subplot(111, projection = ""3d"")\n    if show_title:\n        plt.title(""PointNet"")\n\n    close1 = np.all(np.isclose(p1[""x_adv""], p1[""x_original""]), axis = 1)\n    c1 = np.repeat(""C1"", len(p1[""x_adv""]))\n    c1[close1] = ""C0""\n\n    plt.gca().scatter(*p1[""x_adv""].T, zdir = ""y"", c = c1, s = 5)\n    plt.axis(""scaled"")\n    min = np.min(p1[""x_adv""]) - 0.1\n    max = np.max(p1[""x_adv""]) + 0.1\n    plt.gca().set_xlim(min, max)\n    plt.gca().set_ylim(min, max)\n    plt.gca().set_zlim(min, max)\n    plt.gca().view_init(*camera)\n    if not show_axis_numbers:\n        plt.gca().set_xticklabels([])\n        plt.gca().set_yticklabels([])\n        plt.gca().set_zticklabels([])\n\n    if show_both:\n        plt.subplot(122, projection = ""3d"")\n        if show_title:\n            plt.title(""PointNet++"")\n\n        close2 = np.all(np.isclose(p2[""x_adv""], p2[""x_original""]), axis = 1)\n        c2 = np.repeat(""C1"", len(p2[""x_adv""]))\n        c2[close2] = ""C0""\n\n        plt.gca().scatter(*p2[""x_adv""].T, zdir = ""y"", c = c2, s = 5)\n        plt.axis(""scaled"")\n        min = np.min(p2[""x_adv""]) - 0.1\n        max = np.max(p2[""x_adv""]) + 0.1\n        plt.gca().set_xlim(min, max)\n        plt.gca().set_ylim(min, max)\n        plt.gca().set_zlim(min, max)\n        plt.gca().view_init(*camera)\n        if not show_axis_numbers:\n            plt.gca().set_xticklabels([])\n            plt.gca().set_yticklabels([])\n            plt.gca().set_zticklabels([])\n    \n    plt.subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, wspace = 0, hspace = 0)\n\n    plt.savefig(""point_clouds/images/%s/adv_%s_%s_pred_%s.eps"" % (class_str, class_str, names[i], class_names[p1[""pred_adv""]]))\n    #plt.show()\n    plt.close()\n\n    print(""File %d"" % (i + 1))\n    print(""PointNet adversarial prediction: %s"" % class_names[p1[""pred_adv""]])\n    if show_both:\n        print(""PointNet++ adversarial prediction: %s"" % class_names[p2[""pred_adv""]])'"
src/visualize_feature_vectors_tsne.py,3,"b'import numpy as np\nimport os\nimport argparse\nimport errno\nfrom sklearn.manifold import TSNE\nimport matplotlib\nmatplotlib.use(""Agg"")\nimport matplotlib.pyplot as plt\n\nparser = argparse.ArgumentParser(description = ""t-SNE of feature vectors."", formatter_class = argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(""data"", help = ""Path to the feature vector data file."")\nparser.add_argument(""--adv"", default = None, help = ""Path to the adversarial feature vector data file."")\nparser.add_argument(""--pred-adv"", action = ""store_true"", help = ""Use adversarial predictions instead of labels."")\nparser.add_argument(""--output"", default = ""feature_vector_tsne"", help = ""Output directory."")\nparser.add_argument(""--class-names"", default = ""data/modelnet40_ply_hdf5_2048/shape_names.txt"", help = ""Text file containing a list of class names."")\nparser.add_argument(""--perplexity"", default = 30.0, help = ""Perplexity for t-SNE."")\nargs = parser.parse_args()\nprint(args)\n\nclass_names = [line.rstrip() for line in open(args.class_names)]\n\nwith np.load(args.data) as file:\n    feature_vectors = file[""feature_vectors""]\n    labels = file[""labels""]\n\nif args.adv is not None:\n    with np.load(args.adv) as file:\n        feature_vectors_adv = file[""feature_vectors""]\n        labels_adv = file[""pred_adv""] if args.pred_adv else file[""labels""]\n\nif args.adv is None:\n    x = feature_vectors\nelse:\n    x = np.concatenate((feature_vectors, feature_vectors_adv))\n\nres = TSNE(n_components = 2, perplexity = args.perplexity, random_state = 0).fit_transform(x)\n\nif args.adv is None:\n    embedding = res\nelse:\n    embedding = res[:len(feature_vectors)]\n    embedding_adv = res[len(feature_vectors):]\n\nplt.figure(figsize = (20, 20))\nplt.subplot(111)\n\ncmap = plt.get_cmap(""rainbow"")\nfor i in range(len(class_names)):\n    plt.gca().scatter(*embedding[labels == i].T, c = cmap([float(i) / len(class_names)]), label = class_names[i])\n\nif args.adv is not None:\n    for i in range(len(class_names)):\n        color = cmap([float(i) / len(class_names)])\n        color[:, :3] *= 0.5\n        plt.gca().scatter(*embedding_adv[labels_adv == i].T, c = color, label = ""adversarial %s"" % class_names[i])\n\nplt.gca().legend()\nplt.subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, wspace = 0, hspace = 0)\n\ntry:\n    os.makedirs(args.output)\nexcept OSError as e:\n    if e.errno != errno.EEXIST:\n        raise\nplt.savefig(os.path.join(args.output, ""tsne.jpg""))'"
src/visualize_point_cloud.py,10,"b'import numpy as np\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nload_path = ""point_clouds/pointnet/outliers_untargeted_iter_l2/succeeded_point_clouds_eps_1_0.npz""\nidx = 0\nvisualize_original = False\nsaliency_norm = False\nnum_points_max = 1024\ntriangle_mesh = False\n\nsaliency = None\n\nclass_names = [line.rstrip() for line in open(""shape_names.txt"")]\n\nif load_path[-3:] == ""npy"":\n    xs, ys, zs = np.load(load_path)[:num_points_max].T\n    triangle_mesh = False\nelif load_path[-3:] == ""npz"":\n    file = np.load(load_path)\n\n    if ""x_adv"" in file:\n        points, labels = file[""x_original"" if visualize_original else ""x_adv""], file[""labels""]\n    else:\n        points, labels = file[""points""], file[""labels""]\n    \n    if ""faces"" in file:\n        faces = file[""faces""]\n    else:\n        print(""No triangular faces found in file!"")\n        triangle_mesh = False\n    \n    if ""saliency"" in file:\n        saliency = file[""saliency""]\n        if saliency.ndim == 3:\n            saliency = saliency[np.newaxis]\n        saliency = saliency[:, idx][:, :num_points_max]\n        if ""top_k"" in file:\n            dimension = file[""top_k""][:, idx]\n        else:\n            dimension = None\n\n    print(""Label: %s"" % class_names[labels[idx]])\n\n    xs, ys, zs = points[idx][:num_points_max].T\n    \n    if triangle_mesh:\n        faces = faces[idx][:num_points_max, :3, [0, 2, 1]]\n        unique = np.unique(faces.reshape(-1, faces.shape[-1]), axis = 0)\n        triangles = np.empty(shape = (num_points_max, 3))\n\n        for i in range(num_points_max):\n            for j in range(3):\n                k, = np.where(np.all(unique == faces[i][j], axis = 1))\n                triangles[i][j] = k\n\nprint(""Number of points: %d"" % len(xs))\n\ndef scale_plot():\n    plt.axis(""scaled"")\n    plt.gca().set_xlim(-1, 1)\n    plt.gca().set_ylim(-1, 1)\n    plt.gca().set_zlim(-1, 1)\n    plt.gca().view_init(0, 0)\n\nif saliency is None:\n    plt.figure(figsize = (7, 7))\n    plt.subplot(111, projection = ""3d"")\n    if triangle_mesh:\n        plt.gca().plot_trisurf(*unique.T, triangles = triangles, cmap = ""magma"")\n    plt.gca().scatter(xs, ys, zs, zdir = ""y"", s = 5)\n    scale_plot()\n    plt.subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, wspace = 0, hspace = 0)\nelse:\n    plt.figure(figsize = (12, 4))\n    if saliency_norm:\n        saliency = np.linalg.norm(saliency, axis = 2)\n        saliency = np.clip(saliency / (np.mean(saliency) * 2.0), 0.0, 1.0)\n    else:\n        saliency = np.mean(saliency, axis = 2)\n        saliency = np.clip(saliency / (np.mean(np.abs(saliency)) * 2.0), -1.0, 1.0) / 2.0 + 0.5\n    for i in range(len(saliency)):\n        plt.subplot(1, len(saliency), i + 1, projection = ""3d"")\n        if dimension is not None:\n            plt.title(dimension[i])\n        if triangle_mesh:\n            plt.gca().plot_trisurf(*unique.T, triangles = triangles, cmap = ""magma"")\n        plot = plt.gca().scatter(xs, ys, zs, zdir = ""y"", c = saliency[i], cmap = ""viridis_r"", s = 5)\n        scale_plot()\n    plt.colorbar(plot, cax = plt.axes((0.95, 0.15, 0.01, 0.7)))\n    plt.subplots_adjust(left = 0, bottom = 0, right = 0.95, top = 1, wspace = 0, hspace = 0)\nplt.show()'"
src/pointnet/train.py,12,"b'import argparse\nimport math\nimport h5py\nimport numpy as np\nimport tensorflow as tf\nimport socket\nimport importlib\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, \'models\'))\nsys.path.append(os.path.join(BASE_DIR, \'utils\'))\nimport provider\nimport tf_util\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'GPU to use [default: GPU 0]\')\nparser.add_argument(\'--model\', default=\'pointnet_cls\', help=\'Model name: pointnet_cls or pointnet_cls_basic [default: pointnet_cls]\')\nparser.add_argument(\'--log_dir\', default=\'log\', help=\'Log dir [default: log]\')\nparser.add_argument(\'--num_point\', type=int, default=1024, help=\'Point Number [256/512/1024/2048] [default: 1024]\')\nparser.add_argument(\'--max_epoch\', type=int, default=250, help=\'Epoch to run [default: 250]\')\nparser.add_argument(\'--batch_size\', type=int, default=32, help=\'Batch Size during training [default: 32]\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.001, help=\'Initial learning rate [default: 0.001]\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Initial learning rate [default: 0.9]\')\nparser.add_argument(\'--optimizer\', default=\'adam\', help=\'adam or momentum [default: adam]\')\nparser.add_argument(\'--decay_step\', type=int, default=200000, help=\'Decay step for lr decay [default: 200000]\')\nparser.add_argument(\'--decay_rate\', type=float, default=0.7, help=\'Decay rate for lr decay [default: 0.8]\')\nparser.add_argument(""--adv"", action = ""store_true"", help = ""use adversarial training [default: false]"")\nparser.add_argument(""--classes"", type = int, default = 40, help = ""number of classes [default: 40]"")\nFLAGS = parser.parse_args()\n\n\nBATCH_SIZE = FLAGS.batch_size\nNUM_POINT = FLAGS.num_point\nMAX_EPOCH = FLAGS.max_epoch\nBASE_LEARNING_RATE = FLAGS.learning_rate\nGPU_INDEX = FLAGS.gpu\nMOMENTUM = FLAGS.momentum\nOPTIMIZER = FLAGS.optimizer\nDECAY_STEP = FLAGS.decay_step\nDECAY_RATE = FLAGS.decay_rate\nADV = FLAGS.adv\nNUM_CLASSES = FLAGS.classes\n\nMODEL = importlib.import_module(FLAGS.model) # import network module\nMODEL_FILE = os.path.join(BASE_DIR, \'models\', FLAGS.model+\'.py\')\nLOG_DIR = FLAGS.log_dir\nif not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\nos.system(\'cp %s %s\' % (MODEL_FILE, LOG_DIR)) # bkp of model def\nos.system(\'cp train.py %s\' % (LOG_DIR)) # bkp of train procedure\nLOG_FOUT = open(os.path.join(LOG_DIR, \'log_train.txt\'), \'w\')\nLOG_FOUT.write(str(FLAGS)+\'\\n\')\n\nMAX_NUM_POINT = 2048\n\nBN_INIT_DECAY = 0.5\nBN_DECAY_DECAY_RATE = 0.5\nBN_DECAY_DECAY_STEP = float(DECAY_STEP)\nBN_DECAY_CLIP = 0.99\n\nHOSTNAME = socket.gethostname()\n\n# ModelNet40 official train/test split\nTRAIN_FILES = [""""] if NUM_CLASSES != 40 else provider.getDataFiles( \\\n    os.path.join(BASE_DIR, \'data/modelnet40_ply_hdf5_2048/train_files.txt\'))\nTEST_FILES = [""""] if NUM_CLASSES != 40 else provider.getDataFiles(\\\n    os.path.join(BASE_DIR, \'data/modelnet40_ply_hdf5_2048/test_files.txt\'))\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str+\'\\n\')\n    LOG_FOUT.flush()\n    print(out_str)\n\n\ndef get_learning_rate(batch):\n    learning_rate = tf.train.exponential_decay(\n                        BASE_LEARNING_RATE,  # Base learning rate.\n                        batch * BATCH_SIZE,  # Current index into the dataset.\n                        DECAY_STEP,          # Decay step.\n                        DECAY_RATE,          # Decay rate.\n                        staircase=True)\n    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n    return learning_rate        \n\ndef get_bn_decay(batch):\n    bn_momentum = tf.train.exponential_decay(\n                      BN_INIT_DECAY,\n                      batch*BATCH_SIZE,\n                      BN_DECAY_DECAY_STEP,\n                      BN_DECAY_DECAY_RATE,\n                      staircase=True)\n    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n    return bn_decay\n\ndef train():\n    with tf.Graph().as_default():\n        with tf.device(\'/gpu:\'+str(GPU_INDEX)):\n            pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n            is_training_pl = tf.placeholder(tf.bool, shape=())\n            print(is_training_pl)\n            \n            # Note the global_step=batch parameter to minimize. \n            # That tells the optimizer to helpfully increment the \'batch\' parameter for you every time it trains.\n            batch = tf.Variable(0)\n            bn_decay = get_bn_decay(batch)\n            tf.summary.scalar(\'bn_decay\', bn_decay)\n\n            # Get model and loss\n            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay, num_classes = NUM_CLASSES)\n            loss = MODEL.get_loss(pred, labels_pl, end_points)\n            tf.summary.scalar(\'loss\', loss)\n            \n            if ADV:\n                import adversarial_attacks\n                def model_loss_fn(x, t):\n                    with tf.variable_scope(tf.get_variable_scope(), reuse = tf.AUTO_REUSE):\n                        y, end_points = MODEL.get_model(x, is_training_pl, bn_decay = bn_decay, num_classes = NUM_CLASSES)\n                    if t is None:\n                        loss = None\n                    else:\n                        loss = MODEL.get_loss(y, t, end_points)\n                    return y, loss\n                x_adv = adversarial_attacks.iter_grad_op(pointclouds_pl, model_loss_fn, one_hot = False, iter = 1, eps = 1, ord = ""2"")\n                _, adv_loss = model_loss_fn(x_adv, labels_pl)\n\n            correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))\n            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n            tf.summary.scalar(\'accuracy\', accuracy)\n\n            # Get training operator\n            learning_rate = get_learning_rate(batch)\n            tf.summary.scalar(\'learning_rate\', learning_rate)\n            if OPTIMIZER == \'momentum\':\n                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n            elif OPTIMIZER == \'adam\':\n                optimizer = tf.train.AdamOptimizer(learning_rate)\n            if ADV:\n                train_op = optimizer.minimize((loss + adv_loss) / 2.0, global_step=batch)\n            else:\n                train_op = optimizer.minimize(loss, global_step=batch)\n            \n            # Add ops to save and restore all the variables.\n            saver = tf.train.Saver()\n            \n        # Create a session\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        config.log_device_placement = False\n        sess = tf.Session(config=config)\n\n        # Add summary writers\n        #merged = tf.merge_all_summaries()\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, \'train\'),\n                                  sess.graph)\n        test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, \'test\'))\n\n        # Init variables\n        init = tf.global_variables_initializer()\n        # To fix the bug introduced in TF 0.12.1 as in\n        # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n        #sess.run(init)\n        sess.run(init, {is_training_pl: True})\n\n        ops = {\'pointclouds_pl\': pointclouds_pl,\n               \'labels_pl\': labels_pl,\n               \'is_training_pl\': is_training_pl,\n               \'pred\': pred,\n               \'loss\': loss,\n               \'train_op\': train_op,\n               \'merged\': merged,\n               \'step\': batch}\n\n        for epoch in range(MAX_EPOCH):\n            log_string(\'**** EPOCH %03d ****\' % (epoch))\n            sys.stdout.flush()\n             \n            train_one_epoch(sess, ops, train_writer)\n            eval_one_epoch(sess, ops, test_writer)\n            \n            # Save the variables to disk.\n            if epoch % 10 == 0:\n                save_path = saver.save(sess, os.path.join(LOG_DIR, ""model.ckpt""))\n                log_string(""Model saved in file: %s"" % save_path)\n\n\n\ndef train_one_epoch(sess, ops, train_writer):\n    """""" ops: dict mapping from string to tf ops """"""\n    is_training = True\n    \n    # Shuffle train files\n    train_file_idxs = np.arange(0, len(TRAIN_FILES))\n    np.random.shuffle(train_file_idxs)\n    \n    for fn in range(len(TRAIN_FILES)):\n        log_string(\'----\' + str(fn) + \'-----\')\n        if NUM_CLASSES == 40:\n            current_data, current_label = provider.loadDataFile(TRAIN_FILES[train_file_idxs[fn]])\n        else:\n            with np.load(""point_clouds_unique_train.npz"") as file:\n                current_data, current_label = file[""points""], file[""labels""]\n        current_data = current_data[:,0:NUM_POINT,:]\n        current_data, current_label, _ = provider.shuffle_data(current_data, np.squeeze(current_label))            \n        current_label = np.squeeze(current_label)\n        \n        file_size = current_data.shape[0]\n        num_batches = file_size // BATCH_SIZE\n        \n        total_correct = 0\n        total_seen = 0\n        loss_sum = 0\n       \n        for batch_idx in range(num_batches):\n            start_idx = batch_idx * BATCH_SIZE\n            end_idx = (batch_idx+1) * BATCH_SIZE\n            \n            # Augment batched point clouds by rotation and jittering\n            rotated_data = provider.rotate_point_cloud(current_data[start_idx:end_idx, :, :])\n            jittered_data = provider.jitter_point_cloud(rotated_data)\n            feed_dict = {ops[\'pointclouds_pl\']: jittered_data,\n                         ops[\'labels_pl\']: current_label[start_idx:end_idx],\n                         ops[\'is_training_pl\']: is_training,}\n            summary, step, _, loss_val, pred_val = sess.run([ops[\'merged\'], ops[\'step\'],\n                ops[\'train_op\'], ops[\'loss\'], ops[\'pred\']], feed_dict=feed_dict)\n            train_writer.add_summary(summary, step)\n            pred_val = np.argmax(pred_val, 1)\n            correct = np.sum(pred_val == current_label[start_idx:end_idx])\n            total_correct += correct\n            total_seen += BATCH_SIZE\n            loss_sum += loss_val\n        \n        log_string(\'mean loss: %f\' % (loss_sum / float(num_batches)))\n        log_string(\'accuracy: %f\' % (total_correct / float(total_seen)))\n\n        \ndef eval_one_epoch(sess, ops, test_writer):\n    """""" ops: dict mapping from string to tf ops """"""\n    is_training = False\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n    \n    for fn in range(len(TEST_FILES)):\n        log_string(\'----\' + str(fn) + \'-----\')\n        if NUM_CLASSES == 40:\n            current_data, current_label = provider.loadDataFile(TEST_FILES[fn])\n        else:\n            with np.load(""point_clouds_unique_test.npz"") as file:\n                current_data, current_label = file[""points""], file[""labels""]\n        current_data = current_data[:,0:NUM_POINT,:]\n        current_label = np.squeeze(current_label)\n        \n        file_size = current_data.shape[0]\n        num_batches = file_size // BATCH_SIZE\n        \n        for batch_idx in range(num_batches):\n            start_idx = batch_idx * BATCH_SIZE\n            end_idx = (batch_idx+1) * BATCH_SIZE\n\n            feed_dict = {ops[\'pointclouds_pl\']: current_data[start_idx:end_idx, :, :],\n                         ops[\'labels_pl\']: current_label[start_idx:end_idx],\n                         ops[\'is_training_pl\']: is_training}\n            summary, step, loss_val, pred_val = sess.run([ops[\'merged\'], ops[\'step\'],\n                ops[\'loss\'], ops[\'pred\']], feed_dict=feed_dict)\n            pred_val = np.argmax(pred_val, 1)\n            correct = np.sum(pred_val == current_label[start_idx:end_idx])\n            total_correct += correct\n            total_seen += BATCH_SIZE\n            loss_sum += (loss_val*BATCH_SIZE)\n            for i in range(start_idx, end_idx):\n                l = current_label[i]\n                total_seen_class[l] += 1\n                total_correct_class[l] += (pred_val[i-start_idx] == l)\n            \n    log_string(\'eval mean loss: %f\' % (loss_sum / float(total_seen)))\n    log_string(\'eval accuracy: %f\'% (total_correct / float(total_seen)))\n    log_string(\'eval avg class acc: %f\' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n         \n\n\nif __name__ == ""__main__"":\n    train()\n    LOG_FOUT.close()\n'"
src/pointnet2/train.py,9,"b'\'\'\'\n    Single-GPU training.\n    Will use H5 dataset in default. If using normal, will shift to the normal dataset.\n\'\'\'\nimport argparse\nimport math\nfrom datetime import datetime\nimport h5py\nimport numpy as np\nimport tensorflow as tf\nimport socket\nimport importlib\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = BASE_DIR\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(ROOT_DIR, \'models\'))\nsys.path.append(os.path.join(ROOT_DIR, \'utils\'))\nimport provider\nimport tf_util\nimport modelnet_dataset\nimport modelnet_h5_dataset\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'GPU to use [default: GPU 0]\')\nparser.add_argument(\'--model\', default=\'pointnet2_cls_ssg\', help=\'Model name [default: pointnet2_cls_ssg]\')\nparser.add_argument(\'--log_dir\', default=\'log\', help=\'Log dir [default: log]\')\nparser.add_argument(\'--num_point\', type=int, default=1024, help=\'Point Number [default: 1024]\')\nparser.add_argument(\'--max_epoch\', type=int, default=251, help=\'Epoch to run [default: 251]\')\nparser.add_argument(\'--batch_size\', type=int, default=16, help=\'Batch Size during training [default: 16]\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.001, help=\'Initial learning rate [default: 0.001]\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Initial learning rate [default: 0.9]\')\nparser.add_argument(\'--optimizer\', default=\'adam\', help=\'adam or momentum [default: adam]\')\nparser.add_argument(\'--decay_step\', type=int, default=200000, help=\'Decay step for lr decay [default: 200000]\')\nparser.add_argument(\'--decay_rate\', type=float, default=0.7, help=\'Decay rate for lr decay [default: 0.7]\')\nparser.add_argument(\'--normal\', action=\'store_true\', help=\'Whether to use normal information\')\nparser.add_argument(""--adv"", action = ""store_true"", help = ""use adversarial training [default: false]"")\nparser.add_argument(""--classes"", type = int, default = 40, help = ""number of classes [default: 40]"")\nFLAGS = parser.parse_args()\n\nEPOCH_CNT = 0\n\nBATCH_SIZE = FLAGS.batch_size\nNUM_POINT = FLAGS.num_point\nMAX_EPOCH = FLAGS.max_epoch\nBASE_LEARNING_RATE = FLAGS.learning_rate\nGPU_INDEX = FLAGS.gpu\nMOMENTUM = FLAGS.momentum\nOPTIMIZER = FLAGS.optimizer\nDECAY_STEP = FLAGS.decay_step\nDECAY_RATE = FLAGS.decay_rate\nADV = FLAGS.adv\nNUM_CLASSES = FLAGS.classes\n\nMODEL = importlib.import_module(FLAGS.model) # import network module\nMODEL_FILE = os.path.join(ROOT_DIR, \'models\', FLAGS.model+\'.py\')\nLOG_DIR = FLAGS.log_dir\nif not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\nos.system(\'cp %s %s\' % (MODEL_FILE, LOG_DIR)) # bkp of model def\nos.system(\'cp train.py %s\' % (LOG_DIR)) # bkp of train procedure\nLOG_FOUT = open(os.path.join(LOG_DIR, \'log_train.txt\'), \'w\')\nLOG_FOUT.write(str(FLAGS)+\'\\n\')\n\nBN_INIT_DECAY = 0.5\nBN_DECAY_DECAY_RATE = 0.5\nBN_DECAY_DECAY_STEP = float(DECAY_STEP)\nBN_DECAY_CLIP = 0.99\n\nHOSTNAME = socket.gethostname()\n\n# Shapenet official train/test split\nif FLAGS.normal:\n    assert(NUM_POINT<=10000)\n    DATA_PATH = os.path.join(ROOT_DIR, \'data/modelnet40_normal_resampled\')\n    TRAIN_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split=\'train\', normal_channel=FLAGS.normal, batch_size=BATCH_SIZE)\n    TEST_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split=\'test\', normal_channel=FLAGS.normal, batch_size=BATCH_SIZE)\nelse:\n    assert(NUM_POINT<=2048)\n    TRAIN_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, \'data/modelnet40_ply_hdf5_2048/train_files.txt\'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=True, np_file = NUM_CLASSES != 40)\n    TEST_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, \'data/modelnet40_ply_hdf5_2048/test_files.txt\'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=False, np_file = NUM_CLASSES != 40)\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str+\'\\n\')\n    LOG_FOUT.flush()\n    print(out_str)\n\ndef get_learning_rate(batch):\n    learning_rate = tf.train.exponential_decay(\n                        BASE_LEARNING_RATE,  # Base learning rate.\n                        batch * BATCH_SIZE,  # Current index into the dataset.\n                        DECAY_STEP,          # Decay step.\n                        DECAY_RATE,          # Decay rate.\n                        staircase=True)\n    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n    return learning_rate        \n\ndef get_bn_decay(batch):\n    bn_momentum = tf.train.exponential_decay(\n                      BN_INIT_DECAY,\n                      batch*BATCH_SIZE,\n                      BN_DECAY_DECAY_STEP,\n                      BN_DECAY_DECAY_RATE,\n                      staircase=True)\n    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n    return bn_decay\n\ndef train():\n    with tf.Graph().as_default():\n        with tf.device(\'/gpu:\'+str(GPU_INDEX)):\n            pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n            is_training_pl = tf.placeholder(tf.bool, shape=())\n            \n            # Note the global_step=batch parameter to minimize. \n            # That tells the optimizer to helpfully increment the \'batch\' parameter\n            # for you every time it trains.\n            batch = tf.get_variable(\'batch\', [],\n                initializer=tf.constant_initializer(0), trainable=False)\n            bn_decay = get_bn_decay(batch)\n            tf.summary.scalar(\'bn_decay\', bn_decay)\n\n            # Get model and loss \n            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay, num_classes = NUM_CLASSES)\n            total_loss = MODEL.get_loss(pred, labels_pl, end_points)\n            #losses = tf.get_collection(\'losses\')\n            #total_loss = tf.add_n(losses, name=\'total_loss\')\n            #tf.summary.scalar(\'total_loss\', total_loss)\n            #for l in losses + [total_loss]:\n            #    tf.summary.scalar(l.op.name, l)\n\n            if ADV:\n                import adversarial_attacks\n                def model_loss_fn(x, t):\n                    with tf.variable_scope(tf.get_variable_scope(), reuse = tf.AUTO_REUSE):\n                        y, end_points = MODEL.get_model(x, is_training_pl, bn_decay = bn_decay, num_classes = NUM_CLASSES)\n                    if t is None:\n                        loss = None\n                    else:\n                        loss = MODEL.get_loss(y, t, end_points)\n                    return y, loss\n                x_adv = adversarial_attacks.iter_grad_op(pointclouds_pl, model_loss_fn, one_hot = False, iter = 1, eps = 1, ord = ""2"")\n                _, adv_loss = model_loss_fn(x_adv, labels_pl)\n\n            correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))\n            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n            tf.summary.scalar(\'accuracy\', accuracy)\n\n            print ""--- Get training operator""\n            # Get training operator\n            learning_rate = get_learning_rate(batch)\n            tf.summary.scalar(\'learning_rate\', learning_rate)\n            if OPTIMIZER == \'momentum\':\n                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n            elif OPTIMIZER == \'adam\':\n                optimizer = tf.train.AdamOptimizer(learning_rate)\n            if ADV:\n                train_op = optimizer.minimize((total_loss + adv_loss) / 2.0, global_step=batch)\n            else:\n                train_op = optimizer.minimize(total_loss, global_step=batch)\n            \n            # Add ops to save and restore all the variables.\n            saver = tf.train.Saver()\n        \n        # Create a session\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        config.log_device_placement = False\n        sess = tf.Session(config=config)\n\n        # Add summary writers\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, \'train\'), sess.graph)\n        test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, \'test\'), sess.graph)\n\n        # Init variables\n        init = tf.global_variables_initializer()\n        sess.run(init)\n\n        ops = {\'pointclouds_pl\': pointclouds_pl,\n               \'labels_pl\': labels_pl,\n               \'is_training_pl\': is_training_pl,\n               \'pred\': pred,\n               \'loss\': total_loss,\n               \'train_op\': train_op,\n               \'merged\': merged,\n               \'step\': batch,\n               \'end_points\': end_points}\n\n        best_acc = -1\n        for epoch in range(MAX_EPOCH):\n            log_string(\'**** EPOCH %03d ****\' % (epoch))\n            sys.stdout.flush()\n             \n            train_one_epoch(sess, ops, train_writer)\n            eval_one_epoch(sess, ops, test_writer)\n\n            # Save the variables to disk.\n            if epoch % 10 == 0:\n                save_path = saver.save(sess, os.path.join(LOG_DIR, ""model.ckpt""))\n                log_string(""Model saved in file: %s"" % save_path)\n\n\ndef train_one_epoch(sess, ops, train_writer):\n    """""" ops: dict mapping from string to tf ops """"""\n    is_training = True\n    \n    log_string(str(datetime.now()))\n\n    # Make sure batch data is of same size\n    cur_batch_data = np.zeros((BATCH_SIZE,NUM_POINT,TRAIN_DATASET.num_channel()))\n    cur_batch_label = np.zeros((BATCH_SIZE), dtype=np.int32)\n\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    batch_idx = 0\n    while TRAIN_DATASET.has_next_batch():\n        batch_data, batch_label = TRAIN_DATASET.next_batch(augment=True)\n        #batch_data = provider.random_point_dropout(batch_data)\n        bsize = batch_data.shape[0]\n        cur_batch_data[0:bsize,...] = batch_data\n        cur_batch_label[0:bsize] = batch_label\n\n        feed_dict = {ops[\'pointclouds_pl\']: cur_batch_data,\n                     ops[\'labels_pl\']: cur_batch_label,\n                     ops[\'is_training_pl\']: is_training,}\n        summary, step, _, loss_val, pred_val = sess.run([ops[\'merged\'], ops[\'step\'],\n            ops[\'train_op\'], ops[\'loss\'], ops[\'pred\']], feed_dict=feed_dict)\n        train_writer.add_summary(summary, step)\n        pred_val = np.argmax(pred_val, 1)\n        correct = np.sum(pred_val[0:bsize] == batch_label[0:bsize])\n        total_correct += correct\n        total_seen += bsize\n        loss_sum += loss_val\n        if (batch_idx+1)%50 == 0:\n            log_string(\' ---- batch: %03d ----\' % (batch_idx+1))\n            log_string(\'mean loss: %f\' % (loss_sum / 50))\n            log_string(\'accuracy: %f\' % (total_correct / float(total_seen)))\n            total_correct = 0\n            total_seen = 0\n            loss_sum = 0\n        batch_idx += 1\n\n    TRAIN_DATASET.reset()\n        \ndef eval_one_epoch(sess, ops, test_writer):\n    """""" ops: dict mapping from string to tf ops """"""\n    global EPOCH_CNT\n    is_training = False\n\n    # Make sure batch data is of same size\n    cur_batch_data = np.zeros((BATCH_SIZE,NUM_POINT,TEST_DATASET.num_channel()))\n    cur_batch_label = np.zeros((BATCH_SIZE), dtype=np.int32)\n\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    batch_idx = 0\n    shape_ious = []\n    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n    \n    log_string(str(datetime.now()))\n    log_string(\'---- EPOCH %03d EVALUATION ----\'%(EPOCH_CNT))\n    \n    while TEST_DATASET.has_next_batch():\n        batch_data, batch_label = TEST_DATASET.next_batch(augment=False)\n        bsize = batch_data.shape[0]\n        # for the last batch in the epoch, the bsize:end are from last batch\n        cur_batch_data[0:bsize,...] = batch_data\n        cur_batch_label[0:bsize] = batch_label\n\n        feed_dict = {ops[\'pointclouds_pl\']: cur_batch_data,\n                     ops[\'labels_pl\']: cur_batch_label,\n                     ops[\'is_training_pl\']: is_training}\n        summary, step, loss_val, pred_val = sess.run([ops[\'merged\'], ops[\'step\'],\n            ops[\'loss\'], ops[\'pred\']], feed_dict=feed_dict)\n        test_writer.add_summary(summary, step)\n        pred_val = np.argmax(pred_val, 1)\n        correct = np.sum(pred_val[0:bsize] == batch_label[0:bsize])\n        total_correct += correct\n        total_seen += bsize\n        loss_sum += loss_val\n        batch_idx += 1\n        for i in range(0, bsize):\n            l = batch_label[i]\n            total_seen_class[l] += 1\n            total_correct_class[l] += (pred_val[i] == l)\n    \n    log_string(\'eval mean loss: %f\' % (loss_sum / float(batch_idx)))\n    log_string(\'eval accuracy: %f\'% (total_correct / float(total_seen)))\n    log_string(\'eval avg class acc: %f\' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n    EPOCH_CNT += 1\n\n    TEST_DATASET.reset()\n    return total_correct/float(total_seen)\n\n\nif __name__ == ""__main__"":\n    log_string(\'pid: %s\'%(str(os.getpid())))\n    train()\n    LOG_FOUT.close()\n'"
src/pointnet/models/pointnet_cls.py,1,"b'import tensorflow as tf\nimport numpy as np\nimport math\nimport sys\nimport os\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, \'../utils\'))\nimport tf_util\nfrom transform_nets import input_transform_net, feature_transform_net\n\ndef placeholder_inputs(batch_size, num_point):\n    pointclouds_pl = tf.placeholder(tf.float32, shape=(batch_size, num_point, 3))\n    labels_pl = tf.placeholder(tf.int32, shape=(batch_size))\n    return pointclouds_pl, labels_pl\n\n\ndef get_model(point_cloud, is_training, bn_decay=None, num_classes = 40):\n    """""" Classification PointNet, input is BxNx3, output Bx40 """"""\n    batch_size = point_cloud.get_shape()[0].value\n    num_point = point_cloud.get_shape()[1].value\n    end_points = {}\n\n    with tf.variable_scope(\'transform_net1\') as sc:\n        transform = input_transform_net(point_cloud, is_training, bn_decay, K=3)\n    point_cloud_transformed = tf.matmul(point_cloud, transform)\n    input_image = tf.expand_dims(point_cloud_transformed, -1)\n\n    net = tf_util.conv2d(input_image, 64, [1,3],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv1\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 64, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv2\', bn_decay=bn_decay)\n\n    with tf.variable_scope(\'transform_net2\') as sc:\n        transform = feature_transform_net(net, is_training, bn_decay, K=64)\n    end_points[\'transform\'] = transform\n    net_transformed = tf.matmul(tf.squeeze(net, axis=[2]), transform)\n    net_transformed = tf.expand_dims(net_transformed, [2])\n\n    net = tf_util.conv2d(net_transformed, 64, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv3\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 128, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv4\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 1024, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv5\', bn_decay=bn_decay)\n\n    # Symmetric function: max pooling\n    net = tf_util.max_pool2d(net, [num_point,1],\n                             padding=\'VALID\', scope=\'maxpool\')\n\n    net = tf.reshape(net, [batch_size, -1])\n    features = tf.identity(net, name = ""feature_vector"")\n    net = tf_util.fully_connected(net, 512, bn=True, is_training=is_training,\n                                  scope=\'fc1\', bn_decay=bn_decay)\n    net = tf_util.dropout(net, keep_prob=0.7, is_training=is_training,\n                          scope=\'dp1\')\n    net = tf_util.fully_connected(net, 256, bn=True, is_training=is_training,\n                                  scope=\'fc2\', bn_decay=bn_decay)\n    net = tf_util.dropout(net, keep_prob=0.7, is_training=is_training,\n                          scope=\'dp2\')\n    net = tf_util.fully_connected(net, num_classes, activation_fn=None, scope=\'fc3\')\n\n    return net, end_points\n\n\ndef get_loss(pred, label, end_points, reg_weight=0.001):\n    """""" pred: B*NUM_CLASSES,\n        label: B, """"""\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)\n    classify_loss = tf.reduce_mean(loss)\n    tf.summary.scalar(\'classify loss\', classify_loss)\n\n    # Enforce the transformation as orthogonal matrix\n    transform = end_points[\'transform\'] # BxKxK\n    K = transform.get_shape()[1].value\n    mat_diff = tf.matmul(transform, tf.transpose(transform, perm=[0,2,1]))\n    mat_diff -= tf.constant(np.eye(K), dtype=tf.float32)\n    mat_diff_loss = tf.nn.l2_loss(mat_diff) \n    tf.summary.scalar(\'mat loss\', mat_diff_loss)\n\n    return classify_loss + mat_diff_loss * reg_weight\n\n\nif __name__==\'__main__\':\n    with tf.Graph().as_default():\n        inputs = tf.zeros((32,1024,3))\n        outputs = get_model(inputs, tf.constant(True))\n        print(outputs)\n'"
src/pointnet/utils/pc_util.py,30,"b'"""""" Utility functions for processing point clouds.\n\nAuthor: Charles R. Qi, Hao Su\nDate: November 2016\n""""""\n\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\n\n# Draw point cloud\nfrom eulerangles import euler2mat\n\n# Point cloud IO\nimport numpy as np\nfrom plyfile import PlyData, PlyElement\n\n \n# ----------------------------------------\n# Point Cloud/Volume Conversions\n# ----------------------------------------\n\ndef point_cloud_to_volume_batch(point_clouds, vsize=12, radius=1.0, flatten=True):\n    """""" Input is BxNx3 batch of point cloud\n        Output is Bx(vsize^3)\n    """"""\n    vol_list = []\n    for b in range(point_clouds.shape[0]):\n        vol = point_cloud_to_volume(np.squeeze(point_clouds[b,:,:]), vsize, radius)\n        if flatten:\n            vol_list.append(vol.flatten())\n        else:\n            vol_list.append(np.expand_dims(np.expand_dims(vol, -1), 0))\n    if flatten:\n        return np.vstack(vol_list)\n    else:\n        return np.concatenate(vol_list, 0)\n\n\ndef point_cloud_to_volume(points, vsize, radius=1.0):\n    """""" input is Nx3 points.\n        output is vsize*vsize*vsize\n        assumes points are in range [-radius, radius]\n    """"""\n    vol = np.zeros((vsize,vsize,vsize))\n    voxel = 2*radius/float(vsize)\n    locations = (points + radius)/voxel\n    locations = locations.astype(int)\n    vol[locations[:,0],locations[:,1],locations[:,2]] = 1.0\n    return vol\n\n#a = np.zeros((16,1024,3))\n#print point_cloud_to_volume_batch(a, 12, 1.0, False).shape\n\ndef volume_to_point_cloud(vol):\n    """""" vol is occupancy grid (value = 0 or 1) of size vsize*vsize*vsize\n        return Nx3 numpy array.\n    """"""\n    vsize = vol.shape[0]\n    assert(vol.shape[1] == vsize and vol.shape[1] == vsize)\n    points = []\n    for a in range(vsize):\n        for b in range(vsize):\n            for c in range(vsize):\n                if vol[a,b,c] == 1:\n                    points.append(np.array([a,b,c]))\n    if len(points) == 0:\n        return np.zeros((0,3))\n    points = np.vstack(points)\n    return points\n\n# ----------------------------------------\n# Point cloud IO\n# ----------------------------------------\n\ndef read_ply(filename):\n    """""" read XYZ point cloud from filename PLY file """"""\n    plydata = PlyData.read(filename)\n    pc = plydata[\'vertex\'].data\n    pc_array = np.array([[x, y, z] for x,y,z in pc])\n    return pc_array\n\n\ndef write_ply(points, filename, text=True):\n    """""" input: Nx3, write points to filename as PLY format. """"""\n    points = [(points[i,0], points[i,1], points[i,2]) for i in range(points.shape[0])]\n    vertex = np.array(points, dtype=[(\'x\', \'f4\'), (\'y\', \'f4\'),(\'z\', \'f4\')])\n    el = PlyElement.describe(vertex, \'vertex\', comments=[\'vertices\'])\n    PlyData([el], text=text).write(filename)\n\n\n# ----------------------------------------\n# Simple Point cloud and Volume Renderers\n# ----------------------------------------\n\ndef draw_point_cloud(input_points, canvasSize=500, space=200, diameter=25,\n                     xrot=0, yrot=0, zrot=0, switch_xyz=[0,1,2], normalize=False):\n    """""" Render point cloud to image with alpha channel.\n        Input:\n            points: Nx3 numpy array (+y is up direction)\n        Output:\n            gray image as numpy array of size canvasSizexcanvasSize\n    """"""\n    image = np.zeros((canvasSize, canvasSize))\n    if input_points is None or input_points.shape[0] == 0:\n        return image\n\n    points = input_points[:, switch_xyz]\n    M = euler2mat(zrot, yrot, xrot)\n    points = (np.dot(M, points.transpose())).transpose()\n\n    # Normalize the point cloud\n    # We normalize scale to fit points in a unit sphere\n    if normalize:\n        centroid = np.mean(points, axis=0)\n        points -= centroid\n        furthest_distance = np.max(np.sqrt(np.sum(abs(points)**2,axis=-1)))\n        points /= furthest_distance\n    \n    dist = np.linalg.norm(points, axis = -1)\n    points = points[dist <= 1]\n    if len(points) == 0:\n        return image\n\n    # Pre-compute the Gaussian disk\n    radius = (diameter-1)/2.0\n    disk = np.zeros((diameter, diameter))\n    for i in range(diameter):\n        for j in range(diameter):\n            if (i - radius) * (i-radius) + (j-radius) * (j-radius) <= radius * radius:\n                disk[i, j] = np.exp((-(i-radius)**2 - (j-radius)**2)/(radius**2))\n    mask = np.argwhere(disk > 0)\n    dx = mask[:, 0]\n    dy = mask[:, 1]\n    dv = disk[disk > 0]\n    \n    # Order points by z-buffer\n    zorder = np.argsort(points[:, 2])\n    points = points[zorder, :]\n    points[:, 2] = (points[:, 2] - np.min(points[:, 2])) / (np.max(points[:, 2] - np.min(points[:, 2])))\n    max_depth = np.max(points[:, 2])\n       \n    for i in range(points.shape[0]):\n        j = points.shape[0] - i - 1\n        x = points[j, 0]\n        y = points[j, 1]\n        xc = canvasSize/2 + (x*space)\n        yc = canvasSize/2 + (y*space)\n        xc = int(np.round(xc))\n        yc = int(np.round(yc))\n        \n        px = dx + xc\n        py = dy + yc\n        \n        image[px, py] = image[px, py] * 0.7 + dv * (max_depth - points[j, 2]) * 0.3\n    \n    image = image / np.max(image)\n    return image\n\ndef point_cloud_three_views(points):\n    """""" input points Nx3 numpy array (+y is up direction).\n        return an numpy array gray image of size 500x1500. """""" \n    # +y is up direction\n    # xrot is azimuth\n    # yrot is in-plane\n    # zrot is elevation\n    img1 = draw_point_cloud(points, zrot=110/180.0*np.pi, xrot=45/180.0*np.pi, yrot=0/180.0*np.pi)\n    img2 = draw_point_cloud(points, zrot=70/180.0*np.pi, xrot=135/180.0*np.pi, yrot=0/180.0*np.pi)\n    img3 = draw_point_cloud(points, zrot=180.0/180.0*np.pi, xrot=90/180.0*np.pi, yrot=0/180.0*np.pi)\n    image_large = np.concatenate([img1, img2, img3], 1)\n    return image_large\n\n\nfrom PIL import Image\ndef point_cloud_three_views_demo():\n    """""" Demo for draw_point_cloud function """"""\n    points = read_ply(\'../third_party/mesh_sampling/piano.ply\')\n    im_array = point_cloud_three_views(points)\n    img = Image.fromarray(np.uint8(im_array*255.0))\n    img.save(\'piano.jpg\')\n\nif __name__==""__main__"":\n    point_cloud_three_views_demo()\n\n\nimport matplotlib.pyplot as plt\ndef pyplot_draw_point_cloud(points, output_filename):\n    """""" points is a Nx3 numpy array """"""\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection=\'3d\')\n    ax.scatter(points[:,0], points[:,1], points[:,2])\n    ax.set_xlabel(\'x\')\n    ax.set_ylabel(\'y\')\n    ax.set_zlabel(\'z\')\n    #savefig(output_filename)\n\ndef pyplot_draw_volume(vol, output_filename):\n    """""" vol is of size vsize*vsize*vsize\n        output an image to output_filename\n    """"""\n    points = volume_to_point_cloud(vol)\n    pyplot_draw_point_cloud(points, output_filename)\n'"
src/pointnet/utils/tf_util.py,0,"b'"""""" Wrapper functions for TensorFlow layers.\n\nAuthor: Charles R. Qi\nDate: November 2016\n""""""\n\nimport numpy as np\nimport tensorflow as tf\n\ndef _variable_on_cpu(name, shape, initializer, use_fp16=False):\n  """"""Helper to create a Variable stored on CPU memory.\n  Args:\n    name: name of the variable\n    shape: list of ints\n    initializer: initializer for Variable\n  Returns:\n    Variable Tensor\n  """"""\n  with tf.device(\'/cpu:0\'):\n    dtype = tf.float16 if use_fp16 else tf.float32\n    var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n  return var\n\ndef _variable_with_weight_decay(name, shape, stddev, wd, use_xavier=True):\n  """"""Helper to create an initialized Variable with weight decay.\n\n  Note that the Variable is initialized with a truncated normal distribution.\n  A weight decay is added only if one is specified.\n\n  Args:\n    name: name of the variable\n    shape: list of ints\n    stddev: standard deviation of a truncated Gaussian\n    wd: add L2Loss weight decay multiplied by this float. If None, weight\n        decay is not added for this Variable.\n    use_xavier: bool, whether to use xavier initializer\n\n  Returns:\n    Variable Tensor\n  """"""\n  if use_xavier:\n    initializer = tf.contrib.layers.xavier_initializer()\n  else:\n    initializer = tf.truncated_normal_initializer(stddev=stddev)\n  var = _variable_on_cpu(name, shape, initializer)\n  if wd is not None:\n    weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name=\'weight_loss\')\n    tf.add_to_collection(\'losses\', weight_decay)\n  return var\n\n\ndef conv1d(inputs,\n           num_output_channels,\n           kernel_size,\n           scope,\n           stride=1,\n           padding=\'SAME\',\n           use_xavier=True,\n           stddev=1e-3,\n           weight_decay=0.0,\n           activation_fn=tf.nn.relu,\n           bn=False,\n           bn_decay=None,\n           is_training=None):\n  """""" 1D convolution with non-linear operation.\n\n  Args:\n    inputs: 3-D tensor variable BxLxC\n    num_output_channels: int\n    kernel_size: int\n    scope: string\n    stride: int\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    num_in_channels = inputs.get_shape()[-1].value\n    kernel_shape = [kernel_size,\n                    num_in_channels, num_output_channels]\n    kernel = _variable_with_weight_decay(\'weights\',\n                                         shape=kernel_shape,\n                                         use_xavier=use_xavier,\n                                         stddev=stddev,\n                                         wd=weight_decay)\n    outputs = tf.nn.conv1d(inputs, kernel,\n                           stride=stride,\n                           padding=padding)\n    biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                              tf.constant_initializer(0.0))\n    outputs = tf.nn.bias_add(outputs, biases)\n\n    if bn:\n      outputs = batch_norm_for_conv1d(outputs, is_training,\n                                      bn_decay=bn_decay, scope=\'bn\')\n\n    if activation_fn is not None:\n      outputs = activation_fn(outputs)\n    return outputs\n\n\n\n\ndef conv2d(inputs,\n           num_output_channels,\n           kernel_size,\n           scope,\n           stride=[1, 1],\n           padding=\'SAME\',\n           use_xavier=True,\n           stddev=1e-3,\n           weight_decay=0.0,\n           activation_fn=tf.nn.relu,\n           bn=False,\n           bn_decay=None,\n           is_training=None):\n  """""" 2D convolution with non-linear operation.\n\n  Args:\n    inputs: 4-D tensor variable BxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 2 ints\n    scope: string\n    stride: a list of 2 ints\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n      kernel_h, kernel_w = kernel_size\n      num_in_channels = inputs.get_shape()[-1].value\n      kernel_shape = [kernel_h, kernel_w,\n                      num_in_channels, num_output_channels]\n      kernel = _variable_with_weight_decay(\'weights\',\n                                           shape=kernel_shape,\n                                           use_xavier=use_xavier,\n                                           stddev=stddev,\n                                           wd=weight_decay)\n      stride_h, stride_w = stride\n      outputs = tf.nn.conv2d(inputs, kernel,\n                             [1, stride_h, stride_w, 1],\n                             padding=padding)\n      biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                                tf.constant_initializer(0.0))\n      outputs = tf.nn.bias_add(outputs, biases)\n\n      if bn:\n        outputs = batch_norm_for_conv2d(outputs, is_training,\n                                        bn_decay=bn_decay, scope=\'bn\')\n        #outputs = tf.contrib.layers.batch_norm(outputs, is_training = is_training, decay = (bn_decay if bn_decay is not None else 0.9), scope = ""bn"")\n\n      if activation_fn is not None:\n        outputs = activation_fn(outputs)\n      return outputs\n\n\ndef conv2d_transpose(inputs,\n                     num_output_channels,\n                     kernel_size,\n                     scope,\n                     stride=[1, 1],\n                     padding=\'SAME\',\n                     use_xavier=True,\n                     stddev=1e-3,\n                     weight_decay=0.0,\n                     activation_fn=tf.nn.relu,\n                     bn=False,\n                     bn_decay=None,\n                     is_training=None):\n  """""" 2D convolution transpose with non-linear operation.\n\n  Args:\n    inputs: 4-D tensor variable BxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 2 ints\n    scope: string\n    stride: a list of 2 ints\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n\n  Note: conv2d(conv2d_transpose(a, num_out, ksize, stride), a.shape[-1], ksize, stride) == a\n  """"""\n  with tf.variable_scope(scope) as sc:\n      kernel_h, kernel_w = kernel_size\n      num_in_channels = inputs.get_shape()[-1].value\n      kernel_shape = [kernel_h, kernel_w,\n                      num_output_channels, num_in_channels] # reversed to conv2d\n      kernel = _variable_with_weight_decay(\'weights\',\n                                           shape=kernel_shape,\n                                           use_xavier=use_xavier,\n                                           stddev=stddev,\n                                           wd=weight_decay)\n      stride_h, stride_w = stride\n      \n      # from slim.convolution2d_transpose\n      def get_deconv_dim(dim_size, stride_size, kernel_size, padding):\n          dim_size *= stride_size\n\n          if padding == \'VALID\' and dim_size is not None:\n            dim_size += max(kernel_size - stride_size, 0)\n          return dim_size\n\n      # caculate output shape\n      batch_size = inputs.get_shape()[0].value\n      height = inputs.get_shape()[1].value\n      width = inputs.get_shape()[2].value\n      out_height = get_deconv_dim(height, stride_h, kernel_h, padding)\n      out_width = get_deconv_dim(width, stride_w, kernel_w, padding)\n      output_shape = [batch_size, out_height, out_width, num_output_channels]\n\n      outputs = tf.nn.conv2d_transpose(inputs, kernel, output_shape,\n                             [1, stride_h, stride_w, 1],\n                             padding=padding)\n      biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                                tf.constant_initializer(0.0))\n      outputs = tf.nn.bias_add(outputs, biases)\n\n      if bn:\n        outputs = batch_norm_for_conv2d(outputs, is_training,\n                                        bn_decay=bn_decay, scope=\'bn\')\n\n      if activation_fn is not None:\n        outputs = activation_fn(outputs)\n      return outputs\n\n   \n\ndef conv3d(inputs,\n           num_output_channels,\n           kernel_size,\n           scope,\n           stride=[1, 1, 1],\n           padding=\'SAME\',\n           use_xavier=True,\n           stddev=1e-3,\n           weight_decay=0.0,\n           activation_fn=tf.nn.relu,\n           bn=False,\n           bn_decay=None,\n           is_training=None):\n  """""" 3D convolution with non-linear operation.\n\n  Args:\n    inputs: 5-D tensor variable BxDxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 3 ints\n    scope: string\n    stride: a list of 3 ints\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_d, kernel_h, kernel_w = kernel_size\n    num_in_channels = inputs.get_shape()[-1].value\n    kernel_shape = [kernel_d, kernel_h, kernel_w,\n                    num_in_channels, num_output_channels]\n    kernel = _variable_with_weight_decay(\'weights\',\n                                         shape=kernel_shape,\n                                         use_xavier=use_xavier,\n                                         stddev=stddev,\n                                         wd=weight_decay)\n    stride_d, stride_h, stride_w = stride\n    outputs = tf.nn.conv3d(inputs, kernel,\n                           [1, stride_d, stride_h, stride_w, 1],\n                           padding=padding)\n    biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                              tf.constant_initializer(0.0))\n    outputs = tf.nn.bias_add(outputs, biases)\n    \n    if bn:\n      outputs = batch_norm_for_conv3d(outputs, is_training,\n                                      bn_decay=bn_decay, scope=\'bn\')\n\n    if activation_fn is not None:\n      outputs = activation_fn(outputs)\n    return outputs\n\ndef fully_connected(inputs,\n                    num_outputs,\n                    scope,\n                    use_xavier=True,\n                    stddev=1e-3,\n                    weight_decay=0.0,\n                    activation_fn=tf.nn.relu,\n                    bn=False,\n                    bn_decay=None,\n                    is_training=None):\n  """""" Fully connected layer with non-linear operation.\n  \n  Args:\n    inputs: 2-D tensor BxN\n    num_outputs: int\n  \n  Returns:\n    Variable tensor of size B x num_outputs.\n  """"""\n  with tf.variable_scope(scope) as sc:\n    num_input_units = inputs.get_shape()[-1].value\n    weights = _variable_with_weight_decay(\'weights\',\n                                          shape=[num_input_units, num_outputs],\n                                          use_xavier=use_xavier,\n                                          stddev=stddev,\n                                          wd=weight_decay)\n    outputs = tf.matmul(inputs, weights)\n    biases = _variable_on_cpu(\'biases\', [num_outputs],\n                             tf.constant_initializer(0.0))\n    outputs = tf.nn.bias_add(outputs, biases)\n     \n    if bn:\n      outputs = batch_norm_for_fc(outputs, is_training, bn_decay, \'bn\')\n      #outputs = tf.contrib.layers.batch_norm(outputs, is_training = is_training, decay = (bn_decay if bn_decay is not None else 0.9), scope = ""bn"")\n\n    if activation_fn is not None:\n      outputs = activation_fn(outputs)\n    return outputs\n\n\ndef max_pool2d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2],\n               padding=\'VALID\'):\n  """""" 2D max pooling.\n\n  Args:\n    inputs: 4-D tensor BxHxWxC\n    kernel_size: a list of 2 ints\n    stride: a list of 2 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_h, kernel_w = kernel_size\n    stride_h, stride_w = stride\n    outputs = tf.nn.max_pool(inputs,\n                             ksize=[1, kernel_h, kernel_w, 1],\n                             strides=[1, stride_h, stride_w, 1],\n                             padding=padding,\n                             name=sc.name)\n    return outputs\n\ndef avg_pool2d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2],\n               padding=\'VALID\'):\n  """""" 2D avg pooling.\n\n  Args:\n    inputs: 4-D tensor BxHxWxC\n    kernel_size: a list of 2 ints\n    stride: a list of 2 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_h, kernel_w = kernel_size\n    stride_h, stride_w = stride\n    outputs = tf.nn.avg_pool(inputs,\n                             ksize=[1, kernel_h, kernel_w, 1],\n                             strides=[1, stride_h, stride_w, 1],\n                             padding=padding,\n                             name=sc.name)\n    return outputs\n\n\ndef max_pool3d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2, 2],\n               padding=\'VALID\'):\n  """""" 3D max pooling.\n\n  Args:\n    inputs: 5-D tensor BxDxHxWxC\n    kernel_size: a list of 3 ints\n    stride: a list of 3 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_d, kernel_h, kernel_w = kernel_size\n    stride_d, stride_h, stride_w = stride\n    outputs = tf.nn.max_pool3d(inputs,\n                               ksize=[1, kernel_d, kernel_h, kernel_w, 1],\n                               strides=[1, stride_d, stride_h, stride_w, 1],\n                               padding=padding,\n                               name=sc.name)\n    return outputs\n\ndef avg_pool3d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2, 2],\n               padding=\'VALID\'):\n  """""" 3D avg pooling.\n\n  Args:\n    inputs: 5-D tensor BxDxHxWxC\n    kernel_size: a list of 3 ints\n    stride: a list of 3 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_d, kernel_h, kernel_w = kernel_size\n    stride_d, stride_h, stride_w = stride\n    outputs = tf.nn.avg_pool3d(inputs,\n                               ksize=[1, kernel_d, kernel_h, kernel_w, 1],\n                               strides=[1, stride_d, stride_h, stride_w, 1],\n                               padding=padding,\n                               name=sc.name)\n    return outputs\n\n\n\n\n\ndef batch_norm_template(inputs, is_training, scope, moments_dims, bn_decay):\n  """""" Batch normalization on convolutional maps and beyond...\n  Ref.: http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n  \n  Args:\n      inputs:        Tensor, k-D input ... x C could be BC or BHWC or BDHWC\n      is_training:   boolean tf.Varialbe, true indicates training phase\n      scope:         string, variable scope\n      moments_dims:  a list of ints, indicating dimensions for moments calculation\n      bn_decay:      float or float tensor variable, controling moving average weight\n  Return:\n      normed:        batch-normalized maps\n  """"""\n  decay = bn_decay if bn_decay is not None else 0.9\n  return tf.contrib.layers.batch_norm(inputs, center = True, scale = True, decay = decay, is_training = is_training, scope = scope, updates_collections = None)\n  # with tf.variable_scope(scope) as sc:\n  #   num_channels = inputs.get_shape()[-1].value\n  #   # beta = tf.Variable(tf.constant(0.0, shape=[num_channels]),\n  #   #                    name=\'beta\', trainable=True)\n  #   # gamma = tf.Variable(tf.constant(1.0, shape=[num_channels]),\n  #   #                     name=\'gamma\', trainable=True)\n  #   beta = tf.get_variable(""beta"", shape = [num_channels], trainable = True, initializer = tf.zeros_initializer)\n  #   gamma = tf.get_variable(""gamma"", shape = [num_channels], trainable = True, initializer = tf.ones_initializer)\n  #   batch_mean, batch_var = tf.nn.moments(inputs, moments_dims, name=\'moments\')\n  #   decay = bn_decay if bn_decay is not None else 0.9\n  #   ema = tf.train.ExponentialMovingAverage(decay=decay)\n  #   # Operator that maintains moving averages of variables.\n  #   def apply_fn():\n  #     return ema.apply([batch_mean, batch_var])\n  #   ema_apply_op = tf.cond(is_training,\n  #                         apply_fn,\n  #                         lambda: tf.no_op())\n  \n  #   # Update moving average and return current batch\'s avg and var.\n  #   def mean_var_with_update():\n  #     with tf.control_dependencies([ema_apply_op]):\n  #       return tf.identity(batch_mean), tf.identity(batch_var)\n    \n  #   def not_training_update():\n  #     return ema.average(batch_mean), ema.average(batch_var)\n\n  #   # ema.average returns the Variable holding the average of var.\n  #   mean, var = tf.cond(is_training,\n  #                       mean_var_with_update,\n  #                       not_training_update)\n  #   normed = tf.nn.batch_normalization(inputs, mean, var, beta, gamma, 1e-3)\n  # return normed\n\n\ndef batch_norm_for_fc(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on FC data.\n  \n  Args:\n      inputs:      Tensor, 2D BxC input\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,], bn_decay)\n\n\ndef batch_norm_for_conv1d(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on 1D convolutional maps.\n  \n  Args:\n      inputs:      Tensor, 3D BLC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,1], bn_decay)\n\n\n\n  \ndef batch_norm_for_conv2d(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on 2D convolutional maps.\n  \n  Args:\n      inputs:      Tensor, 4D BHWC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,1,2], bn_decay)\n\n\n\ndef batch_norm_for_conv3d(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on 3D convolutional maps.\n  \n  Args:\n      inputs:      Tensor, 5D BDHWC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,1,2,3], bn_decay)\n\n\ndef dropout(inputs,\n            is_training,\n            scope,\n            keep_prob=0.5,\n            noise_shape=None):\n  """""" Dropout layer.\n\n  Args:\n    inputs: tensor\n    is_training: boolean tf.Variable\n    scope: string\n    keep_prob: float in [0,1]\n    noise_shape: list of ints\n\n  Returns:\n    tensor variable\n  """"""\n  with tf.variable_scope(scope) as sc:\n    outputs = tf.cond(is_training,\n                      lambda: tf.nn.dropout(inputs, keep_prob, noise_shape),\n                      lambda: inputs)\n    return outputs\n'"
src/pointnet2/models/pointnet2_cls_ssg.py,0,"b'""""""\n    PointNet++ Model for point clouds classification\n""""""\n\nimport os\nimport sys\nBASE_DIR = os.path.dirname(__file__)\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, \'../utils\'))\nimport tensorflow as tf\nimport numpy as np\nimport tf_util\nfrom pointnet_util import pointnet_sa_module\n\ndef placeholder_inputs(batch_size, num_point):\n    pointclouds_pl = tf.placeholder(tf.float32, shape=(batch_size, num_point, 3))\n    labels_pl = tf.placeholder(tf.int32, shape=(batch_size))\n    return pointclouds_pl, labels_pl\n\ndef get_model(point_cloud, is_training, bn_decay=None, num_classes = 40):\n    """""" Classification PointNet, input is BxNx3, output Bx40 """"""\n    batch_size = point_cloud.get_shape()[0].value\n    num_point = point_cloud.get_shape()[1].value\n    end_points = {}\n    l0_xyz = point_cloud\n    l0_points = None\n    end_points[\'l0_xyz\'] = l0_xyz\n\n    # Set abstraction layers\n    # Note: When using NCHW for layer 2, we see increased GPU memory usage (in TF1.4).\n    # So we only use NCHW for layer 1 until this issue can be resolved.\n    l1_xyz, l1_points, l1_indices = pointnet_sa_module(l0_xyz, l0_points, npoint=512, radius=0.2, nsample=32, mlp=[64,64,128], mlp2=None, group_all=False, is_training=is_training, bn_decay=bn_decay, scope=\'layer1\', use_nchw=True)\n    l2_xyz, l2_points, l2_indices = pointnet_sa_module(l1_xyz, l1_points, npoint=128, radius=0.4, nsample=64, mlp=[128,128,256], mlp2=None, group_all=False, is_training=is_training, bn_decay=bn_decay, scope=\'layer2\')\n    l3_xyz, l3_points, l3_indices = pointnet_sa_module(l2_xyz, l2_points, npoint=None, radius=None, nsample=None, mlp=[256,512,1024], mlp2=None, group_all=True, is_training=is_training, bn_decay=bn_decay, scope=\'layer3\')\n\n    # Fully connected layers\n    net = tf.reshape(l3_points, [batch_size, -1])\n    features = tf.identity(net, name = ""feature_vector"")\n    net = tf_util.fully_connected(net, 512, bn=True, is_training=is_training, scope=\'fc1\', bn_decay=bn_decay)\n    net = tf_util.dropout(net, keep_prob=0.5, is_training=is_training, scope=\'dp1\')\n    net = tf_util.fully_connected(net, 256, bn=True, is_training=is_training, scope=\'fc2\', bn_decay=bn_decay)\n    net = tf_util.dropout(net, keep_prob=0.5, is_training=is_training, scope=\'dp2\')\n    net = tf_util.fully_connected(net, num_classes, activation_fn=None, scope=\'fc3\')\n\n    return net, end_points\n\n\ndef get_loss(pred, label, end_points):\n    """""" pred: B*NUM_CLASSES,\n        label: B, """"""\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)\n    classify_loss = tf.reduce_mean(loss)\n    tf.summary.scalar(\'classify loss\', classify_loss)\n    tf.add_to_collection(\'losses\', classify_loss)\n    return classify_loss\n\n\nif __name__==\'__main__\':\n    with tf.Graph().as_default():\n        inputs = tf.zeros((32,1024,3))\n        output, _ = get_model(inputs, tf.constant(True))\n        print(output)\n'"
src/pointnet2/utils/eulerangles.py,26,"b'# emacs: -*- mode: python-mode; py-indent-offset: 4; indent-tabs-mode: nil -*-\n# vi: set ft=python sts=4 ts=4 sw=4 et:\n### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ##\n#\n#   See COPYING file distributed along with the NiBabel package for the\n#   copyright and license terms.\n#\n### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ##\n\'\'\' Module implementing Euler angle rotations and their conversions\n\nSee:\n\n* http://en.wikipedia.org/wiki/Rotation_matrix\n* http://en.wikipedia.org/wiki/Euler_angles\n* http://mathworld.wolfram.com/EulerAngles.html\n\nSee also: *Representing Attitude with Euler Angles and Quaternions: A\nReference* (2006) by James Diebel. A cached PDF link last found here:\n\nhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.110.5134\n\nEuler\'s rotation theorem tells us that any rotation in 3D can be\ndescribed by 3 angles.  Let\'s call the 3 angles the *Euler angle vector*\nand call the angles in the vector :math:`alpha`, :math:`beta` and\n:math:`gamma`.  The vector is [ :math:`alpha`,\n:math:`beta`. :math:`gamma` ] and, in this description, the order of the\nparameters specifies the order in which the rotations occur (so the\nrotation corresponding to :math:`alpha` is applied first).\n\nIn order to specify the meaning of an *Euler angle vector* we need to\nspecify the axes around which each of the rotations corresponding to\n:math:`alpha`, :math:`beta` and :math:`gamma` will occur.\n\nThere are therefore three axes for the rotations :math:`alpha`,\n:math:`beta` and :math:`gamma`; let\'s call them :math:`i` :math:`j`,\n:math:`k`.\n\nLet us express the rotation :math:`alpha` around axis `i` as a 3 by 3\nrotation matrix `A`.  Similarly :math:`beta` around `j` becomes 3 x 3\nmatrix `B` and :math:`gamma` around `k` becomes matrix `G`.  Then the\nwhole rotation expressed by the Euler angle vector [ :math:`alpha`,\n:math:`beta`. :math:`gamma` ], `R` is given by::\n\n   R = np.dot(G, np.dot(B, A))\n\nSee http://mathworld.wolfram.com/EulerAngles.html\n\nThe order :math:`G B A` expresses the fact that the rotations are\nperformed in the order of the vector (:math:`alpha` around axis `i` =\n`A` first).\n\nTo convert a given Euler angle vector to a meaningful rotation, and a\nrotation matrix, we need to define:\n\n* the axes `i`, `j`, `k`\n* whether a rotation matrix should be applied on the left of a vector to\n  be transformed (vectors are column vectors) or on the right (vectors\n  are row vectors).\n* whether the rotations move the axes as they are applied (intrinsic\n  rotations) - compared the situation where the axes stay fixed and the\n  vectors move within the axis frame (extrinsic)\n* the handedness of the coordinate system\n\nSee: http://en.wikipedia.org/wiki/Rotation_matrix#Ambiguities\n\nWe are using the following conventions:\n\n* axes `i`, `j`, `k` are the `z`, `y`, and `x` axes respectively.  Thus\n  an Euler angle vector [ :math:`alpha`, :math:`beta`. :math:`gamma` ]\n  in our convention implies a :math:`alpha` radian rotation around the\n  `z` axis, followed by a :math:`beta` rotation around the `y` axis,\n  followed by a :math:`gamma` rotation around the `x` axis.\n* the rotation matrix applies on the left, to column vectors on the\n  right, so if `R` is the rotation matrix, and `v` is a 3 x N matrix\n  with N column vectors, the transformed vector set `vdash` is given by\n  ``vdash = np.dot(R, v)``.\n* extrinsic rotations - the axes are fixed, and do not move with the\n  rotations.\n* a right-handed coordinate system\n\nThe convention of rotation around ``z``, followed by rotation around\n``y``, followed by rotation around ``x``, is known (confusingly) as\n""xyz"", pitch-roll-yaw, Cardan angles, or Tait-Bryan angles.\n\'\'\'\n\nimport math\n\nimport sys\nif sys.version_info >= (3,0):\n    from functools import reduce\n\nimport numpy as np\n\n\n_FLOAT_EPS_4 = np.finfo(float).eps * 4.0\n\n\ndef euler2mat(z=0, y=0, x=0):\n    \'\'\' Return matrix for rotations around z, y and x axes\n\n    Uses the z, then y, then x convention above\n\n    Parameters\n    ----------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Returns\n    -------\n    M : array shape (3,3)\n       Rotation matrix giving same rotation as for given angles\n\n    Examples\n    --------\n    >>> zrot = 1.3 # radians\n    >>> yrot = -0.1\n    >>> xrot = 0.2\n    >>> M = euler2mat(zrot, yrot, xrot)\n    >>> M.shape == (3, 3)\n    True\n\n    The output rotation matrix is equal to the composition of the\n    individual rotations\n\n    >>> M1 = euler2mat(zrot)\n    >>> M2 = euler2mat(0, yrot)\n    >>> M3 = euler2mat(0, 0, xrot)\n    >>> composed_M = np.dot(M3, np.dot(M2, M1))\n    >>> np.allclose(M, composed_M)\n    True\n\n    You can specify rotations by named arguments\n\n    >>> np.all(M3 == euler2mat(x=xrot))\n    True\n\n    When applying M to a vector, the vector should column vector to the\n    right of M.  If the right hand side is a 2D array rather than a\n    vector, then each column of the 2D array represents a vector.\n\n    >>> vec = np.array([1, 0, 0]).reshape((3,1))\n    >>> v2 = np.dot(M, vec)\n    >>> vecs = np.array([[1, 0, 0],[0, 1, 0]]).T # giving 3x2 array\n    >>> vecs2 = np.dot(M, vecs)\n\n    Rotations are counter-clockwise.\n\n    >>> zred = np.dot(euler2mat(z=np.pi/2), np.eye(3))\n    >>> np.allclose(zred, [[0, -1, 0],[1, 0, 0], [0, 0, 1]])\n    True\n    >>> yred = np.dot(euler2mat(y=np.pi/2), np.eye(3))\n    >>> np.allclose(yred, [[0, 0, 1],[0, 1, 0], [-1, 0, 0]])\n    True\n    >>> xred = np.dot(euler2mat(x=np.pi/2), np.eye(3))\n    >>> np.allclose(xred, [[1, 0, 0],[0, 0, -1], [0, 1, 0]])\n    True\n\n    Notes\n    -----\n    The direction of rotation is given by the right-hand rule (orient\n    the thumb of the right hand along the axis around which the rotation\n    occurs, with the end of the thumb at the positive end of the axis;\n    curl your fingers; the direction your fingers curl is the direction\n    of rotation).  Therefore, the rotations are counterclockwise if\n    looking along the axis of rotation from positive to negative.\n    \'\'\'\n    Ms = []\n    if z:\n        cosz = math.cos(z)\n        sinz = math.sin(z)\n        Ms.append(np.array(\n                [[cosz, -sinz, 0],\n                 [sinz, cosz, 0],\n                 [0, 0, 1]]))\n    if y:\n        cosy = math.cos(y)\n        siny = math.sin(y)\n        Ms.append(np.array(\n                [[cosy, 0, siny],\n                 [0, 1, 0],\n                 [-siny, 0, cosy]]))\n    if x:\n        cosx = math.cos(x)\n        sinx = math.sin(x)\n        Ms.append(np.array(\n                [[1, 0, 0],\n                 [0, cosx, -sinx],\n                 [0, sinx, cosx]]))\n    if Ms:\n        return reduce(np.dot, Ms[::-1])\n    return np.eye(3)\n\n\ndef mat2euler(M, cy_thresh=None):\n    \'\'\' Discover Euler angle vector from 3x3 matrix\n\n    Uses the conventions above.\n\n    Parameters\n    ----------\n    M : array-like, shape (3,3)\n    cy_thresh : None or scalar, optional\n       threshold below which to give up on straightforward arctan for\n       estimating x rotation.  If None (default), estimate from\n       precision of input.\n\n    Returns\n    -------\n    z : scalar\n    y : scalar\n    x : scalar\n       Rotations in radians around z, y, x axes, respectively\n\n    Notes\n    -----\n    If there was no numerical error, the routine could be derived using\n    Sympy expression for z then y then x rotation matrix, which is::\n\n      [                       cos(y)*cos(z),                       -cos(y)*sin(z),         sin(y)],\n      [cos(x)*sin(z) + cos(z)*sin(x)*sin(y), cos(x)*cos(z) - sin(x)*sin(y)*sin(z), -cos(y)*sin(x)],\n      [sin(x)*sin(z) - cos(x)*cos(z)*sin(y), cos(z)*sin(x) + cos(x)*sin(y)*sin(z),  cos(x)*cos(y)]\n\n    with the obvious derivations for z, y, and x\n\n       z = atan2(-r12, r11)\n       y = asin(r13)\n       x = atan2(-r23, r33)\n\n    Problems arise when cos(y) is close to zero, because both of::\n\n       z = atan2(cos(y)*sin(z), cos(y)*cos(z))\n       x = atan2(cos(y)*sin(x), cos(x)*cos(y))\n\n    will be close to atan2(0, 0), and highly unstable.\n\n    The ``cy`` fix for numerical instability below is from: *Graphics\n    Gems IV*, Paul Heckbert (editor), Academic Press, 1994, ISBN:\n    0123361559.  Specifically it comes from EulerAngles.c by Ken\n    Shoemake, and deals with the case where cos(y) is close to zero:\n\n    See: http://www.graphicsgems.org/\n\n    The code appears to be licensed (from the website) as ""can be used\n    without restrictions"".\n    \'\'\'\n    M = np.asarray(M)\n    if cy_thresh is None:\n        try:\n            cy_thresh = np.finfo(M.dtype).eps * 4\n        except ValueError:\n            cy_thresh = _FLOAT_EPS_4\n    r11, r12, r13, r21, r22, r23, r31, r32, r33 = M.flat\n    # cy: sqrt((cos(y)*cos(z))**2 + (cos(x)*cos(y))**2)\n    cy = math.sqrt(r33*r33 + r23*r23)\n    if cy > cy_thresh: # cos(y) not close to zero, standard form\n        z = math.atan2(-r12,  r11) # atan2(cos(y)*sin(z), cos(y)*cos(z))\n        y = math.atan2(r13,  cy) # atan2(sin(y), cy)\n        x = math.atan2(-r23, r33) # atan2(cos(y)*sin(x), cos(x)*cos(y))\n    else: # cos(y) (close to) zero, so x -> 0.0 (see above)\n        # so r21 -> sin(z), r22 -> cos(z) and\n        z = math.atan2(r21,  r22)\n        y = math.atan2(r13,  cy) # atan2(sin(y), cy)\n        x = 0.0\n    return z, y, x\n\n\ndef euler2quat(z=0, y=0, x=0):\n    \'\'\' Return quaternion corresponding to these Euler angles\n\n    Uses the z, then y, then x convention above\n\n    Parameters\n    ----------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Returns\n    -------\n    quat : array shape (4,)\n       Quaternion in w, x, y z (real, then vector) format\n\n    Notes\n    -----\n    We can derive this formula in Sympy using:\n\n    1. Formula giving quaternion corresponding to rotation of theta radians\n       about arbitrary axis:\n       http://mathworld.wolfram.com/EulerParameters.html\n    2. Generated formulae from 1.) for quaternions corresponding to\n       theta radians rotations about ``x, y, z`` axes\n    3. Apply quaternion multiplication formula -\n       http://en.wikipedia.org/wiki/Quaternions#Hamilton_product - to\n       formulae from 2.) to give formula for combined rotations.\n    \'\'\'\n    z = z/2.0\n    y = y/2.0\n    x = x/2.0\n    cz = math.cos(z)\n    sz = math.sin(z)\n    cy = math.cos(y)\n    sy = math.sin(y)\n    cx = math.cos(x)\n    sx = math.sin(x)\n    return np.array([\n             cx*cy*cz - sx*sy*sz,\n             cx*sy*sz + cy*cz*sx,\n             cx*cz*sy - sx*cy*sz,\n             cx*cy*sz + sx*cz*sy])\n\n\ndef quat2euler(q):\n    \'\'\' Return Euler angles corresponding to quaternion `q`\n\n    Parameters\n    ----------\n    q : 4 element sequence\n       w, x, y, z of quaternion\n\n    Returns\n    -------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Notes\n    -----\n    It\'s possible to reduce the amount of calculation a little, by\n    combining parts of the ``quat2mat`` and ``mat2euler`` functions, but\n    the reduction in computation is small, and the code repetition is\n    large.\n    \'\'\'\n    # delayed import to avoid cyclic dependencies\n    import nibabel.quaternions as nq\n    return mat2euler(nq.quat2mat(q))\n\n\ndef euler2angle_axis(z=0, y=0, x=0):\n    \'\'\' Return angle, axis corresponding to these Euler angles\n\n    Uses the z, then y, then x convention above\n\n    Parameters\n    ----------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Returns\n    -------\n    theta : scalar\n       angle of rotation\n    vector : array shape (3,)\n       axis around which rotation occurs\n\n    Examples\n    --------\n    >>> theta, vec = euler2angle_axis(0, 1.5, 0)\n    >>> print(theta)\n    1.5\n    >>> np.allclose(vec, [0, 1, 0])\n    True\n    \'\'\'\n    # delayed import to avoid cyclic dependencies\n    import nibabel.quaternions as nq\n    return nq.quat2angle_axis(euler2quat(z, y, x))\n\n\ndef angle_axis2euler(theta, vector, is_normalized=False):\n    \'\'\' Convert angle, axis pair to Euler angles\n\n    Parameters\n    ----------\n    theta : scalar\n       angle of rotation\n    vector : 3 element sequence\n       vector specifying axis for rotation.\n    is_normalized : bool, optional\n       True if vector is already normalized (has norm of 1).  Default\n       False\n\n    Returns\n    -------\n    z : scalar\n    y : scalar\n    x : scalar\n       Rotations in radians around z, y, x axes, respectively\n\n    Examples\n    --------\n    >>> z, y, x = angle_axis2euler(0, [1, 0, 0])\n    >>> np.allclose((z, y, x), 0)\n    True\n\n    Notes\n    -----\n    It\'s possible to reduce the amount of calculation a little, by\n    combining parts of the ``angle_axis2mat`` and ``mat2euler``\n    functions, but the reduction in computation is small, and the code\n    repetition is large.\n    \'\'\'\n    # delayed import to avoid cyclic dependencies\n    import nibabel.quaternions as nq\n    M = nq.angle_axis2mat(theta, vector, is_normalized)\n    return mat2euler(M)\n'"
src/pointnet2/utils/pc_util.py,30,"b'"""""" Utility functions for processing point clouds.\n\nAuthor: Charles R. Qi, Hao Su\nDate: November 2016\n""""""\n\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\n\n# Draw point cloud\nfrom eulerangles import euler2mat\n\n# Point cloud IO\nimport numpy as np\nfrom plyfile import PlyData, PlyElement\n\n \n# ----------------------------------------\n# Point Cloud/Volume Conversions\n# ----------------------------------------\n\ndef point_cloud_to_volume_batch(point_clouds, vsize=12, radius=1.0, flatten=True):\n    """""" Input is BxNx3 batch of point cloud\n        Output is Bx(vsize^3)\n    """"""\n    vol_list = []\n    for b in range(point_clouds.shape[0]):\n        vol = point_cloud_to_volume(np.squeeze(point_clouds[b,:,:]), vsize, radius)\n        if flatten:\n            vol_list.append(vol.flatten())\n        else:\n            vol_list.append(np.expand_dims(np.expand_dims(vol, -1), 0))\n    if flatten:\n        return np.vstack(vol_list)\n    else:\n        return np.concatenate(vol_list, 0)\n\n\ndef point_cloud_to_volume(points, vsize, radius=1.0):\n    """""" input is Nx3 points.\n        output is vsize*vsize*vsize\n        assumes points are in range [-radius, radius]\n    """"""\n    vol = np.zeros((vsize,vsize,vsize))\n    voxel = 2*radius/float(vsize)\n    locations = (points + radius)/voxel\n    locations = locations.astype(int)\n    vol[locations[:,0],locations[:,1],locations[:,2]] = 1.0\n    return vol\n\n#a = np.zeros((16,1024,3))\n#print point_cloud_to_volume_batch(a, 12, 1.0, False).shape\n\ndef volume_to_point_cloud(vol):\n    """""" vol is occupancy grid (value = 0 or 1) of size vsize*vsize*vsize\n        return Nx3 numpy array.\n    """"""\n    vsize = vol.shape[0]\n    assert(vol.shape[1] == vsize and vol.shape[1] == vsize)\n    points = []\n    for a in range(vsize):\n        for b in range(vsize):\n            for c in range(vsize):\n                if vol[a,b,c] == 1:\n                    points.append(np.array([a,b,c]))\n    if len(points) == 0:\n        return np.zeros((0,3))\n    points = np.vstack(points)\n    return points\n\n# ----------------------------------------\n# Point cloud IO\n# ----------------------------------------\n\ndef read_ply(filename):\n    """""" read XYZ point cloud from filename PLY file """"""\n    plydata = PlyData.read(filename)\n    pc = plydata[\'vertex\'].data\n    pc_array = np.array([[x, y, z] for x,y,z in pc])\n    return pc_array\n\n\ndef write_ply(points, filename, text=True):\n    """""" input: Nx3, write points to filename as PLY format. """"""\n    points = [(points[i,0], points[i,1], points[i,2]) for i in range(points.shape[0])]\n    vertex = np.array(points, dtype=[(\'x\', \'f4\'), (\'y\', \'f4\'),(\'z\', \'f4\')])\n    el = PlyElement.describe(vertex, \'vertex\', comments=[\'vertices\'])\n    PlyData([el], text=text).write(filename)\n\n\n# ----------------------------------------\n# Simple Point cloud and Volume Renderers\n# ----------------------------------------\n\ndef draw_point_cloud(input_points, canvasSize=500, space=200, diameter=25,\n                     xrot=0, yrot=0, zrot=0, switch_xyz=[0,1,2], normalize=False):\n    """""" Render point cloud to image with alpha channel.\n        Input:\n            points: Nx3 numpy array (+y is up direction)\n        Output:\n            gray image as numpy array of size canvasSizexcanvasSize\n    """"""\n    image = np.zeros((canvasSize, canvasSize))\n    if input_points is None or input_points.shape[0] == 0:\n        return image\n\n    points = input_points[:, switch_xyz]\n    M = euler2mat(zrot, yrot, xrot)\n    points = (np.dot(M, points.transpose())).transpose()\n\n    # Normalize the point cloud\n    # We normalize scale to fit points in a unit sphere\n    if normalize:\n        centroid = np.mean(points, axis=0)\n        points -= centroid\n        furthest_distance = np.max(np.sqrt(np.sum(abs(points)**2,axis=-1)))\n        points /= furthest_distance\n    \n    dist = np.linalg.norm(points, axis = -1)\n    points = points[dist <= 1]\n\n    # Pre-compute the Gaussian disk\n    radius = (diameter-1)/2.0\n    disk = np.zeros((diameter, diameter))\n    for i in range(diameter):\n        for j in range(diameter):\n            if (i - radius) * (i-radius) + (j-radius) * (j-radius) <= radius * radius:\n                disk[i, j] = np.exp((-(i-radius)**2 - (j-radius)**2)/(radius**2))\n    mask = np.argwhere(disk > 0)\n    dx = mask[:, 0]\n    dy = mask[:, 1]\n    dv = disk[disk > 0]\n    \n    # Order points by z-buffer\n    zorder = np.argsort(points[:, 2])\n    points = points[zorder, :]\n    points[:, 2] = (points[:, 2] - np.min(points[:, 2])) / (np.max(points[:, 2] - np.min(points[:, 2])))\n    max_depth = np.max(points[:, 2])\n       \n    for i in range(points.shape[0]):\n        j = points.shape[0] - i - 1\n        x = points[j, 0]\n        y = points[j, 1]\n        xc = canvasSize/2 + (x*space)\n        yc = canvasSize/2 + (y*space)\n        xc = int(np.round(xc))\n        yc = int(np.round(yc))\n        \n        px = dx + xc\n        py = dy + yc\n        \n        image[px, py] = image[px, py] * 0.7 + dv * (max_depth - points[j, 2]) * 0.3\n    \n    image = image / np.max(image)\n    return image\n\ndef point_cloud_three_views(points):\n    """""" input points Nx3 numpy array (+y is up direction).\n        return an numpy array gray image of size 500x1500. """""" \n    # +y is up direction\n    # xrot is azimuth\n    # yrot is in-plane\n    # zrot is elevation\n    img1 = draw_point_cloud(points, zrot=110/180.0*np.pi, xrot=45/180.0*np.pi, yrot=0/180.0*np.pi)\n    img2 = draw_point_cloud(points, zrot=70/180.0*np.pi, xrot=135/180.0*np.pi, yrot=0/180.0*np.pi)\n    img3 = draw_point_cloud(points, zrot=180.0/180.0*np.pi, xrot=90/180.0*np.pi, yrot=0/180.0*np.pi)\n    image_large = np.concatenate([img1, img2, img3], 1)\n    return image_large\n\n\nfrom PIL import Image\ndef point_cloud_three_views_demo():\n    """""" Demo for draw_point_cloud function """"""\n    points = read_ply(\'../third_party/mesh_sampling/piano.ply\')\n    im_array = point_cloud_three_views(points)\n    img = Image.fromarray(np.uint8(im_array*255.0))\n    img.save(\'piano.jpg\')\n\nif __name__==""__main__"":\n    point_cloud_three_views_demo()\n\n\nimport matplotlib.pyplot as plt\ndef pyplot_draw_point_cloud(points, output_filename):\n    """""" points is a Nx3 numpy array """"""\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection=\'3d\')\n    ax.scatter(points[:,0], points[:,1], points[:,2])\n    ax.set_xlabel(\'x\')\n    ax.set_ylabel(\'y\')\n    ax.set_zlabel(\'z\')\n    #savefig(output_filename)\n\ndef pyplot_draw_volume(vol, output_filename):\n    """""" vol is of size vsize*vsize*vsize\n        output an image to output_filename\n    """"""\n    points = volume_to_point_cloud(vol)\n    pyplot_draw_point_cloud(points, output_filename)\n'"
src/pointnet2/utils/plyfile.py,18,"b'#   Copyright 2014 Darsh Ranjan\n#\n#   This file is part of python-plyfile.\n#\n#   python-plyfile is free software: you can redistribute it and/or\n#   modify it under the terms of the GNU General Public License as\n#   published by the Free Software Foundation, either version 3 of the\n#   License, or (at your option) any later version.\n#\n#   python-plyfile is distributed in the hope that it will be useful,\n#   but WITHOUT ANY WARRANTY; without even the implied warranty of\n#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n#   General Public License for more details.\n#\n#   You should have received a copy of the GNU General Public License\n#   along with python-plyfile.  If not, see\n#       <http://www.gnu.org/licenses/>.\n\nfrom itertools import islice as _islice\n\nimport numpy as _np\nfrom sys import byteorder as _byteorder\n\n\ntry:\n    _range = xrange\nexcept NameError:\n    _range = range\n\n\n# Many-many relation\n_data_type_relation = [\n    (\'int8\', \'i1\'),\n    (\'char\', \'i1\'),\n    (\'uint8\', \'u1\'),\n    (\'uchar\', \'b1\'),\n    (\'uchar\', \'u1\'),\n    (\'int16\', \'i2\'),\n    (\'short\', \'i2\'),\n    (\'uint16\', \'u2\'),\n    (\'ushort\', \'u2\'),\n    (\'int32\', \'i4\'),\n    (\'int\', \'i4\'),\n    (\'uint32\', \'u4\'),\n    (\'uint\', \'u4\'),\n    (\'float32\', \'f4\'),\n    (\'float\', \'f4\'),\n    (\'float64\', \'f8\'),\n    (\'double\', \'f8\')\n]\n\n_data_types = dict(_data_type_relation)\n_data_type_reverse = dict((b, a) for (a, b) in _data_type_relation)\n\n_types_list = []\n_types_set = set()\nfor (_a, _b) in _data_type_relation:\n    if _a not in _types_set:\n        _types_list.append(_a)\n        _types_set.add(_a)\n    if _b not in _types_set:\n        _types_list.append(_b)\n        _types_set.add(_b)\n\n\n_byte_order_map = {\n    \'ascii\': \'=\',\n    \'binary_little_endian\': \'<\',\n    \'binary_big_endian\': \'>\'\n}\n\n_byte_order_reverse = {\n    \'<\': \'binary_little_endian\',\n    \'>\': \'binary_big_endian\'\n}\n\n_native_byte_order = {\'little\': \'<\', \'big\': \'>\'}[_byteorder]\n\n\ndef _lookup_type(type_str):\n    if type_str not in _data_type_reverse:\n        try:\n            type_str = _data_types[type_str]\n        except KeyError:\n            raise ValueError(""field type %r not in %r"" %\n                             (type_str, _types_list))\n\n    return _data_type_reverse[type_str]\n\n\ndef _split_line(line, n):\n    fields = line.split(None, n)\n    if len(fields) == n:\n        fields.append(\'\')\n\n    assert len(fields) == n + 1\n\n    return fields\n\n\ndef make2d(array, cols=None, dtype=None):\n    \'\'\'\n    Make a 2D array from an array of arrays.  The `cols\' and `dtype\'\n    arguments can be omitted if the array is not empty.\n\n    \'\'\'\n    if (cols is None or dtype is None) and not len(array):\n        raise RuntimeError(""cols and dtype must be specified for empty ""\n                           ""array"")\n\n    if cols is None:\n        cols = len(array[0])\n\n    if dtype is None:\n        dtype = array[0].dtype\n\n    return _np.fromiter(array, [(\'_\', dtype, (cols,))],\n                        count=len(array))[\'_\']\n\n\nclass PlyParseError(Exception):\n\n    \'\'\'\n    Raised when a PLY file cannot be parsed.\n\n    The attributes `element\', `row\', `property\', and `message\' give\n    additional information.\n\n    \'\'\'\n\n    def __init__(self, message, element=None, row=None, prop=None):\n        self.message = message\n        self.element = element\n        self.row = row\n        self.prop = prop\n\n        s = \'\'\n        if self.element:\n            s += \'element %r: \' % self.element.name\n        if self.row is not None:\n            s += \'row %d: \' % self.row\n        if self.prop:\n            s += \'property %r: \' % self.prop.name\n        s += self.message\n\n        Exception.__init__(self, s)\n\n    def __repr__(self):\n        return (\'PlyParseError(%r, element=%r, row=%r, prop=%r)\' %\n                self.message, self.element, self.row, self.prop)\n\n\nclass PlyData(object):\n\n    \'\'\'\n    PLY file header and data.\n\n    A PlyData instance is created in one of two ways: by the static\n    method PlyData.read (to read a PLY file), or directly from __init__\n    given a sequence of elements (which can then be written to a PLY\n    file).\n\n    \'\'\'\n\n    def __init__(self, elements=[], text=False, byte_order=\'=\',\n                 comments=[], obj_info=[]):\n        \'\'\'\n        elements: sequence of PlyElement instances.\n\n        text: whether the resulting PLY file will be text (True) or\n            binary (False).\n\n        byte_order: \'<\' for little-endian, \'>\' for big-endian, or \'=\'\n            for native.  This is only relevant if `text\' is False.\n\n        comments: sequence of strings that will be placed in the header\n            between the \'ply\' and \'format ...\' lines.\n\n        obj_info: like comments, but will be placed in the header with\n            ""obj_info ..."" instead of ""comment ..."".\n\n        \'\'\'\n        if byte_order == \'=\' and not text:\n            byte_order = _native_byte_order\n\n        self.byte_order = byte_order\n        self.text = text\n\n        self.comments = list(comments)\n        self.obj_info = list(obj_info)\n        self.elements = elements\n\n    def _get_elements(self):\n        return self._elements\n\n    def _set_elements(self, elements):\n        self._elements = tuple(elements)\n        self._index()\n\n    elements = property(_get_elements, _set_elements)\n\n    def _get_byte_order(self):\n        return self._byte_order\n\n    def _set_byte_order(self, byte_order):\n        if byte_order not in [\'<\', \'>\', \'=\']:\n            raise ValueError(""byte order must be \'<\', \'>\', or \'=\'"")\n\n        self._byte_order = byte_order\n\n    byte_order = property(_get_byte_order, _set_byte_order)\n\n    def _index(self):\n        self._element_lookup = dict((elt.name, elt) for elt in\n                                    self._elements)\n        if len(self._element_lookup) != len(self._elements):\n            raise ValueError(""two elements with same name"")\n\n    @staticmethod\n    def _parse_header(stream):\n        \'\'\'\n        Parse a PLY header from a readable file-like stream.\n\n        \'\'\'\n        lines = []\n        comments = {\'comment\': [], \'obj_info\': []}\n        while True:\n            line = stream.readline().decode(\'ascii\').strip()\n            fields = _split_line(line, 1)\n\n            if fields[0] == \'end_header\':\n                break\n\n            elif fields[0] in comments.keys():\n                lines.append(fields)\n            else:\n                lines.append(line.split())\n\n        a = 0\n        if lines[a] != [\'ply\']:\n            raise PlyParseError(""expected \'ply\'"")\n\n        a += 1\n        while lines[a][0] in comments.keys():\n            comments[lines[a][0]].append(lines[a][1])\n            a += 1\n\n        if lines[a][0] != \'format\':\n            raise PlyParseError(""expected \'format\'"")\n\n        if lines[a][2] != \'1.0\':\n            raise PlyParseError(""expected version \'1.0\'"")\n\n        if len(lines[a]) != 3:\n            raise PlyParseError(""too many fields after \'format\'"")\n\n        fmt = lines[a][1]\n\n        if fmt not in _byte_order_map:\n            raise PlyParseError(""don\'t understand format %r"" % fmt)\n\n        byte_order = _byte_order_map[fmt]\n        text = fmt == \'ascii\'\n\n        a += 1\n        while a < len(lines) and lines[a][0] in comments.keys():\n            comments[lines[a][0]].append(lines[a][1])\n            a += 1\n\n        return PlyData(PlyElement._parse_multi(lines[a:]),\n                       text, byte_order,\n                       comments[\'comment\'], comments[\'obj_info\'])\n\n    @staticmethod\n    def read(stream):\n        \'\'\'\n        Read PLY data from a readable file-like object or filename.\n\n        \'\'\'\n        (must_close, stream) = _open_stream(stream, \'read\')\n        try:\n            data = PlyData._parse_header(stream)\n            for elt in data:\n                elt._read(stream, data.text, data.byte_order)\n        finally:\n            if must_close:\n                stream.close()\n\n        return data\n\n    def write(self, stream):\n        \'\'\'\n        Write PLY data to a writeable file-like object or filename.\n\n        \'\'\'\n        (must_close, stream) = _open_stream(stream, \'write\')\n        try:\n            stream.write(self.header.encode(\'ascii\'))\n            stream.write(b\'\\r\\n\')\n            for elt in self:\n                elt._write(stream, self.text, self.byte_order)\n        finally:\n            if must_close:\n                stream.close()\n\n    @property\n    def header(self):\n        \'\'\'\n        Provide PLY-formatted metadata for the instance.\n\n        \'\'\'\n        lines = [\'ply\']\n\n        if self.text:\n            lines.append(\'format ascii 1.0\')\n        else:\n            lines.append(\'format \' +\n                         _byte_order_reverse[self.byte_order] +\n                         \' 1.0\')\n\n        # Some information is lost here, since all comments are placed\n        # between the \'format\' line and the first element.\n        for c in self.comments:\n            lines.append(\'comment \' + c)\n\n        for c in self.obj_info:\n            lines.append(\'obj_info \' + c)\n\n        lines.extend(elt.header for elt in self.elements)\n        lines.append(\'end_header\')\n        return \'\\r\\n\'.join(lines)\n\n    def __iter__(self):\n        return iter(self.elements)\n\n    def __len__(self):\n        return len(self.elements)\n\n    def __contains__(self, name):\n        return name in self._element_lookup\n\n    def __getitem__(self, name):\n        return self._element_lookup[name]\n\n    def __str__(self):\n        return self.header\n\n    def __repr__(self):\n        return (\'PlyData(%r, text=%r, byte_order=%r, \'\n                \'comments=%r, obj_info=%r)\' %\n                (self.elements, self.text, self.byte_order,\n                 self.comments, self.obj_info))\n\n\ndef _open_stream(stream, read_or_write):\n    if hasattr(stream, read_or_write):\n        return (False, stream)\n    try:\n        return (True, open(stream, read_or_write[0] + \'b\'))\n    except TypeError:\n        raise RuntimeError(""expected open file or filename"")\n\n\nclass PlyElement(object):\n\n    \'\'\'\n    PLY file element.\n\n    A client of this library doesn\'t normally need to instantiate this\n    directly, so the following is only for the sake of documenting the\n    internals.\n\n    Creating a PlyElement instance is generally done in one of two ways:\n    as a byproduct of PlyData.read (when reading a PLY file) and by\n    PlyElement.describe (before writing a PLY file).\n\n    \'\'\'\n\n    def __init__(self, name, properties, count, comments=[]):\n        \'\'\'\n        This is not part of the public interface.  The preferred methods\n        of obtaining PlyElement instances are PlyData.read (to read from\n        a file) and PlyElement.describe (to construct from a numpy\n        array).\n\n        \'\'\'\n        self._name = str(name)\n        self._check_name()\n        self._count = count\n\n        self._properties = tuple(properties)\n        self._index()\n\n        self.comments = list(comments)\n\n        self._have_list = any(isinstance(p, PlyListProperty)\n                              for p in self.properties)\n\n    @property\n    def count(self):\n        return self._count\n\n    def _get_data(self):\n        return self._data\n\n    def _set_data(self, data):\n        self._data = data\n        self._count = len(data)\n        self._check_sanity()\n\n    data = property(_get_data, _set_data)\n\n    def _check_sanity(self):\n        for prop in self.properties:\n            if prop.name not in self._data.dtype.fields:\n                raise ValueError(""dangling property %r"" % prop.name)\n\n    def _get_properties(self):\n        return self._properties\n\n    def _set_properties(self, properties):\n        self._properties = tuple(properties)\n        self._check_sanity()\n        self._index()\n\n    properties = property(_get_properties, _set_properties)\n\n    def _index(self):\n        self._property_lookup = dict((prop.name, prop)\n                                     for prop in self._properties)\n        if len(self._property_lookup) != len(self._properties):\n            raise ValueError(""two properties with same name"")\n\n    def ply_property(self, name):\n        return self._property_lookup[name]\n\n    @property\n    def name(self):\n        return self._name\n\n    def _check_name(self):\n        if any(c.isspace() for c in self._name):\n            msg = ""element name %r contains spaces"" % self._name\n            raise ValueError(msg)\n\n    def dtype(self, byte_order=\'=\'):\n        \'\'\'\n        Return the numpy dtype of the in-memory representation of the\n        data.  (If there are no list properties, and the PLY format is\n        binary, then this also accurately describes the on-disk\n        representation of the element.)\n\n        \'\'\'\n        return [(prop.name, prop.dtype(byte_order))\n                for prop in self.properties]\n\n    @staticmethod\n    def _parse_multi(header_lines):\n        \'\'\'\n        Parse a list of PLY element definitions.\n\n        \'\'\'\n        elements = []\n        while header_lines:\n            (elt, header_lines) = PlyElement._parse_one(header_lines)\n            elements.append(elt)\n\n        return elements\n\n    @staticmethod\n    def _parse_one(lines):\n        \'\'\'\n        Consume one element definition.  The unconsumed input is\n        returned along with a PlyElement instance.\n\n        \'\'\'\n        a = 0\n        line = lines[a]\n\n        if line[0] != \'element\':\n            raise PlyParseError(""expected \'element\'"")\n        if len(line) > 3:\n            raise PlyParseError(""too many fields after \'element\'"")\n        if len(line) < 3:\n            raise PlyParseError(""too few fields after \'element\'"")\n\n        (name, count) = (line[1], int(line[2]))\n\n        comments = []\n        properties = []\n        while True:\n            a += 1\n            if a >= len(lines):\n                break\n\n            if lines[a][0] == \'comment\':\n                comments.append(lines[a][1])\n            elif lines[a][0] == \'property\':\n                properties.append(PlyProperty._parse_one(lines[a]))\n            else:\n                break\n\n        return (PlyElement(name, properties, count, comments),\n                lines[a:])\n\n    @staticmethod\n    def describe(data, name, len_types={}, val_types={},\n                 comments=[]):\n        \'\'\'\n        Construct a PlyElement from an array\'s metadata.\n\n        len_types and val_types can be given as mappings from list\n        property names to type strings (like \'u1\', \'f4\', etc., or\n        \'int8\', \'float32\', etc.). These can be used to define the length\n        and value types of list properties.  List property lengths\n        always default to type \'u1\' (8-bit unsigned integer), and value\n        types default to \'i4\' (32-bit integer).\n\n        \'\'\'\n        if not isinstance(data, _np.ndarray):\n            raise TypeError(""only numpy arrays are supported"")\n\n        if len(data.shape) != 1:\n            raise ValueError(""only one-dimensional arrays are ""\n                             ""supported"")\n\n        count = len(data)\n\n        properties = []\n        descr = data.dtype.descr\n\n        for t in descr:\n            if not isinstance(t[1], str):\n                raise ValueError(""nested records not supported"")\n\n            if not t[0]:\n                raise ValueError(""field with empty name"")\n\n            if len(t) != 2 or t[1][1] == \'O\':\n                # non-scalar field, which corresponds to a list\n                # property in PLY.\n\n                if t[1][1] == \'O\':\n                    if len(t) != 2:\n                        raise ValueError(""non-scalar object fields not ""\n                                         ""supported"")\n\n                len_str = _data_type_reverse[len_types.get(t[0], \'u1\')]\n                if t[1][1] == \'O\':\n                    val_type = val_types.get(t[0], \'i4\')\n                    val_str = _lookup_type(val_type)\n                else:\n                    val_str = _lookup_type(t[1][1:])\n\n                prop = PlyListProperty(t[0], len_str, val_str)\n            else:\n                val_str = _lookup_type(t[1][1:])\n                prop = PlyProperty(t[0], val_str)\n\n            properties.append(prop)\n\n        elt = PlyElement(name, properties, count, comments)\n        elt.data = data\n\n        return elt\n\n    def _read(self, stream, text, byte_order):\n        \'\'\'\n        Read the actual data from a PLY file.\n\n        \'\'\'\n        if text:\n            self._read_txt(stream)\n        else:\n            if self._have_list:\n                # There are list properties, so a simple load is\n                # impossible.\n                self._read_bin(stream, byte_order)\n            else:\n                # There are no list properties, so loading the data is\n                # much more straightforward.\n                self._data = _np.fromfile(stream,\n                                          self.dtype(byte_order),\n                                          self.count)\n\n        if len(self._data) < self.count:\n            k = len(self._data)\n            del self._data\n            raise PlyParseError(""early end-of-file"", self, k)\n\n        self._check_sanity()\n\n    def _write(self, stream, text, byte_order):\n        \'\'\'\n        Write the data to a PLY file.\n\n        \'\'\'\n        if text:\n            self._write_txt(stream)\n        else:\n            if self._have_list:\n                # There are list properties, so serialization is\n                # slightly complicated.\n                self._write_bin(stream, byte_order)\n            else:\n                # no list properties, so serialization is\n                # straightforward.\n                self.data.astype(self.dtype(byte_order),\n                                 copy=False).tofile(stream)\n\n    def _read_txt(self, stream):\n        \'\'\'\n        Load a PLY element from an ASCII-format PLY file.  The element\n        may contain list properties.\n\n        \'\'\'\n        self._data = _np.empty(self.count, dtype=self.dtype())\n\n        k = 0\n        for line in _islice(iter(stream.readline, b\'\'), self.count):\n            fields = iter(line.strip().split())\n            for prop in self.properties:\n                try:\n                    self._data[prop.name][k] = prop._from_fields(fields)\n                except StopIteration:\n                    raise PlyParseError(""early end-of-line"",\n                                        self, k, prop)\n                except ValueError:\n                    raise PlyParseError(""malformed input"",\n                                        self, k, prop)\n            try:\n                next(fields)\n            except StopIteration:\n                pass\n            else:\n                raise PlyParseError(""expected end-of-line"", self, k)\n            k += 1\n\n        if k < self.count:\n            del self._data\n            raise PlyParseError(""early end-of-file"", self, k)\n\n    def _write_txt(self, stream):\n        \'\'\'\n        Save a PLY element to an ASCII-format PLY file.  The element may\n        contain list properties.\n\n        \'\'\'\n        for rec in self.data:\n            fields = []\n            for prop in self.properties:\n                fields.extend(prop._to_fields(rec[prop.name]))\n\n            _np.savetxt(stream, [fields], \'%.18g\', newline=\'\\r\\n\')\n\n    def _read_bin(self, stream, byte_order):\n        \'\'\'\n        Load a PLY element from a binary PLY file.  The element may\n        contain list properties.\n\n        \'\'\'\n        self._data = _np.empty(self.count, dtype=self.dtype(byte_order))\n\n        for k in _range(self.count):\n            for prop in self.properties:\n                try:\n                    self._data[prop.name][k] = \\\n                        prop._read_bin(stream, byte_order)\n                except StopIteration:\n                    raise PlyParseError(""early end-of-file"",\n                                        self, k, prop)\n\n    def _write_bin(self, stream, byte_order):\n        \'\'\'\n        Save a PLY element to a binary PLY file.  The element may\n        contain list properties.\n\n        \'\'\'\n        for rec in self.data:\n            for prop in self.properties:\n                prop._write_bin(rec[prop.name], stream, byte_order)\n\n    @property\n    def header(self):\n        \'\'\'\n        Format this element\'s metadata as it would appear in a PLY\n        header.\n\n        \'\'\'\n        lines = [\'element %s %d\' % (self.name, self.count)]\n\n        # Some information is lost here, since all comments are placed\n        # between the \'element\' line and the first property definition.\n        for c in self.comments:\n            lines.append(\'comment \' + c)\n\n        lines.extend(list(map(str, self.properties)))\n\n        return \'\\r\\n\'.join(lines)\n\n    def __getitem__(self, key):\n        return self.data[key]\n\n    def __setitem__(self, key, value):\n        self.data[key] = value\n\n    def __str__(self):\n        return self.header\n\n    def __repr__(self):\n        return (\'PlyElement(%r, %r, count=%d, comments=%r)\' %\n                (self.name, self.properties, self.count,\n                 self.comments))\n\n\nclass PlyProperty(object):\n\n    \'\'\'\n    PLY property description.  This class is pure metadata; the data\n    itself is contained in PlyElement instances.\n\n    \'\'\'\n\n    def __init__(self, name, val_dtype):\n        self._name = str(name)\n        self._check_name()\n        self.val_dtype = val_dtype\n\n    def _get_val_dtype(self):\n        return self._val_dtype\n\n    def _set_val_dtype(self, val_dtype):\n        self._val_dtype = _data_types[_lookup_type(val_dtype)]\n\n    val_dtype = property(_get_val_dtype, _set_val_dtype)\n\n    @property\n    def name(self):\n        return self._name\n\n    def _check_name(self):\n        if any(c.isspace() for c in self._name):\n            msg = ""Error: property name %r contains spaces"" % self._name\n            raise RuntimeError(msg)\n\n    @staticmethod\n    def _parse_one(line):\n        assert line[0] == \'property\'\n\n        if line[1] == \'list\':\n            if len(line) > 5:\n                raise PlyParseError(""too many fields after ""\n                                    ""\'property list\'"")\n            if len(line) < 5:\n                raise PlyParseError(""too few fields after ""\n                                    ""\'property list\'"")\n\n            return PlyListProperty(line[4], line[2], line[3])\n\n        else:\n            if len(line) > 3:\n                raise PlyParseError(""too many fields after ""\n                                    ""\'property\'"")\n            if len(line) < 3:\n                raise PlyParseError(""too few fields after ""\n                                    ""\'property\'"")\n\n            return PlyProperty(line[2], line[1])\n\n    def dtype(self, byte_order=\'=\'):\n        \'\'\'\n        Return the numpy dtype description for this property (as a tuple\n        of strings).\n\n        \'\'\'\n        return byte_order + self.val_dtype\n\n    def _from_fields(self, fields):\n        \'\'\'\n        Parse from generator.  Raise StopIteration if the property could\n        not be read.\n\n        \'\'\'\n        return _np.dtype(self.dtype()).type(next(fields))\n\n    def _to_fields(self, data):\n        \'\'\'\n        Return generator over one item.\n\n        \'\'\'\n        yield _np.dtype(self.dtype()).type(data)\n\n    def _read_bin(self, stream, byte_order):\n        \'\'\'\n        Read data from a binary stream.  Raise StopIteration if the\n        property could not be read.\n\n        \'\'\'\n        try:\n            return _np.fromfile(stream, self.dtype(byte_order), 1)[0]\n        except IndexError:\n            raise StopIteration\n\n    def _write_bin(self, data, stream, byte_order):\n        \'\'\'\n        Write data to a binary stream.\n\n        \'\'\'\n        _np.dtype(self.dtype(byte_order)).type(data).tofile(stream)\n\n    def __str__(self):\n        val_str = _data_type_reverse[self.val_dtype]\n        return \'property %s %s\' % (val_str, self.name)\n\n    def __repr__(self):\n        return \'PlyProperty(%r, %r)\' % (self.name,\n                                        _lookup_type(self.val_dtype))\n\n\nclass PlyListProperty(PlyProperty):\n\n    \'\'\'\n    PLY list property description.\n\n    \'\'\'\n\n    def __init__(self, name, len_dtype, val_dtype):\n        PlyProperty.__init__(self, name, val_dtype)\n\n        self.len_dtype = len_dtype\n\n    def _get_len_dtype(self):\n        return self._len_dtype\n\n    def _set_len_dtype(self, len_dtype):\n        self._len_dtype = _data_types[_lookup_type(len_dtype)]\n\n    len_dtype = property(_get_len_dtype, _set_len_dtype)\n\n    def dtype(self, byte_order=\'=\'):\n        \'\'\'\n        List properties always have a numpy dtype of ""object"".\n\n        \'\'\'\n        return \'|O\'\n\n    def list_dtype(self, byte_order=\'=\'):\n        \'\'\'\n        Return the pair (len_dtype, val_dtype) (both numpy-friendly\n        strings).\n\n        \'\'\'\n        return (byte_order + self.len_dtype,\n                byte_order + self.val_dtype)\n\n    def _from_fields(self, fields):\n        (len_t, val_t) = self.list_dtype()\n\n        n = int(_np.dtype(len_t).type(next(fields)))\n\n        data = _np.loadtxt(list(_islice(fields, n)), val_t, ndmin=1)\n        if len(data) < n:\n            raise StopIteration\n\n        return data\n\n    def _to_fields(self, data):\n        \'\'\'\n        Return generator over the (numerical) PLY representation of the\n        list data (length followed by actual data).\n\n        \'\'\'\n        (len_t, val_t) = self.list_dtype()\n\n        data = _np.asarray(data, dtype=val_t).ravel()\n\n        yield _np.dtype(len_t).type(data.size)\n        for x in data:\n            yield x\n\n    def _read_bin(self, stream, byte_order):\n        (len_t, val_t) = self.list_dtype(byte_order)\n\n        try:\n            n = _np.fromfile(stream, len_t, 1)[0]\n        except IndexError:\n            raise StopIteration\n\n        data = _np.fromfile(stream, val_t, n)\n        if len(data) < n:\n            raise StopIteration\n\n        return data\n\n    def _write_bin(self, data, stream, byte_order):\n        \'\'\'\n        Write data to a binary stream.\n\n        \'\'\'\n        (len_t, val_t) = self.list_dtype(byte_order)\n\n        data = _np.asarray(data, dtype=val_t).ravel()\n\n        _np.array(data.size, dtype=len_t).tofile(stream)\n        data.tofile(stream)\n\n    def __str__(self):\n        len_str = _data_type_reverse[self.len_dtype]\n        val_str = _data_type_reverse[self.val_dtype]\n        return \'property list %s %s %s\' % (len_str, val_str, self.name)\n\n    def __repr__(self):\n        return (\'PlyListProperty(%r, %r, %r)\' %\n                (self.name,\n                 _lookup_type(self.len_dtype),\n                 _lookup_type(self.val_dtype)))\n'"
