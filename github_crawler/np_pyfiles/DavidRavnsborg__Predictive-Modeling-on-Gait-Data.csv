file_path,api_count,code
gaitLSTM.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Sun Aug 27 13:46:15 2017\n\n@author: david\n""""""\n# load and plot dataset\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.models import Sequential\nfrom math import sqrt\nfrom matplotlib import pyplot\nfrom numpy import array\nfrom pandas import concat\nfrom pandas import DataFrame\nfrom pandas import read_csv\nfrom pandas import Series\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom time import time\n\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced value\ndef inverse_difference(history, yhat, interval=1):\n    return yhat + history[-interval]\n\n# frame a sequence as a supervised learning problem\ndef timeseries_to_supervised(data, lag=1):\n    df = DataFrame(data)\n    columns = [df.shift(i) for i in range(1, lag+1)]\n    columns.append(df)\n    df = concat(columns, axis=1)\n    df.fillna(0, inplace=True)\n    return df\n\n# scale train and test data to [-1, 1]\ndef scale(train, test):\n    # fit scaler\n    scaler = MinMaxScaler(feature_range=(-1, 1))\n    scaler = scaler.fit(train)\n    # transform train\n    train = train.reshape(train.shape[0], train.shape[1])\n    train_scaled = scaler.transform(train)\n    # transform test\n    test = test.reshape(test.shape[0], test.shape[1])\n    test_scaled = scaler.transform(test)\n    return scaler, train_scaled, test_scaled\n\n# inverse scaling for a forecasted value\ndef invert_scale(scaler, X, yhat):\n\tnew_row = [x for x in X] + [yhat]\n\tuninverted = array(new_row)\n\tuninverted = uninverted.reshape(1, len(uninverted))\n\tinverted = scaler.inverse_transform(uninverted)\n\treturn inverted[0, -1]\n\n# fit an LSTM network to training data\ndef fit_lstm(train, batch_size, nb_epoch, neurons):\n    X, y = train[:, 0:-1], train[:, -1]\n    X = X.reshape(X.shape[0], 1, X.shape[1]) # reshapes it from a 2D ndarray to a 3D ndarray\n    model = Sequential()\n    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n    model.add(Dense(1))\n    model.compile(loss=\'mean_squared_error\', optimizer=\'adam\')\n    for i in range(nb_epoch):\n        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n        model.reset_states()\n    return model\n\n# run a repeated experiment\ndef experiment(repeats, series, epochs, batch_size, neurons):\n    # transform data to be stationary\n    raw_values = series.values\n    diff_values = difference(raw_values, 1)\n    # transform data to be supervised learning\n    supervised = timeseries_to_supervised(diff_values, 1)\n    supervised_values = supervised.values\n    # split data into train and test-sets\n    # this splits the data into sets of roughly 80%/20% of the values, rounded down to a multiple of batch size\n    split_point = int(0.8*len(supervised))\n    split_point = split_point - split_point % batch_size\n    # define the end_point as being the end of a range from split_point where it is a multiple of batch size\n    end_point = len(supervised)\n    end_point = end_point - (end_point - split_point ) % batch_size\n    train, test = supervised_values[0:split_point], supervised_values[split_point:end_point]\n    # transform the scale of the data\n    scaler, train_scaled, test_scaled = scale(train, test)\n    # run experiment\n    error_scores = list()\n    for r in range(repeats):\n        # fit the model\n        lstm_model = fit_lstm(train_scaled, batch_size, epochs, neurons)\n        # forecast the entire training dataset to build up state for forecasting\n        train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n        lstm_model.predict(train_reshaped, batch_size=batch_size)\n        # forecast test dataset and reduce length of test set to a multiple of batch_size\n        test_reshaped = test_scaled[:,0:-1]\n        test_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n        output = lstm_model.predict(test_reshaped, batch_size=batch_size)\n        predictions = list()\n        for i in range(len(output)):\n            yhat = output[i,0]\n            X = test_scaled[i, 0:-1]\n            # invert scaling\n            yhat = invert_scale(scaler, X, yhat)\n            # invert differencing\n            yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n            # store forecast\n            predictions.append(yhat)\n        # report performance\n        rmse = sqrt(mean_squared_error(raw_values[split_point:end_point], predictions))\n        print(\'%d) Test RMSE: %.3f\' % (r+1, rmse))\n        error_scores.append(rmse)\n        # line plot of observed vs predicted\n        pyplot.plot(raw_values[split_point:end_point]) \n        pyplot.plot(predictions) \n        pyplot.show()\n    return error_scores\n\n# protocol used for first experiment on dataset\ndef test_multiple_resampling_rates_and_epochs(experiment_func=experiment):\n    # Experiment conditions\n    resampling_rates = [5, 10, 20, 30, 40]\n    resampling_rates = resampling_rates[::-1] # will start with the higher/faster resampling rates, for faster feedback while developing\n    epochs = [125, 250, 500, 1000, 2000, 4000]\n    batch_size = 4\n    neurons = 1\n    repeats = 3\n    \n    experiment_results = {}\n    overall_time_results = {}\n        \n    # load dataset   \n    series = read_csv(\'david240520160001-singleLegVertForceSeries.csv\', header=0, parse_dates=[0], index_col=0, squeeze=True)#, date_parser=parser)\n    for r in resampling_rates:\n        print(\'Training and testing at resampling rate: {}\'.format(r))\n        # reduce sampling rate to speed training of the model\n        series_resampled = series.iloc[::r]\n        # line plot\n        series_resampled.plot()\n        pyplot.show()\n        # experiment\n        epoch_results = DataFrame()\n        time_results = {}\n        for e in epochs:\n            print(\'Running function \\""{}\\"" with parameters (epochs: {}; batch_size: {}; neurons: {})\'.format(experiment_func.__name__, e, batch_size, neurons))\n            ts = time()\n            epoch_results[str(e)] = experiment_func(repeats, series_resampled, e, batch_size, neurons)\n            te = time()\n            runtime = te-ts\n            time_results[str(e)] = runtime\n            print (\'Completed function \\""{}\\"" in {} seconds\'.format(experiment_func.__name__, runtime))\n        # summarize results\n        print(epoch_results.describe())\n        experiment_results[str(r)] = epoch_results\n        overall_time_results[str(r)] = time_results\n        # save boxplot\n        epoch_results.boxplot()\n        pyplot.savefig(\'boxplot_epochs_resample{}.png\'.format(r))\n        pyplot.show()\n    return experiment_results, overall_time_results\n\n# protocol used for second experiment on dataset\ndef test_multiple_batch_sizes_and_neurons(experiment_func=experiment):\n    # Experiment conditions\n    resampling_rate = 5\n    epoch_size = 250\n    batch_size = [1, 2, 4, 8]\n    neurons = [1, 2, 4, 8]\n    repeats = 3\n    \n    experiment_results = {}\n    overall_time_results = {}\n        \n    # load dataset   \n    series = read_csv(\'david240520160001-singleLegVertForceSeries.csv\', header=0, parse_dates=[0], index_col=0, squeeze=True)#, date_parser=parser)\n    # reduce sampling rate to speed training of the model\n    series_resampled = series.iloc[::resampling_rate]\n    for n in neurons:\n        # experiment\n        batch_results = DataFrame()\n        time_results = {}\n        for b in batch_size:\n            print(\'Running function \\""{}\\"" with parameters (epochs: {}; batch_size: {}; neurons: {})\'.format(experiment_func.__name__, epoch_size, b, n))\n            ts = time()\n            batch_results[str(b)] = experiment_func(repeats, series_resampled, epoch_size, b, n)\n            te = time()\n            runtime = te-ts\n            time_results[str(b)] = runtime\n            print (\'Completed function \\""{}\\"" in {} seconds\'.format(experiment_func.__name__, runtime))\n        # summarize results\n        print(batch_results.describe())\n        experiment_results[str(n)] = batch_results\n        overall_time_results[str(n)] = time_results\n        # save boxplot\n        batch_results.boxplot()\n        pyplot.savefig(\'boxplot_batch_size_neurons{}.png\'.format(n))\n        pyplot.show()\n    return experiment_results, overall_time_results\n'"
