file_path,api_count,code
__init__.py,0,b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n'
dataset_container.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom numpy import array, arange, amin, amax, histogram\nfrom numpy import column_stack, median, mean, sum\nfrom plotting import Plotter\nfrom datetime import timedelta\nfrom filter_provider import DatasetFilter, AcceptanceTester\n\nclass DatasetContainer:\n    """"""Contains one single dataset. Holds a list of Datapoint instances \n    describing the actual data. Depending on the name the dataset was \n    initialized with, processing is performed to reject invalid data when \n    appending new points.""""""\n    \n    def __init__(self, dataset_type, time_resolution=timedelta(minutes=1),\n                 filter_provider=DatasetFilter, plotter=Plotter):\n        """"""Initialize the dataset with the dataset_type. Type selects \n        processing for valid data when appending points.\n        \n        Parameters\n        ----------\n            dataset_type : string\n                The dataset type.\n            time_resolution : datetime.timedelta\n                The time resolution of the dataset.\n                (Default: timedelta(minutes=1))\n            filter_provider : class\n                A class providing data filters to the container. Must be \n                callable to apply the filters, and expose an add_filter and \n                count method.\n            plotter : class\n                A class providing plotting functionality. Must expose a plot \n                method.\n        \n        Returns\n        -------\n            None\n        """"""\n        self._type = dataset_type\n        self._raw_datapoints = []\n        self._index = 0\n        self._time_resolution = time_resolution\n        self._accept = AcceptanceTester(self._type)\n        if hasattr(filter_provider, \'add_filter\') \\\n            and hasattr(filter_provider, \'count\') \\\n            and callable(filter_provider.add_filter) \\\n            and callable(filter_provider.count) \\\n            and callable(filter_provider):\n            self._filters = filter_provider()\n        else:\n            raise ValueError(\'Got an invalid filter provider\')\n        if hasattr(plotter, \'plot\') and callable(plotter.plot):\n            self._plotter = plotter\n        else:\n            raise ValueError(\'Got an invalid plotter\')\n        self._data_up_to_date = True\n        self._update_filtered_data()\n        \n    def add_filter(self, filter_type, **kwargs):\n        """"""Add a new filter to the filter provider. filter_type selects the \n        filter that will be applied, any other parameter must be named and will\n        be passed to the actual filter function. When adding a filter, the \n        cached DatasetContainer._filtered_data is updated.\n        \n        Parameters\n        ----------\n            filter_type : string\n                The filter type to add.\n            kwargs : dict\n                Any other named parameters will be stored in the kwargs dict\n                and passed to the filter function when it gets called.\n\n        Returns\n        -------\n            None\n        """"""\n        self._filters.add_filter(filter_type, **kwargs)\n        self._data_up_to_date = False\n\n    def append(self, timestamp, value):\n        """"""Append a Datapoint(timestamp, value) to the dataset. Depending on the\n        type, checks for validity are performed, and if invalid, the data point\n        may be rejected.\n        \n        Parameters\n        ----------\n            timestamp : datetime\n                The timestamp of the Datapoint\n            value : int, float\n                The value to store\n        \n        Returns\n        -------\n            None\n        """"""\n        dp = Datapoint(timestamp, value)\n        if self._accept(dp):\n            self._raw_datapoints.append(dp)\n            self._data_up_to_date = False\n\n    def __getitem__(self, item):\n        """"""Return list of timestamps when called with \'timestamps\' or 0, and \n        list of values when called with \'values\' or 1. If any other value is\n        passed, an IndexError is raised.\n        \n        Parameters\n        ----------\n            item : string or int\n                The item name or index of the item to retrieve.\n        \n        Returns\n        -------\n            numpy.array\n                Depending on the selected item, an array containing the \n                timestamps or values stored in the container are returned. \n        """"""\n        if not self._data_up_to_date:\n            self._update_filtered_data()\n            self._data_up_to_date = True\n        if item == \'timestamps\' or item == 0:\n            return self._filtered_data[\'timestamps\']\n        elif item == \'values\' or item == 1:\n            return self._filtered_data[\'values\']\n        else:\n            raise IndexError(\'Invalid index\')\n    \n    def _update_filtered_data(self):\n        """"""Update the filtered data cache from the raw datapoints.\n        \n        Parameters\n        ----------\n            None\n            \n        Returns\n        -------\n            None\n        """"""\n        timestamps, values = [], []\n        for point in self._raw_datapoints:\n            timestamps.append(point.timestamp)\n            values.append(point.value)\n        timestamps, values = self._filters(array(timestamps), \n                                            array(values))\n        self._filtered_data = {\'timestamps\': timestamps, \'values\': values}\n    \n    def __iter__(self):\n        """"""Return self as iterator.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            self : DatasetContainer\n        """"""\n        return self\n    \n    def next(self):\n        """"""Iterate to the next Datapoint in the list.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            Datapoint\n                The next Datapoint in the container\n        """"""\n        if self._index < len(self._raw_datapoints):\n            self._index += 1\n            return self._raw_datapoints[self._index - 1]\n        else:\n            self._index = 0\n            raise StopIteration\n    \n    def time_resolution(self, value = None):\n        """"""Manage the datasets time resolution. If called without a value, \n        return the current time resolution. If a value is passed, it is set as \n        the new time resolution. The value must be >= 1 min, or an error will \n        be raised.\n        \n        Parameters\n        ----------\n            value : datetime.timedelta, None\n                The new time resolution to set, or None to return the current\n                time resolution only.\n        \n        Returns\n        -------\n            _time_resolution : datetime.timedelta\n                The time resolution of the dataset after the function finishes\n        """"""\n        if not value is None:\n            if value < timedelta(minutes=1):\n                raise ValueError(\'Time resolution cannot be lower than 1 min.\')\n            else:\n                self._time_resolution = value\n            return self._time_resolution\n        else:\n            return self._time_resolution\n    \n    def timestamp_start(self):\n        """"""Return first (chronological) timestamp for the dataset.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            datetime.datetime\n                The earliest timestamp stored in the dataset\n        """"""\n        return min(self[\'timestamps\'])\n    \n    def timestamp_end(self):\n        """"""Return last (chronological) timestamp for the dataset.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            datetime.datetime\n                The latest timestamp stored in the dataset\n        """"""\n        return max(self[\'timestamps\'])\n    \n    def timerange(self):\n        """"""Return the timerange [start, end] of the dataset as a list.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            list\n                A list containing the earliest and the latest timestamp in the \n                dataset.\n        """"""\n        return [self.timestamp_start(), self.timestamp_end()]\n    \n    def _downsample_data(self, func):\n        """"""Arbitrary downsample function. Pass a callable that performs the actual\n        downsampling. func should accept an array of values and return a single\n        number.\n        \n        Parameters\n        ----------\n            func : callable\n                The downsample function to apply. func should accept numpy.array\n                and return a single float or int.\n        \n        Returns\n        -------\n            class\n                A class that provides plotting of the data set.\n        """"""\n        cur_time = self.timestamp_start()\n        res_timestamps = []\n        res_values = []\n        while(cur_time <= self.timestamp_end()):\n            sliced_data = self._timeslice_data(cur_time, cur_time + \n                                                self.time_resolution())\n            val = func(sliced_data[\'values\'])\n            res_timestamps.append(cur_time)\n            res_values.append(val)\n            cur_time += self.time_resolution()\n        return self._plotter(self._type, timestamps=array(res_timestamps), \n                             values=array(res_values))\n    \n    def downsample_mean(self):\n        """"""Downsample data using the Numpy mean function.\n\n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            class\n                A class that provides plotting of the data set.\n        """"""\n        return self._downsample_data(mean)\n    \n    def downsample_median(self):\n        """"""Downsample data using the Numpy median function.\n\n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            class\n                A class that provides plotting of the data set.\n        """"""\n        return self._downsample_data(median)\n    \n    def downsample_sum(self):\n        """"""Downsample data using the Numpy sum function.\n\n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            class\n                A class that provides plotting of the data set.\n        """"""\n        return self._downsample_data(sum)\n    \n    def downsample_none(self):\n        """"""Don\'t downsample, just return full-resolution data as saved in the \n        dataset.\n\n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            class\n                A class that provides plotting of the data set.\n        """"""\n        res_timestamps = self[\'timestamps\'] \n        res_values = self[\'values\']\n        return self._plotter(self._type, timestamps=array(res_timestamps), \n                             values=array(res_values))\n    \n    def downsample_histogram(self, hist_min=None, hist_max=None, \n                             resolution=5):\n        """"""Downsample the data into a 2D histogram of values, where the time\n        resolution of the histogram is that of the dataset. I.e., each histogram\n        timestemp will contain a 1D histogram of values occuring in that \n        timestep in the dataset.\n\n        Parameters\n        ----------\n            hist_min : float, None\n                The minimal value of the histogram. If None is passed, it is \n                computed dynamically.\n                (Default: None)\n            hist_max : float, None\n                The maximum value of the histogram. If None is passed, it is \n                computed dynamically.\n                (Default: None)\n            resolution : float\n                The bin width of the histogram.\n                (Default: 5)\n        \n        Returns\n        -------\n            class\n                A class that provides plotting of the data set.\n        """"""\n        if hist_min is None:\n            #Take the minimum, round to nearest 10\n            hist_min = int(amin(self[\'values\'])/10)*10\n        if hist_max is None:\n            #Take the maximum, round to nearest 10\n            hist_max = int(amax(self[\'values\'])/10)*10\n        bins = arange(hist_min, hist_max, resolution)\n        cur_time = self.timestamp_start()\n        res_timestamps = []\n        res_histogram = []\n        while(cur_time <= self.timestamp_end()):\n            sliced_data = self._timeslice_data(cur_time, cur_time + \n                                                self.time_resolution())\n        \n            hist = histogram(sliced_data[\'values\'], bins, density=True)[0]\n            res_timestamps.append(cur_time)\n            #Scale the maximum of each histogram row to 1:\n            res_histogram.append(hist/amax(hist))\n            cur_time += self.time_resolution()\n        res_timestamps.append(self.timestamp_end())\n        return self._plotter(self._type, timestamps=array(res_timestamps), \n                             bins=bins, histogram=array(res_histogram))\n\n    def _timeslice_data(self, timestamp_start, timestamp_end):\n        """"""Helper function to perform the actual time slicing common to\n        downsampling. Returns a DatasetContainer with the data for which\n        timestamp_start <= timestamp < timestamp_end.\n\n        Parameters\n        ----------\n            timestamp_start : datetime.datetime\n                The earliest timestamp to include\n            timestamp_end : datetime.datetime\n                The first timestamp to exclude\n        \n        Returns\n        -------\n            res : DatasetContainer\n                A container with the data between the start and end values.\n        """"""\n        timestamps = array(self[\'timestamps\']) \n        values = array(self[\'values\'])\n        mask = (timestamps >= timestamp_start)*(timestamps < timestamp_end)\n        res = DatasetContainer(self._type)\n        res.time_resolution(value=self.time_resolution())\n        for timestamp, value in column_stack((timestamps[mask], values[mask])):\n            res.append(timestamp, value)\n        return res\n        \nclass Datapoint:\n    """"""Container for a single data point. Holds Datapoint.timestamp and \n    Datapoint.value. Is iterable to allow for timestamp, value = Datapoint \n    assignments.""""""\n    \n    def __init__(self, timestamp, value):\n        """"""Initialize the Datapoint. Pass a timestamp and a value to hold.\n        \n        Parameters\n        ----------\n            timestamp : datetime.datetime\n                The timestamp of the data point\n            value : float\n                The value of the data point\n        """"""\n        self.timestamp = timestamp\n        self.value = value\n        self._index = 0\n        \n    def __iter__(self):\n        """"""Return self as iterator.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            self : Datapoint\n                This instance of Datapoint\n        """"""\n        return self\n    \n    def next(self):\n        """"""Iterate over the values. First iteration yields timestamp, second\n        iteration yields value.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            datetime.datetime, float\n                Returns the timestamp on the first iteration, the value on the\n                second one.\n        """"""\n        if self._index == 0:\n            self._index += 1\n            return self.timestamp\n        elif self._index == 1:\n            self._index += 1\n            return self.value\n        else:\n            self._index = 0\n            raise StopIteration\n        '"
device_db_mapping.py,0,"b""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\ndevice_db_mapping = {'MI Band': {'table': 'MI_BAND_ACTIVITY_SAMPLE',\n                                 'timestamp': 'TIMESTAMP', \n                                 'heartrate': 'HEART_RATE', \n                                 'activity': 'RAW_KIND',\n                                 'intensity': 'RAW_INTENSITY',\n                                 'steps': 'STEPS'},\n                     'HPlus': {'table': 'HPLUS_HEALTH_ACTIVITY_SAMPLE',\n                               'timestamp': 'TIMESTAMP',\n                               'heartrate': 'HEART_RATE', \n                               'activity': 'RAW_KIND',\n                               'intensity': 'RAW_INTENSITY',\n                               'steps': 'STEPS',\n                               'calories': 'CALORIES',\n                               'distance': 'DISTANCE'},\n                     'NO.1 F1': {'table': 'NO1_F1_ACTIVITY_SAMPLE',\n                                 'timestamp': 'TIMESTAMP', \n                                 'heartrate': 'HEART_RATE', \n                                 'activity': 'RAW_KIND',\n                                 'intensity': 'RAW_INTENSITY',\n                                 'steps': 'STEPS'},\n                     'Pebble': {'table': 'NO1_F1_ACTIVITY_SAMPLE',\n                                'timestamp': 'TIMESTAMP', \n                                'heartrate': 'HEART_RATE', \n                                'intensity': 'RAW_INTENSITY',\n                                'steps': 'STEPS'}}"""
filter_provider.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom numpy import arange\n\nclass AcceptanceTester:\n    """"""Tests data points for acceptance into dataset_container.""""""\n\n    def __init__(self, tester_type):\n        """"""Initialize with the type of data to test.\n        \n        Parameters\n        ----------\n            tester_type : string\n                The type of data that validity should be tested for.\n        \n        Returns\n        -------\n            None\n        """"""\n        self._tester_map = {\'heartrate\': self._test_heartrate,\n                            \'intensity\': self._test_intensity,\n                            \'steps\': self._test_steps}\n        self._tester = self._tester_map.get(tester_type, self._test_accept_all)\n    \n    def __call__(self, Datapoint):\n        """"""Pass a Datapoint to test, returns acceptance based on the type set.\n        \n        Parameters\n        ----------\n            Datapoint : Datapoint\n                The Datapoint to test for acceptance\n        \n        Returns\n        -------\n            bool\n                Whether or not the value is valid.\n        """"""\n        return self._tester(Datapoint)\n        \n    def _test_accept_all(self, Datapoint):\n        """"""Accept all datapoints.\n        \n        Parameters\n        ----------\n            Datapoint : Datapoint\n                The Datapoint being tested.\n        \n        Returns\n        -------\n            True\n                This function always returns True to accept all data points.\n        """"""\n        return True\n    \n    def _test_heartrate(self, Datapoint):\n        """"""Test HR datapoints for acceptance. Do not accept values that match \n        the following:\n            * HR == 255\n            * HR <= 0\n        \n        Parameters\n        ----------\n            Datapoint : Datapoint\n                The Datapoint to test for acceptance\n        \n        Returns\n        -------\n            bool\n                Whether or not the value is valid.\n        """"""\n        return not Datapoint.value >= 255 and not Datapoint.value <= 0\n        \n    def _test_intensity(self, Datapoint):\n        """"""Test intensity datapoints for acceptance. Do not accept values that \n        match the following:\n            * intensity == 255\n        \n        Parameters\n        ----------\n            Datapoint : Datapoint\n                The Datapoint to test for acceptance\n        \n        Returns\n        -------\n            bool\n                Whether or not the value is valid.\n        """"""\n        return not Datapoint.value >= 255\n\n    def _test_steps(self, Datapoint):\n        """"""Test step datapoints for acceptance. Do not accept values that match \n        the following:\n            * steps < 0\n        \n        Parameters\n        ----------\n            Datapoint : Datapoint\n                The Datapoint to test for acceptance\n        \n        Returns\n        -------\n            bool\n                Whether or not the value is valid.\n        """"""\n        return not Datapoint.value < 0\n\nclass DatasetFilter:\n    """"""A class providing dataset filtering.""""""\n    \n    def __init__(self):\n        """"""Initialize the filters.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            None\n        """"""\n        self._filter_map = {\'heartrate\': self._filter_hr}\n        self._filter_params = {}\n        self._filters = []\n        \n    def add_filter(self, filtername, **kwargs):\n        """"""Add a filter to be applied to the dataset. The first parameter \n        selects the filter type, any other parameters must be named and will be \n        stored and passed to the filter function as parameters.\n        \n        Parameters\n        ----------\n            filtername : string\n                The name of the filter to add.\n            kwargs : dict\n                Any other named parameters will be stored and passed to the \n                filter when it is called.\n        \n        Returns\n        -------\n            None\n        """"""\n        if filtername in self._filter_map and not filtername in self._filters:\n            self._filters.append(filtername)\n            self._filter_params[filtername] = kwargs\n    \n    def __call__(self, timestamps, values):\n        """"""Apply the filters that have been set up for this provider to the \n        dataset passed and return the resulting dataset.\n        \n        Parameters\n        ----------\n            timestamps : numpy.array\n                The timestamps of the data to be filtered\n            values : numpy.array\n                The values of the data to be filtered\n        """"""\n        for filtername in self._filters:\n            timestamps, values = self._filter_map[filtername](timestamps, values, \n                                                              **self._filter_params[filtername])\n        return timestamps, values\n    \n    def count(self):\n        """"""Returns the number of filter functions applied to data.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n            int\n                The number of filters stored\n        """"""\n        return len(self._filters)\n    \n    def _filter_hr(self, timestamps, values, delta_doublefilter=3):\n        """"""A heartrate-specific filter. It checks if a value is twice as high as\n        the ones preceding and following it, within the delta_doublefilter \n        environment, and divides the values matching by two.\n        \n        Parameters\n        ----------\n            timestamps : numpy.array\n                The timestamps of the data to be filtered\n            values : numpy.array\n                The values of the data to be filtered\n            delta_doublefilter : int\n                The delta around double the value of a heartrate value for which\n                the filter will still be applied.\n        \n        Returns\n        -------\n            None\n        """"""\n        for i in arange(1, len(values) - 1):\n            diff_lower = abs((float(values[i])/2.) - values[i - 1])\n            diff_upper = abs((float(values[i])/2.) - values[i + 1])\n            if (diff_lower < delta_doublefilter)*\\\n              (diff_upper < delta_doublefilter):\n                values[i] /= 2.\n        return timestamps, values\n        '"
gb_database.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport sqlite3\nimport time\nfrom datetime import datetime\nfrom device_db_mapping import device_db_mapping\nfrom dataset_container import DatasetContainer\n\nclass ResultIterator:\n    """"""A class used to iterate over sqlite3 cursor results in a for loop.""""""\n    \n    def __init__(self, cursor):\n        """"""Initialize the interface with a cursor.\n        \n        Parameters\n        ----------\n            cursor : sqlite.Cursor\n                The database cursor pointing to the results\n        \n        Returns\n        -------\n            None\n        """"""\n        self._cursor = cursor\n\n    def __iter__(self):\n        """"""Return self for iteration.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            self : ResultIterator\n                This instance\n        """"""\n        return self\n    \n    def next(self):\n        """"""Iterate over the cursor result items.\n        \n        Parameters\n        ----------\n            None\n            \n        Returns\n        -------\n            item : sequence\n                One row of results\n        """"""\n        item = self._cursor.fetchone()\n        if not item is None:\n            return item\n        else:\n            raise StopIteration\n            \n    def all(self):\n        """"""Convenience function to return all result items at once.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            list\n                A list containing all rows\n        """"""\n        return self._cursor.fetchall()\n\nclass GadgetbridgeDatabase:\n    """"""Provides a simple abstraction layer around the Sqlite DB.""""""\n    \n    def __init__(self, filename, device):\n        """"""Initiate the interface. Pass a filename and a device name. The device\n        name is used to pull database table mapping.\n        \n        Parameters\n        ----------\n            filename : string\n                The name of the SQLite database file to open\n            device : string\n                The name of the device the data is stored for. This selects\n                table mappings for the database.\n        \n        Returns\n        -------\n            None\n        """"""\n        self._db_filename = filename\n        self._db = sqlite3.connect(self._db_filename)\n        self._cursor = self._db.cursor()\n        self.results = ResultIterator(self._cursor)\n        self._query(\'SELECT name FROM sqlite_master WHERE type=""table"";\')\n        self.tables = [x[0] for x in self.results.all()]\n        self.device = device\n        self._db_names = device_db_mapping[self.device]\n        \n    def __del__(self):\n        """"""Clear the class instance. This closes the database cleanly.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            None\n        """"""\n        self._cursor.close()\n        self._db.close()\n        \n    def _query(self, querystring):\n        """"""Execute a query on the database.\n        \n        Parameters\n        ----------\n            querystring : string\n                The SQLite query string\n        \n        Returns\n        -------\n            None\n        """"""\n        self._cursor.execute(querystring)\n        \n    def query_tableinfo(self, table_name):\n        """"""Retrieve info about a table in the database. Returns a dict \n        containing the entries:\n            * index\n            * name\n            * type\n        for each of the columns in the table.\n        \n        Parameters\n        ----------\n            table_name : string\n                The name of the table that the layout should be queried for.\n        \n        Returns\n        -------\n            None\n        """"""\n        if table_name in self.tables:\n            self.query(\'pragma table_info({table_name:s});\'.format(\n                    table_name=table_name))\n            res = {\'name\': [], \'type\': [], \'index\': []}\n            for row in self.results:\n                res[\'index\'].append(row[0])\n                res[\'name\'].append(row[1])\n                res[\'type\'].append(row[2])\n            return res\n        else:\n            return None\n\n    def _build_querystring(self, dataset, timestamp_min=None, \n                           timestamp_max=None):\n        """"""Build a Sqlite query to pull the dataset from the database.\n        \n        Parameters\n        ----------\n            dataset : string\n                The dataset to build a query string for. Must be one of the \n                following:\n                    * timestamp\n                    * heartrate\n                    * intensity\n                    * activity\n                    * steps\n            timestamp_min : datetime.datetime, None\n                The lower limit (included) to return data for. If None, no \n                lower limit will be set.\n            timestamp_max : datetime.datetime, None\n                The upper limit (not included) to return data for If None, no\n                upper limit will be set.\n        \n        Returns\n        -------\n            string\n                An SQLite query string for the requested dataset\n        """"""\n        restrictions = []\n        if not timestamp_min is None:\n            #val is the string of the Unix timestamp of the datetime:\n            val = str(int(time.mktime(timestamp_min.timetuple())))\n            restrictions.append([self._db_names[\'timestamp\'],\n                                 \'>=\', val])\n        if not timestamp_max is None:\n            #val is the string of the Unix timestamp of the datetime:\n            val = str(int(time.mktime(timestamp_max.timetuple())))\n            restrictions.append([self._db_names[\'timestamp\'],\n                                 \'<\', val])\n        #Build the base query (timestamps is always selected):\n        query_template = \'SELECT {dataset_col:s} FROM {table:s}\'\n        dataset_cols = self._db_names[\'timestamp\'] + \', \'\\\n            + self._db_names[dataset]\n        res = query_template.format(dataset_col=dataset_cols,\n                                     table=self._db_names[\'table\'])\n        #Append restriction expressions, if there are any:\n        if len(restrictions) != 0:\n            field, operator, limit = restrictions[0]\n            query_restrictions = \' WHERE \' + field + \' \' + operator + \' \'\\\n                + limit\n            for field, operator, limit in restrictions[1:]:\n                query_restrictions += \' AND \' + field + \' \' + operator + \' \'\\\n                    + limit\n            res += query_restrictions \n        return res + \';\'\n        \n    def query_dataset(self, dataset, timestamp_min=None, timestamp_max=None):\n        """"""Builds the query to pull a dataset from the database and executes it.\n        \n        Parameters\n        ----------\n            dataset : string\n                The dataset to query from the database. Must be one of the \n                following:\n                    * timestamp\n                    * heartrate\n                    * intensity\n                    * activity\n                    * steps\n            timestamp_min : datetime.datetime, None\n                The lower limit (included) to return data for. If None, no \n                lower limit will be set.\n            timestamp_max : datetime.datetime, None\n                The upper limit (not included) to return data for If None, no\n                upper limit will be set.\n        \n        Returns\n        -------\n            None\n        """"""\n        datasets = self._db_names.keys()\n        datasets.remove(\'table\')\n        datasets.remove(\'timestamp\')\n        if not dataset in datasets:\n            raise LookupError(\'Dataset not available, must be in \' + \\\n                              str(datasets))\n        self._query(self._build_querystring(dataset,\n                                            timestamp_min=timestamp_min, \n                                            timestamp_max=timestamp_max))\n        \n    def retrieve_dataset(self, dataset, timestamp_min=None, timestamp_max=None,\n                         time_resolution=None):\n        """"""Retrieve a dataset from the database.\n        \n        Parameters\n        ----------\n            dataset : string\n                The dataset to retrieve from the database. Must be one of the \n            following:\n                * timestamp\n                * heartrate\n                * intensity\n                * activity\n                * steps\n            timestamp_min : datetime.datetime, None\n                The lower limit (included) to return data for. If None, no \n                lower limit will be set.\n            timestamp_max : datetime.datetime, None\n                The upper limit (not included) to return data for If None, no\n                upper limit will be set.\n            time_resolution : datetime.timedelta, None\n                The time resolution of the dataset container returned. If None,\n                the default of 1 minute will be used.\n        \n        Returns\n        -------\n            res : DatasetContainer\n                The container with the retrieved dataset.\n        """"""\n        self.query_dataset(dataset, timestamp_min=timestamp_min, \n                           timestamp_max=timestamp_max)\n        res = DatasetContainer(dataset, time_resolution=time_resolution)\n        for ts, val in self.results:\n            res.append(datetime.fromtimestamp(ts), val)\n        return res\n    \nif __name__ == \'__main__\':\n    from datetime import timedelta\n    from sys import argv\n    from matplotlib import gridspec, pyplot as plt\n    time_resolution = timedelta(days=1)\n    db = GadgetbridgeDatabase(argv[1], \'MI Band\')\n    time_resolution=timedelta(days=1)\n    heartrate = db.retrieve_dataset(\'heartrate\', time_resolution=time_resolution)\n    heartrate.add_filter(\'heartrate\')\n    steps = db.retrieve_dataset(\'steps\', time_resolution=time_resolution)\n    fig = plt.figure()\n    gs = gridspec.GridSpec(2,1,height_ratios=[4,1])\n    plt.subplot(gs[0])\n    heartrate.downsample_histogram().plot()\n    plt.xticks([])\n    plt.subplot(gs[1])\n    plt.subplots_adjust(hspace=0)\n    steps.downsample_sum().plot()\n    plt.savefig(argv[2])'"
plotting.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom matplotlib import pyplot as plt\nfrom numpy import amin, amax\n\nclass Plotter:\n    """"""A class that creates plots from data.""""""\n    \n    def __init__(self, dataset_name, **kwargs):\n        """"""Initialize the class. Pass the dataset name as first argument. If \n        \'timestamps\' and \'values\' are passed as named arguments, the data is \n        plotted as a line plot. If \'timestamps\', \'bins\' and \'histogram\' are \n        passed, the data is plotted as a histogram plot. An exception is raised\n        when other data is passed.\n        \n        Parameters\n        ----------\n            dataset_name : string\n                A descriptive name of the dataset.\n            kwargs : dict\n                The other parameters must be either:\n                    * timestamps : numpy.array\n                    * values : numpy.array\n                or\n                    * timestamps : numpy.array\n                    * bins : numpy.array\n                    * histogram : numpy.array\n                The combination of names selects the plot type.\n        \n        Returns\n        -------\n            None\n        """"""\n        self._type = dataset_name\n        if \'timestamps\' in kwargs and \'values\' in kwargs:\n            self._plotfunc = self._line_plot\n            self._timestamps = kwargs[\'timestamps\']\n            self._values = kwargs[\'values\']\n        elif \'timestamps\' in kwargs and \'bins\' in kwargs and \\\n            \'histogram\' in kwargs:\n            self._plotfunc = self._hist_plot\n            self._timestamps = kwargs[\'timestamps\']\n            self._bins = kwargs[\'bins\']\n            self._histogram = kwargs[\'histogram\']\n        else:\n            raise InvalidArgumentsException(\'Invalid naming and/or number \'\\\n                                            + \'of arguments\')\n    \n    def plot(self):\n        """"""Plot the data stored in the class as the appropriate plot type.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            None\n        """"""\n        self._plotfunc()\n    \n    def _line_plot(self):\n        """"""Plot the data stored in the class as a line plot.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            None\n        """"""\n        plt.plot(self._timestamps, self._values)\n        plt.ylabel(self._type)\n        plt.xlim(amin(self._timestamps), amax(self._timestamps))\n        plt.grid()\n    \n    def _hist_plot(self):\n        """"""Plot the data stored in the class as a histogram.\n        \n        Parameters\n        ----------\n            None\n        \n        Returns\n        -------\n            None\n        """"""\n        plt.pcolormesh(self._timestamps, self._bins, self._histogram.T)\n        plt.xlim(amin(self._timestamps), amax(self._timestamps))\n        plt.ylabel(self._type + \' histogram\')\n                \nclass InvalidArgumentsException(BaseException):\n    """"""The error raised when an invalid argument is passed.""""""\n    pass'"
tests/__init__.py,0,b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n'
tests/test_acceptance_tester.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom ..filter_provider import AcceptanceTester\nfrom ..dataset_container import Datapoint\nfrom datetime import datetime\n\ndef test_heartrate_accept():\n    """"""Test the correct acceptance for a valid heartrate Datapoint.""""""\n    acc_tester = AcceptanceTester(\'heartrate\')\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 1)\n    assert acc_tester(dp) is True\n\ndef test_heartrate_reject():\n    """"""Test the correct rejection for invalid heartrate datapoints.""""""\n    acc_tester = AcceptanceTester(\'heartrate\')\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 0)\n    assert acc_tester(dp) is False\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), -1)\n    assert acc_tester(dp) is False\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 255)\n    assert acc_tester(dp) is False\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 256)\n    assert acc_tester(dp) is False\n\ndef test_intensity_reject():\n    """"""Test the correct rejection for invalid intensity datapoints.""""""\n    acc_tester = AcceptanceTester(\'intensity\')\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 255)\n    assert acc_tester(dp) is False\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 256)\n    assert acc_tester(dp) is False\n\ndef test_intensity_accept():\n    """"""Test the correct acceptance for a valid intensity Datapoint.""""""\n    acc_tester = AcceptanceTester(\'intensity\')\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 1)\n    assert acc_tester(dp) is True\n\ndef test_steps_accept():\n    """"""Test the correct acceptance for valid steps datapoints.""""""\n    acc_tester = AcceptanceTester(\'steps\')\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 1)\n    assert acc_tester(dp) is True\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 0)\n    assert acc_tester(dp) is True\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 256)\n    assert acc_tester(dp) is True\n\ndef test_steps_reject():\n    """"""Test the correct rejection for an invalid steps Datapoint.""""""\n    acc_tester = AcceptanceTester(\'steps\')\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), -1)\n    assert acc_tester(dp) is False\n\ndef test_nofilter():\n    """"""Test the correct acceptance for a non-specified Datapoint.""""""\n    acc_tester = AcceptanceTester(\'\')\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 1)\n    assert acc_tester(dp) is True\n'"
tests/test_datapoint.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom ..dataset_container import Datapoint\nfrom datetime import datetime\n\ndef test_datapoint_construction():\n    """"""Test that datapoints correctly store the values passed to them.""""""\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 2)\n    assert dp.timestamp == datetime(2018, 1, 1, 12, 0, 0) and dp.value == 2\n\ndef test_datapoint_iteration():\n    """"""Test that data points correctly return values when iterated over""""""\n    dp = Datapoint(datetime(2018, 1, 1, 12, 0, 0), 2)\n    ts, val = dp\n    assert ts == datetime(2018, 1, 1, 12, 0, 0) and val == 2'"
tests/test_dataset_container.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom ..dataset_container import DatasetContainer, Datapoint\nfrom datetime import datetime, timedelta\nfrom numpy import array\nimport pytest\n\n@pytest.fixture\ndef dataset_container():\n    """"""Return a default DatasetContainer instance to run tests against. Activity\n    as a typeshould not have any filters or acceptance testing associated.\n    """"""\n    return DatasetContainer(\'activity\')\n\ndef test_add_filter(dataset_container):\n    """"""Test that filters get correctly assigned.""""""\n    dataset_container.add_filter(\'heartrate\')\n    assert dataset_container._filters.count() == 1\n\ndef test_append(dataset_container):\n    """"""Test that data points get appended correctly.""""""\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    expected_timestamps = array((datetime(2018, 1, 1, 12, 0, 0)))\n    expected_values = array((1))\n    assert len(dataset_container._raw_datapoints) == 1\n    assert dataset_container._raw_datapoints[0].value == 1 \\\n        and dataset_container._raw_datapoints[0].timestamp == datetime(2018, \n                                                                   1, \n                                                                   1, \n                                                                   12, 0, 0)\n    assert (dataset_container._filtered_data[\'timestamps\'] == \n            expected_timestamps).all() \\\n            and (dataset_container._filtered_data[\'values\'] == \n                 expected_values).all()\n\ndef test_iteration(dataset_container):\n    """"""Test that iteration correctly returns the sequence of datapoints \n    stored.\n    """"""\n    datapoints = [Datapoint(datetime(2018, 1, 1, 12, 0, 0), 1), \n                  Datapoint(datetime(2018, 1, 1, 12, 1, 0), 2),\n                  Datapoint(datetime(2018, 1, 1, 12, 2, 0), 3)]\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    for test_datapoint, stored_datapoint in zip(dataset_container, datapoints):\n        assert test_datapoint.timestamp == stored_datapoint.timestamp \\\n            and test_datapoint.value == stored_datapoint.value\n\ndef test_get_timeresolution(dataset_container):\n    """"""Test reading out the time resolution.""""""\n    assert dataset_container.time_resolution() == timedelta(minutes=1)\n\ndef test_set_timeresolution(dataset_container):\n    """"""Test setting the time resolution.""""""\n    timeres = timedelta(hours=1)\n    assert dataset_container.time_resolution(timeres) == timeres\n\ndef test_get_timestamps(dataset_container):\n    """"""Test getting the stored timestamps.""""""\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    expected_timestamps = array((datetime(2018, 1, 1, 12, 0, 0),\n                                 datetime(2018, 1, 1, 12, 1, 0),\n                                 datetime(2018, 1, 1, 12, 2, 0)))\n    assert (dataset_container[0] == expected_timestamps).all()\n    assert (dataset_container[\'timestamps\'] == expected_timestamps).all()\n\ndef test_get_values(dataset_container):\n    """"""Test getting the stored values.""""""\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    expected_values = array((1, 2, 3))\n    assert (dataset_container[1] == expected_values).all()\n    assert (dataset_container[\'values\'] == expected_values).all()\n\ndef test_get_timestamp_start(dataset_container):\n    """"""Test that timestamp_start returns the correct timestamp.""""""\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    assert dataset_container.timestamp_start() == datetime(2018, 1, 1, 12, 0, 0)\n\ndef test_get_timestamp_end(dataset_container):\n    """"""Test that timestamp_end returns the correct timestamp.""""""\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    assert dataset_container.timestamp_end() == datetime(2018, 1, 1, 12, 2, 0)\n\ndef test_get_timerange(dataset_container):\n    """"""Test that timerange returns a list with the correct timestamps.""""""\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    timerange = dataset_container.timerange() \n    assert timerange == [datetime(2018, 1, 1, 12, 0, 0), \n                         datetime(2018, 1, 1, 12, 2, 0)] \n\ndef test_timeslice_data(dataset_container):\n    """"""Test that timeslicing returns the correct time range.""""""\n    start = datetime(2018, 1, 1, 12, 3, 0)\n    end = datetime(2018, 1, 1, 12, 8, 0)\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    dataset_container.append(datetime(2018, 1, 1, 12, 3, 0), 4)\n    dataset_container.append(datetime(2018, 1, 1, 12, 4, 0), 5)\n    dataset_container.append(datetime(2018, 1, 1, 12, 5, 0), 6)\n    dataset_container.append(datetime(2018, 1, 1, 12, 6, 0), 7)\n    dataset_container.append(datetime(2018, 1, 1, 12, 7, 0), 8)\n    dataset_container.append(datetime(2018, 1, 1, 12, 8, 0), 9)\n    dataset_container.append(datetime(2018, 1, 1, 12, 9, 0), 10)\n    dataset_container.append(datetime(2018, 1, 1, 12, 10, 0), 11)\n    dataset_container.time_resolution(timedelta(minutes=5))\n    expected_timestamps = array((datetime(2018, 1, 1, 12, 3, 0),\n                                 datetime(2018, 1, 1, 12, 4, 0),\n                                 datetime(2018, 1, 1, 12, 5, 0),\n                                 datetime(2018, 1, 1, 12, 6, 0),\n                                 datetime(2018, 1, 1, 12, 7, 0)))\n    res = dataset_container._timeslice_data(start, end)\n    res_timestamps = res[\'timestamps\']\n    assert (expected_timestamps == res_timestamps).all()\n    dataset_container.time_resolution(timedelta(hours=1))\n    res = dataset_container._timeslice_data(start, end)\n    res_timestamps = res[\'timestamps\']\n    assert (expected_timestamps == res_timestamps).all()\n\ndef test_downsample_none(dataset_container):\n    """"""Test that the non-downsampling method actually doesn\'t do anything.""""""\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    dataset_container.append(datetime(2018, 1, 1, 12, 3, 0), 4)\n    dataset_container.append(datetime(2018, 1, 1, 12, 4, 0), 5)\n    dataset_container.append(datetime(2018, 1, 1, 12, 5, 0), 6)\n    dataset_container.append(datetime(2018, 1, 1, 12, 6, 0), 7)\n    dataset_container.append(datetime(2018, 1, 1, 12, 7, 0), 8)\n    dataset_container.append(datetime(2018, 1, 1, 12, 8, 0), 9)\n    dataset_container.append(datetime(2018, 1, 1, 12, 9, 0), 10)\n    dataset_container.append(datetime(2018, 1, 1, 12, 10, 0), 11)\n    dataset_container.time_resolution(timedelta(minutes=5))\n    expected_timestamps = array((datetime(2018, 1, 1, 12, 0, 0),\n                                 datetime(2018, 1, 1, 12, 1, 0),\n                                 datetime(2018, 1, 1, 12, 2, 0),\n                                 datetime(2018, 1, 1, 12, 3, 0),\n                                 datetime(2018, 1, 1, 12, 4, 0),\n                                 datetime(2018, 1, 1, 12, 5, 0),\n                                 datetime(2018, 1, 1, 12, 6, 0),\n                                 datetime(2018, 1, 1, 12, 7, 0),\n                                 datetime(2018, 1, 1, 12, 8, 0),\n                                 datetime(2018, 1, 1, 12, 9, 0),\n                                 datetime(2018, 1, 1, 12, 10, 0)))\n    expected_values = array((1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))\n    plotter = dataset_container.downsample_none()\n    assert (plotter._timestamps == expected_timestamps).all()\n    assert (plotter._values == expected_values).all()\n\ndef test_downsample_sum(dataset_container):\n    """"""Test that the sum downsampling works correctly.""""""\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    dataset_container.append(datetime(2018, 1, 1, 12, 3, 0), 4)\n    dataset_container.append(datetime(2018, 1, 1, 12, 4, 0), 5)\n    dataset_container.append(datetime(2018, 1, 1, 12, 5, 0), 6)\n    dataset_container.append(datetime(2018, 1, 1, 12, 6, 0), 7)\n    dataset_container.append(datetime(2018, 1, 1, 12, 7, 0), 8)\n    dataset_container.append(datetime(2018, 1, 1, 12, 8, 0), 9)\n    dataset_container.append(datetime(2018, 1, 1, 12, 9, 0), 10)\n    dataset_container.append(datetime(2018, 1, 1, 12, 10, 0), 11)\n    dataset_container.time_resolution(timedelta(minutes=5))\n    expected_timestamps = array((datetime(2018, 1, 1, 12, 0, 0),\n                                 datetime(2018, 1, 1, 12, 5, 0),\n                                 datetime(2018, 1, 1, 12, 10, 0)))\n    expected_values = array((15, 40, 11))\n    plotter = dataset_container.downsample_sum()\n    assert (plotter._timestamps == expected_timestamps).all()\n    assert (plotter._values == expected_values).all()\n\ndef test_downsample_median(dataset_container):\n    """"""Test that the median downsampling works correctly.""""""\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    dataset_container.append(datetime(2018, 1, 1, 12, 3, 0), 4)\n    dataset_container.append(datetime(2018, 1, 1, 12, 4, 0), 5)\n    dataset_container.append(datetime(2018, 1, 1, 12, 5, 0), 6)\n    dataset_container.append(datetime(2018, 1, 1, 12, 6, 0), 7)\n    dataset_container.append(datetime(2018, 1, 1, 12, 7, 0), 8)\n    dataset_container.append(datetime(2018, 1, 1, 12, 8, 0), 9)\n    dataset_container.append(datetime(2018, 1, 1, 12, 9, 0), 10)\n    dataset_container.append(datetime(2018, 1, 1, 12, 10, 0), 11)\n    dataset_container.time_resolution(timedelta(minutes=5))\n    expected_timestamps = array((datetime(2018, 1, 1, 12, 0, 0),\n                                 datetime(2018, 1, 1, 12, 5, 0),\n                                 datetime(2018, 1, 1, 12, 10, 0)))\n    expected_values = array((3, 8, 11))\n    plotter = dataset_container.downsample_median()\n    assert (plotter._timestamps == expected_timestamps).all()\n    assert (plotter._values == expected_values).all()\n\ndef test_downsample_mean(dataset_container):\n    """"""Test that the mean downsampling works correctly.""""""\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    dataset_container.append(datetime(2018, 1, 1, 12, 3, 0), 4)\n    dataset_container.append(datetime(2018, 1, 1, 12, 4, 0), 5)\n    dataset_container.append(datetime(2018, 1, 1, 12, 5, 0), 6)\n    dataset_container.append(datetime(2018, 1, 1, 12, 6, 0), 7)\n    dataset_container.append(datetime(2018, 1, 1, 12, 7, 0), 8)\n    dataset_container.append(datetime(2018, 1, 1, 12, 8, 0), 9)\n    dataset_container.append(datetime(2018, 1, 1, 12, 9, 0), 10)\n    dataset_container.append(datetime(2018, 1, 1, 12, 10, 0), 11)\n    dataset_container.time_resolution(timedelta(minutes=5))\n    expected_timestamps = array((datetime(2018, 1, 1, 12, 0, 0),\n                                 datetime(2018, 1, 1, 12, 5, 0),\n                                 datetime(2018, 1, 1, 12, 10, 0)))\n    expected_values = array((3, 8, 11))\n    plotter = dataset_container.downsample_mean()\n    assert (plotter._timestamps == expected_timestamps).all()\n    assert (plotter._values == expected_values).all()\n\ndef test_downsample_histogram(dataset_container):\n    """"""Test that the histogram downsampling works correctly.""""""\n    dataset_container.append(datetime(2018, 1, 1, 12, 0, 0), 1)\n    dataset_container.append(datetime(2018, 1, 1, 12, 1, 0), 2)\n    dataset_container.append(datetime(2018, 1, 1, 12, 2, 0), 3)\n    dataset_container.append(datetime(2018, 1, 1, 12, 3, 0), 4)\n    dataset_container.append(datetime(2018, 1, 1, 12, 4, 0), 5)\n    dataset_container.append(datetime(2018, 1, 1, 12, 5, 0), 6)\n    dataset_container.append(datetime(2018, 1, 1, 12, 6, 0), 7)\n    dataset_container.append(datetime(2018, 1, 1, 12, 7, 0), 8)\n    dataset_container.append(datetime(2018, 1, 1, 12, 8, 0), 9)\n    dataset_container.append(datetime(2018, 1, 1, 12, 9, 0), 10)\n    dataset_container.append(datetime(2018, 1, 1, 12, 10, 0), 11)\n    dataset_container.time_resolution(timedelta(minutes=5))\n    expected_timestamps = array((datetime(2018, 1, 1, 12, 0, 0),\n                                 datetime(2018, 1, 1, 12, 5, 0),\n                                 datetime(2018, 1, 1, 12, 10, 0),\n                                 datetime(2018, 1, 1, 12, 10, 0)))\n    expected_bins = array((1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))\n    expected_histogram = array(((1., 1., 1., 1., 1., 0., 0., 0., 0., 0.),\n                                (0., 0., 0., 0., 0., 1., 1., 1., 1., 1.),\n                                (0., 0., 0., 0., 0., 0., 0., 0., 0., 1.)))\n    #hist_max=12, because it is passed as max value to arange\n    plotter = dataset_container.downsample_histogram(hist_min=1, hist_max=12, \n                                                     resolution=1)\n    assert (plotter._timestamps == expected_timestamps).all()\n    assert (plotter._bins == expected_bins).all()\n    assert (plotter._histogram == expected_histogram).all()\n'"
tests/test_dataset_filter.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom ..filter_provider import DatasetFilter\nfrom numpy import array\nfrom datetime import datetime\n\ndef test_addition():\n    """"""Test adding a valid filter to the DatasetFilter class. The filter should\n    get added.\n    """"""\n    ds_filter = DatasetFilter()\n    ds_filter.add_filter(\'heartrate\')\n    assert len(ds_filter._filters) == 1 and ds_filter._filters[0] == \'heartrate\'\n\ndef test_invalid_addition():\n    """"""Test adding an invalid filter to the DatasetFilter class. The filter \n    should not be added.\n    """"""\n    ds_filter = DatasetFilter()\n    ds_filter.add_filter(\'not defined as filter name\')\n    assert len(ds_filter._filters) == 0\n\ndef test_double_addition():\n    """"""Test adding the same filter twice to the DatasetFilter class. Expected\n    behaviour is that the filter only gets added once.\n    """"""\n    ds_filter = DatasetFilter()\n    ds_filter.add_filter(\'heartrate\')\n    ds_filter.add_filter(\'heartrate\')\n    assert len(ds_filter._filters) == 1\n    \ndef test_get_count():\n    """"""Test returning the number of filters from DatasetFilter.get_count().""""""\n    ds_filter = DatasetFilter()\n    assert ds_filter.count() == 0\n    assert ds_filter.count() == len(ds_filter._filters)\n    ds_filter.add_filter(\'heartrate\')\n    assert ds_filter.count() == len(ds_filter._filters)\n    assert ds_filter.count() == 1\n\ndef test_param_passing():\n    """"""Test passing parameters to filters. The parameters should be stored \n    correctly in the DatasetFilter._filter_params dictionary.\n    """"""\n    ds_filter = DatasetFilter()\n    ds_filter.add_filter(\'heartrate\')\n    assert len(ds_filter._filter_params) == 1\n    assert len(ds_filter._filter_params[\'heartrate\'].keys()) == 0\n    ds_filter = DatasetFilter()\n    ds_filter.add_filter(\'heartrate\', test_param=1)\n    assert len(ds_filter._filter_params) == 1\n    assert len(ds_filter._filter_params[\'heartrate\'].keys()) == 1\n    assert ds_filter._filter_params[\'heartrate\'][\'test_param\'] == 1\n\ndef test_heartrate_filter():\n    """"""Test the function of the heartrate filter.""""""\n    ds_filter = DatasetFilter()\n    ds_filter.add_filter(\'heartrate\')    \n    test_times = array((datetime(2018, 1, 1, 12, 0, 0), \n                        datetime(2018, 1, 1, 12, 1, 0), \n                        datetime(2018, 1, 1, 12, 2, 0), \n                        datetime(2018, 1, 1, 12, 3, 0), \n                        datetime(2018, 1, 1, 12, 4, 0), \n                        datetime(2018, 1, 1, 12, 5, 0), \n                        datetime(2018, 1, 1, 12, 6, 0), \n                        datetime(2018, 1, 1, 12, 7, 0), \n                        datetime(2018, 1, 1, 12, 8, 0), \n                        datetime(2018, 1, 1, 12, 9, 0)))\n    test_values = array((50, 52, 51, 101, 53, 52, 50, 106, 51, 52))\n    res_times, res_values = ds_filter(test_times, test_values)\n    assert (test_times == res_times).all()\n    assert (res_values == array((50, 52, 51, 50, 53, 52, 50, 106, 51, 52))).all()\n\ndef test_no_filter():\n    """"""Test that no filter returns the dataset unmodified.""""""\n    ds_filter = DatasetFilter()\n    test_times = array((datetime(2018, 1, 1, 12, 0, 0), \n                        datetime(2018, 1, 1, 12, 1, 0), \n                        datetime(2018, 1, 1, 12, 2, 0), \n                        datetime(2018, 1, 1, 12, 3, 0), \n                        datetime(2018, 1, 1, 12, 4, 0), \n                        datetime(2018, 1, 1, 12, 5, 0), \n                        datetime(2018, 1, 1, 12, 6, 0), \n                        datetime(2018, 1, 1, 12, 7, 0), \n                        datetime(2018, 1, 1, 12, 8, 0), \n                        datetime(2018, 1, 1, 12, 9, 0)))\n    test_values = array((50, 52, 51, 101, 53, 52, 50, 106, 51, 52))\n    res_times, res_values = ds_filter(test_times, test_values)\n    assert (test_times == res_times).all()\n    assert (test_values == res_values).all()\n'"
tests/test_plotter.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom ..plotting import Plotter, InvalidArgumentsException\nfrom datetime import datetime\nfrom numpy import array\nimport pytest\n\ndef test_lineplot_construction():\n    """"""Test that instances for lineplots get constructed correctly.""""""\n    test_times = array((datetime(2018, 1, 1, 12, 0, 0), \n                        datetime(2018, 1, 1, 12, 1, 0), \n                        datetime(2018, 1, 1, 12, 2, 0), \n                        datetime(2018, 1, 1, 12, 3, 0), \n                        datetime(2018, 1, 1, 12, 4, 0), \n                        datetime(2018, 1, 1, 12, 5, 0), \n                        datetime(2018, 1, 1, 12, 6, 0), \n                        datetime(2018, 1, 1, 12, 7, 0), \n                        datetime(2018, 1, 1, 12, 8, 0), \n                        datetime(2018, 1, 1, 12, 9, 0)))\n    test_values = array((1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n    plotter = Plotter(\'test plot\', timestamps=test_times, values=test_values)\n    assert plotter._plotfunc == plotter._line_plot\n    assert (plotter._timestamps == test_times).all()\n    assert (plotter._values == test_values).all()\n    assert plotter._type == \'test plot\'\n\ndef test_histogram_construction():\n    """"""Test that instances for histogram plots get constructed correctly.""""""\n    test_times = array((datetime(2018, 1, 1, 12, 0, 0), \n                        datetime(2018, 1, 1, 12, 1, 0), \n                        datetime(2018, 1, 1, 12, 2, 0), \n                        datetime(2018, 1, 1, 12, 3, 0), \n                        datetime(2018, 1, 1, 12, 4, 0), \n                        datetime(2018, 1, 1, 12, 5, 0), \n                        datetime(2018, 1, 1, 12, 6, 0), \n                        datetime(2018, 1, 1, 12, 7, 0), \n                        datetime(2018, 1, 1, 12, 8, 0), \n                        datetime(2018, 1, 1, 12, 9, 0)))\n    test_bins = array((1, 2, 3, 4, 5))\n    test_histogram = array([[1, 2, 3, 4, 5],\n                            [1, 2, 3, 4, 5],\n                            [1, 2, 3, 4, 5],\n                            [1, 2, 3, 4, 5],\n                            [1, 2, 3, 4, 5],\n                            [1, 2, 3, 4, 5],\n                            [1, 2, 3, 4, 5],\n                            [1, 2, 3, 4, 5],\n                            [1, 2, 3, 4, 5],\n                            [1, 2, 3, 4, 5]])\n    plotter = Plotter(\'test plot\', timestamps=test_times, bins=test_bins, \n                      histogram=test_histogram)\n    assert plotter._plotfunc == plotter._hist_plot\n    assert (plotter._timestamps == test_times).all()\n    assert (plotter._bins == test_bins).all()\n    assert (plotter._histogram == test_histogram).all()\n    assert plotter._type == \'test plot\'\n    \ndef test_invalid_construction():\n    """"""Test that instantiation with incorrect arguments raise an exception.""""""\n    with pytest.raises(InvalidArgumentsException):\n        plotter = Plotter(\'test plot\', foo=1, bar=1)'"
