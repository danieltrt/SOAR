file_path,api_count,code
gradient_descent_numpy.py,7,"b'\n# coding: utf-8\n\n# Gradient Descent using numpy vector operations:\n\nimport numpy as np\n\n\n# Load the data points:\n\ndef load_data():\n\n    #Loading the dataset.\n    dataset = np.genfromtxt(\'data_points.csv\', delimiter="","")\n\n    X = dataset[:, 0]\n    Y = dataset[:, 1]\n\n    return (X,Y)\n\n\n# Initialise the parameters to zeros (ideally a random point to ease computation):\n\ndef initialise_param(dim):\n    w = np.zeros(dim)\n    b = 0\n    return [w, b]\n\n\n# Compute the activation.\n# In this example we are not using an activation functiona as such but are returing the z value as Y_step\n\ndef activation(w, b, X):\n    return np.add(np.multiply(w,X), b)\n\n\n# Calculate the cost, gradients for a single Iteration:\n\ndef propagate_step(w,b,X,Y):\n\n    #Number of Examples\n    m = float(X.shape[0])\n\n    #Activation (prediction for the step)\n    A = activation(w, b, X)\n\n    #Cost\n    cost = (1/m) * (np.sum(np.square(Y-A)))\n\n    #Gradients\n    dw = (-2/m)*(np.dot(X,(Y-A).T))\n    db = (-2/m)*np.sum(Y-A)\n\n    grads = {\'dw\':dw,\n            \'db\':db}\n\n    return grads, cost\n\n\n# Iterate to optimise the costs:\n\ndef optimise(w, b, X, Y, num_iterations=2000, learning_rate=0.0001):\n\n    costs =[]\n\n    for i in range(num_iterations):\n\n        grads, cost = propagate_step(w, b, X, Y)\n\n        if i%100==0:\n            costs.append(cost)\n            print ""Iteration {itr} : Weights w: {w}, b: {b}, Cost: {cst}"".format(itr =i, w=w, b=b, cst=cost)\n\n        w = w - learning_rate*grads[\'dw\']\n        b = b - learning_rate*grads[\'db\']\n\n    params = {\'w\': w,\n             \'b\':b}\n\n    return params, grads, costs\n\n\n# placeholder for the predict.\n\ndef prediction (w, b, X):\n\n    return activation(w, b, X)\n\n# Model() function to bind all the operations together:\n\ndef model():\n\n    X, Y = load_data()\n\n    w, b = initialise_param((1,))\n\n    params, _, _ = optimise(w, b , X, Y, num_iterations=2000, learning_rate=0.0001)\n\n    X_required = np.array([22.00,])\n\n    return prediction(params[\'w\'], params[\'b\'], X_required)\n\n# In[320]:\n\nif __name__ == \'__main__\':\n\n    print model()\n'"
