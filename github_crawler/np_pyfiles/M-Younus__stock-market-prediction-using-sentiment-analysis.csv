file_path,api_count,code
enn.py,3,"b'import pandas as pd\nimport numpy as np\nimport random, math\n\nrandom.seed(786)\nnp.random.seed(786)\n\ndf = pd.read_csv(\'final_data.csv\')\n\n# convert data to list of lists\ndata = df.values.tolist()\n\n# normalization\n# data = list(map(lambda i: list(map(lambda j: j / 20000, i)), data))\n\ninner_threshold = 0.005;\nrate_var = 0;\n\nfinal_ansr = []\n\nsigmoid=lambda x:1/(1+math.e**(-x))\n\ndef fit_func(rec, i):\n    x1, x2, x3, y = i[0], i[1], i[2], i[3]\n\n    out4 = (x1 * rec[\'data\'][\'w14\']) + (x2 * rec[\'data\'][\'w24\']) + (x3 * rec[\'data\'][\'w34\']) + rec[\'data\'][\'o4\']\n    out4 = sigmoid(out4)\n\n    out5 = (x1 * rec[\'data\'][\'w15\']) + (x2 * rec[\'data\'][\'w25\']) + (x3 * rec[\'data\'][\'w35\']) + rec[\'data\'][\'o5\']\n    out5 = sigmoid(out5)\n\n    out6 = (out4 * rec[\'data\'][\'w46\']) + (out5 * rec[\'data\'][\'w56\']) + rec[\'data\'][\'o6\']\n    out6 = sigmoid(out6)\n\n    err6 = out6 * (1 - out6) * (y - out6)\n\n    if abs(err6) <= inner_threshold:\n        # final_ansr.append(out6 * 20000)\n        rec[\'fitness\'] += 1\n\n\nnList = [];\nm = 20;\nn = 25;\nmutation_prob = 75;\nmutation = 0.5;\n\n# ranges for weights & biases\nwl = -2;\nwr = 2;\nbl = -1;\nbr = 1\n\nfor i in range(n):\n    # floating random weights\n    w14, w15, w24, w25, w34, w35, w46, w56 = np.random.uniform(wl, wr, 8)\n    # floating random biases\n    o4, o5, o6 = np.random.uniform(bl, br, 3)\n\n    nList.append({\'data\': {\'w14\': w14, \'w15\': w15, \'w24\': w24, \'w25\': w25, \'w34\': w34, \'w35\': w35, \'w46\': w46,\n                           \'w56\': w56, \'o4\': o4, \'o5\': o5, \'o6\': o6}, \'fitness\': 0})\n\n# fitness calculation for first time/initial population\nfor rec in nList:\n    for i in data:\n        fit_func(rec, i)\n\ncount = 0;\nfinal_rec = 0\nflag = False\nstop_at=600\nwhile (1):\n    count += 1\n    mList = []\n\n    print(f""gen: {count}"")\n\n    if count > stop_at:\n        final_rec = sorted(nList, key=lambda f: f[\'fitness\'], reverse=True)[0]\n        break\n\n    rec_num = 0\n    for rec in nList:\n        # print(""rec_index: {}"".format(rec_num))\n        rec_num += 1\n        if rec[\'fitness\'] == len(data):\n            print(""rec_index: {}"".format(rec_num))\n            final_rec = rec\n            # print(\'gen: {}\'.format(count))\n            print(\'Answer: {}\'.format(rec))\n            flag = True\n            break\n\n    if flag:\n        break\n\n    for j in range(int(m / 2)):\n        # randomly parent selection(not same)\n        # t=temp\n\n        t = random.sample(range(n), 2)\n\n        p1 = nList[t[0]]\n        p2 = nList[t[1]]\n\n        # crossover\n        ch1 = list(p1[\'data\'].values())[:5] + list(p2[\'data\'].values())[5:]\n        ch2 = list(p2[\'data\'].values())[:5] + list(p1[\'data\'].values())[5:]\n\n        # mutation work\n        for k in [ch1, ch2]:\n            if random.randint(0, 100) <= mutation_prob:\n                # get random for mutation in weights\n                t = random.sample(range(8), 3)\n                # get random for mutation in bias\n                t1 = random.randint(8, 10)\n                # odd,do +ve\n                if random.randint(1, 2) == 1:\n                    # mutation in weights\n                    if (k[t[0]] + mutation) >= wl and (k[t[0]] + mutation) <= wr:\n                        k[t[0]] += mutation\n\n                    if (k[t[1]] + mutation) >= wl and (k[t[1]] + mutation) <= wr:\n                        k[t[1]] += mutation\n\n                    if (k[t[2]] + mutation) >= wl and (k[t[2]] + mutation) <= wr:\n                        k[t[2]] += mutation\n\n                    # mutation in bias\n                    if (k[t1] + mutation) >= bl and (k[t1] + mutation) <= br:\n                        k[t1] += mutation\n\n                # even,do -ve\n                else:\n                    # mutation in weights\n                    if (k[t[0]] - mutation) >= wl and (k[t[0]] - mutation) <= wr:\n                        k[t[0]] -= mutation\n\n                    if (k[t[1]] - mutation) >= wl and (k[t[1]] - mutation) <= wr:\n                        k[t[1]] -= mutation\n\n                    if (k[t[2]] - mutation) >= wl and (k[t[2]] - mutation) <= wr:\n                        k[t[2]] -= mutation\n\n                    # mutation in bias\n                    if (k[t1] - mutation) >= bl and (k[t1] - mutation) <= br:\n                        k[t1] -= mutation\n\n        ch1 = {\'data\': {\'w14\': ch1[0], \'w15\': ch1[1], \'w24\': ch1[2], \'w25\': ch1[3], \'w34\': ch1[4], \'w35\': ch1[5],\n                        \'w46\': ch1[6],\n                        \'w56\': ch1[7], \'o4\': ch1[8], \'o5\': ch1[9], \'o6\': ch1[10]}, \'fitness\': 0}\n\n        ch2 = {\'data\': {\'w14\': ch2[0], \'w15\': ch2[1], \'w24\': ch2[2], \'w25\': ch2[3], \'w34\': ch2[4], \'w35\': ch2[5],\n                        \'w46\': ch2[6],\n                        \'w56\': ch2[7], \'o4\': ch2[8], \'o5\': ch2[9], \'o6\': ch2[10]}, \'fitness\': 0}\n\n        # calculate fitness of children\n        for rec in [ch1, ch2]:\n            for i in data:\n                fit_func(rec, i)\n\n        mList.append(ch1)\n        mList.append(ch2)\n\n    # combine both mList and nList and sort it with respect fit func value,also ovverides the nList,so we used in next iteration\n\n    nList = sorted(nList + mList, key=lambda item: item[\'fitness\'], reverse=True)[:25]\n\n# writing data on the basis of fittest\nfor i in data:\n    x1, x2, x3, y = i[0], i[1], i[2], i[3]\n\n    out4 = (x1 * final_rec[\'data\'][\'w14\']) + (x2 * final_rec[\'data\'][\'w24\']) + (x3 * final_rec[\'data\'][\'w34\']) + final_rec[\'data\'][\'o4\']\n    out4 = sigmoid(out4)\n\n    out5 = (x1 * final_rec[\'data\'][\'w15\']) + (x2 * final_rec[\'data\'][\'w25\']) + (x3 * final_rec[\'data\'][\'w35\']) + final_rec[\'data\'][\'o5\']\n    out5 = sigmoid(out5)\n\n    out6 = (out4 * final_rec[\'data\'][\'w46\']) + (out5 * final_rec[\'data\'][\'w56\']) + final_rec[\'data\'][\'o6\']\n    out6 =  sigmoid(out6)\n\n    err6 = out6 * (1 - out6) * (y - out6)\n\n    final_ansr.append(out6 * 20000)\n\n# final_ansr=final_ansr[-len(data):]\ndf[\'Y-ENN\'] = pd.DataFrame(final_ansr)\ndf.to_csv(\'NN-DATA2.csv\', index=False)\n'"
enn_notebook-updated.py,4,"b'\n# coding: utf-8\n\n# In[1]:\n\n\nimport pandas as pd\nimport numpy as np\nimport random, math\n\n\n# In[2]:\n\n\nrandom.seed(786)\nnp.random.seed(786)\n\n\n# In[3]:\n\n\ndf = pd.read_csv(\'final_data.csv\')\n# df1 = df[[\'compound\',\'neg\',\'neu\',\'pos\',\'Close\']]\ndf1 = df[[\'compound\',\'neg\',\'neu\',\'pos\']]\ndf2=df[[\'Close\']]\n# df = df[[\'neg\',\'neu\',\'pos\',\'Close\']]\n\n\n# In[4]:\n\n\nfrom sklearn import preprocessing\nmin_max_scalar=preprocessing.MinMaxScaler()\ndata=min_max_scalar.fit_transform(df1)\n# X_test=min_max_scalar.fit_transform(X_test)\n# Y_train=min_max_scalar.fit_transform(Y_train)\n# Y_test=min_max_scalar.fit_transform(Y_test)\n\n\n# In[5]:\n\n\ndf1=pd.DataFrame(data)\n\n\n# In[6]:\n\n\ndf1.head()\n\n\n# In[7]:\n\n\nclose_max=df2.max()\ndf2/=close_max\n# df2=np.array(df2)\n\n\n# In[8]:\n\n\ndf2.head()\n\n\n# In[9]:\n\n\ndf1[\'4\']=df2\n\n\n# In[10]:\n\n\ndf1.head()\n\n\n# In[11]:\n\n\n# df[\'Close\']=df[\'Close\']/400\n\n\n# In[12]:\n\n\ndata = df1.values.tolist()\n\n\n# In[13]:\n\n\ndata[:2]\n\n\n# In[14]:\n\n\n# data = data.tolist()\n\n\n# In[15]:\n\n\ninner_threshold = 0.005;\nrate_var = 0;\n\nfinal_ansr = []\n\n\n# In[16]:\n\n\nsigmoid=lambda x:1/(1+math.e**(-x))\n\n\n# In[17]:\n\n\ndef fit_func(rec, i):\n    x1, x2, x3, x4, y = i[0], i[1], i[2], i[3], i[4]\n\n    out5 = (x1 * rec[\'data\'][\'w15\']) + (x2 * rec[\'data\'][\'w25\']) + (x3 * rec[\'data\'][\'w35\']) + (x4 * rec[\'data\'][\'w45\']) + rec[\'data\'][\'o5\']\n    out5 = sigmoid(out5)\n\n    out6 = (x1 * rec[\'data\'][\'w16\']) + (x2 * rec[\'data\'][\'w26\']) + (x3 * rec[\'data\'][\'w36\']) + (x4 * rec[\'data\'][\'w46\']) + rec[\'data\'][\'o6\']\n    out6 = sigmoid(out6)\n    \n    out7 = (x1 * rec[\'data\'][\'w17\']) + (x2 * rec[\'data\'][\'w27\']) + (x3 * rec[\'data\'][\'w37\']) + (x4 * rec[\'data\'][\'w47\']) + rec[\'data\'][\'o7\']\n    out7 = sigmoid(out7)\n\n    out8 = (out5 * rec[\'data\'][\'w58\']) + (out6 * rec[\'data\'][\'w68\']) + (out7 * rec[\'data\'][\'w78\']) + rec[\'data\'][\'o8\']\n    out8 = sigmoid(out8)\n    \n    out9 = (out5 * rec[\'data\'][\'w59\']) + (out6 * rec[\'data\'][\'w69\']) + (out7 * rec[\'data\'][\'w79\']) + rec[\'data\'][\'o9\']\n    out9 = sigmoid(out9)\n\n    out10 = (out8 * rec[\'data\'][\'w810\']) + (out9 * rec[\'data\'][\'w910\']) + rec[\'data\'][\'o10\']\n    out10 = sigmoid(out10)\n\n    err10 = out10 * (1 - out10) * (y - out10)\n\n    if abs(err10) <= inner_threshold:\n        # final_ansr.append(out6 * 20000)\n        rec[\'fitness\'] += 1\n\n\n# In[18]:\n\n\nnList = [];\nm = 20;\nn = 25;\nmutation_prob = 75;\nmutation = 0.5;\n\n\n# In[19]:\n\n\n# ranges for weights & biases\nwl = -2;\nwr = 2;\nbl = -1;\nbr = 1\n\n\n# In[20]:\n\n\ntotal_weights=20\ntotal_biases=6\n\n\n# In[21]:\n\n\nfor i in range(n):\n    # floating random weights\n    w15, w16, w17, w25, w26,w27, w35, w36,w37, w45, w46,w47, w58,w59,w68,w69,w78,w79, w810, w910 = np.random.uniform(wl, wr, total_weights)\n    # floating random biases\n    o5, o6, o7,o8, o9, o10 = np.random.uniform(bl, br, total_biases)\n\n    nList.append({\'data\': {\'w15\': w15, \'w16\': w16, \'w17\': w17, \'w25\': w25, \'w26\': w26, \'w27\': w27,\n                           \'w35\': w35,\'w36\': w36, \'w37\': w37, \'w45\': w45, \'w46\': w46,\n                           \'w47\': w47, \'w58\': w58, \'w59\': w59, \'w68\': w68, \'w69\': w69, \'w78\': w78,\n                           \'w79\': w79,\'w810\': w810,\'w910\': w910, \'o5\': o5, \'o6\': o6, \'o7\': o7,\n                           \'o8\': o8, \'o9\': o9, \'o10\': o10},\n                           \'fitness\': 0})\n\n\n# In[22]:\n\n\n# fitness calculation for first time/initial population\nfor rec in nList:\n    for i in data:\n        fit_func(rec, i)\n        \n\n\n# In[23]:\n\n\ncount = 0;\nfinal_rec = 0\nflag = False\nstop_at=100000\n\n\n# In[ ]:\n\n\nwhile (1):\n    count += 1\n    mList = []\n\n    print(f""gen: {count}"")\n\n    if count > stop_at:\n        final_rec = sorted(nList, key=lambda f: f[\'fitness\'], reverse=True)[0]\n        break\n\n    rec_num = 0\n    for rec in nList:\n        # print(""rec_index: {}"".format(rec_num))\n        rec_num += 1\n        if rec[\'fitness\'] == len(data):\n            print(""rec_index: {}"".format(rec_num))\n            final_rec = rec\n            # print(\'gen: {}\'.format(count))\n            print(\'Answer: {}\'.format(rec))\n            flag = True\n            break\n\n    if flag:\n        break\n\n    for j in range(int(m / 2)):\n        # randomly parent selection(not same)\n        # t=temp\n\n        t = random.sample(range(n), 2)\n\n        p1 = nList[t[0]]\n        p2 = nList[t[1]]\n\n        # crossover\n        crossover_point=int((total_weights+total_biases)/2)\n        ch1 = list(p1[\'data\'].values())[:crossover_point] + list(p2[\'data\'].values())[crossover_point:]\n        ch2 = list(p2[\'data\'].values())[:crossover_point] + list(p1[\'data\'].values())[crossover_point:]\n\n        # mutation work\n        for k in [ch1, ch2]:\n            if random.randint(0, 100) <= mutation_prob:\n                # get random for mutation in weights\n                t = random.sample(range(total_weights), 3)\n                # get random for mutation in bias\n                t1 = random.randint(total_weights, (total_weights+total_biases)-1)\n                # odd,do +ve\n                if random.randint(1, 2) == 1:\n                    # mutation in weights\n                    if (k[t[0]] + mutation) >= wl and (k[t[0]] + mutation) <= wr:\n                        k[t[0]] += mutation\n\n                    if (k[t[1]] + mutation) >= wl and (k[t[1]] + mutation) <= wr:\n                        k[t[1]] += mutation\n\n                    if (k[t[2]] + mutation) >= wl and (k[t[2]] + mutation) <= wr:\n                        k[t[2]] += mutation\n\n                    # mutation in bias\n                    if (k[t1] + mutation) >= bl and (k[t1] + mutation) <= br:\n                        k[t1] += mutation\n\n                # even,do -ve\n                else:\n                    # mutation in weights\n                    if (k[t[0]] - mutation) >= wl and (k[t[0]] - mutation) <= wr:\n                        k[t[0]] -= mutation\n\n                    if (k[t[1]] - mutation) >= wl and (k[t[1]] - mutation) <= wr:\n                        k[t[1]] -= mutation\n\n                    if (k[t[2]] - mutation) >= wl and (k[t[2]] - mutation) <= wr:\n                        k[t[2]] -= mutation\n\n                    # mutation in bias\n                    if (k[t1] - mutation) >= bl and (k[t1] - mutation) <= br:\n                        k[t1] -= mutation\n\n                        \n        ch1 = {\'data\': {\'w15\': ch1[0], \'w16\': ch1[1], \'w17\': ch1[2], \'w25\': ch1[3], \'w26\': ch1[4], \'w27\': ch1[5],\n                        \'w35\': ch1[6],\n                        \'w36\': ch1[7], \'w37\': ch1[8], \'w45\': ch1[9], \'w46\': ch1[10],\n                        \'w47\': ch1[11], \'w58\': ch1[12], \'w59\': ch1[13], \'w68\': ch1[14], \'w69\': ch1[15], \'w78\': ch1[16],\n                        \'w79\': ch1[17],\n                        \'w810\': ch1[18], \'w910\': ch1[19], \'o5\': ch1[20], \'o6\': ch1[21],\n                        \'o7\': ch1[22], \'o8\': ch1[23], \'o9\': ch1[24], \'o10\': ch1[25]}, \'fitness\': 0}\n\n        ch2 = {\'data\': {\'w15\': ch2[0], \'w16\': ch2[1], \'w17\': ch2[2], \'w25\': ch2[3], \'w26\': ch2[4], \'w27\': ch2[5],\n                        \'w35\': ch2[6],\n                        \'w36\': ch2[7], \'w37\': ch2[8], \'w45\': ch2[9], \'w46\': ch2[10],\n                        \'w47\': ch2[11], \'w58\': ch2[12], \'w59\': ch2[13], \'w68\': ch2[14], \'w69\': ch2[15], \'w78\': ch2[16],\n                        \'w79\': ch2[17],\n                        \'w810\': ch2[18], \'w910\': ch2[19], \'o5\': ch2[20], \'o6\': ch2[21],\n                        \'o7\': ch2[22], \'o8\': ch2[23], \'o9\': ch2[24], \'o10\': ch2[25]}, \'fitness\': 0}\n\n\n        # calculate fitness of children\n        for rec in [ch1, ch2]:\n            for i in data:\n                fit_func(rec, i)\n\n        mList.append(ch1)\n        mList.append(ch2)\n\n    # combine both mList and nList and sort it with respect fit func value,also ovverides the nList,so we used in next iteration\n\n    nList = sorted(nList + mList, key=lambda item: item[\'fitness\'], reverse=True)[:25]\n\n\n# In[ ]:\n\n\nfor i in data:\n    x1, x2, x3, x4, y = i[0], i[1], i[2], i[3], i[4]\n\n    out5 = (x1 * final_rec[\'data\'][\'w15\']) + (x2 * final_rec[\'data\'][\'w25\']) + (x3 * final_rec[\'data\'][\'w35\']) + (x4 * final_rec[\'data\'][\'w45\']) + final_rec[\'data\'][\'o5\']\n    out5 = sigmoid(out5)\n\n    out6 = (x1 * final_rec[\'data\'][\'w16\']) + (x2 * final_rec[\'data\'][\'w26\']) + (x3 * final_rec[\'data\'][\'w36\']) + (x4 * final_rec[\'data\'][\'w46\']) + final_rec[\'data\'][\'o6\']\n    out6 = sigmoid(out6)\n    \n    out7 = (x1 * final_rec[\'data\'][\'w17\']) + (x2 * final_rec[\'data\'][\'w27\']) + (x3 * final_rec[\'data\'][\'w37\']) + (x4 * final_rec[\'data\'][\'w47\']) + final_rec[\'data\'][\'o7\']\n    out7 = sigmoid(out7)\n\n    out8 = (out5 * final_rec[\'data\'][\'w58\']) + (out6 * final_rec[\'data\'][\'w68\']) + (out7 * final_rec[\'data\'][\'w78\']) + final_rec[\'data\'][\'o8\']\n    out8 = sigmoid(out8)\n    \n    out9 = (out5 * final_rec[\'data\'][\'w59\']) + (out6 * final_rec[\'data\'][\'w69\']) + (out7 * final_rec[\'data\'][\'w79\']) + final_rec[\'data\'][\'o9\']\n    out9 = sigmoid(out9)\n\n    out10 = (out8 * final_rec[\'data\'][\'w810\']) + (out9 * final_rec[\'data\'][\'w910\']) + final_rec[\'data\'][\'o10\']\n    out10 = sigmoid(out10)\n\n    final_ansr.append(out10*close_max)\n\n\n# In[ ]:\n\n\n# final_ansr=final_ansr[-len(data):]\ndf[\'Y-ENN\'] = pd.DataFrame(final_ansr)\ndf.to_csv(\'NN-DATA2.csv\', index=False)\n\n\n# In[ ]:\n\n\nfinal_rec\n\n\n# In[ ]:\n\n\nfrom sklearn.metrics import r2_score\nr2_score(df[[\'Close\']],df[\'Y-ENN\'])\n\n\n# In[ ]:\n\n\ndf[[\'Close\']].head()\n\n\n# In[ ]:\n\n\ndf[\'Y-ENN\'].head()\n\n'"
keras_work_colab.py,0,"b'\n# coding: utf-8\n\n# In[265]:\n\n\nimport pandas as pd\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import r2_score\n\n\n# In[266]:\n\n\n# from google.colab import files\n\n# uploaded = files.upload()\n\n# for fn in uploaded.keys():\n#   print(\'User uploaded file ""{name}"" with length {length} bytes\'.format(\n#       name=fn, length=len(uploaded[fn])))\n\n\n# In[267]:\n\n\ndf=pd.read_csv(\'final_data.csv\')\n\n\n# In[268]:\n\n\ndf.head()\n\n\n# In[269]:\n\n\nX=df[[\'compound\',\'neg\',\'neu\',\'pos\']]\n# X=df[[\'neg\',\'neu\',\'pos\']]\n# Y=df[[\'Close\']]/400     #normalize it\nY=df[[\'Close\']]\n\n\n# In[270]:\n\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n\n\n# In[271]:\n\n\nfrom sklearn import preprocessing\nmin_max_scalar=preprocessing.MinMaxScaler()\nX_train=min_max_scalar.fit_transform(X_train)\nX_test=min_max_scalar.fit_transform(X_test)\nY_train=min_max_scalar.fit_transform(Y_train)\nY_test=min_max_scalar.fit_transform(Y_test)\n\n\n# In[272]:\n\n\n# from sklearn.preprocessing import StandardScaler\n# scalar=StandardScaler()\n# scalar.fit(X_train)\n# X_train=scalar.transform(X_train)\n# X_test=scalar.transform(X_test)\n\n\n# In[273]:\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import losses\nfrom keras import activations\n\n\n# In[274]:\n\n\nmodel=Sequential()\n\n\n# In[275]:\n\n\nmodel.add(Dense(4,activation=activations.sigmoid,input_shape=(4,)))\n# model.add(Dense(3,activation=\'relu\',input_shape=(3,)))\nmodel.add(Dense(3,activation=activations.sigmoid))\nmodel.add(Dense(2,activation=activations.sigmoid))\n# model.add(Dense(100,activation=activations.sigmoid))\n# model.add(Dense(100,activation=activations.sigmoid))\n# model.add(Dense(100,activation=activations.sigmoid))\n# model.add(Dense(100,activation=activations.sigmoid))\nmodel.add(Dense(1,activation=activations.sigmoid))\n\n\n# In[276]:\n\n\nmodel.compile(optimizer=\'adam\',loss=losses.mean_absolute_error)\n\n\n# In[277]:\n\n\n# while 1:\n#     model.fit(X_train,Y_train,epochs=500)\n#     y_pred=model.predict(X_test)\n#     falto=r2_score(Y_test,y_pred)\n#     print(falto)\n#     if falto >= 70.0:\n#         break\n\n\n# In[278]:\n\n\nmodel.fit(X_train,Y_train,verbose=2,epochs=1000000)\n# model.fit(X_train,Y_train,verbose=2)\n\n\n# In[243]:\n\n\ny_pred=model.predict(X_test)\n\n\n# In[244]:\n\n\nmodel.evaluate(X_train,Y_train)\n\n\n# In[245]:\n\n\nmodel.evaluate(X_test,Y_test)\n\n\n# In[246]:\n\n\nprint(r2_score(Y_test,y_pred))\n\n\n# In[247]:\n\n\npd.DataFrame(model.predict(X)).to_csv(\'ansr_y_pred.csv\')\n\n\n# In[248]:\n\n\ny_pred\n\n\n# In[249]:\n\n\nY_test\n\n\n# In[250]:\n\n\nmodel.layers[0].get_weights()\n\n\n# In[251]:\n\n\nmodel.layers[1].get_weights()\n\n\n# In[252]:\n\n\nmodel.layers[2].get_weights()\n\n\n# In[253]:\n\n\nmodel.layers[3].get_weights()\n\n\n# In[254]:\n\n\n# model.save_weights(""model.h5"")\n\n\n# In[255]:\n\n\nmodel_json = model.to_json()\n\n\n# In[256]:\n\n\nmodel_json\n\n\n# In[257]:\n\n\nfrom keras.models import load_model\n\n\n# In[258]:\n\n\n# model.load_weights(\'model_full.h5\')\n\n\n# In[259]:\n\n\n# model.layers[3].get_weights()\n\n\n# In[260]:\n\n\n# y_pred=model.predict(X_test)\n\n\n# In[261]:\n\n\n# print(r2_score(Y_test,y_pred))\n\n\n# In[262]:\n\n\nmodel.save(\'model_full.h5\')\n\n\n# In[263]:\n\n\n# model=load_model(\'model_full.h5\')\n\n'"
plot-NN.py,0,"b'import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf1=pd.read_csv(\'NN-DATA-all.csv\',usecols=[\'Y\'])\n\ndf2=pd.read_csv(\'NN-DATA-all.csv\',usecols=[\'Y-ENN\'])\n\ndf3=pd.read_csv(\'NN-DATA-all.csv\',usecols=[\'Y-ANN\'])\n\ndata1 = df1.values.tolist()\ndata2 = df2.values.tolist()\ndata3 = df3.values.tolist()\n\nplt.plot(range(705),data1, label=\'Y\')\nplt.plot(range(705),data2, label=\'Y-ENN\')\nplt.plot(range(705),data3, label=\'Y-ANN\')\n\nplt.xlabel(\'Row Number\')\nplt.ylabel(\'Values\')\n\nplt.title(""NN Plot"")\n\nplt.legend()\n\nplt.show()'"
