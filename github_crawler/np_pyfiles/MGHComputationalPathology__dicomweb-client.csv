file_path,api_count,code
setup.py,0,"b""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport io\nimport re\n\nimport setuptools\n\nwith io.open('src/dicomweb_client/__init__.py', 'rt', encoding='utf8') as f:\n    version = re.search(r'__version__ = \\'(.*?)\\'', f.read()).group(1)\n\n\nsetuptools.setup(\n    name='dicomweb-client',\n    version=version,\n    description='Client for DICOMweb RESTful services.',\n    author='Markus D. Herrmann',\n    maintainer='Markus D. Herrmann',\n    url='https://github.com/mghcomputationalpathology/dicomweb-client',\n    license='MIT',\n    platforms=['Linux', 'MacOS', 'Windows'],\n    classifiers=[\n        'Environment :: Web Environment',\n        'License :: OSI Approved :: MIT License',\n        'Operating System :: MacOS',\n        'Operating System :: Microsoft :: Windows',\n        'Operating System :: POSIX :: Linux',\n        'Intended Audience :: Science/Research',\n        'Topic :: Internet :: WWW/HTTP',\n        'Topic :: Multimedia :: Graphics',\n        'Topic :: Scientific/Engineering :: Information Analysis',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.5',\n        'Programming Language :: Python :: 3.6',\n        'Programming Language :: Python :: 3.7',\n        'Programming Language :: Python :: 3.8',\n        'Development Status :: 4 - Beta',\n    ],\n    entry_points={\n        'console_scripts': ['dicomweb_client = dicomweb_client.cli:_main'],\n    },\n    include_package_data=True,\n    packages=setuptools.find_packages('src'),\n    package_dir={'': 'src'},\n    extras_require={\n        'gcp': [\n            'google-auth>=1.6',\n            'google-oauth>=1.0',\n        ],\n    },\n    python_requires='>3.5',\n    install_requires=[\n        'pydicom>=1.0',\n        'requests>=2.18',\n        'retrying>=1.3.3',\n    ]\n)\n"""
docs/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/stable/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nimport pkg_resources\n\nsource_dir = os.path.dirname(__file__)\npkg_dir = os.path.join(source_dir, \'..\', \'..\', \'src\', \'dicomweb_client\')\nsys.path.insert(0, os.path.abspath(pkg_dir))\n\n# -- Project information -----------------------------------------------------\n\nproject = \'dicomweb-client\'\ncopyright = \'2020, MGH Computational Pathology\'\nauthor = \'Markus D. Herrmann\'\n\n# The full version, including alpha/beta/rc tags\ntry:\n    release = pkg_resources.get_distribution(\'dicomweb_client\').version\nexcept pkg_resources.DistributionNotFound:\n    print(\'Package ""dicomweb-client"" must be installed to build docs.\')\n    sys.exit(1)\n# The short X.Y version\nversion = \'.\'.join(release.split(\'.\')[:2])\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinxcontrib.autoprogram\',\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.napoleon\',\n    \'sphinx_autodoc_typehints\',\n]\n\nnapoleon_google_docstring = False\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path .\nexclude_patterns = []\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# Concatenate docstring of class definion and __init__ method definition.\nautoclass_content = \'both\'\n\ntypehints_fully_qualified = True\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\'t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\'localtoc.html\', \'relations.html\', \'sourcelink.html\',\n# \'searchbox.html\']``.\n#\n# html_sidebars = {}\n\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'DICOMwebClientdoc\'\n\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'DICOMwebClient.tex\', \'DICOMweb Client Documentation\',\n     \'Markus D. Herrmann\', \'manual\'),\n]\n\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'dicomwebclient\', \'DICOMweb Client Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'DICOMwebClient\', \'DICOMweb Client Documentation\',\n     author, \'DICOMwebClient\', \'Client for DICOMweb services.\',\n     \'Miscellaneous\'),\n]\n\n\n# -- Extension configuration -------------------------------------------------\n'"
tests/conftest.py,0,"b""from pathlib import Path\n\nimport pytest\n\nfrom dicomweb_client.cli import _get_parser\nfrom dicomweb_client.api import DICOMwebClient\n\n\n@pytest.fixture\ndef parser():\n    '''Instance of `argparse.Argparser`.'''\n    return _get_parser()\n\n\n@pytest.fixture\ndef cache_dir():\n    '''Directory where responses are cached.'''\n    return Path(__file__).parent.parent.joinpath('data')\n\n\n@pytest.fixture\ndef client(httpserver):\n    '''Instance of `dicomweb_client.api.DICOMwebClient`.'''\n    return DICOMwebClient(httpserver.url)\n"""
tests/test_api.py,0,"b'import os\nimport json\nimport xml.etree.ElementTree as ET\nfrom io import BytesIO\nfrom http import HTTPStatus\n\nimport pytest\nimport pydicom\nfrom requests.exceptions import HTTPError\nfrom retrying import RetryError\n\nfrom dicomweb_client.api import (\n    DICOMwebClient,\n    load_json_dataset,\n    _load_xml_dataset\n)\n\n\ndef test_url(httpserver):\n    protocol = \'http\'\n    host = \'localhost\'\n    port = 8080\n    path = \'/dcm4chee-arc/aets/DCM4CHEE/rs\'\n    url = \'{protocol}://{host}:{port}{path}\'.format(\n        protocol=protocol, host=host, port=port, path=path\n    )\n    client = DICOMwebClient(url)\n    assert client.protocol == protocol\n    assert client.host == host\n    assert client.port == port\n    assert client.url_prefix == path\n    assert client.qido_url_prefix is None\n    assert client.wado_url_prefix is None\n    assert client.stow_url_prefix is None\n\n\ndef test_url_prefixes(httpserver):\n    wado_url_prefix = \'wado\'\n    qido_url_prefix = \'qido\'\n    stow_url_prefix = \'stow\'\n    client = DICOMwebClient(\n        httpserver.url,\n        wado_url_prefix=wado_url_prefix,\n        qido_url_prefix=qido_url_prefix,\n        stow_url_prefix=stow_url_prefix,\n    )\n    assert client.url_prefix == \'\'\n    assert client.qido_url_prefix == qido_url_prefix\n    assert client.wado_url_prefix == wado_url_prefix\n    assert client.stow_url_prefix == stow_url_prefix\n\n\ndef test_proxies(httpserver):\n    protocol = \'http\'\n    address = \'foo.com\'\n    proxies = {protocol: address}\n    client = DICOMwebClient(httpserver.url, proxies=proxies)\n    assert client._session.proxies[protocol] == address\n\n\ndef test_headers(httpserver):\n    name = \'my-token\'\n    value = \'topsecret\'\n    headers = {name: value}\n    client = DICOMwebClient(httpserver.url, headers=headers)\n    client.store_instances([])\n    request = httpserver.requests[0]\n    assert request.headers[name] == value\n\n\ndef test_lookup_tag(httpserver, client):\n    assert client.lookup_tag(\'StudyInstanceUID\') == \'0020000D\'\n    assert client.lookup_tag(\'SeriesInstanceUID\') == \'0020000E\'\n    assert client.lookup_tag(\'SOPInstanceUID\') == \'00080018\'\n    assert client.lookup_tag(\'PixelData\') == \'7FE00010\'\n\n\ndef test_lookup_keyword(httpserver, client):\n    assert client.lookup_keyword(\'0020000D\') == \'StudyInstanceUID\'\n    assert client.lookup_keyword(\'0020000E\') == \'SeriesInstanceUID\'\n    assert client.lookup_keyword(\'00080018\') == \'SOPInstanceUID\'\n    assert client.lookup_keyword(\'7FE00010\') == \'PixelData\'\n\n\ndef test_set_http_retry_params(httpserver, client):\n    retry = True\n    retriable_error_codes = (HTTPStatus.TOO_MANY_REQUESTS,\n                             HTTPStatus.SERVICE_UNAVAILABLE)\n    max_attempts = 10\n    wait_exponential_multiplier = 100\n    client = DICOMwebClient(httpserver.url)\n    client.set_http_retry_params(retry, max_attempts,\n                                 wait_exponential_multiplier,\n                                 retriable_error_codes)\n    assert client._http_retry == retry\n    assert client._http_retrable_errors == retriable_error_codes\n    assert client._max_attempts == max_attempts\n    assert client._wait_exponential_multiplier == wait_exponential_multiplier\n\n\ndef test_search_for_studies(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'search_for_studies.json\'))\n    with open(cache_filename, \'r\') as f:\n        content = f.read()\n    parsed_content = json.loads(content)\n    headers = {\'content-type\': \'application/dicom+json\'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    assert client.search_for_studies() == parsed_content\n    request = httpserver.requests[0]\n    assert request.path == \'/studies\'\n    assert all(\n        mime[0] in (\'application/json\', \'application/dicom+json\')\n        for mime in request.accept_mimetypes\n    )\n\n\ndef test_search_for_studies_with_retries(httpserver, client, cache_dir):\n    headers = {\'content-type\': \'application/dicom+json\'}\n    max_attempts = 3\n    client.set_http_retry_params(\n        retry=True,\n        max_attempts=max_attempts,\n        wait_exponential_multiplier=10\n    )\n    httpserver.serve_content(\n        content=\'\',\n        code=HTTPStatus.REQUEST_TIMEOUT,\n        headers=headers\n    )\n    with pytest.raises(RetryError):\n        client.search_for_studies()\n    assert len(httpserver.requests) == max_attempts\n\n\ndef test_search_for_studies_with_no_retries(httpserver, client, cache_dir):\n    client.set_http_retry_params(retry=False)\n    headers = {\'content-type\': \'application/dicom+json\'}\n    httpserver.serve_content(\n        content=\'\',\n        code=HTTPStatus.REQUEST_TIMEOUT,\n        headers=headers\n    )\n    with pytest.raises(HTTPError):\n        client.search_for_studies()\n    assert len(httpserver.requests) == 1\n\n\ndef test_search_for_studies_qido_prefix(httpserver, client, cache_dir):\n    client.qido_url_prefix = \'qidors\'\n    cache_filename = str(cache_dir.joinpath(\'search_for_studies.json\'))\n    with open(cache_filename, \'r\') as f:\n        content = f.read()\n    headers = {\'content-type\': \'application/dicom+json\'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    client.search_for_studies()\n    request = httpserver.requests[0]\n    assert request.path == \'/qidors/studies\'\n\n\ndef test_search_for_studies_limit_offset(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'search_for_studies.json\'))\n    with open(cache_filename, \'r\') as f:\n        data = json.loads(f.read())\n    # We will limit the search to 2 studies starting with the 2nd.\n    content = json.dumps(data[1:3])\n    parsed_content = json.loads(content)\n    headers = {\'content-type\': \'application/dicom+json\'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    assert client.search_for_studies(limit=2, offset=1) == parsed_content\n    request = httpserver.requests[0]\n    assert (\n        request.query_string.decode() == \'limit=2&offset=1\' or\n        request.query_string.decode() == \'offset=1&limit=2\'\n    )\n    assert request.path == \'/studies\'\n    assert all(\n        mime[0] in (\'application/json\', \'application/dicom+json\')\n        for mime in request.accept_mimetypes\n    )\n\n\ndef test_search_for_series(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'search_for_series.json\'))\n    with open(cache_filename, \'r\') as f:\n        content = f.read()\n    parsed_content = json.loads(content)\n    headers = {\'content-type\': \'application/dicom+json\'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    assert client.search_for_series() == parsed_content\n    request = httpserver.requests[0]\n    assert request.path == \'/series\'\n    assert all(\n        mime[0] in (\'application/json\', \'application/dicom+json\')\n        for mime in request.accept_mimetypes\n    )\n\n\ndef test_search_for_series_wrong_uid_type(httpserver, client, cache_dir):\n    study_instance_uid = [\'1.2.3.4\']\n    with pytest.raises(TypeError):\n        client.search_for_series(study_instance_uid=study_instance_uid)\n\n\ndef test_search_for_series_wrong_uid_value(httpserver, client, cache_dir):\n    study_instance_uid = \'1_2_3_4\'\n    with pytest.raises(ValueError):\n        client.search_for_series(study_instance_uid=study_instance_uid)\n\n\ndef test_search_for_series_limit_offset(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'search_for_series.json\'))\n    with open(cache_filename, \'r\') as f:\n        data = json.loads(f.read())\n    content = json.dumps(data[1:3])\n    parsed_content = json.loads(content)\n    headers = {\'content-type\': \'application/dicom+json\'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    assert client.search_for_studies(limit=2, offset=1) == parsed_content\n    request = httpserver.requests[0]\n    assert (\n        request.query_string.decode() == \'limit=2&offset=1\' or\n        request.query_string.decode() == \'offset=1&limit=2\'\n    )\n    assert request.path == \'/studies\'\n    assert all(\n        mime[0] in (\'application/json\', \'application/dicom+json\')\n        for mime in request.accept_mimetypes\n    )\n\n\ndef test_search_for_instances(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'search_for_instances.json\'))\n    with open(cache_filename, \'r\') as f:\n        content = f.read()\n    parsed_content = json.loads(content)\n    headers = {\'content-type\': \'application/dicom+json\'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    assert client.search_for_instances() == parsed_content\n    request = httpserver.requests[0]\n    assert request.path == \'/instances\'\n    assert all(\n        mime[0] in (\'application/json\', \'application/dicom+json\')\n        for mime in request.accept_mimetypes\n    )\n\n\ndef test_search_for_instances_limit_offset(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'search_for_instances.json\'))\n    with open(cache_filename, \'r\') as f:\n        content = f.read()\n    parsed_content = json.loads(content)\n    headers = {\'content-type\': \'application/dicom+json\'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    assert client.search_for_instances(limit=2, offset=1) == parsed_content\n    request = httpserver.requests[0]\n    assert (\n        request.query_string.decode() == \'limit=2&offset=1\' or\n        request.query_string.decode() == \'offset=1&limit=2\'\n    )\n    assert request.path == \'/instances\'\n    assert all(\n        mime[0] in (\'application/json\', \'application/dicom+json\')\n        for mime in request.accept_mimetypes\n    )\n\n\ndef test_search_for_instances_includefields(httpserver, client, cache_dir):\n    headers = {\'content-type\': \'application/dicom+json\'}\n    httpserver.serve_content(content=\'\', code=200, headers=headers)\n    f1 = \'StudyInstanceUID\'\n    f2 = \'SeriesInstanceUID\'\n    client.search_for_instances(fields={f1, f2})\n    request = httpserver.requests[0]\n    query_string_opt_1 = \'includefield={}&includefield={}\'.format(f1, f2)\n    query_string_opt_2 = \'includefield={}&includefield={}\'.format(f2, f1)\n    assert (\n        request.query_string.decode() == query_string_opt_1 or\n        request.query_string.decode() == query_string_opt_2\n    )\n    assert request.path == \'/instances\'\n    assert all(\n        mime[0] in (\'application/json\', \'application/dicom+json\')\n        for mime in request.accept_mimetypes\n    )\n\n\ndef test_retrieve_instance_metadata(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'retrieve_instance_metadata.json\'))\n    with open(cache_filename, \'r\') as f:\n        content = f.read()\n    parsed_content = json.loads(content)\n    headers = {\'content-type\': \'application/dicom+json\'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    result = client.retrieve_instance_metadata(\n        study_instance_uid, series_instance_uid, sop_instance_uid\n    )\n    assert result == parsed_content[0]\n    request = httpserver.requests[0]\n    expected_path = (\n        \'/studies/{study_instance_uid}/series/{series_instance_uid}/instances\'\n        \'/{sop_instance_uid}/metadata\'.format(**locals())\n    )\n    assert request.path == expected_path\n    assert all(\n        mime[0] in (\'application/json\', \'application/dicom+json\')\n        for mime in request.accept_mimetypes\n    )\n\n\ndef test_retrieve_instance_metadata_wado_prefix(httpserver, client, cache_dir):\n    client.wado_url_prefix = \'wadors\'\n    cache_filename = str(cache_dir.joinpath(\'retrieve_instance_metadata.json\'))\n    with open(cache_filename, \'r\') as f:\n        content = f.read()\n    parsed_content = json.loads(content)\n    headers = {\'content-type\': \'application/dicom+json\'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    client.retrieve_instance_metadata(\n        study_instance_uid, series_instance_uid, sop_instance_uid\n    )\n    request = httpserver.requests[0]\n    expected_path = (\n        \'/wadors/studies/{study_instance_uid}\'\n        \'/series/{series_instance_uid}\'\n        \'/instances/{sop_instance_uid}/metadata\'.format(**locals())\n    )\n    assert request.path == expected_path\n\n\ndef test_retrieve_instance(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'file.dcm\'))\n    with open(cache_filename, \'rb\') as f:\n        content = f.read()\n    headers = {\n        \'content-type\': (\n            \'multipart/related; \'\n            \'type=""application/dicom""\'\n        ),\n    }\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    result = client.retrieve_instance(\n        study_instance_uid, series_instance_uid, sop_instance_uid\n    )\n    with BytesIO() as fp:\n        pydicom.dcmwrite(fp, result)\n        raw_result = fp.getvalue()\n    assert raw_result == content\n    request = httpserver.requests[0]\n    expected_path = (\n        \'/studies/{study_instance_uid}/series/{series_instance_uid}/instances\'\n        \'/{sop_instance_uid}\'.format(**locals())\n    )\n    assert request.path == expected_path\n    assert request.accept_mimetypes[0][0][:43] == headers[\'content-type\'][:43]\n\n\ndef test_retrieve_instance_any_transfer_syntax(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'file.dcm\'))\n    with open(cache_filename, \'rb\') as f:\n        content = f.read()\n    headers = {\n        \'content-type\': \'multipart/related; type=""application/dicom""\',\n    }\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    client.retrieve_instance(\n        study_instance_uid, series_instance_uid, sop_instance_uid,\n        media_types=(\n            (\'application/dicom\', \'*\', ),\n        )\n    )\n    request = httpserver.requests[0]\n    assert request.accept_mimetypes[0][0][:43] == headers[\'content-type\'][:43]\n\n\ndef test_retrieve_instance_default_transfer_syntax(httpserver, client,\n                                                   cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'file.dcm\'))\n    with open(cache_filename, \'rb\') as f:\n        content = f.read()\n    headers = {\n        \'content-type\': \'multipart/related; type=""application/dicom""\',\n    }\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    client.retrieve_instance(\n        study_instance_uid, series_instance_uid, sop_instance_uid,\n        media_types=(\n            (\'application/dicom\', \'1.2.840.10008.1.2.1\', ),\n        )\n    )\n    request = httpserver.requests[0]\n    assert request.accept_mimetypes[0][0][:43] == headers[\'content-type\'][:43]\n\n\ndef test_retrieve_instance_wrong_transfer_syntax(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'file.dcm\'))\n    with open(cache_filename, \'rb\') as f:\n        content = f.read()\n    headers = {\n        \'content-type\': \'multipart/related; type=""application/dicom""\',\n    }\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    with pytest.raises(ValueError):\n        client.retrieve_instance(\n            study_instance_uid, series_instance_uid, sop_instance_uid,\n            media_types=(\n                (\'application/dicom\', \'1.2.3\', ),\n            )\n        )\n\n\ndef test_retrieve_instance_wrong_mime_type(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'file.dcm\'))\n    with open(cache_filename, \'rb\') as f:\n        content = f.read()\n    headers = {\n        \'content-type\': \'multipart/related; type=""image/dicom""\',\n    }\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    with pytest.raises(ValueError):\n        client.retrieve_instance(\n            study_instance_uid, series_instance_uid, sop_instance_uid,\n            media_types=(\n                (\'image/dicom\', \'1.2.840.10008.1.2.1\', ),\n            )\n        )\n\n\ndef test_retrieve_instance_frames_jpeg(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'retrieve_instance_pixeldata.jpg\'))\n    with open(cache_filename, \'rb\') as f:\n        content = f.read()\n    headers = {\n        \'content-type\': \'multipart/related; type=""image/jpeg""\',\n    }\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    frame_numbers = [114]\n    frame_list = \',\'.join([str(n) for n in frame_numbers])\n    result = client.retrieve_instance_frames(\n        study_instance_uid, series_instance_uid, sop_instance_uid,\n        frame_numbers, media_types=(\'image/jpeg\', )\n    )\n    assert result == [content]\n    request = httpserver.requests[0]\n    expected_path = (\n        \'/studies/{study_instance_uid}/series/{series_instance_uid}/instances\'\n        \'/{sop_instance_uid}/frames/{frame_list}\'.format(**locals())\n    )\n    assert request.path == expected_path\n    assert request.accept_mimetypes[0][0][:36] == headers[\'content-type\'][:36]\n\n\ndef test_retrieve_instance_frames_jpeg_default_transfer_syntax(httpserver,\n                                                               client,\n                                                               cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'retrieve_instance_pixeldata.jpg\'))\n    with open(cache_filename, \'rb\') as f:\n        content = f.read()\n    headers = {\n        \'content-type\': \'multipart/related; type=""image/jpeg""\',\n    }\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    frame_numbers = [114]\n    client.retrieve_instance_frames(\n        study_instance_uid, series_instance_uid, sop_instance_uid,\n        frame_numbers, media_types=(\n            (\'image/jpeg\', \'1.2.840.10008.1.2.4.50\', ),\n        )\n    )\n    request = httpserver.requests[0]\n    assert request.accept_mimetypes[0][0][:36] == headers[\'content-type\'][:36]\n\n\ndef test_retrieve_instance_frames_jp2(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'retrieve_instance_pixeldata.jp2\'))\n    with open(cache_filename, \'rb\') as f:\n        content = f.read()\n    headers = {\n        \'content-type\': \'multipart/related; type=""image/jp2""\',\n    }\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    frame_numbers = [114]\n    frame_list = \',\'.join([str(n) for n in frame_numbers])\n    result = client.retrieve_instance_frames(\n        study_instance_uid, series_instance_uid, sop_instance_uid,\n        frame_numbers, media_types=(\'image/jp2\', )\n    )\n    assert result == [content]\n    request = httpserver.requests[0]\n    expected_path = (\n        \'/studies/{study_instance_uid}/series/{series_instance_uid}/instances\'\n        \'/{sop_instance_uid}/frames/{frame_list}\'.format(**locals())\n    )\n    assert request.path == expected_path\n    assert request.accept_mimetypes[0][0][:35] == headers[\'content-type\'][:35]\n\n\ndef test_retrieve_instance_frames_rendered_jpeg(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'retrieve_instance_pixeldata.jpg\'))\n    with open(cache_filename, \'rb\') as f:\n        content = f.read()\n    headers = {\n        \'content-type\': \'image/jpeg\',\n    }\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    frame_numbers = [1]\n    result = client.retrieve_instance_frames_rendered(\n        study_instance_uid, series_instance_uid, sop_instance_uid,\n        frame_numbers, media_types=(\'image/jpeg\', )\n    )\n    assert result == content\n    request = httpserver.requests[0]\n    expected_path = (\n        \'/studies/{study_instance_uid}/series/{series_instance_uid}/instances\'\n        \'/{sop_instance_uid}/frames/{frame_numbers}/rendered\'.format(\n            study_instance_uid=study_instance_uid,\n            series_instance_uid=series_instance_uid,\n            sop_instance_uid=sop_instance_uid,\n            frame_numbers=\',\'.join([str(n) for n in frame_numbers])\n        )\n    )\n    assert request.path == expected_path\n    assert request.accept_mimetypes[0][0][:11] == headers[\'content-type\'][:11]\n\n\ndef test_retrieve_instance_frames_rendered_jpeg_transfer_syntax(httpserver,\n                                                                client):\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    frame_numbers = [1]\n    with pytest.raises(TypeError):\n        client.retrieve_instance_frames_rendered(\n            study_instance_uid, series_instance_uid, sop_instance_uid,\n            frame_numbers, media_types=(\n                (\'image/jpeg\', \'1.2.840.10008.1.2.4.50\', ),\n            )\n        )\n\n\ndef test_retrieve_instance_frames_rendered_png(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'retrieve_instance_pixeldata.png\'))\n    with open(cache_filename, \'rb\') as f:\n        content = f.read()\n    headers = {\n        \'content-type\': \'image/png\',\n    }\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    frame_numbers = [1]\n    result = client.retrieve_instance_frames_rendered(\n        study_instance_uid, series_instance_uid, sop_instance_uid,\n        frame_numbers, media_types=(\'image/png\', )\n    )\n    assert result == content\n    request = httpserver.requests[0]\n    expected_path = (\n        \'/studies/{study_instance_uid}/series/{series_instance_uid}/instances\'\n        \'/{sop_instance_uid}/frames/{frame_numbers}/rendered\'.format(\n            study_instance_uid=study_instance_uid,\n            series_instance_uid=series_instance_uid,\n            sop_instance_uid=sop_instance_uid,\n            frame_numbers=\',\'.join([str(n) for n in frame_numbers])\n        )\n    )\n    assert request.path == expected_path\n    assert request.accept_mimetypes[0][0][:10] == headers[\'content-type\'][:10]\n\n\ndef test_store_instance_error_with_retries(httpserver, client, cache_dir):\n    dataset = load_json_dataset({})\n    dataset.is_little_endian = True\n    dataset.is_implicit_VR = True\n    max_attempts = 2\n    client.set_http_retry_params(\n        retry=True,\n        max_attempts=max_attempts,\n        wait_exponential_multiplier=10\n    )\n    httpserver.serve_content(\n        content=\'\',\n        code=HTTPStatus.REQUEST_TIMEOUT,\n        headers=\'\'\n    )\n    with pytest.raises(RetryError):\n        client.store_instances([dataset])\n    assert len(httpserver.requests) == max_attempts\n    request = httpserver.requests[0]\n    assert request.headers[\'Content-Type\'].startswith(\n        \'multipart/related; type=""application/dicom""\'\n    )\n\n\ndef test_store_instance_error_with_no_retries(httpserver, client, cache_dir):\n    dataset = load_json_dataset({})\n    dataset.is_little_endian = True\n    dataset.is_implicit_VR = True\n    client.set_http_retry_params(retry=False)\n    httpserver.serve_content(\n        content=\'\',\n        code=HTTPStatus.REQUEST_TIMEOUT,\n        headers=\'\'\n    )\n    with pytest.raises(HTTPError):\n        client.store_instances([dataset])\n    assert len(httpserver.requests) == 1\n    request = httpserver.requests[0]\n    assert request.headers[\'Content-Type\'].startswith(\n        \'multipart/related; type=""application/dicom""\'\n    )\n\n\ndef test_delete_study_error(httpserver, client, cache_dir):\n    study_instance_uid = \'1.2.3\'\n    httpserver.serve_content(\n        content=\'\',\n        code=HTTPStatus.METHOD_NOT_ALLOWED,\n        headers=\'\'\n    )\n    with pytest.raises(HTTPError):\n        client.delete_study(study_instance_uid=study_instance_uid)\n    assert len(httpserver.requests) == 1\n    request = httpserver.requests[0]\n    expected_path = (\n        \'/studies/{study_instance_uid}\'.format(\n            study_instance_uid=study_instance_uid)\n    )\n    assert request.path == expected_path\n    assert request.method == \'DELETE\'\n\n\ndef test_delete_series_error(httpserver, client, cache_dir):\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    httpserver.serve_content(\n        content=\'\',\n        code=HTTPStatus.METHOD_NOT_ALLOWED,\n        headers=\'\'\n    )\n    with pytest.raises(HTTPError):\n        client.delete_series(study_instance_uid=study_instance_uid,\n                             series_instance_uid=series_instance_uid)\n    assert len(httpserver.requests) == 1\n    request = httpserver.requests[0]\n    expected_path = (\n        \'/studies/{study_instance_uid}/series/{series_instance_uid}\'.format(\n            study_instance_uid=study_instance_uid,\n            series_instance_uid=series_instance_uid)\n    )\n    assert request.path == expected_path\n    assert request.method == \'DELETE\'\n\n\ndef test_delete_instance_error(httpserver, client, cache_dir):\n    study_instance_uid = \'1.2.3\'\n    series_instance_uid = \'1.2.4\'\n    sop_instance_uid = \'1.2.5\'\n    httpserver.serve_content(\n        content=\'\',\n        code=HTTPStatus.METHOD_NOT_ALLOWED,\n        headers=\'\'\n    )\n    with pytest.raises(HTTPError):\n        client.delete_instance(study_instance_uid=study_instance_uid,\n                               series_instance_uid=series_instance_uid,\n                               sop_instance_uid=sop_instance_uid)\n    assert len(httpserver.requests) == 1\n    request = httpserver.requests[0]\n    expected_path = (\n        \'/studies/{study_instance_uid}/series/{series_instance_uid}/instances\'\n        \'/{sop_instance_uid}\'.format(\n            study_instance_uid=study_instance_uid,\n            series_instance_uid=series_instance_uid,\n            sop_instance_uid=sop_instance_uid,)\n    )\n    assert request.path == expected_path\n    assert request.method == \'DELETE\'\n\n\ndef test_load_json_dataset_da(httpserver, client, cache_dir):\n    value = [\'2018-11-21\']\n    dicom_json = {\n        \'00080020\': {\n            \'vr\': \'DA\',\n            \'Value\': value\n        }\n    }\n    dataset = load_json_dataset(dicom_json)\n    assert dataset.StudyDate == value[0]\n\n\ndef test_load_json_dataset_tm(httpserver, client, cache_dir):\n    value = [\'113924\']\n    dicom_json = {\n        \'00080030\': {\n            \'vr\': \'TM\',\n            \'Value\': value,\n        },\n    }\n    dataset = load_json_dataset(dicom_json)\n    assert dataset.StudyTime == value[0]\n\n\ndef test_load_json_dataset_pn_vm1(httpserver, client, cache_dir):\n    name = \'Only^Person\'\n    value = [{\'Alphabetic\': name}]\n    dicom_json = {\n        \'00080090\': {\n            \'vr\': \'PN\',\n            \'Value\': value,\n        },\n    }\n    dataset = load_json_dataset(dicom_json)\n    assert dataset.ReferringPhysicianName == name\n\n\ndef test_load_json_dataset_pn_vm2(httpserver, client, cache_dir):\n    names = [\'First^Person\', \'Second^Person\']\n    value = [{\'Alphabetic\': names[0]}, {\'Alphabetic\': names[1]}]\n    dicom_json = {\n        \'0008009C\': {\n            \'vr\': \'PN\',\n            \'Value\': value,\n        },\n    }\n    dataset = load_json_dataset(dicom_json)\n    assert dataset.ConsultingPhysicianName == names\n\n\ndef test_load_json_dataset_pn_vm1_empty(httpserver, client, cache_dir):\n    value = [{}]\n    dicom_json = {\n        \'00080090\': {\n            \'vr\': \'PN\',\n            \'Value\': value,\n        },\n    }\n    dataset = load_json_dataset(dicom_json)\n    # This returns different results for Python2 (None) and Python3 ("""")\n    assert dataset.ReferringPhysicianName in (None, \'\')\n\n\ndef test_load_json_dataset_pn_vm2_empty(httpserver, client, cache_dir):\n    value = [{}]\n    dicom_json = {\n        \'0008009C\': {\n            \'vr\': \'PN\',\n            \'Value\': value,\n        },\n    }\n    dataset = load_json_dataset(dicom_json)\n    assert dataset.ConsultingPhysicianName == []\n\n\ndef test_load_xml_response(httpserver, client, cache_dir):\n    cache_filename = str(cache_dir.joinpath(\'store.xml\'))\n    with open(cache_filename, \'rb\') as f:\n        tree = ET.fromstring(f.read())\n        dataset = _load_xml_dataset(tree)\n    assert dataset.RetrieveURL.startswith(\'https://wadors.hospital.com\')\n    assert len(dataset.ReferencedSOPSequence) == 2\n'"
tests/test_cli.py,0,"b""import json\nimport tempfile\n\nimport pytest\n\nfrom dicomweb_client.api import load_json_dataset\nfrom dicomweb_client.cli import main\n\n\ndef test_parse_search_studies(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'search', 'studies'\n    ])\n    assert getattr(args, 'method') == 'search'\n    assert getattr(args, 'qido_ie') == 'studies'\n    assert getattr(args, 'prettify') is False\n    assert getattr(args, 'dicomize') is False\n    with pytest.raises(AttributeError):\n        getattr(args, 'study_instance_uid')\n    with pytest.raises(AttributeError):\n        getattr(args, 'series_instance_uid')\n    with pytest.raises(AttributeError):\n        getattr(args, 'sop_instance_uid')\n\n\ndef test_parse_search_studies_series(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002',\n            'search', 'studies', '--series', '1.2.3'\n        ])\n\n\ndef test_parse_search_studies_instance(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'search', 'studies',\n            '--instance', '1.2.3'\n        ])\n\n\ndef test_parse_search_series(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'search', 'series'\n    ])\n    assert getattr(args, 'method') == 'search'\n    assert getattr(args, 'qido_ie') == 'series'\n    assert getattr(args, 'prettify') is False\n    assert getattr(args, 'dicomize') is False\n    assert getattr(args, 'study_instance_uid') is None\n    with pytest.raises(AttributeError):\n        getattr(args, 'series_instance_uid')\n    with pytest.raises(AttributeError):\n        getattr(args, 'sop_instance_uid')\n\n\ndef test_parse_search_series_specific_study(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'search', 'series',\n        '--study', '1.2.3'\n    ])\n    assert getattr(args, 'method') == 'search'\n    assert getattr(args, 'qido_ie') == 'series'\n    assert getattr(args, 'prettify') is False\n    assert getattr(args, 'dicomize') is False\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    with pytest.raises(AttributeError):\n        getattr(args, 'series_instance_uid')\n    with pytest.raises(AttributeError):\n        getattr(args, 'sop_instance_uid')\n\n\ndef test_parse_search_series_wrong_argument(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'search', 'series',\n            '--series', '1.2.3'\n        ])\n\n\ndef test_parse_search_instances(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'search', 'instances'\n    ])\n    assert getattr(args, 'method') == 'search'\n    assert getattr(args, 'qido_ie') == 'instances'\n    assert getattr(args, 'prettify') is False\n    assert getattr(args, 'dicomize') is False\n    assert getattr(args, 'study_instance_uid') is None\n    assert getattr(args, 'series_instance_uid') is None\n    with pytest.raises(AttributeError):\n        getattr(args, 'sop_instance_uid')\n\n\ndef test_parse_search_instances_specific_study(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'search', 'instances',\n        '--study', '1.2.3'\n    ])\n    assert getattr(args, 'method') == 'search'\n    assert getattr(args, 'qido_ie') == 'instances'\n    assert getattr(args, 'prettify') is False\n    assert getattr(args, 'dicomize') is False\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'series_instance_uid') is None\n    with pytest.raises(AttributeError):\n        getattr(args, 'sop_instance_uid')\n\n\ndef test_parse_search_instances_specific_study_series(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'search', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4'\n    ])\n    assert getattr(args, 'method') == 'search'\n    assert getattr(args, 'qido_ie') == 'instances'\n    assert getattr(args, 'prettify') is False\n    assert getattr(args, 'dicomize') is False\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'series_instance_uid') == '1.2.4'\n    with pytest.raises(AttributeError):\n        getattr(args, 'sop_instance_uid')\n\n\ndef test_parse_search_instances_prettify(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'search', 'instances', '--prettify'\n    ])\n    assert getattr(args, 'method') == 'search'\n    assert getattr(args, 'qido_ie') == 'instances'\n    assert getattr(args, 'prettify') is True\n    assert getattr(args, 'dicomize') is False\n\n\ndef test_parse_search_instances_dicomize(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'search', 'instances', '--dicomize'\n    ])\n    assert getattr(args, 'method') == 'search'\n    assert getattr(args, 'qido_ie') == 'instances'\n    assert getattr(args, 'prettify') is False\n    assert getattr(args, 'dicomize') is True\n\n\ndef test_parse_search_instances_argument_conflict(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'search', 'instances',\n            '--prettify', '--dicomize'\n        ])\n\n\ndef test_parse_retrieve_study(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'studies',\n        '--study', '1.2.3', 'full'\n    ])\n    assert getattr(args, 'method') == 'retrieve'\n    assert getattr(args, 'wado_ie') == 'studies'\n    assert getattr(args, 'studies_resource') == 'full'\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'save') is False\n    with pytest.raises(AttributeError):\n        getattr(args, 'prettify')\n    with pytest.raises(AttributeError):\n        getattr(args, 'dicomize')\n\n\ndef test_parse_retrieve_study_save(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'studies',\n        '--study', '1.2.3', 'full', '--save'\n    ])\n    assert getattr(args, 'method') == 'retrieve'\n    assert getattr(args, 'wado_ie') == 'studies'\n    assert getattr(args, 'studies_resource') == 'full'\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'save') is True\n    assert getattr(args, 'output_dir') == tempfile.gettempdir()\n\n\ndef test_parse_retrieve_study_metadata(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'studies',\n        '--study', '1.2.3', 'metadata'\n    ])\n    assert getattr(args, 'method') == 'retrieve'\n    assert getattr(args, 'wado_ie') == 'studies'\n    assert getattr(args, 'studies_resource') == 'metadata'\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'prettify') is False\n    assert getattr(args, 'dicomize') is False\n    with pytest.raises(AttributeError):\n        getattr(args, 'series_instance_uid')\n    with pytest.raises(AttributeError):\n        getattr(args, 'sop_instance_uid')\n\n\ndef test_parse_retrieve_study_metadata_unsupported_argument_media_type(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'studies',\n            '--study', '1.2.3', 'metadata', '--media-type', 'application/dicom'\n        ])\n\n\ndef test_parse_retrieve_study_metadata_missing_argument(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'studies', 'metadata'\n        ])\n\n\ndef test_parse_retrieve_study_metadata_wrong_argument(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'studies',\n            '--series', '1.2.3', 'metadata'\n        ])\n\n\ndef test_parse_retrieve_series(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'series',\n        '--study', '1.2.3', '--series', '1.2.4', 'full'\n    ])\n    assert getattr(args, 'method') == 'retrieve'\n    assert getattr(args, 'wado_ie') == 'series'\n    assert getattr(args, 'series_resource') == 'full'\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'series_instance_uid') == '1.2.4'\n    assert getattr(args, 'save') is False\n    with pytest.raises(AttributeError):\n        getattr(args, 'prettify')\n    with pytest.raises(AttributeError):\n        getattr(args, 'dicomize')\n\n\ndef test_parse_retrieve_series_save(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'series',\n        '--study', '1.2.3', '--series', '1.2.4', 'full', '--save'\n    ])\n    assert getattr(args, 'save') is True\n    assert getattr(args, 'output_dir') == tempfile.gettempdir()\n\n\ndef test_parse_retrieve_series_save_directory(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'series',\n        '--study', '1.2.3', '--series', '1.2.4', 'full', '--save',\n        '--output-dir', '/path/to/dir'\n    ])\n    assert getattr(args, 'save') is True\n    assert getattr(args, 'output_dir') == '/path/to/dir'\n\n\ndef test_parse_retrieve_series_metadata(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'series',\n        '--study', '1.2.3', '--series', '1.2.4', 'metadata'\n    ])\n    assert getattr(args, 'method') == 'retrieve'\n    assert getattr(args, 'wado_ie') == 'series'\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'series_instance_uid') == '1.2.4'\n    assert getattr(args, 'prettify') is False\n    assert getattr(args, 'dicomize') is False\n    with pytest.raises(AttributeError):\n        getattr(args, 'sop_instance_uid')\n\n\ndef test_parse_retrieve_series_metadata_extra_argument(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'series',\n            '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5',\n            'metadata'\n        ])\n\n\ndef test_parse_retrieve_series_metadata_missing_argument(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'series',\n            '--study', '1.2.3', 'metadata',\n        ])\n\n\ndef test_parse_store_instances_single_file(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'store', 'instances',\n        '/path/to/file.dcm',\n    ])\n    assert getattr(args, 'method') == 'store'\n    assert getattr(args, 'stow_ie') == 'instances'\n    assert getattr(args, 'study_instance_uid') is None\n    assert getattr(args, 'files') == ['/path/to/file.dcm']\n\n\ndef test_parse_store_instances_chunked(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002',\n        '--chunk-size', '1000',\n        'store', 'instances',\n        '/path/to/file.dcm',\n    ])\n    assert getattr(args, 'chunk_size') == 1000\n\n\ndef test_parse_store_instances_single_file_study_instance_uid(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'store', 'instances',\n        '/path/to/file.dcm', '--study', '1.2.3',\n    ])\n    assert getattr(args, 'method') == 'store'\n    assert getattr(args, 'stow_ie') == 'instances'\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'files') == ['/path/to/file.dcm']\n\n\ndef test_parse_store_instances_multiple_files(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'store', 'instances',\n        '/path/to/f1.dcm', '/path/to/f2.dcm',\n    ])\n    assert getattr(args, 'method') == 'store'\n    assert getattr(args, 'stow_ie') == 'instances'\n    assert getattr(args, 'study_instance_uid') is None\n    assert getattr(args, 'files') == ['/path/to/f1.dcm', '/path/to/f2.dcm']\n\n\ndef test_parse_store_studies(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'store', 'studies',\n            '/path/to/file.dcm',\n        ])\n\n\ndef test_parse_store_series(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'store', 'series',\n            '/path/to/file.dcm',\n        ])\n\n\ndef test_parse_retrieve_instance(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5', 'full',\n    ])\n    assert getattr(args, 'method') == 'retrieve'\n    assert getattr(args, 'wado_ie') == 'instances'\n    assert getattr(args, 'instances_resource') == 'full'\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'series_instance_uid') == '1.2.4'\n    assert getattr(args, 'sop_instance_uid') == '1.2.5'\n    assert getattr(args, 'save') is False\n    with pytest.raises(AttributeError):\n        getattr(args, 'prettify')\n    with pytest.raises(AttributeError):\n        getattr(args, 'dicomize')\n\n\ndef test_parse_retrieve_instance_chunked(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002',\n        '--chunk-size', '1000',\n        'retrieve', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5', 'full',\n    ])\n    assert getattr(args, 'chunk_size') == 1000\n\n\ndef test_parse_retrieve_instance_media_types(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5', 'full',\n        '--media-type', 'application/dicom',\n    ])\n    assert getattr(args, 'media_types') == [\n        ['application/dicom', ],\n    ]\n\n\ndef test_parse_retrieve_instance_media_types_transfer_syntax(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5', 'full',\n        '--media-type', 'application/dicom', '1.2.840.10008.1.2.1',\n    ])\n    assert getattr(args, 'media_types') == [\n        ['application/dicom', '1.2.840.10008.1.2.1', ],\n    ]\n\n\ndef test_parse_retrieve_instance_media_types_transfer_syntax_multiple(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5', 'full',\n        '--media-type', 'application/dicom', '1.2.840.10008.1.2.1',\n        '--media-type', 'application/dicom', '1.2.840.10008.1.2.4.90',\n    ])\n    assert getattr(args, 'media_types') == [\n        ['application/dicom', '1.2.840.10008.1.2.1', ],\n        ['application/dicom', '1.2.840.10008.1.2.4.90', ],\n    ]\n\n\ndef test_parse_retrieve_instance_metadata(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'instances', '--study',\n        '1.2.3', '--series', '1.2.4', '--instance', '1.2.5', 'metadata'\n    ])\n    assert getattr(args, 'method') == 'retrieve'\n    assert getattr(args, 'wado_ie') == 'instances'\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'series_instance_uid') == '1.2.4'\n    assert getattr(args, 'sop_instance_uid') == '1.2.5'\n    assert getattr(args, 'save') is False\n    assert getattr(args, 'output_dir') == tempfile.gettempdir()\n    assert getattr(args, 'prettify') is False\n    assert getattr(args, 'dicomize') is False\n\n\ndef test_parse_retrieve_instance_metadata_missing_argument(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'instances',\n            '--study', '1.2.3', '--series', '1.2.4', 'metadata'\n        ])\n\n\ndef test_parse_retrieve_instance_metadata_missing_argument_2(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'instances',\n            '--study', '1.2.3', '--instance', '1.2.5', 'metadata'\n        ])\n\n\ndef test_parse_retrieve_instance_metadata_missing_argument_3(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'instances',\n            '--series', '1.2.4', '--instance', '1.2.5', 'metadata'\n        ])\n\n\ndef test_parse_retrieve_instance_frames(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5',\n        'frames', '--numbers', '1',\n    ])\n    assert getattr(args, 'method') == 'retrieve'\n    assert getattr(args, 'wado_ie') == 'instances'\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'series_instance_uid') == '1.2.4'\n    assert getattr(args, 'sop_instance_uid') == '1.2.5'\n    assert getattr(args, 'frame_numbers') == [1]\n    assert getattr(args, 'save') is False\n    assert getattr(args, 'output_dir') == tempfile.gettempdir()\n    assert getattr(args, 'show') is False\n    with pytest.raises(AttributeError):\n        assert getattr(args, 'prettify')\n    with pytest.raises(AttributeError):\n        assert getattr(args, 'dicomize')\n\n\ndef test_parse_retrieve_instance_frames_multiple(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5',\n        'frames', '--numbers', '1', '2', '3',\n    ])\n    assert getattr(args, 'method') == 'retrieve'\n    assert getattr(args, 'wado_ie') == 'instances'\n    assert getattr(args, 'study_instance_uid') == '1.2.3'\n    assert getattr(args, 'series_instance_uid') == '1.2.4'\n    assert getattr(args, 'sop_instance_uid') == '1.2.5'\n    assert getattr(args, 'frame_numbers') == [1, 2, 3]\n    assert getattr(args, 'save') is False\n    assert getattr(args, 'output_dir') == tempfile.gettempdir()\n    assert getattr(args, 'show') is False\n    with pytest.raises(AttributeError):\n        assert getattr(args, 'prettify')\n    with pytest.raises(AttributeError):\n        assert getattr(args, 'dicomize')\n\n\ndef test_parse_retrieve_instance_frames_show(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5',\n        'frames', '--numbers', '1', '--show',\n    ])\n    assert getattr(args, 'show') is True\n    assert getattr(args, 'save') is False\n    assert getattr(args, 'output_dir') == tempfile.gettempdir()\n\n\ndef test_parse_retrieve_instance_frames_save(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5',\n        'frames', '--numbers', '1', '--save',\n    ])\n    assert getattr(args, 'show') is False\n    assert getattr(args, 'save') is True\n    assert getattr(args, 'output_dir') == tempfile.gettempdir()\n\n\ndef test_parse_retrieve_instance_frames_show_save(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5',\n        'frames', '--numbers', '1', '--save', '--show'\n    ])\n    assert getattr(args, 'show') is True\n    assert getattr(args, 'save') is True\n    assert getattr(args, 'output_dir') == tempfile.gettempdir()\n\n\ndef test_parse_retrieve_instance_frames_save_file(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'instances',\n        '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5',\n        'frames', '--numbers', '1', '--save', '--output-dir', '/tmp',\n    ])\n    assert getattr(args, 'show') is False\n    assert getattr(args, 'save') is True\n    assert getattr(args, 'output_dir') == '/tmp'\n\n\ndef test_parse_retrieve_instance_frames_missing_argument(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'instances',\n            '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5',\n            'frames', '--numbers',\n        ])\n\n\ndef test_parse_retrieve_study_full_missing_argument(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'studies',\n            '--study', '1.2.3'\n        ])\n\n\ndef test_parse_retrieve_series_missing_argument(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'series',\n            '--studies', '1.2.3', '--series', '1.2.4'\n        ])\n\n\ndef test_parse_retrieve_instance_missing_argument(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'series',\n            '--study', '1.2.3', '--series', '1.2.4', '--instance', '1.2.5'\n        ])\n\n\ndef test_parse_retrieve_bulkdata(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'bulkdata',\n        '--uri', 'http://localhost:8002/bulk/data'\n    ])\n    assert getattr(args, 'method') == 'retrieve'\n    assert getattr(args, 'wado_ie') == 'bulkdata'\n    assert getattr(args, 'media_types') is None\n    assert getattr(args, 'bulkdata_uri') == 'http://localhost:8002/bulk/data'\n\n\ndef test_parse_retrieve_bulkdata_media_type(parser):\n    args = parser.parse_args([\n        '--url', 'http://localhost:8002', 'retrieve', 'bulkdata',\n        '--uri', 'http://localhost:8002/bulk/data',\n        '--media-type', 'image/jpeg'\n    ])\n    assert getattr(args, 'method') == 'retrieve'\n    assert getattr(args, 'wado_ie') == 'bulkdata'\n    assert getattr(args, 'media_types') == [['image/jpeg', ], ]\n    assert getattr(args, 'bulkdata_uri') == 'http://localhost:8002/bulk/data'\n\n\ndef test_parse_retrieve_bulkdata_missing_argument(parser):\n    with pytest.raises(SystemExit):\n        parser.parse_args([\n            '--url', 'http://localhost:8002', 'retrieve', 'bulkdata'\n        ])\n\n\ndef test_search_for_studies(parser, httpserver, cache_dir, capsys):\n    cache_filename = str(cache_dir.joinpath('search_for_studies.json'))\n    with open(cache_filename, 'r') as f:\n        content = f.read()\n    headers = {'content-type': 'application/dicom+json'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    args = parser.parse_args([\n        '--url', httpserver.url, 'search', 'studies',\n    ])\n    with pytest.raises(SystemExit) as exit:\n        main(args)\n    assert exit.value.code == 0\n    stdout, stderr = capsys.readouterr()\n    assert stdout == content\n\n\ndef test_search_for_studies_dicomize(parser, httpserver, cache_dir, capsys):\n    cache_filename = str(cache_dir.joinpath('search_for_studies.json'))\n    with open(cache_filename, 'r') as f:\n        content = f.read()\n    parsed_content = json.loads(content)\n    dicomized_content = '\\n\\n\\n'.join([\n        repr(load_json_dataset(instance))\n        for instance in parsed_content\n    ])\n    dicomized_content += '\\n\\n\\n'\n    headers = {'content-type': 'application/dicom+json'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    args = parser.parse_args([\n        '--url', httpserver.url, 'search', 'studies', '--dicomize'\n    ])\n    with pytest.raises(SystemExit) as exit:\n        main(args)\n    assert exit.value.code == 0\n    stdout, stderr = capsys.readouterr()\n    assert stdout == dicomized_content\n\n\ndef test_search_for_studies_prettify(parser, httpserver, cache_dir, capsys):\n    cache_filename = str(cache_dir.joinpath('search_for_studies.json'))\n    with open(cache_filename, 'r') as f:\n        content = f.read()\n    parsed_content = json.loads(content)\n    prettified_content = json.dumps(parsed_content, indent=4, sort_keys=True)\n    prettified_content += '\\n'\n    headers = {'content-type': 'application/dicom+json'}\n    httpserver.serve_content(content=content, code=200, headers=headers)\n    args = parser.parse_args([\n        '--url', httpserver.url, 'search', 'studies', '--prettify'\n    ])\n    with pytest.raises(SystemExit) as exit:\n        main(args)\n    assert exit.value.code == 0\n    stdout, stderr = capsys.readouterr()\n    assert stdout == prettified_content\n"""
src/dicomweb_client/__init__.py,0,"b""__version__ = '0.40.1'\n\n\nfrom dicomweb_client.api import DICOMwebClient\n"""
src/dicomweb_client/api.py,0,"b'\'\'\'Application Programming Interface (API).\'\'\'\nimport re\nimport os\nimport sys\nimport logging\nimport email\nfrom xml.etree.ElementTree import (\n    Element,\n    fromstring\n)\nfrom collections import OrderedDict\nfrom io import BytesIO\nfrom http import HTTPStatus\nfrom urllib.parse import quote_plus, urlparse\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    List,\n    Mapping,\n    Optional,\n    Set,\n    Sequence,\n    Union,\n    Tuple,\n)\n\nimport requests\nimport retrying\nimport pydicom\n\nfrom dicomweb_client.error import DICOMJSONError\n\n\nlogger = logging.getLogger(__name__)\n\n\ndef _init_dataset():\n    \'\'\'Creates an empty DICOM Data Set.\n\n    Returns\n    -------\n    pydicom.dataset.Dataset\n\n    \'\'\'\n    return pydicom.dataset.Dataset()\n\n\ndef _create_dataelement(\n        tag: pydicom.tag.Tag,\n        vr: str,\n        value: List[Any]\n    ) -> pydicom.dataelem.DataElement:\n    \'\'\'Creates a DICOM Data Element.\n\n    Parameters\n    ----------\n    tag: pydicom.tag.Tag\n        data element tag\n    vr: str\n        data element value representation\n    value: List[Any]\n        data element value(s)\n\n    Returns\n    -------\n    pydicom.dataelem.DataElement\n        data element\n\n    \'\'\'\n    binary_representations = {\'OB\', \'OD\', \'OF\', \'OL\', \'OW\', \'UN\'}\n    try:\n        vm = pydicom.datadict.dictionary_VM(tag)\n    except KeyError:\n        # Private tag\n        vm = str(len(value))\n    if vr not in binary_representations:\n        if not(isinstance(value, list)):\n            raise DICOMJSONError(\n                \'""Value"" of data element ""{}"" must be an array.\'.format(tag)\n            )\n    elem_value: Optional[List[Any]]\n    if vr == \'SQ\':\n        elem_value = []\n        for value_item in value:\n            ds = _init_dataset()\n            if value_item is not None:\n                for key, val in value_item.items():\n                    if \'vr\' not in val:\n                        raise DICOMJSONError(\n                            \'Data element ""{}"" must have key ""vr"".\'.format(tag)\n                        )\n                    supported_keys = {\'Value\', \'BulkDataURI\', \'InlineBinary\'}\n                    val_key = None\n                    for k in supported_keys:\n                        if k in val:\n                            val_key = k\n                            break\n                    if val_key is None:\n                        logger.debug(\n                            \'data element has neither key ""{}"".\'.format(\n                                \'"" nor ""\'.join(supported_keys)\n                            )\n                        )\n                        e = pydicom.dataelem.DataElement(\n                            tag=tag, value=None, VR=vr\n                        )\n                    else:\n                        e = _create_dataelement(key, val[\'vr\'], val[val_key])\n                    ds.add(e)\n            elem_value.append(ds)\n    elif vr == \'PN\':\n        # Special case, see DICOM Part 18 Annex F2.2\n        elem_value = []\n        for v in value:\n            if not isinstance(v, dict):\n                # Some DICOMweb services get this wrong, so we workaround the\n                # the issue and warn the user rather than raising an error.\n                logger.warning(\n                    \'attribute with VR Person Name (PN) is not \'\n                    \'formatted correctly\'\n                )\n                elem_value.append(v)\n            else:\n                elem_value.extend(list(v.values()))\n        if vm == \'1\':\n            try:\n                elem_value = elem_value[0]\n            except IndexError:\n                elem_value = None\n    else:\n        if vm == \'1\':\n            if vr in binary_representations:\n                elem_value = value\n            else:\n                if value:\n                    elem_value = value[0]\n                else:\n                    elem_value = value\n        else:\n            if len(value) == 1 and isinstance(value[0], str):\n                elem_value = value[0].split(\'\\\\\')\n            else:\n                elem_value = value\n    try:\n        return pydicom.dataelem.DataElement(tag=tag, value=elem_value, VR=vr)\n    except Exception:\n        raise ValueError(\n            \'Data element ""{}"" could not be loaded from JSON: {}\'.format(\n                tag, elem_value\n            )\n        )\n\n\ndef load_json_dataset(dataset: Dict[str, dict]) -> pydicom.dataset.Dataset:\n    \'\'\'Loads DICOM Data Set in DICOM JSON format.\n\n    Parameters\n    ----------\n    dataset: Dict[str, dict]\n        mapping where keys are DICOM *Tags* and values are mappings of DICOM\n        *VR* and *Value* key-value pairs\n\n    Returns\n    -------\n    pydicom.dataset.Dataset\n        data set\n\n    \'\'\'\n    ds = _init_dataset()\n    for tag, mapping in dataset.items():\n        vr = mapping[\'vr\']\n        try:\n            value = mapping[\'Value\']\n        except KeyError:\n            logger.debug(\n                \'mapping for data element ""{}"" has no ""Value"" key\'.format(tag)\n            )\n            value = [None]\n        de = _create_dataelement(tag, vr, value)\n        ds.add(de)\n    return ds\n\n\ndef _load_xml_dataset(dataset: Element) -> pydicom.dataset.Dataset:\n    \'\'\'Loads DICOM Data Set in DICOM XML format.\n\n    Parameters\n    ----------\n    dataset: xml.etree.ElementTree.Element\n        parsed element tree\n\n    Returns\n    -------\n    pydicom.dataset.Dataset\n        data set\n\n    \'\'\'\n    ds = pydicom.Dataset()\n    for element in dataset:\n        keyword = element.attrib[\'keyword\']\n        vr = element.attrib[\'vr\']\n        value: Optional[Union[List[Any], str]]\n        if vr == \'SQ\':\n            value = [\n                _load_xml_dataset(item)\n                for item in element\n            ]\n        else:\n            value = list(element)\n            if len(value) == 1:\n                value = value[0].text.strip()\n            elif len(value) > 1:\n                value = [v.text.strip() for v in value]\n            else:\n                value = None\n        setattr(ds, keyword, value)\n    return ds\n\n\nclass DICOMwebClient(object):\n\n    \'\'\'Class for connecting to and interacting with a DICOMweb RESTful service.\n\n    Attributes\n    ----------\n    base_url: str\n        unique resource locator of the DICOMweb service\n    protocol: str\n        name of the protocol, e.g. ``""https""``\n    host: str\n        IP address or DNS name of the machine that hosts the server\n    port: int\n        number of the port to which the server listens\n    url_prefix: str\n        URL path prefix for DICOMweb services (part of `base_url`)\n    qido_url_prefix: Union[str, None]\n        URL path prefix for QIDO-RS (not part of `base_url`)\n    wado_url_prefix: Union[str, None]\n        URL path prefix for WADO-RS (not part of `base_url`)\n    stow_url_prefix: Union[str, None]\n        URL path prefix for STOW-RS (not part of `base_url`)\n    delete_url_prefix: Union[str, None]\n        URL path prefix for DELETE (not part of `base_url`)\n\n    \'\'\'\n\n    def set_http_retry_params(\n            self,\n            retry: bool = True,\n            max_attempts: int = 5,\n            wait_exponential_multiplier: int = 1000,\n            retriable_error_codes: Tuple[HTTPStatus, ...] = (\n                HTTPStatus.TOO_MANY_REQUESTS,\n                HTTPStatus.REQUEST_TIMEOUT,\n                HTTPStatus.SERVICE_UNAVAILABLE,\n                HTTPStatus.GATEWAY_TIMEOUT,\n            )\n        ) -> None:\n        \'\'\'Sets parameters for HTTP retrying logic. These parameters are passed\n        to @retrying.retry which wraps the HTTP requests and retries all\n        responses that return an error code defined in |retriable_error_codes|.\n        The retrying method uses exponential back off using the multiplier\n        |wait_exponential_multiplier| for a max attempts defined by\n        |max_attempts|.\n\n        Parameters\n        ----------\n        retry: bool, optional\n            whether HTTP retrying should be performed, if it is set to\n            ``False``, the rest of the parameters are ignored.\n        max_attempts: int, optional\n            the maximum number of request attempts.\n        wait_exponential_multiplier: float, optional\n            exponential multiplier applied to delay between attempts in ms.\n        retriable_error_codes: tuple, optional\n            tuple of HTTP error codes to retry if raised.\n        \'\'\'\n        self._http_retry = retry\n        if retry:\n            self._max_attempts = max_attempts\n            self._wait_exponential_multiplier = wait_exponential_multiplier\n            self._http_retrable_errors = retriable_error_codes\n\n        else:\n            self._max_attempts = 1\n            self._wait_exponential_multiplier = 1\n            self._http_retrable_errors = ()\n\n    def _is_retriable_http_error(\n            self,\n            response: requests.models.Response\n    ) -> bool:\n        \'\'\'Determines whether the given response\'s status code is retriable.\n\n        Parameters\n        ----------\n        response: requests.models.Response\n            HTTP response object returned by the request method.\n\n        Returns\n        -------\n        bool\n            Whether the HTTP request should be retried.\n        \'\'\'\n        return response.status_code in self._http_retrable_errors\n\n    def __init__(\n            self,\n            url: str,\n            session: Optional[requests.Session] = None,\n            qido_url_prefix: Optional[str] = None,\n            wado_url_prefix: Optional[str] = None,\n            stow_url_prefix: Optional[str] = None,\n            delete_url_prefix: Optional[str] = None,\n            proxies: Optional[Dict[str, str]] = None,\n            headers: Optional[Dict[str, str]] = None,\n            callback: Optional[Callable] = None,\n            chunk_size: Optional[int] = None\n    ) -> None:\n        \'\'\'\n        Parameters\n        ----------\n        url: str\n            base unique resource locator consisting of protocol, hostname\n            (IP address or DNS name) of the machine that hosts the server and\n            optionally port number and path prefix\n        session: requests.Session, optional\n            session required to make connection to the DICOMweb service\n            (see session_utils.py to create a valid session if necessary)\n        qido_url_prefix: str, optional\n        qido_url_prefix: str, optional\n            URL path prefix for QIDO RESTful services\n        wado_url_prefix: str, optional\n            URL path prefix for WADO RESTful services\n        stow_url_prefix: str, optional\n            URL path prefix for STOW RESTful services\n        delete_url_prefix: str, optional\n            URL path prefix for DELETE RESTful services\n        proxies: Dict[str, str], optional\n            mapping of protocol or protocol + host to the URL of a proxy server\n        headers: Dict[str, str], optional\n            custom headers that should be included in request messages,\n            e.g., authentication tokens\n        callback: Callable, optional\n            callback function to manipulate responses generated from requests\n            (see `requests event hooks <http://docs.python-requests.org/en/master/user/advanced/#event-hooks>`_)\n        chunk_size: int, optional\n            maximum number of bytes per data chunk using chunked transfer\n            encoding (helpful for storing and retrieving large objects or large\n            collections of objects such as studies or series)\n\n        \'\'\'  # noqa\n        if session is None:\n            logger.debug(\'initialize HTTP session\')\n            session = requests.session()\n        self._session = session\n        self.base_url = url\n        self.qido_url_prefix = qido_url_prefix\n        self.wado_url_prefix = wado_url_prefix\n        self.stow_url_prefix = stow_url_prefix\n        self.delete_url_prefix = delete_url_prefix\n\n        # This regular expression extracts the scheme and host name from the URL\n        # and optionally the port number and prefix:\n        # <scheme>://<host>(:<port>)(/<prefix>)\n        # For example: ""https://mydomain.com:443/wado-rs"", where\n        # scheme=""https"", host=""mydomain.com"", port=443, prefix=""wado-rs""\n        pattern = re.compile(\n            r\'(?P<scheme>[https]+)://(?P<host>[^/:]+)\'\n            r\'(?::(?P<port>\\d+))?(?:(?P<prefix>/[\\w/]+))?\'\n        )\n        match = re.match(pattern, self.base_url)\n        if match is None:\n            raise ValueError(\'Malformed URL: {}\'.format(self.base_url))\n        try:\n            self.protocol = match.group(\'scheme\')\n            self.host = match.group(\'host\')\n            port = match.group(\'port\')\n        except AttributeError:\n            raise ValueError(\'Malformed URL: {}\'.format(self.base_url))\n        if port:\n            self.port = int(port)\n        else:\n            if self.protocol == \'http\':\n                self.port = 80\n            elif self.protocol == \'https\':\n                self.port = 443\n            else:\n                raise ValueError(\n                    \'URL scheme ""{}"" is not supported.\'.format(self.protocol)\n                )\n        url_components = urlparse(url)\n        self.url_prefix = url_components.path\n        self._session.headers.update({\'Host\': self.host})\n        if headers is not None:\n            self._session.headers.update(headers)\n        if proxies is not None:\n            self._session.proxies = proxies\n        if callback is not None:\n            self._session.hooks = {\'response\': [callback, ]}\n        self._chunk_size = chunk_size\n        self.set_http_retry_params()\n\n    def _parse_qido_query_parameters(\n            self,\n            fuzzymatching: Optional[bool] = None,\n            limit: Optional[int] = None,\n            offset: Optional[int] = None,\n            fields: Optional[Sequence[str]] = None,\n            search_filters: Optional[Dict[str, Any]] = None\n        ) -> Dict[str, Any]:\n        \'\'\'Parses query parameters for inclusion into a HTTP query string\n        of a QIDO-RS request message.\n\n        Parameters\n        ----------\n        fuzzymatching: bool, optional\n            whether fuzzy semantic matching should be performed\n        limit: int, optional\n            maximum number of results that should be returned\n        offset: int, optional\n            number of results that should be skipped\n        fields: Sequence[str], optional\n            names of fields (attributes) that should be included in results\n        search_filters: Dict[str, Any], optional\n            search filter criteria as key-value pairs, where *key* is a keyword\n            or a tag of the attribute and *value* is the expected value that\n            should match\n\n        Returns\n        -------\n        collections.OrderedDict\n            sanitized and sorted query parameters\n\n        \'\'\'\n        params: Dict[str, Union[int, str, List[str]]] = {}\n        if limit is not None:\n            if not(isinstance(limit, int)):\n                raise TypeError(\'Parameter ""limit"" must be an integer.\')\n            if limit < 0:\n                raise ValueError(\'Parameter ""limit"" must not be negative.\')\n            params[\'limit\'] = limit\n        if offset is not None:\n            if not(isinstance(offset, int)):\n                raise TypeError(\'Parameter ""offset"" must be an integer.\')\n            if offset < 0:\n                raise ValueError(\'Parameter ""offset"" must not be negative.\')\n            params[\'offset\'] = offset\n        if fuzzymatching is not None:\n            if not(isinstance(fuzzymatching, bool)):\n                raise TypeError(\'Parameter ""fuzzymatching"" must be boolean.\')\n            if fuzzymatching:\n                params[\'fuzzymatching\'] = \'true\'\n            else:\n                params[\'fuzzymatching\'] = \'false\'\n        if fields is not None:\n            includefields = []\n            for field in set(fields):\n                if not(isinstance(field, str)):\n                    raise TypeError(\'Elements of ""fields"" must be a string.\')\n                includefields.append(field)\n            params[\'includefield\'] = includefields\n        if search_filters is not None:\n            for field, criterion in search_filters.items():\n                if not(isinstance(field, str)):\n                    raise TypeError(\n                        \'Keys of ""search_filters"" must be strings.\'\n                    )\n                # TODO: datetime?\n                params[field] = criterion\n        # Sort query parameters to facilitate unit testing\n        return OrderedDict(sorted(params.items()))\n\n    def _get_service_url(self, service_name: str) -> str:\n        \'\'\'Constructes the URL of a DICOMweb RESTful service.\n\n        Parameters\n        ----------\n        service_name: str\n            name of the RESTful service\n            (choices: ``""qido""``, ``""wado""``, or ``""stow""``)\n\n        Returns\n        -------\n        str\n            full URL for the given service\n\n        \'\'\'\n        service_url = self.base_url\n        if service_name == \'qido\':\n            if self.qido_url_prefix is not None:\n                service_url += \'/{}\'.format(self.qido_url_prefix)\n        elif service_name == \'wado\':\n            if self.wado_url_prefix is not None:\n                service_url += \'/{}\'.format(self.wado_url_prefix)\n        elif service_name == \'stow\':\n            if self.stow_url_prefix is not None:\n                service_url += \'/{}\'.format(self.stow_url_prefix)\n        elif service_name == \'delete\':\n            if self.delete_url_prefix is not None:\n                service_url += \'/{}\'.format(self.delete_url_prefix)\n        else:\n            raise ValueError(\n                \'Unsupported DICOMweb service ""{}"".\'.format(service_name)\n            )\n        return service_url\n\n    def _get_studies_url(\n            self,\n            service_name: str,\n            study_instance_uid: Optional[str] = None\n        ) -> str:\n        \'\'\'Constructes the URL for study-level requests.\n\n        Parameters\n        ----------\n        service_name: str\n            name of the RESTful service\n            (choices: ``""qido""``, ``""wado""``, or ``""stow""``)\n        study_instance_uid: str, optional\n            unique study identifier\n\n        Returns\n        -------\n        str\n            URL\n\n        \'\'\'\n        if study_instance_uid is not None:\n            url = \'{service_url}/studies/{study_instance_uid}\'\n        else:\n            url = \'{service_url}/studies\'\n        service_url = self._get_service_url(service_name)\n        return url.format(\n            service_url=service_url, study_instance_uid=study_instance_uid\n        )\n\n    def _get_series_url(\n            self,\n            service_name: str,\n            study_instance_uid: Optional[str] = None,\n            series_instance_uid: Optional[str] = None\n        ) -> str:\n        \'\'\'Constructes the URL for series-level requests.\n\n        Parameters\n        ----------\n        service_name: str\n            name of the RESTful service\n            (choices: ``""qido""``, ``""wado""``, or ``""stow""``)\n        study_instance_uid: str, optional\n            unique study identifier\n        series_instance_uid: str, optional\n            unique series identifier\n\n        Returns\n        -------\n        str\n            URL\n\n        \'\'\'\n        if study_instance_uid is not None:\n            url = self._get_studies_url(service_name, study_instance_uid)\n            if series_instance_uid is not None:\n                url += \'/series/{series_instance_uid}\'\n            else:\n                url += \'/series\'\n        else:\n            if series_instance_uid is not None:\n                logger.warning(\n                    \'series UID is ignored because study UID is undefined\'\n                )\n            url = \'{service_url}/series\'\n        service_url = self._get_service_url(service_name)\n        return url.format(\n            service_url=service_url, series_instance_uid=series_instance_uid\n        )\n\n    def _get_instances_url(\n            self,\n            service_name: str,\n            study_instance_uid: Optional[str] = None,\n            series_instance_uid: Optional[str] = None,\n            sop_instance_uid: Optional[str] = None\n        ) -> str:\n        \'\'\'Constructes the URL for instance-level requests.\n\n        Parameters\n        ----------\n        service_name: str\n            name of the RESTful service\n            (choices: ``""qido""``, ``""wado""``, or ``""stow""``)\n        study_instance_uid: str, optional\n            unique study identifier\n        series_instance_uid: str, optional\n            unique series identifier\n        sop_instance_uid: str, optional\n            unique instance identifier\n\n        Returns\n        -------\n        str\n            URL\n\n        \'\'\'\n        if study_instance_uid is not None and series_instance_uid is not None:\n            url = self._get_series_url(\n                service_name,\n                study_instance_uid,\n                series_instance_uid\n            )\n            url += \'/instances\'\n            if sop_instance_uid is not None:\n                url += \'/{sop_instance_uid}\'\n        else:\n            if sop_instance_uid is not None:\n                logger.warning(\n                    \'SOP Instance UID is ignored because Study/Series \'\n                    \'Instance UID are undefined\'\n                )\n            url = \'{service_url}/instances\'\n        service_url = self._get_service_url(service_name)\n        return url.format(\n            service_url=service_url, sop_instance_uid=sop_instance_uid\n        )\n\n    def _build_query_string(self, params: Dict[str, Any]) -> str:\n        \'\'\'Builds a HTTP query string for a GET request message.\n\n        Parameters\n        ----------\n        params: dict\n            query parameters as mapping of key-value pairs;\n            in case a key should be included more than once with different\n            values, values need to be provided in form of an iterable (e.g.,\n            ``{""key"": [""value1"", ""value2""]}`` will result in\n            ``""?key=value1&key=value2""``)\n\n        Returns\n        -------\n        str\n            query string\n\n        \'\'\'\n        components = []\n        for key, value in params.items():\n            if isinstance(value, (list, tuple, set)):\n                for v in value:\n                    c = \'=\'.join([key, quote_plus(str(v))])\n                    components.append(c)\n            else:\n                c = \'=\'.join([key, quote_plus(str(value))])\n                components.append(c)\n        if components:\n            return \'?{}\'.format(\'&\'.join(components))\n        else:\n            return \'\'\n\n    def _http_get(\n            self,\n            url: str,\n            params: Optional[Dict[str, Any]] = None,\n            headers: Optional[Dict[str, str]] = None\n        ) -> requests.models.Response:\n        \'\'\'Performs a HTTP GET request.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        params: Dict[str, Any], optional\n            query parameters\n        headers: Dict[str, str], optional\n            HTTP request message headers\n\n        Returns\n        -------\n        requests.models.Response\n            HTTP response message\n\n        \'\'\'\n        @retrying.retry(\n            retry_on_result=self._is_retriable_http_error,\n            wait_exponential_multiplier=self._wait_exponential_multiplier,\n            stop_max_attempt_number=self._max_attempts\n        )\n        def _invoke_get_request(\n                url: str,\n                headers: Optional[Dict[str, str]] = None\n            ) -> requests.models.Response:\n            # Setting stream allows for retrieval of data in chunks using\n            # the iter_content() method\n            return self._session.get(url=url, headers=headers, stream=True)\n\n        if headers is None:\n            headers = {}\n        if params is None:\n            params = {}\n        url += self._build_query_string(params)\n        logger.debug(\'GET: {} {}\'.format(url, headers))\n        response = _invoke_get_request(url, headers)\n        logger.debug(\'request status code: {}\'.format(response.status_code))\n        response.raise_for_status()\n        if response.status_code == 204:\n            logger.warning(\'empty response\')\n        # The server may not return all results, but rather include a warning\n        # header to notify that client that there are remaining results.\n        # (see DICOM Part 3.18 Section 6.7.1.2)\n        if \'Warning\' in response.headers:\n            logger.warning(response.headers[\'Warning\'])\n        return response\n\n    def _http_get_application_json(\n            self,\n            url: str,\n            params: Optional[Dict[str, Any]] = None\n        ) -> List[Dict[str, dict]]:\n        \'\'\'Performs a HTTP GET request that accepts ""applicaton/dicom+json""\n        or ""application/json"" media type.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        params: Dict[str], optional\n            query parameters\n\n        Returns\n        -------\n        List[str, dict]\n            content of HTTP message body in DICOM JSON format\n\n        \'\'\'\n        content_type = \'application/dicom+json, application/json\'\n        response = self._http_get(url, params, {\'Accept\': content_type})\n        if response.content:\n            decoded_response = response.json()\n            # All metadata resources are expected to be sent as a JSON array of\n            # DICOM data sets. However, some origin servers may incorrectly\n            # sent an individual data set.\n            if isinstance(decoded_response, dict):\n                return [decoded_response]\n            return decoded_response\n        return []\n\n    def _decode_multipart_message(\n            self,\n            body: bytes,\n            headers: Mapping[str, str]\n        ) -> List[bytes]:\n        \'\'\'Extracts parts of a HTTP multipart response message.\n\n        Parameters\n        ----------\n        body: bytes\n            HTTP response message body\n        headers: Dict[str, str]\n            HTTP response message headers\n\n        Returns\n        -------\n        List[bytes]\n            message parts\n\n        \'\'\'\n        header = \'\'.join([\n            \'{}: {}\\n\'.format(key, value)\n            for key, value in headers.items()\n        ]).encode()\n        message = email.message_from_bytes(header + body)\n        elements = []\n        for part in message.walk():\n            if part.get_content_maintype() == \'multipart\':\n                # Some servers don\'t handle this correctly.\n                # If only one frame number is provided, return a normal\n                # message body instead of a multipart message body.\n                if part.is_multipart():\n                    continue\n            payload = part.get_payload(decode=True)\n            elements.append(payload)\n        return elements\n\n    def _encode_multipart_message(\n            self,\n            data: Sequence[bytes],\n            content_type: str\n        ) -> bytes:\n        \'\'\'Encodes the payload of a HTTP multipart response message.\n\n        Parameters\n        ----------\n        data: Sequence[bytes]\n            data\n        content_type: str\n            content type of the multipart HTTP request message\n\n        Returns\n        -------\n        bytes\n            HTTP request message body\n\n        \'\'\'\n        multipart, content_type_field, boundary_field = content_type.split(\';\')\n        content_type = content_type_field.split(\'=\')[1].strip(\'""\')\n        boundary = boundary_field.split(\'=\')[1]\n        body = b\'\'\n        for payload in data:\n            body += (\n                \'\\r\\n--{boundary}\'\n                \'\\r\\nContent-Type: {content_type}\\r\\n\\r\\n\'.format(\n                    boundary=boundary,\n                    content_type=content_type\n                ).encode(\'utf-8\')\n            )\n            body += payload\n        body += \'\\r\\n--{boundary}--\'.format(boundary=boundary).encode(\'utf-8\')\n        return body\n\n    def _assert_media_type_is_valid(self, media_type: str):\n        \'\'\'Asserts that a given media type is valid.\n\n        Parameters\n        ----------\n        media_type: str\n            media type\n\n        Raises\n        ------\n        ValueError\n            when `media_type` is invalid\n\n        \'\'\'\n        error_message = \'Not a valid media type: ""{}""\'.format(media_type)\n        sep_index = media_type.find(\'/\')\n        if sep_index == -1:\n            raise ValueError(error_message)\n        media_type_type = media_type[:sep_index]\n        if media_type_type not in {\'application\', \'image\', \'text\', \'video\'}:\n            raise ValueError(error_message)\n        if media_type.find(\'/\', sep_index + 1) > 0:\n            raise ValueError(error_message)\n\n    def _build_range_header_field_value(\n            self,\n            byte_range: Optional[Tuple[int, int]]\n        ) -> str:\n        \'\'\'Builds a range header field value for HTTP GET request messages.\n\n        Parameters\n        ----------\n        byte_range: Tuple[int], optional\n            start and end of byte range\n\n        Returns\n        -------\n        str\n            range header field value\n\n        \'\'\'\n        if byte_range is not None:\n            start = str(byte_range[0])\n            try:\n                end = str(byte_range[1])\n            except IndexError:\n                end = \'\'\n            range_header_field_value = \'bytes={}-{}\'.format(start, end)\n        else:\n            range_header_field_value = \'bytes=0-\'\n        return range_header_field_value\n\n    def _build_accept_header_field_value(\n            self,\n            media_types: Union[Tuple[Union[str, Tuple[str, str]]], None],\n            supported_media_types: Set[str]\n        ) -> str:\n        \'\'\'Builds an accept header field value for HTTP GET request messages.\n\n        Parameters\n        ----------\n        media_types: Union[Tuple[str], None]\n            acceptable media types\n        supported_media_types: Set[str]\n            supported media types\n\n        Returns\n        -------\n        str\n            accept header field value\n\n        \'\'\'\n        if not isinstance(media_types, (list, tuple, set)):\n            raise TypeError(\n                \'Acceptable media types must be provided as a sequence.\'\n            )\n        field_value_parts = []\n        for media_type in media_types:\n            if not isinstance(media_type, str):\n                raise TypeError(\n                    \'Media type ""{}"" is not supported for \'\n                    \'requested resource\'.format(media_type)\n                )\n            self._assert_media_type_is_valid(media_type)\n            if media_type not in supported_media_types:\n                raise ValueError(\n                    \'Media type ""{}"" is not supported for \'\n                    \'requested resource\'.format(media_type)\n                )\n            field_value_parts.append(media_type)\n        return \', \'.join(field_value_parts)\n\n    def _build_multipart_accept_header_field_value(\n            self,\n            media_types: Union[Tuple[Union[str, Tuple[str, str]]], None],\n            supported_media_types: Union[Dict[str, str], Set[str]]\n        ) -> str:\n        \'\'\'Builds an accept header field value for HTTP GET multipart request\n        messages.\n\n        Parameters\n        ----------\n        media_types: Union[Tuple[Union[str, Tuple[str, str]]], None]\n            acceptable media types and optionally the UIDs of the corresponding\n            transfer syntaxes\n        supported_media_types: Union[Dict[str, str], Set[str]]\n            set of supported media types or mapping of transfer syntaxes\n            to their corresponding media types\n\n        Returns\n        -------\n        str\n            accept header field value\n\n        \'\'\'\n        if not isinstance(media_types, (list, tuple, set)):\n            raise TypeError(\n                \'Acceptable media types must be provided as a sequence.\'\n            )\n        field_value_parts = []\n        for item in media_types:\n            if isinstance(item, str):\n                media_type = item\n                transfer_syntax_uid = None\n            else:\n                media_type = item[0]\n                try:\n                    transfer_syntax_uid = item[1]\n                except IndexError:\n                    transfer_syntax_uid = None\n            self._assert_media_type_is_valid(media_type)\n            field_value = \'multipart/related; type=""{}""\'.format(media_type)\n            if isinstance(supported_media_types, dict):\n                if media_type not in supported_media_types.values():\n                    if (not media_type.endswith(\'/*\') or\n                            not media_type.endswith(\'/\')):\n                        raise ValueError(\n                            \'Media type ""{}"" is not supported for \'\n                            \'requested resource.\'.format(media_type)\n                        )\n                if transfer_syntax_uid is not None:\n                    if transfer_syntax_uid != \'*\':\n                        if transfer_syntax_uid not in supported_media_types:\n                            raise ValueError(\n                                \'Transfer syntax ""{}"" is not supported \'\n                                \'for requested resource.\'.format(\n                                    transfer_syntax_uid\n                                )\n                            )\n                        expected_media_type = supported_media_types[\n                            transfer_syntax_uid\n                        ]\n                        if expected_media_type != media_type:\n                            have_same_type = (\n                                self._parse_media_type(media_type)[0] ==\n                                self._parse_media_type(expected_media_type)[0]\n                            )\n                            if (have_same_type and\n                                    (media_type.endswith(\'/*\') or\n                                        media_type.endswith(\'/\'))):\n                                continue\n                            raise ValueError(\n                                \'Transfer syntax ""{}"" is not supported \'\n                                \'for media type ""{}"".\'.format(\n                                    transfer_syntax_uid, media_type\n                                )\n                            )\n                    field_value += \'; transfer-syntax={}\'.format(\n                        transfer_syntax_uid\n                    )\n            else:\n                if media_type not in supported_media_types:\n                    raise ValueError(\n                        \'Media type ""{}"" is not supported for \'\n                        \'requested resource.\'.format(media_type)\n                    )\n            field_value_parts.append(field_value)\n        return \', \'.join(field_value_parts)\n\n    def _http_get_multipart_application_dicom(\n            self,\n            url: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n            params: Optional[Dict[str, Any]] = None\n        ) -> List[pydicom.dataset.Dataset]:\n        \'\'\'Performs a HTTP GET request that accepts a multipart message with\n        ""applicaton/dicom"" media type.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media types and optionally the UIDs of the\n            corresponding transfer syntaxes, (defaults to\n            ``(""application/dicom"", ""1.2.840.10008.1.2.1"")``)\n        params: Dict[str, Any], optional\n            additional HTTP GET query parameters\n\n        Returns\n        -------\n        List[pydicom.dataset.Dataset]\n            DICOM data sets\n\n        \'\'\'\n        default_media_type = \'application/dicom\'\n        supported_media_types = {\n            \'1.2.840.10008.1.2.1\': default_media_type,\n            \'1.2.840.10008.1.2.5\': default_media_type,\n            \'1.2.840.10008.1.2.4.50\': default_media_type,\n            \'1.2.840.10008.1.2.4.51\': default_media_type,\n            \'1.2.840.10008.1.2.4.57\': default_media_type,\n            \'1.2.840.10008.1.2.4.70\': default_media_type,\n            \'1.2.840.10008.1.2.4.80\': default_media_type,\n            \'1.2.840.10008.1.2.4.81\': default_media_type,\n            \'1.2.840.10008.1.2.4.90\': default_media_type,\n            \'1.2.840.10008.1.2.4.91\': default_media_type,\n            \'1.2.840.10008.1.2.4.92\': default_media_type,\n            \'1.2.840.10008.1.2.4.93\': default_media_type,\n            \'1.2.840.10008.1.2.4.100\': default_media_type,\n            \'1.2.840.10008.1.2.4.101\': default_media_type,\n            \'1.2.840.10008.1.2.4.102\': default_media_type,\n            \'1.2.840.10008.1.2.4.103\': default_media_type,\n            \'1.2.840.10008.1.2.4.104\': default_media_type,\n            \'1.2.840.10008.1.2.4.105\': default_media_type,\n            \'1.2.840.10008.1.2.4.106\': default_media_type,\n        }\n        if media_types is None:\n            media_types = (default_media_type, )\n        headers = {\n            \'Accept\': self._build_multipart_accept_header_field_value(\n                media_types, supported_media_types\n            ),\n        }\n        response = self._http_get(url, params, headers)\n        with response as r:\n            if self._chunk_size is not None:\n                logger.info(\'retrieve data in chunks\')\n                content = b\'\'.join([\n                    chunk\n                    for chunk in r.iter_content(chunk_size=self._chunk_size)\n                ])\n            else:\n                content = r.content\n        datasets = self._decode_multipart_message(\n            content,\n            response.headers\n        )\n        return [pydicom.dcmread(BytesIO(ds)) for ds in datasets]\n\n    def _http_get_multipart_application_octet_stream(\n            self,\n            url: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n            byte_range: Optional[Tuple[int, int]] = None,\n            params: Optional[Dict[str, Any]] = None\n        ) -> List[bytes]:\n        \'\'\'Performs a HTTP GET request that accepts a multipart message with\n        ""applicaton/octet-stream"" media type.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media types and optionally the UIDs of the\n            corresponding transfer syntaxes (defaults to\n            ``(""application/octet-stream"", ""1.2.840.10008.1.2.1"")``)\n        byte_range: Tuple[int, int], optional\n            start and end of byte range\n        params: Dict[str, Any], optional\n            additional HTTP GET query parameters\n\n        Returns\n        -------\n        List[bytes]\n            content of HTTP message body parts\n\n        \'\'\'\n        default_media_type = \'application/octet-stream\'\n        supported_media_types = {\n            \'1.2.840.10008.1.2.1\': default_media_type,\n        }\n        if media_types is None:\n            media_types = (default_media_type, )\n        headers = {\n            \'Accept\': self._build_multipart_accept_header_field_value(\n                media_types,\n                supported_media_types\n            ),\n        }\n        if byte_range is not None:\n            headers[\'Range\'] = self._build_range_header_field_value(byte_range)\n        response = self._http_get(url, params, headers)\n        return self._decode_multipart_message(\n            response.content,\n            response.headers\n        )\n\n    def _http_get_multipart_image(\n            self,\n            url: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n            byte_range: Optional[Tuple[int, int]] = None,\n            params: Optional[Dict[str, Any]] = None,\n            rendered: bool = False\n        ) -> List[bytes]:\n        \'\'\'Performs a HTTP GET request that accepts a multipart message with\n        an image media type.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media types and optionally the UIDs of the\n            corresponding transfer syntaxes\n        byte_range: Tuple[int, int], optional\n            start and end of byte range\n        params: Dict[str, Any], optional\n            additional HTTP GET query parameters\n        rendered: bool, optional\n            whether resource should be requested using rendered media types\n\n        Returns\n        -------\n        List[bytes]\n            content of HTTP message body parts\n\n        \'\'\'\n        headers = {}\n        supported_media_types: Union[set, dict]\n        if rendered:\n            supported_media_types = {\n                \'image/jpeg\',\n                \'image/gif\',\n                \'image/png\',\n                \'image/jp2\',\n            }\n        else:\n            supported_media_types = {\n                \'1.2.840.10008.1.2.5\': \'image/x-dicom-rle\',\n                \'1.2.840.10008.1.2.4.50\': \'image/jpeg\',\n                \'1.2.840.10008.1.2.4.51\': \'image/jpeg\',\n                \'1.2.840.10008.1.2.4.57\': \'image/jpeg\',\n                \'1.2.840.10008.1.2.4.70\': \'image/jpeg\',\n                \'1.2.840.10008.1.2.4.80\': \'image/x-jls\',\n                \'1.2.840.10008.1.2.4.81\': \'image/x-jls\',\n                \'1.2.840.10008.1.2.4.90\': \'image/jp2\',\n                \'1.2.840.10008.1.2.4.91\': \'image/jp2\',\n                \'1.2.840.10008.1.2.4.92\': \'image/jpx\',\n                \'1.2.840.10008.1.2.4.93\': \'image/jpx\',\n            }\n            if byte_range is not None:\n                headers[\'Range\'] = self._build_range_header_field_value(\n                    byte_range\n                )\n        headers[\'Accept\'] = self._build_multipart_accept_header_field_value(\n            media_types,\n            supported_media_types\n        )\n        response = self._http_get(url, params, headers)\n        return self._decode_multipart_message(\n            response.content,\n            response.headers\n        )\n\n    def _http_get_multipart_video(\n            self,\n            url: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n            byte_range: Optional[Tuple[int, int]] = None,\n            params: Optional[Dict[str, Any]] = None,\n            rendered: bool = False\n        ) -> List[bytes]:\n        \'\'\'Performs a HTTP GET request that accepts a multipart message with\n        a video media type.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        media_types: Tuple[Union[str, Tuple[str, str]]]\n            acceptable media types and optionally the UIDs of the\n            corresponding transfer syntaxes\n        byte_range: Tuple[int, int], optional\n            start and end of byte range\n        params: Dict[str, Any], optional\n            additional HTTP GET query parameters\n        rendered: bool, optional\n            whether resource should be requested using rendered media types\n\n        Returns\n        -------\n        List[bytes]\n            content of HTTP message body parts\n\n        \'\'\'\n        headers = {}\n        supported_media_types: Union[set, dict]\n        if rendered:\n            supported_media_types = {\n                \'video/\',\n                \'video/*\',\n                \'video/mpeg2\',\n                \'video/mp4\',\n                \'video/H265\',\n            }\n        else:\n            supported_media_types = {\n                \'1.2.840.10008.1.2.4.100\': \'video/mpeg2\',\n                \'1.2.840.10008.1.2.4.101\': \'video/mpeg2\',\n                \'1.2.840.10008.1.2.4.102\': \'video/mp4\',\n                \'1.2.840.10008.1.2.4.103\': \'video/mp4\',\n                \'1.2.840.10008.1.2.4.104\': \'video/mp4\',\n                \'1.2.840.10008.1.2.4.105\': \'video/mp4\',\n                \'1.2.840.10008.1.2.4.106\': \'video/mp4\',\n            }\n            if byte_range is not None:\n                headers[\'Range\'] = self._build_range_header_field_value(\n                    byte_range\n                )\n        headers[\'Accept\'] = self._build_multipart_accept_header_field_value(\n            media_types,\n            supported_media_types\n        )\n        response = self._http_get(url, params, headers)\n        return self._decode_multipart_message(\n            response.content,\n            response.headers\n        )\n\n    def _http_get_application_pdf(\n            self,\n            url: str,\n            params: Optional[Dict[str, Any]] = None\n        ) -> bytes:\n        \'\'\'Performs a HTTP GET request that accepts a message with\n        ""applicaton/pdf"" media type.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        params: Dict[str], optional\n            additional HTTP GET query parameters\n        rendered: bool, optional\n            whether resource should be requested using rendered media types\n\n        Returns\n        -------\n        bytes\n            content of HTTP message body\n\n        \'\'\'\n        media_type = \'application/pdf\'\n        response = self._http_get(url, params, {\'Accept\': media_type})\n        return response.content\n\n    def _http_get_image(\n            self,\n            url: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n            params: Optional[Dict[str, Any]] = None\n        ) -> bytes:\n        \'\'\'Performs a HTTP GET request that accepts a message with an image\n        media type.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            image media type (choices: ``""image/jpeg""``, ``""image/gif""``,\n            ``""image/jp2""``, ``""image/png""``)\n        params: Dict[str, Any], optional\n            additional HTTP GET query parameters\n\n        Returns\n        -------\n        bytes\n            content of HTTP message body\n\n        \'\'\'\n        supported_media_types = {\n            \'image/\',\n            \'image/*\',\n            \'image/jpeg\',\n            \'image/jp2\',\n            \'image/gif\',\n            \'image/png\',\n        }\n        accept_header_field_value = self._build_accept_header_field_value(\n            media_types,\n            supported_media_types\n        )\n        headers = {\n            \'Accept\': accept_header_field_value,\n        }\n        response = self._http_get(url, params, headers)\n        return response.content\n\n    def _http_get_video(\n            self,\n            url: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n            params: Optional[Dict[str, Any]] = None\n        ) -> bytes:\n        \'\'\'Performs a HTTP GET request that accepts a message with an video\n        media type.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            video media type (choices: ``""video/mpeg""``, ``""video/mp4""``,\n            ``""video/H265""``)\n        params: Dict[str, Any], optional\n            additional HTTP GET query parameters\n\n        Returns\n        -------\n        bytes\n            content of HTTP message body\n\n        \'\'\'\n        supported_media_types = {\n            \'video/\',\n            \'video/*\',\n            \'video/mpeg\',\n            \'video/mp4\',\n            \'video/H265\',\n        }\n        accept_header_field_value = self._build_accept_header_field_value(\n            media_types,\n            supported_media_types\n        )\n        headers = {\n            \'Accept\': accept_header_field_value,\n        }\n        response = self._http_get(url, params, headers)\n        return response.content\n\n    def _http_get_text(\n            self,\n            url: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n            params: Optional[Dict[str, Any]] = None\n        ) -> bytes:\n        \'\'\'Performs a HTTP GET request that accepts a message with an text\n        media type.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            text media type (choices: ``""text/html""``, ``""text/plain""``,\n            ``""text/xml""``, ``""text/rtf""``)\n        params: Dict[str, Any], optional\n            additional HTTP GET query parameters\n\n        Returns\n        -------\n        bytes\n            content of HTTP message body\n\n        \'\'\'\n        supported_media_types = {\n            \'text/\',\n            \'text/*\',\n            \'text/html\',\n            \'text/plain\',\n            \'text/rtf\',\n            \'text/xml\',\n        }\n        accept_header_field_value = self._build_accept_header_field_value(\n            media_types, supported_media_types\n        )\n        headers = {\n            \'Accept\': accept_header_field_value,\n        }\n        response = self._http_get(url, params, headers)\n        return response.content\n\n    def _http_post(\n            self,\n            url: str,\n            data: bytes,\n            headers: Dict[str, str]\n        ) -> requests.models.Response:\n        \'\'\'Performs a HTTP POST request.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        data: bytes\n            HTTP request message payload\n        headers: Dict[str, str]\n            HTTP request message headers\n\n        Returns\n        -------\n        requests.models.Response\n            HTTP response message\n\n        \'\'\'\n        logger.debug(\'POST: {} {}\'.format(url, headers))\n\n        def serve_data_chunks(data):\n            for i, offset in enumerate(range(0, len(data), self._chunk_size)):\n                end = offset + self._chunk_size\n                yield data[offset:end]\n\n        @retrying.retry(\n            retry_on_result=self._is_retriable_http_error,\n            wait_exponential_multiplier=self._wait_exponential_multiplier,\n            stop_max_attempt_number=self._max_attempts\n        )\n        def _invoke_post_request(\n                url: str,\n                data: bytes,\n                headers: Optional[Dict[str, str]] = None\n            ) -> requests.models.Response:\n            return self._session.post(url, data=data, headers=headers)\n\n        if self._chunk_size is not None and len(data) > self._chunk_size:\n            logger.info(\'store data in chunks using chunked transfer encoding\')\n            chunked_headers = dict(headers)\n            chunked_headers[\'Transfer-Encoding\'] = \'chunked\'\n            chunked_headers[\'Cache-Control\'] = \'no-cache\'\n            chunked_headers[\'Connection\'] = \'Keep-Alive\'\n            data_chunks = serve_data_chunks(data)\n            response = _invoke_post_request(url, data_chunks, chunked_headers)\n        else:\n            response = _invoke_post_request(url, data, headers)\n        logger.debug(\'request status code: {}\'.format(response.status_code))\n        response.raise_for_status()\n        if not response.ok:\n            logger.warning(\'storage was not successful for all instances\')\n            payload = response.content\n            content_type = response.headers[\'Content-Type\']\n            if content_type in (\'application/dicom+json\', \'application/json\', ):\n                dataset = load_json_dataset(payload)\n            elif content_type in (\'application/dicom+xml\', \'application/xml\', ):\n                tree = fromstring(payload)\n                dataset = _load_xml_dataset(tree)\n            else:\n                raise ValueError(\'Response message has unexpected media type.\')\n            failed_sop_sequence = getattr(dataset, \'FailedSOPSequence\', [])\n            for failed_sop_item in failed_sop_sequence:\n                logger.error(\n                    \'storage of instance {} failed: ""{}""\'.format(\n                        failed_sop_item.ReferencedSOPInstanceUID,\n                        failed_sop_item.FailureReason\n                    )\n                )\n        return response\n\n    def _http_post_multipart_application_dicom(\n            self,\n            url: str,\n            data: Sequence[bytes]\n        ) -> pydicom.Dataset:\n        \'\'\'Performs a HTTP POST request with a multipart payload with\n        ""application/dicom"" media type.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n        data: Sequence[bytes]\n            DICOM data sets that should be posted\n\n        Returns\n        -------\n        pydicom.dataset.Dataset\n            information about stored instances\n\n        \'\'\'\n        content_type = (\n            \'multipart/related; \'\n            \'type=""application/dicom""; \'\n            \'boundary=0f3cf5c0-70e0-41ef-baef-c6f9f65ec3e1\'\n        )\n        content = self._encode_multipart_message(data, content_type)\n        response = self._http_post(\n            url,\n            content,\n            headers={\'Content-Type\': content_type}\n        )\n        if response.content:\n            content_type = response.headers[\'Content-Type\']\n            if content_type in (\'application/dicom+json\', \'application/json\', ):\n                return load_json_dataset(response.json())\n            elif content_type in (\'application/dicom+xml\', \'application/xml\', ):\n                tree = fromstring(response.content)\n                return _load_xml_dataset(tree)\n        return pydicom.Dataset()\n\n    def _http_delete(self, url: str):\n        \'\'\'Performs a HTTP DELETE request to the specified URL.\n\n        Parameters\n        ----------\n        url: str\n            unique resource locator\n\n        Returns\n        -------\n        requests.models.Response\n            HTTP response message\n        \'\'\'\n        @retrying.retry(\n            retry_on_result=self._is_retriable_http_error,\n            wait_exponential_multiplier=self._wait_exponential_multiplier,\n            stop_max_attempt_number=self._max_attempts\n        )\n        def _invoke_delete_request(url: str) -> requests.models.Response:\n            return self._session.delete(url)\n\n        response = _invoke_delete_request(url)\n        if response.status_code == HTTPStatus.METHOD_NOT_ALLOWED:\n            logger.error(\n              \'Resource could not be deleted. The origin server may not support\'\n              \'deletion or you may not have the necessary permissions.\')\n        response.raise_for_status()\n        return response\n\n    def search_for_studies(\n            self,\n            fuzzymatching: Optional[bool] = None,\n            limit: Optional[int] = None,\n            offset: Optional[int] = None,\n            fields: Optional[Sequence[str]] = None,\n            search_filters: Optional[Dict[str, Any]] = None\n        ) -> List[Dict[str, dict]]:\n        \'\'\'Searches for DICOM studies.\n\n        Parameters\n        ----------\n        fuzzymatching: bool, optional\n            whether fuzzy semantic matching should be performed\n        limit: int, optional\n            maximum number of results that should be returned\n        offset: int, optional\n            number of results that should be skipped\n        fields: Sequence[str], optional\n            names of fields (attributes) that should be included in results\n        search_filters: dict, optional\n            search filter criteria as key-value pairs, where *key* is a keyword\n            or a tag of the attribute and *value* is the expected value that\n            should match\n\n        Returns\n        -------\n        List[Dict[str, dict]]\n            study representations\n            (see `Study Result Attributes <http://dicom.nema.org/medical/dicom/current/output/chtml/part18/sect_6.7.html#table_6.7.1-2>`_)\n\n        Note\n        ----\n        The server may only return a subset of search results. In this case,\n        a warning will notify the client that there are remaining results.\n        Remaining results can be requested via repeated calls using the\n        `offset` parameter.\n\n        \'\'\' # noqa\n        url = self._get_studies_url(\'qido\')\n        params = self._parse_qido_query_parameters(\n            fuzzymatching, limit, offset, fields, search_filters\n        )\n        return self._http_get_application_json(url, params)\n\n    def _parse_media_type(self, media_type: str) -> Tuple[str, str]:\n        \'\'\'Parses media type and extracts its type and subtype.\n\n        Parameters\n        ----------\n        media_type: str\n            media type, e.g., ``""image/jpeg""``\n\n        Returns\n        -------\n        Tuple[str, str]\n            type and subtype of media type (``(""image"", ""jpeg"")``)\n\n        Raises\n        ------\n        ValueError\n            when `media_type` is invalid\n\n        \'\'\'\n        self._assert_media_type_is_valid(media_type)\n        media_type_type, media_type_subtype = media_type.split(\'/\')\n        return media_type_type, media_type_subtype\n\n    def _get_common_media_type(\n            self,\n            media_types: Tuple[Union[str, Tuple[str, str]]]\n        ) -> str:\n        \'\'\'Gets common type of acceptable media types and asserts that only\n        one type is specified. For example, ``(""image/jpeg"", ""image/jp2"")``\n        will pass, but ``(""image/jpeg"", ""video/mpeg2"")`` will raise an\n        exception.\n\n        Parameters\n        ----------\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media types and optionally the UIDs of the\n            corresponding transfer syntaxes\n\n        Returns\n        -------\n        str\n            type of media type\n\n        Raises\n        ------\n        ValueError\n            when more than one type is specified\n\n        \'\'\'\n        if media_types is None:\n            raise ValueError(\'No acceptable media types provided.\')\n        common_media_types = []\n        for item in media_types:\n            if isinstance(item, str):\n                media_type = item\n            else:\n                media_type = item[0]\n            if media_type.startswith(\'application\'):\n                common_media_types.append(media_type)\n            else:\n                mtype, msubtype = self._parse_media_type(media_type)\n                common_media_types.append(\'{}/\'.format(mtype))\n        if len(set(common_media_types)) == 0:\n            raise ValueError(\n                \'No common acceptable media type could be identified.\'\n            )\n        elif len(set(common_media_types)) > 1:\n            raise ValueError(\'Acceptable media types must have the same type.\')\n        return common_media_types[0]\n\n    def retrieve_bulkdata(\n            self,\n            url: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n            byte_range: Optional[Tuple[int, int]] = None\n        ) -> List[bytes]:\n        \'\'\'Retrieves bulk data from a given location.\n\n        Parameters\n        ----------\n        url: str\n            location of the bulk data\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media types and optionally the UIDs of the\n            corresponding transfer syntaxes\n        byte_range: Tuple[int], optional\n            start and end of byte range\n\n        Returns\n        -------\n        List[bytes]\n            bulk data items\n\n        \'\'\'\n        if media_types is None:\n            return self._http_get_multipart_application_octet_stream(\n                url, media_types, byte_range\n            )\n        common_media_type = self._get_common_media_type(media_types)\n        if common_media_type == \'application/octet-stream\':\n            return self._http_get_multipart_application_octet_stream(\n                url, media_types, byte_range\n            )\n        elif common_media_type.startswith(\'image\'):\n            return self._http_get_multipart_image(\n                url, media_types, byte_range\n            )\n        else:\n            raise ValueError(\n                \'Media type ""{}"" is not supported for \'\n                \'retrieval of bulkdata.\'.format(common_media_type)\n            )\n\n    def retrieve_study(\n            self,\n            study_instance_uid: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n        ) -> List[pydicom.dataset.Dataset]:\n        \'\'\'Retrieves instances of a given DICOM study.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media types and optionally the UIDs of the\n            corresponding transfer syntaxes\n\n        Returns\n        -------\n        List[pydicom.dataset.Dataset]\n            data sets\n\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n                \'Study Instance UID is required for retrieval of study.\'\n            )\n        url = self._get_studies_url(\'wado\', study_instance_uid)\n        if media_types is None:\n            return self._http_get_multipart_application_dicom(url)\n        common_media_type = self._get_common_media_type(media_types)\n        if common_media_type == \'application/dicom\':\n            return self._http_get_multipart_application_dicom(\n                url, media_types\n            )\n        elif common_media_type == \'application/octet-stream\':\n            return self._http_get_multipart_application_octet_stream(\n                url, media_types\n            )\n        elif common_media_type.startswith(\'image\'):\n            return self._http_get_multipart_image(\n                url, media_types\n            )\n        elif common_media_type.startswith(\'video\'):\n            return self._http_get_multipart_video(\n                url, media_types\n            )\n        else:\n            raise ValueError(\n                \'Media type ""{}"" is not supported for retrieval \'\n                \'of study.\'.format(common_media_type)\n            )\n\n    def retrieve_study_metadata(\n            self,\n            study_instance_uid: str\n        ) -> List[Dict[str, dict]]:\n        \'\'\'Retrieves metadata of instances of a given DICOM study.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n\n        Returns\n        -------\n        List[Dict[str, dict]]\n            metadata in DICOM JSON format\n\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n                \'Study Instance UID is required for retrieval of \'\n                \'study metadata.\'\n            )\n        url = self._get_studies_url(\'wado\', study_instance_uid)\n        url += \'/metadata\'\n        return self._http_get_application_json(url)\n\n    def delete_study(self, study_instance_uid: str) -> None:\n        \'\'\'Deletes specified study and its respective instances.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n\n        Returns\n        -------\n        requests.models.Response\n            HTTP response object returned.\n\n        Note\n        ----\n        The Delete Study resource is not part of the DICOM standard\n        and may not be supported by all origin servers.\n\n        WARNING\n        -------\n        This method performs a DELETE and should be used with caution.\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n              \'Study Instance UID is required for deletion of a study.\'\n            )\n        url = self._get_studies_url(\'delete\', study_instance_uid)\n        return self._http_delete(url)\n\n    def _assert_uid_format(self, uid: str) -> None:\n        \'\'\'Checks whether a DICOM UID has the correct format.\n\n        Parameters\n        ----------\n        uid: str\n            DICOM UID\n\n        Raises\n        ------\n        TypeError\n            when `uid` is not a string\n        ValueError\n            when `uid` doesn\'t match the regular expression pattern\n            ``""^[.0-9]+$""``\n\n        \'\'\'\n        if not isinstance(uid, str):\n            raise TypeError(\'DICOM UID must be a string.\')\n        pattern = re.compile(\'^[.0-9]+$\')\n        if not pattern.search(uid):\n            raise ValueError(\'DICOM UID has invalid format.\')\n\n    def search_for_series(\n            self,\n            study_instance_uid: Optional[str] = None,\n            fuzzymatching: Optional[bool] = None,\n            limit: Optional[int] = None,\n            offset: Optional[int] = None,\n            fields: Optional[Sequence[str]] = None,\n            search_filters: Optional[Dict[str, Any]] = None\n        ) -> List[Dict[str, dict]]:\n        \'\'\'Searches for DICOM series.\n\n        Parameters\n        ----------\n        study_instance_uid: str, optional\n            unique study identifier\n        fuzzymatching: bool, optional\n            whether fuzzy semantic matching should be performed\n        limit: int, optional\n            maximum number of results that should be returned\n        offset: int, optional\n            number of results that should be skipped\n        fields: Union[list, tuple, set], optional\n            names of fields (attributes) that should be included in results\n        search_filters: Dict[str, Union[str, int, float]], optional\n            search filter criteria as key-value pairs, where *key* is a keyword\n            or a tag of the attribute and *value* is the expected value that\n            should match\n\n        Returns\n        -------\n        List[Dict[str, dict]]\n            series representations\n            (see `Series Result Attributes <http://dicom.nema.org/medical/dicom/current/output/chtml/part18/sect_6.7.html#table_6.7.1-2a>`_)\n\n        Note\n        ----\n        The server may only return a subset of search results. In this case,\n        a warning will notify the client that there are remaining results.\n        Remaining results can be requested via repeated calls using the\n        `offset` parameter.\n\n        \'\'\' # noqa\n        if study_instance_uid is not None:\n            self._assert_uid_format(study_instance_uid)\n        url = self._get_series_url(\'qido\', study_instance_uid)\n        params = self._parse_qido_query_parameters(\n            fuzzymatching, limit, offset, fields, search_filters\n        )\n        return self._http_get_application_json(url, params)\n\n    def retrieve_series(\n            self,\n            study_instance_uid: str,\n            series_instance_uid: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None\n        ) -> List[pydicom.dataset.Dataset]:\n        \'\'\'Retrieves instances of a given DICOM series.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n        series_instance_uid: str\n            unique series identifier\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media types and optionally the UIDs of the\n            corresponding transfer syntaxes\n\n        Returns\n        -------\n        List[pydicom.dataset.Dataset]\n            data sets\n\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n                \'Study Instance UID is required for retrieval of series.\'\n            )\n        self._assert_uid_format(study_instance_uid)\n        if series_instance_uid is None:\n            raise ValueError(\n                \'Series Instance UID is required for retrieval of series.\'\n            )\n        self._assert_uid_format(series_instance_uid)\n        url = self._get_series_url(\n            \'wado\', study_instance_uid, series_instance_uid\n        )\n        if media_types is None:\n            return self._http_get_multipart_application_dicom(url)\n        common_media_type = self._get_common_media_type(media_types)\n        if common_media_type == \'application/dicom\':\n            return self._http_get_multipart_application_dicom(\n                url, media_types\n            )\n        elif common_media_type == \'application/octet-stream\':\n            return self._http_get_multipart_application_octet_stream(\n                url, media_types\n            )\n        elif common_media_type.startswith(\'image\'):\n            return self._http_get_multipart_image(\n                url, media_types\n            )\n        elif common_media_type.startswith(\'video\'):\n            return self._http_get_multipart_video(\n                url, media_types\n            )\n        else:\n            raise ValueError(\n                \'Media type ""{}"" is not supported for retrieval \'\n                \'of series.\'.format(common_media_type)\n            )\n\n    def retrieve_series_metadata(\n            self,\n            study_instance_uid: str,\n            series_instance_uid: str,\n        ) -> List[Dict[str, dict]]:\n        \'\'\'Retrieves metadata for instances of a given DICOM series.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n        series_instance_uid: str\n            unique series identifier\n\n        Returns\n        -------\n        Dict[str, dict]\n            metadata in DICOM JSON format\n\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n                \'Study Instance UID is required for retrieval of \'\n                \'series metadata.\'\n            )\n        self._assert_uid_format(study_instance_uid)\n        if series_instance_uid is None:\n            raise ValueError(\n                \'Series Instance UID is required for retrieval of \'\n                \'series metadata.\'\n            )\n        self._assert_uid_format(series_instance_uid)\n        url = self._get_series_url(\n            \'wado\', study_instance_uid, series_instance_uid\n        )\n        url += \'/metadata\'\n        return self._http_get_application_json(url)\n\n    def retrieve_series_rendered(\n            self, study_instance_uid,\n            series_instance_uid,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n            params: Optional[Dict[str, Any]] = None\n        ) -> bytes:\n        \'\'\'Retrieves an individual, server-side rendered DICOM series.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n        series_instance_uid: str\n            unique series identifier\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media types (choices: ``""image/jpeg""``, ``""image/jp2""``,\n            ``""image/gif""``, ``""image/png""``, ``""video/gif""``, ``""video/mp4""``,\n            ``""video/h265""``, ``""text/html""``, ``""text/plain""``,\n            ``""text/xml""``, ``""text/rtf""``, ``""application/pdf""``)\n        params: Dict[str, Any], optional\n            additional parameters relevant for given `media_type`,\n            e.g., ``{""quality"": 95}`` for ``""image/jpeg""``\n\n        Returns\n        -------\n        bytes\n            rendered series\n\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n                \'Study Instance UID is required for retrieval of \'\n                \'rendered series.\'\n            )\n        if series_instance_uid is None:\n            raise ValueError(\n                \'Series Instance UID is required for retrieval of \'\n                \'rendered series.\'\n            )\n        url = self._get_series_url(\n            \'wado\', study_instance_uid, series_instance_uid\n        )\n        url += \'/rendered\'\n        if media_types is None:\n            response = self._http_get(url, params)\n            return response.content\n        common_media_type = self._get_common_media_type(media_types)\n        if common_media_type.startswith(\'image\'):\n            return self._http_get_image(url, media_types, params)\n        elif common_media_type.startswith(\'video\'):\n            return self._http_get_video(url, media_types, params)\n        elif common_media_type.startswith(\'text\'):\n            return self._http_get_text(url, media_types, params)\n        elif common_media_type == \'application/pdf\':\n            return self._http_get_application_pdf(url, params)\n        else:\n            raise ValueError(\n                \'Media type ""{}"" is not supported for \'\n                \'retrieval of rendered series.\'.format(common_media_type)\n            )\n\n    def delete_series(\n            self,\n            study_instance_uid: str,\n            series_instance_uid: str\n        ) -> None:\n        \'\'\'Deletes specified series and its respective instances.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n        series_instance_uid: str\n            unique series identifier\n\n        Note\n        ----\n        The Delete Series resource is not part of the DICOM standard\n        and may not be supported by all origin servers.\n        Returns\n        -------\n        requests.models.Response\n            HTTP response object returned.\n\n        WARNING\n        -------\n        This method performs a DELETE and should be used with caution.\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n              \'Study Instance UID is required for deletion of a series.\'\n            )\n        if series_instance_uid is None:\n            raise ValueError(\n                \'Series Instance UID is required for deletion of a series.\'\n            )\n        url = self._get_series_url(\'delete\', study_instance_uid,\n                                   series_instance_uid)\n        return self._http_delete(url)\n\n    def search_for_instances(\n            self,\n            study_instance_uid: Optional[str] = None,\n            series_instance_uid: Optional[str] = None,\n            fuzzymatching: Optional[bool] = None,\n            limit: Optional[int] = None,\n            offset: Optional[int] = None,\n            fields: Optional[Sequence[str]] = None,\n            search_filters: Optional[Dict[str, Any]] = None\n        ) -> List[Dict[str, dict]]:\n        \'\'\'Searches for DICOM instances.\n\n        Parameters\n        ----------\n        study_instance_uid: str, optional\n            unique study identifier\n        series_instance_uid: str, optional\n            unique series identifier\n        fuzzymatching: bool, optional\n            whether fuzzy semantic matching should be performed\n        limit: int, optional\n            maximum number of results that should be returned\n        offset: int, optional\n            number of results that should be skipped\n        fields: Union[list, tuple, set], optional\n            names of fields (attributes) that should be included in results\n        search_filters: Dict[str, Union[str, int, float]], optional\n            search filter criteria as key-value pairs, where *key* is a keyword\n            or a tag of the attribute and *value* is the expected value that\n            should match\n\n        Returns\n        -------\n        List[Dict[str, dict]]\n            instance representations\n            (see `Instance Result Attributes <http://dicom.nema.org/medical/dicom/current/output/chtml/part18/sect_6.7.html#table_6.7.1-2b>`_)\n\n        Note\n        ----\n        The server may only return a subset of search results. In this case,\n        a warning will notify the client that there are remaining results.\n        Remaining results can be requested via repeated calls using the\n        `offset` parameter.\n\n        \'\'\' # noqa\n        if study_instance_uid is not None:\n            self._assert_uid_format(study_instance_uid)\n        url = self._get_instances_url(\n            \'qido\', study_instance_uid, series_instance_uid\n        )\n        params = self._parse_qido_query_parameters(\n            fuzzymatching, limit, offset, fields, search_filters\n        )\n        return self._http_get_application_json(url, params)\n\n    def retrieve_instance(\n            self,\n            study_instance_uid: str,\n            series_instance_uid: str,\n            sop_instance_uid: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None\n        ) -> pydicom.dataset.Dataset:\n        \'\'\'Retrieves an individual DICOM instance.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n        series_instance_uid: str\n            unique series identifier\n        sop_instance_uid: str\n            unique instance identifier\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media types and optionally the UIDs of the\n            corresponding transfer syntaxes\n\n        Returns\n        -------\n        pydicom.dataset.Dataset\n            data set\n\n        \'\'\'\n\n        if study_instance_uid is None:\n            raise ValueError(\n                \'Study Instance UID is required for retrieval of instance.\'\n            )\n        self._assert_uid_format(study_instance_uid)\n        if series_instance_uid is None:\n            raise ValueError(\n                \'Series Instance UID is required for retrieval of instance.\'\n            )\n        self._assert_uid_format(series_instance_uid)\n        if sop_instance_uid is None:\n            raise ValueError(\n                \'SOP Instance UID is required for retrieval of instance.\'\n            )\n        self._assert_uid_format(sop_instance_uid)\n        url = self._get_instances_url(\n            \'wado\', study_instance_uid, series_instance_uid, sop_instance_uid\n        )\n        if media_types is None:\n            return self._http_get_multipart_application_dicom(url)[0]\n        common_media_type = self._get_common_media_type(media_types)\n        if common_media_type == \'application/dicom\':\n            return self._http_get_multipart_application_dicom(\n                url, media_types\n            )[0]\n        elif common_media_type == \'application/octet-stream\':\n            return self._http_get_multipart_application_octet_stream(\n                url, media_types\n            )[0]\n        elif common_media_type.startswith(\'image\'):\n            frames = self._http_get_multipart_image(\n                url, media_types\n            )\n            if len(frames) > 1:\n                return frames\n            else:\n                return frames[0]\n        elif common_media_type.startswith(\'video\'):\n            frames = self._http_get_multipart_video(\n                url, media_types\n            )\n            if len(frames) > 1:\n                return frames\n            else:\n                return frames[0]\n        else:\n            raise ValueError(\n                \'Media type ""{}"" is not supported for retrieval \'\n                \'of instance.\'.format(common_media_type)\n            )\n\n    def store_instances(\n            self,\n            datasets: Sequence[pydicom.dataset.Dataset],\n            study_instance_uid: Optional[str] = None\n        ) -> Dict[str, dict]:\n        \'\'\'Stores DICOM instances.\n\n        Parameters\n        ----------\n        datasets: Sequence[pydicom.dataset.Dataset]\n            instances that should be stored\n        study_instance_uid: str, optional\n            unique study identifier\n\n        Returns\n        -------\n        pydicom.dataset.Dataset\n            information about status of stored instances\n\n        \'\'\'\n        url = self._get_studies_url(\'stow\', study_instance_uid)\n        encoded_datasets = list()\n        for ds in datasets:\n            with BytesIO() as b:\n                pydicom.dcmwrite(b, ds)\n                encoded_ds = b.getvalue()\n            encoded_datasets.append(encoded_ds)\n        return self._http_post_multipart_application_dicom(\n            url,\n            encoded_datasets\n        )\n\n    def delete_instance(\n        self,\n        study_instance_uid: str,\n        series_instance_uid: str,\n        sop_instance_uid: str\n    ) -> None:\n        \'\'\'Deletes specified instance.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n        series_instance_uid: str\n            unique series identifier\n        sop_instance_uid: str\n            unique instance identifier\n\n        Returns\n        -------\n        requests.models.Response\n            HTTP response object returned.\n\n        Note\n        ----\n        The Delete Instance resource is not part of the DICOM standard\n        and may not be supported by all origin servers.\n\n        WARNING\n        -------\n        This method performs a DELETE and should be used with caution.\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n              \'Study Instance UID is required for deletion of an instance.\'\n            )\n        if series_instance_uid is None:\n            raise ValueError(\n                \'Series Instance UID is required for deletion of an instance.\'\n            )\n        if sop_instance_uid is None:\n            raise ValueError(\n                \'SOP Instance UID is required for deletion of an instance.\'\n            )\n        url = self._get_instances_url(\'delete\', study_instance_uid,\n                                      series_instance_uid, sop_instance_uid)\n        return self._http_delete(url)\n\n    def retrieve_instance_metadata(\n            self,\n            study_instance_uid: str,\n            series_instance_uid: str,\n            sop_instance_uid: str\n        ) -> Dict[str, dict]:\n        \'\'\'Retrieves metadata of an individual DICOM instance.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n        series_instance_uid: str\n            unique series identifier\n        sop_instance_uid: str\n            unique instance identifier\n\n        Returns\n        -------\n        Dict[str, dict]\n            metadata in DICOM JSON format\n\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n                \'Study Instance UID is required for retrieval of \'\n                \'instance metadata.\'\n            )\n        if series_instance_uid is None:\n            raise ValueError(\n                \'Series Instance UID is required for retrieval of \'\n                \'instance metadata.\'\n            )\n        if sop_instance_uid is None:\n            raise ValueError(\n                \'SOP Instance UID is required for retrieval of \'\n                \'instance metadata.\'\n            )\n        url = self._get_instances_url(\n            \'wado\', study_instance_uid, series_instance_uid, sop_instance_uid\n        )\n        url += \'/metadata\'\n        return self._http_get_application_json(url)[0]\n\n    def retrieve_instance_rendered(\n            self,\n            study_instance_uid: str,\n            series_instance_uid: str,\n            sop_instance_uid: str,\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n            params: Optional[Dict[str, Any]] = None\n        ) -> bytes:\n        \'\'\'Retrieves an individual, server-side rendered DICOM instance.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n        series_instance_uid: str\n            unique series identifier\n        sop_instance_uid: str\n            unique instance identifier\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media types (choices: ``""image/jpeg""``, ``""image/jp2""``,\n            ``""image/gif""``, ``""image/png""``, ``""video/gif""``, ``""video/mp4""``,\n            ``""video/h265""``, ``""text/html""``, ``""text/plain""``,\n            ``""text/xml""``, ``""text/rtf""``, ``""application/pdf""``)\n        params: Dict[str], optional\n            additional parameters relevant for given `media_type`,\n            e.g., ``{""quality"": 95}`` for ``""image/jpeg""``\n\n        Returns\n        -------\n        bytes\n            rendered instance\n\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n                \'Study Instance UID is required for retrieval of \'\n                \'rendered instance.\'\n            )\n        if series_instance_uid is None:\n            raise ValueError(\n                \'Series Instance UID is required for retrieval of \'\n                \'rendered instance.\'\n            )\n        if sop_instance_uid is None:\n            raise ValueError(\n                \'SOP Instance UID is required for retrieval of \'\n                \'rendered instance.\'\n            )\n        url = self._get_instances_url(\n            \'wado\', study_instance_uid, series_instance_uid, sop_instance_uid\n        )\n        url += \'/rendered\'\n        if media_types is None:\n            response = self._http_get(url, params)\n            return response.content\n        common_media_type = self._get_common_media_type(media_types)\n        if common_media_type.startswith(\'image\'):\n            return self._http_get_image(url, media_types, params)\n        elif common_media_type.startswith(\'video\'):\n            return self._http_get_video(url, media_types, params)\n        elif common_media_type.startswith(\'text\'):\n            return self._http_get_text(url, media_types, params)\n        elif common_media_type == \'application/pdf\':\n            return self._http_get_application_pdf(url, params)\n        else:\n            raise ValueError(\n                \'Media type ""{}"" is not supported for \'\n                \'retrieval of rendered instance.\'.format(common_media_type)\n            )\n\n    def retrieve_instance_frames(\n            self,\n            study_instance_uid: str,\n            series_instance_uid: str,\n            sop_instance_uid: str,\n            frame_numbers: Sequence[int],\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None\n        ) -> List[bytes]:\n        \'\'\'Retrieves one or more frames of an individual DICOM instance.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n        series_instance_uid: str\n            unique series identifier\n        sop_instance_uid: str\n            unique instance identifier\n        frame_numbers: Sequence[int]\n            one-based positional indices of the frames within the instance\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media types and optionally the UIDs of the\n            corresponding transfer syntaxes\n\n        Returns\n        -------\n        List[bytes]\n            pixel data for each frame\n\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n                \'Study Instance UID is required for retrieval of frames.\'\n            )\n        if series_instance_uid is None:\n            raise ValueError(\n                \'Series Instance UID is required for retrieval of frames.\'\n            )\n        if sop_instance_uid is None:\n            raise ValueError(\n                \'SOP Instance UID is required for retrieval of frames.\'\n            )\n        url = self._get_instances_url(\n            \'wado\', study_instance_uid, series_instance_uid, sop_instance_uid\n        )\n        frame_list = \',\'.join([str(n) for n in frame_numbers])\n        url += \'/frames/{frame_list}\'.format(frame_list=frame_list)\n        if media_types is None:\n            return self._http_get_multipart_application_octet_stream(url)\n        common_media_type = self._get_common_media_type(media_types)\n        if common_media_type == \'application/octet-stream\':\n            return self._http_get_multipart_application_octet_stream(\n                url, media_types\n            )\n        elif common_media_type.startswith(\'image\'):\n            return self._http_get_multipart_image(url, media_types)\n        elif common_media_type.startswith(\'video\'):\n            return self._http_get_multipart_video(url, media_types)\n        else:\n            raise ValueError(\n                \'Media type ""{}"" is not supported for \'\n                \'retrieval of frames.\'.format(common_media_type)\n            )\n\n    def retrieve_instance_frames_rendered(\n            self,\n            study_instance_uid: str,\n            series_instance_uid: str,\n            sop_instance_uid: str,\n            frame_numbers: Sequence[int],\n            media_types: Optional[Tuple[Union[str, Tuple[str, str]]]] = None,\n            params: Optional[Dict[str, Any]] = None\n        ) -> bytes:\n        \'\'\'Retrieves one or more server-side rendered frames of an\n        individual DICOM instance.\n\n        Parameters\n        ----------\n        study_instance_uid: str\n            unique study identifier\n        series_instance_uid: str\n            unique series identifier\n        sop_instance_uid: str\n            unique instance identifier\n        frame_numbers: Sequence[int]\n            one-based positional index of the frame within the instance\n        media_types: Tuple[Union[str, Tuple[str, str]]], optional\n            acceptable media type (choices: ``""image/jpeg""``, ``""image/jp2""``,\n            ``""image/gif""``, ``""image/png""``)\n        params: Dict[str], optional\n            additional parameters relevant for given `media_type`,\n            e.g., ``{""quality"": 95}`` for ``""image/jpeg""`` media type\n\n        Returns\n        -------\n        bytes\n            rendered frames\n\n        Note\n        ----\n        Not all media types are compatible with all SOP classes.\n\n        \'\'\'\n        if study_instance_uid is None:\n            raise ValueError(\n                \'Study Instance UID is required for retrieval of \'\n                \'rendered frame.\'\n            )\n        if series_instance_uid is None:\n            raise ValueError(\n                \'Series Instance UID is required for retrieval of \'\n                \'rendered frame.\'\n            )\n        if sop_instance_uid is None:\n            raise ValueError(\n                \'SOP Instance UID is required for retrieval of rendered frame.\'\n            )\n        url = self._get_instances_url(\n            \'wado\', study_instance_uid, series_instance_uid, sop_instance_uid\n        )\n        url += \'/frames/{frame_numbers}/rendered\'.format(\n            frame_numbers=\',\'.join([str(n) for n in frame_numbers])\n        )\n        if media_types is None:\n            # Try and hope for the best...\n            response = self._http_get(url, params)\n            return response.content\n        common_media_type = self._get_common_media_type(media_types)\n        if common_media_type.startswith(\'image\'):\n            return self._http_get_image(url, media_types, params)\n        elif common_media_type.startswith(\'video\'):\n            return self._http_get_video(url, media_types, params)\n        else:\n            raise ValueError(\n                \'Media type ""{}"" is not supported for \'\n                \'retrieval of rendered frame.\'.format(common_media_type)\n            )\n\n    @staticmethod\n    def lookup_keyword(\n            tag: Union[str, int, Tuple[str, str], pydicom.tag.Tag]\n        ) -> str:\n        \'\'\'Looks up the keyword of a DICOM attribute.\n\n        Parameters\n        ----------\n        tag: Union[str, int, Tuple[str, str], pydicom.tag.Tag]\n            attribute tag (e.g. ``""00080018""``)\n\n        Returns\n        -------\n        str\n            attribute keyword (e.g. ``""SOPInstanceUID""``)\n\n        \'\'\'\n        return pydicom.datadict.keyword_for_tag(tag)\n\n    @staticmethod\n    def lookup_tag(keyword: str) -> str:\n        \'\'\'Looks up the tag of a DICOM attribute.\n\n        Parameters\n        ----------\n        keyword: str\n            attribute keyword (e.g. ``""SOPInstanceUID""``)\n\n        Returns\n        -------\n        str\n            attribute tag as HEX string (e.g. ``""00080018""``)\n\n        \'\'\'\n        tag = pydicom.datadict.tag_for_keyword(keyword)\n        tag = pydicom.tag.Tag(tag)\n        return \'{0:04x}{1:04x}\'.format(tag.group, tag.element).upper()\n'"
src/dicomweb_client/cli.py,0,"b'\'\'\'Command Line Interface (CLI)\'\'\'\nimport os\nimport sys\nimport json\nimport logging\nimport argparse\nimport tempfile\nimport traceback\nimport getpass\nfrom io import BytesIO\n\nimport pydicom\n\nfrom dicomweb_client.api import DICOMwebClient, load_json_dataset\nfrom dicomweb_client.log import configure_logging\nfrom dicomweb_client.session_utils import (\n    create_session,\n    create_session_from_user_pass,\n    add_certs_to_session,\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef _get_parser():\n    \'\'\'Builds the object for parsing command line arguments.\n\n    Returns\n    -------\n    argparse.ArgumentParser\n\n    \'\'\'\n    parser = argparse.ArgumentParser(\n        description=\'Client for DICOMweb RESTful services.\',\n        prog=\'dicomweb_client\'\n    )\n    parser.add_argument(\n        \'-v\', \'--verbosity\', dest=\'logging_verbosity\', default=0,\n        action=\'count\',\n        help=(\n            \'logging verbosity that maps to a logging level \'\n            \'(default: error, -v: warning, -vv: info, -vvv: debug, \'\n            \'-vvvv: debug + traceback); \'\n            \'all log messages are written to standard error\'\n        )\n    )\n    parser.add_argument(\n        \'-u\', \'--user\', dest=\'username\', metavar=\'NAME\',\n        help=\'username for authentication with the DICOMweb service\'\n    )\n    parser.add_argument(\n        \'-p\', \'--password\', dest=\'password\', metavar=\'PASSWORD\',\n        help=\'password for authentication with the DICOMweb service\'\n    )\n    parser.add_argument(\n        \'--ca\', dest=\'ca_bundle\', metavar=\'CERT-FILE\',\n        help=\'path to a CA bundle file\'\n    )\n    parser.add_argument(\n        \'--cert\', dest=\'cert\', metavar=\'CERT-FILE\',\n        help=\'path to a client certificate file in PEM format\'\n    )\n    parser.add_argument(\n        \'--bearer-token\', dest=\'bearer_token\', metavar=\'TOKEN\',\n        help=\'bearer token for authentication with the DICOMweb service\'\n    )\n    parser.add_argument(\n        \'--url\', dest=\'url\', metavar=\'URL\',\n        help=\'uniform resource locator of the DICOMweb service\'\n    )\n    parser.add_argument(\n        \'--chunk-size\', dest=\'chunk_size\', type=int, metavar=\'NUM\',\n        help=\'maximum size of a network transfer chunk in bytes\'\n    )\n\n    abstract_optional_study_parser = argparse.ArgumentParser(add_help=False)\n    abstract_optional_study_parser.add_argument(\n        \'--study\', metavar=\'UID\', dest=\'study_instance_uid\',\n        help=\'unique study identifer (StudyInstanceUID)\'\n    )\n\n    abstract_required_study_parser = argparse.ArgumentParser(add_help=False)\n    abstract_required_study_parser.add_argument(\n        \'--study\', metavar=\'UID\', dest=\'study_instance_uid\', required=True,\n        help=\'unique study identifier (StudyInstanceUID)\'\n    )\n\n    abstract_optional_series_parser = argparse.ArgumentParser(add_help=False)\n    abstract_optional_series_parser.add_argument(\n        \'--series\', metavar=\'UID\', dest=\'series_instance_uid\',\n        help=\'unique series identifier (SeriesInstanceUID)\'\n    )\n\n    abstract_required_series_parser = argparse.ArgumentParser(add_help=False)\n    abstract_required_series_parser.add_argument(\n        \'--series\', metavar=\'UID\', dest=\'series_instance_uid\', required=True,\n        help=\'unique series identifier (SeriesInstanceUID)\'\n    )\n\n    abstract_optional_instance_parser = argparse.ArgumentParser(add_help=False)\n    abstract_optional_instance_parser.add_argument(\n        \'--instance\', metavar=\'UID\', dest=\'sop_instance_uid\',\n        help=\'unique instance identifier (SOPInstanceUID)\'\n    )\n\n    abstract_required_instance_parser = argparse.ArgumentParser(add_help=False)\n    abstract_required_instance_parser.add_argument(\n        \'--instance\', metavar=\'UID\', dest=\'sop_instance_uid\', required=True,\n        help=\'unique instance identifier (SOPInstanceUID)\'\n    )\n\n    abstract_search_parser = argparse.ArgumentParser(add_help=False)\n    abstract_search_parser.add_argument(\n        \'--filter\', metavar=\'KEY=VALUE\', dest=\'search_filters\',\n        action=\'append\', default=[],\n        help=\'query filter criterion\'\n    )\n    abstract_search_parser.add_argument(\n        \'--field\', metavar=\'NAME\', dest=\'search_fields\', action=\'append\',\n        help=\'field that should be included in response\'\n    )\n    abstract_search_parser.add_argument(\n        \'--limit\', metavar=\'NUM\', type=int, dest=\'search_limit\',\n        help=\'number of items that should be maximally retrieved\'\n    )\n    abstract_search_parser.add_argument(\n        \'--offset\', metavar=\'NUM\', type=int, dest=\'search_offset\',\n        help=\'number of items that should be skipped\'\n    )\n    abstract_search_parser.add_argument(\n        \'--fuzzy\', dest=\'search_fuzzymatching\', action=\'store_true\',\n        help=\'perform fuzzy matching\'\n    )\n\n    abstract_retrieve_parser = argparse.ArgumentParser(add_help=False)\n    abstract_retrieve_parser.add_argument(\n        \'--media-type\', metavar=\'MEDIATYPE\', action=\'append\', default=None,\n        nargs=\'+\', dest=\'media_types\',\n        help=(\n            \'acceptable media type and the optionally the UID of a \'\n            \'corresponding tranfer syntax separted by a whitespace\'\n            \'(e.g., ""image/jpeg"" or ""image/jpeg 1.2.840.10008.1.2.4.50"")\'\n        )\n    )\n\n    abstract_fmt_parser = argparse.ArgumentParser(add_help=False)\n    abstract_fmt_group = abstract_fmt_parser.add_mutually_exclusive_group()\n    abstract_fmt_group.add_argument(\n        \'--prettify\', action=\'store_true\',\n        help=\'pretty print JSON response message\'\n    )\n    abstract_fmt_group.add_argument(\n        \'--dicomize\', action=\'store_true\',\n        help=\'convert JSON response message to DICOM data set\'\n    )\n\n    abstract_save_parser = argparse.ArgumentParser(add_help=False)\n    abstract_save_parser.add_argument(\n        \'--save\', action=\'store_true\',\n        help=\'whether downloaded data should be saved\'\n    )\n    abstract_save_parser.add_argument(\n        \'--output-dir\', metavar=\'PATH\', dest=\'output_dir\',\n        default=tempfile.gettempdir(),\n        help=\'path to directory where downloaded data should be saved\'\n    )\n\n    abstract_load_parser = argparse.ArgumentParser(add_help=False)\n    abstract_load_parser.add_argument(\n        metavar=\'PATH\', dest=\'files\', nargs=\'+\',\n        help=\'paths to DICOM files that should be loaded\'\n    )\n\n    subparsers = parser.add_subparsers(dest=\'method\', help=\'services\')\n    subparsers.required = True\n\n    # QIDO\n    search_parser = subparsers.add_parser(\n        \'search\',\n        description=(\n            \'QIDO-RS: Query based on ID for DICOM Objects by RESTful Serices.\'\n        )\n    )\n    search_subparsers = search_parser.add_subparsers(\n        dest=\'qido_ie\', metavar=\'INFORMATION ENTITIES\', description=\'\', help=\'\'\n    )\n    search_subparsers.required = True\n\n    # QIDO - Studies\n    search_for_studies_parser = search_subparsers.add_parser(\n        \'studies\',\n        description=\'Search for DICOM studies.\',\n        parents=[abstract_search_parser, abstract_fmt_parser]\n    )\n    search_for_studies_parser.set_defaults(func=_search_for_studies)\n\n    # QUIDO - Series\n    search_for_series_parser = search_subparsers.add_parser(\n        \'series\',\n        description=\'Search for DICOM series.\',\n        parents=[\n            abstract_search_parser, abstract_fmt_parser,\n            abstract_optional_study_parser\n        ]\n    )\n    search_for_series_parser.set_defaults(func=_search_for_series)\n\n    # QIDO - Instances\n    search_for_instances_parser = search_subparsers.add_parser(\n        \'instances\', description=\'Search for DICOM instances.\',\n        parents=[\n            abstract_fmt_parser, abstract_search_parser,\n            abstract_optional_study_parser, abstract_optional_series_parser\n        ]\n    )\n    search_for_instances_parser.set_defaults(func=_search_for_instances)\n\n    # WADO\n    retrieve_parser = subparsers.add_parser(\n        \'retrieve\',\n        description=\'WADO-RS: Web Access to DICOM Objects by RESTful Services.\',\n    )\n    retrieve_subparsers = retrieve_parser.add_subparsers(\n        dest=\'wado_ie\', metavar=\'INFORMATION ENTITIES\', help=\'\', description=\'\'\n    )\n    retrieve_subparsers.required = True\n\n    # WADO - studies\n    retrieve_studies_parser = retrieve_subparsers.add_parser(\n        \'studies\', help=\'retrieve data for instances of a given study\',\n        description=(\n            \'Retrieve data for all DICOM instances of a given DICOM study.\'\n        ),\n        parents=[abstract_required_study_parser]\n    )\n    retrieve_studies_subparsers = retrieve_studies_parser.add_subparsers(\n        dest=\'studies_resource\'\n    )\n    retrieve_studies_subparsers.required = True\n\n    retrieve_studies_metadata_parser = retrieve_studies_subparsers.add_parser(\n        \'metadata\', description=(\n            \'Retrieve metadata of DICOM instances of a given DICOM study.\'\n        ),\n        parents=[abstract_fmt_parser, abstract_save_parser]\n    )\n    retrieve_studies_metadata_parser.set_defaults(\n        func=_retrieve_study_metadata\n    )\n\n    retrieve_studies_full_parser = retrieve_studies_subparsers.add_parser(\n        \'full\', description=(\n            \'Retrieve DICOM instances of a given DICOM study.\'\n        ),\n        parents=[abstract_save_parser, abstract_retrieve_parser]\n    )\n    retrieve_studies_full_parser.set_defaults(func=_retrieve_study)\n\n    # WADO - series\n    retrieve_series_parser = retrieve_subparsers.add_parser(\n        \'series\', help=\'retrieve data for instances of a given series\',\n        description=(\n            \'Retrieve data for all DICOM instances of a given DICOM series.\'\n        ),\n        parents=[\n            abstract_required_study_parser, abstract_required_series_parser,\n        ]\n    )\n    retrieve_series_subparsers = retrieve_series_parser.add_subparsers(\n        dest=\'series_resource\'\n    )\n    retrieve_series_subparsers.required = True\n\n    retrieve_series_metadata_parser = retrieve_series_subparsers.add_parser(\n        \'metadata\', description=(\n            \'Retrieve metadata of DICOM instances of a given DICOM series.\'\n        ),\n        parents=[abstract_fmt_parser, abstract_save_parser]\n    )\n    retrieve_series_metadata_parser.set_defaults(\n        func=_retrieve_series_metadata\n    )\n\n    retrieve_series_full_parser = retrieve_series_subparsers.add_parser(\n        \'full\', description=(\n            \'Retrieve DICOM instances of a given DICOM series.\'\n        ),\n        parents=[abstract_save_parser, abstract_retrieve_parser]\n    )\n    retrieve_series_full_parser.set_defaults(func=_retrieve_series)\n\n    # WADO - instance\n    retrieve_instance_parser = retrieve_subparsers.add_parser(\n        \'instances\', help=\'retrieve data of a given instance\',\n        description=(\n            \'Retrieve data for an individual DICOM instance.\'\n        ),\n        parents=[\n            abstract_required_study_parser, abstract_required_series_parser,\n            abstract_required_instance_parser\n        ]\n    )\n    retrieve_instance_subparsers = retrieve_instance_parser.add_subparsers(\n        dest=\'instances_resource\'\n    )\n    retrieve_instance_subparsers.required = True\n\n    retrieve_instance_metadata_parser = retrieve_instance_subparsers.add_parser(\n        \'metadata\', description=(\n            \'Retrieve metadata of an invidividual DICOM instance.\'\n        ),\n        parents=[abstract_fmt_parser, abstract_save_parser]\n    )\n    retrieve_instance_metadata_parser.set_defaults(\n        func=_retrieve_instance_metadata\n    )\n\n    retrieve_instance_full_parser = retrieve_instance_subparsers.add_parser(\n        \'full\', description=(\'Retrieve a DICOM instance.\'),\n        parents=[abstract_save_parser, abstract_retrieve_parser]\n    )\n    retrieve_instance_full_parser.set_defaults(func=_retrieve_instance)\n\n    retrieve_instance_frames_parser = retrieve_instance_subparsers.add_parser(\n        \'frames\', description=(\n            \'Retrieve one or more frames of the pixel data element of an \'\n            \'invidividual DICOM instance.\'\n        ),\n        parents=[abstract_save_parser, abstract_retrieve_parser]\n    )\n    retrieve_instance_frames_parser.add_argument(\n        \'--numbers\', metavar=\'NUM\', type=int, nargs=\'+\', dest=\'frame_numbers\',\n        help=\'frame numbers\'\n    )\n    retrieve_instance_frames_parser.add_argument(\n        \'--show\', action=\'store_true\',\n        help=\'display retrieved images\'\n    )\n    retrieve_instance_frames_parser.set_defaults(func=_retrieve_instance_frames)\n\n    # WADO - bulkdata\n    retrieve_bulkdata_parser = retrieve_subparsers.add_parser(\n        \'bulkdata\', help=\'retrieve bulk data from a known location\',\n        description=(\n            \'Retrieve bulk data of a DICOM object from a known location.\'\n        ),\n        parents=[abstract_retrieve_parser]\n    )\n    retrieve_bulkdata_parser.add_argument(\n        \'--uri\', metavar=\'URI\', dest=\'bulkdata_uri\', required=True,\n        help=\'unique resource identifier of bulk data element\'\n    )\n    retrieve_bulkdata_parser.set_defaults(func=_retrieve_bulkdata)\n\n    # STOW\n    store_parser = subparsers.add_parser(\n        \'store\',\n        description=\'STOW-RS: Store Over the Web by RESTful Services.\',\n    )\n    store_subparsers = store_parser.add_subparsers(\n        dest=\'stow_ie\', metavar=\'INFORMATION ENTITIES\', help=\'\', description=\'\'\n    )\n    store_subparsers.required = True\n\n    # STOW - instances\n    store_studies_parser = store_subparsers.add_parser(\n        \'instances\', help=\'store one or more DICOM instances\',\n        description=\'Store DICOM instances.\',\n        parents=[abstract_optional_study_parser, abstract_load_parser]\n    )\n    store_studies_parser.set_defaults(func=_store_instances)\n\n    return parser\n\n\ndef _parse_search_parameters(args):\n    params = dict()\n    if args.search_fuzzymatching:\n        params[\'fuzzymatching\'] = args.search_fuzzymatching\n    params[\'offset\'] = args.search_offset\n    params[\'limit\'] = args.search_limit\n    params[\'fields\'] = args.search_fields\n    params[\'search_filters\'] = {}\n    for f in args.search_filters:\n        k, v = f.split(\'=\')\n        params[\'search_filters\'][k] = v\n    return params\n\n\ndef _print_instance(data):\n    logger.info(\'print instance\')\n    with BytesIO() as fp:\n        pydicom.dcmwrite(fp, data)\n        output = fp.getvalue()\n    print(output)\n\n\ndef _print_metadata(data, prettify=False, dicomize=False):\n    logger.info(\'print metadata\')\n    if dicomize:\n        if isinstance(data, list):\n            for ds in data:\n                dcm_ds = load_json_dataset(ds)\n                print(dcm_ds)\n                print(\'\\n\')\n        else:\n            dcm_ds = load_json_dataset(data)\n            print(dcm_ds)\n    elif prettify:\n        print(json.dumps(data, indent=4, sort_keys=True))\n    else:\n        print(json.dumps(data, sort_keys=True))\n\n\ndef _save_instance(data, directory, sop_instance_uid):\n    filename = \'{}.dcm\'.format(sop_instance_uid)\n    filepath = os.path.join(directory, filename)\n    logger.info(\'save instance to file: {}\'.format(filepath))\n    pydicom.dcmwrite(filepath, data)\n\n\ndef _save_metadata(data, directory, sop_instance_uid, prettify=False,\n                   dicomize=False):\n    if dicomize:\n        filename = \'{}.dcm\'.format(sop_instance_uid)\n    else:\n        filename = \'{}.json\'.format(sop_instance_uid)\n    filepath = os.path.join(directory, filename)\n    logger.info(\'save metadata to file: {}\'.format(filepath))\n    if dicomize:\n        dataset = load_json_dataset(data)\n        dataset.save_as(filepath)\n    else:\n        with open(filepath, \'w\') as f:\n            if prettify:\n                json.dump(data, f, indent=4, sort_keys=True)\n            else:\n                json.dump(data, f, sort_keys=True)\n\n\ndef _print_pixel_data(pixels):\n    logger.info(\'print pixel data\')\n    print(pixels)\n    print(\'\\n\')\n\n\ndef _create_headers(args):\n    headers = {}\n    if hasattr(args, ""bearer_token""):\n        headers = {\n            ""Authorization"": ""Bearer {}"".format(args.bearer_token)\n        }\n    return headers\n\n\ndef _search_for_studies(client, args):\n    \'\'\'Searches for *Studies* and writes metadata to standard output.\'\'\'\n    params = _parse_search_parameters(args)\n    studies = client.search_for_studies(**params)\n    _print_metadata(studies, args.prettify, args.dicomize)\n\n\ndef _search_for_series(client, args):\n    \'\'\'Searches for Series and writes metadata to standard output.\'\'\'\n    params = _parse_search_parameters(args)\n    series = client.search_for_series(args.study_instance_uid, **params)\n    _print_metadata(series, args.prettify, args.dicomize)\n\n\ndef _search_for_instances(client, args):\n    \'\'\'Searches for Instances and writes metadata to standard output.\'\'\'\n    params = _parse_search_parameters(args)\n    instances = client.search_for_instances(\n        args.study_instance_uid, args.series_instance_uid, **params\n    )\n    _print_metadata(instances, args.prettify, args.dicomize)\n\n\ndef _retrieve_study(client, args):\n    \'\'\'Retrieves all Instances of a given Study and either writes them to\n    standard output or to files on disk.\n    \'\'\'\n    instances = client.retrieve_study(\n        args.study_instance_uid,\n        media_types=args.media_types,\n    )\n    for inst in instances:\n        sop_instance_uid = inst.SOPInstanceUID\n        if args.save:\n            _save_instance(inst, args.output_dir, sop_instance_uid)\n        else:\n            _print_instance(inst)\n\n\ndef _retrieve_series(client, args):\n    \'\'\'Retrieves all Instances of a given Series and either writes them to\n    standard output or to files on disk.\n    \'\'\'\n    instances = client.retrieve_series(\n        args.study_instance_uid, args.series_instance_uid,\n        media_types=args.media_types,\n    )\n    for inst in instances:\n        sop_instance_uid = inst.SOPInstanceUID\n        if args.save:\n            _save_instance(inst, args.output_dir, sop_instance_uid)\n        else:\n            _print_instance(inst)\n\n\ndef _retrieve_instance(client, args):\n    \'\'\'Retrieves an Instances and either writes it to standard output or to a\n    file on disk.\n    \'\'\'\n    instance = client.retrieve_instance(\n        args.study_instance_uid, args.series_instance_uid,\n        args.sop_instance_uid,\n        media_types=args.media_types,\n    )\n    if args.save:\n        _save_instance(instance, args.output_dir, args.sop_instance_uid)\n    else:\n        _print_instance(instance)\n\n\ndef _retrieve_study_metadata(client, args):\n    \'\'\'Retrieves metadata for all Instances of a given Study and either\n    writes it to standard output or to files on disk.\n    \'\'\'\n    metadata = client.retrieve_study_metadata(args.study_instance_uid)\n    if args.save:\n        for md in metadata:\n            tag = client.lookup_tag(\'SOPInstanceUID\')\n            sop_instance_uid = md[tag][\'Value\'][0]\n            _save_metadata(\n                md, args.output_dir, sop_instance_uid, args.prettify,\n                args.dicomize\n            )\n    else:\n        _print_metadata(metadata, args.prettify, args.dicomize)\n\n\ndef _retrieve_series_metadata(client, args):\n    \'\'\'Retrieves metadata for all Instances of a given Series and either\n    writes it to standard output or to files on disk.\n    \'\'\'\n    metadata = client.retrieve_series_metadata(\n        args.study_instance_uid, args.series_instance_uid\n    )\n    if args.save:\n        for md in metadata:\n            tag = client.lookup_tag(\'SOPInstanceUID\')\n            sop_instance_uid = md[tag][\'Value\'][0]\n            _save_metadata(\n                md, args.output_dir, sop_instance_uid, args.prettify,\n                args.dicomize\n            )\n    else:\n        _print_metadata(metadata, args.prettify, args.dicomize)\n\n\ndef _retrieve_instance_metadata(client, args):\n    \'\'\'Retrieves metadata for an individual Instances and either\n    writes it to standard output or to a file on disk.\n    \'\'\'\n    metadata = client.retrieve_instance_metadata(\n        args.study_instance_uid, args.series_instance_uid,\n        args.sop_instance_uid\n    )\n    if args.save:\n        _save_metadata(\n            metadata, args.output_dir, args.sop_instance_uid, args.prettify,\n            args.dicomize\n        )\n    else:\n        _print_metadata(metadata, args.prettify, args.dicomize)\n\n\ndef _retrieve_instance_frames(client, args):\n    \'\'\'Retrieves frames for an individual instances and either\n    writes them to standard output or files on disk or displays them in a GUI\n    (depending on the requested content type).\n    Frames can only be saved and shown if they are retrieved using\n    image media types.\n    \'\'\'\n    pixel_data = client.retrieve_instance_frames(\n        args.study_instance_uid,\n        args.series_instance_uid,\n        args.sop_instance_uid,\n        args.frame_numbers,\n        media_types=args.media_types,\n    )\n\n    for i, data in enumerate(pixel_data):\n        if args.save:\n            if data[:2] == b\'\\xFF\\xD8\':       # SOI marker => JPEG\n                if data[2:4] == b\'\\xFF\\xF7\':  # SOF 55 marker => JPEG-LS\n                    extension = \'jls\'\n                else:\n                    extension = \'jpg\'\n            elif data[:2] == b\'\\xFF\\x4F\':     # SOC marker => JPEG 2000\n                extension = \'jp2\'\n            else:\n                extension = \'dat\'\n            filename = (\n                \'{sop_instance_uid}_{frame_number}.{extension}\'.format(\n                    sop_instance_uid=args.sop_instance_uid,\n                    frame_number=args.frame_numbers[i],\n                    extension=extension\n                )\n            )\n            filepath = os.path.join(args.output_dir, filename)\n            with open(filepath, \'bw\') as fp:\n                fp.write(data)\n        else:\n            _print_pixel_data(data)\n\n\ndef _retrieve_bulkdata(client, args):\n    \'\'\'Retrieves bulk data and either writes them to standard output or to a\n    file on disk.\n    \'\'\'\n    data = client.retrieve_bulkdata(args.bulkdata_uri, args.media_type)\n    print(data)\n    print(\'\\n\')\n\n\ndef _store_instances(client, args):\n    \'\'\'Loads Instances from files on disk and stores them.\'\'\'\n    datasets = [pydicom.dcmread(f) for f in args.files]\n    client.store_instances(datasets)\n\n\ndef _main():\n    parser = _get_parser()\n    args = parser.parse_args()\n    main(args)\n\n\ndef main(args):\n    \'\'\'Main entry point for the ``dicomweb_client`` command line program.\'\'\'\n\n    configure_logging(args.logging_verbosity)\n\n    if args.username:\n        if not args.password:\n            message = \'Enter password for user ""{0}"": \'.format(args.username)\n            args.password = getpass.getpass(message)\n        session = create_session_from_user_pass(args.username, args.password)\n    else:\n        session = create_session()\n\n    try:\n        session = add_certs_to_session(session, args.ca_bundle, args.cert)\n        session.headers.update(_create_headers(args))\n        client = DICOMwebClient(\n            args.url,\n            session=session,\n            chunk_size=args.chunk_size\n        )\n        args.func(client, args)\n        sys.exit(0)\n    except Exception as err:\n        logger.error(str(err))\n        if args.logging_verbosity > 3:\n            tb = traceback.format_exc()\n            logger.error(tb)\n        sys.exit(1)\n'"
src/dicomweb_client/error.py,0,"b""'''Custom error classes'''\nimport requests\n\n\nclass DICOMJSONError(ValueError):\n    '''Exception class for malformatted DICOM JSON.'''\n    pass\n"""
src/dicomweb_client/log.py,0,"b'\'\'\'Utility functions for logging configuration\'\'\'\nimport sys\nimport logging\n\n\ndef _map_logging_verbosity(verbosity: int) -> int:\n    \'\'\'Maps logging verbosity to logging level.\n\n    Parameters\n    ----------\n    verbosity: int\n        logging verbosity (e.g. ``2``)\n\n    Returns\n    -------\n    int\n        logging level (e.g. ``logging.INFO``)\n\n    \'\'\'\n    levels = (logging.ERROR, logging.WARN, logging.INFO, logging.DEBUG)\n    try:\n        return levels[verbosity]\n    except IndexError:\n        return levels[-1]\n\n\ndef configure_logging(verbosity: int) -> logging.Logger:\n    \'\'\'Configures the root logger with a ""stderr"" stream handler that directs\n    logging messages to standard error (to allow capturing program standard\n    output, e.g. in order to redirect it to a file).\n\n    Logging verbosity maps to levels as follows::\n\n            0 -> no messages\n            1 -> CRITICAL, ERROR & WARN/WARNING messages\n            2 -> CRITICAL, ERROR, WARN/WARNING, & INFO messages\n            3 -> CRITICAL, ERROR, WARN/WARNING, INFO & DEBUG messages\n            4 -> all messages\n\n    Parameters\n    ----------\n    verbosity: int\n        logging verbosity\n\n    Returns\n    -------\n    logging.Logger\n        package root logger\n\n    \'\'\'\n    if verbosity > 3:\n        fmt = (\n            \'%(asctime)s | %(levelname)-8s | %(name)-40s | \'\n            \'%(lineno)-4s | %(message)s\'\n        )\n    else:\n        fmt = \'%(asctime)s | %(levelname)-8s | %(name)-40s | %(message)s\'\n    datefmt = \'%Y-%m-%d %H:%M:%S\'\n    formatter = logging.Formatter(fmt=fmt, datefmt=datefmt)\n\n    stderr_handler = logging.StreamHandler(stream=sys.stderr)\n    stderr_handler.name = \'stderr\'\n    stderr_handler.setFormatter(formatter)\n\n    root_logger = logging.getLogger()\n    root_logger.addHandler(stderr_handler)\n    level = _map_logging_verbosity(verbosity)\n    root_logger.setLevel(logging.ERROR)\n\n    pkg_name = __name__.split(\'.\')[0]\n    pkg_logger = logging.getLogger(pkg_name)\n    pkg_logger.setLevel(level)\n\n    if verbosity > 4:\n        requests_logger = logging.getLogger(\'urllib3\')\n        requests_logger.setLevel(level)\n        requests_logger.propagate = True\n\n    return pkg_logger\n'"
src/dicomweb_client/session_utils.py,0,"b'import logging\nimport os\nfrom typing import Optional, Any\n\nimport requests\n\nlogger = logging.getLogger(__name__)\n\n\ndef create_session() -> requests.Session:\n    \'\'\'Creates an unauthorized session.\n\n    Returns\n    -------\n    requests.Session\n        unauthorized session\n\n    \'\'\'\n    logger.debug(\'initialize HTTP session\')\n    return requests.Session()\n\n\ndef create_session_from_auth(\n        auth: requests.auth.AuthBase\n    ) -> requests.Session:\n    \'\'\'Creates a session from a gicen AuthBase object.\n\n    Parameters\n    ----------\n    auth: requests.auth.AuthBase\n        an implementation of `requests.auth.AuthBase` to be used for\n        authentication with services\n\n    Returns\n    -------\n    requests.Session\n        authorized session\n\n    \'\'\'\n    logger.debug(\'initialize HTTP session\')\n    session = requests.Session()\n    logger.debug(\'authenticate HTTP session\')\n    session.auth = auth\n    return session\n\n\ndef create_session_from_user_pass(\n        username: str,\n        password: str\n    ) -> requests.Session:\n    \'\'\'Creates a session from a given username and password.\n\n    Parameters\n    ----------\n    username: str\n        username for authentication with services\n    password: str\n        password for authentication with services\n\n    Returns\n    -------\n    requests.Session\n        authorized session\n\n    \'\'\'\n    logger.debug(\'initialize HTTP session\')\n    session = requests.Session()\n    logger.debug(\'authenticate and authorize HTTP session\')\n    session.auth = (username, password)\n    return session\n\n\ndef add_certs_to_session(\n        session: requests.Session,\n        ca_bundle: Optional[str] = None,\n        cert: Optional[str] = None\n    ) -> requests.Session:\n    \'\'\'Adds CA bundle and certificate to an existing session.\n\n    Parameters\n    ----------\n    session: requests.Session\n        input session\n    ca_bundle: str, optional\n        path to CA bundle file\n    cert: str, optional\n        path to client certificate file in Privacy Enhanced Mail (PEM) format\n\n    Returns\n    -------\n    requests.Session\n        verified session\n\n    \'\'\'\n    if ca_bundle is not None:\n        ca_bundle = os.path.expanduser(os.path.expandvars(ca_bundle))\n        if not os.path.exists(ca_bundle):\n            raise OSError(\n                \'CA bundle file does not exist: {}\'.format(ca_bundle)\n            )\n        logger.debug(\'use CA bundle file: {}\'.format(ca_bundle))\n        session.verify = ca_bundle\n    if cert is not None:\n        cert = os.path.expanduser(os.path.expandvars(cert))\n        if not os.path.exists(cert):\n            raise OSError(\n                \'Certificate file does not exist: {}\'.format(cert)\n            )\n        logger.debug(\'use certificate file: {}\'.format(cert))\n        session.cert = cert\n    return session\n\n\ndef create_session_from_gcp_credentials(\n        google_credentials: Optional[Any] = None\n    ) -> requests.Session:\n    \'\'\'Creates an authorized session for Google Cloud Platform.\n\n    Parameters\n    ----------\n    google_credentials: Any\n        Google cloud credentials.\n        (see https://cloud.google.com/docs/authentication/production\n        for more information on Google cloud authentication).\n        If not set, will be initialized to ``google.auth.default()``\n\n    Returns\n    -------\n    requests.Session\n        Google cloud authorized session\n\n    \'\'\'\n    try:\n        from google.auth.transport import requests as google_requests\n        if google_credentials is None:\n            import google.auth\n            google_credentials, _ = google.auth.default(\n                scopes=[\'https://www.googleapis.com/auth/cloud-platform\']\n            )\n    except ImportError:\n        raise ImportError(\n            \'The dicomweb-client package needs to be installed with the \'\n            \'""gcp"" extra requirements to support interaction with the \'\n            \'Google Cloud Healthcare API: pip install dicomweb-client[gcp]\'\n        )\n    logger.debug(\'initialize, authenticate and authorize HTTP session\')\n    return google_requests.AuthorizedSession(google_credentials)\n'"
