file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n# pylint: disable=invalid-name\n""""""\nAudioTSM\n~~~~~~~~\n\nAudioTSM is a python library for real-time audio time-scale modification\nprocedures, i.e. algorithms that change the speed of an audio signal without\nchanging its pitch.\n\n:copyright: (c) 2017 by Muges.\n:license: MIT, see LICENSE for more details.\n""""""\n\nimport os\nimport re\nimport sys\nfrom setuptools import setup, find_packages\nfrom setuptools.command.test import test as TestCommand\n\n\ndef find_version():\n    """"""Read the package\'s version from __init__.py""""""\n    version_filename = os.path.abspath(""audiotsm/__init__.py"")\n    with open(version_filename) as fileobj:\n        version_content = fileobj.read()\n    version_match = re.search(r""^__version__ = [\'\\""]([^\'\\""]*)[\'\\""]"",\n                              version_content, re.M)\n    if version_match:\n        return version_match.group(1)\n    raise RuntimeError(""Unable to find version string."")\n\n\nclass PyTest(TestCommand):\n    def finalize_options(self):\n        TestCommand.finalize_options(self)\n        self.test_args = [\'--cov=audiotsm\', \'tests/unit\']\n        self.test_suite = True\n\n    def run_tests(self):\n        import pytest\n\n        errcode = pytest.main(self.test_args)\n        sys.exit(errcode)\n\n\n# \'setup.py publish\' shortcut.\nif sys.argv[-1] == \'publish\':\n    os.system(\'python setup.py sdist bdist_wheel\')\n    os.system(\'twine upload dist/*\')\n    sys.exit()\n\n\nwith open(\'README.rst\', \'r\') as f:\n    long_description = f.read()\n\n\nsetup(\n    name=""audiotsm"",\n    version=find_version(),\n    description=""A real-time audio time-scale modification library"",\n    long_description=long_description,\n    license=""MIT"",\n    url=""https://github.com/Muges/audiotsm"",\n    author=""Muges"",\n    author_email=""git@muges.fr"",\n\n    packages=find_packages(),\n\n    install_requires=[\n        ""numpy"",\n    ],\n    tests_require=[\n        ""pytest"",\n        ""pytest-coverage"",\n        ""sounddevice"",\n    ],\n    extras_require={\n        ""stream"": [""sounddevice""],\n        ""gstreamer"": [""gstbasetransform""]\n    },\n\n    cmdclass={\n        \'test\': PyTest,\n    },\n\n    classifiers=[\n        ""License :: OSI Approved :: MIT License"",\n        ""Programming Language :: Python"",\n        ""Programming Language :: Python :: 2"",\n        ""Programming Language :: Python :: 2.7"",\n        ""Programming Language :: Python :: 3"",\n        ""Programming Language :: Python :: 3.4"",\n        ""Programming Language :: Python :: 3.5"",\n        ""Programming Language :: Python :: 3.6"",\n        ""Topic :: Multimedia :: Sound/Audio""\n    ]\n)\n'"
audiotsm/__init__.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm` module provides several time-scale modification procedures:\n\n- :func:`~audiotsm.ola` (Overlap-Add);\n- :func:`~audiotsm.wsola` (Waveform Similarity-based Overlap-Add);\n- :func:`~audiotsm.phasevocoder` (Phase Vocoder).\n\nThe OLA procedure should only be used on percussive audio signals. The WSOLA\nand the Phase Vocoder procedures are improvements of the OLA procedure, and\nshould both give good results in most cases.\n\n.. note::\n\n    If you are unsure which procedure and parameters to choose, using\n    :func:`~audiotsm.phasevocoder` with the default parameters should give good\n    results in most cases. You can listen to the output of the different\n    procedures on various audio files and at various speeds on the `examples\n    page`_.\n\nEach of the function of this module returns a :class:`~audiotsm.base.tsm.TSM`\nobject which implements a time-scale modification procedure.\n\n.. autofunction:: audiotsm.ola\n.. autofunction:: audiotsm.wsola\n.. autofunction:: audiotsm.phasevocoder\n.. autoclass:: audiotsm.PhaseLocking\n    :members:\n\n.. _examples page: https://muges.github.io/audiotsm/\n""""""\n\n__version__ = ""0.1.2""\n\n\nfrom .ola import ola\nfrom .wsola import wsola\nfrom .phasevocoder import phasevocoder, PhaseLocking\n'"
audiotsm/ola.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.ola` module implements the OLA (Overlap-Add) time-scale\nmodification procedure.\n""""""\n\nfrom audiotsm.base import AnalysisSynthesisTSM, Converter\nfrom audiotsm.utils.windows import hanning\n\n\nclass OLAConverter(Converter):\n    """"""A Converter implementing the OLA (Overlap-Add) time-scale modification\n    procedure.""""""\n    def convert_frame(self, analysis_frame):\n        return analysis_frame\n\n\ndef ola(channels, speed=1., frame_length=256, analysis_hop=None,\n        synthesis_hop=None):\n    """"""Returns a :class:`~audiotsm.base.tsm.TSM` object implementing the OLA\n    (Overlap-Add) time-scale modification procedure.\n\n    In most cases, you should not need to set the ``frame_length``, the\n    ``analysis_hop`` or the ``synthesis_hop``. If you want to fine tune these\n    parameters, you can check the documentation of the\n    :class:`~audiotsm.base.analysis_synthesis.AnalysisSynthesisTSM` class to\n    see what they represent.\n\n    :param channels: the number of channels of the input signal.\n    :type channels: int\n    :param speed: the speed ratio by which the speed of the signal will be\n        multiplied (for example, if ``speed`` is set to 0.5, the output signal\n        will be half as fast as the input signal).\n    :type speed: float, optional\n    :param frame_length: the length of the frames.\n    :type frame_length: int, optional\n    :param analysis_hop: the number of samples between two consecutive analysis\n        frames (``speed * synthesis_hop`` by default). If ``analysis_hop`` is\n        set, the ``speed`` parameter will be ignored.\n    :type analysis_hop: int, optional\n    :param synthesis_hop: the number of samples between two consecutive\n        synthesis frames (``frame_length // 2`` by default).\n    :type synthesis_hop: int, optional\n    :returns: a :class:`audiotsm.base.tsm.TSM` object\n    """"""\n    if synthesis_hop is None:\n        synthesis_hop = frame_length // 2\n\n    if analysis_hop is None:\n        analysis_hop = int(synthesis_hop * speed)\n\n    analysis_window = None\n    synthesis_window = hanning(frame_length)\n\n    converter = OLAConverter()\n\n    return AnalysisSynthesisTSM(\n        converter, channels, frame_length, analysis_hop, synthesis_hop,\n        analysis_window, synthesis_window)\n'"
audiotsm/phasevocoder.py,15,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.phasevocoder` module implements the phase vocoder time-scale\nmodification procedure.\n""""""\n\nimport numpy as np\n\nfrom audiotsm.base import AnalysisSynthesisTSM, Converter\nfrom audiotsm.utils.windows import hanning\n\n\ndef find_peaks(amplitude):\n    """"""Find the peaks in an array.\n\n    A value is considered to be a peak if it is higher than its four closest\n    neighbours.\n\n    :param amplitude: an array of floats of shape ``(n,)``.\n    :type amplitude: :class:`numpy.ndarray`\n    :returns: an array ``a`` of bools of shape ``(n,)``, where ``a[i]`` is\n        ``True`` if there is a peak in the ``amplitude`` array at index ``i``.\n    """"""\n    # Pad the array with -1 at the beginning and the end to avoid overflows.\n    padded = np.concatenate((-np.ones(2), amplitude, -np.ones(2)))\n\n    # Shift the array by one/two values to the left/right\n    shifted_l2 = padded[:-4]\n    shifted_l1 = padded[1:-3]\n    shifted_r1 = padded[3:-1]\n    shifted_r2 = padded[4:]\n\n    # Compare the original array with the shifted versions.\n    peaks = ((amplitude >= shifted_l2) & (amplitude >= shifted_l1) &\n             (amplitude >= shifted_r1) & (amplitude >= shifted_r2))\n\n    return peaks\n\n\ndef all_peaks(amplitude):\n    """"""A peak finder that considers all values to be peaks.\n\n    This is used for the phase vocoder without phase locking.\n    :param amplitude: an array of floats of shape ``(n,)``.\n    :type amplitude: :class:`numpy.ndarray`\n    :returns: an array ``a`` of bools of shape ``(n,)``, where ``a[i]`` is\n        ``True`` if there is a peak in the ``amplitude`` array at index ``i``.\n    """"""\n    return np.ones_like(amplitude, dtype=bool)\n\n\ndef get_closest_peaks(peaks):\n    """"""Returns an array containing the index of the closest peak of each index.\n\n    :param peaks: an array of bools of shape ``(n,)``, as returned by\n        :func:`find_peaks`.\n    :type peaks: :class:`numpy.ndarray`\n    :returns: an array ``a`` of ints of shape ``(n,)``, where ``a[i]`` is the\n        index of the peak that is closest to ``i``.\n    """"""\n    closest_peak = np.empty_like(peaks, dtype=int)\n    previous = -1\n    for i, is_peak in enumerate(peaks):\n        if is_peak:\n            if previous >= 0:\n                closest_peak[previous:(previous + i) // 2 + 1] = previous\n                closest_peak[(previous + i) // 2 + 1:i] = i\n            else:\n                closest_peak[:i] = i\n            previous = i\n    closest_peak[previous:] = previous\n\n    return closest_peak\n\n\nclass PhaseVocoderConverter(Converter):\n    """"""A Converter implementing the phase vocoder time-scale modification\n    procedure.""""""\n    # pylint: disable=too-many-instance-attributes\n    def __init__(self, channels, frame_length, analysis_hop, synthesis_hop,\n                 peak_finder):\n        # pylint: disable=too-many-arguments\n        self._channels = channels\n        self._frame_length = frame_length\n        self._synthesis_hop = synthesis_hop\n        self._analysis_hop = analysis_hop\n        self._find_peaks = peak_finder\n\n        # Centers of the FFT frequency bins\n        self._center_frequency = np.fft.rfftfreq(frame_length) * 2 * np.pi\n        fft_length = len(self._center_frequency)\n\n        self._first = True\n\n        self._previous_phase = np.empty((channels, fft_length))\n        self._output_phase = np.empty((channels, fft_length))\n\n        # Buffer used to compute the phase increment and the instantaneous\n        # frequency\n        self._buffer = np.empty(fft_length)\n\n    def clear(self):\n        self._first = True\n\n    def convert_frame(self, frame):\n        # pylint: disable=arguments-differ\n        for k in range(0, self._channels):\n            # Compute the FFT of the analysis frame\n            stft = np.fft.rfft(frame[k])\n            amplitude = np.abs(stft)\n            phase = np.angle(stft)\n            del stft\n\n            peaks = self._find_peaks(amplitude)\n            closest_peak = get_closest_peaks(peaks)\n\n            if self._first:\n                # Leave the first frame unchanged\n                self._output_phase[k, :] = phase\n            else:\n                # Compute the phase increment\n                self._buffer[peaks] = (\n                    phase[peaks] - self._previous_phase[k, peaks] -\n                    self._analysis_hop * self._center_frequency[peaks]\n                )\n\n                # Unwrap the phase increment\n                self._buffer[peaks] += np.pi\n                self._buffer[peaks] %= 2 * np.pi\n                self._buffer[peaks] -= np.pi\n\n                # Compute the instantaneous frequency (in the same buffer,\n                # since the phase increment wont be required after that)\n                self._buffer[peaks] /= self._analysis_hop\n                self._buffer[peaks] += self._center_frequency[peaks]\n\n                self._buffer[peaks] *= self._synthesis_hop\n                self._output_phase[k][peaks] += self._buffer[peaks]\n\n                # Phase locking\n                self._output_phase[k] = (\n                    self._output_phase[k][closest_peak] +\n                    phase - phase[closest_peak]\n                )\n\n                # Compute the new stft\n                output_stft = amplitude * np.exp(1j * self._output_phase[k])\n\n                frame[k, :] = np.fft.irfft(output_stft).real\n\n            # Save the phase for the next analysis frame\n            self._previous_phase[k, :] = phase\n            del phase\n            del amplitude\n\n        self._first = False\n\n        return frame\n\n    def set_analysis_hop(self, analysis_hop):\n        self._analysis_hop = analysis_hop\n\n\nclass PhaseLocking(object):\n    """"""Enumeration of phase locking strategies.""""""\n    # pylint: disable=too-few-public-methods\n\n    NONE = 0\n    """"""No phase locking.""""""\n\n    IDENTITY = 1\n    """"""Identity phase locking.""""""\n\n    @classmethod\n    def from_str(cls, name):\n        """"""Returns a phase locking strategy given its name.""""""\n        if name.lower() == \'none\':\n            return cls.NONE\n        elif name.lower() == \'identity\':\n            return cls.IDENTITY\n        else:\n            raise ValueError(\n                \'Invalid phase locking name: ""{}""\'.format(name))\n\n\ndef phasevocoder(channels, speed=1., frame_length=2048, analysis_hop=None,\n                 synthesis_hop=None, phase_locking=PhaseLocking.IDENTITY):\n    """"""Returns a :class:`~audiotsm.base.tsm.TSM` object implementing the phase\n    vocoder time-scale modification procedure.\n\n    In most cases, you should not need to set the ``frame_length``, the\n    ``analysis_hop`` or the ``synthesis_hop``. If you want to fine tune these\n    parameters, you can check the documentation of the\n    :class:`~audiotsm.base.analysis_synthesis.AnalysisSynthesisTSM` class to\n    see what they represent.\n\n    :param channels: the number of channels of the input signal.\n    :type channels: int\n    :param speed: the speed ratio by which the speed of the signal will be\n        multiplied (for example, if ``speed`` is set to 0.5, the output signal\n        will be half as fast as the input signal).\n    :type speed: float, optional\n    :param frame_length: the length of the frames.\n    :type frame_length: int, optional\n    :param analysis_hop: the number of samples between two consecutive analysis\n        frames (``speed * synthesis_hop`` by default). If ``analysis_hop`` is\n        set, the ``speed`` parameter will be ignored.\n    :type analysis_hop: int, optional\n    :param synthesis_hop: the number of samples between two consecutive\n        synthesis frames (``frame_length // 4`` by default).\n    :type synthesis_hop: int, optional\n    :param phase_locking: a phase locking strategy.\n    :type phase_locking: :class:`PhaseLocking`, optional\n    :returns: a :class:`audiotsm.base.tsm.TSM` object\n    """"""\n    # pylint: disable=too-many-arguments\n    if synthesis_hop is None:\n        synthesis_hop = frame_length // 4\n\n    if analysis_hop is None:\n        analysis_hop = int(synthesis_hop * speed)\n\n    analysis_window = hanning(frame_length)\n    synthesis_window = hanning(frame_length)\n\n    if phase_locking == PhaseLocking.NONE:\n        # No phase locking: all freqyency bins are considered to be peaks\n        peak_finder = all_peaks\n    elif phase_locking == PhaseLocking.IDENTITY:\n        peak_finder = find_peaks\n    else:\n        raise ValueError(\n            \'Invalid phase_locking value: ""{}""\'.format(phase_locking))\n\n    converter = PhaseVocoderConverter(channels, frame_length, analysis_hop,\n                                      synthesis_hop, peak_finder)\n\n    return AnalysisSynthesisTSM(\n        converter, channels, frame_length, analysis_hop, synthesis_hop,\n        analysis_window, synthesis_window)\n'"
audiotsm/wsola.py,6,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.wsola` module implements the WSOLA (Waveform\nSimilarity-based Overlap-Add) time-scale modification procedure.\n\nWSOLA works in the same way as OLA, with the exception that it allows slight\nshift of the position of the analysis frames.\n""""""\n\nimport numpy as np\n\nfrom audiotsm.base import AnalysisSynthesisTSM, Converter\nfrom audiotsm.utils.windows import hanning\n\n\nclass WSOLAConverter(Converter):\n    """"""A Converter implementing the WSOLA (Waveform Similarity-based\n    Overlap-Add) time-scale modification procedure.""""""\n    def __init__(self, channels, frame_length, synthesis_hop, tolerance):\n        self._channels = channels\n        self._frame_length = frame_length\n        self._synthesis_hop = synthesis_hop\n        self._tolerance = tolerance\n\n        self._synthesis_frame = np.empty((channels, frame_length))\n        self._natural_progression = np.empty((channels, frame_length))\n        self._first = True\n\n    def clear(self):\n        self._first = True\n\n    def convert_frame(self, analysis_frame):\n        for k in range(0, self._channels):\n            if self._first:\n                delta = 0\n            else:\n                cross_correlation = np.correlate(\n                    analysis_frame[k, :-self._synthesis_hop],\n                    self._natural_progression[k])\n                delta = np.argmax(cross_correlation)\n                del cross_correlation\n\n            # Copy the shifted analysis frame to the synthesis frame buffer\n            np.copyto(self._synthesis_frame[k],\n                      analysis_frame[k, delta:delta + self._frame_length])\n\n            # Save the natural progression (what the next synthesis frame would\n            # be at normal speed)\n            delta += self._synthesis_hop\n            np.copyto(self._natural_progression[k],\n                      analysis_frame[k, delta:delta + self._frame_length])\n\n        self._first = False\n\n        return self._synthesis_frame\n\n\ndef wsola(channels, speed=1., frame_length=1024, analysis_hop=None,\n          synthesis_hop=None, tolerance=None):\n    """"""Returns a :class:`~audiotsm.base.tsm.TSM` object implementing the WSOLA\n    (Waveform Similarity-based Overlap-Add) time-scale modification procedure.\n\n    In most cases, you should not need to set the ``frame_length``, the\n    ``analysis_hop``, the ``synthesis_hop``, or the ``tolerance``. If you want\n    to fine tune these parameters, you can check the documentation of the\n    :class:`~audiotsm.base.analysis_synthesis.AnalysisSynthesisTSM` class to\n    see what the first three represent.\n\n    WSOLA works in the same way as OLA, with the exception that it allows\n    slight shift (at most ``tolerance``) of the position of the analysis\n    frames.\n\n    :param channels: the number of channels of the input signal.\n    :type channels: int\n    :param speed: the speed ratio by which the speed of the signal will be\n        multiplied (for example, if ``speed`` is set to 0.5, the output signal\n        will be half as fast as the input signal).\n    :type speed: float, optional\n    :param frame_length: the length of the frames.\n    :type frame_length: int, optional\n    :param analysis_hop: the number of samples between two consecutive analysis\n        frames (``speed * synthesis_hop`` by default). If ``analysis_hop`` is\n        set, the ``speed`` parameter will be ignored.\n    :type analysis_hop: int, optional\n    :param synthesis_hop: the number of samples between two consecutive\n        synthesis frames (``frame_length // 2`` by default).\n    :type synthesis_hop: int, optional\n    :param tolerance: the maximum number of samples that the analysis frame can\n        be shifted.\n    :type tolerance: int\n    :returns: a :class:`audiotsm.base.tsm.TSM` object\n    """"""\n    # pylint: disable=too-many-arguments\n    if synthesis_hop is None:\n        synthesis_hop = frame_length // 2\n\n    if analysis_hop is None:\n        analysis_hop = int(synthesis_hop * speed)\n\n    if tolerance is None:\n        tolerance = frame_length // 2\n\n    analysis_window = None\n    synthesis_window = hanning(frame_length)\n\n    converter = WSOLAConverter(channels, frame_length, synthesis_hop,\n                               tolerance)\n\n    return AnalysisSynthesisTSM(\n        converter, channels, frame_length, analysis_hop, synthesis_hop,\n        analysis_window, synthesis_window, tolerance,\n        tolerance + synthesis_hop)\n'"
examples/audiotsmcli.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n""""""\naudiotsmcli\n~~~~~~~~~~~\n\nChange the speed of an audio file without changing its pitch.\n""""""\n\nimport argparse\nimport os\n\nfrom audiotsm import ola, wsola, phasevocoder, PhaseLocking\nfrom audiotsm.io.stream import StreamWriter\nfrom audiotsm.io.wav import WavReader, WavWriter\n\n\ndef create_writer(output, reader):\n    """"""Create a Writer with the same parameters as ``reader``.\n\n    :param output: the path of the output wav file. If it is None, the output\n        will be played with a StreamWriter.\n    :type output: str\n    :param reader: the WavReader used as input of the TSM\n    """"""\n    if output:\n        return WavWriter(output, reader.channels, reader.samplerate)\n\n    return StreamWriter(reader.channels, reader.samplerate)\n\n\ndef create_tsm(name, channels, parameters):\n    """"""Create a TSM object given the method name and its parameters.""""""\n    if name == ""ola"":\n        return ola(channels, **parameters)\n    if name == ""wsola"":\n        return wsola(channels, **parameters)\n    if name == ""phasevocoder"":\n        return phasevocoder(channels, **parameters)\n\n    raise ValueError(""unknown TSM method: {}"".format(name))\n\n\ndef main():\n    """"""Change the speed of an audio file without changing its pitch.""""""\n\n    # Parse command line arguments\n    parser = argparse.ArgumentParser(description=(\n        ""Change the speed of an audio file without changing its pitch.""))\n    parser.add_argument(\n        \'-s\', \'--speed\', metavar=""S"", type=float, default=1.,\n        help=""Set the speed ratio (e.g 0.5 to play at half speed)"")\n    parser.add_argument(\n        \'-m\', \'--method\', type=str, default=""wsola"",\n        help=""Select the TSM method (ola, wsola, or phasevocoder)"")\n    parser.add_argument(\n        \'-l\', \'--frame-length\', metavar=\'N\', type=int, default=None,\n        help=""Set the frame length to N."")\n    parser.add_argument(\n        \'-a\', \'--analysis-hop\', metavar=\'N\', type=int, default=None,\n        help=""Set the analysis hop to N."")\n    parser.add_argument(\n        \'--synthesis-hop\', metavar=\'N\', type=int, default=None,\n        help=""Set the synthesis hop to N."")\n    parser.add_argument(\n        \'-t\', \'--tolerance\', metavar=\'N\', type=int, default=None,\n        help=""Set the tolerance to N (only used when method is set to wsola)."")\n    parser.add_argument(\n        \'-p\', \'--phase-locking\', metavar=\'S\', type=str, default=None,\n        help=(""Set the phase locking strategy (none or identity; ""\n              ""only used when method is set to phasevocoder).""))\n    parser.add_argument(\n        \'-o\', \'--output\', metavar=\'FILENAME\', type=str, default=None,\n        help=""Write the output in the wav file FILENAME."")\n    parser.add_argument(\n        \'input_filename\', metavar=\'INPUT_FILENAME\', type=str,\n        help=""The audio input file"")\n\n    args = parser.parse_args()\n\n    if not os.path.isfile(args.input_filename):\n        parser.error(\n            \'The input file ""{}"" does not exist.\'.format(args.input_filename))\n\n    # Get TSM method parameters\n    parameters = {}\n    if args.speed:\n        parameters[\'speed\'] = args.speed\n    if args.frame_length:\n        parameters[\'frame_length\'] = args.frame_length\n    if args.analysis_hop:\n        parameters[\'analysis_hop\'] = args.analysis_hop\n    if args.synthesis_hop:\n        parameters[\'synthesis_hop\'] = args.synthesis_hop\n    if args.tolerance is not None and args.method == ""wsola"":\n        parameters[\'tolerance\'] = args.tolerance\n    if args.phase_locking and args.method == ""phasevocoder"":\n        parameters[\'phase_locking\'] = PhaseLocking.from_str(args.phase_locking)\n\n    # Run the TSM procedure\n    with WavReader(args.input_filename) as reader:\n        with create_writer(args.output, reader) as writer:\n            tsm = create_tsm(args.method, reader.channels, parameters)\n            tsm.run(reader, writer)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
examples/audiotsmcli_gst.py,0,"b'#!/usr/bin/env python\n\n""""""\nChange the speed of an audio file without changing its pitch (with GStreamer).\n""""""\n\nimport argparse\nimport os\nimport sys\nimport gi\ngi.require_version(\'Gst\', \'1.0\')\n\n# pylint: disable=wrong-import-position\nfrom gi.repository import Gst, GObject\nGst.init(sys.argv)\nimport audiotsm.gstreamer.wsola  # pylint: disable=unused-import\n# pylint: enable=wrong-import-position\n\n\nclass Pipeline(Gst.Pipeline):\n    """"""A gstreamer pipeline that changes the speed of an audio file, write the\n    output to another file, and quit the main gobject loop with this is done.\n\n    :param tsm_description: the description used to create the tsm element of\n        the pipeline. This will be used as input of the\n        :func:`Gst.parse_launch` function.\n    """"""\n    def __init__(self, tsm_description=""audiotsm-wsola""):\n        super().__init__()\n\n        self._speed = 0\n\n        # Create the playbin, that will handle the decoding of the audio files\n        self.playbin = Gst.ElementFactory.make(\'playbin\', \'playbin\')\n        self.add(self.playbin)\n\n        # Create the audiotsm bin, that will handle the TSM\n        audiotsmbin = Gst.Bin(\'audiotsm\')\n\n        # Create the elements of the audiotsm bin, add them, and link them\n        self.tsm = Gst.parse_launch(tsm_description)\n        converter = Gst.ElementFactory.make(\'audioconvert\', \'converter\')\n        encoder = Gst.ElementFactory.make(\'wavenc\', \'encoder\')\n        self.sink = Gst.ElementFactory.make(\'filesink\', \'sink\')\n\n        audiotsmbin.add(self.tsm)\n        audiotsmbin.add(converter)\n        audiotsmbin.add(encoder)\n        audiotsmbin.add(self.sink)\n\n        self.tsm.link(converter)\n        converter.link(encoder)\n        encoder.link(self.sink)\n\n        # Add the sink pad of the TSM plugin to the audiotsm bin.\n        self.tsm_sink_pad = Gst.GhostPad.new(\n            \'sink\', self.tsm.get_static_pad(\'sink\'))\n        audiotsmbin.add_pad(self.tsm_sink_pad)\n\n        # And link it to the playbin\n        self.playbin.set_property(""audio-sink"", audiotsmbin)\n\n        bus = self.get_bus()\n        bus.add_signal_watch()\n        bus.connect(""message::error"", self._on_error)\n        bus.connect(""message::eos"", self._on_eos)\n\n    def _on_error(self, _, message):\n        """"""Called when there is an error during the playback.""""""\n        # pylint: disable=no-self-use\n        err, debug = message.parse_error()\n        print(""Error: %s"" % err, debug)\n        sys.exit()\n\n    def _on_eos(self, _1, _2):\n        """"""Called when the end of the audio file is reached.""""""\n        # pylint: disable=no-self-use\n        sys.exit()\n\n    def set_speed(self, speed):\n        """"""Set the speed ratio.""""""\n        self._speed = speed\n\n    def save(self, path):\n        """"""Save the output of the TSM procedure to path, then quit the GObject\n        loop.""""""\n        self.sink.set_property(\'location\', path)\n        self.set_state(Gst.State.PAUSED)\n        self.get_state(Gst.CLOCK_TIME_NONE)\n\n        self.playbin.seek(self._speed, Gst.Format.BYTES, Gst.SeekFlags.FLUSH,\n                          Gst.SeekType.SET, 0, Gst.SeekType.NONE, -1)\n\n        self.set_state(Gst.State.PLAYING)\n\n    def set_src_uri(self, uri):\n        """"""Set the uri of the source audio file.""""""\n        self.playbin.set_property(""uri"", uri)\n\n\ndef main():\n    """"""Change the speed of an audio file without changing its pitch.""""""\n\n    parser = argparse.ArgumentParser(description=(\n        ""Change the speed of an audio file without changing its pitch.""))\n    parser.add_argument(\n        \'-s\', \'--speed\', metavar=""S"", type=float, default=1.,\n        help=""Set the speed ratio (e.g 0.5 to play at half speed)"")\n    parser.add_argument(\n        \'input_filename\', metavar=\'INPUT_FILENAME\', type=str,\n        help=""The audio input file"")\n    parser.add_argument(\n        \'output_filename\', metavar=\'OUTPUT_FILENAME\', type=str,\n        help=""The audio output file"")\n\n    args = parser.parse_args()\n\n    if not os.path.isfile(args.input_filename):\n        parser.error(\n            \'The input file ""{}"" does not exist.\'.format(args.input_filename))\n\n    pipeline = Pipeline()\n    pipeline.set_speed(args.speed)\n    pipeline.set_src_uri(\'file:///\' + os.path.realpath(args.input_filename))\n    pipeline.save(args.output_filename)\n\n    loop = GObject.MainLoop()\n    loop.run()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
examples/audiotsmgtk.py,2,"b'#!/usr/bin/env python\n\n""""""\nA simple gtk audio player using audiotsm with gstreamer.\n""""""\n\nimport os\nimport sys\nimport numpy as np\nimport gi\ngi.require_version(\'Gst\', \'1.0\')\ngi.require_version(\'Gtk\', \'3.0\')\n\n# pylint: disable=wrong-import-position\nfrom gi.repository import Gst, GObject, Gtk\nGst.init(sys.argv)\nimport audiotsm.gstreamer.phasevocoder  # pylint: disable=unused-import\n# pylint: enable=wrong-import-position\n\n\ndef get_icon_name(icon_names):\n    """"""Return the first icon name that is available in the current GTK icon\n    theme.""""""\n    theme = Gtk.IconTheme.get_default()\n\n    for icon_name in icon_names:\n        if theme.has_icon(icon_name):\n            return icon_name\n\n    return """"\n\n\ndef format_time(time):\n    """"""Format a time as ""minutes:seconds"".""""""\n    minutes, seconds = divmod(time // Gst.SECOND, 60)\n    return ""{}:{:02d}"".format(minutes, seconds)\n\n\nclass Player(Gst.Pipeline):\n    """"""A gstreamer pipeline that provides an easy-to-use player with a\n    changeable playing speed.\n\n    :param tsm_description: the description used to create the tsm element of\n        the pipeline. This will be used as input of the\n        :func:`Gst.parse_launch` function.\n\n    Signals\n    ~~~~~~~\n\n    ``position-changed(position, duration)``\n        Emitted at regular time interval during the playback.\n    ``state-changed(state)``\n        Emitted when the state of the player changes.\n    """"""\n    __gsignals__ = {\n        \'position-changed\':\n            (GObject.SIGNAL_RUN_FIRST, None, (GObject.TYPE_LONG,\n                                              GObject.TYPE_LONG)),\n        \'state-changed\':\n            (GObject.SIGNAL_RUN_FIRST, None, (GObject.TYPE_INT,))\n    }\n\n    def __init__(self, tsm_description=""audiotsm-phase-vocoder""):\n        super().__init__()\n\n        self._speed = 1.0\n        self._speed_set = False\n\n        # Create the playbin, that will handle the decoding of the audio files\n        self.playbin = Gst.ElementFactory.make(\'playbin\', \'playbin\')\n        self.add(self.playbin)\n\n        # Create the audiotsm bin, that will handle the TSM\n        audiotsmbin = Gst.Bin(\'audiotsm\')\n\n        # Create the elements of the audiotsm bin, add them, and link them\n        self.tsm = Gst.parse_launch(tsm_description)\n        converter = Gst.ElementFactory.make(\'audioconvert\', \'converter\')\n        sink = Gst.ElementFactory.make(\'autoaudiosink\', \'sink\')\n\n        audiotsmbin.add(self.tsm)\n        audiotsmbin.add(converter)\n        audiotsmbin.add(sink)\n\n        self.tsm.link(converter)\n        converter.link(sink)\n\n        # Add the sink pad of the TSM plugin to the audiotsm bin.\n        self.tsm_sink_pad = Gst.GhostPad.new(\n            \'sink\', self.tsm.get_static_pad(\'sink\'))\n        audiotsmbin.add_pad(self.tsm_sink_pad)\n\n        # And link it to the playbin\n        self.playbin.set_property(""audio-sink"", audiotsmbin)\n\n        bus = self.get_bus()\n        bus.add_signal_watch()\n        bus.connect(""message::error"", self._on_error)\n        bus.connect(""message::eos"", self._on_eos)\n        bus.connect(""message::state-changed"", self._on_state_changed)\n\n        # The timer that will emit the position-changed signal\n        self.position_timer = None\n\n    def do_state_changed(self, *args):\n        # pylint: disable=missing-docstring\n        # Override the do_state_changed method that is automatically called\n        # when the state-changed signal is emitted, and raises an exception.\n        pass\n\n    def _emit_position(self):\n        """"""Emit a position-changed signal. Called every 200ms during\n        playback.""""""\n        position = self.get_position()\n        duration = self.get_duration()\n        if duration != 0:\n            self.emit(\'position-changed\', position, duration)\n\n        return True\n\n    def get_duration(self):\n        """"""Return the duration of the file currently played, or 0 if it is\n        unknown.\n\n        This is not affected by the speed ratio.""""""\n        success, duration = self.query_duration(Gst.Format.TIME)\n        if success:\n            return duration\n\n        return 0\n\n    def get_position(self):\n        """"""Return the current playback position of the file, or 0 if it is\n        unknown.\n\n        This is not affected by the speed ratio.""""""\n        success, position = self.playbin.query_position(Gst.Format.TIME)\n        if success:\n            return position\n\n        return 0\n\n    def _on_error(self, bus, message):\n        """"""Called when there is an error during the playback.""""""\n        self.set_state(Gst.State.NULL)\n        err, debug = message.parse_error()\n        print(""Error: %s"" % err, debug)\n\n    def _on_eos(self, bus, message):\n        """"""Called when the end of the audio file is reached.""""""\n        duration = self.get_duration()\n        self.emit(\'position-changed\', duration, duration)\n        self.set_state(Gst.State.READY)\n\n    def _on_state_changed(self, bus, message):\n        """"""Called when the state of an element of the pipeline changes.""""""\n        state = message.parse_state_changed()[1]\n\n        if message.src != self.playbin:\n            # Ignore messages that do not come from the playbin\n            return\n\n        if state == Gst.State.READY:\n            self._speed_set = False\n\n        if state == Gst.State.PAUSED:\n            self._emit_position()\n\n        if state == Gst.State.PLAYING:\n            if not self._speed_set:\n                self._speed_set = True\n                self.playbin.seek(\n                    self._speed, Gst.Format.TIME, Gst.SeekFlags.FLUSH,\n                    Gst.SeekType.SET, 0, Gst.SeekType.NONE, -1)\n\n            if self.position_timer is None:\n                self._emit_position()\n                self.position_timer = (\n                    GObject.timeout_add(100, self._emit_position)\n                )\n        else:\n            if self.position_timer is not None:\n                GObject.source_remove(self.position_timer)\n                self.position_timer = None\n\n        self.emit(\'state-changed\', state)\n\n    def seek(self, position):\n        """"""Send a seek event to the playbin.""""""\n        self.playbin.seek(self._speed, Gst.Format.TIME, Gst.SeekFlags.FLUSH,\n                          Gst.SeekType.SET, position, Gst.SeekType.NONE, -1)\n\n    def set_speed(self, speed):\n        """"""Set the speed ratio.""""""\n        if speed != self._speed:\n            self._speed = speed\n\n            position = self.get_position()\n            self.playbin.seek(\n                self._speed, Gst.Format.TIME, Gst.SeekFlags.FLUSH,\n                Gst.SeekType.SET, position, Gst.SeekType.NONE, -1)\n\n    def set_uri(self, uri):\n        """"""Set the uri of the audio file.""""""\n        self.set_state(Gst.State.NULL)\n        self.playbin.set_property(""uri"", uri)\n        self.set_state(Gst.State.PAUSED)\n\n    def toggle(self):\n        """"""Toggle between play and pause.""""""\n        success, state, _ = self.get_state(0)\n        if success != Gst.StateChangeReturn.SUCCESS:\n            return\n\n        if state == Gst.State.PLAYING:\n            self.set_state(Gst.State.PAUSED)\n        else:\n            self.set_state(Gst.State.PLAYING)\n\n\nclass MainWindow(Gtk.Window):\n    """"""The main window of audiotsmgtk.""""""\n    def __init__(self):\n        super().__init__(Gtk.WindowType.TOPLEVEL)\n        self.set_title(\'audiotsmgtk\')\n        self.set_default_size(700, -1)\n        self.connect(\'destroy\', Gtk.main_quit)\n\n        self._seeking = False\n\n        # Headerbar\n        headerbar = Gtk.HeaderBar()\n        headerbar.set_title(\'audiotsmgtk\')\n        headerbar.set_show_close_button(True)\n        self.set_titlebar(headerbar)\n\n        # Open button\n        icon_name = get_icon_name([\n            \'document-open-symbolic\', \'document-open\'])\n        open_button = Gtk.Button.new_from_icon_name(\n            icon_name, Gtk.IconSize.BUTTON)\n        open_button.connect(\'clicked\', self.on_open)\n        headerbar.pack_start(open_button)\n\n        # Play/pause button\n        icon_name = get_icon_name([\n            \'media-playback-start-symbolic\', \'media-playback-start\'])\n        self.toggle_button = Gtk.Button.new_from_icon_name(\n            icon_name, Gtk.IconSize.BUTTON)\n        self.toggle_button.connect(\'clicked\', self.on_toggle)\n        self.toggle_button.set_relief(Gtk.ReliefStyle.NONE)\n\n        # Position and duration labels\n        self.position_label = Gtk.Label(""0:00"")\n        self.duration_label = Gtk.Label(""0:00"")\n\n        # Seek bar\n        self.seek_bar = Gtk.HScale.new_with_range(0, 100, 1)\n        self.seek_bar.set_draw_value(False)\n        self.seek_bar.connect(\'button-press-event\', self.on_seeking_start)\n        self.seek_bar.connect(\'button-release-event\', self.on_seeking_end)\n\n        # Speed\n        speed_label = Gtk.Label.new(""Speed:"")\n        speed_scale = Gtk.HScale.new_with_range(0, 100, 1)\n        speed_scale.set_draw_value(False)\n        for i in range(9):\n            # Divide the speed scale in eight sections. Going from one marker\n            # to the next will multiply the speed by two.\n            speed_scale.add_mark(i * 12.5, Gtk.PositionType.BOTTOM, None)\n        self.speed_label = Gtk.Label()\n        speed_scale.connect(\'change-value\', self.on_speed_scale_changed)\n        speed_scale.connect(\'button-release-event\',\n                            self.on_speed_scale_released)\n        speed_scale.set_value(50)\n        self.speed_label.set_text(\'100.0 %\')\n\n        # Layout\n        self.set_border_width(10)\n        vbox = Gtk.VBox.new(False, 10)\n        player_hbox = Gtk.HBox.new(False, 10)\n        speed_hbox = Gtk.HBox.new(False, 10)\n\n        player_hbox.pack_start(self.toggle_button, False, False, 0)\n        player_hbox.pack_start(self.position_label, False, False, 0)\n        player_hbox.pack_start(self.seek_bar, True, True, 0)\n        player_hbox.pack_start(self.duration_label, False, False, 0)\n\n        speed_hbox.pack_start(speed_label, False, False, 0)\n        speed_hbox.pack_start(speed_scale, True, True, 0)\n        speed_hbox.pack_start(self.speed_label, False, False, 0)\n\n        vbox.pack_start(player_hbox, False, False, 0)\n        vbox.pack_start(speed_hbox, False, False, 0)\n        self.add(vbox)\n\n        # Player\n        self.player = Player()\n        self.player.connect(\'position-changed\', self.on_position_changed)\n        self.player.connect(\'state-changed\', self.on_state_changed)\n\n    def open_file(self, path):\n        """"""Open an audio file.""""""\n        name = os.path.basename(path)\n        self.set_title(name)\n\n        uri = \'file://\' + os.path.realpath(path)\n        self.player.set_uri(uri)\n\n    def on_open(self, button):\n        """"""Called when the open button is clicked.""""""\n        dialog = Gtk.FileChooserDialog(\n            \'Open audio file\', self, Gtk.FileChooserAction.OPEN,\n            (Gtk.STOCK_CANCEL, Gtk.ResponseType.CANCEL,\n             Gtk.STOCK_OPEN, Gtk.ResponseType.OK))\n\n        response = dialog.run()\n        if response == Gtk.ResponseType.OK:\n            path = dialog.get_filename()\n            self.open_file(path)\n\n        dialog.destroy()\n\n    def on_position_changed(self, player, position, duration):\n        """"""Show the current playback position.""""""\n        self.position_label.set_text(format_time(position))\n        self.duration_label.set_text(format_time(duration))\n\n        self.seek_bar.set_range(0, duration)\n        if not self._seeking:\n            self.seek_bar.set_value(position)\n\n    def on_state_changed(self, player, state):\n        """"""Show the state of the player.""""""\n        if state == Gst.State.PLAYING:\n            icon_name = get_icon_name([\n                \'media-playback-pause-symbolic\', \'media-playback-pause\'])\n        else:\n            icon_name = get_icon_name([\n                \'media-playback-start-symbolic\', \'media-playback-start\'])\n\n        self.toggle_button.set_image(Gtk.Image.new_from_icon_name(\n            icon_name, Gtk.IconSize.BUTTON))\n\n    def on_seeking_start(self, seek_bar, event):\n        """"""Called when the user clicks on the seek bar.""""""\n        if event.button == 1:\n            self._seeking = True\n\n    def on_seeking_end(self, seek_bar, event):\n        """"""Called when the user release the seek bar.""""""\n        if event.button == 1:\n            self._seeking = False\n            self.player.seek(seek_bar.get_value())\n\n    def on_speed_scale_changed(self, scale, scroll, value):\n        """"""Called when the user changes the value of the speed scale.""""""\n        # The value in the parameters may be bigger than the maximum value of\n        # the scale. Overwrite it with the actual value of the scale.\n        value = scale.get_value()\n\n        # Convert the value of the scale to a speed. This makes the scale\n        # logarithmic (adding 12.5 to the value of the scale multiplies the\n        # speed by two).\n        speed = 6.25 * np.exp(np.log(2) * value / 12.5)\n\n        self.speed_label.set_text(\'{:.1f} %\'.format(speed))\n\n    def on_speed_scale_released(self, scale, event):\n        """"""Called when the user releases the speed scale.""""""\n        # The value in the parameters may be bigger than the maximum value of\n        # the scale. Overwrite it with the actual value of the scale.\n        value = scale.get_value()\n\n        # Convert the value of the scale to a speed. This makes the scale\n        # logarithmic (adding 12.5 to the value of the scale multiplies the\n        # speed by two).\n        speed = 6.25 * np.exp(np.log(2) * value / 12.5)\n\n        self.speed_label.set_text(\'{:.1f} %\'.format(speed))\n        self.player.set_speed(speed / 100)\n\n    def on_toggle(self, _):\n        """"""Method called when the play/pause button is clicked.""""""\n        self.player.toggle()\n\n\ndef main():\n    """"""Run audiotsmgtk.""""""\n    if len(sys.argv) <= 1:\n        print(\'usage: audiotsmgtk.py <filename>\')\n        return\n\n    window = MainWindow()\n    window.open_file(sys.argv[1])\n\n    window.show_all()\n\n    GObject.threads_init()\n    Gtk.main()\n\n\nif __name__ == ""__main__"":\n    main()\n'"
examples/sine.py,3,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n""""""\nsine\n~~~~\n\nRun a TSM procedure on a signal generated with numpy.\n""""""\n# pylint: disable=invalid-name\n\nimport numpy as np\nimport sounddevice as sd\nfrom audiotsm import wsola\nfrom audiotsm.io.array import ArrayReader, ArrayWriter\n\n\n# The parameters of the input signal\nlength = 1  # in seconds\nsamplerate = 44100  # in Hz\nfrequency = 440  # an A4\n\n# Generate the input signal\ntime = np.linspace(0, length, int(length * samplerate))\ninput_signal = np.sin(np.pi * frequency * time).reshape((1, -1))\n\n# Run the TSM procedure\nreader = ArrayReader(input_signal)\nwriter = ArrayWriter(channels=1)\n\ntsm = wsola(channels=1, speed=0.5)\ntsm.run(reader, writer)\n\n# Play the output\n# This example was written to show how to use an ArrayWriter. If you want to\n# play the output of a TSM procedure you should use an\n# audiotsm.io.stream.StreamWriter.\nsd.play(np.ascontiguousarray(writer.data.T), samplerate, blocking=True)\n'"
audiotsm/base/__init__.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\naudiotsm.base\n~~~~~~~~~~~~~\n\nThis module provides base classes for the implementation of time-scale\nmodification procedures.\n""""""\n\nfrom .tsm import TSM\nfrom .analysis_synthesis import AnalysisSynthesisTSM, Converter\n'"
audiotsm/base/analysis_synthesis.py,3,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.base.analysis_synthesis` module provides a base class for\nreal-time analysis-synthesis based audio time-scale modification procedures.\n""""""\n\nimport numpy as np\n\nfrom audiotsm.utils import (windows, CBuffer, NormalizeBuffer)\nfrom .tsm import TSM\n\nEPSILON = 0.0001\n\n\nclass AnalysisSynthesisTSM(TSM):\n    """"""A :class:`audiotsm.base.tsm.TSM` for real-time analysis-synthesis based\n    time-scale modification procedures.\n\n    The basic principle of an analysis-synthesis based TSM procedure is to\n    first decompose the input signal into short overlapping frames, called the\n    analysis frames. The frames have a fixed length ``frame_length``, and are\n    separated by ``analysis_hop`` samples, as illustrated below::\n\n                 <--------frame_length--------><-analysis_hop->\n       Frame 1:  [~~~~~~~~~~~~~~~~~~~~~~~~~~~~]\n       Frame 2:                  [~~~~~~~~~~~~~~~~~~~~~~~~~~~~]\n       Frame 3:                                  [~~~~~~~~~~~~~~~~~~~~~~~~~~~~]\n       ...\n\n    It then relocates the frames on the time axis by changing the distance\n    between them (to ``synthesis_hop``), as illustrated below::\n\n                 <--------frame_length--------><----synthesis_hop---->\n       Frame 1:  [~~~~~~~~~~~~~~~~~~~~~~~~~~~~]\n       Frame 2:                         [~~~~~~~~~~~~~~~~~~~~~~~~~~~~]\n       Frame 3:                                               [~~~~~~~~~~~~~~~~~~~~~~~~~~~~]\n       ...\n\n    This changes the speed of the signal by the ratio ``analysis_hop /\n    synthesis_hop`` (for example, if the ``synthesis_hop`` is twice the\n    ``analysis_hop``, the output signal will be half as fast as the input\n    signal).\n\n    However this simple method introduces artifacts to the signal. These\n    artifacts can be reduced by modifying the analysis frames by various\n    methods. This is done by a ``converter`` object, which converts the\n    analysis frames into modified frames called the synthesis frames.\n\n    To further reduce the artifacts, window functions (the ``analysis_window``\n    and the ``synthesis_window``) can be applied to the analysis frames and the\n    synthesis frames in order to smooth the signal.\n\n    Some TSM procedures (e.g. WSOLA-like methods) may need to have access to\n    some samples preceeding or following an analysis frame to generate the\n    synthesis frame. The `delta_before` and `delta_after` parameters allow to\n    specify the numbers of samples needed before and after the analysis frame,\n    so that they are available to the ``converter``.\n\n    For more details on Time-Scale Modification procedures, I recommend reading\n    ""`A Review of Time-Scale Modification of Music Signals`_"" by Jonathan\n    Driedger and Meinard M\xc3\xbcller.\n\n    .. _A Review of Time-Scale Modification of Music Signals:\n        http://www.mdpi.com/2076-3417/6/2/57\n\n    :param converter: an object that implements the conversion of the analysis\n        frames into synthesis frames.\n    :type converter: :class:`Converter`\n    :param channels: the number of channels of the input signal.\n    :type channels: int\n    :param frame_length: the length of the frames.\n    :type frame_length: int\n    :param analysis_hop: the number of samples between two consecutive analysis\n        frames.\n    :type analysis_hop: int\n    :param synthesis_hop: the number of samples between two consecutive\n        synthesis frames.\n    :type synthesis_hop: int\n    :param analysis_window: a window applied to the analysis frames\n    :type analysis_window: :class:`numpy.ndarray`\n    :param synthesis_window: a window applied to the synthesis frames\n    :type synthesis_window: :class:`numpy.ndarray`\n    :param delta_before: the number of samples preceding an analysis frame that\n        the converter requires (this is usually 0, except for WSOLA-like\n        methods)\n    :type delta_before: int\n    :param delta_after: the number of samples following an analysis frame that\n        the converter requires (this is usually 0, except for WSOLA-like\n        methods)\n    :type delta_after: int\n    """"""  # noqa: E501\n    # pylint: disable=too-many-instance-attributes\n    def __init__(self, converter, channels, frame_length, analysis_hop,\n                 synthesis_hop, analysis_window, synthesis_window,\n                 delta_before=0, delta_after=0):\n        # pylint: disable=too-many-arguments\n        self._converter = converter\n\n        self._channels = channels\n        self._frame_length = frame_length\n        self._analysis_hop = analysis_hop\n        self._synthesis_hop = synthesis_hop\n\n        self._analysis_window = analysis_window\n        self._synthesis_window = synthesis_window\n\n        self._delta_before = delta_before\n        self._delta_after = delta_after\n\n        # When the analysis hop is larger than the frame length, some samples\n        # from the input need to be skipped. self._skip_input_samples tracks\n        # how many samples should be skipped before reading the analysis frame.\n        self._skip_input_samples = 0\n\n        # This attribute is used to start the output signal in the middle of a\n        # frame, which should be the peek of the window function\n        self._skip_output_samples = 0\n\n        # Compute the normalize window\n        self._normalize_window = windows.product(self._analysis_window,\n                                                 self._synthesis_window)\n\n        if self._normalize_window is None:\n            self._normalize_window = np.ones(self._frame_length)\n\n        # Initialize the buffers\n        delta = self._delta_before + self._delta_after\n        self._in_buffer = CBuffer(self._channels, self._frame_length + delta)\n        self._analysis_frame = np.empty(\n            (self._channels, self._frame_length + delta))\n        self._out_buffer = CBuffer(self._channels, self._frame_length)\n        self._normalize_buffer = NormalizeBuffer(self._frame_length)\n\n        self.clear()\n\n    def clear(self):\n        # Clear the buffers\n        self._in_buffer.remove(self._in_buffer.length)\n        self._out_buffer.remove(self._out_buffer.length)\n        self._out_buffer.right_pad(self._frame_length)\n        self._normalize_buffer.remove(self._normalize_buffer.length)\n\n        # Left pad the input with half a frame of zeros, and ignore that half\n        # frame in the output. This makes the output signal start in the middle\n        # of a frame, which should be the peak of the window function.\n        self._in_buffer.write(np.zeros(\n            (self._channels, self._delta_before + self._frame_length // 2)))\n        self._skip_output_samples = self._frame_length // 2\n\n        # Clear the converter\n        self._converter.clear()\n\n    def flush_to(self, writer):\n        if self._in_buffer.remaining_length == 0:\n            raise RuntimeError(""There is still data to process in the input ""\n                               ""buffer, flush_to method should only be called ""\n                               ""when write_to returns True."")\n\n        n = self._out_buffer.write_to(writer)\n        if self._out_buffer.ready == 0:\n            # The output buffer is empty\n            self.clear()\n            return n, True\n\n        return n, False\n\n    def get_max_output_length(self, input_length):\n        input_length -= self._skip_input_samples\n        if input_length <= 0:\n            return 0\n\n        n_frames = input_length // self._analysis_hop + 1\n        return n_frames * self._synthesis_hop\n\n    def _process_frame(self):\n        """"""Read an analysis frame from the input buffer, process it, and write\n        the result to the output buffer.""""""\n        # Generate the analysis frame and discard the input samples that will\n        # not be needed anymore\n        self._in_buffer.peek(self._analysis_frame)\n        self._in_buffer.remove(self._analysis_hop)\n\n        # Apply the analysis window\n        windows.apply(self._analysis_frame, self._analysis_window)\n\n        # Convert the analysis frame into a synthesis frame\n        synthesis_frame = self._converter.convert_frame(self._analysis_frame)\n\n        # Apply the synthesis window\n        windows.apply(synthesis_frame, self._synthesis_window)\n\n        # Overlap and add the synthesis frame in the output buffer\n        self._out_buffer.add(synthesis_frame)\n\n        # The overlap and add step changes the volume of the signal. The\n        # normalize_buffer is used to keep track of ""how much of the input\n        # signal was added"" to each part of the output buffer, allowing to\n        # normalize it.\n        self._normalize_buffer.add(self._normalize_window)\n\n        # Normalize the samples that are ready to be written to the output\n        normalize = self._normalize_buffer.to_array(end=self._synthesis_hop)\n        normalize[normalize < EPSILON] = 1\n        self._out_buffer.divide(normalize)\n        self._out_buffer.set_ready(self._synthesis_hop)\n        self._normalize_buffer.remove(self._synthesis_hop)\n\n    def read_from(self, reader):\n        n = reader.skip(self._skip_input_samples)\n        self._skip_input_samples -= n\n        if self._skip_input_samples > 0:\n            return n\n\n        n += self._in_buffer.read_from(reader)\n\n        if (self._in_buffer.remaining_length == 0 and\n                self._out_buffer.remaining_length >= self._synthesis_hop):\n            # The input buffer has enough data to process, and there is enough\n            # space in the output buffer to store the output\n            self._process_frame()\n\n            # Skip output samples if necessary\n            skipped = self._out_buffer.remove(self._skip_output_samples)\n            self._out_buffer.right_pad(skipped)\n            self._skip_output_samples -= skipped\n\n            # Set the number of input samples to be skipped\n            self._skip_input_samples = self._analysis_hop - self._frame_length\n            if self._skip_input_samples < 0:\n                self._skip_input_samples = 0\n\n        return n\n\n    def set_speed(self, speed):\n        self._analysis_hop = int(self._synthesis_hop * speed)\n        self._converter.set_analysis_hop(self._analysis_hop)\n\n    def write_to(self, writer):\n        n = self._out_buffer.write_to(writer)\n        self._out_buffer.right_pad(n)\n\n        if (self._in_buffer.remaining_length > 0 and\n                self._out_buffer.ready == 0):\n            # There is not enough data to process in the input buffer, and the\n            # output buffer is empty\n            return n, True\n\n        return n, False\n\n\nclass Converter(object):\n    """"""A base class for objects implementing the conversion of analysis frames\n    into synthesis frames.""""""\n\n    def clear(self):\n        """"""Clears the state of the Converter, making it ready to be used on\n        another signal (or another part of a signal). It is called by the\n        :func:`~audiotsm.base.tsm.TSM.clear` method and the constructor of\n        :class:`AnalysisSynthesisTSM`.""""""\n        # pylint: disable=no-self-use\n        return\n\n    def convert_frame(self, analysis_frame):\n        """"""Converts an analysis frame into a synthesis frame.\n\n        :param analysis_frame: a matrix of shape (``m``, ``delta_before +\n            frame_length + delta_after``), with ``m`` the number of channels,\n            containing the analysis frame and some samples before and after\n            (as specified by the ``delta_before`` and ``delta_after``\n            parameters of the :class:`AnalysisSynthesisTSM` calling the\n            :class:`Converter`).\n\n            ``analysis_frame[:, delta_before:-delta_after]`` contains the\n            actual analysis frame (without the samples preceeding and following\n            it).\n        :type analysis_frame: :class:`numpy.ndarray`\n        :returns: a synthesis frame represented as a :class:`numpy.ndarray` of\n            shape (``m``, ``frame_length``), with ``m`` the number of channels.\n        """"""\n        raise NotImplementedError\n\n    def set_analysis_hop(self, analysis_hop):\n        """"""Change the value of the analysis hop. This is called by the\n        :func:`~audiotsm.base.tsm.TSM.set_speed` method.""""""\n        # pylint: disable=no-self-use,unused-argument\n        return\n'"
audiotsm/base/tsm.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.base.tsm` module provides an abstract class for real-time\naudio time-scale modification procedures.\n""""""\n\n\nclass TSM(object):\n    """"""An abstract class for real-time audio time-scale modification\n    procedures.\n\n    If you want to use a :class:`~audiotsm.base.tsm.TSM` object to run a TSM\n    procedure on a signal, you should use the\n    :func:`~audiotsm.base.tsm.TSM.run` method in most cases.\n    """"""\n\n    def clear(self):\n        """"""Clears the state of the :class:`~audiotsm.base.tsm.TSM` object,\n        making it ready to be used on another signal (or another part of a\n        signal).\n\n        This method should be called before processing a new file, or seeking\n        to another part of a signal.\n        """"""\n        raise NotImplementedError\n\n    def flush_to(self, writer):\n        """"""Writes as many output samples as possible to ``writer``, assuming\n        that there are no remaining samples that will be added to the input\n        (i.e. that the :func:`~audiotsm.base.tsm.TSM.write_to` method will not\n        be called), and returns the number of samples that were written.\n\n        :param writer: a :class:`audiotsm.io.base.Writer`.\n        :returns: a tuple (``n``, ``finished``), with:\n\n            - ``n`` the number of samples that were written to ``writer``\n            - ``finished`` a boolean that is ``True`` when there are no samples\n              remaining to flush.\n        :rtype: (int, bool)\n        """"""\n        raise NotImplementedError\n\n    def get_max_output_length(self, input_length):\n        """"""Returns the maximum number of samples that will be written to the\n        output given the numver of samples of the input.\n\n        :param input_length: the number of samples of the input.\n        :type input_length: int\n        :returns: the maximum number of samples that will be written to the\n            output.\n        """"""\n        raise NotImplementedError\n\n    def read_from(self, reader):\n        """"""Reads as many samples as possible from ``reader``, processes them,\n        and returns the number of samples that were read.\n\n        :param reader: a :class:`audiotsm.io.base.Reader`.\n        :returns: the number of samples that were read from ``reader``.\n        """"""\n        raise NotImplementedError\n\n    def run(self, reader, writer, flush=True):\n        """"""Runs the TSM procedure on the content of ``reader`` and writes the\n        output to ``writer``.\n\n        :param reader: a :class:`audiotsm.io.base.Reader`.\n        :param writer: a :class:`audiotsm.io.base.Writer`.\n        :param flush: ``True`` if there is no more data to process.\n        :type flush: bool, optional\n        """"""\n        finished = False\n        while not (finished and reader.empty):\n            self.read_from(reader)\n            _, finished = self.write_to(writer)\n\n        if flush:\n            finished = False\n            while not finished:\n                _, finished = self.flush_to(writer)\n\n            self.clear()\n\n    def set_speed(self, speed):\n        """"""Sets the speed ratio.\n\n        :param speed: the speed ratio by which the speed of the signal will be\n            multiplied (for example, if ``speed`` is set to 0.5, the output\n            signal will be half as fast as the input signal).\n        :type speed: float\n        """"""\n        raise NotImplementedError\n\n    def write_to(self, writer):\n        """"""Writes as many result samples as possible to ``writer``.\n\n        :param writer: a :class:`audiotsm.io.base.Writer`.\n        :returns: a tuple (``n``, ``finished``), with:\n\n            - ``n`` the number of samples that were written to ``writer``\n            - ``finished`` a boolean that is ``True`` when there are no samples\n              remaining to write. In this case, the\n              :func:`~audiotsm.base.tsm.TSM.read_from` method should be called\n              to add new input samples, or, if there are no remaining input\n              samples, the :func:`~audiotsm.base.tsm.TSM.flush_to` method\n              should be called to get the last output samples.\n        :rtype: (int, bool)\n        """"""\n        raise NotImplementedError\n'"
audiotsm/gstreamer/__init__.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.gstreamer` module implements three audio filters allowing to\nuse the TSM procedures with gstreamer:\n\n- ``audiotsm-ola``, defined in the :mod:`audiotsm.gstreamer.ola` module;\n- ``audiotsm-wsola``, defined in the :mod:`audiotsm.gstreamer.wsola` module;\n- ``audiotsm-phase-vocoder``, defined in the\n  :mod:`audiotsm.gstreamer.phasevocoder` module.\n\n.. note::\n\n    If you are unsure which filter to choose, using ``audiotsm-phase-vocoder``\n    should give good results in most cases. You can listen to the output of the\n    different procedures on various audio files and at various speeds on the\n    `examples page`_.\n\nIn order to use these audio filters, you should first import the module\ncorresponding to the TSM procedure you want to use, for example::\n\n    import audiotsm.gstreamer.phasevocoder\n\nThen, you should create the audio filter with ``Gst.ElementFactory.make``, as\nfollow::\n\n    tsm = Gst.ElementFactory.make(""audiotsm-phase-vocoder"")\n\nYou should then create a gstreamer pipeline using the audio filter you created.\nSee ``examples/audiotsmcli_gst.py`` for an example of pipeline.\n\nThe audio filters work in the same manner as the ``scaletempo`` gstreamer\nplugin. You can change the playback rate by sending a seek event to the\npipeline::\n\n    speed = 0.5\n    pipeline.seek(speed, Gst.Format.BYTES, Gst.SeekFlags.FLUSH,\n                  Gst.SeekType.NONE, -1, Gst.SeekType.NONE, -1)\n\nThe other parameters of the TSM procedure are available as properties, as\ndocumented for each of the procedures below.\n\n.. _examples page: https://muges.github.io/audiotsm/\n""""""\n'"
audiotsm/gstreamer/base.py,2,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`~audiotsm.gstreamer.base` module provides a base class for gstreamer\nplugin using :class:`~audiotsm.base.tsm.TSM` objects.\n""""""\n\nimport numpy as np\nimport gi\ngi.require_version(\'Gst\', \'1.0\')\ngi.require_version(\'GstAudio\', \'1.0\')\n\n# pylint: disable=wrong-import-position\nfrom gi.repository import GObject, GLib, Gst, GstAudio\nfrom audiotsm import __version__\nfrom audiotsm.io.array import ArrayReader, ArrayWriter\nfrom gstbasetransform import BaseTransform\n# pylint: enable=wrong-import-position\n\nCAPS = Gst.Caps.from_string(\n    ""audio/x-raw,format=S16LE,layout=interleaved"")\n\n\ndef audioformatinfo_to_dtype(info):\n    """"""Return the data type corresponding to a ``GstAudio.AudioFormatInfo``\n    object.\n\n    :param info: a ``GstAudio.AudioFormatInfo``.\n    :returns: the corresponding data type, to be used in :mod:`numpy`\n        functions.\n    """"""\n    endianness = \'<\' if info.endianness == GLib.LITTLE_ENDIAN else \'>\'\n\n    if info.flags & GstAudio.AudioFormatFlags.INTEGER:\n        if info.flags & GstAudio.AudioFormatFlags.SIGNED:\n            _type = \'i\'\n        else:\n            _type = \'u\'\n    elif info.flags & GstAudio.AudioFormatFlags.FLOAT:\n        _type = \'f\'\n    else:\n        raise ValueError(\n            \'unsupported audio format flags: {}\'.format(info.flags))\n\n    samplewidth = info.width // 8  # in bytes\n\n    return \'{}{}{}\'.format(endianness, _type, samplewidth)\n\n\nclass GstTSM(BaseTransform):\n    """"""Gstreamer TSM plugin.\n\n    Subclasses should implement the :func:`~GstTSM.create_tsm` method and\n    provide two class attributes:\n\n    - ``__gstmetadata__ = (longname, classification, description, author)``.\n      See the documentation of the gst_element_class_set_metadata_ function for\n      more details.\n    - ``plugin_name``, the name of the plugin.\n\n    Calling the :func:`~GstTSM.register` class method on a subclass will\n    register it, enabling you to instantiate an audio filter with\n    ``Gst.ElementFactory.make(plugin_name)``.\n\n    .. _gst_element_class_set_metadata:\n        https://gstreamer.freedesktop.org/data/doc/gstreamer/head/gstreamer/html/GstElement.html#gst-element-class-set-metadata\n    """"""  # noqa: E501\n    # pylint: disable=no-member\n\n    __gsttemplates__ = (Gst.PadTemplate.new(""src"",\n                                            Gst.PadDirection.SRC,\n                                            Gst.PadPresence.ALWAYS,\n                                            CAPS),\n                        Gst.PadTemplate.new(""sink"",\n                                            Gst.PadDirection.SINK,\n                                            Gst.PadPresence.ALWAYS,\n                                            CAPS))\n\n    def __init__(self):\n        super().__init__()\n\n        self._channels = 0\n        self._samplerate = 0\n        self._bps = 0  # bytes per sample\n        self._dtype = \'\'\n        self._audioformatinfo = None\n\n        self._tsm = None\n        self._position = 0\n\n    @classmethod\n    def plugin_init(cls, plugin):\n        """"""Initialize the plugin.""""""\n        plugin_type = GObject.type_register(cls)\n        Gst.Element.register(plugin, cls.plugin_name, 0, plugin_type)\n        return True\n\n    @classmethod\n    def register(cls):\n        """"""Register the plugin.\n\n        Register the plugin to make it possible to instantiate it with\n        ``Gst.ElementFactory.make``.""""""\n        Gst.Plugin.register_static(\n            Gst.VERSION_MAJOR, Gst.VERSION_MINOR, cls.plugin_name,\n            cls.get_metadata(\'description\'), cls.plugin_init, __version__,\n            \'MIT/X11\', \'audiotsm\', \'audiotsm\', \'\')\n\n    def _gstbuffer_to_ndarray(self, gstbuffer):\n        """"""Return the data contained in ``gstbuffer`` as a\n        :class:`numpy.ndarray`.\n\n        :param gstbuffer: a :class:`Gst.Buffer`.\n        """"""\n        _, mapinfo = gstbuffer.map(Gst.MapFlags.READ)\n        data = mapinfo.data\n        gstbuffer.unmap(mapinfo)\n\n        data = np.frombuffer(data, self._dtype).astype(np.float32) / 32767\n        data = data.reshape((-1, self._channels)).T\n\n        return data\n\n    def _ndarray_to_gstbuffer(self, gstbuffer, data):\n        """"""Write the ``data`` to ``gstbuffer``.\n\n        This method is a bit hack-ish. It would be better to set the size of\n        the :class:`Gst.Buffer` in advance with the\n        :func:`GstBase.BaseTransform.do_transform_size` virtual method, but it\n        is not possible to do so with pygst.\n\n        :param gstbuffer: a :class:`Gst.Buffer`.\n        :param data: a :class:`numpy.ndarray`.\n        """"""\n        length = data.shape[1]\n\n        if length <= 0:\n            gstbuffer.set_size(0)\n            gstbuffer.duration = 0\n            return\n\n        np.clip(data, -1, 1, out=data)\n        data = (data.T.reshape((-1,)) * 32767).astype(self._dtype).tobytes()\n        size = len(data)\n\n        # Copy as many bytes as possible to the buffer directly\n        n = gstbuffer.fill(0, data)\n\n        if n < size:\n            Gst.warning(\'the output buffer is too small, allocating memory\')\n\n            # Allocate memory for the rest of the data\n            # This may add noise to the audio signal\n            data = data[n:]\n            mem = Gst.Memory.new_wrapped(0, data, len(data), 0, None, None)\n            gstbuffer.append_memory(mem)\n\n        gstbuffer.set_size(size)\n\n    def do_sink_event(self, event):\n        """"""Sink pad event handler.""""""\n        if event.type == Gst.EventType.CAPS:\n            # CAPS event, used to negotiate the format with the ""upstream""\n            # gstreamer element.\n            caps = event.parse_caps()\n            structure = caps.get_structure(0)\n\n            # Ensure that the layout is interleaved\n            layout = structure.get_string(\'layout\')\n            if layout != \'interleaved\':\n                # Returns False if we were unable to agree on a format.\n                return False\n\n            # Get number of channels\n            success, self._channels = structure.get_int(\'channels\')\n            if not success:\n                # Returns False if we were unable to agree on a format.\n                return False\n\n            # Get samplerate\n            success, self._samplerate = structure.get_int(\'rate\')\n            if not success:\n                # Returns False if we were unable to agree on a format.\n                return False\n\n            # Get and parse samples format\n            samples_format = structure.get_string(\'format\')\n            if samples_format is None:\n                # Returns False if we were unable to agree on a format.\n                return False\n\n            self._audioformatinfo = GstAudio.AudioFormat.get_info(\n                GstAudio.AudioFormat.from_string(samples_format)\n            )\n            self._dtype = audioformatinfo_to_dtype(self._audioformatinfo)\n\n            self._bps = self._channels * self._audioformatinfo.width // 8\n\n            # Create the TSM object\n            self._tsm = self.create_tsm(self._channels)\n\n        if event.type == Gst.EventType.SEGMENT:\n            segment = event.parse_segment()\n\n            self._tsm.set_speed(segment.rate)\n            self._position = segment.position\n\n            segment.applied_rate = segment.rate\n            segment.rate = 1.0\n            event = Gst.Event.new_segment(segment)\n            self.srcpad.push_event(event)\n\n        if event.type == Gst.EventType.EOS:\n            # Flush the TSM object at the end of the stream\n            writer = ArrayWriter(self._channels)\n            self._tsm.flush_to(writer)\n\n            # Write the output to a Gst.Buffer\n            out_buffer = Gst.Buffer.new()\n            self._ndarray_to_gstbuffer(out_buffer, writer.data)\n\n            out_buffer.pts = self._position\n            self._position += out_buffer.duration\n\n            # Send the buffer downstream\n            self.srcpad.push(out_buffer)\n\n        # Propagate the event downstream\n        return self.srcpad.push_event(event)\n\n    def do_transform(self, in_buffer, out_buffer):\n        """"""Run the data of ``in_buffer`` through the\n        :class:`~audiotsm.base.tsm.TSM` object and write the output to\n        ``out_buffer``.\n\n        :param in_buffer: a ``Gst.Buffer`` containing the input data.\n        :param out_buffer: a ``Gst.Buffer`` where the output data will be\n            written.\n        """"""\n        # There is a bug that increases the refcount of out_buffer, making it\n        # non writable (https://bugzilla.gnome.org/show_bug.cgi?id=727702#c4).\n        # Set the refcount to 1 to fix this.\n        refcount = out_buffer.mini_object.refcount\n        out_buffer.mini_object.refcount = 1\n\n        # Set the position of the output buffer\n        out_buffer.pts = self._position\n\n        # Run the TSM procedure\n        reader = ArrayReader(self._gstbuffer_to_ndarray(in_buffer))\n        writer = ArrayWriter(self._channels)\n\n        self._tsm.run(reader, writer, flush=False)\n\n        self._ndarray_to_gstbuffer(out_buffer, writer.data)\n        out_buffer.duration = (\n            (out_buffer.get_size() * Gst.SECOND) //\n            (self._bps * self._samplerate)\n        )\n        self._position += out_buffer.duration\n\n        # Reset the refcount\n        out_buffer.mini_object.refcount = refcount\n\n        return Gst.FlowReturn.OK\n\n    def do_transform_size(self, direction, caps, size, othercaps):\n        """"""Returns the size of the output buffer given the size of the input\n        buffer.""""""\n        input_length = size // self._bps\n        output_length = self._tsm.get_max_output_length(input_length)\n        output_size = output_length * self._bps\n        return True, output_size\n\n    def create_tsm(self, channels):\n        """"""Returns the :class:`~audiotsm.base.tsm.TSM` object used by the audio\n        filter.""""""\n        raise NotImplementedError()\n'"
audiotsm/gstreamer/ola.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.gstreamer.ola` module implements an audio filter allowing to\nuse the OLA procedure with gstreamer.\n""""""\n\nimport gi\ngi.require_version(\'Gst\', \'1.0\')\n\n# pylint: disable=wrong-import-position\nfrom gi.repository import GObject, Gst\nfrom audiotsm import ola\nfrom .base import GstTSM\n# pylint: enable=wrong-import-position\n\n\nclass OLA(GstTSM):\n    """"""OLA gstreamer audio filter.""""""\n    __gstmetadata__ = (\n        \'OLA time-scale modification\', \'Transform\',\n        \'Change the speed of an audio stream with the OLA procedure\',\n        \'Muges\'\n    )\n\n    plugin_name = ""audiotsm-ola""\n    """"""The plugin name, to be used in ``Gst.ElementFactory.make``.""""""\n\n    frame_length = GObject.Property(type=int, default=-1,\n                                    flags=GObject.ParamFlags.WRITABLE)\n    """"""The length of the frames.\n\n    This is a write-only attribute, that will only take effect the next time\n    the audio filter is setup (usually on the next song).""""""\n\n    synthesis_hop = GObject.Property(type=int, default=-1,\n                                     flags=GObject.ParamFlags.WRITABLE)\n    """"""The number of samples between two consecutive synthesis frames.\n\n    This is a write-only attribute, that will only take effect the next time\n    the audio filter is setup (usually on the next song).""""""\n\n    def create_tsm(self, channels):\n        parameters = {}\n        if self.frame_length > 0:\n            parameters[\'frame_length\'] = self.frame_length\n        if self.synthesis_hop > 0:\n            parameters[\'synthesis_hop\'] = self.synthesis_hop\n\n        return ola(channels, **parameters)\n\n\nOLA.register()\n\n# Register the plugin to make it usable outside python, e.g. with the\n# following commands (this does not seem to work):\n# export GST_PLUGIN_PATH=$PWD/audiotsm/gstreamer/\n# gst-launch-1.0 fakesrc num-buffers=10 ! audiotsm-ola ! fakesink\n_OLA_TYPE = GObject.type_register(OLA)\n__gstelementfactory__ = (OLA.plugin_name, Gst.Rank.NONE, _OLA_TYPE)\n'"
audiotsm/gstreamer/phasevocoder.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.gstreamer.phasevocoder` module implements an audio filter\nallowing to use the phase vocoder procedure with gstreamer.\n""""""\n\nimport gi\ngi.require_version(\'Gst\', \'1.0\')\n\n# pylint: disable=wrong-import-position\nfrom gi.repository import GObject, Gst\nfrom audiotsm import phasevocoder\nfrom .base import GstTSM\n# pylint: enable=wrong-import-position\n\n\nclass PhaseVocoder(GstTSM):\n    """"""Phase vocoder gstreamer audio filter.""""""\n    __gstmetadata__ = (\n        \'Phase vocoder time-scale modification\', \'Transform\',\n        \'Change the speed of an audio stream with the phase vocoder procedure\',\n        \'Muges\'\n    )\n\n    plugin_name = ""audiotsm-phase-vocoder""\n    """"""The plugin name, to be used in ``Gst.ElementFactory.make``.""""""\n\n    frame_length = GObject.Property(type=int, default=-1,\n                                    flags=GObject.ParamFlags.WRITABLE)\n    """"""The length of the frames.\n\n    This is a write-only attribute, that will only take effect the next time\n    the audio filter is setup (usually on the next song).""""""\n\n    synthesis_hop = GObject.Property(type=int, default=-1,\n                                     flags=GObject.ParamFlags.WRITABLE)\n    """"""The number of samples between two consecutive synthesis frames.\n\n    This is a write-only attribute, that will only take effect the next time\n    the audio filter is setup (usually on the next song).""""""\n\n    phase_locking = GObject.Property(type=int, default=-1,\n                                     flags=GObject.ParamFlags.WRITABLE)\n    """"""The phase locking strategy.\n\n    This is a write-only attribute, that will only take effect the next time\n    the audio filter is setup (usually on the next song).""""""\n\n    def create_tsm(self, channels):\n        parameters = {}\n        if self.frame_length > 0:\n            parameters[\'frame_length\'] = self.frame_length\n        if self.synthesis_hop > 0:\n            parameters[\'synthesis_hop\'] = self.synthesis_hop\n        if self.phase_locking >= 0:\n            parameters[\'phase_locking\'] = self.phase_locking\n\n        return phasevocoder(channels, **parameters)\n\n\nPhaseVocoder.register()\n\n# Register the plugin to make it usable outside python, e.g. with the\n# following commands (this does not seem to work):\n# export GST_PLUGIN_PATH=$PWD/audiotsm/gstreamer/\n# gst-launch-1.0 fakesrc num-buffers=10 ! audiotsm-phase-vocoder ! fakesink\n_PV_TYPE = GObject.type_register(PhaseVocoder)\n__gstelementfactory__ = (PhaseVocoder.plugin_name, Gst.Rank.NONE, _PV_TYPE)\n'"
audiotsm/gstreamer/wsola.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.gstreamer.wsola` module implements an audio filter\nallowing to use the WSOLA procedure with gstreamer.\n""""""\n\nimport gi\ngi.require_version(\'Gst\', \'1.0\')\n\n# pylint: disable=wrong-import-position\nfrom gi.repository import GObject, Gst\nfrom audiotsm import wsola\nfrom .base import GstTSM\n# pylint: enable=wrong-import-position\n\n\nclass WSOLA(GstTSM):\n    """"""WSOLA gstreamer audio filter.""""""\n    __gstmetadata__ = (\n        \'WSOLA time-scale modification\', \'Transform\',\n        \'Change the speed of an audio stream with the WSOLA procedure\',\n        \'Muges\'\n    )\n\n    plugin_name = ""audiotsm-wsola""\n    """"""The plugin name, to be used in ``Gst.ElementFactory.make``.""""""\n\n    frame_length = GObject.Property(type=int, default=-1,\n                                    flags=GObject.ParamFlags.WRITABLE)\n    """"""The length of the frames.\n\n    This is a write-only attribute, that will only take effect the next time\n    the audio filter is setup (usually on the next song).""""""\n\n    synthesis_hop = GObject.Property(type=int, default=-1,\n                                     flags=GObject.ParamFlags.WRITABLE)\n    """"""The number of samples between two consecutive synthesis frames.\n\n    This is a write-only attribute, that will only take effect the next time\n    the audio filter is setup (usually on the next song).""""""\n\n    tolerance = GObject.Property(type=int, default=-1,\n                                 flags=GObject.ParamFlags.WRITABLE)\n    """"""The maximum number of samples that the analysis frame can be shifted.\n\n    This is a write-only attribute, that will only take effect the next time\n    the audio filter is setup (usually on the next song).""""""\n\n    def create_tsm(self, channels):\n        parameters = {}\n        if self.frame_length > 0:\n            parameters[\'frame_length\'] = self.frame_length\n        if self.synthesis_hop > 0:\n            parameters[\'synthesis_hop\'] = self.synthesis_hop\n        if self.tolerance >= 0:\n            parameters[\'tolerance\'] = self.tolerance\n\n        return wsola(channels, **parameters)\n\n\nWSOLA.register()\n\n# Register the plugin to make it usable outside python, e.g. with the\n# following commands (this does not seem to work):\n# export GST_PLUGIN_PATH=$PWD/audiotsm/gstreamer/\n# gst-launch-1.0 fakesrc num-buffers=10 ! audiotsm-wsola ! fakesink\n_WSOLA_TYPE = GObject.type_register(WSOLA)\n__gstelementfactory__ = (WSOLA.plugin_name, Gst.Rank.NONE, _WSOLA_TYPE)\n'"
audiotsm/io/__init__.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\n:class:`~audiotsm.base.tsm.TSM` objects use :class:`~audiotsm.io.base.Reader`\nobjects as input and :class:`~audiotsm.io.base.Writer` objects as output.\n\nThe :mod:`audiotsm.io` package provides Readers and Writers allowing to use\n`numpy arrays`_ or `wav files`_ as input or output of a\n:class:`~audiotsm.base.tsm.TSM`, to `play the output in real-time <play in\nreal-time>`_, as well as base classes to `implement your own <implementing your\nown>`_ Readers and Writers.\n""""""\n'"
audiotsm/io/array.py,5,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.io.array` module provides a Reader and Writers allowing to\nuse a :class:`numpy.ndarray` as input or output of a\n:class:`~audiotsm.base.tsm.TSM` object.\n""""""\n\nimport numpy as np\n\nfrom . import base\n\n\nclass ArrayReader(base.Reader):\n    """"""A :class:`~audiotsm.io.base.Reader` allowing to use\n    :class:`numpy.ndarray` as input of a :class:`~audiotsm.base.tsm.TSM`\n    object.\n\n    :param data: a matrix of shape (``m``, ``n``), with ``m`` the number of\n        channels and ``n`` the length of the buffer, where the samples will be\n        read.\n    :type data: :class:`numpy.ndarray`\n    """"""\n    def __init__(self, data):\n        self._data = data\n\n    @property\n    def channels(self):\n        return self._data.shape[0]\n\n    @property\n    def empty(self):\n        return self._data.shape[1] == 0\n\n    def read(self, buffer):\n        if buffer.shape[0] != self._data.shape[0]:\n            raise ValueError(""the two buffers should have the same number of ""\n                             ""channels"")\n\n        # Number of samples to read\n        n = min(buffer.shape[1], self._data.shape[1])\n        np.copyto(buffer[:, :n], self._data[:, :n])\n\n        # Remove the samples that were read\n        self._data = self._data[:, n:]\n\n        return n\n\n    def skip(self, n):\n        if n > self._data.shape[1]:\n            n = self._data.shape[1]\n\n        self._data = self._data[:, n:]\n\n        return n\n\n\nclass ArrayWriter(base.Writer):\n    """"""A :class:`~audiotsm.io.base.Writer` allowing to get the output of a\n    :class:`~audiotsm.base.tsm.TSM` object as a :class:`numpy.ndarray`.\n\n    Writing to an :class:`~audiotsm.io.array.ArrayWriter` will add the data at\n    the end of the :attr:`~audiotsm.io.array.ArrayWriter.data` attribute.\n\n    :param channels: the number of channels of the signal.\n    :type channels: int\n    """"""\n\n    def __init__(self, channels):\n        self._channels = channels\n        self._data = []\n\n    @property\n    def channels(self):\n        return self._channels\n\n    def write(self, buffer):\n        if buffer.shape[0] != self._channels:\n            raise ValueError(""the buffer should have the same number of ""\n                             ""channels as the ArrayWriter"")\n\n        self._data.append(np.copy(buffer))\n\n        return buffer.shape[1]\n\n    @property\n    def data(self):\n        """"""A :class:`numpy.ndarray` of shape (``m``, ``n``), with ``m`` the\n        number of channels and ``n`` the length of the data, where the samples\n        have written.""""""\n        if not self._data:\n            return np.ndarray((self._channels, 0), dtype=np.float32)\n\n        data = np.concatenate(self._data, axis=1)\n        self._data = [data]\n\n        return data\n\n\nclass FixedArrayWriter(base.Writer):\n    """"""A :class:`~audiotsm.io.base.Writer` allowing to use\n    :class:`numpy.ndarray` as output of a TSM object.\n\n    Contrary to an :class:`~audiotsm.io.array.ArrayWriter`, a\n    :class:`~audiotsm.io.array.FixedArrayWriter` takes the buffer in which the\n    data will be written as a parameter of its constructor. The buffer is of\n    fixed size, and it will not be possible to write more samples to the\n    :class:`~audiotsm.io.array.FixedArrayWriter` than the buffer can contain.\n\n    :param data: a matrix of shape (``m``, ``n``), with ``m`` the number of\n        channels and ``n`` the length of the buffer, where the samples will be\n        written.\n    :type data: :class:`numpy.ndarray`\n    """"""\n    def __init__(self, data):\n        self._data = data\n\n    @property\n    def channels(self):\n        return self._data.shape[0]\n\n    def write(self, buffer):\n        if buffer.shape[0] != self._data.shape[0]:\n            raise ValueError(""the two buffers should have the same number of ""\n                             ""channels"")\n\n        # Number of samples to write\n        n = min(buffer.shape[1], self._data.shape[1])\n        np.copyto(self._data[:, :n], buffer[:, :n])\n\n        self._data = self._data[:, n:]\n\n        return n\n'"
audiotsm/io/base.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.io.base` module provides base classes for the input and\noutput of :class:`~audiotsm.base.tsm.TSM` objects.\n""""""\n\n\nclass Reader(object):\n    """"""An abstract class for the input of a :class:`~audiotsm.base.tsm.TSM`\n    object.""""""\n\n    @property\n    def channels(self):\n        """"""The number of channels of the :class:`~audiotsm.io.base.Reader`.""""""\n        raise NotImplementedError()\n\n    @property\n    def empty(self):\n        """"""True if there is no more data to read.""""""\n        raise NotImplementedError()\n\n    def read(self, buffer):\n        """"""Reads as many samples from the :class:`~audiotsm.io.base.Reader` as\n        possible, write them to ``buffer``, and returns the number of samples\n        that were read.\n\n        :param buffer: a matrix of shape (``m``, ``n``), with ``m`` the number\n            of channels and ``n`` the length of the buffer, where the samples\n            will be written.\n        :type buffer: :class:`numpy.ndarray`\n        :returns: the number of samples that were read. It should always be\n            equal to the length of the buffer, except when there is no more\n            values to be read.\n        :raises ValueError: if the :class:`~audiotsm.io.base.Reader` and the\n            buffer do not have the same number of channels\n        """"""\n        raise NotImplementedError()\n\n    def skip(self, n):\n        """"""Try to skip ``n`` samples, an returns the number of samples that\n        were actually skipped.""""""\n        raise NotImplementedError()\n\n\nclass Writer(object):\n    """"""An abstract class for the output of a :class:`~audiotsm.base.tsm.TSM`\n    object.""""""\n\n    @property\n    def channels(self):\n        """"""The number of channels of the :class:`~audiotsm.io.base.Writer`.""""""\n        raise NotImplementedError()\n\n    def write(self, buffer):\n        """"""Write as many samples from the :class:`~audiotsm.io.base.Writer` as\n        possible from ``buffer``, and returns the number of samples that were\n        written.\n\n        :param buffer: a matrix of shape (``m``, ``n``), with ``m`` the number\n            of channels and ``n`` the length of the buffer, where the samples\n            will be read.\n        :type buffer: :class:`numpy.ndarray`\n        :returns: the number of samples that were written. It should always be\n            equal to the length of the buffer, except when there is no more\n            space in the :class:`~audiotsm.io.base.Writer`.\n        :raises ValueError: if the :class:`~audiotsm.io.base.Writer` and the\n            buffer do not have the same number of channels\n        """"""\n        raise NotImplementedError()\n'"
audiotsm/io/stream.py,1,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.io.stream` module provides a\n:class:`~audiotsm.io.base.Writer` allowing to play the output of a\n:class:`~audiotsm.base.tsm.TSM` object in real-time.\n""""""\n\n\nimport numpy as np\nfrom sounddevice import OutputStream\n\nfrom . import base\n\n\nclass StreamWriter(base.Writer):\n    """"""A :class:`~audiotsm.io.base.Writer` allowing to play the output of a\n    :class:`~audiotsm.base.tsm.TSM` object directly.\n\n    You should stop the :class:`~audiotsm.io.stream.StreamWriter` after using\n    it with the :func:`~audiotsm.io.stream.StreamWriter.stop` method, or use it\n    in a ``with`` statement as follow::\n\n        with WavWriter(2, 44100) as writer:\n            # use writer...\n\n    :param channels: the number of channels of the signal.\n    :type channels: int\n    :param samplerate: the sampling rate of the signal.\n    :type samplerate: int\n    :param attrs: additional parameters used to create the\n        :class:`sounddevice.OutputStream` that is used by the\n        :class:`~audiotsm.io.stream.StreamWriter`.\n    """"""\n    def __init__(self, channels, samplerate, **attrs):\n        self._channels = channels\n\n        self._stream = OutputStream(samplerate=samplerate, channels=channels,\n                                    **attrs)\n        self._stream.start()\n\n    @property\n    def channels(self):\n        return self._channels\n\n    def write(self, buffer):\n        if buffer.shape[0] != self.channels:\n            raise ValueError(""the buffer should have the same number of ""\n                             ""channels as the WavWriter"")\n\n        self._stream.write(np.ascontiguousarray(buffer.T))\n\n        return buffer.shape[1]\n\n    def stop(self):\n        """"""Stop the stream.""""""\n        self._stream.stop()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, _1, _2, _3):\n        self.stop()\n'"
audiotsm/io/wav.py,4,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.io.wav` module provides a :class:`~audiotsm.io.base.Reader`\nand a :class:`~audiotsm.io.base.Writer` allowing to use wav files as input or\noutput of a :class:`~audiotsm.base.tsm.TSM` object.\n""""""\n\nimport wave\nimport numpy as np\n\nfrom . import base\n\n\nclass WavReader(base.Reader):\n    """"""A :class:`~audiotsm.io.base.Reader` allowing to use a wav file as input\n    of a :class:`~audiotsm.base.tsm.TSM` object.\n\n    You should close the :class:`~audiotsm.io.wav.WavReader` after using it\n    with the :func:`~audiotsm.io.wav.WavReader.close` method, or use it in a\n    ``with`` statement as follow::\n\n        with WavReader(filename) as reader:\n            # use reader...\n\n    :param filename: the name of an existing wav file.\n    :type filename: str\n    """"""\n    def __init__(self, filename):\n        self._reader = wave.open(filename, \'rb\')\n\n    @property\n    def channels(self):\n        return self._reader.getnchannels()\n\n    @property\n    def empty(self):\n        return self._reader.tell() == self._reader.getnframes()\n\n    def close(self):\n        """"""Close the wav file.""""""\n        self._reader.close()\n\n    def read(self, buffer):\n        if buffer.shape[0] != self.channels:\n            raise ValueError(""the buffer should have the same number of ""\n                             ""channels as the WavReader"")\n\n        frames = self._reader.readframes(buffer.shape[1])\n        frames = np.frombuffer(frames, \'<i2\').astype(np.float32) / 32676\n\n        # Separate channels\n        frames = frames.reshape((-1, self.channels)).T\n\n        n = frames.shape[1]\n        np.copyto(buffer[:, :n], frames)\n        del frames\n\n        return n\n\n    @property\n    def samplerate(self):\n        """"""The samplerate of the wav file.""""""\n        return self._reader.getframerate()\n\n    @property\n    def samplewidth(self):\n        """"""The sample width in bytes of the wav file.""""""\n        return self._reader.getsamplewidth()\n\n    def skip(self, n):\n        current_pos = self._reader.tell()\n        new_pos = min(current_pos + n, self._reader.getnframes())\n\n        self._reader.setpos(new_pos)\n\n        return new_pos - current_pos\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, _1, _2, _3):\n        self.close()\n\n\nclass WavWriter(base.Writer):\n    """"""A :class:`~audiotsm.io.base.Writer` allowing to use a wav file as output\n    of a :class:`~audiotsm.base.tsm.TSM` object.\n\n    You should close the :class:`~audiotsm.io.wav.WavWriter` after using it\n    with the :func:`~audiotsm.io.wav.WavWriter.close` method, or use it in a\n    ``with`` statement as follow::\n\n        with WavWriter(filename, 2, 44100) as writer:\n            # use writer...\n\n    :param filename: the name of the wav file (it will be overwritten if it\n        already exists).\n    :type filename: str\n    :param channels: the number of channels of the signal.\n    :type channels: int\n    :param samplerate: the sampling rate of the signal.\n    :type samplerate: int\n    """"""\n    def __init__(self, filename, channels, samplerate):\n        self._writer = wave.open(filename, \'wb\')\n        self._channels = channels\n        self._writer.setnchannels(channels)\n        self._writer.setframerate(samplerate)\n        self._writer.setsampwidth(2)\n\n    @property\n    def channels(self):\n        return self._channels\n\n    def close(self):\n        """"""Close the wav file.""""""\n        self._writer.close()\n\n    def write(self, buffer):\n        if buffer.shape[0] != self.channels:\n            raise ValueError(""the buffer should have the same number of ""\n                             ""channels as the WavWriter"")\n\n        np.clip(buffer, -1, 1, out=buffer)\n\n        n = buffer.shape[1]\n        frames = (buffer.T.reshape((-1,)) * 32676).astype(np.int16).tobytes()\n        self._writer.writeframes(frames)\n        del frames\n\n        return n\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, _1, _2, _3):\n        self.close()\n'"
audiotsm/utils/__init__.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.utils` module provides utility functions and classes used in\nthe implementation of time-scale modification procedures.\n\n.. autoclass:: audiotsm.utils.CBuffer\n    :members:\n    :undoc-members:\n\n.. autoclass:: audiotsm.utils.NormalizeBuffer\n    :members:\n    :undoc-members:\n""""""\n\nfrom .cbuffer import CBuffer\nfrom .normalizebuffer import NormalizeBuffer\n'"
audiotsm/utils/cbuffer.py,8,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.utils.cbuffer` module implements a circular buffer used to\nstore multichannel audio data.\n""""""\n\nimport numpy as np\n\n\nclass CBuffer(object):\n    """"""A :class:`CBuffer` is a circular buffer used to store multichannel audio\n    data.\n\n    It can be seen as a variable-size buffer whose length is bounded by\n    ``max_length``. The :func:`CBuffer.write` and :func:`CBuffer.right_pad`\n    methods allow to add samples at the end of the buffer, while the\n    :func:`CBuffer.read` and :func:`CBuffer.remove` methods allow to remove\n    samples from the beginning of the buffer.\n\n    Contrary to the samples added by the :func:`CBuffer.write` and\n    :func:`CBuffer.read_from`, those added by the :func:`CBuffer.right_pad`\n    method are considered not to be ready to be read. Effectively, this means\n    that they can be modified by the :func:`CBuffer.add` and\n    :func:`CBuffer.divide` methods, but have to be marked as ready to be read\n    with the :func:`CBuffer.set_ready` method before being read with the\n    :func:`CBuffer.peek`, :func:`CBuffer.read`, or :func:`CBuffer.write_to`\n    methods.\n\n    :param channels: the number of channels of the buffer.\n    :type channels: int\n    :param max_length: the maximum length of the buffer (i.e. the maximum\n        number of samples that can be stored in each channel).\n    :type max_length: int\n    """"""\n    def __init__(self, channels, max_length):\n        self._data = np.zeros((channels, max_length), dtype=np.float32)\n        self._channels = channels\n        self._max_length = max_length\n\n        self._offset = 0\n        self._ready = 0\n        self._length = 0\n\n    def __repr__(self):\n        return ""CBuffer(offset={}, length={}, ready={}, data=\\n{})"".format(\n            self._offset, self._length, self._ready, repr(self.to_array()))\n\n    def add(self, buffer):\n        """"""Adds a ``buffer`` element-wise to the :class:`CBuffer`.\n\n        :param buffer: a matrix of shape (``m``, ``n``), with ``m`` the number\n            of channels and ``n`` the length of the buffer.\n        :type buffer: :class:`numpy.ndarray`\n        :raises ValueError: if the :class:`CBuffer` and the ``buffer`` do not\n            have the same number of channels or the :class:`CBuffer` is smaller\n            than the ``buffer`` (``self.length < n``).\n        """"""\n        if buffer.shape[0] != self._data.shape[0]:\n            raise ValueError(""the two buffers should have the same number of ""\n                             ""channels"")\n\n        n = buffer.shape[1]\n        if n > self._length:\n            raise ValueError(""not enough space remaining in CBuffer"")\n\n        # Compute the slice of data where the values will be added\n        start = self._offset\n        end = self._offset + n\n\n        if end <= self._max_length:\n            self._data[:, start:end] += buffer[:, :n]\n        else:\n            end -= self._max_length\n            self._data[:, start:] += buffer[:, :self._max_length - start]\n            self._data[:, :end] += buffer[:, self._max_length - start:n]\n\n    def divide(self, array):\n        """"""Divides each channel of the :class:`CBuffer` element-wise by the\n        ``array``.\n\n        :param array: an array of shape (``n``,).\n        :type array: :class:`numpy.ndarray`\n        :raises ValueError: if the length of the :class:`CBuffer` is smaller\n            than the length of the array (``self.length < n``).\n        """"""\n        n = len(array)\n        if n > self._length:\n            raise ValueError(""not enough space remaining in the CBuffer"")\n\n        # Compute the slice of data where the values will be divided\n        start = self._offset\n        end = self._offset + n\n\n        if end <= self._max_length:\n            self._data[:, start:end] /= array[:n]\n        else:\n            end -= self._max_length\n            self._data[:, start:] /= array[:self._max_length - start]\n            self._data[:, :end] /= array[self._max_length - start:n]\n\n    @property\n    def length(self):\n        """"""The number of samples of each channel of the :class:`CBuffer`.""""""\n        return self._length\n\n    def peek(self, buffer):\n        """"""Reads as many samples from the :class:`CBuffer` as possible, without\n        removing them from the :class:`CBuffer`, writes them to the ``buffer``,\n        and returns the number of samples that were read.\n\n        The samples need to be marked as ready to be read with the\n        :func:`CBuffer.set_ready` method in order to be read. This is done\n        automatically by the :func:`CBuffer.write` and\n        :func:`CBuffer.read_from` methods.\n\n        :param buffer: a matrix of shape (``m``, ``n``), with ``m`` the number\n            of channels and ``n`` the length of the buffer, where the samples\n            will be written.\n        :type buffer: :class:`numpy.ndarray`\n        :returns: the number of samples that were read from the\n            :class:`CBuffer`.\n        :raises ValueError: if the :class:`CBuffer` and the ``buffer`` do not\n            have the same number of channels.\n        """"""\n        if buffer.shape[0] != self._data.shape[0]:\n            raise ValueError(""the two buffers should have the same number of ""\n                             ""channels"")\n\n        n = min(buffer.shape[1], self._ready)\n\n        # Compute the slice of data the values will be read from\n        start = self._offset\n        end = self._offset + n\n\n        if end <= self._max_length:\n            np.copyto(buffer[:, :n], self._data[:, start:end])\n        else:\n            end -= self._max_length\n            np.copyto(buffer[:, :self._max_length - start],\n                      self._data[:, start:])\n            np.copyto(buffer[:, self._max_length - start:n],\n                      self._data[:, :end])\n\n        return n\n\n    def read(self, buffer):\n        """"""Reads as many samples from the :class:`CBuffer` as possible, removes\n        them from the :class:`CBuffer`, writes them to the ``buffer``, and\n        returns the number of samples that were read.\n\n        The samples need to be marked as ready to be read with the\n        :func:`CBuffer.set_ready` method in order to be read. This is done\n        automatically by the :func:`CBuffer.write` and\n        :func:`CBuffer.read_from` methods.\n\n        :param buffer: a matrix of shape (``m``, ``n``), with ``m`` the number\n            of channels and ``n`` the length of the buffer, where the samples\n            will be written.\n        :type buffer: :class:`numpy.ndarray`\n        :returns: the number of samples that were read from the\n            :class:`CBuffer`.\n        :raises ValueError: if the :class:`CBuffer` and the ``buffer`` do not\n            have the same number of channels.\n        """"""\n        n = self.peek(buffer)\n        self.remove(n)\n        return n\n\n    def read_from(self, reader):\n        """"""Reads as many samples as possible from ``reader``, writes them to\n        the :class:`CBuffer`, and returns the number of samples that were read.\n\n        The written samples are marked as ready to be read.\n\n        :param reader: a :class:`audiotsm.io.base.Reader`.\n        :returns: the number of samples that were read from ``reader``.\n        :raises ValueError: if the :class:`CBuffer` and ``reader`` do not have\n            the same number of channels.\n        """"""\n        # Compute the slice of data that will be written to\n        start = (self._offset + self._length) % self._max_length\n        end = start + self._max_length - self._length\n\n        if end <= self._max_length:\n            n = reader.read(self._data[:, start:end])\n        else:\n            # There is not enough space to copy the whole buffer, it has to be\n            # split into two parts, one of which will be copied at the end of\n            # _data, and the other at the beginning.\n            end -= self._max_length\n\n            n = reader.read(self._data[:, start:])\n            n += reader.read(self._data[:, :end])\n\n        self._length += n\n        self._ready = self._length\n        return n\n\n    @property\n    def ready(self):\n        """"""The number of samples that can be read.""""""\n        return self._ready\n\n    @property\n    def remaining_length(self):\n        """"""The number of samples that can be added to the :class:`CBuffer`.""""""\n        return self._max_length - self._ready\n\n    def remove(self, n):\n        """"""Removes the first ``n`` samples of the :class:`CBuffer`, preventing\n        them to be read again, and leaving more space for new samples to be\n        written.\n\n        :param n: the number of samples to remove.\n        :type n: int\n        :returns: the number of samples that were removed.\n        """"""\n        if n >= self._length:\n            n = self._length\n\n        # Compute the slice of data that will be reset to 0\n        start = self._offset\n        end = self._offset + n\n\n        if end <= self._max_length:\n            self._data[:, start:end] = 0\n        else:\n            end -= self._max_length\n            self._data[:, start:] = 0\n            self._data[:, :end] = 0\n\n        self._offset += n\n        self._offset %= self._max_length\n        self._length -= n\n\n        self._ready -= n\n        if self._ready < 0:\n            self._ready = 0\n\n        return n\n\n    def right_pad(self, n):\n        """"""Add zeros at the end of the :class:`CBuffer`.\n\n        The added samples are not marked as ready to be read. The\n        :func:`CBuffer.set_ready` will need to be called in order to be able to\n        read them.\n\n        :param n: the number of zeros to add.\n        :type n: int\n        :raises ValueError: if there is not enough space to add the zeros.\n        """"""\n        if n > self._max_length - self._length:\n            raise ValueError(""not enough space remaining in :class:`CBuffer`"")\n\n        self._length += n\n\n    def set_ready(self, n):\n        """"""Mark the next ``n`` samples as ready to be read.\n\n        :param n: the number of samples to mark as ready to be read.\n        :type n: int\n        :raises ValueError: if there is less than ``n`` samples that are not\n            ready yet.\n        """"""\n        if self._ready + n > self._length:\n            raise ValueError(""not enough samples to be marked as ready"")\n\n        self._ready += n\n\n    def to_array(self):\n        """"""Returns an array containing the same data as the :class:`CBuffer`.\n\n        :returns: a :class:`numpy.ndarray` of shape (``m``, ``n``), with ``m``\n            the number of channels and ``n`` the length of the buffer.\n        """"""\n        out = np.empty((self._channels, self._ready))\n        self.peek(out)\n        return out\n\n    def write(self, buffer):\n        """"""Writes as many samples from the ``buffer`` to the :class:`CBuffer`\n        as possible, and returns the number of samples that were read.\n\n        The written samples are marked as ready to be read.\n\n        :param buffer: a matrix of shape (``m``, ``n``), with ``m``\n            the number of channels and ``n`` the length of the buffer, where\n            the samples will be read.\n        :type buffer: :class:`numpy.ndarray`\n        :returns: the number of samples that were written to the\n            :class:`CBuffer`.\n        :raises ValueError: if the :class:`CBuffer` and the ``buffer`` do not\n            have the same number of channels.\n        """"""\n        if buffer.shape[0] != self._data.shape[0]:\n            raise ValueError(""the two buffers should have the same number of ""\n                             ""channels"")\n\n        n = min(buffer.shape[1], self._max_length - self._length)\n\n        # Compute the slice of data that will be written to\n        start = (self._offset + self._length) % self._max_length\n        end = start + n\n\n        if end <= self._max_length:\n            np.copyto(self._data[:, start:end], buffer[:, :n])\n        else:\n            # There is not enough space to copy the whole buffer, it has to be\n            # split into two parts, one of which will be copied at the end of\n            # _data, and the other at the beginning.\n            end -= self._max_length\n\n            np.copyto(self._data[:, start:],\n                      buffer[:, :self._max_length - start])\n            np.copyto(self._data[:, :end],\n                      buffer[:, self._max_length - start:n])\n\n        self._length += n\n        self._ready = self._length\n        return n\n\n    def write_to(self, writer):\n        """"""Writes as many samples as possible to ``writer``, deletes them from\n        the :class:`CBuffer`, and returns the number of samples that were\n        written.\n\n        The samples need to be marked as ready to be read with the\n        :func:`CBuffer.set_ready` method in order to be read. This is done\n        automatically by the :func:`CBuffer.write` and\n        :func:`CBuffer.read_from` methods.\n\n        :param writer: a :class:`audiotsm.io.base.Writer`.\n        :returns: the number of samples that were written to ``writer``.\n        :raises ValueError: if the :class:`CBuffer` and ``writer`` do not have\n            the same number of channels.\n        """"""\n        # Compute the slice of data the values will be read from\n        start = self._offset\n        end = self._offset + self._ready\n\n        if end <= self._max_length:\n            n = writer.write(self._data[:, start:end])\n        else:\n            end -= self._max_length\n            n = writer.write(self._data[:, start:])\n            n += writer.write(self._data[:, :end])\n\n        self.remove(n)\n        return n\n'"
audiotsm/utils/normalizebuffer.py,4,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.normalizebuffer` module implements a mono-channel circular\nbuffer used to normalize audio buffers.\n""""""\n\nimport numpy as np\n\n\nclass NormalizeBuffer(object):\n    """"""A :class:`NormalizeBuffer` is a mono-channel circular buffer, used to\n    normalize audio buffers.\n\n    :param length: the length of the :class:`NormalizeBuffer`.\n    :type length: int\n    """"""\n    def __init__(self, length):\n        self._data = np.zeros(length)\n        self._offset = 0\n        self._length = length\n\n    def __repr__(self):\n        return ""NormalizeBuffer(offset={}, length={}, data=\\n{})"".format(\n            self._offset, self._length, repr(self.to_array()))\n\n    def add(self, window):\n        """"""Adds a window element-wise to the :class:`NormalizeBuffer`.\n\n        :param window: an array of shape (``n``,).\n        :type window: :class:`numpy.ndarray`\n        :raises ValueError: if the window is larger than the buffer (``n >\n            self.length``).\n        """"""\n        n = len(window)\n        if n > self._length:\n            raise ValueError(""the window should be smaller than the ""\n                             ""NormalizeBuffer"")\n\n        # Compute the slice of data where the values will be added\n        start = self._offset\n        end = self._offset + n\n\n        if end <= self._length:\n            self._data[start:end] += window\n        else:\n            end -= self._length\n            self._data[start:] += window[:self._length - start]\n            self._data[:end] += window[self._length - start:]\n\n    @property\n    def length(self):\n        """"""The length of the CBuffer.""""""\n        return self._length\n\n    def remove(self, n):\n        """"""Removes the first ``n`` values of the :class:`NormalizeBuffer`.\n\n        :param n: the number of values to remove.\n        :type n: int\n        """"""\n        if n >= self._length:\n            n = self._length\n        if n == 0:\n            return\n\n        # Compute the slice of data to reset\n        start = self._offset\n        end = self._offset + n\n\n        if end <= self._length:\n            self._data[start:end] = 0\n        else:\n            end -= self._length\n            self._data[start:] = 0\n            self._data[:end] = 0\n\n        self._offset += n\n        self._offset %= self._length\n\n    def to_array(self, start=0, end=None):\n        """"""Returns an array containing the same data as the\n        :class:`NormalizeBuffer`, from index ``start`` (included) to index\n        ``end`` (exluded).\n\n        :returns: :class:`numpy.ndarray`\n        """"""\n        if end is None:\n            end = self._length\n\n        start += self._offset\n        end += self._offset\n\n        if end <= self._length:\n            return np.copy(self._data[start:end])\n\n        end -= self._length\n        if start < self._length:\n            return np.concatenate((self._data[start:], self._data[:end]))\n\n        start -= self._length\n        return np.copy(self._data[start:end])\n'"
audiotsm/utils/windows.py,3,"b'# -*- coding: utf-8 -*-\n\n""""""\nThe :mod:`audiotsm.utils.windows` module contains window functions used for\ndigital signal processing.\n""""""\n\nimport numpy as np\n\n\ndef apply(buffer, window):\n    """"""Applies a window to a buffer.\n\n    :param buffer: a matrix of shape (``m``, ``n``), with ``m`` the number of\n        channels and ``n`` the length of the buffer.\n    :type buffer: :class:`numpy.ndarray`\n    :param window: a :class:`numpy.ndarray` of shape (``n``,).\n    """"""\n    if window is None:\n        return\n\n    for channel in buffer:\n        channel *= window\n\n\ndef hanning(length):\n    """"""Returns a periodic Hanning window.\n\n    Contrary to :func:`numpy.hanning`, which returns the symetric Hanning\n    window, :func:`hanning` returns a periodic Hanning window, which is better\n    for spectral analysis.\n\n    :param length: the number of points of the Hanning window\n    :type length: :class:`int`\n    :return: the window as a :class:`numpy.ndarray` of shape (``length``,).\n    """"""\n    if length <= 0:\n        return np.zeros(0)\n\n    time = np.arange(length)\n    return 0.5 * (1 - np.cos(2 * np.pi * time / length))\n\n\ndef product(window1, window2):\n    """"""Returns the product of two windows.\n\n    :param window1: a :class:`numpy.ndarray` of shape (``n``,) or ``None``.\n    :param window2: a :class:`numpy.ndarray` of shape (``n``,) or ``None``.\n    :returns: the product of the two windows. If one of the windows is equal to\n        ``None``, the other is returned, and if the two are equal to ``None``,\n        ``None`` is returned.\n    """"""\n    if window1 is None:\n        return window2\n\n    if window2 is None:\n        return window1\n\n    return window1 * window2\n'"
docs/ghpages/generate.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n""""""\nGenerate example page for github pages.\n""""""\n\nimport os\nimport re\nfrom distutils.dir_util import copy_tree\nfrom docutils.core import publish_parts\nfrom jinja2 import Environment, FileSystemLoader, Markup\nimport sass\n\nSCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT = os.path.join(SCRIPT_DIR, "".."", "".."")\n\nASSETS_DIR = os.path.join(SCRIPT_DIR, ""assets"")\nTEMPLATES_DIR = os.path.join(SCRIPT_DIR, ""templates"")\nCREDITS_PATH = os.path.join(ROOT, ""tests"", ""integration"", ""data"", ""README.rst"")\nDESTINATION_DIR = os.path.join(ROOT, ""build"", ""ghpages"")\nEXAMPLES_DIR = os.path.join(DESTINATION_DIR, ""examples"")\n\nCSS_FILE = os.path.join(SCRIPT_DIR, ""scss"", ""audiotsm.scss"")\n\nENVIRONMENT = Environment(\n    loader=FileSystemLoader(TEMPLATES_DIR),\n    autoescape=True, trim_blocks=False)\n\nSPEED_DIR_RE = re.compile(r\'speed-([\\d\\.]+)\')\nFILE_RE = re.compile(r\'([^_]+)_(.+)\\.wav\')\n\nMETHOD_NAME = {\n    \'ola\': \'OLA\',\n    \'wsola\': \'WSOLA\',\n    \'phasevocoder\': Markup(\'Phase<br/>Vocoder\'),\n    \'phasevocoder_identity\': Markup(\n        \'Phase Vocoder<br/>(identity)\'),\n}\nMETHOD_SORT = [\'ola\', \'wsola\', \'phasevocoder\', \'phasevocoder_identity\']\n\n\ndef get_examples():\n    speeds = set()\n    methods = set()\n    files = {}\n\n    for speed_dir in os.listdir(EXAMPLES_DIR):\n        match = SPEED_DIR_RE.match(speed_dir)\n        if match:\n            speed = match.group(1)\n            speeds.add(speed)\n            files[speed] = {}\n        elif speed_dir == \'orig\':\n            speed = \'orig\'\n            files[speed] = {}\n        else:\n            print(\'invalid speed directory ""{}""\'.format(speed_dir))\n            continue\n\n        speed_dir = os.path.join(EXAMPLES_DIR, speed_dir)\n        for root, _, filenames in os.walk(speed_dir):\n            for filename in filenames:\n                fullpath = os.path.join(root, filename)\n                path = os.path.relpath(fullpath, DESTINATION_DIR)\n                name = os.path.relpath(fullpath, speed_dir)\n\n                if speed == \'orig\':\n                    name = os.path.splitext(name)[0]\n                    files[speed][name] = path\n                else:\n                    match = FILE_RE.match(name)\n                    if match:\n                        name = match.group(1)\n                        method = match.group(2)\n                        methods.add(method)\n                        if name not in files[speed]:\n                            files[speed][name] = {}\n                        files[speed][name][method] = path\n                    else:\n                        print(\'invalid example file ""{}""\'.format(filename))\n\n    return {\n        \'speeds\': sorted(speeds, key=float),\n        \'methods\': [\n            (method, METHOD_NAME[method])\n            for method in sorted(methods, key=METHOD_SORT.index)\n        ],\n        \'files\': files\n    }\n\n\ndef generate_css():\n    """"""Generate css stylesheet.""""""\n    css = sass.compile(filename=CSS_FILE)\n\n    css_dir = os.path.join(DESTINATION_DIR, ""css"")\n    if not os.path.isdir(css_dir):\n        os.makedirs(css_dir)\n\n    filename = os.path.join(css_dir, ""audiotsm.css"")\n    with open(filename, \'w\') as fileobj:\n        fileobj.write(css)\n\n\ndef generate_index():\n    """"""Generate index.html.""""""\n    context = get_examples()\n\n    with open(CREDITS_PATH) as fileobj:\n        context[\'credits\'] = Markup(\n            publish_parts(fileobj.read(), writer_name=\'html\')[\'fragment\'])\n\n    filename = os.path.join(DESTINATION_DIR, \'index.html\')\n    with open(filename, \'w\') as fileobj:\n        template = ENVIRONMENT.get_template(\'index.html\')\n        html = template.render(context)\n        fileobj.write(html)\n\n\ndef main():\n    """"""Generate github pages.""""""\n    # Copy assets\n    copy_tree(ASSETS_DIR, DESTINATION_DIR)\n\n    generate_css()\n    generate_index()\n\n\nif __name__ == ""__main__"":\n    main()\n'"
docs/sphinx/conf.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# audiotsm documentation build configuration file, created by\n# sphinx-quickstart on Mon Sep  4 13:47:35 2017.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport os\nimport re\nimport sys\nfrom unittest import mock\n\n\ndef find_version():\n    """"""Read the package\'s version from __init__.py""""""\n    version_filename = os.path.abspath(""../../audiotsm/__init__.py"")\n    with open(version_filename) as fileobj:\n        version_content = fileobj.read()\n    version_match = re.search(r""^__version__ = [\'\\""]([^\'\\""]*)[\'\\""]"",\n                              version_content, re.M)\n    if version_match:\n        return version_match.group(1)\n    raise RuntimeError(""Unable to find version string."")\n\n\n_release = find_version()\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.intersphinx\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'toc\'\n\n# General information about the project.\nproject = \'audiotsm\'\ncopyright = \'2017, Muges\'\nauthor = \'Muges\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = \'.\'.join(_release.split(\'.\')[:2])\n# The full version, including alpha/beta/rc tags.\nrelease = _release\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = \'en\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# If true, Sphinx will warn about all references where the target cannot be\n# found.\nnitpicky = True\n\n# A list of (type, target) tuples (by default empty) that should be ignored\n# when generating warnings in \xe2\x80\x9cnitpicky mode\xe2\x80\x9d. Note that type should include\n# the domain name if present. Example entries would be (\'py:func\', \'int\') or\n# (\'envvar\', \'LD_LIBRARY_PATH\').\nnitpick_ignore = [\n    (\'py:obj\', \'optional\')\n]\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n\nintersphinx_mapping = {\n    \'python\': (\'https://docs.python.org/3.6\', None),\n    \'numpy\': (\'https://docs.scipy.org/doc/numpy/\', None),\n    \'sounddevice\':\n        (\'https://python-sounddevice.readthedocs.io/en/latest/\', None)\n}\n\n# Mock modules\nautodoc_mock_imports = [\'numpy\', \'gi\', \'gi.types\', \'sounddevice\']\n\n\nclass BaseTransform(object):\n    @staticmethod\n    def get_metadata(_):\n        return \'\'\n\n\nsys.modules[\'gstbasetransform\'] = mock.Mock(BaseTransform=BaseTransform)\nsys.modules[\'gi.repository\'] = mock.Mock()\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# This is required for the alabaster theme\n# refs: http://alabaster.readthedocs.io/en/latest/installation.html#sidebars\nhtml_sidebars = {\n    \'**\': [\n        \'about.html\',\n        \'navigation.html\',\n        \'relations.html\',  # needs \'show_related\': True theme option to display\n        \'searchbox.html\',\n        \'donate.html\',\n    ]\n}\n\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'audiotsmdoc\'\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'audiotsm.tex\', \'audiotsm Documentation\',\n     \'Author\', \'manual\'),\n]\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'audiotsm\', \'audiotsm Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'audiotsm\', \'audiotsm Documentation\',\n     author, \'audiotsm\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n\n# -- Options for Epub output ----------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = project\nepub_author = author\nepub_publisher = author\nepub_copyright = copyright\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier = \'\'\n\n# A unique identification for the text.\n#\n# epub_uid = \'\'\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\'search.html\']\n'"
tests/integration/conftest.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nPytest configuration\n""""""\n\nimport fnmatch\nimport os\nimport pytest\n\n\ndef pytest_namespace():\n    """"""Set pytest global variables.""""""\n    return {\'DATA_DIR\': os.path.join(""tests"", ""integration"", ""data"")}\n\n\ndef pytest_addoption(parser):\n    """"""Add command line options to the pytest command.""""""\n    parser.addoption(\n        ""--data-all"", action=""store_true"", help=""run on all data files"")\n    parser.addoption(\n        ""--data-save"", action=""store_true"",\n        help=""save the output of the data tests to build/examples"")\n\n\ndef get_data_files():\n    """"""Recursively look for wav files in the DATA_DIR directory, and returns\n    their paths.""""""\n    # pylint: disable=no-member\n    data_files = []\n    for root, _, filenames in os.walk(pytest.DATA_DIR):\n        for filename in fnmatch.filter(filenames, \'*.wav\'):\n            data_files.append(os.path.join(root, filename))\n\n    return data_files\n\n\ndef pytest_generate_tests(metafunc):\n    """"""Generate tests for test_data.py.""""""\n    if \'speed\' in metafunc.fixturenames:\n        metafunc.parametrize(\'speed\', [1 / 1.2, 1 / 1.8, 2])\n\n    if \'tsm_name\' in metafunc.fixturenames:\n        metafunc.parametrize(\'tsm_name\', [\n            ""ola"", ""wsola"", ""phasevocoder"", ""phasevocoder_identity""])\n\n    if \'save\' in metafunc.fixturenames:\n        metafunc.parametrize(""save"", [metafunc.config.getoption(\'data_save\')])\n\n    if \'data_file\' in metafunc.fixturenames:\n        data_files = get_data_files()\n        if not metafunc.config.getoption(\'data_all\'):\n            # Only test with two files\n            data_files = data_files[:2]\n        metafunc.parametrize(""data_file"", data_files)\n'"
tests/integration/test_data.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nTests the TSM procedures on real data.\n""""""\n\nimport os\nimport shutil\nimport pytest\n\nfrom audiotsm import ola, wsola, phasevocoder, PhaseLocking\nfrom audiotsm.io.wav import WavReader, WavWriter\nfrom audiotsm.io.array import ArrayWriter\n\nEXAMPLES_DIR = os.path.join(""build"", ""ghpages"", ""examples"")\n\n\ndef create_tsm(name, channels, speed):\n    """"""Create a TSM object given the method name and its parameters.""""""\n    if name == ""ola"":\n        return ola(channels, speed)\n    if name == ""wsola"":\n        return wsola(channels, speed)\n    if name == ""phasevocoder"":\n        return phasevocoder(channels, speed, phase_locking=PhaseLocking.NONE)\n    if name == ""phasevocoder_identity"":\n        return phasevocoder(channels, speed,\n                            phase_locking=PhaseLocking.IDENTITY)\n\n    raise ValueError(""unknown TSM method: {}"".format(name))\n\n\ndef test_data(data_file, speed, tsm_name, save):\n    """"""Test the TSM procedures on real data.""""""\n    reader = None\n    writer = None\n\n    try:\n        # Create the reader\n        reader = WavReader(data_file)\n\n        # Create the writer\n        if save:\n            # pylint: disable=no-member\n            rel_path = os.path.relpath(data_file, pytest.DATA_DIR)\n            # pylint: enable=no-member\n\n            # Copy original file to ""orig"" directory\n            orig_file = os.path.join(EXAMPLES_DIR, ""orig"", rel_path)\n            orig_dir = os.path.dirname(orig_file)\n            if not os.path.isdir(orig_dir):\n                os.makedirs(orig_dir)\n            if not os.path.isfile(orig_file):\n                shutil.copy2(data_file, orig_file)\n\n            # Generate output file path\n            speed_dir = ""speed-{:.2f}"".format(speed)\n            name = os.path.splitext(rel_path)[0]\n            output_name = ""{}_{}.wav"".format(name, tsm_name)\n            output_file = os.path.join(EXAMPLES_DIR, speed_dir, output_name)\n            output_dir = os.path.dirname(output_file)\n            if not os.path.isdir(output_dir):\n                os.makedirs(output_dir)\n\n            writer = WavWriter(output_file, reader.channels, reader.samplerate)\n        else:\n            writer = ArrayWriter(reader.channels)\n\n        # Create and run the TSM\n        tsm = create_tsm(tsm_name, reader.channels, speed)\n        tsm.run(reader, writer)\n\n    finally:\n        # Close files\n        if reader:\n            reader.close()\n        if save and writer:\n            writer.close()\n'"
tests/unit/test_phasevocoder.py,4,"b'# -*- coding: utf-8 -*-\n\n""""""\nTests for the audiotsm.phasevocoder package.\n""""""\n\nimport pytest\nimport numpy as np\nfrom numpy.testing import assert_array_equal\n\nfrom audiotsm.phasevocoder import find_peaks, get_closest_peaks\n\n\n@pytest.mark.parametrize(""amplitude, peaks"", [\n    ([], []),\n    ([0], [True]),\n    ([1], [True]),\n    ([1, 0, 0, 1, 0, 0, 0, 1, 0],\n     [True, False, False, True, False, False, False, True, False]),\n    ([0, 1, 2, 3, 1, 2, 4, 5, -1, 6, 0],\n     [False, False, False, True, False, False, False, False, False, True,\n      False]),\n])\ndef test_find_peaks(amplitude, peaks):\n    """"""Run tests for the find_peaks function.""""""\n    actual_peaks = find_peaks(np.array(amplitude))\n    assert_array_equal(actual_peaks, np.array(peaks, dtype=bool))\n\n\n@pytest.mark.parametrize(""peaks, closest_peak"", [\n    ([], []),\n    ([True], [0]),\n    ([True], [0]),\n    ([True, False, False, True, False, False, False, True, False],\n     [0, 0, 3, 3, 3, 3, 7, 7, 7]),\n    ([True, True, True, True, True, True, True, True, True],\n     [0, 1, 2, 3, 4, 5, 6, 7, 8]),\n    ([False, False, False, True, False, False, False, False, False, True,\n      False],\n     [3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9]),\n])\ndef test_get_closest_peaks(peaks, closest_peak):\n    """"""Run tests for the get_closest_peaks.""""""\n    actual_closest_peak = get_closest_peaks(np.array(peaks))\n    assert_array_equal(actual_closest_peak, np.array(closest_peak, dtype=int))\n'"
tests/unit/io/test_io_array.py,12,"b'# -*- coding: utf-8 -*-\n\n""""""\nTests for the audiotsm.io.array package.\n""""""\n\nimport pytest\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\n\nfrom audiotsm.io.array import ArrayReader, ArrayWriter, FixedArrayWriter\n\n\n@pytest.mark.parametrize(""data_in, read_out, n_out, data_out"", [\n    ([[]], [[]], 0, [[]]),\n    ([[]], [[0]], 0, [[]]),\n    ([[1, 2, 3], [4, 5, 6]], [[], []], 0, [[1, 2, 3], [4, 5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], [[1], [4]], 1, [[2, 3], [5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], [[1, 2], [4, 5]], 2, [[3], [6]]),\n    ([[1, 2, 3], [4, 5, 6]], [[1, 2, 3], [4, 5, 6]], 3, [[], []]),\n    ([[1, 2, 3], [4, 5, 6]], [[1, 2, 3, 0], [4, 5, 6, 0]], 3, [[], []]),\n])\ndef test_read(data_in, read_out, n_out, data_out):\n    """"""Run tests for the ArrayReader.read method.""""""\n    reader = ArrayReader(np.array(data_in))\n\n    buffer = np.zeros_like(read_out, dtype=np.float32)\n    n = reader.read(buffer)\n    assert_almost_equal(buffer, read_out)\n    assert n == n_out\n\n    # Check the data remaining in the reader\n    buffer = np.zeros_like(data_out)\n    reader.read(buffer)\n    assert_almost_equal(buffer, data_out)\n\n    # Check that there is no more data in the reader\n    buffer = np.zeros_like(data_in)\n    n = reader.read(buffer)\n    assert not buffer.any()\n    assert n == 0\n\n\n@pytest.mark.parametrize(""data_in, n_in, n_out, data_out"", [\n    ([[]], 0, 0, [[]]),\n    ([[]], 1, 0, [[]]),\n    ([[1, 2, 3], [4, 5, 6]], 0, 0, [[1, 2, 3], [4, 5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 1, 1, [[2, 3], [5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 2, 2, [[3], [6]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 3, [[], []]),\n    ([[1, 2, 3], [4, 5, 6]], 4, 3, [[], []]),\n])\ndef test_skip(data_in, n_in, n_out, data_out):\n    """"""Run tests for the ArrayReader.skip method.""""""\n    reader = ArrayReader(np.array(data_in))\n\n    n = reader.skip(n_in)\n    assert n == n_out\n\n    # Check the data remaining in the reader\n    buffer = np.zeros_like(data_out)\n    reader.read(buffer)\n    assert_almost_equal(buffer, data_out)\n\n    # Check that there is no more data in the reader\n    buffer = np.zeros_like(data_in)\n    n = reader.read(buffer)\n    assert not buffer.any()\n    assert n == 0\n\n\n@pytest.mark.parametrize(""write1, write2, n1_out, n2_out, buffer_out"", [\n    ([[], []], [[], []], 0, 0, [[], []]),\n\n    ([[1, 2, 3], [4, 5, 6]], [[], []], 3, 0, [[1, 2, 3], [4, 5, 6]]),\n    ([[1, 2], [4, 5]], [[3], [6]], 2, 1, [[1, 2, 3], [4, 5, 6]]),\n    ([[1], [4]], [[2, 3], [5, 6]], 1, 2, [[1, 2, 3], [4, 5, 6]]),\n    ([[], []], [[1, 2, 3], [4, 5, 6]], 0, 3, [[1, 2, 3], [4, 5, 6]]),\n\n    ([[1, 2, 3], [4, 5, 6]], [[7], [8]], 3, 0, [[1, 2, 3], [4, 5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], [[7], [8]], 2, 0, [[1, 2], [4, 5]]),\n\n    ([[1, 2], [4, 5]], [[], []], 2, 0, [[1, 2, 0], [4, 5, 0]]),\n])\ndef test_fixed_array_write(write1, write2, n1_out, n2_out, buffer_out):\n    """"""Run tests for the FixedArrayWriter.write method.""""""\n    buffer = np.zeros_like(buffer_out, dtype=np.float32)\n    writer = FixedArrayWriter(buffer)\n\n    n = writer.write(np.array(write1, dtype=np.float32))\n    assert n == n1_out\n    n = writer.write(np.array(write2, dtype=np.float32))\n    assert n == n2_out\n\n    assert_almost_equal(buffer, buffer_out)\n\n\n@pytest.mark.parametrize(""write1, write2, n1_out, n2_out, buffer_out"", [\n    ([[], []], [[], []], 0, 0, [[], []]),\n\n    ([[1, 2, 3], [4, 5, 6]], [[], []], 3, 0, [[1, 2, 3], [4, 5, 6]]),\n    ([[1, 2], [4, 5]], [[3], [6]], 2, 1, [[1, 2, 3], [4, 5, 6]]),\n    ([[1], [4]], [[2, 3], [5, 6]], 1, 2, [[1, 2, 3], [4, 5, 6]]),\n    ([[], []], [[1, 2, 3], [4, 5, 6]], 0, 3, [[1, 2, 3], [4, 5, 6]]),\n\n    ([[1, 2], [4, 5]], [[], []], 2, 0, [[1, 2], [4, 5]]),\n])\ndef test_array_write(write1, write2, n1_out, n2_out, buffer_out):\n    """"""Run tests for the ArrayWriter.write method.""""""\n    writer = ArrayWriter(len(write1))\n\n    n = writer.write(np.array(write1, dtype=np.float32))\n    assert n == n1_out\n    n = writer.write(np.array(write2, dtype=np.float32))\n    assert n == n2_out\n\n    assert_almost_equal(writer.data, buffer_out)\n'"
tests/unit/utils/test_cbuffer.py,9,"b'# -*- coding: utf-8 -*-\n\n""""""\nTests for the audiotsm.utils.cbuffer package.\n""""""\n\nimport pytest\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\n\nfrom audiotsm.io.array import ArrayReader, FixedArrayWriter\nfrom audiotsm.utils import CBuffer\n\n\ndef generate_cbuffers(array, ready, max_length):\n    """"""Generate different CBuffers containing the same data as ``array``.""""""\n    array = np.array(array)\n    for i in range(0, max_length):\n        buffer = CBuffer(array.shape[0], max_length)\n\n        # Add and remove i samples to rotate the buffer\n        buffer.right_pad(i)\n        buffer.remove(i)\n\n        buffer.right_pad(array.shape[1])\n        buffer.add(array)\n        buffer.set_ready(ready)\n        yield buffer\n\n\ndef generate_test_cases(cases):\n    """"""For each tuple (data, ready, max_length, *params) of an array, generate\n    multiple test cases (buffer, *params), where buffer is a CBuffer containing\n    ``data``.""""""\n    for case in cases:\n        for buffer in generate_cbuffers(*case[:3]):\n            yield (buffer,) + case[3:]\n\n\n@pytest.mark.parametrize(""in_buffer, add, out"", generate_test_cases([\n    ([[]], 0, 0, [[]], [[]]),\n    ([[]], 0, 2, [[]], [[]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 3, [[], []], [[1, 2, 3], [4, 5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 5, [[], []], [[1, 2, 3], [4, 5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 3, [[0.25, -0.25], [0.5, -0.5]],\n     [[1.25, 1.75, 3], [4.5, 4.5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 5, [[0.25, -0.25], [0.5, -0.5]],\n     [[1.25, 1.75, 3], [4.5, 4.5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 3, [[0.25, 0, -0.25], [0.5, 0, -0.5]],\n     [[1.25, 2, 2.75], [4.5, 5, 5.5]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 5, [[0.25, 0, -0.25], [0.5, 0, -0.5]],\n     [[1.25, 2, 2.75], [4.5, 5, 5.5]]),\n]))\ndef test_cbuffer_add(in_buffer, add, out):\n    """"""Run tests for the CBuffer.add method.""""""\n    in_buffer.add(np.array(add))\n    assert_almost_equal(in_buffer.to_array(), np.array(out))\n\n\n@pytest.mark.parametrize(""in_buffer, array, out"", generate_test_cases([\n    ([[]], 0, 0, [], [[]]),\n    ([[]], 0, 2, [], [[]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 3, [], [[1, 2, 3], [4, 5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 5, [], [[1, 2, 3], [4, 5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 3, [0.5], [[2, 2, 3], [8, 5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 3, [0.5, 0.25], [[2, 8, 3], [8, 20, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 3, [0.5, 0.25, 3], [[2, 8, 1], [8, 20, 2]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 5, [0.5], [[2, 2, 3], [8, 5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 5, [0.5, 0.25], [[2, 8, 3], [8, 20, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], 3, 5, [0.5, 0.25, 3], [[2, 8, 1], [8, 20, 2]]),\n]))\ndef test_cbuffer_divide(in_buffer, array, out):\n    """"""Run tests for the CBuffer.divide method.""""""\n    in_buffer.divide(np.array(array))\n    assert_almost_equal(in_buffer.to_array(), np.array(out))\n\n\n@pytest.mark.parametrize(\n    ""in_buffer, out_buffer, out_n, remaining_data"",\n    generate_test_cases([\n        ([[]], 0, 0, [[]], 0, [[]]),\n        ([[]], 0, 2, [[]], 0, [[]]),\n        ([[]], 0, 0, [[0, 0]], 0, [[]]),\n        ([[]], 0, 2, [[0, 0]], 0, [[]]),\n\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[], []], 0, [[1, 2, 3], [4, 5, 6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[1], [4]], 1, [[2, 3], [5, 6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[1, 2], [4, 5]], 2, [[3], [6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[1, 2, 3], [4, 5, 6]], 3, [[], []]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[1, 2, 3, 0], [4, 5, 6, 0]], 3,\n         [[], []]),\n\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[], []], 0, [[1, 2, 3], [4, 5, 6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[1], [4]], 1, [[2, 3], [5, 6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[1, 2], [4, 5]], 2, [[3], [6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[1, 2, 3], [4, 5, 6]], 3, [[], []]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[1, 2, 3, 0], [4, 5, 6, 0]], 3,\n         [[], []]),\n\n        ([[1, 2, 3], [4, 5, 6]], 2, 3, [[], []], 0, [[1, 2], [4, 5]]),\n        ([[1, 2, 3], [4, 5, 6]], 2, 3, [[1], [4]], 1, [[2], [5]]),\n        ([[1, 2, 3], [4, 5, 6]], 2, 3, [[1, 2], [4, 5]], 2, [[], []]),\n        ([[1, 2, 3], [4, 5, 6]], 2, 3, [[1, 2, 0], [4, 5, 0]], 2, [[], []]),\n        ([[1, 2, 3], [4, 5, 6]], 2, 3, [[1, 2, 0, 0], [4, 5, 0, 0]], 2,\n         [[], []]),\n    ]))\ndef test_cbuffer_read(in_buffer, out_buffer, out_n, remaining_data):\n    """"""Run tests for the CBuffer.read method.""""""\n    read_buffer = np.zeros_like(out_buffer, dtype=np.float32)\n    n = in_buffer.read(read_buffer)\n\n    assert n == out_n\n    assert_almost_equal(read_buffer, out_buffer)\n    assert_almost_equal(in_buffer.to_array(), remaining_data)\n\n\n@pytest.mark.parametrize(\n    ""in_buffer, write_buffer, out_n, out_data"",\n    generate_test_cases([\n        ([[]], 0, 0, [[]], 0, [[]]),\n        ([[], []], 0, 0, [[], []], 0, [[], []]),\n        ([[], []], 0, 0, [[1, 2], [3, 4]], 0, [[], []]),\n        ([[], []], 0, 1, [[1, 2], [3, 4]], 1, [[1], [3]]),\n        ([[], []], 0, 2, [[1, 2], [3, 4]], 2, [[1, 2], [3, 4]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[7, 8], [9, 0]], 0,\n         [[1, 2, 3], [4, 5, 6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 4, [[7, 8], [9, 0]], 1,\n         [[1, 2, 3, 7], [4, 5, 6, 9]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[7, 8], [9, 0]], 2,\n         [[1, 2, 3, 7, 8], [4, 5, 6, 9, 0]]),\n    ]))\ndef test_cbuffer_read_from(in_buffer, write_buffer, out_n, out_data):\n    """"""Run tests for the CBuffer.write method.""""""\n    reader = ArrayReader(np.array(write_buffer))\n    n = in_buffer.read_from(reader)\n\n    assert n == out_n\n    assert_almost_equal(in_buffer.to_array(), out_data)\n\n\n@pytest.mark.parametrize(\n    ""in_buffer, write_buffer, out_n, out_data"",\n    generate_test_cases([\n        ([[]], 0, 0, [[]], 0, [[]]),\n        ([[], []], 0, 0, [[], []], 0, [[], []]),\n        ([[], []], 0, 0, [[1, 2], [3, 4]], 0, [[], []]),\n        ([[], []], 0, 1, [[1, 2], [3, 4]], 1, [[1], [3]]),\n        ([[], []], 0, 2, [[1, 2], [3, 4]], 2, [[1, 2], [3, 4]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[7, 8], [9, 0]], 0,\n         [[1, 2, 3], [4, 5, 6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 4, [[7, 8], [9, 0]], 1,\n         [[1, 2, 3, 7], [4, 5, 6, 9]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[7, 8], [9, 0]], 2,\n         [[1, 2, 3, 7, 8], [4, 5, 6, 9, 0]]),\n    ]))\ndef test_cbuffer_write(in_buffer, write_buffer, out_n, out_data):\n    """"""Run tests for the CBuffer.write method.""""""\n    n = in_buffer.write(np.array(write_buffer))\n\n    assert n == out_n\n    assert_almost_equal(in_buffer.to_array(), out_data)\n\n\n@pytest.mark.parametrize(\n    ""in_buffer, out_buffer, out_n, remaining_data"",\n    generate_test_cases([\n        ([[]], 0, 0, [[]], 0, [[]]),\n        ([[]], 0, 2, [[]], 0, [[]]),\n        ([[]], 0, 0, [[0, 0]], 0, [[]]),\n        ([[]], 0, 2, [[0, 0]], 0, [[]]),\n\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[], []], 0, [[1, 2, 3], [4, 5, 6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[1], [4]], 1, [[2, 3], [5, 6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[1, 2], [4, 5]], 2, [[3], [6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[1, 2, 3], [4, 5, 6]], 3, [[], []]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 3, [[1, 2, 3, 0], [4, 5, 6, 0]], 3,\n         [[], []]),\n\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[], []], 0, [[1, 2, 3], [4, 5, 6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[1], [4]], 1, [[2, 3], [5, 6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[1, 2], [4, 5]], 2, [[3], [6]]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[1, 2, 3], [4, 5, 6]], 3, [[], []]),\n        ([[1, 2, 3], [4, 5, 6]], 3, 5, [[1, 2, 3, 0], [4, 5, 6, 0]], 3,\n         [[], []]),\n\n        ([[1, 2, 3], [4, 5, 6]], 2, 3, [[], []], 0, [[1, 2], [4, 5]]),\n        ([[1, 2, 3], [4, 5, 6]], 2, 3, [[1], [4]], 1, [[2], [5]]),\n        ([[1, 2, 3], [4, 5, 6]], 2, 3, [[1, 2], [4, 5]], 2, [[], []]),\n        ([[1, 2, 3], [4, 5, 6]], 2, 3, [[1, 2, 0], [4, 5, 0]], 2, [[], []]),\n        ([[1, 2, 3], [4, 5, 6]], 2, 3, [[1, 2, 0, 0], [4, 5, 0, 0]], 2,\n         [[], []]),\n    ]))\ndef test_cbuffer_write_to(in_buffer, out_buffer, out_n, remaining_data):\n    """"""Run tests for the CBuffer.read method.""""""\n    read_buffer = np.zeros_like(out_buffer, dtype=np.float32)\n    writer = FixedArrayWriter(read_buffer)\n    n = in_buffer.write_to(writer)\n\n    assert n == out_n\n    assert_almost_equal(read_buffer, out_buffer)\n    assert_almost_equal(in_buffer.to_array(), remaining_data)\n'"
tests/unit/utils/test_normalizebuffer.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""\nTests for the audiotsm.utils.normalizebuffer package.\n""""""\n\nimport pytest\nfrom numpy.testing import assert_almost_equal\n\nfrom audiotsm.utils import NormalizeBuffer\n\n\ndef generate_normalize_buffers(array):\n    """"""Generate different NormalizeBuffers containing the same data as\n    ``array``.""""""\n    for i in range(0, len(array)):\n        buffer = NormalizeBuffer(len(array))\n        buffer.remove(i)\n        buffer.add(array)\n        yield buffer\n\n\ndef generate_test_cases(cases):\n    """"""For each tuple (data, *params) of an array, generate multiple test cases\n    (buffer, *params), where buffer is a NormalizeBuffer containing\n    ``data``.""""""\n    for case in cases:\n        for buffer in generate_normalize_buffers(case[0]):\n            yield (buffer,) + case[1:]\n\n\n@pytest.mark.parametrize(""buffer, window, out"", generate_test_cases([\n    ([], [], []),\n    ([0.5, 1.5, 2.5], [0.25, 0, -0.25], [0.75, 1.5, 2.25]),\n    ([0.5, 1.5, 2.5, 3.5, 4.5], [0.25, 0, -0.25], [0.75, 1.5, 2.25, 3.5, 4.5])\n]))\ndef test_normalize_buffer_add(buffer, window, out):\n    """"""Run tests for the NormalizeBuffer.add method.""""""\n    buffer.add(window)\n    assert_almost_equal(buffer.to_array(), out)\n\n\n@pytest.mark.parametrize(""buffer, n, out"", generate_test_cases([\n    ([], 0, []),\n    ([1], 0, [1]),\n    ([1], 1, [0]),\n    ([1, 0.75, 0.5], 0, [1, 0.75, 0.5]),\n    ([1, 0.75, 0.5], 1, [0.75, 0.5, 0]),\n    ([1, 0.75, 0.5], 2, [0.5, 0, 0]),\n    ([1, 0.75, 0.5], 3, [0, 0, 0]),\n    ([1, 0.75, 0.5], 4, [0, 0, 0]),\n]))\ndef test_normalize_buffer_remove(buffer, n, out):\n    """"""Run tests for the NormalizeBuffer.remove method.""""""\n    buffer.remove(n)\n    assert_almost_equal(buffer.to_array(), out)\n\n\n@pytest.mark.parametrize(""buffer, start, end, out"", generate_test_cases([\n    ([], 0, 0, []),\n    ([1], 0, 0, []),\n    ([1], 0, 1, [1]),\n    ([1, 0.75, 0.5], 0, 0, []),\n    ([1, 0.75, 0.5], 0, 1, [1]),\n    ([1, 0.75, 0.5], 0, 2, [1, 0.75]),\n    ([1, 0.75, 0.5], 0, 3, [1, 0.75, 0.5]),\n    ([1, 0.75, 0.5], 1, 1, []),\n    ([1, 0.75, 0.5], 1, 2, [0.75]),\n    ([1, 0.75, 0.5], 1, 3, [0.75, 0.5]),\n    ([1, 0.75, 0.5], 2, 2, []),\n    ([1, 0.75, 0.5], 2, 3, [0.5]),\n    ([1, 0.75, 0.5], 3, 3, []),\n]))\ndef test_normalize_buffer_to_array(buffer, start, end, out):\n    """"""Run tests for the NormalizeBuffer.to_array method.""""""\n    assert_almost_equal(buffer.to_array(start, end), out)\n'"
tests/unit/utils/test_windows.py,6,"b'# -*- coding: utf-8 -*-\n\n""""""\nTests for the audiotsm.utils.windows package.\n""""""\n\nimport pytest\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\n\nfrom audiotsm.utils import windows\n\n\n@pytest.mark.parametrize(""buffer, window, out"", [\n    ([[]], None, [[]]),\n    ([[]], [], [[]]),\n    ([[1, 2, 3], [4, 5, 6]], None, [[1, 2, 3], [4, 5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], [1, 1, 1], [[1, 2, 3], [4, 5, 6]]),\n    ([[1, 2, 3], [4, 5, 6]], [2, 0.5, 1], [[2, 1, 3], [8, 2.5, 6]]),\n])\ndef test_apply(buffer, window, out):\n    """"""Run tests for apply.""""""\n    buffer = np.array(buffer, dtype=np.float32)\n    windows.apply(buffer, window)\n    assert_almost_equal(buffer, np.array(out))\n\n\n@pytest.mark.parametrize(""length, window"", [\n    (0, []),\n    (1, [0.]),\n    (3, [0, 0.75, 0.75]),\n    (4, [0, 0.5, 1, 0.5]),\n    (8, [0, 0.14644661, 0.5, 0.85355339, 1, 0.85355339, 0.5, 0.146446611]),\n])\ndef test_hanning(length, window):\n    """"""Run tests for hanning.""""""\n    assert_almost_equal(windows.hanning(length), np.array(window))\n\n\n@pytest.mark.parametrize(""window1, window2, out"", [\n    (None, None, None),\n    (None, [], []),\n    (None, [1, 2], [1, 2]),\n    ([], None, []),\n    ([1, 2], None, [1, 2]),\n    ([1, 2], [3, 4], [3, 8]),\n])\ndef test_product(window1, window2, out):\n    """"""Run tests for product.""""""\n    if window1 is not None:\n        window1 = np.array(window1)\n    if window2 is not None:\n        window2 = np.array(window2)\n\n    if out is None:\n        assert windows.product(window1, window2) is None\n    else:\n        assert_almost_equal(windows.product(window1, window2), np.array(out))\n'"
