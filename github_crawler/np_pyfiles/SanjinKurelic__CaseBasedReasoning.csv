file_path,api_count,code
CalculateIV.py,0,"b'import pandas\nimport numpy\n\n\nclass ScriptSetting:\n    csv_file_name = \'telecom.csv\'\n    csv_separator = \',\'\n    csv_null_values = \'null\'\n    csv_true_values = \'true\'\n    csv_false_values = \'false\'\n    columns_out_of_prediction = [\'customerId\']\n    missing_column = \'customerAge\'\n    missing_column_range = [14, 18, 28, 35, 40, 60, 150]\n    negative_influence = \'negative\'\n    positive_influence = \'positive\'\n\n\ndef load_data_frame_from_csv(file_name):\n    data_frame = pandas.read_csv(file_name,\n                                 sep=ScriptSetting.csv_separator,\n                                 na_values=ScriptSetting.csv_null_values,\n                                 true_values=ScriptSetting.csv_true_values,\n                                 false_values=ScriptSetting.csv_false_values\n                                 )\n\n    print(""Number of rows: "" + str(len(data_frame.index)))\n    print(""Number of columns: "" + str(len(data_frame.columns)))\n    return data_frame\n\n\n# Return list of columns that contain missing values\ndef get_missing_columns(data_frame):\n    return data_frame.columns[data_frame.isna().any()].tolist()\n\n\ndef subset_columns(data_frame, columns):\n    return [column for column in data_frame.columns if column not in columns]\n\n\n# Convert all string columns to numerical columns by adding numerical categories\ndef columns_to_number(data_frame):\n    for column in data_frame.select_dtypes(exclude=[numpy.number, numpy.bool_]).columns:\n        data_frame[column] = pandas.Series(data_frame.loc[:, column].astype(\'category\').cat.codes,\n                                           index=data_frame.index)\n    return data_frame\n\n\n# Normalize all numeric columns that do not contain null values (Z-scaling)\ndef normalize_data(data_frame):\n    # Non-null columns\n    columns = subset_columns(data_frame, get_missing_columns(data_frame) + ScriptSetting.columns_out_of_prediction)\n    # Numerical columns\n    for column in data_frame[columns].select_dtypes(include=numpy.number).columns:\n        data_frame[column] = (data_frame[column] - data_frame[column].mean()) / data_frame[column].std(ddof=0)\n    return data_frame\n\n\n# List of columns for which we will count Euclid distance\ndef get_predict_columns(data_frame):\n    return subset_columns(data_frame, [ScriptSetting.missing_column] + ScriptSetting.columns_out_of_prediction)\n\n\n# Calculating Information Value (IV) and Weight of Evidence (WoE) for every column\ndef count_iv_woe(data_frame, age_range):\n    column_influence = {ScriptSetting.positive_influence: {}, ScriptSetting.negative_influence: {}}\n\n    # Make copy of data frame and add target variable\n    df_iv_woe = data_frame.copy()\n    age_range_name = str(age_range).replace(\']\', \'\').replace(\', \', \'-\').replace(\'(\', \'\')\n    age_range_name = \'range_\' + age_range_name\n    df_iv_woe[age_range_name] = \'F\'\n    # Set target variable to current age range\n    df_iv_woe.loc[df_iv_woe[ScriptSetting.missing_column] == age_range, age_range_name] = \'T\'\n\n    # For each column calculate IV and Woe\n    for column in get_predict_columns(data_frame):\n        i_v = pandas.crosstab(df_iv_woe[column], df_iv_woe[age_range_name]).apply(lambda c: c / c.sum(), axis=0)\n        i_v = i_v.replace(0.0, 0.00001)\n\n        i_v[\'WoE\'] = numpy.log(i_v[\'T\'] / i_v[\'F\'])\n        i_v[\'IV\'] = (i_v[\'T\'] - i_v[\'F\']) * numpy.log(i_v[\'T\'] / i_v[\'F\'])\n\n        # If we have variables with IV > 0.5, add them to influence columns\n        if len(i_v[i_v[\'IV\'] > 0.5].index) > 0:\n            for IV_index, IV_row in i_v[i_v[\'IV\'] > 0.5].iterrows():\n                influence_type = ScriptSetting.positive_influence\n                # If WoE is negative, this variable has the opposite result than target variable\n                if IV_row[\'WoE\'] < 0:\n                    influence_type = ScriptSetting.negative_influence\n\n                column_influence[influence_type][column] = IV_index\n\n    return column_influence\n\n\n# Group data in ranges\ndef group_data(data_frame):\n    columns_group = get_predict_columns(data_frame)\n    df_ranged = data_frame.copy()\n    # For every numeric column, we create 5 (or less) ranges\n    for column in df_ranged[columns_group].select_dtypes(include=numpy.number).columns:\n        column_bin = pandas.qcut(df_ranged[column], 5, duplicates=\'drop\')\n        df_ranged[column] = column_bin\n\n    # We have grouped missing column in special defined ranges\n    age_bin = pandas.cut(df_ranged[ScriptSetting.missing_column], ScriptSetting.missing_column_range)\n    df_ranged[ScriptSetting.missing_column] = age_bin\n\n    column_influence = {}\n    # For every age range calculates influence of other columns\n    for age_id, age_range in age_bin.drop_duplicates().iteritems():\n        if pandas.isnull(age_range):\n            continue\n\n        column_influence[age_range] = count_iv_woe(df_ranged, age_range)\n\n    return column_influence\n\n\ndef start():\n    pandas.set_option(\'display.max_columns\', None)\n    df = load_data_frame_from_csv(ScriptSetting.csv_file_name)\n\n    # Normalize (z-scale) all numeric columns except columns containing missing values\n    normalize_data(df)\n\n    # Transform all alpha columns to number columns\n    columns_to_number(df)\n\n    # Remove all missing rows except the one in the defining missing column\n    columns = get_missing_columns(df)\n    columns.remove(ScriptSetting.missing_column)\n    df = df.dropna(subset=columns).copy()\n\n    # Get columns that influences missing column\n    column_influences = group_data(df)\n    # Output dictionary in user readable form\n    for a_range, influences in column_influences.items():\n        print(\'\\n\' + str(a_range) + \':\')\n        if len(influences[ScriptSetting.positive_influence]) > 0:\n            print(\'Positive influence:\')\n            for variable, value in influences[ScriptSetting.positive_influence].items():\n                print(str(variable) + \' = \' + str(value))\n        else:\n            print(\'There is no positive influence\')\n\n        if len(influences[ScriptSetting.negative_influence]) > 0:\n            print(\'Opposite influence:\')\n            for variable, value in influences[ScriptSetting.negative_influence].items():\n                print(str(variable) + \' = \' + str(value))\n        else:\n            print(\'There is no opposite influence\')\n\n\nif __name__ == ""__main__"":\n    start()\n'"
FindMissingValues.py,0,"b'import pandas\nimport numpy\nimport math\n\n\nclass ScriptSetting:\n    csv_file_name = \'telecom.csv\'\n    csv_separator = \',\'\n    csv_null_values = \'null\'\n    csv_true_values = \'true\'\n    csv_false_values = \'false\'\n    column_identifier = \'customerId\'\n    columns_out_of_prediction = [\'customerId\']\n\n\ndef load_data_frame_from_csv(file_name):\n    data_frame = pandas.read_csv(file_name,\n                                 sep=ScriptSetting.csv_separator,\n                                 na_values=ScriptSetting.csv_null_values,\n                                 true_values=ScriptSetting.csv_true_values,\n                                 false_values=ScriptSetting.csv_false_values\n                                 )\n\n    print(""Number of rows: "" + str(len(data_frame.index)))\n    print(""Number of columns: "" + str(len(data_frame.columns)))\n    return data_frame\n\n\n# Return list of columns that contain missing values\ndef get_missing_columns(data_frame):\n    return data_frame.columns[data_frame.isna().any()].tolist()\n\n\n# Return only columns in defining criteria\ndef subset_columns(data_frame, columns):\n    return [column for column in data_frame.columns if column not in columns]\n\n\n# Convert all string columns to numerical columns by adding numerical categories\ndef columns_to_number(data_frame):\n    for column in data_frame.select_dtypes(exclude=[numpy.number, numpy.bool_]).columns:\n        data_frame[column] = pandas.Series(data_frame.loc[:, column].astype(\'category\').cat.codes,\n                                           index=data_frame.index)\n    return data_frame\n\n\n# Normalize all numeric columns that do not contain null values (Z-scaling)\ndef normalize_data(data_frame):\n    # Non-null columns\n    columns = subset_columns(data_frame, get_missing_columns(data_frame) + ScriptSetting.columns_out_of_prediction)\n    # Numerical columns\n    for column in data_frame[columns].select_dtypes(include=numpy.number).columns:\n        data_frame[column] = (data_frame[column] - data_frame[column].mean()) / data_frame[column].std(ddof=0)\n    return data_frame\n\n\n# List of columns for which we will count Euclid distance\ndef get_predict_columns(data_frame, missing_column):\n    return subset_columns(data_frame, [missing_column] + ScriptSetting.columns_out_of_prediction)\n\n\n# Calculate Euclid distance\ndef euclid_distance(data_frame, missing_column):\n    # All rows except missing ones for missing_column\n    df_removed_missing_rows = data_frame.dropna(subset=[missing_column]).copy()\n    # All rows that contain missing values for missing_column\n    df_missing_rows = data_frame[data_frame.isnull().unstack()[missing_column]].copy()\n    # Columns that we will use for calculating euclid distance\n    columns = get_predict_columns(data_frame, missing_column)\n    # Found values that we return\n    found_values = {}\n\n    # For every row that is not missing value\n    for index_missing, df_missing_row in df_missing_rows.iterrows():\n        value = \'\'\n        min_distance = None\n\n        # For every row that do not contain missing values\n        for index_removed, df_removed_row in df_removed_missing_rows.iterrows():\n            current_distance = 0\n\n            # (a1 - b1)^2 + (a2 - b2)^2 + ... + (an - bn)^2\n            for column in columns:\n                current_distance += math.pow(df_missing_row[column] - df_removed_row[column], 2)\n            # sqrt from up expression\n            current_distance = math.sqrt(current_distance)\n\n            # If that is min distance save it\n            if (min_distance is None) or (min_distance > current_distance):\n                min_distance = current_distance\n                value = df_removed_row[missing_column]\n\n        # Save founded values\n        found_values[str(data_frame.loc[index_missing][ScriptSetting.column_identifier])] = str(value)\n\n    return found_values\n\n\ndef start():\n    pandas.set_option(\'display.max_columns\', None)\n    df = load_data_frame_from_csv(ScriptSetting.csv_file_name)\n\n    # Normalize (z-scale) all numerical columns except columns containing missing values\n    normalize_data(df)\n\n    # Transform all alpha columns to numbers\n    columns_to_number(df)\n\n    # Find missing values\n    found_values = {}\n    for missing_column in get_missing_columns(df):\n        found_values.update(euclid_distance(df, missing_column))\n\n    for key, val in found_values.items():\n        print(str(key) + \' => \' + str(val))\n\n\nif __name__ == ""__main__"":\n    start()\n'"
