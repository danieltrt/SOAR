file_path,api_count,code
cifar_pre_process.py,13,"b'import numpy as np\nimport pickle\nfrom gc import collect\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndef unpickle(file):\n\twith open(file, \'rb\') as fo:\n\t\tcifar_dict = pickle.load(fo, encoding=\'bytes\')\n\treturn cifar_dict\n\ndef one_hot_encode(vec, vals=10):\n\tn = len(vec)\n\ty = np.zeros((n, vals))\n\ty[range(n), vec] = 1\n\treturn y\n\ndef normalize(x):\n\tmn=x.min()\n\tmx=x.max()\n\tx = (x-mn)/(mx-mn)\n\treturn x\n\n#Class to handel the dataset\nclass CifarPreProcess():\n\tdef __init__(self,CIFAR_DIR = \'../cifar-10-batches-py/\'):\n\t\tself.CIFAR_DIR=CIFAR_DIR\n\t\tfiles = [\'batches.meta\',\'data_batch_1\',\'data_batch_2\',\'data_batch_3\',\'data_batch_4\',\'data_batch_5\',\'test_batch\']\n\n\t\tself.all_data = []\n\n\t\tfor i,fname in enumerate(files):\n\t\t\tself.all_data.append(unpickle(self.CIFAR_DIR+fname))\n\n\t\tself.names = self.all_data[0][b\'label_names\']\n\t\tfor i,nm in enumerate(self.names):\n\t\t\tself.names[i]=nm.decode(""utf-8"")\n\t\tself.st = 0\n\t\tself.train_len = 0\n\t\t\n\t\tself.training_images = None\n\t\tself.training_labels = None\n\t\t\n\t\tself.test_images = None\n\t\tself.test_labels = None\n\n\t\tself.itr_train = None\n\t\n\tdef set_up_images(self):\n\t\t\n\t\tprint(""Setting Up Training Images and Labels"")\n\t\t\n\t\t# Vertically stacks the training images\n\t\tself.training_images = np.vstack([d[b\'data\'] for d in self.all_data[1:-1]])\n\t\tself.train_len = self.training_images.shape[0]\n\t\tself.training_images = normalize(self.training_images.reshape(self.train_len,3,32,32).transpose(0,2,3,1))\n\t\tself.training_images = self.training_images.astype(np.float32)\n\t\t# One hot Encodes the training labels (e.g. [0,0,0,1,0,0,0,0,0,0])\n\t\tself.training_labels = one_hot_encode(np.hstack([d[b""labels""] for d in self.all_data[1:-1]]), 10)\n\n\t\tprint(""Setting Up Test Images and Labels"")\n\n\t\t# Vertically stacks the test images\n\t\tself.test_images = np.vstack([d[b""data""] for d in [self.all_data[-1]]])\n\t\ttest_len = self.test_images.shape[0]\n\t\tself.test_images = normalize(self.test_images.reshape(test_len,3,32,32).transpose(0,2,3,1))\n\t\tself.test_images = self.test_images.astype(np.float32)\n\t\t# One hot Encodes the test labels (e.g. [0,0,0,1,0,0,0,0,0,0])\n\t\tself.test_labels = one_hot_encode(np.hstack([d[b""labels""] for d in [self.all_data[-1]]]), 10)\n\t\tself.shuffle_datasets()\n\t\tself.all_data=None\n\t\tcollect()\n\n\tdef shuffle_datasets(self):\n\t\tidxs = np.arange(len(self.training_images))\n\t\tnp.random.shuffle(idxs)\n\t\tself.training_images = self.training_images[idxs]\n\t\tself.training_labels = self.training_labels[idxs]\n\t\tidxs = np.arange(len(self.test_images))\n\t\tnp.random.shuffle(idxs)\n\t\tself.test_images = self.test_images[idxs]\n\t\tself.test_labels = self.test_labels[idxs]\n\n\tdef data_augment(self,batch_size=64):\n\t\tself.batch_size=batch_size\n\t\tself.datagen = ImageDataGenerator(\n\t\t\trotation_range=15,\n\t\t\twidth_shift_range=0.1,\n\t\t\theight_shift_range=0.1,\n\t\t\thorizontal_flip=True,\n\t\t\t)\n\t\tself.datagen.fit(self.training_images)\n\t\tself.itr_train = self.datagen.flow(self.training_images, self.training_labels, batch_size=batch_size)\n\t\tcollect()\n\t\treturn self.itr_train\n\n\tdef make_dataset_from_iterator(self):\n\t\tif self.itr_train is None:\n\t\t\treturn None\n\t\tsteps=self.training_images.shape[0]//self.batch_size\n\t\tINP=np.empty((steps,self.batch_size,*self.training_images.shape[1:]),dtype=np.float32)\n\t\tLBL=np.empty((steps,self.batch_size,*self.training_labels.shape[1:]),dtype=np.float32)\n\t\tfor idx in range(steps):\n\t\t\ttry:\n\t\t\t\tINP[idx],LBL[idx]=self.itr_train.next()\n\t\t\texcept ValueError:\n\t\t\t\tINP[idx],LBL[idx]=self.itr_train.next()\n\t\treturn INP.reshape(-1,*self.training_images.shape[1:]),LBL.reshape(-1,*self.training_labels.shape[1:])\n\n\tdef batch_gen(self,size,ck=0):\n\t\tif not ck:\n\t\t\tck=self.st\n\t\t\tself.st = (self.st + size) % self.train_len\n\t\tx = self.training_images[ck:ck+size].reshape(-1,32,32,3)\n\t\ty = self.training_labels[ck:ck+size]\n\t\treturn x, y'"
nnet/__init__.py,0,b''
nnet/autodiff.py,0,b'#!/usr/bin/env python3'
nnet/autograd.py,0,b'#!/usr/bin/env python3'
nnet/cnn_old.py,29,"b'#!/usr/bin/env python3\nimport numpy as np\n\n## THIS FILE IS OLD VERSION - REMOVED FROM MASTER\n\nsd=np.random.randint(1000)\n# print(sd)\nnp.random.seed(sd)\t#470\n\nclass conv_net:\n\tdef __init__(self):\n\t\tself.learning_rate=0.01\n\n\tdef init_kernel_bias(self, num_inp_channels, kernel_size, num_kernels):\n\t\tshape = [num_inp_channels, kernel_size, kernel_size, num_kernels]\n\t\tweights = 0.1*np.random.randn(*shape)\n\t\tbias = 0.5*np.random.randn(1,num_kernels)\n\t\treturn weights, bias\n\n\tdef __str__(self):\n\t\treturn str(self.__dict__)\n\n\tdef sigmoid(self,x):\n\t\tx=np.clip(x,-500,500)\n\t\treturn 1.0/(1+np.exp(-x))\n\n\tdef sigmoid_der(self,x,y):\n\t\treturn x * (1 - x)\n\n\tdef elliot_function( signal, derivative=False ):\n\t\t"""""" A fast approximation of sigmoid """"""\n\t\ts = 1 # steepness\n\t\t\n\t\tabs_signal = (1 + np.abs(signal * s))\n\t\tif derivative:\n\t\t\treturn 0.5 * s / abs_signal**2\n\t\telse:\n\t\t\t# Return the activation signal\n\t\t\treturn 0.5*(signal * s) / abs_signal + 0.5\n\n\tdef relu(self,x):\n\t\tx[x<0]=0\n\t\treturn x\n\n\tdef relu_der(self,x,y):\n\t\treturn (y > 0)\n\n\tdef softmax(self,x):\n\t\t# exps = np.exp(x)\n\t\texps = np.exp(x-np.max(x, axis=1, keepdims = True))\n\t\treturn exps/np.sum(exps, axis=1, keepdims = True)\n\n\tdef soft_der(self,x,y):\n\t\treturn np.ones(self.softmax(x).shape)\n\n\tdef del_cross_soft(self,out,res):\n\t\tres = res.argmax(axis=1)\n\t\tm = res.shape[0]\n\t\tgrad = out\n\t\tgrad[range(m),res]-=1\n\t\tgrad = grad/m\n\t\treturn grad\n\n\tdef normalize(self,x):\n\t\tmn=x.min()\n\t\tmx=x.max()\n\t\tx = (x-mn)/(mx-mn)\n\t\treturn x\n\n\tdef batch_norm(self,aa):\n\t\tgamma=aa.std()\n\t\tbeta=aa.mean()\n\t\tad=(aa-beta)/gamma\t\t\t\t# normalize\n\t\tad=ad*gamma+beta\t\t\t\t# recover\n\t\treturn ad\n\n\tdef conv2d(self,inp,kernels,biases,stride=[1,1],padding=0):\t\t#padding=(ksz-1)/2 for same shape in stride 1\n\t\t#inp[batches,row,col,d],kernels(d,ksz,ksz,num_ker),biases[1,num_ker],stride[row,col]\n\t\tinp=inp.transpose(0,3,1,2)  #inp[batches,d,row,col]\n\t\tksz=kernels.shape[1]\n\t\tnum_ker=kernels.shape[3]\n\t\tif not padding:\t\t\t\t\t\t\t#take care of padding in backprop too\n\t\t\tpadding=(ksz-1)//2\t\t\t\t\t#currently don\'t give \'even\' ksz\n\t\tout_row,out_col=((inp.shape[2]-ksz+2*padding)//stride[0]+1),((inp.shape[3]-ksz+2*padding)//stride[1]+1)\n\t\tbatches,d,row,col=inp.shape\n\t\trow+=2*padding\n\t\tcol+=2*padding\n\t\tpadded=np.zeros((batches,d,row,col))\n\t\tpadded[:,:,padding:-padding,padding:-padding]=inp\n\t\t# Take all windows into a matrix\n\t\tkern = kernels.reshape(-1,num_ker)\n\t\twindow=(np.arange(ksz)[:,None]*row+np.arange(ksz)).ravel()+np.arange(d)[:,None]*row*col\n\t\tslider=(np.arange(out_row*stride[0])[:,None]*row+np.arange(out_col*stride[1]))\n\t\tind = window.ravel()+slider[::stride[0],::stride[1]].ravel()[:,None]\n\t\toutput=np.empty((batches,out_row*out_col,num_ker))\n\t\tfor i,img in enumerate(padded):\t\t#img[d,row,col]\n\t\t\t# windows(out_row*out_col, ksz*ksz*d) . kernels(d*ksz*ksz,num_ker)\n\t\t\toutput[i]=np.dot(np.take(img, ind), kern)+biases\n\t\t# output=np.array([(np.dot(np.take(i,ind),kern)+biases) for i in padded]).reshape(batches,out_row,out_col,num_ker)\n\t\t# bind= np.arange(batches)[:,None]*d*row*col+ind.ravel()\t\t#for batches\n\t\t# output=(np.dot(np.take(padded, bind).reshape(-1,d*ksz*ksz), kern)+biases)\n\t\t\t\t\t# [batches*out_row*out_col,d*ksz*ksz] . [d*ksz*ksz, num_ker]\n\t\treturn output.reshape(batches,out_row,out_col,num_ker)\n\n\tdef conv2d_back(self,errors,inp,kernels,biases,stride=[1,1],layer=1):\t\t\t\t\t\t\t\t#strides[batch,row,col,depth]\n\t\t#errors[batches,esz,esz,num_ker],inp[batches,row,col,d],kernels(d,ksz,ksz,num_ker),biases[1,num_ker],stride[row,col]\n\t\tbatches,esz,esz,num_ker=errors.shape\n\t\tinp=inp.transpose(3,1,2,0)\t\t#inp[d,row,col,batches]\n\t\tflipped=np.flip(kernels,(1,2)).transpose(3,1,2,0)\t#flipped[num_ker,ksz,ksz,d]\n\t\tksz=flipped.shape[1]\n\t\tpad=(ksz-1)//2\n\t\td_kernels=self.conv2d(inp,errors,0,padding=pad)\n\t\td_kernels/=batches\t\t#take mean change over batches\n\t\t# Backprop for inp.\t\terrors[batches,esz,esz,num_ker]\tflipped[num_ker,ksz,ksz,d]\n\t\tif layer:\n\t\t\td_inputs=self.conv2d(errors,flipped,0)\n\t\telse:\n\t\t\td_inputs=0\n\t\td_bias=errors.reshape(-1,num_ker).mean(axis=0)[None,:]\n\n\t\treturn d_inputs, d_kernels*self.learning_rate, d_bias*self.learning_rate\n\n\tdef max_pool(self,inp,ksize=[2,2],stride=[2,2]):\n\t\t#inp[batches,row,col,d], kernels[ksz,ksz], stride[row,col]\n\t\tksz=ksize[0]\n\t\tbatches,row,col,d=inp.shape\n\t\tout_row,out_col=row//ksz,col//ksz\n\t\tipp=inp.reshape(batches,out_row,ksz,out_col,ksz,d)\n\t\toutput=ipp.max(axis=(2,4),keepdims=True)\n\t\tmask=((ipp-output)==0)\n\t\t#[batches,o_row,o_col,d]\n\t\treturn output.squeeze().reshape(batches,out_row,out_col,d), mask\n\n\tdef max_pool_back(self,errors,inp,mask,ksize=[2,2],stride=[2,2]):\n\t\t#errors[batches,esz,esz,d],inp[batches,row,col,d],kernels[ksz,ksz],stride[row,col]\n\t\tksz=ksize[0]\n\t\tbatches,row,col,d=inp.shape\n\t\tout_row,out_col=row//ksz,col//ksz\n\t\treturn (mask*errors.reshape(batches,out_row,1,out_col,1,d)).reshape(inp.shape)'"
nnet/coled_tracker.py,4,"b'#!/usr/bin/env python3\nimport numpy as np\nfrom gc import collect\n\n# For a single shared large memory block to reuse and not repeat allocation\n\n# FIX: If new mem is allocated. Remove the self from objs\n\nclass coled_tracker:\n\tdef __init__(self):\n\t\tself.dtype=np.float32\n\t\tself.objs=set()\n\t\tself.COLED=None\n\n\tdef alloc(self,coled_size,obj):\n\t\ttry:\n\t\t\tself.objs.remove(obj)\n\t\texcept:\n\t\t\tpass\n\t\tif self.COLED is None:\n\t\t\tself.COLED=np.empty(coled_size,dtype=self.dtype)\n\t\t\tfor oo in self.objs:\n\t\t\t\ttry:\n\t\t\t\t\too.coled=self.COLED.ravel()[:oo.coled.size].reshape(oo.coled.shape)\n\t\t\t\texcept:\n\t\t\t\t\tself.objs.remove(oo)\n\t\t\tself.objs.add(obj)\n\t\t\treturn self.COLED\n\t\telse:\n\t\t\tif self.COLED.size>=coled_size:\n\t\t\t\tself.objs.add(obj)\n\t\t\t\treturn self.COLED.ravel()[:coled_size]\n\t\t\telse:\n\t\t\t\tself.COLED=np.empty(coled_size,dtype=self.dtype)\n\t\t\t\tfor oo in self.objs:\n\t\t\t\t\ttry:\n\t\t\t\t\t\too.coled=self.COLED.ravel()[:oo.coled.size].reshape(oo.coled.shape)\n\t\t\t\t\texcept:\n\t\t\t\t\t\tself.objs.remove(oo)\n\t\t\t\tself.objs.add(obj)\n\t\t\t\treturn self.COLED.ravel()[:coled_size]\n\n\tdef free(self):\n\t\tobs=list(self.objs)\n\t\tmx=obs[0]\n\t\tfor oo in obs:\n\t\t\ttry:\n\t\t\t\tif oo.coled.nbytes>mx.coled.nbytes:\n\t\t\t\t\tmx=oo\n\t\t\texcept:\n\t\t\t\tself.objs.remove(oo)\n\t\tif len(self.objs)>0:\n\t\t\tif self.COLED.nbytes>mx.coled.nbytes:\n\t\t\t\tself.COLED=np.empty(mx.coled.size,dtype=self.dtype)\n\t\t\t\tfor oo in self.objs:\n\t\t\t\t\too.coled=self.COLED.ravel()[:oo.coled.size].reshape(oo.coled.shape)\n\t\tcollect()'"
nnet/functions.py,12,"b'#!/usr/bin/env python3\nimport numpy as np\n\n### CAN TURN THESE INTO CLASSES\n\ndef sigmoid(z,a=None,derivative=False):\n\tif derivative:\n\t\treturn a*(1-a)\n\telse:\n\t\treturn 1.0/(1+np.exp(-z.clip(-88.72283,88.72283)))\n\ndef elliot(z,a=None, derivative=False):\n\t# A fast approximation of sigmoid\n\tabs_signal=(1+np.abs(z))\n\tif derivative:\n\t\treturn 0.5/abs_signal**2\n\telse:\n\t\treturn 0.5/abs_signal+0.5\n\ndef relu(z,a=None,derivative=False):\n\tif derivative:\n\t\treturn z>0\n\telse:\n\t\tz[z<0]=0\n\t\treturn z\n\ndef elu(z,a=None,derivative=False):\t\t\t#alpha is 1\n\tif derivative:\n\t\treturn np.where(z>0, 1, a+1)\n\telse:\n\t\treturn np.where(z>0, z, np.exp(z)-1)#*alpha\n\ndef leakyRelu(z,a=None,derivative=False):\n\talpha=0.2\n\tif derivative:\n\t\t# dz = np.ones_like(z,dtype=np.float32)\n\t\t# dz[z < 0] = alpha\n\t\t# return dz\n\t\treturn np.clip(z > 0, alpha, 1.0)\n\telse:\n\t\treturn np.where(z>0, z, z*alpha)\n\ndef tanh(z,a=None,derivative=False):\n\tif derivative:\n\t\treturn 1-a**2\n\telse:\n\t\treturn np.tanh(z)\n\ndef softmax(z,a=None,derivative=False):\n\tif derivative:\n\t\t# a1*(1-a1)-a1a2\n\t\treturn 1\n\telse:\n\t\texps = np.exp(z-np.max(z, axis=1, keepdims = True))\n\t\treturn exps/np.sum(exps, axis=1, keepdims = True)\n\ndef cross_entropy_with_logits(logits,labels,epsilon=1e-12):\n\treturn -np.sum(labels*np.log(logits+epsilon),axis=0,keepdims=True)\n\ndef cross_entropy(logits,labels,epsilon=1e-12):\n\tlabels=labels.clip(epsilon,1-epsilon)\n\tlogits=logits.clip(epsilon,1-epsilon)\n\treturn -labels*np.log(logits)-(1-labels)*np.log(1-logits)\n\ndef del_cross_sigmoid(logits,labels):\n\treturn (logits-labels)\n\ndef del_cross_soft(logits,labels):\n\treturn (logits-labels)\n\ndef mean_squared_error(logits, labels):\n\treturn ((logits-labels)**2)/2\n\ndef del_mean_squared_error(logits, labels):\n\treturn (logits-labels)\n\ndef echo(z,a=None,derivative=False,**kwargs):\n\treturn z'"
nnet/layers.py,67,"b'#!/usr/bin/env python3\nimport numpy as np\nfrom nnet.functions import *\nfrom nnet.coled_tracker import coled_tracker\nfrom ctypes import CDLL,c_int,c_void_p\nimport os\nimport sys\n\nctake=CDLL(os.path.join(os.path.dirname(__file__),""libctake.so""))\t# gcc nnet/ctake_threaded.c -fPIC -shared -o nnet/libctake.so -O3 -lpthread\nif sys.platform == \'win32\':\n\tNUM_THREADS = int(os.environ[\'NUMBER_OF_PROCESSORS\'])\nelse:\n\tNUM_THREADS = int(os.popen(""nproc"").read())\n\nsd=np.random.randint(1000)\nprint(""Seed:"",sd)\nnp.random.seed(sd)\nseq_instance=None\t\t# fix this. It\'s same for multiple models. Will be fixed by self.previous_layer, or a dict for each instance\nCOLT=coled_tracker()\n\n"""""" \nProlly make parallel C code to pad faster.\n""""""\n\nclass Layer:\n\tdef __init__(self):\n\t\tself.name=self.__class__.__name__\n\t\tself.type=self.__class__.__name__\n\t\tself.dtype=np.float32\n\t\tself.param=0\n\t\tself.activation=echo\n\t\tself.input_layer=None\n\t\tself.output_layers=[]\n\n\tdef __str__(self):\n\t\treturn self.name+super().__str__()\n\n\tdef __call__(self,lyr):\n\t\tself.input_layer=lyr\n\t\tlyr.output_layers.append(self)\n\t\treturn self\n\nclass conv2d(Layer):\n\tdef __init__(self,num_kernels=0,input_shape=None,kernel_size=0,kernels=None,activation=echo,biases=0,stride=[1,1],dilation=[1,1],dlate=[1,1],padding=None,batches=1,backp=True,std=0.01,name=None,out_row=None,out_col=None,off_transpose=0):\t\t#padding=(ksz-1)/2 for same shape in stride 1\n\t\t#input_shape[row,col,channels],kernels(channels,ksz,ksz,num_kernels),biases[1,num_ker],stride[row,col]\n\t\tsuper().__init__()\n\t\tif input_shape is None:\n\t\t\tinput_shape=seq_instance.get_inp_shape()\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tself.activation=activation\n\t\tself.dtype=np.float32\n\t\tself.stride=stride\n\t\tself.type=self.__class__.__name__\n\t\tself.input_shape=input_shape\n\t\tself.row,self.col,self.channels=input_shape\n\t\tself.batches=batches\n\t\tself.kernels=kernels\n\t\tself.biases=biases\n\t\tself.w_m=0\n\t\tself.w_v=0\n\t\tself.b_m=0\n\t\tself.b_v=0\n\t\tself.d_c_b=0\n\t\tif self.kernels is None:\n\t\t\tself.kernel_size=kernel_size\n\t\t\tself.num_kernels=num_kernels\n\t\t\tself.kernels,self.biases = self.init_kernel_bias(self.channels,self.kernel_size,self.num_kernels,std=std)\n\t\telse:\n\t\t\tself.kernel_size=kernels.shape[1]\n\t\t\tself.num_kernels=kernels.shape[3]\n\t\tself.kern = self.kernels.reshape(-1,self.num_kernels)\n\t\tself.weights = self.kernels\n\t\tself.padding=padding\n\t\tself.dilation=dilation\n\t\tself.dlate=dlate\n\t\tself.erow=self.row+(self.row-1)*(self.dlate[0]-1)\n\t\tself.ecol=self.col+(self.col-1)*(self.dlate[1]-1)\n\t\tif self.padding is None:\t\t\t\t\t\t\t#take care of padding in backprop too\n\t\t\tself.padding=(self.kernel_size-1)//2\t\t\t\t\t#currently don\'t give \'even\' kernel_size\n\t\tif out_row is None:\n\t\t\tself.out_row=(self.erow-self.kernel_size+2*self.padding-(self.kernel_size-1)*(self.dilation[0]-1))//stride[0]+1\n\t\telse:\n\t\t\tself.out_row=out_row\n\t\tif out_col is None:\n\t\t\tself.out_col=(self.ecol-self.kernel_size+2*self.padding-(self.kernel_size-1)*(self.dilation[0]-1))//stride[1]+1\n\t\telse:\n\t\t\tself.out_col=out_col\n\t\tself.prow=self.erow+2*self.padding\n\t\tself.pcol=self.ecol+2*self.padding\n\t\tself.padded=np.zeros((self.batches,self.channels,self.prow,self.pcol),dtype=self.dtype)\n\t\tself.param=(self.kernel_size*self.kernel_size*self.channels+1)*self.num_kernels\n\t\t# Take all windows into a matrix\n\t\tself.dksz=self.kernel_size+(self.kernel_size-1)*(self.dilation[0]-1)\n\t\tself.off_transpose=off_transpose\n\t\tif (self.stride[0]+self.stride[1])>2:\n\t\t\tif backp:\n\t\t\t\tif self.off_transpose==0:\n\t\t\t\t\tcuut=self.padding-self.padding//self.stride[0]\n\t\t\t\t\tself.off_transpose=(self.row+2*self.padding)*cuut+cuut\n\t\twindow=(np.arange(self.dksz,step=self.dilation[0])[:,None]*self.prow+np.arange(self.dksz,step=self.dilation[1])).ravel()+np.arange(self.channels)[:,None]*self.prow*self.pcol+self.off_transpose\n\t\tslider=(np.arange(self.out_row*stride[0])[:,None]*self.prow+np.arange(self.out_col*stride[1]))\n\t\tself.ind = window.ravel()+slider[::stride[0],::stride[1]].ravel()[:,None]\n\t\tself.output=np.empty((self.batches,self.out_row*self.out_col,self.num_kernels),dtype=self.dtype)\n\t\t# self.coled=np.empty((self.batches,*self.ind.shape),dtype=self.dtype).reshape(-1,self.channels*self.kernel_size*self.kernel_size)\n\t\tself.coled=COLT.alloc(self.ind.size*self.batches,self).reshape(-1,self.channels*self.kernel_size*self.kernel_size)\n\t\tCOLT.free()\n\t\t# bind= np.arange(self.batches)[:,None]*self.channels*self.prow*self.pcol+self.ind.ravel()\t\t#for self.batches\n\t\tself.shape=(None,self.out_row,self.out_col,self.num_kernels)\n\t\tself.is_not_dker=True\n\t\tself.bias_is_not_0=True\n\t\tif np.isscalar(self.biases):\n\t\t\tif self.biases==0:\n\t\t\t\tself.bias_is_not_0=False\n\t\tif backp:\n\t\t\tself.init_back()\n\n\tdef init_back(self):\t\t\t\t# flipped kernel has same reference as original one so it will be updated automatically with original kernel\n\t\tself.flipped=self.kernels[:,::-1,::-1,:].transpose(3,1,2,0)\t#flipped[num_kernels,kernel_size,kernel_size,channels]\n\t\tif (self.stride[0]+self.stride[1])>2:\n\t\t\tpadk=self.padding\n\t\t\tpadi=self.kernel_size-1\n\t\t\tdistride=[1,1]\n\t\t\toff_transpose_ker=self.off_transpose\n\t\t\toff_transpose_inp=0\n\t\telif (self.dlate[0]+self.dlate[1])>2:\n\t\t\tpadk=self.padding\n\t\t\tpadi=self.kernel_size-1\n\t\t\tdistride=self.dlate\n\t\t\toff_transpose_ker=0\n\t\t\toff_transpose_inp=(self.out_row+2*padi)*padi+padi\n\t\telse:\n\t\t\tpadk=padi=(self.kernel_size-1)//2\n\t\t\tdistride=self.stride\n\t\t\toff_transpose_ker=off_transpose_inp=0\n\t\tgrads=self.output.reshape(self.batches,self.out_row,self.out_col,self.num_kernels)\n\t\tself.d_ker=conv2d(input_shape=(self.row,self.col,self.batches),kernels=grads,activation=echo,dilation=self.stride,dlate=self.dlate,padding=padk,backp=False,off_transpose=off_transpose_ker,out_row=self.kernel_size,out_col=self.kernel_size,batches=self.channels)\n\t\tself.d_ker.is_not_dker=False\n\t\t# self.d_ker.dlate=self.dlate\n\t\tself.d_inp=conv2d(input_shape=(self.out_row,self.out_col,self.num_kernels),kernels=self.flipped,activation=echo,stride=distride,dlate=self.stride,padding=padi,off_transpose=off_transpose_inp,backp=False,out_row=self.row,out_col=self.col)\n\n\tdef init_kernel_bias(self,num_inp_channels, kernel_size, num_kernels,mean=0,std=0.01):\n\t\tweights = std*np.random.randn(num_inp_channels, kernel_size, kernel_size, num_kernels) + mean\n\t\t# weights/=np.sqrt(num_inp_channels)\n\t\tbias = std*np.random.randn(1,num_kernels) + mean\n\t\treturn weights.astype(self.dtype), bias.astype(self.dtype)\n\n\tdef forward(self,inp,training=True):\n\t\tself.inp=inp.transpose(0,3,1,2)\n\t\t#inp[batches,channels,row,col]\n\t\tbatches,channels=self.inp.shape[:2]\n\t\tif (self.channels!=channels) or (self.batches!=batches):\n\t\t\tself.channels=channels\n\t\t\tself.batches=batches\n\t\t\tself.padded=np.zeros((self.batches,self.channels,self.prow,self.pcol),dtype=self.dtype)\n\t\t\tself.dksz=self.kernel_size+(self.kernel_size-1)*(self.dilation[0]-1)\n\t\t\twindow=(np.arange(self.dksz,step=self.dilation[0])[:,None]*self.prow+np.arange(self.dksz,step=self.dilation[1])).ravel()+np.arange(self.channels)[:,None]*self.prow*self.pcol+self.off_transpose\n\t\t\tslider=(np.arange(self.out_row*self.stride[0])[:,None]*self.prow+np.arange(self.out_col*self.stride[1]))\n\t\t\tself.ind = window.ravel()+slider[::self.stride[0],::self.stride[1]].ravel()[:,None]\n\t\t\t# self.coled=np.empty((self.batches,*self.ind.shape),dtype=self.dtype).reshape(-1,self.channels*self.kernel_size*self.kernel_size)\n\t\t\tself.coled=COLT.alloc(self.ind.size*self.batches,self).reshape(-1,self.channels*self.kernel_size*self.kernel_size)\n\t\t\tCOLT.free()\n\t\t\tif not self.is_not_dker:\n\t\t\t\tif self.padding:\n\t\t\t\t\tself.padded[:,:,self.padding:-self.padding:self.dlate[0],self.padding:-self.padding:self.dlate[1]]=self.inp \t# this takes time. FIX \n\t\t\t\telse:\n\t\t\t\t\tself.padded[:,:,::self.dlate[0],::self.dlate[1]]=self.inp\n\t\tif self.is_not_dker:\n\t\t\tif self.padding:\n\t\t\t\tself.padded[:,:,self.padding:-self.padding:self.dlate[0],self.padding:-self.padding:self.dlate[1]]=self.inp \t# this takes time. FIX \n\t\t\telse:\n\t\t\t\tself.padded[:,:,::self.dlate[0],::self.dlate[1]]=self.inp\n\t\tself.kern=self.kernels.reshape(-1,self.num_kernels)\n\t\t# for i,img in enumerate(self.padded):\t\t#img[self.channels,self.row,self.col]\n\t\t\t# windows(out_row*out_col, kernel_size*kernel_size*channels) . kernels(channels*kernel_size*kernel_size,num_kernels)\n\t\t\t# self.output[i]=np.dot(img.take(self.ind), self.kern)\n\t\t# output=np.array([(np.dot(np.take(i,self.ind),self.kern)+self.biases) for i in padded]).reshape(self.batches,self.out_row,self.out_col,self.num_kernels)\n\t\t# output=(np.dot(np.take(padded, bind).reshape(-1,self.channels*kernel_size*kernel_size), self.kern)+self.biases)\n\t\t\t\t\t# [self.batches*self.out_row*self.out_col,self.channels*kernel_size*kernel_size] . [self.channels*kernel_size*kernel_size, self.num_kernels]\n\t\tctake.take(c_void_p(np.ascontiguousarray(self.padded).ctypes.data),c_void_p(self.ind.ctypes.data),c_void_p(self.coled.ctypes.data),c_int(self.batches),c_int(self.padded[0].size),c_int(self.ind.size),c_int(NUM_THREADS))\n\t\tself.output=self.coled.dot(self.kern)\n\t\tif self.bias_is_not_0:\n\t\t\tself.output+=self.biases\n\t\tself.z_out=self.output.reshape(self.batches,self.out_row,self.out_col,self.num_kernels)\n\t\tself.a_out=self.activation(self.z_out)\n\t\treturn self.a_out\n\n\tdef backprop(self,grads,layer=1):\t\t\t\t\t\t\t\t#strides[batch,row,col,depth]\n\t\t#grads[batches,esz,esz,num_kernels],inp[batches,channels,row,col],kernels(channels,kernel_size,kernel_size,num_kernels),biases[1,num_kernels],stride[row,col]\n\t\tif self.activation != echo:\n\t\t\tgrads*=self.activation(self.z_out,self.a_out,derivative=True)\n\t\tself.d_ker.kernels=grads\n\t\tself.d_ker.padded=np.ascontiguousarray(self.padded.transpose(1,0,2,3))\n\t\tself.d_c_w=self.d_ker.forward(self.inp.transpose(1,2,3,0))\t#[channels,row,col,batches]\n\t\t# self.d_c_w/=self.batches\t\t#take mean change over batches\n\t\t# Backprop for inp.\t\tgrads[batches,esz,esz,num_kernels]\tself.flipped[num_kernels,kernel_size,kernel_size,channels]\n\t\tif layer:\n\t\t\td_inputs=self.d_inp.forward(grads)\n\t\telse:\n\t\t\td_inputs=0\n\t\tif self.bias_is_not_0:\n\t\t\tself.d_c_b=self.d_ker.kern.sum(axis=0,keepdims=True)\n\t\t# self.d_c_b=self.d_ker.kern.mean(axis=0,keepdims=True)\n\t\treturn d_inputs\n\nclass conv2dtranspose(conv2d):\n\tdef __init__(self,num_kernels=0,input_shape=None,kernel_size=0,kernels=None,activation=echo,biases=0,stride=[1,1],dilation=[1,1],dlate=[1,1],padding=None,batches=1,backp=True,std=0.01,name=None,out_row=None,out_col=None):\n\t\tif input_shape is None:\n\t\t\tinput_shape=seq_instance.get_inp_shape()\n\t\tout_row=stride[0]*input_shape[0]\n\t\tout_col=stride[1]*input_shape[1]\n\t\tif (stride[0]+stride[1])>2:\n\t\t\tdlate=stride\n\t\t\tstride=[1,1]\n\t\t\tif padding is None:\n\t\t\t\tpadding=(kernel_size+1)//2\n\t\tsuper().__init__(num_kernels=num_kernels,input_shape=input_shape,kernel_size=kernel_size,kernels=kernels,activation=activation,biases=biases,stride=stride,dilation=dilation,dlate=dlate,padding=padding,batches=batches,backp=backp,std=std,name=name,out_row=out_row,out_col=out_col)\n\nclass max_pool(Layer):\n\tdef __init__(self,input_shape=None,ksize=[2,2],stride=[2,2],name=None):\n\t\t#inp[batches,row,col,channels], kernels[ksz,ksz], stride[row,col]\n\t\tsuper().__init__()\n\t\tself.ksz=ksize[0]\n\t\tself.param=0\n\t\tself.dtype=np.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tif input_shape is None:\n\t\t\tinput_shape=seq_instance.get_inp_shape()\n\t\tself.batches=1\n\t\tself.row,self.col,self.channels=input_shape\n\t\tself.rem_col=self.row%self.ksz\n\t\tif self.rem_col:\n\t\t\tself.padded=np.zeros((self.batches,self.row,self.col,self.channels),dtype=self.dtype)\n\t\tself.out_row,self.out_col=self.row//self.ksz,self.col//self.ksz\n\t\tself.row-=self.rem_col\n\t\tself.col-=self.rem_col\n\t\tself.shape=(None,self.out_row,self.out_col,self.channels)\n\t\tself.activation=echo\n\n\tdef forward(self,inp,training=True):\n\t\tself.input_shape=inp.shape\n\t\tbatches=self.input_shape[0]\n\t\tif self.rem_col:\n\t\t\tinp=inp[:,:-self.rem_col,:-self.rem_col,:]\n\t\t\tif self.batches!=batches:\n\t\t\t\tself.padded=np.zeros(self.input_shape,dtype=self.dtype)\n\t\tself.batches=batches\n\t\tinp=inp.reshape(self.batches,self.out_row,self.ksz,self.out_col,self.ksz,self.channels)\n\t\toutput=inp.max(axis=(2,4),keepdims=True)\n\t\tself.mask=(inp==output)\n\t\treturn output.reshape(self.batches,self.out_row,self.out_col,self.channels)\n\n\tdef backprop(self,grads,layer=1):\n\t\t#grads[self.batches,esz,esz,self.channels],inp[self.batches,row,col,self.channels],kernels[self.ksz,self.ksz],stride[row,col]\n\t\tz_out=(self.mask*grads.reshape(self.batches,self.out_row,1,self.out_col,1,self.channels))\n\t\tif self.rem_col:\n\t\t\tself.padded[:,:-self.rem_col,:-self.rem_col,:]=z_out.reshape(self.batches,self.row,self.col,self.channels)\n\t\t\treturn self.padded.reshape(self.input_shape)\n\t\telse:\n\t\t\treturn z_out.reshape(self.input_shape)\n\nclass globalAveragePool(Layer):\n\tdef __init__(self,input_shape=None,name=None):\n\t\tsuper().__init__()\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tif input_shape is None:\n\t\t\tinput_shape=seq_instance.get_inp_shape()\n\t\tself.param=0\n\t\tself.batches=1\n\t\tself.row,self.col,self.channels=input_shape\n\t\tself.Ncount=self.row*self.col\n\t\tself.shape=(None,self.channels)\n\t\tself.activation=echo\n\n\tdef forward(self,inp,training=True):\n\t\tself.input_shape=inp.shape\n\t\tself.batches=self.input_shape[0]\n\t\tinp=inp.reshape(self.batches,self.Ncount,self.channels)\n\t\toutput=inp.mean(axis=1)\n\t\treturn output.reshape(self.batches,self.channels)\n\n\tdef backprop(self,grads,layer=1):\n\t\t# grads/=self.Ncount\n\t\tz_out=grads.repeat(self.Ncount,axis=0).reshape(self.batches,self.row,self.col,self.channels)\n\t\treturn z_out\n\nclass upsampling(Layer):\n\tdef __init__(self,input_shape=None,ksize=[2,2],stride=[2,2],name=None):\n\t\t#inp[batches,row,col,channels], kernels[ksz,ksz], stride[row,col]\n\t\tsuper().__init__()\n\t\tself.ksz=ksize[0]\n\t\tself.param=0\n\t\tself.dtype=np.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tif input_shape is None:\n\t\t\tinput_shape=seq_instance.get_inp_shape()\n\t\tself.batches=1\n\t\tself.row,self.col,self.channels=input_shape\n\t\tself.out_row,self.out_col=self.row*self.ksz,self.col*self.ksz\n\t\tself.shape=(None,self.out_row,self.out_col,self.channels)\n\t\tself.activation=echo\n\n\tdef forward(self,inp,training=True):\n\t\tself.input_shape=inp.shape\n\t\treturn inp.repeat(2,axis=2).repeat(2,axis=1)\n\n\tdef backprop(self,grads,layer=1):\n\t\t#grads[self.batches,esz,esz,self.channels],inp[self.batches,row,col,self.channels],kernels[self.ksz,self.ksz],stride[row,col]\n\t\tgrads=grads.reshape(self.input_shape[0],self.row,self.ksz,self.col,self.ksz,self.channels)\n\t\treturn grads.sum(axis=(2,4),keepdims=True).reshape(self.input_shape)\n\nclass flatten(Layer):\n\tdef __init__(self,name=None):\n\t\tsuper().__init__()\n\t\tself.type=self.__class__.__name__\n\t\tself.dtype=np.float32\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tinput_shape=seq_instance.get_inp_shape()\n\t\tself.r,self.c,self.channels=input_shape\n\t\tself.fsz=self.r*self.c*self.channels\n\t\tself.shape=(None,self.fsz)\n\t\tself.param=0\n\t\tself.activation=echo\n\n\tdef forward(self,inp,training=True):\n\t\treturn inp.reshape(-1,self.fsz)\n\n\tdef backprop(self,grads,layer=1):\n\t\treturn grads.reshape(-1,self.r,self.c,self.channels)\n\nclass reshape(Layer):\n\tdef __init__(self,target_shape,name=None):\n\t\tsuper().__init__()\n\t\tself.type=self.__class__.__name__\n\t\tself.dtype=np.float32\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tself.input_shape=seq_instance.get_inp_shape()\n\t\tself.target_shape=target_shape\n\t\ttt=1\n\t\tfor i in self.input_shape:\n\t\t\ttt*=i\n\t\tfor i in target_shape:\n\t\t\ttt/=i\n\t\tif tt!=1:\n\t\t\traise Exception(""Cannot reshape input ""+str(self.input_shape)+"" to ""+str(target_shape)+\'.\')\n\t\tself.shape=(None,*target_shape)\n\t\tself.param=0\n\t\tself.activation=echo\n\n\tdef forward(self,inp,training=True):\n\t\treturn inp.reshape(-1,*self.target_shape)\n\n\tdef backprop(self,grads,layer=1):\n\t\treturn grads.reshape(-1,*self.input_shape)\n\nclass dense(Layer):\n\tdef __init__(self,num_out,input_shape=None,weights=None,biases=None,activation=echo,mean=0,std=0.01,name=None):\n\t\tsuper().__init__()\n\t\tself.dtype=np.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tif input_shape is None:\n\t\t\tself.input_shape=seq_instance.get_inp_shape()[0]\n\t\telse:\n\t\t\tself.input_shape=input_shape\n\t\tself.activation=activation\n\t\tif weights is None:\n\t\t\tself.weights = std*np.random.randn(self.input_shape,num_out).astype(self.dtype) + mean\n\t\t\t# weights/=np.sqrt(self.input_shape)\n\t\telse:\n\t\t\tif weights.shape!=(self.input_shape,num_out):\n\t\t\t\traise Exception(""weights should be of shape: ""+str((self.input_shape,num_out)))\n\t\t\telse:\n\t\t\t\tself.weights = weights\n\t\tif biases is None:\n\t\t\tself.biases = std*np.random.randn(1,num_out).astype(self.dtype) + mean\n\t\telse:\n\t\t\tif biases.shape!=(1,num_out):\n\t\t\t\traise Exception(""biases should be of shape: ""+str((1,num_out)))\n\t\t\telse:\n\t\t\t\tself.biases = biases\n\t\tself.kernels = self.weights\n\t\tself.w_m=0\n\t\tself.w_v=0\n\t\tself.b_m=0\n\t\tself.b_v=0\n\t\tself.shape=(None,num_out)\n\t\tself.param=self.input_shape*num_out + num_out\n\t\tself.not_softmax_cross_entrp=True\n\t\tif self.activation==echo:\n\t\t\tself.notEcho=False\n\t\telse:\n\t\t\tself.notEcho=True\n\n\tdef forward(self,inp,training=True):\n\t\tself.inp=inp\n\t\tself.z_out=np.dot(inp,self.weights)+self.biases\n\t\tself.a_out=self.activation(self.z_out)\n\t\treturn self.a_out\n\n\tdef backprop(self,grads,layer=1):\n\t\tif self.notEcho and self.not_softmax_cross_entrp:\t\t\t# make it better in future\n\t\t\tgrads*=self.activation(self.z_out,self.a_out,derivative=True)\n\t\td_c_b=grads\n\t\tself.d_c_w=np.dot(self.inp.T,d_c_b)#/self.inp.shape[0]\n\t\tif layer:\n\t\t\td_c_a=np.dot(d_c_b,self.weights.T)\n\t\telse:\n\t\t\td_c_a=0\n\t\tself.d_c_b=d_c_b.sum(axis=0,keepdims=True)\n\t\t# self.d_c_b=d_c_b.mean(axis=0,keepdims=True)\n\t\treturn d_c_a\n\nclass dropout(Layer):\n\tdef __init__(self,rate=0.2,name=None):\n\t\tsuper().__init__()\n\t\tself.dtype=np.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tinput_shape=seq_instance.get_inp_shape()\n\t\tself.shape=(None,*input_shape)\n\t\tself.batches=1\n\t\tself.rate=rate\n\t\tself.scale=1/(1-rate)\n\t\tself.mask=np.random.random((self.batches,*input_shape),dtype=np.float32)>self.rate\n\t\tself.param=0\n\t\tself.activation=echo\n\n\tdef forward(self,inp,training=True):\n\t\tif training:\n\t\t\tself.mask=(self.scale*(np.random.random(inp.shape,dtype=np.float32)>self.rate)).astype(np.float32,copy=False) \t\t#generate mask with rate probability\n\t\t\treturn inp*self.mask\n\t\telse:\n\t\t\tself.mask.fill(1.0)\n\t\t\treturn inp\n\n\tdef backprop(self,grads,layer=1):\n\t\treturn grads*self.mask\n\nclass BatchNormalization(Layer):\t\t\t\t\t#Have to add references to each brah\n\tdef __init__(self,momentum=0.9,epsilon=1e-10,name=None):\n\t\tsuper().__init__()\n\t\tself.dtype=np.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tinput_shape=seq_instance.get_inp_shape()\n\t\tself.shape=(None,*input_shape)\n\t\tself.batches=1\n\t\tself.inp_shape=(self.batches,*input_shape)\n\t\tself.biases=np.zeros(input_shape).astype(self.dtype)\t\t#biases is beta\n\t\tself.weights=np.ones(input_shape).astype(self.dtype)\t\t#weights is gamma\n\t\tself.gamma=self.weights\n\t\tself.beta=self.biases\n\t\tself.kernels = self.weights\n\t\tself.w_m=0\n\t\tself.w_v=0\n\t\tself.b_m=0\n\t\tself.b_v=0\n\t\tself.epsilon=epsilon\n\t\tself.momentum=momentum\n\t\tself.moving_mean=None\n\t\tself.moving_var=None\n\t\tself.param=4*input_shape[-1]\n\t\tself.activation=echo\n\n\tdef forward(self,inp,training=True):\t\t# yeah, I know, too many repetitions\n\t\t#inp[batches,row,col,channels]\n\t\tif training:\n\t\t\tself.inp_shape=inp.shape\n\t\t\tmean=inp.mean(axis=0)\t\t\t\t\t#(row,col,channels)\n\t\t\tself.xmu=inp-mean \t\t\t\t\t\t#(batches,row,col,channels)\n\t\t\tvar=(self.xmu**2).mean(axis=0)\t\t\t#(row,col,channels)\n\t\t\tself.ivar=1/(var+self.epsilon)\t\t\t#(row,col,channels)\n\t\t\tself.istd=np.sqrt(self.ivar)\t\t\t\t#(row,col,channels)\n\t\t\tself.xnorm=self.xmu*self.istd \t\t\t\t#(batches,row,col,channels)\n\t\t\tif self.moving_mean is None:\n\t\t\t\tself.moving_mean=mean\n\t\t\t\tself.moving_var=var\n\t\t\telse:\n\t\t\t\tself.moving_mean=self.momentum*self.moving_mean + (1-self.momentum)*mean\n\t\t\t\tself.moving_var=self.momentum*self.moving_var + (1-self.momentum)*var\n\t\telse:\n\t\t\tif self.moving_mean is None:\n\t\t\t\tself.inp_shape=inp.shape\n\t\t\t\tmean=inp.mean(axis=0)\t\t\t\t\t#(row,col,channels)\n\t\t\t\tself.xmu=inp-mean \t\t\t\t\t\t#(batches,row,col,channels)\n\t\t\t\tvar=(self.xmu**2).mean(axis=0)\t\t\t#(row,col,channels)\n\t\t\t\tself.ivar=1/(var+self.epsilon)\t\t\t#(row,col,channels)\n\t\t\t\tself.istd=np.sqrt(self.ivar)\t\t\t\t#(row,col,channels)\n\t\t\t\tself.moving_mean=mean\n\t\t\t\tself.moving_var=var\n\t\t\t\tself.xnorm=self.xmu*self.istd \t\t\t\t#(batches,row,col,channels)\n\t\t\telse:\n\t\t\t\tself.inp_shape=inp.shape\n\t\t\t\tself.xmu=inp\t\t\t\t\t\t\t\t#(batches,row,col,channels)\t## all this is just for proper shape while model.free()\n\t\t\t\tself.istd=self.moving_var\t\t\t\t\t#(row,col,channels)\n\t\t\t\tself.xnorm=(inp-self.moving_mean)/np.sqrt(self.moving_var+self.epsilon)\n\t\treturn self.xnorm*self.weights+self.biases\n\n\tdef backprop(self,grads,layer=1):\n\t\t#grads(batches,row,col,channels), xmu(batches,row,col,channels)=inp-mean\n\t\tbatches=self.inp_shape[0]\n\t\tif batches!=self.batches:\n\t\t\tself.batches=batches\n\t\tself.d_c_b=grads.sum(axis=0) \t\t\t\t#(row,col,channels)\t\t# biases is beta\n\t\tself.d_c_w=(self.xnorm*grads).sum(axis=0)\t#(row,col,channels)\t\t# gamma is weights\n\t\td_inp=self.istd*self.weights*(self.batches*grads-self.d_c_b-self.xmu*self.ivar*((grads*self.xmu).sum(axis=0)))\n\t\t# d_inp=(1/self.batches)*self.istd*self.weights*(self.batches*grads-self.d_c_b-self.xmu*self.ivar*((grads*self.xmu).sum(axis=0)))\n\t\treturn d_inp\n\nclass Activation(Layer):\n\tdef __init__(self,activation=echo,input_shape=None,name=None):\n\t\tsuper().__init__()\n\t\tself.dtype=np.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tif input_shape is None:\n\t\t\tinput_shape=seq_instance.get_inp_shape()\n\t\tself.activation=activation\n\t\tself.shape=(None,*input_shape)\n\t\tself.param=0\n\t\tself.not_softmax_cross_entrp=True\n\t\tif self.activation==echo:\n\t\t\tself.notEcho=False\n\t\telse:\n\t\t\tself.notEcho=True\n\n\tdef forward(self,inp,training=True):\n\t\tself.z_out=inp\n\t\tself.a_out=self.activation(self.z_out)\n\t\treturn self.a_out\n\n\tdef backprop(self,grads,layer=1):\n\t\tif self.notEcho and self.not_softmax_cross_entrp:\n\t\t\tgrads*=self.activation(self.z_out,self.a_out,derivative=True)\n\t\treturn grads\n\nclass InputLayer(Layer):\t\t#just placeholder\n\tdef __init__(self,shape=None):\n\t\tsuper().__init__()\n\t\tself.name=\'input_layer\'\n\t\tself.type=self.__class__.__name__\n\t\tself.dtype=np.float32\n\t\ttry:\n\t\t\tself.shape=(None,*shape)\n\t\texcept:\n\t\t\tself.shape=(None,shape)\n\t\tself.param=0\n\t\tself.activation=echo'"
nnet/network.py,8,"b'#!/usr/bin/env python3\nfrom nnet import layers\nfrom nnet.functions import *\nfrom nnet.optimizers import *\nimport pickle\nfrom gc import collect\nimport time\n\n### TO-DO- In train/fit unifunc, transpose whole data of inp at once and remove from layers.\n\nclass Sequential:\n\tdef __init__(self):\n\t\tlayers.seq_instance=self\n\t\tself.sequence=[]\n\t\tself.learning_rate=0.001\n\t\tself.dtype=np.float32\n\n\tdef add(self,obj):\n\t\tif len(self.sequence)>0:\n\t\t\tobj(self.sequence[-1])\n\t\tself.sequence.append(obj)\n\n\tdef get_inp_shape(self):\n\t\treturn self.sequence[-1].shape[1:]\n\n\tdef forward(self,X_inp,training=True):\n\t\tfor obj in self.sequence:\n\t\t\tX_inp=obj.forward(X_inp,training=training)\n\t\treturn X_inp\n\n\tdef backprop(self,err,i):\n\t\tfor obj in self.sequence[::-1]:\n\t\t\terr=obj.backprop(err,layer=i)\n\t\t\ti-=1\n\t\treturn err\n\n\tdef predict(self,X_inp):\n\t\tself.svd_inp=X_inp[:1].astype(self.dtype)\n\t\treturn self.forward(X_inp.astype(self.dtype),training=False)\n\n\tdef train_on_batch(self,X_inp,labels):\n\t\tX_inp=self.forward(X_inp.astype(self.dtype))\n\t\terr=self.del_loss(X_inp,labels.astype(self.dtype))\n\t\tself.backprop(err,self.lenseq_m1)\n\t\tself.optimizer(self.sequence,self.learning_rate,self.beta)\n\t\treturn X_inp\n\n\tdef not_train_on_batch(self,X_inp,labels):\n\t\tX_inp=self.forward(X_inp.astype(self.dtype))\n\t\terr=self.del_loss(X_inp,labels.astype(self.dtype))\n\t\terr=self.backprop(err,self.lenseq_m1+1)\n\t\treturn X_inp,err\n\n\tdef fit(self,X_inp=None,labels=None,iterator=None,batch_size=1,epochs=1,validation_data=None,shuffle=True,accuracy_metric=True,infobeta=0.2):\n\t\tlnxinp=len(X_inp)\n\t\tacc=0\n\t\tloss=0\n\t\tsam_time=0\n\t\tfor epch in range(epochs):\n\t\t\tprint(""EPOCH:"",epch+1,""/"",epochs)\n\t\t\tif iterator==None:\n\t\t\t\ts=np.random.permutation(lnxinp)\n\t\t\t\tX_inp=X_inp[s]\n\t\t\t\tlabels=labels[s]\n\t\t\tstart=time.time()\n\t\t\tidx=0\n\t\t\twhile idx<lnxinp:\n\t\t\t\tsmtst=time.time()\n\t\t\t\tif iterator!=None:\n\t\t\t\t\tinp,y_inp=iterator.next()\n\t\t\t\telse:\n\t\t\t\t\tinp=X_inp[idx:idx+batch_size]\n\t\t\t\t\ty_inp=labels[idx:idx+batch_size]\n\t\t\t\tidx+=inp.shape[0]\n\t\t\t\tlogits=self.train_on_batch(inp,y_inp)\n\t\t\t\tif accuracy_metric:\n\t\t\t\t\tif self.loss==cross_entropy_with_logits:\n\t\t\t\t\t\tans=logits.argmax(axis=1)\n\t\t\t\t\t\tcor=y_inp.argmax(axis=1)\n\t\t\t\t\telse:\n\t\t\t\t\t\tans=logits\n\t\t\t\t\t\tcor=y_inp\n\t\t\t\t\tnacc=(ans==cor).mean()\n\t\t\t\t\tacc =infobeta*nacc + (1-infobeta)*acc\n\t\t\t\tsample_loss=self.loss(logits=logits,labels=y_inp).mean()/10\n\t\t\t\tloss =infobeta*sample_loss + (1-infobeta)*loss\n\t\t\t\tsamtm=time.time()-smtst\n\t\t\t\tsam_time=infobeta*samtm + (1-infobeta)*sam_time\n\t\t\t\trem_sam=(lnxinp-idx)/batch_size\n\t\t\t\teta=int(rem_sam*sam_time)\n\t\t\t\tprint(""\\rProgress: {} / {}  - {}s - {:.2}s/sample - loss: {:.4f} - accuracy: {:.4f}"".format(str(idx).rjust(6),lnxinp,eta,sam_time,sample_loss,acc),end=""      _"")\n\t\t\tend=time.time()\n\t\t\tprint(""\\nEpoch time: {:.3f}s"".format(end-start))\n\t\t\tif accuracy_metric:\n\t\t\t\tself.validate(validation_data,batch_size,infobeta)\n\n\tdef validate(self,validation_data,batch_size,infobeta=0.2):\n\t\tif validation_data != None:\n\t\t\tVX,VY=validation_data\n\t\t\tlnvx=len(VX)\n\t\telse:\n\t\t\tlnvx=-1\n\t\tvidx=0\n\t\tvacc=0\n\t\tvloss=0\n\t\tprint(""Calculating Validation Accuracy...."",end="""")\n\t\twhile vidx<=lnvx:\n\t\t\tinp=VX[vidx:vidx+batch_size]\n\t\t\ty_inp=VY[vidx:vidx+batch_size]\n\t\t\tvidx+=batch_size\n\t\t\tlogits=self.predict(inp)\n\t\t\tif self.loss==cross_entropy_with_logits:\n\t\t\t\tans=logits.argmax(axis=1)\n\t\t\t\tcor=y_inp.argmax(axis=1)\n\t\t\telse:\n\t\t\t\tans=logits\n\t\t\t\tcor=y_inp\n\t\t\tvacc+=(ans==cor).sum()\n\t\t\tsample_loss=self.loss(logits=logits,labels=y_inp).mean()/10\n\t\t\tvloss=infobeta*sample_loss + (1-infobeta)*vloss\n\t\tprint(""\\rValidation Accuracy:"",str(vacc/lnvx)[:5],""- val_loss:"",str(vloss)[:6])\n\n\tdef free(self):\t\t\t#just to free memory of large batch after predict\n\t\tX_inp=self.svd_inp\n\t\terr=self.forward(X_inp,False)\n\t\tself.backprop(err,self.lenseq_m1)\n\t\tlayers.COLT.free()\t\t\t\t\t# MAKE ONE TO FREE UNUSED objs IN COLT\n\t\tcollect()\n\n\tdef compile(self,optimizer=adam,beta=0.9,loss=cross_entropy_with_logits,learning_rate=0.001):\n\t\tself.optimizer=optimizer\n\t\tself.beta=beta\n\t\tself.learning_rate=learning_rate\n\t\tself.loss=loss\n\t\tif self.loss==cross_entropy_with_logits:\n\t\t\tself.sequence[-1].not_softmax_cross_entrp=False\n\t\t\tself.del_loss=del_cross_soft\n\t\telif self.loss==mean_squared_error:\n\t\t\tself.del_loss=del_mean_squared_error\n\t\tself.lenseq_m1=len(self.sequence)-1\n\n\tdef save_weights(self,path):\n\t\tsv_me=[]\n\t\tfor obj in self.sequence:\n\t\t\tif obj.param>0:\n\t\t\t\tif obj.__class__==layers.BatchNormalization:\n\t\t\t\t\tsv_me.append((obj.weights,obj.biases,obj.moving_mean,obj.moving_var))\n\t\t\t\telse:\n\t\t\t\t\tsv_me.append((obj.weights,obj.biases))#,obj.w_m,obj.w_v,obj.b_m,obj.b_v))\n\t\twith open(path,\'wb\') as f:\n\t\t\tpickle.dump(sv_me,f)\n\n\tdef load_weights(self,path):\n\t\twith open(path,\'rb\') as f:\n\t\t\tsv_me=pickle.load(f)\n\t\tidx=0\n\t\tfor obj in self.sequence:\n\t\t\tif obj.param>0:\n\t\t\t\tif obj.__class__==layers.BatchNormalization:\n\t\t\t\t\tobj.weights,obj.biases,obj.moving_mean,obj.moving_var=sv_me[idx]\n\t\t\t\telse:\n\t\t\t\t\tobj.weights,obj.biases=sv_me[idx]\n\t\t\t\t\t# obj.weights,obj.biases,obj.w_m,obj.w_v,obj.b_m,obj.b_v=sv_me[idx]\n\t\t\t\t\tif obj.__class__==layers.conv2d:\n\t\t\t\t\t\tobj.kernels=obj.weights\n\t\t\t\t\t\tobj.init_back()\n\t\t\t\tobj.kernels=obj.weights\n\t\t\t\tidx+=1\n\n\tdef summary(self):\n\t\tipl=layers.InputLayer(self.sequence[0].input_shape)\n\t\treps=90\n\t\tprint(chr(9149)*reps)\n\t\tprint(""Layer (type)"".ljust(25),"" Output Shape"".ljust(25),""Activation"".ljust(17),""Param #"")\n\t\tprint(\'=\'*reps)\n\t\tprint(\'- {}({})\'.format(ipl.name,ipl.type).ljust(25),\'{}\'.format(ipl.shape).ljust(25),\' {}\'.format(ipl.activation.__name__).ljust(17),ipl.param)\n\t\tself.total_param=0\n\t\tself.non_train_param=0\n\t\tfor i,obj in enumerate(self.sequence):\n\t\t\tprint(\'_\'*reps)\n\t\t\tprint(\'{} {}({})\'.format(i,obj.name,obj.type).ljust(25)[:25],\'{}\'.format(obj.shape).ljust(25),\' {}\'.format(obj.activation.__name__).ljust(17),obj.param)\n\t\t\tself.total_param+=obj.param\n\t\t\tif obj.__class__==layers.BatchNormalization:\n\t\t\t\tself.non_train_param+=obj.param//2\n\t\tprint(\'=\'*reps)\n\t\tprint(""Total Params: {:,}"".format(self.total_param))\n\t\tprint(""Trainable Params: {:,}"".format(self.total_param-self.non_train_param))\n\t\tprint(""Non-trainable Params: {:,}"".format(self.non_train_param))'"
nnet/optimizers.py,10,"b'#!/usr/bin/env python3\nimport numpy as np\n\n### CAN TURN THESE INTO CLASSES\n\ndef iterative(sequence,learning_rate=0.01,beta=0):\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\tobj.weights-=(learning_rate*obj.d_c_w)\n\t\t\tobj.biases-=(learning_rate*obj.d_c_b)\n\ndef momentum(sequence,learning_rate=0.1,beta1=0.9,weight_decay=0.0005):\t\t# will have to specify it\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\tobj.w_m=beta1*obj.w_m - learning_rate*obj.d_c_w - weight_decay*learning_rate*obj.weights\n\t\t\tobj.weights+=obj.w_m\n\t\t\tobj.b_m=beta1*obj.b_m - learning_rate*obj.d_c_b - weight_decay*learning_rate*obj.biases\n\t\t\tobj.biases+=obj.b_m\n\ndef rmsprop(sequence,learning_rate=0.001,beta1=0.9,epsilon=1e-8):\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\tobj.w_v=beta1*obj.w_v + (1-beta1)*(obj.d_c_w**2)\n\t\t\tobj.weights-=learning_rate*(obj.d_c_w/np.sqrt(obj.w_v+epsilon))\n\t\t\tobj.b_v=beta1*obj.b_v + (1-beta1)*(obj.d_c_b**2)\n\t\t\tobj.biases-=learning_rate*(obj.d_c_b/np.sqrt(obj.b_v+epsilon))\n\ndef adagrad(sequence,learning_rate=0.01,beta1=0.9,epsilon=1e-8):\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\tobj.w_v+=(obj.d_c_w**2)\n\t\t\tobj.weights-=learning_rate*(obj.d_c_w/np.sqrt(obj.w_v+epsilon))\n\t\t\tobj.b_v+=(obj.d_c_b**2)\n\t\t\tobj.biases-=learning_rate*(obj.d_c_b/np.sqrt(obj.b_v+epsilon))\n\ndef adam(sequence,learning_rate=0.001,beta1=0.9,beta2=0.999,epsilon=1e-8,decay=0):\t\t# decay not functional rn\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\t# Update weights\n\t\t\tobj.w_m=beta1*obj.w_m + (1-beta1)*obj.d_c_w\n\t\t\tobj.w_v=beta2*obj.w_v + (1-beta2)*(obj.d_c_w**2)\n\t\t\tmcap=obj.w_m/(1-beta1)\n\t\t\tvcap=obj.w_v/(1-beta2)\n\t\t\tobj.d_c_w=mcap/(np.sqrt(vcap)+epsilon)\n\t\t\tobj.weights-=learning_rate*obj.d_c_w\n\t\t\t# Update biases\n\t\t\tobj.b_m=beta1*obj.b_m + (1-beta1)*obj.d_c_b\n\t\t\tobj.b_v=beta2*obj.b_v + (1-beta2)*(obj.d_c_b**2)\n\t\t\tmcap=obj.b_m/(1-beta1)\n\t\t\tvcap=obj.b_v/(1-beta2)\n\t\t\tobj.d_c_b=mcap/(np.sqrt(vcap)+epsilon)\n\t\t\tobj.biases-=learning_rate*obj.d_c_b\n\ndef adamax(sequence,learning_rate=0.002,beta1=0.9,beta2=0.999,epsilon=1e-8):\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\t# Update weights\n\t\t\tobj.w_m=beta1*obj.w_m + (1-beta1)*obj.d_c_w\n\t\t\tobj.w_v=np.maximum(beta2*obj.w_v,abs(obj.d_c_w))\n\t\t\tobj.weights-=(learning_rate/(1-beta1))*(obj.w_m/(obj.w_v+epsilon))\n\t\t\t# Update biases\n\t\t\tobj.b_m=beta1*obj.b_m + (1-beta1)*obj.d_c_b\n\t\t\tobj.b_v=np.maximum(beta2*obj.b_v,abs(obj.d_c_b))\n\t\t\tobj.biases-=(learning_rate/(1-beta1))*(obj.b_m/(obj.b_v+epsilon))\n\ndef adadelta(sequence,learning_rate=0.01,beta1=0.9,epsilon=1e-8):\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\tobj.w_v=beta1*obj.w_v + (1-beta1)*(obj.d_c_w**2)\n\t\t\tobj.d_c_w=np.sqrt((obj.w_m+epsilon)/(obj.w_v+epsilon))*obj.d_c_w\n\t\t\tobj.w_m=beta1*obj.w_m + (1-beta1)*(obj.d_c_w**2)\n\t\t\tobj.weights-=obj.d_c_w\n\n\t\t\tobj.b_v=beta1*obj.b_v + (1-beta1)*(obj.d_c_b**2)\n\t\t\tobj.d_c_b=np.sqrt((obj.b_m+epsilon)/(obj.b_v+epsilon))*obj.d_c_b\n\t\t\tobj.b_m=beta1*obj.b_m + (1-beta1)*(obj.d_c_b**2)\n\t\t\tobj.biases-=obj.d_c_b'"
nnet/server.py,0,b''
nnet_gpu/__init__.py,0,b''
nnet_gpu/autograd.py,0,b'#!/usr/bin/env python3'
nnet_gpu/coled_tracker.py,4,"b'#!/usr/bin/env python3\nimport numpy as np\nfrom gc import collect\n\n# For a single shared large memory block to reuse and not repeat allocation\n\n# FIX: If new mem is allocated. Remove the self from objs\n\nclass coled_tracker:\n\tdef __init__(self):\n\t\tself.dtype=np.float32\n\t\tself.objs=set()\n\t\tself.COLED=None\n\n\tdef alloc(self,coled_size,obj):\n\t\ttry:\n\t\t\tself.objs.remove(obj)\n\t\texcept:\n\t\t\tpass\n\t\tif self.COLED is None:\n\t\t\tself.COLED=np.empty(coled_size,dtype=self.dtype)\n\t\t\tfor oo in self.objs:\n\t\t\t\ttry:\n\t\t\t\t\too.coled=self.COLED.ravel()[:oo.coled.size].reshape(oo.coled.shape)\n\t\t\t\texcept:\n\t\t\t\t\tself.objs.remove(oo)\n\t\t\tself.objs.add(obj)\n\t\t\treturn self.COLED\n\t\telse:\n\t\t\tif self.COLED.size>=coled_size:\n\t\t\t\tself.objs.add(obj)\n\t\t\t\treturn self.COLED.ravel()[:coled_size]\n\t\t\telse:\n\t\t\t\tself.COLED=np.empty(coled_size,dtype=self.dtype)\n\t\t\t\tfor oo in self.objs:\n\t\t\t\t\ttry:\n\t\t\t\t\t\too.coled=self.COLED.ravel()[:oo.coled.size].reshape(oo.coled.shape)\n\t\t\t\t\texcept:\n\t\t\t\t\t\tself.objs.remove(oo)\n\t\t\t\tself.objs.add(obj)\n\t\t\t\treturn self.COLED.ravel()[:coled_size]\n\n\tdef free(self):\n\t\tobs=list(self.objs)\n\t\tmx=obs[0]\n\t\tfor oo in obs:\n\t\t\ttry:\n\t\t\t\tif oo.coled.nbytes>mx.coled.nbytes:\n\t\t\t\t\tmx=oo\n\t\t\texcept:\n\t\t\t\tself.objs.remove(oo)\n\t\tif len(self.objs)>0:\n\t\t\tif self.COLED.nbytes>mx.coled.nbytes:\n\t\t\t\tself.COLED=np.empty(mx.coled.size,dtype=self.dtype)\n\t\t\t\tfor oo in self.objs:\n\t\t\t\t\too.coled=self.COLED.ravel()[:oo.coled.size].reshape(oo.coled.shape)\n\t\tcollect()'"
nnet_gpu/memory_handler.py,0,b''
nnet_gpu/network.py,7,"b'#!/usr/bin/env python3\nfrom . import layers\nfrom .functions import *\nfrom .optimizers import *\nfrom .stream_handler import stream_maps\n\nimport pickle\nfrom gc import collect\nimport time\n\n### TO-DO- In train/fit unifunc, transpose whole data of inp at once and remove from layers.\n\nclass Sequential:\n\tdef __init__(self):\n\t\tlayers.seqinst.seq_instance=self\n\t\tself.sequence=[]\n\t\tself.learning_rate=0.001\n\t\tself.dtype=cp.float32\n\n\tdef add(self,obj):\n\t\tif len(self.sequence)>0:\n\t\t\tobj(self.sequence[-1])\n\t\tself.sequence.append(obj)\n\n\tdef get_inp_shape(self):\n\t\treturn self.sequence[-1].shape[1:]\n\n\tdef forward(self,X_inp,training=True):\n\t\tfor obj in self.sequence:\n\t\t\tX_inp=obj.forward(X_inp,training=training)\n\t\treturn X_inp\n\n\tdef backprop(self,grads,i):\n\t\tfor obj in self.sequence[::-1]:\n\t\t\tgrads=obj.backprop(grads,layer=i)\n\t\t\ti-=1\n\t\treturn grads\n\n\tdef predict(self,X_inp):\n\t\treturn self.forward(X_inp.astype(self.dtype,copy=False),training=False)\n\n\tdef train_on_batch(self,X_inp,labels):\n\t\tX_inp=self.forward(X_inp.astype(self.dtype,copy=False))\n\t\tgrads=self.del_loss(X_inp,labels.astype(self.dtype,copy=False))\n\t\tself.backprop(grads,self.lenseq_m1)\n\t\tself.optimizer(self.sequence,self.learning_rate,self.beta)\n\t\treturn X_inp\n\n\tdef not_train_on_batch(self,X_inp,labels):\n\t\tX_inp=self.forward(X_inp.astype(self.dtype,copy=False))\n\t\tgrads=self.del_loss(X_inp,labels.astype(self.dtype,copy=False))\n\t\tgrads=self.backprop(grads,self.lenseq_m1+1)\n\t\treturn X_inp,grads\n\n\tdef fit(self,X_inp=None,labels=None,iterator=None,batch_size=1,epochs=1,validation_data=None,shuffle=True,accuracy_metric=True,infobeta=0.2):\n\t\tlnxinp=len(X_inp)\n\t\tacc=0\n\t\tloss=sample_loss=0\n\t\tsam_time=0\n\t\tfor epch in range(epochs):\n\t\t\tprint(""EPOCH:"",epch+1,""/"",epochs)\n\t\t\tif iterator==None:\n\t\t\t\tif shuffle:\n\t\t\t\t\ts=cp.random.permutation(lnxinp).astype(cp.int32,copy=False)\n\t\t\t\t\tX_inp=X_inp[s]\n\t\t\t\t\tlabels=labels[s]\n\t\t\t\t\tdel s\n\t\t\tstart=time.time()\n\t\t\tidx=0\n\t\t\teval_stream=stream_maps.get_next_stream()\n\t\t\twhile idx<lnxinp:\n\t\t\t\tsmtst=time.time()\n\t\t\t\tif iterator!=None:\n\t\t\t\t\tinp,y_inp=iterator.next()\n\t\t\t\t\tinp=cp.asarray(inp)\n\t\t\t\t\ty_inp=cp.asarray(y_inp)\n\t\t\t\telse:\n\t\t\t\t\tinp=cp.asarray(X_inp[idx:idx+batch_size])\n\t\t\t\t\ty_inp=cp.asarray(labels[idx:idx+batch_size])\n\t\t\t\tidx+=inp.shape[0]\n\t\t\t\tlogits=self.train_on_batch(inp,y_inp)\n\t\t\t\tself.logit_event=cp.cuda.get_current_stream().record()\n\t\t\t\twith eval_stream:\n\t\t\t\t\teval_stream.wait_event(self.logit_event)\n\t\t\t\t\tif accuracy_metric:\n\t\t\t\t\t\tif self.loss==cross_entropy_with_logits:\n\t\t\t\t\t\t\tans=logits.argmax(axis=1)\n\t\t\t\t\t\t\tcor=y_inp.argmax(axis=1)\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tans=logits\n\t\t\t\t\t\t\tcor=y_inp\n\t\t\t\t\t\tnacc=(ans==cor).mean().get(eval_stream)\n\t\t\t\t\t\tacc =infobeta*nacc + (1-infobeta)*acc\n\t\t\t\t\tsample_loss=self.loss(logits=logits,labels=y_inp).mean().get(eval_stream)/10\n\t\t\t\t\tloss =infobeta*sample_loss + (1-infobeta)*loss\n\t\t\t\t\tsamtm=time.time()-smtst\n\t\t\t\t\tsam_time=infobeta*samtm + (1-infobeta)*sam_time\n\t\t\t\t\trem_sam=(lnxinp-idx)/batch_size\n\t\t\t\t\teta=int(rem_sam*sam_time)\n\t\t\t\t\tprint(f""\\rProgress: {str(idx):>6} / {lnxinp}  - {eta}s - {sam_time:.3f}s/sample - loss: {sample_loss:.4f} - accuracy: {acc:.4f}"",end="" -  _"")\n\t\t\tend=time.time()\n\t\t\tprint(f""\\b\\bTime: {end-start:.3f}s"")\n\t\t\tif accuracy_metric:\n\t\t\t\tself.validate(validation_data,batch_size,infobeta)\n\n\tdef validate(self,validation_data,batch_size,infobeta=0.2):\n\t\tif validation_data != None:\n\t\t\tVX,VY=validation_data\n\t\t\tlnvx=len(VX)\n\t\telse:\n\t\t\tlnvx=-1\n\t\tvidx=0\n\t\tvacc=0\n\t\tvloss=0\n\t\tprint(""Calculating Validation Accuracy...."",end="""")\n\t\tstart=time.time()\n\t\twhile vidx<lnvx:\n\t\t\tinp=cp.asarray(VX[vidx:vidx+batch_size])\n\t\t\ty_inp=cp.asarray(VY[vidx:vidx+batch_size])\n\t\t\tvidx+=inp.shape[0]\n\t\t\tlogits=self.predict(inp)\n\t\t\tif self.loss==cross_entropy_with_logits:\n\t\t\t\tans=logits.argmax(axis=1)\n\t\t\t\tcor=y_inp.argmax(axis=1)\n\t\t\telse:\n\t\t\t\tans=logits\n\t\t\t\tcor=y_inp\n\t\t\tvacc+=(ans==cor).sum()\n\t\t\tsample_loss=self.loss(logits=logits,labels=y_inp).mean()/10\n\t\t\tvloss=infobeta*sample_loss + (1-infobeta)*vloss\n\t\tend=time.time()\n\t\tprint(f""\\rValidation Accuracy: {(vacc/lnvx).get():.4f} - val_loss: {vloss.get():.4f} - Time: {end-start:.3f}s"")\n\n\tdef compile(self,optimizer=adam,beta=0.9,loss=cross_entropy_with_logits,learning_rate=0.001):\n\t\tself.optimizer=optimizer\n\t\tself.beta=beta\n\t\tself.learning_rate=learning_rate\n\t\tself.loss=loss\n\t\tif self.loss==cross_entropy_with_logits:\n\t\t\tself.sequence[-1].not_softmax_cross_entrp=False\n\t\t\tself.del_loss=del_cross_soft\n\t\telif self.loss==mean_squared_error:\n\t\t\tself.del_loss=del_mean_squared_error\n\t\tself.lenseq_m1=len(self.sequence)-1\n\n\tdef save_weights(self,path):\t# has problems if u wanna train the network further. Need to fix that.\n\t\tsv_me=[]\t\t\t\t\t# OK for just validation and prediction.\n\t\tfor obj in self.sequence:\t# FIX: Prolly d_ker is seeing different kernel\n\t\t\tif obj.param>0:\n\t\t\t\tif obj.__class__==layers.BatchNormalization:\n\t\t\t\t\tsv_me.append((obj.weights,obj.biases,obj.moving_mean,obj.moving_var))\n\t\t\t\telse:\n\t\t\t\t\tsv_me.append((obj.weights,obj.biases))#,obj.w_m,obj.w_v,obj.b_m,obj.b_v))\n\t\twith open(path,\'wb\') as f:\n\t\t\tpickle.dump(sv_me,f)\n\n\tdef load_weights(self,path):\n\t\twith open(path,\'rb\') as f:\n\t\t\tsv_me=pickle.load(f)\n\t\tidx=0\n\t\tfor obj in self.sequence:\n\t\t\tif obj.param>0:\n\t\t\t\tif obj.__class__==layers.BatchNormalization:\n\t\t\t\t\tobj.weights,obj.biases,obj.moving_mean,obj.moving_var=sv_me[idx]\n\t\t\t\telse:\n\t\t\t\t\tobj.weights,obj.biases=sv_me[idx]\n\t\t\t\t\tif obj.__class__==layers.conv2d:\n\t\t\t\t\t\tobj.kernels=obj.weights\n\t\t\t\t\t\tobj.init_back()\n\t\t\t\tobj.kernels=obj.weights\n\t\t\t\tidx+=1\n\n\tdef summary(self):\n\t\tipl=layers.InputLayer(self.sequence[0].input_shape)\n\t\treps=90\n\t\tprint(chr(9149)*reps)\n\t\tprint(""Layer (type)"".ljust(25),"" Output Shape"".ljust(25),""Activation"".ljust(17),""Param #"")\n\t\tprint(\'=\'*reps)\n\t\tprint(\'- {}({})\'.format(ipl.name,ipl.type).ljust(25),\'{}\'.format(ipl.shape).ljust(25),\' {}\'.format(ipl.activation.__name__).ljust(17),ipl.param)\n\t\tself.total_param=0\n\t\tself.non_train_param=0\n\t\tfor i,obj in enumerate(self.sequence):\n\t\t\tprint(\'_\'*reps)\n\t\t\tprint(\'{} {}({})\'.format(i,obj.name,obj.type).ljust(25)[:25],\'{}\'.format(obj.shape).ljust(25),\' {}\'.format(obj.activation.__name__).ljust(17),obj.param)\n\t\t\tself.total_param+=obj.param\n\t\t\tif obj.__class__==layers.BatchNormalization:\n\t\t\t\tself.non_train_param+=obj.param//2\n\t\tprint(\'=\'*reps)\n\t\tprint(""Total Params: {:,}"".format(self.total_param))\n\t\tprint(""Trainable Params: {:,}"".format(self.total_param-self.non_train_param))\n\t\tprint(""Non-trainable Params: {:,}"".format(self.non_train_param))'"
nnet_gpu/stream_handler.py,0,b'#!/usr/bin/env python3\nimport cupy as cp\n\nN_STREAMS = 16\n\nclass stream_mapper:\n\tdef __init__(self):\n\t\tself.default_stream=cp.cuda.Stream.null#get_current_stream()\n\t\tself.streams=[cp.cuda.Stream(non_blocking=True) for i in range(N_STREAMS)]\n\t\tself.idx=0\n\n\tdef get_next_stream(self):\n\t\tself.idx=(self.idx+1)%len(self.streams)\n\t\treturn self.streams[self.idx]\n\t\t# return self.default_stream\n\nstream_maps=stream_mapper()'
nnet_gpu/functions/__init__.py,0,b'#!/usr/bin/env python3\n\nfrom .functions import *'
nnet_gpu/functions/functions.py,0,"b'#!/usr/bin/env python3\nimport numpy as np\nimport cupy as cp\n\n### CAN TURN THESE INTO CLASSES\n\ndef sigmoid(z,a=None,derivative=False):\n\tif derivative:\n\t\treturn a*(1-a)\n\telse:\n\t\treturn 1.0/(1+cp.exp(-z.clip(-88.72283,88.72283)))\n\ndef elliot(z,a=None, derivative=False):\n\t# A fast approximation of sigmoid\n\tabs_signal=(1+cp.abs(z))\n\tif derivative:\n\t\treturn 0.5/abs_signal**2\n\telse:\n\t\treturn 0.5/abs_signal+0.5\n\ndef relu(z,a=None,derivative=False):\n\tif derivative:\n\t\treturn z>0\n\telse:\n\t\t# z[z<0]=0\n\t\t# return z\n\t\t# return z*(z>0)\n\t\treturn cp.maximum(0,z)\n\nclass relu_impl:\n\t# can cache z>0 ??\n\tdef forward(self,z):\n\t\treturn cp.maximum(0,z)\n\n\tdef backprop(self,z,a=None,grads=None):\n\t\tgrads*=(z>0)\n\t\treturn grads\n\ndef elu(z,a=None,derivative=False):\t\t\t#alpha is 1\n\tif derivative:\n\t\treturn cp.where(z>0, 1, a+1)\n\telse:\n\t\treturn cp.where(z>0, z, cp.exp(z)-1)#*alpha\n\ndef leakyRelu(z,a=None,derivative=False):\n\talpha=0.2\n\tif derivative:\n\t\t# dz = cp.ones_like(z,dtype=cp.float32)\n\t\t# dz[z < 0] = alpha\n\t\t# return dz\n\t\treturn cp.clip(z > 0, alpha, 1.0)\n\telse:\n\t\treturn cp.where(z>0, z, z*alpha)\n\ndef tanh(z,a=None,derivative=False):\n\tif derivative:\n\t\treturn 1-a**2\n\telse:\n\t\treturn cp.tanh(z)\n\ndef softmax(z,a=None,derivative=False):\n\tif derivative:\n\t\t# a1*(1-a1)-a1a2\n\t\treturn 1\n\telse:\n\t\texps = cp.exp(z-cp.max(z, axis=1, keepdims = True))\n\t\t# return exps/cp.sum(exps, axis=1, keepdims = True)\n\t\texps/=cp.sum(exps, axis=1, keepdims = True)\n\t\treturn exps\n\n\ndef cross_entropy_with_logits(logits,labels,epsilon=1e-12):\n\treturn -cp.sum(labels*cp.log(logits+epsilon),axis=0,keepdims=True)\n\ndef cross_entropy(logits,labels,epsilon=1e-12):\n\tlabels=labels.clip(epsilon,1-epsilon)\n\tlogits=logits.clip(epsilon,1-epsilon)\n\treturn -labels*cp.log(logits)-(1-labels)*cp.log(1-logits)\n\ndef del_cross_sigmoid(logits,labels):\n\treturn (logits-labels)\n\ndef del_cross_soft(logits,labels):\n\treturn (logits-labels)\n\ndef mean_squared_error(logits, labels):\n\treturn ((logits-labels)**2)/2\n\ndef del_mean_squared_error(logits, labels):\n\treturn (logits-labels)\n\ndef echo(z,a=None,derivative=False,**kwargs):\n\treturn z'"
nnet_gpu/layers/BatchNormalization.py,3,"b""#!/usr/bin/env python3\nfrom .base_layer import *\nfrom . import seqinst\nfrom ..stream_handler import stream_maps\n\nclass BatchNormalization(Layer):\n\tdef __init__(self,momentum=0.9,epsilon=1e-10,name=None):\n\t\tsuper().__init__()\n\t\tself.dtype=cp.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tinput_shape=seqinst.seq_instance.get_inp_shape()\n\t\tself.shape=(None,*input_shape)\n\t\tself.batches=1\n\t\tself.inp_shape=(self.batches,*input_shape)\n\t\tself.biases=cp.zeros(input_shape,dtype=self.dtype)\t\t#biases is beta\n\t\tself.weights=cp.ones(input_shape,dtype=self.dtype)\t\t#weights is gamma\n\t\tself.gamma=self.weights\n\t\tself.beta=self.biases\n\t\tself.kernels = self.weights\n\t\tself.w_m=cp.zeros_like(self.weights,dtype=self.dtype)\n\t\tself.w_v=cp.zeros_like(self.weights,dtype=self.dtype)\n\t\tself.b_m=cp.zeros_like(self.biases,dtype=self.dtype)\n\t\tself.b_v=cp.zeros_like(self.biases,dtype=self.dtype)\n\t\tself.epsilon=epsilon\n\t\tself.momentum=momentum\n\t\tself.moving_mean=None\n\t\tself.moving_var=None\n\t\tself.param=4*input_shape[-1]\n\t\tself.activation=echo\n\t\tself.backp_stream=stream_maps.get_next_stream()\n\t\tself.grad_event=stream_maps.default_stream.record()\n\t\t# self.update_moving = cp.ElementwiseKernel(\n\t\t# 'T inp, int32 row, int32 col, int32 out_row, int32 out_col,'\n\t\t# 'T coled',\n\t\t# '''\n\t\t# \tint in_y = ky * dy + out_y * sy - ph;\n\t\t# \tint in_x = kx * dx + out_x * sx - pw;\n\t\t# ''',\n\t\t# 'update_moving')\n\n\tdef forward(self,inp,training=True):\t\t# yeah, I know, too many repetitions\n\t\t#inp[batches,row,col,channels]\t\t\t## MAKE A KERNEL\n\t\tself.inp_shape=inp.shape\n\t\tif training:\n\t\t\tmean=inp.mean(axis=0)\t\t\t\t\t#(row,col,channels)\n\t\t\tself.xmu=inp-mean \t\t\t\t\t\t#(batches,row,col,channels)\n\t\t\tvar=(self.xmu**2).mean(axis=0)\t\t\t#(row,col,channels)\n\t\t\tself.grad_event=stream_maps.default_stream.record(self.grad_event)\n\t\t\tself.ivar=1/(var+self.epsilon)\t\t\t#(row,col,channels)\n\t\t\tself.istd=cp.sqrt(self.ivar)\t\t\t\t#(row,col,channels)\n\t\t\tself.xnorm=self.xmu*self.istd \t\t\t\t#(batches,row,col,channels)\n\t\t\twith self.backp_stream:\n\t\t\t\tself.backp_stream.wait_event(self.grad_event)\n\t\t\t\tif self.moving_mean is None:\n\t\t\t\t\tself.moving_mean=mean\n\t\t\t\t\tself.moving_var=var\n\t\t\t\telse:\n\t\t\t\t\tself.moving_mean=self.momentum*self.moving_mean + (1-self.momentum)*mean\n\t\t\t\t\tself.moving_var =self.momentum*self.moving_var  + (1-self.momentum)*var\n\t\telse:\n\t\t\tif self.moving_mean is None:\n\t\t\t\tmean=inp.mean(axis=0)\t\t\t\t\t#(row,col,channels)\n\t\t\t\tself.xmu=inp-mean \t\t\t\t\t\t#(batches,row,col,channels)\n\t\t\t\tvar=(self.xmu**2).mean(axis=0)\t\t\t#(row,col,channels)\n\t\t\t\tself.ivar=1/(var+self.epsilon)\t\t\t#(row,col,channels)\n\t\t\t\tself.istd=cp.sqrt(self.ivar)\t\t\t\t#(row,col,channels)\n\t\t\t\tself.moving_mean=mean\n\t\t\t\tself.moving_var=var\n\t\t\t\tself.xnorm=self.xmu*self.istd \t\t\t\t#(batches,row,col,channels)\n\t\t\telse:\n\t\t\t\tself.xmu=inp-self.moving_mean\t\t\t\t#(batches,row,col,channels)\t## all this is just for proper shape while model.free()\n\t\t\t\tself.ivar=1/(self.moving_var+self.epsilon)\n\t\t\t\tself.istd=cp.sqrt(self.ivar)\t#(row,col,channels)\n\t\t\t\tself.xnorm=self.xmu*self.istd\n\t\t\t\t# self.xnorm=(inp-self.moving_mean)/cp.sqrt(self.moving_var+self.epsilon)\n\t\treturn self.xnorm*self.weights+self.biases\n\n\tdef backprop(self,grads,layer=1):\n\t\t#grads(batches,row,col,channels), xmu(batches,row,col,channels)=inp-mean\n\t\tbatches=self.inp_shape[0]\n\t\tif batches!=self.batches:\n\t\t\tself.batches=batches\n\n\t\tself.d_c_b=grads.sum(axis=0) \t\t\t\t#(row,col,channels)\t\t# biases is beta\n\t\tself.grad_event=stream_maps.default_stream.record(self.grad_event)\n\n\t\twith self.backp_stream:\n\t\t\tself.backp_stream.wait_event(self.grad_event)\n\t\t\tself.d_c_w=(self.xnorm*grads).sum(axis=0)\t#(row,col,channels)\t\t# gamma is weights\n\n\t\t# d_inp=(1/self.batches)*self.istd*self.weights*(self.batches*grads-self.d_c_b-self.xmu*self.ivar*((grads*self.xmu).sum(axis=0)))\n\t\td_inp=self.istd*self.weights*(self.batches*grads-self.d_c_b-self.xmu*self.ivar*((grads*self.xmu).sum(axis=0)))\n\t\treturn d_inp"""
nnet_gpu/layers/__init__.py,0,b'#!/usr/bin/env python3\n\nfrom .activation import Activation\nfrom .base_layer import Layer\nfrom .base_layer import InputLayer\nfrom .BatchNormalization import BatchNormalization\nfrom .convolution.conv2d import conv2d\nfrom .convolution.conv2dtranspose import conv2dtranspose\nfrom .dense import dense\nfrom .dropout import dropout\nfrom .pooling.max_pool import max_pool\nfrom .pooling.globalAveragePool import globalAveragePool\nfrom .shaping import flatten\nfrom .shaping import reshape\nfrom .upsampling import upsampling\n\nimport cupyx'
nnet_gpu/layers/activation.py,0,"b'#!/usr/bin/env python3\nfrom .base_layer import *\nfrom . import seqinst\nfrom ..stream_handler import stream_maps\n\nclass Activation(Layer):\n\tdef __init__(self,activation=echo,input_shape=None,name=None):\n\t\tsuper().__init__()\n\t\tself.dtype=cp.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tif input_shape is None:\n\t\t\tinput_shape=seqinst.seq_instance.get_inp_shape()\n\t\tself.activation=activation\n\t\tself.shape=(None,*input_shape)\n\t\tself.param=0\n\t\tself.not_softmax_cross_entrp=True\n\t\tif self.activation==echo:\n\t\t\tself.notEcho=False\n\t\telse:\n\t\t\tself.notEcho=True\n\n\tdef forward(self,inp,training=True):\n\t\tself.z_out=inp\n\t\tself.a_out=self.activation(self.z_out)\n\t\treturn self.a_out\n\n\tdef backprop(self,grads,layer=1):\n\t\tif self.notEcho and self.not_softmax_cross_entrp:\n\t\t\tgrads*=self.activation(self.z_out,self.a_out,derivative=True)\n\t\treturn grads\n'"
nnet_gpu/layers/base_layer.py,0,"b""#!/usr/bin/env python3\nfrom ..functions import *\nimport numpy as np\nimport cupy as cp\nfrom . import seqinst\n\nclass Layer:\n\tdef __init__(self):\n\t\tself.name=self.__class__.__name__\n\t\tself.type=self.__class__.__name__\n\t\tself.dtype=cp.float32\n\t\tself.param=0\n\t\tself.activation=echo\n\t\tself.input_layer=None\n\t\tself.output_layers=[]\n\t\tself.bias_is_not_0=True\n\n\tdef __str__(self):\n\t\treturn self.name+super().__str__()\n\n\tdef __call__(self,lyr):\n\t\tself.input_layer=lyr\n\t\tlyr.output_layers.append(self)\n\t\treturn self\n\nclass InputLayer(Layer):\t\t#just placeholder\n\tdef __init__(self,shape=None):\n\t\tsuper().__init__()\n\t\tself.name='input_layer'\n\t\tself.type=self.__class__.__name__\n\t\tself.dtype=cp.float32\n\t\ttry:\n\t\t\tself.shape=(None,*shape)\n\t\texcept:\n\t\t\tself.shape=(None,shape)\n\t\tself.param=0\n\t\tself.activation=echo"""
nnet_gpu/layers/dense.py,3,"b'#!/usr/bin/env python3\nfrom .base_layer import *\nfrom . import seqinst\nfrom ..stream_handler import stream_maps\n\nclass dense(Layer):\n\tdef __init__(self,num_out,input_shape=None,weights=None,biases=None,activation=echo,mean=0,std=0.01,name=None):\n\t\tsuper().__init__()\n\t\tself.dtype=cp.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tif input_shape is None:\n\t\t\tself.input_shape=seqinst.seq_instance.get_inp_shape()[0]\n\t\telse:\n\t\t\tself.input_shape=input_shape\n\t\tself.activation=activation\n\t\tif weights is None:\n\t\t\tself.weights = std*cp.random.randn(self.input_shape,num_out,dtype=self.dtype) + mean\n\t\t\t# weights/=np.sqrt(self.input_shape)\n\t\telse:\n\t\t\tif weights.shape!=(self.input_shape,num_out):\n\t\t\t\traise Exception(""weights should be of shape: ""+str((self.input_shape,num_out)))\n\t\t\telse:\n\t\t\t\tself.weights = cp.asarray(weights)\n\t\tif biases is None:\n\t\t\tself.biases = std*cp.random.randn(1,num_out,dtype=self.dtype) + mean\n\t\telse:\n\t\t\tif biases.shape!=(1,num_out):\n\t\t\t\traise Exception(""biases should be of shape: ""+str((1,num_out)))\n\t\t\telse:\n\t\t\t\tself.biases = cp.asarray(biases)\n\t\tself.kernels = self.weights\n\t\tself.w_m=cp.zeros_like(self.weights,dtype=self.dtype)\n\t\tself.w_v=cp.zeros_like(self.weights,dtype=self.dtype)\n\t\tself.b_m=cp.zeros_like(self.biases,dtype=self.dtype)\n\t\tself.b_v=cp.zeros_like(self.biases,dtype=self.dtype)\n\t\tself.shape=(None,num_out)\n\t\tself.param=self.input_shape*num_out + num_out\n\t\tself.not_softmax_cross_entrp=True\n\t\tif self.activation==echo:\n\t\t\tself.notEcho=False\n\t\telse:\n\t\t\tself.notEcho=True\n\t\tself.backp_stream=stream_maps.get_next_stream()\n\t\tself.grad_event=stream_maps.default_stream.record()\n\n\tdef forward(self,inp,training=True):\n\t\tself.inp=inp\n\t\tself.z_out=self.inp.dot(self.weights)+self.biases\n\t\tself.a_out=self.activation(self.z_out)\n\t\treturn self.a_out\n\n\tdef backprop(self,grads,layer=1):\n\t\tif self.notEcho and self.not_softmax_cross_entrp:\t\t\t# make it better in future\n\t\t\tgrads*=self.activation(self.z_out,self.a_out,derivative=True)\n\t\tself.grad_event=stream_maps.default_stream.record(self.grad_event)\n\t\twith self.backp_stream:\n\t\t\tself.backp_stream.wait_event(self.grad_event)\n\t\t\tself.d_c_w=self.inp.T.dot(grads)#/self.inp.shape[0]\n\t\tif layer:\n\t\t\td_c_a=grads.dot(self.weights.T)\n\t\telse:\n\t\t\td_c_a=0\n\t\twith self.backp_stream:\n\t\t\tself.d_c_b=grads.sum(axis=0,keepdims=True)\n\t\t\t# self.d_c_b=grads.mean(axis=0,keepdims=True)\n\t\treturn d_c_a'"
nnet_gpu/layers/dropout.py,1,"b'#!/usr/bin/env python3\nfrom .base_layer import *\nfrom . import seqinst\n\nclass dropout(Layer):\n\tdef __init__(self,rate=0.2,name=None):\t\t\t# rate = amount to drop\n\t\tsuper().__init__()\n\t\tself.dtype=cp.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tinput_shape=seqinst.seq_instance.get_inp_shape()\n\t\tself.shape=(None,*input_shape)\n\t\tself.batches=1\n\t\tself.rate=rate\n\t\tself.scale=cp.float32(1/(1-rate))\n\t\tself.mask=cp.random.random((self.batches,*input_shape),dtype=cp.float32)>self.rate\n\t\tself.param=0\n\t\tself.activation=echo\n\n\tdef forward(self,inp,training=True):\n\t\tif training:\n\t\t\tself.mask=(self.scale*(cp.random.random(inp.shape,dtype=cp.float32)>self.rate)).astype(cp.float32,copy=False) \t\t#generate mask with rate probability\n\t\t\treturn inp*self.mask\n\t\telse:\n\t\t\tself.mask.fill(1.0)\n\t\t\treturn inp\n\n\tdef backprop(self,grads,layer=1):\n\t\treturn grads*self.mask\n'"
nnet_gpu/layers/seqinst.py,0,b'#!/usr/bin/env python3\n\nseq_instance = None'
nnet_gpu/layers/shaping.py,2,"b'#!/usr/bin/env python3\nfrom .base_layer import *\nfrom . import seqinst\n\nclass flatten(Layer):\n\tdef __init__(self,name=None):\n\t\tsuper().__init__()\n\t\tself.type=self.__class__.__name__\n\t\tself.dtype=cp.float32\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tinput_shape=seqinst.seq_instance.get_inp_shape()\n\t\tself.r,self.c,self.channels=input_shape\n\t\tself.fsz=self.r*self.c*self.channels\n\t\tself.shape=(None,self.fsz)\n\t\tself.param=0\n\t\tself.activation=echo\n\n\tdef forward(self,inp,training=True):\n\t\treturn inp.reshape(-1,self.fsz)\n\n\tdef backprop(self,grads,layer=1):\n\t\treturn grads.reshape(-1,self.r,self.c,self.channels)\n\nclass reshape(Layer):\n\tdef __init__(self,target_shape,name=None):\n\t\tsuper().__init__()\n\t\tself.type=self.__class__.__name__\n\t\tself.dtype=cp.float32\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tself.input_shape=seqinst.seq_instance.get_inp_shape()\n\t\tself.target_shape=target_shape\n\t\ttt=1\n\t\tfor i in self.input_shape:\n\t\t\ttt*=i\n\t\tfor i in target_shape:\n\t\t\ttt/=i\n\t\tif tt!=1:\n\t\t\traise Exception(""Cannot reshape input ""+str(self.input_shape)+"" to ""+str(target_shape)+\'.\')\n\t\tself.shape=(None,*target_shape)\n\t\tself.param=0\n\t\tself.activation=echo\n\n\tdef forward(self,inp,training=True):\n\t\treturn inp.reshape(-1,*self.target_shape)\n\n\tdef backprop(self,grads,layer=1):\n\t\treturn grads.reshape(-1,*self.input_shape)'"
nnet_gpu/layers/upsampling.py,2,"b'#!/usr/bin/env python3\nfrom .base_layer import *\nfrom . import seqinst\n\nclass upsampling(Layer):\n\tdef __init__(self,input_shape=None,ksize=[2,2],stride=[2,2],name=None):\n\t\t#inp[batches,row,col,channels], kernels[ksz,ksz], stride[row,col]\n\t\tsuper().__init__()\n\t\tself.ksz=ksize[0]\n\t\tself.param=0\n\t\tself.dtype=cp.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tif input_shape is None:\n\t\t\tinput_shape=seqinst.seq_instance.get_inp_shape()\n\t\tself.batches=1\n\t\tself.row,self.col,self.channels=input_shape\n\t\tself.out_row,self.out_col=self.row*self.ksz,self.col*self.ksz\n\t\tself.shape=(None,self.out_row,self.out_col,self.channels)\n\t\tself.activation=echo\n\n\tdef forward(self,inp,training=True):\n\t\tself.input_shape=inp.shape\n\t\treturn inp.repeat(2,axis=2).repeat(2,axis=1)\n\n\tdef backprop(self,grads,layer=1):\n\t\t#grads[self.batches,esz,esz,self.channels],inp[self.batches,row,col,self.channels],kernels[self.ksz,self.ksz],stride[row,col]\n\t\tgrads=grads.reshape(self.input_shape[0],self.row,self.ksz,self.col,self.ksz,self.channels)\n\t\treturn grads.sum(axis=(2,4),keepdims=True).reshape(self.input_shape)'"
nnet_gpu/optimizers/__init__.py,0,b'#!/usr/bin/env python3\n\nfrom .optimizers import *'
nnet_gpu/optimizers/optimizers.py,0,"b""#!/usr/bin/env python3\nimport numpy as np\nimport cupy as cp\n\n### CAN TURN THESE INTO CLASSES\n\ndef iterative(sequence,learning_rate=0.01,beta=0):\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\tobj.weights-=(learning_rate*obj.d_c_w)\n\t\t\tobj.biases-=(learning_rate*obj.d_c_b)\n\ndef momentum(sequence,learning_rate=0.1,beta1=0.9,weight_decay=0.0005):\t\t# will have to specify it\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\tobj.w_m=beta1*obj.w_m - learning_rate*obj.d_c_w - weight_decay*learning_rate*obj.weights\n\t\t\tobj.weights+=obj.w_m\n\t\t\tobj.b_m=beta1*obj.b_m - learning_rate*obj.d_c_b - weight_decay*learning_rate*obj.biases\n\t\t\tobj.biases+=obj.b_m\n\ndef rmsprop(sequence,learning_rate=0.001,beta1=0.9,epsilon=1e-8):\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\tobj.w_v=beta1*obj.w_v + (1-beta1)*(obj.d_c_w**2)\n\t\t\tobj.weights-=learning_rate*(obj.d_c_w/cp.sqrt(obj.w_v+epsilon))\n\t\t\tobj.b_v=beta1*obj.b_v + (1-beta1)*(obj.d_c_b**2)\n\t\t\tobj.biases-=learning_rate*(obj.d_c_b/cp.sqrt(obj.b_v+epsilon))\n\ndef adagrad(sequence,learning_rate=0.01,beta1=0.9,epsilon=1e-8):\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\tobj.w_v+=(obj.d_c_w**2)\n\t\t\tobj.weights-=learning_rate*(obj.d_c_w/cp.sqrt(obj.w_v+epsilon))\n\t\t\tobj.b_v+=(obj.d_c_b**2)\n\t\t\tobj.biases-=learning_rate*(obj.d_c_b/cp.sqrt(obj.b_v+epsilon))\n\nadamkern=cp.ElementwiseKernel(\n\t'T grad, float32 one_minus_beta1, float32 one_minus_beta2, float32 epsilon, float32 learning_rate',\n\t'T param, T m, T v',\n\t'''\tm += one_minus_beta1 * (grad - m);\n\t\tv += one_minus_beta2 * (grad * grad - v);\n\t\tT mcap = m / one_minus_beta1;\n\t\tT vcap = v / one_minus_beta2;\n\t\tparam -= learning_rate * (mcap / (sqrt(vcap) + epsilon));''',\n\t'adamkern')\n\ndef adam(sequence,learning_rate=0.001,beta1=0.9,beta2=0.999,epsilon=1e-8):\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\t# Update weights\n\t\t\twith obj.backp_stream:\n\t\t\t\tadamkern(obj.d_c_w, 1-beta1, 1-beta2, epsilon, learning_rate, \n\t\t\t\t\tobj.weights, obj.w_m, obj.w_v)\n\t\t\t\t# Update biases\n\t\t\t\tif obj.bias_is_not_0:\n\t\t\t\t\tadamkern(obj.d_c_b, 1-beta1, 1-beta2, epsilon, learning_rate, \n\t\t\t\t\tobj.biases, obj.b_m, obj.b_v)\n\ndef adamax(sequence,learning_rate=0.002,beta1=0.9,beta2=0.999,epsilon=1e-8):\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\t# Update weights\n\t\t\tobj.w_m=beta1*obj.w_m + (1-beta1)*obj.d_c_w\n\t\t\tobj.w_v=cp.maximum(beta2*obj.w_v,abs(obj.d_c_w))\n\t\t\tobj.weights-=(learning_rate/(1-beta1))*(obj.w_m/(obj.w_v+epsilon))\n\t\t\t# Update biases\n\t\t\tobj.b_m=beta1*obj.b_m + (1-beta1)*obj.d_c_b\n\t\t\tobj.b_v=cp.maximum(beta2*obj.b_v,abs(obj.d_c_b))\n\t\t\tobj.biases-=(learning_rate/(1-beta1))*(obj.b_m/(obj.b_v+epsilon))\n\ndef adadelta(sequence,learning_rate=0.01,beta1=0.9,epsilon=1e-8):\n\tfor obj in sequence:\n\t\tif obj.param>0:\n\t\t\tobj.w_v=beta1*obj.w_v + (1-beta1)*(obj.d_c_w**2)\n\t\t\tobj.d_c_w=cp.sqrt((obj.w_m+epsilon)/(obj.w_v+epsilon))*obj.d_c_w\n\t\t\tobj.w_m=beta1*obj.w_m + (1-beta1)*(obj.d_c_w**2)\n\t\t\tobj.weights-=obj.d_c_w\n\n\t\t\tobj.b_v=beta1*obj.b_v + (1-beta1)*(obj.d_c_b**2)\n\t\t\tobj.d_c_b=cp.sqrt((obj.b_m+epsilon)/(obj.b_v+epsilon))*obj.d_c_b\n\t\t\tobj.b_m=beta1*obj.b_m + (1-beta1)*(obj.d_c_b**2)\n\t\t\tobj.biases-=obj.d_c_b"""
nnet_gpu/layers/convolution/__init__.py,0,b''
nnet_gpu/layers/convolution/conv2d.py,7,"b'#!/usr/bin/env python3\nfrom ..base_layer import *\nfrom .. import seqinst\nfrom ...stream_handler import stream_maps\nfrom .conv_utils import *\n\nclass conv2d(Layer):\n\tdef __init__(self,num_kernels=0, input_shape=None, kernel_size=0, kernels=None, activation=echo, biases=0, stride=(1,1), dilation=(1,1), padding=None, batches=1, backp=True, std=0.01, name=None, out_row=None, out_col=None, off_transpose=0):\n\t\t#input_shape[row,col,channels], kernels(channels,ksz[0],ksz[1],num_kernels), biases[1,num_ker], stride[row,col]\n\t\tsuper().__init__()\n\t\tif input_shape is None:\n\t\t\tinput_shape=seqinst.seq_instance.get_inp_shape()\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tself.activation=activation\n\t\tself.dtype=cp.float32\n\t\tself.stride=stride\n\t\tself.type=self.__class__.__name__\n\t\tself.input_shape=input_shape\n\t\tself.row,self.col,self.channels=input_shape\n\t\tself.batches=batches\n\t\tself.kernels=kernels\n\t\tself.biases=biases\n\t\tif self.kernels is None:\n\t\t\tif np.isscalar(kernel_size):\n\t\t\t\tself.kernel_size=(kernel_size,kernel_size)\n\t\t\telse:\n\t\t\t\tself.kernel_size=kernel_size\n\t\t\tself.kernels,self.biases = self.init_kernel_bias(self.channels,self.kernel_size,num_kernels,std=std,dtype=self.dtype)\n\t\telse:\n\t\t\tself.kernel_size=kernels.shape[1:3]\n\t\tself.weights = self.kernels\n\t\tself.bias_is_not_0=True\n\t\tif cp.isscalar(self.biases):\t\t\t\t# DO BETTER FIX\n\t\t\tif self.biases==0:\n\t\t\t\tself.bias_is_not_0=False\n\t\tself.dilation = dilation\n\t\tself.padding = padding\n\t\tif padding == None:\n\t\t\tself.padding = self.cal_padding(self.row, self.kernel_size[0], self.stride[0], self.dilation[0]), self.cal_padding(self.col, self.kernel_size[1], self.stride[1], self.dilation[1])\n\t\tif out_row is None:\n\t\t\tself.out_row=self.cal_outsize(self.row,self.kernel_size[0],self.stride[0],self.padding[0],self.dilation[0])\n\t\telse:\n\t\t\tself.out_row=out_row\n\t\tif out_col is None:\n\t\t\tself.out_col=self.cal_outsize(self.row,self.kernel_size[1],self.stride[1],self.padding[1],self.dilation[1])\n\t\telse:\n\t\t\tself.out_col=out_col\n\t\tself.param=(self.kernel_size[0]*self.kernel_size[1]*self.channels+1)*self.num_kernels\n\t\tif backp:\n\t\t\tself.backp_stream=stream_maps.get_next_stream()\n\t\t\tself.grad_event=stream_maps.default_stream.record()\n\t\t\tself.w_m=cp.zeros_like(self.weights,dtype=self.dtype)\n\t\t\tself.w_v=cp.zeros_like(self.weights,dtype=self.dtype)\n\t\t\tif self.bias_is_not_0:\n\t\t\t\tself.b_m=cp.zeros_like(self.biases,dtype=self.dtype)\n\t\t\t\tself.b_v=cp.zeros_like(self.biases,dtype=self.dtype)\n\t\t\tself.init_back()\n\n\tdef cal_padding(self,sz,ksz,stride,dilation):\n\t\treturn (ksz - 1) // 2\n\n\t@property\n\tdef num_kernels(self):\n\t\treturn self.kernels.shape[3]\n\n\t@property\n\tdef shape(self):\n\t\treturn (None,self.out_row,self.out_col,self.num_kernels)\n\n\t# @property\n\t# def bias_is_not_0(self):\n\t# \tif cp.isscalar(self.biases):\n\t# \t\tif self.biases==0:\n\t# \t\t\treturn False\n\t# \treturn True\n\n\tdef init_back(self):\n\t\tglobal conv2dtranspose\n\t\tfrom .conv2dtranspose import conv2dtranspose\n\t\tgrads = emptyHelper((self.batches,self.out_row,self.out_col,self.num_kernels))\n\t\tself.d_ker=conv2d(input_shape=(self.row,self.col,self.batches),kernels=grads,activation=echo,stride=(1,1),dilation=self.stride,padding=self.padding,backp=False,out_row=self.kernel_size[0],out_col=self.kernel_size[1])\n\t\tself.d_inp=conv2dtranspose(input_shape=(self.out_row,self.out_col,self.num_kernels),kernels=self.kernels,activation=echo,stride=self.stride,padding=self.padding,dilation=self.dilation,backp=False,out_row=self.row,out_col=self.col)\n\n\tdef init_kernel_bias(self,num_inp_channels, kernel_size, num_kernels,mean=0,std=0.01,dtype=cp.float32):\n\t\tweights = std*cp.random.randn(num_inp_channels, kernel_size[0], kernel_size[1], num_kernels,dtype=cp.float32) + mean\n\t\t# weights/=cp.sqrt(num_inp_channels)\n\t\tbias = std*cp.random.randn(1,num_kernels,dtype=cp.float32) + mean\n\t\treturn weights.astype(dtype,copy=False), bias.astype(dtype,copy=False)\n\n\tdef cal_outsize(self,sz,ksz,stride,pad,dilation=1):\n\t\tdksz = (ksz-1)*dilation + 1\t\t# dilated kernel\n\t\treturn (sz + 2*pad - dksz)//stride + 1\n\n\tdef forward(self,inp,training=True):\n\t\tinp=cp.ascontiguousarray(inp.transpose(0,3,1,2))\n\t\tself.inp=inp\n\t\t#inp[batches,channels,row,col]\n\t\tself.batches,self.channels,self.row,self.col=self.inp.shape\n\t\tcoled = cp.empty((self.batches, self.channels, self.kernel_size[0], self.kernel_size[1], self.out_row, self.out_col), dtype=self.dtype)\n\t\tim2col(self.inp.reduced_view(), self.row, self.col, self.out_row, self.out_col,\n\t\t\t\tself.kernel_size[0], self.kernel_size[1], self.stride[0], self.stride[1], self.padding[0], self.padding[1],\n\t\t\t\tself.dilation[0], self.dilation[1],\n\t\t\t\tcoled)\n\t\tself.z_out = cp.tensordot(coled, self.kernels, ((1, 2, 3), (0, 1, 2)))\n\t\tif self.bias_is_not_0:\n\t\t\tself.z_out=cp.add(self.z_out,self.biases)\n\t\tassert self.z_out.shape==(self.batches,self.out_row,self.out_col,self.num_kernels)\n\t\tself.a_out=self.activation(self.z_out)\n\t\treturn self.a_out\t\t\t\t# a_out[self.batches,self.out_row,self.out_col,self.num_kernels]\n\n\tdef backprop(self,grads,layer=1):\t\t\t\t\t\t\t\t#strides[batch,row,col,depth]\n\t\t""""""\n\t\tgrads[batches,esz,esz,num_kernels],inp[batches,channels,row,col],kernels(channels,ksz,ksz,num_kernels),biases[1,num_kernels]\n\t\t1.) For kernel gradient (self.d_ker):\n\t\t\t\tConvolve the gradients as kernel over saved input with stride 1 and dilate the gradient with\n\t\t\t\tcurrent stride value and same current padding.\n\t\t\t\tThe channels are treated as batches and batches as channel so it gives the correct kernel gradient shape.\n\n\t\t2.) For input gradient (self.d_inp):\n\t\t\t\tTransposed convolution over gradients with self.kernels as kernel. Should give original input shape back.\n\t\t\t\tAll parameters stride,padding,dilation are same as current.\n\n\t\t3.) For biases gradient :\n\t\t\t\tIt\'s just same as gradient. Just reshape and sum/mean it.\n\n\t\tTODO: Compare difference of sum and mean for bias.\n\t\t""""""\n\t\tif self.activation != echo:\n\t\t\tgrads*=self.activation(self.z_out,self.a_out,derivative=True)\n\t\tself.d_ker.kernels=grads \t\t\t\t\t\t# set gradients as kernel\n\t\tself.grad_event=stream_maps.default_stream.record(self.grad_event)\n\t\twith self.backp_stream:\n\t\t\tself.backp_stream.wait_event(self.grad_event)\n\t\t\tself.d_c_w=self.d_ker.forward(self.inp.transpose(1,2,3,0))\t#[channels,row,col,batches]\n\t\t# self.d_c_w/=self.batches\t\t#take mean change over batches\n\t\t# Backprop for inp.\tgrads[batches,esz,esz,num_kernels]\tself.flipped[num_kernels,kernel_size[0],kernel_size[1],channels]\n\t\tif layer:\n\t\t\td_inputs=cp.ascontiguousarray(self.d_inp.forward(grads))\n\t\t\tassert d_inputs.shape == (self.batches,self.row,self.col,self.channels),f""{(self.batches,self.row,self.col,self.channels)},{d_inputs.shape}""\n\t\telse:\n\t\t\td_inputs=0\n\t\tif self.bias_is_not_0:\n\t\t\twith self.backp_stream:\n\t\t\t\tself.d_c_b=grads.reshape(-1,self.num_kernels).sum(axis=0,keepdims=True)\n\t\t\t\t# self.d_c_b=grads.reshape(-1,self.num_kernels).mean(axis=0,keepdims=True)\n\t\treturn d_inputs'"
nnet_gpu/layers/convolution/conv2dtranspose.py,5,"b'#!/usr/bin/env python3\nfrom .conv2d import *\n\nclass conv2dtranspose(conv2d):\t\t\t\t\t\t\t\t\t\t# kernels are flipped of cpu version rn, cpukern = gpukern[:,::-1,::-1,:].transpose(3,1,2,0)\n\tdef __init__(self, num_kernels=0, input_shape=None, kernel_size=0, kernels=None, activation=echo, biases=0, stride=(1,1), dilation=(1,1), padding=None, batches=1, backp=True, std=0.01, name=None, out_row=None, out_col=None):\n\t\tsuper().__init__(num_kernels=num_kernels, input_shape=input_shape, kernel_size=kernel_size, kernels=kernels, activation=activation, biases=biases, stride=stride, dilation=dilation, padding=padding, batches=batches, backp=backp, std=std, name=name, out_row=out_row, out_col=out_col)\n\n\tdef cal_padding(self, sz, ksz, stride, dilation):\n\t\toht = self.cal_outsize(sz,ksz,stride,0,dilation)\n\t\treturn (stride * (sz - 1) + ksz - oht) // 2\n\t\n\t@property\n\tdef num_kernels(self):\n\t\treturn self.kernels.shape[0]\n\n\tdef init_kernel_bias(self, num_inp_channels, kernel_size, num_kernels, mean=0, std=0.01, dtype=cp.float32):\n\t\tweights = std*cp.random.randn(num_kernels, kernel_size[0], kernel_size[1], num_inp_channels, dtype=cp.float32) + mean\n\t\t# weights/=cp.sqrt(num_inp_channels)\n\t\tbias = std*cp.random.randn(1,num_kernels,dtype=cp.float32) + mean\n\t\treturn weights.astype(dtype,copy=False), bias.astype(dtype,copy=False)\n\n\tdef init_back(self):\n\t\tinp = emptyHelper((self.batches,self.row,self.col,self.channels))\n\t\tself.d_ker=conv2d(input_shape=(self.row,self.col,self.batches),kernels=inp,activation=echo,stride=(1,1),dilation=self.stride,padding=self.padding,backp=False,out_row=self.kernel_size[0],out_col=self.kernel_size[1])\n\t\tself.d_inp=conv2d(input_shape=(self.out_row,self.out_col,self.num_kernels),kernels=self.kernels,activation=echo,stride=self.stride,padding=self.padding,dilation=self.dilation,backp=False,out_row=self.row,out_col=self.col)\n\n\tdef cal_outsize(self,sz,ksz,stride,pad,dilation=1):\n\t\t# dksz = (ksz-1)*dilation + 1\t\t# dilated kernel\n\t\treturn sz*stride\n\n\tdef forward(self,inp,training=True):\n\t\tself.inp=inp.transpose(0,3,1,2)\n\t\t#inp[batches,channels,row,col]\n\t\tself.batches,self.channels,self.row,self.col=self.inp.shape\n\t\tcoled=cp.tensordot(self.kernels,self.inp,(3,1))\n\t\tcoled=cp.moveaxis(coled,3,0)\t\t\t\t# CAN WE REMOVE THIS SOMEHOW ??\n\t\tcoled=cp.ascontiguousarray(coled)\n\t\tself.z_out=cp.empty((self.batches, self.num_kernels, self.out_row, self.out_col), dtype=coled.dtype)\n\t\tcol2im(coled.reduced_view(), self.out_row, self.out_col, self.row, self.col,\n\t\t\t\tself.kernel_size[0], self.kernel_size[1], self.stride[0], self.stride[1], self.padding[0], self.padding[1],\n\t\t\t\tself.dilation[0], self.dilation[1],\n\t\t\t\tself.z_out)\n\t\tself.z_out=self.z_out.transpose(0,2,3,1)\n\t\tif self.bias_is_not_0:\n\t\t\tself.z_out=cp.add(self.z_out,self.biases)\t\t\t\t# z_out[batches,out_row,out_col,num_kernels]\n\t\tself.a_out=self.activation(self.z_out)\n\t\treturn self.a_out\t\t\t\t# a_out[batches,out_row,out_col,num_kernels]\n\n\tdef backprop(self,grads,layer=1):\n\t\tif self.activation != echo:\n\t\t\tgrads*=self.activation(self.z_out,self.a_out,derivative=True)\n\t\tself.d_ker.kernels=self.inp.transpose(0,2,3,1)\t# t makes[batches,row,col,channels]\n\t\tself.grad_event=stream_maps.default_stream.record(self.grad_event)\n\t\twith self.backp_stream:\n\t\t\tself.backp_stream.wait_event(self.grad_event)\n\t\t\tself.d_c_w=self.d_ker.forward(grads.transpose(3,1,2,0))\t#[channels,row,col,batches]\n\t\t# self.d_c_w/=self.batches\t\t#take mean change over batches\n\t\t# Backprop for inp.\tgrads[batches,esz,esz,num_kernels]\tself.flipped[num_kernels,kernel_size[0],kernel_size[1],channels]\n\t\tif layer:\n\t\t\td_inputs=cp.ascontiguousarray(self.d_inp.forward(grads))\n\t\t\tassert d_inputs.shape == (self.batches,self.row,self.col,self.channels),f""{(self.batches,self.row,self.col,self.channels)},{d_inputs.shape}""\n\t\telse:\n\t\t\td_inputs=0\n\t\tif self.bias_is_not_0:\n\t\t\twith self.backp_stream:\n\t\t\t\tself.d_c_b=grads.reshape(-1,self.num_kernels).sum(axis=0,keepdims=True)\n\t\t\t\t# self.d_c_b=grads.reshape(-1,self.num_kernels).mean(axis=0,keepdims=True)\n\t\treturn d_inputs'"
nnet_gpu/layers/convolution/conv_utils.py,0,"b""#!/usr/bin/env python3\nimport cupy as cp\n\n# Both kernels from chainer. May make more efficient by calculating indices once and reusing them all time,\n# like done in CPU version, instead of having to calculate everytime.\nim2col = cp.ElementwiseKernel(\n\t'raw T inp, int32 row, int32 col, int32 out_row, int32 out_col,'\n\t'int32 kh, int32 kw, int32 sy, int32 sx, int32 ph, int32 pw,'\n\t'int32 dy, int32 dx',\n\t'T coled',\n\t'''\n\t\tint c0 = i / (kh * kw * out_row * out_col);\t\t// select channel\n\t\tint ky = i / (kw * out_row * out_col) % kh;\t\t// select kernel y\n\t\tint kx = i / (out_row * out_col) % kw;\t\t\t// select kernel x\n\t\tint out_y = i / out_col % out_row;\t\t\t\t// select output y\n\t\tint out_x = i % out_col;\t\t\t\t\t\t// select output x\n\t\tint in_y = ky * dy + out_y * sy - ph;\n\t\tint in_x = kx * dx + out_x * sx - pw;\n\t\tif (in_y >= 0 && in_y < row && in_x >= 0 && in_x < col) {\t// if in image bounds\n\t\t\tcoled = inp[col * (in_y + row * c0) + in_x];\t// choose pixel\n\t\t} else {\n\t\t\tcoled = 0;\t\t\t\t\t\t// pad with 0\n\t\t}\n\t''',\n\t'im2col')\n\ncol2im = cp.ElementwiseKernel(\n\t'raw T coled, int32 row, int32 col, int32 out_row, int32 out_col,'\n\t'int32 kh, int32 kw, int32 sy, int32 sx, int32 ph, int32 pw,'\n\t'int32 dy, int32 dx',\n\t'T inp',\n\t'''\n\t\tint c0 = i / (row * col);\n\t\tint y  = i / col % row;\n\t\tint x  = i % col;\n\t\tT val = 0;\n\t\tfor (int ky = 0; ky < kh; ++ky) {\n\t\t\tint out_y = (y + ph - ky * dy);\n\t\t\tif (0 > out_y || out_y >= out_row * sy) continue;\n\t\t\tif (out_y % sy != 0) continue;\n\t\t\tout_y /= sy;\n\t\t\tfor (int kx = 0; kx < kw; ++kx) {\n\t\t\t\tint out_x = (x + pw - kx * dx);\n\t\t\t\tif (0 > out_x || out_x >= out_col * sx) continue;\n\t\t\t\tif (out_x % sx != 0) continue;\n\t\t\t\tout_x /= sx;\n\t\t\t\tint k = out_y + out_row * (kx + kw * (ky + kh * c0));\n\t\t\t\tval = val + coled[out_x + out_col * k];\n\t\t\t}\n\t\t}\n\t\tinp = val;\n\t''',\n\t'col2im')\n\nclass emptyHelper:\n\tdef __init__(self,shape):\n\t\tself.shape=shape"""
nnet_gpu/layers/pooling/globalAveragePool.py,3,"b'#!/usr/bin/env python3\nfrom .max_pool import *\n\nclass globalAveragePool(Layer):\n\tdef __init__(self,input_shape=None,name=None):\n\t\tsuper().__init__()\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tif input_shape is None:\n\t\t\tinput_shape=seqinst.seq_instance.get_inp_shape()\n\t\tself.param=0\n\t\tself.batches=1\n\t\tself.row,self.col,self.channels=input_shape\n\t\tself.Ncount=self.row*self.col\n\t\tself.shape=(None,self.channels)\n\n\tdef forward(self,inp,training=True):\n\t\tself.input_shape=inp.shape\n\t\tself.batches=self.input_shape[0]\n\t\tinp=inp.reshape(self.batches,self.Ncount,self.channels)\n\t\toutput=inp.mean(axis=1)\n\t\treturn output.reshape(self.batches,self.channels)\n\n\tdef backprop(self,grads,layer=1):\n\t\t# grads/=self.Ncount\n\t\tz_out=grads.repeat(self.Ncount,axis=0).reshape(self.batches,self.row,self.col,self.channels)\n\t\treturn z_out'"
nnet_gpu/layers/pooling/max_pool.py,3,"b'#!/usr/bin/env python3\nfrom ..base_layer import *\nfrom .. import seqinst\nfrom ...stream_handler import stream_maps\n\nclass max_pool(Layer):\n\tdef __init__(self,input_shape=None,ksize=[2,2],stride=[2,2],name=None):\n\t\t#inp[batches,row,col,channels], kernels[ksz,ksz], stride[row,col]\n\t\tsuper().__init__()\n\t\tself.ksz=ksize[0]\n\t\tself.param=0\n\t\tself.dtype=cp.float32\n\t\tself.type=self.__class__.__name__\n\t\tif name is None:\n\t\t\tself.name=self.__class__.__name__\n\t\telse:\n\t\t\tself.name=name\n\t\tif input_shape is None:\n\t\t\tinput_shape=seqinst.seq_instance.get_inp_shape()\n\t\tself.batches=1\n\t\tself.row,self.col,self.channels=input_shape\n\t\t# self.rem_col=self.row%self.ksz\n\t\t# if self.rem_col:\n\t\t# \tself.padded=cp.zeros((self.batches,self.row,self.col,self.channels),dtype=self.dtype)\n\t\tself.out_row,self.out_col=self.row//self.ksz,self.col//self.ksz\n\t\t# self.row-=self.rem_col\n\t\t# self.col-=self.rem_col\n\t\tself.shape=(None,self.out_row,self.out_col,self.channels)\n\t\tself.mask_stream=stream_maps.get_next_stream()\n\t\tself.out_event=stream_maps.default_stream.record()\n\n\tdef forward(self,inp,training=True):\n\t\tself.input_shape=inp.shape\n\t\tbatches=self.input_shape[0]\n\t\t# if self.rem_col:\n\t\t# \tinp=inp[:,:-self.rem_col,:-self.rem_col,:]\n\t\t# \tif self.batches!=batches:\n\t\t# \t\tself.padded=cp.zeros(self.input_shape,dtype=self.dtype)\n\t\tself.batches=batches\n\t\tinp=inp.reshape(self.batches,self.out_row,self.ksz,self.out_col,self.ksz,self.channels)\n\t\toutput=inp.max(axis=(2,4),keepdims=True)\n\t\tself.out_event=stream_maps.default_stream.record(self.out_event)\n\t\twith self.mask_stream:\n\t\t\tself.mask_stream.wait_event(self.out_event)\n\t\t\tself.mask=(inp==output)\n\t\treturn output.reshape(self.batches,self.out_row,self.out_col,self.channels)\n\n\tdef backprop(self,grads,layer=1):\n\t\t#grads[self.batches,esz,esz,self.channels],inp[self.batches,row,col,self.channels],kernels[self.ksz,self.ksz],stride[row,col]\n\t\tz_out=(self.mask*grads.reshape(self.batches,self.out_row,1,self.out_col,1,self.channels))\n\t\t# if self.rem_col:\n\t\t# \tself.padded[:,:-self.rem_col,:-self.rem_col,:]=z_out.reshape(self.batches,self.row,self.col,self.channels)\n\t\t# \treturn self.padded.reshape(self.input_shape)\n\t\t# else:\n\t\treturn z_out.reshape(self.input_shape)'"
