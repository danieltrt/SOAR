file_path,api_count,code
LeNet.py,22,"b'# -*- coding: utf-8 -*-\n\'\'\'\nAuthor: Site Li\nWebsite: http://blog.csdn.net/site1997\n\'\'\'\nimport numpy as np\nfrom scipy.signal import convolve2d\nfrom skimage.measure import block_reduce\nimport fetch_MNIST\n\n\nclass LeNet(object):\n    #The network is like:\n    #    conv1 -> pool1 -> conv2 -> pool2 -> fc1 -> relu -> fc2 -> relu -> softmax\n    # l0      l1       l2       l3        l4     l5      l6     l7      l8        l9\n    def __init__(self, lr=0.1):\n        self.lr = lr\n        # 6 convolution kernal, each has 1 * 5 * 5 size\n        self.conv1 = xavier_init(6, 1, 5, 5)\n        # the size for mean pool is 2 * 2, stride = 2\n        self.pool1 = [2, 2]\n        # 16 convolution kernal, each has 6 * 5 * 5 size\n        self.conv2 = xavier_init(16, 6, 5, 5)\n        # the size for mean pool is 2 * 2, stride = 2\n        self.pool2 = [2, 2]\n        # fully connected layer 256 -> 200\n        self.fc1 = xavier_init(256, 200, fc=True)\n        # fully connected layer 200 -> 10\n        self.fc2 = xavier_init(200, 10, fc=True)\n\n    def forward_prop(self, input_data):\n        self.l0 = np.expand_dims(input_data, axis=1) / 255   # (batch_sz, 1, 28, 28)\n        self.l1 = self.convolution(self.l0, self.conv1)      # (batch_sz, 6, 24, 24)\n        self.l2 = self.mean_pool(self.l1, self.pool1)        # (batch_sz, 6, 12, 12)\n        self.l3 = self.convolution(self.l2, self.conv2)      # (batch_sz, 16, 8, 8)\n        self.l4 = self.mean_pool(self.l3, self.pool2)        # (batch_sz, 16, 4, 4)\n        self.l5 = self.fully_connect(self.l4, self.fc1)      # (batch_sz, 200)\n        self.l6 = self.relu(self.l5)                         # (batch_sz, 200)\n        self.l7 = self.fully_connect(self.l6, self.fc2)      # (batch_sz, 10)\n        self.l8 = self.relu(self.l7)                         # (batch_sz, 10)\n        self.l9 = self.softmax(self.l8)                      # (batch_sz, 10)\n        return self.l9\n\n    def backward_prop(self, softmax_output, output_label):\n        l8_delta             = (output_label - softmax_output) / softmax_output.shape[0]\n        l7_delta             = self.relu(self.l8, l8_delta, deriv=True)                     # (batch_sz, 10)\n        l6_delta, self.fc2   = self.fully_connect(self.l6, self.fc2, l7_delta, deriv=True)  # (batch_sz, 200)\n        l5_delta             = self.relu(self.l6, l6_delta, deriv=True)                     # (batch_sz, 200)\n        l4_delta, self.fc1   = self.fully_connect(self.l4, self.fc1, l5_delta, deriv=True)  # (batch_sz, 16, 4, 4)\n        l3_delta             = self.mean_pool(self.l3, self.pool2, l4_delta, deriv=True)    # (batch_sz, 16, 8, 8)\n        l2_delta, self.conv2 = self.convolution(self.l2, self.conv2, l3_delta, deriv=True)  # (batch_sz, 6, 12, 12)\n        l1_delta             = self.mean_pool(self.l1, self.pool1, l2_delta, deriv=True)    # (batch_sz, 6, 24, 24)\n        l0_delta, self.conv1 = self.convolution(self.l0, self.conv1, l1_delta, deriv=True)  # (batch_sz, 1, 28, 28)\n\n    def convolution(self, input_map, kernal, front_delta=None, deriv=False):\n        N, C, W, H = input_map.shape\n        K_NUM, K_C, K_W, K_H = kernal.shape\n        if deriv == False:\n            feature_map = np.zeros((N, K_NUM, W-K_W+1, H-K_H+1))\n            for imgId in range(N):\n                for kId in range(K_NUM):\n                    for cId in range(C):\n                        feature_map[imgId][kId] += \\\n                          convolve2d(input_map[imgId][cId], kernal[kId,cId,:,:], mode=\'valid\')\n            return feature_map\n        else :\n            # front->back (propagate loss)\n            back_delta = np.zeros((N, C, W, H))\n            kernal_gradient = np.zeros((K_NUM, K_C, K_W, K_H))\n            padded_front_delta = \\\n              np.pad(front_delta, [(0,0), (0,0), (K_W-1, K_H-1), (K_W-1, K_H-1)], mode=\'constant\', constant_values=0)\n            for imgId in range(N):\n                for cId in range(C):\n                    for kId in range(K_NUM):\n                        back_delta[imgId][cId] += \\\n                          convolve2d(padded_front_delta[imgId][kId], kernal[kId,cId,::-1,::-1], mode=\'valid\')\n                        kernal_gradient[kId][cId] += \\\n                          convolve2d(front_delta[imgId][kId], input_map[imgId,cId,::-1,::-1], mode=\'valid\')\n            # update weights\n            kernal += self.lr * kernal_gradient\n            return back_delta, kernal\n\n    def mean_pool(self, input_map, pool, front_delta=None, deriv=False):\n        N, C, W, H = input_map.shape\n        P_W, P_H = tuple(pool)\n        if deriv == False:\n            feature_map = np.zeros((N, C, W/P_W, H/P_H))\n            feature_map = block_reduce(input_map, tuple((1, 1, P_W, P_H)), func=np.mean)\n            return feature_map\n        else :\n            # front->back (propagate loss)\n            back_delta = np.zeros((N, C, W, H))\n            back_delta = front_delta.repeat(P_W, axis = 2).repeat(P_H, axis = 3)\n            back_delta /= (P_W * P_H)\n            return back_delta\n\n    def fully_connect(self, input_data, fc, front_delta=None, deriv=False):\n        N = input_data.shape[0]\n        if deriv == False:\n            output_data = np.dot(input_data.reshape(N, -1), fc)\n            return output_data\n        else :\n            # front->back (propagate loss)\n            back_delta = np.dot(front_delta, fc.T).reshape(input_data.shape)\n            # update weights\n            fc += self.lr * np.dot(input_data.reshape(N, -1).T, front_delta)\n            return back_delta, fc\n\n    def relu(self, x, front_delta=None, deriv=False):\n        if deriv == False:\n            return x * (x > 0)\n        else :\n            # propagate loss\n            back_delta = front_delta * 1. * (x > 0)\n            return back_delta\n\n    def softmax(self, x):\n        y = list()\n        for t in x:\n            e_t = np.exp(t - np.max(t))\n            y.append(e_t / e_t.sum())\n        return np.array(y)\n\n\ndef xavier_init(c1, c2, w=1, h=1, fc=False):\n    fan_1 = c2 * w * h\n    fan_2 = c1 * w * h\n    ratio = np.sqrt(6.0 / (fan_1 + fan_2))\n    params = ratio * (2*np.random.random((c1, c2, w, h)) - 1)\n    if fc == True:\n        params = params.reshape(c1, c2)\n    return params\n\ndef convertToOneHot(labels):\n    oneHotLabels = np.zeros((labels.size, labels.max()+1))\n    oneHotLabels[np.arange(labels.size), labels] = 1\n    return oneHotLabels\n\ndef shuffle_dataset(data, label):\n    N = data.shape[0]\n    index = np.random.permutation(N)\n    x = data[index, :, :]; y = label[index, :]\n    return x, y\n\nif __name__ == \'__main__\':\n    train_imgs = fetch_MNIST.load_train_images()\n    train_labs = fetch_MNIST.load_train_labels().astype(int)\n    # size of data;                  batch size\n    data_size = train_imgs.shape[0]; batch_sz = 64;\n    # learning rate; max iteration;    iter % mod (avoid index out of range)\n    lr = 0.01;     max_iter = 50000; iter_mod = int(data_size/batch_sz)\n    train_labs = convertToOneHot(train_labs)\n    my_CNN = LeNet(lr)\n    for iters in range(max_iter):\n        # starting index and ending index for input data\n        st_idx = (iters % iter_mod) * batch_sz\n        # shuffle the dataset\n        if st_idx == 0:\n            train_imgs, train_labs = shuffle_dataset(train_imgs, train_labs)\n        input_data = train_imgs[st_idx : st_idx + batch_sz]\n        output_label = train_labs[st_idx : st_idx + batch_sz]\n        softmax_output = my_CNN.forward_prop(input_data)\n        if iters % 50 == 0:\n            # calculate accuracy\n            correct_list = [ int(np.argmax(softmax_output[i])==np.argmax(output_label[i])) for i in range(batch_sz) ]\n            accuracy = float(np.array(correct_list).sum()) / batch_sz\n            # calculate loss\n            correct_prob = [ softmax_output[i][np.argmax(output_label[i])] for i in range(batch_sz) ]\n            correct_prob = filter(lambda x: x > 0, correct_prob)\n            loss = -1.0 * np.sum(np.log(correct_prob))\n            print ""The %d iters result:"" % iters\n            print ""The accuracy is %f The loss is %f "" % (accuracy, loss)\n        my_CNN.backward_prop(softmax_output, output_label)\n'"
fetch_MNIST.py,8,"b'# encoding: utf-8\n""""""\n@author: monitor1379 \n@contact: yy4f5da2@hotmail.com\n@site: www.monitor1379.com\n\n@version: 1.0\n@license: Apache Licence\n@file: mnist_decoder.py\n@time: 2016/8/16 20:03\n\n\xe5\xaf\xb9MNIST\xe6\x89\x8b\xe5\x86\x99\xe6\x95\xb0\xe5\xad\x97\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xbabmp\xe5\x9b\xbe\xe7\x89\x87\xe6\x96\x87\xe4\xbb\xb6\xe6\xa0\xbc\xe5\xbc\x8f\xe3\x80\x82\n\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\x8b\xe8\xbd\xbd\xe5\x9c\xb0\xe5\x9d\x80\xe4\xb8\xbahttp://yann.lecun.com/exdb/mnist\xe3\x80\x82\n\xe7\x9b\xb8\xe5\x85\xb3\xe6\xa0\xbc\xe5\xbc\x8f\xe8\xbd\xac\xe6\x8d\xa2\xe8\xa7\x81\xe5\xae\x98\xe7\xbd\x91\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xbb\xa3\xe7\xa0\x81\xe6\xb3\xa8\xe9\x87\x8a\xe3\x80\x82\n\n========================\n\xe5\x85\xb3\xe4\xba\x8eIDX\xe6\x96\x87\xe4\xbb\xb6\xe6\xa0\xbc\xe5\xbc\x8f\xe7\x9a\x84\xe8\xa7\xa3\xe6\x9e\x90\xe8\xa7\x84\xe5\x88\x99\xef\xbc\x9a\n========================\nTHE IDX FILE FORMAT\n\nthe IDX file format is a simple format for vectors and multidimensional matrices of various numerical types.\nThe basic format is\n\nmagic number\nsize in dimension 0\nsize in dimension 1\nsize in dimension 2\n.....\nsize in dimension N\ndata\n\nThe magic number is an integer (MSB first). The first 2 bytes are always 0.\n\nThe third byte codes the type of the data:\n0x08: unsigned byte\n0x09: signed byte\n0x0B: short (2 bytes)\n0x0C: int (4 bytes)\n0x0D: float (4 bytes)\n0x0E: double (8 bytes)\n\nThe 4-th byte codes the number of dimensions of the vector/matrix: 1 for vectors, 2 for matrices....\n\nThe sizes in each dimension are 4-byte integers (MSB first, high endian, like in most non-Intel processors).\n\nThe data is stored like in a C array, i.e. the index in the last dimension changes the fastest.\n""""""\n\nimport numpy as np\nimport struct\nimport matplotlib.pyplot as plt\n\n#data_path = \'/Users/didi/Desktop/python_workspace/Neural Network/data/\'\n# \xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe6\x96\x87\xe4\xbb\xb6\ntrain_images_idx3_ubyte_file = \'./data/train-images-idx3-ubyte\'\n# \xe8\xae\xad\xe7\xbb\x83\xe9\x9b\x86\xe6\xa0\x87\xe7\xad\xbe\xe6\x96\x87\xe4\xbb\xb6\ntrain_labels_idx1_ubyte_file = \'./data/train-labels-idx1-ubyte\'\n\n# \xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe6\x96\x87\xe4\xbb\xb6\ntest_images_idx3_ubyte_file = \'./data/t10k-images-idx3-ubyte\'\n# \xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe6\xa0\x87\xe7\xad\xbe\xe6\x96\x87\xe4\xbb\xb6\ntest_labels_idx1_ubyte_file = \'./data/t10k-labels-idx1-ubyte\'\n\n\ndef decode_idx3_ubyte(idx3_ubyte_file):\n    """"""\n    \xe8\xa7\xa3\xe6\x9e\x90idx3\xe6\x96\x87\xe4\xbb\xb6\xe7\x9a\x84\xe9\x80\x9a\xe7\x94\xa8\xe5\x87\xbd\xe6\x95\xb0\n    :param idx3_ubyte_file: idx3\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\n    :return: \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\n    """"""\n    # \xe8\xaf\xbb\xe5\x8f\x96\xe4\xba\x8c\xe8\xbf\x9b\xe5\x88\xb6\xe6\x95\xb0\xe6\x8d\xae\n    bin_data = open(idx3_ubyte_file, \'rb\').read()\n\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb4\xe4\xbf\xa1\xe6\x81\xaf\xef\xbc\x8c\xe4\xbe\x9d\xe6\xac\xa1\xe4\xb8\xba\xe9\xad\x94\xe6\x95\xb0\xe3\x80\x81\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe9\x87\x8f\xe3\x80\x81\xe6\xaf\x8f\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe9\xab\x98\xe3\x80\x81\xe6\xaf\x8f\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe5\xae\xbd\n    offset = 0\n    fmt_header = \'>iiii\'\n    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)\n    print \'\xe9\xad\x94\xe6\x95\xb0:%d, \xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe9\x87\x8f: %d\xe5\xbc\xa0, \xe5\x9b\xbe\xe7\x89\x87\xe5\xa4\xa7\xe5\xb0\x8f: %d*%d\' % (magic_number, num_images, num_rows, num_cols)\n\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\n    image_size = num_rows * num_cols\n    offset += struct.calcsize(fmt_header)\n    fmt_image = \'>\' + str(image_size) + \'B\'\n    images = np.empty((num_images, num_rows, num_cols))\n    for i in range(num_images):\n        if (i + 1) % 10000 == 0:\n            print \'\xe5\xb7\xb2\xe8\xa7\xa3\xe6\x9e\x90 %d\' % (i + 1) + \'\xe5\xbc\xa0\'\n        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))\n        offset += struct.calcsize(fmt_image)\n    return images\n\n\ndef decode_idx1_ubyte(idx1_ubyte_file):\n    """"""\n    \xe8\xa7\xa3\xe6\x9e\x90idx1\xe6\x96\x87\xe4\xbb\xb6\xe7\x9a\x84\xe9\x80\x9a\xe7\x94\xa8\xe5\x87\xbd\xe6\x95\xb0\n    :param idx1_ubyte_file: idx1\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\n    :return: \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\n    """"""\n    # \xe8\xaf\xbb\xe5\x8f\x96\xe4\xba\x8c\xe8\xbf\x9b\xe5\x88\xb6\xe6\x95\xb0\xe6\x8d\xae\n    bin_data = open(idx1_ubyte_file, \'rb\').read()\n\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb4\xe4\xbf\xa1\xe6\x81\xaf\xef\xbc\x8c\xe4\xbe\x9d\xe6\xac\xa1\xe4\xb8\xba\xe9\xad\x94\xe6\x95\xb0\xe5\x92\x8c\xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\n    offset = 0\n    fmt_header = \'>ii\'\n    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)\n    print \'\xe9\xad\x94\xe6\x95\xb0:%d, \xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe9\x87\x8f: %d\xe5\xbc\xa0\' % (magic_number, num_images)\n\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\n    offset += struct.calcsize(fmt_header)\n    fmt_image = \'>B\'\n    labels = np.empty(num_images)\n    for i in range(num_images):\n        if (i + 1) % 10000 == 0:\n            print \'\xe5\xb7\xb2\xe8\xa7\xa3\xe6\x9e\x90 %d\' % (i + 1) + \'\xe5\xbc\xa0\'\n        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\n        offset += struct.calcsize(fmt_image)\n    return labels\n\n\ndef load_train_images(idx_ubyte_file=train_images_idx3_ubyte_file):\n    """"""\n    TRAINING SET IMAGE FILE (train-images-idx3-ubyte):\n    [offset] [type]          [value]          [description]\n    0000     32 bit integer  0x00000803(2051) magic number\n    0004     32 bit integer  60000            number of images\n    0008     32 bit integer  28               number of rows\n    0012     32 bit integer  28               number of columns\n    0016     unsigned byte   ??               pixel\n    0017     unsigned byte   ??               pixel\n    ........\n    xxxx     unsigned byte   ??               pixel\n    Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n\n    :param idx_ubyte_file: idx\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\n    :return: n*row*col\xe7\xbb\xb4np.array\xe5\xaf\xb9\xe8\xb1\xa1\xef\xbc\x8cn\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe9\x87\x8f\n    """"""\n    return decode_idx3_ubyte(idx_ubyte_file)\n\n\ndef load_train_labels(idx_ubyte_file=train_labels_idx1_ubyte_file):\n    """"""\n    TRAINING SET LABEL FILE (train-labels-idx1-ubyte):\n    [offset] [type]          [value]          [description]\n    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n    0004     32 bit integer  60000            number of items\n    0008     unsigned byte   ??               label\n    0009     unsigned byte   ??               label\n    ........\n    xxxx     unsigned byte   ??               label\n    The labels values are 0 to 9.\n\n    :param idx_ubyte_file: idx\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\n    :return: n*1\xe7\xbb\xb4np.array\xe5\xaf\xb9\xe8\xb1\xa1\xef\xbc\x8cn\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe9\x87\x8f\n    """"""\n    return decode_idx1_ubyte(idx_ubyte_file)\n\n\ndef load_test_images(idx_ubyte_file=test_images_idx3_ubyte_file):\n    """"""\n    TEST SET IMAGE FILE (t10k-images-idx3-ubyte):\n    [offset] [type]          [value]          [description]\n    0000     32 bit integer  0x00000803(2051) magic number\n    0004     32 bit integer  10000            number of images\n    0008     32 bit integer  28               number of rows\n    0012     32 bit integer  28               number of columns\n    0016     unsigned byte   ??               pixel\n    0017     unsigned byte   ??               pixel\n    ........\n    xxxx     unsigned byte   ??               pixel\n    Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n\n    :param idx_ubyte_file: idx\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\n    :return: n*row*col\xe7\xbb\xb4np.array\xe5\xaf\xb9\xe8\xb1\xa1\xef\xbc\x8cn\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe9\x87\x8f\n    """"""\n    return decode_idx3_ubyte(idx_ubyte_file)\n\n\ndef load_test_labels(idx_ubyte_file=test_labels_idx1_ubyte_file):\n    """"""\n    TEST SET LABEL FILE (t10k-labels-idx1-ubyte):\n    [offset] [type]          [value]          [description]\n    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n    0004     32 bit integer  10000            number of items\n    0008     unsigned byte   ??               label\n    0009     unsigned byte   ??               label\n    ........\n    xxxx     unsigned byte   ??               label\n    The labels values are 0 to 9.\n\n    :param idx_ubyte_file: idx\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\n    :return: n*1\xe7\xbb\xb4np.array\xe5\xaf\xb9\xe8\xb1\xa1\xef\xbc\x8cn\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe9\x87\x8f\n    """"""\n    return decode_idx1_ubyte(idx_ubyte_file)\n\n\n\n\ndef run():\n    train_images = load_train_images() # (60000, 28, 28) 0~255\n    train_labels = load_train_labels() # (60000,)        1~10\n    # test_images = load_test_images()\n    # test_labels = load_test_labels()\n    print type(train_images), train_images.shape\n    print type(train_labels), train_labels.shape\n\n    # \xe6\x9f\xa5\xe7\x9c\x8b\xe5\x89\x8d\xe5\x8d\x81\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\x8a\xe5\x85\xb6\xe6\xa0\x87\xe7\xad\xbe\xe4\xbb\xa5\xe8\xaf\xbb\xe5\x8f\x96\xe6\x98\xaf\xe5\x90\xa6\xe6\xad\xa3\xe7\xa1\xae\n    for i in range(10):\n        print train_labels[i]\n        print np.max(train_images), np.min(train_images)\n        plt.imshow(train_images[i], cmap=\'gray\')\n        plt.show()\n    print \'done\'\n\nif __name__ == \'__main__\':\n    run()\n\n\'\'\'\n\xe4\xbd\x9c\xe8\x80\x85\xef\xbc\x9amonitor1379\n\xe9\x93\xbe\xe6\x8e\xa5\xef\xbc\x9ahttps://www.jianshu.com/p/84f72791806f\n\xe4\xbe\x86\xe6\xba\x90\xef\xbc\x9a\xe7\xae\x80\xe4\xb9\xa6\n\xe8\x91\x97\xe4\xbd\x9c\xe6\x9d\x83\xe5\xbd\x92\xe4\xbd\x9c\xe8\x80\x85\xe6\x89\x80\xe6\x9c\x89\xe3\x80\x82\xe5\x95\x86\xe4\xb8\x9a\xe8\xbd\xac\xe8\xbd\xbd\xe8\xaf\xb7\xe8\x81\x94\xe7\xb3\xbb\xe4\xbd\x9c\xe8\x80\x85\xe8\x8e\xb7\xe5\xbe\x97\xe6\x8e\x88\xe6\x9d\x83\xef\xbc\x8c\xe9\x9d\x9e\xe5\x95\x86\xe4\xb8\x9a\xe8\xbd\xac\xe8\xbd\xbd\xe8\xaf\xb7\xe6\xb3\xa8\xe6\x98\x8e\xe5\x87\xba\xe5\xa4\x84\xe3\x80\x82\n\'\'\''"
