file_path,api_count,code
main.py,3,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Fri Nov 16 15:40:59 2018\n\n@author: nsde\n""""""\n\nif __name__ == ""__main__"":\n    import tensorflow as tf\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from libcpab import Cpab\n\n    from tensorflow import keras\n    \n    class mylayer(keras.layers.Layer):\n        def __init__(self):\n            self.cpab = Cpab([5,], backend=\'tensorflow\', device=\'gpu\')\n            super().__init__()\n            \n        def call(self, x):\n            return self.cpab.transform_data(x,\n                                            self.cpab.sample_transformation(100),\n                                            outsize=(50,))\n            \n    model = keras.Sequential()\n    model.add(keras.layers.InputLayer(input_shape=(50,10), batch_size=100))\n    model.add(mylayer())\n    model.add(keras.layers.Conv1D(32, 7, activation=\'relu\'))\n    model.add(keras.layers.Conv1D(64, 5, activation=\'relu\'))\n    model.add(keras.layers.Conv1D(128, 3, activation=\'relu\'))\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(10, activation=\'softmax\'))\n    \n    model.compile(optimizer=\'adam\', loss=\'categorical_crossentropy\')\n    \n    X = np.random.rand(1000,50,10)\n    y = np.random.random_integers(0,9,1000)\n    y = keras.utils.to_categorical(y, 10)\n    \n    model.fit(X,y,batch_size=100,epochs=10)\n    model.save_weights(\'myweights.h5\')\n    model.load_weights(\'myweights.h5\')\n    \n    \n#    T = Cpab([3, 3], backend=\'tensorflow\', device=\'gpu\', zero_boundary=True,\n#             volume_perservation=False, override=False)\n#\n#    theta = T.sample_transformation()\n#    #theta = T.identity()\n#\n#    grid = T.uniform_meshgrid([350, 350])\n#\n#    grid_t = T.transform_grid(grid, theta)\n#    \n#    im = plt.imread(\'version1.4/data/cat.jpg\')\n#    im = np.expand_dims(im, 0) / 255\n#    im = tf.cast(im, tf.float32)\n#    \n#    im_t = T.interpolate(im, grid_t, outsize=(350, 350))\n#    \n#    im = im.numpy()\n#    im_t = im_t.numpy()\n#    \n#    plt.figure()\n#    plt.imshow(im[0])\n#    plt.axis(\'off\')    \n#    plt.tight_layout()\n#    plt.imsave(\'data/cat.jpg\', im[0])\n#    \n#    plt.figure()\n#    plt.imshow(im_t[0])\n#    plt.axis(\'off\')    \n#    plt.tight_layout()\n#    plt.imsave(\'data/deform_cat.jpg\', im_t[0])\n#\n#    T.visualize_vectorfield(theta)\n#    plt.axis([0,1,0,1])\n#    plt.tight_layout()\n#    plt.savefig(\'data/velocity_field.jpg\')\n#    plt.show()\n'"
setup.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Wed Nov 21 15:26:46 2018\n\n@author: nsde\n""""""\n\n#%%\nfrom distutils.core import setup\n\n#%%\nsetup(name = ""libcpab"",\n      version = ""2.0"",\n      description = ""Diffiomorphism for dummies"",\n      author = ""Nicki Skafte Detlefsen"",\n      author_email = ""nsde@dtu.dk"",\n      packages = [""libcpab""],\n      license = ""MIT"",\n      long_description = open(\'README.md\').read())'"
examples/alignment_demo.py,1,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Fri Aug  9 12:51:31 2019\n\n@author: nsde\n""""""\n\n#%%\nfrom libcpab import Cpab\nfrom libcpab import CpabAligner\nfrom libcpab.core.utility import get_dir\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport argparse\n\n#%%\ndef argparser():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--backend\', default=\'numpy\',\n                        choices=[\'numpy\', \'tensorflow\', \'pytorch\'],\n                        help=\'backend to run demo with\')\n    parser.add_argument(\'--device\', default=\'cpu\',\n                        choices=[\'cpu\', \'gpu\'],\n                        help=\'device to run demo on\')\n    parser.add_argument(\'--alignment_type\', default=\'sampling\',\n                        choices=[\'sampling\', \'gradient\'],\n                        help=\'how to align samples\')\n    parser.add_argument(\'--maxiter\', type=int, default=100,\n                        help=\'number of iteration in alignment algorithm\')\n    return parser.parse_args()\n\n\n#%%\nif __name__ == ""__main__"":\n    # Input arguments\n    args = argparser()\n\n    # Load some data\n    data = plt.imread(get_dir(__file__) + \'/../data/cat.jpg\') / 255\n    data = np.expand_dims(data, 0)  # create batch effect\n\n    # Create transformer class\n    T = Cpab([1, 1], backend=args.backend, device=args.device, zero_boundary=True,\n             volume_perservation=False, override=False)\n\n    # Sample random transformation\n    theta = 0.5*T.sample_transformation(1)\n\n    # Convert data to the backend format\n    data = T.backend.to(data, device=args.device)\n\n    # Pytorch have other data format than tensorflow and numpy, color information\n    # is the second dim. We need to correct this before and after\n    data = data.permute(0, 3, 1, 2) if args.backend == \'pytorch\' else data\n\n    # Transform the images\n    transformed_data = T.transform_data(data, theta, outsize=(350, 350))\n\n    # Now lets see if we can esimate the transformation we just used, by\n    # iteratively trying to transform the data\n    A = CpabAligner(T)\n    \n    # Do by sampling, work for all backends\n    if args.alignment_type == \'sampling\':\n        theta_est = A.alignment_by_sampling(\n            data, transformed_data, maxiter=args.maxiter)\n    # Or do it by gradient descend (only tensorflow and pytorch)\n    else:\n        theta_est = A.alignment_by_gradient(\n            data, transformed_data, maxiter=args.maxiter)\n\n    # Lets see what we converged to\n    trans_est = T.transform_data(data, theta_est, outsize=(350, 350))\n    \n    # Revert pytorch format\n    if args.backend == \'pytorch\':\n        data = data.permute(0, 2, 3, 1)\n        transformed_data = transformed_data.permute(0, 2, 3, 1)\n        trans_est = trans_est.permute(0, 2, 3, 1)\n\n    # Show the results\n    data = T.backend.tonumpy(data)\n    transformed_data = T.backend.tonumpy(transformed_data)\n    trans_est = T.backend.to(trans_est)\n    \n    print(\'Theta:    \', T.backend.tonumpy(theta))\n    print(\'Theta est:\', T.backend.tonumpy(theta_est))\n    \n    plt.subplots(1, 3)\n    plt.subplot(1, 3, 1)\n    plt.imshow(data[0])\n    plt.axis(\'off\')\n    plt.title(\'Source\')\n    plt.subplot(1, 3, 2)\n    plt.imshow(transformed_data[0])\n    plt.axis(\'off\')\n    plt.title(\'Target\')\n    plt.subplot(1, 3, 3)\n    plt.imshow(trans_est[0])\n    plt.axis(\'off\')\n    plt.title(\'Estimate\')\n    plt.show()\n    \n    \n'"
examples/sequential_demo.py,2,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Aug 13 14:05:57 2019\n\n@author: nsde\n""""""\n\n#%%\nfrom libcpab import Cpab\nfrom libcpab import CpabSequential\nfrom libcpab.core.utility import show_images, get_dir # utility functions\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport argparse\n\n#%%\ndef argparser():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--backend\', default=\'numpy\',\n                        choices=[\'numpy\', \'tensorflow\', \'pytorch\'],\n                        help=\'backend to run demo with\')\n    parser.add_argument(\'--device\', default=\'cpu\',\n                        choices=[\'cpu\', \'gpu\'],\n                        help=\'device to run demo on\')\n    return parser.parse_args()\n\n\n#%%\nif __name__ == \'__main__\':\n    args = argparser()\n    print(""---Running script with arguments---"")\n    print(""\\n"".join([str(k) + \':\' + str(v) for k,v in vars(args).items()]))\n    print(""-----------------------------------"")\n    \n    # Load some data\n    data = plt.imread(get_dir(__file__) + \'/../data/cat.jpg\') / 255\n    data = np.expand_dims(data, 0)  # create batch effect\n\n    # Create multiple transformers\n    T1 = Cpab([1, 1], backend=args.backend, device=args.device, zero_boundary=True,\n              volume_perservation=False, override=False)\n    T2 = Cpab([2, 2], backend=args.backend, device=args.device, zero_boundary=True,\n              volume_perservation=False, override=False)\n    T3 = Cpab([3, 3], backend=args.backend, device=args.device, zero_boundary=True,\n              volume_perservation=False, override=False)\n\n    # Combine into one single transformer\n    T = CpabSequential(T1, T2, T3)\n\n    # Sample transformations (one for each transformation)\n    thetas = T.sample_transformation(1)\n    # scale down, else the output will be very deform\n    thetas = [T.backend.to(0.5*t, device=args.device) for t in thetas]\n\n    # Convert data to the backend format\n    data = T.backend.to(data, device=args.device)\n\n    # Pytorch have other data format than tensorflow and numpy, color information\n    # is the second dim. We need to correct this before and after\n    data = data.permute(0, 3, 1, 2) if args.backend == \'pytorch\' else data\n\n    # Transform the images, output_all=True will return all intermidian transforms\n    all_transformed_data = T.transform_data(data, \n                                            thetas, \n                                            outsize=(350, 350), \n                                            output_all=True)\n\n    # Get the corresponding numpy arrays in correct format\n    transformed_data = [data.permute(0, 2, 3, 1) if args.backend == \'pytorch\' else data]\n    transformed_data[0] = T.backend.tonumpy(transformed_data[0])\n\n    for td in all_transformed_data:\n        td = td.permute(0, 2, 3, 1) if args.backend == \'pytorch\' else td\n        transformed_data.append(T.backend.tonumpy(td))\n    transformed_data = np.concatenate(transformed_data, axis=0)\n\n    # Show transformed samples\n    show_images(transformed_data)\n'"
examples/simple_demo.py,1,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Aug  8 15:29:26 2019\n\n@author: nsde\n""""""\n\n#%%\nfrom libcpab import Cpab\nfrom libcpab.core.utility import show_images, get_dir # utility functions\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport argparse\n\n#%%\ndef argparser():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--backend\', default=\'numpy\', \n                        choices=[\'numpy\', \'tensorflow\', \'pytorch\'],\n                        help=\'backend to run demo with\')\n    parser.add_argument(\'--device\', default=\'cpu\',\n                        choices=[\'cpu\', \'gpu\'],\n                        help=\'device to run demo on\')\n    return parser.parse_args()\n\n#%%\nif __name__ == ""__main__"":\n    args = argparser()\n    print(""---Running script with arguments---"")\n    print(""\\n"".join([str(k) + \':\' + str(v) for k,v in vars(args).items()]))\n    print(""-----------------------------------"")\n    \n    import tensorflow as tf\n    tf.config.set_soft_device_placement(True)\n    \n    # Number of transformed samples \n    N = 9\n    \n    # Load some data\n    data = plt.imread(get_dir(__file__) + \'/../data/cat.jpg\') / 255\n    data = np.tile(data[None], [N,1,1,1]) # create batch of data\n    \n    # Create transformer class\n    T = Cpab([3, 3], backend=args.backend, device=args.device, \n             zero_boundary=True, volume_perservation=False, override=False)\n\n    # Sample random transformation\n    theta = T.sample_transformation(N)\n    \n    # Convert data to the backend format\n    data = T.backend.to(data, device=args.device)\n    \n    # Pytorch have other data format than tensorflow and numpy, color \n    # information is the second dim. We need to correct this before and after\n    data = data.permute(0,3,1,2) if args.backend==\'pytorch\' else data\n\n    # Transform the images\n    t_data = T.transform_data(data, theta, outsize=(350, 350))\n    \n    # Get the corresponding numpy arrays in correct format\n    t_data = t_data.permute(0,2,3,1) if args.backend==\'pytorch\' else t_data\n    t_data = T.backend.tonumpy(t_data)\n    \n    # Show transformed samples\n    show_images(t_data)\n'"
libcpab/__init__.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Aug 30 12:57:19 2018\n\n@author: nsde\n""""""\n\n#%%\nfrom .cpab import Cpab\nfrom .alignment import CpabAligner\nfrom .sequential import CpabSequential\n\n\n'"
libcpab/alignment.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Wed Nov 28 16:13:00 2018\n\n@author: nsde\n""""""\nfrom .cpab import Cpab\nfrom tqdm import tqdm \n\n#%%\nclass CpabAligner(object):\n    \'\'\' EXPERIMENTAL, NOT PROPER TESTED\n    This class implementes implementes gradient based and sampling based \n    alignment of data by optimizing the parametrization of a given CPAB\n    transformation \'\'\'\n    \n    def __init__(self, cpab_class):        \n        assert isinstance(cpab_class, Cpab), \'\'\'The input class \n            needs to be an instance of the core cpab class \'\'\'\n        self.T = cpab_class\n        \n        if self.T.backend_name == \'numpy\':\n            from .numpy import functions as backend\n        elif self.T.backend_name == \'tensorflow\':\n            from .tensorflow import functions as backend\n        elif self.T.backend_name == \'pytorch\':\n            from .pytorch import functions as backend\n        self.backend = backend\n    \n    #%%\n    def alignment_by_sampling(self, x1, x2, maxiter=100):\n        \'\'\' MCMC sampling minimization \'\'\'\n        self.T._check_type(x1)\n        self.T._check_type(x2)\n        assert x1.shape == x2.shape,\' Two data points does not have the same shape \'\n        outsize = (x2.shape[1], x2.shape[2]) if self.T.backend_name != \'pytorch\' else  \\\n            (x2.shape[2], x2.shape[3])\n\n        current_sample = self.T.identity(1)\n        current_error = self.backend.norm(x1 - x2)\n        accept_ratio = 0\n        \n        for i in tqdm(range(maxiter), desc=\'Alignment of samples\', unit=\'samples\'):\n            # Sample and transform \n            theta = 1e-1*self.T.sample_transformation(1, mean=current_sample.flatten())\n            x1_trans = self.T.transform_data(x1, theta, outsize=outsize)\n            \n            # Calculate new error\n            new_error = self.backend.norm(x1_trans - x2)\n            \n            if new_error < current_error:\n                current_sample = theta\n                current_error = new_error\n                accept_ratio += 1\n        print(\'Acceptence ratio: \', accept_ratio / maxiter * 100, \'%\')\n        return current_sample    \n    \n    #%%\n    def alignment_by_gradient(self, x1, x2, maxiter=100, lr=1e-2):\n        \'\'\' Gradient based minimization \'\'\'\n        assert self.T.backend_name != \'numpy\', \\\n            \'\'\' Cannot do gradient decent when using the numpy backend \'\'\'\n        self.T._check_type(x1)\n        self.T._check_type(x2)\n        assert x1.shape == x2.shape,\' Two data points does not have the same shape \'\n        outsize = (x2.shape[1], x2.shape[2]) if self.T.backend_name != \'pytorch\' else  \\\n            (x2.shape[2], x2.shape[3])\n        \n        if self.T.backend_name == \'pytorch\':\n            import torch\n            theta = torch.autograd.Variable(self.T.identity(1, epsilon=1e-6), requires_grad=True)\n            optimizer = torch.optim.Adam([theta], lr=lr)\n        \n            pb = tqdm(desc=\'Alignment of samples\', unit=\'iters\', total=maxiter)\n            for i in range(maxiter):\n                optimizer.zero_grad()\n                x1_trans = self.T.transform_data(x1, theta, outsize=x1.shape[2:])\n                loss = self.backend.norm(x1_trans - x2)\n                loss.backward()\n                optimizer.step()\n                \n                pb.update()\n                pb.set_postfix({\'loss\': loss.item()})\n            pb.close()\n            \n            return theta\n        \n        if self.T.backend_name == \'tensorflow\':\n            import tensorflow as tf\n            theta = tf.Variable(self.T.identity(1, epsilon=1e-6))\n            optimizer = tf.keras.optimizers.Adam(lr=lr)\n            \n            pb = tqdm(desc=\'Alignment of samples\', unit=\'iters\', total=maxiter)\n            for i in range(maxiter):\n                with tf.GradientTape() as tape:\n                    x1_trans = self.T.transform_data(x1, theta, outsize=outsize)\n                    loss = self.backend.norm(x1_trans - x2)\n                    grads = tape.gradient(loss, theta)\n                optimizer.apply_gradients(zip([grads], [theta]))\n            \n                pb.update()\n                pb.set_postfix({\'loss\': loss.numpy()})\n            pb.close()\n            \n            return theta.value()\n                '"
libcpab/cpab.py,13,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Fri Nov 16 15:34:36 2018\n\n@author: nsde\n""""""\n\n#%%\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom .core.utility import params, get_dir, create_dir\nfrom .core.tesselation import Tesselation1D, Tesselation2D, Tesselation3D\n\n#%%\nclass Cpab(object):\n    """""" Core class for this library. This class contains all the information\n        about the tesselation, transformation ect. The user is not meant to\n        use anything else than this specific class.\n        \n    Arguments:\n        tess_size: list, with the number of cells in each dimension\n        \n        backend: string, computational backend to use. Choose between \n            ""numpy"" (default), ""pytorch"" or ""tensorflow""\n        \n        device: string, either ""cpu"" (default) or ""gpu"". For the numpy backend\n            only the ""cpu"" option is valid\n        \n        zero_boundary: bool, determines is the velocity at the boundary is zero \n        \n        volume_perservation: bool, determine if the transformation is \n            volume perservating\n            \n        override: bool, if true a new basis will always be created and saved,\n            when the class is called\n        \n    Methods:\n        @get_theta_dim\n        @get_params\n        @get_bases\n        @uniform_meshgrid\n        @sample_transformation\n        @sample_transformation_with_smooth_prior\n        @identity\n        @transform_grid\n        @interpolate\n        @transform_data\n        @calc_vectorfield\n        @visualize_vectorfield\n        @visualize_tesselation\n        @visualize_deformgrid\n    """"""\n    def __init__(self, \n                 tess_size,\n                 backend = \'numpy\',\n                 device = \'cpu\', \n                 zero_boundary=True,\n                 volume_perservation=False,\n                 override=False):\n        # Check input\n        self._check_input(tess_size, backend, device, \n                          zero_boundary, volume_perservation, override)\n        \n        # Parameters\n        self.params = params()\n        self.params.nc = tess_size\n        self.params.ndim = len(tess_size)\n        self.params.Ashape = [self.params.ndim, self.params.ndim+1]\n        self.params.valid_outside = not(zero_boundary)\n        self.params.zero_boundary = zero_boundary\n        self.params.volume_perservation = volume_perservation\n        self.params.domain_max = [1 for e in self.params.nc]\n        self.params.domain_min = [0 for e in self.params.nc]\n        self.params.inc = [(self.params.domain_max[i] - self.params.domain_min[i]) / \n                           self.params.nc[i] for i in range(self.params.ndim)]\n        self.params.nstepsolver = 50\n        self.params.numeric_grad = False\n        self.params.use_slow = False\n        \n        # For saving the basis\n        self._dir = get_dir(__file__) + \'/../basis_files/\'\n        create_dir(self._dir)\n        \n        # Specific for the different dims\n        if self.params.ndim == 1:\n            self.params.nC = self.params.nc[0]\n            self.params.params_pr_cell = 2\n            tesselation = Tesselation1D\n        elif self.params.ndim == 2:\n            self.params.nC = 4*np.prod(self.params.nc)\n            self.params.params_pr_cell = 6\n            tesselation = Tesselation2D\n        elif self.params.ndim == 3:\n            self.params.nC = 5*np.prod(self.params.nc)\n            self.params.params_pr_cell = 12\n            tesselation = Tesselation3D\n            \n        # Initialize tesselation\n        self.tesselation = tesselation(self.params.nc, self.params.domain_min, \n                                       self.params.domain_max, self.params.zero_boundary, \n                                       self.params.volume_perservation,\n                                       self._dir, override)\n        \n        # Extract parameters from tesselation\n        self.params.constrain_mat = self.tesselation.L\n        self.params.basis = self.tesselation.B\n        self.params.D, self.params.d = self.params.basis.shape\n                \n        # Load backend and set device\n        self.backend_name = backend\n        if self.backend_name == \'numpy\':\n            from .numpy import functions as backend\n        elif self.backend_name == \'tensorflow\':\n            from .tensorflow import functions as backend\n        elif self.backend_name == \'pytorch\':\n            from .pytorch import functions as backend\n        self.backend = backend\n        self.device = device.lower()\n        \n        # Assert that we have a recent version of the backend\n        self.backend.assert_version()\n        \n    #%%\n    def get_theta_dim(self):\n        """""" Method that returns the dimensionality of the transformation""""""\n        return self.params.d\n    \n    #%%\n    def get_params(self):\n        """""" Returns a class with all parameters for the transformation """"""\n        return self.params\n    \n    #%%\n    def get_basis(self):\n        """""" Method that return the basis of transformation""""""\n        return self.params.basis\n    \n    #%%\n    def set_solver_params(self, nstepsolver=50, numeric_grad=False, use_slow=False):\n        """""" Function for setting parameters that controls parameters of the\n            integration algorithm. Only use if you know what you do.\n        Arguments:\n            nstepsolver: int, number of iterations to take in integration. Higher\n                number give better approximations but takes longer time to compute\n            numeric_grad: bool, determines if we should use the analytical grad\n                or numeric grad for gradient computations\n            use_slow: bool, determine if the integration should be done using the\n                pure ""python"" version of each backend\n        """"""\n        assert nstepsolver > 0, \'\'\'nstepsolver must be a positive number\'\'\'\n        assert type(nstepsolver) == int, \'\'\'nstepsolver must be integer\'\'\'\n        assert type(numeric_grad) == bool, \'\'\'numeric_grad must be bool\'\'\'\n        assert type(use_slow) == bool, \'\'\'use_slow must be bool\'\'\'\n        self.params.nstepsolver = nstepsolver\n        self.params.numeric_grad = numeric_grad\n        self.params.use_slow = use_slow\n        \n    #%%    \n    def uniform_meshgrid(self, n_points):\n        """""" Constructs a meshgrid \n        Arguments:\n            n_points: list, number of points in each dimension\n        Output:\n            grid: [ndim, nP] matrix of points, where nP = product(n_points)\n        """"""\n        return self.backend.uniform_meshgrid(self.params.ndim,\n                                             self.params.domain_min,\n                                             self.params.domain_max,\n                                             n_points, self.device)\n      \n    #%%\n    def sample_transformation(self, n_sample=1, mean=None, cov=None):\n        """""" Method for sampling transformation from simply multivariate gaussian\n            As default the method will sample from a standard normal\n        Arguments:\n            n_sample: integer, number of transformations to sample\n            mean: [d,] vector, mean of multivariate gaussian\n            cov: [d,d] matrix, covariance of multivariate gaussian\n        Output:\n            samples: [n_sample, d] matrix. Each row is a independent sample from\n                a multivariate gaussian\n        """"""\n        if mean is not None: self._check_type(mean); self._check_device(mean)\n        if cov is not None: self._check_type(cov); self._check_device(cov)\n        samples = self.backend.sample_transformation(self.params.d, n_sample, \n                                                     mean, cov, self.device)\n        return self.backend.to(samples, device=self.device)\n        \n    \n    #%%\n    def sample_transformation_with_prior(self, n_sample=1, mean=None, \n                                         length_scale=0.1, output_variance=1):\n        """""" Function for sampling smooth transformations. The smoothness is determined\n            by the distance between cell centers. The closer the cells are to each other,\n            the more the cell parameters should correlate -> smooth transistion in\n            parameters. The covariance in the D-space is calculated using the\n            squared exponential kernel.\n                \n        Arguments:\n            n_sample: integer, number of transformation to sample\n            mean: [d,] vector, mean of multivariate gaussian\n            length_scale: float>0, determines how fast the covariance declines \n                between the cells \n            output_variance: float>0, determines the overall variance from the mean\n        Output:\n            samples: [n_sample, d] matrix. Each row is a independen sample from\n                a multivariate gaussian\n        """"""\n        \n        # Get cell centers and convert to backend type\n        centers = self.backend.to(self.tesselation.get_cell_centers(), device=self.device)\n        \n        # Get distance between cell centers\n        dist = self.backend.pdist(centers)\n        \n        # Make into a covariance matrix between parameters\n        ppc = self.params.params_pr_cell\n        cov_init = self.backend.zeros(self.params.D, self.params.D, device=self.device)\n        \n        for i in range(self.params.nC):\n            for j in range(self.params.nC):\n                # Make block matrix with large values\n                block = 100*self.backend.maximum(dist)*self.backend.ones(ppc, ppc)\n                # Fill in diagonal with actual values\n                block[self.backend.arange(ppc), self.backend.arange(ppc)] = \\\n                    self.backend.repeat(dist[i,j], ppc)\n                # Fill block into the large covariance\n                cov_init[ppc*i:ppc*(i+1), ppc*j:ppc*(j+1)] = block\n        \n        # Squared exponential kernel\n        cov_avees = output_variance**2 * self.backend.exp(-(cov_init / (2*length_scale**2)))\n\n        # Transform covariance to theta space\n        B = self.backend.to(self.params.basis, self.device)\n        B_t = self.backend.transpose(B)\n        cov_theta = self.backend.matmul(B_t, self.backend.matmul(cov_avees, B))\n        \n        # Sample\n        samples = self.sample_transformation(n_sample, mean=mean, cov=cov_theta)\n        return samples\n    \n    #%%\n    def identity(self, n_sample=1, epsilon=0):\n        """""" Method for getting the identity parameters for the identity \n            transformation (vector of zeros) \n        Arguments:\n            n_sample: integer, number of transformations to sample\n            epsilon: float>0, small number to add to the identity transformation\n                for stability during training\n        Output:\n            samples: [n_sample, d] matrix. Each row is a sample    \n        """"""\n        return self.backend.identity(self.params.d, n_sample, epsilon, self.device)\n    \n    #%%\n    def transform_grid(self, grid, theta):\n        """""" Main method of the class. Integrates the grid using the parametrization\n            in theta.\n        Arguments:\n            grid: [ndim, n_points] matrix or [n_batch, ndim, n_points] tensor i.e.\n                either a single grid for all theta values, or a grid for each theta\n                value\n            theta: [n_batch, d] matrix,\n        Output:\n            transformed_grid: [n_batch, ndim, n_points] tensor, with the transformed\n                grid. The slice transformed_grid[i] corresponds to the grid being\n                transformed by theta[i]\n        """"""\n        self._check_type(grid); self._check_device(grid)\n        self._check_type(theta); self._check_device(theta)\n        if len(grid.shape) == 3: # check that grid and theta can broadcastes together\n            assert grid.shape[0] == theta.shape[0], \'\'\'When passing a 3D grid, expects\n                the first dimension to be of same length as the first dimension of\n                theta\'\'\'\n        transformed_grid = self.backend.transformer(grid, theta, self.params)\n        return transformed_grid\n    \n    #%%    \n    def interpolate(self, data, grid, outsize):\n        """""" Linear interpolation method\n        Arguments:\n            data: [n_batch, *data_shape] tensor, with input data. The format of\n                the data_shape depends on the dimension of the data AND the\n                backend that is being used. In tensorflow and numpy:\n                    In 1D: [n_batch, number_of_features, n_channels]\n                    In 2D: [n_batch, width, height, n_channels]\n                    In 3D: [n_batch, width, height, depth, n_channels]\n                In pytorch:\n                    In 1D: [n_batch, n_channels, number_of_features]\n                    In 2D: [n_batch, n_channels, width, height]\n                    In 3D: [n_batch, n_channels, width, height, depth]\n            grid: [n_batch, ndim, n_points] tensor with grid points that are \n                used to interpolate the data\n            outsize: list, with number of points in the output\n        Output:\n            interlated: [n_batch, *outsize] tensor with the interpolated data\n        """"""            \n        self._check_type(data); self._check_device(data)\n        self._check_type(grid); self._check_device(grid)\n        return self.backend.interpolate(self.params.ndim, data, grid, outsize)\n    \n    #%%\n    def transform_data(self, data, theta, outsize):\n        """""" Combination of the transform_grid and interpolate methods for easy\n            transformation of data.\n        Arguments:\n            data: [n_batch, *data_shape] tensor, with input data. The format of\n                the data_shape depends on the dimension of the data AND the\n                backend that is being used. In tensorflow and numpy:\n                    In 1D: [n_batch, number_of_features, n_channels]\n                    In 2D: [n_batch, width, height, n_channels]\n                    In 3D: [n_batch, width, height, depth, n_channels]\n                In pytorch:\n                    In 1D: [n_batch, n_channels, number_of_features]\n                    In 2D: [n_batch, n_channels, width, height]\n                    In 3D: [n_batch, n_channels, width, height, depth]\n            theta: [n_batch, d] matrix with transformation parameters. Each row\n                correspond to a transformation.\n            outsize: list, number of points in each direction that is transformed\n                and interpolated\n        Output:\n            data_t: [n_batch, *outsize] tensor, transformed and interpolated data\n        """"""\n\n        self._check_type(data); self._check_device(data)\n        self._check_type(theta); self._check_device(theta)\n        grid = self.uniform_meshgrid(outsize)\n        grid_t = self.transform_grid(grid, theta)\n        data_t = self.interpolate(data, grid_t, outsize)\n        return data_t\n    \n    #%%\n    def calc_vectorfield(self, grid, theta):\n        """""" For each point in grid, calculate the velocity of the point based\n            on the parametrization in theta\n        Arguments:\n            grid: [ndim, nP] matrix, with points\n            theta: [1, d] single parametrization vector\n        Output:    \n            v: [ndim, nP] matrix, with velocity vectors for each point\n        """"""\n        self._check_type(grid); self._check_device(grid)\n        self._check_type(theta); self._check_device(theta)\n        v = self.backend.calc_vectorfield(grid, theta, self.params)\n        return v\n    \n    #%%\n    def visualize_vectorfield(self, theta, nb_points = 50, fig = plt.figure()):\n        """""" Utility function that helps visualize the vectorfield for a specific\n            parametrization vector theta \n        Arguments:    \n            theta: [1, d] single parametrization vector\n            nb_points: number of points in each dimension to plot i.e. in 2D\n                with nb_points=50 the function will plot 50*50=2500 arrows!\n            fig: matplotlib figure handle\n        Output:\n            plot: handle to quiver plot\n        """"""\n        self._check_type(theta)\n        \n        # Calculate vectorfield and convert to numpy\n        grid = self.uniform_meshgrid([nb_points for _ in range(self.params.ndim)])\n        v = self.calc_vectorfield(grid, theta)\n        v = self.backend.tonumpy(v)\n        grid = self.backend.tonumpy(grid)\n        \n        # Plot\n        if self.params.ndim == 1:\n            ax = fig.add_subplot(111)\n            plot = ax.quiver(grid[0,:], np.zeros_like(grid), v, np.zeros_like(v), units=\'xy\')\n            ax.set_xlim(self.params.domain_min[0], self.params.domain_max[0])\n        elif self.params.ndim == 2:\n            ax = fig.add_subplot(111)\n            plot = ax.quiver(grid[0,:], grid[1,:], v[0,:], v[1,:], units=\'xy\')\n            ax.set_xlim(self.params.domain_min[0], self.params.domain_max[0])\n            ax.set_ylim(self.params.domain_min[1], self.params.domain_max[1])            \n        elif self.params.ndim==3:\n            from mpl_toolkits.mplot3d import Axes3D\n            ax = fig.add_subplot(111, projection=\'3d\')\n            plot = ax.quiver(grid[0,:], grid[1,:], grid[2,:], v[0,:], v[1,:], v[2,:],\n                             length=0.3, arrow_length_ratio=0.5)\n            ax.set_xlim3d(self.params.domain_min[0], self.params.domain_max[0])\n            ax.set_ylim3d(self.params.domain_min[1], self.params.domain_max[1])\n            ax.set_zlim3d(self.params.domain_min[2], self.params.domain_max[2])\n            ax.set_xlabel(\'x\'); ax.set_ylabel(\'y\'); ax.set_zlabel(\'z\')\n        plt.axis(\'equal\')\n        plt.title(\'Velocity field\')\n        return plot\n    \n    #%%\n    def visualize_deformgrid(self, theta, nb_lines = 10, nb_points= 1000, fig = plt.figure()):\n        """""" Utility function that helps visualize a deformation. Currently\n            only implemented in 2D.\n        Arguments:\n            theta: [1, d] single parametrization vector\n            nb_lines: int, number of lines in x/y direction\n            nb_points: int, number of points on each line\n            fig: matplotlib figure handle\n        Output:\n            plot: list of plot handles to lines\n        """"""\n        if self.params.ndim == 2:\n            x = np.linspace(0,1,nb_lines)\n            y = np.linspace(0,1,nb_lines)\n            plots = []\n            for i in range(nb_lines):\n                xx = x[i]*np.ones((1,nb_points))\n                yy = np.linspace(0,1,nb_points).reshape(1,nb_points)\n                grid = np.concatenate((xx, yy), axis=0)\n                grid = self.transform_grid(grid, theta)[0]\n                plot = plt.plot(grid[0], grid[1], \'-k\')\n                plots.append(plot)\n      \n            for i in range(nb_lines):\n                xx = np.linspace(0,1,nb_points).reshape(1,nb_points)\n                yy = y[i]*np.ones((1,nb_points))\n                grid = np.concatenate((xx, yy), axis=0)\n                grid = self.transform_grid(grid, theta)[0]\n                plot = plt.plot(grid[0], grid[1], \'-k\')            \n                plots.append(plot)\n            return plots\n        else:\n            raise NotImplementedError(\'This is only implemented for 2D domain\')\n    \n    #%%\n    def visualize_tesselation(self, nb_points = 50, show_outside=False, fig=plt.figure()):\n        """""" Utility function that helps visualize the tesselation.\n        Arguments:\n            nb_points: number of points in each dimension\n            show_outside: if true, will sample points outside the normal [0,1]^ndim\n                domain to show how the tesselation (or in fact the findcellidx)\n                function extends to outside domain.\n            fig: matplotlib figure handle\n        Output:\n            plot: handle to tesselation plot\n        """"""\n        if show_outside:\n            domain_size = [self.params.domain_max[i] - self.params.domain_min[i] \n                           for i in range(self.params.ndim)]\n            domain_min = [self.params.domain_min[i]-domain_size[i]/10 \n                          for i in range(self.params.ndim)]\n            domain_max = [self.params.domain_max[i]+domain_size[i]/10 \n                          for i in range(self.params.ndim)]\n            grid = self.backend.uniform_meshgrid(self.params.ndim, domain_min, \n                        domain_max, [nb_points for _ in range(self.params.ndim)])\n        else:\n            grid = self.uniform_meshgrid([nb_points for _ in range(self.params.ndim)])\n        \n        # Find cellindex and convert to numpy\n        idx = self.backend.findcellidx(self.params.ndim, grid, self.params.nc)\n        idx = self.backend.tonumpy(idx)\n        grid = self.backend.tonumpy(grid)\n        \n        # Plot\n        if self.params.ndim == 1:\n            ax = fig.add_subplot(111)\n            plot = ax.scatter(grid.flatten(), np.zeros_like(grid).flatten(), c=idx)\n        elif self.params.ndim == 2:\n            ax = fig.add_subplot(111)\n            plot = ax.imshow(idx.reshape(self.params.ndim*[nb_points]))\n        elif self.params.ndim == 3:\n            import matplotlib.animation as animation\n            idx = idx.reshape(self.params.ndim*[nb_points])\n            im = plt.imshow(idx[0,:,:], animated=True)\n            def update(frames):\n                im.set_array(idx[frames,:,:])\n                return im,\n            plot = animation.FuncAnimation(fig, update, frames=nb_points, blit=True)\n            cbar = plt.colorbar()\n            cbar.set_clim(idx.min(), idx.max())\n            cbar.update_ticks()\n            \n        plt.axis(\'equal\')\n        plt.title(\'Tesselation \' + str(self.params.nc))\n        return plot\n    \n    #%%\n    def _check_input(self, tess_size, backend, device, \n                     zero_boundary, volume_perservation, override):\n        """""" Utility function used to check the input to the class.\n            Not meant to be called by the user. """"""\n        assert len(tess_size) > 0 and len(tess_size) <= 3, \\\n            \'\'\'Transformer only supports 1D, 2D or 3D\'\'\'\n        assert type(tess_size) == list or type(tess_size) == tuple, \\\n            \'\'\'Argument tess_size must be a list or tuple\'\'\'\n        assert all([type(e)==int for e in tess_size]), \\\n            \'\'\'All elements of tess_size must be integers\'\'\'\n        assert all([e > 0 for e in tess_size]), \\\n            \'\'\'All elements of tess_size must be positive\'\'\'\n        assert backend in [\'numpy\', \'tensorflow\', \'pytorch\'], \\\n            \'\'\'Unknown backend, choose between \'numpy\', \'tensorflow\' or \'pytorch\' \'\'\'\n        assert device in [\'cpu\', \'gpu\'], \\\n            \'\'\'Unknown device, choose between \'cpu\' or \'gpu\' \'\'\'\n        if backend == \'numpy\':\n            assert device == \'cpu\', \'\'\'Cannot use gpu with numpy backend \'\'\'\n        assert type(zero_boundary) == bool, \\\n            \'\'\'Argument zero_boundary must be True or False\'\'\'\n        assert type(volume_perservation) == bool, \\\n            \'\'\'Argument volume_perservation must be True or False\'\'\'\n        assert type(override) == bool, \\\n            \'\'\'Argument override must be True or False \'\'\'\n            \n    #%%\n    def _check_type(self, x):\n        """""" Assert that the type of x is compatible with the class i.e\n                numpy backend expects np.array\n                pytorch backend expects torch.tensor\n                tensorflow backend expects tf.tensor\n        """"""\n        assert isinstance(x, self.backend.backend_type()), \\\n            \'\'\' Input has type {0} but expected type {1} \'\'\'.format(\n            type(x), self.backend.backend_type())\n            \n    #%%\n    def _check_device(self, x):\n        """""" Asssert that x is on the same device (cpu or gpu) as the class """"""\n        assert self.backend.check_device(x, self.device), \'\'\'Input is placed on \n            device {0} but the class expects it to be on device {1}\'\'\'.format(\n            str(x.device), self.device)\n            \n    #%%\n    def __repr__(self):\n        output = \'\'\'\n        CPAB transformer class. \n            Parameters:\n                Tesselation size:           {0}\n                Total number of cells:      {1}\n                Theta size:                 {2}\n                Domain lower bound:         {3}\n                Domain upper bound:         {4}\n                Zero Boundary:              {5}\n                Volume perservation:        {6}\n            Backend:                        {7}\n        \'\'\'.format(self.params.nc, self.params.nC, self.params.d, \n            self.params.domain_min, self.params.domain_max, \n            self.params.zero_boundary, self.params.volume_perservation,\n            self.backend_name)\n        return output\n'"
libcpab/sequential.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Wed Jan  2 10:45:48 2019\n\n@author: nsde\n""""""\n\n#%%\nfrom .cpab import Cpab\n\nimport matplotlib.pyplot as plt\n\n#%%\nclass CpabSequential(object):\n    \'\'\' Helper class meant to make it easy to work with a sequence of transformers.\n        Main method of the class are the transform_grid() and transform_data() that\n        works similar to the methods of the core class.\n        Example:\n            T1 = cpab([2,2], ...)\n            T2 = cpab([4,4], ...)\n            theta1 = T1.sample_theta()\n            theta2 = T2.sample_theta()\n            T = SequentialCpab(T1, T2)\n            data_trans = T.transform_data(some_data, theta1, theta2, outputshape)\n    \'\'\'\n    def __init__(self, *cpab):\n        self.n_cpab = len(cpab)\n        self.cpab = cpab\n        \n        # Assert that all cpab classes are valid\n        for i in range(self.n_cpab):\n            assert isinstance(self.cpab[i], Cpab), \\\n                \'\'\' Class {0} is not a member of the cpab core class \'\'\'.format(i)\n        \n        # Assert that all cpab classes have same dimensionality\n        self.ndim = self.cpab[0].params.ndim\n        for i in range(1, self.n_cpab):\n            assert self.ndim == self.cpab[i].params.ndim, \\\n                \'\'\' Mismatching dimensionality of transformers. Transformer 1\n                have dimensionality {0} but transformer {1} have dimensionality\n                {2}\'\'\'.format(self.ndim, i+1, self.cpab[i].params.ndim)\n                \n        # Assert that all cpab classes have same backend\n        self.backend = self.cpab[0].backend\n        self.backend_name = self.cpab[0].backend_name\n        for i in range(1, self.n_cpab):\n            assert self.backend_name == self.cpab[i].backend_name, \\\n                \'\'\' Mismatch in backend. Transformer 1 have backend {0} but\n                transformer {1} have backend {2}\'\'\'.format(\n                self.backend_name, i+1, self.cpab[i].backend_name)\n        \n                \n    #%%\n    def get_theta_dim(self):\n        return [c.get_theta_dim for c in self.cpab]\n    \n    #%%\n    def get_params(self):\n        return [c.get_params() for c in self.cpab]\n    \n    #%%\n    def get_basis(self):\n        return [c.get_basis() for c in self.cpab]\n    \n    #%%\n    def uniform_meshgrid(self, n_points):\n        return self.cpab[0].uniform_meshgrid(n_points)\n    \n    #%%\n    def sample_transformation(self, n_sample, means=None, covs=None):\n        if means==None:\n            means = self.n_cpab * [None]\n        else:\n            assert len(means)==self.n_cpab, \'\'\' The number of supplied means\n                should be equal to the number of transformations \'\'\'\n        if covs==None:\n            covs = self.n_cpab * [None]\n        else:\n            assert len(covs)==self.n_cpab, \'\'\' The number of supplied covariances\n                should be equal to the number of transformations \'\'\'\n\n        return [c.sample_transformation(n_sample, mean, cov) for c,mean,cov in \n                zip(self.cpab, means, covs)]\n        \n    #%%\n    def identity(self, n_sample, epsilon=0):\n        return [c.identity(n_sample, epsilon) for c in self.cpab]\n    \n    #%%\n    def transform_grid(self, grid, thetas, output_all=False):\n        # Check shapes of thetas\n        self._assert_theta_shape(thetas)\n\n        if not output_all:\n            # Transform in sequence\n            for i in range(self.n_cpab):\n                grid = self.cpab[i].transform_grid(grid, thetas[i])\n        else:\n            grid = [self.cpab[0].transform_grid(grid, thetas[0])]\n            for i in range(1, self.n_cpab):\n                grid.append(self.cpab[i].transform_grid(grid[-1], thetas[i]))\n        \n        return grid\n        \n    #%%\n    def transform_data(self, data, thetas, outsize, output_all=False):\n        # Check shapes of thetas\n        self._assert_theta_shape(thetas)\n        \n        if not output_all:\n            # Transform in sequence\n            grid = self.uniform_meshgrid(outsize)\n            grid_t = self.transform_grid(grid, thetas, output_all=output_all)\n            \n            # Interpolate using final grid\n            data_t = self.cpab[-1].interpolate(data, grid_t, outsize)\n            return data_t\n        else:\n            # Transform in sequence\n            grid = self.uniform_meshgrid(outsize)\n            grid_t = self.transform_grid(grid, thetas, output_all=output_all)\n            \n            # Interpolate all grids\n            data_t = [self.cpab[0].interpolate(data, grid_t[0], outsize)]\n            for i in range(1, self.n_cpab):\n                data_t.append(self.cpab[i].interpolate(data, grid_t[i], outsize))\n            return data_t\n    \n    #%%\n    def _assert_theta_shape(self, thetas):\n        n_theta = len(thetas)\n        assert n_theta == self.n_cpab, \\\n            \'\'\' Number of parametrizations needed are {0}\'\'\'.format(self.n_trans)\n        batch_size = thetas[0].shape[0]\n        for i in range(1, n_theta):\n            assert batch_size == thetas[i].shape[0], \'\'\' Batch size should be the\n                same for all theta\'s \'\'\'\n    \n    #%%\n    def __repr__(self):\n        for i in range(self.n_cpab):\n            print(""======= Transformer {0} ======= "".format(i+1))\n            print(self.cpab[i])'"
libcpab/core/__init__.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Fri Nov 16 15:26:48 2018\n\n@author: nsde\n""""""\n\n#%%\nimport numpy as np\n\n#%%'"
libcpab/core/tesselation.py,50,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Sun Nov 18 14:23:25 2018\n\n@author: nsde\n""""""\n\n#%%\nimport numpy as np\nfrom .utility import make_hashable, check_if_file_exist, null, save_obj, load_obj\n\n#%%\nclass Tesselation(object):\n    """""" Base tesselation class. This function is not meant to be called,\n        but descripes the base structure that needs to be implemented in\n        1D, 2D, and 3D. Additionally, some functionallity is shared across\n        the different dimensions.\n        \n    Args:\n        nc: list with number of cells\n        domain_min: value of the lower bound(s) of the domain\n        domain_max: value of the upper bound(s) of the domain\n        zero_boundary: bool, if true the velocity is zero on the boundary\n        volume_perservation: bool, if true volume is perserved\n        \n    Methods that should not be implemented in subclasses:\n        @get_cell_centers:\n        @create_continuity_constrains:\n        @create_zero_trace_constrains:\n            \n    Methods that should be implemented in subclasses:\n        @find_verts:\n        @find_verts_outside:\n        @create_zero_boundary_constrains:\n        \n    """"""\n    def __init__(self, nc, domain_min, domain_max,\n                 zero_boundary = True, volume_perservation=False, \n                 direc=None, override=False):\n        """""" Initilization of the class that create the constrain matrix L\n        Arguments:\n            nc: list, number of cells in each dimension\n            domain_min: list, lower domain bound in each dimension\n            domain_max: list, upper domain bound in each dimension\n            zero_boundary: bool, determines is the velocity at the boundary is zero\n            volume_perservation: bool, determine if the transformation is\n                volume perservating\n            direc: string, where to store the basis\n            override: bool, determines if we should calculate the basis even\n                if it already exists\n        """"""\n        \n        # Save parameters\n        self.nc = nc\n        self.domain_min = domain_min\n        self.domain_max = domain_max\n        self.zero_boundary = zero_boundary\n        self.volume_perservation = volume_perservation\n        self.dir = direc\n        self._basis_file = self.dir + \\\n                            \'cpab_basis_dim\' + str(len(self.nc)) + \'_tess\' + \\\n                            \'_\'.join([str(e) for e in self.nc]) + \'_\' + \\\n                            \'vo\' + str(int(not self.zero_boundary)) + \'_\' + \\\n                            \'zb\' + str(int(self.zero_boundary)) + \'_\' + \\\n                            \'vp\' + str(int(self.volume_perservation))\n\n        # Check if file exist else calculate the basis\n        if not check_if_file_exist(self._basis_file+\'.pkl\') or override:\n            # Get vertices\n            self.find_verts()\n            \n            # Find shared vertices\n            self.find_shared_verts()\n            \n            # find auxility vertices, if transformation is valid outside\n            if not zero_boundary: self.find_verts_outside()\n            \n            # Get continuity constrains\n            self.L = self.create_continuity_constrains()\n            \n            # If zero boundary, add constrains\n            if zero_boundary:\n                temp = self.create_zero_boundary_constrains()\n                self.L = np.concatenate((self.L, temp), axis=0)\n                \n            # If volume perservation, add constrains\n            if volume_perservation:\n                temp = self.create_zero_trace_constrains()\n                self.L = np.concatenate((self.L, temp), axis=0)\n            \n            # Find null space\n            self.B = null(self.L)\n        \n            # Save to file\n            save_obj(self.__dict__, self._basis_file)\n        \n        else:\n            self.__dict__ = load_obj(self._basis_file)\n    \n    def get_cell_centers(self):\n        """""" Get the centers of all the cells """"""\n        return np.mean(self.verts[:,:,:self.ndim], axis=1)\n    \n    def find_verts(self):\n        """""" Function that should find the different vertices of all cells in\n            the tesselation """"""\n        raise NotImplementedError\n        \n    def find_shared_verts(self):\n        """""" Find pairs of cells that share ndim-vertices. It is these pairs,\n            where we need to add continuity constrains at """"""\n        # Iterate over all pairs of cell to find cells with intersecting cells\n        shared_v, shared_v_idx = [ ], [ ]\n        for i in range(self.nC):\n            for j in range(self.nC):\n                if i != j:\n                    vi = make_hashable(self.verts[i])\n                    vj = make_hashable(self.verts[j])\n                    shared_verts = set(vi).intersection(vj)\n                    if len(shared_verts) == self.ndim and (j,i) not in shared_v_idx:\n                        shared_v.append(list(shared_verts)[:self.ndim])\n                        shared_v_idx.append((i,j))\n        \n        # Save result\n        self.shared_v = np.asarray(shared_v)\n        self.shared_v_idx = shared_v_idx\n        \n    def find_verts_outside(self):\n        """""" If the transformation should be valid outside, this function should\n            add additional auxilliry points to the tesselation that secures\n            continuity outside the domain """"""\n        raise NotImplementedError\n        \n    def create_continuity_constrains(self):\n        """""" This function goes through all pairs (i,j) of cells that share a\n            boundary. In N dimension we need to add N*N constrains (one for each\n            dimension times one of each vertex in the boundary) """"""\n        Ltemp = np.zeros(shape=(0,self.n_params*self.nC))\n        for idx, (i,j) in enumerate(self.shared_v_idx):\n            for vidx in range(self.ndim):\n                for k in range(self.ndim):\n                    index1 = self.n_params*i + k*(self.ndim+1)\n                    index2 = self.n_params*j + k*(self.ndim+1)\n                    row = np.zeros(shape=(1,self.n_params*self.nC))\n                    row[0,index1:index1+(self.ndim+1)] = self.shared_v[idx][vidx]\n                    row[0,index2:index2+(self.ndim+1)] = -self.shared_v[idx][vidx]\n                    Ltemp = np.vstack((Ltemp, row))\n        return Ltemp\n        \n    def create_zero_boundary_constrains(self):\n        """""" Function that creates a constrain matrix L, containing constrains that\n            secure 0 velocity at the boundary """"""\n        raise NotImplementedError\n        \n    def create_zero_trace_constrains(self):\n        """""" The volume perservation constrains, that corresponds to the trace\n            of each matrix being 0. These can be written general for all dims.""""""\n        Ltemp = np.zeros((self.nC, self.n_params*self.nC))\n        row = np.concatenate((np.eye(self.ndim), np.zeros((self.ndim, 1))), axis=1).flatten()\n        for c in range(self.nC):\n            Ltemp[c,self.n_params*c:self.n_params*(c+1)] = row\n        return Ltemp\n        \n#%%\nclass Tesselation1D(Tesselation):\n    def __init__(self, nc, domain_min, domain_max,\n                 zero_boundary = True, volume_perservation=False, \n                 direc=None, override=False):\n        # 1D parameters\n        self.n_params = 2\n        self.nC = np.prod(nc)\n        self.ndim = 1\n        \n        # Initialize super class\n        super(Tesselation1D, self).__init__(nc, domain_min, domain_max,\n             zero_boundary, volume_perservation, direc, override)\n        \n    def find_verts(self):\n        Vx = np.linspace(self.domain_min[0], self.domain_max[0], self.nc[0]+1)\n        \n        # Find cell index and verts for each cell\n        cells, verts = [ ], [ ]\n        for i in range(self.nc[0]):\n            v1 = tuple([Vx[i], 1])\n            v2 = tuple([Vx[i+1], 1])\n            verts.append((v1, v2))\n            cells.append((i))\n        \n        # Convert to array\n        self.verts = np.asarray(verts)\n        self.cells = cells\n        \n    def find_verts_outside(self):\n        pass # in 1D, we do not need auxilliry points\n        \n    def create_zero_boundary_constrains(self):\n        Ltemp = np.zeros((2,2*self.nC))\n        Ltemp[0,:2] = [self.domain_min[0], 1]\n        Ltemp[1,-2:] = [self.domain_max[0], 1]\n        return Ltemp\n\n#%%\nclass Tesselation2D(Tesselation):\n    def __init__(self, nc, domain_min, domain_max,\n                 zero_boundary = True, volume_perservation=False, \n                 direc=None, override=False):\n        # 1D parameters\n        self.n_params = 6 \n        self.nC = 4*np.prod(nc) # 4 triangle per cell\n        self.ndim = 2\n        \n        # Initialize super class\n        super(Tesselation2D, self).__init__(nc, domain_min, domain_max,\n             zero_boundary, volume_perservation, direc, override)\n    \n    def find_verts(self):\n        Vx = np.linspace(self.domain_min[0], self.domain_max[0], self.nc[0]+1)\n        Vy = np.linspace(self.domain_min[1], self.domain_max[1], self.nc[1]+1)\n        \n        # Find cell index and verts for each cell\n        cells, verts = [ ], [ ]\n        for i in range(self.nc[1]):\n            for j in range(self.nc[0]):\n                ul = tuple([Vx[j],Vy[i],1])\n                ur = tuple([Vx[j+1],Vy[i],1])\n                ll = tuple([Vx[j],Vy[i+1],1])\n                lr = tuple([Vx[j+1],Vy[i+1],1])\n                \n                center = [(Vx[j]+Vx[j+1])/2,(Vy[i]+Vy[i+1])/2,1]\n                center = tuple(center)                 \n                \n                verts.append((center,ul,ur))  # order matters!\n                verts.append((center,ur,lr))  # order matters!\n                verts.append((center,lr,ll))  # order matters!\n                verts.append((center,ll,ul))  # order matters!                \n        \n                cells.append((j,i,0))\n                cells.append((j,i,1))\n                cells.append((j,i,2))\n                cells.append((j,i,3))\n                \n        # Convert to array\n        self.verts = np.asarray(verts)\n        self.cells = cells\n        \n    def find_verts_outside(self):\n        shared_v, shared_v_idx = [ ], [ ]\n        \n        left =   np.zeros((self.nC, self.nC), np.bool)    \n        right =  np.zeros((self.nC, self.nC), np.bool) \n        top =    np.zeros((self.nC, self.nC), np.bool) \n        bottom = np.zeros((self.nC, self.nC), np.bool) \n        \n        for i in range(self.nC):\n            for j in range(self.nC):\n                \n                vi = make_hashable(self.verts[i])\n                vj = make_hashable(self.verts[j])\n                shared_verts = set(vi).intersection(vj)\n                \n                mi = self.cells[i]\n                mj = self.cells[j]\n        \n                # leftmost col, left triangle, adjacent rows\n                if  mi[0]==mj[0]==0 and \\\n                    mi[2]==mj[2]==3 and \\\n                    np.abs(mi[1]-mj[1])==1: \n                        \n                    left[i,j]=True\n                \n                # rightmost col, right triangle, adjacent rows                 \n                if  mi[0]==mj[0]==self.nc[0]-1 and \\\n                    mi[2]==mj[2]==1 and \\\n                    np.abs(mi[1]-mj[1])==1: \n        \n                    right[i,j]=True\n                \n                # uppermost row, upper triangle , adjacent cols                    \n                if  mi[1]==mj[1]==0 and \\\n                    mi[2]==mj[2]==0 and \\\n                    np.abs(mi[0]-mj[0])==1:\n                        \n                    top[i,j]=True\n                \n                # lowermost row, # lower triangle, # adjacent cols            \n                if  mi[1]==mj[1]==self.nc[1]-1 and \\\n                    mi[2]==mj[2]==2 and \\\n                    np.abs(mi[0]-mj[0])==1:\n                        \n                    bottom[i,j]=True\n                                \n                if  len(shared_verts) == 1 and \\\n                    any([left[i,j],right[i,j],top[i,j],bottom[i,j]]) and \\\n                    (j,i) not in shared_v_idx:\n                        \n                    v_aux = list(shared_verts)[0] # v_aux is a tuple\n                    v_aux = list(v_aux) # Now v_aux is a list (i.e. mutable)\n                    if left[i,j] or right[i,j]:\n                        v_aux[0]-=10 # Create a new vertex  with the same y\n                    elif top[i,j] or bottom[i,j]:\n                        v_aux[1]-=10 # Create a new vertex  with the same x\n                    else:\n                        raise ValueError(""WTF?"")                        \n                    shared_verts = [tuple(shared_verts)[0], tuple(v_aux)]\n                    shared_v.append(shared_verts)\n                    shared_v_idx.append((i,j))\n        \n        # Concat to the current list of vertices\n        if shared_v:\n            self.shared_v = np.concatenate((self.shared_v, shared_v))\n            self.shared_v_idx = np.concatenate((self.shared_v_idx, shared_v_idx))\n        \n    def create_zero_boundary_constrains(self):\n        xmin, ymin = self.domain_min\n        xmax, ymax = self.domain_max\n        Ltemp = np.zeros(shape=(0,6*self.nC))\n        for c in range(self.nC):\n            for v in self.verts[c]:\n                if(v[0] == xmin or v[0] == xmax): \n                    row = np.zeros(shape=(6*self.nC))\n                    row[(6*c):(6*(c+1))] = np.append(v,np.zeros((1,3)))\n                    Ltemp = np.vstack((Ltemp, row))\n                if(v[1] == ymin or v[1] == ymax): \n                    row = np.zeros(shape=(6*self.nC))\n                    row[(6*c):(6*(c+1))] = np.append(np.zeros((1,3)),v)\n                    Ltemp = np.vstack((Ltemp, row))\n        return Ltemp\n\n#%%\nclass Tesselation3D(Tesselation):\n    def __init__(self, nc, domain_min, domain_max,\n                 zero_boundary = True, volume_perservation=False, \n                 direc=None, override=False):\n        # 1D parameters\n        self.n_params = 12\n        self.nC = 5*np.prod(nc) # 6 triangle per cell\n        self.ndim = 3\n        \n        # Initialize super class\n        super(Tesselation3D, self).__init__(nc, domain_min, domain_max,\n             zero_boundary, volume_perservation, direc, override)\n    \n    def find_verts(self):\n        Vx = np.linspace(self.domain_min[0], self.domain_max[0], self.nc[0]+1)\n        Vy = np.linspace(self.domain_min[1], self.domain_max[1], self.nc[1]+1)\n        Vz = np.linspace(self.domain_min[2], self.domain_max[2], self.nc[2]+1)\n        \n        # Find cell index and verts for each cell\n        cells, verts = [ ], [ ]\n        for i in range(self.nc[2]):\n            for j in range(self.nc[1]):        \n                for k in range(self.nc[0]):\n                    ul0 = tuple([Vx[k],Vy[j],Vz[i],1])\n                    ur0 = tuple([Vx[k+1],Vy[j],Vz[i],1])\n                    ll0 = tuple([Vx[k],Vy[j+1],Vz[i],1])\n                    lr0 = tuple([Vx[k+1],Vy[j+1],Vz[i],1])\n                    ul1 = tuple([Vx[k],Vy[j],Vz[i+1],1])\n                    ur1 = tuple([Vx[k+1],Vy[j],Vz[i+1],1])\n                    ll1 = tuple([Vx[k],Vy[j+1],Vz[i+1],1])\n                    lr1 = tuple([Vx[k+1],Vy[j+1],Vz[i+1],1])\n\n                    tf=False                    \n                    if k%2==0:\n                        if (i%2==0 and j%2==1) or  (i%2==1 and j%2==0):\n                            tf=True\n                    else:\n                        if (i%2==0 and j%2==0) or  (i%2==1 and j%2==1):\n                            tf=True\n                    \n                    if tf:\n                        ul0,ur0,lr0,ll0 = ur0,lr0,ll0,ul0\n                        ul1,ur1,lr1,ll1 = ur1,lr1,ll1,ul1\n                    \n                    # ORDER MATTERS \n                    verts.append((ll1,ur1,ul0,lr0))  # central part\n                    verts.append((ul1,ur1,ll1,ul0))\n                    verts.append((lr1,ur1,ll1,lr0))\n                    verts.append((ll0,ul0,lr0,ll1))\n                    verts.append((ur0,ul0,lr0,ur1))\n                    \n                    for l in range(5):\n                        cells.append((k,j,i,l))\n        \n        # Convert to array\n        self.verts = np.asarray(verts)\n        self.cells = cells\n\n    def find_verts_outside(self):\n        shared_verts, shared_verts_idx = [ ], [ ]\n        # Iterate over all pairs of cells\n        for i in range(self.nC):\n            for j in range(self.nC):\n                if i != j:\n                    # Add constrains for each side\n                    for d in range(self.ndim):\n                        # Get cell vertices\n                        vi = self.verts[i]    \n                        vj = self.verts[j]\n                        ci = self.cells[i]\n                        cj = self.cells[j]\n                        # Conditions for adding a constrain\n                        upper_cond = sum(vi[:,d]==self.domain_min[d]) == 3 and \\\n                                     sum(vj[:,d]==self.domain_min[d]) == 3\n                        lower_cond = sum(vi[:,d]==self.domain_max[d]) == 3 and \\\n                                     sum(vj[:,d]==self.domain_max[d]) == 3\n                        dist_cond = (sum([abs(i1-i2) for i1,i2 in zip(ci[:3], cj[:3])]) == 0) # same cell\n                        idx_cond = (j,i) not in shared_verts_idx\n                        if (upper_cond or lower_cond) and dist_cond and idx_cond:\n                            # Find the shared points\n                            vi = make_hashable(vi)\n                            vj = make_hashable(vj)\n                            sv = set(vi).intersection(vj)\n                            center = [(v1 + v2) / 2.0 for v1, v2 in zip(vi[0], vj[0])]\n                            center[d] += (-1) if upper_cond else (+1)\n                            shared_verts.append(list(sv.union([tuple(center)])))\n                            shared_verts_idx.append((i,j))\n                            \n        # Add to already found pairs\n        if shared_verts:\n            self.shared_v = np.concatenate((self.shared_v, np.asarray(shared_verts)))\n            self.shared_v_idx += shared_verts_idx\n\n            \n    def create_zero_boundary_constrains(self):\n        xmin, ymin, zmin = self.domain_min\n        xmax, ymax, zmax = self.domain_max\n        Ltemp = np.zeros(shape=(0, 12*self.nC))\n        for c in range(self.nC):\n            for v in self.verts[c]:\n                if(v[0] == xmin or v[0] == xmax):\n                    row = np.zeros(shape=(12*self.nC))\n                    row[(12*c):(12*(c+1))] = np.concatenate([v, np.zeros((8,))])\n                    Ltemp = np.vstack((Ltemp, row))\n                if(v[1] == ymin or v[1] == ymax):\n                    row = np.zeros(shape=(12*self.nC))\n                    row[(12*c):(12*(c+1))] = np.concatenate([np.zeros((4,)), v, np.zeros((4,))])\n                    Ltemp = np.vstack((Ltemp, row))\n                if(v[2] == zmin or v[2] == zmax):\n                    row = np.zeros(shape=(12*self.nC))\n                    row[(12*c):(12*(c+1))] = np.concatenate([np.zeros((8,)), v])\n                    Ltemp = np.vstack((Ltemp, row))\n        return Ltemp\n                    \n#%%\nif __name__ == ""__main__"":\n    tess1 = Tesselation1D([5], [0], [1], zero_boundary=True, volume_perservation=True)\n    tess2 = Tesselation2D([2,2], [0,0], [1,1], zero_boundary=False, volume_perservation=True)\n    tess3 = Tesselation3D([2,2,2], [0,0,0], [1,1,1], zero_boundary=True, volume_perservation=False)\n'"
libcpab/core/utility.py,7,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Mon Nov 20 09:39:44 2017\n\n@author: nsde\n""""""\n#%%\ntry:\n    import cPickle as pkl\nexcept:\n    import pickle as pkl\nimport os, random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.linalg as la\nfrom scipy import transpose, compress\n\n#%%\nclass params:\n    pass\n    \n    def __repr__(self):\n        return str(self.__dict__)\n\n#%%\ndef null(A, eps = 1e-6):\n    """""" Find the null space of a matrix\n        \n    Arguments:\n        A: `Matrix` [n,m]. Matrix to find the null space of\n        eps: `float` (default: 1e-6). Only singular values below the value of\n            eps are used to determine the null space\n    \n    Output:\n        `Matrix` [n,m]. The null space of the input matrix\n    """"""\n    u, s, vh = la.svd(A)\n    padding = np.max([0, np.shape(A)[-1] - np.shape(s)[0]])\n    null_mask = np.concatenate(((s <= eps), np.ones((padding,), dtype=bool)), axis=0)\n    null_space = compress(null_mask, vh, axis=0)\n    return transpose(null_space)\n\n#%%\ndef make_hashable(arr):\n    """""" Make an array hasable. In this way we can use built-in functions like\n        set(...) and intersection(...) on the array\n    """"""\n    return tuple([tuple(r.tolist()) for r in arr])\n\n#%%\ndef load_obj(name):\n    """""" Function for saving a variable as a pickle file """"""\n    with open(name + \'.pkl\', \'rb\') as f:\n        return pkl.load(f)\n\n#%%\ndef save_obj(obj, name):\n    """""" Function for loading a pickle file """"""\n    with open(name + \'.pkl\', \'wb\') as f:\n        pkl.dump(obj, f, pkl.HIGHEST_PROTOCOL)\n\n#%%\ndef get_path(file):\n    """""" Get the path of the input file """"""\n    return os.path.realpath(file)\n\n#%%\ndef get_dir(file):\n    """""" Get directory of the input file """"""\n    return os.path.dirname(os.path.realpath(file))\n\n#%%\ndef create_dir(direc):\n    """""" Create a dir if it does not already exists """"""\n    if not os.path.exists(direc):\n        os.mkdir(direc)\n\n#%%\ndef check_if_file_exist(file):\n    return os.path.isfile(file)\n\n#%%\ndef uniqueid_generator(x):\n    """""" Function to generate uniquely id of x bits """"""\n    seed = random.getrandbits(x)\n    while True:\n       yield str(seed)\n       seed += 1\nuniqueid = uniqueid_generator(12)\n\n#%%\ndef show_images(images, cols=\'auto\', title=None, scaling=False):\n    """""" Display a list of images in a single figure with matplotlib.\n    \n    Arguments\n        images: List/tensor of np.arrays compatible with plt.imshow.\n    \n        cols (Default = \'auto\'): Number of columns in figure (number of rows is \n                                 set to np.ceil(n_images/float(cols))).\n        \n        title: One main title for the hole figure\n            \n        scaling (Default = False): If True, will rescale the figure by the\n                number of images. Good if one want to show many.\n    """"""\n    n_images = len(images)\n    cols = np.round(np.sqrt(n_images)) if cols==\'auto\' else cols\n    rows = np.ceil(n_images/float(cols))\n    fig = plt.figure()\n    if type(title)==str: fig.suptitle(title, fontsize=20)\n    for n, image in enumerate(images):\n        a = fig.add_subplot(cols, rows, n + 1)\n        if image.ndim == 2: plt.gray()\n        a.imshow(image)\n        a.axis(\'off\')\n        a.axis(\'equal\')\n        a.set_xticklabels([])\n        a.set_yticklabels([])\n    if scaling: fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    fig.subplots_adjust(wspace=0, hspace=0)\n    plt.tight_layout()\n    plt.show()\n\n#%%\nif __name__ == \'__main__\':\n    pass    \n'"
libcpab/numpy/__init__.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Fri Nov 16 15:26:48 2018\n\n@author: nsde\n""""""\n\n#%%\nimport numpy as np\n'"
libcpab/numpy/findcellidx.py,30,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Wed Nov 21 14:31:34 2018\n\n@author: nsde\n""""""\n\n#%%\nimport numpy as np\n\n#%%\ndef mymin(a, b):\n    return np.where(a < b, a, np.round(b))\n\n#%%\ndef findcellidx(ndim, p, nc):\n    if ndim==1:   return findcellidx1D(p, *nc)\n    elif ndim==2: return findcellidx2D(p, *nc)\n    elif ndim==3: return findcellidx3D(p, *nc)\n    \n#%%\ndef findcellidx1D(p, nx):\n    p = p.copy()\n    idx = np.floor(p[0] * nx)\n    idx = np.maximum(0.0, np.minimum(idx, nx-1))\n    idx = idx.flatten().astype(np.int32)\n    return idx\n\n#%%\ndef findcellidx2D(p, nx, ny):\n    p = p.copy()\n    \n    inc_x = 1.0 / nx\n    inc_y = 1.0 / ny\n    \n    p0 = np.minimum(nx * inc_x - 1e-8, np.maximum(0.0, p[0]))\n    p1 = np.minimum(ny * inc_y - 1e-8, np.maximum(0.0, p[1]))\n    \n    xmod = np.fmod(p0, inc_x)\n    ymod = np.fmod(p1, inc_y)\n    \n    x = xmod / inc_x\n    y = ymod / inc_y\n    \n    idx = mymin(nx-1, (p0-xmod) / inc_x) + \\\n          mymin(ny-1, (p1-ymod) / inc_y) * nx\n    idx *= 4\n    \n    # Out of bound left\n    cond1 = (p[0]<=0) & ((p[1]<=0) & (p[1]/inc_y<p[0]/inc_x))\n    cond2 = (~ cond1) & (p[0]<=0) & ((p[1] >= ny * inc_y) & (p[1]/inc_y - ny > -p[0]/inc_x))\n    cond3 = (~ cond1) & (~ cond2) & (p[0]<=0)\n    idx[cond2] += 2\n    idx[cond3] += 3\n\n    # Out of bound right\n    out = cond1 | cond2 | cond3\n    cond4 = (~ out) & (p[0] >= nx*inc_x) & ((p[1]<=0) & (-p[1]/inc_y > p[0]/inc_x - nx))\n    cond5 = (~ out) & (~ cond4) & (p[0] >= nx*inc_x) & ((p[1] >= ny*inc_y) & (p[1]/inc_y - ny > p[0]/inc_x-nx))\n    cond6 = (~ out) & (~ cond4) & (~ cond5) & (p[0] >= nx*inc_x)\n    idx[cond5] += 2\n    idx[cond6] += 1\n    \n    # Out of bound up, nothing to do\n    \n    # Out of bound down\n    out = out | cond4 | cond5 | cond6\n    cond7 = (~ out) & (p[1] >= ny*inc_y)\n    idx[cond7] += 2\n\n    # Ok, we are inbound\n    out = out | cond7\n    cond8 = (~ out) & (x<y) & (1-x<y)\n    cond9 = (~ out) & (~ cond8) & (x<y)\n    cond10 = (~ out) & (~ cond8) & (~ cond9) & (x>=y) & (1-x<y)\n    idx[cond8] += 2\n    idx[cond9] += 3\n    idx[cond10] += 1\n    idx = idx.flatten().astype(np.int32)\n    return idx\n\n#%%\ndef findcellidx3D(p, nx, ny, nz):\n    p = p.copy()\n    # Conditions for points outside\n    cond =  np.logical_or(np.logical_or(\n            np.logical_or(p[0,:] < 0.0, p[0,:] > 1.0),\n            np.logical_or(p[1,:] < 0.0, p[1,:] > 1.0)),\n            np.logical_or(p[2,:] < 0.0, p[2,:] > 1.0))\n        \n    # Push the points inside boundary\n    inc_x, inc_y, inc_z = 1.0 / nx, 1.0 / ny, 1.0 / nz\n    half = 0.5\n    points_outside = p[:, cond]\n    points_outside -= half\n    abs_x = np.abs(points_outside[0])\n    abs_y = np.abs(points_outside[1])\n    abs_z = np.abs(points_outside[2])\n    push_x = (half * inc_x)*(np.logical_and(abs_x < abs_y, abs_x < abs_z))\n    push_y = (half * inc_y)*(np.logical_and(abs_y < abs_x, abs_x < abs_z))\n    push_z = (half * inc_z)*(np.logical_and(abs_z < abs_x, abs_x < abs_y))\n    cond_x = abs_x > half\n    cond_y = abs_y > half\n    cond_z = abs_z > half\n    points_outside[0, cond_x] = np.copysign(half - push_x[cond_x], points_outside[0, cond_x])\n    points_outside[1, cond_y] = np.copysign(half - push_y[cond_y], points_outside[1, cond_y])\n    points_outside[2, cond_z] = np.copysign(half - push_z[cond_z], points_outside[2, cond_z])\n    points_outside += half\n    p[:, cond] = points_outside\n\n    # Find row, col, depth placement and cell placement\n    inc_x, inc_y, inc_z = 1.0/nx, 1.0/ny, 1.0/nz\n    p0 = np.minimum(nx * inc_x - 1e-8, np.maximum(0.0, p[0]))\n    p1 = np.minimum(ny * inc_y - 1e-8, np.maximum(0.0, p[1]))\n    p2 = np.minimum(nz * inc_z - 1e-8, np.maximum(0.0, p[2]))\n\n    xmod = np.mod(p0, inc_x)\n    ymod = np.mod(p1, inc_y)\n    zmod = np.mod(p2, inc_z)\n    \n    i = mymin(nx - 1, ((p0 - xmod) / inc_x))\n    j = mymin(ny - 1, ((p1 - ymod) / inc_y))\n    k = mymin(nz - 1, ((p2 - zmod) / inc_z))\n    idx = 5 * (i + j * nx + k * nx * ny)\n\n    x = xmod / inc_x\n    y = ymod / inc_y\n    z = zmod / inc_z\n    \n    # Find subcell location\n    cond = np.logical_or(np.logical_or(np.logical_or(\n            ((k%2==0) & (i%2==0) & (j%2==1)),\n            ((k%2==0) & (i%2==1) & (j%2==0))),\n            ((k%2==1) & (i%2==0) & (j%2==0))),\n            ((k%2==1) & (i%2==1) & (j%2==1)))\n\n    tmp = x.copy()\n    x[cond] = y[cond]\n    y[cond] = 1-tmp[cond]\n    \n    cond1 = -x-y+z >= 0\n    cond2 = x+y+z-2 >= 0\n    cond3 = -x+y-z >= 0\n    cond4 = x-y-z >= 0\n    idx[cond1] += 1\n    idx[cond2 & ~cond1] += 2\n    idx[cond3 & ~cond1 & ~cond2] += 3\n    idx[cond4 & ~cond1 & ~cond2 & ~cond3] += 4\n    idx = idx.flatten().astype(np.int32)\n    return idx'"
libcpab/numpy/functions.py,29,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Fri Nov 16 16:01:52 2018\n\n@author: nsde\n""""""\n\n#%%\nimport numpy as np\nfrom .interpolation import interpolate\nfrom .transformer import CPAB_transformer as transformer\nfrom .findcellidx import findcellidx\n\n#%%\ndef assert_version():\n    numbers = np.__version__.split(\'.\')\n    version = float(numbers[0] + \'.\' + numbers[1])\n    assert version >= 1.14, \\\n        \'\'\' You are using a older installation of numpy, please install 1.15.\n            or newer \'\'\'\n\n#%%\ndef to(x, dtype=np.float32, device=None): \n    return np.array(x)\n\n#%%\ndef tonumpy(x):\n    return x\n\n#%%\ndef check_device(x, device_name):\n    return True # always return true, because device can only be cpu\n\n#%%\ndef backend_type():\n    return np.ndarray\n\n#%%\ndef pdist(mat):\n    norm = np.sum(mat * mat, 1)\n    norm = np.reshape(norm, (-1, 1))\n    D = norm - 2*np.matmul(mat, mat.T) + norm.T\n    return D\n\n#%%\ndef norm(x):\n    return np.linalg.norm(x)\n\n#%%\ndef matmul(x,y):\n    return np.matmul(x,y)\n\n#%%\ndef transpose(x):\n    return x.T\n\n#%%\ndef exp(x):\n    return np.exp(x)\n\n#%%\ndef zeros(*s):\n    return np.zeros(*s)\n    \n#%%\ndef ones(*s):\n    return np.ones(*s)\n\n#%%\ndef arange(x):\n    return np.arange(x)\n    \n#%%\ndef repeat(x, reps):\n    return np.repeat(x, reps)\n\n#%%\ndef batch_repeat(x, n_batch):\n    return np.repeat(x[None], n_batch, axis=0)\n\n#%%\ndef maximum(x):\n    return np.max(x)\n    \n#%%\ndef sample_transformation(d, n_sample=1, mean=None, cov=None, device=\'cpu\'):\n    mean = np.zeros(d, dtype=np.float32) if mean is None else mean\n    cov = np.eye(d, dtype=np.float32) if cov is None else cov\n    samples = np.random.multivariate_normal(mean, cov, size=n_sample)\n    return samples\n\n#%%\ndef identity(d, n_sample=1, epsilon=0, device=\'cpu\'):\n    assert epsilon>=0, ""epsilon need to be larger than or 0""\n    return np.zeros((n_sample, d), dtype=np.float32) + epsilon\n\n#%%\ndef uniform_meshgrid(ndim, domain_min, domain_max, n_points, device=\'cpu\'):\n    lin = [np.linspace(domain_min[i], domain_max[i], n_points[i]) for i in range(ndim)]\n    mesh = np.meshgrid(*lin[::-1], indexing=\'ij\')\n    grid = np.vstack([array.flatten() for array in mesh[::-1]])\n    return grid\n\n#%%\ndef calc_vectorfield(grid, theta, params):\n    # Calculate velocity fields\n    Avees = np.matmul(params.basis, theta.flatten())\n    As = np.reshape(Avees, (params.nC, *params.Ashape))\n    \n    # Find cell index\n    idx = findcellidx(params.ndim, grid, params.nc)\n    \n    # Do indexing\n    Aidx = As[idx]\n    \n    # Convert to homogeneous coordinates\n    grid = np.concatenate((grid, np.ones((1, grid.shape[1]))), axis=0)\n    grid = np.transpose(grid[None], axes=[2,1,0])\n    \n    # Do matrix multiplication\n    v = np.matmul(Aidx, grid)\n    return np.transpose(v[:,:,0]) # output: [ndim, nP] \n    '"
libcpab/numpy/interpolation.py,32,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Nov 20 10:26:30 2018\n\n@author: nsde\n""""""\n\n#%%\nimport numpy as np\n\n#%%\ndef interpolate(ndim, data, grid, outsize):\n    if ndim==1: return interpolate1D(data, grid, outsize)\n    elif ndim==2: return interpolate2D(data, grid, outsize)\n    elif ndim==3: return interpolate3D(data, grid, outsize)\n\n#%%    \ndef interpolate1D(data, grid, outsize):\n    # Problem size\n    n_batch = data.shape[0]\n    width = data.shape[1]\n    n_channels = data.shape[2]\n    out_width = outsize[0]\n    \n    # Extract points\n    x = grid[:,0].flatten()\n\n    # Scale to domain\n    x = x * (width-1)\n    \n    # Do sampling\n    x0 = np.floor(x).astype(np.int32); x1 = x0+1\n    \n    # Clip values\n    x0 = np.clip(x0, 0, width-1)\n    x1 = np.clip(x1, 0, width-1)\n    \n    # Batch effect\n    batch_size = out_width\n    batch_idx = np.arange(n_batch).repeat(batch_size)\n    \n    # Index\n    c0 = data[batch_idx, x0, :]\n    c1 = data[batch_idx, x1, :]\n    \n    # Interpolation weights\n    xd = (x-x0.astype(np.float32)).reshape((-1,1))\n    \n    # Do interpolation\n    c = c0*(1-xd) + c1*xd\n    \n    # Reshape\n    new_data = np.reshape(c, (n_batch, out_width, n_channels))\n    return new_data\n    \n    \n#%%    \ndef interpolate2D(data, grid, outsize):\n    # Problem size\n    n_batch = data.shape[0]\n    width = data.shape[1]\n    height = data.shape[2]\n    n_channels = data.shape[3]\n    out_width, out_height = outsize\n    \n    # Extract points\n    x = grid[:,0].flatten()\n    y = grid[:,1].flatten()\n    \n    # Scale to domain\n    x = x * (width-1)\n    y = y * (height-1)\n    \n    # Do sampling\n    x0 = np.floor(x).astype(np.int32); x1 = x0+1\n    y0 = np.floor(y).astype(np.int32); y1 = y0+1\n    \n    # Clip values\n    x0 = np.clip(x0, 0, width-1)\n    x1 = np.clip(x1, 0, width-1)\n    y0 = np.clip(y0, 0, height-1)\n    y1 = np.clip(y1, 0, height-1)\n    \n    # Batch effect\n    batch_size = out_width*out_height\n    batch_idx = np.arange(n_batch).repeat(batch_size)\n    \n    # Index\n    c00 = data[batch_idx, x0, y0, :]\n    c01 = data[batch_idx, x0, y1, :]\n    c10 = data[batch_idx, x1, y0, :]\n    c11 = data[batch_idx, x1, y1, :]\n    \n    # Interpolation weights\n    xd = (x-x0.astype(np.float32)).reshape((-1,1))\n    yd = (y-y0.astype(np.float32)).reshape((-1,1))\n    \n    # Do interpolation\n    c0 = c00*(1-xd) + c10*xd\n    c1 = c01*(1-xd) + c11*xd\n    c = c0*(1-yd) + c1*yd\n    \n    # Reshape\n    new_data = np.reshape(c, (n_batch, out_height, out_width, n_channels))\n    new_data = np.transpose(new_data, (0, 2, 1, 3))\n    return new_data\n    \n#%%    \ndef interpolate3D(data, grid, outsize):\n    # Problem size\n    n_batch = data.shape[0]\n    width = data.shape[1]\n    height = data.shape[2]\n    depth = data.shape[3]\n    n_channels = data.shape[4]    \n    out_width, out_height, out_depth = outsize\n    \n    # Extract points\n    x = grid[:,0].flatten()\n    y = grid[:,1].flatten()\n    z = grid[:,2].flatten()\n    \n    # Scale to domain\n    x = x * (width-1)\n    y = y * (height-1)\n    z = z * (depth-1)\n    \n    # Do sampling\n    x0 = np.floor(x).astype(np.int32); x1 = x0+1\n    y0 = np.floor(y).astype(np.int32); y1 = y0+1\n    z0 = np.floor(z).astype(np.int32); z1 = z0+1\n    \n    # Clip values\n    x0 = np.clip(x0, 0, width-1)\n    x1 = np.clip(x1, 0, width-1)\n    y0 = np.clip(y0, 0, height-1)\n    y1 = np.clip(y1, 0, height-1)\n    z0 = np.clip(z0, 0, depth-1)\n    z1 = np.clip(z1, 0, depth-1)\n    \n    # Batch effect\n    batch_size = out_width*out_height*out_depth\n    batch_idx = np.arange(n_batch).repeat(batch_size)\n    \n    # Index\n    c000 = data[batch_idx, x0, y0, z0, :]\n    c001 = data[batch_idx, x0, y0, z1, :]\n    c010 = data[batch_idx, x0, y1, z0, :]\n    c011 = data[batch_idx, x0, y1, z1, :]\n    c100 = data[batch_idx, x1, y0, z0, :]\n    c101 = data[batch_idx, x1, y0, z1, :]\n    c110 = data[batch_idx, x1, y1, z0, :]\n    c111 = data[batch_idx, x1, y1, z1, :]\n    \n    # Interpolation weights\n    xd = (x-x0.astype(np.float32)).reshape((-1,1))\n    yd = (y-y0.astype(np.float32)).reshape((-1,1))\n    zd = (z-z0.astype(np.float32)).reshape((-1,1))\n    \n    # Do interpolation\n    c00 = c000*(1-xd) + c100*xd\n    c01 = c001*(1-xd) + c101*xd\n    c10 = c010*(1-xd) + c110*xd\n    c11 = c011*(1-xd) + c111*xd\n    c0 = c00*(1-yd) + c10*yd\n    c1 = c01*(1-yd) + c11*yd\n    c = c0*(1-zd) + c1*zd\n    \n    # Reshape\n    new_data = np.reshape(c, (n_batch, out_depth, out_height, out_width, n_channels))\n    new_data = np.transpose(new_data, (0, 3, 2, 1, 4))\n    return new_data\n        \n'"
libcpab/numpy/transformer.py,13,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Nov 20 10:27:16 2018\n\n@author: nsde\n""""""\n\n#%%\nimport numpy as np\nfrom scipy.linalg import expm\nfrom .findcellidx import findcellidx\n\n#%%\ncompiled = False\n\n#%%\ndef CPAB_transformer(points, theta, params):\n    if compiled: return CPAB_transformer_fast(points, theta, params)\n    else: return CPAB_transformer_slow(points, theta, params)\n\n#%%\ndef CPAB_transformer_slow(points, theta, params):\n    # Problem parameters\n    n_theta = theta.shape[0]\n    n_points = points.shape[-1]\n    \n    # Create homogenous coordinates\n    ones = np.ones((n_theta, 1, n_points))\n    if len(points.shape)==2: # tile if 2D grid\n        newpoints = np.tile(points, [n_theta, 1, 1]) # [n_theta, ndim, n_points]\n    else:\n        newpoints = points\n    newpoints = np.concatenate((newpoints, ones), axis=1) # [n_theta, ndim+1, n_points]\n    newpoints = np.transpose(newpoints, (0, 2, 1)) # [n_theta, n_points, ndim+1]\n    newpoints = np.reshape(newpoints, (-1, params.ndim+1)) #[n_theta*n_points, ndim+1]]\n    newpoints = newpoints[:,:,None] # [n_theta*n_points, ndim+1, 1]\n    \n    # Get velocity fields\n    B = params.basis\n    Avees = np.matmul(B, theta.T)\n    As = Avees.T.reshape(n_theta*params.nC, *params.Ashape)\n    zero_row = np.zeros((n_theta*params.nC, 1, params.ndim+1))\n    AsSquare = np.concatenate([As, zero_row], axis=1)\n    \n    # Take matrix exponential\n    dT = 1.0 / params.nstepsolver\n    Trels = np.stack([expm(dT*array) for array in AsSquare])\n    \n    # Take care of batch effect\n    batch_idx = params.nC*(np.ones((n_points, n_theta)) * np.arange(n_theta))\n    batch_idx = batch_idx.T.flatten().astype(np.int32)\n    \n    # Do integration\n    for i in range(params.nstepsolver):\n        idx = findcellidx(params.ndim, newpoints[:,:,0].T, params.nc) + batch_idx\n        Tidx = Trels[idx]\n        newpoints = np.matmul(Tidx, newpoints)\n    \n    newpoints = newpoints.squeeze()[:,:params.ndim].T\n    newpoints = np.transpose(newpoints.reshape(params.ndim, n_theta, n_points), (1,0,2))\n    return newpoints\n\n#%%\ndef CPAB_transformer_fast(points, theta):\n    # TODO: jit compile cpp code into callable python code\n    pass'"
libcpab/pytorch/__init__.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Fri Nov 16 15:26:48 2018\n\n@author: nsde\n""""""\n\n#%%\nimport torch\n\n#%%'"
libcpab/pytorch/expm.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Dec 13 09:14:45 2018\n\n@author: nsde\n""""""\n#%%\nimport torch\n\n#%%\ndef expm(A):\n    """""" """"""\n    n_A = A.shape[0]\n    A_fro = torch.sqrt(A.abs().pow(2).sum(dim=(1,2), keepdim=True))\n    \n    # Scaling step\n    maxnorm = torch.Tensor([5.371920351148152]).type(A.dtype).to(A.device)\n    zero = torch.Tensor([0.0]).type(A.dtype).to(A.device)\n    n_squarings = torch.max(zero, torch.ceil(log2(A_fro / maxnorm)))\n    Ascaled = A / 2.0**n_squarings    \n    n_squarings = n_squarings.flatten().type(torch.int64)\n    \n    # Pade 13 approximation\n    U, V = pade13(Ascaled)\n    P = U + V\n    Q = -U + V\n    R, _ = torch.solve(P, Q) # solve P = Q*R\n    \n    # Unsquaring step    \n    n = n_squarings.max()\n    res = [R]\n    for i in range(n):\n        res.append(res[-1].matmul(res[-1]))\n    R = torch.stack(res)\n    expmA = R[n_squarings, torch.arange(n_A)]\n    return expmA\n\n#%%\ndef log2(x):\n    return torch.log(x) / torch.log(torch.Tensor([2.0])).type(x.dtype).to(x.device)\n\n#%%    \ndef pade13(A):\n    b = torch.Tensor([64764752532480000., 32382376266240000., 7771770303897600.,\n                      1187353796428800., 129060195264000., 10559470521600.,\n                      670442572800., 33522128640., 1323241920., 40840800.,\n                      960960., 16380., 182., 1.]).type(A.dtype).to(A.device)\n        \n    ident = torch.eye(A.shape[1], dtype=A.dtype).to(A.device)\n    A2 = torch.matmul(A,A)\n    A4 = torch.matmul(A2,A2)\n    A6 = torch.matmul(A4,A2)\n    U = torch.matmul(A, torch.matmul(A6, b[13]*A6 + b[11]*A4 + b[9]*A2) + b[7]*A6 + b[5]*A4 + b[3]*A2 + b[1]*ident)\n    V = torch.matmul(A6, b[12]*A6 + b[10]*A4 + b[8]*A2) + b[6]*A6 + b[4]*A4 + b[2]*A2 + b[0]*ident\n    return U, V'"
libcpab/pytorch/findcellidx.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Wed Nov 21 14:31:34 2018\n\n@author: nsde\n""""""\n\n#%%\nimport torch\n\n#%%\ndef mymin(a, b):\n    return torch.where(a < b, a, torch.round(b))\n\n#%%\ndef findcellidx(ndim, p, nc):\n    if ndim==1:   return findcellidx1D(p, *nc)\n    elif ndim==2: return findcellidx2D(p, *nc)\n    elif ndim==3: return findcellidx3D(p, *nc)\n    \n#%%\ndef findcellidx1D(p, nx):\n    n = p.shape[1]\n    idx = torch.floor(p[0] * nx)\n    idx = torch.max(torch.zeros(n, device=p.device), \n                    torch.min(idx, (nx-1)*torch.ones(n, device=p.device)))\n    return idx.flatten().to(torch.int64)\n\n#%%\ndef findcellidx2D(p, nx, ny):\n    n = p.shape[1]\n    inc_x = 1.0 / nx\n    inc_y = 1.0 / ny\n    \n    #p0 = torch.min(nx * inc_x - 1e-8, torch.max(0.0, p[0]))\n    #p1 = torch.min(ny * inc_y - 1e-8, torch.max(0.0, p[1]))\n    p0 = torch.clamp(p[0], 0.0, nx * inc_x - 1e-8)\n    p1 = torch.clamp(p[1], 0.0, ny * inc_y - 1e-8)\n    \n    xmod = torch.fmod(p0, inc_x)\n    ymod = torch.fmod(p1, inc_y)\n    \n    x = xmod / inc_x\n    y = ymod / inc_y\n    \n    idx = mymin((nx-1)*torch.ones(n, device=p.device), (p0-xmod) / inc_x) + \\\n          mymin((ny-1)*torch.ones(n, device=p.device), (p1-ymod) / inc_y) * nx\n    idx *= 4\n    \n    # Out of bound left\n    cond1 = (p[0]<=0) & ((p[1]<=0) & (p[1]/inc_y<p[0]/inc_x))\n    cond2 = (~ cond1) & (p[0]<=0) & ((p[1] >= ny * inc_y) & (p[1]/inc_y - ny > -p[0]/inc_x))\n    cond3 = (~ cond1) & (~ cond2) & (p[0]<=0)\n    idx[cond2] += 2\n    idx[cond3] += 3\n\n    # Out of bound right\n    out = cond1 | cond2 | cond3\n    cond4 = (~ out) & (p[0] >= nx*inc_x) & ((p[1]<=0) & (-p[1]/inc_y > p[0]/inc_x - nx))\n    cond5 = (~ out) & (~ cond4) & (p[0] >= nx*inc_x) & ((p[1] >= ny*inc_y) & (p[1]/inc_y - ny > p[0]/inc_x-nx))\n    cond6 = (~ out) & (~ cond4) & (~ cond5) & (p[0] >= nx*inc_x)\n    idx[cond5] += 2\n    idx[cond6] += 1\n    \n    # Out of bound up, nothing to do\n    \n    # Out of bound down\n    out = out | cond4 | cond5 | cond6\n    cond7 = (~ out) & (p[1] >= ny*inc_y)\n    idx[cond7] += 2\n\n    # Ok, we are inbound\n    out = out | cond7\n    cond8 = (~ out) & (x<y) & (1-x<y)\n    cond9 = (~ out) & (~ cond8) & (x<y)\n    cond10 = (~ out) & (~ cond8) & (~ cond9) & (x>=y) & (1-x<y)\n    idx[cond8] += 2\n    idx[cond9] += 3\n    idx[cond10] += 1\n    return idx.flatten().to(torch.int64)\n    \n#%%\ndef findcellidx3D(p, nx, ny, nz):\n    # Conditions for points outside\n    cond =  (p[0,:] < 0.0) | (p[0,:] > 1.0) | \\\n            (p[1,:] < 0.0) | (p[1,:] > 1.0) | \\\n            (p[2,:] < 0.0) | (p[2,:] > 1.0) \n        \n    # Push the points inside boundary\n    inc_x, inc_y, inc_z = 1.0 / nx, 1.0 / ny, 1.0 / nz\n    half = 0.5\n    points_outside = p[:, cond]\n    points_outside -= half\n    abs_x = torch.abs(points_outside[0])\n    abs_y = torch.abs(points_outside[1])\n    abs_z = torch.abs(points_outside[2])\n    push_x = ((half * inc_x)*((abs_x < abs_y) & (abs_x < abs_z))).to(torch.float32)\n    push_y = ((half * inc_y)*((abs_y < abs_x) & (abs_x < abs_z))).to(torch.float32)\n    push_z = ((half * inc_z)*((abs_z < abs_x) & (abs_x < abs_y))).to(torch.float32)\n    cond_x = abs_x > half\n    cond_y = abs_y > half\n    cond_z = abs_z > half\n    points_outside[0, cond_x] = points_outside[0, cond_x].sign() * (half - push_x[cond_x])\n    points_outside[1, cond_y] = points_outside[1, cond_y].sign() * (half - push_y[cond_y])\n    points_outside[2, cond_z] = points_outside[2, cond_z].sign() * (half - push_z[cond_z])\n    points_outside += half\n    p[:, cond] = points_outside\n\n    # Find row, col, depth placement and cell placement\n    inc_x, inc_y, inc_z = 1.0/nx, 1.0/ny, 1.0/nz\n    zero = torch.tensor(0.0).to(p.device)\n    p0 = torch.min(torch.tensor(nx * inc_x - 1e-4).to(p.device), torch.max(zero, p[0]))\n    p1 = torch.min(torch.tensor(ny * inc_y - 1e-4).to(p.device), torch.max(zero, p[1]))\n    p2 = torch.min(torch.tensor(nz * inc_z - 1e-4).to(p.device), torch.max(zero, p[2]))\n\n    xmod = torch.fmod(p0, inc_x)\n    ymod = torch.fmod(p1, inc_y)\n    zmod = torch.fmod(p2, inc_z)\n    \n    i = mymin(torch.tensor(nx - 1).to(torch.float32).to(p.device), ((p0 - xmod) / inc_x))\n    j = mymin(torch.tensor(ny - 1).to(torch.float32).to(p.device), ((p1 - ymod) / inc_y))\n    k = mymin(torch.tensor(nz - 1).to(torch.float32).to(p.device), ((p2 - zmod) / inc_z))\n    idx = 5 * (i + j * nx + k * nx * ny)\n\n    x = xmod / inc_x\n    y = ymod / inc_y\n    z = zmod / inc_z\n    \n    # Find subcell location\n    cond =  ((k%2==0) & (i%2==0) & (j%2==1)) | \\\n            ((k%2==0) & (i%2==1) & (j%2==0)) | \\\n            ((k%2==1) & (i%2==0) & (j%2==0)) | \\\n            ((k%2==1) & (i%2==1) & (j%2==1))\n\n    tmp = x.clone()\n    x[cond] = y[cond]\n    y[cond] = 1-tmp[cond]\n    \n    cond1 = (-x-y+z) >= 0\n    cond2 = (x+y+z-2) >= 0\n    cond3 = (-x+y-z) >= 0\n    cond4 = (x-y-z) >= 0\n    idx[cond1] += 1\n    idx[cond2 & (~cond1)] += 2\n    idx[cond3 & (~cond1) & (~cond2)] += 3\n    idx[cond4 & (~cond1) & (~cond2) & (~cond3)] += 4\n    idx = idx.flatten().to(torch.int64)\n    return idx\n'"
libcpab/pytorch/functions.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Fri Nov 16 16:01:52 2018\n\n@author: nsde\n""""""\n\n#%%\nimport torch\nfrom .interpolation import interpolate\nfrom .transformer import CPAB_transformer as transformer\nfrom .findcellidx import findcellidx\n\n#%%\ndef assert_version():\n    numbers = torch.__version__.split(\'.\')\n    version = float(numbers[0] + \'.\' + numbers[1])\n    assert version >= 1.0, \\\n        \'\'\' You are using a older installation of pytorch, please install 1.0.0\n            or newer \'\'\'\n\n#%%\ndef to(x, dtype=torch.float32, device=None):\n    if type(device)==str:\n        device = torch.device(""cuda"") if device==""gpu"" else torch.device(""cpu"")\n    return torch.tensor(x, dtype=dtype, device=device)\n\n#%%\ndef tonumpy(x):\n    return x.cpu().numpy()\n\n#%%\ndef check_device(x, device_name):\n    return (x.is_cuda) == (device_name==""gpu"")\n\n#%%\ndef backend_type():\n    return torch.Tensor\n\n#%%\ndef pdist(mat):\n    norm = torch.sum(mat * mat, 1)\n    norm = torch.reshape(norm, (-1, 1))\n    D = norm - 2*mat.mm(mat.t()) + norm.t()\n    return D\n\n#%%\ndef norm(x):\n    return torch.norm(x)\n\n#%%\ndef matmul(x,y):\n    return torch.matmul(x,y)\n\n#%%\ndef transpose(x):\n    return x.t()\n\n#%%\ndef exp(x):\n    return torch.exp(x)\n\n#%%\ndef zeros(*s):\n    return torch.zeros(*s)\n    \n#%%\ndef ones(*s):\n    return torch.ones(*s)\n\n#%%\ndef arange(x):\n    return torch.arange(x)\n    \n#%%\ndef repeat(x, reps):\n    return x.repeat(reps)\n\n#%%\ndef batch_repeat(x, reps):\n    return x.repeat(reps, *(x.dim()*[1]))\n\n#%%\ndef maximum(x):\n    return x.max()\n\n#%%\ndef sample_transformation(d, n_sample=1, mean=None, cov=None, device=\'cpu\'):\n    device = torch.device(\'cpu\') if device==\'cpu\' else torch.device(\'cuda\')\n    mean = torch.zeros(d, dtype=torch.float32, device=device) if mean is None else mean\n    cov = torch.eye(d, dtype=torch.float32, device=device) if cov is None else cov\n    distribution = torch.distributions.MultivariateNormal(mean, cov)\n    return distribution.sample((n_sample,)).to(device)\n\n#%%\ndef identity(d, n_sample=1, epsilon=0, device=\'cpu\'):\n    assert epsilon>=0, ""epsilon need to be larger than 0""\n    device = torch.device(\'cpu\') if device==\'cpu\' else torch.device(\'cuda\')\n    return torch.zeros(n_sample, d, dtype=torch.float32, device=device) + epsilon\n\n#%%\ndef uniform_meshgrid(ndim, domain_min, domain_max, n_points, device=\'cpu\'):\n    device = torch.device(\'cpu\') if device==\'cpu\' else torch.device(\'cuda\')\n    lin = [torch.linspace(domain_min[i], domain_max[i], n_points[i], \n                          device=device) for i in range(ndim)]\n    mesh = torch.meshgrid(lin[::-1])\n    grid = torch.cat([g.reshape(1,-1) for g in mesh[::-1]], dim=0)\n    return grid\n\n#%%\ndef calc_vectorfield(grid, theta, params):   \n    # Calculate velocity fields\n    B = to(params.basis, dtype=theta.dtype, device=theta.device)\n    Avees = torch.matmul(B, theta.flatten())\n    As = torch.reshape(Avees, (params.nC, *params.Ashape))\n    \n    # Find cell index\n    idx = findcellidx(params.ndim, grid, params.nc)\n    \n    # Do indexing\n    Aidx = As[idx]\n    \n    # Convert to homogeneous coordinates\n    grid = torch.cat((grid, torch.ones(1, grid.shape[1], device=grid.device)), dim=0)\n    grid = grid[None].permute(2,1,0)\n    \n    # Do matrix multiplication\n    v = torch.matmul(Aidx, grid)\n    return v[:,:,0].t()\n'"
libcpab/pytorch/interpolation.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Nov 20 10:26:30 2018\n\n@author: nsde\n""""""\n\n#%%\nimport torch\n\n#%%\ndef interpolate(ndim, data, grid, outsize):\n    if ndim==1: return interpolate1D(data, grid, outsize)\n    elif ndim==2: return interpolate2D(data, grid, outsize)\n    elif ndim==3: return interpolate3D(data, grid, outsize)\n\n#%%    \ndef interpolate1D(data, grid, outsize):\n    # Problem size\n    n_batch = data.shape[0]\n    n_channels = data.shape[1]\n    width = data.shape[2]\n    out_width = outsize[0]\n    \n    # Extract points\n    x = grid[:,0].flatten()\n\n    # Scale to domain\n    x = x * (width-1)\n    \n    # Do sampling\n    x0 = torch.floor(x).to(torch.int64); x1 = x0+1\n    \n    # Clip values\n    x0 = torch.clamp(x0, 0, width-1)\n    x1 = torch.clamp(x1, 0, width-1)\n    \n    # Batch effect\n    batch_size = out_width\n    batch_idx = torch.arange(n_batch).repeat(batch_size, 1).t().flatten()\n    \n    # Index\n    c0 = data[batch_idx, :, x0]\n    c1 = data[batch_idx, :, x1]\n    \n    # Interpolation weights\n    xd = (x-x0.to(torch.float32)).reshape((-1,1))\n    \n    # Do interpolation\n    c = c0*(1-xd) + c1*xd\n    \n    # Reshape\n    new_data = torch.reshape(c, (n_batch, out_width, n_channels))\n    new_data = new_data.permute(0, 2, 1)\n    return new_data.contiguous()\n    \n#%%    \ndef interpolate2D(data, grid, outsize):\n    # Problem size\n    n_batch = data.shape[0]\n    n_channels = data.shape[1]\n    width = data.shape[2]\n    height = data.shape[3]\n    out_width, out_height = outsize\n    \n    # Extract points\n    x = grid[:,0].flatten()\n    y = grid[:,1].flatten()\n    \n    # Scale to domain\n    x = x * (width-1)\n    y = y * (height-1)\n    \n    # Do sampling\n    x0 = torch.floor(x).to(torch.int64); x1 = x0+1\n    y0 = torch.floor(y).to(torch.int64); y1 = y0+1\n    \n    # Clip values\n    x0 = torch.clamp(x0, 0, width-1)\n    x1 = torch.clamp(x1, 0, width-1)\n    y0 = torch.clamp(y0, 0, height-1)\n    y1 = torch.clamp(y1, 0, height-1)\n    \n    # Batch effect\n    batch_size = out_width*out_height\n    batch_idx = torch.arange(n_batch).repeat(batch_size, 1).t().flatten()\n    \n    # Index\n    c00 = data[batch_idx, :, x0, y0]\n    c01 = data[batch_idx, :, x0, y1]\n    c10 = data[batch_idx, :, x1, y0]\n    c11 = data[batch_idx, :, x1, y1]\n    \n    # Interpolation weights\n    xd = (x-x0.to(torch.float32)).reshape((-1,1))\n    yd = (y-y0.to(torch.float32)).reshape((-1,1))\n    \n    # Do interpolation\n    c0 = c00*(1-xd) + c10*xd\n    c1 = c01*(1-xd) + c11*xd\n    c = c0*(1-yd) + c1*yd\n    \n    # Reshape\n    new_data = torch.reshape(c, (n_batch, out_height, out_width, n_channels))\n    new_data = new_data.permute(0, 3, 2, 1)\n    return new_data.contiguous()\n    \n#%%    \ndef interpolate3D(data, grid, outsize):\n    # Problem size\n    n_batch = data.shape[0]\n    n_channels = data.shape[1]\n    width = data.shape[2]\n    height = data.shape[3]\n    depth = data.shape[4]\n    out_width, out_height, out_depth = outsize\n    \n    # Extract points\n    x = grid[:,0].flatten()\n    y = grid[:,1].flatten()\n    z = grid[:,2].flatten()\n    \n    # Scale to domain\n    x = x * (width-1)\n    y = y * (height-1)\n    z = z * (depth-1)\n    \n    # Do sampling\n    x0 = torch.floor(x).to(torch.int64); x1 = x0+1\n    y0 = torch.floor(y).to(torch.int64); y1 = y0+1\n    z0 = torch.floor(z).to(torch.int64); z1 = z0+1\n    \n    # Clip values\n    x0 = torch.clamp(x0, 0, width-1)\n    x1 = torch.clamp(x1, 0, width-1)\n    y0 = torch.clamp(y0, 0, height-1)\n    y1 = torch.clamp(y1, 0, height-1)\n    z0 = torch.clamp(z0, 0, depth-1)\n    z1 = torch.clamp(z1, 0, depth-1)\n    \n    # Batch effect\n    batch_size = out_width*out_height*out_depth\n    #batch_idx = (torch.arange(n_batch)*batch_size).repeat(batch_size)\n    batch_idx = torch.arange(n_batch).repeat(batch_size, 1).t().flatten()\n    # Index\n    c000 = data[batch_idx, :, x0, y0, z0]\n    c001 = data[batch_idx, :, x0, y0, z1]\n    c010 = data[batch_idx, :, x0, y1, z0]\n    c011 = data[batch_idx, :, x0, y1, z1]\n    c100 = data[batch_idx, :, x1, y0, z0]\n    c101 = data[batch_idx, :, x1, y0, z1]\n    c110 = data[batch_idx, :, x1, y1, z0]\n    c111 = data[batch_idx, :, x1, y1, z1]\n    \n    # Interpolation weights\n    xd = (x-x0.to(torch.float32)).reshape((-1,1))\n    yd = (y-y0.to(torch.float32)).reshape((-1,1))\n    zd = (z-z0.to(torch.float32)).reshape((-1,1))\n   \n    # Do interpolation\n    c00 = c000*(1-xd) + c100*xd\n    c01 = c001*(1-xd) + c101*xd\n    c10 = c010*(1-xd) + c110*xd\n    c11 = c011*(1-xd) + c111*xd\n    c0 = c00*(1-yd) + c10*yd\n    c1 = c01*(1-yd) + c11*yd\n    c = c0*(1-zd) + c1*zd\n    \n    # Reshape\n    new_data = torch.reshape(c, (n_batch, out_depth, out_height, out_width, n_channels))\n    new_data = new_data.permute(0, 4, 3, 2, 1)\n    return new_data.contiguous()'"
libcpab/pytorch/transformer.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Nov 20 10:27:16 2018\n\n@author: nsde\n""""""\n\n#%%\nimport torch\nfrom torch.utils.cpp_extension import load\nfrom .findcellidx import findcellidx\nfrom .expm import expm\nfrom ..core.utility import get_dir\n\n#%%\nclass _notcompiled:\n    # Small class, with structure similar to the compiled modules we can default\n    # to. The class will never be called but the program can compile at run time\n    def __init__(self):\n        def f(*args):\n            return None\n        self.forward = f\n        self.backward = f\n\n#%%\n_dir = get_dir(__file__)\n_verbose = False # TODO: set this flag in the main class, maybe\n# Jit compile cpu source\ntry:\n    cpab_cpu = load(name = \'cpab_cpu\',\n                    sources = [_dir + \'/transformer.cpp\',\n                               _dir + \'/../core/cpab_ops.cpp\'],\n                    verbose=_verbose)\n    _cpu_succes = True\n    if _verbose:\n        print(70*\'=\')\n        print(\'succesfully compiled cpu source\')\n        print(70*\'=\')\nexcept Exception as e:\n    cpab_cpu = _notcompiled()\n    _cpu_succes = False\n    if _verbose:\n        print(70*\'=\')\n        print(\'Unsuccesfully compiled cpu source\')\n        print(\'Error was: \')\n        print(e)\n        print(70*\'=\')\n\n# Jit compile gpu source\ntry:\n    cpab_gpu = load(name = \'cpab_gpu\',\n                    sources = [_dir + \'/transformer_cuda.cpp\',\n                               _dir + \'/transformer_cuda.cu\',\n                               _dir + \'/../core/cpab_ops.cu\'],\n                    verbose=_verbose,\n                    with_cuda=True)\n    _gpu_succes = True\n    if _verbose:\n        print(70*\'=\')\n        print(\'succesfully compiled gpu source\')\n        print(70*\'=\')\nexcept Exception as e:\n    cpab_gpu = _notcompiled()\n    _gpu_succes = False\n    if _verbose:\n        print(70*\'=\')\n        print(\'Unsuccesfully compiled gpu source\')\n        print(\'Error was: \')\n        print(e)\n\n#%%\ndef CPAB_transformer(points, theta, params):\n    if points.is_cuda and theta.is_cuda:\n        if not params.use_slow and _gpu_succes:\n            if _verbose: print(\'using fast gpu implementation\')\n            return CPAB_transformer_fast(points, theta, params)\n        else:\n            if _verbose: print(\'using slow gpu implementation\')\n            return CPAB_transformer_slow(points, theta, params)\n    else:\n        if not params.use_slow and _cpu_succes:\n            if _verbose: print(\'using fast cpu implementation\')\n            return CPAB_transformer_fast(points, theta, params)\n        else:\n            if _verbose: print(\'using slow cpu implementation\')\n            return CPAB_transformer_slow(points, theta, params)\n        \n#%%\ndef CPAB_transformer_slow(points, theta, params):\n    # Problem parameters\n    n_theta = theta.shape[0]\n    n_points = points.shape[-1]\n    \n    # Create homogenous coordinates\n    ones = torch.ones((n_theta, 1, n_points)).to(points.device)\n    if len(points.shape) == 2:\n        newpoints = points[None].repeat(n_theta, 1, 1) # [n_theta, ndim, n_points]\n    else:\n        newpoints = points\n    newpoints = torch.cat((newpoints, ones), dim=1) # [n_theta, ndim+1, n_points]\n    newpoints = newpoints.permute(0, 2, 1) # [n_theta, n_points, ndim+1]\n    newpoints = torch.reshape(newpoints, (-1, params.ndim+1)) #[n_theta*n_points, ndim+1]]\n    newpoints = newpoints[:,:,None] # [n_theta*n_points, ndim+1, 1]\n    \n    # Get velocity fields\n    B = torch.tensor(params.basis, dtype=torch.float32, device=theta.device)\n    Avees = torch.matmul(B, theta.t())\n    As = Avees.t().reshape(n_theta*params.nC, *params.Ashape)\n    zero_row = torch.zeros(n_theta*params.nC, 1, params.ndim+1, device=As.device)\n    AsSquare = torch.cat([As, zero_row], dim=1)\n    \n    # Take matrix exponential\n    dT = 1.0 / params.nstepsolver\n    Trels = expm(dT*AsSquare)\n    \n    # Take care of batch effect\n    batch_idx = params.nC*(torch.ones(n_points, n_theta, dtype=torch.int64) * torch.arange(n_theta))\n    batch_idx = batch_idx.t().flatten().to(theta.device)\n    \n    # Do integration\n    for i in range(params.nstepsolver):\n        idx = findcellidx(params.ndim, newpoints[:,:,0].t(), params.nc) + batch_idx\n        Tidx = Trels[idx.long()]\n        newpoints = torch.matmul(Tidx, newpoints)\n    \n    newpoints = newpoints.squeeze()[:,:params.ndim].t()\n    newpoints = newpoints.reshape(params.ndim, n_theta, n_points).permute(1,0,2)\n    return newpoints\n\n#%%\ndef CPAB_transformer_fast(points, theta, params):\n    if params.numeric_grad: return _CPABFunction_NumericGrad.apply(points, theta, params)\n    else: return _CPABFunction_AnalyticGrad.apply(points, theta, params)\n\n#%%\nclass _CPABFunction_AnalyticGrad(torch.autograd.Function):\n    # Function that connects the forward pass to the backward pass\n    @staticmethod\n    def forward(ctx, points, theta, params):\n        device = points.device\n        \n        # Problem size\n        n_theta = theta.shape[0]\n        \n        # Get velocity fields\n        B = torch.Tensor(params.basis).to(device)\n        Avees = torch.matmul(B, theta.t())\n        As = Avees.t().reshape(n_theta*params.nC, *params.Ashape)\n        zero_row = torch.zeros(n_theta*params.nC, 1, params.ndim+1).to(device)\n        AsSquare = torch.cat([As, zero_row], dim=1)\n        \n        # Take matrix exponential\n        dT = 1.0 / params.nstepsolver\n        Trels = expm(dT*AsSquare)\n        Trels = Trels[:,:params.ndim,:].view(n_theta, params.nC, *params.Ashape)\n        \n        # Convert to tensor\n        nstepsolver = torch.tensor(params.nstepsolver, dtype=torch.int32, device=device)\n        nc = torch.tensor(params.nc, dtype=torch.int32, device=device)\n\n        # Call integrator\n        if points.is_cuda:\n            newpoints = cpab_gpu.forward(points.contiguous(), \n                                         Trels.contiguous(), \n                                         nstepsolver.contiguous(), \n                                         nc.contiguous())\n        else:            \n            newpoints = cpab_cpu.forward(points.contiguous(), \n                                         Trels.contiguous(), \n                                         nstepsolver.contiguous(), \n                                         nc.contiguous())\n\n        # Save of backward\n        Bs = B.t().view(-1, params.nC, *params.Ashape)\n        As = As.view(n_theta, params.nC, *params.Ashape)\n        ctx.save_for_backward(points, theta, As, Bs, nstepsolver, nc)\n        # Output result\n        return newpoints\n\n    @staticmethod\n    @torch.autograd.function.once_differentiable\n    def backward(ctx, grad): # grad [n_theta, ndim, n]\n        # Grap input\n        points, theta, As, Bs, nstepsolver, nc = ctx.saved_tensors\n\n        # Call integrator, gradient: [d, n_theta, ndim, n]\n        if points.is_cuda:\n            gradient = cpab_gpu.backward(points.contiguous(), \n                                         As.contiguous(), \n                                         Bs.contiguous(), \n                                         nstepsolver.contiguous(), \n                                         nc.contiguous())\n        else:\n            gradient = cpab_cpu.backward(points.contiguous(), \n                                         As.contiguous(), \n                                         Bs.contiguous(), \n                                         nstepsolver.contiguous(), \n                                         nc.contiguous())\n            \n        # Backpropagate and reduce to [d, n_theta] matrix\n        g = gradient.mul_(grad).sum(dim=(2,3))\n        return None, g.t(), None # transpose, since pytorch expects a [n_theta, d] matrix\n\n#%%\nclass _CPABFunction_NumericGrad(torch.autograd.Function):\n    # Function that connects the forward pass to the backward pass\n    @staticmethod\n    def forward(ctx, points, theta, params):\n        device = points.device\n        \n        # Problem size\n        n_theta = theta.shape[0]\n        \n        # Get velocity fields\n        B = torch.Tensor(params.basis).to(device)\n        Avees = torch.matmul(B, theta.t())\n        As = Avees.t().reshape(n_theta*params.nC, *params.Ashape)\n        zero_row = torch.zeros(n_theta*params.nC, 1, params.ndim+1).to(device)\n        AsSquare = torch.cat([As, zero_row], dim=1)\n        \n        # Take matrix exponential\n        dT = 1.0 / params.nstepsolver\n        Trels = expm(dT*AsSquare)\n        Trels = Trels[:,:params.ndim,:].view(n_theta, params.nC, *params.Ashape)\n        \n        # Convert to tensor\n        nstepsolver = torch.tensor([params.nstepsolver], dtype=torch.int32).to(device)\n        nc = torch.tensor(params.nc, dtype=torch.int32).to(device)\n\n        # Call integrator\n        if points.is_cuda:\n            newpoints = cpab_gpu.forward(points.contiguous(), \n                                         Trels.contiguous(), \n                                         nstepsolver.contiguous(), \n                                         nc.contiguous())\n        else:            \n            newpoints = cpab_cpu.forward(points.contiguous(), \n                                         Trels.contiguous(), \n                                         nstepsolver.contiguous(), \n                                         nc.contiguous())\n            \n        # Save of backward\n        ctx.save_for_backward(points, theta, newpoints, nstepsolver, nc, params)\n        # Output result\n        return newpoints\n        \n    @staticmethod\n    @torch.autograd.function.once_differentiable\n    def backward(ctx, grad): # grad [n_theta, ndim, n]\n        # Grap input\n        points, theta, newpoints, nstepsolver, nc, params = ctx.saved_tensors\n        device = points.device\n        h = 0.01\n        gradient = [ ]\n        \n        # Problem size\n        n_theta, d = theta.shape\n        \n        for i in range(d):\n            # Permute theta\n            temp = theta.clone()\n            temp[:,i] += h\n            \n            # Get velocity fields\n            B = torch.Tensor(params.basis).to(device)\n            Avees = torch.matmul(B, temp.t())\n            As = Avees.t().reshape(n_theta*params.nC, *params.Ashape)\n            zero_row = torch.zeros(n_theta*params.nC, 1, params.ndim+1).to(device)\n            AsSquare = torch.cat([As, zero_row], dim=1)\n            \n            # Take matrix exponential\n            dT = 1.0 / params.nstepsolver\n            Trels = expm(dT*AsSquare)\n            Trels = Trels[:,:params.ndim,:].view(n_theta, params.nC, *params.Ashape)\n            \n            # Call integrator\n            if points.is_cuda:\n                temp_points = cpab_gpu.forward(points.contiguous(), \n                                               Trels.contiguous(), \n                                               nstepsolver.contiguous(), \n                                               nc.contiguous())\n            else:            \n                temp_points = cpab_cpu.forward(points.contiguous(), \n                                               Trels.contiguous(), \n                                               nstepsolver.contiguous(), \n                                               nc.contiguous())\n            \n            diff = (temp_points - newpoints) / h\n            \n            # Do finite gradient\n            gradient.append((grad * diff).sum(dim=[1,2])) # gradient [n_theta, ]\n        \n        # Reshaping\n        gradient = torch.stack(gradient, dim = 1) # [n_theta, d]\n        return None, gradient\n\n'"
libcpab/tensorflow/__init__.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Fri Nov 16 15:26:48 2018\n\n@author: nsde\n""""""\n\n#%%\nimport tensorflow as tf\n\n#%%'"
libcpab/tensorflow/cpab.py,19,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Jul 12 16:02:06 2018\n\n@author: nsde\n""""""\n#%%\nimport numpy as np\nimport tensorflow as tf\n\nfrom ..helper.setup_constrains_1d import get_constrain_matrix_1D\nfrom ..helper.setup_constrains_2d import get_constrain_matrix_2D\nfrom ..helper.setup_constrains_3d import get_constrain_matrix_3D\nfrom ..helper.utility import get_dir, save_obj, load_obj, create_dir, check_if_file_exist\nfrom ..helper.math import null\n\nfrom .cpab1d.transformer import tf_cpab_transformer_1D\nfrom .cpab2d.transformer import tf_cpab_transformer_2D\nfrom .cpab3d.transformer import tf_cpab_transformer_3D\nfrom .helper.tf_interpolate import tf_interpolate_1D, tf_interpolate_2D, tf_interpolate_3D\nfrom .helper.tf_findcellidx import tf_findcellidx_1D, tf_findcellidx_2D, tf_findcellidx_3D\nfrom .helper.tf_funcs import tf_shape_i\n\n#%%\nclass cpab(object):\n    \'\'\'\n    \n    \'\'\'\n    def __init__(self, tess_size, \n                 zero_boundary=True, \n                 volume_perservation=False,\n                 return_tf_tensors=False,\n                 override=False):\n        # Check input\n        assert len(tess_size) > 0 and len(tess_size) <= 3, \\\n            \'\'\'Transformer only support 1D, 2D or 3D\'\'\'\n        assert type(tess_size) == list or type(tess_size) == tuple, \\\n            \'\'\'Argument tess_size must be a list or tuple\'\'\'\n        assert all([type(e)==int for e in tess_size]), \\\n            \'\'\'All elements of tess_size must be integers\'\'\'\n        assert all([e > 0 for e in tess_size]), \\\n            \'\'\'All elements of tess_size must be positive\'\'\'\n        assert type(zero_boundary) == bool, \\\n            \'\'\'Argument zero_boundary must be True or False\'\'\'\n        assert type(volume_perservation) == bool, \\\n            \'\'\'Argument volume_perservation must be True or False\'\'\'\n        \n        # Parameters\n        self._nc = tess_size\n        self._ndim = len(tess_size)\n        self._Ashape = [self._ndim, self._ndim+1]\n        self._valid_outside = not(zero_boundary)\n        self._zero_boundary = zero_boundary\n        self._volume_perservation = volume_perservation\n        self._domain_max = [1 for e in self._nc]\n        self._domain_min = [0 for e in self._nc]\n        self._inc = [(self._domain_max[i] - self._domain_min[i]) / \n                    self._nc[i] for i in range(self._ndim)]\n        self._nstepsolver = 50\n        \n        # Special cases\n        assert not(self._ndim==3 and not zero_boundary), \\\n            \'\'\'Non zero boundary is not implemented for 3D\'\'\'\n        \n        # For saving the basis\n        self._dir = get_dir(__file__) + \'/../basis_files/\'\n        self._basis_name = \'cpab_basis_dim\' + str(self._ndim) + \'_tess\' + \\\n                          \'_\'.join([str(e) for e in self._nc]) + \'_\' + \\\n                          \'vo\' + str(int(self._valid_outside)) + \'_\' + \\\n                          \'zb\' + str(int(self._zero_boundary)) + \'_\' + \\\n                          \'vp\' + str(int(self._volume_perservation))\n        self._basis_file = self._dir + self._basis_name\n        create_dir(self._dir)\n        \n        # Specific for the different dims\n        if self._ndim == 1:\n            self._nC = self._nc[0]\n            get_constrain_matrix_f = get_constrain_matrix_1D\n            self._transformer = tf_cpab_transformer_1D\n            self._interpolate = tf_interpolate_1D\n            self._findcellidx = tf_findcellidx_1D            \n        elif self._ndim == 2:\n            self._nC = 4*np.prod(self._nc)\n            get_constrain_matrix_f = get_constrain_matrix_2D\n            self._transformer = tf_cpab_transformer_2D\n            self._interpolate = tf_interpolate_2D\n            self._findcellidx = tf_findcellidx_2D\n        elif self._ndim == 3:\n            self._nC = 6*np.prod(self._nc)\n            get_constrain_matrix_f = get_constrain_matrix_3D\n            self._transformer = tf_cpab_transformer_3D\n            self._interpolate = tf_interpolate_3D\n            self._findcellidx = tf_findcellidx_3D\n            \n        # Check if we have already created the basis\n        if not check_if_file_exist(self._basis_file+\'.pkl\') or override:\n            # Get constrain matrix\n            L = get_constrain_matrix_f(self._nc, self._domain_min, self._domain_max,\n                                       self._valid_outside, self._zero_boundary,\n                                       self._volume_perservation)\n                \n            # Find null space of constrain matrix\n            B = null(L)\n            self._constrain_mat = L\n            self._basis = B\n            self._D, self._d = B.shape\n            \n            # Save basis as pkl file\n            obj = {\'basis\': self._basis, \'constrains\': self._constrain_mat, \'ndim\': self._ndim,\n                   \'D\': self._D, \'d\': self._d, \'nc\': self._nc, \'nC\': self._nC,\n                   \'Ashape\': self._Ashape, \'nstepsolver\': self._nstepsolver}\n            save_obj(obj, self._basis_file)\n            save_obj(obj, self._dir + \'current_basis\')\n            \n        else: # if it exist, just load it\n            file = load_obj(self._basis_file)\n            self._basis = file[\'basis\']\n            self._constrain_mat = file[\'constrains\']\n            self._D = file[\'D\']\n            self._d = file[\'d\']\n            \n            # Save as the current basis\n            obj = {\'basis\': self._basis, \'constrains\': self._constrain_mat, \'ndim\': self._ndim,\n                   \'D\': self._D, \'d\': self._d, \'nc\': self._nc, \'nC\': self._nC,\n                   \'Ashape\': self._Ashape, \'nstepsolver\': self._nstepsolver}\n            save_obj(obj, self._dir + \'current_basis\')\n            \n        # To run tensorflow\n        self._return_tf_tensors = return_tf_tensors\n        self._fixed_data = False\n        self._sess = tf.Session()\n        \n    #%%\n    def get_theta_dim(self):\n        return self._d\n    \n    #%%\n    def get_basis(self):\n        return self._basis\n    \n    #%%\n    def get_params(self):\n        return {\'valid_outside\': self._valid_outside,\n                \'zero_boundary\': self._zero_boundary,\n                \'volume_perservation\': self._volume_perservation,\n                \'Ashape\': self._Ashape,\n                \'domain_min\': self._domain_min,\n                \'domain_max\': self._domain_max,\n                \'cell_increment\': self._inc,\n                \'theta_dim\': self._d,\n                \'original_dim\': self._D}\n\n    #%%\n    def uniform_meshgrid(self, n_points):\n        \'\'\' \'\'\'\n        if self._is_tf_tensor(n_points):\n            lin_p = [tf.linspace(tf.cast(self._domain_min[i], tf.float32), \n                                 tf.cast(self._domain_max[i], tf.float32), n_points[i])\n                    for i in range(self._ndim)]\n            mesh_p = tf.meshgrid(*lin_p[::-1])                        \n            grid = tf.concat([tf.reshape(array, (1, -1)) for array in mesh_p[::-1]], axis=0)\n            if not self._return_tf_tensors: grid = self._sess.run(grid)\n        else:\n            assert len(n_points) == self._ndim, \\\n                \'n_points needs to be a list equal to the dimensionality of the transformation\'\n            lin_p = [np.linspace(self._domain_min[i], self._domain_max[i], n_points[i])\n                    for i in range(self._ndim)]\n            mesh_p = np.meshgrid(*lin_p[::-1], indexing=\'ij\')\n            grid = np.vstack([array.flatten() for array in mesh_p[::-1]])\n            if self._return_tf_tensors: grid = tf.cast(grid, tf.float32)\n        return grid\n    \n    #%%\n    def sample_transformation(self, n_sample=1, mean=None, cov=None):\n        \'\'\' \'\'\'\n        mean = np.zeros((self._d,)) if mean is None else mean\n        cov = np.eye(self._d) if cov is None else cov\n        theta = np.random.multivariate_normal(mean, cov, size=n_sample)\n        if self._return_tf_tensors: theta = tf.cast(theta, tf.float32)\n        return theta\n    \n    #%%\n    def identity(self, n_sample=1, epsilon=0):\n        theta = np.zeros(shape=(n_sample, self._d)) + epsilon\n        if self._return_tf_tensors: theta = tf.cast(theta, tf.float32)\n        return theta\n\n    #%%\n    def transform_grid(self, points, theta):\n        \'\'\' \'\'\'\n        # Assert if numpy array, else trust the user\n        if not self._is_tf_tensor(points):\n            assert points.shape[0] == self._ndim, \\\n             \'Expects a grid of \' + str(self._ndim) + \'d points\'            \n        if not self._is_tf_tensor(theta):\n            assert theta.shape[1] == self._d, \\\n                 \'Expects theta to have shape N x \' + str(self._d)\n        \n        # Call transformer\n        if self._return_tf_tensors:\n            points = tf.cast(points, tf.float32)\n            theta = tf.cast(theta, tf.float32)\n            newpoints = self._transformer(points, theta)\n            newpoints.set_shape((None, self._ndim, tf_shape_i(points, 1)))\n        else:\n            if self._fixed_data:\n                newpoints = self._transformer_np(points, theta)    \n            else:\n                points = tf.cast(points, tf.float32)\n                theta = tf.cast(theta, tf.float32)\n                newpoints = self._sess.run(self._transformer(points, theta))\n        return newpoints\n\n    #%%\n    def interpolate(self, data, transformed_points):\n        \'\'\' \'\'\'\n        # Call interpolator \n        if self._return_tf_tensors:\n            data = tf.cast(data, tf.float32)\n            transformed_points = tf.cast(transformed_points, tf.float32)\n            new_data = self._interpolate(data, transformed_points)\n        else:\n            if self._fixed_data:\n                new_data = self._interpolate_np(data, transformed_points)\n            else:\n                data = tf.cast(data, tf.float32)\n                transformed_points = tf.cast(transformed_points, tf.float32)\n                new_data = self._sess.run(self._interpolate(data, transformed_points))\n        return new_data\n    \n    #%%\n    def transform_data(self, data, theta):\n        \'\'\' \'\'\'\n        # Find grid size\n        if self._is_tf_tensor(data):\n            data_size = data.get_shape().as_list()[1:self._ndim+1]\n        else:\n            data_size = data.shape[1:self._ndim+1]\n        \n        # Fix equal size interpolation for 2D\n        if self._ndim==2:\n            data_size = data_size[::-1]\n        \n        # Create grid, call transformer, and interpolate\n        points = self.uniform_meshgrid(data_size)\n        new_points = self.transform_grid(points, theta)\n        new_data = self.interpolate(data, new_points)\n        return new_data\n    \n    #%%\n    def fix_data_size(self, data_size):\n        assert not self._return_tf_tensors, \\\n            "" Cannot fix data size with return_tf_tensors true ""\n        data_p = tf.placeholder(tf.float32, (None, *data_size))\n        theta_p = tf.placeholder(tf.float32, (None, self._d))\n        if self._ndim==1 or self._ndim==3:\n            points1_p = tf.placeholder(tf.float32, (self._ndim, np.prod(data_size)))\n            points2_p = tf.placeholder(tf.float32, (None, self._ndim, np.prod(data_size)))\n        else:\n            points1_p = tf.placeholder(tf.float32, (self._ndim, np.prod(data_size[:2])))\n            points2_p = tf.placeholder(tf.float32, (None, self._ndim, np.prod(data_size[:2])))\n    \n        self._transformer_np = self._sess.make_callable(self._transformer(points1_p, theta_p), \n                                                        [points1_p, theta_p])\n        self._interpolate_np = self._sess.make_callable(self._interpolate(data_p, points2_p), \n                                                        [data_p, points2_p])\n        self._fixed_data = True\n        \n    #%%\n    def calc_vectorfield(self, points, theta):\n        # Construct the affine transformations\n        Avees = self._theta2Avees(theta)\n        As = self._Avees2As(Avees)\n        \n        # Find cells and extract correct affine transformation\n        if self._is_tf_tensor(points):\n            idx = self._sess.run(self._findcellidx(tf.transpose(points), *self._nc))    \n        else:\n            idx = self._sess.run(self._findcellidx(points.T, *self._nc))\n        Aidx = As[idx]\n        \n        # Make homogeneous coordinates\n        points = np.expand_dims(np.vstack((points, np.ones((1, points.shape[1])))).T,2)\n        \n        # Do matrix-vector multiplication\n        v = np.matmul(Aidx, points)\n        return np.squeeze(v).T\n    \n    #%%\n    def visualize_vectorfield(self, theta, nb_points=10):\n        points = self.uniform_meshgrid([nb_points for i in range(self._ndim)])\n        v = self.calc_vectorfield(points, theta)\n        \n        # Plot\n        import matplotlib.pyplot as plt\n        if self._ndim==1:\n            fig = plt.figure()\n            ax = fig.add_subplot(111)\n            ax.quiver(points[0,:], np.zeros_like(points), v, np.zeros_like(v))\n            ax.set_xlim(self._domain_min[0], self._domain_max[0])\n        elif self._ndim==2:\n            fig = plt.figure()\n            ax = fig.add_subplot(111)\n            ax.quiver(points[0,:], points[1,:], v[0,:], v[1,:])\n            ax.set_xlim(self._domain_min[0], self._domain_max[0])\n            ax.set_ylim(self._domain_min[1], self._domain_max[1])\n        elif self._ndim==3:\n            from mpl_toolkits.mplot3d import Axes3D\n            fig = plt.figure()\n            ax = fig.add_subplot(111, projection=\'3d\')\n            ax.quiver(points[0,:], points[1,:], points[2,:], v[0,:], v[1,:], v[2,:],\n                      length=0.3, arrow_length_ratio=0.5)\n            ax.set_xlim3d(self._domain_min[0], self._domain_max[0])\n            ax.set_ylim3d(self._domain_min[1], self._domain_max[1])\n            ax.set_zlim3d(self._domain_min[2], self._domain_max[2])\n        plt.axis(\'equal\')\n        plt.title(\'Velocity field\')\n        plt.show()\n\n    #%%\n    def _theta2Avees(self, theta):\n        Avees = self._basis.dot(theta)\n        return Avees\n    \n    #%%\n    def _Avees2As(self, Avees):\n        As = np.reshape(Avees, (self._nC, *self._Ashape))\n        return As\n    \n    #%%\n    def _As2squareAs(self, As):\n        squareAs = np.zeros(shape=(self._nC, self._ndim+1, self._ndim+1))\n        squareAs[:,:-1,:] = As\n        return squareAs\n    \n    #%%\n    def _is_tf_tensor(self, tensor):\n        return  isinstance(tensor, tf.Tensor) or \\\n                isinstance(tensor, tf.Variable)\n\n#%%\nif __name__ == \'__main__\':\n    pass\n'"
libcpab/tensorflow/expm.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Feb 21 17:06:05 2019\n\n@author: nsde\n""""""\n\n#%%\nimport tensorflow as tf\n\n#%%\ntry:\n    expm = tf.linalg.expm\nexcept:\n    def expm(A):\n        """""" """"""\n        n_A = A.shape[0]\n        A_fro = tf.sqrt(tf.reduce_sum(tf.pow(tf.abs(A), 2.0), axis=[1,2], keepdims=True))\n        \n        # Scaling step\n        with tf.device(A.device):\n            maxnorm = tf.cast([5.371920351148152], dtype=A.dtype)\n            zero = tf.cast([0.0], dtype=A.dtype)\n        n_squarings = tf.maximum(zero, tf.math.ceil(log2(A_fro / maxnorm)))\n        Ascaled = A / 2.0**n_squarings\n        n_squarings = tf.cast(tf.reshape(n_squarings, (-1, )), tf.int64)\n        \n        # Pade 13 approximation\n        U, V = pade13(Ascaled)\n        P = U + V\n        Q = -U + V\n        R = tf.linalg.solve(Q, P)\n        \n        # Unsquaring step\n        n = tf.reduce_max(n_squarings)\n        res = [R]\n        for i in range(n):\n            res.append(tf.matmul(res[-1], res[-1]))\n        R = tf.stack(res)\n        expmA = tf.gather_nd(R, tf.transpose(tf.stack([n_squarings, tf.range(n_A, dtype=tf.int64)])))\n        return expmA\n\n#%%\ndef log2(x):\n    with tf.device(x.device):\n        denum = tf.math.log(tf.cast([2.0], dtype=x.dtype))\n    return tf.math.log(x) / denum\n\n#%%\ndef pade13(A):\n    with tf.device(A.device):\n        b = tf.cast([64764752532480000., 32382376266240000., 7771770303897600.,\n                     1187353796428800., 129060195264000., 10559470521600.,\n                     670442572800., 33522128640., 1323241920., 40840800.,\n                     960960., 16380., 182., 1.], dtype=A.dtype)\n        ident = tf.eye(A.shape[1], dtype=A.dtype)\n    A2 = tf.matmul(A,A)\n    A4 = tf.matmul(A2,A2)\n    A6 = tf.matmul(A4,A2)\n    U = tf.matmul(A, tf.matmul(A6, b[13]*A6 + b[11]*A4 + b[9]*A2) + b[7]*A6 + b[5]*A4 + b[3]*A2 + b[1]*ident)\n    V = tf.matmul(A6, b[12]*A6 + b[10]*A4 + b[8]*A2) + b[6]*A6 + b[4]*A4 + b[2]*A2 + b[0]*ident\n    return U, V\n\n#%%\nif __name__ == \'__main__\':\n        A = tf.random.normal((5,3,3), mean=1)\n        expmA = expm(A)\n'"
libcpab/tensorflow/findcellidx.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Wed Nov 21 14:31:34 2018\n\n@author: nsde\n""""""\n\n#%%\nimport tensorflow as tf\n\n#%%\ndef mymin(a, b):\n    return tf.where(a < b, a, tf.round(b))\n\n#%%\ndef fmod(numer, denom): # tf.math.mod not registered for tf.float32 on gpu\n    tquou = tf.math.floor(numer / denom)\n    return numer - tquou * denom\n\n#%%\ndef findcellidx(ndim, p, nc):\n    if ndim==1:   return findcellidx1D(p, *nc)\n    elif ndim==2: return findcellidx2D(p, *nc)\n    elif ndim==3: return findcellidx3D(p, *nc)\n    \n#%%\ndef findcellidx1D(p, nx):\n    idx = tf.floor(p * nx)\n    idx = tf.minimum(0.0, tf.maximum(idx, nx-1))\n    idx = tf.cast(tf.reshape(idx, (-1,)), tf.int32)\n    return idx\n\n#%%\ndef findcellidx2D(p, nx, ny):\n    with tf.device(p.device):\n        inc_x = tf.cast(1.0 / nx, tf.float32)\n        inc_y = tf.cast(1.0 / ny, tf.float32)\n    \n    p0 = tf.minimum(nx * inc_x - 1e-8, tf.maximum(0.0, p[0]))\n    p1 = tf.minimum(ny * inc_y - 1e-8, tf.maximum(0.0, p[1]))\n    \n    xmod = fmod(p0, inc_x)\n    ymod = fmod(p1, inc_y)\n    \n    x = xmod / inc_x\n    y = ymod / inc_y\n    \n    idx = mymin((nx-1) * tf.ones_like(p0), (p0-xmod) / inc_x) + \\\n          mymin((ny-1) * tf.ones_like(p1), (p1-ymod) / inc_y) * nx\n    idx *= 4\n    \n    # Out of bound left\n    cond1 = (p[0]<=0) & ((p[1]<=0) & (p[1]/inc_y<p[0]/inc_x))\n    cond2 = (~ cond1) & (p[0]<=0) & ((p[1] >= ny * inc_y) & (p[1]/inc_y - ny > -p[0]/inc_x))\n    cond3 = (~ cond1) & (~ cond2) & (p[0]<=0)\n    idx = tf.where(cond2, idx+2, idx) #idx[cond2] += 2\n    idx = tf.where(cond3, idx+3, idx) #idx[cond3] += 3\n\n    # Out of bound right\n    out = cond1 | cond2 | cond3\n    cond4 = (~ out) & (p[0] >= nx*inc_x) & ((p[1]<=0) & (-p[1]/inc_y > p[0]/inc_x - nx))\n    cond5 = (~ out) & (~ cond4) & (p[0] >= nx*inc_x) & ((p[1] >= ny*inc_y) & (p[1]/inc_y - ny > p[0]/inc_x-nx))\n    cond6 = (~ out) & (~ cond4) & (~ cond5) & (p[0] >= nx*inc_x)\n    idx = tf.where(cond5, idx+2, idx) #idx[cond5] += 2\n    idx = tf.where(cond6, idx+1, idx) #idx[cond6] += 1\n    \n    # Out of bound up, nothing to do\n    \n    # Out of bound down\n    out = out | cond4 | cond5 | cond6\n    cond7 = (~ out) & (p[1] >= ny*inc_y)\n    idx = tf.where(cond7, idx+2, idx) #idx[cond7] += 2\n\n    # Ok, we are inbound\n    out = out | cond7\n    cond8 = (~ out) & (x<y) & (1-x<y)\n    cond9 = (~ out) & (~ cond8) & (x<y)\n    cond10 = (~ out) & (~ cond8) & (~ cond9) & (x>=y) & (1-x<y)\n    idx = tf.where(cond8, idx+2, idx) #idx[cond8] += 2\n    idx = tf.where(cond9, idx+3, idx) #idx[cond9] += 3\n    idx = tf.where(cond10, idx+1, idx) #idx[cond10] += 1\n    idx = tf.cast(tf.reshape(idx, (-1,)), tf.int32)\n    return idx\n    \n#%%\ndef findcellidx3D(p, nx, ny, nz):\n    # Conditions for points outside\n    cond =  tf.logical_or(tf.logical_or(\n            tf.logical_or(p[0,:] < 0.0, p[0,:] > 1.0),\n            tf.logical_or(p[1,:] < 0.0, p[1,:] > 1.0)),\n            tf.logical_or(p[2,:] < 0.0, p[2,:] > 1.0))\n    \n    # Push the points inside boundary\n    inc_x, inc_y, inc_z = 1.0 / nx, 1.0 / ny, 1.0 / nz\n    half = 0.5\n    points_outside = p[:, cond]\n    points_outside -= half\n    abs_x = tf.abs(points_outside[0])\n    abs_y = tf.abs(points_outside[1])\n    abs_z = tf.abs(points_outside[2])\n    push_x = (half * inc_x)*(tf.logical_and(abs_x < abs_y, abs_x < abs_z))\n    push_y = (half * inc_y)*(tf.logical_and(abs_y < abs_x, abs_x < abs_z))\n    push_z = (half * inc_z)*(tf.logical_and(abs_z < abs_x, abs_x < abs_y))\n    cond_x = abs_x > half\n    cond_y = abs_y > half\n    cond_z = abs_z > half\n    points_outside[0, cond_x] = (half - push_x[cond_x]) * tf.sign(points_outside[0, cond_x])\n    points_outside[1, cond_y] = (half - push_y[cond_y]) * tf.sign(points_outside[1, cond_y])\n    points_outside[2, cond_z] = (half - push_z[cond_z]) * tf.sign(points_outside[2, cond_z])\n    points_outside += half\n    p[:, cond] = points_outside\n\n    # Find row, col, depth placement and cell placement\n    inc_x, inc_y, inc_z = 1.0/nx, 1.0/ny, 1.0/nz\n    p0 = tf.minimum(nx * inc_x - 1e-8, tf.maximum(0.0, p[0]))\n    p1 = tf.minimum(ny * inc_y - 1e-8, tf.maximum(0.0, p[1]))\n    p2 = tf.minimum(nz * inc_z - 1e-8, tf.maximum(0.0, p[2]))\n\n    xmod = fmod(p0, inc_x)\n    ymod = fmod(p1, inc_y)\n    zmod = fmod(p2, inc_z)\n    \n    i = mymin((nx - 1) * tf.ones_like(p0), ((p0 - xmod) / inc_x))\n    j = mymin((ny - 1) * tf.ones_like(p1), ((p1 - ymod) / inc_y))\n    k = mymin((nz - 1) * tf.ones_like(p2) , ((p2 - zmod) / inc_z))\n    idx = 5 * (i + j * nx + k * nx * ny)\n\n    x = xmod / inc_x\n    y = ymod / inc_y\n    z = zmod / inc_z\n    \n    # Find subcell location\n    cond = tf.logical_or(tf.logical_or(tf.logical_or(\n            ((k%2==0) & (i%2==0) & (j%2==1)),\n            ((k%2==0) & (i%2==1) & (j%2==0))),\n            ((k%2==1) & (i%2==0) & (j%2==0))),\n            ((k%2==1) & (i%2==1) & (j%2==1)))\n\n    tmp = x.copy()\n    x = tf.where(cond, y, x) #x[cond] = y[cond]\n    y = tf.where(cond, 1-tmp, y) #y[cond] = 1-tmp[cond]\n    \n    cond1 = -x-y+z >= 0\n    cond2 = x+y+z-2 >= 0\n    cond3 = -x+y-z >= 0\n    cond4 = x-y-z >= 0\n    idx = tf.where(cond1, idx+1, idx) #idx[cond1] += 1\n    idx = tf.where(cond2 & ~cond1, idx+2, idx) #idx[cond2 & ~cond1] += 2\n    idx = tf.where(cond3 & ~cond1 & ~cond2, idx+3, idx) #idx[cond3 & ~cond1 & ~cond2] += 3\n    idx = tf.where(cond4 & ~cond1 & ~cond2 & cond3, idx+4, idx) #idx[cond4 & ~cond1 & ~cond2 & ~cond3] += 4\n    idx = tf.cast(tf.reshape(idx, (-1,)), tf.int32)\n    return idx'"
libcpab/tensorflow/functions.py,0,"b'# -*- coding: utf-8 -*- \n""""""\nCreated on Fri Nov 16 16:01:52 2018\n\n@author: nsde\n""""""\n\n#%%\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nfrom tensorflow.python.framework.ops import Tensor\nfrom tensorflow.python.ops.resource_variable_ops import ResourceVariable\nfrom .interpolation import interpolate\nfrom .transformer import CPAB_transformer as transformer\nfrom .findcellidx import findcellidx\n\n#%%\ndef assert_version():\n    numbers = tf.__version__.split(\'.\')\n    version = float(numbers[0] + \'.\' + numbers[1])\n    assert version >= 2.0, \\\n        \'\'\' You are using a older installation of pytorch, please install 2.0.0\n            or newer \'\'\'\n\n#%%\ndef to(x, dtype=tf.float32, device=None):\n    with tf.device(device):\n        x = tf.identity(tf.cast(x, dtype=dtype))\n        return x\n\n#%%\ndef tonumpy(x):\n    return x.cpu().numpy()\n\n#%%\ndef check_device(x, device_name):\n    if x.device==\'\': # if x is placeholder, accept\n        return True\n    else: # else check if we match\n        return (\'GPU\' in x.device) == (device_name==""gpu"")\n\n#%%\ndef backend_type():\n    return (Tensor, ResourceVariable)\n\n#%%\ndef pdist(mat):\n    norm = tf.reduce_sum(mat * mat, 1)\n    norm = tf.reshape(norm, (-1, 1))\n    D = norm - 2*tf.matmul(mat, tf.transpose(mat)) + tf.transpose(norm)\n    return D\n\n#%%\ndef norm(x):\n    return tf.norm(x)\n\n#%%\ndef matmul(x,y):\n    return tf.matmul(x,y)\n\n#%%\ndef transpose(x):\n    return tf.transpose(x)\n\n#%%\ndef exp(x):\n    return tf.exp(x)\n\n#%%\ndef zeros(*s):\n    return tf.zeros(*s)\n    \n#%%\ndef ones(*s):\n    return tf.ones(*s)\n\n#%%\ndef arange(x):\n    return tf.range(x)\n    \n#%%\ndef repeat(x, reps):\n    return tf.tile([x], [reps])\n\n#%%\ndef batch_repeat(x, reps):\n    return x.repeat(reps, *(x.dim()*[1]))\n\n#%%\ndef maximum(x):\n    return tf.reduce_max(x)\n\n#%%\ndef sample_transformation(d, n_sample=1, mean=None, cov=None, device=\'cpu\'):\n    with tf.device(device):\n        mean = tf.zeros((d,), dtype=tf.float32) if mean is None else mean\n        cov = tf.eye(d, dtype=tf.float32) if cov is None else cov\n        distribution = tfp.distributions.MultivariateNormalFullCovariance(mean, cov)\n        return distribution.sample(n_sample)\n    \n#%%\ndef identity(d, n_sample=1, epsilon=0, device=\'cpu\'):\n    assert epsilon>=0, ""epsilon need to be larger than 0""\n    with tf.device(device):\n        return tf.zeros((n_sample, d), dtype=tf.float32) + epsilon\n\n#%%\ndef uniform_meshgrid(ndim, domain_min, domain_max, n_points, device=\'cpu\'):\n    with tf.device(device):\n        lin = [tf.linspace(tf.cast(domain_min[i], tf.float32), \n               tf.cast(domain_max[i], tf.float32), n_points[i]) for i in range(ndim)]\n        mesh = tf.meshgrid(*lin[::-1])\n        grid = tf.concat([tf.reshape(array, (1, -1)) for array in mesh[::-1]], axis=0)\n        return grid\n\n#%%\ndef calc_vectorfield(grid, theta, params):\n    # Calculate velocity fields\n    B = to(params.basis, dtype=theta.dtype, device=theta.device)\n    Avees = tf.tensordot(B, tf.reshape(theta, (-1,)), 1)\n    As = tf.reshape(Avees, (params.nC, *params.Ashape))\n    \n    # Find cell index\n    idx = findcellidx(params.ndim, grid, params.nc)\n    \n    # Do indexing\n    Aidx = tf.gather(As, idx)\n    \n    # Convert to homogeneous coordinates\n    with tf.device(grid.device):\n        onerow = tf.ones((1, grid.shape[1]))\n    grid = tf.concat((grid, onerow), axis=0)\n    grid = tf.transpose(grid[None], perm=[2,1,0])\n    \n    # Do matrix multiplication\n    v = tf.matmul(Aidx, grid)\n    return tf.transpose(tf.squeeze(v))\n'"
libcpab/tensorflow/helper.py,1,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Wed Nov 21 09:35:18 2018\n\n@author: nsde\n""""""\n\n#%%\nimport tensorflow as tf\n\n#%%\ndef tf_repeat(x, n_repeats):\n    """""" Tensorflow implementation of np.repeat(x, n_repeats) """"""\n    with tf.name_scope(\'repeat\'):\n        ones = tf.ones(shape=(n_repeats, ))\n        rep = tf.transpose(tf.expand_dims(ones, 1), [1, 0])\n        rep = tf.cast(rep, x.dtype)\n        x = tf.matmul(tf.reshape(x, (-1, 1)), rep)\n        return tf.reshape(x, [-1])\n\n#%%\ndef tf_shape_i(tensor, i):\n    """""" Extracts the i\'th dimension of a tensor. If the dimension is unknown,\n        the function will return a dynamic tensor else it will return a static\n        number.\n    """"""\n    shape = tensor.get_shape().as_list()\n    if shape[i]!=None:\n        return shape[i]\n    else:\n        return tf.shape(tensor)[i]\n'"
libcpab/tensorflow/interpolation.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Nov 20 10:26:30 2018\n\n@author: nsde\n""""""\n\n#%%\nimport tensorflow as tf\nfrom .helper import tf_shape_i, tf_repeat\n\n#%%\ndef interpolate(ndim, data, grid, outsize):\n    if ndim==1: return interpolate1D(data, grid, outsize)\n    elif ndim==2: return interpolate2D(data, grid, outsize)\n    elif ndim==3: return interpolate3D(data, grid, outsize)\n\n#%%\ndef interpolate1D(data, grid, outsize):\n    data, grid = tf.cast(data, tf.float32), tf.cast(grid, tf.float32)\n\n    # Constants\n    n_batch = data.shape[0]\n    length_d = data.shape[1]\n    n_channel = data.shape[2]\n    length_g = outsize[0]\n    max_x = tf.cast(length_d-1, tf.int32)\n\n    # Extract points\n    x = tf.reshape(grid[:,0], (-1,)) # [n_theta x n_points]\n\n    # Scale to domain\n    x = x * (length_d-1)\n\n    # Do sampling\n    x0 = tf.cast(tf.floor(x), tf.int32)\n    x1 = x0 + 1\n\n    # Clip values\n    x0 = tf.clip_by_value(x0, 0, max_x)\n    x1 = tf.clip_by_value(x1, 0, max_x)\n\n    # Batch effect\n    batch_idx = tf.reshape(tf.transpose(tf.reshape(tf.tile(tf.range(n_batch), (length_g,)), (length_g, n_batch))), (-1,))\n\n    # Index\n    i1 = tf.gather_nd(data, tf.stack([batch_idx, x0], axis=1))\n    i2 = tf.gather_nd(data, tf.stack([batch_idx, x1], axis=1))\n\n    # Convert to floats\n    x0 = tf.cast(x0, tf.float32)\n    x1 = tf.cast(x1, tf.float32)\n\n    # Do interpolation\n    new_data = i1 + tf.transpose((x - x0) * tf.transpose((i2 - i1), perm=[1,0]), perm=[1,0]) #w1*i1 + w2*i2\n\n    # Reshape and return\n    new_data = tf.reshape(new_data, (n_batch, length_g, n_channel))\n    return new_data\n\n#%%\ndef interpolate2D(data, grid, outsize):\n    data, grid = tf.cast(data, tf.float32), tf.cast(grid, tf.float32)\n\n    # Problem size\n    n_batch = data.shape[0]\n    width = data.shape[1]\n    height = data.shape[2]\n    n_channels = data.shape[3]\n    out_width, out_height = outsize\n    \n    # Cast value to float dtype\n    x = tf.reshape(grid[:,0], (-1, ))\n    y = tf.reshape(grid[:,1], (-1, ))\n    max_x = tf.cast(width - 1, tf.int32)\n    max_y = tf.cast(height - 1, tf.int32)\n\n    # Scale indices from [0, 1] to [0, width/height]\n    x = x * (width-1)\n    y = y * (height-1)\n\n    # Do sampling\n    x0 = tf.cast(tf.floor(x), tf.int32)\n    x1 = x0 + 1\n    y0 = tf.cast(tf.floor(y), tf.int32)\n    y1 = y0 + 1\n\n    # Clip values\n    x0 = tf.clip_by_value(x0, 0, max_x)\n    x1 = tf.clip_by_value(x1, 0, max_x)\n    y0 = tf.clip_by_value(y0, 0, max_y)\n    y1 = tf.clip_by_value(y1, 0, max_y)\n    \n    # Batch effect\n    batch_size = out_width*out_height\n    batch_idx = tf.tile(tf.range(n_batch), (batch_size,))\n    \n    # Index\n    c00 = tf.gather_nd(data, tf.stack([batch_idx, x0, y0], axis=1))\n    c01 = tf.gather_nd(data, tf.stack([batch_idx, x0, y1], axis=1))\n    c10 = tf.gather_nd(data, tf.stack([batch_idx, x1, y0], axis=1))\n    c11 = tf.gather_nd(data, tf.stack([batch_idx, x1, y1], axis=1))\n\n    # Interpolation weights\n    xd = tf.reshape(x-tf.cast(x0, tf.float32), (-1,1))\n    yd = tf.reshape(y-tf.cast(y0, tf.float32), (-1,1))\n    \n    # Do interpolation\n    c0 = c00*(1-xd) + c10*xd\n    c1 = c01*(1-xd) + c11*xd\n    c = c0*(1-yd) + c1*yd\n    \n    # Reshape\n    newim = tf.reshape(c, (n_batch, out_height, out_width, n_channels))\n    return newim\n\n#%%    \ndef interpolate3D(data, grid, outsize):\n    data, grid = tf.cast(data, tf.float32), tf.cast(grid, tf.float32)\n            \n    # Constants\n    n_batch = tf_shape_i(data,0)\n    width = tf_shape_i(data,1)\n    height = tf_shape_i(data,2)\n    depth = tf_shape_i(data,3)\n    max_x = tf.cast(width - 1, tf.int32)\n    max_y = tf.cast(height - 1, tf.int32)\n    max_z = tf.cast(depth - 1, tf.int32)\n    \n    # Extact points\n    x = tf.reshape(grid[:,0], (-1,))\n    y = tf.reshape(grid[:,1], (-1,))\n    z = tf.reshape(grid[:,2], (-1,))\n    \n    # Scale to domain\n    x = x * (width-1)\n    y = y * (height-1)\n    z = z * (depth-1)\n    \n    # Do sampling\n    x0 = tf.cast(tf.floor(x), tf.int32)\n    x1 = x0 + 1\n    y0 = tf.cast(tf.floor(y), tf.int32)\n    y1 = y0 + 1\n    z0 = tf.cast(tf.floor(z), tf.int32)\n    z1 = z0 + 1\n    \n    # Clip values\n    x0 = tf.clip_by_value(x0, 0, max_x)\n    x1 = tf.clip_by_value(x1, 0, max_x)\n    y0 = tf.clip_by_value(y0, 0, max_y)\n    y1 = tf.clip_by_value(y1, 0, max_y)\n    z0 = tf.clip_by_value(z0, 0, max_z)\n    z1 = tf.clip_by_value(z1, 0, max_z)\n    \n    dim1 = width * height * depth\n    base = tf_repeat(tf.range(n_batch) * dim1, dim1)\n    \n    c000 = tf.gather_nd(data, tf.stack([base, x0, y0, z0], axis=1))\n    c001 = tf.gather_nd(data, tf.stack([base, x0, y0, z1], axis=1))\n    c010 = tf.gather_nd(data, tf.stack([base, x0, y1, z0], axis=1))\n    c011 = tf.gather_nd(data, tf.stack([base, x0, y1, z1], axis=1))\n    c100 = tf.gather_nd(data, tf.stack([base, x1, y0, z0], axis=1))\n    c101 = tf.gather_nd(data, tf.stack([base, x1, y0, z1], axis=1))\n    c110 = tf.gather_nd(data, tf.stack([base, x1, y1, z0], axis=1))\n    c111 = tf.gather_nd(data, tf.stack([base, x1, y1, z1], axis=1))\n    \n    # Float casting\n    x0_f = tf.cast(x0, tf.float32)\n    y0_f = tf.cast(y0, tf.float32)\n    z0_f = tf.cast(z0, tf.float32)\n    \n    # Interpolation weights\n    xd = (x-x0_f)\n    yd = (y-y0_f)\n    zd = (z-z0_f)\n    \n    # Do interpolation\n    c00 = c000*(1-xd) + c100*xd\n    c01 = c001*(1-xd) + c101*xd\n    c10 = c010*(1-xd) + c110*xd\n    c11 = c011*(1-xd) + c111*xd\n    c0 = c00*(1-yd) + c10*yd\n    c1 = c01*(1-yd) + c11*yd\n    c = c0*(1-zd) + c1*zd\n    \n    # Reshape and return\n    new_data = tf.transpose(tf.reshape(c, (n_batch, depth, height, width)), perm=[0,3,2,1])\n    return new_data\n'"
libcpab/tensorflow/transformer.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Nov 20 10:27:16 2018\n\n@author: nsde\n""""""\n\n#%%\nimport tensorflow as tf\nfrom .findcellidx import findcellidx\nfrom .expm import expm\nfrom ..core.utility import get_dir\nfrom sys import platform as _platform\n\n#%%\n# Small helper function that does nothing\ndef f(*args):\n    return None\n\n#%%\n_verbose = True\ntry:\n    dir_path = get_dir(__file__)\n    transformer_module = tf.load_op_library(dir_path + \'/trans_op.so\')\n    transformer_op = transformer_module.calc_trans\n    grad_op = transformer_module.calc_grad\n    compiled = True\n    if _verbose:\n        print(70*\'=\')\n        print(\'Succesfully loaded c++ source\')\nexcept Exception as e:\n    transformer_op = f\n    grad_op = f\n    compiled = False\n    if _verbose:\n        print(70*\'=\')\n        print(\'Unsuccesfully loaded c++ source\')\n        print(\'Error was: \')\n        print(e)\n\n#%%\ndef CPAB_transformer(points, theta, params):\n    if not params.use_slow and compiled:\n        return CPAB_transformer_fast(points, theta, params)\n    else:\n        return CPAB_transformer_slow(points, theta, params)\n    \n#%%\ndef CPAB_transformer_slow(points, theta, params):\n    with tf.device(points.device):\n        # Problem parameters\n        n_theta = theta.shape[0]\n        n_points = points.shape[-1]\n    \n        # Create homogenous coordinates\n        ones = tf.ones((n_theta, 1, n_points))\n        if len(points.shape) == 2:\n            newpoints = tf.tile(points[None], (n_theta, 1, 1)) # [n_theta, ndim, n_points]\n        else:\n            newpoints = points\n\n        newpoints = tf.concat((newpoints, ones), axis=1) # [n_theta, ndim+1, n_points]\n        newpoints = tf.transpose(newpoints, perm=(0, 2, 1)) # [n_theta, n_points, ndim+1]\n        newpoints = tf.reshape(newpoints, (-1, params.ndim+1)) #[n_theta*n_points, ndim+1]]\n        newpoints = newpoints[:,:,None] # [n_theta*n_points, ndim+1, 1]\n\n        # Get velocity fields\n        B = tf.cast(params.basis, dtype=tf.float32)\n        zero_row = tf.zeros((n_theta*params.nC, 1, params.ndim+1))\n        Avees = tf.matmul(B, tf.transpose(theta))\n        As = tf.reshape(tf.transpose(Avees), (n_theta*params.nC, *params.Ashape))\n        AsSquare = tf.concat([As, zero_row], axis=1)\n\n        # Take matrix exponential\n        dT = 1.0 / params.nstepsolver\n        Trels = expm(dT*AsSquare)\n    \n        # Take care of batch effect\n        batch_idx = params.nC*(tf.ones((n_points, n_theta), dtype=tf.int32) * tf.range(n_theta))\n        batch_idx = tf.reshape(tf.transpose(batch_idx), (-1,))\n    \n        # Do integration\n        for i in range(params.nstepsolver):\n            idx = findcellidx(params.ndim, tf.transpose(newpoints[:,:,0]), params.nc) + batch_idx\n            Tidx = tf.gather(Trels, idx)\n            newpoints = tf.cast(tf.matmul(tf.cast(Tidx, tf.float64), \n                                          tf.cast(newpoints, tf.float64)), tf.float32)\n\n        newpoints = tf.transpose(tf.squeeze(newpoints)[:,:params.ndim])\n        newpoints = tf.transpose(tf.reshape(newpoints, (params.ndim, n_theta, n_points)), perm=[1,0,2])\n        return newpoints\n\n#%%\ndef CPAB_transformer_fast(points, theta, params):\n    # This is just stupid. We need the tf.custom_gradient decorator to equip the fast\n    # gpu version with the gradient operation. But by using the decorator, we can only\n    # call the actual function with tensor-input, and params is a dict. Therefore, this\n    # small work around\n    @tf.custom_gradient\n    def actual_function(points, theta):\n        device = theta.device\n        n_theta = theta.shape[0]\n        \n        # Get Volocity fields\n        B = tf.cast(params.basis, dtype=tf.float32)\n        Avees = tf.matmul(B, tf.transpose(theta))\n        As = tf.reshape(tf.transpose(Avees), (n_theta*params.nC, *params.Ashape))\n        zero_row = tf.zeros((n_theta*params.nC, 1, params.ndim+1))\n        AsSquare = tf.concat([As, zero_row], axis=1)\n        \n        # Take matrix exponential\n        dT = 1.0 / params.nstepsolver\n        Trels = expm(dT * AsSquare)\n        Trels = tf.reshape(Trels[:,:params.ndim,:], (n_theta, params.nC, *params.Ashape))\n        \n        # Convert to tensor\n        nstepsolver = tf.cast(params.nstepsolver, dtype=tf.int32)\n        nc = tf.cast(params.nc, dtype=tf.int32)\n    \n        # Call integrator\n        newpoints = transformer_op(points, Trels, nstepsolver, nc)\n        Bs = tf.reshape(tf.transpose(B), (-1, params.nC, *params.Ashape))\n        As = tf.reshape(As, (n_theta, params.nC, *params.Ashape))\n        \n        def grad(grad):\n            gradient = grad_op(points, As, Bs, nstepsolver, nc)\n            g = tf.reduce_sum(gradient * grad, axis=[2,3])\n            return None, tf.transpose(g)\n    \n        return newpoints, grad\n    \n    with tf.device(points.device):\n        return actual_function(points, theta)\n'"
