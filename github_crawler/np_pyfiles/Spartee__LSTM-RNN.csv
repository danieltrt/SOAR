file_path,api_count,code
CryptoNet.py,5,"b'from model import build_LSTM_model\nimport time\nimport numpy as np\nfrom numpy import newaxis\nimport matplotlib.pyplot as plt\nimport statistics\n\n\nclass CryptoNet:\n\n    def __init__(self, data_file, layers, sequence_length, deep):\n        self.data = data_file\n        self.layers = layers\n        self.seq_len = sequence_length\n        self.model = None\n        self.train_data = None   # [input_train, output_train]\n        self.test_data = None    # [prediction_data, test_data]\n        self.deep = deep\n\n\n\n    def prepare_data(self, test=False):\n        """"""Prepare the data by reading in one sequence, spliting into multiple,\n           scale the data for Keras layers, and then split into test/train data\n           TODO: Add cross validation split of data""""""\n\n        f = open(self.data, \'rb\').read()\n        data = f.decode().split(\'\\n\')\n\n        # Split the data into sequences for LSTM model\n        temp_seq_len = self.seq_len + 1\n        sequences = []\n        for num in range(len(data) - temp_seq_len):\n            seq = data[num: num + temp_seq_len]\n            sequences.append(seq)\n\n        # Normalize the data so that the percent change in the sequence is represented.\n        # e.g. [0.0, -0.05577030433238028, -0.15701283981526903, -0.17998578992776548, .... -0.015487287060375832]\n        scaled_data = []\n        for sequence in sequences:\n            scaled_sequence = [((float(p) / float(sequence[0])) - 1) for p in sequence]\n            scaled_data.append(scaled_sequence)\n\n        # Put data into numpy array and section off data into needed parts for model\n        scaled_data = np.array(scaled_data)\n\n        # split into train and test sections\n        num_training_rows = round(.9 * scaled_data.shape[0])\n        training_data = scaled_data[:int(num_training_rows), :]\n        np.random.shuffle(training_data)\n\n\n        # Training data\n        input_train = training_data[:, :-1]  # input training data\n        output_train = training_data[:, -1]  # output target data\n\n        # reshape input data\n        input_train = np.reshape(input_train, (input_train.shape[0],\n                                               input_train.shape[1], 1))\n        # return training data\n        self.train_data = [input_train, output_train]\n\n\n        # Testing data\n        prediction_input = scaled_data[int(num_training_rows):, :-1]  # input prediction data\n        true_data = scaled_data[int(num_training_rows):, -1]  # correct data that we will plot against\n\n        # Reshape prediction input data\n        prediction_input = np.reshape(prediction_input, (prediction_input.shape[0],\n                                                         prediction_input.shape[1], 1))\n        # return testing data\n        self.test_data = [prediction_input, true_data]\n\n\n\n    def train_model(self, batch, training_cycles, optimizer, valid_split):\n\n        # Start the clock\n        training_time = time.time()\n\n        # Build the model to be trained\n        self.model = build_LSTM_model(self.layers, optimizer, self.deep)\n\n        # Assert prepare_data has been called\n        assert self.train_data is not None\n        input_train = self.train_data[0]\n        output_train = self.train_data[1]\n\n        # Fit the model to parameters\n        self.model.fit(input_train, output_train,\n                       batch_size=batch, nb_epoch=training_cycles,\n                       validation_split=valid_split)\n\n        print(\'Training lasted ->  \', time.time() - training_time)\n\n\n    def predict_trends(self, trend_length):\n        """"""Predict a number of trends with the length given as a parameter""""""\n        final_trends = []\n        predict_data = self.test_data[0]\n        num_trends = int(len(predict_data) / trend_length)\n\n        for x in range(num_trends):\n            window = predict_data[x * trend_length]\n            trend_predictions = []\n            for y in range(trend_length):\n                current_trend = self.model.predict(window[newaxis, :, :])[0, 0]\n                trend_predictions.append(current_trend)\n\n                # Decrease the size of the window\n                window = window[1:]\n\n                # Insert prediction into window\n                window = np.insert(window, [self.seq_len-1], trend_predictions[-1], axis=0)\n\n            final_trends.append(trend_predictions)\n        return final_trends\n\n\n    def evaluate_performance(self, predictions, trend_length):\n        """"""Return the average trend error of each of the predictions based on the\n           factual data provided in test_data""""""\n        trend_errors = [0] * len(predictions)\n        correct_data = self.test_data[1]\n        i = 0\n        for predict in predictions:\n            for trend in predict:\n                trend_errors[int(i/trend_length)] += abs(trend - correct_data[i])\n                i += 1\n\n        average_trend_error = statistics.mean(trend_errors)\n        return average_trend_error\n\n\n    def plot_trends(self, trend_predictions, trend_length, error):\n        """"""Plots the various trends predicted by the model against a factually\n           correct set of data.""""""\n\n        true_data = self.test_data[1]\n\n        graph = plt.figure()\n        true_data_line = graph.add_subplot(111)\n        true_data_line.plot(true_data, label=\'Historical Data\')\n\n        # Add padding for the plotted graph\n        for x, datum in enumerate(trend_predictions):\n            padding = [None for y in range(x * trend_length)]\n            plt.plot(padding + datum)\n        plt.ylabel(""Percent change in BTC/USD"")\n        plt.xlabel(""Data from Predictions"")\n        plt.text(1, 1, ""Trend Length: "" + str(trend_length))\n        plt.text(.9, .9, ""Error: "" + str(error))\n        plt.legend()\n        plt.show()\n\n\nif __name__ == \'__main__\':\n\n    deep = True\n    if deep:\n\n        # Test Deep Neural Network\n\n        DeepCN = CryptoNet(data_file=\'data/BTC_Dateless.csv\', sequence_length=75, layers=[1, 75, 300, 900, 1], deep=True)\n        DeepCN.prepare_data(test=True)\n        DeepCN.train_model(batch=400, training_cycles=10, optimizer=\'rmsprop\', valid_split=0.1)\n\n        metrics = []\n        trend_length_intervals = [5, 10, 15, 20, 30]\n        for interval in trend_length_intervals:\n            trends = DeepCN.predict_trends(trend_length=interval)\n            average_error = DeepCN.evaluate_performance(trends, interval)\n            DeepCN.plot_trends(trends, interval, average_error)\n            metrics += (interval, average_error)\n\n        print(metrics)\n\n    else:\n\n        # Test Neural Network\n\n        BasicCN = CryptoNet(data_file=\'data/BTC_Dateless.csv\', sequence_length=50, layers=[1, 50, 100, 1], deep=False)\n        BasicCN.prepare_data(test=True)\n        BasicCN.train_model(batch=400, training_cycles=10, optimizer=\'rmsprop\', valid_split=0.1)\n\n        metrics = []\n        trend_length_intervals = [5, 10, 15, 20, 30]\n        for interval in trend_length_intervals:\n            trends = BasicCN.predict_trends(trend_length=interval)\n            average_error = BasicCN.evaluate_performance(trends, interval)\n            BasicCN.plot_trends(trends, interval, average_error)\n            metrics += (interval, average_error)\n\n        print(metrics)\n\n\n\n\n\n'"
model.py,0,"b'import os\nimport time\nimport warnings\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\n\n\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\'] = \'3\'\nwarnings.filterwarnings(""ignore"")\n\n\ndef build_LSTM_model(layers, optimize, deep=False):\n    """"""Constructs the LSTM model using the layers from Keras. Dropout layers\n       added at the end of each layer to help prevent overfitting. Linear\n       activation function for output layer. Optimizer can vary as a parameter\n       but rmsprop usually does the best as it is meant for RNN\'s\n       TODO: Assert layer size for all models""""""\n\n    LSTM_model = Sequential()\n\n    # Input layer\n    LSTM_model.add(LSTM(input_shape=(layers[1], layers[0]), output_dim=layers[1], return_sequences=True))\n    LSTM_model.add(Dropout(.2))\n\n    if deep:\n\n        LSTM_model.add(LSTM(input_shape=(layers[1], layers[0]), output_dim=layers[2], return_sequences=True))\n        LSTM_model.add(Dropout(.2))\n\n        # Hidden Layer\n        LSTM_model.add(LSTM(layers[3], return_sequences=False))\n        LSTM_model.add(Dropout(.2))\n\n        # Output layer\n        LSTM_model.add(Dense(output_dim=layers[4]))\n        LSTM_model.add(Activation(""linear""))\n\n    else:\n\n        # Hidden Layer\n        LSTM_model.add(LSTM(layers[2], return_sequences=False))\n        LSTM_model.add(Dropout(.2))\n\n        # Output layer\n        LSTM_model.add(Dense(output_dim=layers[3]))\n        LSTM_model.add(Activation(""linear""))\n\n    # time the compilation\n    start = time.time()\n    LSTM_model.compile(loss=""mse"", optimizer=optimize)\n    print(""LSTM model took "", time.time() - start, "" time to compile"")\n\n    return LSTM_model\n'"
