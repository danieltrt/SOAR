file_path,api_count,code
setup.py,0,"b'# -*- coding: utf-8 -*-\n#\n""""""Setuptools-based setup script for WLSQM.""""""\n\nfrom __future__ import division, print_function, absolute_import\n\n#########################################################\n# Config\n#########################################################\n\n# choose build type here\n#\nbuild_type=""optimized""\n#build_type=""debug""\n\n\n#########################################################\n# Init\n#########################################################\n\n# check for Python 2.7 or later\n# http://stackoverflow.com/questions/19534896/enforcing-python-version-in-setup-py\nimport sys\nif sys.version_info < (2,7):\n    sys.exit(\'Sorry, Python < 2.7 is not supported\')\n\nimport os\nimport platform\n\nfrom setuptools import setup\nfrom setuptools.extension import Extension\n\ntry:\n    from Cython.Build import cythonize\nexcept ImportError:\n    sys.exit(""Cython not found. Cython is needed to build the extension modules for WLSQM."")\n\n\n#########################################################\n# Definitions\n#########################################################\n\nsystem = platform.system()\n\nif system == ""Windows"":\n    my_extra_compile_args_math = [""/openmp""]\n    my_extra_compile_args_nonmath = []\n    my_extra_link_args = []\n    debug = False\nelse:\n    extra_compile_args_math_optimized    = [\'-fopenmp\', \'-march=native\', \'-O2\', \'-msse\', \'-msse2\', \'-mfma\', \'-mfpmath=sse\']\n    extra_compile_args_math_debug        = [\'-fopenmp\', \'-march=native\', \'-O0\', \'-g\']\n\n    extra_compile_args_nonmath_optimized = [\'-O2\']\n    extra_compile_args_nonmath_debug     = [\'-O0\', \'-g\']\n\n    extra_link_args_optimized    = [\'-fopenmp\']\n    extra_link_args_debug        = [\'-fopenmp\']\n\n\n    if build_type == \'optimized\':\n        my_extra_compile_args_math    = extra_compile_args_math_optimized\n        my_extra_compile_args_nonmath = extra_compile_args_nonmath_optimized\n        my_extra_link_args            = extra_link_args_optimized\n        debug = False\n        print( ""build configuration selected: optimized"" )\n    else: # build_type == \'debug\':\n        my_extra_compile_args_math    = extra_compile_args_math_debug\n        my_extra_compile_args_nonmath = extra_compile_args_nonmath_debug\n        my_extra_link_args            = extra_link_args_debug\n        debug = True\n        print( ""build configuration selected: debug"" )\n\n\n#########################################################\n# Long description\n#########################################################\n\nDESC=""""""WLSQM (Weighted Least SQuares Meshless) is a fast and accurate meshless least-squares interpolator for Python, implemented in Cython.\n\nGiven scalar data values on a set of points in 1D, 2D or 3D, WLSQM constructs a piecewise polynomial global surrogate model (a.k.a. response surface), using up to 4th order polynomials.\n\nUse cases include response surface modeling, and computing space derivatives of data known only as values at discrete points in space. No grid or mesh is needed.\n\nAny derivative of the model function (e.g. d2f/dxdy) can be easily evaluated, up to the order of the polynomial.\n\nSensitivity data of solution DOFs (on the data values at points other than the reference in the local neighborhood) can be optionally computed.\n\nPerformance-critical parts are implemented in Cython. LAPACK is used via SciPy\'s Cython-level bindings. OpenMP is used for parallelization over the independent local problems (also in the linear solver step).\n\nThis implementation is targeted for high performance in a single-node environment, such as a laptop. The main target is x86_64.\n""""""\n\n#########################################################\n# Helpers\n#########################################################\n\nmy_include_dirs = ["".""]  # IMPORTANT, see https://github.com/cython/cython/wiki/PackageHierarchy\n\ndef ext(extName):\n    extPath = extName.replace(""."", os.path.sep)+"".pyx""\n    return Extension( extName,\n                      [extPath],\n                      extra_compile_args=my_extra_compile_args_nonmath\n                    )\ndef ext_math(extName):\n    if system == ""Windows"":\n        libraries = []\n    else:\n        libraries = [""m""]  # ""m"" links libm, the math library on unix-likes; see http://docs.cython.org/src/tutorial/external.html\n    extPath = extName.replace(""."", os.path.sep)+"".pyx""\n    return Extension( extName,\n                      [extPath],\n                      extra_compile_args=my_extra_compile_args_math,\n                      extra_link_args=my_extra_link_args,\n                      libraries=libraries\n                    )\n\n# http://stackoverflow.com/questions/13628979/setuptools-how-to-make-package-contain-extra-data-folder-and-all-folders-inside\ndatadirs  = (""examples"",)\ndataexts  = ("".py"", "".pyx"", "".pxd"", "".c"", "".sh"", "".lyx"", "".pdf"")\ndatafiles = []\ngetext = lambda filename: os.path.splitext(filename)[1]\nfor datadir in datadirs:\n    datafiles.extend( [(root, [os.path.join(root, f) for f in files if getext(f) in dataexts])\n                       for root, dirs, files in os.walk(datadir)] )\n\ndatafiles.append( (\'.\', [""README.md"", ""LICENSE.md"", ""TODO.md"", ""CHANGELOG.md""]) )\ndatafiles.append( (\'.\', [""example.png""]) )\n\n\n#########################################################\n# Utility modules\n#########################################################\n\next_module_ptrwrap       = ext(     ""wlsqm.utils.ptrwrap"")        # Pointer wrapper for Cython/Python integration\next_module_lapackdrivers = ext_math(""wlsqm.utils.lapackdrivers"")  # Simple Python interface to LAPACK for solving many independent linear equation systems efficiently in parallel. Built on top of scipy.linalg.cython_lapack.\n\n#########################################################\n# WLSQM (Weighted Least SQuares Meshless method)\n#########################################################\n\next_module_defs     = ext(     ""wlsqm.fitter.defs"")      # definitions (named constants)\next_module_infra    = ext(     ""wlsqm.fitter.infra"")     # memory allocation infrastructure\next_module_impl     = ext_math(""wlsqm.fitter.impl"")      # low-level routines (implementation)\next_module_polyeval = ext_math(""wlsqm.fitter.polyeval"")  # evaluation of Taylor expansions and general polynomials\next_module_interp   = ext_math(""wlsqm.fitter.interp"")    # interpolation of fitted model\next_module_simple   = ext_math(""wlsqm.fitter.simple"")    # simple API\next_module_expert   = ext_math(""wlsqm.fitter.expert"")    # advanced API\n\n#########################################################\n\n# Extract __version__ from the package __init__.py\n# (since it\'s not a good idea to actually run __init__.py during the build process).\n#\n# http://stackoverflow.com/questions/2058802/how-can-i-get-the-version-defined-in-setup-py-setuptools-in-my-package\n#\nimport ast\nwith open(\'wlsqm/__init__.py\', \'r\') as f:\n    for line in f:\n        if line.startswith(\'__version__\'):\n            version = ast.parse(line).body[0].value.s\n            break\n    else:\n        version = \'0.0.unknown\'\n        print( ""WARNING: Version information not found, using placeholder \'%s\'"" % (version) )\n\n\nsetup(\n    name = ""wlsqm"",\n    version = version,\n    author = ""Juha Jeronen"",\n    author_email = ""juha.jeronen@jyu.fi"",\n    url = ""https://github.com/Technologicat/python-wlsqm"",\n\n    description = ""Weighted least squares meshless interpolator"",\n    long_description = DESC,\n\n    license = ""BSD"",\n    platforms = [""Linux""],  # free-form text field; http://stackoverflow.com/questions/34994130/what-platforms-argument-to-setup-in-setup-py-does\n\n    classifiers = [ ""Development Status :: 4 - Beta"",\n                    ""Environment :: Console"",\n                    ""Intended Audience :: Developers"",\n                    ""Intended Audience :: Science/Research"",\n                    ""License :: OSI Approved :: BSD License"",\n                    ""Operating System :: POSIX :: Linux"",\n                    ""Programming Language :: Cython"",\n                    ""Programming Language :: Python"",\n                    ""Programming Language :: Python :: 2"",\n                    ""Programming Language :: Python :: 2.7"",\n                    ""Programming Language :: Python :: 3"",\n                    ""Programming Language :: Python :: 3.4"",\n                    ""Topic :: Scientific/Engineering"",\n                    ""Topic :: Scientific/Engineering :: Mathematics"",\n                    ""Topic :: Software Development :: Libraries"",\n                    ""Topic :: Software Development :: Libraries :: Python Modules""\n                  ],\n\n    # 0.16 seems to be the first SciPy version that has cython_lapack.pxd. ( https://github.com/scipy/scipy/commit/ba438eab99ce8f55220a6ff652500f07dd6a547a )\n    setup_requires = [""cython"", ""scipy (>=0.16)""],\n    install_requires = [""numpy"", ""scipy (>=0.16)""],\n    provides = [""wlsqm""],\n\n    # same keywords as used as topics on GitHub\n    keywords = [""numerical interpolation differentiation curve-fitting least-squares meshless numpy cython""],\n\n    ext_modules = cythonize( [ ext_module_lapackdrivers,\n                               ext_module_ptrwrap,\n                               ext_module_defs,\n                               ext_module_infra,\n                               ext_module_impl,\n                               ext_module_polyeval,\n                               ext_module_interp,\n                               ext_module_simple,\n                               ext_module_expert ],\n\n                             include_path = my_include_dirs,\n\n                             gdb_debug = debug ),\n\n    # Declare packages so that  python -m setup build  will copy .py files (especially __init__.py).\n    packages = [""wlsqm"", ""wlsqm.utils"", ""wlsqm.fitter""],\n\n    # Install also Cython headers so that other Cython modules can cimport ours\n    # FIXME: force sdist, but sdist only, to keep the .pyx files (this puts them also in the bdist)\n    package_data={\'wlsqm.utils\': [\'*.pxd\', \'*.pyx\'],  # note: paths relative to each package\n                  \'wlsqm.fitter\': [\'*.pxd\', \'*.pyx\']},\n\n    # Disable zip_safe, because:\n    #   - Cython won\'t find .pxd files inside installed .egg, hard to compile libs depending on this one\n    #   - dynamic loader may need to have the library unzipped to a temporary folder anyway (at import time)\n    zip_safe = False,\n\n    # Usage examples; not in a package\n    data_files = datafiles\n)\n'"
examples/expertsolver_example.py,17,"b'# -*- coding: utf-8 -*-\n""""""A minimal usage example for ExpertSolver.\n\nJJ 2017-03-28\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\n\nimport scipy.spatial.ckdtree\n\nimport matplotlib.pyplot as plt\nimport mpl_toolkits.mplot3d.axes3d\n\nimport wlsqm\n\n\ndef project_onto_regular_grid_2D(x, F, nvis=101, fit_order=1, nk=10):\n    """"""Project scalar data from a 2D point cloud onto a regular grid.\n\nUseful for plotting. Uses the WLSQM meshless method.\n\nThe bounding box of the x data is automatically used as the bounds of the generated regular grid.\n\nParameters:\n    x : rank-2 array, dtype np.float64\n        Point cloud, one point per row. x[i,:] = (xi,yi)\n\n    F : rank-1 array, dtype np.float64\n        The corresponding function values. F[i] = F( x[i,:] )\n\n    nvis : int\n        Number of points per axis in the generated regular grid.\n\n    fit_order : int\n        Order of the surrogate polynomial, one of [0,1,2,3,4].\n\n    nk : int\n        Number of nearest neighbors to use for fitting the model.\n\nReturn value:\n    tuple (X,Y,Z)\n        where\n        X,Y are rank-2 meshgrid arrays representing the generated regular grid, and\n        Z is an array of the same shape, containing the corresponding data values.\n\n""""""\n    # Form the neighborhoods.\n\n    # index the input points for fast searching\n    tree = scipy.spatial.cKDTree( data=x )\n\n    # Find max_nk nearest neighbors of each input point.\n    #\n    # The +1 is for the point itself, since it is always the nearest to itself.\n    #\n    # (cKDTree.query() supports querying for arbitrary x; here we just set these x as the same as the points in the tree.)\n    #\n    dd,ii = tree.query( x, 1 + nk )\n\n    # Take only the neighbors of points[i], excluding the point itself.\n    #\n    ii = ii[:,1:]  # points[ ii[i,k] ] is the kth nearest neighbor of points[i]. Shape of ii is (npoints, nk).\n\n    # neighbor point indices (pointing to rows in x[]); typecast to int32\n    hoods = np.array( ii, dtype=np.int32 )\n\n    npoints  = x.shape[0]\n    nk_array = nk * np.ones( (npoints,), dtype=np.int32 )  # number of neighbors, i.e. nk_array[i] is the number of actually used columns in hoods[i,:]\n\n    # Construct the model by least-squares fitting\n    #\n    fit_order_array = fit_order            * np.ones( (npoints,), dtype=np.int32 )\n    knowns_array    = wlsqm.b2_F           * np.ones( (npoints,), dtype=np.int64 )  # bitmask! wlsqm.b*\n    wm_array        = wlsqm.WEIGHT_UNIFORM * np.ones( (npoints,), dtype=np.int32 )\n    solver = wlsqm.ExpertSolver( dimension=2,\n                                 nk=nk_array,\n                                 order=fit_order_array,\n                                 knowns=knowns_array,\n                                 weighting_method=wm_array,\n                                 algorithm=wlsqm.ALGO_BASIC,\n                                 do_sens=False,\n                                 max_iter=10,  # must be an int even though this parameter is not used in ALGO_BASIC mode\n                                 ntasks=8,\n                                 debug=False )\n\n    no = wlsqm.number_of_dofs( dimension=2, order=fit_order )\n    fi = np.empty( (npoints,no), dtype=np.float64 )\n    fi[:,0] = F  # fi[i,0] contains the function value at point x[i,:]\n\n    solver.prepare( xi=x, xk=x[hoods] )  # generate problem matrices from the geometry of the point cloud\n    solver.solve( fk=fi[hoods,0], fi=fi, sens=None )  # compute least-squares fit to data\n\n\n    # generate the regular grid for output\n    #\n    xx  = np.linspace( np.min(x[:,0]), np.max(x[:,0]), nvis )\n    yy  = np.linspace( np.min(x[:,1]), np.max(x[:,1]), nvis )\n    X,Y = np.meshgrid(xx,yy)\n\n    # make a flat list of grid points (rank-2 array, one point per row)\n    #\n    Xlin = np.reshape(X, -1)\n    Ylin = np.reshape(Y, -1)\n    xout = np.empty( (len(Xlin), 2), dtype=np.float64 )\n    xout[:,0] = Xlin\n    xout[:,1] = Ylin\n\n    # Using the model, interpolate onto the regular grid\n    #\n    solver.prep_interpolate()  # prepare global model\n    Z,mi = solver.interpolate( xout, mode=\'nearest\' )  # use the nearest local model; fast, surprisingly accurate\n                                                       # if a reasonable number of points (and continuous-looking\n                                                       # although technically has jumps over Voronoi cell boundaries)\n    # when mode=""nearest"", ""mi"" is an array containing the index of the local model (which belongs to x[mi,:]) used for each evaluation\n\n    return (X, Y, np.reshape( Z, X.shape ))\n\n\ndef plot_wireframe( data, figno=None ):\n    """"""Make and label a wireframe plot.\n\nParameters:\n    data : dict\n        key   : ""x"",""y"",""z""\n        value : tuple (rank-2 array in meshgrid format, axis label)\n\nReturn value:\n    ax\n        The Axes3D object that was used for plotting.\n""""""\n    # http://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html\n    fig = plt.figure(figno)\n\n    # Axes3D has a tendency to underestimate how much space it needs; it draws its labels\n    # outside the window area in certain orientations.\n    #\n    # This causes the labels to be clipped, which looks bad. We prevent this by creating the axes\n    # in a slightly smaller rect (leaving a margin). This way the labels will show - outside the Axes3D,\n    # but still inside the figure window.\n    #\n    # The final touch is to set the window background to a matching white, so that the\n    # background of the figure appears uniform.\n    #\n    fig.patch.set_color( (1,1,1) )\n    fig.patch.set_alpha( 1.0 )\n    x0y0wh = [ 0.02, 0.02, 0.96, 0.96 ]  # left, bottom, width, height      (here as fraction of subplot area)\n\n    ax = mpl_toolkits.mplot3d.axes3d.Axes3D(fig, rect=x0y0wh)\n\n    X,xlabel = data[""x""]\n    Y,ylabel = data[""y""]\n    Z,zlabel = data[""z""]\n    ax.plot_wireframe( X, Y, Z )\n\n    ax.view_init(34, -40)\n    ax.axis(\'tight\')\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    ax.set_title(zlabel)\n\n    return ax\n\n\ndef main():\n    x = np.random.random( (1000, 2) )                # point cloud (no mesh topology!)\n    F = np.sin(np.pi*x[:,0]) * np.cos(np.pi*x[:,1])  # function values on the point cloud\n    X,Y,Z = project_onto_regular_grid_2D(x, F, fit_order=2, nk=30)\n    plot_wireframe( {""x"" : (X, r""$x$""),\n                     ""y"" : (Y, r""$y$""),\n                     ""z"" : (Z, r""$f(x,y)$"")} )\n\nif __name__ == \'__main__\':\n    main()\n    plt.show()\n'"
examples/lapackdrivers_example.py,50,"b'# -*- coding: utf-8 -*-\n#\n""""""Performance benchmarking and usage examples for the wlsqm.utils.lapackdrivers module.\n\nJJ 2016-11-02\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport time\n\nimport numpy as np\nfrom numpy.linalg import solve as numpy_solve  # for comparison purposes\n\nimport matplotlib.pyplot as plt\n\ntry:\n    import wlsqm.utils.lapackdrivers as drivers\nexcept ImportError:\n    import sys\n    sys.exit( ""WLSQM not found; is it installed?"" )\n\n# from find_neighbors2.py\nclass SimpleTimer:\n    def __init__(self, label="""", n=None):\n        self.label = label\n        self.n     = n      # number of repetitions done inside the ""with..."" section (for averaging in timing info)\n\n    def __enter__(self):\n        self.t0 = time.time()\n        return self\n\n    def __exit__(self, errtype, errvalue, traceback):\n        dt         = time.time() - self.t0\n        identifier = (""%s"" % self.label) if len(self.label) else ""time taken: ""\n        avg        = ("", avg. %gs per run"" % (dt/self.n)) if self.n is not None else """"\n        print( ""%s%gs%s"" % (identifier, dt, avg) )\n\n# from util.py\ndef f5(seq, idfun=None):\n   """"""Uniqify a list (remove duplicates).\n\n   This is the fast order-preserving uniqifier ""f5"" from\n   http://www.peterbe.com/plog/uniqifiers-benchmark\n\n   The list does not need to be sorted.\n\n   The return value is the uniqified list.\n\n   """"""\n   # order preserving\n   if idfun is None:\n       def idfun(x): return x\n   seen = {}\n   result = []\n   for item in seq:\n       marker = idfun(item)\n       # in old Python versions:\n       # if seen.has_key(marker)\n       # but in new ones:\n       if marker in seen: continue\n       seen[marker] = 1\n       result.append(item)\n   return result\n\n\n\ndef main():\n#    # exact solution is (3/10, 2/5, 0)\n#    A = np.array( ( (2., 1.,  3.),\n#                    (2., 6.,  8.),\n#                    (6., 8., 18.) ), dtype=np.float64, order=\'F\' )\n#    b = np.array(   (1., 3., 5.),    dtype=np.float64 )\n\n#    # symmetric matrix for testing symmetric solver\n#    A = np.array( ( (2., 1.,  3.),\n#                    (1., 6.,  8.),\n#                    (3., 8., 18.) ), dtype=np.float64, order=\'F\' )\n#    b = np.array(   (1., 3., 5.),    dtype=np.float64 )\n\n    # random matrix\n    n = 5\n    A = np.random.sample( (n,n) )\n    A = np.array( A, dtype=np.float64, order=\'F\' )\n    drivers.symmetrize( A )  # fast Cython implementation of  A = 0.5 * (A + A.T)\n    b = np.random.sample( (n,) )\n\n    # test that it works\n\n    x = numpy_solve(A, b)\n    print( ""NumPy:"", x )\n\n    A2 = A.copy(order=\'F\')\n    x2 = b.copy()\n    drivers.symmetric(A2, x2)\n    print( ""dsysv:"", x2 )\n\n    A3 = A.copy(order=\'F\')\n    x3 = b.copy()\n    drivers.general(A3, x3)\n    print( ""dgesv:"", x3 )\n\n    assert (np.abs(x - x3) < 1e-10).all(), ""Something went wrong, solutions do not match""  # check general solver first\n    assert (np.abs(x - x2) < 1e-10).all(), ""Something went wrong, solutions do not match""  # then check symmetric solver\n\n\n    # test performance\n\n    # for verification only - very slow (serial only!)\n    use_numpy = True\n\n    # parallel processing\n    ntasks = 8\n\n#    # overview, somewhat fast but not very accurate\n#    sizes = f5( map( lambda x: int(x), np.ceil(3*np.logspace(0, 3, 21, dtype=int)) ) )\n#    reps = map( lambda x: int(x), 10.**(4 - np.log10(sizes)) )\n\n#    # ""large n""\n#    sizes = f5( map( lambda x: int(x), np.ceil(3*np.logspace(2, 3, 21, dtype=int)) ) )\n#    reps = map( lambda x: int(x), 10.**(5 - np.log10(sizes)) )\n\n    # ""small n"" (needs more repetitions to eliminate noise from other running processes since a single solve is very fast)\n    sizes = f5( map( lambda x: int(x), np.ceil(3*np.logspace(0, 2, 21, dtype=int)) ) )\n    reps = map( lambda x: int(x), 10.**(6 - np.log10(sizes)) )\n\n    print( ""performance test: %d tasks, sizes %s"" % (ntasks, sizes) )\n\n    results1 = np.empty( (len(sizes),), dtype=np.float64 )\n    results2 = np.empty( (len(sizes),), dtype=np.float64 )\n    results3 = np.empty( (len(sizes),), dtype=np.float64 )\n    results4 = np.empty( (len(sizes),), dtype=np.float64 )\n    results5 = np.empty( (len(sizes),), dtype=np.float64 )\n    results6 = np.empty( (len(sizes),), dtype=np.float64 )\n    results7 = np.empty( (len(sizes),), dtype=np.float64 )\n\n#    # many LHS (completely independent problems)\n#    n = 5\n#    reps=int(1e5)\n#    A = np.random.sample( (n,n,reps) )\n#    A = 0.5 * (A + A.transpose(1,0,2))  # symmetrize\n#    A = np.array( A, dtype=np.float64, order=\'F\' )\n#    b = np.random.sample( (n,reps) )\n#    b = np.array( b, dtype=np.float64, order=\'F\' )\n#    with SimpleTimer(label=""msymmetric "", n=reps) as s:\n#        drivers.msymmetricp(A, b, ntasks)\n#    with SimpleTimer(label=""mgeneral "", n=reps) as s:\n#        drivers.mgeneralp(A, b, ntasks)\n\n\n    for j,item in enumerate(zip(sizes,reps)):\n        n,r = item\n        print( ""testing size %d, reps = %d"" % (n, r) )\n\n        # same LHS, many different RHS\n\n        print( ""    prep same LHS, many RHS..."" )\n\n        A = np.random.sample( (n,n) )\n        # symmetrize\n#        A *= 0.5\n#        A += A.T  # not sure if this works\n        A = np.array( A, dtype=np.float64, order=\'F\' )\n#        A = 0.5 * (A + A.T)  # symmetrize\n        drivers.symmetrize(A)\n        b = np.random.sample( (n,r) )\n        b = np.array( b, dtype=np.float64, order=\'F\' )\n\n        print( ""    solve:"" )\n\n#        # for verification only - very slow (Python loop, serial!)\n#        if use_numpy:\n#            t0 = time.time()\n#            x = np.empty( (n,r), dtype=np.float64 )\n#            for k in range(r):\n#                x[:,k] = numpy_solve(A, b[:,k])\n#            results1[j] = (time.time() - t0) / r\n\n        print( ""        symmetricsp"" )\n        t0 = time.time()\n        A2 = A.copy(order=\'F\')\n        x2 = b.copy(order=\'F\')\n        drivers.symmetricsp(A2, x2, ntasks)\n        results2[j] = (time.time() - t0) / r\n\n        print( ""        generalsp"" )\n        t0 = time.time()\n        A3 = A.copy(order=\'F\')\n        x3 = b.copy(order=\'F\')\n        drivers.generalsp(A3, x3, ntasks)\n        results3[j] = (time.time() - t0) / r\n\n        # different LHS for each problem\n\n        print( ""    prep independent problems..."" )\n\n        A = np.random.sample( (n,n,r) )\n        # symmetrize\n#        A *= 0.5\n#        A += A.transpose(1,0,2)  # this doesn\'t work\n        A = np.array( A, dtype=np.float64, order=\'F\' )\n#        A = 0.5 * (A + A.transpose(1,0,2))\n        drivers.msymmetrizep(A, ntasks)\n        b = np.random.sample( (n,r) )\n        b = np.array( b, dtype=np.float64, order=\'F\' )\n\n        print( ""    solve:"" )\n\n        # for verification only - very slow (Python loop, serial!)\n        if use_numpy:\n            print( ""        NumPy"" )\n            t0 = time.time()\n            x = np.empty( (n,r), dtype=np.float64, order=\'F\' )\n            for k in range(r):\n                x[:,k] = numpy_solve(A[:,:,k], b[:,k])\n            results1[j] = (time.time() - t0) / r\n\n        print( ""        msymmetricp"" )\n        t0 = time.time()\n        A2 = A.copy(order=\'F\')\n        x2 = b.copy(order=\'F\')\n        drivers.msymmetricp(A2, x2, ntasks)\n        results4[j] = (time.time() - t0) / r\n\n        print( ""        mgeneralp"" )\n        t0 = time.time()\n        A3 = A.copy(order=\'F\')\n        x3 = b.copy(order=\'F\')\n        drivers.mgeneralp(A3, x3, ntasks)\n        results5[j] = (time.time() - t0) / r\n\n        print( ""        msymmetricfactorp & msymmetricfactoredp"" )  # factor once, then it is possible to solve multiple times (although we now test only once)\n        t0 = time.time()\n        ipiv = np.empty( (n,r), dtype=np.intc, order=\'F\' )\n        fact = A.copy(order=\'F\')\n        x4   = b.copy(order=\'F\')\n        drivers.msymmetricfactorp( fact, ipiv, ntasks )\n        drivers.msymmetricfactoredp( fact, ipiv, x4, ntasks )\n        results6[j] = (time.time() - t0) / r\n\n        print( ""        mgeneralfactorp & mgeneralfactoredp"" )  # factor once, then it is possible to solve multiple times (although we now test only once)\n        t0 = time.time()\n        ipiv = np.empty( (n,r), dtype=np.intc, order=\'F\' )\n        fact = A.copy(order=\'F\')\n        x5   = b.copy(order=\'F\')\n        drivers.mgeneralfactorp( fact, ipiv, ntasks )\n        drivers.mgeneralfactoredp( fact, ipiv, x5, ntasks )\n        results7[j] = (time.time() - t0) / r\n\n        if use_numpy:\n#            print( np.max(np.abs(x - x3)) )  # DEBUG\n#            print( np.max(np.abs(x - x5)) )  # DEBUG\n            print( np.max(np.abs(x2 - x4)) )  # DEBUG\n            assert (np.abs(x - x5) < 1e-10).all(), ""Something went wrong, solutions do not match""  # check general solver first\n            assert (np.abs(x - x3) < 1e-10).all(), ""Something went wrong, solutions do not match""  # check general solver\n#            assert (np.abs(x - x2) < 1e-5).all(), ""Something went wrong, solutions do not match""  # doesn\'t make sense to compare, DSYSV is more accurate for badly conditioned symmetric matrices\n            assert (np.abs(x2 - x4) < 1e-7).all(), ""Something went wrong, solutions do not match""  # check symmetric solvers against each other\n                                                                                                   # (not exactly the same algorithm (DSYTRS2 vs. DSYTRS), so there may be slight deviation)\n\n\n# old, serial only\n#\n#    for j,item in enumerate(zip(sizes,reps)):\n#        n,r = item\n#        print( ""testing size %d, reps = %d"" % (n, r) )\n#\n#        A = np.random.sample( (n,n) )\n#        A = 0.5 * (A + A.T)  # symmetrize\n#        A = np.array( A, dtype=np.float64, order=\'F\' )\n#        b = np.random.sample( (n,) )\n#\n#        t0 = time.time()\n#        for k in range(r):\n#            x = numpy_solve(A, b)\n#        results1[j] = (time.time() - t0) / r\n#\n#        t0 = time.time()\n#        for k in range(r):\n#            A2 = A.copy(order=\'F\')\n#            x2 = b.copy()\n#            drivers.symmetric(A2, x2)\n#        results2[j] = (time.time() - t0) / r\n#\n#        t0 = time.time()\n#        for k in range(r):\n#            A3 = A.copy(order=\'F\')\n#            x3 = b.copy()\n#            drivers.general(A3, x3)\n#        results3[j] = (time.time() - t0) / r\n\n\n    # visualize\n\n    plt.figure(1)\n    plt.clf()\n    if use_numpy:\n        plt.loglog(sizes, results1, \'k-\', label=\'NumPy\')\n    plt.loglog(sizes, results2, \'b--\', label=\'dsysv, same LHS, many RHS\')\n    plt.loglog(sizes, results3, \'b-\',  label=\'dgesv, same LHS, many RHS\')\n    plt.loglog(sizes, results4, \'r--\', label=\'dsysv, independent problems\')\n    plt.loglog(sizes, results5, \'r-\',  label=\'dgesv, independent problems\')\n    plt.loglog(sizes, results6, \'g--\', label=\'dsytrf+dsytrs, independent problems\')\n    plt.loglog(sizes, results7, \'g-\',  label=\'dgetrf+dgetrs, independent problems\')\n    plt.xlabel(\'n\')\n    plt.ylabel(\'t\')\n    plt.title(\'Average time per problem instance, %d parallel tasks\' % (ntasks))\n    plt.axis(\'tight\')\n    plt.grid(b=True, which=\'both\')\n    plt.legend(loc=\'best\')\n\n    plt.savefig(\'figure1_latest.pdf\')\n\n\nif __name__ == \'__main__\':\n    main()\n    plt.show()\n'"
examples/sudoku_lhs.py,13,"b'# -*- coding: utf-8 -*-\n""""""Latin hypercube sampler with a sudoku-like constraint.\n\nTested on Python 2.7 and 3.4.\n\nLicense: 2-clause BSD; copyright 2010-2017 Juha Jeronen and University of Jyv\xc3\xa4skyl\xc3\xa4.\n\nThe sudoku LHS algorithm is a bit like the first stage in the design of an N-dimensional\nsudoku puzzle, hence the name: each ""box"" must have exactly the same number of samples,\nand no two samples may occur on the same hyperplane. The algorithm runs in linear time\n(w.r.t. number of samples) and consumes a linear amount of memory.\n\nThe Sudoku LHS sampling method is inspired by, but not related to, orthogonal sampling.\nThe latter refers to LHS sampling using orthogonal arrays; about that, see the articles\n    B. Tang 1993:    Orthogonal Array-Based Latin Hypercubes,\n    A. B. Owen 1992: Orthogonal arrays for computer experiments, integration and\n                     visualization,\n    K. Q. Ye 1998:   Orthogonal column Latin hypercubes and their application in computer\n                     experiments\nfor more information.\n\nLatin hypercube sampling is very classical (original paper: M. D. McKay, R. J. Beckman,\nW. J. Conover 1979: A Comparison of Three Methods for Selecting Values of Input Variables\nin the Analysis of Output from a Computer Code).\nSee e.g. Wikipedia for a description:\n    http://en.wikipedia.org/wiki/Latin_hypercube_sampling\n\nHistorical note:\n    The variant of sudoku sampling implemented here was originally developed as part of\n    the SAVU project in 2010, and briefly mentioned in the paper\n        Jeronen, J. SAVU: A Statistical Approach for Uncertain Data in Dynamics\n        of Axially Moving Materials. In: A. Cangiani, R. Davidchack, E. Georgoulis,\n        A. Gorban, J. Levesley, M. Tretyakov (eds.) Numerical Mathematics and\n        Advanced Applications 2011: Proceedings of ENUMATH 2011, the 9th European Conference\n        on Numerical Mathematics and Advanced Applications, Leicester, September 2011,\n        831-839, Springer, 2013.\n\n    Later, Shields and Zhang independently developed and published a variant of sudoku sampling\n    in the paper\n        Michael D. Shields and Jiaxin Zhang. The generalization of Latin hypercube sampling.\n        Reliability Engineering & System Safety 148:96-108, 2016.\n        http://doi.org/10.1016/j.ress.2015.12.002\n\nJJ 2010-09-23 (MATLAB version)\nJJ 2012-03-12 (Python version)\nJJ 2017-04-25 (Python3 compatibility, NumPyDoc style docstring, define __version__)\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\n\n__version__ = \'1.0.0\'\n\ndef sample(N,k,n, visualize=False, showdiag=False, verbose=False):\n    """"""Create a coarsely `N`-dimensionally stratified latin hypercube sample (LHS) of range(`k` * `m`) in `N` dimensions.\n\nParameters:\n    N : int, >= 1\n        number of dimensions\n    k : int, >= 1\n        number of large subdivisions (sudoku boxes, ""subspaces"") per dimension\n    n : int, >= 1\n        number of samples to place in each subspace\n    visualize : bool (optional)\n        If True, the results (projected into two dimensions pairwise)\n        are plotted using Matplotlib when the sampling is finished.\n    showdiag : bool (optional)\n        If True, and `N` >= 3, show also one-dimensional projection\n        of the result onto each axis.\n\n        Implies ""visualize"".\n\n        This should produce a straight line with no holes onto\n        each subplot that is on the diagonal of the plot array;\n        mainly intended for debug.\n    verbose : bool (optional)\n        If this exists and is true, progress messages and warnings\n        (for non-integer input) are printed.\n\nReturn value:\n    tuple (`S`, `m`), where:\n        S : (`k` * `m`)-by-`N` rank-2 np.array\n            where each row is an `N`-tuple of integers in range(1, `k` * `m` + 1).\n\n        m : int, >= 1\n            number of bins per parameter in one subspace (i.e. sample slots\n            per axis in one box).\n\n            `m` = `n` * (`k` ** (`N` - 1)), but is provided as output for convenience.\n\n**Examples:**\n\n    `N` = 2 dimensions, k = 3 subspaces per axis, `n` = 1 sample per subspace.\n    `m` will be `n` * (`k` ** (`N` - 1)) = 1 * 3**(2-1) = 3. Plot the result and show progress messages::\n\n        S,m = sample(2, 3, 1, visualize=True, verbose=True)\n\n    For comparison with the previous example, try this classical Latin hypercube\n    that has 9 samples in total, plotting the result. We choose 9, because in\n    the previous example, `k` * `m` = 3*3 = 9::\n\n        S,m = sample(2, 1, 9, visualize=True)\n\n**Notes:**\n\n    If `k` = 1, the algorithm reduces to classical Latin hypercube sampling.\n\n    If `N` = 1, the algorithm simply produces a random permutation of range(`k`).\n\n    Let `m` = `n` * (`k` ** (`N` - 1)) denote the number of bins for one variable\n    in one subspace. The total number of samples is always exactly `k` * `m\'.\n    Each component of a sample can take on values 0, 1, ..., (`k` * `m` - 1).\n""""""\n    # sanity check input\n    if not isinstance(N, int)  or  N < 1:\n        raise ValueError(""N must be int >= 1, got %g"" % (N))\n    if not isinstance(k, int)  or  k < 1:\n        raise ValueError(""k must be int >= 1, got %g"" % (k))\n    if not isinstance(n, int)  or  n < 1:\n        raise ValueError(""n must be int >= 1, got %g"" % (n))\n\n    # showing the diagonal implies visualization\n    if showdiag:\n        visualize = True\n\n    # Discussion.\n\n    # Proof that the following algorithm implements a Sudoku-like LHS method:\n    #\n    # * We desire two properties: Latin hypercube sampling globally, and equal density\n    #   in each subspace.\n    # * The independent index vector generation for each parameter guarantees the Latin\n    #   hypercube property: some numbers will have been used, and removed from the index\n    #   vectors, when the next subspace along the same hyperplane is reached. Thus, the same\n    #   indices cannot be used again for any such subspace. This process continues until each\n    #   index has been used exactly once.\n    # * The equal density property is enforced by the fact that each subspace gets exactly one\n    #   sample generated in one run of the loop. The total number of samples is, by design,\n    #   divisible by the number of these subspaces. Therefore, each subspace will have the\n    #   same sample density.\n    #\n    # Run time and memory cost:\n    #\n    # * Exactly k*m samples will be generated. This can be seen from the fact that there are\n    #   k*m bins per parameter, and they all get filled by exactly one sample.\n    # * Thus, runtime is in O(k*m) = O( k * n*k^(N-1) ) = O( n*k^N ). (This isn\'t as bad as it\n    #   looks. All it\'s saying is that a linear number of bins gets filled. This is much less\n    #   than the total number of bins (k*m)^N - which is why LHS is needed in the first place.\n    #   We get a reduction in sample count by the factor (k*m)^(N-1).)\n    # * Required memory for the final result is (k*m)*N reals (plus some overhead), where the\n    #   N comes from the fact that each N-tuple generated has N elements. Note that the index\n    #   vectors also use up k*m*N reals in total (k*N vectors, each with m elements). Thus the\n    #   memory cost is 2*k*m*N reals plus overhead.\n    # * Note that using a more complicated implementation that frees the elements of the index\n    #   vectors as they are used up probably wouldn\'t help with the memory usage, because many\n    #   vector implementations never decrease their storage space even if elements are deleted.\n    # * In other programming languages, one might work around this by using linked lists\n    #   instead of vectors, and arranging the memory allocations for the elements in a very\n    #   special way (i.e. such that the last ones in memory always get deleted first). By\n    #   using a linked list for the results, too, and allocating them over the deleted\n    #   elements of the index vectors (since they shrink at exactly the same rate the results\n    #   grow), one might be able to bring down the memory usage to k*m*N plus overhead.\n    # * Finally, note that in practical situations N, k and m are usually small, so the factor\n    #   of 2 doesn\'t really matter.\n\n    # Algorithm.\n\n    # Find necessary number of bins per subspace so that equal nonzero density is possible.\n    # A brief analysis shows that in order to exactly fill up all k*m bins for one variable,\n    # we must have k*m = n*k^N, i.e...\n    m = n * k**(N-1)\n\n    # Create index vectors for each subspace for each parameter. (There are k*N of these.)\n    if verbose:\n        print(\'Allocating %d elements for solution...\' % (N*k*m))\n\n    I    = np.empty( [N,k,m], dtype=int, order=""C"" )  # index vectors\n    Iidx = np.zeros( [N,k],   dtype=int, order=""C"" )  # index of first ""not yet used"" element in each index vector\n\n    # Create random permutations of range(m) so that in the sampling loop\n    # we may simply pick the first element from each index vector.\n    #\n    for i in range(N):\n        for j in range(k):\n            tmp = np.array( range(m), dtype=int )\n            np.random.shuffle(tmp)\n            I[i,j,:] = tmp\n\n    if verbose:\n        print(\'Generating sample...\')\n        print(\'Looping through %d subspaces.\' % (k**N))\n\n    L  = k*m   # number of samples still waiting for placement\n    Ns = k**N  # number of subspaces in total (cartesian product\n               #         of k subspaces per axis in N dimensions)\n\n    # Start with an empty result set. We will place the generated samples here.\n    S = np.empty( [L,N], dtype=int, order=""C"" )\n    out_idx = 0  # index of current output sample in S\n\n    # create views for linear indexing\n    I_lin    = np.reshape(I, -1)\n    Iidx_lin = np.reshape(Iidx, -1)\n\n    # we will need an array of range(N) several times in the loop...\n    rgN = np.arange(N, dtype=int)\n\n    while L > 0:\n        # Loop over all subspaces, placing one sample in each.\n        for j in range(Ns):  # index subspaces linearly\n            # Find, in each dimension, which subspace we are in.\n            # Compute the multi-index (vector containing an index in each dimension)\n            # for this subspace.\n            #\n            # Simple example: (N,k,n) = (2,3,1)\n            #   =>  pj = 0 0, 1 0, 2 0,  0 1, 1 1, 2 1,  0 2, 1 2, 2 2\n            #   when j =  0,   1,   2,    3,   4,   5,    6,   7,   8\n            #\n            pj = np.array( ( j // (k**rgN) ) % k, dtype=int )\n\n            # Construct one sample point.\n            #\n            # To do this, we grab the first ""not yet used"" element in all index vectors\n            # (one for each dimension) corresponding to this subspace.\n            #\n            # Along the dth dimension, we are in the pj[d]th subspace.\n            # Hence, in the dth dimension, we want to refer to the vector whose index is pj[d].\n            #\n            # Hence, we should take\n            #  row = d  (effectively, range(N))\n            #  col = pj[d]\n            #\n            # The array Iidx is of the shape [N,k]. NumPy uses C-contiguous ordering\n            # by default; last index varies fastest. Hence, the element [row,col] is at\n            # k*row + col.\n            #\n            # This gets us a vector of linear indices into Iidx, where the dth element\n            # corresponds to the linear index of the pj[d]th vector.\n            #\n            i = np.array( k*rgN + pj, dtype=int )\n\n            # Extract the ""first unused element"" data from Iidx for each of the vectors,\n            # to get the actual sample slot numbers (random permutations) stored in I.\n            #\n            indices = Iidx_lin[i]\n\n            # Indexing: the array I is of shape [N,k,m] and has C storage order.\n            #\n            idx_first = np.array( k*m*rgN + m*pj + indices, dtype=int )\n\n            s = I_lin[idx_first] # this is our new sample point (vector of length N)\n            Iidx_lin[i] += 1     # move to the next element in the selected index vectors\n\n            # Now s contains a sample from (range(m), range(m), ..., range(m)) (N elements).\n            # By its construction, the sample conforms globally to the Latin hypercube\n            # requirement.\n\n            # Compute the base index along each dimension. In the global numbering\n            # which goes 0, 1, ..., (k*m-1) along each axis, the first element\n            # of the current subspace is at this multi-index:\n            #\n            a = pj*m\n\n            # Add the new sample to the result set.\n            S[out_idx,:] = a+s\n            out_idx += 1\n\n        # We placed exactly Ns samples during the for loop.\n        L -= Ns\n\n    # Result visualization (for debug and illustrative purposes)\n    #\n    if visualize  and  N > 1:\n        if verbose:\n            print(\'Plotting...\')\n\n        import itertools\n        import matplotlib.pyplot as plt\n\n        # if the grid would show more lines than this, the lines are hidden.\n        max_major_lines = 5\n        max_minor_lines = 15\n\n        if k*m > 100:\n            style = \'b.\'\n        else:\n            style = \'bo\' # use circles when a small number of bins\n\n        plt.figure(1)\n        plt.clf()\n\n        if N >= 3:\n            # We\'ll make a ""pairs"" plot (like the pairs() function of the ""R""\n            # statistics software).\n\n            # generate all pairs of dimensions, make explicit list\n            pair_list = list(itertools.combinations(range(N), 2))\n\n            # make final list.\n            #\n            # We want to populate both sides of the diagonal in the plot,\n            # so we need pair_list, plus another copy of it\n            # with the first and second components switched in each pair.\n            #\n            pairs = list(pair_list) # copy\n            pairs.extend( tuple(reversed(pair)) for pair in pair_list )\n\n            # Show also the diagonal if requested.\n            #\n            # This should produce a straight line with no holes onto\n            # each subplot that is on the diagonal of the plot array.\n            #\n            if showdiag:\n                pairs.extend( [ (j,j) for j in range(N) ] )\n        else: # N == 2:\n            pairs = [ (0, 1) ]\n\n        Np = len(pairs)\n        for i in range(Np):\n            if N >= 3:\n                if verbose:\n                    print(\'Subplot %d of %d...\' % ((i+1), Np))\n                plt.subplot( N,N, N*pairs[i][1] + (pairs[i][0] + 1) )\n\n            # off-diagonal projection? (i.e. a true 2D projection)\n            if pairs[i][0] != pairs[i][1]:\n                # Plot the points picked by the sample\n                plt.plot( S[:,pairs[i][0]], S[:,pairs[i][1]], style)\n                axmax = k*m\n\n                # Mark the subspaces onto the figure\n                # (if few enough to fit reasonably on screen)\n                #\n                if k <= max_major_lines:\n                    for j in range(k):\n                        xy = -0.5 + j*m\n                        plt.plot( [xy, xy], [-0.5, axmax - 0.5], \'k\', linewidth=2.0 )\n                        plt.plot( [-0.5, axmax - 0.5], [xy, xy], \'k\', linewidth=2.0 )\n\n                # Mark bins (if few enough to fit reasonably on screen)\n                #\n                if k*m <= max_minor_lines:\n                    for j in range(k*m):\n                        xy = -0.5 + j\n                        plt.plot( [xy, xy], [-0.5, axmax - 0.5], \'k\')\n                        plt.plot( [-0.5, axmax - 0.5], [xy, xy], \'k\')\n\n                # Make a box around the area\n                plt.plot( [-0.5,         axmax - 0.5], [-0.5,        -0.5],         \'k\', \\\n                         linewidth=2.0  )\n                plt.plot( [-0.5,         axmax - 0.5], [axmax - 0.5, axmax - 0.5], \'k\', \\\n                         linewidth=2.0  )\n                plt.plot( [-0.5,         -0.5],        [-0.5,        axmax - 0.5], \'k\', \\\n                         linewidth=2.0  )\n                plt.plot( [axmax - 0.5,  axmax - 0.5],  [-0.5,       axmax - 0.5], \'k\', \\\n                         linewidth=2.0  )\n\n                # Set the axes so that the extreme indices just fit into the view\n                plt.axis(""equal"")\n                plt.axis( [-0.5, axmax-0.5, -0.5, axmax-0.5 ] )\n            else: # 1D projection\n                plt.plot( S[:,pairs[i][0]], np.zeros( [k*m] ), style)\n                plt.axis( [-0.5, axmax-0.5, -0.5, 0.5] )\n\n        # Label the variables.\n        #\n        # We only do this if the diagonal subplots are blank.\n        #\n        if N >= 3:\n            if not showdiag:\n                for i in range(N):\n                    plt.subplot(N,N, N*i+(i+1))\n                    my_label = \'Row: x = var %d\' % i\n                    plt.text(0.5,0.6, my_label, horizontalalignment=""center"", fontweight=""bold"")\n                    my_label = \'Col: y = var %d\' % i\n                    plt.text(0.5,0.4, my_label, horizontalalignment=""center"", fontweight=""bold"")\n                    plt.axis(""off"")\n        else:\n            plt.xlabel(\'Var 0\', fontweight=""bold"")\n            plt.ylabel(\'Var 1\', fontweight=""bold"")\n\n        if verbose:\n            print(\'Plotting done. Showing figure...\')\n\n        # show figures and enter gtk mainloop\n        plt.show()\n\n    return (S,m)\n'"
examples/wlsqm_example.py,84,"b'# -*- coding: utf-8 -*-\n#\n""""""Testing script for wlsqm, doubles as a usage example.\n\n-JJ 2016-11-10\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport time\n\nimport numpy as np\nimport sympy as sy\n\nimport scipy.spatial  # cKDTree\n\nimport matplotlib.pyplot as plt\nimport mpl_toolkits.mplot3d.axes3d as p3\n\ntry:\n    import wlsqm\nexcept ImportError:\n    import sys\n    sys.exit(""WLSQM not found; is it installed?"")\n\nimport sudoku_lhs\n\n\n# from various scripts, e.g. miniprojects/misc/tworods/main2.py\ndef axis_marginize(ax, epsx, epsy):\n    a = ax.axis()\n    w = a[1] - a[0]\n    h = a[3] - a[2]\n    ax.axis( [ a[0] - w*epsx, a[1] + w*epsx, a[2] - h*epsy, a[3] + h*epsy] )\n\n\n# from find_neighbors2.py\nclass SimpleTimer:\n    def __init__(self, label="""", n=None):\n        self.label = label\n        self.n     = n      # number of repetitions done inside the ""with..."" section (for averaging in timing info)\n\n    def __enter__(self):\n        self.t0 = time.time()\n        return self\n\n    def __exit__(self, errtype, errvalue, traceback):\n        dt         = time.time() - self.t0\n        identifier = (""%s"" % self.label) if len(self.label) else ""time taken: ""\n        avg        = ("", avg. %gs per run"" % (dt/self.n)) if self.n is not None else """"\n        print( ""%s%gs%s"" % (identifier, dt, avg) )\n\n\n# many simultaneous local models, 2D\n#\ndef testmany2d():\n    #########################\n    # config\n    #########################\n\n    ntasks = 8  # OpenMP parallelization\n\n    axislims = [0., 1., 0., 1.]  # [xmin, xmax, ymin, ymax], for plotting\n    nvis = 201  # number of visualization points per axis\n\n    expr    = sy.sympify(""sin(pi*x) * cos(pi*y)"")\n\n    points_per_axis = 100  # for point cloud generation\n\n    r      = 5e-2  # neighborhood radius\n    max_nk = 100   # maximum number of neighbor points to accept into each neighborhood (affects memory allocation)\n\n    knowns = 1  # function value is known\n\n    fit_order = 4\n    weighting_method = wlsqm.WEIGHT_CENTER\n\n    max_iter = 10  # for iterative fitting method\n\n    reps = 20  # for demonstration of solving multiple times using the same geometry\n\n    #########################\n    # the test itself\n    #########################\n\n    print()\n    print( ""="" * 79 )\n    print( ""many neighborhoods, 2D case"" )\n    print( ""="" * 79 )\n    print()\n\n    # create a stratified point cloud\n    print( ""generating sudoku sample"" )\n    with SimpleTimer(label=(""    done in "")) as s:\n        S,m = sudoku_lhs.sample(2, points_per_axis, 1)\n        bins_per_axis = m*points_per_axis\n        S = S / float(bins_per_axis - 1)  # scale the sample from [0, bins_per_axis-1]**2 to [0, 1]**2\n        npoints = len(S)\n        print( ""    %d points"" % (npoints) )\n\n    # index the point cloud for fast neighbor searching\n    print( ""indexing sample"" )\n    with SimpleTimer(label=(""    done in "")) as s:\n        tree = scipy.spatial.cKDTree( data=S )\n\n    # If this was an IBVP, we would here get the previous state of the unknown field.\n    #\n    # In this example, we just sample our function f().\n    #\n    lambdify_numpy_2d = lambda expr: sy.lambdify((""x"",""y""), expr, modules=""numpy"")  # SymPy expr --> lambda(x,y)\n    f                 = lambdify_numpy_2d(expr)\n    dfdx              = lambdify_numpy_2d(sy.diff(expr, ""x""))\n    dfdy              = lambdify_numpy_2d(sy.diff(expr, ""y""))\n\n    print( ""evaluating example function"" )\n    with SimpleTimer(label=(""    done in "")) as s:\n        no = wlsqm.number_of_dofs( dimension=2, order=fit_order )\n        fi = np.empty( (npoints,no), dtype=np.float64 )\n        fi[:,0] = f( S[:,0], S[:,1] )  # fi[i,0] contains the function value at point S[i,:]\n\n    # find the neighborhoods\n    print( ""generating neighborhoods for each point"" )\n    with SimpleTimer(label=(""    done in "")) as s:\n        hoods = np.zeros( (npoints,max_nk), dtype=np.int32 )  # neighbor point indices (pointing to rows in S[])\n        nk    = np.empty( (npoints,), dtype=np.int32 )        # number of neighbors, i.e. nk[i] is the number of actually used columns in hoods[i,:]\n        for i in range(npoints):\n            I = tree.query_ball_point( S[i], r )  # indices of neighbors of S[i] at distance <= r  (but also including S[i] itself!)\n            I = [ idx for idx in I if idx != i ]  # exclude S[i] itself\n            if len(I) > max_nk:\n                I = I[:max_nk]\n            I = np.array( I, dtype=np.int32 )\n            nk[i] = len(I)\n            hoods[i,:nk[i]] = I\n\n    # DEBUG\n    print( ""number of neighbors min = %g, avg = %g, max = %g"" % ( np.min(nk), np.mean(nk), np.max(nk) ) )\n    print( ""neighbor lists for each problem instance:"" )\n    print( hoods )\n    print( ""number of neighbors for each problem instance:"" )\n    print( nk )\n\n    # perform the fitting\n    print( ""fitting %d local surrogate models of order %d, driver mode (fit each model once)"" % (npoints, fit_order) )\n    fit_order_array = fit_order        * np.ones( (npoints,), dtype=np.int32 )\n    knowns_array    = knowns           * np.ones( (npoints,), dtype=np.int64 )\n    wm_array        = weighting_method * np.ones( (npoints,), dtype=np.int32 )\n    with SimpleTimer(label=(""    done in "")) as s:\n#        max_iterations_taken = wlsqm.fit_2D_many( xk=S[hoods], fk=fi[hoods,0], nk=nk,\n#                                                   xi=S, fi=fi,\n#                                                   sens=None, do_sens=False,\n#                                                   order=fit_order_array, knowns=knowns_array, weighting_method=wm_array,\n#                                                   debug=False )\n        max_iterations_taken = wlsqm.fit_2D_many_parallel( xk=S[hoods], fk=fi[hoods,0], nk=nk,\n                                                            xi=S, fi=fi,\n                                                            sens=None, do_sens=False,\n                                                            order=fit_order_array, knowns=knowns_array, weighting_method=wm_array,\n                                                            ntasks=ntasks, debug=False )\n#        max_iterations_taken = wlsqm.fit_2D_iterative_many( xk=S[hoods], fk=fi[hoods,0], nk=nk,\n#                                                             xi=S, fi=fi,\n#                                                             sens=None, do_sens=False,\n#                                                             order=fit_order_array, knowns=knowns_array, weighting_method=wm_array,\n#                                                             max_iter=max_iter, debug=False )\n#        max_iterations_taken = wlsqm.fit_2D_iterative_many_parallel( xk=S[hoods], fk=fi[hoods,0], nk=nk,\n#                                                            xi=S, fi=fi,\n#                                                            sens=None, do_sens=False,\n#                                                            order=fit_order_array, knowns=knowns_array, weighting_method=wm_array,\n#                                                            max_iter=max_iter, ntasks=ntasks, debug=False )\n\n    # Expert mode: allows solving multiple times (with new fk data) in the same geometry, performing the prepare step only once.\n    #\n    # This is especially good for a large number of repetitions with ALGO_BASIC, where a large majority of the computational cost comes from the prepare step.\n    #\n    # The total advantage is slightly smaller for a small number of repetitions with ALGO_ITERATIVE,\n    # since the iterative mode already uses this strategy internally (also when invoked in driver mode).\n    #\n    print( ""fitting %d local surrogate models of order %d, expert mode"" % (npoints, fit_order) )\n    print( ""    init"" )\n    with SimpleTimer(label=(""        done in "")) as s:\n        solver = wlsqm.ExpertSolver( dimension=2, nk=nk, order=fit_order_array, knowns=knowns_array, weighting_method=wm_array, algorithm=wlsqm.ALGO_BASIC, do_sens=False, max_iter=max_iter, ntasks=ntasks, debug=False )\n    print( ""    prepare"" )\n    with SimpleTimer(label=(""        done in "")) as s:\n        solver.prepare( xi=S, xk=S[hoods] )\n    print( ""    fit (each model %d times)"" % (reps) )\n    with SimpleTimer(label=(""        %d reps done in "" % reps), n=reps) as s:\n        for k in range(reps):\n            solver.solve( fk=fi[hoods,0], fi=fi, sens=None )\n\n    # DEBUG\n    print( ""max corrective iterations taken: %d"" % (max_iterations_taken) )\n    # see that we got the derivatives at each point\n    if fit_order > 0:  # no derivatives if piecewise constant fit\n        print( dfdx( S[:,0], S[:,1] ) - fi[:,1] )\n        print( dfdy( S[:,0], S[:,1] ) - fi[:,2] )\n\n    #########################\n    # plotting\n    #########################\n\n    xx   = np.linspace(axislims[0], axislims[1], nvis)\n    yy   = np.linspace(axislims[2], axislims[3], nvis)\n    X,Y  = np.meshgrid(xx, yy)\n    W    = f(X,Y)\n\n    shp = np.shape(X)\n    Xlin = np.reshape(X, -1)\n    Ylin = np.reshape(Y, -1)\n    x = np.empty( (len(Xlin), 2), dtype=np.float64 )\n    x[:,0] = Xlin\n    x[:,1] = Ylin\n    print( ""preparing to interpolate global model"" )\n    with SimpleTimer(label=(""    done in "")) as s:\n        solver.prep_interpolate()\n    print( ""interpolating global model to %d points"" % (len(Xlin)) )\n    with SimpleTimer(label=(""    done in "")) as s:\n        W2,dummy = solver.interpolate( x, mode=\'continuous\', r=r )  # slow, continuous\n#        W2,dummy = solver.interpolate( x, mode=\'nearest\' )  # fast, surprisingly accurate if a reasonable number of points (and continuous-looking although technically has jumps over Voronoi cell boundaries)\n    W2 = np.reshape( W2, shp )\n\n    # make 3d plot of the function\n    #\n    # see http://matplotlib.sourceforge.net/examples/mplot3d/lines3d_demo.html\n\n    fig = plt.figure(3, figsize=(12,12))\n    plt.clf()\n\n    # Axes3D has a tendency to underestimate how much space it needs; it draws its labels\n    # outside the window area in certain orientations.\n    #\n    # This causes the labels to be clipped, which looks bad. We prevent this by creating the axes\n    # in a slightly smaller rect (leaving a margin). This way the labels will show - outside the Axes3D,\n    # but still inside the figure window.\n    #\n    # The final touch is to set the window background to a matching white, so that the\n    # background of the figure appears uniform.\n    #\n    fig.patch.set_color( (1,1,1) )\n    fig.patch.set_alpha( 1.0 )\n    x0y0wh = [ 0.02, 0.02, 0.96, 0.96 ]  # left, bottom, width, height      (here as fraction of subplot area)\n\n#    # compute the corresponding figure coordinates for the 2x1 subplot layout\n#    x0y0wh[0] = 0.5 + 0.5*x0y0wh[0]  # left\n#    x0y0wh[2] = 0.5*x0y0wh[2]        # width\n\n    ax = p3.Axes3D(fig, rect=x0y0wh)\n\n    stride = max(1, (nvis-1)//10)  # pick a good-looking stride (for lines; we actually have more vertices, making a smoother-looking curve between the lines)\n    # use linewidth=0 to remove the wireframe if desired.\n#    surf = ax.plot_surface(X,Y,W, rstride=stride, cstride=stride, cmap=matplotlib.cm.Blues_r, clim=[fmin,fmax], linewidth=0.25, alpha=0.5)\n    ax.plot_wireframe(X,Y,W, rstride=stride, cstride=stride, color=\'k\', linewidth=0.5, linestyle=\'solid\')\n#        plt.colorbar(surf, shrink=0.5, aspect=5)\n#        plt.colorbar(surf, shrink=0.96)\n\n    # sampled points\n    if points_per_axis < 50:\n        ax.plot( S[:,0], S[:,1], f( S[:,0], S[:,1] ), linestyle=\'none\', marker=\'o\', markeredgecolor=\'r\', markerfacecolor=\'none\' )  # exact\n\n    # surrogate model (global, patched)\n    ax.plot_wireframe(X,Y,W2, rstride=stride, cstride=stride, color=\'r\', linewidth=0.5, linestyle=\'solid\')\n\n#    ax.view_init(20, -48)\n#    ax.view_init(18, -46)\n#    ax.view_init(18, -128)\n    ax.view_init(34, 140)\n\n    ax.axis(\'tight\')\n    ax.set_zlim(-1.01, 1.01)\n    plt.xlabel(\'$x$\')\n    plt.ylabel(\'$y$\')\n    ax.set_title(\'f(x,y)\')\n\n\n    print( ""    uninit"" )\n    with SimpleTimer(label=(""        done in "")) as s:\n        del solver\n\n\n# one local model, 3D\n#\ndef test3d():\n    #########################\n    # config\n    #########################\n\n    axislims = [0., 1., 0., 1.]  # [xmin, xmax, ymin, ymax], for plotting\n    nvis = 101  # number of visualization points per axis\n\n    # Let\'s manufacture a solution (for which we know the derivatives analytically):\n    #\n    expr    = sy.sympify(""sin(pi*x) * cos(pi*y) * exp(z)"")\n#    expr    = sy.sympify(""exp(x)*exp(y)*exp(z)"")\n#    expr    = sy.sympify(""1*x + 2*y + 3*z"")\n#    expr    = sy.sympify(""0 + 1*x + 2*y + 3*z + 4*x**2 + 5*x*y + 6*y**2 + 7*y*z + 8*z**2 + 9*x*z + 10*x**3 + 11*x**2*y + 12*x*y**2 + 13*y**3 + 14*y**2*z + 15*y*z**2 + 16*z**3 + 17*z**2*x + 18*z*x**2 + 19*x*y*z"")\n\n    noise_eps = 0#1e-3 # introduce this much Gaussian noise into each sampled function value (use 0. to turn off)\n\n    xi = np.array( (0.45, 0.25, 0.35) )  # point (x,y,z) where we wish to find the derivatives\n#    xi = np.array( (0., 0., 0.) )  # point (x,y,z) where we wish to find the derivatives\n\n    # Degree of the surrogate polynomial; a full polynomial of this order will be used.\n    #\n    # In the fit, when compared to the original function (if any is available),\n    # usually the highest order will be nonsense, and the lower orders will be pretty accurate.\n    #\n    # (I.e. the unfittable part seems to favor the highest order; which OTOH has the highest spatial frequency. Maybe there\'s something here?)\n    #\n    fit_order = 4  # 0 (constant), 1 (linear), 2 (quadratic), 3 (cubic) or 4 (quartic)\n\n#    weighting_method = wlsqm.WEIGHT_UNIFORM  # best overall fit for function values\n    weighting_method = wlsqm.WEIGHT_CENTER  # emphasize center to improve derivatives at the point xi\n\n    max_iter = 100  # maximum number of refinement iterations for iterative fitting\n\n    do_sens = False  # do sensitivity analysis of solution? ( d( fi[j] ) / d( fk[k] ) )\n\n    debug = False#True  # print row scaling and condition number information? (if True, then do_sens must be False; the combination with both True is not supported)\n\n    # Bitmask of what we know at point xi. In this example, just set the bits;\n    # the data (from expr) will be automatically inserted into fi[].\n    #\n    # See the constants b3_* in wlsqm.fitter.defs.\n    #\n    knowns = 1\n\n    # How many neighbor points to generate (to simulate the meshless \'grid\').\n    #\n    # At least n_unknowns  points are needed to make the model fitting work at all\n    # (but then the fit will be nonsensical, since it is possible to make the polynomial\n    #  pass through exactly those points).\n    #\n    # n_unknows + 1  is the first value that makes the fitting overdetermined,\n    # i.e. where the least-squares procedure starts providing any advantage.\n    #\n    # Here ""unknown"" means any element of fi[] not tagged as known in the ""knowns"" bitmask.\n    #\n    nk = 200  # used if grid_type == \'random\'\n\n    r  = 1e-1  # neighborhood radius\n\n#    grid_type = \'random\'\n    grid_type = \'stencil\'\n#    grid_type = \'sudoku\'\n\n    #########################\n    # the test itself\n    #########################\n\n    print()\n    print( ""="" * 79 )\n    print( ""3D case"" )\n    print( ""="" * 79 )\n    print()\n\n    print( ""expr: %s, xi = %s"" % (expr, xi) )\n\n    labels = [""F"",\n              ""DX"", ""DY"", ""DZ"",\n              ""DX2"", ""DXDY"", ""DY2"", ""DYDZ"", ""DZ2"", ""DXDZ"",\n              ""DX3"", ""DX2DY"", ""DXDY2"", ""DY3"", ""DY2DZ"", ""DYDZ2"", ""DZ3"", ""DXDZ2"", ""DX2DZ"", ""DXDYDZ"",\n              ""DX4"", ""DX3DY"", ""DX2DY2"", ""DXDY3"", ""DY4"", ""DY3DZ"", ""DY2DZ2"", ""DYDZ3"", ""DZ4"", ""DXDZ3"", ""DX2DZ2"", ""DX3DZ"", ""DX2DYDZ"", ""DXDY2DZ"", ""DXDYDZ2"" ]\n    print( ""legend: %s"" % (""\\t"".join(labels)) )\n    knowns_str = """"\n    for j in range(wlsqm.SIZE3):  # SIZE3 = maximum size of c matrix for 3D case\n        if j > 0:\n            knowns_str += \'\\t\'\n        if knowns & (1 << j):\n            knowns_str += labels[j]\n    print( ""knowns: %s"" % knowns_str )\n#    # http://stackoverflow.com/questions/699866/python-int-to-binary\n#    print ""knowns (mask): %s"" % format(knowns, \'010b\')[::-1]\n\n    print( ""surrogate order: %d"" % fit_order )\n\n    if noise_eps > 0.:\n        print( ""simulating noisy input with eps = %g"" % noise_eps )\n\n    # SymPy expr --> lambda(x,y)\n    lambdify_numpy_3d = lambda expr: sy.lambdify((""x"",""y"",""z""), expr, modules=""numpy"")\n    f          = lambdify_numpy_3d(expr)\n\n    dfdx       = lambdify_numpy_3d(sy.diff(expr, ""x""))\n    dfdy       = lambdify_numpy_3d(sy.diff(expr, ""y""))\n    dfdz       = lambdify_numpy_3d(sy.diff(expr, ""z""))\n\n    d2fdx2     = lambdify_numpy_3d(sy.diff(expr, ""x"", 2))\n    d2fdxdy    = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x""), ""y"" ))\n    d2fdy2     = lambdify_numpy_3d(sy.diff(expr, ""y"", 2))\n    d2fdydz    = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""y""), ""z"" ))\n    d2fdz2     = lambdify_numpy_3d(sy.diff(expr, ""z"", 2))\n    d2fdxdz    = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x""), ""z"" ))\n\n    d3fdx3     = lambdify_numpy_3d(sy.diff(expr, ""x"", 3))\n    d3fdx2dy   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x"", 2), ""y"" ))\n    d3fdxdy2   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x""), ""y"", 2 ))\n    d3fdy3     = lambdify_numpy_3d(sy.diff(expr, ""y"", 3))\n    d3fdy2dz   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""y"", 2), ""z"" ))\n    d3fdydz2   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""y""), ""z"", 2 ))\n    d3fdz3     = lambdify_numpy_3d(sy.diff(expr, ""z"", 3))\n    d3fdxdz2   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x""), ""z"", 2 ))\n    d3fdx2dz   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x"", 2), ""z"" ))\n    d3fdxdydz  = lambdify_numpy_3d(sy.diff( sy.diff( sy.diff(expr, ""x""), ""y""), ""z""))\n\n    d4fdx4     = lambdify_numpy_3d(sy.diff(expr, ""x"", 4))\n    d4fdx3dy   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x"", 3), ""y"" ))\n    d4fdx2dy2  = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x"", 2), ""y"", 2 ))\n    d4fdxdy3   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x""), ""y"", 3 ))\n    d4fdy4     = lambdify_numpy_3d(sy.diff(expr, ""y"", 4))\n    d4fdy3dz   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""y"", 3), ""z"" ))\n    d4fdy2dz2  = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""y"", 2), ""z"" , 2))\n    d4fdydz3   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""y""), ""z"", 3 ))\n    d4fdz4     = lambdify_numpy_3d(sy.diff(expr, ""z"", 4))\n    d4fdxdz3   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x""), ""z"", 3 ))\n    d4fdx2dz2  = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x"", 2), ""z"" , 2))\n    d4fdx3dz   = lambdify_numpy_3d(sy.diff( sy.diff(expr, ""x"", 3), ""z"" ))\n    d4fdx2dydz = lambdify_numpy_3d(sy.diff( sy.diff( sy.diff(expr, ""x"", 2), ""y""), ""z""))\n    d4fdxdy2dz = lambdify_numpy_3d(sy.diff( sy.diff( sy.diff(expr, ""x""), ""y"", 2), ""z""))\n    d4fdxdydz2 = lambdify_numpy_3d(sy.diff( sy.diff( sy.diff(expr, ""x""), ""y""), ""z"", 2))\n\n    # list so we can refer to the functions by indices\n    funcs = ( f,\n              dfdx, dfdy, dfdz,\n              d2fdx2, d2fdxdy, d2fdy2, d2fdydz, d2fdz2, d2fdxdz,\n              d3fdx3, d3fdx2dy, d3fdxdy2, d3fdy3, d3fdy2dz, d3fdydz2, d3fdz3, d3fdxdz2, d3fdx2dz, d3fdxdydz,\n              d4fdx4, d4fdx3dy, d4fdx2dy2, d4fdxdy3, d4fdy4, d4fdy3dz, d4fdy2dz2, d4fdydz3, d4fdz4, d4fdxdz3, d4fdx2dz2, d4fdx3dz, d4fdx2dydz, d4fdxdy2dz, d4fdxdydz2\n            )\n\n    # create neighbor points xk around the point xi - this simulates our meshless \'grid\'\n    #\n    if grid_type == \'random\':\n        xk = np.tile(xi, (nk,1)) + r*2.*( np.random.sample( (nk,3) ) - 0.5 )\n\n    elif grid_type == \'stencil\':\n        points_per_axis = max(1,fit_order) + 1\n\n        tt = np.linspace(-1., 1., points_per_axis)\n        X,Y,Z = np.meshgrid(tt,tt,tt)\n        X = np.reshape(X, -1)\n        Y = np.reshape(Y, -1)\n        Z = np.reshape(Z, -1)\n\n        # convert to list of (x,y) pairs, rejecting the point (0,0) (that represents xi itself), if present\n        point_list = [ (x,y,z) for x,y,z in zip(X,Y,Z) if (x,y,z) != (0.,0.,0.) ]\n\n        nk = len(point_list)\n        xk = np.array( [ ( xi[0] + r*p[0], xi[1] + r*p[1], xi[2] + r*p[2] ) for p in point_list ] )\n\n    elif grid_type == \'sudoku\':\n        points_per_axis = max(1,fit_order) + 1\n\n        S,m = sudoku_lhs.sample(3, points_per_axis, 1)\n        bins_per_axis = points_per_axis*m\n        S = S / float(bins_per_axis - 1)  # scale the sample from [0, bins_per_axis-1]**3 to [0, 1]**3\n        S = 2. * (S - 0.5) # move to [-1, 1]**3\n\n        # If points_per_axis is odd, a bin exists exactly at the center, so Sudoku LHS may place one point there.\n        #\n        # This would coincide with the point xi, so it is not useful, because we want the neighbors to be\n        # distinct from xi.\n        #\n        # Thus, for odd points_per_axis, filter the sample to remove the point at the origin if it happens to be there.\n        # Note that because of the scaling, the coordinates might not be exactly zero. We HACK by checking numerical equality;\n        # a proper solution would be to filter S before the conversion to float.\n        #\n        if points_per_axis % 2 == 1:\n            point_list = S.tolist()\n            oldlen = len(point_list)\n            point_list = [item for item in point_list if not (abs(item[0]) < 1e-8 and abs(item[1]) < 1e-8 and abs(item[2]) < 1e-8)]\n            S = np.array(point_list)\n            if len(point_list) < oldlen:\n                print( ""Sudoku LHS sampled the point at the origin; discarding it from the sample"" )\n\n        nk = len(S)\n        xk = np.tile(xi, (nk,1)) + r*S\n\n    else:\n        raise ValueError(""Unknown grid_type \'%s\'; valid: \'random\', \'stencil\', \'sudoku\'"" % grid_type)\n\n    # sample the function values at the neighbor points xk (these are used to fit the surrogate model)\n    #\n    sample_also_xi_str = "" (and xi itself)"" if knowns & 1 else """"\n    print( ""sampling %d points%s"" % (nk, sample_also_xi_str) )\n    fk = np.empty( (nk,), dtype=np.float64 )\n    for k in range(nk):\n        fk[k] = f( xk[k,0], xk[k,1], xk[k,2] )\n\n    # simulate numerical errors by adding noise to the neighbor point function value samples\n    #\n    if noise_eps > 0.:\n#        # uniform\n#        noise = noise_eps*2.*(np.random.sample( np.shape(fk) ) - 0.5)\n\n        # Gaussian, truncated\n        mu    = 0.0\n        sigma = noise_eps / 3.\n        noise = np.random.normal( loc=mu, scale=sigma, size=np.shape(fk) )\n        noise[noise < -3.*sigma] = -3.*sigma\n        noise[noise > +3.*sigma] = +3.*sigma\n\n        fk += noise\n\n    # set knowns *at point xi*\n    #\n    # we use nan to spot unfilled entries\n    fi = np.nan * np.empty( (wlsqm.SIZE3,), dtype=np.float64 )  # F, DX, DY, DZ, ... at point xi\n    for d in range(wlsqm.SIZE3):\n        if knowns & (1 << d):\n            fi[d] = funcs[d]( xi[0], xi[1], xi[2] )  # fill in the known value  # TODO: add noise here too?\n\n    # allocate array for sensitivity data\n    #\n    # for output; sens[k,j] = d(fi[j])/d(fk[k]) if f[i] unknown\n    #                         nan if fi[j] known\n    #\n    # Note that if order=1, the part on second derivatives is not touched (so that an (nk,3) array\n    # is valid); hence we pre-fill by nan.\n    #\n    if do_sens:\n        sens = np.nan * np.empty( (nk,wlsqm.SIZE3), dtype=np.float64 )\n    else:\n        sens = None\n\n    # fit the surrogate model (see wlsqm.fitter.simple for detailed documentation)\n    #\n    if debug:\n        print()  # blank line before debug info\n\n    iterations_taken = wlsqm.fit_3D_iterative( xk, fk, xi, fi, sens, do_sens=do_sens, order=fit_order, knowns=knowns, debug=debug, weighting_method=weighting_method, max_iter=max_iter )\n#    iterations_taken = wlsqm.fit_3D( xk, fk, xi, fi, sens, do_sens=do_sens, order=fit_order, knowns=knowns, debug=debug, weighting_method=weighting_method )\n\n    print( ""refinement iterations taken: %d"" % iterations_taken )\n\n    # check exact solution and relative error\n    #\n    exact = np.array( [func( xi[0], xi[1], xi[2] ) for func in funcs] )\n    err   = (fi - exact)\n\n    print()\n    print( ""derivatives at xi:"" )\n    print( ""exact:"" )\n    print( exact )\n    print( ""wlsqm solution:"" )\n    print( fi )\n    if do_sens:\n        print( ""sensitivity:"" )\n        print( sens )\n    print( ""abs error:"" )\n    print( err )\n    print( ""rel error:"" )\n    print( (err / exact) )\n\n    #########################\n    # plotting\n    #########################\n\n    # surrogate model - the returned fi[] are actually the coefficients of a polynomial\n    model    = wlsqm.lambdify_fit( xi, fi, dimension=3, order=fit_order )  # lambda x,y : ...\n\n    print()\n    print( ""function values at neighbor points:"" )\n    fxk =     f( xk[:,0], xk[:,1], xk[:,2] )\n    mxk = model( xk[:,0], xk[:,1], xk[:,2] )\n    print( ""exact:"" )\n    print( fxk )\n    print( ""wlsqm solution:"" )\n    print( mxk )\n    print( ""abs error:"" )\n    errf = mxk - fxk\n    print( errf )\n    print( ""rel error:"" )\n    print( (errf / fxk) )\n\n    # comparison\n    xx2        = np.linspace(xi[0] - r, xi[0] + r, nvis)\n    yy2        = np.linspace(xi[1] - r, xi[1] + r, nvis)\n    zz2        = np.linspace(xi[2] - r, xi[2] + r, nvis)\n    X2,Y2,Z2   = np.meshgrid(xx2, yy2, zz2)\n    W2         = model(X2,Y2,Z2)\n    W3         =     f(X2,Y2,Z2)\n    diff       = W2 - W3  # fitted - exact\n    idx        = np.argmax(np.abs( diff ))\n    diff_lin   = np.reshape(diff, -1)\n    W3_lin     = np.reshape(W3, -1)\n    maxerr_abs = diff_lin[idx]\n    maxerr_rel = diff_lin[idx] / W3_lin[idx]\n    print( ""largest absolute total fit error (over the domain of the fit, not just the neighbor points):"" )\n    print( ""absolute: %g"" % (maxerr_abs) )\n    print( ""relative: %g"" % (maxerr_rel) )\n\n\n# one local model, 2D\n#\ndef test2d():\n    #########################\n    # config\n    #########################\n\n    axislims = [0., 1., 0., 1.]  # [xmin, xmax, ymin, ymax], for plotting\n    nvis = 101  # number of visualization points per axis\n\n    # Let\'s manufacture a solution (for which we know the derivatives analytically):\n    #\n#    expr     = sy.sympify(""2*x + 3*y"")\n#    expr     = sy.sympify(""0.2*x + 0.3*y"")\n#    expr     = sy.sympify(""1.0 + 2*x + 3*y + 4*x**2 + 5*x*y + 6*y**2"")\n#    expr     = sy.sympify(""0.1 + 0.2*x + 0.3*y + 0.4*x**2 + 0.5*x*y + 0.6*y**2"")\n#    expr    = sy.sympify(""sin(pi*x)"")\n    expr    = sy.sympify(""sin(pi*x) * cos(pi*y)"")\n#    expr    = sy.sympify(""exp(x) * 1/(1 + y) - 1"")\n#    expr    = sy.sympify(""exp(x) * log(1 + y)"")\n#    expr     = sy.sympify(""1.0 + 2*x + 3*y + 4*x**2 + 5*x*y + 6*y**2 + 7*x**3 + 8*y**4"")\n\n    noise_eps = 0#1e-3 # introduce this much Gaussian noise into each sampled function value (use 0. to turn off)\n\n    xi = np.array( (0.45, 0.25) )  # point (x,y) where we wish to find the derivatives\n\n    # Degree of the surrogate polynomial; a full polynomial of this order will be used.\n    #\n    # In the fit, when compared to the original function (if any is available),\n    # usually the highest order will be nonsense, and the lower orders will be pretty accurate.\n    #\n    # (I.e. the unfittable part seems to favor the highest order; which OTOH has the highest spatial frequency. Maybe there\'s something here?)\n    #\n    fit_order = 4  # 0 (constant), 1 (linear), 2 (quadratic), 3 (cubic) or 4 (quartic)\n\n#    weighting_method = wlsqm.WEIGHT_UNIFORM  # best overall fit for function values\n    weighting_method = wlsqm.WEIGHT_CENTER  # emphasize center to improve derivatives at the point xi\n\n    max_iter = 100  # maximum number of refinement iterations for iterative fitting\n\n    do_sens = False  # do sensitivity analysis of solution? ( d( fi[j] ) / d( fk[k] ) )\n\n    debug = False#True  # print row scaling and condition number information? (if True, then do_sens must be False; the combination with both True is not supported)\n\n    # Bitmask of what we know at point xi. In this example, just set the bits;\n    # the data (from expr) will be automatically inserted into fi[].\n    #\n    # Bits from least sig. to most sig.: F, DX, DY, DX2, DXDY, DY2, ... (see ordering of ""labels"", below)\n    #\n    knowns = 1\n\n    # How many neighbor points to generate (to simulate the meshless \'grid\').\n    #\n    # At least n_unknowns  points are needed to make the model fitting work at all\n    # (but then the fit will be nonsensical, since it is possible to make the polynomial\n    #  pass through exactly those points).\n    #\n    # n_unknows + 1  is the first value that makes the fitting overdetermined,\n    # i.e. where the least-squares procedure starts providing any advantage.\n    #\n    # Here ""unknown"" means any element of fi[] not tagged as known in the ""knowns"" bitmask.\n    #\n    nk = 24  # used if grid_type == \'random\'\n\n    r  = 1e-1  # neighborhood radius\n\n#    grid_type = \'random\'\n#    grid_type = \'stencil\'\n    grid_type = \'sudoku\'\n\n    #########################\n    # the test itself\n    #########################\n\n    print()\n    print( ""="" * 79 )\n    print( ""2D case"" )\n    print( ""="" * 79 )\n    print()\n\n    print( ""expr: %s, xi = %s"" % (expr, xi) )\n\n    labels = [""F"", ""DX"", ""DY"", ""DX2"", ""DXDY"", ""DY2"", ""DX3"", ""DX2DY"", ""DXDY2"", ""DY3"", ""DX4"", ""DX3DY"", ""DX2DY2"", ""DXDY3"", ""DY4""]\n    print( ""legend: %s"" % (""\\t"".join(labels)) )\n    knowns_str = """"\n    for j in range(wlsqm.SIZE2):  # SIZE2 = maximum size of c matrix for 2D case\n        if j > 0:\n            knowns_str += \'\\t\'\n        if knowns & (1 << j):\n            knowns_str += labels[j]\n    print( ""knowns: %s"" % knowns_str )\n#    # http://stackoverflow.com/questions/699866/python-int-to-binary\n#    print (""knowns (mask): %s"" % format(knowns, \'010b\')[::-1] )\n\n    print( ""surrogate order: %d"" % fit_order )\n\n    if noise_eps > 0.:\n        print( ""simulating noisy input with eps = %g"" % noise_eps )\n\n    # SymPy expr --> lambda(x,y)\n    lambdify_numpy_2d = lambda expr: sy.lambdify((""x"",""y""), expr, modules=""numpy"")\n    f         = lambdify_numpy_2d(expr)\n    dfdx      = lambdify_numpy_2d(sy.diff(expr, ""x""))\n    dfdy      = lambdify_numpy_2d(sy.diff(expr, ""y""))\n    d2fdx2    = lambdify_numpy_2d(sy.diff(expr, ""x"", 2))\n    d2fdxdy   = lambdify_numpy_2d(sy.diff( sy.diff(expr, ""x""), ""y"" ))\n    d2fdy2    = lambdify_numpy_2d(sy.diff(expr, ""y"", 2))\n    d3fdx3    = lambdify_numpy_2d(sy.diff(expr, ""x"", 3))\n    d3fdx2dy  = lambdify_numpy_2d(sy.diff( sy.diff(expr, ""x"", 2), ""y"" ))\n    d3fdxdy2  = lambdify_numpy_2d(sy.diff( sy.diff(expr, ""x""), ""y"", 2 ))\n    d3fdy3    = lambdify_numpy_2d(sy.diff(expr, ""y"", 3))\n    d4fdx4    = lambdify_numpy_2d(sy.diff(expr, ""x"", 4))\n    d4fdx3dy  = lambdify_numpy_2d(sy.diff( sy.diff(expr, ""x"", 3), ""y"" ))\n    d4fdx2dy2 = lambdify_numpy_2d(sy.diff( sy.diff(expr, ""x"", 2), ""y"", 2 ))\n    d4fdxdy3  = lambdify_numpy_2d(sy.diff( sy.diff(expr, ""x""), ""y"", 3 ))\n    d4fdy4    = lambdify_numpy_2d(sy.diff(expr, ""y"", 4))\n    funcs = (f, dfdx, dfdy, d2fdx2, d2fdxdy, d2fdy2, d3fdx3, d3fdx2dy, d3fdxdy2, d3fdy3, d4fdx4, d4fdx3dy, d4fdx2dy2, d4fdxdy3, d4fdy4)  # list so we can refer to the functions by indices\n\n    # create neighbor points xk around the point xi - this simulates our meshless \'grid\'\n    #\n    if grid_type == \'random\':\n        xk = np.tile(xi, (nk,1)) + r*2.*( np.random.sample( (nk,2) ) - 0.5 )\n\n    elif grid_type == \'stencil\':\n        points_per_axis = max(1,fit_order) + 1\n\n        tt = np.linspace(-1., 1., points_per_axis)\n        X,Y = np.meshgrid(tt,tt)\n        X = np.reshape(X, -1)\n        Y = np.reshape(Y, -1)\n\n        # convert to list of (x,y) pairs, rejecting the point (0,0) (that represents xi itself), if present\n        point_list = [ (x,y) for x,y in zip(X,Y) if (x,y) != (0.,0.) ]\n\n        nk = len(point_list)\n        xk = np.array( [ ( xi[0] + r*p[0], xi[1] + r*p[1] ) for p in point_list ] )\n\n    elif grid_type == \'sudoku\':\n        points_per_axis = max(1,fit_order) + 1\n\n        S,m = sudoku_lhs.sample(2, points_per_axis, 1)\n        bins_per_axis = points_per_axis*m\n        S = S / float(bins_per_axis - 1)  # scale the sample from [0, bins_per_axis-1]**2 to [0, 1]**2\n        S = 2. * (S - 0.5) # move to [-1, 1]**2\n\n        # If points_per_axis is odd, a bin exists exactly at the center, so Sudoku LHS may place one point there.\n        #\n        # This would coincide with the point xi, so it is not useful, because we want the neighbors to be\n        # distinct from xi.\n        #\n        # Thus, for odd points_per_axis, filter the sample to remove the point at the origin if it happens to be there.\n        # Note that because of the scaling, the coordinates might not be exactly zero. We HACK by checking numerical equality;\n        # a proper solution would be to filter S before the conversion to float.\n        #\n        if points_per_axis % 2 == 1:\n            point_list = S.tolist()\n            oldlen = len(point_list)\n            point_list = [ item for item in point_list if not (abs(item[0]) < 1e-8 and abs(item[1]) < 1e-8) ]\n            S = np.array(point_list)\n            if len(point_list) < oldlen:\n                print( ""Sudoku LHS sampled the point at the origin; discarding it from the sample"" )\n\n        nk = len(S)\n        xk = np.tile(xi, (nk,1)) + r*S\n\n    else:\n        raise ValueError(""Unknown grid_type \'%s\'; valid: \'random\', \'stencil\', \'sudoku\'"" % grid_type)\n\n    # sample the function values at the neighbor points xk (these are used to fit the surrogate model)\n    #\n    sample_also_xi_str = "" (and xi itself)"" if knowns & 1 else """"\n    print( ""sampling %d points%s"" % (nk, sample_also_xi_str) )\n    fk = np.empty( (nk,), dtype=np.float64 )\n    for k in range(nk):\n        fk[k] = f( xk[k,0], xk[k,1] )\n\n    # simulate numerical errors by adding noise to the neighbor point function value samples\n    #\n    if noise_eps > 0.:\n#        # uniform\n#        noise = noise_eps*2.*(np.random.sample( np.shape(fk) ) - 0.5)\n\n        # Gaussian, truncated\n        mu    = 0.0\n        sigma = noise_eps / 3.\n        noise = np.random.normal( loc=mu, scale=sigma, size=np.shape(fk) )\n        noise[noise < -3.*sigma] = -3.*sigma\n        noise[noise > +3.*sigma] = +3.*sigma\n\n        fk += noise\n\n    # set knowns *at point xi*\n    #\n    # we use nan to spot unfilled entries\n    fi = np.nan * np.empty( (wlsqm.SIZE2,), dtype=np.float64 )  # F, DX, DY, DX2, DXDY, DY2, DX3, DX2DY, DXDY2, DY3 at point xi\n    for d in range(wlsqm.SIZE2):\n        if knowns & (1 << d):\n            fi[d] = funcs[d]( xi[0], xi[1] )  # fill in the known value  # TODO: add noise here too?\n\n    # allocate array for sensitivity data\n    #\n    # for output; sens[k,j] = d(fi[j])/d(fk[k]) if f[i] unknown\n    #                         nan if fi[j] known\n    #\n    # Note that if order=1, the part on second derivatives is not touched (so that an (nk,3) array\n    # is valid); hence we pre-fill by nan.\n    #\n    if do_sens:\n        sens = np.nan * np.empty( (nk,wlsqm.SIZE2), dtype=np.float64 )\n    else:\n        sens = None\n\n    # fit the surrogate model (see wlsqm.fitter.simple for detailed documentation)\n    #\n    if debug:\n        print()  # blank line before debug info\n    iterations_taken = wlsqm.fit_2D_iterative( xk, fk, xi, fi, sens, do_sens=do_sens, order=fit_order, knowns=knowns, debug=debug, weighting_method=weighting_method, max_iter=max_iter )\n    print( ""refinement iterations taken: %d"" % iterations_taken )\n\n    # check exact solution and relative error\n    #\n    exact = np.array( [func( xi[0], xi[1] ) for func in funcs] )\n    err   = (fi - exact)\n\n    print()\n    print( ""derivatives at xi:"" )\n    print( ""exact:"" )\n    print( exact )\n    print( ""wlsqm solution:"" )\n    print( fi )\n    if do_sens:\n        print( ""sensitivity:"" )\n        print( sens )\n    print( ""abs error:"" )\n    print( err )\n    print( ""rel error:"" )\n    print( (err / exact) )\n\n    #########################\n    # plotting\n    #########################\n\n    xx   = np.linspace(axislims[0], axislims[1], nvis)\n    yy   = np.linspace(axislims[2], axislims[3], nvis)\n    X,Y  = np.meshgrid(xx, yy)\n    W    = f(X,Y)\n\n    # surrogate model - the returned fi[] are actually the coefficients of a polynomial\n    model = wlsqm.lambdify_fit( xi, fi, dimension=2, order=fit_order )  # lambda x,y : ...\n    xx2   = np.linspace(xi[0] - r, xi[0] + r, nvis)\n    yy2   = np.linspace(xi[1] - r, xi[1] + r, nvis)\n    X2,Y2 = np.meshgrid(xx2, yy2)\n    W2    = model(X2,Y2)\n\n#    # It is also possible to interpolate the model using the C API wrapper directly.\n#    # The result is exactly the same; sometimes this API may be more convenient.\n#    #\n#    # Note that for the C API, the points x to which to interpolate the model must be formatted as x[k,:] = (xk,yk).\n#    #\n#    shp = np.shape(X2)\n#    X2lin = np.reshape(X2, -1)\n#    Y2lin = np.reshape(Y2, -1)\n#    temp_x = np.array( [ (x,y) for x,y in zip(X2lin,Y2lin) ] )\n#    out = wlsqm.interpolate_fit( xi, fi, dimension=2, order=fit_order, x=temp_x )\n#    out = np.reshape( out, shp )\n#    print()\n#    print( ""difference between Python and C API model interpolation:"" )\n#    print( out - W2 )  # should be close to zero\n\n    print()\n    print( ""function values at neighbor points:"" )\n    fxk = f( xk[:,0], xk[:,1] )\n    mxk = model( xk[:,0], xk[:,1] )\n    print( ""exact:"" )\n    print( fxk )\n    print( ""wlsqm solution:"" )\n    print( mxk )\n    print( ""abs error:"" )\n    errf = mxk - fxk\n    print( errf )\n    print( ""rel error:"" )\n    print( (errf / fxk) )\n\n    # comparison\n    W3   = f(X2,Y2)\n    diff = W2 - W3  # fitted - exact\n    idx  = np.argmax(np.abs( diff ))\n    diff_lin = np.reshape(diff, -1)\n    W3_lin   = np.reshape(W3, -1)\n    maxerr_abs = diff_lin[idx]\n    maxerr_rel = diff_lin[idx] / W3_lin[idx]\n    print( ""largest absolute total fit error (over the domain of the fit, not just the neighbor points):"" )\n    print( ""absolute: %g"" % (maxerr_abs) )\n    print( ""relative: %g"" % (maxerr_rel) )\n\n    fig = plt.figure(2, figsize=(12,6))  # for 2x1 subplots\n#    fig = plt.figure(2, figsize=(12,12))\n    fig.clf()\n\n    ax = plt.subplot(1,2, 1)\n\n    ax.plot( (xx[0],  xx[-1]), (yy[0],  yy[0]),  \'k-\' )\n    ax.plot( (xx[-1], xx[-1]), (yy[0],  yy[-1]), \'k-\' )\n    ax.plot( (xx[0],  xx[-1]), (yy[-1], yy[-1]), \'k-\' )\n    ax.plot( (xx[0],  xx[0]),  (yy[0],  yy[-1]), \'k-\' )\n\n    ax.plot( xk[:,0], xk[:,1], linestyle=\'none\', marker=\'o\', markeredgecolor=\'r\', markerfacecolor=\'none\' )\n    ax.plot( (xi[0] - r, xi[0] + r), (xi[1] - r, xi[1] - r), \'r-\' )\n    ax.plot( (xi[0] + r, xi[0] + r), (xi[1] - r, xi[1] + r), \'r-\' )\n    ax.plot( (xi[0] - r, xi[0] + r), (xi[1] + r, xi[1] + r), \'r-\' )\n    ax.plot( (xi[0] - r, xi[0] - r), (xi[1] - r, xi[1] + r), \'r-\' )\n    ax.plot( (xi[0],), (xi[1],), linestyle=\'none\', marker=\'x\', markeredgecolor=\'k\', markerfacecolor=\'none\' )\n    plt.axis(\'tight\')\n    axis_marginize(ax, 0.02, 0.02)\n    plt.grid(b=True, which=\'both\')\n    plt.xlabel(\'x\')\n    plt.ylabel(\'y\')\n    plt.subplot(1,2, 2)\n\n    # make 3d plot of the function\n    #\n    # see http://matplotlib.sourceforge.net/examples/mplot3d/lines3d_demo.html\n\n    # Axes3D has a tendency to underestimate how much space it needs; it draws its labels\n    # outside the window area in certain orientations.\n    #\n    # This causes the labels to be clipped, which looks bad. We prevent this by creating the axes\n    # in a slightly smaller rect (leaving a margin). This way the labels will show - outside the Axes3D,\n    # but still inside the figure window.\n    #\n    # The final touch is to set the window background to a matching white, so that the\n    # background of the figure appears uniform.\n    #\n    fig.patch.set_color( (1,1,1) )\n    fig.patch.set_alpha( 1.0 )\n    x0y0wh = [ 0.02, 0.02, 0.96, 0.96 ]  # left, bottom, width, height      (here as fraction of subplot area)\n\n    # compute the corresponding figure coordinates for the 2x1 subplot layout\n    x0y0wh[0] = 0.5 + 0.5*x0y0wh[0]  # left\n    x0y0wh[2] = 0.5*x0y0wh[2]        # width\n\n    ax = p3.Axes3D(fig, rect=x0y0wh)\n\n    stride = max(1, (nvis-1)//10)  # pick a good-looking stride (for lines; we actually have more vertices, making a smoother-looking curve between the lines)\n    # use linewidth=0 to remove the wireframe if desired.\n#    surf = ax.plot_surface(X,Y,W, rstride=stride, cstride=stride, cmap=matplotlib.cm.Blues_r, clim=[fmin,fmax], linewidth=0.25, alpha=0.5)\n    ax.plot_wireframe(X,Y,W, rstride=stride, cstride=stride, color=\'k\', linewidth=0.5, linestyle=\'solid\')\n#        plt.colorbar(surf, shrink=0.5, aspect=5)\n#        plt.colorbar(surf, shrink=0.96)\n\n    # sampled points\n    if noise_eps > 0.:\n        ax.plot( xk[:,0], xk[:,1], f( xk[:,0], xk[:,1] ), linestyle=\'none\', marker=\'o\', markeredgecolor=\'k\', markerfacecolor=\'none\' )  # exact\n        ax.plot( xk[:,0], xk[:,1], fk[:], linestyle=\'none\', marker=\'o\', markeredgecolor=\'r\', markerfacecolor=\'none\' )  # including noise\n    else:\n        ax.plot( xk[:,0], xk[:,1], f( xk[:,0], xk[:,1] ), linestyle=\'none\', marker=\'o\', markeredgecolor=\'r\', markerfacecolor=\'none\' )  # exact\n\n    # surrogate model\n    ax.plot_wireframe(X2,Y2,W2, rstride=stride, cstride=stride, color=\'r\', linewidth=0.5, linestyle=\'solid\')\n\n    # point xi\n    ax.plot( (xi[0],), (xi[1],), f( xi[0], xi[1] ), linestyle=\'none\', marker=\'x\', markeredgecolor=\'k\', markerfacecolor=\'none\' )\n\n#    ax.view_init(20, -48)\n#    ax.view_init(18, -46)\n#    ax.view_init(18, -128)\n    ax.view_init(34, 140)\n\n    ax.axis(\'tight\')\n    ax.set_zlim(-1.01, 1.01)\n    plt.xlabel(\'$x$\')\n    plt.ylabel(\'$y$\')\n    ax.set_title(\'f(x,y)\')\n\n\n# one local model, 1D\n#\ndef test1d():\n    #########################\n    # config\n    #########################\n\n    axislims = [0., 1., 0., 1.]  # [xmin, xmax, ymin, ymax], for plotting\n    nvis = 101  # number of visualization points\n\n    # Let\'s manufacture a solution (for which we know the derivatives analytically):\n    #\n#    expr     = sy.sympify(""2*x"")\n#    expr     = sy.sympify(""0.2*x"")\n#    expr     = sy.sympify(""1.0 + 2*x + 4*x**2"")\n#    expr     = sy.sympify(""0.1 + 0.2*x + 0.4*x**2"")\n    expr     = sy.sympify(""sin(pi*x)"")\n#    expr     = sy.sympify(""1 / (1 + x)"")\n#    expr     = sy.sympify(""exp(x)"")\n#    expr     = sy.sympify(""log(1 + x)"")\n#    expr     = sy.sympify(""1.0 + 2*x + 4*x**2 + 7*x**3"")\n\n    noise_eps = 0#1e-3  # introduce this much Gaussian noise into each sampled function value (use 0. to turn off)\n\n    xi = 0.45  # point x where we wish to find the derivatives\n\n    # Degree of the surrogate polynomial.\n    #\n    # In the fit, when compared to the original function (if any is available),\n    # usually the highest order will be nonsense, and the lower orders will be pretty accurate.\n    #\n    fit_order = 4  # 0 (constant), 1 (linear), 2 (quadratic), 3 (cubic) or 4 (quartic)\n\n#    weighting_method = wlsqm.WEIGHT_UNIFORM  # best overall fit for function values\n    weighting_method = wlsqm.WEIGHT_CENTER  # emphasize center to improve derivatives at the point xi\n\n    max_iter = 100  # maximum number of refinement iterations for iterative fitting\n\n    do_sens = False  # do sensitivity analysis of solution? ( d( fi[j] ) / d( fk[k] ) )\n\n    debug = False#True  # print row scaling and condition number information? (if True, then do_sens must be False; the combination with both True is not supported)\n\n    # Bitmask of what we know at point xi. In this example, just set the bits;\n    # the data (from expr) will be automatically inserted into fi[].\n    #\n    # Bits from least sig. to most sig.: F, DX, DX2, DX3, DX4\n    #\n    knowns = 1\n\n    # How many neighbor points to generate (to simulate the meshless \'grid\').\n    #\n    # At least n_unknowns  points are needed to make the model fitting work at all\n    # (but then the fit will be nonsensical, since it is possible to make the polynomial\n    #  pass through exactly those points).\n    #\n    # n_unknows + 1  is the first value that makes the fitting overdetermined,\n    # i.e. where the least-squares procedure starts providing any advantage.\n    #\n    # Here ""unknown"" means any element of fi[] not tagged as known in the ""knowns"" bitmask.\n    #\n    nk = 7  # used if grid_type == \'random\'\n\n    r  = 1e-1  # neighborhood radius\n\n#    grid_type = \'random\'\n    grid_type = \'stencil\'\n\n    #########################\n    # the test itself\n    #########################\n\n    print()\n    print( ""="" * 79 )\n    print( ""1D case"" )\n    print( ""="" * 79 )\n    print()\n\n    print( ""expr: %s, xi = %s"" % (expr, xi) )\n    labels = [""F"", ""DX"", ""DX2"", ""DX3"", ""DX4""]\n    print( ""legend: %s"" % (""\\t"".join(labels)) )\n    knowns_str = """"\n    for j in range(wlsqm.SIZE1):  # SIZE1 = maximum size of c matrix for 1D case\n        if j > 0:\n            knowns_str += \'\\t\'\n        if knowns & (1 << j):\n            knowns_str += labels[j]\n    print( ""knowns: %s"" % knowns_str )\n\n    print( ""surrogate order: %d"" % fit_order )\n\n    if noise_eps > 0.:\n        print( ""simulating noisy input with eps = %g"" % noise_eps )\n\n    # SymPy expr --> lambda(x)\n    lambdify_numpy_1d = lambda expr: sy.lambdify((""x""), expr, modules=""numpy"")\n    f       = lambdify_numpy_1d(expr)\n    dfdx    = lambdify_numpy_1d(sy.diff(expr, ""x""))\n    d2fdx2  = lambdify_numpy_1d(sy.diff(expr, ""x"", 2))\n    d3fdx3  = lambdify_numpy_1d(sy.diff(expr, ""x"", 3))\n    d4fdx4  = lambdify_numpy_1d(sy.diff(expr, ""x"", 4))\n    funcs = (f, dfdx, d2fdx2, d3fdx3, d4fdx4)  # list so we can refer to the functions by indices\n\n    # create neighbor points xk around the point xi - this simulates our meshless \'grid\'\n    #\n    if grid_type == \'random\':\n        xk = xi + r*2.*( np.random.sample( (nk,) ) - 0.5 )\n\n    elif grid_type == \'stencil\':\n        points_per_axis = max(1,fit_order) + 1\n\n        tt = np.linspace(-1., 1., points_per_axis)\n\n        # reject the point at the origin if it is there\n        point_list = [ x for x in tt if x != 0. ]\n\n        xk = np.array( [ xi + r*p for p in point_list ] )\n        nk = len(xk)\n\n    else:\n        raise ValueError(""Unknown grid_type \'%s\'; valid: \'random\', \'stencil\'"" % grid_type)\n\n\n    # sample the function values at the neighbor points xk (these are used to fit the surrogate model)\n    #\n    sample_also_xi_str = "" (and xi itself)"" if knowns & 1 else """"\n    print( ""sampling %d points%s"" % (nk, sample_also_xi_str) )\n    fk = np.empty( (nk,), dtype=np.float64 )\n    for k in range(nk):\n        fk[k] = f( xk[k] )\n\n    # simulate numerical errors by adding noise to the neighbor point function value samples\n    #\n    if noise_eps > 0.:\n#        # uniform\n#        noise = noise_eps*2.*(np.random.sample( np.shape(fk) ) - 0.5)\n\n        # Gaussian, truncated\n        mu    = 0.0\n        sigma = noise_eps / 3.\n        noise = np.random.normal( loc=mu, scale=sigma, size=np.shape(fk) )\n        noise[noise < -3.*sigma] = -3.*sigma\n        noise[noise > +3.*sigma] = +3.*sigma\n\n        fk += noise\n\n    # set knowns *at point xi*\n    #\n    # we use nan to spot unfilled entries\n    fi = np.nan * np.empty( (wlsqm.SIZE1,), dtype=np.float64 )\n    for d in range(wlsqm.SIZE1):\n        if knowns & (1 << d):\n            fi[d] = funcs[d]( xi )  # fill in the known value  # TODO: add noise here too?\n\n    # allocate array for sensitivity data\n    #\n    # for output; sens[k,j] = d(fi[j])/d(fk[k]) if f[i] unknown\n    #                         nan if fi[j] known\n    #\n    # Note that if order=1, the part on second derivatives is not touched (so that an (nk,3) array\n    # is valid); hence we pre-fill by nan.\n    #\n    if do_sens:\n        sens = np.nan * np.empty( (nk,wlsqm.SIZE1), dtype=np.float64 )\n    else:\n        sens = None\n\n    # do the numerical differentiation\n    #\n    # xk : in, (nk,) array of neighbor point coordinates\n    # fk : in, (nk,) array of function values at the neighbor points\n    # xi : in, double, coordinate of the point xi\n    # fi : in/out: if order=2, (3,) array containing (f, dfdx, d2fdx2) at point xi\n    #              if order=1, (2,) array containing (f, dfdx) at point xi\n    #      on input:  those elements must be filled that correspond to the bitmask ""knowns"".\n    #      on output: the unknown elements will be filled in (leaving the knowns untouched).\n    # sens : out: if order=2, (nk,3) array containing sensitivity information.\n    #             if order=1, (nk,2) array containing sensitivity information.\n    #             if fi[j] is unknown: sens[k,j] = d( fi[j] ) / d( fk[k] )\n    #             if fi[j] is known:   sens[:,j] = nan (to indicate ""not applicable"").\n    # order  : in, order of the surrogate polynomial. Can be 1 or 2.\n    #          Linear fit gives first derivatives only and has O(h**2) error.\n    #          Quadratic fit gives first and second derivatives and has O(h**3) error.\n    # knowns : in, bitmask describing what is known about the function at the point xi.\n    #          See the b1_* (bitmask, 1D case) constants.\n    #\n    if debug:\n        print()  # blank line before debug info\n    iterations_taken = wlsqm.fit_1D_iterative( xk, fk, xi, fi, sens, do_sens=do_sens, order=fit_order, knowns=knowns, debug=debug, weighting_method=weighting_method, max_iter=max_iter )\n    print( ""refinement iterations taken: %d"" % iterations_taken )\n\n    # check exact solution and relative error\n    #\n    exact = np.array( [func( xi ) for func in funcs] )\n    err   = (fi - exact)\n\n    print()\n    print( ""derivatives at xi:"" )\n    print( ""exact:"" )\n    print( exact )\n    print( ""wlsqm solution:"" )\n    print( fi )\n    if do_sens:\n        print( ""sensitivity:"" )\n        print( sens )\n    print( ""abs error:"" )\n    print( err )\n    print( ""rel error:"" )\n    print( (err / exact) )\n\n    #########################\n    # plotting\n    #########################\n\n    nvis = 10001\n    xx   = np.linspace(axislims[0], axislims[1], nvis)\n    ww   = f(xx)\n\n    # surrogate model - the returned fi[] are actually the coefficients of a polynomial\n    model = wlsqm.lambdify_fit( xi, fi, dimension=1, order=fit_order )  # lambda x : ...\n    xx2   = np.linspace(xi - r, xi + r, nvis)\n    ww2   = model(xx2)\n\n#    # It is also possible to interpolate the model using the C API wrapper directly.\n#    # The result is exactly the same; sometimes this API may be more convenient.\n#    #\n#    # Note that for the C API, the points x to which to interpolate the model must be formatted as x[:] = (xk).\n#    #\n#    out = wlsqm.interpolate_fit( xi, fi, dimension=1, order=fit_order, x=xx2 )\n#    print\n#    print ""difference between Python and C API model interpolation:""\n#    print out - ww2  # should be close to zero\n\n    print()\n    print( ""function values (and derivatives) at neighbor points:"" )\n    flags = [ wlsqm.i1_F, wlsqm.i1_X, wlsqm.i1_X2, wlsqm.i1_X3, wlsqm.i1_X4 ]\n    for label,func,flag in zip(labels,funcs,flags):\n        m   = wlsqm.lambdify_fit( xi, fi, dimension=1, order=fit_order, diff=flag )  # using diff=..., derivatives of the model can be lambdified, too\n        fxk = func( xk )\n        mxk = m( xk )\n        print( label )\n        print( ""exact:"" )\n        print( fxk )\n        print( ""wlsqm solution:"" )\n        print( mxk )\n        print( ""abs error:"" )\n        errf = mxk - fxk\n        print( errf )\n        print( ""rel error:"" )\n        print( (errf / fxk) )\n\n    # comparison\n    ww3  = f(xx2)\n    diff = ww2 - ww3  # fitted - exact\n    idx  = np.argmax(np.abs( diff ))\n    maxerr_abs = diff[idx]\n    maxerr_rel = diff[idx] / ww3[idx]\n    print( ""largest absolute total fit error (over the domain of the fit, not just the neighbor points):"" )\n    print( ""absolute: %g"" % (maxerr_abs) )\n    print( ""relative: %g"" % (maxerr_rel) )\n\n    fig = plt.figure(1, figsize=(6,6))\n    fig.clf()\n\n    ax = plt.subplot(1,1, 1)\n\n    # the function\n    ax.plot( xx, ww, color=\'k\', linewidth=0.5, linestyle=\'solid\' )\n\n    # surrogate model\n    ax.plot( xx2, ww2, color=\'r\', linewidth=1., linestyle=\'solid\' )\n\n    # sampled points\n    #\n    fxk = f(xk)\n    if noise_eps > 0.:\n        ax.plot( xk, fxk, linestyle=\'none\', marker=\'o\', markeredgecolor=\'k\', markerfacecolor=\'none\' )  # exact\n        ax.plot( xk, fk, linestyle=\'none\', marker=\'o\', markeredgecolor=\'r\', markerfacecolor=\'none\' )  # including noise\n    else:\n        ax.plot( xk, fxk, linestyle=\'none\', marker=\'o\', markeredgecolor=\'r\', markerfacecolor=\'none\' )  # exact\n\n    # helper lines for easier reading of figure\n#    ax.plot( np.tile(xk, (2,1)), np.tile((-0.05, 0.05), (nk,1)).T, \'k--\' )\n    tmp = np.zeros( (2,nk), dtype=np.float64 )  # for vertical lines from zero level to f(xk)\n    tmp[1,:] = fxk\n    ax.plot( np.tile(xk, (2,1)), tmp, \'r--\', linewidth=0.25 )\n\n    # sampled region\n    ax.plot( (xi - r, xi + r), (0., 0.), \'r-\', linewidth=2. )\n    ax.plot( (xi - r, xi - r), (0., f(xi-r)), \'r--\', linewidth=0.5 )\n    ax.plot( (xi + r, xi + r), (0., f(xi+r)), \'r--\', linewidth=0.5 )\n\n    # point xi\n    ax.plot( xi, f(xi), linestyle=\'none\', marker=\'x\', markeredgecolor=\'k\', markerfacecolor=\'none\' )\n\n    plt.axis(\'tight\')\n    axis_marginize(ax, 0.02, 0.02)\n    plt.grid(b=True, which=\'both\')\n    plt.xlabel(\'x\')\n    plt.ylabel(\'y\')\n\n\ndef main():\n    test3d()\n    test2d()\n    test1d()\n    testmany2d()\n#    wlsqm.test_pointer_wrappers()\n    print()\n    plt.show()\n\nif __name__ == \'__main__\':\n    main()\n'"
wlsqm/__init__.py,0,"b'# -*- coding: utf-8 -*-\n#\n""""""WLSQM (Weighted Least SQuares Meshless): a fast and accurate meshless least-squares interpolator for Python, for scalar-valued data defined as point values on 1D, 2D and 3D point clouds.\n\nA general overview can be found in the README.\n\nFor the API, refer to  wlsqm.fitter.simple  and  wlsqm.fitter.expert.\n\nWhen imported, this module imports all symbols from the following modules to the local namespace:\n\n    wlsqm.fitter.defs    # definitions (constants) (common)\n    wlsqm.fitter.simple  # simple API\n    wlsqm.fitter.interp  # interpolation of fitted model (for simple API)\n    wlsqm.fitter.expert  # advanced API\n\nThis makes the names available as wlsqm.fit_2D(), wlsqm.ExpertSolver, etc.\n\nJJ 2017-02-22\n""""""\n\n# absolute_import: https://www.python.org/dev/peps/pep-0328/\nfrom __future__ import division, print_function, absolute_import\n\n__version__ = \'0.1.6\'\n\nfrom .fitter.defs   import *  # definitions (constants) (common)\nfrom .fitter.simple import *  # simple API\nfrom .fitter.interp import *  # interpolation of fitted model (for simple API)\nfrom .fitter.expert import *  # advanced API\n\n'"
wlsqm/fitter/__init__.py,0,b''
wlsqm/utils/__init__.py,0,b''
