file_path,api_count,code
setup.py,0,"b'# -*- coding: utf-8 -*-\n#\n""""""Setuptools-based setup.py for sudoku_lhs.\n\nSupports Python 2.7 and 3.4.\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\ntry:\n    # Python 3\n    MyFileNotFoundError = FileNotFoundError\nexcept:  # FileNotFoundError does not exist in Python 2.7\n    # Python 2.7\n    # - open() raises IOError\n    # - remove() (not currently used here) raises OSError\n    MyFileNotFoundError = (IOError, OSError)\n\n#########################################################\n# General config\n#########################################################\n\n# Name of the top-level package of your library.\n#\n# This is also the top level of its source tree, relative to the top-level project directory setup.py resides in.\n#\nlibname=""sudoku_lhs""\n\n# Short description for package list on PyPI\n#\nSHORTDESC=""LHS with sudoku constraint""\n\n# Long description for package homepage on PyPI\n#\nDESC=""""""Latin hypercube sampler with a sudoku-like constraint.\n\nThe sudoku LHS algorithm is a bit like the first stage in the design\nof an `N`-dimensional sudoku puzzle, hence the name: each ""sudoku box""\nmust have exactly the same number of samples, and no two samples may\noccur on the same axis-aligned hyperplane.\n\nThis gives coarse stratification in `N` dimensions with linear runtime.\n\nSupports Python 2.7 and 3.4.\n""""""\n\n# Set up data files for packaging.\n#\n# Directories (relative to the top-level directory where setup.py resides) in which to look for data files.\ndatadirs  = (""test"",)\n\n# File extensions to be considered as data files. (Literal, no wildcards.)\ndataexts  = ("".py"",  "".pyx"", "".pxd"",  "".c"", "".cpp"", "".h"",  "".sh"",  "".lyx"", "".tex"", "".txt"", "".pdf"")\n\n# Standard documentation to detect (and package if it exists).\n#\nstandard_docs     = [""README"", ""LICENSE"", ""TODO"", ""CHANGELOG"", ""AUTHORS""]  # just the basename without file extension\nstandard_doc_exts = ["".md"", "".rst"", "".txt"", """"]  # commonly .md for GitHub projects, but other projects may use .rst or .txt (or even blank).\n\n\n#########################################################\n# Init\n#########################################################\n\n# check for Python 2.7 or later\n# http://stackoverflow.com/questions/19534896/enforcing-python-version-in-setup-py\nimport sys\nif sys.version_info < (2,7):\n    sys.exit(\'Sorry, Python < 2.7 is not supported\')\n\nimport os\n\nfrom setuptools import setup\n\n\n# Gather user-defined data files\n#\n# http://stackoverflow.com/questions/13628979/setuptools-how-to-make-package-contain-extra-data-folder-and-all-folders-inside\n#\ndatafiles = []\ngetext = lambda filename: os.path.splitext(filename)[1]\nfor datadir in datadirs:\n    datafiles.extend( [(root, [os.path.join(root, f) for f in files if getext(f) in dataexts])\n                       for root, dirs, files in os.walk(datadir)] )\n\n\n# Add standard documentation (README et al.), if any, to data files\n#\ndetected_docs = []\nfor docname in standard_docs:\n    for ext in standard_doc_exts:\n        filename = """".join( (docname, ext) )  # relative to the directory in which setup.py resides\n        if os.path.isfile(filename):\n            detected_docs.append(filename)\ndatafiles.append( (\'.\', detected_docs) )\n\n\n# Extract __version__ from the package __init__.py\n# (since it\'s not a good idea to actually run __init__.py during the build process).\n#\n# http://stackoverflow.com/questions/2058802/how-can-i-get-the-version-defined-in-setup-py-setuptools-in-my-package\n#\nimport ast\ninit_py_path = os.path.join(libname, \'__init__.py\')\nversion = \'0.0.unknown\'\ntry:\n    with open(init_py_path) as f:\n        for line in f:\n            if line.startswith(\'__version__\'):\n                version = ast.parse(line).body[0].value.s\n                break\n        else:\n            print( ""WARNING: Version information not found in \'%s\', using placeholder \'%s\'"" % (init_py_path, version), file=sys.stderr )\nexcept MyFileNotFoundError:\n    print( ""WARNING: Could not find file \'%s\', using placeholder version information \'%s\'"" % (init_py_path, version), file=sys.stderr )\n\n\n#########################################################\n# Call setup()\n#########################################################\n\nsetup(\n    name = ""sudoku_lhs"",\n    version = version,\n    author = ""Juha Jeronen"",\n    author_email = ""juha.jeronen@jyu.fi"",\n    url = ""https://github.com/Technologicat/sudoku_lhs"",\n\n    description = SHORTDESC,\n    long_description = DESC,\n\n    license = ""BSD"",\n\n    # free-form text field; http://stackoverflow.com/questions/34994130/what-platforms-argument-to-setup-in-setup-py-does\n    platforms = [""Linux""],\n\n    # See\n    #    https://pypi.python.org/pypi?%3Aaction=list_classifiers\n    #\n    # for the standard classifiers.\n    #\n    # Remember to configure these appropriately for your project, especially license!\n    #\n    classifiers = [ ""Development Status :: 4 - Beta"",\n                    ""Environment :: Console"",\n                    ""Intended Audience :: Developers"",\n                    ""Intended Audience :: Science/Research"",\n                    ""License :: OSI Approved :: BSD License"",\n                    ""Operating System :: POSIX :: Linux"",\n                    ""Programming Language :: Python"",\n                    ""Programming Language :: Python :: 2"",\n                    ""Programming Language :: Python :: 2.7"",\n                    ""Programming Language :: Python :: 3"",\n                    ""Programming Language :: Python :: 3.4"",\n                    ""Topic :: Scientific/Engineering"",\n                    ""Topic :: Scientific/Engineering :: Mathematics"",\n                    ""Topic :: Software Development :: Libraries"",\n                    ""Topic :: Software Development :: Libraries :: Python Modules""\n                  ],\n\n    # See\n    #    http://setuptools.readthedocs.io/en/latest/setuptools.html\n    #\n    setup_requires = [""numpy""],\n    install_requires = [""numpy""],\n    provides = [""sudoku_lhs""],\n\n    # keywords for PyPI (in case you upload your project)\n    #\n    # e.g. the keywords your project uses as topics on GitHub, minus ""python"" (if there)\n    #\n    keywords = [""latin-hypercube sudoku numerical sampling-methods numpy""],\n\n    # Declare packages so that  python -m setup build  will copy .py files (especially __init__.py).\n    #\n    # This **does not** automatically recurse into subpackages, so they must also be declared.\n    #\n    packages = [""sudoku_lhs""],\n\n    zip_safe = True,  # no Cython extensions\n\n    # Custom data files not inside a Python package\n    data_files = datafiles\n)\n\n'"
sudoku_lhs/__init__.py,0,"b'# -*- coding: utf-8 -*-\n#\n""""""Init for sudoku_lhs.\n\nSee the submodules sudoku, lhs and comb for the actual samplers.\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\n# This is extracted automatically by the top-level setup.py.\n__version__ = \'0.1.1\'\n\nimport sudoku_lhs.sudoku as sudoku\nimport sudoku_lhs.lhs as lhs\nimport sudoku_lhs.comb as comb\n\n'"
sudoku_lhs/comb.py,3,"b'# -*- coding: utf-8 -*-\n#\n""""""Trivial combinatorial sampler.""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nfrom itertools import chain\n\nimport numpy as np\n\n# http://stackoverflow.com/questions/17973507/why-is-converting-a-long-2d-list-to-numpy-array-so-slow\ndef __longlist2array(longlist):\n    flat = np.fromiter(chain.from_iterable(longlist), np.array(longlist[0][0]).dtype, -1)\n    return flat.reshape((len(longlist), -1))\n\n\ndef sample(N,k):\n    """"""Generate all `k` ** `N` combinations of range(`k`) ""outer-raised"" to power `N`.\n\nParameters:\n    N : int, >= 1\n        number of dimensions\n    k : int, >= 1\n        number of bins per axis\n\nReturn value:\n    rank-2 np.array\n        first index indexes the sample number, the second indexes the axis\n        (i.e. each row is an N-dimensional sample).\n\n**Notes:**\n\nThe possibilities are enumerated by generating a nested list comprehension::\n\n    [ [j1] for j1 in range(k) ]\n    [ [j1,j2] for j1 in range(k) for j2 in range(k) ]\n    [ [j1,j2,j3] for j1 in range(k) for j2 in range(k) for j3 in range(k) ]\n    # ...\n\nI.e., in general,::\n\n    [ [j1, ..., jN] for j1 in range(k) ... for jN in range(k) ]\n\nThis is then eval\'d and the resulting list, converted to an np.array, is returned.\n""""""\n    # sanity check input\n    if not isinstance(N, int)  or  N < 1:\n        raise ValueError(""N must be int >= 1, got %g"" % (N))\n    if not isinstance(k, int)  or  k < 1:\n        raise ValueError(""k must be int >= 1, got %g"" % (k))\n\n    code = ""[ [""\n    code += ""j0""  # no comma (this may be the only one)\n    for j in range(1,N):\n        code += "", j%d"" % j\n    code += ""]""\n    for j in range(N):\n        code += "" for j%d in range(%d)"" % (j, k)\n    code += "" ]""\n\n    return __longlist2array(eval(code))\n\n'"
sudoku_lhs/lhs.py,4,"b'# -*- coding: utf-8 -*-\n#\n""""""Classical latin hypercube sampler.""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\n\ndef sample(N,k):\n    """"""Generate a latin hypercube sample in `N` dimensions.\n\nParameters:\n    N : int, >= 1\n        number of dimensions\n    k : int, >= 1\n        number of bins per axis\n\nReturn value:\n    rank-2 np.array\n        first index indexes the sample number, the second indexes the axis\n        (i.e. each row is an N-dimensional sample).\n\n**Notes:**\n\nIn the result, range(k) on the first axis is paired with a random permutation\nof range(k) on each subsequent axis.\n""""""\n    # sanity check input\n    if not isinstance(N, int)  or  N < 1:\n        raise ValueError(""N must be int >= 1, got %g"" % (N))\n    if not isinstance(k, int)  or  k < 1:\n        raise ValueError(""k must be int >= 1, got %g"" % (k))\n\n    S = np.empty( (k,N), dtype=int, order=""C"" )\n\n    S[:,0] = range(k)\n    for j in range(1, N):\n        tmp = np.array( range(k), dtype=int )\n        np.random.shuffle(tmp)\n        S[:,j] = tmp\n\n    return S\n\n'"
sudoku_lhs/sudoku.py,13,"b'# -*- coding: utf-8 -*-\n""""""Latin hypercube sampler with a sudoku-like constraint.""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\n\ndef sample(N,k,n, visualize=False, showdiag=False, verbose=False):\n    """"""Create a coarsely `N`-dimensionally stratified latin hypercube sample (LHS) of range(`k` * `m`) in `N` dimensions.\n\nParameters:\n    N : int, >= 1\n        number of dimensions\n    k : int, >= 1\n        number of large subdivisions (sudoku boxes, ""subspaces"") per dimension\n    n : int, >= 1\n        number of samples to place in each subspace\n    visualize : bool (optional)\n        If True, the results (projected into two dimensions pairwise)\n        are plotted using Matplotlib when the sampling is finished.\n    showdiag : bool (optional)\n        If True, and `N` >= 3, show also one-dimensional projection\n        of the result onto each axis.\n\n        Implies ""visualize"".\n\n        This should produce a straight line with no holes onto\n        each subplot that is on the diagonal of the plot array;\n        mainly intended for debug.\n    verbose : bool (optional)\n        If this exists and is true, progress messages and warnings\n        (for non-integer input) are printed.\n\nReturn value:\n    tuple (`S`, `m`), where:\n        S : (`k` * `m`)-by-`N` rank-2 np.array\n            where each row is an `N`-tuple of integers in range(1, `k` * `m` + 1).\n\n        m : int, >= 1\n            number of bins per parameter in one subspace (i.e. sample slots\n            per axis in one box).\n\n            `m` = `n` * (`k` ** (`N` - 1)), but is provided as output for convenience.\n\n**Examples:**\n\n    `N` = 2 dimensions, k = 3 subspaces per axis, `n` = 1 sample per subspace.\n    `m` will be `n` * (`k` ** (`N` - 1)) = 1 * 3**(2-1) = 3. Plot the result and show progress messages::\n\n        S,m = sample(2, 3, 1, visualize=True, verbose=True)\n\n    For comparison with the previous example, try this classical Latin hypercube\n    that has 9 samples in total, plotting the result. We choose 9, because in\n    the previous example, `k` * `m` = 3*3 = 9::\n\n        S,m = sample(2, 1, 9, visualize=True)\n\n**Notes:**\n\n    If `k` = 1, the algorithm reduces to classical Latin hypercube sampling.\n\n    If `N` = 1, the algorithm simply produces a random permutation of range(`k`).\n\n    Let `m` = `n` * (`k` ** (`N` - 1)) denote the number of bins for one variable\n    in one subspace. The total number of samples is always exactly `k` * `m\'.\n    Each component of a sample can take on values 0, 1, ..., (`k` * `m` - 1).\n""""""\n    # sanity check input\n    if not isinstance(N, int)  or  N < 1:\n        raise ValueError(""N must be int >= 1, got %g"" % (N))\n    if not isinstance(k, int)  or  k < 1:\n        raise ValueError(""k must be int >= 1, got %g"" % (k))\n    if not isinstance(n, int)  or  n < 1:\n        raise ValueError(""n must be int >= 1, got %g"" % (n))\n\n    # showing the diagonal implies visualization\n    if showdiag:\n        visualize = True\n\n    # Discussion.\n\n    # Proof that the following algorithm implements a Sudoku-like LHS method:\n    #\n    # * We desire two properties: Latin hypercube sampling globally, and equal density\n    #   in each subspace.\n    # * The independent index vector generation for each parameter guarantees the Latin\n    #   hypercube property: some numbers will have been used, and removed from the index\n    #   vectors, when the next subspace along the same hyperplane is reached. Thus, the same\n    #   indices cannot be used again for any such subspace. This process continues until each\n    #   index has been used exactly once.\n    # * The equal density property is enforced by the fact that each subspace gets exactly one\n    #   sample generated in one run of the loop. The total number of samples is, by design,\n    #   divisible by the number of these subspaces. Therefore, each subspace will have the\n    #   same sample density.\n    #\n    # Run time and memory cost:\n    #\n    # * Exactly k*m samples will be generated. This can be seen from the fact that there are\n    #   k*m bins per parameter, and they all get filled by exactly one sample.\n    # * Thus, runtime is in O(k*m) = O( k * n*k^(N-1) ) = O( n*k^N ). (This isn\'t as bad as it\n    #   looks. All it\'s saying is that a linear number of bins gets filled. This is much less\n    #   than the total number of bins (k*m)^N - which is why LHS is needed in the first place.\n    #   We get a reduction in sample count by the factor (k*m)^(N-1).)\n    # * Required memory for the final result is (k*m)*N reals (plus some overhead), where the\n    #   N comes from the fact that each N-tuple generated has N elements. Note that the index\n    #   vectors also use up k*m*N reals in total (k*N vectors, each with m elements). Thus the\n    #   memory cost is 2*k*m*N reals plus overhead.\n    # * Note that using a more complicated implementation that frees the elements of the index\n    #   vectors as they are used up probably wouldn\'t help with the memory usage, because many\n    #   vector implementations never decrease their storage space even if elements are deleted.\n    # * In other programming languages, one might work around this by using linked lists\n    #   instead of vectors, and arranging the memory allocations for the elements in a very\n    #   special way (i.e. such that the last ones in memory always get deleted first). By\n    #   using a linked list for the results, too, and allocating them over the deleted\n    #   elements of the index vectors (since they shrink at exactly the same rate the results\n    #   grow), one might be able to bring down the memory usage to k*m*N plus overhead.\n    # * Finally, note that in practical situations N, k and m are usually small, so the factor\n    #   of 2 doesn\'t really matter.\n\n    # Algorithm.\n\n    # Find necessary number of bins per subspace so that equal nonzero density is possible.\n    # A brief analysis shows that in order to exactly fill up all k*m bins for one variable,\n    # we must have k*m = n*k^N, i.e...\n    m = n * k**(N-1)\n\n    # Create index vectors for each subspace for each parameter. (There are k*N of these.)\n    if verbose:\n        print(\'Allocating %d elements for solution...\' % (N*k*m))\n\n    I    = np.empty( [N,k,m], dtype=int, order=""C"" )  # index vectors\n    Iidx = np.zeros( [N,k],   dtype=int, order=""C"" )  # index of first ""not yet used"" element in each index vector\n\n    # Create random permutations of range(m) so that in the sampling loop\n    # we may simply pick the first element from each index vector.\n    #\n    for i in range(N):\n        for j in range(k):\n            tmp = np.array( range(m), dtype=int )\n            np.random.shuffle(tmp)\n            I[i,j,:] = tmp\n\n    if verbose:\n        print(\'Generating sample...\')\n        print(\'Looping through %d subspaces.\' % (k**N))\n\n    L  = k*m   # number of samples still waiting for placement\n    Ns = k**N  # number of subspaces in total (cartesian product\n               #         of k subspaces per axis in N dimensions)\n\n    # Start with an empty result set. We will place the generated samples here.\n    S = np.empty( [L,N], dtype=int, order=""C"" )\n    out_idx = 0  # index of current output sample in S\n\n    # create views for linear indexing\n    I_lin    = np.reshape(I, -1)\n    Iidx_lin = np.reshape(Iidx, -1)\n\n    # we will need an array of range(N) several times in the loop...\n    rgN = np.arange(N, dtype=int)\n\n    while L > 0:\n        # Loop over all subspaces, placing one sample in each.\n        for j in range(Ns):  # index subspaces linearly\n            # Find, in each dimension, which subspace we are in.\n            # Compute the multi-index (vector containing an index in each dimension)\n            # for this subspace.\n            #\n            # Simple example: (N,k,n) = (2,3,1)\n            #   =>  pj = 0 0, 1 0, 2 0,  0 1, 1 1, 2 1,  0 2, 1 2, 2 2\n            #   when j =  0,   1,   2,    3,   4,   5,    6,   7,   8\n            #\n            pj = np.array( ( j // (k**rgN) ) % k, dtype=int )\n\n            # Construct one sample point.\n            #\n            # To do this, we grab the first ""not yet used"" element in all index vectors\n            # (one for each dimension) corresponding to this subspace.\n            #\n            # Along the dth dimension, we are in the pj[d]th subspace.\n            # Hence, in the dth dimension, we want to refer to the vector whose index is pj[d].\n            #\n            # Hence, we should take\n            #  row = d  (effectively, range(N))\n            #  col = pj[d]\n            #\n            # The array Iidx is of the shape [N,k]. NumPy uses C-contiguous ordering\n            # by default; last index varies fastest. Hence, the element [row,col] is at\n            # k*row + col.\n            #\n            # This gets us a vector of linear indices into Iidx, where the dth element\n            # corresponds to the linear index of the pj[d]th vector.\n            #\n            i = np.array( k*rgN + pj, dtype=int )\n\n            # Extract the ""first unused element"" data from Iidx for each of the vectors,\n            # to get the actual sample slot numbers (random permutations) stored in I.\n            #\n            indices = Iidx_lin[i]\n\n            # Indexing: the array I is of shape [N,k,m] and has C storage order.\n            #\n            idx_first = np.array( k*m*rgN + m*pj + indices, dtype=int )\n\n            s = I_lin[idx_first] # this is our new sample point (vector of length N)\n            Iidx_lin[i] += 1     # move to the next element in the selected index vectors\n\n            # Now s contains a sample from (range(m), range(m), ..., range(m)) (N elements).\n            # By its construction, the sample conforms globally to the Latin hypercube\n            # requirement.\n\n            # Compute the base index along each dimension. In the global numbering\n            # which goes 0, 1, ..., (k*m-1) along each axis, the first element\n            # of the current subspace is at this multi-index:\n            #\n            a = pj*m\n\n            # Add the new sample to the result set.\n            S[out_idx,:] = a+s\n            out_idx += 1\n\n        # We placed exactly Ns samples during the for loop.\n        L -= Ns\n\n    # Result visualization (for debug and illustrative purposes)\n    #\n    if visualize  and  N > 1:\n        if verbose:\n            print(\'Plotting...\')\n\n        import itertools\n        import matplotlib.pyplot as plt\n\n        # if the grid would show more lines than this, the lines are hidden.\n        max_major_lines = 5\n        max_minor_lines = 15\n\n        major_color = ""#a0a0a0""\n        minor_color = ""#e0e0e0""\n\n        if k*m > 100:\n            style = \'.\'\n        else:\n            style = \'o\' # use circles when a small number of bins\n\n        plt.figure(1)\n        plt.clf()\n\n        if N >= 3:\n            # We\'ll make a ""pairs"" plot (like the pairs() function of the ""R""\n            # statistics software).\n\n            # generate all pairs of dimensions, make explicit list\n            pair_list = list(itertools.combinations(range(N), 2))\n\n            # make final list.\n            #\n            # We want to populate both sides of the diagonal in the plot,\n            # so we need pair_list, plus another copy of it\n            # with the first and second components switched in each pair.\n            #\n            pairs = list(pair_list) # copy\n            pairs.extend( tuple(reversed(pair)) for pair in pair_list )\n\n            # Show also the diagonal if requested.\n            #\n            # This should produce a straight line with no holes onto\n            # each subplot that is on the diagonal of the plot array.\n            #\n            if showdiag:\n                pairs.extend( [ (j,j) for j in range(N) ] )\n        else: # N == 2:\n            pairs = [ (0, 1) ]\n\n        Np = len(pairs)\n        for i in range(Np):\n            if N >= 3:\n                if verbose:\n                    print(\'Subplot %d of %d...\' % ((i+1), Np))\n                plt.subplot( N,N, N*pairs[i][1] + (pairs[i][0] + 1) )\n\n            # off-diagonal projection? (i.e. a true 2D projection)\n            if pairs[i][0] != pairs[i][1]:\n                # Plot the points picked by the sample\n                plt.plot( S[:,pairs[i][0]], S[:,pairs[i][1]], style)\n                axmax = k*m\n\n                # Mark bins (if few enough to fit reasonably on screen)\n                #\n                if k*m <= max_minor_lines:\n                    for j in range(k*m):\n                        xy = -0.5 + j\n                        plt.plot( [xy, xy], [-0.5, axmax - 0.5], color=minor_color)\n                        plt.plot( [-0.5, axmax - 0.5], [xy, xy], color=minor_color)\n\n                # Mark the subspaces onto the figure\n                # (if few enough to fit reasonably on screen)\n                #\n                if k <= max_major_lines:\n                    for j in range(k):\n                        xy = -0.5 + j*m\n                        plt.plot( [xy, xy], [-0.5, axmax - 0.5], color=major_color, linewidth=2.0 )\n                        plt.plot( [-0.5, axmax - 0.5], [xy, xy], color=major_color, linewidth=2.0 )\n\n                # Make a box around the area\n                plt.plot( [-0.5,         axmax - 0.5], [-0.5,        -0.5],        \'k\', \\\n                         linewidth=2.0  )\n                plt.plot( [-0.5,         axmax - 0.5], [axmax - 0.5, axmax - 0.5], \'k\', \\\n                         linewidth=2.0  )\n                plt.plot( [-0.5,         -0.5],        [-0.5,        axmax - 0.5], \'k\', \\\n                         linewidth=2.0  )\n                plt.plot( [axmax - 0.5,  axmax - 0.5],  [-0.5,       axmax - 0.5], \'k\', \\\n                         linewidth=2.0  )\n\n                # Set the axes so that the extreme indices just fit into the view\n                plt.axis(""equal"")\n                plt.axis( [-0.5, axmax-0.5, -0.5, axmax-0.5 ] )\n            else: # 1D projection\n                plt.plot( S[:,pairs[i][0]], np.zeros( [k*m] ), style)\n                plt.axis( [-0.5, axmax-0.5, -0.5, 0.5] )\n\n        # Label the variables.\n        #\n        # We only do this if the diagonal subplots are blank.\n        #\n        if N >= 3:\n            if not showdiag:\n                for i in range(N):\n                    plt.subplot(N,N, N*i+(i+1))\n                    my_label = \'Row: x = var %d\' % i\n                    plt.text(0.5,0.6, my_label, horizontalalignment=""center"", fontweight=""bold"")\n                    my_label = \'Col: y = var %d\' % i\n                    plt.text(0.5,0.4, my_label, horizontalalignment=""center"", fontweight=""bold"")\n                    plt.axis(""off"")\n        else:\n            plt.xlabel(\'Var 0\', fontweight=""bold"")\n            plt.ylabel(\'Var 1\', fontweight=""bold"")\n\n        if verbose:\n            print(\'Plotting done. Showing figure...\')\n\n        # show figures and enter gtk mainloop\n        plt.show()\n\n    return (S,m)\n'"
test/sudoku_cor_test.py,30,"b'# -*- coding: utf-8 -*-\n""""""Test statistical independence of components of generated sample.""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\n\nimport sudoku_lhs.sudoku as sudoku\nimport sudoku_lhs.lhs as lhs  # classical LHS, for comparison\n\n# emulate MATLAB corr(X) - pairwise linear correlation coefficient of columns of x\n#\n# x : rank-2 np.array\n#     data, size (nrow, ncol)\n#\n# out : rank-2 np.array\n#     correlation coefficient array, size (ncol, ncol)\n#\ndef corr(x):\n    ncol = x.shape[1]\n    out  = np.empty( (ncol,ncol), dtype=np.float64, order=""C"" )\n    for j in range(ncol):\n        for k in range(ncol):\n            out[j,k] = np.corrcoef( x[:,j], x[:,k] )[0,1]  # corrcoeff[0,1] = correlation between columns j and k  ( [0,0] is j,j  and [1,1] is k,k,  which are always 1 )\n    return out\n\ndef get_max_corr(R):\n    n = R.shape[0] # == R.shape[1]\n    tmp = R - np.eye(n)  # remove the ones on the diagonal (they do not contain any useful information)\n    return np.max(np.abs(tmp))\n\n\ndef test():\n    ndim  = 4  # Number of dimensions.\n    nsam  = 10 # Subdivisions (""k"") for sudoku LHS. Needs to be about 10 for meaningful results.\n\n    nreps = 10 # This many sets of nruns runs will be performed.\n    nruns = 10 # This many runs will be performed for each set. Needs to be large (e.g. 1000) for meaningful results.\n\n    nlhs = nsam**ndim\n    print( ""Monte Carlo vs. LHS with %d samples vs. sudoku LHS with %d sudoku boxes in %d dimensions."" % (nlhs, nsam, ndim) )\n    print( ""Performing %d sets of %d runs."" % (nreps, nruns) )\n\n    means_MC        = np.zeros( (nreps,), dtype=np.float64 )\n    means_LHS       = np.zeros( (nreps,), dtype=np.float64 )\n    means_SudokuLHS = np.zeros( (nreps,), dtype=np.float64 )\n\n    xxlhs = np.arange(nlhs)\n    for j in range(nreps):\n        print( \'Set %d of %d...\' % (j+1, nreps) )\n\n        unique_MC      = np.zeros( (nruns,), dtype=np.float64 )\n        cors_MC        = np.zeros( (nruns,), dtype=np.float64 )\t\n        cors_LHS       = np.zeros( (nruns,), dtype=np.float64 )\n        cors_SudokuLHS = np.zeros( (nruns,), dtype=np.float64 )\n\n        for k in range(nruns):\n            # comparison: plain (pseudo-) Monte Carlo\n            xxmc = []\n            for l in range(ndim):\n                xxmc.append( np.floor(nlhs*np.random.random(nlhs)) )  # nlhs random integers in range(nlhs)\n\n            a = np.array( xxmc, dtype=np.float64 ).T\n            c = corr(a)\n            cors_MC[k] = get_max_corr(c)\n            # LHS always produces unique values, MC is not guaranteed to.\n            unique_MC[k] = 100.0 * len(np.unique(a.reshape(-1))) / nlhs\n\n            # traditional LHS\n            #\n            a = lhs.sample(ndim, nlhs)\n            c = corr(a)\n            cors_LHS[k] = get_max_corr(c)\n\n            # sudoku LHS\n            a,m = sudoku.sample(ndim,nsam,1)\n            c = corr(a)\n            cors_SudokuLHS[k] = get_max_corr(c)\n\n        uMC        = np.mean(unique_MC)\n        mMC        = np.mean(cors_MC)\n        mLHS       = np.mean(cors_LHS)\n        mSudokuLHS = np.mean(cors_SudokuLHS)\n\n        vMC        = np.var(cors_MC)\n        vLHS       = np.var(cors_LHS)\n        vSudokuLHS = np.var(cors_SudokuLHS)\n\n        print( \'Mean correlation (MC): %0.6g, variance %0.6g, mean uniq. bins %0.3g%%\' % (mMC, vMC, uMC) )\n        print( \'Mean correlation (LHS): %0.6g, variance %0.6g\' % (mLHS, vLHS) )\n        print( \'Mean correlation (Sudoku LHS): %0.6g, variance %0.6g\' % (mSudokuLHS, vSudokuLHS) )\n        print( \'Improvement (over MC): %0.6gx\' % (abs(mMC/mSudokuLHS)) )\n        print( \'Improvement (over LHS): %0.6gx\' % (abs(mLHS/mSudokuLHS)) )\n\n        means_MC[j]        = mMC\n        means_LHS[j]       = mLHS\n        means_SudokuLHS[j] = mSudokuLHS\n\n    print(""All done."")\n\n    mMC        = np.mean(means_MC)\n    mLHS       = np.mean(means_LHS)\n    mSudokuLHS = np.mean(means_SudokuLHS)\n\n    vMC        = np.var(means_MC)\n    vLHS       = np.var(means_LHS)\n    vSudokuLHS = np.var(means_SudokuLHS)\n\n    print( ""Mean correlation over all runs (MC): %0.6g (var. over sets %0.6g)"" % (mMC, vMC) )\n    print( \'Mean correlation over all runs (LHS): %0.6g (var. over sets %0.6g)\' % (mLHS, vLHS) )\n    print( \'Mean correlation over all runs (Sudoku LHS): %0.6g (var. over sets %0.6g)\' % (mSudokuLHS, vSudokuLHS) )\n    print( \'Improvement (over MC): %0.6gx\' % (abs(mMC/mSudokuLHS)) )\n    print( \'Improvement (over LHS): %0.6gx\' % (abs(mLHS/mSudokuLHS)) )\n\n\nif __name__ == \'__main__\':\n    test()\n\n'"
