file_path,api_count,code
Main.py,94,"b'import cv2\nimport numpy as np\nimport pathlib\nimport os\nfrom shutil import copyfile\nfrom preprocessing import Prep as p\nfrom featext.texture import Haralick as har\nfrom featext.texture import Tamura as tam\nfrom featext.texture import King as k\nfrom featext.physical import Gabor as g\nfrom mlmodels import Classifiers as CLF\nfrom mlmodels import DecisionSurfacePlotter as DSP\n\nimgcount = 0\n\ndef __showImages(lstofimgs):\n    for tpls in lstofimgs:\n        cv2.namedWindow(tpls[1], cv2.WINDOW_NORMAL)\n        cv2.imshow(tpls[1], tpls[0])\n        if (tpls[2] != None):\n            cv2.imwrite(tpls[2], tpls[0])\n        else:\n            continue\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n\ndef __showGLCM(feobj):\n    print(feobj.getGLCM())\n\ndef __showHaralickFeatures(feobj):\n    print(""->.->.->.->.->.->.->.->.->.HARALICK TEXTURE FEATURES.<-.<-.<-.<-.<-.<-.<-.<-.<- \\n"")\n    __showGLCM(feobj)\n    print(""\\n"")\n    print(""Angular Second Moment-ASM of seg gray img %f \\n"" % feobj.getAngularSecondMomentASM())\n    print(""Energy of seg gray img %f \\n"" % feobj.getEnergy())\n    print(""Entropy of seg gray img %f \\n"" % feobj.getEntropy())\n    print(""Contrast of seg gray img %f \\n"" % feobj.getContrast())\n    print(""Homogeneity of seg gray img %f \\n"" % feobj.getHomogeneity())\n    print(""Directional-Moment of seg gray img %f \\n"" % feobj.getDm())\n    print(""Correlation of seg gray img %f \\n"" % feobj.getCorrelation())\n    print(""Haralick-Correlation of seg gray img %f \\n"" % feobj.getHarCorrelation())\n    print(""Cluster-Shade of seg gray img %f \\n"" % feobj.getClusterShade())\n    print(""Cluster-Prominence of seg gray img %f \\n"" % feobj.getClusterProminence())\n    print(""Moment1 of seg gray img %f \\n"" % feobj.getMoment1())\n    print(""Moment2 of seg gray img %f \\n"" % feobj.getMoment2())\n    print(""Moment3 of seg gray img %f \\n"" % feobj.getMoment3())\n    print(""Moment4 of seg gray img %f \\n"" % feobj.getMoment4())\n    print(""Differential-ASM of seg gray img %f \\n"" % feobj.getDasm())\n    print(""Differential-Mean of seg gray img %f \\n"" % feobj.getDmean())\n    print(""Differential-Entropy of seg gray img %f \\n"" % feobj.getDentropy())\n\ndef __showTamuraFeatures(feobj2):\n    print(""->.->.->.->.->.->.->.->.->.TAMURA TEXTURE FEATURES.<-.<-.<-.<-.<-.<-.<-.<-.<- \\n"")\n    print(""Tamura-Coarseness of seg gray img %f \\n"" % feobj2.getCoarseness())\n    print(""Tamura-Contrast of seg gray img %f \\n"" % feobj2.getContrast())\n    print(""Tamura-Kurtosis of seg gray img %f \\n"" % feobj2.getKurtosis())\n    print(""Tamura-LineLikeness of seg gray img %f \\n"" % feobj2.getLineLikeness())\n    print(""Tamura-Directionality of seg gray img %f \\n"" % feobj2.getDirectionality())\n    print(""Tamura-Regularity of seg gray img %f \\n"" % feobj2.getRegularity())\n    print(""Tamura-Roughness of seg gray img %f \\n"" % feobj2.getRoughness())\n\ndef __showKingsFeatures(feobj4):\n    print(""->.->.->.->.->.->.->.->.->.KING\'S TEXTURE FEATURES.<-.<-.<-.<-.<-.<-.<-.<-.<- \\n"")\n    print(""\\n"")\n    print(feobj4.getNGTDM())\n    print(""\\n"")\n    print(""King\'s-Coarseness of seg gray img %f \\n"" % feobj4.getKingsCoarseness())\n    print(""King\'s-Contrast of seg gray img %f \\n"" % feobj4.getKingsContrast())\n    print(""King\'s-Busyness of seg gray img %f \\n"" % feobj4.getKingsBusyness())\n    print(""King\'s-Complexity of seg gray img %f \\n"" % feobj4.getKingsComplexity())\n    print(""King\'s-Strength of seg gray img %f \\n"" % feobj4.getKingsStrength())\n\ndef __showGaborPhysicalFeatures(feobj3):\n    print(""->.->.->.->.->.->.->.->.->.GABOR PHYSICAL FEATURES OF LESION.<-.<-.<-.<-.<-.<-.<-.<-.<- \\n"")\n    print(""List of Contour-Points ::: \\n"")\n    print(feobj3.getListOfContourPoints())\n    print(""\\n"")\n    print(""Hierarchy of extracted contours ::: \\n"")\n    print(feobj3.getHierarchyOfContours())\n    print(""\\n"")\n    print(""List of moments for corresponding-contours ::: \\n"")\n    print(feobj3.getListOfMomentsForCorrespondingContours())\n    print(""\\n"")\n    print(""List of centroids for corresponding-contours ::: \\n"")\n    print(feobj3.getListOfCentroidsForCorrespondingContours())\n    print(""\\n"")\n    print(""List of areas for corresponding-contours ::: \\n"")\n    print(feobj3.getListOfAreasForCorrespondingContours())\n    print(""\\n"")\n    print(""List of perimeters for corresponding-contours ::: \\n"")\n    print(feobj3.getListOfPerimetersForCorrespondingContours())\n    print(""\\n"")\n    print(""Mean_Edge of covering rectangle for lesion img %f \\n"" % feobj3.getMeanEdgeOfCoveringRect())\n    print(""Bounded_Circle radius %f \\n"" % feobj3.getBoundedCircRadius())\n    print(""Asymmetry-Index of lesion %f \\n"" % feobj3.getAsymmetryIndex())\n    print(""Compact-Index of lesion %f \\n"" % feobj3.getCompactIndex())\n    print(""Fractal-Dimension of lesion %f \\n"" % feobj3.getFractalDimension())\n    print(""Diameter of lesion %f \\n"" % feobj3.getDiameter())\n    print(""Color-Variance of lesion %f \\n"" % feobj3.getColorVariance())\n\ndef __createDataSet(restype, img_num):\n    print(""------------------+++++++++++++============FOR %s SET==============++++++++++++++---------------------- \\n"" % restype.upper())\n    if (((pathlib.Path(\'dataset.npz\')).exists() == True) & ((pathlib.Path(\'dataset.npz\')).is_file() == True)):\n        dset, featnames = (np.load(\'dataset.npz\'))[\'dset\'], (np.load(\'dataset.npz\'))[\'featnames\']\n    else:\n        dset = np.empty(0, dtype=np.dtype([(\'featureset\', float, (34,)), (\'result\', object)]), order=\'C\')\n        featnames = np.array([\'ASM\', \'ENERGY\', \'ENTROPY\', \'CONTRAST\', \'HOMOGENEITY\', \'DM\', \'CORRELATION\', \'HAR-CORRELATION\', \'CLUSTER-SHADE\', \'CLUSTER-PROMINENCE\', \'MOMENT-1\', \'MOMENT-2\', \'MOMENT-3\', \'MOMENT-4\', \'DASM\', \'DMEAN\', \'DENTROPY\', \'TAM-COARSENESS\', \'TAM-CONTRAST\', \'TAM-KURTOSIS\', \'TAM-LINELIKENESS\', \'TAM-DIRECTIONALITY\', \'TAM-REGULARITY\', \'TAM-ROUGHNESS\', \'ASYMMETRY-INDEX\', \'COMPACT-INDEX\', \'FRACTAL-DIMENSION\', \'DIAMETER\', \'COLOR-VARIANCE\', \'KINGS-COARSENESS\', \'KINGS-CONTRAST\', \'KINGS-BUSYNESS\', \'KINGS-COMPLEXITY\', \'KINGS-STRENGTH\'], dtype=object, order=\'C\')\n    for i in range(0, img_num, 1):\n         os.makedirs(\'results/dataset/\' + restype + \'/\' + str(i))\n         global imgcount\n         print(""\\t _-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_ \\t \\n"")\n         print(""Iterating for image - %d \\n"" % i)\n         print(""\\t _-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_ \\t \\n"")\n         obj = p.Prep(\'images/\' + restype + \'/\' + str(i) + \'.jpg\')\n         feobj = har.HarFeat(obj.getSegGrayImg())\n         feobj2 = tam.TamFeat(obj.getSegGrayImg())\n         feobj3 = g.Gabor(obj.getSegGrayImg(), obj.getSegColImg())\n         feobj4 = k.KingFeat(obj.getSegGrayImg())\n         __showImages([(obj.getActImg(), \'imgcol\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'imgcol\' + str(imgcount) + \'.jpg\'),\n                       (obj.getGrayImg(), \'imggray\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'imggray\' + str(imgcount) + \'.jpg\'),\n                       (obj.getInvrtGrayImg(), \'imggrayinvrt\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'imggrayinvrt\' + str(imgcount) + \'.jpg\'),\n                       (obj.getBinaryImg(), \'imgbin\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'imgbin\' + str(imgcount) + \'.jpg\'),\n                       (obj.getSegColImg(), \'segimgcol\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'segimgcol\' + str(imgcount) + \'.jpg\'),\n                       (obj.getSegGrayImg(), \'segimggray\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'segimggray\' + str(imgcount) + \'.jpg\'),\n                       (feobj2.getPrewittHorizontalEdgeImg(), \'PrewittX\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'PrewittX\' + str(imgcount) + \'.jpg\'),\n                       (feobj2.getPrewittVerticalEdgeImg(), \'PrewittY\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'PrewittY\' + str(imgcount) + \'.jpg\'),\n                       (feobj2.getCombinedPrewittImg(), \'PrewittIMG\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'PrewittIMG\' + str(imgcount) + \'.jpg\'),\n                       (feobj3.getGaussianBlurredImage(), \'gblurimg\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'gblurimg\' + str(imgcount) + \'.jpg\'),\n                       (feobj3.getSelectedContourImg(), \'slccntimg\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'slccntimg\' + str(imgcount) + \'.jpg\'),\n                       (feobj3.getBoundingRectImg(), \'bndrectimg\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'bndrectimg\' + str(imgcount) + \'.jpg\'),\n                       (feobj3.getBoundedCircImg(), \'bndcircimg\' + str(imgcount), \'results/dataset/\' + restype + \'/\' + str(imgcount) + \'/\' + \'bndcircimg\' + str(imgcount) + \'.jpg\')])\n         __showHaralickFeatures(feobj)\n         __showTamuraFeatures(feobj2)\n         __showKingsFeatures(feobj4)\n         __showGaborPhysicalFeatures(feobj3)\n         featarr = np.empty(0, dtype=float, order=\'C\')\n         featarr = np.insert(featarr, featarr.size, feobj.getAngularSecondMomentASM(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getEnergy(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getEntropy(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getContrast(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getHomogeneity(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getDm(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getCorrelation(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getHarCorrelation(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getClusterShade(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getClusterProminence(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getMoment1(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getMoment2(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getMoment3(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getMoment4(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getDasm(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getDmean(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj.getDentropy(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj2.getCoarseness(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj2.getContrast(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj2.getKurtosis(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj2.getLineLikeness(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj2.getDirectionality(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj2.getRegularity(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj2.getRoughness(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj3.getAsymmetryIndex(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj3.getCompactIndex(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj3.getFractalDimension(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj3.getDiameter(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj3.getColorVariance(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj4.getKingsCoarseness(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj4.getKingsContrast(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj4.getKingsBusyness(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj4.getKingsComplexity(), 0)\n         featarr = np.insert(featarr, featarr.size, feobj4.getKingsStrength(), 0)\n         dset = np.insert(dset, dset.size, (featarr, restype), 0)\n         imgcount = imgcount + 1\n    print(featnames)\n    print(dset)\n    print(dset[\'featureset\'])\n    print(dset[\'result\'])\n    print(""\\n"")\n    np.savez(\'dataset\', dset=dset, featnames=featnames)\n\ndef __createAndTrainMlModels():\n    dset, featnames = (np.load(\'dataset.npz\'))[\'dset\'], (np.load(\'dataset.npz\'))[\'featnames\']\n    CLF.Classifiers(featureset=dset[\'featureset\'], target=__convertTargetTypeToInt(dset[\'result\']), mode=\'train\', path=\'mlmodels/\')\n    print(""Training successfully completed!!! \\n"")\n\ndef __getTestImages():\n    count = 0\n    dset = np.empty(0, dtype=np.dtype([(\'featureset\', float, (34,)), (\'result\', object)]), order=\'C\')\n    featnames = np.array([\'ASM\', \'ENERGY\', \'ENTROPY\', \'CONTRAST\', \'HOMOGENEITY\', \'DM\', \'CORRELATION\', \'HAR-CORRELATION\', \'CLUSTER-SHADE\', \'CLUSTER-PROMINENCE\', \'MOMENT-1\', \'MOMENT-2\', \'MOMENT-3\', \'MOMENT-4\', \'DASM\', \'DMEAN\', \'DENTROPY\', \'TAM-COARSENESS\', \'TAM-CONTRAST\', \'TAM-KURTOSIS\', \'TAM-LINELIKENESS\', \'TAM-DIRECTIONALITY\', \'TAM-REGULARITY\', \'TAM-ROUGHNESS\', \'ASYMMETRY-INDEX\', \'COMPACT-INDEX\', \'FRACTAL-DIMENSION\', \'DIAMETER\', \'COLOR-VARIANCE\', \'KINGS-COARSENESS\', \'KINGS-CONTRAST\', \'KINGS-BUSYNESS\', \'KINGS-COMPLEXITY\', \'KINGS-STRENGTH\'], dtype=object, order=\'C\')\n    while(True):\n        os.makedirs(\'results/testset/\' + str(count))\n        print(""\\t _-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_ \\t \\n"")\n        print(""Iterating for image - %d \\n"" % count)\n        print(""\\t _-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_ \\t \\n"")\n        imgnm = str(input(\'Enter image name : \\n\'))\n        obj = p.Prep(\'temp/\' + imgnm)\n        feobj = har.HarFeat(obj.getSegGrayImg())\n        feobj2 = tam.TamFeat(obj.getSegGrayImg())\n        feobj3 = g.Gabor(obj.getSegGrayImg(), obj.getSegColImg())\n        feobj4 = k.KingFeat(obj.getSegGrayImg())\n        __showImages([(obj.getActImg(), \'imgcol\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'imgcol\' + str(count) + \'.jpg\'),\n                      (obj.getGrayImg(), \'imggray\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'imggray\' + str(count) + \'.jpg\'),\n                      (obj.getInvrtGrayImg(), \'imggrayinvrt\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'imggrayinvrt\' + str(count) + \'.jpg\'),\n                      (obj.getBinaryImg(), \'imgbin\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'imgbin\' + str(count) + \'.jpg\'),\n                      (obj.getSegColImg(), \'segimgcol\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'segimgcol\' + str(count) + \'.jpg\'),\n                      (obj.getSegGrayImg(), \'segimggray\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'segimggray\' + str(count) + \'.jpg\'),\n                      (feobj2.getPrewittHorizontalEdgeImg(), \'PrewittX\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'PrewittX\' + str(count) + \'.jpg\'),\n                      (feobj2.getPrewittVerticalEdgeImg(), \'PrewittY\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'PrewittY\' + str(count) + \'.jpg\'),\n                      (feobj2.getCombinedPrewittImg(), \'PrewittIMG\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'PrewittIMG\' + str(count) + \'.jpg\'),\n                      (feobj3.getGaussianBlurredImage(), \'gblurimg\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'gblurimg\' + str(count) + \'.jpg\'),\n                      (feobj3.getSelectedContourImg(), \'slccntimg\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'slccntimg\' + str(count) + \'.jpg\'),\n                      (feobj3.getBoundingRectImg(), \'bndrectimg\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'bndrectimg\' + str(count) + \'.jpg\'),\n                      (feobj3.getBoundedCircImg(), \'bndcircimg\' + str(count), \'results/testset/\' + str(count) + \'/\' + \'bndcircimg\' + str(count) + \'.jpg\')])\n        __showHaralickFeatures(feobj)\n        __showTamuraFeatures(feobj2)\n        __showKingsFeatures(feobj4)\n        __showGaborPhysicalFeatures(feobj3)\n        featarr = np.empty(0, dtype=float, order=\'C\')\n        featarr = np.insert(featarr, featarr.size, feobj.getAngularSecondMomentASM(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getEnergy(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getEntropy(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getContrast(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getHomogeneity(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getDm(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getCorrelation(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getHarCorrelation(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getClusterShade(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getClusterProminence(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getMoment1(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getMoment2(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getMoment3(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getMoment4(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getDasm(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getDmean(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj.getDentropy(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj2.getCoarseness(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj2.getContrast(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj2.getKurtosis(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj2.getLineLikeness(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj2.getDirectionality(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj2.getRegularity(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj2.getRoughness(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj3.getAsymmetryIndex(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj3.getCompactIndex(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj3.getFractalDimension(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj3.getDiameter(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj3.getColorVariance(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj4.getKingsCoarseness(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj4.getKingsContrast(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj4.getKingsBusyness(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj4.getKingsComplexity(), 0)\n        featarr = np.insert(featarr, featarr.size, feobj4.getKingsStrength(), 0)\n        dset = np.insert(dset, dset.size, (featarr, str(input(\'Enter your result : \\n\'))), 0)\n        count = count + 1\n        if(str(input(\'Do you want to enter more images?? \\n\')) == \'y\'):\n            continue\n        else:\n            break\n    print(featnames)\n    print(dset)\n    print(dset[\'featureset\'])\n    print(dset[\'result\'])\n    print(""\\n"")\n    np.savez(\'testcase\', dset=dset, featnames=featnames)\n\ndef __convertTargetTypeToInt(arr):\n    cvt_arr = np.zeros((arr.size,), int, \'C\')\n    for i in range(0, arr.size, 1):\n        if (arr[i] == \'malignant\'):\n            cvt_arr[i] = 1\n        elif (arr[i] == \'negative\'):\n            cvt_arr[i] = -1\n        else:\n            continue\n    return cvt_arr\n\ndef __convertTargetTypeToStr(arr):\n    cvt_arr = np.empty((arr.size,), object, \'C\')\n    for i in range(0, arr.size, 1):\n        if (int(np.round(arr[i])) >= 1):\n            cvt_arr[i] = \'malignant\'\n        elif (int(np.round(arr[i])) <= -1):\n            cvt_arr[i] = \'negative\'\n        elif (int(np.round(arr[i])) == 0):\n            cvt_arr[i] = \'benign\'\n        else:\n            pass\n    return cvt_arr\n\ndef __predictFromSavedTestCase():\n    clasfobj = CLF.Classifiers(path=\'mlmodels/\')\n    dset, featnames = (np.load(\'testcase.npz\'))[\'dset\'], (np.load(\'testcase.npz\'))[\'featnames\']\n    print(featnames)\n    print(dset)\n    print(dset[\'featureset\'])\n    print(dset[\'result\'])\n    print(""\\n"")\n    print(""Now predicting results : \\n \\n"")\n    pred_res = clasfobj.predicto(dset[\'featureset\'], __convertTargetTypeToInt(dset[\'result\']))\n    return pred_res\n\ndef __printPredResWithProperFormatting(predres, type=None):\n    if (type == \'SVM\'):\n        print(""FOR SVM - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'SVM\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'SVM\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'SVM\'])[\'Accuracy\'] * 100) + ""\\n"")\n    elif (type == \'SVR\'):\n        print(""FOR SVR - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'SVR\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'SVR\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'SVR\'])[\'Accuracy\'] * 100) + ""\\n"")\n    elif (type == \'NuSVM\'):\n        print(""FOR NuSVM - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'NuSVM\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'NuSVM\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'NuSVM\'])[\'Accuracy\'] * 100) + ""\\n"")\n    elif (type == \'NuSVR\'):\n        print(""FOR NuSVR - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'NuSVR\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'NuSVR\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'NuSVR\'])[\'Accuracy\'] * 100) + ""\\n"")\n    elif (type == \'LinSVM\'):\n        print(""FOR LinSVM - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'LinSVM\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'LinSVM\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'LinSVM\'])[\'Accuracy\'] * 100) + ""\\n"")\n    elif (type == \'LinSVR\'):\n        print(""FOR LinSVR - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'LinSVR\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'LinSVR\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'LinSVR\'])[\'Accuracy\'] * 100) + ""\\n"")\n    elif (type == \'MLPC\'):\n        print(""FOR MLPC - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'MLPC\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'MLPC\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'MLPC\'])[\'Accuracy\'] * 100) + ""\\n"")\n    elif (type == \'MLPR\'):\n        print(""FOR MLPR - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'MLPR\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'MLPR\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'MLPR\'])[\'Accuracy\'] * 100) + ""\\n"")\n    elif (type == \'DTC\'):\n        print(""FOR DTC - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'DTC\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'DTC\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'DTC\'])[\'Accuracy\'] * 100) + ""\\n"")\n    elif (type == \'DTR\'):\n        print(""FOR DTR - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'DTR\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'DTR\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'DTR\'])[\'Accuracy\'] * 100) + ""\\n"")\n    elif (type == \'RFC\'):\n        print(""FOR RFC - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'RFC\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'RFC\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'RFC\'])[\'Accuracy\'] * 100) + ""\\n"")\n    elif (type == \'RFR\'):\n        print(""FOR RFR - \\n Prediction results (String) : "" + str(__convertTargetTypeToStr((predres[\'RFR\'])[\'Prediction Results\'])) + "" \\n Prediction results (raw) : "" + str((predres[\'RFR\'])[\'Prediction Results\']) + "" \\n Prediction Accuracy : "" + str((predres[\'RFR\'])[\'Accuracy\'] * 100) + ""\\n"")\n    else:\n        print(""Please enter the correct model acronym!! Your imaginary model does not exist in our model dictionary, sorry!! \\n"")\n        print(""Now exiting from prediction mode!! \\n"")\n\ndef __printfeatsfromfile(fl=\'testcase.npz\'):\n    dset, featnames = (np.load(fl))[\'dset\'], (np.load(fl))[\'featnames\']\n    for i in range(0, ((dset[\'featureset\']).shape)[0], 1):\n        print(""~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \\n"")\n        print(""Printing features for stored image - %d \\n"" % i)\n        for j in range(0, ((dset[\'featureset\']).shape)[1], 1):\n            print("" %s \\t -:- \\t %f \\n"" % (str(featnames[j]), (dset[\'featureset\'])[i,j]))\n        print(""Image is of type --- %s \\n"" % (str((dset[\'result\'])[i])).upper())\n        print(""~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \\n"")\n\ndef __listFilesInDir(loc):\n     return list([str(flnm) for flnm in os.listdir(loc) if os.path.isfile(os.path.join(loc, flnm))])\n\ndef main_menu():\n    print(""^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^_______WELCOME TO THE MELANOMA-PREDICTION PROGRAM_______^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \\n"")\n    print(""\\t This is a nascent approach towards detecting Melanoma-Skin-Lesion, using OpenCV, NumPY, Matplotlib and SciKit in Python Programming Language. \\n"")\n    print(""\\t This project utilizes some of the core concepts of \\\'DIGITAL IMAGE PROCESSING\\\' & \\\'MACHINE LEARNING\\\'. \\n"")\n    print(""\\t This program can categorize the cancerous-lesion as Malignant, Benign or Negative. \\n"")\n    print(""\\t Try understanding the meaning of each option, before selecting the appropriate one. \\n"")\n    while (True):\n       print(""\\t Available options are given below : \\n"")\n       print(""\\t 1.Create \\\'training-dataset\\\' from the images of known ->MELANOMA<- types!! \\n"")\n       print(""\\t 2.Train classifiers and regressors on the created \\\'training-dataset\\\'!! \\n"")\n       print(""\\t 3.Create \\\'testing-dataset\\\' from the supervised images in temp folder!! \\n"")\n       print(""\\t 4.Predict results from the \\\'testcase.npz\\\' numpy file!! \\n"")\n       print(""\\t 5.Print \\\'feature-descriptors\\\' of images strored in numpy files, \\\'dataset.npz\\\' or \\\'testcase.npz\\\'!! \\n"")\n       print(""\\t 6.Plot \\\'Classifier/Regressor\\\' graphs!! \\n"")\n       print(""\\t 7.Add the \\\'feature-sets\\\' to \\\'testcase.npz\\\' or \\\'dataset.npz\\\' numpy files, to make mlmodels more accurate!! \\n"")\n       print(""\\t 8.Print only the selected \\\'feature-sets\\\' of an image!! \\n"")\n       print(""\\t 9.List files present in valid \\\'project-directories\\\'!! \\n"")\n       print(""\\t 10.Get color plates of an image!! \\n"")\n       print(""\\t Enter \\\'e\\\' to exit!! \\n"")\n       c = str(input(""Enter your choice - \\n""))\n       if (c == \'1\'):\n           print(""If you see a \\\'results\\\' folder in the root directory of the project, delete the \\\'dataset\\\' folder in it. \\n"")\n           print(""Now, before you proceed, just make sure that you have your corresponding images in the \\\'images\\\' folder under the \\\'malignant\\\', \\\'benign\\\' or \\\'negative\\\' directories. \\n"")\n           print(""If you haven\'t already made the directories, please make them and place the corresponding images in them. \\n"")\n           print(""The image file-names must be numeric starting from 0 in sequence under each category folder. \\n"")\n           print(""Eg. - 0.jpg, 1.jpg, 2.jpg, ..... etc \\n"")\n           print(""You must provide images under each category!!! \\n"")\n           input(""Just press any key when your are ready : \\n"")\n           __createDataSet(""malignant"", int(input(""Enter the number of images you placed under the \\\'images/malignant\\\' directory - \\n"")))\n           __createDataSet(""benign"", int(input(""Enter the number of images you placed under the \\\'images/benign\\\' directory - \\n"")))\n           __createDataSet(""negative"", int(input(""Enter the number of images you placed under the \\\'images/negative\\\' directory - \\n"")))\n           print(""\\\'Training-Dataset\\\' successfully generated!! \\n"")\n           print(""This dataset consists of the features-array of the corresponding images and their classified types. \\n"")\n           print(""All results are stored in the numpy file \\\'dataset.npz\\\'. \\n"")\n           print(""Total training-images count : %d \\n"" % imgcount)\n       elif (c == \'2\'):\n           print(""Now we\'ll train our various classifiers and regressors on the training-data stored in the \\\'dataset.npz\\\' numpy file. \\n"")\n           print(""All machine-learning models will be saved as individual \\\'.pkl\\\' files in the \\\'mlmodels\\\' python-package. \\n"")\n           __createAndTrainMlModels()\n           print(""Training is now complete!! \\n"")\n       elif (c == \'3\'):\n           print(""If you see a \\\'results\\\' folder in the root directory of the project, delete the \\\'testset\\\' folder in it. \\n"")\n           print(""Now, before you proceed, just make sure that you have your test-images in the \\\'temp\\\' folder. \\n"")\n           print(""If you haven\'t already made the directories, please make them and place the test-images in them. \\n"")\n           input(""Just press any key when your are ready : \\n"")\n           __getTestImages()\n           print(""\\\'Testing-Dataset\\\' successfully generated!! \\n"")\n           print(""This dataset consists of the features-array of the test-images and their supervised-classified types. \\n"")\n           print(""All results are stored in the numpy file \\\'testset.npz\\\' \\n"")\n       elif (c == \'4\'):\n           print(""This will predict results from \\\'testcase.npz\\\' and also calculate the prediction accuracy of the individual models. \\n"")\n           pred_res = __predictFromSavedTestCase()\n           print(""Before we start, here is the reference legend __ \\n"")\n           print(""\\\'1\\\' : MALIGNANT. \\n"")\n           print(""\\\'0\\\' : BENIGN. \\n"")\n           print(""\\\'-1\\\' : NEGATIVE. \\n"")\n           while (True):\n              type = str(input(\'Select Classifier/Regressor acronym : \\n\'))\n              if (type in pred_res):\n                    __printPredResWithProperFormatting(pred_res, type)\n              else:\n                  __printPredResWithProperFormatting(pred_res)\n                  break\n       elif (c == \'5\'):\n           print(""This option prints the features of the images stored in the \\\'testcase.npz\\\' numpy file, by default. \\n"")\n           print(""You can also print the values stored in the \\\'dataset.npz\\\' file, just enter this file-name below. \\n"")\n           print(""Before you print the feature-contents, make sure that you had previously generated the \\\'dataset.npz\\\' and \\\'testcase.npz\\\' numpy files. \\n"")\n           __printfeatsfromfile(str(input(\'Enter the filename : \\n\')))\n           print(""PRINTING COMPLETE!!! \\n"")\n       elif (c == \'6\'):\n           print(""\\t Before you proceed, make sure that you had previously generated the \\\'dataset.npz\\\' numpy file which is existing in the root directory of the project!!! \\n"")\n           dset, featnames = (np.load(\'dataset.npz\'))[\'dset\'], (np.load(\'dataset.npz\'))[\'featnames\']\n           print(""\\t Given below are the set of features, along with their corresponding indexes. \\n"")\n           for count in range(0, featnames.size, 1):\n               print(str(count)+"". ""+str(featnames[count])+"" \\n"")\n           print(""You have to select a combination of any two features!! \\n"")\n           print(""You can also enter multiple combinations, in such a case they will be appended to a list!! \\n"")\n           flist = []\n           fnlist = []\n           while(True):\n               feat_corrs = [int(input(\'Enter the index of first feature ... \\n\')), int(input(\'Enter the index of second feature ... \\n\'))]\n               flist.append(feat_corrs)\n               fnlist.append([featnames[feat_corrs[0]], featnames[feat_corrs[1]]])\n               if (str(input(\'Do you want to add more feature combinations?? - (y/n) \\n\')) == \'y\'):\n                   continue\n               else:\n                   break\n           DSP.plotForAll(dset[\'featureset\'], __convertTargetTypeToInt(dset[\'result\']), flist, fnlist)\n           print(""DONE!!! \\n"")\n       elif (c == \'7\'):\n           def __modify_flnm(string, number):\n               ret_str = """"\n               for char in string:\n                   if (char.isalpha()):\n                       ret_str = ret_str + char\n                   else:\n                       break\n               return (ret_str + str(number) + "".jpg"")\n           def __case7_inner(ptr, typ, flnumber):\n               os.mkdir(""results/dataset/"" + typ + ""/"" + str(flnumber))\n               for name in __listFilesInDir(""results/testset/"" + str(ptr)):\n                   copyfile(src=""results/testset/"" + str(ptr) + ""/"" + name, dst=""results/dataset/"" + typ + ""/"" + str(flnumber) + ""/"" + __modify_flnm(name, flnumber))\n           print(""This option creates a modified \\\'dataset.npz\\\' numpy file. \\n"")\n           print(""This file includes the feature-sets and the supervised classification results of the test-images. \\n"")\n           print(""All the employed mlmodels are automatically re-trained iteratively, on the new modified training-dataset at the end of this step. \\n"")\n           print(""Please bear in mind, that re-training the models on the same test-set again, will result in errors. \\n"")\n           featnames = np.array([\'ASM\', \'ENERGY\', \'ENTROPY\', \'CONTRAST\', \'HOMOGENEITY\', \'DM\', \'CORRELATION\', \'HAR-CORRELATION\', \'CLUSTER-SHADE\', \'CLUSTER-PROMINENCE\', \'MOMENT-1\', \'MOMENT-2\', \'MOMENT-3\', \'MOMENT-4\', \'DASM\', \'DMEAN\', \'DENTROPY\', \'TAM-COARSENESS\', \'TAM-CONTRAST\', \'TAM-KURTOSIS\', \'TAM-LINELIKENESS\', \'TAM-DIRECTIONALITY\', \'TAM-REGULARITY\', \'TAM-ROUGHNESS\', \'ASYMMETRY-INDEX\', \'COMPACT-INDEX\', \'FRACTAL-DIMENSION\', \'DIAMETER\', \'COLOR-VARIANCE\', \'KINGS-COARSENESS\', \'KINGS-CONTRAST\', \'KINGS-BUSYNESS\', \'KINGS-COMPLEXITY\', \'KINGS-STRENGTH\'], dtype=object, order=\'C\')\n           nfls = list([len(__listFilesInDir(""images/"" + str(cls))) for cls in (\'benign\', \'malignant\', \'negative\')])\n           trainset, testset = (np.load(\'dataset.npz\'))[\'dset\'], (np.load(\'testcase.npz\'))[\'dset\']\n           for feat, index in zip(testset, range(0, testset.size, 1)):\n               if (feat[1] == \'benign\'):\n                   copyfile(src=""temp/""+str(index)+"".jpg"", dst=""images/""+str(feat[1])+""/""+str(nfls[0])+"".jpg"")\n                   __case7_inner(index, feat[1], nfls[0])\n                   trainset = np.insert(trainset, (nfls[1]+nfls[0]), feat, 0)\n                   nfls[0] = nfls[0] + 1\n               elif (feat[1] == \'malignant\'):\n                   copyfile(src=""temp/""+str(index)+"".jpg"", dst=""images/""+str(feat[1])+""/""+str(nfls[1])+"".jpg"")\n                   __case7_inner(index, feat[1], nfls[1])\n                   trainset = np.insert(trainset, nfls[1], feat, 0)\n                   nfls[1] = nfls[1] + 1\n               elif (feat[1] == \'negative\'):\n                   copyfile(src=""temp/""+str(index)+"".jpg"", dst=""images/""+str(feat[1])+""/""+str(nfls[2])+"".jpg"")\n                   __case7_inner(index, feat[1], nfls[2])\n                   trainset = np.insert(trainset, (nfls[1]+nfls[0]+nfls[2]), feat, 0)\n                   nfls[2] = nfls[2] + 1\n               else:\n                   pass\n           np.savez(\'dataset.npz\', dset=trainset, featnames=featnames)\n           __createAndTrainMlModels()\n       elif (c == \'8\'):\n           def __case8_inner(img_gry, img_col):\n                print(""Options for selecting the feature-sets are as follows : \\n"")\n                print(""a. Print \\\'Haralick-Texture\\\' features. \\n"")\n                print(""b. Print \\\'Tamura-Texture\\\' features. \\n"")\n                print(""c. Print \\\'King-Texture\\\' features. \\n"")\n                print(""d. Print \\\'Gabor\\\' physical features. \\n"")\n                print(""Any other character input, will result in a default case, displaying \\\'Feature-Set not found!! Sorry!\\\' \\n"")\n                chc = str(input(""Enter your choice : \\n""))\n                if (chc == \'a\'):\n                    __showImages([(img_col, \'imgcol\', None), (img_gry, \'imggray\', None)])\n                    __showHaralickFeatures(har.HarFeat(img_gry))\n                elif (chc == \'b\'):\n                    tobj = tam.TamFeat(img_gry)\n                    __showImages([(img_col, \'imgcol\', None), (img_gry, \'imggray\', None), (tobj.getPrewittHorizontalEdgeImg(), \'PrewittX\', None), (tobj.getPrewittVerticalEdgeImg(), \'PrewittY\', None), (tobj.getCombinedPrewittImg(), \'PrewittIMG\', None)])\n                    __showTamuraFeatures(tobj)\n                elif (chc == \'c\'):\n                    __showImages([(img_col, \'imgcol\', None), (img_gry, \'imggray\', None)])\n                    __showKingsFeatures(k.KingFeat(img_gry))\n                elif (chc == \'d\'):\n                    gobj = g.Gabor(img_gry, img_col)\n                    __showImages([(img_col, \'imgcol\', None), (img_gry, \'imggray\', None), (gobj.getGaussianBlurredImage(), \'gblurimg\', None), (gobj.getSelectedContourImg(), \'slccntimg\', None), (gobj.getBoundingRectImg(), \'bndrectimg\', None), (gobj.getBoundedCircImg(), \'bndcircimg\', None)])\n                    __showGaborPhysicalFeatures(gobj)\n                else:\n                    print(""Oopsy-Daisy!! Feature-Set not found!! Sorry!! Please enter the correct character!! \\n"")\n           print(""\\t In this step we\'ll get the selected feature-sets of the input-image(will be converted to gray-scale) and print them on screen!! \\n"")\n           print(""\\t Initially we\'ll perform some pre-processing operations on the original gray-scale image and create some variants!! \\n"")\n           print(""\\t You\'ll get the option of selecting either the pre-processed image variants or the original gray-scale image for getting the selected feature-set!! \\n"")\n           print(""\\t Before you proceed, make-sure to create a \\\'test\\\' directory inside the project root and place the required images there!! \\n"")\n           print(""\\t No-worries if you had created the \\\'test\\\' directory before, just place your images of choice in there!! \\n"")\n           print(""\\t All features are generated over gray-scale images, hence your original color image will be converted to it\'s corresponding gray-scale image!! \\n"")\n           obj = p.Prep(\'test/\' + str(input(""Enter file-name of image : \\n"")))\n           print(""Otsu\'s threshold-level for the input-image is %d \\n"" % obj.getOtsuThresholdLevel())\n           print(""Options for selecting the image-variant are as follows : \\n"")\n           print(""a. Select inverted gray-scale image. \\n"")\n           print(""b. Select segmented binary image. \\n"")\n           print(""c. Select segmented gray-scale image. \\n"")\n           print(""Any other character input, will result in a default case, where the selected image will be the original gray-scale image. \\n"")\n           chc = str(input(""Enter your choice : \\n""))\n           if (chc == \'a\'):\n               __case8_inner(obj.getInvrtGrayImg(), obj.getActImg())\n           elif (chc == \'b\'):\n               __case8_inner(obj.getBinaryImg(), obj.getSegColImg())\n           elif (chc == \'c\'):\n               __case8_inner(obj.getSegGrayImg(), obj.getSegColImg())\n           else:\n               __case8_inner(obj.getGrayImg(), obj.getActImg())\n       elif (c == \'9\'):\n           print(""\\t Before you use this option, it is recommended that you go through the project-structure once. \\n"")\n           for fls in __listFilesInDir(str(input(""\\t Please Enter A Valid Directory Path. \\n""))):\n               print(fls + \'\\n\')\n           print(""\\t Successfully Listed All File-Names. \\n"")\n       elif (c == \'10\'):\n           print(""\\t This option displays the 3 individual color-plates(R-G-B) of the test image placed in the \\\'/test\\\' directory. \\n"")\n           print(""\\t Before you proceed make sure that you have created the \\\'test\\\' directory and placed the corresponding images there. \\n"")\n           obj = p.Prep(\'test/\' + str(input(""Enter file-name of image : \\n"")))\n           __showImages([(obj.getActImg(), \'act_img\', None), (obj.getSegColImg(), \'act_seg_img\', None), (obj.getColorPlates(obj.getActImg(), \'R\'), \'act_img_red\', None), (obj.getColorPlates(obj.getActImg(), \'G\'), \'act_img_green\', None), (obj.getColorPlates(obj.getActImg(), \'B\'), \'act_img_blue\', None), (obj.getColorPlates(obj.getSegColImg(), \'R\'), \'seg_img_red\', None), (obj.getColorPlates(obj.getSegColImg(), \'G\'), \'seg_img_green\', None), (obj.getColorPlates(obj.getSegColImg(), \'B\'), \'seg_img_blue\', None)])\n           print(""\\t DONE !!! \\n"")\n       else:\n           print(""Thank-You For Using This Program!!!"")\n           print(""Now Exiting."")\n           break\n\nmain_menu()\n\n\n\n'"
featext/__init__.py,0,b''
mlmodels/Classifiers.py,0,"b""from sklearn.externals import joblib\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.svm import NuSVC, NuSVR\nfrom sklearn.svm import LinearSVC, LinearSVR\nfrom sklearn.neural_network import MLPClassifier as MLPC\nfrom sklearn.neural_network import MLPRegressor as MLPR\nfrom sklearn.tree import DecisionTreeClassifier as DTC\nfrom sklearn.tree import DecisionTreeRegressor as DTR\nfrom sklearn.ensemble import RandomForestClassifier as RFC\nfrom sklearn.ensemble import RandomForestRegressor as RFR\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import explained_variance_score\n\nclass Classifiers(object):\n\n    def __init__(self, featureset=None, target=None, mode='predict', path=''):\n        if (mode == 'train'):\n            self.__svm = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n            self.__svr = SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto', kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n            self.__nusvm = NuSVC(cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, nu=0.5, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n            self.__nusvr = NuSVR(C=1.0, cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf', max_iter=-1, nu=0.5, shrinking=True, tol=0.001, verbose=False)\n            self.__linsvm = LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True, intercept_scaling=1, loss='squared_hinge', max_iter=1000, multi_class='ovr', penalty='l2', random_state=None, tol=0.0001, verbose=0)\n            self.__linsvr = LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True, intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000, random_state=None, tol=0.0001, verbose=0)\n            self.__mlpc = MLPC(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08, hidden_layer_sizes=(100, 25), learning_rate='constant', learning_rate_init=0.001, max_iter=200, momentum=0.9, nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False, warm_start=False)\n            self.__mlpr = MLPR(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08, hidden_layer_sizes=(100, 25), learning_rate='constant', learning_rate_init=0.001, max_iter=200, momentum=0.9, nesterovs_momentum=True, power_t=0.5, random_state=None, shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False, warm_start=False)\n            self.__dtc = DTC(class_weight=None, criterion='gini', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter='best')\n            self.__dtr = DTR(criterion='mse', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter='best')\n            self.__rfc = RFC(bootstrap=True, class_weight=None, criterion='gini', max_depth=100, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False)\n            self.__rfr = RFR(bootstrap=True, criterion='mse', max_depth=None, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False)\n            (self.__svm, self.__svr, self.__nusvm, self.__nusvr, self.__linsvm, self.__linsvr, self.__mlpc, self.__mlpr, self.__dtc, self.__dtr, self.__rfc, self.__rfr) = self.__trainAll(X=list(featureset), Y=list(target))\n            self.__saveModelsToFile(path)\n        else:\n            self.__svm = joblib.load(path + 'Mel_SVM.pkl')\n            self.__svr = joblib.load(path + 'Mel_SVR.pkl')\n            self.__nusvm = joblib.load(path + 'Mel_NuSVM.pkl')\n            self.__nusvr = joblib.load(path + 'Mel_NuSVR.pkl')\n            self.__linsvm = joblib.load(path + 'Mel_LinSVM.pkl')\n            self.__linsvr = joblib.load(path + 'Mel_LinSVR.pkl')\n            self.__mlpc = joblib.load(path + 'Mel_MLPC.pkl')\n            self.__mlpr = joblib.load(path + 'Mel_MLPR.pkl')\n            self.__dtc = joblib.load(path + 'Mel_DTC.pkl')\n            self.__dtr = joblib.load(path + 'Mel_DTR.pkl')\n            self.__rfc = joblib.load(path + 'Mel_RFC.pkl')\n            self.__rfr = joblib.load(path + 'Mel_RFR.pkl')\n\n    def __trainAll(self, X, Y):\n        return ((self.__svm).fit(X, Y), (self.__svr).fit(X, Y), (self.__nusvm).fit(X, Y), (self.__nusvr).fit(X, Y), (self.__linsvm).fit(X, Y), (self.__linsvr).fit(X, Y), (self.__mlpc).fit(X, Y), (self.__mlpr).fit(X, Y), (self.__dtc).fit(X, Y), (self.__dtr).fit(X, Y), (self.__rfc).fit(X, Y), (self.__rfr).fit(X, Y))\n\n    def __saveModelsToFile(self, path):\n        joblib.dump(self.__svm, (path + 'Mel_SVM.pkl'))\n        joblib.dump(self.__svr, (path + 'Mel_SVR.pkl'))\n        joblib.dump(self.__nusvm, (path + 'Mel_NuSVM.pkl'))\n        joblib.dump(self.__nusvr, (path + 'Mel_NuSVR.pkl'))\n        joblib.dump(self.__linsvm, (path + 'Mel_LinSVM.pkl'))\n        joblib.dump(self.__linsvr, (path + 'Mel_LinSVR.pkl'))\n        joblib.dump(self.__mlpc, (path + 'Mel_MLPC.pkl'))\n        joblib.dump(self.__mlpr, (path + 'Mel_MLPR.pkl'))\n        joblib.dump(self.__dtc, (path + 'Mel_DTC.pkl'))\n        joblib.dump(self.__dtr, (path + 'Mel_DTR.pkl'))\n        joblib.dump(self.__rfc, (path + 'Mel_RFC.pkl'))\n        joblib.dump(self.__rfr, (path + 'Mel_RFR.pkl'))\n\n    def predicto(self, extfeatarr, supresults):\n        svm_res = (self.__svm).predict(list(extfeatarr))\n        svr_res = (self.__svr).predict(list(extfeatarr))\n        nusvm_res = (self.__nusvm).predict(list(extfeatarr))\n        nusvr_res = (self.__nusvr).predict(list(extfeatarr))\n        linsvm_res = (self.__linsvm).predict(list(extfeatarr))\n        linsvr_res = (self.__linsvr).predict(list(extfeatarr))\n        mlpc_res = (self.__mlpc).predict(list(extfeatarr))\n        mlpr_res = (self.__mlpr).predict(list(extfeatarr))\n        dtc_res = (self.__dtc).predict(list(extfeatarr))\n        dtr_res = (self.__dtr).predict(list(extfeatarr))\n        rfc_res = (self.__rfc).predict(list(extfeatarr))\n        rfr_res = (self.__rfr).predict(list(extfeatarr))\n        return ({\n                    'SVM' : { 'Prediction Results' : svm_res, 'Accuracy' : accuracy_score(list(supresults), svm_res)},\n                    'SVR': {'Prediction Results': svr_res, 'Accuracy': explained_variance_score(list(supresults), svr_res)},\n                    'NuSVM': {'Prediction Results': nusvm_res, 'Accuracy': accuracy_score(list(supresults), nusvm_res)},\n                    'NuSVR': {'Prediction Results': nusvr_res, 'Accuracy': explained_variance_score(list(supresults), nusvr_res)},\n                    'LinSVM': {'Prediction Results': linsvm_res, 'Accuracy': accuracy_score(list(supresults), linsvm_res)},\n                    'LinSVR': {'Prediction Results': linsvr_res, 'Accuracy': explained_variance_score(list(supresults), linsvr_res)},\n                    'MLPC': {'Prediction Results': mlpc_res, 'Accuracy': accuracy_score(list(supresults), mlpc_res)},\n                    'MLPR': {'Prediction Results': mlpr_res, 'Accuracy': explained_variance_score(list(supresults), mlpr_res)},\n                    'DTC': {'Prediction Results': dtc_res, 'Accuracy': accuracy_score(list(supresults), dtc_res)},\n                    'DTR': {'Prediction Results': dtr_res, 'Accuracy': explained_variance_score(list(supresults), dtr_res)},\n                    'RFC': {'Prediction Results': rfc_res, 'Accuracy': accuracy_score(list(supresults), rfc_res)},\n                    'RFR': {'Prediction Results': rfr_res, 'Accuracy': explained_variance_score(list(supresults), rfr_res)}\n                })"""
mlmodels/DecisionSurfacePlotter.py,8,"b'import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as Pchs\nfrom sklearn import clone\nfrom sklearn.externals import joblib\nfrom sklearn.ensemble import RandomForestClassifier\n\n(__col_map, __rnd_seed) = (plt.cm.RdYlGn, 13)\n\ndef plotForAll(X, Y, ftup, feats):\n    classifiers = [joblib.load(\'mlmodels/Mel_SVM.pkl\'), joblib.load(\'mlmodels/Mel_NuSVM.pkl\'), joblib.load(\'mlmodels/Mel_LinSVM.pkl\'), joblib.load(\'mlmodels/Mel_MLPC.pkl\'), joblib.load(\'mlmodels/Mel_DTC.pkl\'), joblib.load(\'mlmodels/Mel_RFC.pkl\')]\n    regressors = [joblib.load(\'mlmodels/Mel_SVR.pkl\'), joblib.load(\'mlmodels/Mel_NuSVR.pkl\'), joblib.load(\'mlmodels/Mel_LinSVR.pkl\'), joblib.load(\'mlmodels/Mel_MLPR.pkl\'), joblib.load(\'mlmodels/Mel_DTR.pkl\'), joblib.load(\'mlmodels/Mel_RFR.pkl\')]\n    titles = ()\n    models = []\n    for nplot in range(0, 2, 1):\n        if (nplot == 0):\n            print(""_-__-_ IN CASE OF CLASSIFERS _-__-_ \\n"")\n            titles = (\'SVM\', \'NuSVM\', \'LinSVM\', \'MLPC\', \'DTC\', \'RFC\')\n            plt.figure(""Decision Surface For Classifiers"", edgecolor=\'b\')\n            plt.suptitle(""Plot of Classifiers on feature subsets of the Melanoma-Dataset"")\n            models = classifiers\n        else:\n            print(""_-__-_ IN CASE OF REGRESSORS _-__-_ \\n"")\n            titles = (\'SVR\', \'NuSVR\', \'LinSVR\', \'MLPR\', \'DTR\', \'RFR\')\n            plt.figure(""Decision Surface For Regressors"", edgecolor=\'b\')\n            plt.suptitle(""Plot of Regressors on feature subsets of the Melanoma-Dataset"")\n            models = regressors\n        index = np.arange(0, X.shape[0], 1)\n        plot_index = 1\n        for idx_pair, feat in zip(ftup, feats):\n                x = X[:, idx_pair]\n                np.random.seed(__rnd_seed)\n                np.random.shuffle(index)\n                x = x[index]\n                y = Y[index]\n                x = (x - x.mean(axis=0)) / x.std(axis=0)\n                plt.subplots_adjust(wspace=1.0, hspace=1.0)\n                print("" "" + feat[0] + "" Vs. "" + feat[1] + "" :- \\n"")\n                for mdl, title in zip(models, titles):\n                        obj = plt.subplot(len(ftup), len(models), plot_index)\n                        clf = (clone(mdl)).fit(x, y)\n                        scr = clf.score(x, y)\n                        print(""Feasibility Score For "" + title + "" Model - "" + str(scr * 100))\n                        x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n                        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n                        xx, yy = np.meshgrid(np.arange(x_min, x_max, ((x_max - x_min) / 100.0)), np.arange(y_min, y_max, ((y_max - y_min) / 100.0)))\n                        if isinstance(clf, RandomForestClassifier):\n                            alpha_blend = 1.0 / len(clf.estimators_)\n                            for tree in clf.estimators_:\n                                (obj).contourf(xx, yy, (tree.predict(np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape), alpha=alpha_blend, cmap=__col_map)\n                        else:\n                            (obj).contourf(xx, yy, (clf.predict(np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape), cmap=__col_map)\n                        xx_coarser, yy_coarser = np.meshgrid(np.arange(x_min, x_max, ((x_max - x_min) / 50.0)), np.arange(y_min, y_max, ((y_max - y_min) / 50.0)))\n                        (obj).scatter(xx_coarser, yy_coarser, s=15, c=clf.predict(np.c_[xx_coarser.ravel(), yy_coarser.ravel()]).reshape(xx_coarser.shape), cmap=__col_map, edgecolors=""none"")\n                        (obj).scatter(x[:, 0], x[:, 1], c=y, marker=\'p\', cmap=__col_map, edgecolor=\'k\', s=20)\n                        (obj).set_xlim(xx.min(), xx.max())\n                        (obj).set_ylim(yy.min(), yy.max())\n                        (obj).set_xlabel(feat[0])\n                        (obj).set_ylabel(feat[1])\n                        (obj).set_xticks(())\n                        (obj).set_yticks(())\n                        if (plot_index == (len(ftup) * len(models))):\n                            plt.legend(handles=[Pchs.Patch(color=\'red\', label=\'MALIGNANT\'), Pchs.Patch(color=\'yellow\', label=\'BENIGN\'), Pchs.Patch(color=\'green\', label=\'NEGATIVE\')], loc=\'upper right\', fontsize=\'small\')\n                        if (plot_index <= len(models)):\n                            (obj).set_title(title)\n                        plot_index += 1\n                print(""::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: \\n \\n"")\n    plt.show()'"
mlmodels/__init__.py,0,b''
preprocessing/Prep.py,11,"b""import cv2\nimport numpy as np\nimport math\nfrom util import Util as u\n\nclass Prep(object):\n\n    def __init__(self, path):\n        self.__img = cv2.imread(path, cv2.IMREAD_COLOR)\n        self.__imgray = cv2.cvtColor(self.__img, cv2.COLOR_BGR2GRAY)\n        self.__invimgray = self.__negate()\n        self.__ottlvl = self.__OtsuAutoThresh()\n        self.__binimg = self.__imBinarize()\n        (self.__seg_col, self.__seg_gray) = self.__cvtBinToColAndGray()\n\n    def __negate(self):\n        inv_img = (self.__imgray).copy()\n        (r, c) = inv_img.shape\n        for x in range(0, r, 1):\n            for y in range(0, c, 1):\n                    inv_img[x,y] = np.invert(inv_img[x,y])\n        return inv_img\n\n    def getColorPlates(self, src_clrimg, plate):\n            temp_img = src_clrimg.copy()\n            for x in temp_img:\n                for y in x:\n                    if plate == 'B':\n                        y[1] = 0\n                        y[2] = 0\n                    elif plate == 'G':\n                        y[0] = 0\n                        y[2] = 0\n                    elif plate == 'R':\n                        y[0] = 0\n                        y[1] = 0\n            return temp_img\n\n    def __rmHoles(self, src_binimg):\n            ffill_img = src_binimg.copy()\n            mask = np.zeros((((ffill_img.shape)[0])+2, ((ffill_img.shape)[1])+2), np.uint8, 'C')\n            cv2.floodFill(ffill_img, mask, (0,0), 255)\n            final_img = src_binimg | cv2.bitwise_not(ffill_img)\n            return final_img\n\n    def __OtsuAutoThresh(self):\n        app_grlvls_wth_freq = u.getArrayOfGrayLevelsWithFreq(self.__invimgray)\n        dt = np.dtype([('wcv', float), ('bcv', float), ('glvl', np.uint8)])\n        var_ary = np.empty(0, dt, 'C')\n        for x in range(0, app_grlvls_wth_freq.size, 1):\n                  thrslvl = (app_grlvls_wth_freq[x])[0]\n                  wb = 0.0\n                  mb = 0.0\n                  varb2 = 0.0\n                  wf = 0.0\n                  mf = 0.0\n                  varf2 = 0.0\n                  (wf, mf, varf2) = self.__threshSubPt(x, app_grlvls_wth_freq.size, app_grlvls_wth_freq, wf, mf, varf2)\n                  if (x == 0):\n                      pass\n                  else:\n                      (wb, mb, varb2) = self.__threshSubPt(0, x, app_grlvls_wth_freq, wb, mb, varb2)\n                  wcv = (wb * varb2) + (wf * varf2)\n                  bcv = (wb * wf) * math.pow((mb - mf), 2)\n                  var_ary = np.append(var_ary, np.array([(wcv, bcv, thrslvl)], dtype=dt), 0)\n        u.quickSort(var_ary, 0, var_ary.size - 1)\n        ottlvl = (var_ary[0])[2]\n        return ottlvl\n\n    def __threshSubPt(self, lower, upper, app_grlvls_wth_freq, w, m, var2):\n        for h in range(lower, upper, 1):\n            w = w + (app_grlvls_wth_freq[h])[1]\n            m = m + float(np.uint32((app_grlvls_wth_freq[h])[0]) * np.uint32((app_grlvls_wth_freq[h])[1]))\n        m = m / w\n        for h in range(lower, upper, 1):\n            var2 = var2 + float((math.pow((((app_grlvls_wth_freq[h])[0]) - m), 2)) * ((app_grlvls_wth_freq[h])[1]))\n        var2 = var2 / w\n        w = w / float((math.pow(app_grlvls_wth_freq.size, 2)))\n        return (w, m, var2)\n\n    def __imBinarize(self):\n        binimg = np.zeros((self.__invimgray).shape, np.uint8, 'C')\n        for x in range(0, ((self.__invimgray).shape)[0], 1):\n            for y in range(0, ((self.__invimgray).shape)[1], 1):\n                if (self.__invimgray[x, y] < self.__ottlvl):\n                    binimg[x, y] = np.uint8(0)\n                else:\n                    binimg[x, y] = np.uint8(255)\n        binimg = self.__rmHoles(binimg)\n        return binimg\n\n    def __cvtBinToColAndGray(self):\n        seg_col = np.zeros((self.__img).shape, np.uint8, 'C')\n        seg_gray = np.zeros((self.__imgray).shape, np.uint8, 'C')\n        i = 0\n        for x in seg_col:\n            j = 0\n            for y in x:\n                if ((self.__binimg)[i, j] == 255):\n                    y[0] = (self.__img)[i, j, 0]\n                    y[1] = (self.__img)[i, j, 1]\n                    y[2] = (self.__img)[i, j, 2]\n                    seg_gray[i, j] = self.__imgray[i, j]\n                j = j + 1\n            i = i + 1\n        return (seg_col, seg_gray)\n\n    def getActImg(self):\n        return self.__img\n\n    def getGrayImg(self):\n        return self.__imgray\n\n    def getInvrtGrayImg(self):\n        return self.__invimgray\n\n    def getBinaryImg(self):\n        return self.__binimg\n\n    def getOtsuThresholdLevel(self):\n        return self.__ottlvl\n\n    def getSegColImg(self):\n        return self.__seg_col\n\n    def getSegGrayImg(self):\n        return self.__seg_gray\n"""
preprocessing/__init__.py,0,b''
util/Util.py,7,"b""import numpy as np\nimport copy\n\ndef search(arr, ins_val, low, high):\n    fnd_idx = -1\n    if (arr.size == 0):\n        pass\n    else:\n        while (low <= high):\n            mid = int(low + ((high - low) / 2))\n            if (ins_val > (arr[mid])[0]):\n                low = mid + 1\n                continue\n            if (ins_val < (arr[mid])[0]):\n                high = mid - 1\n                continue\n            if (ins_val == (arr[mid])[0]):\n                fnd_idx = mid\n                break\n    return fnd_idx\n\ndef quickSort(arr, low, high):\n    if low < high:\n        pi = __partition(arr, low, high)\n        quickSort(arr, low, pi - 1)\n        quickSort(arr, pi + 1, high)\n\ndef __partition(arr, low, high):\n    i = (low - 1)\n    pivot = (arr[high])[0]\n    for j in range(low, high,1):\n        if (arr[j])[0] <= pivot:\n            i = i + 1\n            temp = copy.deepcopy(arr[i])\n            arr[i] = copy.deepcopy(arr[j])\n            arr[j] = copy.deepcopy(temp)\n    temp2 = copy.deepcopy(arr[i+1])\n    arr[i+1] = copy.deepcopy(arr[high])\n    arr[high] = copy.deepcopy(temp2)\n    return (i+1)\n\ndef __ins(arr, ins_val, index):\n    if (arr.size == 0):\n        arr = np.insert(arr, index, (ins_val, np.array([ 1 ], np.uint32)), 0)\n        return arr\n    else:\n        fnd_idx = search(arr, ins_val, 0, arr.size-1)\n        if (fnd_idx >= 0):\n            ((arr[fnd_idx])[1])[0] = np.uint32(((arr[fnd_idx])[1])[0]) + np.uint32(1)\n            return arr\n        else:\n            while (index >= 0):\n                    if (ins_val > (arr[index - 1])[0]):\n                        arr = np.insert(arr, index, (ins_val, np.array([ 1 ], np.uint32)), 0)\n                        break\n                    if (ins_val < (arr[index - 1])[0]):\n                        if (index == 0):\n                            arr = np.insert(arr, index, (ins_val, np.array([ 1 ], np.uint32)), 0)\n                        index = index - 1\n                        continue\n                    else:\n                        ((arr[index - 1])[1])[0] = np.uint32(((arr[index - 1])[1])[0]) + np.uint32(1)\n                        break\n            return arr\n\ndef getArrayOfGrayLevelsWithFreq(gray_img, lvldtype=np.uint8):\n    aryoflst = np.empty(0, np.dtype([('glvl', lvldtype), ('freq', np.uint32, (1,))]), 'C')\n    for x in range(0, (gray_img.shape)[0], 1):\n        for y in range(0, (gray_img.shape)[1], 1):\n            aryoflst = __ins(aryoflst, gray_img[x, y], index=aryoflst.size)\n    return aryoflst\n"""
util/__init__.py,0,b''
featext/physical/Gabor.py,5,"b""import numpy as np\nimport cv2\n\nclass Gabor(object):\n\n        def __init__(self, img, corr_colimg, imtype='color'):\n            tup = cv2.findContours(cv2.GaussianBlur(img, (3, 3), sigmaX=0, sigmaY=0), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n            self.__gblurimg = tup[0]\n            self.__contours = tup[1]\n            self.__hierarchy = tup[2]\n            cnt = self.__selectMostAptContourIndex()\n            self.__momLstForConts = self.__generateMoments()\n            self.__centroidLstForConts = self.__generateCentroidOfCnts()\n            (self.__arLstForConts, self.__periLstForConts) = self.__generateAreaNPeriOfCnts()\n            self.__selecCntImg = self.__generateContourImg(imtype, cnt)\n            (self.__imgcovrect, self.__meanEdge) = self.__generateBoundingRectRotated(imtype, cnt)\n            (self.__imgcovcirc, self.__rad) = self.__generateMinEncCirc(imtype, cnt)\n            self.__asyidxofles = self.__generateAsymmetryIndex(totar=img.size, cnt=cnt)\n            self.__cmptidx = self.__generateCompactIndex(cnt)\n            self.__fracdimen = self.__generateFractalDimension()\n            self.__diameter = self.__calculateDiameter()\n            self.__colorvar = self.__generateColorVariance(corr_colimg)\n\n        def __selectMostAptContourIndex(self):\n            tmplst = [ len(c) for c in self.__contours ]\n            return tmplst.index(max(tmplst))\n\n        def __generateMoments(self):\n            moments = []\n            for c in self.__contours:\n                moments.append(cv2.moments(c))\n            return moments\n\n        def __generateCentroidOfCnts(self):\n            centroids = []\n            for mlc in self.__momLstForConts:\n                coorX = int(mlc['m10'] / mlc['m00'])\n                coorY = int(mlc['m01'] / mlc['m00'])\n                centroids.append((coorX, coorY))\n            return centroids\n\n        def __generateAreaNPeriOfCnts(self):\n            areas = []\n            peri = []\n            for c in self.__contours:\n                areas.append(cv2.contourArea(c))\n                peri.append(cv2.arcLength(c, True))\n            return (areas, peri)\n\n        def __generateContourImg(self, imtype='gray', cnt=0):\n            if (imtype == 'gray'):\n                return cv2.drawContours((self.__gblurimg).copy(), [self.__contours[cnt]], 0, 255, 2, cv2.LINE_AA)\n            else:\n                tmp = cv2.cvtColor(self.__gblurimg, cv2.COLOR_GRAY2BGR)\n                return cv2.drawContours(tmp, [self.__contours[cnt]], 0, (0,255,0), 2, cv2.LINE_AA)\n\n        def __generateBoundingRectRotated(self, imtype='gray', cnt=0):\n            rect = cv2.minAreaRect(self.__contours[cnt])\n            mean_edge = ((rect[1])[0] + ((rect[1])[0])) / 2\n            if (imtype == 'gray'):\n                return (cv2.drawContours((self.__gblurimg).copy(), [np.int0(cv2.boxPoints(rect))], 0, 255, 2, cv2.LINE_AA), mean_edge)\n            else:\n                return (cv2.drawContours(cv2.cvtColor(self.__gblurimg, cv2.COLOR_GRAY2BGR), [np.int0(cv2.boxPoints(rect))], 0, (0,255,0), 2, cv2.LINE_AA), mean_edge)\n\n        def __generateMinEncCirc(self, imtype='gray', cnt=0):\n            (x, y), radius = cv2.minEnclosingCircle(self.__contours[cnt])\n            center = (int(x), int(y))\n            radius = int(radius)\n            if (imtype == 'gray'):\n                return (cv2.circle((self.__gblurimg).copy(), center, radius, 255, 2, cv2.LINE_AA), radius)\n            else:\n                return (cv2.circle(cv2.cvtColor(self.__gblurimg, cv2.COLOR_GRAY2BGR), center, radius, (0,255,0), 2, cv2.LINE_AA), radius)\n\n        def __generateAsymmetryIndex(self, totar, cnt=0):\n            return ((self.__arLstForConts[cnt] / totar) * 100)\n\n        def __generateCompactIndex(self, cnt=0):\n            return (np.power(self.__periLstForConts[cnt], 2) / (4 * np.pi * self.__arLstForConts[cnt]))\n\n        def __generateFractalDimension(self):\n            return (np.log(self.__meanEdge) / np.log(1 / self.__meanEdge))\n\n        def __calculateDiameter(self):\n            return (2 * self.__rad)\n\n        def __generateColorVariance(self, colimg):\n            return (np.var(cv2.cvtColor(colimg, cv2.COLOR_BGR2HSV), axis=None, dtype=float))\n\n        def getGaussianBlurredImage(self):\n            return self.__gblurimg\n\n        def getListOfContourPoints(self):\n            return self.__contours\n\n        def getHierarchyOfContours(self):\n            return self.__hierarchy\n\n        def getListOfMomentsForCorrespondingContours(self):\n            return self.__momLstForConts\n\n        def getListOfCentroidsForCorrespondingContours(self):\n            return self.__centroidLstForConts\n\n        def getListOfAreasForCorrespondingContours(self):\n            return self.__arLstForConts\n\n        def getListOfPerimetersForCorrespondingContours(self):\n            return self.__periLstForConts\n\n        def getSelectedContourImg(self):\n            return self.__selecCntImg\n\n        def getBoundingRectImg(self):\n            return self.__imgcovrect\n\n        def getMeanEdgeOfCoveringRect(self):\n            return self.__meanEdge\n\n        def getBoundedCircImg(self):\n            return self.__imgcovcirc\n\n        def getBoundedCircRadius(self):\n            return self.__rad\n\n        def getAsymmetryIndex(self):\n            return self.__asyidxofles\n\n        def getCompactIndex(self):\n            return self.__cmptidx\n\n        def getFractalDimension(self):\n            return self.__fracdimen\n\n        def getDiameter(self):\n            return self.__diameter\n\n        def getColorVariance(self):\n            return self.__colorvar\n\n\n\n\n"""
featext/physical/__init__.py,0,b''
featext/texture/Haralick.py,2,"b""import numpy as np\nimport math\nfrom util import Util as u\n\nclass HarFeat(object):\n\n    def __init__(self, img, offset=()):\n        glvlwthfreq = u.getArrayOfGrayLevelsWithFreq(img)\n        if (len(offset) == 0):\n            self.__glcm = self.__generateGLCM(img, glvlwthfreq)\n        else:\n            self.__glcm = self.__generateGLCM(img, glvlwthfreq, offset)\n        (self.__asm, self.__energy, self.__entropy, self.__contrast, self.__idm_homogeneity, self.__dm, self.__correlation, self.__har_correlation, self.__cluster_shade, self.__cluster_prominence, self.__moment1, self.__moment2, self.__moment3, self.__moment4, self.__dasm, self.__dmean, self.__dentropy) = self.__generateHaralickFeatures(self.__glcm, glvlwthfreq)\n\n    def __generateGLCM(self, img, glvlwthfreq, offset=(0,1)):\n        coocurmat = np.zeros((glvlwthfreq.size, glvlwthfreq.size), np.uint32, 'C')\n        for i in range(0, (img.shape)[0], 1):\n            for j in range(0, (img.shape)[1], 1):\n                if ((((i + offset[0]) < 0) | ((i + offset[0]) >= img.shape[0])) | (((j + offset[1]) < 0) | ((j + offset[1]) >= img.shape[1]))):\n                    continue\n                else:\n                    first = u.search(glvlwthfreq, img[i,j], 0, glvlwthfreq.size-1)\n                    second = u.search(glvlwthfreq, img[(i + offset[0]),(j + offset[1])], 0, glvlwthfreq.size-1)\n                    coocurmat[first, second] = np.uint32(coocurmat[first, second]) + np.uint32(1)\n        return coocurmat\n\n    def __generateHaralickFeatures(self, glcm, glvlwthfreq):\n        sumofglcm = glcm.sum(axis=None, dtype=float)\n        asm = 0.0\n        correlation = 0.0\n        har_correlation = 0.0\n        entropy = 0.0\n        contrast = 0.0\n        idm_homogeneity = 0.0\n        cluster_shade = 0.0\n        cluster_prominence = 0.0\n        m1 = 0.0\n        m3 = 0.0\n        m4 = 0.0\n        dm = 0.0\n        ux = 0.0\n        uy = 0.0\n        vx = 0.0\n        vy = 0.0\n        (energy, m2, asm, entropy, contrast, idm_homogeneity, dm, ux, uy, m1, m3, m4) = self.__genHarFeatPt1(glcm, glvlwthfreq, asm, entropy, contrast, idm_homogeneity, dm, ux, uy, m1, m3, m4, sumofglcm)\n        (cluster_shade, cluster_prominence, correlation, har_correlation) = self.__genHarFeatPt2(glcm, glvlwthfreq, ux, uy, vx, vy, correlation, cluster_shade, cluster_prominence, har_correlation, sumofglcm)\n        dasm = 0.0\n        dmean = 0.0\n        dentropy = 0.0\n        for k in range(0, glvlwthfreq.size, 1):\n            psum = 0.0\n            for i in range(0,(glcm.shape)[0], 1):\n                 for j in range(0, (glcm.shape)[1], 1):\n                        if (math.fabs(i - j) == k):\n                            psum = psum + (float(glcm[i,j]) / sumofglcm)\n                        else:\n                            continue\n            (dasm, dmean) = ((dasm + math.pow(psum, 2)), (dmean + (k * psum)))\n            if (psum <= 0.0):\n                dentropy = dentropy + 0.0\n                continue\n            else:\n                dentropy = dentropy + (psum * (- math.log(psum)))\n        return (asm, energy, entropy, contrast, idm_homogeneity, dm, correlation, har_correlation, cluster_shade, cluster_prominence, m1, m2, m3, m4, dasm, dmean, dentropy)\n\n    def __genHarFeatPt1(self, glcm, glvlwthfreq, asm, entropy, contrast, idm_homogeneity, dm, ux, uy, m1, m3, m4, sumofglcm):\n        i = 0\n        for x in glcm:\n            j=0\n            for item in x:\n                y = float(item) / sumofglcm\n                if (y == 0.0):\n                    pass\n                else:\n                    asm = asm + math.pow(y, 2)\n                    entropy = entropy + (y * (- math.log(y)))\n                    contrast = contrast + (math.pow((float((glvlwthfreq[i])[0]) - float((glvlwthfreq[j])[0])), 2) * y)\n                    idm_homogeneity = idm_homogeneity + ((1 / (1 + math.pow((float((glvlwthfreq[i])[0]) - float((glvlwthfreq[j])[0])), 2))) * y)\n                    dm = dm + (math.fabs(float((glvlwthfreq[i])[0]) - float((glvlwthfreq[j])[0])) * y)\n                    ux = ux + (float((glvlwthfreq[i])[0]) * y)\n                    uy = uy + (float((glvlwthfreq[j])[0]) * y)\n                    m1 = m1 + ((float((glvlwthfreq[i])[0]) - float((glvlwthfreq[j])[0])) * y)\n                    m3 = m3 + (math.pow((float((glvlwthfreq[i])[0]) - float((glvlwthfreq[j])[0])), 3) * y)\n                    m4 = m4 + (math.pow((float((glvlwthfreq[i])[0]) - float((glvlwthfreq[j])[0])), 4) * y)\n                j = j + 1\n            i = i + 1\n        return (math.sqrt(asm), contrast, asm, entropy, contrast, idm_homogeneity, dm, ux, uy, m1, m3, m4)\n\n    def __genHarFeatPt2(self, glcm, glvlwthfreq, ux, uy, vx, vy, correlation, cluster_shade, cluster_prominence, har_correlation, sumofglcm):\n        i = 0\n        for x in glcm:\n            j = 0\n            for item in x:\n                y = float(item) / sumofglcm\n                if (y == 0.0):\n                    pass\n                else:\n                    vx = vx + (math.pow((float((glvlwthfreq[i])[0]) - ux), 2) * y)\n                    vy = vy + (math.pow((float((glvlwthfreq[j])[0]) - uy), 2) * y)\n                    correlation = correlation + ((float((glvlwthfreq[i])[0]) - ux) * (float((glvlwthfreq[j])[0]) - uy) * y)\n                    cluster_shade = cluster_shade + (math.pow(((float((glvlwthfreq[i])[0]) - ux) + (float((glvlwthfreq[j])[0]) - uy)), 3) * y)\n                    cluster_prominence = cluster_prominence + (math.pow(((float((glvlwthfreq[i])[0]) - ux) + (float((glvlwthfreq[j])[0]) - uy)), 4) * y)\n                    har_correlation = har_correlation + ((float((glvlwthfreq[i])[0]) * float((glvlwthfreq[j])[0]) * y) - math.pow(((ux + uy) / 2), 2))\n                j = j + 1\n            i = i + 1\n        (vx, vy) = (math.sqrt(vx), math.sqrt(vy))\n        (correlation, har_correlation) = ((correlation / (vx * vy)), (har_correlation / math.pow(((vx + vy) / 2), 2)))\n        return (cluster_shade, cluster_prominence, correlation, har_correlation)\n\n    def getGLCM(self):\n        return self.__glcm\n\n    def getAngularSecondMomentASM(self):\n        return self.__asm\n\n    def getEnergy(self):\n        return self.__energy\n\n    def getEntropy(self):\n        return self.__entropy\n\n    def getContrast(self):\n        return self.__contrast\n\n    def getHomogeneity(self):\n        return self.__idm_homogeneity\n\n    def getDm(self):\n        return self.__dm\n\n    def getCorrelation(self):\n        return self.__correlation\n\n    def getHarCorrelation(self):\n        return self.__har_correlation\n\n    def getClusterShade(self):\n        return self.__cluster_shade\n\n    def getClusterProminence(self):\n        return self.__cluster_prominence\n\n    def getMoment1(self):\n        return self.__moment1\n\n    def getMoment2(self):\n        return self.__moment2\n\n    def getMoment3(self):\n        return self.__moment3\n\n    def getMoment4(self):\n        return self.__moment4\n\n    def getDasm(self):\n        return self.__dasm\n\n    def getDmean(self):\n        return self.__dmean\n\n    def getDentropy(self):\n        return self.__dentropy\n    \n\n\n"""
featext/texture/King.py,6,"b""import numpy as np\nfrom util import Util as u\n\nclass KingFeat(object):\n\n    def __init__(self, img, d=2, e=0.3):\n        glvlwthfreq = u.getArrayOfGrayLevelsWithFreq(img)\n        self.__ngtdm = self.__generateNGTDM(img, glvlwthfreq, d)\n        (self.__coarseness, factor) = self.__generateKingsCoarseness(glvlwthfreq, img.size, e)\n        self.__contrast = self.__generateKingsContrast(glvlwthfreq, img.size)\n        self.__busyness = self.__generateBusyness(glvlwthfreq, img.size, factor)\n        self.__complexity = self.__generateComplexity(glvlwthfreq, img.size)\n        self.__strength = self.__generateStrength(glvlwthfreq, img.size, e)\n\n    def __generateNGTDM(self, img, glvlwthfreq, d):\n        ngtdm = np.zeros(glvlwthfreq.shape, float, 'C')\n        for i in range(0, (img.shape)[0], 1):\n            for j in range(0, (img.shape)[1], 1):\n                if (img[i, j] == 0):\n                    continue\n                else:\n                    index = u.search(glvlwthfreq, img[i, j], 0, glvlwthfreq.size - 1)\n                    ngtdm[index] = ngtdm[index] + np.fabs(img[i, j] - (self.__calculateSubSum(img, i, j, d) / (np.power(((2 * d) + 1), 2) - 1)))\n        return ngtdm\n\n    def __calculateSubSum(self, img, i, j, d):\n        sum = 0.0\n        m = -d\n        while(m < d):\n            n = -d\n            while(n < d):\n                (x, y) = self.__checkLimits((i + m), (j + n), img.shape)\n                sum = sum + img[x, y]\n                n = n + 1\n            m = m + 1\n        return sum\n\n    def __checkLimits(self, x, y, shape):\n        if (x < 0):\n            x = 0\n        if (x >= shape[0]):\n            x = shape[0] - 1\n        if (y < 0):\n            y = 0\n        if (y >= shape[1]):\n            y = shape[1] - 1\n        return (x, y)\n\n    def __generateKingsCoarseness(self, glvlwthfreq, totpix, e):\n        sum = 0.0\n        for i in range(0, glvlwthfreq.size, 1):\n            sum = sum + ((float((glvlwthfreq[i])[1]) / float(totpix)) * self.__ngtdm[i])\n        return ((1 /(e + sum)), sum)\n\n    def __generateKingsContrast(self, glvlwthfreq, totpix):\n        sum = 0.0\n        for i in range(0, glvlwthfreq.size, 1):\n            for j in range(0, glvlwthfreq.size, 1):\n              if((glvlwthfreq[i])[0] == (glvlwthfreq[j])[0]):\n                  continue\n              else:\n                  sum = sum + (((float((glvlwthfreq[i])[1])) / float(totpix)) * ((float((glvlwthfreq[j])[1])) / float(totpix)) * np.power((float((glvlwthfreq[i])[0]) - float((glvlwthfreq[j])[0])), 2))\n        sum = sum * (1.0 / float(glvlwthfreq.size * (glvlwthfreq.size - 1))) * ((1.0 / np.power(float(totpix), 2)) * (self.__ngtdm).sum(axis=None, dtype=float))\n        return sum\n\n    def __generateBusyness(self, glvlwthfreq, totpix, factor):\n        sum = 0.0\n        for i in range(0, glvlwthfreq.size, 1):\n            for j in range(0, glvlwthfreq.size, 1):\n                    sum = sum + ((float((glvlwthfreq[i])[0]) * ((float((glvlwthfreq[i])[1])) / float(totpix))) - (float((glvlwthfreq[j])[0]) * ((float((glvlwthfreq[j])[1])) / float(totpix))))\n        sum = factor / sum\n        return sum\n\n    def __generateComplexity(self, glvlwthfreq, totpix):\n        sum = 0.0\n        for i in range(0, glvlwthfreq.size, 1):\n            for j in range(0, glvlwthfreq.size, 1):\n                sum = sum + ((np.fabs(float((glvlwthfreq[i])[0]) - float((glvlwthfreq[j])[0])) / (np.power(float(totpix), 2) * (((float((glvlwthfreq[i])[1])) / float(totpix)) + ((float((glvlwthfreq[j])[1])) / float(totpix))))) * ((((float((glvlwthfreq[i])[1])) / float(totpix)) * self.__ngtdm[i]) + (((float((glvlwthfreq[j])[1])) / float(totpix)) * self.__ngtdm[j])))\n        return sum\n\n    def __generateStrength(self, glvlwthfreq, totpix, e):\n        sum = 0.0\n        for i in range(0, glvlwthfreq.size, 1):\n            for j in range(0, glvlwthfreq.size, 1):\n                sum = sum + ((((float((glvlwthfreq[i])[1])) / float(totpix)) + ((float((glvlwthfreq[j])[1])) / float(totpix))) * np.power((float((glvlwthfreq[i])[0]) - float((glvlwthfreq[j])[0])), 2))\n        sum = sum / (e + (self.__ngtdm).sum(axis=None, dtype=float))\n        return sum\n\n    def getNGTDM(self):\n        return self.__ngtdm\n\n    def getKingsCoarseness(self):\n        return self.__coarseness\n\n    def getKingsContrast(self):\n        return self.__contrast\n\n    def getKingsBusyness(self):\n        return self.__busyness\n\n    def getKingsComplexity(self):\n        return self.__complexity\n\n    def getKingsStrength(self):\n        return self.__strength"""
featext/texture/Tamura.py,38,"b'import numpy as np\nfrom util import Util as u\nimport cv2\nfrom threading import Thread, Lock, Event\nfrom queue import Queue\nimport time\n\nclass TamFeat(object):\n\n    q = Queue(maxsize=4)\n\n    def __init__(self, img):\n        t = time.time()\n        (self.__coarseness, varCrs) = self.__generateCoarseness(img)\n        print(""Coarseness Calc-Time : %f secs\\n"" % (time.time() - t))\n        (self.__contrast, self.__kurtosis, varCon) = self.__generateContrastAndKurtosis(img)\n        self.__img_hor_x = cv2.filter2D(img, -1, np.array([[1,1,1],[0,0,0],[-1,-1,-1]], dtype=np.int16))\n        self.__img_vert_y = cv2.filter2D(img, -1, np.array([[-1,0,1],[-1,0,1],[-1,0,1]], dtype=np.int16))\n        self.__delg_img = np.round((np.add(self.__img_hor_x, self.__img_vert_y, dtype=float) * 0.5)).astype(np.int8)\n        self.__theta_img = np.tanh(np.divide((self.__img_vert_y).astype(float), (self.__img_hor_x).astype(float), dtype=float, out=np.zeros_like((self.__img_vert_y).astype(float)), where=self.__img_hor_x != 0)) + (float(np.pi) / 2.0)\n        (self.__linelikeness, varLin) = self.__generateLineLikeness(self.__delg_img, self.__theta_img)\n        (self.__directionality, varDir) = self.__generateDirectionality(self.__delg_img, self.__theta_img)\n        self.__regularity = self.__generateRegularity(np.sqrt(varCrs), np.sqrt(varDir), np.sqrt(varCon), np.sqrt(varLin))\n        self.__roughness = self.__generateRoughness(self.__coarseness, self.__contrast)\n\n    def __generateCoarseness(self, src_img):\n        def __tds_opt(tds, mode=\'s\'):\n            for t in tds:\n                if (mode == \'s\'):\n                    t.start()\n                else:\n                    t.join()\n        lock = Lock()\n        sbest = np.zeros(src_img.shape, np.uint32, \'C\')\n        for x in range(0, (src_img.shape)[0], 1):\n            for y in range(0, (src_img.shape)[1], 1):\n                emax = np.empty(0, np.dtype([(\'E\', float), (\'K\', int)]), \'C\')\n                #print((x,y))\n                for k in range(1, 7, 1):\n                    tds = [Thread(target=self.__nebAvg, name=\'Cor0\', args=(x + np.float_power(2, k-1), y, k, src_img, lock, Event(), 0)), Thread(target=self.__nebAvg, name=\'Cor1\', args=(x - np.float_power(2, k-1), y, k, src_img, lock, Event(), 1)), Thread(target=self.__nebAvg, name=\'Cor2\', args=(x, y + np.float_power(2, k-1), k, src_img, lock, Event(), 2)), Thread(target=self.__nebAvg, name=\'Cor3\', args=(x, y - np.float_power(2, k-1), k, src_img, lock, Event(), 3))]\n                    __tds_opt(tds)\n                    __tds_opt(tds, \'j\')\n                    nbavgs = self.__getFromQueue()\n                    emax = np.insert(emax, emax.size, (np.abs(nbavgs[0] - nbavgs[1]), k-1), 0)\n                    emax = np.insert(emax, emax.size, (np.abs(nbavgs[2] - nbavgs[3]), k-1), 0)\n                    #emax = np.insert(emax, emax.size, (np.abs(self.__nebAvg(x + np.float_power(2, k-1), y, k, src_img) - self.__nebAvg(x - np.float_power(2, k-1), y, k, src_img)), k-1), 0)\n                    #emax = np.insert(emax, emax.size, (np.abs(self.__nebAvg(x, y + np.float_power(2, k-1), k, src_img) - self.__nebAvg(x, y - np.float_power(2, k-1), k, src_img)), k-1), 0)\n                emax.sort(axis=0, kind=\'mergesort\', order=\'E\')\n                sbest[x, y] = np.float_power(2, (emax[emax.size-1])[1])\n        varCrs = self.__generateVariance(u.getArrayOfGrayLevelsWithFreq(sbest, lvldtype=np.uint32), np.mean(sbest, axis=None, dtype=float))\n        return ((float(np.sum(sbest, axis=None, dtype=float) / float(sbest.size))), varCrs)\n\n    def __nebAvg(self, x, y, k, src_img, lck, evt, pos):\n        lck.acquire()\n        avg = 0.0\n        const = np.float_power(2, k-1)\n        xh = int(np.round(x + const - 1))\n        xl = int(np.round(x - const))\n        yh = int(np.round(y + const - 1))\n        yl = int(np.round(y - const))\n        (xl, xh, yl, yh) = self.__checkSigns(xl, xh, yl, yh, src_img.shape)\n        for r in range(xl, xh, 1):\n            for c in range(yl, yh, 1):\n                avg = avg + (float(src_img[r, c]) / float(np.float_power(2, 2*k)))\n        (TamFeat.q).put((avg, pos))\n        lck.release()\n        evt.set()\n        #return avg\n\n    def __getFromQueue(self):\n        nbavgs = [0.0, 0.0, 0.0, 0.0]\n        while ((TamFeat.q).empty() == False):\n            item = (TamFeat.q).get()\n            nbavgs[ item[1] ] = item[0]\n            (TamFeat.q).task_done()\n        (TamFeat.q).join()\n        return nbavgs\n\n    def __checkSigns(self, xl, xh, yl, yh, shape):\n        if (xl < 0):\n            xl = 0\n        if (xl > shape[0]):\n            xl = shape[0]\n        if (xh < 0):\n            xh = 0\n        if (xh > shape[0]):\n            xh = shape[0]\n        if (yl < 0):\n            yl = 0\n        if (yl > shape[1]):\n            yl = shape[1]\n        if (yh < 0):\n            yh = 0\n        if (yh > shape[1]):\n            yh = shape[1]\n        return (xl, xh, yl, yh)\n\n    def __generateContrastAndKurtosis(self, src_img):\n        glvlwthfreq = u.getArrayOfGrayLevelsWithFreq(src_img)\n        m = np.mean(src_img, axis=None, dtype=float)\n        variance = self.__generateVariance(glvlwthfreq, m)\n        kurtosis = 0.0\n        for tup in glvlwthfreq:\n            kurtosis = kurtosis + (np.float_power((float(tup[0]) - m), 4) * (float(tup[1]) / float(src_img.size)))\n        kurtosis = kurtosis / np.float_power(variance, 2)\n        contrast = float(np.sqrt(variance)) / np.float_power(kurtosis, 0.25)\n        return (contrast, kurtosis, variance)\n\n    def __generateVariance(self, matlvls, m):\n        gls = np.ascontiguousarray(matlvls[\'glvl\'], dtype=float)\n        frq = np.ascontiguousarray(matlvls[\'freq\'], dtype=float)\n        totpix = frq.sum(axis=None, dtype=float)\n        variance = 0.0\n        for g in range(0, matlvls.size, 1):\n            variance = variance + (np.float_power((gls[g] - m), 2) * (frq[g] / totpix))\n        return variance\n\n    def __generateLineLikeness(self, delg_img, theta_img, d=4, t=12):\n        dirlevels = u.getArrayOfGrayLevelsWithFreq(theta_img, lvldtype=float)\n        ditfctcm = np.zeros((dirlevels.size, dirlevels.size), dtype=np.uint32, order=\'C\')\n        for i in range(0, (theta_img.shape)[0], 1):\n            for j in range(0, (theta_img.shape)[1], 1):\n                if (np.fabs(delg_img[i,j]) > t):\n                    x = int(np.round(np.fabs(d * np.cos(theta_img[i, j]))))\n                    y = int(np.round(np.fabs(d * np.sin(theta_img[i, j]))))\n                    if ((x < 0) | (x >= (theta_img.shape)[0]) | (y < 0) | (y >= (theta_img.shape)[1])):\n                        continue\n                    else:\n                        if ((theta_img[x, y] > (theta_img[i, j] - 1)) & (theta_img[x, y] < (theta_img[i, j] + 1))):\n                             idx1, idx2 = u.search(dirlevels, theta_img[i, j], 0, dirlevels.size-1), u.search(dirlevels, theta_img[x, y], 0, dirlevels.size-1)\n                             ditfctcm[idx1, idx2] = ditfctcm[idx1, idx2] + 1\n                        else:\n                            continue\n        varLin = self.__generateVariance(u.getArrayOfGrayLevelsWithFreq(ditfctcm, lvldtype=np.uint32), np.mean(ditfctcm, axis=None, dtype=float))\n        return (self.__lineLikenessSubPart(ditfctcm, dirlevels), varLin)\n\n    def __lineLikenessSubPart(self, ditfctcm, dirlevels):\n        dir = 0.0\n        for i in range(0, (ditfctcm.shape)[0], 1):\n            for j in range(0, (ditfctcm.shape)[0], 1):\n                dir = dir + float(ditfctcm[i, j]) * np.cos((((dirlevels[i])[0] - (dirlevels[j])[0]) * 2.0 * np.pi) / dirlevels.size)\n        dir = dir / ditfctcm.sum(axis=None, dtype=float)\n        return dir\n\n    def __generateDirectionality(self, delg_img, theta_img, t=12):\n        temp = np.zeros_like(theta_img)\n        for i in range(0, (delg_img.shape)[0], 1):\n            for j in range(0, (delg_img.shape)[1], 1):\n                if (delg_img[i, j] > t):\n                    temp[i, j] = theta_img[i, j]\n        varDir = self.__generateVariance(u.getArrayOfGrayLevelsWithFreq(temp, lvldtype=float), np.mean(temp, axis=None, dtype=float))\n        return ((1 / np.sqrt(varDir)), varDir)\n\n    def __generateRegularity(self, sdCrs, sdDir, sdCon, sdLin, r=0.4):\n        return  (1 - (r * (sdCrs + sdDir + sdCon + sdLin)))\n\n    def __generateRoughness(self, coarseness, contrast):\n        return (contrast + coarseness)\n\n    def getCoarseness(self):\n        return self.__coarseness\n\n    def getContrast(self):\n        return self.__contrast\n\n    def getKurtosis(self):\n        return self.__kurtosis\n\n    def getPrewittHorizontalEdgeImg(self):\n        return self.__img_hor_x\n\n    def getPrewittVerticalEdgeImg(self):\n        return self.__img_vert_y\n\n    def getCombinedPrewittImg(self):\n        return (self.__delg_img).astype(np.uint8)\n\n    def getPrewittDirFactOfImg(self):\n        return self.__theta_img\n\n    def getLineLikeness(self):\n        return self.__linelikeness\n\n    def getDirectionality(self):\n        return self.__directionality\n\n    def getRegularity(self):\n        return self.__regularity\n\n    def getRoughness(self):\n        return self.__roughness'"
featext/texture/__init__.py,0,b''
