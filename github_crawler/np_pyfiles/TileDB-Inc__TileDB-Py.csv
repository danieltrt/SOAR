file_path,api_count,code
setup.py,0,"b'from __future__ import absolute_import, print_function\n\nimport ctypes\nimport multiprocessing\nimport os\nimport sys\nimport urllib\nimport shutil\nimport subprocess\nimport zipfile\nimport platform\nfrom distutils.sysconfig import get_config_var\nfrom distutils.version import LooseVersion\n\n\ntry:\n    # For Python 3\n    from urllib.request import urlopen\n    import io\n\n    def get_zipfile(url):\n        """"""Returns a ZipFile constructed from the file at the given URL.""""""\n        r = urlopen(url)\n        return zipfile.ZipFile(io.BytesIO(r.read()))\nexcept ImportError:\n    # Python 2\n    from urllib2 import urlopen\n    import StringIO\n\n    def get_zipfile(url):\n        """"""Returns a ZipFile constructed from the file at the given URL.""""""\n        r = urlopen(url)\n        return zipfile.ZipFile(StringIO.StringIO(r.read()))\n\nfrom setuptools import setup, Extension, find_packages\nfrom pkg_resources import resource_filename\n\nimport sys\nfrom sys import version_info as ver\n\nprint(""setup.py sys.argv is: "", sys.argv)\n\n# Target branch\nTILEDB_VERSION = ""2.0.2""\n# allow overriding w/ environment variable\nTILEDB_VERSION = os.environ.get(""TILEDB_VERSION"") or TILEDB_VERSION\n\n# Use `setup.py [] --debug` for a debug build of libtiledb\nTILEDB_DEBUG_BUILD = False\n\n# Use `setup.py [] --modular` for a modular build of libtiledb_py\n#   Each .pyx file will be built as a separate shared library for faster\n#   compilation. This is disabled by default to avoid distributing multiple\n#   shared libraries.\nTILEDBPY_MODULAR = False\n\n# Allow to override TILEDB_FORCE_ALL_DEPS with environment variable\nTILEDB_FORCE_ALL_DEPS = ""TILEDB_FORCE_ALL_DEPS"" in os.environ\nTILEDB_SERIALIZATION = ""TILEDB_SERIALIZATION"" in os.environ\nCMAKE_GENERATOR = os.environ.get(""CMAKE_GENERATOR"", None)\n\n# Directory containing this file\nCONTAINING_DIR = os.path.abspath(os.path.dirname(__file__))\n\n# Build directory path\nBUILD_DIR = os.path.join(CONTAINING_DIR, ""build"")\n\n# TileDB package source directory\nTILEDB_PKG_DIR = os.path.join(CONTAINING_DIR, ""tiledb"")\n\n# Set deployment target for mac\n#\n# Need to ensure thatextensions are built for macos 10.9 when compiling on a\n# 10.9 system or above, overriding distutils behaviour which is to target\n# the version used to build the current python binary.\n#\n# TO OVERRIDE:\n#   set MACOSX_DEPLOYMENT_TARGET before calling setup.py\n#\n# From https://github.com/pandas-dev/pandas/pull/24274\n# 3-Clause BSD License: https://github.com/pandas-dev/pandas/blob/master/LICENSE\nif sys.platform == \'darwin\':\n  if \'MACOSX_DEPLOYMENT_TARGET\' not in os.environ:\n      current_system = LooseVersion(platform.mac_ver()[0])\n      python_target = LooseVersion(\n          get_config_var(\'MACOSX_DEPLOYMENT_TARGET\'))\n      if python_target < \'10.9\' and current_system >= \'10.9\':\n          os.environ[\'MACOSX_DEPLOYMENT_TARGET\'] = \'10.9\'\n\ndef is_windows():\n    return os.name == \'nt\'\n\ndef _libtiledb_exists(library_dirs):\n    """"""\n    Checks the given list of paths and returns true if any contain the TileDB library.\n    :return: The path to the TileDB library, or None.\n    """"""\n\n    print(""libtiledb_exists checking \'library_dirs\': {}"".format(library_dirs))\n\n    if len(library_dirs) > 0:\n        names = libtiledb_library_names()\n        paths = [os.path.join(d, n) for d in library_dirs for n in names]\n        for p in paths:\n            if os.path.exists(p):\n                return p\n        raise RuntimeError(""Could not find given --tiledb library path(s):\\n{}""\n                .format(""\\n"".join(paths)))\n    # If no explicit path is given check to see if TileDB is globally installed.\n    import ctypes\n    if os.name == ""posix"":\n        if sys.platform == ""darwin"":\n            lib_name = ""libtiledb.dylib""\n        else:\n            lib_name = ""libtiledb.so""\n    elif os.name == ""nt"":\n        lib_name = ""tiledb.dll""\n    try:\n        # note: this is a relative path on linux\n        #       https://bugs.python.org/issue21042\n        ctypes.CDLL(lib_name)\n        return lib_name\n    except:\n        pass\n\n    return None\n\ndef libtiledb_exists(library_dirs):\n    lib = _libtiledb_exists(library_dirs)\n    print(""libtiledb_exists found: \'{}\'"".format(lib))\n    return lib\n\n\ndef libtiledb_library_names():\n    """"""\n    :return: List of TileDB shared library names.\n    """"""\n    if os.name == ""posix"":\n        if sys.platform == ""darwin"":\n            return [""libtiledb.dylib""]\n        else:\n            return [""libtiledb.so""]\n    elif os.name == ""nt"":\n            return [""tiledb.dll""]\n    else:\n        raise RuntimeError(""Unsupported OS name "" + os.name)\n\n\ndef download_libtiledb():\n    """"""\n    Downloads the native TileDB source.\n    :return: Path to extracted source directory.\n    """"""\n    dest_name = ""TileDB-{}"".format(TILEDB_VERSION)\n    dest = os.path.join(BUILD_DIR, dest_name)\n    if not os.path.exists(dest):\n        url = ""https://github.com/TileDB-Inc/TileDB/archive/{}.zip"".format(TILEDB_VERSION)\n        print(""Downloading TileDB package from {}..."".format(TILEDB_VERSION))\n        try:\n            with get_zipfile(url) as z:\n                z.extractall(BUILD_DIR)\n        except urllib.error.URLError:\n            # try falling back to wget, maybe SSL is broken\n            subprocess.check_call([\'wget\', url], shell=True)\n            with zipfile.ZipFile(""{}.zip"".format(TILEDB_VERSION)) as z:\n                z.extractall(BUILD_DIR)\n    return dest\n\n\ndef build_libtiledb(src_dir):\n    """"""\n    Builds and installs the native TileDB library.\n    :param src_dir: Path to libtiledb source directory.\n    :return: Path to the directory where the library was installed.\n    """"""\n    libtiledb_build_dir = os.path.join(src_dir, ""build"")\n    libtiledb_install_dir = os.path.join(src_dir, ""dist"")\n    if not os.path.exists(libtiledb_build_dir):\n        os.makedirs(libtiledb_build_dir)\n\n    print(""Building libtiledb in directory {}..."".format(libtiledb_build_dir))\n    cmake = os.environ.get(""CMAKE"", ""cmake"")\n    cmake_cmd = [cmake,\n                    ""-DCMAKE_INSTALL_PREFIX={}"".format(libtiledb_install_dir),\n                    ""-DTILEDB_TESTS=OFF"",\n                    ""-DTILEDB_S3=ON"",\n                    ""-DTILEDB_HDFS={}"".format(""ON"" if os.name == ""posix"" else ""OFF""),\n                    ""-DTILEDB_INSTALL_LIBDIR=lib"",\n                    ""-DTILEDB_CPP_API=ON"",\n                    ""-DTILEDB_LOG_OUTPUT_ON_FAILURE=ON"",\n                    ""-DTILEDB_FORCE_ALL_DEPS:BOOL={}"".format(""ON"" if TILEDB_FORCE_ALL_DEPS else ""OFF""),\n                    ""-DTILEDB_SERIALIZATION:BOOL={}"".format(""ON"" if TILEDB_SERIALIZATION else ""OFF"")\n                    ]\n\n    extra_cmake_args = os.environ.get(""CMAKE_ARGS"", [])\n    if extra_cmake_args:\n        cmake_cmd.extend(extra_cmake_args.split())\n\n    if TILEDB_DEBUG_BUILD:\n        build_type = ""Debug""\n    else:\n        build_type = ""Release""\n\n    cmake_cmd.append(""-DCMAKE_BUILD_TYPE={}"".format(build_type))\n\n    if os.name == \'nt\':\n        cmake_cmd.extend([\'-A\', \'x64\', ""-DMSVC_MP_FLAG=/MP4""])\n\n    if CMAKE_GENERATOR:\n        cmake_cmd.extend([\'-G\', CMAKE_GENERATOR])\n\n    # cmake target directory -- important\n    cmake_cmd.append(src_dir)\n\n    print(""CMake configure command: {}"".format(cmake_cmd))\n\n    have_make = True\n    try:\n        subprocess.check_call([""make"", ""-v""])\n    except:\n        have_make = False\n\n    if have_make and not os.name == \'nt\':\n        njobs = multiprocessing.cpu_count() or 2\n        build_cmd = [""make"", ""-j{:d}"".format(njobs)]\n        install_cmd = [""make"", ""install-tiledb""]\n    else:\n        build_cmd = [""cmake"", ""--build"", ""."", ""--config"", build_type]\n        install_cmd = [""cmake"", ""--build"", ""."", ""--config"", build_type, ""--target"", ""install-tiledb""]\n\n    # Build and install libtiledb\n    # - run cmake\n    # - run build via \'cmake --build\'\n    # - run install-tiledb\n    subprocess.check_call(cmake_cmd, cwd=libtiledb_build_dir)\n    subprocess.check_call(build_cmd, cwd=libtiledb_build_dir)\n    subprocess.check_call(install_cmd, cwd=libtiledb_build_dir)\n\n    return libtiledb_install_dir\n\n\ndef find_or_install_libtiledb(setuptools_cmd):\n    """"""\n    Find the TileDB library required for building the Cython extension. If not found,\n    download, build and install TileDB, copying the resulting shared libraries\n    into a path where they will be found by package_data or the build process.\n\n    :param setuptools_cmd: The setuptools command instance.\n    """"""\n    tiledb_ext = None\n    core_ext = None\n    print(""ext_modules: "", setuptools_cmd.distribution.ext_modules)\n    for ext in setuptools_cmd.distribution.ext_modules:\n        if ext.name == ""tiledb.libtiledb"":\n            tiledb_ext = ext\n        elif ext.name == ""tiledb.core"":\n            core_ext = ext\n\n    print(""tiledb_ext: "", tiledb_ext)\n    print(""core_ext: "", core_ext)\n    print(""tiledb_ext.library_dirs: "", tiledb_ext.library_dirs)\n    wheel_build = getattr(tiledb_ext, \'tiledb_wheel_build\', False)\n    from_source = getattr(tiledb_ext, \'tiledb_from_source\', False)\n    lib_exists = libtiledb_exists(tiledb_ext.library_dirs)\n    do_install = False\n\n    # Download, build and locally install TileDB if needed.\n    if from_source or not lib_exists:\n        src_dir = download_libtiledb()\n        prefix_dir = build_libtiledb(src_dir)\n        do_install = True\n    elif lib_exists:\n        prefix_dir = os.path.abspath(os.path.join(os.path.split(lib_exists)[0], ""..""))\n    elif hasattr(tiledb_ext, \'tiledb_path\'):\n        prefix_dir = getattr(tiledb_ext, \'tiledb_path\')\n\n\n    if wheel_build and is_windows() and lib_exists:\n        do_install = True\n\n    print(""prefix_dir: "", core_ext)\n    print(""do_install: "", do_install)\n\n    if do_install:\n        lib_subdir = \'bin\' if os.name==\'nt\' else \'lib\'\n        native_subdir = \'\' if is_windows() else \'native\'\n        # Copy libtiledb shared object(s) to the package directory so they can be found\n        # with package_data.\n        dest_dir = os.path.join(TILEDB_PKG_DIR, native_subdir)\n        for libname in libtiledb_library_names():\n            src = os.path.join(prefix_dir, lib_subdir, libname)\n            if not os.path.exists(dest_dir):\n                os.makedirs(dest_dir)\n            dest = os.path.join(dest_dir, libname)\n            print(""Copying file {0} to {1}"".format(src, dest))\n            shutil.copy(src, dest)\n\n        # Copy dependencies\n        if is_windows():\n            def do_copy(src, dest):\n                print(""Copying file {0} to {1}"".format(src, dest))\n                shutil.copy(src, dest)\n\n            # lib files for linking\n            src = os.path.join(prefix_dir, ""lib"", ""tiledb.lib"")\n            dest = os.path.join(dest_dir, ""tiledb.lib"")\n            do_copy(src, dest)\n\n            # tbb\n            src = os.path.join(prefix_dir, ""bin"", ""tbb.dll"")\n            dest = os.path.join(dest_dir, ""tbb.dll"")\n            do_copy(src, dest)\n            src = os.path.join(prefix_dir, ""lib"", ""tbb.lib"")\n            dest = os.path.join(dest_dir, ""tbb.lib"")\n            do_copy(src, dest)\n\n            #\n            tiledb_ext.library_dirs += [os.path.join(prefix_dir, ""lib"")]\n            core_ext.library_dirs += [os.path.join(prefix_dir, ""lib"")]\n\n        # Update the TileDB Extension instance with correct build-time paths.\n        tiledb_ext.library_dirs += [os.path.join(prefix_dir, lib_subdir)]\n        tiledb_ext.include_dirs += [os.path.join(prefix_dir, ""include"")]\n        core_ext.library_dirs += [os.path.join(prefix_dir, lib_subdir)]\n        core_ext.include_dirs += [os.path.join(prefix_dir, ""include"")]\n\n        # Update package_data so the shared object gets installed with the Python module.\n        libtiledb_objects = [os.path.join(native_subdir, libname)\n                             for libname in libtiledb_library_names()]\n\n        # Make sure the built library is usable\n        for shared_obj in libtiledb_objects:\n            if is_windows(): continue\n            test_path = os.path.join(TILEDB_PKG_DIR, shared_obj)\n            # should only ever be 1, not sure why libtiledb_library_names -> List\n            try:\n                ctypes.CDLL(test_path)\n            except:\n                print(""\\n-------------------"")\n                print(""Failed to load shared library: {}"".format(test_path))\n                print(""-------------------\\n"")\n                raise\n\n        # This needs to be a glob in order to pick up the versioned SO\n        libtiledb_objects = [so + \'*\' for so in libtiledb_objects]\n\n        if is_windows():\n            libtiledb_objects.extend(\n                [os.path.join(native_subdir, libname) for libname in\n                              [""tiledb.lib"", ""tbb.dll"", ""tbb.lib""]])\n        print(""\\n-------------------"")\n        print(""libtiledb_objects: "", libtiledb_objects)\n        print(""-------------------\\n"")\n        setuptools_cmd.distribution.package_data.update({""tiledb"": libtiledb_objects})\n\n\nclass LazyCommandClass(dict):\n    """"""\n    Lazy command class that defers operations requiring Cython and numpy until\n    they\'ve actually been downloaded and installed by setup_requires.\n    """"""\n\n    def __contains__(self, key):\n        return (\n                key in [\'build_ext\', \'bdist_wheel\', \'bdist_egg\']\n                or super(LazyCommandClass, self).__contains__(key)\n        )\n\n    def __setitem__(self, key, value):\n        if key == \'build_ext\':\n            raise AssertionError(""build_ext overridden!"")\n        super(LazyCommandClass, self).__setitem__(key, value)\n\n    def __getitem__(self, key):\n        if key == \'build_ext\':\n            return self.make_build_ext_cmd()\n        elif key == \'bdist_wheel\':\n            return self.make_bdist_wheel_cmd()\n        elif key == \'bdist_egg\':\n            return self.make_bdist_egg_cmd()\n        else:\n            return super(LazyCommandClass, self).__getitem__(key)\n\n    def make_build_ext_cmd(self):\n        """"""\n        :return: A command class implementing \'build_ext\'.\n        """"""\n        from Cython.Distutils import build_ext as cython_build_ext\n\n        class build_ext(cython_build_ext):\n            """"""\n            Custom build_ext command that lazily adds numpy\'s include_dir to\n            extensions.\n            """"""\n\n            def build_extensions(self):\n                """"""\n                Lazily append numpy\'s include directory to Extension includes.\n\n                This is done here rather than at module scope because setup.py\n                may be run before numpy has been installed, in which case\n                importing numpy and calling `numpy.get_include()` will fail.\n                """"""\n                numpy_incl = resource_filename(\'numpy\', \'core/include\')\n                for ext in self.extensions:\n                    ext.include_dirs.append(numpy_incl)\n\n                find_or_install_libtiledb(self)\n\n                # This explicitly calls the superclass method rather than the\n                # usual super() invocation because distutils\' build_class, of\n                # which Cython\'s build_ext is a subclass, is an old-style class\n                # in Python 2, which doesn\'t support `super`.\n                cython_build_ext.build_extensions(self)\n\n        return build_ext\n\n    def make_bdist_wheel_cmd(self):\n        """"""\n        :return: A command class implementing \'bdist_wheel\'.\n        """"""\n        from wheel.bdist_wheel import bdist_wheel\n\n        class bdist_wheel_cmd(bdist_wheel):\n            def run(self):\n                # This may modify package_data:\n                find_or_install_libtiledb(self)\n                bdist_wheel.run(self)\n\n        return bdist_wheel_cmd\n\n    def make_bdist_egg_cmd(self):\n        """"""\n        :return: A command class implementing \'bdist_egg\'.\n        """"""\n        from setuptools.command.bdist_egg import bdist_egg\n\n        class bdist_egg_cmd(bdist_egg):\n            def run(self):\n                # This may modify package_data:\n                find_or_install_libtiledb(self)\n                bdist_egg.run(self)\n\n        return bdist_egg_cmd\n\nclass get_pybind_include(object):\n  """"""Helper class to determine the pybind11 include path\n  The purpose of this class is to postpone importing pybind11\n  until it is actually installed, so that the ``get_include()``\n  method can be invoked. """"""\n\n  def __init__(self, user=False):\n    self.user = user\n\n  def __str__(self):\n    import pybind11\n    return pybind11.get_include(self.user)\n\ndef cmake_available():\n    """"""\n    Checks whether CMake command is available and >= version 3.3.\n    :return:\n    """"""\n    try:\n        output = subprocess.check_output([\'cmake\', \'--version\']).split()\n        version = output[2].decode(\'utf-8\').split(\'.\')\n        return int(version[0]) >= 3 and int(version[1]) >= 3\n    except:\n        return False\n\nnumpy_required_version = \'numpy<=1.16\' if sys.hexversion <0x3050000 else \'numpy>=1.7\'\ndef setup_requires():\n    req = [\'cython>=0.27\',\n           numpy_required_version,\n           \'setuptools>=18.0\',\n           \'setuptools_scm>=1.5.4\',\n           \'wheel>=0.30\',\n           \'pybind11\']\n    # Add cmake requirement if libtiledb is not found and cmake is not available.\n    if not libtiledb_exists(LIB_DIRS) and not cmake_available():\n        req.append(\'cmake>=3.11.0\')\n    return req\n\n\nTESTS_REQUIRE = []\nif ver < (3,):\n    TESTS_REQUIRE.extend([""unittest2"", ""mock""])\n\n# Allow setting (lib) TileDB directory if it is installed on the system\nTILEDB_PATH = os.environ.get(""TILEDB_PATH"", """")\nprint(""TILEDB_PATH from env: \'{}\'"".format(TILEDB_PATH))\n# Sources & libraries\nINC_DIRS = []\nLIB_DIRS = []\nLIBS = [""tiledb""]\nDEF_MACROS = []\n\n# Pass command line flags to setup.py script\n# handle --tiledb=[PATH] --lflags=[FLAGS] --cxxflags=[FLAGS]\nargs = sys.argv[:]\nfor arg in args:\n    if arg.find(\'--tiledb=\') == 0:\n        TILEDB_PATH = os.path.expanduser(arg.split(\'=\')[1])\n        sys.argv.remove(arg)\n    if arg.find(\'--lflags=\') == 0:\n        LFLAGS = arg.split(\'=\')[1].split()\n        sys.argv.remove(arg)\n    if arg.find(\'--cxxflags=\') == 0:\n        CXXFLAGS = arg.split(\'=\')[1].split()\n        sys.argv.remove(arg)\n    if arg.find(\'--debug\') == 0:\n        TILEDB_DEBUG_BUILD = True\n        sys.argv.remove(arg)\n    if arg.find(\'--modular\') == 0:\n        TILEDBPY_MODULAR = True\n        sys.argv.remove(arg)\n\n# Global variables\nCXXFLAGS = os.environ.get(""CXXFLAGS"", """").split()\nif not is_windows():\n  CXXFLAGS.append(""-std=c++11"")\n  if not TILEDB_DEBUG_BUILD:\n    CXXFLAGS.append(""-Wno-deprecated-declarations"")\n  elif TILEDB_DEBUG_BUILD:\n    CXXFLAGS.append(""-g"")\n    CXXFLAGS.append(""-O0"")\n    CXXFLAGS.append(""-UNDEBUG"") # defined by distutils\nLFLAGS = os.environ.get(""LFLAGS"", """").split()\n\nif TILEDB_PATH != \'\' and TILEDB_PATH != \'source\':\n    print(""TILEDB_PATH in block before: \'{}\'"".format(TILEDB_PATH))\n    TILEDB_PATH=os.path.normpath(TILEDB_PATH)\n    print(""TILEDB_PATH in block after: \'{}\'"".format(TILEDB_PATH))\n    LIB_DIRS += [os.path.join(os.path.normpath(TILEDB_PATH), \'lib\')]\n    if sys.platform.startswith(""linux""):\n        LIB_DIRS += [os.path.join(TILEDB_PATH, \'lib64\'),\n                     os.path.join(TILEDB_PATH, \'lib\', \'x86_64-linux-gnu\')]\n    elif os.name == \'nt\':\n        LIB_DIRS += [os.path.join(TILEDB_PATH, \'bin\')]\n    INC_DIRS += [os.path.join(TILEDB_PATH, \'include\')]\n    if sys.platform == \'darwin\':\n        LFLAGS += [\'-Wl,-rpath,{}\'.format(p) for p in LIB_DIRS]\n\nwith open(\'README.md\') as f:\n    README_MD = f.read()\n\n# Source files for build\nMODULAR_SOURCES = [\n  \'tiledb/np2buf.pyx\',\n  \'tiledb/indexing.pyx\',\n  \'tiledb/libmetadata.pyx\',\n  ]\nMODULAR_HEADERS = [\n  \'tiledb/libtiledb.pxd\',\n  \'tiledb/indexing.pxd\'\n  ]\n\n__extensions = [\n  Extension(\n    ""tiledb.libtiledb"",\n    include_dirs=INC_DIRS,\n    define_macros=DEF_MACROS,\n    sources=[""tiledb/libtiledb.pyx""],\n    depends=MODULAR_HEADERS,\n    library_dirs=LIB_DIRS,\n    libraries=LIBS,\n    extra_link_args=LFLAGS,\n    extra_compile_args=CXXFLAGS,\n    language=""c++""\n    ),\n  Extension(\n    ""tiledb.core"",\n    [""tiledb/core.cc""],\n    include_dirs = INC_DIRS + [\n        get_pybind_include(),\n        get_pybind_include(user=True)\n    ],\n    language=""c++"",\n    library_dirs=LIB_DIRS,\n    libraries=LIBS,\n    extra_link_args=LFLAGS,\n    extra_compile_args=CXXFLAGS,\n    )\n]\n\nif TILEDBPY_MODULAR:\n  for source in MODULAR_SOURCES:\n    module_name = os.path.splitext(os.path.split(source)[-1])[0]\n    if module_name+\'.pxd\' in MODULAR_HEADERS:\n      deps = module_name+\'.pxd\'\n    else:\n      deps = None\n    ext = Extension(\n        ""tiledb.{}"".format(module_name),\n        include_dirs=INC_DIRS,\n        define_macros=DEF_MACROS,\n        sources=[source],\n        depends=[deps] if deps else [],\n        library_dirs=LIB_DIRS,\n        libraries=LIBS,\n        extra_link_args=LFLAGS,\n        extra_compile_args=CXXFLAGS,\n        language=""c++""\n        )\n    __extensions.append(ext)\nelse:\n  __extensions[0].depends += MODULAR_SOURCES\n\n# Helper to set Extension attributes correctly based on python version\ndef ext_attr_update(attr, value):\n  for x in __extensions:\n    if sys.version_info < (3,0):\n        x.__dict__[attr] = value\n    else:\n        x.__setattr__(attr, value)\n\n# Monkey patches to be forwarded to cythonize\n# some of these will error out if passed directly\n# to Extension(..) above\n\nif ((\'bdist_wheel\' in sys.argv) or (\'TILEDB_WHEEL_BUILD\' in os.environ)):\n    ext_attr_update(\'tiledb_wheel_build\', True)\n\n\n# - build with `#line` directive annotations\n# (equivalent to `emit_linenums` command line directive)\next_attr_update(\'cython_line_directives\', 1)\n\n# - generate XML debug mapping file (`cython_debug`)\nif TILEDB_DEBUG_BUILD:\n  ext_attr_update(\'cython_gdb\', True)\n  __extensions[1].depends += ""tiledb/debug.cc""\n\n# - set rt lib dirs to get correct RPATH on unixy platforms\n#   note that we set rpath for darwin separately above.\nif not is_windows():\n  ext_attr_update(\'runtime_library_dirs\', LIB_DIRS)\n\nif TILEDB_PATH == \'source\':\n  ext_attr_update(\'tiledb_from_source\', True)\nelif TILEDB_PATH != \'\':\n  ext_attr_update(\'tiledb_path\', TILEDB_PATH)\n\n# This must always be set so the compile-time conditional has a value\next_attr_update(\'cython_compile_time_env\', {\'TILEDBPY_MODULAR\': TILEDBPY_MODULAR})\n\nsetup(\n    name=\'tiledb\',\n    description=""Pythonic interface to the TileDB array storage manager"",\n    long_description=README_MD,\n    long_description_content_type=\'text/markdown\',\n    author=\'TileDB, Inc.\',\n    author_email=\'help@tiledb.io\',\n    maintainer=\'TileDB, Inc.\',\n    maintainer_email=\'help@tiledb.io\',\n    url=\'https://github.com/TileDB-Inc/TileDB-Py\',\n    license=\'MIT\',\n    platforms=[\'any\'],\n    use_scm_version={\n        \'version_scheme\': \'guess-next-dev\',\n        \'local_scheme\': \'dirty-tag\',\n        \'write_to\': \'tiledb/version.py\'\n    },\n    ext_modules=__extensions,\n    setup_requires=setup_requires(),\n    install_requires=[\n        numpy_required_version,\n        \'wheel>=0.30\'\n    ],\n    tests_require=TESTS_REQUIRE,\n    packages=find_packages(),\n    cmdclass=LazyCommandClass(),\n    zip_safe=False,\n    classifiers=[\n        \'Development Status :: 4 - Beta\',\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Information Technology\',\n        \'Intended Audience :: Science/Research\',\n        \'License :: OSI Approved :: MIT License\',\n        \'Programming Language :: Python\',\n        \'Topic :: Software Development :: Libraries :: Python Modules\',\n        \'Operating System :: Unix\',\n        \'Operating System :: POSIX :: Linux\',\n        \'Operating System :: MacOS :: MacOS X\',\n        \'Programming Language :: Python :: 2\',\n        \'Programming Language :: Python :: 2.7\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.5\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Programming Language :: Python :: 3.7\',\n        \'Programming Language :: Python :: 3.8\',\n    ],\n)\n'"
examples/config.py,0,"b'# config.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/config.html\n#\n# This program shows how to set/get the TileDB configuration parameters.\n#\n\nimport tiledb\n\n\ndef set_get_config_ctx_vfs():\n    # Create config object\n    config = tiledb.Config()\n\n    # Set/get config to/from ctx\n    ctx = tiledb.Ctx(config)\n    config_ctx = ctx.config()\n\n    # Set/get config to/from VFS\n    vfs = tiledb.VFS(config)\n    config_vfs = vfs.config()\n\n\ndef set_get_config():\n    config = tiledb.Config()\n\n    # Set value\n    config[""vfs.s3.connect_timeout_ms""] = 5000\n\n    # Get value\n    tile_cache_size = config[""sm.tile_cache_size""]\n    print(""Tile cache size: %s"" % str(tile_cache_size))\n\n\ndef print_default():\n    config = tiledb.Config()\n    print(""\\nDefault settings:"")\n    for p in config.items():\n        print(""\\""%s\\"" : \\""%s\\"""" % (p[0], p[1]))\n\n\ndef iter_config_with_prefix():\n    config = tiledb.Config()\n    # Print only the S3 settings.\n    print(""\\nVFS S3 settings:"")\n    for p in config.items(""vfs.s3.""):\n        print(""\\""%s\\"" : \\""%s\\"""" % (p[0], p[1]))\n\n\ndef save_load_config():\n    # Save to file\n    config = tiledb.Config()\n    config[""sm.tile_cache_size""] = 0\n    config.save(""tiledb_config.txt"")\n\n    # Load from file\n    config_load = tiledb.Config.load(""tiledb_config.txt"")\n    print(""\\nTile cache size after loading from file: %s"" % str(config_load[""sm.tile_cache_size""]))\n\n\nset_get_config_ctx_vfs()\nset_get_config()\nprint_default()\niter_config_with_prefix()\nsave_load_config()\n'"
examples/errors.py,0,"b'# errors.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/errors.html\n#\n# This example shows how to catch errors in TileDB.\n#\n\nimport tiledb\n\n# Catch an error\ntry:\n    tiledb.group_create(""my_group"")\n    tiledb.group_create(""my_group"")\nexcept tiledb.TileDBError as e:\n    print(""TileDB exception: %s"" % e.message)\n\n# clean up\nif tiledb.VFS().is_dir(""my_group""):\n    tiledb.remove(""my_group"")\n\n# Setting a different error handler for the context is not yet supported.'"
examples/fragments_consolidation.py,7,"b'# fragments_consolidation.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/fragments-consolidation.html\n#\n# When run, this program will create a simple 2D dense array, write some data\n# with three queries (creating three fragments), optionally consolidate\n# and read the entire array data back.\n#\n\nimport numpy as np\nimport sys\nimport tiledb\n\narray_name = ""fragments_consolidation""\n\n\ndef create_array():\n    # The array will be 4x4 with dimensions ""rows"" and ""cols"", with domain [1,4] and space tiles 2x2.\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 4), tile=2, dtype=np.int32),\n                        tiledb.Dim(name=""cols"", domain=(1, 4), tile=2, dtype=np.int32))\n\n    # The array will be dense with a single attribute ""a"" so each (i,j) cell can store an integer.\n    schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                attrs=[tiledb.Attr(name=""a"", dtype=np.int32)])\n\n    # Create the (empty) array on disk.\n    tiledb.DenseArray.create(array_name, schema)\n\n\ndef write_array_1():\n    with tiledb.DenseArray(array_name, mode=\'w\') as A:\n        A[1:3, 1:5] = np.array(([1, 2, 3, 4, 5, 6, 7, 8]))\n\n\ndef write_array_2():\n    with tiledb.DenseArray(array_name, mode=\'w\') as A:\n        A[2:4, 2:4] = np.array(([101, 102, 103, 104]))\n\n\ndef write_array_3():\n    with tiledb.DenseArray(array_name, mode=\'w\') as A:\n        # Note: sparse (unordered) writes to dense arrays are not yet supported in Python.\n        # Instead we can make two single-cell writes (results in total of 4 fragments).\n        A[1:2, 1:2] = np.array(([201]))\n        A[3:4, 4:5] = np.array(([202]))\n\n\ndef read_array():\n    with tiledb.DenseArray(array_name, mode=\'r\') as A:\n        # Read the entire array. To get coord values as well, we use the .query() syntax.\n        data = A.query(coords=True)[:, :]\n        a_vals = data[""a""]\n        rows = data[""rows""]\n        cols = data[""cols""]\n        for i in range(rows.shape[0]):\n            for j in range(cols.shape[0]):\n                print(""Cell {} has data {}"".format(str((rows[i,j], cols[i,j])), str(a_vals[i, j])))\n\n\n# Create and write array only if it does not exist\nif tiledb.object_type(array_name) != ""array"":\n    create_array()\n    write_array_1()\n    write_array_2()\n    write_array_3()\n\n# Optionally consolidate\nif len(sys.argv) > 1 and sys.argv[1] == ""consolidate"":\n    config = tiledb.Config()\n    config[""sm.consolidation.steps""] = 1\n    config[""sm.consolidation.step_max_frags""] = 3\n    config[""sm.consolidation.step_min_frags""] = 1\n    tiledb.consolidate(config=config, uri=array_name)\n\nread_array()\n'"
examples/multi_attribute.py,7,"b'# multi_attribute.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/multi-attribute-arrays.html\n#\n# When run, this program will create a simple 2D dense array with two\n# attributes, write some data to it, and read a slice of the data back on\n# (i) both attributes, and (ii) subselecting on only one of the attributes.\n#\n\n\nimport numpy as np\nimport sys\nimport tiledb\n\n# Name of the array to create.\narray_name = ""multi_attribute""\n\n\ndef create_array():\n    # Check if the array already exists.\n    if tiledb.object_type(array_name) == ""array"":\n        return\n\n    # The array will be 4x4 with dimensions ""rows"" and ""cols"", with domain [1,4].\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 4), tile=4, dtype=np.int32),\n                        tiledb.Dim(name=""cols"", domain=(1, 4), tile=4, dtype=np.int32))\n\n    # Add two attributes ""a1"" and ""a2"", so each (i,j) cell can store\n    # a character on ""a1"" and a vector of two floats on ""a2"".\n    schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                attrs=[tiledb.Attr(name=""a1"", dtype=np.uint8),\n                                       tiledb.Attr(name=""a2"",\n                                                   dtype=np.dtype([("""", np.float32), ("""", np.float32), ("""", np.float32)]))])\n\n    # Create the (empty) array on disk.\n    tiledb.DenseArray.create(array_name, schema)\n\n\ndef write_array():\n    # Open the array and write to it.\n    with tiledb.DenseArray(array_name, mode=\'w\') as A:\n        data_a1 = np.array((list(map(ord, [\'a\', \'b\', \'c\', \'d\', \'e\', \'f\', \'g\', \'h\',\n                                           \'i\', \'j\', \'k\', \'l\', \'m\', \'n\', \'o\', \'p\']))))\n        data_a2 = np.array(([(1.1, 1.2, 1.3), (2.1, 2.2, 2.3), (3.1, 3.2, 3.3), (4.1, 4.2, 4.3),\n                             (5.1, 5.2, 5.3), (6.1, 6.2, 6.3), (7.1, 7.2, 7.3), (8.1, 8.2, 8.3),\n                             (9.1, 9.2, 9.3), (10.1, 10.2, 10.3), (11.1, 11.2, 11.3), (12.1, 12.2, 12.3),\n                             (13.1, 13.2, 13.3), (14.1, 14.2, 14.3), (15.1, 15.2, 15.3), (16.1, 16.2, 16.3)]),\n                           dtype=[("""", np.float32), ("""", np.float32), ("""", np.float32)])\n        A[:, :] = {""a1"": data_a1, ""a2"": data_a2}\n\n\ndef read_array():\n    # Open the array and read from it.\n    with tiledb.DenseArray(array_name, mode=\'r\') as A:\n        # Slice only rows 1, 2 and cols 2, 3, 4.\n        data = A[1:3, 2:5]\n        print(""Reading both attributes a1 and a2:"")\n        a1, a2 = data[""a1""].flat, data[""a2""].flat\n        for i, v in enumerate(a1):\n            print(""a1: \'%s\', a2: (%.1f,%.1f,%.1f)"" % (chr(v), a2[i][0], a2[i][1], a2[i][2]))\n\n\ndef read_array_subselect():\n    # Open the array and read from it.\n    with tiledb.DenseArray(array_name, mode=\'r\') as A:\n        # Slice only rows 1, 2 and cols 2, 3, 4, attribute \'a1\' only.\n        # We use the \'.query()\' syntax which allows attribute subselection.\n        data = A.query(attrs=[""a1""])[1:3, 2:5]\n        print(""Subselecting on attribute a1:"")\n        for a in data[""a1""].flat:\n            print(""a1: \'%s\'"" % chr(a))\n\n\ncreate_array()\nwrite_array()\nread_array()\nread_array_subselect()\n'"
examples/multirange_indexing.py,4,"b'# multirange_indexing.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2020 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB documentation:\n#  https://docs.tiledb.com/developer/api-usage/reading-arrays/multi-range-subarrays\n#\n# When run, this program will create a simple 2D dense array with two\n# attributes, write some data to it, and read a slice of the data back on\n# (i) both attributes, and (ii) subselecting on only one of the attributes.\n#\n\n\nimport numpy as np\nimport sys\nimport tiledb\n\n# Name of the array to create.\narray_name = ""multi_range""\n\n\ndef create_array():\n    # Check if the array already exists.\n    if tiledb.object_type(array_name) == ""array"":\n        return\n\n    dom = tiledb.Domain(tiledb.Dim(name=""x"", domain=(1, 20), tile=4, dtype=np.int64),\n                        tiledb.Dim(name=""y"", domain=(1, 20), tile=4, dtype=np.int64))\n\n    # Add two attributes ""a1"" and ""a2"", so each (i,j) cell can store\n    # a character on ""a1"" and a vector of two floats on ""a2"".\n    schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                attrs=[tiledb.Attr(name=""a"", dtype=np.float64)])\n\n    # Create the (empty) array on disk.\n    tiledb.DenseArray.create(array_name, schema)\n\n\ndef write_array():\n    # Open the array and write to it.\n    with tiledb.DenseArray(array_name, mode=\'w\') as A:\n        data_a = np.arange(400).reshape(20,20)\n        A[:, :] = {""a"": data_a}\n\n\ndef read_array():\n    # Open the array and read from it.\n    with tiledb.DenseArray(array_name, mode=\'r\') as A:\n        # Slice only rows: (1,3) inclusive, and 5\n        #            cols: 2, 5, 7\n        data = A.multi_index[ [(1,3), 5], [2,5,7] ]\n        print(""Reading attribute \'a\', [ [1:3, 5], [2,5,7] ]"")\n        a = data[\'a\']\n        print(a)\n\ncreate_array()\nwrite_array()\nread_array()\n'"
examples/object.py,3,"b'# object.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/object.html\n#\n# This program creates a hierarchy as shown below. Specifically, it creates\n# groups `dense_arrays` and `sparse_arrays` in a group `my_group`, and\n# then some dense/sparse arrays and key-value store in those groups.\n#\n# my_group/\n#   - dense_arrays/\n#     - array_A\n#     - array_B\n#   - sparse_arrays/\n#     - array_C\n#     - array_D\n#\n# The program then shows how to list this hierarchy, as well as\n# move/remove TileDB objects.\n#\n\n# For print() in Python 2\nfrom __future__ import print_function\n\nimport numpy as np\nimport tiledb\nimport os\n\n\ndef create_array(array_name, sparse):\n    if tiledb.object_type(array_name) == ""array"":\n        return\n\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 4), tile=4, dtype=np.int32),\n                        tiledb.Dim(name=""cols"", domain=(1, 4), tile=4, dtype=np.int32))\n    schema = tiledb.ArraySchema(domain=dom, sparse=sparse,\n                                attrs=[tiledb.Attr(name=""a"", dtype=np.int32)])\n    if sparse:\n        tiledb.SparseArray.create(array_name, schema)\n    else:\n        tiledb.DenseArray.create(array_name, schema)\n\ndef path(p):\n    return os.path.join(os.getcwd(), p)\n\ndef create_hierarchy():\n    # Create groups\n    tiledb.group_create(path(""my_group""))\n    tiledb.group_create(path(""my_group/dense_arrays""))\n    tiledb.group_create(path(""my_group/sparse_arrays""))\n\n    # Create arrays\n    create_array(path(""my_group/dense_arrays/array_A""), False)\n    create_array(path(""my_group/dense_arrays/array_B""), False)\n    create_array(path(""my_group/sparse_arrays/array_C""), True)\n    create_array(path(""my_group/sparse_arrays/array_D""), True)\n\n\ndef list_obj(path):\n\n    # List children\n    print(""\\nListing hierarchy:"")\n    tiledb.ls(path, lambda obj_path, obj_type: print(obj_path, obj_type))\n\n    # Walk in a path with a pre- and post-order traversal\n    print(""\\nPreorder traversal:"")\n    tiledb.walk(path, lambda obj_path, obj_type: print(obj_path, obj_type))  # Default order is preorder\n\n    print(""\\nPostorder traversal:"")\n    tiledb.walk(path, lambda obj_path, obj_type: print(obj_path, obj_type), order=""postorder"")\n\n\ndef move_remove_obj():\n    tiledb.move(path(""my_group""), path(""my_group_2""))\n    tiledb.remove(path(""my_group_2/dense_arrays""))\n    tiledb.remove(path(""my_group_2/sparse_arrays/array_C""))\n\n\ncreate_hierarchy()\nlist_obj(""my_group"")\nmove_remove_obj()  # Renames \'my_group\' to \'my_group_2\'\nlist_obj(""my_group_2"")\n\n# clean up\ntiledb.remove(""my_group_2"")\n'"
examples/quickstart_dense.py,4,"b'# quickstart_dense.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB quickstart tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/quickstart.html\n#\n# When run, this program will create a simple 2D dense array, write some data\n# to it, and read a slice of the data back.\n#\n\nimport numpy as np\nimport sys\nimport tiledb\n\n# Name of the array to create.\narray_name = ""quickstart_dense""\n\n\ndef create_array():\n\n    # The array will be 4x4 with dimensions ""rows"" and ""cols"", with domain [1,4].\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 4), tile=4, dtype=np.int32),\n                        tiledb.Dim(name=""cols"", domain=(1, 4), tile=4, dtype=np.int32))\n\n    # The array will be dense with a single attribute ""a"" so each (i,j) cell can store an integer.\n    schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                attrs=[tiledb.Attr(name=""a"", dtype=np.int32)])\n\n    # Create the (empty) array on disk.\n    tiledb.DenseArray.create(array_name, schema)\n\n\ndef write_array():\n    # Open the array and write to it.\n    with tiledb.DenseArray(array_name, mode=\'w\') as A:\n        data = np.array(([1, 2, 3, 4],\n                         [5, 6, 7, 8],\n                         [9, 10, 11, 12],\n                         [13, 14, 15, 16]))\n        A[:] = data\n\n\ndef read_array():\n    # Open the array and read from it.\n    with tiledb.DenseArray(array_name, mode=\'r\') as A:\n        # Slice only rows 1, 2 and cols 2, 3, 4.\n        data = A[1:3, 2:5]\n        print(data[""a""])\n\n\nif tiledb.object_type(array_name) != ""array"":\n    create_array()\n    write_array()\n\nread_array()\n'"
examples/quickstart_sparse.py,4,"b'# quickstart_sparse.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB quickstart tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/quickstart.html\n#\n# When run, this program will create a simple 2D sparse array, write some data\n# to it, and read a slice of the data back.\n#\n\n\nimport numpy as np\nimport sys\nimport tiledb\n\n# Name of the array to create.\narray_name = ""quickstart_sparse""\n\n\ndef create_array():\n    # The array will be 4x4 with dimensions ""rows"" and ""cols"", with domain [1,4].\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 4), tile=4, dtype=np.int32),\n                        tiledb.Dim(name=""cols"", domain=(1, 4), tile=4, dtype=np.int32))\n\n    # The array will be sparse with a single attribute ""a"" so each (i,j) cell can store an integer.\n    schema = tiledb.ArraySchema(domain=dom, sparse=True,\n                                attrs=[tiledb.Attr(name=""a"", dtype=np.int32)])\n\n    # Create the (empty) array on disk.\n    tiledb.SparseArray.create(array_name, schema)\n\n\ndef write_array():\n    # Open the array and write to it.\n    with tiledb.SparseArray(array_name, mode=\'w\') as A:\n        # Write some simple data to cells (1, 1), (2, 4) and (2, 3).\n        I, J = [1, 2, 2], [1, 4, 3]\n        data = np.array(([1, 2, 3]))\n        A[I, J] = data\n\n\ndef read_array():\n    # Open the array and read from it.\n    with tiledb.SparseArray(array_name, mode=\'r\') as A:\n        # Slice only rows 1, 2 and cols 2, 3, 4.\n        data = A[1:3, 2:5]\n        a_vals = data[""a""]\n        for i, coord in enumerate(zip(data[""rows""], data[""cols""])):\n            print(""Cell (%d, %d) has data %d"" % (coord[0], coord[1], a_vals[i]))\n\n\nif tiledb.object_type(array_name) != ""array"":\n    create_array()\n    write_array()\n\nread_array()\n'"
examples/reading_dense_layouts.py,5,"b'# reading_dense_layouts.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/reading.html\n#\n# When run, this program will create a simple 2D dense array, write some data\n# to it, and read a slice of the data back in the layout of the user\'s choice\n# (passed as an argument to the program: ""row"", ""col"", or ""global"").\n#\n\nimport numpy as np\nimport sys\nimport tiledb\n\n# Name of the array to create.\narray_name = ""reading_dense_layouts""\n\n\ndef create_array():\n    # The array will be 4x4 with dimensions ""rows"" and ""cols"", with domain [1,4].\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 4), tile=2, dtype=np.int32),\n                        tiledb.Dim(name=""cols"", domain=(1, 4), tile=2, dtype=np.int32))\n\n    # The array will be dense with a single attribute ""a"" so each (i,j) cell can store an integer.\n    schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                attrs=[tiledb.Attr(name=""a"", dtype=np.int32)])\n\n    # Create the (empty) array on disk.\n    tiledb.DenseArray.create(array_name, schema)\n\n\ndef write_array():\n    # Open the array and write to it.\n    with tiledb.DenseArray(array_name, mode=\'w\') as A:\n        # NOTE: global writes are not currently supported in the Python API.\n        # The following code will produce the same array as the corresponding\n        # C++ example in the docs (which wrote in global order)\n        data = np.array(([1, 2, 5, 6],\n                         [3, 4, 7, 8],\n                         [9, 10, 13, 14],\n                         [11, 12, 15, 16]))\n        A[:] = data\n\n\ndef read_array(order):\n    # Open the array and read from it.\n    with tiledb.DenseArray(array_name, mode=\'r\') as A:\n        # Get non-empty domain\n        print(""Non-empty domain: {}"".format(A.nonempty_domain()))\n\n        # Slice only rows 1, 2 and cols 2, 3, 4.\n        # NOTE: The `query` syntax is required to get the coordinates for\n        # dense arrays and specify an order other than the default row-major\n        data = A.query(attrs=[""a""], order=order, coords=True)[1:3, 2:5]\n        a_vals = data[""a""]\n        coords = np.asarray(list(zip(data[""rows""], data[""cols""])))\n\n        if order != \'G\' and a_vals.flags[\'F_CONTIGUOUS\']:\n            print(""NOTE: The following result array has col-major layout internally"")\n\n        if order != \'G\':\n            for i in range(coords.shape[0]):\n                for j in range(coords.shape[1]):\n                    print(""Cell {} has data {}"".format(str(coords[i, j]), str(a_vals[i, j])))\n        else:\n            # When reading in global order, TileDB always returns a vector (1D array)\n            for i in range(coords.shape[0]):\n                print(""Cell {} has data {}"".format(str(coords[i]), str(a_vals[i])))\n\n\n# Check if the array already exists.\nif tiledb.object_type(array_name) != ""array"":\n    create_array()\n    write_array()\n\nlayout = """"\nif len(sys.argv) > 1:\n    layout = sys.argv[1]\n\norder = \'C\'\nif layout == ""col"":\n    order = \'F\'\nelif layout == ""global"":\n    order = \'G\'\nelse:\n    order = \'C\'\n\nread_array(order)\n'"
examples/reading_sparse_layouts.py,4,"b'# reading_sparse_layouts.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/reading.html\n#\n# When run, this program will create a simple 2D sparse array, write some data\n# to it, and read a slice of the data back in the layout of the user\'s choice\n# (passed as an argument to the program: ""row"", ""col"", or ""global"").\n#\n\n\nimport numpy as np\nimport sys\nimport tiledb\n\n# Name of the array to create.\narray_name = ""reading_sparse_layouts""\n\n\ndef create_array():\n    # The array will be 4x4 with dimensions ""rows"" and ""cols"", with domain [1,4].\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 4), tile=2, dtype=np.int32),\n                        tiledb.Dim(name=""cols"", domain=(1, 4), tile=2, dtype=np.int32))\n\n    # The array will be sparse with a single attribute ""a"" so each (i,j) cell can store an integer.\n    schema = tiledb.ArraySchema(domain=dom, sparse=True,\n                                attrs=[tiledb.Attr(name=""a"", dtype=np.int32)])\n\n    # Create the (empty) array on disk.\n    tiledb.SparseArray.create(array_name, schema)\n\n\ndef write_array():\n    # Open the array and write to it.\n    with tiledb.SparseArray(array_name, mode=\'w\') as A:\n        # To write, the coordinates must be split into two vectors, one per dimension\n        I, J = [1, 1, 2, 1, 2, 2], [1, 2, 2, 4, 3, 4]\n        data = np.array(([1, 2, 3, 4, 5, 6]));\n        A[I, J] = data\n\ndef read_array(order):\n    # Open the array and read from it.\n    with tiledb.SparseArray(array_name, mode=\'r\') as A:\n        # Get non-empty domain\n        print(""Non-empty domain: {}"".format(A.nonempty_domain()))\n\n        # Slice only rows 1, 2 and cols 2, 3, 4.\n        # NOTE: The `query` syntax is required to specify an order\n        # other than the default row-major\n        data = A.query(attrs=[""a""], order=order, coords=True)[1:3, 2:5]\n        a_vals = data[""a""]\n\n        for i, coord in enumerate(zip(data[""rows""], data[""cols""])):\n            print(""Cell {} has data {}"".format(str(coord), str(a_vals[i])))\n\n\n# Check if the array already exists.\nif tiledb.object_type(array_name) != ""array"":\n    create_array()\n    write_array()\n\nlayout = """"\nif len(sys.argv) > 1:\n    layout = sys.argv[1]\n\norder = \'C\'\nif layout == ""col"":\n    order = \'F\'\nelif layout == ""global"":\n    order = \'G\'\nelse:\n    order = \'C\'\n\nread_array(order)\n'"
examples/string_float_int_dimensions.py,4,"b'# quickstart_dense.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB quickstart tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/quickstart.html\n#\n# When run, this program will create a simple 2D dense array, write some data\n# to it, and read a slice of the data back.\n#\n\nimport tiledb\nimport numpy as np\nimport random\n\npath = ""sparse_mixed_demo""\n\nctx = tiledb.Ctx()\n\ndom = tiledb.Domain(*[\n    tiledb.Dim(name=""str_dim"", domain=(None,None), dtype=np.bytes_, ctx=ctx),\n    tiledb.Dim(name=""int64_dim"", domain=(0, 100), tile=10, dtype=np.int64, ctx=ctx),\n    tiledb.Dim(name=""float64_dim"", domain=(-100.0,100.0), tile=10, dtype=np.float64, ctx=ctx)],\n                    ctx=ctx)\n\natt = tiledb.Attr(name=""a"", ctx=ctx, dtype=np.int64)\nschema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,), sparse=True, capacity=10000)\ntiledb.SparseArray.create(path, schema)\n\ndata = [1,2,3,4]\nc_str = [b""aa"",b""bbb"", b""c"", b""dddd""]\nc_int64 = [0,10,20,30]\nc_float64 = [-95.0, -61.5, 1.3, 42.7]\n\nwith tiledb.open(path, \'w\') as A:\n    A[c_str, c_int64, c_float64] = data\n\nwith tiledb.open(path) as A:\n    print(""\\n\\nRead full array:\\n"")\n    print(A[:])\n\n    print(""\\n\\nRead string slice A[\'c\':\'dddd\']:\\n"")\n    print(A[\'c\':\'dddd\'])\n\n    print(""\\n\\nRead A[:, 10]: \\n"")\n    print(A[\'aa\':\'bbb\'])\n\n    print(""\\n\\nRead A.multi_index[\'aa\':\'c\', 0:10]\\n"")\n    print(A.multi_index[\'aa\':\'c\', 0:10])\n\n    print(""\\n\\nRead A.multi_index[\'aa\':\'bbb\', :, -95.0:-61.5]\\n"")\n    print(A.multi_index[\'aa\':\'bbb\', :, -95.0:-61.5])\n'"
examples/using_tiledb_stats.py,4,"b'# using_tiledb_stats.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/performance/using-tiledb-statistics.html\n#\n# When run, this program will create a 0.5GB dense array, and enable the\n# TileDB statistics surrounding reads from the array.\n#\n\nimport numpy as np\nimport tiledb\n\n# Name of array.\narray_name = ""stats_array""\n\n\ndef create_array(row_tile_extent, col_tile_extent):\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 12000), tile=row_tile_extent, dtype=np.int32),\n                        tiledb.Dim(name=""cols"", domain=(1, 12000), tile=col_tile_extent, dtype=np.int32))\n\n    schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                attrs=[tiledb.Attr(name=""a"", dtype=np.int32)])\n\n    # Create the (empty) array on disk.\n    tiledb.DenseArray.create(array_name, schema)\n\n\ndef write_array():\n    # Open the array and write to it.\n    with tiledb.DenseArray(array_name, mode=\'w\') as A:\n        data = np.arange(12000 * 12000)\n        A[:] = data\n\n\ndef read_array():\n    # Open the array and read from it.\n    with tiledb.DenseArray(array_name, mode=\'r\') as A:\n        # Read a slice of 3,000 rows.\n        # Enable the stats for the read query, and print the report.\n        tiledb.stats_enable()\n        data1 = A[1:3001, 1:12001]\n        tiledb.stats_dump()\n        tiledb.stats_disable()\n\n\n# Create array with each row as a tile.\ncreate_array(1, 12000)\nwrite_array()\nread_array()\n'"
examples/variable_length.py,8,"b'\n#%%\nimport tiledb\nimport numpy as np\nfrom tiledb.tests.common import assert_subarrays_equal\n\narray_name = ""variable_length_array""\n\n#%%\n\ndef create_array():\n    ctx = tiledb.Ctx()\n\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 4), tile=4, dtype=np.int64),\n                        tiledb.Dim(name=""cols"", domain=(1, 4), tile=4, dtype=np.int64),\n                        ctx=ctx)\n\n    attrs = [\n        tiledb.Attr(name=""a1"", var=True, dtype=\'U\', ctx=ctx),\n        tiledb.Attr(name=""a2"", var=True, dtype=np.int64, ctx=ctx)\n        ]\n\n    schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                attrs=attrs,\n                                ctx=ctx)\n\n    tiledb.Array.create(array_name, schema, ctx=ctx)\n\n    return schema\n\n\ndef generate_data():\n    # generate test input data\n    a1_data = np.array([\n                    ""a"", ""bb"", ""ccc"", ""dd"",\n                    ""eee"", ""f"", ""g"", ""hhh"",\n                    ""i"", ""jjj"", ""kk"", ""l"",\n                    ""m"", ""n"", ""oo"", ""p""\n                ], dtype=np.object)\n\n    a1_data = a1_data.reshape(4,4)\n\n    a2_data = np.array(\n                list(map(\n                    lambda v: np.repeat(v[0], v[1]).astype(np.int64),\n                    [\n                    (1,1), (2,2), (3,1), (4,1),\n                    (5,1), (6,2), (7,2), (8,3),\n                    (9,2), (10,1),(11,1),(12,2),\n                    (13,1),(14,3),(15,1),(16,1),\n                    ]\n                )), dtype=np.object)\n    a2_data = a2_data.reshape(4,4)\n\n    data_dict = { \'a1\': a1_data,\n                  \'a2\': a2_data\n                }\n\n    return data_dict\n\n\ndef write_array(data_dict):\n    ctx = tiledb.Ctx()\n\n    # open array for writing, and write data\n    with tiledb.open(array_name, \'w\', ctx=ctx) as array:\n        array[:] = data_dict\n\ndef test_output_subarrays(test_dict):\n    from numpy.testing import assert_array_equal\n\n    ctx = tiledb.Ctx()\n    with tiledb.open(array_name, ctx=ctx) as A:\n        rt_dict = A[:]\n        assert_subarrays_equal(test_dict[\'a2\'], rt_dict[\'a2\'])\n\ncreate_array()\ndata = generate_data()\nwrite_array(data)\ntest_output_subarrays(data)\n'"
examples/vfs.py,0,"b'# vfs.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/vfs.html\n#\n# This program explores the various TileDB VFS tools.\n#\n\nimport struct\nimport tiledb\nimport os\n\ndef path(p):\n    return os.path.join(os.getcwd(), p)\n\ndef dirs_files():\n    # Create TileDB VFS\n    vfs = tiledb.VFS()\n\n    # Create directory\n    if not vfs.is_dir(""dir_A""):\n        vfs.create_dir(path(""dir_A""))\n        print(""Created \'dir_A\'"")\n    else:\n        print(""\'dir_A\' already exists"")\n\n    # Creating an (empty) file\n    if not vfs.is_file(""dir_A/file_A""):\n        vfs.touch(path(""dir_A/file_A""))\n        print(""Created empty file \'dir_A/file_A\'"")\n    else:\n        print(""\'dir_A/file_A\' already exists"")\n\n    # Getting the file size\n    print(""Size of file \'dir_A/file_A\': {}"".format(vfs.file_size(path(""dir_A/file_A""))))\n\n    # Moving files (moving directories is similar)\n    print(""Moving file \'dir_A/file_A\' to \'dir_A/file_B\'"")\n    vfs.move_file(path(""dir_A/file_A""), path(""dir_A/file_B""))\n\n    # Deleting files and directories\n    print(""Deleting \'dir_A/file_B\' and \'dir_A\'"")\n    vfs.remove_file(path(""dir_A/file_B""))\n    vfs.remove_dir(path(""dir_A""))\n\n\ndef write():\n    # Create TileDB VFS\n    vfs = tiledb.VFS()\n\n    # Create VFS file handle\n    f = vfs.open(""tiledb_vfs.bin"", ""wb"")\n\n    # Write binary data\n    vfs.write(f, struct.pack(""f"", 153.0))\n    vfs.write(f, ""abcd"".encode(""utf-8""))\n    vfs.close(f)\n\n    # Write binary data again - this will overwrite the previous file\n    f = vfs.open(""tiledb_vfs.bin"", ""wb"")\n    vfs.write(f, struct.pack(""f"", 153.1))\n    vfs.write(f, ""abcdef"".encode(""utf-8""))\n    vfs.close(f)\n\n    # Append binary data to existing file (this will NOT work on S3)\n    f = vfs.open(""tiledb_vfs.bin"", ""ab"")\n    vfs.write(f, ""ghijkl"".encode(""utf-8""))\n    vfs.close(f)\n\n\ndef read():\n    # Create TileDB VFS\n    vfs = tiledb.VFS()\n\n    # Read binary data\n    f = vfs.open(""tiledb_vfs.bin"", ""rb"")\n    f1 = struct.unpack(""f"", vfs.read(f, 0, 4))[0]\n    s1 = bytes.decode(vfs.read(f, 4, 12), ""utf-8"")\n    print(""Binary read:\\n{}\\n{}"".format(f1, s1))\n\n    vfs.close(f)\n\n\ndirs_files()\nwrite()\nread()\n'"
examples/writing_dense_multiple.py,5,"b'# writing_dense_multiple.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/writing-dense.html\n#\n# When run, this program will create a simple 2D dense array, write some data\n# to it with two write queries, and read the entire array data back.\n#\n\nimport numpy as np\nimport sys\nimport tiledb\n\n# Name of the array to create.\narray_name = ""writing_dense_multiple""\n\n\ndef create_array():\n    # The array will be 4x4 with dimensions ""rows"" and ""cols"", with domain [1,4].\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 4), tile=2, dtype=np.int32),\n                        tiledb.Dim(name=""cols"", domain=(1, 4), tile=2, dtype=np.int32))\n\n    # The array will be dense with a single attribute ""a"" so each (i,j) cell can store an integer.\n    schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                attrs=[tiledb.Attr(name=""a"", dtype=np.int32)])\n\n    # Create the (empty) array on disk.\n    tiledb.DenseArray.create(array_name, schema)\n\ndef write_array():\n    # Open the array and write to it.\n    with tiledb.DenseArray(array_name, mode=\'w\') as A:\n        # First write\n        data = np.array(([1, 2], [3, 4]))\n        A[1:3, 1:3] = data\n\n        # Second write\n        data = np.array(([5, 6, 7, 8],\n                         [9, 10, 11, 12]))\n        A[2:4, 1:5] = data\n\ndef read_array():\n    # Open the array and read from it.\n    with tiledb.DenseArray(array_name, mode=\'r\') as A:\n        # Slice the entire array\n        data = A[:]\n        print(data[""a""])\n\n\nif tiledb.object_type(array_name) != ""array"":\n    create_array()\n    write_array()\n\nread_array()\n'"
examples/writing_dense_padding.py,4,"b'# writing_dense_padding.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/writing-dense.html\n#\n# When run, this program will create a simple 2D dense array, write some data\n# to it in a way that some space is empty, and read the entire array data back.\n#\n\nimport numpy as np\nimport sys\nimport tiledb\n\n# Name of the array to create.\narray_name = ""writing_dense_padding""\n\n\ndef create_array():\n    # The array will be 4x4 with dimensions ""rows"" and ""cols"", with domain [1,4].\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 4), tile=2, dtype=np.int32),\n                        tiledb.Dim(name=""cols"", domain=(1, 4), tile=2, dtype=np.int32))\n\n    # The array will be dense with a single attribute ""a"" so each (i,j) cell can store an integer.\n    schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                attrs=[tiledb.Attr(name=""a"", dtype=np.int32)])\n\n    # Create the (empty) array on disk.\n    tiledb.DenseArray.create(array_name, schema)\n\ndef write_array():\n    # Open the array and write to it.\n    with tiledb.DenseArray(array_name, mode=\'w\') as A:\n        # Write to [2,3], [1,2]\n        data = np.array(([1, 2], [3, 4]))\n        A[2:4, 1:3] = data\n\ndef read_array():\n    # Open the array and read from it.\n    with tiledb.DenseArray(array_name, mode=\'r\') as A:\n        # Slice the entire array\n        data = A[:]\n        print(data[""a""])\n\n\nif tiledb.object_type(array_name) != ""array"":\n    create_array()\n    write_array()\n\nread_array()\n'"
examples/writing_sparse_multiple.py,5,"b'# writing_sparse_multiple.py\n#\n# LICENSE\n#\n# The MIT License\n#\n# Copyright (c) 2018 TileDB, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n#\n# DESCRIPTION\n#\n# This is a part of the TileDB tutorial:\n#   https://docs.tiledb.io/en/latest/tutorials/writing-sparse.html\n#\n# When run, this program will create a simple 2D sparse array, write some data\n# to it twice, and read all the data back.\n#\n\nimport numpy as np\nimport sys\nimport tiledb\n\n# Name of the array to create.\narray_name = ""writing_sparse_multiple""\n\n\ndef create_array():\n    # The array will be 4x4 with dimensions ""rows"" and ""cols"", with domain [1,4].\n    dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(1, 4), tile=4, dtype=np.int32),\n                        tiledb.Dim(name=""cols"", domain=(1, 4), tile=4, dtype=np.int32))\n\n    # The array will be sparse with a single attribute ""a"" so each (i,j) cell can store an integer.\n    schema = tiledb.ArraySchema(domain=dom, sparse=True,\n                                attrs=[tiledb.Attr(name=""a"", dtype=np.int32)])\n\n    # Create the (empty) array on disk.\n    tiledb.SparseArray.create(array_name, schema)\n\n\ndef write_array():\n    # Open the array and write to it.\n    with tiledb.SparseArray(array_name, mode=\'w\') as A:\n        # First write\n        I, J = [1, 2, 2], [1, 4, 3]\n        data = np.array(([1, 2, 3]))\n        A[I, J] = data\n\n        # Second write\n        I, J = [4, 2], [1, 4]\n        data = np.array(([4, 20]))\n        A[I, J] = data\n\ndef read_array():\n    # Open the array and read from it.\n    with tiledb.SparseArray(array_name, mode=\'r\') as A:\n        # Slice entire array\n        data = A[1:5, 1:5]\n        a_vals = data[""a""]\n        for i, coord in enumerate(zip(data[""rows""], data[""cols""])):\n            print(""Cell (%d, %d) has data %d"" % (coord[0], coord[1], a_vals[i]))\n\n\nif tiledb.object_type(array_name) != ""array"":\n    create_array()\n    write_array()\n\nread_array()\n'"
tiledb/__init__.py,0,"b'from __future__ import absolute_import\n\nimport ctypes\nimport os\nimport sys\n\nif os.name == ""posix"":\n    if sys.platform == ""darwin"":\n        lib_name = ""libtiledb.dylib""\n    else:\n        lib_name = ""libtiledb.so""\nelse:\n    lib_name = ""tiledb""\n\n# On Windows and whl builds, we may have a shared library already linked, or\n# adjacent to, the cython .pyd shared object. In this case, we can import directly\n# from .libtiledb\ntry:\n    import tiledb\n    from .libtiledb import Ctx\nexcept:\n    try:\n        lib_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), ""native"")\n        ctypes.CDLL(os.path.join(lib_dir, lib_name))\n    except OSError as e:\n        # Otherwise try loading by name only.\n        ctypes.CDLL(lib_name)\n\nfrom .libtiledb import (\n     Array,\n     Ctx,\n     Config,\n     Dim,\n     Domain,\n     Attr,\n     ArraySchema,\n     TileDBError,\n     VFS,\n     FileIO,\n     FilterList,\n     GzipFilter,\n     ZstdFilter,\n     LZ4Filter,\n     Bzip2Filter,\n     RleFilter,\n     DoubleDeltaFilter,\n     BitShuffleFilter,\n     ByteShuffleFilter,\n     BitWidthReductionFilter,\n     PositiveDeltaFilter,\n     consolidate,\n     default_ctx,\n     group_create,\n     object_type,\n     ls,\n     walk,\n     remove,\n     move,\n     schema_like,\n     stats_enable,\n     stats_disable,\n     stats_reset,\n     stats_dump,\n     vacuum\n)\n\nfrom .array import DenseArray, SparseArray\n\nfrom .highlevel import (\n     open,\n     save,\n     from_numpy,\n     empty_like,\n     array_exists\n)\n\n# TODO restricted imports\nfrom .dataframe_ import from_dataframe, from_csv, open_dataframe\n\nfrom .version import version as __version__\n\n# Note: we use a modified namespace packaging to allow continuity of existing TileDB-Py imports.\n#       Therefore, \'tiledb/__init__.py\' must *only* exist in this package.\n#       Furthermore, in sub-packages, the `find_packages` helper will not work at the\n#       root directory due to lack of \'tiledb/__init__.py\'. Sub-package \'setup.py\' scripts\n#       must declare constituents accordingly, such as by running \'find_packages\' on a sub-directory\n#       and applying prefixes accordingly.\n#   1) https://packaging.python.org/guides/packaging-namespace-packages/#native-namespace-packages\n#   2) https://stackoverflow.com/a/53486554\n#\n# Note: \'pip -e\' in particular will not work without this declaration:\n__path__ = __import__(\'pkgutil\').extend_path(__path__, __name__)\n'"
tiledb/array.py,0,"b'from .libtiledb import DenseArrayImpl, SparseArrayImpl\n\n# Extensible (pure Python) array class definitions inheriting from the\n# Cython implemention. The cloudarray mix-in adds optional functionality\n# for registering arrays and executing functions on the\n\n# NOTE: the mixin import must be inside the __new__ initializer because it\n#       needs to be deferred. tiledb.cloud is not yet known to the importer\n#       when this code is imported.\n#       TODO: might be possible to work-around/simplify by using\n#       import meta-hooks instead.\n\nclass DenseArray(DenseArrayImpl):\n    _mixin_init = False\n\n    def __new__(cls, *args, **kwargs):\n        if not cls._mixin_init:\n            # must set before importing, because import is not thread-safe\n            #   https://github.com/TileDB-Inc/TileDB-Py/issues/244\n            cls._mixin_init = True\n            try:\n                from tiledb.cloud import cloudarray\n                DenseArray.__bases__ = DenseArray.__bases__ + (cloudarray.CloudArray,)\n                DenseArray.__doc__ = DenseArrayImpl.__doc__\n            except ImportError:\n                pass\n\n        obj = super(DenseArray, cls).__new__(cls, *args, **kwargs)\n        return obj\n\nclass SparseArray(SparseArrayImpl):\n    _mixin_init = False\n\n    def __new__(cls, *args, **kwargs):\n        if not cls._mixin_init:\n            cls._mixin_init = True\n            try:\n                from tiledb.cloud import cloudarray\n                SparseArray.__bases__ = SparseArray.__bases__ + (cloudarray.CloudArray,)\n                SparseArray.__doc__ = DenseArrayImpl.__doc__\n            except ImportError:\n                pass\n\n        obj = super(SparseArray, cls).__new__(cls, *args, **kwargs)\n        return obj\n'"
tiledb/dataframe_.py,17,"b'import tiledb, numpy as np\nimport json\nimport sys\nimport os\nimport io\nfrom collections import OrderedDict\nimport warnings\n\nif sys.version_info >= (3,3):\n    unicode_type = str\nelse:\n    unicode_type = unicode\nunicode_dtype = np.dtype(unicode_type)\n\n# TODO\n# - handle missing values\n# - handle extended datatypes\n# - implement distributed CSV import\n# - implement support for read CSV via TileDB VFS from any supported FS\n\nTILEDB_KWARG_DEFAULTS = {\n    \'cell_order\': \'row-major\',\n    \'tile_order\': \'row-major\',\n    \'allows_duplicates\': False,\n    \'sparse\': False,\n    \'mode\': \'ingest\',\n    \'attrs_filters\': None,\n    \'coords_filters\': None\n}\n\ndef parse_tiledb_kwargs(kwargs):\n    args = dict(TILEDB_KWARG_DEFAULTS)\n\n    if \'ctx\' in kwargs:\n        args[\'ctx\'] = kwargs.pop(\'ctx\')\n    if \'sparse\' in kwargs:\n        args[\'sparse\'] = kwargs.pop(\'sparse\')\n    if \'index_dims\' in kwargs:\n        args[\'index_dims\'] = kwargs.pop(\'index_dims\')\n    if \'allows_duplicates\' in kwargs:\n        args[\'allows_duplicates\'] = kwargs.pop(\'allows_duplicates\')\n    if \'mode\' in kwargs:\n        args[\'mode\'] = kwargs.pop(\'mode\')\n    if \'attrs_filters\' in kwargs:\n        args[\'attrs_filters\'] = kwargs.pop(\'attrs_filters\')\n    if \'coords_filters\' in kwargs:\n        args[\'coords_filters\'] = kwargs.pop(\'coords_filters\')\n\n    return args\n\nclass ColumnInfo:\n    def __init__(self, dtype, repr=None):\n        self.dtype = dtype\n        self.repr = repr\n\ndef dtype_from_column(col):\n    import pandas as pd\n\n    col_dtype = col.dtype\n    # TODO add more basic types here\n    if col_dtype in (np.int32, np.int64, np.uint32, np.uint64, np.float, np.double,\n                     np.uint8):\n        return ColumnInfo(col_dtype)\n\n    # TODO this seems kind of brittle\n    if col_dtype.base == np.dtype(\'M8[ns]\'):\n        if col_dtype == np.dtype(\'datetime64[ns]\'):\n            return ColumnInfo(col_dtype)\n        elif hasattr(col_dtype, \'tz\'):\n            raise ValueError(""datetime with tz not yet supported"")\n        else:\n            raise ValueError(""unsupported datetime subtype ({})"".format(type(col_dtype)))\n\n    # Pandas 1.0 has StringDtype extension type\n    if col_dtype.name == \'string\':\n        return ColumnInfo(unicode_dtype)\n\n    if col_dtype == \'bool\':\n        return ColumnInfo(np.uint8, repr=np.dtype(\'bool\'))\n\n    if col_dtype == np.dtype(""O""):\n        # Note: this does a full scan of the column... not sure what else to do here\n        #       because Pandas allows mixed string column types (and actually has\n        #       problems w/ allowing non-string types in object columns)\n        inferred_dtype = pd.api.types.infer_dtype(col)\n\n        if inferred_dtype == \'bytes\':\n            return ColumnInfo(np.bytes_)\n\n        elif inferred_dtype == \'string\':\n            # TODO we need to make sure this is actually convertible\n            return ColumnInfo(unicode_dtype)\n\n        elif inferred_dtype == \'mixed\':\n            raise ValueError(\n                ""Column \'{}\' has mixed value dtype and cannot yet be stored as a TileDB attribute""\n            )\n\n    raise ValueError(\n        ""Unhandled column type: \'{}\'"".format(\n            col_dtype\n        )\n    )\n\n# TODO make this a staticmethod on Attr?\ndef attrs_from_df(df, index_dims=None, filters=None, ctx=None):\n    attr_reprs = dict()\n\n    if ctx is None:\n        ctx = tiledb.default_ctx()\n\n    attrs = list()\n    for name, col in df.items():\n        # ignore any column used as a dim/index\n        if index_dims and name in index_dims:\n            continue\n        attr_info = dtype_from_column(col)\n        attrs.append(tiledb.Attr(name=name, dtype=attr_info.dtype, filters=filters))\n\n        if attr_info.repr is not None:\n            attr_reprs[name] = attr_info.repr\n\n    return attrs, attr_reprs\n\ndef dim_for_column(ctx, df, col, col_name):\n    if isinstance(col, np.ndarray):\n        col_values = col\n    else:\n        col_values = col.values\n\n    if len(col_values) < 1:\n        raise ValueError(""Empty column \'{}\' cannot be used for dimension!"".format(col_name))\n\n    dim_info = dtype_from_column(col_values)\n\n    if col_values.dtype is np.dtype(\'O\'):\n        if type(col_values[0]) in (bytes, unicode_type):\n            dim_min, dim_max = (None, None)\n            # TODO... core only supports TILEDB_ASCII right now\n            dim_info = ColumnInfo(np.bytes_)\n        else:\n            raise TypeError(""other unknown column type not yet supported"")\n    else:\n        dim_min = np.min(col_values)\n        dim_max = np.max(col_values)\n\n    dim = tiledb.Dim(\n        name = col_name,\n        domain = (dim_min, dim_max),\n        dtype = dim_info.dtype,\n        tile = 1 # TODO\n    )\n\n    return dim\n\ndef get_index_metadata(dataframe):\n    md = dict()\n    for index in dataframe.index.names:\n        # Note: this may be expensive.\n        md[index] = dtype_from_column(dataframe.index.get_level_values(index)).dtype\n\n    return md\n\ndef write_array_metadata(array, attr_metadata = None, index_metadata = None):\n    """"""\n    :param array: open, writable TileDB array\n    :param metadata: dict\n    :return:\n    """"""\n    if attr_metadata:\n        attr_md_dict = {n: str(t) for n,t in attr_metadata.items()}\n        array.meta[\'__pandas_attribute_repr\'] = json.dumps(attr_md_dict)\n\n    if index_metadata:\n        index_md_dict = {n: str(t) for n,t in index_metadata.items()}\n        array.meta[\'__pandas_index_dims\'] = json.dumps(index_md_dict)\n\ndef create_dims(ctx, dataframe, index_dims):\n    import pandas as pd\n    index = dataframe.index\n    index_dict = OrderedDict()\n\n    if isinstance(index, pd.MultiIndex):\n        for name in index.names:\n            index_dict[name] = dataframe.index.get_level_values(name)\n\n    elif isinstance(index, (pd.Index, pd.RangeIndex, pd.Int64Index)):\n        if hasattr(index, \'name\') and index.name is not None:\n            name = index.name\n        else:\n            name = \'rows\'\n\n        index_dict[name] = index.values\n\n    else:\n        raise ValueError(""Unhandled index type {}"".format(type(index)))\n\n    dims = list(\n        dim_for_column(ctx, dataframe, values, name) for name,values in index_dict.items()\n    )\n\n    if index_dims:\n        for name in index_dims:\n            col = dataframe[name]\n            dims.append(\n                dim_for_column(ctx, dataframe, col.values, name)\n            )\n\n    return dims\n\ndef from_dataframe(uri, dataframe, **kwargs):\n    # deprecated in 0.6.3\n    warnings.warn(""tiledb.from_dataframe is deprecated; please use .from_pandas"",\n                  DeprecationWarning)\n\n    from_pandas(uri, dataframe, **kwargs)\n\ndef from_pandas(uri, dataframe, **kwargs):\n    """"""Create TileDB array at given URI from pandas dataframe\n\n    :param uri: URI for new TileDB array\n    :param dataframe: pandas DataFrame\n    :param mode: Creation mode, one of \'ingest\' (default), \'create_schema\', \'append\'\n    :param kwargs: optional keyword arguments for Pandas and TileDB.\n        TileDB arguments: tile_order, cell_order, allows_duplicates, sparse,\n                          mode, attrs_filters, coords_filters\n    :return:\n    """"""\n    args = parse_tiledb_kwargs(kwargs)\n\n    ctx = args.get(\'ctx\', None)\n    tile_order = args[\'tile_order\']\n    cell_order = args[\'cell_order\']\n    allows_duplicates = args[\'allows_duplicates\']\n    sparse = args[\'sparse\']\n    index_dims = args.get(\'index_dims\', None)\n    mode = args.get(\'mode\', \'ingest\')\n    attrs_filters = args.get(\'attrs_filters\', None)\n    coords_filters = args.get(\'coords_filters\', None)\n\n    write = True\n    create_array = True\n    if mode is not None:\n        if mode == \'schema_only\':\n            write = False\n        elif mode == \'append\':\n            create_array = False\n\n    if ctx is None:\n        ctx = tiledb.default_ctx()\n\n    if create_array:\n        if attrs_filters is None:\n           attrs_filters = tiledb.FilterList(\n                [tiledb.ZstdFilter(1, ctx=ctx)])\n\n        if coords_filters is None:\n            coords_filters = tiledb.FilterList(\n                [tiledb.ZstdFilter(1, ctx=ctx)])\n\n        nrows = len(dataframe)\n        tiling = np.min((nrows % 200, nrows))\n\n        # create the domain and attributes\n        dims = create_dims(ctx, dataframe, index_dims)\n\n        if len(dims) > 1:\n            sparse = True\n        if any([d.dtype in (np.bytes_, np.unicode_) for d in dims]):\n            sparse = True\n        if any([np.issubdtype(d.dtype, np.datetime64) for d in dims]):\n            sparse = True\n\n        domain = tiledb.Domain(\n           *dims,\n           ctx = ctx\n        )\n\n        attrs, attr_metadata = attrs_from_df(dataframe, index_dims=index_dims,\n                                             filters=attrs_filters)\n\n        # now create the ArraySchema\n        schema = tiledb.ArraySchema(\n            domain=domain,\n            attrs=attrs,\n            cell_order=cell_order,\n            tile_order=tile_order,\n            coords_filters=coords_filters,\n            allows_duplicates=allows_duplicates,\n            sparse=sparse\n        )\n\n        tiledb.Array.create(uri, schema, ctx=ctx)\n\n    if write:\n        write_dict = {k: v.values for k,v in dataframe.to_dict(orient=\'series\').items()}\n\n        index_metadata = get_index_metadata(dataframe)\n\n        try:\n            A = tiledb.open(uri, \'w\', ctx=ctx)\n\n            if A.schema.sparse:\n                coords = []\n                for k in range(A.schema.ndim):\n                    coords.append(dataframe.index.get_level_values(k))\n\n                # TODO ensure correct col/dim ordering\n                A[tuple(coords)] = write_dict\n\n            else:\n                A[:] = write_dict\n\n            if create_array:\n                write_array_metadata(A, attr_metadata, index_metadata)\n        finally:\n            A.close()\n\n\ndef open_dataframe(uri):\n    """"""Open TileDB array at given URI as a Pandas dataframe\n\n    If the array was saved using tiledb.from_dataframe, then columns\n    will be interpreted as non-primitive pandas or numpy types when\n    available.\n\n    :param uri:\n    :return: dataframe constructed from given TileDB array URI\n\n    **Example:**\n\n    >>> import tiledb\n    >>> df = tiledb.open_dataframe(""iris.tldb"")\n    >>> tiledb.objec_type(""iris.tldb"")\n    \'array\'\n    """"""\n    warnings.warn(""open_dataframe is deprecated and will be removed in the next release"",\n                  DeprecationWarning)\n\n    import pandas as pd\n\n    # TODO support `distributed=True` option?\n\n    with tiledb.open(uri) as A:\n        #if not \'__pandas_attribute_repr\' in A.meta \\\n        #    and not \'__pandas_repr\' in A.meta:\n        #    raise ValueError(""Missing required keys to reload overloaded dataframe dtypes"")\n\n        # TODO missing key should only be a warning, return best-effort?\n        # TODO this should be generalized for round-tripping overloadable types\n        #      for any array (e.g. np.uint8 <> bool)\n        repr_meta = None\n        index_dims = None\n        if \'__pandas_attribute_repr\' in A.meta:\n            # backwards compatibility... unsure if necessary at this point\n            repr_meta = json.loads(A.meta[\'__pandas_attribute_repr\'])\n        if \'__pandas_index_dims\' in A.meta:\n            index_dims = json.loads(A.meta[\'__pandas_index_dims\'])\n\n        data = A[:]\n        indexes = list()\n\n        for col_name, col_val in data.items():\n            if repr_meta and col_name in repr_meta:\n                new_col = pd.Series(col_val, dtype=repr_meta[col_name])\n                data[col_name] = new_col\n            elif index_dims and col_name in index_dims:\n                new_col = pd.Series(col_val, dtype=index_dims[col_name])\n                data[col_name] = new_col\n                indexes.append(col_name)\n\n    new_df = pd.DataFrame.from_dict(data)\n    if len(indexes) > 0:\n        new_df.set_index(indexes, inplace=True)\n\n    return new_df\n\n\ndef from_csv(uri, csv_file, **kwargs):\n    """"""Create TileDB array at given URI from a CSV file\n\n    :param uri: URI for new TileDB array\n    :param csv_file: input CSV file\n    :param kwargs: optional keyword arguments for Pandas and TileDB.\n                TileDB context and configuration arguments\n                may be passed in a dictionary as `tiledb_args={...}`\n    :return: None\n\n    **Example:**\n\n    >>> import tiledb\n    >>> tiledb.from_csv(""iris.tldb"", ""iris.csv"")\n    >>> tiledb.object_type(""iris.tldb"")\n    \'array\'\n    """"""\n    try:\n        import pandas\n    except ImportError as exc:\n        print(""tiledb.from_csv requires pandas"")\n        raise\n\n    mode = kwargs.pop(\'mode\', None)\n    tiledb_args = parse_tiledb_kwargs(kwargs)\n    if mode is not None:\n        tiledb_args[\'mode\'] = mode\n        # For schema-only mode we need to pass a max read count into\n        #   pandas.read_csv\n        # Note that \'nrows\' is a pandas arg!\n        if mode == \'schema_only\' and not \'nrows\' in kwargs:\n            kwargs[\'nrows\'] = 500\n\n    if isinstance(csv_file, str) and not os.path.isfile(csv_file):\n        # for non-local files, use TileDB VFS i/o\n        ctx = tiledb_args.get(\'ctx\', tiledb.default_ctx())\n        vfs = tiledb.VFS(ctx=ctx)\n        csv_file = tiledb.FileIO(vfs, csv_file, mode=\'rb\')\n\n    df = pandas.read_csv(csv_file, **kwargs)\n\n    kwargs.update(tiledb_args)\n    from_pandas(uri, df, **kwargs)'"
tiledb/highlevel.py,2,"b'import tiledb\nfrom tiledb.libtiledb import *\n\nimport numpy as np\n\ndef open(uri, mode=\'r\', key=None, attr=None, config=None, ctx=None):\n    """"""\n    Open a TileDB array at the given URI\n\n    :param uri: any TileDB supported URI\n    :param key: encryption key, str or None\n    :param str mode: (default \'r\') Open the array object in read \'r\' or write \'w\' mode\n    :param attr: attribute name to select from a multi-attribute array, str or None\n    :param config: TileDB config dictionary, dict or None\n    :return:\n    """"""\n    if ctx and config:\n      raise ValueError(""Received extra Ctx or Config argument: either one may be provided, but not both"")\n\n    if config:\n        cfg = tiledb.Config(config)\n        ctx = tiledb.Ctx(cfg)\n\n    if ctx is None:\n        ctx = default_ctx()\n\n    return tiledb.Array.load_typed(uri, mode, key, None, attr, ctx)\n\ndef save(uri, array, config=None, **kw):\n    """"""\n    Save array-like object at the given URI.\n\n    :param uri: str or None\n    :param array: array-like object convertible to NumPy\n    :param config: TileDB config dictionary, dict or None\n    :param kw: optional keyword args will be forwarded to tiledb.Array constructor\n    :return:\n    """"""\n    if not isinstance(array, np.ndarray):\n        raise ValueError(""expected NumPy ndarray, not \'{}\'"".format(type(array)))\n    if config:\n        cfg = Config(config)\n        ctx = tiledb.Ctx(cfg)\n    else:\n        ctx = default_ctx()\n\n    return tiledb.from_numpy(uri, array, ctx=ctx)\n\n\ndef empty_like(uri, arr, config=None, key=None, tile=None):\n    """"""\n    Create and return an empty, writeable DenseArray with schema based on\n    a NumPy-array like object.\n\n    :param uri:\n    :param arr: NumPy ndarray, or shape tuple\n    :param ctx:\n    :param kw:\n    :return:\n    """"""\n    if config:\n        cfg = tiledb.Config(config)\n        ctx = tiledb.Ctx(cfg)\n    else:\n        ctx = default_ctx()\n\n    if arr is ArraySchema:\n        schema = arr\n    else:\n        schema = schema_like(arr, tile=tile, ctx=ctx)\n\n    tiledb.DenseArray.create(uri, key=key, schema=schema)\n    return tiledb.DenseArray(uri, mode=\'w\', key=key, ctx=ctx)\n\n\ndef from_numpy(uri, array, ctx=None, **kw):\n    """"""\n    Convenience method, see `tiledb.DenseArray.from_numpy`\n    """"""\n    if not ctx:\n        ctx = default_ctx()\n    if not isinstance(array, np.ndarray):\n        raise Exception(""from_numpy is only currently supported for numpy.ndarray"")\n\n    return DenseArray.from_numpy(uri, array, ctx=ctx, **kw)\n\ndef array_exists(uri, isdense=False, issparse=False):\n    """"""\n    Check if arrays exists and is open-able at the given URI\n\n    Optionally restrict to `isdense` or `issparse` array types.\n    """"""\n    try:\n        a = tiledb.open(uri)\n    except TileDBError as exc:\n        return False\n\n    if isdense:\n        rval = not a.schema.sparse\n    elif issparse:\n        rval = a.schema.sparse\n    else:\n        rval = True\n\n    a.close()\n    return rval'"
tiledb/metadata.py,0,"b'from __future__ import absolute_import\n\nimport sys\nimport array as cparray\nfrom tiledb import libtiledb as libmetadata\nfrom tiledb.libtiledb import ustring\n\nclass Metadata(object):\n\n    def __init__(self, array):\n        self.array = array\n\n    def __setitem__(self, key, value):\n        """"""\n        Implementation of [key] <- val (dict item assignment)\n\n        :param key: key to set\n        :param value: corresponding value\n        :return: None\n        """"""\n\n        libmetadata.put_metadata(self.array, key, value)\n\n    def __getitem__(self, key):\n        """"""\n        Implementation of [key] -> val (dict item retrieval)\n        :param key:\n        :return:\n        """"""\n        if not (isinstance(key, str) or isinstance(key, unicode)):\n            raise ValueError(""Unexpected key type \'{}\': expected str ""\n                             ""type"".format(type(key)))\n\n        # `get_metadata` expects unicode\n        key = ustring(key)\n        v = libmetadata.get_metadata(self.array, key)\n\n        if v is None:\n            raise TileDBError(""Failed to unpack value for key: \'{}\'"".format(key))\n\n        return v\n\n    def __contains__(self, key):\n        """"""\n        Returns True if \'key\' is found in metadata store.\n        Provides support for python \'in\' syntax (\'k in A.meta\')\n\n        :param key: Target key to check.\n        :return:\n        """"""\n\n        try:\n            self[key]\n        except KeyError:\n            return False\n\n        return True\n\n    def consolidate(self):\n        """"""\n        Consolidate array metadata. Array must be closed.\n\n        :return:\n        """"""\n\n        # TODO: ensure that the array is not x-locked?\n\n        libmetadata.consolidate_metadata(self.array)\n\n    def __delitem__(self, key):\n        """"""\n        Remove key from metadata.\n\n        **Example:**\n\n        >>> # given A = tiledb.open(uri, ...)\n        >>> del A.meta[\'key\']\n\n        :param key:\n        :return:\n        """"""\n\n        libmetadata.del_metadata(self.array, key)\n\n    def __len__(self):\n        """"""\n        :return: length of metadata store\n        """"""\n\n        return libmetadata.len_metadata(self.array)\n\n    def keys(self):\n        """"""\n        Return metadata keys as list.\n\n        :return: List of array metadata keys.\n        """"""\n\n        return libmetadata.load_metadata(self.array, unpack=False)\n\n    def values(self):\n        # TODO this should be an iterator\n\n        data = libmetadata.load_metadata(self.array, unpack=True)\n        return data.values()\n\n    def pop(self, key, default=None):\n        raise NotImplementedError(""dict.pop requires read-write access to array"")\n\n    def items(self):\n        # TODO this should be an iterator\n        data = libmetadata.load_metadata(self.array, unpack=True)\n        return tuple( (k, data[k]) for k in data.keys() )\n\n    def _set_numpy(self, key, value):\n        """"""\n        Test helper: directly set meta key-value from a NumPy array.\n        Key type and array dimensionality are checked, but no other type-checking\n        is done.\n\n        :param key: key\n        :param arr: 1d NumPy ndarray\n        :return:\n        """"""\n\n        libmetadata._set_metadata_numpy(self.array, key, value)'"
tiledb/multirange_indexing.py,5,"b'import tiledb\nfrom tiledb import Array, ArraySchema, TileDBError\nimport os, numpy as np\nimport sys, weakref\nfrom collections import OrderedDict\n\ndef mr_dense_result_shape(ranges, base_shape = None):\n    # assumptions: len(ranges) matches number of dims\n    if base_shape is not None:\n        assert len(ranges) == len(base_shape), ""internal error: mismatched shapes""\n\n    new_shape = list()\n    for i,rr in enumerate(ranges):\n        if rr != ():\n            m = list(map(lambda y: abs(y[1] - y[0]) + 1, rr))\n            new_shape.append(np.sum(m))\n        else:\n            if base_shape is None:\n                raise ValueError(""Missing required base_shape for whole-dimension slices"")\n            # empty range covers dimension\n            new_shape.append(base_shape[i])\n\n    return tuple(new_shape)\n\ndef mr_dense_result_numel(ranges):\n    return np.prod(mr_dense_result_shape(ranges))\n\ndef sel_to_subranges(dim_sel):\n    subranges = list()\n    for range in dim_sel:\n        if np.isscalar(range):\n            subranges.append( (range, range) )\n        elif isinstance(range, slice):\n            if range.step is not None:\n                raise ValueError(""Stepped slice ranges are not supported"")\n            elif range.start is None and range.stop is None:\n                # \':\' full slice\n                pass\n            else:\n                subranges.append( (range.start, range.stop) )\n        elif isinstance(range, tuple):\n            subranges.extend((range,))\n        elif isinstance(range, list):\n            for el in range:\n                subranges.append( (el, el) )\n        else:\n            raise TypeError(""Unsupported selection "")\n\n    return tuple(subranges)\n\n\nclass MultiRangeIndexer(object):\n    """"""\n    Implements multi-range / outer / orthogonal indexing.\n\n    """"""\n\n    def __init__(self, array, query = None):\n        if not issubclass(type(array), tiledb.Array):\n            raise ValueError(""Internal error: MultiRangeIndexer expected tiledb.Array"")\n        self.array_ref = weakref.ref(array)\n        self.schema = array.schema\n        self.query = query\n\n    @property\n    def array(self):\n        assert self.array_ref() is not None, \\\n            ""Internal error: invariant violation (indexing call w/ dead array_ref)""\n        return self.array_ref()\n\n    @classmethod\n    def __test_init__(cls, array):\n        """"""\n        Internal helper method for testing getitem range calculation.\n        :param array:\n        :return:\n        """"""\n        m = cls.__new__(cls)\n        m.array_ref = weakref.ref(array)\n        m.schema = array.schema\n        m.query = None\n        return m\n\n    def getitem_ranges(self, idx):\n        dom = self.schema.domain\n        ndim = dom.ndim\n\n        if isinstance(idx, tuple):\n            idx = list(idx)\n        else:\n            idx = [idx]\n\n        ranges = list()\n        for i,sel in enumerate(idx):\n            if not isinstance(sel, list):\n                sel = [sel]\n            subranges = sel_to_subranges(sel)\n            ranges.append(subranges)\n\n        # extend the list to ndim\n        if len(ranges) < ndim:\n            ranges.extend([ tuple() for _ in range(ndim-len(ranges))])\n\n        rval = tuple(ranges)\n        return rval\n\n    def __getitem__(self, idx):\n        # implements multi-range / outer / orthogonal indexing\n        ranges = self.getitem_ranges(idx)\n\n        schema = self.schema\n        dom = self.schema.domain\n        attr_names = tuple(self.schema.attr(i).name for i in range(self.schema.nattr))\n\n        coords = None\n        if self.query is not None:\n            # if we are called via Query object, then we need to respect Query semantics\n            attr_names = tuple(self.query.attrs) if self.query.attrs else attr_names # query.attrs might be None -> all\n            coords = self.query.coords\n\n        from tiledb.core import PyQuery\n        q = PyQuery(self.array._ctx_(), self.array, attr_names, coords)\n\n        q.set_ranges(ranges)\n        q.submit()\n\n        result_dict = OrderedDict(q.results())\n\n        final_names = dict()\n        for name, item in result_dict.items():\n            if len(item[1]) > 0:\n                arr = q.unpack_buffer(name, item[0], item[1])\n            else:\n                arr = item[0]\n                final_dtype = schema.attr_or_dim_dtype(name)\n                if (len(arr) < 1 and\n                        (np.issubdtype(final_dtype, np.str_) or\n                         np.issubdtype(final_dtype, np.unicode_))):\n                    # special handling to get correctly-typed empty array\n                    # (expression below changes itemsize from 0 to 1)\n                    arr.dtype = final_dtype.str + \'1\'\n                else:\n                    arr.dtype = schema.attr_or_dim_dtype(name)\n            if name == \'__attr\':\n                final_names[name] = \'\'\n            result_dict[name] = arr\n\n        for name, replacement in final_names.items():\n            result_dict[replacement] = result_dict.pop(name)\n\n        if self.schema.sparse:\n            return result_dict\n        else:\n            result_shape = mr_dense_result_shape(ranges, self.schema.shape)\n            for arr in result_dict.values():\n                # TODO check/test layout\n                arr.shape = result_shape\n            return result_dict\n'"
doc/source/conf.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n\n# -- Imports configuration -------------------------------------------------\n\nimport os\nimport sys\nfrom os.path import abspath, join, dirname\n\nsys.path.insert(0, abspath(join(dirname(__file__))))\n\n# -- ReadTheDocs configuration ---------------------------------------------\n\n# Special handling on ReadTheDocs builds.\n# Some of this code is from https://github.com/robotpy/robotpy-docs/blob/master/conf.py\nreadthedocs = os.environ.get(\'READTHEDOCS\', None) == \'True\'\nrtd_version = os.environ.get(\'READTHEDOCS_VERSION\', \'latest\')\nrtd_version = rtd_version if rtd_version in [\'stable\', \'latest\'] else \'stable\'\n\n# -- Project information -----------------------------------------------------\n\nproject = \'TileDB-Py\'\ncopyright = \'2019, TileDB, Inc.\'\nauthor = \'TileDB, Inc.\'\n\n# The short X.Y version\nversion = \'0.6\'\n# The full version, including alpha/beta/rc tags\nrelease = \'0.6.2\'\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.doctest\',\n    \'sphinx.ext.intersphinx\',\n]\n\n# Mapping for linking between RTD subprojects.\nif readthedocs:\n    intersphinx_mapping = {\n        \'tiledb\': (\'https://tiledb-inc-tiledb.readthedocs-hosted.com/en/%s/\' % rtd_version, None),\n        \'tiledb-py\': (\'https://tiledb-inc-tiledb.readthedocs-hosted.com/projects/python-api/en/%s/\' % rtd_version, None),\n        \'python\': (\'https://docs.python.org/\', None)\n    }\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path .\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'friendly\'\n\n\n# -- Options for HTML output -------------------------------------------------\n\nhtml_static_path = [\'_static\']\nhtml_logo = \'_static/tileDB_uppercase_600_112.png\'\nhtml_favicon = \'_static/favicon.ico\'\n\nif readthedocs:\n    html_theme = \'default\'\nelse:\n    import sphinx_rtd_theme\n    html_theme = \'sphinx_rtd_theme\'\n    html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'TileDB-Pydoc\'\n\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'TileDB-Py.tex\', \'TileDB-Py Documentation\',\n     \'TileDB, Inc.\', \'manual\'),\n]\n\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'tiledb-py\', \'TileDB-Py Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'TileDB-Py\', \'TileDB-Py Documentation\',\n     author, \'TileDB-Py\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n# -- Custom Document processing ----------------------------------------------\n\n# Generate the sidebar automatically so that it is identical across all subprojects.\n# This (and gensidebar.py) from https://github.com/robotpy/robotpy-docs\nimport gensidebar\ngensidebar.generate_sidebar({\'on_rtd\': readthedocs, \'rtd_version\': rtd_version}, \'tiledb-py\')\n\n# -- Custom setup -----------------------------------------------------------\n\ndef setup(app):\n    app.add_stylesheet(\'custom.css\')\n'"
doc/source/gensidebar.py,0,"b""#\n# This file generates the sidebar/toctree for all TileDB projects and should\n# be copied to each project when it is updated.\n#\n# This file is originally from the RobotPy documentation project\n# https://github.com/robotpy/robotpy-docs, licensed under Apache v2.\n#\n\nimport os\n\ndef write_if_changed(fname, contents):\n\n    try:\n        with open(fname, 'r') as fp:\n            old_contents = fp.read()\n    except:\n        old_contents = ''\n\n    if old_contents != contents:\n        with open(fname, 'w') as fp:\n            fp.write(contents)\n\ndef generate_sidebar(conf, conf_api):\n\n    version = conf['rtd_version']\n\n    lines = [\n        '', '.. DO NOT MODIFY! THIS PAGE IS AUTOGENERATED!',\n        '   To edit the sidebar, modify gensidebar.py and re-build the docs.', ''\n    ]\n\n    url_base = 'https://tiledb-inc-tiledb.readthedocs-hosted.com'\n    lang = 'en'\n\n    def toctree(name):\n        lines.extend(['.. toctree::',\n                      '    :caption: %s' % name,\n                      '    :maxdepth: 1',\n                      ''])\n\n    def endl():\n        lines.append('')\n\n    def write(desc, link):\n        if conf_api == 'tiledb':\n            args = desc, link\n        else:\n            args = desc, '%s/%s/%s/%s.html' % (url_base, lang, version, link)\n\n        lines.append('    %s <%s>' % args)\n\n    def write_api(project, desc, rst_page):\n        # From non-root project to root project link\n        if project == 'tiledb' and conf_api != 'tiledb':\n            args = desc, url_base, lang, version, rst_page\n            lines.append('    %s API <%s/%s/%s/%s.html>' % args)\n        # From anything to non-root project link\n        elif project != conf_api:\n            args = desc, url_base, project, lang, version, rst_page\n            lines.append('    %s API <%s/projects/%s/%s/%s/%s.html>' % args)\n        # Local project link\n        else:\n            args = desc, rst_page\n            lines.append('    %s API <%s>' % args)\n\n    def write_api_url(desc, url):\n        lines.append('    %s API <%s>' % (desc, url))\n\n    #\n    # Specify the sidebar contents here\n    #\n\n    toctree('API Reference')\n    write_api('tiledb', 'C', 'c-api')\n    write_api('tiledb', 'C++', 'c++-api')\n    write_api('tiledb-py', 'Python', 'python-api')\n    write_api_url('R', 'https://tiledb-inc.github.io/TileDB-R/reference/index.html')\n    write_api_url('Java', 'https://www.javadoc.io/doc/io.tiledb/tiledb-java')\n    write_api_url('Go', 'https://godoc.org/github.com/TileDB-Inc/TileDB-Go')\n    endl()\n\n    write_if_changed('_sidebar.rst.inc', '\\n'.join(lines))\n"""
tiledb/tests/__init__.py,0,"b'""""""\nUnit tests for TileDB\n=====================\n\nThis package contains modules which provide a ``suite()`` function\nwhich returns a test suite for tiledb functionality\n""""""\n\nfrom tiledb.tests.all import suite\n\n'"
tiledb/tests/all.py,0,"b'""""""\nRun all test casess\n""""""\n\nimport os\nimport sys\nimport unittest\n\n\ndef suite():\n    test_dir = os.path.dirname(__file__)\n    return unittest.TestLoader().discover(\n        start_dir=test_dir, pattern=""test_*.py""\n    )\n\n\ndef suite_test():\n    """"""\n    suite_test()\n\n    Run all the tests in the test suite\n    """"""\n\n    ret = unittest.TextTestRunner(verbosity=2).run(suite())\n    sys.exit(not ret.wasSuccessful())\n\n\nif __name__ == \'__main__\':\n    unittest.TextTestRunner().run(suite())\n'"
tiledb/tests/check_csv_dir.py,0,"b'# This is a helper function to run tests on an external\n# directory, for example the contents of the Pandas\n# CSV tests:\n#   https://github.com/pandas-dev/pandas/tree/master/pandas/tests/io/data/csv\n# It takes one argument, the test directory, and checks that all\n# .csv files contained within are correctly round-tripped via\n# `tiledb.from_csv` and `tiledb.open_dataframe`\n\nimport tiledb\nimport os\nimport sys\nimport tempfile\nimport pandas as pd\nimport pandas._testing as tm\nfrom glob import glob\n\n\ndef check_csv_roundtrip(input_csv):\n    basename = os.path.basename(input_csv)\n    tmp = tempfile.mktemp(prefix=""csvtest-""+basename)\n    os.mkdir(tmp)\n\n    array_uri = os.path.join(tmp, ""tiledb_from_csv"")\n    tiledb.from_csv(array_uri, input_csv)\n\n    df_csv = pd.read_csv(input_csv)\n    df_back = tiledb.open_dataframe(array_uri)\n\n    tm.assert_frame_equal(df_csv, df_back)\n    return True\n\n\ndef check_csv_dir(path):\n    files = glob(os.path.join(path, ""*.csv""))\n    res = [check_csv_roundtrip(f) for f in files]\n\n    assert len(res) == len(files), ""Failed to check all files!""\n\nif __name__ == \'__main__\':\n    if len(sys.argv) != 2:\n        print(""expected one argument: path to CSV directory"")\n\n    check_csv_dir(sys.argv[1])\n'"
tiledb/tests/common.py,28,"b'from __future__ import absolute_import\n\nimport glob\nimport os\nimport sys\nimport random\nimport shutil\nimport tempfile\nimport datetime\nimport traceback\nfrom unittest import TestCase\n\nimport numpy as np\nfrom numpy.testing import assert_equal, assert_array_equal\n\n\nclass DiskTestCase(TestCase):\n    pathmap = dict()\n\n    def setUp(self):\n        prefix = \'tiledb-\' + self.__class__.__name__\n        self.rootdir = tempfile.mkdtemp(prefix=prefix)\n\n    def tearDown(self):\n        # Remove every directory starting with rootdir\n        for dirpath in glob.glob(self.rootdir + ""*""):\n            try:\n                shutil.rmtree(dirpath)\n            except OSError as exc:\n                print(""test \'{}\' error deleting \'{}\'"".format(self.__class__.__name__,\n                                                             dirpath))\n                print(""registered paths and originating functions:"")\n                for path,frame in self.pathmap.items():\n                    print(""  \'{}\' <- \'{}\'"".format(path,frame))\n                raise exc\n\n    def path(self, path):\n        out = os.path.abspath(os.path.join(self.rootdir, path))\n        frame = traceback.extract_stack(limit=2)[-2][2]\n        self.pathmap[out] = frame\n        return out\n\n\ndef assert_subarrays_equal(a, b):\n    assert_equal(a.shape, b.shape)\n\n    for a_el, b_el in zip(a.flat, b.flat):\n        assert_array_equal(a_el, b_el)\n\ndef assert_all_arrays_equal(*arrays):\n    # TODO this should display raise in the calling location if possible\n    assert len(arrays) % 2 == 0, \\\n           ""Expected even number of arrays""\n\n    for a1,a2 in zip(arrays[0::2], arrays[1::2]):\n        assert_array_equal(a1, a2)\n\n# python 2 vs 3 compatibility\nif sys.hexversion >= 0x3000000:\n    getchr = chr\nelse:\n    getchr = unichr\n\ndef gen_chr(max, printable=False):\n    while True:\n        # TODO we exclude 0x0 here because the key API does not embedded NULL\n        s = getchr(random.randrange(1, max))\n        if printable and not s.isprintable():\n            continue\n        if len(s) > 0:\n            break\n    return s\n\ndef rand_utf8(size=5):\n    return u\'\'.join([gen_chr(0xD7FF) for _ in range(0, size)])\n\ndef rand_ascii(size=5, printable=False):\n    return u\'\'.join([gen_chr(127, printable) for _ in range(0,size)])\n\ndef rand_ascii_bytes(size=5, printable=False):\n    return b\'\'.join([gen_chr(127, printable).encode(\'utf-8\') for _ in range(0,size)])\n\ndef dtype_max(dtype):\n    if not np.issubdtype(dtype, np.generic):\n        raise TypeError(""expected numpy dtype!"")\n\n    if np.issubdtype(dtype, np.floating):\n        finfo = np.finfo(dtype)\n        return finfo.max\n\n    elif np.issubdtype(dtype, np.integer):\n        iinfo = np.iinfo(dtype)\n        return int(iinfo.max)\n\n    elif np.issubdtype(dtype, np.datetime64):\n        return np.datetime64(datetime.datetime.max)\n\n    raise ""Unknown dtype for dtype_max \'{}\'"".format(str(dtype))\n\ndef dtype_min(dtype):\n    if not np.issubdtype(dtype, np.generic):\n        raise TypeError(""expected numpy dtype!"")\n\n    if np.issubdtype(dtype, np.floating):\n        finfo = np.finfo(dtype)\n        return finfo.min\n\n    elif np.issubdtype(dtype, np.integer):\n        iinfo = np.iinfo(dtype)\n        return int(iinfo.min)\n\n    elif np.issubdtype(dtype, np.datetime64):\n        return np.datetime64(datetime.datetime.min)\n\n    raise ""Unknown dtype for dtype_min \'{dtype}\'"".format(str(dtype))\n\ndef rand_int_sequential(size, dtype=np.uint64):\n    arr = np.random.randint(\n        dtype_min(dtype), high=dtype_max(dtype), size=size, dtype=dtype\n    )\n    return np.sort(arr)\n\ndef rand_datetime64_array(size, start=None, stop=None, dtype=None):\n    if not dtype:\n        dtype = np.dtype(\'M8[ns]\')\n\n    # generate randint inbounds on the range of M8[ns]\n    # (TODO this will give weird results for ps/fs/as scale but those are uncommon)\n    if start is None:\n        start = np.datetime64(\'1678-01-01\')\n    else:\n        start = np.datetime64(start)\n    if stop is None:\n        stop = np.datetime64(\'2202-01-01\')\n    else:\n        stop = np.datetime64(stop)\n\n    arr = np.random.randint(\n        start.astype(dtype).astype(np.int64), stop.astype(dtype).astype(np.int64),\n        size=size, dtype=np.int64\n    )\n    arr.sort()\n\n    return arr.astype(dtype)\n\ndef intspace(start, stop, num=50, dtype=np.int64):\n    """"""\n    Return evenly spaced values over range ensuring that stop is\n    always the maximum (will not overflow with int dtype as linspace)\n    :param start:\n    :param stop:\n    :param num:\n    :param dtype:\n    :return:\n    """"""\n    rval = np.zeros(num, dtype=dtype)\n    step = (stop-start) // num\n    nextval = start\n\n    if np.issubdtype(dtype, np.integer) and step < 1:\n      raise ValueError(""Cannot use non-integral step value \'{}\' for integer dtype!"".format(\n                      step))\n\n    for i in range(num):\n        rval[i] = nextval\n        nextval += step\n\n    rval[-1] = stop\n    return rval\n'"
tiledb/tests/test_core.py,3,"b'import unittest, os\n\nimport tiledb\nfrom tiledb import TileDBError, core\nfrom tiledb.tests.common import DiskTestCase\nimport sys\nimport numpy as np\nfrom numpy.testing import assert_array_equal\n\nclass CoreCCTest(DiskTestCase):\n\n    def test_pyquery_basic(self):\n        ctx = tiledb.default_ctx()\n        uri = self.path(""test_pyquery_basic"")\n        with tiledb.from_numpy(uri, np.random.rand(4)) as A:\n            pass\n\n        with tiledb.open(uri) as a:\n            q = core.PyQuery(ctx, a, ("""",), False)\n\n            try:\n                q.test_err(""bad foo happened"")\n            except Exception as exc:\n                assert isinstance(exc, tiledb.TileDBError)\n                assert exc.message == ""bad foo happened""\n\n            q.set_ranges([[(0, 3)]])\n\n            with self.assertRaises(TileDBError):\n                q.set_ranges([[(0, 3.0)]])\n\n            q.set_ranges([[(0, np.int32(3))]])\n\n            with self.assertRaises(TileDBError):\n                q.set_ranges([[(3, ""a"")]])\n\n            if sys.hexversion >= 0x3000000:\n                # assertRaisesRegex is not available in 2.7\n                with self.assertRaisesRegex(\n                    TileDBError,\n                    ""Failed to cast dim range \'\\\\(1.2344, 5.6789\\\\)\' to dim type UINT64.*$"",\n                ):\n                    q.set_ranges([[(1.2344, 5.6789)]])\n\n                with self.assertRaisesRegex(\n                    TileDBError,\n                    ""Failed to cast dim range \'\\\\(\'aa\', \'bbbb\'\\\\)\' to dim type UINT64.*$"",\n                ):\n                    q.set_ranges([[(""aa"", ""bbbb"")]])\n\n        with tiledb.open(uri) as a:\n            q2 = core.PyQuery(ctx, a, ("""",), False)\n\n            q2.set_ranges([[(0,3)]])\n            q2.submit()\n            res = q2.results()[\'\'][0]\n            res.dtype = np.double\n            assert_array_equal(res, a[:])\n'"
tiledb/tests/test_dask.py,18,"b'try:\n    import dask, dask.array as da\n    import_failed = False\nexcept ImportError:\n    import_failed = True\n\nimport unittest\n\nimport tiledb\nfrom tiledb.tests.common import DiskTestCase\n\nimport numpy as np\nfrom numpy.testing import assert_array_equal, assert_approx_equal\n\n\nclass DaskSupport(DiskTestCase):\n    def setUp(self):\n        if import_failed:\n            self.skipTest(""Dask not available"")\n        else:\n            super().setUp()\n\n    def test_dask_from_numpy_1d(self):\n        uri = self.path(""np_1attr"")\n        A = np.random.randn(50,50)\n        T = tiledb.from_numpy(uri, A, tile=50)\n        T.close()\n\n        with tiledb.open(uri) as T:\n            D = da.from_tiledb(T)\n            assert_array_equal(D, A)\n\n        D2 = da.from_tiledb(uri)\n        assert_array_equal(D2, A)\n        self.assertAlmostEqual(np.mean(A), D2.mean().compute(scheduler=\'single-threaded\'))\n\n    def _make_multiattr_2d(self, uri, shape=(0,100), tile=10):\n        dom = tiledb.Domain(\n                tiledb.Dim(""x"", (0,10), dtype=np.uint64, tile=tile),\n                tiledb.Dim(""y"", (0,50), dtype=np.uint64, tile=tile))\n        schema = tiledb.ArraySchema(\n                    attrs=(tiledb.Attr(""attr1""),\n                           tiledb.Attr(""attr2"")),\n                    domain=dom)\n\n        tiledb.DenseArray.create(uri, schema)\n\n    def test_dask_multiattr_2d(self):\n        uri = self.path(""multiattr"")\n\n        self._make_multiattr_2d(uri)\n\n        with tiledb.DenseArray(uri, \'w\') as T:\n            ar1 = np.random.randn(*T.schema.shape)\n            ar2 = np.random.randn(*T.schema.shape)\n            T[:] = {\'attr1\': ar1,\n                    \'attr2\': ar2}\n        with tiledb.DenseArray(uri, mode=\'r\', attr=\'attr2\') as T:\n            # basic round-trip from dask.array\n            D = da.from_tiledb(T, attribute=\'attr2\')\n            assert_array_equal(ar2, np.array(D))\n\n        # smoke-test computation\n        # note: re-init from_tiledb each time, or else dask just uses the cached materialization\n        D = da.from_tiledb(uri, attribute=\'attr2\')\n        self.assertAlmostEqual(np.mean(ar2), D.mean().compute(scheduler=\'threads\'))\n        D = da.from_tiledb(uri, attribute=\'attr2\')\n        self.assertAlmostEqual(np.mean(ar2), D.mean().compute(scheduler=\'single-threaded\'))\n        D = da.from_tiledb(uri, attribute=\'attr2\')\n        self.assertAlmostEqual(np.mean(ar2), D.mean().compute(scheduler=\'processes\'))\n\n        # test dask.distributed\n        from dask.distributed import Client\n        D = da.from_tiledb(uri, attribute=\'attr2\')\n        with Client() as client:\n            assert_approx_equal(D.mean().compute(), np.mean(ar2))\n\n    def test_dask_write(self):\n        uri = self.path(""dask_w"")\n        D = da.random.random(10,10)\n        D.to_tiledb(uri)\n        DT = da.from_tiledb(uri)\n        assert_array_equal(D, DT)\n\n    def test_dask_overlap_blocks(self):\n        uri = self.path(""np_overlap_blocks"")\n        A = np.ones((2, 50, 50))\n        T = tiledb.from_numpy(uri, A, tile=(1, 5, 5))\n        T.close()\n\n        with tiledb.open(uri) as T:\n            D = da.from_tiledb(T)\n            assert_array_equal(D, A)\n\n        D2 = da.from_tiledb(uri)\n        assert_array_equal(D2, A)\n\n        D3 = D2.map_overlap(\n                lambda x: x + 1, depth={0: 0, 1: 1, 2: 1},\n                dtype=A.dtype\n                ).compute()\n        assert_array_equal(D2 * 2, D3)\n\n    def test_labeled_dask_overlap_blocks(self):\n        uri = self.path(""np_labeled_overlap_blocks"")\n        A = np.ones((2, 50, 50))\n\n        dom = tiledb.Domain(\n                tiledb.Dim(name=""BANDS"", domain=(0, 1), tile=1),\n                tiledb.Dim(name=""Y"", domain=(0, 49),\n                        tile=5, dtype=np.uint64),\n                tiledb.Dim(name=""X"", domain=(0, 49),\n                        tile=5, dtype=np.uint64))\n\n        schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                    attrs=[tiledb.Attr(name=""TDB_VALUES"",\n                                        dtype=A.dtype)])\n\n        tiledb.DenseArray.create(uri, schema)\n\n        with tiledb.open(uri, \'w\', attr=""TDB_VALUES"") as T:\n            T[:] = A\n\n        D2 = da.from_tiledb(uri, attribute=""TDB_VALUES"")\n\n        D3 = D2.map_overlap(\n                lambda x: x + 1, depth={0: 0, 1: 1, 2: 1},\n                dtype=D2.dtype\n                ).compute()\n        assert_array_equal(D2 + 1, D3)\n\n    def test_labeled_dask_blocks(self):\n        uri = self.path(""np_labeled_map_blocks"")\n        A = np.ones((2, 50, 50))\n\n        dom = tiledb.Domain(\n                tiledb.Dim(name=""BANDS"", domain=(0, 1), tile=1),\n                tiledb.Dim(name=""Y"", domain=(0, 49),\n                        tile=5, dtype=np.uint64),\n                tiledb.Dim(name=""X"", domain=(0, 49),\n                        tile=5, dtype=np.uint64))\n\n        schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                    attrs=[tiledb.Attr(name=""TDB_VALUES"",\n                                        dtype=A.dtype)])\n\n        tiledb.DenseArray.create(uri, schema)\n        with tiledb.open(uri, \'w\', attr=\'TDB_VALUES\') as D1:\n            D1[:] = A\n\n        D2 = da.from_tiledb(uri, attribute=""TDB_VALUES"")\n\n        D3 = D2.map_blocks(\n                lambda x: x + 1,\n                dtype=D2.dtype\n                ).compute(scheduler=\'processes\')\n        assert_array_equal(D2 + 1, D3)\n'"
tiledb/tests/test_domain_index.py,24,"b'#%%\n\nimport numpy as np\nimport tiledb\n\nfrom tiledb.tests.common import *\n\nclass DomainIndexingSparseTest(DiskTestCase):\n\n    def test_int_domain_indexing(self):\n        path = self.path(""int_domain_indexing"")\n\n        dom = tiledb.Domain(tiledb.Dim(name=""x"", domain=(-10,10), tile=1, dtype=np.int64))\n        schema = tiledb.ArraySchema(domain=dom, sparse=True,\n                                    attrs=[tiledb.Attr(name=""a"", dtype=np.float64)])\n\n        tiledb.SparseArray.create(path, schema)\n\n        X = np.arange(-10,11,step=1)\n        val = np.random.rand(len(X))\n\n        with tiledb.SparseArray(path, mode=\'w\') as A:\n            A[X] = val\n\n        with tiledb.SparseArray(path) as A:\n            assert_array_equal(A.domain_index[ X[0]][\'a\'], val[0])\n            assert_array_equal(A.domain_index[ X[-1]][\'a\'], val[-1])\n            assert_array_equal(A.domain_index[ X[0]:X[-1] ][\'a\'], val[:])\n            # sanity check\n            assert_array_equal(A.domain_index[ X[0]:X[-1] ][\'x\'], X[:])\n\n    def test_fp_domain_indexing(self):\n        array_path = self.path(""test_domain_idx"")\n\n\n        # test case from https://github.com/TileDB-Inc/TileDB-Py/issues/201\n        tile = 1\n        dom = tiledb.Domain(tiledb.Dim(name=""x"", domain=(-89.75, 89.75), tile=tile, dtype=np.float64),\n                            tiledb.Dim(name=""y"", domain=(-179.75, 179.75), tile=tile, dtype=np.float64),\n                            tiledb.Dim(name=""z"", domain=(157498, 157863), tile=tile, dtype=np.float64)\n                            )\n        schema = tiledb.ArraySchema(domain=dom, sparse=True,\n                                    attrs=[tiledb.Attr(name=""data"", dtype=np.float64)])\n\n        tiledb.SparseArray.create(array_path, schema)\n\n        # fake data\n        X = np.linspace(-89.75, 89.75, 359)\n        Y = np.linspace(-179.75, 179.75, 359)\n        Z = np.linspace(157498, 157857, 359)\n\n        #data = np.random.rand(*map(lambda x: x[0], (X.shape, Y.shape, Z.shape)))\n        data = np.random.rand(X.shape[0])\n\n        with tiledb.SparseArray(array_path, mode=\'w\') as A:\n            A[X, Y, Z] = data\n\n        with tiledb.SparseArray(array_path) as A:\n\n            # check direct slicing\n            assert_array_equal(\n                A.domain_index[ X[0], Y[0], Z[0] ][\'data\'],\n                data[0])\n\n            # check small slice ranges\n            tmp = A.domain_index[\n                X[0] : np.nextafter(X[0], 0), Y[0] : np.nextafter(Y[0], 0), Z[0] : np.nextafter(Z[0], Z[0] + 1)\n                ]\n            assert_array_equal(\n                tmp[\'data\'],\n                data[0]\n            )\n\n            # check slicing last element\n            tmp = A.domain_index[ X[-1], Y[-1], Z[-1] ]\n            assert_array_equal(\n                tmp[\'data\'],\n                data[ -1 ]\n            )\n\n            # check slice range multiple components\n            tmp = A.domain_index[ X[1]:X[2], Y[1]:Y[2], Z[1]:Z[2] ]\n            assert_array_equal(\n                tmp[\'data\'],\n                data[1:3]\n            )\n\n            # check an interior point\n            coords = X[145], Y[145], Z[145]\n            tmp = A.domain_index[coords]\n            assert_array_equal(\n                tmp[\'x\'],\n                X[145]\n            )\n            assert_array_equal(\n                tmp[\'data\'],\n                data[145]\n            )\n\n            # check entire domain\n            tmp = A.domain_index[X[0]:X[-1], Y[0]:Y[-1], Z[0]:Z[-1]]\n            assert_array_equal(\n                tmp[\'data\'],\n                data[:]\n            )\n\n            # check entire domain\n            # TODO uncomment if vectorized indexing is available\n            #coords = np.array([X,Y,Z]).transpose().flatten()\n            #tmp = A.domain_index[X,Y,Z]\n            #assert_array_equal(\n            #    tmp[\'data\'],\n            #    data[:]\n            #)\n\n    def test_fp_domain_count(self):\n        array_path = self.path(""test_domain_count"")\n        tile = 1\n\n        dom = tiledb.Domain(tiledb.Dim(name=""x"", domain=(0.0, 2.0), tile=tile, dtype=np.float64),\n                            tiledb.Dim(name=""y"", domain=(0.0, 2.0), tile=tile, dtype=np.float64),\n                            )\n        schema = tiledb.ArraySchema(domain=dom, sparse=True,\n                                    attrs=[tiledb.Attr(name=""data"", dtype=np.float64)])\n\n        tiledb.SparseArray.create(array_path, schema)\n\n        # fake data\n        X = [1.0]\n        Y = [1.0]\n        data = [1.0]\n\n        with tiledb.SparseArray(array_path, mode=\'w\') as A:\n            A[X, Y] = data\n\n        with tiledb.SparseArray(array_path) as A:\n            # check direct slicing\n            assert_array_equal(\n                A.domain_index[ X[0], Y[0] ][\'data\'],\n                data[0])\n\n            # check counting by slice\n            assert_equal(A.domain_index[0:2.0, 0:1.0][\'x\'].shape[0], 1)\n            assert_equal(A.domain_index[0:2.0, 0:1.0][\'y\'].shape[0], 1)\n            assert_equal(A.domain_index[0:2.0, np.nextafter(1.0, 2.0)][\'x\'].shape[0], 0)\n            assert_equal(A.domain_index[0:2.0, np.nextafter(1.0, 2.0)][\'y\'].shape[0], 0)\n\nclass DomainIndexingDenseTest(DiskTestCase):\n\n    def test_int_domain_indexing(self):\n        path = self.path(""dense_int_domain_indexing"")\n\n        dom = tiledb.Domain(tiledb.Dim(name=""x"", domain=(0,10), tile=1, dtype=np.int64))\n        schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                    attrs=[tiledb.Attr(name=""a"", dtype=np.float64)])\n\n        tiledb.DenseArray.create(path, schema)\n\n        X = np.arange(0,11,step=1)\n        val = np.random.rand(len(X))\n\n        with tiledb.DenseArray(path, mode=\'w\') as A:\n            A[:] = val\n\n        with tiledb.DenseArray(path) as A:\n            assert_array_equal(A.domain_index[ X[0]][\'a\'], val[0])\n            assert_array_equal(A.domain_index[ X[-1]][\'a\'], val[-1])\n            assert_array_equal(A.domain_index[ X[0]:X[-1] ][\'a\'], val[:])\n            # sanity check\n            assert_array_equal(A.domain_index[ X[0]:X[-1] ][\'x\'], X[:])\n\n'"
tiledb/tests/test_examples.py,0,"b'import os, sys, glob, unittest, tempfile, shutil, platform\nimport subprocess\n\ndef run_checked(args):\n  tmp = tempfile.mkdtemp()\n  cmd = [sys.executable] + args\n  proc = subprocess.Popen(cmd, cwd=tmp, stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n  out, err = proc.communicate()\n  status = proc.returncode\n\n  if status != 0:\n    print(""Call failed: {}"".format(args))\n    print(""--- stdout:"")\n    print(out.decode())\n    print(""--- stderr:"")\n    print(err.decode())\n    sys.exit(1)\n\n  shutil.rmtree(tmp)\n\nclass ExamplesTest(unittest.TestCase):\n\n  @unittest.skipIf(\'TRAVIS\' in os.environ, ""Don\'t run examples/ unittests on travis"")\n  def test_examples(self):\n    examples_path = os.path.abspath(os.path.join(os.path.split(__file__)[0], ""../../examples""))\n    for ex in glob.glob(examples_path+""/*.py""):\n      args = [ex]\n      run_checked(args)\n\n  # some of the doctests are missing a clean-up step on windows\n  @unittest.skipIf(platform.system() == \'Windows\', """")\n  def test_docs(self):\n    if sys.version_info >= (3,6):\n      doctest_args = [\'-m\', \'doctest\', \'-o\', \'NORMALIZE_WHITESPACE\', \'-f\',\n                      os.path.abspath(os.path.join(__file__, \'../../\', \'libtiledb.pyx\'))]\n      run_checked(doctest_args)\n\n'"
tiledb/tests/test_libtiledb.py,249,"b'# -*- coding: utf-8 -*-\n\nfrom __future__ import absolute_import\n\nimport sys, os, io, re, platform, unittest, random\n\nimport numpy as np\nfrom numpy.testing import assert_array_equal\n\nimport tiledb\nfrom tiledb.tests.common import DiskTestCase, assert_subarrays_equal, rand_utf8, rand_ascii, rand_ascii_bytes\n\ndef safe_dump(obj):\n    # TODO this doesn\'t actually redirect the C level stdout used by libtiledb dump\n    #      functions...\n    try:\n        import io\n        from contextlib import redirect_stdout\n        with io.StringIO() as buf, redirect_stdout(buf):\n            obj.dump()\n    except ImportError:\n        obj.dump()\n    except Exception as exc:\n        print(""Exception occurred calling \'obj.dump()\' with redirect."", exc,\n              ""\\nTrying \'obj.dump()\' alone."")\n        obj.dump()\n\nclass VersionTest(unittest.TestCase):\n\n    def test_version(self):\n        v = tiledb.libtiledb.version()\n        self.assertIsInstance(v, tuple)\n        self.assertTrue(len(v) == 3)\n        self.assertTrue(v[0] >= 1, ""TileDB major version must be >= 1"")\n\n\nclass StatsTest(unittest.TestCase):\n\n    def test_stats(self):\n        tiledb.libtiledb.stats_enable()\n        tiledb.libtiledb.stats_reset()\n        tiledb.libtiledb.stats_disable()\n\n\nclass Config(DiskTestCase):\n\n    def test_config(self):\n        config = tiledb.Config()\n        config[""sm.tile_cache_size""] = 100\n        assert(repr(config) is not None)\n        ctx = tiledb.Ctx(config)\n\n    def test_ctx_config(self):\n        ctx = tiledb.Ctx({""sm.tile_cache_size"": 100})\n        config = ctx.config()\n        self.assertEqual(config[""sm.tile_cache_size""], ""100"")\n\n    def test_vfs_config(self):\n        config = tiledb.Config()\n        config[""vfs.min_parallel_size""] = 1\n        ctx = tiledb.Ctx()\n        self.assertEqual(ctx.config()[""vfs.min_parallel_size""], ""10485760"")\n        vfs = tiledb.VFS(config, ctx=ctx)\n        self.assertEqual(vfs.config()[""vfs.min_parallel_size""], ""1"")\n\n    def test_config_iter(self):\n        config = tiledb.Config()\n        k, v = [], []\n        for p in config.items():\n            k.append(p[0])\n            v.append(p[1])\n        self.assertTrue(len(k) > 0)\n\n        k, v = [], []\n        for p in config.items(""vfs.s3.""):\n            k.append(p[0])\n            v.append(p[1])\n        self.assertTrue(len(k) > 0)\n\n    def test_config_bad_param(self):\n        config = tiledb.Config()\n        config[""sm.foo""] = ""bar""\n        ctx = tiledb.Ctx(config)\n        self.assertEqual(ctx.config()[""sm.foo""], ""bar"")\n\n    def test_config_unset(self):\n        config = tiledb.Config()\n        config[""sm.tile_cach_size""] = 100\n        del config[""sm.tile_cache_size""]\n        # check that config parameter is default\n        self.assertEqual(config[""sm.tile_cache_size""], tiledb.Config()[""sm.tile_cache_size""])\n\n    def test_config_from_file(self):\n        config_path = self.path(""config"")\n        with open(config_path, ""w"") as fh:\n            fh.write(""sm.tile_cache_size 100"")\n        config = tiledb.Config.load(config_path)\n        self.assertEqual(config[""sm.tile_cache_size""], ""100"")\n\n    def test_ctx_config_from_file(self):\n        config_path = self.path(""config"")\n        with open(config_path, ""w"") as fh:\n            fh.write(""sm.tile_cache_size 100"")\n        ctx = tiledb.Ctx(config=tiledb.Config.load(config_path))\n        config = ctx.config()\n        self.assertEqual(config[""sm.tile_cache_size""], ""100"")\n\n    def test_ctx_config_dict(self):\n        ctx = tiledb.Ctx(config={""sm.tile_cache_size"": \'100\'})\n        config = ctx.config()\n        self.assertIsInstance(config, tiledb.Config)\n        self.assertEqual(config[""sm.tile_cache_size""], \'100\')\n\n\nclass GroupTestCase(DiskTestCase):\n\n    def setUp(self):\n        super(GroupTestCase, self).setUp()\n\n        ctx = tiledb.Ctx()\n        self.group1 = self.path(""group1"")\n        self.group2 = self.path(""group1/group2"")\n        self.group3 = self.path(""group1/group3"")\n        self.group4 = self.path(""group1/group3/group4"")\n\n        tiledb.group_create(self.group1, ctx=ctx)\n        tiledb.group_create(self.group2, ctx=ctx)\n        tiledb.group_create(self.group3, ctx=ctx)\n        tiledb.group_create(self.group4, ctx=ctx)\n\n    def is_group(self, ctx, uri):\n        return tiledb.object_type(uri, ctx=ctx) == ""group""\n\n\nclass GroupTest(GroupTestCase):\n\n    def test_is_group(self):\n        ctx = tiledb.Ctx()\n        self.assertTrue((ctx, self.group1))\n        self.assertTrue(self.is_group(ctx, self.group2))\n        self.assertTrue(self.is_group(ctx, self.group3))\n        self.assertTrue(self.is_group(ctx, self.group4))\n\n    def test_walk_group(self):\n        ctx = tiledb.Ctx()\n\n        groups = []\n        def append_to_groups(path, obj):\n            groups.append((os.path.normpath(path), obj))\n\n        tiledb.walk(self.path(""""), append_to_groups, order=""preorder"", ctx=ctx)\n\n        groups.sort()\n\n        self.assertTrue(groups[0][0].endswith(self.group1) and groups[0][1] == ""group"")\n        self.assertTrue(groups[1][0].endswith(self.group2) and groups[1][1] == ""group"")\n        self.assertTrue(groups[2][0].endswith(self.group3) and groups[2][1] == ""group"")\n        self.assertTrue(groups[3][0].endswith(self.group4) and groups[3][1] == ""group"")\n\n        groups = []\n\n        tiledb.walk(self.path(""""), append_to_groups, order=""postorder"", ctx=ctx)\n\n        self.assertTrue(groups[0][0].endswith(self.group2) and groups[0][1] == ""group"")\n        self.assertTrue(groups[1][0].endswith(self.group4) and groups[1][1] == ""group"")\n        self.assertTrue(groups[2][0].endswith(self.group3) and groups[2][1] == ""group"")\n        self.assertTrue(groups[3][0].endswith(self.group1) and groups[3][1] == ""group"")\n\n    def test_remove_group(self):\n        ctx = tiledb.Ctx()\n\n        tiledb.remove(self.group3, ctx=ctx)\n\n        self.assertFalse(self.is_group(ctx, self.group3))\n        self.assertFalse(self.is_group(ctx, self.group4))\n\n    def test_move_group(self):\n        ctx = tiledb.Ctx()\n\n        self.assertTrue(self.is_group(ctx, self.group2))\n        tiledb.move(self.group2, self.group2 + ""_moved"", ctx=ctx)\n        self.assertFalse(self.is_group(ctx, self.group2))\n        self.assertTrue(self.is_group(ctx, self.group2 + ""_moved""))\n\n\nclass DimensionTest(unittest.TestCase):\n\n    def test_minimal_dimension(self):\n        ctx = tiledb.Ctx()\n        dim = tiledb.Dim(domain=(0, 4), tile=5, ctx=ctx)\n        self.assertEqual(dim.name, ""__dim_0"", ""automatic dimension name is incorrect"")\n        self.assertEqual(dim.shape, (5,))\n        self.assertEqual(dim.tile, 5)\n\n    def test_dimension(self):\n        ctx = tiledb.Ctx()\n        dim = tiledb.Dim(name=""d1"", ctx=ctx, domain=(0, 3), tile=2)\n        self.assertEqual(dim.name, ""d1"")\n        self.assertEqual(dim.shape, (4,))\n        self.assertEqual(dim.tile, 2)\n\n    def test_datetime_dimension(self):\n        ctx = tiledb.Ctx()\n\n        # Regular usage\n        dim = tiledb.Dim(name=""d1"", ctx=ctx, domain=(np.datetime64(\'2010-01-01\'), np.datetime64(\'2020-01-01\')),\n                         tile=np.timedelta64(20, \'D\'), dtype=np.datetime64(\'\', \'D\'))\n        self.assertEqual(dim.dtype, np.dtype(np.datetime64(\'\', \'D\')))\n        self.assertEqual(dim.tile, np.timedelta64(20, \'D\'))\n        self.assertNotEqual(dim.tile, np.timedelta64(21, \'D\'))\n        self.assertNotEqual(dim.tile, np.timedelta64(20, \'W\')) # Sanity check unit\n        self.assertTupleEqual(dim.domain, (np.datetime64(\'2010-01-01\'), np.datetime64(\'2020-01-01\')))\n\n        # No tile extent specified\n        with self.assertRaises(tiledb.TileDBError):\n            tiledb.Dim(name=""d1"", ctx=ctx, domain=(np.datetime64(\'2010-01-01\'), np.datetime64(\'2020-01-01\')),\n                       dtype=np.datetime64(\'\', \'D\'))\n\n        # Integer tile extent is ok\n        dim = tiledb.Dim(name=""d1"", ctx=ctx, domain=(np.datetime64(\'2010-01-01\'), np.datetime64(\'2020-01-01\')),\n                         tile=20, dtype=np.datetime64(\'\', \'D\'))\n        self.assertEqual(dim.dtype, np.dtype(np.datetime64(\'\', \'D\')))\n        self.assertEqual(dim.tile, np.timedelta64(20, \'D\'))\n\n        # Year resolution\n        dim = tiledb.Dim(name=""d1"", ctx=ctx, domain=(np.datetime64(\'2010\'), np.datetime64(\'2020\')),\n                         tile=5, dtype=np.datetime64(\'\', \'Y\'))\n        self.assertEqual(dim.dtype, np.dtype(np.datetime64(\'\', \'Y\')))\n        self.assertEqual(dim.tile, np.timedelta64(5, \'Y\'))\n        self.assertTupleEqual(dim.domain, (np.datetime64(\'2010\', \'Y\'), np.datetime64(\'2020\', \'Y\')))\n\n        # End domain promoted to day resolution\n        dim = tiledb.Dim(name=""d1"", ctx=ctx, domain=(np.datetime64(\'2010-01-01\'), np.datetime64(\'2020\')),\n                         tile=2, dtype=np.datetime64(\'\', \'D\'))\n        self.assertEqual(dim.tile, np.timedelta64(2, \'D\'))\n        self.assertTupleEqual(dim.domain, (np.datetime64(\'2010-01-01\', \'D\'), np.datetime64(\'2020-01-01\', \'D\')))\n\n        # Domain values can\'t be integral\n        with self.assertRaises(TypeError):\n            dim = tiledb.Dim(name=""d1"", ctx=ctx, domain=(-10, 10), tile=2, dtype=np.datetime64(\'\', \'D\'))\n\n\nclass DomainTest(unittest.TestCase):\n\n    def test_domain(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n            tiledb.Dim(""d1"", (1, 4), 2, dtype=\'u8\'),\n            tiledb.Dim(""d2"", (1, 4), 2, dtype=\'u8\'))\n        safe_dump(dom)\n        self.assertEqual(dom.ndim, 2)\n        self.assertEqual(dom.dtype, np.dtype(""uint64""))\n        self.assertEqual(dom.shape, (4, 4))\n\n        # check that we can iterate over the dimensions\n        dim_names = [dim.name for dim in dom]\n        self.assertEqual([""d1"", ""d2""], dim_names)\n\n        # check that we can access dim by name\n        dim_d1 = dom.dim(""d1"")\n        self.assertEqual(dim_d1, dom.dim(0))\n\n    def test_datetime_domain(self):\n        ctx = tiledb.Ctx()\n        dim = tiledb.Dim(name=""d1"", ctx=ctx, domain=(np.datetime64(\'2010-01-01\'), np.datetime64(\'2020-01-01\')),\n                         tile=np.timedelta64(20, \'D\'), dtype=np.datetime64(\'\', \'D\'))\n        dom = tiledb.Domain(dim)\n        self.assertEqual(dom.dtype, np.datetime64(\'\', \'D\'))\n\n    def test_domain_mixed_names_error(self):\n        ctx = tiledb.Ctx()\n        with self.assertRaises(tiledb.TileDBError):\n            tiledb.Domain(\n                tiledb.Dim(""d1"", (1, 4), 2, dtype=\'u8\'),\n                tiledb.Dim(""__dim_0"", (1, 4), 2, dtype=\'u8\'))\n\nclass AttributeTest(unittest.TestCase):\n\n    def test_minimal_attribute(self):\n        ctx = tiledb.Ctx()\n        attr = tiledb.Attr(ctx=ctx)\n        self.assertTrue(attr.isanon)\n        self.assertEqual(attr.name, u"""")\n        self.assertEqual(attr.dtype, np.float_)\n        #self.assertEqual(attr.compressor, (None, -1))\n\n    def test_attribute(self):\n        ctx = tiledb.Ctx()\n        attr = tiledb.Attr(""foo"", ctx=ctx)\n        safe_dump(attr)\n        self.assertEqual(attr.name, ""foo"")\n        self.assertEqual(attr.dtype, np.float64,\n                         ""default attribute type is float64"")\n        #compressor, level = attr.compressor\n        #self.assertEqual(compressor, None, ""default to no compression"")\n        #self.assertEqual(level, -1, ""default compression level when none is specified"")\n\n    def test_full_attribute(self):\n        ctx = tiledb.Ctx()\n        filter_list = tiledb.FilterList([tiledb.ZstdFilter(10, ctx=ctx)], ctx=ctx)\n        attr = tiledb.Attr(""foo"", dtype=np.int64, filters=filter_list, ctx=ctx)\n        #attr = tiledb.Attr(ctx, ""foo"", dtype=np.int64, compressor=(""zstd"", 10))\n        filter_list = tiledb.FilterList([tiledb.ZstdFilter(10, ctx=ctx)], ctx=ctx)\n        attr = tiledb.Attr(""foo"", ctx=ctx, dtype=np.int64, filters=filter_list)\n        safe_dump(attr)\n        self.assertEqual(attr.name, ""foo"")\n        self.assertEqual(attr.dtype, np.int64)\n\n        # <todo>\n        #compressor, level = attr.compressor\n        #self.assertEqual(compressor, ""zstd"")\n        #self.assertEqual(level, 10)\n\n    def test_ncell_attribute(self):\n        ctx = tiledb.Ctx()\n        dtype = np.dtype([("""", np.int32), ("""", np.int32), ("""", np.int32)])\n        attr = tiledb.Attr(""foo"", ctx=ctx, dtype=dtype)\n\n        self.assertEqual(attr.dtype, dtype)\n        self.assertEqual(attr.ncells, 3)\n\n        # dtype subarrays not supported\n        with self.assertRaises(TypeError):\n            tiledb.Attr(""foo"", ctx=ctx, dtype=np.dtype((np.int32, 2)))\n\n        # mixed type record arrays not supported\n        with self.assertRaises(TypeError):\n            tiledb.Attr(""foo"", ctx=ctx, dtype=np.dtype([("""", np.float32), ("""", np.int32)]))\n\n    def test_ncell_bytes_attribute(self):\n        ctx = tiledb.Ctx()\n        dtype = np.dtype((np.bytes_, 10))\n        attr = tiledb.Attr(""foo"", ctx=ctx, dtype=dtype)\n\n        self.assertEqual(attr.dtype, dtype)\n        self.assertEqual(attr.ncells, 10)\n\n    def test_vararg_attribute(self):\n        ctx = tiledb.Ctx()\n        attr = tiledb.Attr(""foo"", ctx=ctx, dtype=np.bytes_)\n        self.assertEqual(attr.dtype, np.dtype(np.bytes_))\n        self.assertTrue(attr.isvar)\n\n    def test_datetime_attribute(self):\n        ctx = tiledb.Ctx()\n        attr = tiledb.Attr(""foo"", ctx=ctx, dtype=np.datetime64(\'\', \'D\'))\n        self.assertEqual(attr.dtype, np.dtype(np.datetime64(\'\', \'D\')))\n        self.assertNotEqual(attr.dtype, np.dtype(np.datetime64))\n        self.assertNotEqual(attr.dtype, np.dtype(np.datetime64(\'\', \'Y\')))\n\n    def test_filter(self):\n        ctx = tiledb.Ctx()\n        gzip_filter = tiledb.libtiledb.GzipFilter(ctx=ctx, level=10)\n        self.assertIsInstance(gzip_filter, tiledb.libtiledb.Filter)\n        self.assertEqual(gzip_filter.level, 10)\n\n        bw_filter = tiledb.libtiledb.BitWidthReductionFilter(ctx=ctx, window=10)\n        self.assertIsInstance(bw_filter, tiledb.libtiledb.Filter)\n        self.assertEqual(bw_filter.window, 10)\n\n        filter_list = tiledb.libtiledb.FilterList([gzip_filter, bw_filter], chunksize=1024, ctx=ctx)\n        self.assertEqual(filter_list.chunksize, 1024)\n        self.assertEqual(len(filter_list), 2)\n        self.assertEqual(filter_list[0].level, gzip_filter.level)\n        self.assertEqual(filter_list[1].window, bw_filter.window)\n\n        # test filter list iteration\n        self.assertEqual(len(list(filter_list)), 2)\n\n        # test `filters` kwarg accepts python list of filters\n        tiledb.Attr(""foo"", ctx=ctx, dtype=np.int64, filters=[gzip_filter])\n        tiledb.Attr(""foo"", ctx=ctx, dtype=np.int64, filters=(gzip_filter,))\n\n        attr = tiledb.Attr(""foo"",\n                           ctx=ctx,\n                           dtype=np.int64,\n                           filters=filter_list)\n\n        self.assertEqual(len(attr.filters), 2)\n        self.assertEqual(attr.filters.chunksize, filter_list.chunksize)\n\n    def test_filter_list(self):\n        ctx = tiledb.Ctx()\n        # should be constructible without a `filters` keyword arg set\n        filter_list1 = tiledb.FilterList(ctx=ctx)\n        filter_list1.append(tiledb.GzipFilter(ctx=ctx))\n        self.assertEqual(len(filter_list1), 1)\n\n        filter_list2 = [x for x in filter_list1]\n        attr = tiledb.Attr(filters=filter_list2)\n        self.assertEqual(len(attr.filters), 1)\n\n\nclass ArraySchemaTest(unittest.TestCase):\n\n    def test_unique_attributes(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n            tiledb.Dim(""d1"", (1, 4), 2, dtype=\'u8\', ctx=ctx),\n            tiledb.Dim(""d2"", (1, 4), 2, dtype=\'u8\', ctx=ctx),\n            ctx=ctx)\n\n        attr1 = tiledb.Attr(""foo"", ctx=ctx, dtype=float)\n        attr2 = tiledb.Attr(""foo"", ctx=ctx, dtype=int)\n\n        with self.assertRaises(tiledb.TileDBError):\n            tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(attr1, attr2))\n\n    def test_dense_array_schema(self):\n        ctx = tiledb.Ctx()\n        domain = tiledb.Domain(\n            tiledb.Dim(domain=(1, 8), tile=2, ctx=ctx),\n            tiledb.Dim(domain=(1, 8), tile=2, ctx=ctx))\n        a1 = tiledb.Attr(""val"", ctx=ctx, dtype=\'f8\')\n        schema = tiledb.ArraySchema(ctx=ctx, domain=domain, attrs=(a1,))\n        self.assertFalse(schema.sparse)\n        self.assertEqual(schema.cell_order, ""row-major"")\n        self.assertEqual(schema.tile_order, ""row-major"")\n        self.assertEqual(schema.domain, domain)\n        self.assertEqual(schema.ndim, 2)\n        self.assertEqual(schema.shape, (8, 8))\n        self.assertEqual(schema.nattr, 1)\n        self.assertEqual(schema.domain.homogeneous, True)\n        self.assertEqual(schema.attr(0), a1)\n        self.assertTrue(schema.has_attr(""val""))\n        self.assertFalse(schema.has_attr(""nononoattr""))\n        self.assertEqual(schema,\n            tiledb.ArraySchema(ctx=ctx, domain=domain, attrs=(a1,)))\n        self.assertNotEqual(schema,\n            tiledb.ArraySchema(domain=domain, attrs=(a1,), sparse=True, ctx=ctx))\n        with self.assertRaises(tiledb.TileDBError):\n            schema.allows_duplicates\n        # test iteration over attributes\n        self.assertEqual(list(schema), [a1])\n\n    def test_dense_array_schema_fp_domain_error(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n            tiledb.Dim(ctx=ctx, domain=(1, 8), tile=2, dtype=np.float64), ctx=ctx)\n        att = tiledb.Attr(""val"", ctx=ctx, dtype=np.float64)\n\n        with self.assertRaises(tiledb.TileDBError):\n            tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,))\n\n    def test_sparse_schema(self):\n        ctx = tiledb.Ctx()\n\n        # create dimensions\n        d1 = tiledb.Dim(""d1"", domain=(1, 1000), tile=10, dtype=""uint64"", ctx=ctx)\n        d2 = tiledb.Dim(""d2"", domain=(101, 10000), tile=100, dtype=""uint64"", ctx=ctx)\n\n        # create domain\n        domain = tiledb.Domain(d1, d2, ctx=ctx)\n\n        # create attributes\n        a1 = tiledb.Attr(""a1"", dtype=""int32,int32,int32"", ctx=ctx)\n        a2 = tiledb.Attr(""a2"",\n                         filters=tiledb.FilterList([tiledb.GzipFilter(-1, ctx=ctx)], ctx=ctx),\n                         dtype=""float32"", ctx=ctx)\n\n        # create sparse array with schema\n        coords_filters = tiledb.FilterList([tiledb.ZstdFilter(4, ctx=ctx)], ctx=ctx)\n        offsets_filters = tiledb.FilterList([tiledb.LZ4Filter(5, ctx=ctx)], ctx=ctx)\n\n        schema = tiledb.ArraySchema(domain=domain,\n                                    attrs=(a1, a2),\n                                    capacity=10,\n                                    cell_order=\'col-major\',\n                                    tile_order=\'row-major\',\n                                    allows_duplicates=True,\n                                    sparse=True,\n                                    coords_filters=coords_filters,\n                                    offsets_filters=offsets_filters,\n                                    ctx=ctx)\n\n        safe_dump(schema)\n        self.assertTrue(schema.sparse)\n        self.assertEqual(schema.capacity, 10)\n        self.assertEqual(schema.cell_order, ""col-major"")\n        self.assertEqual(schema.tile_order, ""row-major"")\n\n        # <todo>\n        #self.assertEqual(schema.coords_compressor, (\'zstd\', 4))\n        #self.assertEqual(schema.offsets_compressor, (\'lz4\', 5))\n\n        self.assertEqual(schema.domain, domain)\n        self.assertEqual(schema.ndim, 2)\n        self.assertEqual(schema.shape, (1000, 9900))\n        self.assertEqual(schema.nattr, 2)\n        self.assertEqual(schema.attr(0), a1)\n        self.assertEqual(schema.attr(""a2""), a2)\n        self.assertEqual(schema.allows_duplicates, True)\n        self.assertEqual(schema,\n                         tiledb.ArraySchema(\n                                    domain=domain,\n                                    attrs=(a1, a2),\n                                    capacity=10,\n                                    cell_order=\'col-major\',\n                                    tile_order=\'row-major\',\n                                    allows_duplicates=True,\n                                    sparse=True,\n                                    coords_filters=coords_filters,\n                                    offsets_filters=offsets_filters,\n                                    ctx=ctx))\n\n        # test iteration over attributes\n        self.assertEqual(list(schema), [a1, a2])\n\n    def test_sparse_schema_filter_list(self):\n        ctx = tiledb.Ctx()\n\n        # create dimensions\n        d1 = tiledb.Dim(""d1"", domain=(1, 1000), tile=10, dtype=""uint64"", ctx=ctx)\n        d2 = tiledb.Dim(""d2"", domain=(101, 10000), tile=100, dtype=""uint64"", ctx=ctx)\n\n        # create domain\n        domain = tiledb.Domain(d1, d2, ctx=ctx)\n\n        # create attributes\n        a1 = tiledb.Attr(""a1"", dtype=""int32,int32,int32"", ctx=ctx)\n        #a2 = tiledb.Attr(ctx, ""a2"", compressor=(""gzip"", -1), dtype=""float32"")\n        filter_list = tiledb.FilterList([tiledb.GzipFilter(ctx=ctx)], ctx=ctx)\n        a2 = tiledb.Attr(""a2"", filters=filter_list, dtype=""float32"", ctx=ctx)\n\n        off_filters_pylist = [tiledb.libtiledb.ZstdFilter(level=10,ctx=ctx)]\n        off_filters = tiledb.libtiledb.FilterList(\n                        filters=off_filters_pylist,\n                        chunksize=2048,\n                        ctx=ctx)\n\n        coords_filters_pylist = [tiledb.libtiledb.Bzip2Filter(level=5, ctx=ctx)]\n        coords_filters = tiledb.libtiledb.FilterList(\n                        filters=coords_filters_pylist,\n                        chunksize=4096, ctx=ctx)\n\n        # create sparse array with schema\n        schema = tiledb.ArraySchema(domain=domain,\n                                    attrs=(a1, a2),\n                                    capacity=10,\n                                    cell_order=\'col-major\',\n                                    tile_order=\'row-major\',\n                                    coords_filters=coords_filters,\n                                    offsets_filters=off_filters,\n                                    sparse=True,\n                                    ctx=ctx)\n        safe_dump(schema)\n        self.assertTrue(schema.sparse)\n\n        # make sure we can construct ArraySchema with python lists of filters\n        schema2 = tiledb.ArraySchema(domain=domain,\n                                    attrs=(a1, a2),\n                                    capacity=10,\n                                    cell_order=\'col-major\',\n                                    tile_order=\'row-major\',\n                                    coords_filters=coords_filters_pylist,\n                                    offsets_filters=off_filters,\n                                    sparse=True,\n                                    ctx=ctx)\n        self.assertEqual(len(schema2.coords_filters), 1)\n        self.assertEqual(len(schema2.offsets_filters), 1)\n\n    def test_mixed_string_schema(self):\n        ctx = tiledb.Ctx()\n        dims = [\n            tiledb.Dim(name=""dpos"", ctx=ctx, domain=(-100.0, 100.0), tile=10, dtype=np.float64),\n            tiledb.Dim(name=""str_index"", domain=(None,None), tile=None, dtype=np.bytes_)\n        ]\n        dom = tiledb.Domain(*dims)\n        attrs = [\n            tiledb.Attr(name=""val"", dtype=np.float64, ctx=ctx)\n        ]\n\n        schema = tiledb.ArraySchema(domain=dom, attrs=attrs, sparse=True, ctx=ctx)\n\n        self.assertTrue(schema.domain.has_dim(""str_index""))\n        self.assertFalse(schema.domain.has_dim(""nonono_str_index""))\n        self.assertTrue(schema.domain.dim(""str_index"").isvar)\n        self.assertFalse(schema.domain.dim(""dpos"").isvar)\n        self.assertEqual(schema.domain.dim(""dpos"").dtype, np.double)\n        self.assertEqual(schema.domain.dim(""str_index"").dtype, np.bytes_)\n        self.assertFalse(schema.domain.homogeneous)\n\nclass ArrayTest(DiskTestCase):\n\n    def create_array_schema(self, ctx):\n        domain = tiledb.Domain(\n            tiledb.Dim(domain=(1, 8), tile=2, ctx=ctx),\n            tiledb.Dim(domain=(1, 8), tile=2, ctx=ctx),\n            ctx=ctx)\n        a1 = tiledb.Attr(""val"", dtype=\'f8\', ctx=ctx)\n        return tiledb.ArraySchema(domain=domain, attrs=(a1,), ctx=ctx)\n\n    def test_array_create(self):\n        config = tiledb.Config()\n        config[""sm.consolidation.step_min_frag""] = 0\n        config[""sm.consolidation.steps""] = 1\n        ctx = tiledb.Ctx(config=config)\n        schema = self.create_array_schema(ctx)\n\n        # persist array schema\n        tiledb.libtiledb.Array.create(self.path(""foo""), schema)\n\n        # these should be no-ops\n        #   full signature\n        tiledb.consolidate(self.path(""foo""), config=config, ctx=ctx)\n        #   kw signature\n        tiledb.consolidate(uri=self.path(""foo""), ctx=ctx)\n\n        # load array in readonly mode\n        array = tiledb.libtiledb.Array(self.path(""foo""), mode=\'r\', ctx=ctx)\n        self.assertTrue(array.isopen)\n        self.assertEqual(array.schema, schema)\n        self.assertEqual(array.mode, \'r\')\n        self.assertEqual(array.uri, self.path(""foo""))\n\n        # test that we cannot consolidate an array in readonly mode\n        with self.assertRaises(tiledb.TileDBError):\n            array.consolidate()\n\n        # we have not written anything, so the array is empty\n        self.assertIsNone(array.nonempty_domain())\n\n        array.reopen()\n        self.assertTrue(array.isopen)\n\n        array.close()\n        self.assertEqual(array.isopen, False)\n\n        with self.assertRaises(tiledb.TileDBError):\n            # cannot get schema from closed array\n            array.schema\n\n        with self.assertRaises(tiledb.TileDBError):\n            # cannot re-open a closed array\n            array.reopen()\n\n    def test_array_create_with_ctx(self):\n        config = tiledb.Config()\n        config[""sm.consolidation.step_min_frag""] = 0\n        config[""sm.consolidation.steps""] = 1\n        ctx = tiledb.Ctx(config=config)\n        schema = self.create_array_schema(ctx)\n\n        with self.assertRaises(TypeError):\n            tiledb.libtiledb.Array.create(self.path(""foo""), schema, ctx=""foo"")\n\n        # persist array schema\n        tiledb.libtiledb.Array.create(self.path(""foo""), schema, ctx=tiledb.Ctx())\n\n    def test_array_create_encrypted(self):\n        config = tiledb.Config()\n        config[""sm.consolidation.step_min_frags""] = 0\n        config[""sm.consolidation.steps""] = 1\n        ctx = tiledb.Ctx(config=config)\n        schema = self.create_array_schema(ctx)\n        # persist array schema\n        tiledb.libtiledb.Array.create(self.path(""foo""), schema,\n                                      key=b""0123456789abcdeF0123456789abcdeF"")\n\n        # check that we can open the array sucessfully\n        for key in (b""0123456789abcdeF0123456789abcdeF"", ""0123456789abcdeF0123456789abcdeF""):\n            with tiledb.libtiledb.Array(self.path(""foo""), ctx=ctx, mode=\'r\', key=key) as array:\n                self.assertTrue(array.isopen)\n                self.assertEqual(array.schema, schema)\n                self.assertEqual(array.mode, \'r\')\n            tiledb.consolidate(uri=self.path(""foo""), config=config, key=key, ctx=ctx)\n\n        # check that opening the array with the wrong key fails:\n        with self.assertRaises(tiledb.TileDBError):\n            tiledb.libtiledb.Array(self.path(""foo""), ctx=ctx, mode=\'r\',\n                                   key=b""0123456789abcdeF0123456789abcdeX"")\n\n        # check that opening the array with the wrong key length fails:\n        with self.assertRaises(tiledb.TileDBError):\n            tiledb.libtiledb.Array(self.path(""foo""), ctx=ctx, mode=\'r\',\n                                   key=b""0123456789abcdeF0123456789abcde"")\n\n        # check that consolidating the array with the wrong key fails:\n        with self.assertRaises(tiledb.TileDBError):\n            tiledb.consolidate(self.path(""foo""), config,\n                               key=b""0123456789abcdeF0123456789abcde"", ctx=ctx)\n\n    def test_array_doesnt_exist(self):\n        ctx = tiledb.Ctx()\n        with self.assertRaises(tiledb.TileDBError):\n            tiledb.libtiledb.Array(self.path(""foo""), mode=\'r\', ctx=ctx)\n\n    def test_create_schema_matches(self):\n        ctx = tiledb.Ctx()\n        dims = (tiledb.Dim(ctx=ctx, domain=(0, 6), tile=2),)\n        dom = tiledb.Domain(*dims, ctx=ctx)\n        att = tiledb.Attr(ctx=ctx, dtype=np.byte)\n\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,), sparse=True)\n        uri = self.path(\'s1\')\n        with self.assertRaises(ValueError):\n            tiledb.DenseArray.create(uri, schema)\n\n        dense_schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,))\n        uri = self.path(\'d1\')\n        with self.assertRaises(ValueError):\n            tiledb.SparseArray.create(uri, dense_schema)\n\n        class MySparseArray(tiledb.SparseArray):\n            pass\n\n        with self.assertRaises(ValueError):\n            MySparseArray.create(uri, dense_schema)\n\nclass DenseArrayTest(DiskTestCase):\n\n    def test_array_1d(self):\n        A = np.arange(1050)\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, 1049), tile=100, dtype=np.int64, ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(ctx=ctx, dtype=A.dtype)\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,))\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            self.assertEqual(len(A), len(T))\n            self.assertEqual(A.ndim, T.ndim)\n            self.assertEqual(A.shape, T.shape)\n\n            self.assertEqual(1, T.nattr)\n            self.assertEqual(A.dtype, T.attr(0).dtype)\n            self.assertEqual(T.dim(T.schema.domain.dim(0).name), T.dim(0))\n            with self.assertRaises(ValueError): T.dim(1.0)\n\n            self.assertIsInstance(T.timestamp, int)\n            self.assertTrue(T.timestamp > 0)\n\n            # check empty array\n            B = T[:]\n\n            self.assertEqual(A.shape, B.shape)\n            self.assertEqual(A.dtype, B.dtype)\n            self.assertIsNone(T.nonempty_domain())\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            # check set array\n            T[:] = A\n\n        read1_timestamp = -1\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            self.assertEqual(((0, 1049),), T.nonempty_domain())\n\n            # check timestamp\n            read1_timestamp = T.timestamp\n            self.assertTrue(read1_timestamp > 0)\n\n            # check slicing\n            assert_array_equal(A, np.array(T))\n            assert_array_equal(A, T[:])\n            assert_array_equal(A, T[...])\n            assert_array_equal(A, T[slice(None)])\n            assert_array_equal(A[:10], T[:10])\n            assert_array_equal(A[10:20], T[10:20])\n            assert_array_equal(A[-10:], T[-10:])\n\n            # ellipsis\n            assert_array_equal(A[:10, ...], T[:10, ...])\n            assert_array_equal(A[10:50, ...], T[10:50, ...])\n            assert_array_equal(A[-50:, ...], T[-50:, ...])\n            assert_array_equal(A[..., :10], T[..., :10])\n            assert_array_equal(A[..., 10:20], T[..., 10:20])\n            assert_array_equal(A[..., -50:], T[..., -50:])\n\n            # across tiles\n            assert_array_equal(A[:150], T[:150])\n            assert_array_equal(A[-250:], T[-250:])\n\n            # point index\n            self.assertEqual(A[0], T[0])\n            self.assertEqual(A[-1], T[-1])\n\n            # point index with all index types\n            self.assertEqual(A[123], T[np.int8(123)])\n            self.assertEqual(A[123], T[np.uint8(123)])\n            self.assertEqual(A[123], T[np.int16(123)])\n            self.assertEqual(A[123], T[np.uint16(123)])\n            self.assertEqual(A[123], T[np.int64(123)])\n            self.assertEqual(A[123], T[np.uint64(123)])\n            self.assertEqual(A[123], T[np.int32(123)])\n            self.assertEqual(A[123], T[np.uint32(123)])\n\n            # mixed-type slicing\n            # https://github.com/TileDB-Inc/TileDB-Py/issues/140\n            self.assertEqual(A[0:1], T[0:np.uint16(1)])\n            self.assertEqual(A[0:1], T[np.int64(0):1])\n            with self.assertRaises(IndexError):\n                # this is a consequence of NumPy promotion rules\n                self.assertEqual(A[0:1], T[np.uint64(0):1])\n\n            # basic step\n            assert_array_equal(A[:50:2], T[:50:2])\n            assert_array_equal(A[:2:50], T[:2:50])\n            assert_array_equal(A[10:-1:50], T[10:-1:50])\n\n            # indexing errors\n            with self.assertRaises(IndexError):\n                T[:, :]\n            with self.assertRaises(IndexError):\n                T[:, 50]\n            with self.assertRaises(IndexError):\n                T[50, :]\n            with self.assertRaises(IndexError):\n                T[0, 0]\n\n            # check single ellipsis\n            with self.assertRaises(IndexError):\n                T[..., 1:5, ...]\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            # check partial assignment\n            B = np.arange(1e5, 2e5).astype(A.dtype)\n            T[190:310] = B[190:310]\n\n        read2_timestamp = -1\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(A[:190], T[:190])\n            assert_array_equal(B[190:310], T[190:310])\n            assert_array_equal(A[310:], T[310:])\n\n            # test timestamps are updated\n            read2_timestamp = T.timestamp\n            self.assertTrue(read2_timestamp > read1_timestamp)\n\n    def test_array_1d_set_scalar(self):\n        A = np.zeros(50)\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(ctx=ctx, domain=(0, 49), tile=50), ctx=ctx)\n        att = tiledb.Attr(dtype=A.dtype, ctx=ctx)\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(A, T[:])\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\') as T:\n            value = -1,3,10\n            A[0], A[1], A[3] = value\n            T[0], T[1], T[3] = value\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\') as T:\n            assert_array_equal(A, T[:])\n\n        for value in (-1, 3, 10):\n            with tiledb.DenseArray(self.path(""foo""), mode=\'w\') as T:\n                A[5:25] = value\n                T[5:25] = value\n            with tiledb.DenseArray(self.path(""foo""), mode=\'r\') as T:\n                assert_array_equal(A, T[:])\n            with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n                A[:] = value\n                T[:] = value\n            with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n                assert_array_equal(A, T[:])\n\n    def test_array_id_point_queries(self):\n        #TODO: handle queries like T[[2, 5, 10]] = ?\n        pass\n\n    def test_array_2d(self):\n        A = np.arange(10000).reshape((1000, 10))\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n                       tiledb.Dim(domain=(0, 999), tile=100, ctx=ctx),\n                       tiledb.Dim(domain=(0, 9), tile=2, ctx=ctx),\n                       ctx=ctx)\n        att = tiledb.Attr(dtype=A.dtype, ctx=ctx)\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            self.assertEqual(len(A), len(T))\n            self.assertEqual(A.ndim, T.ndim)\n            self.assertEqual(A.shape, T.shape)\n\n            self.assertEqual(1, T.nattr)\n            self.assertEqual(A.dtype, T.attr(0).dtype)\n\n            # check that the non-empty domain is None\n            self.assertIsNone(T.nonempty_domain())\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            # Set data\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(A, T[:])\n\n            # check the non-empty domain spans the whole domain\n            self.assertEqual(((0, 999), (0, 9)), T.nonempty_domain())\n\n            # check array-like\n            assert_array_equal(A, np.array(T))\n\n            # slicing\n            assert_array_equal(A, T[:])\n            assert_array_equal(A, T[...])\n            assert_array_equal(A, T[slice(None)])\n\n            # slice first dimension\n            assert_array_equal(A[:10], T[:10])\n            assert_array_equal(A[:10], T[:10])\n            assert_array_equal(A[10:20], T[10:20])\n            assert_array_equal(A[-10:], T[-10:])\n            assert_array_equal(A[:10, :], T[:10, :])\n            assert_array_equal(A[10:20, :], T[10:20, :])\n            assert_array_equal(A[-10:, :], T[-10:, :])\n            assert_array_equal(A[:10, ...], T[:10, ...])\n            assert_array_equal(A[10:20, ...], T[10:20, ...])\n            assert_array_equal(A[-10:, ...], T[-10:, ...])\n            assert_array_equal(A[:10, :, ...], T[:10, :, ...])\n            assert_array_equal(A[10:20, :, ...], T[10:20, :, ...])\n            assert_array_equal(A[-10:, :, ...], T[-10:, :, ...])\n\n            # slice second dimension\n            assert_array_equal(A[:, :2], T[:, :2])\n            assert_array_equal(A[:, 2:4], T[:, 2:4])\n            assert_array_equal(A[:, -2:], T[:, -2:])\n            assert_array_equal(A[..., :2], T[..., :2])\n            assert_array_equal(A[..., 2:4], T[..., 2:4])\n            assert_array_equal(A[..., -2:], T[..., -2:])\n            assert_array_equal(A[:, ..., :2], T[:, ..., :2])\n            assert_array_equal(A[:, ..., 2:4], T[:, ..., 2:4])\n            assert_array_equal(A[:, ..., -2:], T[:, ..., -2:])\n\n            # slice both dimensions\n            assert_array_equal(A[:10, :2], T[:10, :2])\n            assert_array_equal(A[10:20, 2:4], T[10:20, 2:4])\n            assert_array_equal(A[-10:, -2:], T[-10:, -2:])\n\n            # slice across tile boundries\n            assert_array_equal(A[:110], T[:110])\n            assert_array_equal(A[190:310], T[190:310])\n            assert_array_equal(A[-110:], T[-110:])\n            assert_array_equal(A[:110, :], T[:110, :])\n            assert_array_equal(A[190:310, :], T[190:310, :])\n            assert_array_equal(A[-110:, :], T[-110:, :])\n            assert_array_equal(A[:, :3], T[:, :3])\n            assert_array_equal(A[:, 3:7], T[:, 3:7])\n            assert_array_equal(A[:, -3:], T[:, -3:])\n            assert_array_equal(A[:110, :3], T[:110, :3])\n            assert_array_equal(A[190:310, 3:7], T[190:310, 3:7])\n            assert_array_equal(A[-110:, -3:], T[-110:, -3:])\n\n            # single row/col/item\n            assert_array_equal(A[0], T[0])\n            assert_array_equal(A[-1], T[-1])\n            assert_array_equal(A[:, 0], T[:, 0])\n            assert_array_equal(A[:, -1], T[:, -1])\n            self.assertEqual(A[0, 0], T[0, 0])\n            self.assertEqual(A[-1, -1], T[-1, -1])\n\n            # too many indices\n            with self.assertRaises(IndexError):\n                T[:, :, :]\n            with self.assertRaises(IndexError):\n                T[0, :, :]\n            with self.assertRaises(IndexError):\n                T[:, 0, :]\n            with self.assertRaises(IndexError):\n                T[:, :, 0]\n            with self.assertRaises(IndexError):\n                T[0, 0, 0]\n\n            # only single ellipsis allowed\n            with self.assertRaises(IndexError):\n                T[..., ...]\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            # check partial assignment\n            B = np.arange(10000, 20000).reshape((1000, 10))\n            T[190:310, 3:7] = B[190:310, 3:7]\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(A[:190], T[:190])\n            assert_array_equal(A[:, :3], T[:, :3])\n            assert_array_equal(B[190:310, 3:7], T[190:310, 3:7])\n            assert_array_equal(A[310:], T[310:])\n            assert_array_equal(A[:, 7:], T[:, 7:])\n\n    def test_fixed_string(self):\n        ctx = tiledb.Ctx()\n        a = np.array([\'ab\', \'cd\', \'ef\', \'gh\', \'ij\', \'kl\'], dtype=\'|S2\')\n        with tiledb.from_numpy(self.path(\'fixed_string\'), a) as T:\n            with tiledb.open(self.path(\'fixed_string\')) as R:\n                self.assertEqual(T.dtype, R.dtype)\n                self.assertEqual(R.attr(0).ncells, 2)\n                assert_array_equal(T,R)\n\n    def test_ncell_int(self):\n        a = np.array([(1, 2), (3, 4), (5, 6)], dtype=[("""", np.int16), ("""", np.int16)])\n        with tiledb.from_numpy(self.path(\'ncell_int16\'), a) as T:\n            with tiledb.open(self.path(\'ncell_int16\')) as R:\n                self.assertEqual(T.dtype, R.dtype)\n                self.assertEqual(R.attr(0).ncells, 2)\n                assert_array_equal(T,R)\n                assert_array_equal(T, R.multi_index[0:2][\'\'])\n\n\n    def test_open_with_timestamp(self):\n        import time\n        A = np.zeros(3)\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(ctx=ctx, domain=(0, 2), tile=3, dtype=np.int64), ctx=ctx)\n        att = tiledb.Attr(ctx=ctx, dtype=A.dtype)\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,))\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n\n        # write\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        read1_timestamp = -1\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            read1_timestamp = T.timestamp\n            self.assertEqual(T[0], 0)\n            self.assertEqual(T[1], 0)\n            self.assertEqual(T[2], 0)\n\n        # sleep 200ms and write\n        time.sleep(0.2)\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[0:1] = 1\n\n        read2_timestamp = -1\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            read2_timestamp = T.timestamp\n            self.assertTrue(read2_timestamp > read1_timestamp)\n\n        # sleep 200ms and write\n        time.sleep(0.2)\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[1:2] = 2\n\n        read3_timestamp = -1\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            read3_timestamp = T.timestamp\n            self.assertTrue(read3_timestamp > read2_timestamp > read1_timestamp)\n\n        # read at first timestamp\n        with tiledb.DenseArray(self.path(""foo""), timestamp=read1_timestamp, mode=\'r\', ctx=ctx) as T:\n            self.assertEqual(T[0], 0)\n            self.assertEqual(T[1], 0)\n            self.assertEqual(T[2], 0)\n\n        # read at second timestamp\n        with tiledb.DenseArray(self.path(""foo""), timestamp=read2_timestamp, mode=\'r\', ctx=ctx) as T:\n            self.assertEqual(T[0], 1)\n            self.assertEqual(T[1], 0)\n            self.assertEqual(T[2], 0)\n\n        # read at third timestamp\n        with tiledb.DenseArray(self.path(""foo""), timestamp=read3_timestamp, mode=\'r\', ctx=ctx) as T:\n            self.assertEqual(T[0], 1)\n            self.assertEqual(T[1], 2)\n            self.assertEqual(T[2], 0)\n\n    def test_ncell_attributes(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(ctx=ctx, domain=(0, 9), tile=10, dtype=int), ctx=ctx)\n        attr = tiledb.Attr(ctx=ctx, dtype=[("""", np.int32), ("""", np.int32), ("""", np.int32)])\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(attr,))\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n\n        A = np.ones((10,), dtype=[("""", np.int32), ("""", np.int32), ("""", np.int32)])\n        self.assertEqual(A.dtype, attr.dtype)\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(A, T[:])\n            assert_array_equal(A[:5], T[:5])\n\n    def test_complex_attributes(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(ctx=ctx, domain=(0, 9), tile=10,\n                                       dtype=int), ctx=ctx)\n        attr = tiledb.Attr(ctx=ctx, dtype=np.complex64)\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(attr,))\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n\n        A = np.random.rand(20).astype(np.float32).view(dtype=np.complex64)\n\n        self.assertEqual(schema, tiledb.schema_like(A, dim_dtype=int))\n        self.assertEqual(A.dtype, attr.dtype)\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(A, T[:])\n            assert_array_equal(A[:5], T[:5])\n\n    def test_multiple_attributes(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n                       tiledb.Dim(domain=(0, 1), tile=1, dtype=np.int64, ctx=ctx),\n                       tiledb.Dim(domain=(0, 3), tile=4, dtype=np.int64, ctx=ctx),\n                       ctx=ctx)\n        attr_int = tiledb.Attr(""ints"", dtype=int, ctx=ctx)\n        attr_float = tiledb.Attr(""floats"", dtype=float, ctx=ctx)\n        schema = tiledb.ArraySchema(ctx=ctx,\n                                    domain=dom,\n                                    attrs=(attr_int, attr_float))\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n\n        V_ints = np.array([[0, 1, 2, 3,],\n                           [4, 6, 7, 5]])\n        V_floats = np.array([[0.0, 1.0, 2.0, 3.0,],\n                             [4.0, 6.0, 7.0, 5.0]])\n\n        V = {""ints"": V_ints, ""floats"": V_floats}\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = V\n\n        # check setting attribute in different order from Attr definition\n        #   https://github.com/TileDB-Inc/TileDB-Py/issues/299\n        V2 = {""floats"": V_floats, ""ints"": V_ints}\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = V\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            R = T[:]\n            assert_array_equal(V[""ints""], R[""ints""])\n            assert_array_equal(V[""floats""], R[""floats""])\n\n            R = T.query(attrs=(""ints"",))[1:3]\n            assert_array_equal(V[""ints""][1:3], R[""ints""])\n\n            R = T.query(attrs=(""floats"",), order=\'F\')[:]\n            self.assertTrue(R[""floats""].flags.f_contiguous)\n\n            R = T.query(attrs=(""ints"",), coords=True)[0, 0:3]\n            self.assertTrue(""__dim_0"" in R)\n            self.assertTrue(""__dim_1"" in R)\n            assert_array_equal(R[""__dim_0""], np.array([0,0,0]))\n            assert_array_equal(R[""__dim_1""], np.array([0,1,2]))\n\n            # Global order returns results as a linear buffer\n            R = T.query(attrs=(""ints"",), order=\'G\')[:]\n            self.assertEqual(R[""ints""].shape, (8,))\n\n            with self.assertRaises(tiledb.TileDBError):\n                T.query(attrs=(""unknown""))[:]\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            # check error ncells length\n            V[""ints""] = V[""ints""][1:2].copy()\n            with self.assertRaises(tiledb.TileDBError):\n                T[:] = V\n\n            # check error attribute does not exist\n            V[""foo""] = V[""ints""].astype(np.int8)\n            with self.assertRaises(tiledb.TileDBError):\n                T[:] = V\n\n    def test_array_2d_s1(self):\n        # This array is currently read back with dtype object\n        A = np.array([[\'A\', \'B\'], [\'C\', \'\']], dtype=\'S\')\n\n        uri = self.path(""varlen_2d_s1"")\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(0, 1), tile=2, dtype=np.int64),\n                            tiledb.Dim(name=""cols"", domain=(0, 1), tile=2, dtype=np.int64), ctx=ctx)\n\n        schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                    attrs=[tiledb.Attr(name=""a"", dtype=\'S\', ctx=ctx)],\n                                    ctx=ctx)\n\n        tiledb.DenseArray.create(uri, schema)\n\n        with tiledb.DenseArray(uri, mode=\'w\', ctx=ctx) as T:\n            T[...] = A\n\n        with tiledb.DenseArray(uri) as T:\n            assert_array_equal(A, T)\n\n            res = T.multi_index[(0,1), (0,1)][\'a\']\n            assert_array_equal(A, res)\n\n    def test_array_2d_s3_mixed(self):\n        # This array is currently read back with dtype object\n        A = np.array([[\'AAA\', \'B\'], [\'AB\', \'C\']], dtype=\'S3\')\n\n        uri = self.path(""varlen_2d_s1"")\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(0, 1), tile=2, dtype=np.int64),\n                            tiledb.Dim(name=""cols"", domain=(0, 1), tile=2, dtype=np.int64), ctx=ctx)\n\n        schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                    attrs=[tiledb.Attr(name=""a"", dtype=\'S3\', ctx=ctx)],\n                                    ctx=ctx)\n\n        tiledb.DenseArray.create(uri, schema)\n\n        with tiledb.DenseArray(uri, mode=\'w\', ctx=ctx) as T:\n            T[...] = A\n\n        with tiledb.DenseArray(uri) as T:\n            assert_array_equal(A, T)\n\n            res = T.multi_index[(0,1), (0,1)][\'a\']\n            assert_array_equal(A, res)\n\n    def test_incomplete_dense(self):\n        path = self.path(""incomplete_dense"")\n        # create 10 MB array\n        data = np.arange(1310720, dtype=np.int64)\n        # if `tile` is not set, it defaults to the full array and we\n        # only read 8 bytes at a time.\n        use_tile=131072\n        #use_tile = None\n        with tiledb.from_numpy(path, data, tile=use_tile) as A:\n            pass\n\n        # create context with 1 MB memory budget (2 MB total, 1 MB usable)\n        config = tiledb.Config({\'sm.memory_budget\': 2 * 1024**2,\n                                \'py.init_buffer_bytes\': 1024**2 })\n        ctx = tiledb.Ctx(config=config)\n        self.assertEqual(\n            config[\'py.init_buffer_bytes\'],\n            str(1024**2)\n        )\n        # TODO would be good to check repeat count here. Not currently exposed by retry loop.\n        with tiledb.DenseArray(path, ctx=ctx) as A:\n            res_mr = A.multi_index[ slice(0, len(data) - 1) ]\n            assert_array_equal(res_mr[""""], data)\n            res_idx = A[:]\n            assert_array_equal(res_idx, data)\n\n    def test_incomplete_dense_varlen(self):\n        ncells = 100\n\n        path = self.path(""incomplete_dense_varlen"")\n        str_data = [rand_utf8(random.randint(0, n)) for n in range(ncells)]\n        data = np.array(str_data, dtype=np.unicode_)\n\n        # basic write\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(1, len(data)), tile=len(data), ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(dtype=np.unicode_, var=True, ctx=ctx)\n\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n\n        tiledb.DenseArray.create(path, schema)\n        with tiledb.DenseArray(path, mode=\'w\', ctx=ctx) as T:\n            T[:] = data\n\n        with tiledb.DenseArray(path, mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(data, T[:])\n\n        # set the memory to the max length of a cell\n        # these settings force ~100 retries\n        # TODO would be good to check repeat count here; not yet exposed\n        #      Also would be useful to have max cell config in libtiledb.\n        init_buffer_bytes = 1024**2\n        config = tiledb.Config({\'sm.memory_budget\': ncells,\n                                \'sm.memory_budget_var\': ncells,\n                                \'py.init_buffer_bytes\': init_buffer_bytes })\n\n        ctx2 = tiledb.Ctx(config=config)\n        self.assertEqual(\n            config[\'py.init_buffer_bytes\'],\n            str(init_buffer_bytes)\n        )\n\n        with tiledb.DenseArray(path, mode=\'r\', ctx=ctx2) as T2:\n            assert_array_equal(data, T2[:])\n\n    def test_incomplete_sparse_varlen(self):\n        ncells = 100\n\n        path = self.path(""incomplete_dense_varlen"")\n        str_data = [rand_utf8(random.randint(0, n)) for n in range(ncells)]\n        data = np.array(str_data, dtype=np.unicode_)\n        coords = np.arange(ncells)\n\n        # basic write\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, len(data)+100), tile=len(data), ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(dtype=np.unicode_, var=True, ctx=ctx)\n\n        schema = tiledb.ArraySchema(dom, (att,), sparse=True, ctx=ctx)\n\n        tiledb.SparseArray.create(path, schema)\n        with tiledb.SparseArray(path, mode=\'w\', ctx=ctx) as T:\n            T[coords] = data\n\n        with tiledb.SparseArray(path, mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(data, T[:][\'\'])\n\n        # set the memory to the max length of a cell\n        # these settings force ~100 retries\n        # TODO would be good to check repeat count here; not yet exposed\n        #      Also would be useful to have max cell config in libtiledb.\n        init_buffer_bytes = 1024**2\n        config = tiledb.Config({\'sm.memory_budget\': ncells,\n                                \'sm.memory_budget_var\': ncells,\n                                \'py.init_buffer_bytes\': init_buffer_bytes })\n\n        ctx2 = tiledb.Ctx(config=config)\n        self.assertEqual(\n            config[\'py.init_buffer_bytes\'],\n            str(init_buffer_bytes)\n        )\n\n        with tiledb.SparseArray(path, mode=\'r\', ctx=ctx2) as T2:\n            assert_array_equal(\n                data,\n                T2[:][\'\']\n            )\n\n            assert_array_equal(\n                data,\n                T2.multi_index[0:ncells][\'\']\n            )\n\n            # ensure that empty results are handled correctly\n            assert_array_equal(\n                T2.multi_index[101:105][\'\'],\n                np.array([], dtype=np.dtype(\'<U\'))\n            )\n\n    def test_written_fragment_info(self):\n        uri = self.path(""test_written_fragment_info"")\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, 9), tile=10, dtype=np.int64, ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(ctx=ctx, dtype=np.int64)\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,))\n        tiledb.DenseArray.create(uri, schema)\n\n        with tiledb.DenseArray(uri, mode=\'w\', ctx=ctx) as T:\n            T[:] = np.arange(0, 10, dtype=np.int64)\n\n            self.assertTrue(T.last_write_info is not None)\n            self.assertTrue(len(T.last_write_info.keys()) == 1)\n            print(T.last_write_info.values())\n            t_w1, t_w2 = list(T.last_write_info.values())[0]\n            self.assertTrue(t_w1 > 0)\n            self.assertTrue(t_w2 > 0)\n\n    def test_missing_schema_error(self):\n        uri = self.path(""test_missing_schema_error"")\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, 9), tile=10, dtype=np.int64, ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(ctx=ctx, dtype=np.int64)\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,))\n        tiledb.DenseArray.create(uri, schema)\n\n        with tiledb.DenseArray(uri, mode=\'w\', ctx=ctx) as T:\n            T[:] = np.arange(0, 10, dtype=np.int64)\n\n        tiledb.VFS().remove_file(os.path.join(uri, ""__array_schema.tdb""))\n\n        with self.assertRaises(tiledb.TileDBError):\n            tiledb.DenseArray(uri)\n\n\nclass DenseVarlen(DiskTestCase):\n    def test_varlen_write_bytes(self):\n        A = np.array([\'aa\',\'bbb\',\'ccccc\',\'ddddddddddddddddddddd\',\'ee\',\'ffffff\',\'g\',\'hhhhhhhhhh\'], dtype=bytes)\n\n        # basic write\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(ctx=ctx, domain=(1, len(A)), tile=len(A)), ctx=ctx)\n        att = tiledb.Attr(dtype=np.bytes_, ctx=ctx)\n\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(A[:], T[:])\n\n            assert_array_equal(A, T.multi_index[1:len(A)][\'\'])\n\n\n    def test_varlen_write_unicode(self):\n        A = np.array([\'aa\',\'bbb\',\n                      \'ccccc\',\'ddddddddddddddddddddd\',\n                      \'ee\',\'ffffff\',\'g\',\'\',\'hhhhhhhhhh\'], dtype=np.unicode_)\n\n        # basic write\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(1, len(A)), tile=len(A), ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(dtype=np.unicode_, var=True, ctx=ctx)\n\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(A[:], T[:])\n\n    def test_varlen_write_floats(self):\n        # Generates 8 variable-length float64 subarrays (subarray len and content are randomized)\n        A = np.array([np.random.rand(x) for x in np.random.randint(1,12,8)], dtype=np.object)\n\n        # basic write\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(1, len(A)), tile=len(A)), ctx=ctx)\n        att = tiledb.Attr(dtype=np.float64, var=True, ctx=ctx)\n\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            T_ = T[:]\n            # TODO/note: the return is a 0-element array.\n            assert_array_equal(A[0], T[1][()])\n            assert_array_equal(A[-1], T[-1][()])\n            self.assertEqual(len(A), len(T_))\n            # can\'t use assert_array_equal w/ np.object array\n            self.assertTrue(all(np.array_equal(x,A[i]) for i,x in enumerate(T_)))\n\n    def test_varlen_write_floats_2d(self):\n        A = np.array([np.random.rand(x) for x in np.arange(1,10)], dtype=np.object).reshape(3,3)\n\n        # basic write\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(1, 3), tile=len(A)),\n                            tiledb.Dim(domain=(1, 3), tile=len(A)),\n                            ctx=ctx)\n        att = tiledb.Attr(dtype=np.float64, var=True, ctx=ctx)\n\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            T_ = T[:]\n            self.assertEqual(len(A), len(T_))\n            # can\'t use assert_array_equal w/ np.object array\n            self.assertTrue(np.all([np.array_equal(A.flat[i], T[:].flat[i]) for i in np.arange(0, 9)]))\n\n    def test_varlen_write_int_subarray(self):\n        A = np.array(list(map(lambda x: np.array(x, dtype=np.uint64),\n                        [np.arange(i, 2 * i + 1) for i in np.arange(0, 16)])\n                        ),\n                     dtype=\'O\').reshape(4,4)\n\n        uri = self.path(""test_varlen_write_int_subarray"")\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, 3), tile=len(A)),\n                            tiledb.Dim(domain=(0, 3), tile=len(A)),\n                            ctx=ctx)\n        att = tiledb.Attr(dtype=np.uint64, var=True, ctx=ctx)\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n\n        tiledb.DenseArray.create(uri, schema)\n\n        # NumPy forces single-element object arrays into a contiguous layout\n        #       so we alternate the size to get a consistent baseline array.\n        A_onestwos = np.array(\n            list(map(lambda x: np.array(x, dtype=np.uint64),\n                     list([(1,) if x % 2 == 0 else (1, 2) for x in range(16)]))),\n            dtype=np.dtype(\'O\')).reshape(4,4)\n\n        with tiledb.open(uri, \'w\') as T:\n            T[:] = A_onestwos\n\n        with tiledb.open(uri, \'w\') as T:\n            T[1:3,1:3] = A[1:3,1:3]\n\n        A_assigned = A_onestwos.copy()\n        A_assigned[1:3,1:3] = A[1:3,1:3]\n\n        with tiledb.open(uri) as T:\n            assert_subarrays_equal(A_assigned, T[:])\n\n    def test_varlen_write_fixedbytes(self):\n        # The actual dtype of this array is \'S21\'\n        A = np.array([\'aa\',\'bbb\',\'ccccc\',\'ddddddddddddddddddddd\',\'ee\',\n                      \'ffffff\',\'g\',\'hhhhhhhhhh\'], dtype=np.dtype(\'S\'))\n\n        # basic write\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(ctx=ctx, domain=(1, len(A)), tile=len(A)), ctx=ctx)\n        att = tiledb.Attr(dtype=np.bytes_, ctx=ctx)\n\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(A[:], T[:])\n\n\n    def test_varlen_write_fixedunicode(self):\n        A = np.array([u\'aa\',u\'bbb\',u\'ccccc\',u\'ddddddddddddddddddddd\',u\'ee\',\n                      u\'ffffff\',u\'g\',u\'hhhhhhhhhh\'], dtype=np.dtype(\'U\'))\n\n        # basic write\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(ctx=ctx, domain=(1, len(A)), tile=len(A)), ctx=ctx)\n        att = tiledb.Attr(dtype=np.unicode_, ctx=ctx)\n\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(A[:], T[:])\n\n\n    def test_varlen_write_ints(self):\n        A = np.array([np.uint64(np.random.randint(0,pow(10,6),x)) for x in np.random.randint(1,12,8)], dtype=np.object)\n\n        print(""random sub-length test array: {}"".format(A))\n\n        # basic write\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(1, len(A)), tile=len(A), ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(dtype=np.int64, var=True, ctx=ctx)\n\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            T_ = T[:]\n            self.assertEqual(len(A), len(T))\n            # can\'t use assert_array_equal w/ np.object array\n            self.assertTrue(all(np.array_equal(x,A[i]) for i,x in enumerate(T_)))\n\n    def test_varlen_wrong_domain(self):\n        A = np.array([\'aa\',\'bbb\',\'ccccc\',\'ddddddddddddddddddddd\',\'ee\',\'ffffff\',\'g\',\'hhhhhhhhhh\'])\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(1, 3), tile=3), ctx=ctx)\n        att = tiledb.Attr(dtype=np.bytes_, ctx=ctx)\n\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            with self.assertRaises(tiledb.TileDBError):\n                T[:] = A\n\n    def test_array_varlen_mismatched(self):\n        # Test that we raise a TypeError when passing a heterogeneous object array.\n        A = np.array(\n                [  b\'aa\', b\'bbb\', b\'cccc\',\n                   np.uint64([1,3,4]), ],\n                dtype = np.object)\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, 3), tile=4, ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(dtype=np.bytes_, var=True, ctx=ctx)\n\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\') as T:\n            with self.assertRaises(TypeError):\n                T[:] = A\n\n    def test_array_varlen_2d_s_fixed(self):\n        A = np.array([[\'AAAAAAAAAa\', \'BBB\'], [\'ACCC\', \'BBBCBCBCBCCCBBCBCBCCBC\']], dtype=\'S\')\n\n        uri = self.path(""varlen_2d_s_fixed"")\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(name=""rows"", domain=(0, 1), tile=2, dtype=np.int64),\n                            tiledb.Dim(name=""cols"", domain=(0, 1), tile=2, dtype=np.int64), ctx=ctx)\n\n        schema = tiledb.ArraySchema(domain=dom, sparse=False,\n                                    attrs=[tiledb.Attr(name=""a"", dtype=\'S\', var=True, ctx=ctx)],\n                                    ctx=ctx)\n\n        tiledb.DenseArray.create(uri, schema)\n\n        with tiledb.DenseArray(uri, mode=\'w\', ctx=ctx) as T:\n            T[...] = A\n\n        with tiledb.DenseArray(uri) as T:\n            assert_array_equal(A, T)\n\n\nclass SparseArray(DiskTestCase):\n\n    @unittest.expectedFailure\n    def test_simple_1d_sparse_vector(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, 3), tile=4, dtype=int, ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(dtype=int, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, attrs=(att,), sparse=True, ctx=ctx)\n        tiledb.SparseArray.create(self.path(""foo""), schema)\n\n        values = np.array([3, 4])\n        with tiledb.SparseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[[1, 2]] = values\n\n        with tiledb.SparseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(T[[1, 2]], values)\n\n    @unittest.expectedFailure\n    def test_simple_2d_sparse_vector(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(ctx,\n                            tiledb.Dim(ctx, domain=(0, 3), tile=4, dtype=int),\n                            tiledb.Dim(ctx, domain=(0, 3), tile=4, dtype=int))\n        attr = tiledb.Attr(ctx, dtype=float)\n        schema = tiledb.ArraySchema(ctx, domain=dom, attrs=(attr,), sparse=True)\n        tiledb.SparseArray.create(self.path(""foo""), schema)\n\n        values = np.array([3, 4], dtype=float)\n        with tiledb.SparseArray(ctx, self.path(""foo""), mode=\'w\') as T:\n            T[[1, 2], [1, 2]] = values\n\n        with tiledb.SparseArray(ctx, self.path(""foo""), mode=\'r\') as T:\n            assert_array_equal(T[[1, 2], [1, 2]], values)\n\n    @unittest.expectedFailure\n    def test_simple3d_sparse_vector(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(ctx,\n                            tiledb.Dim(ctx, ""x"", domain=(0, 3), tile=4, dtype=int),\n                            tiledb.Dim(ctx, ""y"", domain=(0, 3), tile=4, dtype=int),\n                            tiledb.Dim(ctx, ""z"", domain=(0, 3), tile=4, dtype=int))\n        attr = tiledb.Attr(ctx, dtype=float)\n        schema = tiledb.ArraySchema(ctx, domain=dom, attrs=(attr,), sparse=True)\n        tiledb.SparseArray.create(self.path(""foo""), schema)\n\n        values = np.array([3, 4], dtype=float)\n        with tiledb.SparseArray(ctx, self.path(""foo""), mode=\'w\') as T:\n            T[[1, 2], [1, 2], [1, 2]] = values\n\n        with tiledb.SparseArray(ctx, self.path(""foo""), mode=\'r\') as T:\n            assert_array_equal(T[[1, 2], [1, 2], [1, 2]], values)\n\n    @unittest.expectedFailure\n    def test_sparse_ordered_fp_domain(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n                tiledb.Dim(""x"", domain=(0.0, 10.0), tile=2.0, dtype=float, ctx=ctx),\n                ctx=ctx)\n        attr = tiledb.Attr(dtype=float, ctx=ctx)\n        attr = tiledb.Attr(dtype=float, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, attrs=(attr,), sparse=True, ctx=ctx)\n        tiledb.SparseArray.create(self.path(""foo""), schema)\n\n        values = np.array([3.3, 2.7])\n        with tiledb.SparseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[[2.5, 4.2]] = values\n        with tiledb.SparseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(T[[2.5, 4.2]], values)\n\n    @unittest.expectedFailure\n    def test_sparse_unordered_fp_domain(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(""x"", domain=(0.0, 10.0), tile=2.0, dtype=float), ctx=ctx)\n        attr = tiledb.Attr(dtype=float, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, attrs=(attr,), sparse=True, ctx=ctx)\n        tiledb.SparseArray.create(self.path(""foo""), schema)\n        values = np.array([3.3, 2.7])\n        with tiledb.SparseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[[4.2, 2.5]] = values\n\n        with tiledb.SparseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(T[[2.5, 4.2]], values[::-1])\n\n    @unittest.expectedFailure\n    def test_multiple_attributes(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n                tiledb.Dim(domain=(1, 10), tile=10, dtype=int, ctx=ctx),\n                tiledb.Dim(domain=(1, 10), tile=10, dtype=int, ctx=ctx),\n                ctx=ctx)\n        attr_int = tiledb.Attr(""ints"", dtype=int, ctx=ctx)\n        attr_float = tiledb.Attr(""floats"", dtype=""float"", ctx=ctx)\n        schema = tiledb.ArraySchema(\n                                domain=dom,\n                                attrs=(attr_int, attr_float,),\n                                sparse=True,\n                                ctx=ctx)\n        tiledb.SparseArray.create(self.path(""foo""), schema)\n\n        I = np.array([1, 1, 1, 2, 3, 3, 3, 4])\n        J = np.array([1, 2, 4, 3, 1, 6, 7, 5])\n\n        V_ints = np.array([0, 1, 2, 3, 4, 6, 7, 5])\n        V_floats = np.array([0.0, 1.0, 2.0, 3.0, 4.0, 6.0, 7.0, 5.0])\n\n        V = {""ints"": V_ints, ""floats"": V_floats}\n        with tiledb.SparseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[I, J] = V\n        with tiledb.SparseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            R = T[I, J]\n        assert_array_equal(V[""ints""], R[""ints""])\n        assert_array_equal(V[""floats""], R[""floats""])\n\n        # check error attribute does not exist\n        # TODO: should this be an attribute error?\n        with tiledb.SparseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            V[""foo""] = V[""ints""].astype(np.int8)\n            with self.assertRaises(tiledb.TileDBError):\n                T[I, J] = V\n\n            # check error ncells length\n            V[""ints""] = V[""ints""][1:2].copy()\n            with self.assertRaises(AttributeError):\n                T[I, J] = V\n\n    def test_query_fp_domain_index(self):\n        uri = self.path(""query_fp_domain_index"")\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n            tiledb.Dim(""x"", domain=(-10.0, 10.0), tile=2.0, dtype=float, ctx=ctx),\n            ctx=ctx)\n        attr = tiledb.Attr(""a"", dtype=np.float32, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, attrs=(attr,), sparse=True, ctx=ctx)\n        tiledb.SparseArray.create(uri, schema)\n\n        values = np.array([3.3, 2.7])\n        with tiledb.SparseArray(uri, mode=\'w\', ctx=ctx) as T:\n            T[[2.5, 4.2]] = values\n        with tiledb.SparseArray(uri, mode=\'r\', ctx=ctx) as T:\n            assert_array_equal(\n                T.query(coords=True).domain_index[-10.0: np.nextafter(4.2, 0)][""a""],\n                np.float32(3.3)\n            )\n            assert_array_equal(\n                T.query(coords=True).domain_index[-10.0: np.nextafter(4.2, 0)][""x""],\n                np.float32([2.5])\n            )\n            assert_array_equal(\n                T.query(coords=False).domain_index[-10.0: 5.0][""a""],\n                np.float32([3.3, 2.7])\n            )\n            self.assertTrue(\n                \'coords\' not in T.query(coords=False).domain_index[-10.0: 5.0]\n            )\n\n    def test_subarray(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n                tiledb.Dim(""x"", domain=(1, 10000), tile=100, dtype=int, ctx=ctx), ctx=ctx)\n        att = tiledb.Attr("""", dtype=float, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, attrs=(att,), sparse=True, ctx=ctx)\n        tiledb.SparseArray.create(self.path(""foo""), schema)\n\n        with tiledb.SparseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            self.assertIsNone(T.nonempty_domain())\n\n        with tiledb.SparseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[[50, 60, 100]] = [1.0, 2.0, 3.0]\n\n        with tiledb.SparseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            self.assertEqual(((50, 100),), T.nonempty_domain())\n\n            # retrieve just valid coordinates in subarray T[40:60]\n            assert_array_equal(T[40:61][""x""], [50, 60])\n\n            #TODO: dropping coords with one anon value returns just an array\n            res = T.query(coords=False)[40:61]\n            assert_array_equal(res[""""], [1.0, 2.0])\n            self.assertEqual((""coords"" in res), False)\n\n    def test_sparse_bytes(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n            tiledb.Dim(""x"", domain=(1, 10000), tile=100, dtype=int, ctx=ctx), ctx=ctx)\n        att = tiledb.Attr("""", var=True, dtype=np.bytes_, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, attrs=(att,), sparse=True, ctx=ctx)\n        tiledb.SparseArray.create(self.path(""foo""), schema)\n\n        with tiledb.SparseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            self.assertIsNone(T.nonempty_domain())\n        A = np.array([b\'aaa\', b\'bbbbbbbbbbbbbbbbbbbb\', b\'ccccccccccccccccccccccccc\'],\n                     dtype=np.bytes_)\n\n        with tiledb.SparseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[[50, 60, 100]] = A\n\n        with tiledb.SparseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            self.assertEqual(((50, 100),), T.nonempty_domain())\n\n            # retrieve just valid coordinates in subarray T[40:60]\n            assert_array_equal(T[40:61][""x""], [50, 60])\n\n            #TODO: dropping coords with one anon value returns just an array\n            res = T.query(coords=False)[40:61]\n            assert_array_equal(res[""""], A[0:2])\n            self.assertEqual((""coords"" in res), False)\n\n    def test_sparse_unicode(self):\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n            tiledb.Dim(""x"", domain=(1, 10000), tile=100, dtype=int, ctx=ctx), ctx=ctx)\n        att = tiledb.Attr("""", var=True, dtype=np.unicode_, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, attrs=(att,), sparse=True, ctx=ctx)\n        tiledb.SparseArray.create(self.path(""foo""), schema)\n\n        with tiledb.SparseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            self.assertIsNone(T.nonempty_domain())\n\n        A = np_array = np.array([u\'1234545lkjalsdfj\', u\'mnopqrs\', u\'ijkl\', u\'gh\', u\'abcdef\',\n                                 u\'a\xce\xb1b\xce\xb2\xce\xb2c\xce\xb3\xce\xb3\xce\xb3d\xce\xb4\xce\xb4\xce\xb4\xce\xb4\', u\'a\xce\xb1b\xce\xb2\xce\xb2c\', u\'\', u\'\xce\xb3\xce\xb3\xce\xb3d\xce\xb4\xce\xb4\xce\xb4\xce\xb4\'], dtype=object)\n\n        with tiledb.SparseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[[3, 4, 5, 6, 7, 50, 60, 70, 100]] = A\n\n        with tiledb.SparseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            self.assertEqual(((3, 100),), T.nonempty_domain())\n\n            # retrieve just valid coordinates in subarray T[40:60]\n            assert_array_equal(T[40:61][""x""], [50, 60])\n\n            #TODO: dropping coords with one anon value returns just an array\n            res = T.query(coords=False)[40:61]\n            assert_array_equal(res[""""], A[5:7])\n            self.assertEqual((""coords"" in res), False)\n\n    def test_sparse_fixes(self):\n        uri = self.path(""test_sparse_fixes"")\n        # indexing a 1 element item in a sparse array\n        # (issue directly reported)\n        # the test here is that the indexing does not raise\n        ctx = tiledb.Ctx()\n        dims = (tiledb.Dim(\'foo\', ctx=ctx, domain=(0, 6), tile=2),\n                tiledb.Dim(\'bar\', ctx=ctx, domain=(0, 6), tile=1),\n                tiledb.Dim(\'baz\', ctx=ctx, domain=(0, 100), tile=1))\n        dom = tiledb.Domain(*dims, ctx=ctx)\n        att = tiledb.Attr(name=""strattr"", ctx=ctx, dtype=\'S1\')\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,),\n                                    sparse=True)\n        tiledb.SparseArray.create(uri, schema)\n        with tiledb.SparseArray(uri) as T:\n            T[:]\n\n        # - test that assigning incompatible value to fixed-len str raises error\n        # - test that value-conversion error raises exception w/ attr name context\n        c = np.vstack(list((x,y,z) for x in range(7) for y in range(7) for z in range(101)))\n        with tiledb.SparseArray(uri, \'w\') as T:\n            with self.assertRaises(ValueError):\n                T[c[:,0],c[:,1],c[:,2]] = {\'strattr\': np.random.rand(7,7,101)}\n            save_exc = list()\n            try:\n                T[c[:,0],c[:,1],c[:,2]] = {\'strattr\': np.random.rand(7,7,101)}\n            except ValueError as e:\n                save_exc.append(e)\n            exc = save_exc.pop()\n            if (sys.version_info > (3,3)):\n                self.assertEqual(str(exc.__context__),\n                                 ""Cannot write a string value to non-string typed attribute \'strattr\'!"")\n\n    def test_sparse_fixes_ch1560(self):\n        from tiledb import Domain, Attr, Dim\n        from collections import OrderedDict\n        from numpy import array\n\n        uri = self.path(""sparse_fixes_ch1560"")\n        ctx = tiledb.Ctx({\'sm.check_coord_dups\': False})\n        schema = tiledb.ArraySchema(\n            domain=Domain(*[\n                Dim(name=\'id\', domain=(1, 5000), tile=25, dtype=\'int32\', ctx=ctx),\n            ]),\n            attrs=[\n                Attr(name=\'a1\', dtype=\'datetime64[s]\', ctx=ctx),\n                Attr(name=\'a2\', dtype=\'|S0\', ctx=ctx),\n                Attr(name=\'a3\', dtype=\'|S0\', ctx=ctx),\n                Attr(name=\'a4\', dtype=\'int32\', ctx=ctx),\n                Attr(name=\'a5\', dtype=\'int8\', ctx=ctx),\n                Attr(name=\'a6\', dtype=\'int32\', ctx=ctx),\n            ],\n            cell_order=\'row-major\',\n            tile_order=\'row-major\',\n            sparse=True)\n\n        tiledb.SparseArray.create(uri, schema)\n\n        data = OrderedDict(\n            [\n                (\'a1\', array([\'2017-04-01T04:00:00\', \'2019-10-01T00:00:00\',\n                              \'2019-10-01T00:00:00\', \'2019-10-01T00:00:00\'],\n                             dtype=\'datetime64[s]\')),\n                (\'a2\', [b\'Bus\', b\'The RIDE\', b\'The RIDE\', b\'The RIDE\']),\n                (\'a3\', [b\'Bus\', b\'The RIDE\', b\'The RIDE\', b\'The RIDE\']),\n                (\'a4\', array([6911721,  138048,  138048,  138048], dtype=\'int32\')),\n                (\'a5\', array([20, 23, 23, 23], dtype=\'int8\')),\n                (\'a6\', array([345586,   6002,   6002,   6002], dtype=\'int32\'))\n            ])\n\n        with tiledb.open(uri, \'w\', ctx=ctx) as A:\n            A[[1,462, 462, 462]] = data\n\n        with tiledb.open(uri, ctx=ctx) as A:\n            res = A[:]\n            res.pop(\'id\')\n            for k,v in res.items():\n                if isinstance(data[k], (np.ndarray,list)):\n                    assert_array_equal(res[k], data[k])\n                else:\n                    self.assertEqual(res[k], data[k])\n\n    def test_sparse_2d_varlen_int(self):\n        path = self.path(\'test_sparse_2d_varlen_int\')\n        dtype = np.int32\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n            tiledb.Dim(domain=(1, 4), tile=2, ctx=ctx),\n            tiledb.Dim(domain=(1, 4), tile=2, ctx=ctx),\n            ctx=ctx)\n        att = tiledb.Attr(dtype=dtype, var=True, ctx=ctx)\n        schema = tiledb.ArraySchema(dom, (att,), sparse=True, ctx=ctx)\n\n        tiledb.SparseArray.create(path, schema)\n\n        c1 = np.array([1,2,3,4])\n        c2 = np.array([2,1,3,4])\n\n        data = np.array([\n            np.array([1,1], dtype=np.int32),\n            np.array([2], dtype=np.int32),\n            np.array([3,3,3], dtype=np.int32),\n            np.array([4], dtype=np.int32)\n            ], dtype=\'O\')\n\n        with tiledb.SparseArray(path, \'w\') as A:\n            A[c1, c2] = data\n\n        with tiledb.SparseArray(path) as A:\n            res = A[:]\n            assert_subarrays_equal(\n                res[\'\'],\n                data\n            )\n            assert_array_equal(\n                res[\'__dim_0\'],\n                c1\n            )\n            assert_array_equal(\n                res[\'__dim_1\'],\n                c2\n            )\n\n    def test_sparse_mixed_domain_uint_float64(self):\n        path = self.path(""mixed_domain_uint_float64"")\n        ctx = tiledb.Ctx()\n        dims = [\n            tiledb.Dim(name=""index"", domain=(0, 51), tile=11, dtype=np.uint64),\n            tiledb.Dim(name=""dpos"", ctx=ctx, domain=(-100.0, 100.0), tile=10, dtype=np.float64)\n        ]\n        dom = tiledb.Domain(*dims)\n        attrs = [\n            tiledb.Attr(name=""val"", dtype=np.float64, ctx=ctx)\n        ]\n\n        schema = tiledb.ArraySchema(domain=dom, attrs=attrs, sparse=True, ctx=ctx)\n        tiledb.SparseArray.create(path, schema, ctx=ctx)\n\n        data = np.random.rand(50, 63)\n        coords1 = np.repeat(np.arange(0,50), 63)\n        coords2 = np.linspace(-100.0,100.0, num=3150)\n\n        with tiledb.open(path, \'w\') as A:\n            A[coords1, coords2] = data\n\n        # tiledb returns coordinates in sorted order, so we need to check the output\n        # sorted by the first dim coordinates\n        sidx = np.argsort(coords1, kind=\'stable\')\n        coords2_idx = np.tile(np.arange(0,63), 50)[sidx]\n\n        with tiledb.open(path) as A:\n            res = A[:]\n            assert_subarrays_equal(data[coords1[sidx],coords2_idx[sidx]], res[\'val\'])\n            a_nonempty = A.nonempty_domain()\n            self.assertEqual(a_nonempty[0], (0,49))\n            self.assertEqual(a_nonempty[1], (-100.0, 100.0))\n\n    def test_sparse_string_domain(self):\n        path = self.path(""sparse_string_domain"")\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(name=""d"", domain=(None,None), dtype=np.bytes_, ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(name=""a"", ctx=ctx, dtype=np.int64)\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,), sparse=True, capacity=10000)\n        tiledb.SparseArray.create(path, schema)\n\n        data = [1,2,3,4]\n        coords = [b""aa"",b""bbb"", b""c"", b""dddd""]\n\n        with tiledb.open(path, \'w\') as A:\n            A[coords] = data\n\n        with tiledb.open(path) as A:\n            ned = A.nonempty_domain()[0]\n            res = A[ned[0] : ned[1]]\n            assert_array_equal(res[\'a\'], data)\n            self.assertEqual(set(res[\'d\']), set(coords))\n            self.assertEqual(A.nonempty_domain(), ((b""aa"", b""dddd""),))\n\n\n    def test_sparse_string_domain2(self):\n        path = self.path(""sparse_string_domain2"")\n        ctx = tiledb.Ctx()\n        dims = [\n            tiledb.Dim(name=""str"", domain=(None,None), tile=None, dtype=np.bytes_),\n        ]\n        dom = tiledb.Domain(*dims)\n        attrs = [\n            tiledb.Attr(name=""val"", dtype=np.float64, ctx=ctx)\n        ]\n\n        schema = tiledb.ArraySchema(domain=dom, attrs=attrs, sparse=True, ctx=ctx)\n        tiledb.SparseArray.create(path, schema, ctx=ctx)\n\n        data = np.random.rand(10)\n        coords = [rand_ascii_bytes(random.randint(5, 50)) for _ in range(10)]\n\n        with tiledb.open(path, \'w\') as A:\n            A[coords] = data\n\n        with tiledb.open(path) as A:\n            ned = A.nonempty_domain()[0]\n            res = A[ned[0] : ned[1]]\n            self.assertTrue(set(res[\'str\']) == set(coords))\n            # must check data ordered by coords\n            assert_array_equal(res[\'val\'], data[np.argsort(coords, kind=\'stable\')])\n\nclass DenseIndexing(DiskTestCase):\n\n    def _test_index(self, A, T, idx):\n        expected = A[idx]\n        actual = T[idx]\n        assert_array_equal(expected, actual)\n\n    good_index_1d = [\n        # single value\n        42,\n        -1,\n        # slices\n        slice(0, 1050),\n        slice(50, 150),\n        slice(0, 2000),\n        slice(-150, -50),\n\n        # TODO: indexing failures\n        #slice(-2000, 2000),\n        #slice(0, 0),  # empty result\n        #slice(-1, 0),  # empty result\n\n        # total selections\n        slice(None),\n        Ellipsis,\n        (),\n        (Ellipsis, slice(None)),\n        # slice with step\n        slice(None),\n        slice(None, None),\n        slice(None, None, 1),\n        slice(None, None, 10),\n        slice(None, None, 100),\n        slice(None, None, 1000),\n        slice(None, None, 10000),\n        slice(0, 1050),\n        slice(0, 1050, 1),\n        slice(0, 1050, 10),\n        slice(0, 1050, 100),\n        slice(0, 1050, 1000),\n        slice(0, 1050, 10000),\n        slice(1, 31, 3),\n        slice(1, 31, 30),\n        slice(1, 31, 300),\n        slice(81, 121, 3),\n        slice(81, 121, 30),\n        slice(81, 121, 300),\n        slice(50, 150),\n        slice(50, 150, 1),\n        slice(50, 150, 10),\n\n        # TODO: negative steps\n        slice(None, None, -1),\n        slice(None, None, -10),\n        slice(None, None, -100),\n        slice(None, None, -1000),\n        slice(None, None, -10000),\n        #slice(1050, -1, -1),\n        #slice(1050, -1, -10),\n        #slice(1050, -1, -100),\n        #slice(1050, -1, -1000),\n        #slice(1050, -1, -10000),\n        #slice(1050, 0, -1),\n        #slice(1050, 0, -10),\n        #slice(1050, 0, -100),\n        #slice(1050, 0, -1000),\n        #slice(1050, 0, -10000),\n        #slice(150, 50, -1),\n        #slice(150, 50, -10),\n        #slice(31, 1, -3),\n        #slice(121, 81, -3),\n        #slice(-1, 0, -1),\n    ]\n\n    bad_index_1d = [\n        2.3,\n        \'foo\',\n        b\'xxx\',\n        None,\n        (0, 0),\n        (slice(None), slice(None)),\n    ]\n\n    def test_index_1d(self):\n        A = np.arange(1050, dtype=int)\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, 1049), tile=100, ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(ctx=ctx, dtype=int)\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,))\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            for idx in self.good_index_1d:\n                self._test_index(A, T, idx)\n\n            for idx in self.bad_index_1d:\n                with self.assertRaises(IndexError):\n                    T[idx]\n\n    good_index_2d = [\n        # single row\n        42,\n        -1,\n        (42, slice(None)),\n        (-1, slice(None)),\n        # single col\n        (slice(None), 4),\n        (slice(None), -1),\n        # row slices\n        slice(None),\n        slice(0, 1000),\n        slice(250, 350),\n        slice(0, 2000),\n        slice(-350, -250),\n        slice(0, 0),  # empty result\n        slice(-1, 0),  # empty result\n        slice(-2000, 0),\n        slice(-2000, 2000),\n        # 2D slices\n        (slice(None), slice(1, 5)),\n        (slice(250, 350), slice(None)),\n        (slice(250, 350), slice(1, 5)),\n        (slice(250, 350), slice(-5, -1)),\n        (slice(250, 350), slice(-50, 50)),\n        (slice(250, 350, 10), slice(1, 5)),\n        (slice(250, 350), slice(1, 5, 2)),\n        (slice(250, 350, 33), slice(1, 5, 3)),\n        # total selections\n        (slice(None), slice(None)),\n        Ellipsis,\n        (),\n        (Ellipsis, slice(None)),\n        (Ellipsis, slice(None), slice(None)),\n\n        #TODO: negative steps\n        #slice(None, None, -1),\n        #(slice(None, None, -1), slice(None)),\n    ]\n\n    bad_index_2d = [\n        2.3,\n        \'foo\',\n        b\'xxx\',\n        None,\n        (2.3, slice(None)),\n        (0, 0, 0),\n        (slice(None), slice(None), slice(None)),\n    ]\n\n    def test_index_2d(self):\n        A = np.arange(10000).reshape((1000, 10))\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(\n                       tiledb.Dim(ctx=ctx, domain=(0, 999), tile=100),\n                       tiledb.Dim(ctx=ctx, domain=(0, 9), tile=2),\n                       ctx=ctx)\n        att = tiledb.Attr(dtype=A.dtype, ctx=ctx)\n        schema = tiledb.ArraySchema(dom, (att,), ctx=ctx)\n        tiledb.DenseArray.create(self.path(""foo""), schema)\n\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'w\', ctx=ctx) as T:\n            T[:] = A\n\n        with tiledb.DenseArray(self.path(""foo""), mode=\'r\', ctx=ctx) as T:\n            for idx in self.good_index_1d:\n                self._test_index(A, T, idx)\n\n            for idx in self.bad_index_2d:\n                with self.assertRaises(IndexError):\n                    T[idx]\n\n\nclass DatetimeSlicing(DiskTestCase):\n    def test_dense_datetime_vector(self):\n        ctx = tiledb.Ctx()\n        uri = self.path(""foo_datetime_vector"")\n\n        # Domain is 10 years, day resolution, one tile per 365 days\n        dim = tiledb.Dim(name=""d1"", ctx=ctx,\n                         domain=(np.datetime64(\'2010-01-01\'), np.datetime64(\'2020-01-01\')),\n                         tile=np.timedelta64(365, \'D\'), dtype=np.datetime64(\'\', \'D\').dtype)\n        dom = tiledb.Domain(dim, ctx=ctx)\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom,\n                                    attrs=(tiledb.Attr(\'a1\', dtype=np.float64),))\n        tiledb.Array.create(uri, schema)\n\n        # Write a few years of data at the beginning using a timedelta object\n        ndays = 365 * 2\n        a1_vals = np.random.rand(ndays)\n        start = np.datetime64(\'2010-01-01\')\n        # Datetime indexing is inclusive, so a delta of one less\n        end = start + np.timedelta64(ndays - 1, \'D\')\n        with tiledb.DenseArray(uri, \'w\', ctx=ctx) as T:\n            T[start: end] = {\'a1\': a1_vals}\n\n        # Read back data\n        with tiledb.DenseArray(uri, \'r\', attr=\'a1\', ctx=ctx) as T:\n            assert_array_equal(T[start: end], a1_vals)\n\n        # Check nonempty domain\n        with tiledb.DenseArray(uri, \'r\', ctx=ctx) as T:\n            nonempty = T.nonempty_domain()\n            d1_nonempty = nonempty[0]\n            self.assertEqual(d1_nonempty[0].dtype, np.datetime64(\'\', \'D\'))\n            self.assertEqual(d1_nonempty[1].dtype, np.datetime64(\'\', \'D\'))\n            self.assertTupleEqual(d1_nonempty, (start, end))\n\n        # Slice a few days from the middle using two datetimes\n        with tiledb.DenseArray(uri, \'r\', attr=\'a1\', ctx=ctx) as T:\n            # Slice using datetimes\n            actual = T[np.datetime64(\'2010-11-01\'): np.datetime64(\'2011-01-31\')]\n\n            # Convert datetime interval to integer offset/length into original array\n            # must be cast to int because float slices are not allowed in NumPy 1.12+\n            read_offset = int( (np.datetime64(\'2010-11-01\') - start) / np.timedelta64(1, \'D\') )\n            read_ndays = int( (np.datetime64(\'2011-01-31\') - np.datetime64(\'2010-11-01\') + 1) / np.timedelta64(1, \'D\') )\n            expected = a1_vals[read_offset : read_offset + read_ndays]\n            assert_array_equal(actual, expected)\n\n        # Slice the first year\n        with tiledb.DenseArray(uri, \'r\', attr=\'a1\', ctx=ctx) as T:\n            actual = T[np.datetime64(\'2010\'): np.datetime64(\'2011\')]\n\n            # Convert datetime interval to integer offset/length into original array\n            read_offset = int( (np.datetime64(\'2010-01-01\') - start) / np.timedelta64(1, \'D\') )\n            read_ndays = int( (np.datetime64(\'2011-01-01\') - np.datetime64(\'2010-01-01\') + 1) / np.timedelta64(1, \'D\') )\n            expected = a1_vals[read_offset: read_offset + read_ndays]\n            assert_array_equal(actual, expected)\n\n    def test_sparse_datetime_vector(self):\n        ctx = tiledb.Ctx()\n        uri = self.path(""foo_datetime_sparse_vector"")\n\n        # ns resolution, one tile per second, max domain possible\n        dim = tiledb.Dim(name=""d1"", ctx=ctx,\n                         domain=(np.datetime64(0, \'ns\'), np.datetime64(int(np.iinfo(np.int64).max) - 1000000000, \'ns\')),\n                         tile=np.timedelta64(1, \'s\'), dtype=np.datetime64(\'\', \'ns\').dtype)\n        self.assertEqual(dim.tile, np.timedelta64(\'1000000000\', \'ns\'))\n        dom = tiledb.Domain(dim, ctx=ctx)\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, sparse=True,\n                                    attrs=(tiledb.Attr(\'a1\', dtype=np.float64),))\n        tiledb.Array.create(uri, schema)\n\n        # Write 10k cells every 1000 ns starting at time 0\n        coords = np.datetime64(0, \'ns\') + np.arange(0, 10000 * 1000, 1000)\n        a1_vals = np.random.rand(len(coords))\n        with tiledb.SparseArray(uri, \'w\', ctx=ctx) as T:\n            T[coords] = {\'a1\': a1_vals}\n\n        # Read all\n        with tiledb.SparseArray(uri, \'r\', ctx=ctx) as T:\n            assert_array_equal(T[:][\'a1\'], a1_vals)\n\n        # Read back first 10 cells\n        with tiledb.SparseArray(uri, \'r\', ctx=ctx) as T:\n            start = np.datetime64(0, \'ns\')\n            vals = T[start: start + np.timedelta64(10000, \'ns\')][\'a1\']\n            assert_array_equal(vals, a1_vals[0: 11])\n\n    def test_datetime_types(self):\n        ctx = tiledb.Ctx()\n\n        units = [\'h\', \'m\', \'s\', \'ms\', \'us\', \'ns\', \'ps\', \'fs\']\n\n        for res in units:\n            uri = self.path(""test_datetime_type_"" + res)\n\n            tmax = 1000\n            tile = np.timedelta64(1, res)\n\n            dim = tiledb.Dim(name=""d1"", ctx=ctx,\n                             domain=(np.datetime64(0, res), np.datetime64(tmax, res)),\n                             tile=tile, dtype=np.datetime64(\'\', res).dtype)\n\n            dom = tiledb.Domain(dim, ctx=ctx)\n            schema = tiledb.ArraySchema(ctx=ctx, domain=dom, sparse=True,\n                                        attrs=(tiledb.Attr(\'a1\', dtype=np.float64),))\n\n            tiledb.Array.create(uri, schema)\n\n            # Write tmax cells every 10 units starting at time 0\n            coords = np.datetime64(0, res) + np.arange(0, tmax, 10)  # np.arange(0, 10000 * 1000, 1000)\n            a1_vals = np.random.rand(len(coords))\n            with tiledb.SparseArray(uri, \'w\', ctx=ctx) as T:\n                T[coords] = {\'a1\': a1_vals}\n\n            # Read all\n            with tiledb.SparseArray(uri, \'r\', ctx=ctx) as T:\n                assert_array_equal(T[:][\'a1\'], a1_vals)\n\n            # Read back first 10 cells\n            with tiledb.SparseArray(uri, \'r\', ctx=ctx) as T:\n                start = np.datetime64(0, res)\n                vals = T[start: start + np.timedelta64(int(tmax/10), res)][\'a1\']\n                assert_array_equal(vals, a1_vals[0: 11])\n\n\nclass PickleTest(DiskTestCase):\n    # test that DenseArray and View can be pickled for multiprocess use\n    # note that the current pickling is by URI and attributes (it is\n    #     not, and likely should not be, a way to serialize array data)\n    def test_pickle_roundtrip(self):\n        import io, pickle\n\n        ctx = tiledb.Ctx()\n        uri = self.path(""foo"")\n        with tiledb.DenseArray.from_numpy(uri, np.random.rand(5), ctx=ctx) as T:\n            with io.BytesIO() as buf:\n                pickle.dump(T, buf)\n                buf.seek(0)\n                with pickle.load(buf) as T2:\n                    assert_array_equal(T, T2)\n\n            with io.BytesIO() as buf, tiledb.DenseArray(uri) as V:\n                pickle.dump(V, buf)\n                buf.seek(0)\n                with pickle.load(buf) as V2:\n                    # make sure anonymous view pickles and round-trips\n                    assert_array_equal(V, V2)\n\n    def test_pickle_with_config(self):\n        import io, pickle\n        opts = dict()\n        opts[\'vfs.s3.region\'] = \'kuyper-belt-1\'\n        opts[\'vfs.max_parallel_ops\'] = 1\n\n        config = tiledb.Config(params=opts)\n        ctx = tiledb.Ctx(config)\n\n        uri = self.path(""pickle_config"")\n        T = tiledb.DenseArray.from_numpy(uri, np.random.rand(3,3), ctx=ctx)\n\n        with io.BytesIO() as buf:\n            pickle.dump(T, buf)\n            buf.seek(0)\n            T2 = pickle.load(buf)\n            assert_array_equal(T, T2)\n            self.maxDiff = None\n            d1 = ctx.config().dict()\n            d2 = T2._ctx_().config().dict()\n            self.assertEqual(d1[\'vfs.s3.region\'], d2[\'vfs.s3.region\'])\n            self.assertEqual(d1[\'vfs.max_parallel_ops\'], d2[\'vfs.max_parallel_ops\'])\n        T.close()\n        T2.close()\n\n\nclass ArrayViewTest(DiskTestCase):\n    def test_view_multiattr(self):\n        import io, pickle\n        ctx = tiledb.Ctx()\n        uri = self.path(""foo_multiattr"")\n        dom = tiledb.Domain(tiledb.Dim(ctx=ctx, domain=(0, 2), tile=3),\n                            tiledb.Dim(ctx=ctx, domain=(0, 2), tile=3),\n                            ctx=ctx)\n        schema = tiledb.ArraySchema(ctx=ctx,\n                                    domain=dom,\n                                    attrs=(tiledb.Attr(""""), tiledb.Attr(""named"")))\n        tiledb.libtiledb.Array.create(uri, schema)\n\n        anon_ar = np.random.rand(3, 3)\n        named_ar = np.random.rand(3, 3)\n\n        with tiledb.DenseArray(uri, \'w\', ctx=ctx) as T:\n            T[:] = {\'\': anon_ar, \'named\': named_ar}\n\n        with self.assertRaises(KeyError):\n            T = tiledb.DenseArray(uri, \'r\', attr=""foo111"", ctx=ctx)\n\n        with tiledb.DenseArray(uri, \'r\', attr=""named"", ctx=ctx) as T:\n            assert_array_equal(T, named_ar)\n            # make sure each attr view can pickle and round-trip\n            with io.BytesIO() as buf:\n                pickle.dump(T, buf)\n                buf.seek(0)\n                with pickle.load(buf) as T_rt:\n                    assert_array_equal(T, T_rt)\n\n        with tiledb.DenseArray(uri, \'r\', attr="""", ctx=ctx) as T:\n            assert_array_equal(T, anon_ar)\n\n            with io.BytesIO() as buf:\n                pickle.dump(T, buf)\n                buf.seek(0)\n                with pickle.load(buf) as tmp:\n                    assert_array_equal(tmp, anon_ar)\n\n        # set subarray on multi-attribute\n        range_ar = np.arange(0,9).reshape(3,3)\n        with tiledb.DenseArray(uri, \'w\', attr=\'named\', ctx=ctx) as V_named:\n            V_named[1:3,1:3] = range_ar[1:3,1:3]\n\n        with tiledb.DenseArray(uri, \'r\', attr=\'named\', ctx=ctx) as V_named:\n            assert_array_equal(V_named[1:3,1:3], range_ar[1:3,1:3])\n\n\nclass RWTest(DiskTestCase):\n    def test_read_write(self):\n        ctx = tiledb.Ctx()\n\n        dom = tiledb.Domain(tiledb.Dim(ctx=ctx, domain=(0, 2), tile=3), ctx=ctx)\n        att = tiledb.Attr(ctx=ctx, dtype=\'int64\')\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,))\n        tiledb.libtiledb.Array.create(self.path(""foo""), schema)\n\n        np_array = np.array([1, 2, 3], dtype=\'int64\')\n\n        with tiledb.DenseArray(self.path(""foo""), mode=""w"", ctx=ctx) as arr:\n            arr.write_direct(np_array)\n\n        with tiledb.DenseArray(self.path(""foo""), mode=""r"", ctx=ctx) as arr:\n            safe_dump(arr)\n            self.assertEqual(arr.nonempty_domain(), ((0, 2),))\n            self.assertEqual(arr.ndim, np_array.ndim)\n            assert_array_equal(arr.read_direct(), np_array)\n\n\nclass NumpyToArray(DiskTestCase):\n\n    def test_to_array0d(self):\n        # Cannot create 0-dim arrays in TileDB\n        ctx = tiledb.Ctx()\n        np_array = np.array(1)\n        with self.assertRaises(tiledb.TileDBError):\n            with tiledb.DenseArray.from_numpy(self.path(""foo""), np_array, ctx=ctx) as A:\n                pass\n\n    def test_to_array1d(self):\n        ctx = tiledb.Ctx()\n        np_array = np.array([1.0, 2.0, 3.0])\n        with tiledb.DenseArray.from_numpy(self.path(""foo""), np_array, ctx=ctx) as arr:\n            assert_array_equal(arr[:], np_array)\n\n    def test_to_array2d(self):\n        ctx = tiledb.Ctx()\n        np_array = np.ones((100, 100), dtype=\'i8\')\n        with tiledb.DenseArray.from_numpy(self.path(""foo""), np_array, ctx=ctx) as arr:\n            assert_array_equal(arr[:], np_array)\n\n    def test_to_array3d(self):\n        ctx = tiledb.Ctx()\n        np_array = np.ones((1, 1, 1), dtype=\'i1\')\n        with tiledb.DenseArray.from_numpy(self.path(""foo""), np_array, ctx=ctx) as arr:\n            assert_array_equal(arr[:], np_array)\n\n    def test_bytes_to_array1d(self):\n        np_array = np.array([b\'abcdef\', b\'gh\', b\'ijkl\', b\'mnopqrs\', b\'\', b\'1234545lkjalsdfj\'], dtype=object)\n        with tiledb.DenseArray.from_numpy(self.path(""foo""), np_array) as arr:\n            assert_array_equal(arr[:], np_array)\n\n        with tiledb.DenseArray(self.path(""foo"")) as arr_reload:\n            assert_array_equal(arr_reload[:], np_array)\n\n    def test_unicode_to_array1d(self):\n        np_array = np.array([\'1234545lkjalsdfj\', \'mnopqrs\', \'ijkl\', \'gh\', \'abcdef\',\n                             \'a\xce\xb1b\xce\xb2\xce\xb2c\xce\xb3\xce\xb3\xce\xb3d\xce\xb4\xce\xb4\xce\xb4\xce\xb4\', \'""a\xce\xb1b\xce\xb2\xce\xb2c\', \'\', \'\xce\xb3\xce\xb3\xce\xb3d\xce\xb4\xce\xb4\xce\xb4\xce\xb4\'], dtype=object)\n        with tiledb.DenseArray.from_numpy(self.path(""foo""), np_array) as arr:\n            assert_array_equal(arr[:], np_array)\n\n        with tiledb.DenseArray(self.path(""foo"")) as arr_reload:\n            assert_array_equal(arr_reload[:], np_array)\n\n    def test_array_interface(self):\n        # Tests that __array__ interface works\n        ctx = tiledb.Ctx()\n        np_array1 = np.arange(1, 10)\n        with tiledb.DenseArray.from_numpy(self.path(""arr1""), np_array1, ctx=ctx) as arr1:\n            assert_array_equal(np.array(arr1), np_array1)\n\n        # Test that __array__ interface throws an error when number of attributes > 1\n        dom = tiledb.Domain(tiledb.Dim(ctx=ctx, domain=(0, 2), tile=3), ctx=ctx)\n        foo = tiledb.Attr(""foo"", dtype=\'i8\', ctx=ctx)\n        bar = tiledb.Attr(""bar"", dtype=\'i8\', ctx=ctx)\n        schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(foo, bar))\n        tiledb.DenseArray.create(self.path(""arr2""), schema)\n        with self.assertRaises(ValueError):\n            with tiledb.DenseArray(self.path(""arr2""), mode=\'r\', ctx=ctx) as arr2:\n                np.array(arr2)\n\n    def test_array_getindex(self):\n        # Tests that __getindex__ interface works\n        ctx = tiledb.Ctx()\n        np_array = np.arange(1, 10)\n        with tiledb.DenseArray.from_numpy(self.path(""foo""), np_array, ctx=ctx) as arr:\n            assert_array_equal(arr[5:10], np_array[5:10])\n\n    def test_to_array1d_attr_name(self):\n        ctx = tiledb.Ctx()\n        np_array = np.array([1.0, 2.0, 3.0])\n        with tiledb.DenseArray.from_numpy(self.path(""foo""), np_array, attr_name=\'a\', ctx=ctx) as arr:\n            assert_array_equal(arr[:][\'a\'], np_array)\n\nclass VFS(DiskTestCase):\n\n    def test_supports(self):\n        ctx = tiledb.Ctx()\n        vfs = tiledb.VFS(ctx=ctx)\n\n        self.assertTrue(vfs.supports(""file""))\n        self.assertIsInstance(vfs.supports(""s3""), bool)\n        self.assertIsInstance(vfs.supports(""hdfs""), bool)\n\n        with self.assertRaises(ValueError):\n            vfs.supports(""invalid"")\n\n    def test_dir(self):\n        ctx = tiledb.Ctx()\n        vfs = tiledb.VFS(ctx=ctx)\n\n        dir = self.path(""foo"")\n        self.assertFalse(vfs.is_dir(dir))\n\n        # create\n        vfs.create_dir(dir)\n        self.assertTrue(vfs.is_dir(dir))\n\n        # remove\n        vfs.remove_dir(dir)\n        self.assertFalse(vfs.is_dir(dir))\n\n        # create nested path\n        dir = self.path(""foo/bar"")\n        with self.assertRaises(tiledb.TileDBError):\n            vfs.create_dir(dir)\n\n        vfs.create_dir(self.path(""foo""))\n        vfs.create_dir(self.path(""foo/bar""))\n        self.assertTrue(vfs.is_dir(dir))\n\n    def test_file(self):\n        ctx = tiledb.Ctx()\n        vfs = tiledb.VFS(ctx=ctx)\n\n        file = self.path(""foo"")\n        self.assertFalse(vfs.is_file(file))\n\n        # create\n        vfs.touch(file)\n        self.assertTrue(vfs.is_file(file))\n\n        # remove\n        vfs.remove_file(file)\n        self.assertFalse(vfs.is_file(file))\n\n        # check nested path\n        file = self.path(""foo/bar"")\n        with self.assertRaises(tiledb.TileDBError):\n            vfs.touch(file)\n\n    def test_move(self):\n        ctx = tiledb.Ctx()\n        vfs = tiledb.VFS(ctx=ctx)\n\n        vfs.create_dir(self.path(""foo""))\n        vfs.create_dir(self.path(""bar""))\n        vfs.touch(self.path(""bar/baz""))\n\n        self.assertTrue(vfs.is_file(self.path(""bar/baz"")))\n\n        vfs.move_file(self.path(""bar/baz""), self.path(""foo/baz""))\n\n        self.assertFalse(vfs.is_file(self.path(""bar/baz"")))\n        self.assertTrue(vfs.is_file(self.path(""foo/baz"")))\n\n        # moving to invalid dir should raise an error\n        with self.assertRaises(tiledb.TileDBError):\n            vfs.move_dir(self.path(""foo/baz""), self.path(""do_not_exist/baz""))\n\n    def test_write_read(self):\n        ctx = tiledb.Ctx()\n        vfs = tiledb.VFS(ctx=ctx)\n\n        buffer = b""bar""\n        fh = vfs.open(self.path(""foo""), ""wb"")\n        vfs.write(fh, buffer)\n        vfs.close(fh)\n        self.assertEqual(vfs.file_size(self.path(""foo"")), 3)\n\n        fh = vfs.open(self.path(""foo""), ""rb"")\n        self.assertEqual(vfs.read(fh, 0, 3), buffer)\n        vfs.close(fh)\n\n        # write / read empty input\n        fh = vfs.open(self.path(""baz""), ""wb"")\n        vfs.write(fh, b"""")\n        vfs.close(fh)\n        self.assertEqual(vfs.file_size(self.path(""baz"")), 0)\n\n        fh = vfs.open(self.path(""baz""), ""rb"")\n        self.assertEqual(vfs.read(fh, 0, 0), b"""")\n        vfs.close(fh)\n\n        # read from file that does not exist\n        with self.assertRaises(tiledb.TileDBError):\n            vfs.open(self.path(""do_not_exist""), ""rb"")\n\n    def test_io(self):\n        ctx = tiledb.Ctx()\n        vfs = tiledb.VFS(ctx=ctx)\n\n        buffer = b""0123456789""\n        fio = tiledb.FileIO(vfs, self.path(""foo""), mode=""wb"")\n        fio.write(buffer)\n        fio.flush()\n        self.assertEqual(fio.tell(), len(buffer))\n\n        fio = tiledb.FileIO(vfs, self.path(""foo""), mode=""rb"")\n        with self.assertRaises(IOError):\n            fio.write(b""foo"")\n\n        self.assertEqual(vfs.file_size(self.path(""foo"")), len(buffer))\n\n        fio = tiledb.FileIO(vfs, self.path(""foo""), mode=\'rb\')\n        self.assertEqual(fio.read(3), b\'012\')\n        self.assertEqual(fio.tell(), 3)\n        self.assertEqual(fio.read(3), b\'345\')\n        self.assertEqual(fio.tell(), 6)\n        self.assertEqual(fio.read(10), b\'6789\')\n        self.assertEqual(fio.tell(), 10)\n\n        # seek from beginning\n        fio.seek(0)\n        self.assertEqual(fio.tell(), 0)\n        self.assertEqual(fio.read(), buffer)\n\n        # seek must be positive when SEEK_SET\n        with self.assertRaises(ValueError):\n            fio.seek(-1, 0)\n\n        # seek from current positfion\n        fio.seek(5)\n        self.assertEqual(fio.tell(), 5)\n        fio.seek(3, 1)\n        self.assertEqual(fio.tell(), 8)\n        fio.seek(-3, 1)\n        self.assertEqual(fio.tell(), 5)\n\n        # seek from end\n        fio.seek(-4, 2)\n        self.assertEqual(fio.tell(), 6)\n\n        # Test readall\n        fio.seek(0)\n        self.assertEqual(fio.readall(), buffer)\n        self.assertEqual(fio.tell(), 10)\n\n        fio.seek(5)\n        self.assertEqual(fio.readall(), buffer[5:])\n        self.assertEqual(fio.readall(), b"""")\n\n        # Reading from the end should return empty\n        fio.seek(0)\n        fio.read()\n        self.assertEqual(fio.read(), b"""")\n\n        # Test writing and reading lines with TextIOWrapper\n        lines = [rand_utf8(random.randint(0, 50))+\'\\n\' for _ in range(10)]\n        rand_uri = self.path(""test_fio.rand"")\n        with tiledb.FileIO(vfs, rand_uri, \'wb\') as f:\n            txtio = io.TextIOWrapper(f, encoding=\'utf-8\')\n            txtio.writelines(lines)\n            txtio.flush()\n\n        with tiledb.FileIO(vfs, rand_uri, \'rb\') as f2:\n            txtio = io.TextIOWrapper(f2, encoding=\'utf-8\')\n            self.assertEqual(txtio.readlines(), lines)\n\n    def test_ls(self):\n        import os\n        basepath = self.path(""test_vfs_ls"")\n        os.mkdir(basepath)\n        for id in (1,2,3):\n            dir = os.path.join(basepath, ""dir""+str(id))\n            os.mkdir(dir)\n            fname =os.path.join(basepath, ""file_""+str(id))\n            os.close(os.open(fname, os.O_CREAT | os.O_EXCL))\n\n        expected = (\'dir1\',\'dir2\',\'dir3\', \'file_1\', \'file_2\', \'file_3\')\n        vfs = tiledb.VFS(ctx=tiledb.Ctx())\n        self.assertSetEqual(\n            set(os.path.normpath(\n                \'file://\' + os.path.join(basepath, x)) for x in expected),\n            set(os.path.normpath(x) for x in vfs.ls(basepath))\n        )\n\nclass ConsolidationTest(DiskTestCase):\n\n    def test_array_vacuum(self):\n        ctx = tiledb.Ctx()\n        vfs = tiledb.VFS(ctx=ctx)\n        path = self.path(""test_array_vacuum"")\n\n        dshape = (0, 19)\n        num_writes = 10\n\n        def create_array(target_path):\n            dom = tiledb.Domain(tiledb.Dim(ctx=ctx, domain=dshape, tile=3), ctx=ctx)\n            att = tiledb.Attr(ctx=ctx, dtype=\'int64\')\n            schema = tiledb.ArraySchema(ctx=ctx, domain=dom, attrs=(att,))\n            tiledb.libtiledb.Array.create(target_path, schema)\n\n        def write_fragments(target_path):\n            for i in range(num_writes):\n                with tiledb.open(target_path, \'w\') as A:\n                    A[i:dshape[1]] = np.random.rand(dshape[1] - i)\n\n        create_array(path)\n        write_fragments(path)\n        paths = vfs.ls(path)\n        self.assertEqual(len(paths), 3 + 2 * num_writes)\n\n        tiledb.consolidate(path, ctx=ctx)\n        tiledb.vacuum(path, ctx=ctx)\n\n        paths = vfs.ls(path)\n        self.assertEqual(len(paths), 5)\n\n        del path\n\n        path2 = self.path(""test_array_vacuum_fragment_meta"")\n        create_array(path2)\n        write_fragments(path2)\n        tiledb.consolidate(path2,\n                           config=tiledb.Config({\'sm.consolidation.mode\': \'fragment_meta\'}))\n        tiledb.vacuum(path2,\n                      config=tiledb.Config({\'sm.vacuum.mode\': \'fragment_meta\'}))\n        paths = vfs.ls(path2)\n\n        self.assertEqual(len(paths), 3 + 2 * num_writes + 1)\n\nclass RegTests(DiskTestCase):\n    def test_tiledb_py_0_6_anon_attr(self):\n        # Test that anonymous attributes internally stored as ""__attr"" are presented as """"\n        # Normally, we can\'t actually write an attribute named ""__attr"" anymore, so we\n        # restore a schema written by a patched libtiledb, and rename the attr file.\n\n        schema_data = b\'\\x05\\x00\\x00\\x00]\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x01\\x05\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\x00\\x00\\x009\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00q\\x00\\x00\\x009\\x00\\x00\\x00x\\x01ce\\x80\\x00\\x01u(\\x83\\x81\\x11\\x08\\x19\\x18\\x98XA\\xc4\\x7f `\\xc0\\x10\\x01\\xc9\\x83p\\n\\x1b\\x88\\x84\\xb0\\x81\\x8a\\xc1l\\x88\\x00H\\x9c\\r\\x88\\xe3\\xe3\\x13KJ\\x8aP\\x94\\x01\\x00\\xa2c\\x0bD\'\n\n        path = self.path(""tiledb_py_0_6_anon_attr"")\n        ctx = tiledb.default_ctx()\n        dom = tiledb.Domain(tiledb.Dim(name=""d"", domain=(0, 0), tile=1, dtype=np.uint8))\n        attrs = (tiledb.Attr(name=""_attr_"", dtype=np.uint8, ctx=ctx),)\n\n        schema = tiledb.ArraySchema(domain=dom, attrs=attrs, sparse=False, ctx=ctx)\n        tiledb.DenseArray.create(path, schema, ctx=ctx)\n\n        with tiledb.open(path, \'w\') as A:\n            A[0] = 1\n\n        fragment_name = os.path.split(list(A.last_write_info.keys())[0])[-1]\n        fragment_path = os.path.join(path, fragment_name)\n\n        # fix up the array the override schema\n        with open(os.path.join(path, ""__array_schema.tdb""), \'wb\') as f:\n            f.write(schema_data)\n        import shutil\n        shutil.move(\n            os.path.join(fragment_path, ""_attr_.tdb""),\n            os.path.join(fragment_path, ""__attr.tdb"")\n        )\n\n        with tiledb.open(path) as A:\n            self.assertEqual(A.schema.attr(0).name, """")\n            self.assertEqual(A.schema.attr(0)._internal_name, ""__attr"")\n            self.assertEqual(A[0], 1)\n            mres = A.multi_index[0]\n            self.assertEqual(mres[\'\'], 1)\n            self.assertEqual(mres[\'d\'], 0)\n\nclass MemoryTest(DiskTestCase):\n    # sanity check that memory usage doesn\'t increase more than 2x when reading 40MB 100x\n    # https://github.com/TileDB-Inc/TileDB-Py/issues/150\n\n    def setUp(self):\n        super(MemoryTest, self).setUp()\n        import sys\n        if not sys.platform.startswith(""linux""):\n            self.skipTest(""Only run MemoryTest on linux"")\n\n    @staticmethod\n    def use_many_buffers(path):\n        import psutil, os\n        # https://stackoverflow.com/questions/938733/total-memory-used-by-python-process\n        process = psutil.Process(os.getpid())\n\n        x = np.ones(10000000, dtype=np.float32)\n        ctx = tiledb.Ctx()\n        d1 = tiledb.Dim(\n            \'test_domain\', domain=(0, x.shape[0] - 1), tile=10000, dtype=""uint32"")\n        domain = tiledb.Domain(d1)\n        v = tiledb.Attr(\n            \'test_value\',\n            dtype=""float32"")\n\n        schema = tiledb.ArraySchema(\n            domain=domain, attrs=(v,), cell_order=""row-major"", tile_order=""row-major"")\n\n        A = tiledb.DenseArray.create(path, schema)\n\n        with tiledb.DenseArray(path, mode=""w"", ctx=ctx) as A:\n            A[:] = {\'test_value\': x}\n\n        with tiledb.DenseArray(path, mode=\'r\') as data:\n            data[:]\n            initial = process.memory_info().rss\n            print(""  initial RSS: {}"".format(round(initial / (10 ** 6)), 2))\n            for i in range(100):\n                # read but don\'t store: this memory should be freed\n                data[:]\n\n                if i % 10 == 0:\n                    print(\'    read iter {}, RSS (MB): {}\'.format(\n                        i, round(process.memory_info().rss / (10 ** 6), 2)))\n\n        return initial\n\n    def test_memory_cleanup(self):\n        import tiledb, numpy as np\n        import psutil, os\n\n        # run function which reads 100x from a 40MB test array\n        # TODO: RSS is too loose to do this end-to-end, so should use instrumentation.\n        print(""Starting TileDB-Py memory test:"")\n        initial = self.use_many_buffers(self.path(\'test_memory_cleanup\'))\n\n        process = psutil.Process(os.getpid())\n        final = process.memory_info().rss\n        print(""  final RSS: {}"".format(round(final / (10 ** 6)), 2))\n\n        import gc\n        gc.collect()\n\n        final_gc = process.memory_info().rss\n        print(""  final RSS after forced GC: {}"".format(round(final_gc / (10 ** 6)), 2))\n\n        self.assertTrue(final < (2 * initial))\n\nhas_psutil = False\ntry:\n    import psutil\n    has_psutil = True\nexcept ImportError:\n    pass\n\nclass HighlevelTests(DiskTestCase):\n    def test_open(self):\n        uri = self.path(""test_open"")\n        with tiledb.from_numpy(uri, np.random.rand(10)) as A:\n            pass\n\n        ctx = tiledb.Ctx()\n        with tiledb.DenseArray(uri, ctx=ctx) as A:\n            self.assertEqual(A._ctx_(), ctx)\n\n        with tiledb.open(uri, ctx=ctx) as A:\n            self.assertEqual(A._ctx_(), ctx)\n\n        config = tiledb.Config()\n        with tiledb.open(uri, config=config) as A:\n            self.assertEqual(A._ctx_().config(), config)\n\n        with self.assertRaises(KeyError):\n            # This path must test `tiledb.open` specifically\n            # https://github.com/TileDB-Inc/TileDB-Py/issues/277\n            tiledb.open(uri, \'r\', attr=\'the-missing-attr\')\n\n    @unittest.skipIf(not has_psutil or \\\n                     sys.version_info < (3,2), """")\n    def test_ctx_thread_cleanup(self):\n        import warnings\n        # This test checks that contexts are destroyed correctly.\n        # It creates new contexts repeatedly, in-process, and\n        # checks that the total number of threads stays stable.\n        config = {\n            \'sm.num_reader_threads\': 128,\n        }\n        ll = list()\n        uri = self.path(""test_ctx_thread_cleanup"")\n        with tiledb.from_numpy(uri, np.random.rand(100)) as A:\n            pass\n\n        thisproc = psutil.Process(os.getpid())\n\n        for n in range(0, 10):\n            if n > 0:\n                retry = 0\n                while retry < 3:\n                    try:\n                        # checking exact thread count is unreliable, so\n                        # make sure we are holding < 2x per run.\n                        self.assertTrue(len(thisproc.threads()) < 2 * start_threads)\n                        break\n                    except AssertionError as exc:\n                            raise exc\n                    except RuntimeError as rterr:\n                        retry += 1\n                        if retry > 2:\n                            raise rterr\n                        warnings.warn(""Thread cleanup test RuntimeError: {} \\n    on iteration: {}"".format(str(rterr), n))\n\n            with tiledb.DenseArray(uri, ctx=tiledb.Ctx(config)) as A:\n                res = A[:]\n\n            if n == 0:\n                start_threads = len(thisproc.threads())\n\n# Wrapper to execute specific code in subprocess so that we can ensure the thread count\n# init is correct. Necessary because multiprocess.get_context is only available in Python 3.4+,\n# and the multiprocessing method may be set to fork by other tests (e.g. dask).\ndef init_test_wrapper(cfg=None):\n    import subprocess, os\n    python_exe = sys.executable\n    cmd = \'from test_libtiledb import *; init_test_helper({})\'.format(cfg)\n    test_path = os.path.dirname(os.path.abspath(__file__))\n\n    sp_output = subprocess.check_output([python_exe, \'-c\', cmd], cwd=test_path)\n    return int(sp_output.decode(\'UTF-8\').strip())\n\ndef init_test_helper(cfg=None):\n    import tiledb\n    tiledb.libtiledb.initialize_ctx(cfg)\n    num_tbb_threads = tiledb.default_ctx().config()[\'sm.num_tbb_threads\']\n    print(int(num_tbb_threads))\n\nclass ContextTest(unittest.TestCase):\n    def test_default_context(self):\n        ctx = tiledb.default_ctx()\n        self.assertIsInstance(ctx, tiledb.Ctx)\n        self.assertIsInstance(ctx.config(), tiledb.Config)\n\n    def test_init_config(self):\n        self.assertEqual(-1, init_test_wrapper())\n\n        self.assertEqual(\n            1,\n            init_test_wrapper({\'sm.num_tbb_threads\': 1})\n        )\n\n\nclass ReprTest(unittest.TestCase):\n    def test_attr_repr(self):\n        attr = tiledb.Attr(name=""itsanattr"", dtype=np.float64)\n        self.assertTrue(\n            re.match(r""Attr\\(name=[u]?\'itsanattr\', dtype=\'float64\'\\)"",\n                     repr(attr))\n        )\n\n        g = dict()\n        exec(""from tiledb import Attr; from numpy import float64"", g)\n        self.assertEqual(\n            eval(repr(attr), g),\n            attr\n        )\n\n    def test_arrayschema_repr(self):\n        ctx = tiledb.default_ctx()\n        for sparse in [False, True]:\n            domain = tiledb.Domain(\n                tiledb.Dim(domain=(1, 8), tile=2, ctx=ctx),\n                tiledb.Dim(domain=(1, 8), tile=2, ctx=ctx),\n                ctx=ctx)\n            a1 = tiledb.Attr(""val"", dtype=\'f8\', ctx=ctx)\n            orig_schema = tiledb.ArraySchema(domain=domain, attrs=(a1,), sparse=sparse, ctx=ctx)\n\n            schema_repr = repr(orig_schema)\n            g = dict()\n            setup = (""from tiledb import ArraySchema, Domain, Attr, Dim\\n""\n                     ""import numpy as np\\n"")\n\n            exec(setup, g)\n            new_schema = eval(schema_repr, g)\n\n            self.assertEqual(new_schema, orig_schema)\n\n#if __name__ == \'__main__\':\n#    # run a single example for in-process debugging\n#    # better to use `pytest --gdb` if available\n#    t = DenseArrayTest()\n#    t.setUp()\n#    t.test_array_1d()\n'"
tiledb/tests/test_metadata.py,19,"b'#%%\n\nimport tiledb\nfrom tiledb.libtiledb import ustring\nimport numpy as np\n\nimport unittest, os, time\nfrom tiledb.tests.common import *\n\nclass MetadataTest(DiskTestCase):\n\n    def test_metadata_basic(self):\n        path = self.path(""test_md_basic"")\n\n        with tiledb.from_numpy(path, np.ones((5,), np.float64)) as A:\n            pass\n\n        # sanity checks\n        A = tiledb.open(path)\n        A.close()\n\n        # can\'t read from a closed array\n        with self.assertRaises(tiledb.TileDBError):\n            A.meta[\'x\']\n\n        with tiledb.Array(path) as A:\n            # can\'t write to a mode=\'r\' array\n            with self.assertRaises(tiledb.TileDBError):\n                A.meta[\'invalid_write\'] = 1\n\n            # missing key raises KeyError\n            with self.assertRaises(KeyError):\n                 A.meta[\'xyz123nokey\']\n\n        # test invalid input\n        with tiledb.Array(path, \'w\') as A:\n            # keys must be strings\n            with self.assertRaises(ValueError):\n                A.meta[123] = 1\n\n            # can\'t write an int > typemax(Int64)\n            with self.assertRaises(OverflowError):\n                A.meta[\'bigint\'] = np.iinfo(np.int64).max + 1\n\n            # can\'t write mixed-type list\n            with self.assertRaises(TypeError):\n                A.meta[\'mixed_list\'] = [1, 2.1]\n\n            # can\'t write mixed-type tuple\n            with self.assertRaises(TypeError):\n                A.meta[\'mixed_list\'] = (0, 3.1)\n\n            # can\'t write objects\n            with self.assertRaises(ValueError):\n                A.meta[\'object\'] = object\n\n        test_vals = {\n            \'int\': 10,\n            \'double\': 1.000001212,\n            \'bytes\': b""0123456789abcdeF0123456789abcdeF"",\n            \'str\': ""abcdefghijklmnopqrstuvwxyz"",\n            \'emptystr\': """",\n            \'tuple_int\': (1,2,3,2,1, int(np.random.randint(0,10000,1)[0]) ),\n            \'list_int\': [1,2,3,2,1, int(np.random.randint(0,10000,1)[0]) ],\n            \'tuple_float\': (10.0, 11.0, float(np.random.rand(1)[0]) ),\n            \'list_float\': [10.0, 11.0, float(np.random.rand(1)[0]) ]\n        }\n\n        def tupleize(v):\n            if isinstance(v, list):\n                v = tuple(v)\n            return v\n\n        with tiledb.Array(path, mode=\'w\') as A:\n            for k,v in test_vals.items():\n                A.meta[k] = v\n\n        with tiledb.Array(path) as A:\n            for k,v in test_vals.items():\n                # metadata only has one iterable type: tuple, so we cannot\n                # perfectly round-trip the input type.\n\n                self.assertEqual(A.meta[k], tupleize(v))\n\n        # test dict-like functionality\n        with tiledb.Array(path) as A:\n            self.assertSetEqual(set(A.meta.keys()), set(test_vals.keys()))\n            self.assertFalse(\'gnokey\' in A.meta)\n            self.assertEqual(len(A.meta), len(test_vals))\n\n            for k,v in A.meta.items():\n                self.assertTrue(k in test_vals.keys())\n                self.assertEqual(tupleize(v), tupleize(test_vals[k]),)\n\n        # test a 1 MB blob\n        blob = np.random.rand(int((1024**2)/8)).tostring()\n        with tiledb.Array(path, \'w\') as A:\n            A.meta[\'bigblob\'] = blob\n\n        with tiledb.Array(path) as A:\n            self.assertEqual(A.meta[\'bigblob\'], blob)\n            self.assertEqual(len(A.meta), len(test_vals)+1)\n\n        # test del key\n        with tiledb.Array(path, \'w\') as A:\n            del A.meta[\'bigblob\']\n\n        with tiledb.Array(path) as A:\n            self.assertTrue(\'bigblob\' not in A.meta)\n            self.assertEqual(len(A.meta), len(test_vals))\n            with self.assertRaises(KeyError):\n                A.meta[\'bigblob\']\n\n        # test pop NotImplementedError\n        with tiledb.Array(path, \'w\') as A:\n            with self.assertRaises(NotImplementedError):\n                A.meta.pop(\'nokey\', \'hello!\')\n\n        # Note: this requires a work-around to check all keys\n        # test empty value\n        with tiledb.Array(path, \'w\') as A:\n            A.meta[\'empty_val\'] = ()\n\n        with tiledb.Array(path) as A:\n            self.assertTrue(\'empty_val\' in A.meta)\n            self.assertEqual(A.meta[\'empty_val\'], ())\n\n\n    def test_metadata_consecutive(self):\n        ctx = tiledb.Ctx({\n            \'sm.vacuum.mode\': \'array_meta\',\n            \'sm.consolidation.mode\': \'array_meta\'\n        })\n        vfs = tiledb.VFS(ctx=ctx)\n        path = self.path(""test_md_consecutive"")\n\n        write_count = 100\n\n        with tiledb.from_numpy(path, np.ones((5,), np.float64), ctx=ctx) as A:\n            pass\n\n        randints = np.random.randint(0,int(np.iinfo(np.int64).max) - 1,\n                                     size=write_count, dtype=np.int64)\n        randutf8s = [rand_utf8(i) for i in np.random.randint(1,30,size=write_count)]\n\n        # write 100 times, then consolidate\n        for i in range(write_count):\n            with tiledb.Array(path, mode=\'w\', ctx=ctx) as A:\n                A.meta[\'randint\'] = int(randints[i])\n                A.meta[\'randutf8\'] = randutf8s[i]\n                time.sleep(0.001)\n\n        with tiledb.Array(path) as A:\n            self.assertEqual(A.meta[\'randint\'], randints[-1])\n            self.assertEqual(A.meta[\'randutf8\'], randutf8s[-1])\n\n        with tiledb.Array(path, mode=\'w\', ctx=ctx) as aw:\n            aw.meta.consolidate()\n\n        with tiledb.Array(path) as A:\n            self.assertEqual(A.meta[\'randint\'], randints[-1])\n            self.assertEqual(A.meta[\'randutf8\'], randutf8s[-1])\n\n        # use randutf8s as keys, then consolidate\n        for _ in range(2):\n            for i in range(write_count):\n                with tiledb.Array(path, mode=\'w\') as A:\n                    A.meta[randutf8s[i] + u\'{}\'.format(randints[i])] = int(randints[i])\n                    A.meta[randutf8s[i]] = randutf8s[i]\n                    time.sleep(0.001)\n\n        # test data\n        with tiledb.Array(path, ctx=ctx) as A:\n            for i in range(write_count):\n                key_int = randutf8s[i] + u\'{}\'.format(randints[i])\n                self.assertEqual(A.meta[key_int], randints[i])\n                self.assertEqual(A.meta[randutf8s[i]], randutf8s[i])\n\n        # test expected number of fragments before consolidating\n        self.assertEqual(\n            len( vfs.ls(os.path.join(path, ""__meta"")) ),\n            302\n            )\n\n        with tiledb.Array(path, mode=\'w\', ctx=ctx) as A:\n            A.meta.consolidate()\n\n        # test expected number of fragments before vacuuming\n        self.assertEqual(\n            len( vfs.ls(os.path.join(path, ""__meta"")) ),\n            304\n            )\n\n        tiledb.vacuum(path, ctx=ctx)\n\n        # should only have one fragment+\'.ok\' after vacuuming\n        self.assertEqual(\n            len( vfs.ls(os.path.join(path, ""__meta"")) ),\n            1\n            )\n\n        # test data again after consolidation\n        with tiledb.Array(path, ctx=ctx) as A:\n            for i in range(write_count):\n                key_int = randutf8s[i] + u\'{}\'.format(randints[i])\n                self.assertEqual(A.meta[key_int], randints[i])\n                self.assertEqual(A.meta[randutf8s[i]], randutf8s[i])\n\n    def test_metadata_small_dtypes(self):\n        path = self.path(""test_md_small_dtypes"")\n\n        with tiledb.from_numpy(path, np.arange(1)) as A:\n            pass\n\n        test_vals = {\n            ""np.int8"": np.array((-1,), dtype=np.int8),\n            ""np.uint8"": np.array((2,), dtype=np.uint8),\n            ""np.int16"": np.array((-3,), dtype=np.int16),\n            ""np.uint16"": np.array((4,), dtype=np.uint16),\n            ""np.int32"": np.array((-5,), dtype=np.int32),\n            ""np.uint32"": np.array((6,), dtype=np.uint32),\n            ""np.float32"": np.array((-7.0,), dtype=np.float32)\n        }\n\n        with tiledb.Array(path, \'w\') as A:\n            for k,v in test_vals.items():\n                A.meta._set_numpy(k, v)\n\n        # note: the goal here is to test read-back of these datatypes,\n        #       which is currently done as int for all types\n        with tiledb.Array(path) as A:\n            for k,v in test_vals.items():\n                self.assertEqual(A.meta[k], int(v))\n'"
tiledb/tests/test_multi_index.py,50,"b'""""""\nTODO\n- # implement mock of expected behavior in pure numpy w/ test function\n\n\n- implement read function and tests (single [x], multi-attribute [ ])\n- implement custom indexer\n- implement oindex...\n""""""\n\nimport tiledb\nfrom tiledb.multirange_indexing import *\nimport os, numpy as np\nimport sys\n\nfrom numpy.testing import assert_array_equal\nimport unittest\nfrom tiledb.tests.common import *\n\ndef make_1d_dense(ctx, path, attr_name=\'\'):\n    a_orig = np.arange(36)\n\n    dom = tiledb.Domain(tiledb.Dim(domain=(0, 35), tile=35, dtype=np.uint64, ctx=ctx),\n                        ctx=ctx)\n    att = tiledb.Attr(name=attr_name, dtype=np.int64, ctx=ctx)\n    schema = tiledb.ArraySchema(domain=dom, attrs=(att,), sparse=False, ctx=ctx)\n    tiledb.DenseArray.create(path, schema)\n\n    with tiledb.DenseArray(path, \'w\') as A:\n        A[:] = a_orig\n\n\ndef make_2d_dense(ctx, path, attr_name=\'\'):\n    a_orig = np.arange(1,37).reshape(9, 4)\n\n    dom = tiledb.Domain(tiledb.Dim(domain=(0, 8), tile=9, dtype=np.uint64, ctx=ctx),\n                        tiledb.Dim(domain=(0, 3), tile=4, dtype=np.uint64, ctx=ctx),\n                        ctx=ctx)\n    att = tiledb.Attr(name=attr_name, dtype=np.int64, ctx=ctx)\n    schema = tiledb.ArraySchema(domain=dom, attrs=(att,), sparse=False, ctx=ctx)\n    tiledb.DenseArray.create(path, schema)\n\n    with tiledb.DenseArray(path, \'w\') as A:\n        A[:] = a_orig\n\nclass TestMultiRange(DiskTestCase):\n\n    def test_multirange_1d_1dim_ranges(self):\n        path = self.path(\'test_multirange_1d_1dim_ranges\')\n        attr_name = \'a\'\n\n        ctx = tiledb.Ctx()\n        make_1d_dense(ctx, path, attr_name=attr_name)\n\n        expected = np. array([0],\n                             dtype=np.uint64)\n\n\n        with tiledb.DenseArray(path) as A:\n            ranges = ( ((0, 0),), )\n            expected = np.array([0], dtype=np.int64)\n            a = tiledb.libtiledb.multi_index(A, (attr_name,), ranges)[attr_name]\n            assert_array_equal(a, expected)\n            self.assertEqual(a.dtype, expected.dtype)\n\n            #===\n        #with tiledb.DenseArray(path) as A:\n            ranges2 = ( ((1, 1), (5,8)), )\n            expected2 = np.array([1,5,6,7,8], dtype=np.int64)\n            a2 = tiledb.libtiledb.multi_index(A, (attr_name,), ranges2)[attr_name]\n            assert_array_equal(a2, expected2)\n            self.assertEqual(a2.dtype, expected2.dtype)\n\n    def test_multirange_2d_1dim_ranges(self):\n        path = self.path(\'test_multirange_1dim_ranges\')\n        attr_name = \'a\'\n\n        ctx = tiledb.Ctx()\n        make_2d_dense(ctx, path, attr_name=attr_name)\n\n        expected = np. array([ 1,  2,  3,  4,\n                               21, 22, 23, 24,\n                               25, 26, 27, 28,\n                               29, 30, 31, 32, 33,\n                               34, 35, 36],\n                             dtype=np.uint64)\n\n        ranges = (\n            ( (0, 0), (5,8), ),\n        )\n\n        with tiledb.DenseArray(path) as A:\n            a = tiledb.libtiledb.multi_index(A, (attr_name,), ranges)[attr_name]\n\n            assert_array_equal(a, expected)\n\n    def test_multirange_2d_2dim_ranges(self):\n        ctx = tiledb.Ctx()\n        path = self.path(\'test_multirange_2dim_ranges\')\n        attr_name = \'a\'\n\n        make_2d_dense(ctx, path, attr_name=attr_name)\n\n        expected = np.array([1, 2, 3, 4,\n                             5, 6, 7, 8,\n                             9, 10, 11, 12,\n                             13, 14, 15, 16,\n                             17, 18, 19, 20])\n\n        ranges = (\n            ( (0,4), ),\n            ( (0,3), )\n        )\n\n        with tiledb.DenseArray(path) as A:\n            a = tiledb.libtiledb.multi_index(A, (attr_name,), ranges)[attr_name]\n            assert_array_equal(a, expected)\n\n\n    def test_shape_funcs(self):\n        #-----------\n        range1el = ( ((1,1),), )\n        self.assertEqual(\n            mr_dense_result_shape(range1el),\n            (1,))\n        self.assertEqual(\n            mr_dense_result_numel(range1el),\n            1)\n\n        #-----------\n        range1d = tuple([((1, 2), (4, 4))])\n        self.assertEqual(\n            mr_dense_result_shape(range1d),\n            (3,))\n        self.assertEqual(\n            mr_dense_result_numel(range1d),\n            3\n        )\n\n        #-----------\n        range2d1 = (\n            ( (3,6), (7,7), (10,12) ),\n            ( (5,7), ),\n        )\n\n        self.assertEqual(\n            mr_dense_result_shape(range2d1),\n            (8,3)\n        )\n        self.assertEqual(\n            mr_dense_result_numel(range2d1),\n            24\n        )\n\n        #-----------\n        range2d2 = (\n            [(3,6), (7,7), (10,12)],\n            [(5,7), (10,10)]\n        )\n\n    def test_3d(self):\n        range3d1 = (\n            ( (2,4), ),\n            ( (3,6), ),\n            ( (1,4), (5,9) )\n        )\n\n        #self.assertEqual()\n\n    def test_sel_to_ranges(self):\n        class Obj(object): pass\n        class IBI(object):\n            def __getitem__(self, idx):\n                return idx\n\n        def make_arr(ndim):\n            arr = Obj()\n            arr.schema = Obj()\n            arr.schema.domain = Obj()\n            arr.schema.domain.ndim = ndim\n            return arr\n\n        ibi = IBI()\n        # ndim = 1\n        arr = make_arr(1)\n        m = MultiRangeIndexer.__test_init__(arr)\n        self.assertEqual(\n            m.getitem_ranges( ibi[[1]] ),\n            (((1, 1),),)\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[[1, 2]] ),\n            (((1, 1), (2, 2)),)\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[slice(1, 2)], ),\n            (((1, 2),),)\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[1:2, 3:5] ),\n            (((1, 2),), ((3, 5),),)\n        )\n\n        # ndim = 2\n        arr2 = make_arr(2)\n        m = MultiRangeIndexer.__test_init__(arr2)\n\n        self.assertEqual(\n            m.getitem_ranges( ibi[[1]] ),\n            (((1, 1),), ())\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[slice(1, 33)] ),\n            (((1, 33),), ())\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[ [1, 2], [1], slice(1, 3) ] ),\n            (((1, 1), (2, 2)), ((1, 1),), ((1, 3),))\n        )\n\n        # ndim = 3\n        arr3 = make_arr(3)\n        m = MultiRangeIndexer.__test_init__(arr3)\n\n        self.assertEqual(\n            m.getitem_ranges( ibi[1, 2, 3] ),\n            (\n                ((1, 1),), ((2, 2,),), ((3, 3),)\n            )\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[1, 2] ),\n            (\n                (((1, 1),), ((2, 2,),), ())\n            )\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[1:2, 3:4]),\n            (((1, 2),), ((3, 4),), ())\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[1:2, 3:4, 5:6] ),\n            (((1, 2),), ((3, 4),), ((5, 6),))\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[[1], [2], [5, 6]] ),\n            (((1, 1),), ((2, 2),), ((5, 5), (6, 6),))\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[1, [slice(3, 6), 8], slice(4, 6)] ),\n            (\n                ((1, 1),),\n                ((3, 6), (8, 8)),\n                ((4, 6),)\n            )\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[ (1,2) ]),\n            (\n                ((1,1),),\n                ((2,2),),\n                (),\n            )\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[ [(1,2)] ]),\n            (\n                ((1,2),),\n                (),\n                (),\n            )\n        )\n        self.assertEqual(\n            m.getitem_ranges( ibi[ [ (1,2), 4], [slice(1,4)] ] ),\n            (\n                ((1,2), (4,4)),\n                ((1,4),),\n                ()\n            )\n        )\n\n\n    def test_multirange_1d_dense_int64(self):\n        attr_name = \'\'\n        ctx = tiledb.Ctx()\n        path = self.path(\'multi_index_1d\')\n\n        dom = tiledb.Domain(tiledb.Dim(name=\'coords\', domain=(-10, 10), tile=9,\n                                       dtype=np.int64, ctx=ctx),\n                            ctx=ctx)\n        att = tiledb.Attr(name=attr_name, dtype=np.float32, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, attrs=(att,), ctx=ctx)\n        tiledb.DenseArray.create(path, schema)\n\n        orig_array = np.random.rand(schema.domain.dim(0).size).astype(np.float32)\n        with tiledb.open(path, \'w\') as A:\n            A[:] = orig_array\n\n        with tiledb.open(path) as A:\n            # stepped ranges are not supported\n            with self.assertRaises(ValueError):\n                A.multi_index[ 1::2 ]\n\n            assert_array_equal(\n                orig_array[ [0,-1] ],\n                A.multi_index[ [-10,10] ][attr_name]\n            )\n            self.assertEqual(\n                orig_array[0],\n                A.multi_index[-10][attr_name]\n            )\n            self.assertEqual(\n                -10,\n                A.multi_index[-10][\'coords\'].view(\'i8\')\n            )\n            assert_array_equal(\n                orig_array[0:],\n                A.multi_index[ [(-10, 10)] ][attr_name]\n            )\n            assert_array_equal(\n                orig_array[0:],\n                A.multi_index[ [slice(-10, 10),] ][attr_name]\n            )\n            assert_array_equal(\n                orig_array[0:10],\n                A.multi_index[ -10:np.int64(-1) ][attr_name]\n            )\n\n\n    def test_multirange_1d_sparse_double(self):\n        attr_name = \'\'\n        ctx = tiledb.Ctx()\n        path = self.path(\'mr_1d_sparse_double\')\n\n        dom = tiledb.Domain(tiledb.Dim(name=\'coords\', domain=(0, 30), tile=10,\n                                       dtype=np.float64, ctx=ctx),\n                            ctx=ctx)\n        att = tiledb.Attr(name=attr_name, dtype=np.float64, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, sparse=True, attrs=(att,), ctx=ctx)\n        tiledb.SparseArray.create(path, schema)\n\n        coords = np.linspace(0,30, num=31)\n        orig_array = np.random.rand(coords.size)\n\n        with tiledb.open(path, \'w\') as A:\n            A[coords] = orig_array\n\n        with tiledb.open(path) as A:\n            assert_array_equal(\n                orig_array[ [0] ],\n                A.multi_index[ [0] ][attr_name]\n            )\n            assert_array_equal(\n                orig_array[-1],\n                A.multi_index[30][attr_name]\n            )\n            assert_array_equal(\n                orig_array[-1],\n                A.multi_index[30.0][attr_name]\n            )\n            assert_array_equal(\n                orig_array[coords.size-3:coords.size],\n                A.multi_index[(28.0,30.0),][attr_name]\n            )\n            res = A.multi_index[ slice(0,5) ]\n            assert_array_equal(\n                orig_array[0:6],\n                res[attr_name]\n            )\n            assert_array_equal(\n                coords[0:6],\n                res[\'coords\'].astype(np.float64)\n            )\n\n\n    def test_multirange_2d_sparse_domain_utypes(self):\n        attr_name = \'foo\'\n        ctx = tiledb.Ctx()\n\n        types = (np.uint8, np.uint16, np.uint32, np.uint64)\n\n        for dtype in types:\n            min = 0\n            max = int(np.iinfo(dtype).max) - 1\n            path = self.path(\'multi_index_2d_sparse_\' + str(dtype.__name__))\n\n            dom = tiledb.Domain(tiledb.Dim(domain=(min, max), tile=1,\n                                           dtype=dtype, ctx=ctx),\n                                ctx=ctx)\n\n            att = tiledb.Attr(name=attr_name, dtype=dtype, ctx=ctx)\n            schema = tiledb.ArraySchema(domain=dom, sparse=True, attrs=(att,), ctx=ctx)\n            tiledb.SparseArray.create(path, schema)\n\n            coords = intspace(min, max, num=100, dtype=dtype)\n\n            with tiledb.open(path, \'w\') as A:\n                A[coords] = coords\n\n            with tiledb.open(path) as A:\n\n                res = A.multi_index[slice(coords[0], coords[-1])]\n                assert_array_equal(\n                    res[attr_name],\n                    coords\n                )\n                assert_array_equal(\n                    res[\'__dim_0\'].astype(dtype),\n                    coords\n                )\n\n                res = A.multi_index[coords[0]]\n                assert_array_equal(\n                    res[attr_name],\n                    coords[0]\n                )\n                assert_array_equal(\n                    res[\'__dim_0\'].astype(dtype),\n                    coords[0]\n                )\n\n                res = A.multi_index[coords[-1]]\n                assert_array_equal(\n                    res[attr_name],\n                    coords[-1]\n                )\n                assert_array_equal(\n                    res[\'__dim_0\'].astype(dtype),\n                    coords[-1]\n                )\n\n                midpoint = len(coords)//2\n                start = midpoint-20\n                stop = midpoint+20\n                srange = slice(coords[start], coords[stop])\n                res = A.multi_index[ srange ]\n                assert_array_equal(\n                    res[attr_name],\n                    coords[start:stop+1])\n                assert_array_equal(\n                    res[\'__dim_0\'].astype(dtype),\n                    coords[start:stop+1])\n\n    def test_multirange_2d_sparse_float(self):\n        attr_name = \'\'\n        ctx = tiledb.Ctx()\n        path = self.path(\'mr_2d_sparse_float\')\n\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, 10), tile=1,\n                                       dtype=np.float32, ctx=ctx),\n                            tiledb.Dim(domain=(0, 10), tile=1,\n                                       dtype=np.float32, ctx=ctx),\n                            ctx=ctx)\n        att = tiledb.Attr(name=attr_name, dtype=np.float64, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, attrs=(att,), sparse=True, ctx=ctx)\n        tiledb.SparseArray.create(path, schema)\n\n        orig_array = np.random.rand(11,11)\n        d1 = np.linspace(0, 10, num=11, dtype=np.float32)\n        d2 = np.linspace(0, 10, num=11, dtype=np.float32)\n        coords_d1,coords_d2 = np.meshgrid(d1,d2,indexing=\'ij\')\n\n        with tiledb.open(path, \'w\') as A:\n            A[coords_d1.flatten(),coords_d2.flatten()] = orig_array\n\n        with tiledb.open(path) as A:\n            res = A.multi_index[[0], :]\n            assert_array_equal(\n                orig_array[[0], :].squeeze(),\n                res[attr_name]\n            )\n            assert_array_equal(\n                coords_d1[0, :],\n                res[\'__dim_0\']\n            )\n\n            #===\n            res = A.multi_index[10, :]\n            assert_array_equal(\n                orig_array[[-1], :].squeeze(),\n                res[attr_name]\n            )\n            assert_array_equal(\n                coords_d2[[-1], :].squeeze(),\n                res[\'__dim_1\']\n            )\n\n            #===\n            res = A.multi_index[ [ slice(0,2), [5]] ]\n            assert_array_equal(\n                np.vstack([orig_array[0:3,:], orig_array[5,:]]).flatten(),\n                res[attr_name]\n            )\n            assert_array_equal(\n                np.vstack((coords_d1[0:3], coords_d1[5])).flatten(),\n                res[\'__dim_0\']\n            )\n\n            #===\n            res = A.multi_index[ slice(0.0, 2.0), slice(2.0, 5.0) ]\n            assert_array_equal(\n                orig_array[0:3,2:6].flatten(),\n                res[attr_name]\n            )\n            assert_array_equal(\n                coords_d1[0:3,2:6].flatten(),\n                res[\'__dim_0\']\n            )\n            assert_array_equal(\n                coords_d2[0:3,2:6].flatten(),\n                res[\'__dim_1\']\n            )\n            res = A.multi_index[ slice(np.float32(0.0), np.float32(2.0)), slice(np.float32(2.0), np.float32(5.0)) ]\n            assert_array_equal(\n                orig_array[0:3,2:6].flatten(),\n                res[attr_name]\n            )\n            assert_array_equal(\n                coords_d1[0:3,2:6].flatten(),\n                res[\'__dim_0\']\n            )\n            assert_array_equal(\n                coords_d2[0:3,2:6].flatten(),\n                res[\'__dim_1\']\n            )\n\n    def test_multirange_1d_sparse_query(self):\n        ctx = tiledb.Ctx()\n        path = self.path(\'mr_1d_sparse_query\')\n\n        dom = tiledb.Domain(tiledb.Dim(name=\'coords\', domain=(-100, 100),\n                                       tile=1, dtype=np.float32, ctx=ctx),\n                            ctx=ctx)\n        attrs = [tiledb.Attr(name=""U"", dtype=np.float64, ctx=ctx),\n                 tiledb.Attr(name=""V"", dtype=np.uint32, ctx=ctx)]\n\n        schema = tiledb.ArraySchema(domain=dom, attrs=attrs, sparse=True, ctx=ctx)\n        tiledb.SparseArray.create(path, schema)\n\n        U = np.random.rand(11)\n        V = np.random.randint(0,np.iinfo(np.uint32).max, 11, dtype=np.uint32)\n\n        coords = np.linspace(-10, 10, num=11, dtype=np.float32)\n        data = {\'U\':  U,\n                \'V\':  V}\n\n        with tiledb.open(path, \'w\') as A:\n            A[coords] = data\n\n        with tiledb.open(path) as A:\n            for k,d in data.items():\n                Q = A.query(attrs=k)\n                res = Q.multi_index[[-10]]\n                assert_array_equal(\n                    d[[0]],\n                    res[k]\n                )\n                assert_array_equal(\n                    coords[[0]],\n                    res[\'coords\'].view(\'f4\')\n                )\n\n                res = A.multi_index[10, :]\n                assert_array_equal(\n                    d[[-1]].squeeze(),\n                    res[k]\n                )\n                assert_array_equal(\n                    coords[[-1]],\n                    res[\'coords\'].view(\'f4\')\n                )\n\n                res = A.multi_index[ [ slice(coords[0],coords[2]), [coords[-1]]] ]\n                assert_array_equal(\n                    np.hstack([ d[0:3], d[-1] ]),\n                    res[k]\n                )\n\n    def test_multirange_1d_dense_vectorized(self):\n        ctx = tiledb.Ctx()\n        path = self.path(\'mr_1d_dense_vectorized\')\n\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, 999), tile=1000,\n                                       dtype=np.uint32, ctx=ctx),\n                            ctx=ctx)\n        attrs = tiledb.Attr(name=""U"", dtype=np.float64, ctx=ctx)\n\n        schema = tiledb.ArraySchema(domain=dom, attrs=(attrs,), sparse=False, ctx=ctx)\n        tiledb.DenseArray.create(path, schema)\n\n        data = np.random.rand(1000)\n        with tiledb.DenseArray(path, \'w\') as A:\n            A[0] = data[0]\n            A[-1] = data[-1]\n            A[:] = data\n\n        for _ in range(0,50):\n            with tiledb.DenseArray(path) as A:\n                idxs = random.sample(range(0, 999), k=100)\n                res = A.multi_index[idxs]\n                assert_array_equal(\n                    data[idxs],\n                    res[\'U\']\n                )\n\n    def test_multirange_2d_dense_float(self):\n        attr_name = \'\'\n        ctx = tiledb.Ctx()\n        path = self.path(\'multirange_2d_dense_float\')\n\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, 10), tile=1,\n                                       dtype=np.int64, ctx=ctx),\n                            tiledb.Dim(domain=(0, 10), tile=1,\n                                       dtype=np.int64, ctx=ctx),\n                            ctx=ctx)\n        att = tiledb.Attr(name=attr_name, dtype=np.float64, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, attrs=(att,), sparse=False, ctx=ctx)\n        tiledb.DenseArray.create(path, schema)\n\n        orig_array = np.random.rand(11,11)\n\n        with tiledb.open(path, \'w\') as A:\n            A[:] = orig_array\n\n        with tiledb.open(path) as A:\n            assert_array_equal(\n                orig_array[[0], :],\n                A.multi_index[[0], :][attr_name]\n            )\n\n            assert_array_equal(\n                orig_array[[-1,-1], :],\n                A.multi_index[[10,10], :][attr_name]\n            )\n            assert_array_equal(\n                orig_array[0:4,7:10],\n                A.multi_index[[(0,3)], slice(7,9)][attr_name]\n            )\n            # TODO this should be an error to match NumPy 1.12 semantics\n            #assert_array_equal(\n            #    orig_array[0:4,7:10],\n            #    A.multi_index[[(np.float64(0),np.float64(3.0))], slice(7,9)][attr_name]\n            #)\n'"
tiledb/tests/test_pandas_dataframe.py,31,"b'from __future__ import absolute_import\n\ntry:\n    import pandas as pd\n    import pandas._testing as tm\n\n    import_failed = False\nexcept ImportError:\n    import_failed = True\n\nimport unittest, os\nimport warnings\nimport string, random\nimport numpy as np\nfrom numpy.testing import assert_array_equal, assert_array_almost_equal\n\nimport tiledb\nfrom tiledb.tests.common import *\n\nif (sys.version_info > (3,0)):\n    str_type = str\nelse:\n    str_type = unicode\n\ndef make_dataframe_basic1(col_size=10):\n    # ensure no duplicates when using as string dim\n    chars = list()\n    for _ in range(col_size):\n        next = rand_ascii_bytes(2)\n        while next in chars:\n            next = rand_ascii_bytes(2)\n        chars.append(next)\n\n    data_dict = {\n        \'time\': rand_datetime64_array(col_size),\n        \'x\': np.array([rand_ascii(4).encode(\'UTF-8\') for _ in range(col_size)]),\n        \'chars\': np.array(chars),\n        \'cccc\': np.arange(0, col_size),\n\n        \'q\': np.array([rand_utf8(np.random.randint(1, 100)) for _ in range(col_size)]),\n        \'t\': np.array([rand_utf8(4) for _ in range(col_size)]),\n\n        \'r\': np.array([rand_ascii_bytes(np.random.randint(1, 100)) for _ in range(col_size)]),\n        \'s\': np.array([rand_ascii() for _ in range(col_size)]),\n        \'u\': np.array([rand_ascii_bytes() for _ in range(col_size)]),\n        \'v\': np.array([rand_ascii_bytes() for _ in range(col_size)]),\n\n        \'vals_int64\': np.random.randint(dtype_max(np.int64), size=col_size, dtype=np.int64),\n        \'vals_float64\': np.random.rand(col_size),\n    }\n\n    # TODO: dump this dataframe to pickle/base64 so that it can be reconstructed if\n    #       there are weird failures on CI?\n\n    df = pd.DataFrame.from_dict(data_dict)\n    return df\n\ndef make_dataframe_basic2():\n    # This code is from Pandas feather i/o tests ""test_basic"" function:\n    #   https://github.com/pandas-dev/pandas/blob/master/pandas/tests/io/test_feather.py\n    # (available under BSD 3-clause license\n    #   https://github.com/pandas-dev/pandas/blob/master/LICENSE\n\n    import pandas as pd\n\n    df = pd.DataFrame(\n        {\n            ""string"": list(""abc""),\n            ""int"": list(range(1, 4)),\n            ""uint"": np.arange(3, 6).astype(""u1""),\n            ""float"": np.arange(4.0, 7.0, dtype=""float64""),\n            # TODO ""float_with_null"": [1.0, np.nan, 3],\n            ""bool"": [True, False, True],\n            # TODO ""bool_with_null"": [True, np.nan, False],\n            #""cat"": pd.Categorical(list(""abc"")),\n            ""dt"": pd.date_range(""20130101"", periods=3),\n            #""dttz"": pd.date_range(""20130101"", periods=3, tz=""US/Eastern""),\n            #""dt_with_null"": [\n            #    pd.Timestamp(""20130101""),\n            #    pd.NaT,\n            #    pd.Timestamp(""20130103""),\n            #],\n            ""dtns"": pd.date_range(""20130101"", periods=3, freq=""ns""),\n        }\n    )\n\n    return df\n\ndef make_dataframe_basic3(col_size=10, time_range=(None,None)):\n    df_dict = {\n        \'time\': rand_datetime64_array(col_size, start=time_range[0], stop=time_range[1]),\n        \'double_range\': np.linspace(-1000, 1000, col_size),\n        \'int_vals\': np.random.randint(dtype_max(np.int64), size=col_size, dtype=np.int64)\n        }\n    df = pd.DataFrame(df_dict)\n    return df\n\nclass PandasDataFrameRoundtrip(DiskTestCase):\n    def setUp(self):\n        if import_failed:\n            self.skipTest(""Pandas not available"")\n        else:\n            super(PandasDataFrameRoundtrip, self).setUp()\n\n    def test_dataframe_basic_rt1_manual(self):\n\n        uri = self.path(""dataframe_basic_rt1_manual"")\n\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(name=""i_chars"",\n                                       domain=(0, 10000),\n                                       tile=10,\n                                       dtype=np.uint64),\n                            tiledb.Dim(name=""datetime"",\n                                       domain=(0, np.iinfo(np.uint64).max - 3600 * 1000000000),\n                                       tile=3600 * 1000000000,\n                                       dtype=np.uint64),\n                            tiledb.Dim(name=""cccc"",\n                                       domain=(0, dtype_max(np.uint64) - 1),\n                                       tile=dtype_max(np.uint64),\n                                       dtype=np.uint64),\n                            ctx=ctx)\n\n        compression = tiledb.FilterList([tiledb.ZstdFilter(level=-1)])\n        attrs = [\n            tiledb.Attr(name=""x"", dtype=\'S\', filters=compression, ctx=ctx),\n            tiledb.Attr(name=""chars"", dtype=\'|S2\', filters=compression, ctx=ctx),\n\n            tiledb.Attr(name=""q"", dtype=\'U\', filters=compression, ctx=ctx),\n            tiledb.Attr(name=""r"", dtype=\'S\', filters=compression, ctx=ctx),\n            tiledb.Attr(name=""s"", dtype=\'U\', filters=compression, ctx=ctx),\n            tiledb.Attr(name=""vals_int64"", dtype=np.int64, filters=compression, ctx=ctx),\n            tiledb.Attr(name=""vals_float64"", dtype=np.float64, filters=compression, ctx=ctx),\n            tiledb.Attr(name=""t"", dtype=\'U\', filters=compression, ctx=ctx),\n            tiledb.Attr(name=""u"", dtype=\'S\', filters=compression, ctx=ctx),\n            tiledb.Attr(name=""v"", dtype=\'S\', filters=compression, ctx=ctx),\n        ]\n        schema = tiledb.ArraySchema(domain=dom, sparse=True,\n                                    attrs=attrs,\n                                    ctx=ctx)\n        tiledb.SparseArray.create(uri, schema)\n\n        df = make_dataframe_basic1()\n        incr = 0\n        with tiledb.SparseArray(uri, \'w\') as A:\n            s_ichars = []\n            for s in df[\'chars\']:\n                s_ichars.append(incr)\n                incr += 1\n\n            times = df[\'time\']\n            cccc = df[\'cccc\']\n\n            df = df.drop(columns=[\'time\', \'cccc\'], axis=1)\n            A[s_ichars, times, cccc] = df.to_dict(orient=\'series\')\n\n        with tiledb.SparseArray(uri) as A:\n            df1 = pd.DataFrame.from_dict(A[:])\n            for col in df.columns:\n                assert_array_equal(df[col], df1[col])\n\n    def test_dataframe_basic1(self):\n        uri = self.path(""dataframe_basic_rt1"")\n        df = make_dataframe_basic1()\n\n        tiledb.from_dataframe(uri, df)\n\n        # TODO tiledb.read_dataframe\n        with tiledb.open(uri) as B:\n            df_readback = pd.DataFrame.from_dict(B[:])\n\n        tm.assert_frame_equal(df, df_readback)\n\n    def test_dataframe_basic2(self):\n        uri = self.path(""dataframe_basic_rt2"")\n\n        df = make_dataframe_basic2()\n\n        tiledb.from_dataframe(uri, df)\n\n        with tiledb.open(uri) as B:\n            df_readback = tiledb.open_dataframe(uri)\n            tm.assert_frame_equal(df, df_readback)\n\n    def test_dataframe_csv_rt1(self):\n        def rand_dtype(dtype, size):\n            import os\n            nbytes = size * np.dtype(dtype).itemsize\n\n            randbytes = os.urandom(nbytes)\n            return np.frombuffer(randbytes, dtype=dtype)\n\n        uri = self.path(""dataframe_csv_rt1"")\n        os.mkdir(uri)\n        col_size=15\n        data_dict = {\n            \'dates\': np.array(\n                rand_dtype(np.uint64, col_size), dtype=np.dtype(\'datetime64[ns]\')\n            ),\n            \'float64s\': rand_dtype(np.float64, col_size),\n            \'ints\': rand_dtype(np.int64, col_size),\n            \'strings\': [rand_utf8(5) for _ in range(col_size)],\n        }\n\n        df_orig = pd.DataFrame.from_dict(data_dict)\n\n        csv_uri = os.path.join(uri, ""test.csv"")\n        # note: encoding must be specified to avoid printing the b\'\' bytes\n        #       prefix, see https://github.com/pandas-dev/pandas/issues/9712\n        df_orig.to_csv(csv_uri, mode=\'w\')\n\n        csv_array_uri = os.path.join(uri, ""tiledb_csv"")\n        tiledb.from_csv(csv_array_uri, csv_uri, index_col = 0, parse_dates=[1])\n\n        df_from_array = tiledb.open_dataframe(csv_array_uri)\n        tm.assert_frame_equal(df_orig, df_from_array)\n\n        # Test reading via TileDB VFS. The main goal is to support reading\n        # from a remote VFS, using local with `file://` prefix as a test for now.\n        with tiledb.FileIO(tiledb.VFS(), csv_uri, \'rb\') as fio:\n            csv_uri_unc = ""file:///"" + csv_uri\n            csv_array_uri2 = ""file:///"" + os.path.join(csv_array_uri+""_2"")\n            tiledb.from_csv(csv_array_uri2, csv_uri_unc, index_col=0, parse_dates=[1])\n\n            df_from_array2 = tiledb.open_dataframe(csv_array_uri2)\n            tm.assert_frame_equal(df_orig, df_from_array2)\n\n    def test_dataframe_index_to_sparse_dims(self):\n        # This test\n        # - loops over all of the columns from make_basic_dataframe,\n        # - sets the index to the current column\n        # - creates a dataframe\n        # - check that indexing the nonempty_domain of the resulting\n        #   dimension matches the input\n\n        # TODO should find a way to dump the whole dataframe dict to a\n        #      (print-safe) bytestring in order to debug generated output\n        df = make_dataframe_basic1(100)\n\n        for col in df.columns:\n            uri = self.path(""df_indx_dim+{}"".format(str(col)))\n\n            # ensure that all column which will be used as string dim index\n            # is sorted, because that is how it will be returned\n            if df.dtypes[col] == \'O\':\n                df.sort_values(col, inplace=True)\n\n                # also ensure that string columns are converted to bytes\n                # b/c only TILEDB_ASCII supported for string dimension\n                if type(df[col][0]) == str_type:\n                    df[col] = [x.encode(\'UTF-8\') for x in df[col]]\n\n            new_df = df.drop_duplicates(subset=col)\n            new_df.set_index(col, inplace=True)\n\n            tiledb.from_dataframe(uri, new_df, sparse=True)\n\n            with tiledb.open(uri) as A:\n                self.assertEqual(A.domain.dim(0).name, col)\n\n                nonempty = A.nonempty_domain()[0]\n                res = A.multi_index[nonempty[0]:nonempty[1]]\n\n                # TODO use tiledb.open_dataframe here\n                res_df = pd.DataFrame(res, index=res.pop(col))\n                tm.assert_frame_equal(new_df, res_df, check_like=True)\n\n    def test_dataframe_multiindex_dims(self):\n        uri = self.path(""df_multiindex_dims"")\n\n        col_size = 10\n        df = make_dataframe_basic3(col_size)\n        df_dict = df.to_dict(orient=\'series\')\n        df.set_index([\'time\', \'double_range\'], inplace=True)\n\n        tiledb.from_dataframe(uri, df)\n\n        with tiledb.open(uri) as A:\n            ned_time = A.nonempty_domain()[0]\n            ned_dbl = A.nonempty_domain()[1]\n\n            res = A.multi_index[slice(*ned_time), :]\n            assert_array_equal(\n                res[\'time\'], df_dict[\'time\']\n            )\n            assert_array_equal(\n                res[\'double_range\'], df_dict[\'double_range\']\n            )\n            assert_array_equal(\n                res[\'int_vals\'], df.int_vals.values\n            )\n\n    def test_csv_col_to_sparse_dims(self):\n        df = make_dataframe_basic3(20)\n\n        # Test 1: basic round-trip\n        tmp_dir = self.path(""csv_col_to_sparse_dims"")\n        os.mkdir(tmp_dir)\n        tmp_csv = os.path.join(tmp_dir, ""generated.csv"")\n\n        df.sort_values(\'time\', inplace=True)\n        df.to_csv(tmp_csv, index=False)\n        df.set_index([\'time\', \'double_range\'], inplace=True)\n\n        tmp_array = os.path.join(tmp_dir, ""array"")\n        tiledb.from_csv(tmp_array, tmp_csv, index_col=[\'time\', \'double_range\'], parse_dates=[\'time\'])\n\n        df_bk = tiledb.open_dataframe(tmp_array)\n\n        tm.assert_frame_equal(df, df_bk)\n\n        # Test 2: check from_csv `sparse` and `allows_duplicates` keyword args\n        df = make_dataframe_basic3(20)\n        tmp_csv2 = os.path.join(tmp_dir, ""generated2.csv"")\n        tmp_array2a = os.path.join(tmp_dir, ""array2a"")\n        tmp_array2b = os.path.join(tmp_dir, ""array2b"")\n\n        # create a duplicate value\n        df.loc[0, \'int_vals\'] = df.int_vals[1]\n        df.sort_values(\'int_vals\', inplace=True)\n\n        df.to_csv(tmp_csv2, index=False)\n\n        # try once and make sure error is raised because of duplicate value\n        with self.assertRaisesRegex(tiledb.TileDBError, ""Duplicate coordinates \\\\(.*\\\\) are not allowed""):\n            tiledb.from_csv(tmp_array2a, tmp_csv2, index_col=[\'int_vals\'], sparse=True)\n\n        # try again, check from_csv(allows_duplicates=True, sparse=True)\n        tiledb.from_csv(tmp_array2b, tmp_csv2, index_col=[\'int_vals\'],\n                        sparse=True, allows_duplicates=True, float_precision=\'round-trip\')\n\n        with tiledb.open(tmp_array2b) as A:\n            #self.assertTrue(A.schema.sparse)\n            res = A[:]\n            assert_array_equal(res[\'int_vals\'], df.int_vals.values)\n            assert_array_almost_equal(res[\'double_range\'], df.double_range.values)\n\n    def test_csv_schema_only(self):\n        col_size = 10\n        df = make_dataframe_basic3(col_size)\n\n        tmp_dir = self.path(""csv_schema_only"")\n        os.mkdir(tmp_dir)\n        tmp_csv = os.path.join(tmp_dir, ""generated.csv"")\n\n        df.sort_values(\'time\', inplace=True)\n        df.to_csv(tmp_csv, index=False)\n\n        attrs_filters = tiledb.FilterList([tiledb.ZstdFilter(1)])\n        # from_dataframe default is 1, so use 7 here to check\n        #   the arg is correctly parsed/passed\n        coords_filters = tiledb.FilterList([tiledb.ZstdFilter(7)])\n\n        tmp_array = os.path.join(tmp_dir, ""array"")\n        tiledb.from_csv(tmp_array, tmp_csv,\n                        index_col=[\'time\', \'double_range\'],\n                        parse_dates=[\'time\'],\n                        mode=\'schema_only\',\n                        coords_filters=coords_filters)\n\n        t0, t1 = df.time.min(), df.time.max()\n\n        import numpy\n        ref_schema = tiledb.ArraySchema(\n                        domain=tiledb.Domain(*[\n                          tiledb.Dim(name=\'time\', domain=(t0.to_datetime64(), t1.to_datetime64()), tile=1, dtype=\'datetime64[ns]\'),\n                          tiledb.Dim(name=\'double_range\', domain=(-1000.0, 1000.0), tile=1.0, dtype=\'float64\'),\n                        ]),\n                        attrs=[\n                          tiledb.Attr(name=\'int_vals\', dtype=\'int64\', filters=attrs_filters),\n                        ],\n                        coords_filters=coords_filters,\n                        cell_order=\'row-major\',\n                        tile_order=\'row-major\',\n                        sparse=True,\n                        allows_duplicates=False)\n                        # note: filters omitted\n\n        array_nfiles = len(tiledb.VFS().ls(tmp_array))\n        self.assertEqual(array_nfiles, 3)\n\n        with tiledb.open(tmp_array) as A:\n            self.assertEqual(A.schema, ref_schema)\n\n            # TODO currently no equality check for filters\n            self.assertEqual(\n                A.schema.coords_filters[0].level, coords_filters[0].level\n            )\n            self.assertEqual(\n                A.schema.attr(0).filters[0].level, attrs_filters[0].level\n            )\n\n        # Test mode=\'append\'\n        tiledb.from_csv(tmp_array, tmp_csv,\n                        index_col=[\'time\', \'double_range\'], mode=\'append\')\n        df2 = make_dataframe_basic3(10, time_range=(t0, t1))\n        df2.sort_values(\'time\', inplace=True)\n        df2.set_index([\'time\', \'double_range\'], inplace=True)\n        tiledb.from_dataframe(tmp_array, df2, mode=\'append\')\n\n        with tiledb.open(tmp_array) as A:\n            res = A[:]\n            df_bk = pd.DataFrame(res)\n            df_bk.set_index([\'time\',\'double_range\'], inplace=True)\n\n            df.set_index([\'time\',\'double_range\'], inplace=True)\n            df_combined = pd.concat([df, df2])\n            df_combined.sort_index(level=\'time\', inplace=True)\n            tm.assert_frame_equal(df_bk, df_combined)'"
tiledb/tests/test_util.py,10,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tiledb\nfrom tiledb import *\nfrom tiledb.libtiledb import index_as_tuple, replace_ellipsis\nfrom tiledb.tests.common import DiskTestCase\n\nimport numpy as np\nfrom numpy.testing import assert_equal, assert_approx_equal,\\\n                          assert_array_equal, assert_raises\n\nimport unittest\nfrom unittest import TestCase\n\n\nclass UtilTest(DiskTestCase):\n    def test_empty_like(self):\n        arr = np.zeros((10,10), dtype=np.float32)\n\n        def check_schema(self, s):\n            self.assertEqual(s.attr(0).dtype, np.float32)\n            self.assertEqual(s.shape, (10,10))\n            self.assertEqual(s.domain.dim(0).shape, (10,))\n            self.assertEqual(s.domain.dim(1).shape, (10,))\n\n        with self.assertRaises(ValueError):\n            schema_like(\'\', None)\n\n        schema = schema_like(arr, tile=1)\n        self.assertIsInstance(schema, ArraySchema)\n        check_schema(self, schema)\n\n        uri = self.path(""empty_like"")\n        T = empty_like(uri, arr)\n        check_schema(self, T.schema)\n        self.assertEqual(T.shape, arr.shape)\n        self.assertEqual(T.dtype, arr.dtype)\n\n\n        # test a fake object with .shape, .ndim, .dtype\n        class FakeArray(object):\n            def __init__(self, shape, dtype):\n                self.shape = shape\n                self.ndim = len(shape)\n                self.dtype = dtype\n\n        fake = FakeArray((3,3), np.int16)\n        schema2 = empty_like(self.path(\'fake_like\'), fake)\n        self.assertIsInstance(schema2, Array)\n        self.assertEqual(schema2.shape, fake.shape)\n        self.assertEqual(schema2.dtype, fake.dtype)\n        self.assertEqual(schema2.ndim, fake.ndim)\n\n        # test passing shape and dtype directly\n        schema3 = schema_like(shape=(4,4), dtype=np.float32)\n        self.assertIsInstance(schema3, ArraySchema)\n        self.assertEqual(schema3.attr(0).dtype, np.float32)\n        self.assertEqual(schema3.domain.dim(0).tile, 4)\n        schema3 = schema_like(shape=(4,4), dtype=np.float32, tile=1)\n        self.assertEqual(schema3.domain.dim(0).tile, 1)\n\n    def test_open(self):\n        uri = self.path(""load"")\n        with tiledb.from_numpy(uri, np.array(np.arange(3))) as T:\n            with tiledb.open(uri) as T2:\n                self.assertEqual(T.schema, T2.schema)\n                assert_array_equal(T, T2)\n\n    def test_save(self):\n        uri = self.path(""test_save"")\n        arr = np.array(np.arange(3))\n        with tiledb.save(uri, arr) as tmp:\n            with tiledb.open(uri) as T:\n                assert_array_equal(arr, T)\n\n    def test_array_exists(self):\n        import tempfile\n        with tempfile.NamedTemporaryFile() as tmpfn:\n            self.assertFalse(tiledb.array_exists(tmpfn.name))\n\n        uri = self.path(""test_array_exists_dense"")\n        with tiledb.from_numpy(uri, np.arange(0,5)) as T:\n            self.assertTrue(tiledb.array_exists(uri))\n            self.assertTrue(tiledb.array_exists(uri, isdense=True))\n            self.assertFalse(tiledb.array_exists(uri, issparse=True))\n\n        uri = self.path(""test_array_exists_sparse"")\n        ctx = tiledb.Ctx()\n        dom = tiledb.Domain(tiledb.Dim(domain=(0, 3), tile=4, dtype=int, ctx=ctx), ctx=ctx)\n        att = tiledb.Attr(dtype=int, ctx=ctx)\n        schema = tiledb.ArraySchema(domain=dom, attrs=(att,), sparse=True, ctx=ctx)\n        tiledb.Array.create(uri, schema)\n\n        with tiledb.SparseArray(uri, mode=\'w\') as T:\n            T[[0,1]] = np.array([0,1])\n\n        self.assertTrue(tiledb.array_exists(uri))\n        self.assertTrue(tiledb.array_exists(uri, issparse=True))\n        self.assertFalse(tiledb.array_exists(uri, isdense=True))\n'"
