file_path,api_count,code
setup.py,0,"b""from distutils.core import setup\nfrom catkin_pkg.python_setup import generate_distutils_setup\n\nsetup_args = generate_distutils_setup(\n    packages=['slam'],\n    package_dir={'': 'src'},\n)\n\nsetup(**setup_args)\n"""
nodes/gridmap_listener.py,3,"b""#!/usr/bin/env python\nimport math\nimport sys\nimport time\nimport threading\n\nimport numpy as np\nfrom slam.gridmap import GridMap\nfrom slam.utils import normalize_angle\n\nimport rospy\nimport tf, tf2_ros\nimport std_msgs.msg, geometry_msgs.msg, nav_msgs.msg, sensor_msgs.msg\n\n\nclass GridmapListener:\n    def __init__(self):\n        self.lock = threading.Lock()\n\n        self.tf_buffer = tf2_ros.Buffer()\n        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer)\n\n        self.scan_sub = rospy.Subscriber('scan', sensor_msgs.msg.LaserScan, self._scan_cb)\n\n        self.map_pub = rospy.Publisher('gridmap', nav_msgs.msg.OccupancyGrid, queue_size=1)\n\n        self.last_scan_msg = None\n        self.last_tf_msg = None\n        self.gridmap = GridMap(grid_size=0.1)\n        self.gridmap.init_gridmap((50, 50))\n\n        self.gridmap_msg = nav_msgs.msg.OccupancyGrid()\n        self.gridmap_msg.info.map_load_time = rospy.Time.now()\n        self.gridmap_msg.info.resolution = self.gridmap._grid_size\n        self.gridmap_msg.info.width = self.gridmap._map_size[1]\n        self.gridmap_msg.info.height = self.gridmap._map_size[0]\n\n\n    def _scan_cb(self, msg):\n        with self.lock:\n            self.last_scan_msg = msg\n\n            trans = None\n            try:\n                trans = self.tf_buffer.lookup_transform('base_footprint',\n                    'odom', rospy.Time.now())\n            except (\n                tf2_ros.LookupException,\n                tf2_ros.ConnectivityException,\n                tf2_ros.ExtrapolationException\n            ):\n                pass\n\n            if trans:\n                self.last_tf_msg = trans\n\n    def update_map(self):\n        with self.lock:\n            if not self.last_scan_msg or not self.last_tf_msg:\n                return\n\n            rx = self.last_tf_msg.transform.translation.x\n            ry = self.last_tf_msg.transform.translation.y\n\n            quat = (\n                self.last_tf_msg.transform.rotation.x,\n                self.last_tf_msg.transform.rotation.y,\n                self.last_tf_msg.transform.rotation.z,\n                self.last_tf_msg.transform.rotation.w,\n            )\n            (roll, pitch, yaw) = tf.transformations.euler_from_quaternion(\n                quat\n            )\n\n            rtheta = normalize_angle(yaw)\n            rob_pose = np.matrix([rx, ry, rtheta]).T\n\n            # TODO: Calculate laser offset\n            range_scan = {\n                'ranges': np.array(self.last_scan_msg.ranges, dtype=np.float32),\n                'maximum_range': self.last_scan_msg.range_max,\n                'start_angle': self.last_scan_msg.angle_min,\n                'angular_resolution': self.last_scan_msg.angle_increment,\n                'laser_offset': np.matrix([0, 0, 0])\n            }\n            s_angle = range_scan['start_angle']\n            ang_res = range_scan['angular_resolution']\n            num_beams = len(range_scan['ranges'])\n            print(s_angle, ang_res, s_angle + ang_res * num_beams)\n            print(\n                self.last_scan_msg.angle_min,\n                self.last_scan_msg.angle_increment,\n                self.last_scan_msg.angle_max,\n            )\n            rospy.loginfo('Updating map')\n\n            self.gridmap.update(rob_pose, range_scan)\n\n            self.gridmap_msg.header.stamp = rospy.Time.now()\n            prob_map = self.gridmap.get_prob_map() * 100\n            self.gridmap_msg.data = prob_map.flatten()\n            self.map_pub.publish(self.gridmap_msg)\n\n\n\ndef gridmap_listener():\n    rospy.init_node('gridmap_listener')\n    rospy.loginfo('Initialized gridmap_listener')\n\n    listener = GridmapListener()\n\n    rate = rospy.Rate(30.0)\n    while not rospy.is_shutdown():\n\n        listener.update_map()\n\n        rate.sleep()\n\n\n\nif __name__ == '__main__':\n    try:\n        gridmap_listener()\n    except rospy.ROSInterruptException:\n        pass\n"""
nodes/gridmap_publisher.py,2,"b""#!/usr/bin/env python\nimport numpy as np\nimport math\nimport sys\nfrom slam.gridmap import GridMap, LaserDataMatlab\n\nimport rospy\nimport tf, tf2_ros\nimport geometry_msgs.msg\nfrom std_msgs.msg import Header\nfrom nav_msgs.msg import OccupancyGrid, MapMetaData\nfrom sensor_msgs.msg import LaserScan\nfrom rospy.numpy_msg import numpy_msg\n\n\ndef timestep_gen(timesteps):\n    for t in timesteps:\n        yield t\n\n\ndef gridmap_publisher():\n    gridmap_pub = rospy.Publisher('gridmap', OccupancyGrid, queue_size=1)\n    pose_pub = rospy.Publisher('pose', geometry_msgs.msg.PoseStamped, queue_size=10)\n    scan_pub = rospy.Publisher('scan', LaserScan, queue_size=10)\n    rospy.init_node('gridmap_publisher', sys.argv)\n    rospy.loginfo('Initialized gridmap_publisher')\n\n    # Gridmap \n    laser_data = LaserDataMatlab(sys.argv[1])\n    gridmap = GridMap(grid_size=0.1)\n    gridmap.init_from_laserdata(laser_data)\n\n    # Setup ros message\n    timestep_list = laser_data.get_timestep_list()\n    timesteps = timestep_gen(timestep_list)\n    timestep_len = len(timestep_list)\n\n    map_meta = MapMetaData()\n    # map_meta.map_load_time = rospy.Time().now()\n    map_meta.resolution = gridmap._grid_size\n\n    grid_map = gridmap.get_prob_map() * 100\n    grid_map = grid_map.astype(np.int8)\n\n    # Width = cols\n    map_meta.width = grid_map.shape[1]\n    # Height = rows\n    map_meta.height = grid_map.shape[0]\n\n    map_meta.origin.position.x = 0\n    map_meta.origin.position.y = 0\n    map_meta.origin.position.z = 0\n\n    # Broadcast robot transform\n\n    pose_tf_br = tf2_ros.TransformBroadcaster()\n\n    rbase_tf = geometry_msgs.msg.TransformStamped()\n    rbase_tf.header.stamp = rospy.Time.now()\n    rbase_tf.header.frame_id = 'map'\n    rbase_tf.child_frame_id = 'robot_base'\n\n    rate = rospy.Rate(10)\n\n    rx = 0 - gridmap._offset[0]\n    ry = 0 - gridmap._offset[1]\n    rtheta = 0\n\n    pose_msg = geometry_msgs.msg.PoseStamped()\n    pose_msg.header.frame_id = 'map'\n\n    scan_msg = LaserScan()\n    scan_msg.header.frame_id = 'robot_base'\n\n    # Get info about laser scan\n    laser_scan_temp = laser_data.get_range_scan(0)\n\n    # This info doesn't change\n    start_angle = laser_scan_temp['start_angle']\n    angular_resolution = laser_scan_temp['angular_resolution']\n\n    scan_msg.angle_min = start_angle\n    scan_msg.angle_increment = angular_resolution\n    scan_msg.range_min = 0\n    scan_msg.time_increment = 0\n\n    robot_pose = None\n    range_scan = None\n    while not rospy.is_shutdown():\n        try:\n            t = next(timesteps)\n            robot_pose = laser_data.get_pose(t)\n            range_scan = laser_data.get_range_scan(t)\n            gridmap.update(robot_pose, range_scan)\n        except StopIteration:\n            robot_pose = laser_data.get_pose(timestep_len-1)\n            range_scan = laser_data.get_range_scan(timestep_len-1)\n\n        grid_map = gridmap.get_prob_map() * 100\n        grid_map = grid_map.astype(np.int8)\n\n        rx = robot_pose.item(0) - gridmap._offset[0]\n        ry = robot_pose.item(1) - gridmap._offset[1]\n        rtheta = robot_pose.item(2)\n\n        # Robot_base transform \n        rbase_tf.transform.translation.x = rx\n        rbase_tf.transform.translation.y = ry\n        rbase_tf.transform.translation.z = 0\n\n        quat = tf.transformations.quaternion_from_euler(0, 0, rtheta)\n        rbase_tf.transform.rotation.x = quat[0]\n        rbase_tf.transform.rotation.y = quat[1]\n        rbase_tf.transform.rotation.z = quat[2]\n        rbase_tf.transform.rotation.w = quat[3]\n\n        # Robot pose \n        pose_msg.pose.position.x = rx\n        pose_msg.pose.position.y = ry\n        pose_msg.pose.position.z = 0\n\n        pose_quat = tf.transformations.quaternion_from_euler(0, 0, rtheta)\n        pose_msg.pose.orientation.x = pose_quat[0]\n        pose_msg.pose.orientation.y = pose_quat[1]\n        pose_msg.pose.orientation.z = pose_quat[2]\n        pose_msg.pose.orientation.w = pose_quat[3]\n\n        # Laser scan\n        # Get changing info from current scan\n        num_beams = len(range_scan['ranges'])\n        max_range = range_scan['maximum_range']\n        laser_ranges = range_scan['ranges']\n\n        valid_endpoints = (laser_ranges < max_range) & (laser_ranges > 0)\n        laser_ranges = laser_ranges[valid_endpoints]\n\n        scan_msg.angle_max = start_angle + num_beams * angular_resolution\n        scan_msg.range_max = max_range\n        scan_msg.ranges = laser_ranges\n        scan_msg.time_increment = (1/50) / num_beams\n        scan_msg.scan_time = rospy.Time.now().nsecs - scan_msg.scan_time\n\n        # Publish everything\n        rbase_tf.header.stamp = rospy.Time.now()\n        pose_msg.header.stamp = rospy.Time.now()\n        scan_msg.header.stamp = rospy.Time.now()\n\n        pose_tf_br.sendTransform(rbase_tf)\n        pose_pub.publish(pose_msg)\n        scan_pub.publish(scan_msg)\n\n        h = Header()\n        h.stamp = rospy.Time.now()\n        map_meta.map_load_time = rospy.Time().now()\n        gridmap_pub.publish(\n            header=h,\n            info=map_meta,\n            data=grid_map.flatten()\n        )\n\n        rate.sleep()\n\n\nif __name__ == '__main__':\n    try:\n        gridmap_publisher()\n    except rospy.ROSInterruptException:\n        pass\n"""
src/setup.py,0,"b""from setuptools import setup\n\nsetup(\n    name='slam-algorithms',\n    packages=['slam'],\n    include_package_data=True,\n    install_requires=[\n    ]\n)\n\n"""
src/slam/__init__.py,0,b''
src/slam/ekf_localization.py,17,"b'import numpy as np\r\nimport math\r\nfrom slam.utils import normalize_angle\r\n\r\n\r\nclass EKFLocalizationKnown:\r\n    def __init__(self, pose, motion_command=None):\r\n        # Main estimate\r\n        self.mean = np.copy(pose)\r\n        self.cov = np.zeros((self.mean.size, self.mean.size))\r\n\r\n        # Intermediate variables\r\n        self._mean = np.copy(self.mean)\r\n        self._cov = np.copy(self.cov)\r\n\r\n        self.motion_command = motion_command\r\n\r\n    def predict(self, command):\r\n        self._mean = self.motion_command(self.mean, command)\r\n\r\n        # TODO: Put in motion model\r\n        theta_n = normalize_angle(self.mean.item(2))\r\n        rot1, trans, rot2 = command\r\n\r\n        ang = normalize_angle(theta_n + rot1)\r\n        Gt = np.matrix([\r\n            [1, 0, - trans * math.sin(ang)],\r\n            [0, 1, trans * math.cos(ang)],\r\n            [0, 0, 1],\r\n\r\n        ])\r\n\r\n        # motion noise\r\n        Rt = np.matrix([\r\n            [0.1, 0, 0],\r\n            [0, 0.1, 0],\r\n            [0, 0, 0.01]\r\n        ])\r\n\r\n        self._cov = Gt * self.cov * Gt.T + Rt\r\n\r\n        return self._mean, self._cov\r\n\r\n    def correct(self, measurements, local_map):\r\n        # measurement noise\r\n        Qt = np.eye(self._mean.size - 1) * 0.01\r\n\r\n        rx = self._mean.item(0)\r\n        ry = self._mean.item(1)\r\n        rtheta = normalize_angle(self._mean.item(2))\r\n\r\n        # TODO: Fix kalman gain calculation\r\n        for reading in measurements:\r\n            # TODO: Put in measurement model\r\n            lid, srange, sbearing = reading\r\n            z_measured = np.matrix([srange, normalize_angle(sbearing)]).T\r\n\r\n            # Expected observation\r\n            lx, ly = local_map.get(lid)\r\n            dx = lx - rx\r\n            dy = ly - ry\r\n            delta = np.matrix([dx, dy]).T\r\n            q = delta.T * delta\r\n            z_expected = np.matrix([\r\n                math.sqrt(q),\r\n                normalize_angle(np.arctan2(dy, dx) - rtheta)\r\n            ]).T\r\n            # Jacobian\r\n            Ht = np.matrix([\r\n                [-math.sqrt(q) * dx, -math.sqrt(q) * dy, 0],\r\n                [dy, -dx, -q]\r\n            ])\r\n            Ht = np.multiply((1.0 / q), Ht)\r\n\r\n            Kgain = self._cov * Ht.T * np.linalg.inv(Ht * self._cov * Ht.T + Qt)\r\n\r\n            diff = z_measured - z_expected\r\n            diff[1] = normalize_angle(diff.item(1))\r\n\r\n            self._mean = self._mean + Kgain * diff\r\n            self._cov = (np.eye(self._mean.size) - Kgain * Ht) * self._cov\r\n\r\n        self.mean = np.copy(self._mean)\r\n        self.cov = np.copy(self._cov)\r\n\r\n        return self.mean, self.cov\r\n'"
src/slam/ekf_slam.py,34,"b'import numpy as np\nimport math\nfrom slam.utils import normalize_angle\n\n\nclass EKFSLAMKnown:\n    def __init__(self, pose, num_landmarks, motion_command):\n        self.rsize = 3\n        self.lmsize = 2\n\n        landmark_pose = np.zeros((2 * num_landmarks, 1))\n\n        self.mean = np.concatenate((np.copy(pose), landmark_pose))\n        self.cov = np.zeros((self.mean.size, self.mean.size))\n        lm_cov = np.eye(2 * num_landmarks)\n        np.fill_diagonal(\n            lm_cov,\n            10 ** 10\n        )\n        self.cov[self.rsize:, self.rsize:] = lm_cov\n\n        self.motion_command = motion_command\n\n    def get_mu_lid(self, lid):\n        return self.rsize + self.lmsize * (lid - 1)\n\n    def get_landmark(self, lid):\n        mu_lid = self.get_mu_lid(lid)\n\n        lx = self.mean[mu_lid, :].item(0)\n        ly = self.mean[mu_lid + 1, :].item(0)\n\n        return (lx, ly)\n\n    def set_landmark(self, lid, lx, ly):\n        mu_lid = self.get_mu_lid(lid)\n\n        self.mean[mu_lid, :] = lx\n        self.mean[mu_lid + 1, :] = ly\n\n    def predict(self, command):\n        robot_pose = self.mean[:self.rsize, :]\n        self.mean[:self.rsize, :] = self.motion_command(\n            robot_pose,\n            command\n        )\n\n        # TODO: Put in motion model\n        theta_n = normalize_angle(self.mean.item(2))\n        rot1, trans, rot2 = command\n\n        ang = normalize_angle(theta_n + rot1)\n        Gtx = np.matrix([\n            [1, 0, - trans * math.sin(ang)],\n            [0, 1, trans * math.cos(ang)],\n            [0, 0, 1],\n        ])\n\n        lmsize = self.mean.shape[0] - self.rsize\n\n        r1zeros = np.zeros((self.rsize, lmsize))\n        r2zeros = np.copy(r1zeros.T)\n\n        gr1 = np.concatenate((Gtx, r1zeros), axis=1)\n        gr2 = np.concatenate((r2zeros, np.eye(lmsize)), axis=1)\n        Gt = np.concatenate((gr1, gr2))\n\n        # motion noise\n        Rtx = np.matrix([\n            [0.1, 0, 0],\n            [0, 0.1, 0],\n            [0, 0, 0.01]\n        ])\n\n        rr1zeros = np.zeros((self.rsize, lmsize))\n        rr2zeros = np.copy(rr1zeros.T)\n\n        rr1 = np.concatenate(\n            (Rtx, rr1zeros),\n            axis=1\n        )\n        rr2 = np.concatenate(\n            (rr2zeros, np.zeros((lmsize, lmsize))),\n            axis=1\n        )\n        Rt = np.concatenate((rr1, rr2))\n\n        self.cov = Gt * self.cov * Gt.T + Rt\n\n        return self.mean, self.cov\n\n    def correct(self, measurements, local_map):\n        rx = self.mean.item(0)\n        ry = self.mean.item(1)\n        rtheta = normalize_angle(self.mean.item(2))\n\n        Htfull = np.matrix([])\n        Zdiff = np.matrix([])\n        for reading in measurements:\n            # TODO: Put in measurement model\n            lid, srange, sbearing = reading\n            z_measured = np.matrix([srange, normalize_angle(sbearing)]).T\n\n            mu_lid = self.get_mu_lid(lid)\n\n            # Expected observation\n            lx = 0\n            ly = 0\n            if not local_map.is_added(lid):\n                lx = rx + srange * math.cos(sbearing + rtheta)\n                ly = ry + srange * math.sin(sbearing + rtheta)\n                local_map.add((lid, lx, ly))\n\n                self.mean[mu_lid, :] = lx\n                self.mean[mu_lid + 1, :] = ly\n            else:\n                lx = self.mean[mu_lid, :].item(0)\n                ly = self.mean[mu_lid + 1, :].item(0)\n\n            dx = lx - rx\n            dy = ly - ry\n\n            delta = np.matrix([dx, dy]).T\n            q = delta.T * delta\n            z_expected = np.matrix([\n                math.sqrt(q),\n                normalize_angle(np.arctan2(dy, dx) - rtheta)\n            ]).T\n            qst = math.sqrt(q)\n            # Measurement jacobian\n            Htt = np.matrix([\n                [-qst * dx, -qst * dy, 0, qst * dx, qst * dy],\n                [dy, -dx, -q, -dy, dx]\n            ])\n            Htt = np.multiply((1.0 / q), Htt)\n\n            F = np.zeros((5, self.mean.size))\n            F[:self.rsize, :self.rsize] = np.eye(self.rsize)\n            F[self.rsize:, mu_lid:mu_lid + self.lmsize] = np.eye(self.lmsize)\n\n            Ht = Htt * F\n\n            Htfull = np.concatenate((Htfull, Ht)) if Htfull.size else np.copy(Ht)\n\n            diff = z_measured - z_expected\n            # Important to normalize_angles\n            diff[1] = normalize_angle(diff.item(1))\n\n            Zdiff = np.concatenate((Zdiff, diff)) if Zdiff.size else np.copy(diff)\n\n        # measurement noise\n        Qt = np.eye(Zdiff.shape[0]) * 0.01\n\n        Kgain = self.cov * Htfull.T * np.linalg.inv(Htfull * self.cov * Htfull.T + Qt)\n\n        self.mean = self.mean + Kgain * Zdiff\n        self.cov = (np.eye(self.mean.size) - Kgain * Htfull) * self.cov\n\n        return self.mean, self.cov\n'"
src/slam/gridmap.py,30,"b""import math\nimport numpy as np\nimport scipy.io as sio\nfrom slam.utils import (bresenham_line, prob2log, log2prob,\n    vector2transform2D, transform2vector2D)\n\n\nclass LaserDataMatlab:\n    def __init__(self, filename):\n        self.filename = filename\n        laser_content = None\n        try:\n            laser_content = sio.loadmat(filename)\n        except FileNotFoundError:\n            raise ValueError('Provide a laser scan .mat file')\n\n        self._laser = laser_content['laser']\n        self._poses = np.asmatrix(np.vstack(self._laser['pose'][0]))\n\n    @property\n    def poses(self):\n        return self._poses\n\n    def get_timestep_list(self):\n        return list(range(len(self.poses)))\n\n    def get_pose(self, timestep):\n        return self._poses[timestep].T\n\n    def get_range_scan(self, timestep):\n        range_scan = self._laser[0, timestep]\n        ranges = range_scan['ranges'][0]\n        max_range = range_scan['maximum_range'][0][0]\n        start_angle = range_scan['start_angle'][0][0]\n        angular_res = range_scan['angular_resolution'][0][0]\n        laser_offset = np.asmatrix(range_scan['laser_offset'])\n\n        return {\n            'ranges': ranges,\n            'maximum_range': max_range,\n            'start_angle': start_angle,\n            'angular_resolution': angular_res,\n            'laser_offset': laser_offset\n        }\n\n    def init_gridmap_from_data(self, gridmap):\n        pose_x_min = np.min(self._poses[:, 0])\n        pose_x_max = np.max(self._poses[:, 0])\n        pose_y_min = np.min(self._poses[:, 1])\n        pose_y_max = np.max(self._poses[:, 1])\n\n        map_borders = (pose_x_min-gridmap._border, pose_x_max+gridmap._border,\n                       pose_y_min-gridmap._border, pose_y_max+gridmap._border)\n\n        offset_x = map_borders[0]\n        offset_y = map_borders[2]\n        gridmap._offset = (offset_x, offset_y)\n\n        gridmap._map_size_meters = (map_borders[1]-offset_x, map_borders[3]-offset_y)\n        gridmap._map_size = tuple([math.ceil(dim/gridmap._grid_size) for dim in gridmap._map_size_meters])\n\n        log_odds_prior = prob2log(gridmap._prior)\n        gridmap._grid_map = np.ones(gridmap._map_size) * log_odds_prior\n\n\nclass GridMap:\n    def __init__(self, grid_size=0.5, border=30):\n        # Default \n        self._prior = 0.5\n        self._prob_occ = 0.9\n        self._prob_free = 0.35\n\n        self._border = border\n        self._grid_size = grid_size\n\n        self._offset = None\n        self._map_size_meters = None\n        self._map_size = None\n        self._grid_map = None\n\n    def init_gridmap(self, map_size):\n        self._offset = (map_size[0]/2.0, map_size[1]/2.0)\n        self._map_size_meters = map_size\n        self._map_size = tuple([math.ceil(dim/self._grid_size) for dim in self._map_size_meters])\n\n        log_odds_prior = prob2log(self._prior)\n        self._grid_map = np.ones(self._map_size) * log_odds_prior\n\n    def init_from_laserdata(self, laserdata):\n        laserdata.init_gridmap_from_data(self)\n\n    def inv_sensor_model(self, scan, pose):\n        map_update = np.zeros(self._grid_map.shape)\n\n        rob_trans = vector2transform2D(pose)\n        robot_pose_map_frame = GridMap.world_to_map_coordinates(\n            pose[0:2, :], self._grid_size, self._offset\n        )\n\n        laser_end_points = GridMap.laser_as_cartesian(scan, 30)\n        laser_end_points = rob_trans * laser_end_points\n\n        laser_end_map_frame = GridMap.world_to_map_coordinates(\n            laser_end_points[0:2, :], self._grid_size, self._offset\n        )\n\n        for col in range(laser_end_map_frame.shape[1]):\n            rx = int(robot_pose_map_frame.item(0))\n            ry = int(robot_pose_map_frame.item(1))\n            lx = int(laser_end_map_frame.item((0, col)))\n            ly = int(laser_end_map_frame.item((1, col)))\n\n            bres_points = bresenham_line((rx, ry), (lx, ly))\n            for point in bres_points:\n                px, py = point\n                map_update[py, px] = self._grid_map[py, px] + \\\n                    prob2log(self._prob_free)\n\n            map_update[py, px] = self._grid_map[py, px] + \\\n                prob2log(self._prob_occ)\n\n        return map_update, robot_pose_map_frame, laser_end_map_frame\n\n    def update(self, robot_pose, laser_scan):\n        map_update, pose_map_frame, laser_map_frame = self.inv_sensor_model(\n            laser_scan, robot_pose\n        )\n\n        log_odds_prior = prob2log(self._prior)\n        map_update = map_update - log_odds_prior * np.ones(map_update.shape)\n        self._grid_map = self._grid_map + map_update\n\n    def get_prob_map(self):\n        return np.ones(self._grid_map.shape) - log2prob(self._grid_map)\n\n    def raycast(self, pose, scan_endpoints, occ_prob):\n        prob_map = self.get_prob_map()\n        pose_transf = vector2transform2D(pose)\n        scan_endpoints = pose_transf * scan_endpoints\n\n        pose_map = GridMap.world_to_map_coordinates(\n            pose[0:2, :], self._grid_size, self._offset\n        )\n\n        scan_endpoints_map = GridMap.world_to_map_coordinates(\n            scan_endpoints[0:2, :], self._grid_size, self._offset\n        )\n\n        log_odds = prob2log(occ_prob)\n        result_x = np.zeros(scan_endpoints_map.shape[1])\n        result_y = np.zeros(scan_endpoints_map.shape[1])\n        rx = int(pose_map.item(0))\n        ry = int(pose_map.item(1))\n        for col in range(scan_endpoints_map.shape[1]):\n            lx = int(scan_endpoints_map.item((0, col)))\n            ly = int(scan_endpoints_map.item((1, col)))\n            bres_points = bresenham_line((rx, ry), (lx, ly))\n            last_point = None\n            for point in bres_points:\n                px, py = point\n                last_point = point\n                if self._grid_map[py, px] >= log_odds:\n                    break\n            result_x[col] = last_point[0]\n            result_y[col] = last_point[1]\n\n        return np.vstack([result_x, result_y])\n\n    @staticmethod\n    def generate_laser_scan(max_range, num_beams, start_angle, angular_res):\n        angles = np.linspace(start_angle, start_angle + angular_res * num_beams, num_beams)\n        endpoints = np.vstack([\n            max_range * np.cos(angles),\n            max_range * np.sin(angles),\n            np.ones( (1, len(angles)) )\n        ])\n\n        return endpoints\n\n    @staticmethod\n    def calculate_scan_mse(scan1_map_end, scan2_map_end):\n        if scan1_map_end.shape[1] != scan2_map_end.shape[1]:\n            raise ValueError('Scans must have equal number of endpoints')\n        result = 0.0\n        diffs = np.matrix([])\n        m = scan1_map_end.shape[1]\n        for col in range(m):\n            lx1 = int(scan1_map_end.item((0, col)))\n            ly1 = int(scan1_map_end.item((1, col)))\n            lx2 = int(scan2_map_end.item((0, col)))\n            ly2 = int(scan2_map_end.item((1, col)))\n\n            point_diff = np.matrix([\n                lx1 - lx2,\n                ly2 - ly2\n            ]).T\n\n            diffs = np.concatenate((diffs, point_diff)) if diffs.size else np.copy(point_diff)\n\n        return np.asscalar(diffs.T * diffs) / (2 * m)\n\n    @staticmethod\n    def laser_as_cartesian(rl, max_range=15):\n        ranges = rl['ranges']\n        num_beams = len(ranges)\n        max_range = min(max_range, rl['maximum_range'])\n        idx = (ranges < max_range) & (ranges > 0)\n\n        s_angle = rl['start_angle']\n        a_res = rl['angular_resolution']\n        angles = np.linspace(s_angle, s_angle+num_beams*a_res, num_beams)[idx]\n        ranges = ranges[idx]\n\n        cs = np.cos(angles)\n        sn = np.sin(angles)\n        points = np.vstack([\n            ranges * cs,\n            ranges * sn,\n            np.ones( (1, len(angles)) )\n        ])\n        transf = vector2transform2D(rl['laser_offset'])\n\n        return transf * points\n\n    @staticmethod\n    def world_to_map_coordinates(world_points, grid_size, offset):\n        ofx, ofy = offset\n        map_points = np.zeros(world_points.shape)\n\n        for i in range(map_points.shape[1]):\n            col = world_points[:, [i]]\n            map_points[:, [i]] = np.array([\n                [math.ceil((col[0] - ofx) / grid_size)],\n                [math.ceil((col[1] - ofy) / grid_size)]\n            ])\n\n        return map_points\n\n"""
src/slam/map.py,0,"b'\r\n\r\nclass LandmarkMap:\r\n    def __init__(self, landmarks):\r\n        self.landmarks = {int(l[0]): tuple(l[1:]) for l in landmarks}\r\n\r\n    def is_added(self, lid):\r\n        return lid in self.landmarks.keys()\r\n\r\n    def add(self, landmark):\r\n        lid, lx, ly = landmark\r\n\r\n        if not self.is_added(lid):\r\n            self.landmarks[lid] = (lx, ly)\r\n\r\n    def get(self, lid):\r\n        if self.is_added(lid):\r\n            return self.landmarks[lid]'"
src/slam/particle_filter.py,15,"b""import math\nimport numpy as np\nfrom slam.utils import normalize_angle\n\n\nclass ParticleFilter:\n    def __init__(self, init_pose, num_particles, motion_model, sampler,\n    resampler):\n        if not motion_model or not sampler:\n            raise RuntimeError('Provide motion_model and sampler')\n        if not resampler:\n            raise RuntimeErro('Provide resampling algorithm')\n        if num_particles < 1:\n            raise RuntimeError('Number of particles must be positive')\n\n        self.particles = []\n        self.motion_model = motion_model\n        self.sampler = sampler\n        self.resampler = resampler\n\n        self._init(init_pose, num_particles)\n\n    def _init(self, init_pose, num_particles):\n        weight = 1.0 / num_particles\n        for i in range(num_particles):\n            particle = (weight, np.copy(init_pose))\n            self.particles.append(particle)\n\n    def predict(self, command, noise):\n        for i, particle in enumerate(self.particles):\n            weight, pose = particle\n            pose = self.motion_model(pose, command, noise, self.sampler)\n            self.particles[i] = (weight, np.copy(pose))\n\n    def correct(self, measurements, sensor_noise, landmark_map):\n        normalizer = 0\n        for i, particle in enumerate(self.particles):\n            weight, pose = particle\n            rx = pose.item(0)\n            ry = pose.item(1)\n            rtheta = pose.item(2)\n\n            vrange, vbearing = sensor_noise\n\n            # Matrix of measurement differences\n            Zdiff = np.matrix([])\n            for reading in measurements:\n                lid, srange, sbearing = reading\n                # Sensor measurement\n                z_measured = np.matrix([srange, sbearing]).T\n\n                lx, ly = landmark_map.get(lid)\n\n                dx = lx - rx\n                dy = ly - ry\n\n                delta = np.matrix([dx, dy]).T\n                q = delta.T * delta\n                # Expected (predicted) measurement\n                z_expected = np.matrix([\n                    math.sqrt(q),\n                    normalize_angle(np.arctan2(dy, dx) - rtheta)\n                ]).T\n\n                # Difference between measured and expected\n                diff = z_expected - z_measured\n                diff[1] = normalize_angle(diff.item(1))\n                # Collect all measurement differences\n                Zdiff = np.concatenate((Zdiff, diff)) if Zdiff.size else np.copy(diff)\n\n            # Making sensor noise matrix with different diagonal elements\n            Qdiag = np.array(\n                [[vrange, vbearing] for i in range(len(measurements))]\n            )\n            # Flatten the array\n            Qdiag.shape = (len(sensor_noise) * len(measurements), )\n            Qt = np.diag(Qdiag)\n            # Qt = np.eye(Zdiff.shape[0]) * 0.1\n\n            # Normal distribution is probably a good idea \n            # Highest weight when (z_expected - z_measured) is 0\n            denom = 1 / math.sqrt( np.linalg.det(2*math.pi*Qt) )\n            new_weight = denom * math.exp(-1/2 * Zdiff.T * np.linalg.pinv(Qt) * Zdiff)\n\n            normalizer = normalizer + new_weight\n            self.particles[i] = (new_weight, np.copy(pose))\n\n        self.particles = [(weight/normalizer, pose) for weight, pose in self.particles]\n\n    def resample(self):\n        self.particles = self.resampler(self.particles)\n\n\ndef low_variance_resampling(particles):\n    new_particles = []\n\n    Jinv = 1 / len(particles)\n    r = np.random.uniform(0, Jinv)\n    # weight\n    c = particles[0][0]\n    i = 0\n    for j in range(0, len(particles)):\n        # Or j-1 if out of range\n        U = r + (j) * Jinv\n        while U > c:\n            i = i + 1\n            c = c + particles[i][0]\n        new_particles.append(particles[i])\n\n    return new_particles\n\n\n\n"""
src/slam/robot.py,2,"b'import numpy as np\n\n\nclass BaseRobot:\n    def __init__(self, x, y, theta, motion_command):\n        self._pose = np.matrix([x, y, theta]).T\n        self._motion_command = motion_command\n\n    @property\n    def pose(self):\n        return self._pose\n\n    @pose.setter\n    def pose(self, new_pose):\n        self._pose = np.copy(new_pose)\n\n    @pose.deleter\n    def pose(self):\n        self._pose = None\n        del self._pose\n\n    @property\n    def motion(self):\n        return self._motion_command\n\n    @motion.setter\n    def motion(self, motion_model):\n        self._motion_command = motion_model\n\n    @motion.deleter\n    def motion(self):\n        del self._motion_command\n\n    def motion_command(self, command):\n        self._pose = self._motion_command(self._pose, command)\n'"
src/slam/ukf.py,22,"b'import math\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.linalg import sqrtm\nfrom slam.utils import normalize_angle\nfrom slam.motion_models.odometry_model import odometry_command\n\n\nclass UKF:\n    def __init__(self, pose):\n        state_size = pose.shape[0]\n        self.mean = np.zeros((state_size, 1))\n        self.cov = np.eye(state_size) * 0.001\n        self.state_size = state_size\n\n        # Unscented transform parameters\n        n = state_size\n        self.alpha = 0.5\n        self.beta = 2\n        self.kappa = 50\n        self.lambd = self.alpha*self.alpha*(n+self.kappa)-n\n\n    def predict(self, motion_model_transform, command, noise):\n        sigma_points, w_m, w_c = compute_sigma_points(\n            self.mean, self.cov, self.lambd, self.alpha, self.beta\n        )\n        # Normalize\n        for i in range(sigma_points.shape[1]):\n            sigma_points[2, i] = normalize_angle(sigma_points[2, i])\n\n        # Angles are normalized in motion model\n        sigma_points = motion_model_transform(sigma_points, command)\n\n        # TODO: rewrite to normalize differences\n        self.mean, self.cov = recover_gaussian(sigma_points, w_m, w_c)\n\n        # fix angles\n        average_theta = 0\n        avg_x = avg_y = 0\n        for i in range(sigma_points.shape[1]):\n            avg_x = avg_x + w_m[i]*math.cos(sigma_points[2, i])\n            avg_y = avg_y + w_m[i]*math.sin(sigma_points[2, i])\n        average_theta = normalize_angle(np.arctan2(avg_y, avg_x))\n        self.mean[2] = average_theta\n\n        # fix angles in covariance matrix too\n        for i in range(self.cov.shape[1]):\n            self.cov[2, i] = normalize_angle(self.cov[2, i])\n\n        Rt = np.diag(noise)\n        self.cov = self.cov + Rt\n\n        return self.mean, self.cov\n\n    def correct(self, meas_model_transform, measurements, noise, landmark_map):\n        sigma_points, w_m, w_c = compute_sigma_points(\n            self.mean, self.cov, self.lambd, self.alpha, self.beta\n        )\n        # Normalize\n        for i in range(sigma_points.shape[1]):\n            sigma_points[2, i] = normalize_angle(sigma_points[2, i])\n\n        for reading in measurements:\n            # Real measurement\n            lid, srange, sbearing = reading\n            z_measured = np.matrix([srange, normalize_angle(sbearing)]).T\n\n            # Predicted measurement\n            # Transform points through measurment_model\n            # Resulting matrix has 2 rows (range, bearing) and same number of columns\n            z_points = meas_model_transform(sigma_points, reading, landmark_map)\n\n            # Recover gaussian for predicted measurement\n            # TODO: rewrite to normalize differences\n            zt, St = recover_gaussian(z_points, w_m, w_c)\n\n            # Normalize bearing\n            average_bearing = 0\n            avg_x = avg_y = 0\n            for i in range(z_points.shape[1]):\n                # normalize \n                z_points[1, i] = normalize_angle(z_points[1, i])\n                # weighted sums of cosines and sines of the angle\n                avg_x = avg_x + w_m[i]*math.cos(z_points[1, i])\n                avg_y = avg_y + w_m[i]*math.sin(z_points[1, i])\n            average_bearing = normalize_angle(np.arctan2(avg_y, avg_x))\n            zt[1] = average_bearing\n\n            # normalize bearing in covariance matrix \n            for i in range(St.shape[1]):\n                St[1, i] = normalize_angle(St[1, i])\n\n            # Measurement noise\n            Qt = np.diag(noise)\n            St = St + Qt\n\n            sigma_x_z = np.zeros((self.mean.shape[0], zt.shape[0]))\n            for i in range(z_points.shape[1]):\n                s_diff = sigma_points[:, [i]] - self.mean\n                z_diff = z_points[:, [i]] - zt\n\n                # Normalize angles\n                s_diff[2] = normalize_angle(s_diff[2])\n                z_diff[1] = normalize_angle(z_diff[1])\n\n                sigma_x_z = sigma_x_z + w_c[i] * s_diff * z_diff.T\n\n            # Normalization time\n            for i in range(sigma_x_z.shape[1]):\n                sigma_x_z[2, i] = normalize_angle(sigma_x_z[2, i])\n\n            # broadcasting error if not matrix\n            sigma_x_z = np.matrix(sigma_x_z)\n\n            # Kalman gain\n            Kt = sigma_x_z * np.linalg.pinv(St)\n\n            # Normalize\n            z_diff = z_measured - zt\n            z_diff[1] = normalize_angle(z_diff[1])\n\n            self.mean = self.mean + Kt * (z_diff)\n            self.cov = self.cov - Kt * St * Kt.T\n\n            # normalize angle\n            self.mean[2] = normalize_angle(self.mean[2])\n            for i in range(self.cov.shape[1]):\n                self.cov[2, i] = normalize_angle(self.cov[2, i])\n\n        return self.mean, self.cov\n\n\ndef odometry_model_transform(points, command):\n    for i in range(points.shape[1]):\n        pose_col = np.copy(points[:, [i]])\n        points[:, [i]] = odometry_command(pose_col, command)\n    return points\n\n\ndef measurement_model_transform(points, measurement, landmark_map):\n    z_points = np.zeros((points.shape[0]-1, points.shape[1]))\n    for i in range(points.shape[1]):\n        rx = points[0, i]\n        ry = points[1, i]\n        rtheta = points[2, i]\n\n        lid, srange, sbearing = measurement\n        z_measured = np.matrix([srange, normalize_angle(sbearing)]).T\n\n        lx, ly = landmark_map.get(lid)\n\n        dx = lx - rx\n        dy = ly - ry\n        delta = np.matrix([dx, dy]).T\n        q = delta.T * delta\n        z_expected = np.matrix([\n            math.sqrt(q),\n            normalize_angle(np.arctan2(dy, dx) - rtheta)\n        ]).T\n\n        z_points[:, [i]] = z_expected\n    return z_points\n\n\ndef compute_sigma_points(mu, sigma, lambd, alpha, beta):\n    n = mu.shape[0]\n    sigma_points = np.zeros((n, 2*n+1))\n\n    sigma_points[:, [0]] = mu\n\n    # mroot = np.linalg.cholesky(sigma)\n    mroot = sqrtm(sigma)\n    mroot = math.sqrt(n+lambd) * mroot\n\n    # compute sigma points\n    for i in range(1, n+1):\n        sigma_points[:,[i]] = mu + mroot[:, [i-1]]\n\n    for i in range(n+1, 2*n+1):\n        sigma_points[:,[i]] = mu - mroot[:, [i-n-1]]\n\n    # compute weights for mean and covariance recovery\n    w_m = np.zeros(2*n+1)\n    w_c = np.zeros(2*n+1)\n\n    w_m[0] = lambd / (n + lambd)\n    w_c[0] = w_m[0] + (1 - alpha**2 + beta)\n    weight = 1 / ( 2 * (n + lambd))\n    for t in range(1,2*n+1):\n        w_m[t] = weight\n        w_c[t] = weight\n\n    return sigma_points, w_m, w_c\n\n\ndef recover_gaussian(sigma_points, w_m, w_c):\n    n = sigma_points.shape[0]\n    n_col = sigma_points.shape[1]\n\n    mu = np.zeros((n, 1))\n\n    # Recover mean\n    for i in range(0, n_col):\n        mu = mu + w_m[i] * sigma_points[:, [i]]\n\n    # Recover covariance\n    sigma = np.zeros((n, n))\n    for i in range(0, n_col):\n        sigma = sigma + w_c[i]*(sigma_points[:, [i]] - mu) * (sigma_points[:, [i]] - mu).T\n\n    return mu, sigma\n\n'"
src/slam/utils.py,6,"b'import math\nimport random\nimport numpy as np\n\n\ndef normalize_angle(phi):\n    return phi - 2*math.pi * math.floor((phi + math.pi) / (2*math.pi))\n\n\ndef sample_normal_distribution(b):\n    return np.random.normal(0, b, 1)[0]\n\n\ndef sample_triangular_distribution(b):\n    return b * random.uniform(-1, 1) * random.uniform(-1, 1)\n\n\ndef log2prob(l):\n    return 1 - (1 / (1 + np.exp(l)))\n\n\ndef prob2log(p):\n    return np.log(p / (1 - p))\n\n\ndef vector2transform2D(vector):\n    angle = vector.item(2)\n    cs = math.cos(angle)\n    sn = math.sin(angle)\n    return np.matrix([\n        [cs, -sn, vector.item(0)],\n        [sn, cs, vector.item(1)],\n        [0, 0, 1]\n    ])\n\n\ndef transform2vector2D(t):\n    return np.matrix([\n        [t[0, 2]],\n        [t[1, 2]],\n        [np.arctan2(t[1, 0], t[0, 0])]\n    ])\n\n\ndef bresenham_line(start, end):\n    # Copy/paste from roguebasin\n    # Setup initial conditions\n    x1, y1 = start\n    x2, y2 = end\n    dx = x2 - x1\n    dy = y2 - y1\n\n    # Determine how steep the line is\n    is_steep = abs(dy) > abs(dx)\n\n    # Rotate line\n    if is_steep:\n        x1, y1 = y1, x1\n        x2, y2 = y2, x2\n\n    # Swap start and end points if necessary and store swap state\n    swapped = False\n    if x1 > x2:\n        x1, x2 = x2, x1\n        y1, y2 = y2, y1\n        swapped = True\n\n    # Recalculate differentials\n    dx = x2 - x1\n    dy = y2 - y1\n\n    # Calculate error\n    error = int(dx / 2.0)\n    ystep = 1 if y1 < y2 else -1\n\n    # Iterate over bounding box generating points between start and end\n    y = y1\n    points = []\n    for x in range(x1, x2 + 1):\n        coord = (y, x) if is_steep else (x, y)\n        points.append(coord)\n        error -= abs(dy)\n        if error < 0:\n            y += ystep\n            error += dx\n\n    # Reverse the list if the coordinates were swapped\n    if swapped:\n        points.reverse()\n    return points\n\n\n'"
src/slam/data/__init__.py,0,"b'from .read_simple import read_simple_world, read_simple_data'"
src/slam/data/read_simple.py,0,"b'\r\n\r\ndef read_simple_data(filename):\r\n    odometry = []\r\n    sensor = []\r\n\r\n    with open(filename, \'r\') as f:\r\n        meas_pack = []\r\n        for line in f:\r\n            data = line.strip().split("" "")\r\n\r\n            if data[0] == ""ODOMETRY"":\r\n                if len(meas_pack) != 0:\r\n                    sensor.append(meas_pack)\r\n                    meas_pack = []\r\n                # rotation1, translation, rotation2\r\n                data[1:] = [float(d) for d in data[1:]]\r\n                odometry.append(tuple(data[1:]))\r\n            elif data[0] == ""SENSOR"":\r\n                # id of observed landmark\r\n                data[1] = int(data[1])\r\n                # range, bearing\r\n                data[2:] = [float(d) for d in data[2:]]\r\n\r\n                meas_pack.append(tuple(data[1:]))\r\n\r\n    return odometry, sensor\r\n\r\n\r\ndef read_simple_world(filename):\r\n    landmarks = []\r\n\r\n    with open(filename, \'r\') as f:\r\n        for line in f:\r\n            data = line.strip().split("" "")\r\n            data[0] = int(data[0])\r\n            data[1:] = [float(d) for d in data[1:]]\r\n\r\n            landmarks.append(tuple(data))\r\n\r\n    return landmarks'"
src/slam/motion_models/__init__.py,0,b''
src/slam/motion_models/odometry_model.py,4,"b'import numpy as np\nimport math\nfrom slam.utils import normalize_angle\n\n\ndef odometry_command(pose, command):\n    rot1, trans, rot2 = command\n    theta_old = normalize_angle(pose.item(2))\n\n    normalized = normalize_angle(theta_old + rot1)\n    update_vec = np.matrix([\n        trans * math.cos(normalized),\n        trans * math.sin(normalized),\n        normalize_angle(rot1 + rot2)\n    ]).T\n\n    pose = pose + update_vec\n    pose[2] = normalize_angle(pose.item(2))\n\n    return np.copy(pose)\n\n\ndef odometry_sample(pose, command, noise, sample=None):\n    if not sample:\n        raise ValueError(""Provide a sampler"")\n\n    rot1, trans, rot2 = command\n    r1_noise, t_noise, r2_noise = noise\n    theta_old = normalize_angle(pose.item(2))\n\n    rot1_h = rot1 - sample(r1_noise)\n    trans_h = trans - sample(t_noise)\n    rot2_h = rot2 - sample(r2_noise)\n\n    normalized = normalize_angle(theta_old + rot1_h)\n    update_vec = np.matrix([\n        trans_h * math.cos(normalized),\n        trans_h * math.sin(normalized),\n        normalize_angle(rot1_h + rot2_h)\n    ]).T\n\n    temp = pose + update_vec\n    temp[2] = normalize_angle(temp.item(2))\n\n    return np.copy(temp)\n\n'"
