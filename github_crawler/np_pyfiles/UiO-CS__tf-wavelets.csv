file_path,api_count,code
setup.py,0,"b'from setuptools import setup\n\n# Install python package\nsetup(\n    name=""tfwavelets"",\n    version=0.1,\n    author=""Kristian Monsen Haug, Mathias Lohne"",\n    author_email=""mathialo@ifi.uio.no"",\n    license=""MIT"",\n    description=""TensorFlow implementation of descrete wavelets"",\n    url=""https://github.com/UiO-CS/tf-wavelets"",\n    install_requires=[""tensorflow"", ""numpy""],\n    packages=[""tfwavelets""],\n    zip_safe=False)\n'"
tests.py,18,"b'import tfwavelets as tfw\nimport numpy as np\n\n\ndef check_orthonormality_1d(wavelet, tol=1e-5, N=8):\n    matrix = np.zeros((N, N))\n\n    for i in range(N):\n        unit = np.zeros(N)\n        unit[i] = 1\n\n        matrix[:, i] = tfw.wrappers.dwt1d(unit, wavelet)\n\n    error1 = np.mean(np.abs(matrix.T @ matrix - np.eye(N)))\n    error2 = np.mean(np.abs(matrix @ matrix.T - np.eye(N)))\n    assert error1 < tol, ""Mean error: %g"" % error1\n    assert error2 < tol, ""Mean error: %g"" % error2\n\n\ndef check_linearity_1d(wavelet, tol=1e-5, N=256):\n    x1 = np.random.random(N)\n    x2 = np.random.random(N)\n\n    c1 = np.random.random(1)\n    c2 = np.random.random(1)\n\n    test1 = tfw.wrappers.dwt1d(c1 * x1 + c2 * x2)\n    test2 = c1 * tfw.wrappers.dwt1d(x1) + c2 * tfw.wrappers.dwt1d(x2)\n\n    error = np.mean(np.abs(test1 - test2))\n    assert error < tol, ""Mean error: %g"" % error\n\n\ndef check_linearity_2d(wavelet, tol=1e-5, N=256):\n    x1 = np.random.random((N, N))\n    x2 = np.random.random((N, N))\n\n    c1 = np.random.random(1)\n    c2 = np.random.random(1)\n\n    test1 = tfw.wrappers.dwt2d(c1 * x1 + c2 * x2)\n    test2 = c1 * tfw.wrappers.dwt2d(x1) + c2 * tfw.wrappers.dwt2d(x2)\n\n    error = np.mean(np.abs(test1 - test2))\n    assert error < tol, ""Mean error: %g"" % error\n\n\ndef check_inverse_1d(wavelet, levels=1, tol=1e-4, N=256):\n    signal = np.random.random(N)\n\n    reconstructed = tfw.wrappers.idwt1d(\n        tfw.wrappers.dwt1d(signal, levels=levels),\n        levels=levels\n    )\n\n    error = np.mean(np.abs(signal - reconstructed))\n    assert error < tol, ""Mean error: %g"" % error\n\n\ndef check_inverse_2d(wavelet, levels=1, tol=1e-4, N=256):\n    signal = np.random.random((N, N))\n\n    reconstructed = tfw.wrappers.idwt2d(\n        tfw.wrappers.dwt2d(signal, levels=levels),\n        levels=levels\n    )\n\n    error = np.mean(np.abs(signal - reconstructed))\n    assert error < tol, ""Mean error: %g"" % error\n\n\ndef test_ortho_haar():\n    check_orthonormality_1d(""haar"")\n\ndef test_linear_haar_1d():\n    check_linearity_1d(""haar"")\n\ndef test_linear_haar_2d():\n    check_linearity_2d(""haar"")\n\ndef test_inverse_haar_1d():\n    check_inverse_1d(""haar"", levels=1)\n\ndef test_inverse_haar_1d_level2():\n    check_inverse_1d(""haar"", levels=2)\n\ndef test_inverse_haar_2d():\n    check_inverse_2d(""haar"", levels=2)\n\ndef test_ortho_db2():\n    check_orthonormality_1d(""db2"")\n\ndef test_linear_db2_2d():\n    check_linearity_2d(""db2"")\n\ndef test_linear_db2_1d():\n    check_linearity_1d(""db2"")\n\ndef test_inverse_db2_1d():\n    check_inverse_1d(""db2"", levels=1)\n\ndef test_inverse_db2_1d_level2():\n    check_inverse_1d(""db2"", levels=2)\n\ndef test_inverse_db2_2d():\n    check_inverse_2d(""db2"", levels=2)\n\n\ndef test_ortho_db3():\n    check_orthonormality_1d(""db3"")\n\ndef test_linear_db3_2d():\n    check_linearity_2d(""db3"")\n\ndef test_linear_db3_1d():\n    check_linearity_1d(""db3"")\n\ndef test_inverse_db3_1d():\n    check_inverse_1d(""db3"", levels=1)\n\ndef test_inverse_db3_1d_level2():\n    check_inverse_1d(""db3"", levels=2)\n\ndef test_inverse_db3_2d():\n    check_inverse_2d(""db3"", levels=2)\n\n\ndef test_ortho_db4():\n    check_orthonormality_1d(""db4"")\n\ndef test_linear_db4_2d():\n    check_linearity_2d(""db4"")\n\ndef test_linear_db4_1d():\n    check_linearity_1d(""db4"")\n\ndef test_inverse_db4_1d():\n    check_inverse_1d(""db4"", levels=1)\n\ndef test_inverse_db4_1d_level2():\n    check_inverse_1d(""db4"", levels=2)\n\ndef test_inverse_db4_2d():\n    check_inverse_2d(""db4"", levels=2)\n'"
tfwavelets/__init__.py,0,"b'""""""\nThe tfwavelets package offers ways to achieve discrete wavelet transforms in tensorflow.\n\nThe package consists of the following modules:\n\n    * \'nodes\' contains methods to construct TF subgraphs computing the 1D or 2D DWT or\n      IDWT. Intended to be used if you need a DWT in your own TF graph.\n    * \'wrappers\' contains methods that wraps around the functionality in nodes. The\n      construct a full TF graph, launches a session, and evaluates the graph. Intended to\n      be used when you just want to compute the DWT/IDWT of a signal.\n    * \'dwtcoeffs\' contains predefined wavelets, as well as the classes necessary to\n      create more user-defined wavelets.\n    * \'utils\' contains some useful helper functions, mostly used during the implementation\n      of the other modules.\n""""""\nfrom . import nodes\nfrom . import wrappers\nfrom . import dwtcoeffs\nfrom . import utils\n\n'"
tfwavelets/dwtcoeffs.py,33,"b'""""""\nThe \'dwtcoeffs\' module contains predefined wavelets, as well as the classes necessary to\ncreate more user-defined wavelets.\n\nWavelets are defined by the Wavelet class. A Wavelet object mainly consists of four Filter\nobjects (defined by the Filter class) representing the decomposition and reconstruction\nlow pass and high pass filters.\n\nExamples:\n    You can define your own wavelet by creating four filters, and combining them to a wavelet:\n\n    >>> decomp_lp = Filter([1 / np.sqrt(2), 1 / np.sqrt(2)], 0)\n    >>> decomp_hp = Filter([1 / np.sqrt(2), -1 / np.sqrt(2)], 1)\n    >>> recon_lp = Filter([1 / np.sqrt(2), 1 / np.sqrt(2)], 0)\n    >>> recon_hp = Filter([-1 / np.sqrt(2), 1 / np.sqrt(2)], 1)\n    >>> haar = Wavelet(decomp_lp, decomp_hp, recon_lp, recon_hp)\n\n""""""\n\nimport numpy as np\nimport tensorflow as tf\nfrom tfwavelets.utils import adapt_filter, to_tf_mat\n\n\nclass Filter:\n    """"""\n    Class representing a filter.\n\n    Attributes:\n        coeffs (tf.constant):      Filter coefficients\n        zero (int):                Origin of filter (which index of coeffs array is\n                                   actually indexed as 0).\n        edge_matrices (iterable):  List of edge matrices, used for circular convolution.\n                                   Stored as 3D TF tensors (constants).\n    """"""\n\n\n    def __init__(self, coeffs, zero):\n        """"""\n        Create a filter based on given filter coefficients\n\n        Args:\n            coeffs (np.ndarray):       Filter coefficients\n            zero (int):                Origin of filter (which index of coeffs array is\n                                       actually indexed as 0).\n        """"""\n        self.coeffs = tf.constant(adapt_filter(coeffs), dtype=tf.float32)\n\n        if not isinstance(coeffs, np.ndarray):\n            coeffs = np.array(self.coeffs)\n        self._coeffs = coeffs.astype(np.float32)\n\n        self.zero = zero\n\n        self.edge_matrices = to_tf_mat(self._edge_matrices())\n\n\n    def __getitem__(self, item):\n        """"""\n        Returns filter coefficients at requested indeces. Indeces are offset by the filter\n        origin\n\n        Args:\n            item (int or slice):    Item(s) to get\n\n        Returns:\n            np.ndarray: Item(s) at specified place(s)\n        """"""\n        if isinstance(item, slice):\n            return self._coeffs.__getitem__(\n                slice(item.start + self.zero, item.stop + self.zero, item.step)\n            )\n        else:\n            return self._coeffs.__getitem__(item + self.zero)\n\n\n    def num_pos(self):\n        """"""\n        Number of positive indexed coefficients in filter, including the origin. Ie,\n        strictly speaking it\'s the number of non-negative indexed coefficients.\n\n        Returns:\n            int: Number of positive indexed coefficients in filter.\n        """"""\n        return len(self._coeffs) - self.zero\n\n\n    def num_neg(self):\n        """"""\n        Number of negative indexed coefficients, excluding the origin.\n\n        Returns:\n            int: Number of negative indexed coefficients\n        """"""\n        return self.zero\n\n\n    def _edge_matrices(self):\n        """"""Computes the submatrices needed at the ends for circular convolution.\n\n        Returns:\n            Tuple of 2d-arrays, (top-left, top-right, bottom-left, bottom-right).\n        """"""\n        if not isinstance(self._coeffs, np.ndarray):\n            self._coeffs = np.array(self._coeffs)\n\n        n, = self._coeffs.shape\n        self._coeffs = self._coeffs[::-1]\n\n        # Some padding is necesssary to keep the submatrices\n        # from having having columns in common\n        padding = max((self.zero, n - self.zero - 1))\n        matrix_size = n + padding\n        filter_matrix = np.zeros((matrix_size, matrix_size), dtype=np.float32)\n        negative = self._coeffs[\n                   -(self.zero + 1):]  # negative indexed filter coeffs (and 0)\n        positive = self._coeffs[\n                   :-(self.zero + 1)]  # filter coeffs with strictly positive indeces\n\n        # Insert first row\n        filter_matrix[0, :len(negative)] = negative\n\n        # Because -0 == 0, a length of 0 makes it impossible to broadcast\n        # (nor is is necessary)\n        if len(positive) > 0:\n            filter_matrix[0, -len(positive):] = positive\n\n        # Cycle previous row to compute the entire filter matrix\n        for i in range(1, matrix_size):\n            filter_matrix[i, :] = np.roll(filter_matrix[i - 1, :], 1)\n\n        # TODO: Indexing not thoroughly tested\n        num_pos = len(positive)\n        num_neg = len(negative)\n        top_left = filter_matrix[:num_pos, :(num_pos + num_neg - 1)]\n        top_right = filter_matrix[:num_pos, -num_pos:]\n        bottom_left = filter_matrix[-num_neg + 1:, :num_neg - 1]\n        bottom_right = filter_matrix[-num_neg + 1:, -(num_pos + num_neg - 1):]\n\n        # Indexing wrong when there are no negative indexed coefficients\n        if num_neg == 1:\n            bottom_left = np.zeros((0, 0), dtype=np.float32)\n            bottom_right = np.zeros((0, 0), dtype=np.float32)\n\n        return top_left, top_right, bottom_left, bottom_right\n\n\nclass TrainableFilter(Filter):\n    """"""\n    Class representing a trainable filter.\n\n    Attributes:\n        coeffs (tf.Variable):      Filter coefficients\n        zero (int):                Origin of filter (which index of coeffs array is\n                                   actually indexed as 0).\n    """"""\n\n\n    def __init__(self, initial_coeffs, zero, name=None):\n        """"""\n        Create a trainable filter initialized with given filter coefficients\n\n        Args:\n            initial_coeffs (np.ndarray):    Initial filter coefficients\n            zero (int):                     Origin of filter (which index of coeffs array\n                                            is actually indexed as 0).\n            name (str):                     Optional. Name of tf variable created to hold\n                                            the filter coeffs.\n        """"""\n        super().__init__(initial_coeffs, zero)\n\n        self.coeffs = tf.Variable(\n            initial_value=adapt_filter(initial_coeffs),\n            trainable=True,\n            name=name,\n            dtype=tf.float32,\n            constraint=tf.keras.constraints.max_norm(np.sqrt(2), [1, 2])\n        )\n\n        # Erase stuff that will be invalid once the filter coeffs has changed\n        self._coeffs = [None]*len(self._coeffs)\n        self.edge_matrices = None\n\n\nclass Wavelet:\n    """"""\n    Class representing a wavelet.\n\n    Attributes:\n        decomp_lp (Filter):    Filter coefficients for decomposition low pass filter\n        decomp_hp (Filter):    Filter coefficients for decomposition high pass filter\n        recon_lp (Filter):     Filter coefficients for reconstruction low pass filter\n        recon_hp (Filter):     Filter coefficients for reconstruction high pass filter\n    """"""\n\n\n    def __init__(self, decomp_lp, decomp_hp, recon_lp, recon_hp):\n        """"""\n        Create a new wavelet based on specified filters\n\n        Args:\n            decomp_lp (Filter):    Filter coefficients for decomposition low pass filter\n            decomp_hp (Filter):    Filter coefficients for decomposition high pass filter\n            recon_lp (Filter):     Filter coefficients for reconstruction low pass filter\n            recon_hp (Filter):     Filter coefficients for reconstruction high pass filter\n        """"""\n        self.decomp_lp = decomp_lp\n        self.decomp_hp = decomp_hp\n        self.recon_lp = recon_lp\n        self.recon_hp = recon_hp\n\n\nclass TrainableWavelet(Wavelet):\n    """"""\n    Class representing a trainable wavelet\n\n    Attributes:\n        decomp_lp (TrainableFilter):    Filter coefficients for decomposition low pass filter\n        decomp_hp (TrainableFilter):    Filter coefficients for decomposition high pass filter\n        recon_lp (TrainableFilter):     Filter coefficients for reconstruction low pass filter\n        recon_hp (TrainableFilter):     Filter coefficients for reconstruction high pass filter\n    """"""\n\n\n    def __init__(self, wavelet):\n        """"""\n        Create a new trainable wavelet initialized as specified wavelet\n\n        Args:\n            wavelet (Wavelet):          Starting point for the trainable wavelet\n        """"""\n        super().__init__(\n            TrainableFilter(wavelet.decomp_lp._coeffs, wavelet.decomp_lp.zero),\n            TrainableFilter(wavelet.decomp_hp._coeffs, wavelet.decomp_hp.zero),\n            TrainableFilter(wavelet.recon_lp._coeffs, wavelet.recon_lp.zero),\n            TrainableFilter(wavelet.recon_hp._coeffs, wavelet.recon_hp.zero)\n        )\n\n\n# Haar wavelet\nhaar = Wavelet(\n    Filter(np.array([0.70710677, 0.70710677]), 1),\n    Filter(np.array([-0.70710677, 0.70710677]), 0),\n    Filter(np.array([0.70710677, 0.70710677]), 0),\n    Filter(np.array([0.70710677, -0.70710677]), 1),\n)\n\n# Daubechies wavelets\ndb1 = haar\ndb2 = Wavelet(\n    Filter(np.array([-0.12940952255092145,\n                     0.22414386804185735,\n                     0.836516303737469,\n                     0.48296291314469025]), 3),\n    Filter(np.array([-0.48296291314469025,\n                     0.836516303737469,\n                     -0.22414386804185735,\n                     -0.12940952255092145]), 0),\n    Filter(np.array([0.48296291314469025,\n                     0.836516303737469,\n                     0.22414386804185735,\n                     -0.12940952255092145]), 0),\n    Filter(np.array([-0.12940952255092145,\n                     -0.22414386804185735,\n                     0.836516303737469,\n                     -0.48296291314469025]), 3)\n)\ndb3 = Wavelet(\n    Filter(np.array([0.035226291882100656,\n                    -0.08544127388224149,\n                    -0.13501102001039084,\n                    0.4598775021193313,\n                    0.8068915093133388,\n                    0.3326705529509569]), 5),\n    Filter(np.array([-0.3326705529509569,\n                    0.8068915093133388,\n                    -0.4598775021193313,\n                    -0.13501102001039084,\n                    0.08544127388224149,\n                    0.035226291882100656]), 0),\n    Filter(np.array([0.3326705529509569,\n                    0.8068915093133388,\n                    0.4598775021193313,\n                    -0.13501102001039084,\n                    -0.08544127388224149,\n                    0.035226291882100656]), 0),\n    Filter(np.array([0.035226291882100656,\n                    0.08544127388224149,\n                    -0.13501102001039084,\n                    -0.4598775021193313,\n                    0.8068915093133388,\n                    -0.3326705529509569]), 5)\n)\ndb4 = Wavelet(\n    Filter(np.array([-0.010597401784997278,\n                    0.032883011666982945,\n                    0.030841381835986965,\n                    -0.18703481171888114,\n                    -0.02798376941698385,\n                    0.6308807679295904,\n                    0.7148465705525415,\n                    0.23037781330885523]), 7),\n    Filter(np.array([-0.23037781330885523,\n                    0.7148465705525415,\n                    -0.6308807679295904,\n                    -0.02798376941698385,\n                    0.18703481171888114,\n                    0.030841381835986965,\n                    -0.032883011666982945,\n                    -0.010597401784997278]), 0),\n    Filter(np.array([0.23037781330885523,\n                    0.7148465705525415,\n                    0.6308807679295904,\n                    -0.02798376941698385,\n                    -0.18703481171888114,\n                    0.030841381835986965,\n                    0.032883011666982945,\n                    -0.010597401784997278]), 0),\n    Filter(np.array([-0.010597401784997278,\n                    -0.032883011666982945,\n                    0.030841381835986965,\n                    0.18703481171888114,\n                    -0.02798376941698385,\n                    -0.6308807679295904,\n                    0.7148465705525415,\n                    -0.23037781330885523]), 7)\n)\n\n'"
tfwavelets/nodes.py,0,"b'""""""\nThe \'nodes\' module contains methods to construct TF subgraphs computing the 1D or 2D DWT\nor IDWT. Intended to be used if you need a DWT in your own TF graph.\n""""""\n\nimport tensorflow as tf\n\n\ndef cyclic_conv1d(input_node, filter_):\n    """"""\n    Cyclic convolution\n\n    Args:\n        input_node:  Input signal (3-tensor [batch, width, in_channels])\n        filter_:     Filter\n\n    Returns:\n        Tensor with the result of a periodic convolution\n    """"""\n    # Create shorthands for TF nodes\n    kernel_node = filter_.coeffs\n    tl_node, tr_node, bl_node, br_node = filter_.edge_matrices\n\n    # Do inner convolution\n    inner = tf.nn.conv1d(input_node, kernel_node[::-1], stride=1, padding=\'VALID\')\n\n    # Create shorthands for shapes\n    input_shape = tf.shape(input_node)\n    tl_shape = tf.shape(tl_node)\n    tr_shape = tf.shape(tr_node)\n    bl_shape = tf.shape(bl_node)\n    br_shape = tf.shape(br_node)\n\n    # Slices of the input signal corresponding to the corners\n    tl_slice = tf.slice(input_node,\n                        [0, 0, 0],\n                        [-1, tl_shape[2], -1])\n    tr_slice = tf.slice(input_node,\n                        [0, input_shape[1] - tr_shape[2], 0],\n                        [-1, tr_shape[2], -1])\n    bl_slice = tf.slice(input_node,\n                        [0, 0, 0],\n                        [-1, bl_shape[2], -1])\n    br_slice = tf.slice(input_node,\n                        [0, input_shape[1] - br_shape[2], 0],\n                        [-1, br_shape[2], -1])\n\n    # TODO: It just werks (It\'s the magic of the algorithm). i.e. Why do we have to transpose?\n    tl = tl_node @ tf.transpose(tl_slice, perm=[2, 1, 0])\n    tr = tr_node @ tf.transpose(tr_slice, perm=[2, 1, 0])\n    bl = bl_node @ tf.transpose(bl_slice, perm=[2, 1, 0])\n    br = br_node @ tf.transpose(br_slice, perm=[2, 1, 0])\n\n    head = tf.transpose(tl + tr, perm=[2, 1, 0])\n    tail = tf.transpose(bl + br, perm=[2, 1, 0])\n\n    return tf.concat((head, inner, tail), axis=1)\n\n\ndef cyclic_conv1d_alt(input_node, filter_):\n    """"""\n    Alternative cyclic convolution. Uses more memory than cyclic_conv1d.\n\n    Args:\n        input_node:         Input signal\n        filter_ (Filter):   Filter object\n\n    Returns:\n        Tensor with the result of a periodic convolution.\n    """"""\n    kernel_node = filter_.coeffs\n\n    N = int(input_node.shape[1])\n\n    start = N - filter_.num_neg()\n    end = filter_.num_pos() - 1\n\n    # Perodically extend input signal\n    input_new = tf.concat(\n        (input_node[:, start:, :], input_node, input_node[:, 0:end, :]),\n        axis=1\n    )\n\n    # Convolve with periodic extension\n    result = tf.nn.conv1d(input_new, kernel_node[::-1], stride=1, padding=""VALID"")\n\n    return result\n\n\ndef upsample(input_node, odd=False):\n    """"""Upsamples. Doubles the length of the input, filling with zeros\n\n    Args:\n        input_node: 3-tensor [batch, spatial dim, channels] to be upsampled\n        odd:        Bool, optional. If True, content of input_node will be\n                    placed on the odd indeces of the output. Otherwise, the\n                    content will be places on the even indeces. This is the\n                    default behaviour.\n\n    Returns:\n        The upsampled output Tensor.\n    """"""\n\n    columns = []\n    for col in tf.unstack(input_node, axis=1):\n        columns.extend([col, tf.zeros_like(col)])\n\n    if odd:\n        # https://stackoverflow.com/questions/30097512/how-to-perform-a-pairwise-swap-of-a-list\n        # TODO: Understand\n        # Rounds down to even number\n        l = len(columns) & -2\n        columns[1:l:2], columns[:l:2] = columns[:l:2], columns[1:l:2]\n\n    # TODO: Should we actually expand the dimension?\n    return tf.expand_dims(tf.concat(columns, 1), -1)\n\n\ndef dwt1d(input_node, wavelet, levels=1):\n    """"""\n    Constructs a TF computational graph computing the 1D DWT of an input signal.\n\n    Args:\n        input_node:     A 3D tensor containing the signal. The dimensions should be\n                        [batch, signal, channels].\n        wavelet:        Wavelet object\n        levels:         Number of levels.\n\n    Returns:\n        The output node of the DWT graph.\n    """"""\n    # TODO: Check that level is a reasonable number\n    # TODO: Check types\n\n    coeffs = [None] * (levels + 1)\n\n    last_level = input_node\n\n    for level in range(levels):\n        lp_res = cyclic_conv1d_alt(last_level, wavelet.decomp_lp)[:, ::2, :]\n        hp_res = cyclic_conv1d_alt(last_level, wavelet.decomp_hp)[:, 1::2, :]\n\n        last_level = lp_res\n        coeffs[levels - level] = hp_res\n\n    coeffs[0] = last_level\n    return tf.concat(coeffs, axis=1)\n\n\ndef dwt2d(input_node, wavelet, levels=1):\n    """"""\n    Constructs a TF computational graph computing the 2D DWT of an input signal.\n\n    Args:\n        input_node:     A 3D tensor containing the signal. The dimensions should be\n                        [rows, cols, channels].\n        wavelet:        Wavelet object.\n        levels:         Number of levels.\n\n    Returns:\n        The output node of the DWT graph.\n    """"""\n    # TODO: Check that level is a reasonable number\n    # TODO: Check types\n\n    coeffs = [None] * levels\n\n    last_level = input_node\n    m, n = int(input_node.shape[0]), int(input_node.shape[1])\n\n    for level in range(levels):\n        local_m, local_n = m // (2 ** level), n // (2 ** level)\n\n        first_pass = dwt1d(last_level, wavelet, 1)\n        second_pass = tf.transpose(\n            dwt1d(\n                tf.transpose(first_pass, perm=[1, 0, 2]),\n                wavelet,\n                1\n            ),\n            perm=[1, 0, 2]\n        )\n\n        last_level = tf.slice(second_pass, [0, 0, 0], [local_m // 2, local_n // 2, 1])\n        coeffs[level] = [\n            tf.slice(second_pass, [local_m // 2, 0, 0], [local_m // 2, local_n // 2, 1]),\n            tf.slice(second_pass, [0, local_n // 2, 0], [local_m // 2, local_n // 2, 1]),\n            tf.slice(second_pass, [local_m // 2, local_n // 2, 0],\n                     [local_m // 2, local_n // 2, 1])\n        ]\n\n    for level in range(levels - 1, -1, -1):\n        upper_half = tf.concat([last_level, coeffs[level][0]], 0)\n        lower_half = tf.concat([coeffs[level][1], coeffs[level][2]], 0)\n\n        last_level = tf.concat([upper_half, lower_half], 1)\n\n    return last_level\n\n\ndef idwt1d(input_node, wavelet, levels=1):\n    """"""\n    Constructs a TF graph that computes the 1D inverse DWT for a given wavelet.\n\n    Args:\n        input_node (tf.placeholder):             Input signal. A 3D tensor with dimensions\n                                                 as [batch, signal, channels]\n        wavelet (tfwavelets.dwtcoeffs.Wavelet):  Wavelet object.\n        levels (int):                            Number of levels.\n\n    Returns:\n        Output node of IDWT graph.\n    """"""\n    m, n = int(input_node.shape[0]), int(input_node.shape[1])\n\n    first_n = n // (2 ** levels)\n    last_level = tf.slice(input_node, [0, 0, 0], [m, first_n, 1])\n\n    for level in range(levels - 1, -1 , -1):\n        local_n = n // (2 ** level)\n\n        detail = tf.slice(input_node, [0, local_n//2, 0], [m, local_n//2, 1])\n\n        lowres_padded = upsample(last_level, odd=False)\n        detail_padded = upsample(detail, odd=True)\n\n        lowres_filtered = cyclic_conv1d_alt(lowres_padded, wavelet.recon_lp)\n        detail_filtered = cyclic_conv1d_alt(detail_padded, wavelet.recon_hp)\n\n        last_level = lowres_filtered + detail_filtered\n\n    return last_level\n\n\ndef idwt2d(input_node, wavelet, levels=1):\n    """"""\n    Constructs a TF graph that computes the 2D inverse DWT for a given wavelet.\n\n    Args:\n        input_node (tf.placeholder):             Input signal. A 3D tensor with dimensions\n                                                 as [rows, cols, channels]\n        wavelet (tfwavelets.dwtcoeffs.Wavelet):  Wavelet object.\n        levels (int):                            Number of levels.\n\n    Returns:\n        Output node of IDWT graph.\n    """"""\n    m, n = int(input_node.shape[0]), int(input_node.shape[1])\n    first_m, first_n = m // (2 ** levels), n // (2 ** levels)\n\n    last_level = tf.slice(input_node, [0, 0, 0], [first_m, first_n, 1])\n\n    for level in range(levels - 1, -1, -1):\n        local_m, local_n = m // (2 ** level), n // (2 ** level)\n\n        # Extract detail spaces\n        detail_tr = tf.slice(input_node, [local_m // 2, 0, 0],\n                             [local_n // 2, local_m // 2, 1])\n        detail_bl = tf.slice(input_node, [0, local_n // 2, 0],\n                             [local_n // 2, local_m // 2, 1])\n        detail_br = tf.slice(input_node, [local_n // 2, local_m // 2, 0],\n                             [local_n // 2, local_m // 2, 1])\n\n        # Construct image of this DWT level\n        upper_half = tf.concat([last_level, detail_tr], 0)\n        lower_half = tf.concat([detail_bl, detail_br], 0)\n\n        this_level = tf.concat([upper_half, lower_half], 1)\n\n        # First pass, corresponding to second pass in dwt2d\n        first_pass = tf.transpose(\n            idwt1d(\n                tf.transpose(this_level, perm=[1, 0, 2]),\n                wavelet,\n                1\n            ),\n            perm=[1, 0, 2]\n        )\n        # Second pass, corresponding to first pass in dwt2d\n        second_pass = idwt1d(first_pass, wavelet, 1)\n\n        last_level = second_pass\n\n    return last_level\n'"
tfwavelets/utils.py,4,"b'""""""\nThe \'utils\' module contains some useful helper functions, mostly used during the\nimplementation of the other modules.\n""""""\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndef adapt_filter(filter):\n    """"""\n    Expands dimensions of a 1d vector to match the required tensor dimensions in a TF\n    graph.\n\n    Args:\n        filter (np.ndarray):     A 1D vector containing filter coefficients\n\n    Returns:\n        np.ndarray: A 3D vector with two empty dimensions as dim 2 and 3.\n\n    """"""\n    # Add empty dimensions for batch size and channel num\n    return np.expand_dims(np.expand_dims(filter, -1), -1)\n\n\ndef to_tf_mat(matrices):\n    """"""\n    Expands dimensions of 2D matrices to match the required tensor dimensions in a TF\n    graph, and wrapping them as TF constants.\n\n    Args:\n        matrices (iterable):    A list (or tuple) of 2D numpy arrays.\n\n    Returns:\n        iterable: A list of all the matrices converted to 3D TF tensors.\n    """"""\n    result = []\n\n    for matrix in matrices:\n        result.append(\n            tf.constant(np.expand_dims(matrix, 0), dtype=tf.float32)\n        )\n\n    return result\n'"
tfwavelets/wrappers.py,20,"b'""""""\nThe \'wrappers\' module contains methods that wraps around the functionality in nodes. The\nconstruct a full TF graph, launches a session, and evaluates the graph. Intended to be\nused when you just want to compute the DWT/IDWT of a signal.\n""""""\n\nimport numpy as np\nimport tfwavelets as tfw\nimport tensorflow as tf\n\n\ndef dwt1d(signal, wavelet=""haar"", levels=1):\n    """"""\n    Computes the DWT of a 1D signal.\n\n    Args:\n        signal (np.ndarray):    A 1D array to compute DWT of.\n        wavelet (str):          Type of wavelet (haar or db2)\n        levels (int):           Number of DWT levels\n\n    Returns:\n        np.ndarray: The DWT of the signal.\n\n    Raises:\n        ValueError: If wavelet is not supported\n    """"""\n    # Prepare signal for tf. Turn into 32bit floats for GPU computation, and\n    # expand dims to make it into a 3d tensor so tf.nn.conv1d is happy\n    signal = signal.astype(np.float32)\n    signal = np.expand_dims(signal, 0)\n    signal = np.expand_dims(signal, -1)\n\n    # Construct and compute TF graph\n    return _construct_and_compute_graph(\n        signal,\n        tfw.nodes.dwt1d,\n        _parse_wavelet(wavelet),\n        levels\n    )\n\n\ndef dwt2d(signal, wavelet=""haar"", levels=1):\n    """"""\n    Computes the DWT of a 2D signal.\n\n    Args:\n        signal (np.ndarray):    A 2D array to compute DWT of.\n        wavelet (str):          Type of wavelet (haar or db2)\n        levels (int):           Number of DWT levels\n\n    Returns:\n        np.ndarray: The DWT of the signal.\n\n    Raises:\n        ValueError: If wavelet is not supported\n    """"""\n    # Prepare signal for tf. Turn into 32bit floats for GPU computation, and\n    # expand dims to make it into a 3d tensor so tf.nn.conv1d is happy\n    signal = signal.astype(np.float32)\n    signal = np.expand_dims(signal, -1)\n\n    # Construct and compute TF graph\n    return _construct_and_compute_graph(\n        signal,\n        tfw.nodes.dwt2d,\n        _parse_wavelet(wavelet),\n        levels\n    )\n\n\ndef idwt1d(signal, wavelet=""haar"", levels=1):\n    """"""\n    Computes the inverse DWT of a 1D signal.\n\n    Args:\n        signal (np.ndarray):    A 1D array to compute IDWT of.\n        wavelet (str):          Type of wavelet (haar or db2)\n        levels (int):           Number of DWT levels\n\n    Returns:\n        np.ndarray: The IDWT of the signal.\n\n    Raises:\n        ValueError: If wavelet is not supported\n    """"""\n    # Prepare signal for tf. Turn into 32bit floats for GPU computation, and\n    # expand dims to make it into a 3d tensor so tf.nn.conv1d is happy\n    signal = signal.astype(np.float32)\n    signal = np.expand_dims(signal, 0)\n    signal = np.expand_dims(signal, -1)\n\n    # Construct and compute TF graph\n    return _construct_and_compute_graph(\n        signal,\n        tfw.nodes.idwt1d,\n        _parse_wavelet(wavelet),\n        levels\n    )\n\n\ndef idwt2d(signal, wavelet=""haar"", levels=1):\n    """"""\n    Computes the inverse DWT of a 2D signal.\n\n    Args:\n        signal (np.ndarray):    A 2D array to compute iDWT of.\n        wavelet (str):          Type of wavelet (haar or db2)\n        levels (int):           Number of DWT levels\n\n    Returns:\n        np.ndarray: The IDWT of the signal.\n\n    Raises:\n        ValueError: If wavelet is not supported\n    """"""\n    # Prepare signal for tf. Turn into 32bit floats for GPU computation, and\n    # expand dims to make it into a 3d tensor so tf.nn.conv1d is happy\n    signal = signal.astype(np.float32)\n    signal = np.expand_dims(signal, -1)\n\n    # Construct and compute TF graph\n    return _construct_and_compute_graph(\n        signal,\n        tfw.nodes.idwt2d,\n        _parse_wavelet(wavelet),\n        levels\n    )\n\n\ndef _construct_and_compute_graph(input_signal, node, wavelet_obj, levels):\n    """"""\n    Constructs a TF graph processing the input signal with given node and evaluates it.\n\n    Args:\n        input_signal:       Input signal. A 3D array with [batch, signal, channels]\n        node:               Node to process signal with, any kind of dwt/idwt\n        wavelet_obj:        Wavelet object to pass to node\n        levels:             Num of levels (passed to node)\n\n    Returns:\n\n    """"""\n    # Placeholder for input signal\n    tf_signal = tf.placeholder(dtype=tf.float32, shape=input_signal.shape)\n\n    # Set up tf graph\n    output = node(tf_signal, wavelet=wavelet_obj, levels=levels)\n\n    # Compute graph\n    with tf.Session() as sess:\n        signal = sess.run(output, feed_dict={tf_signal: input_signal})\n\n    # Remove empty dimensions and return\n    return np.squeeze(signal)\n\n\ndef _parse_wavelet(wavelet):\n    """"""\n    Look for wavelet coeffs in database, and return them if they exists\n\n    Args:\n        wavelet (str):     Name of wavelet\n\n    Returns:\n        (np.ndarray, np.ndarray): Filters for wavelet\n\n    Raises:\n        ValueError: If wavelet is not supported\n    """"""\n    if wavelet == ""haar"":\n        return tfw.dwtcoeffs.haar\n    elif wavelet == ""db2"":\n        return tfw.dwtcoeffs.db2\n    elif wavelet == ""db3"":\n        return tfw.dwtcoeffs.db3\n    elif wavelet == ""db4"":\n        return tfw.dwtcoeffs.db4\n    else:\n        raise ValueError(""dwt1d does not support wavelet {}"".format(wavelet))\n'"
