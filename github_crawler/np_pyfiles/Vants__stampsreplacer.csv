file_path,api_count,code
Main.py,0,"b'import os\n\nimport sys\n\nfrom scripts import RESOURCES_PATH\nfrom scripts.processes.CreateLonLat import CreateLonLat\nfrom scripts.processes.PhaseCorrection import PhaseCorrection\nfrom scripts.processes.PsEstGamma import PsEstGamma\nfrom scripts.processes.PsFiles import PsFiles\nfrom scripts.processes.PsSelect import PsSelect\nfrom scripts.processes.PsWeed import PsWeed\nfrom scripts.utils.internal.ConfigUtils import ConfigUtils\nfrom scripts.utils.internal.LoggerFactory import LoggerFactory\nfrom scripts.utils.internal.ProcessHandler import ProcessHandler\n\n\nclass Main:\n    processes = [CreateLonLat, PsFiles, PsEstGamma, PsSelect, PsWeed, PhaseCorrection]\n\n    def __init__(self) -> None:\n        self.__logger = LoggerFactory.create(""Main"")\n\n        self.__process_factory = self.__make_process_factory()\n\n    def run(self, start=0, end=8):\n        """"""\n        The parameters start and end indicate the index of the process start and when to end\n        processing. The smallest number is 0 and the greatest 5 (see len(self.processes)).\n\n        You can run one process at the time when you set start and end to equal value\n        (:e.g. run(0, 0)).\n\n        :param start: step index where to start processing\n        :param end: step index where to end processing\n        :return: saves result(s) to save_load_path that is configuration\n        """"""\n\n        step = -1\n        try:\n            for step in range(len(self.processes)):\n                if (step - 1) == end:\n                    break\n                elif step < start:\n                    self.__load_saved(step)\n                else:\n                    self.__start_process(step)\n        except Exception:\n            self.__logger.error(""Main process run error"", exc_info=True)\n            end = (step - 1)\n        finally:\n            self.__save_results(start, end)\n\n    def __load_saved(self, step: int):\n        self.__process_factory.load_results(self.processes[step])\n\n    def __start_process(self, step: int):\n        self.__process_factory.start_process(self.processes[step])\n\n    def __save_results(self, start: int, end: int):\n        for step in range(len(self.processes)):\n            if step < start:\n                continue\n            elif (step - 1) == end:\n                break\n            elif step >= start:\n                self.__process_factory.save_process(self.processes[step])\n\n    def __assert_params(self, start: int, stop: int):\n        if start < 0:\n            raise AttributeError(""Start less than 0"")\n        elif stop > len(self.processes):\n            raise AttributeError(\n                ""Stop more than than {0} or len(self.processes)"".format(len(self.processes)))\n\n    def __make_process_factory(self) -> ProcessHandler:\n        path, geo_file_path, save_load_path, rand_dist_cached = self.__get_from_config()\n        return ProcessHandler(path, geo_file_path, save_load_path, rand_dist_cached)\n\n    # noinspection PyMethodMayBeStatic\n    def __get_from_config(self) -> (str, str, str, bool):\n        self.__logger.info(""Loading params form {0}"".format(RESOURCES_PATH))\n\n        config = ConfigUtils(RESOURCES_PATH)\n        initial_path = config.get_default_section(\'path\')\n        patch_folder = config.get_default_section(\'patch_folder\')\n        # Stamps or SNAP files/folder(not mandatory)/PATCH_1\n        path = os.path.join(initial_path, patch_folder)\n\n        geo_file = config.get_default_section(\'geo_file\')\n        geo_file_path = os.path.join(initial_path, geo_file)\n\n        save_load_path = config.get_default_section(\'save_load_path\')\n\n        rand_dist_cached = config.get_default_section(\'rand_dist_cached\') == \'True\'\n\n        self.__logger.info(""Loaded params. path {0}, geo_file_path {1}, save_load_path {2},""\n                           "" rand_dist_cached {3}"".format(path, geo_file_path, save_load_path,\n                                                          rand_dist_cached))\n        return path, geo_file_path, save_load_path, rand_dist_cached\n\n\nif __name__ == \'__main__\':\n    if len(sys.argv) > 3:\n        print(""Use Main <start> <end>. Params are not mandatory"")\n    elif len(sys.argv) == 1:\n        main = Main()\n        main.run()\n    else:\n        main = Main()\n        main.run(start=int(sys.argv[1]), end=int(sys.argv[2]))\n'"
cython_setup.py,0,"b'from distutils.core import setup\nfrom pathlib import Path\n\nfrom Cython.Build import cythonize\n\ncompileable_files_path = [Path(""scripts"", ""utils"", ""ArrayUtils.py""),\n                          Path(""scripts"", ""utils"", ""MatlabUtils.py""),\n                          Path(""scripts"", ""utils"", ""MatrixUtils.py""),\n                          Path(""scripts"", ""processes"", ""CreateLonLat.py""),\n                          Path(""scripts"", ""processes"", ""PsEstGamma.py""),\n                          Path(""scripts"", ""processes"", ""PsFiles.py""),\n                          Path(""scripts"", ""processes"", ""PhaseCorrection.py""),\n                          Path(""scripts"", ""processes"", ""PsWeed.py""),\n                          Path(""scripts"", ""processes"", ""PsSelect.py""),\n                          Path(""scripts"", ""funs"", ""PsTopofit.py"")]\nfiles_str = []\n\nfor file_name_with_path in compileable_files_path:\n    if not file_name_with_path.exists():\n        print(""No file \'{0}\'"".format(str(file_name_with_path)))\n    else:\n        files_str.append(str(file_name_with_path))\n\n\nsetup(ext_modules=cythonize(files_str))\n'"
scripts/MetaSubProcess.py,0,"b'from abc import ABCMeta, abstractmethod\n\n\nclass MetaSubProcess(metaclass=ABCMeta):\n    @abstractmethod\n    def start_process(self): pass\n\n    @abstractmethod\n    def save_results(self, save_path: str): pass\n\n    @abstractmethod\n    def load_results(self, load_path): pass\n'"
scripts/__init__.py,0,"b""import os\n\nRESOURCES_PATH = os.path.abspath(\n    os.path.join(os.path.dirname(os.path.realpath(__file__)), '..', 'resources'))"""
tests/MetaTestCase.py,1,"b'import os\nfrom unittest import TestCase\nimport numpy as np\n\nfrom scripts.utils.internal.FolderConstants import FolderConstants\nfrom scripts.utils.internal.ConfigUtils import ConfigUtils\nfrom tests import TEST_RESOURCES_PATH\n\n\nclass MetaTestCase(TestCase):\n    """"""Abstract class for tests. Setup function and some helper functions""""""\n    _PLACES = 5\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n        cls._config = ConfigUtils(TEST_RESOURCES_PATH)\n\n        cls._PATH = cls._config.get_default_section(\'tests_files_path\')\n\n        PATCH_FOLDER = cls._config.get_default_section(\'patch_folder\')\n\n        cls._PATCH_1_FOLDER = os.path.join(cls._PATH, PATCH_FOLDER, FolderConstants.PATCH_FOLDER_NAME)\n\n        cls._PATH_PATCH_FOLDER = os.path.join(cls._PATH, PATCH_FOLDER)\n\n        cls._SAVE_LOAD_PATH = cls._config.get_default_section(\'save_load_path\')\n\n    def assert_array_not_empty(self, array: np.ndarray):\n        self.assertNotEqual(array.size, 0)'"
tests/__init__.py,0,"b""import os\n\nTEST_RESOURCES_PATH = os.path.abspath(\n    os.path.join(os.path.dirname(os.path.realpath(__file__)), 'resources'))\n"""
tests/test_main.py,0,"b'import os\nimport unittest\n\nimport numpy as np\n\nfrom scripts import RESOURCES_PATH\nfrom Main import Main\nfrom scripts.processes.CreateLonLat import CreateLonLat\nfrom scripts.processes.PsEstGamma import PsEstGamma\nfrom scripts.processes.PsFiles import PsFiles\nfrom scripts.utils.internal.ConfigUtils import ConfigUtils\nfrom scripts.utils.internal.FolderConstants import FolderConstants\nfrom scripts.utils.internal.LoggerFactory import LoggerFactory\nfrom tests.MetaTestCase import MetaTestCase\n\n\nclass TestMain(MetaTestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        """"""Load configuartion for testing.""""""\n        super().setUpClass()\n\n        cls._config = ConfigUtils(RESOURCES_PATH)\n\n        cls._PATH = cls._config.get_default_section(\'path\')\n\n        PATCH_FOLDER = cls._config.get_default_section(\'patch_folder\')\n\n        cls._PATCH_1_FOLDER = os.path.join(cls._PATH, PATCH_FOLDER,\n                                           FolderConstants.PATCH_FOLDER_NAME)\n\n        cls._PATH_PATCH_FOLDER = os.path.join(cls._PATH, PATCH_FOLDER)\n\n        cls._SAVE_LOAD_PATH = cls._config.get_default_section(\'save_load_path\')\n\n        cls.__logger = LoggerFactory.create(""TestMain"")\n\n    @unittest.skip(""Skiping whole process test"")\n    def test_run_whole_process(self):\n        """"""Please be cautios with this test. This takes very long time and deletes all files in\n        SAVE_LOAD_PATH directory.""""""\n\n        main = Main()\n        main.run()\n\n    def test_run_only_first(self):\n        self.__delete_saved_files(self._SAVE_LOAD_PATH, ""lonlat_process"")\n\n        main = Main()\n        main.run(0, 0)\n\n        # geo_ref_product parameter may be empty cause we use saved data\n        lonlat_process = CreateLonLat(self._PATH, """")\n        lonlat_process.load_results(self._SAVE_LOAD_PATH)\n\n        self.assert_array_not_empty(lonlat_process.lonlat)\n        self.assert_array_not_empty(lonlat_process.pscands_ij)\n\n    def test_run_start_second_stop_second(self):\n        self.__delete_saved_files(self._SAVE_LOAD_PATH, ""ps_files"")\n\n        main = Main()\n        main.run(1, 1)\n\n        # Let\'s put empty arrays here. These are not needed when loading data\n        ps_files_loaded = PsFiles(self._PATH_PATCH_FOLDER, CreateLonLat(self._PATH, """"))\n        ps_files_loaded.load_results(self._SAVE_LOAD_PATH)\n\n        # \xc3\x9chest kontrollist piisab k\xc3\xbcll. T\xc3\xa4psemad kontrollid on juba spetsiifilises klassis\n        self.assert_array_not_empty(ps_files_loaded.bperp)\n\n    def test_run_start_second_stop_third(self):\n        self.__delete_saved_files(self._SAVE_LOAD_PATH, ""ps_files"")\n        self.__delete_saved_files(self._SAVE_LOAD_PATH, ""ps_est_gamma"")\n\n        main = Main()\n        main.run(1, 2)\n\n        # Let\'s put empty arrays here. These are not needed when loading data\n        ps_files_loaded = PsFiles(self._PATH_PATCH_FOLDER, CreateLonLat(self._PATH, """"))\n        ps_files_loaded.load_results(self._SAVE_LOAD_PATH)\n\n        self.assert_array_not_empty(ps_files_loaded.bperp)\n\n        ps_est_gamma_loaded = PsEstGamma(ps_files_loaded)\n        ps_est_gamma_loaded.load_results(self._SAVE_LOAD_PATH)\n\n        self.assert_array_not_empty(ps_est_gamma_loaded.low_pass)\n\n    def __delete_saved_files(self, path, file_name=None):\n        """"""This deletes all .npz files in path directory when file name is not showed.""""""\n\n        self.__logger.info(""Deleting .npz files in "" + path)\n        for file in os.listdir(path):\n            file_path = os.path.join(path, file)\n            file_extension = os.path.splitext(file)[-1].lower()\n            try:\n                if os.path.isfile(file_path) and file_extension == \'.npz\':\n                    if file_name is not None and file == file_name:\n                        os.remove(file_path)\n                    elif file_name is None:\n                        os.remove(file_path)\n            except OSError as e:\n                self.__logger.error(""Error when deleting: "" + str(e))\n'"
scripts/funs/PsTopofit.py,34,"b'import numpy as np\n\nimport math\n\nfrom scripts.utils.ArrayUtils import ArrayUtils\nfrom scripts.utils.MatlabUtils import MatlabUtils\n\n\n# Todo tests for class\nclass PsTopofit:\n    """"""Class calculation for Topofit. The main logic in topofit ps_topofit_loop function""""""\n\n    k_ps = np.ndarray\n    c_ps = np.ndarray\n    coh_ps = np.ndarray\n    n_opt = np.ndarray\n    ph_res = np.ndarray\n\n    def __init__(self, sw_array_shape: tuple, nr_ps: int, nr_ifg: int):\n        self.__nr_ps = nr_ps\n\n        self.k_ps = np.zeros(sw_array_shape)\n        self.c_ps = np.zeros(sw_array_shape)\n        self.coh_ps = np.zeros(sw_array_shape)\n        self.n_opt = np.zeros(sw_array_shape)\n        self.ph_res = np.zeros((nr_ps, nr_ifg))\n\n    def ps_topofit_loop(self, ph: np.ndarray, ph_patch: np.ndarray, bprep: np.ndarray,\n                        nr_trial_wraps: float, ifg_ind=None):\n        """"""\n        The Function for calculating topofit. The arrays that are initialized in constructor are filled with\n        values in this function.\n\n        :param ph:\n        :param ph_patch:\n        :param bprep:\n        :param nr_trial_wraps:\n        :param ifg_ind:\n        :return: None. The calculated values are written in the class parameters (k_ps, c_ps, coh_ps,\n        n_opt, ph_res).\n        """"""\n\n        for i in range(self.__nr_ps):\n            psdph = np.multiply(ph[i, :], ph_patch[i, :].conj())\n\n            if np.count_nonzero(np.isnan(psdph)) == 0 and np.count_nonzero(psdph == 0) == 0:\n                if ifg_ind is not None:\n                    psdph = psdph / np.abs(psdph)\n                    psdph = psdph[ifg_ind]\n\n                phase_residual, coh_0, static_offset, k_0 = self.ps_topofit_fun(psdph,\n                                                                       bprep[i, ifg_ind].conj().transpose(),\n                                                                       nr_trial_wraps)\n                self.k_ps[i] = k_0[0]\n                self.c_ps[i] = static_offset\n                self.coh_ps[i] = coh_0\n                self.n_opt[i] = len(k_0)\n                if psdph is None:\n                    self.ph_res[i, :] = np.angle(phase_residual).transpose()\n                else:\n                    self.ph_res[i, ifg_ind] = np.angle(phase_residual).transpose()[0]\n            else:\n                self.k_ps[i] = np.nan\n                self.coh_ps[i] = 0\n\n    @staticmethod\n    def ps_topofit_fun(phase: np.ndarray, bperp_meaned: np.ndarray, nr_trial_wraps: float):\n        # To make sure that the results are correct we transform bperp_meaned into column matrix\n        if (len(bperp_meaned.shape) == 1):\n            bperp_meaned = ArrayUtils.to_col_matrix(bperp_meaned)\n\n        # The result of get_nr_trial_wraps is not correct in this case, so we need to find it again\n        bperp_range = np.amax(bperp_meaned) - np.amin(bperp_meaned)\n\n        CONST = 8 * nr_trial_wraps  # todo what const? Why 8\n        trial_multi_start = -np.ceil(CONST)\n        trial_multi_end = np.ceil(CONST)\n        trial_multi = ArrayUtils.arange_include_last(trial_multi_start, trial_multi_end, 1)\n\n        trial_phase = bperp_meaned / bperp_range * math.pi / 4\n        trial_phase = np.exp(np.outer(-1j * trial_phase, trial_multi))\n\n        # In order to successfully multiply, we need to transform \'phase\' array to column matrix\n        phase = ArrayUtils.to_col_matrix(phase)\n        phase_tile = np.tile(phase, (1, len(trial_multi)))\n        phaser = np.multiply(trial_phase, phase_tile)\n\n        phaser_sum = MatlabUtils.sum(phaser)\n\n        phase_abs_sum = MatlabUtils.sum(np.abs(phase))\n        trial_coherence = np.abs(phaser_sum) / phase_abs_sum\n        trial_coherence_max_ind = np.where(trial_coherence == MatlabUtils.max(trial_coherence))\n\n        k_0 = (math.pi / 4 / bperp_range) * trial_multi[trial_coherence_max_ind][0]\n\n        re_phase = np.multiply(phase, np.exp(-1j * (k_0 * bperp_meaned)))\n        phase_offset = MatlabUtils.sum(re_phase)\n        re_phase = np.angle(re_phase * phase_offset.conjugate())\n        weigth = np.abs(phase)\n        bperp_meaned_weighted = weigth * bperp_meaned\n        re_phase_weighted = weigth * re_phase\n        # Numpy linalg functions work only with 2d array\n        if len(bperp_meaned_weighted.shape) > 2:\n            bperp_meaned_weighted = bperp_meaned_weighted[0]\n        if len(re_phase_weighted.shape) > 2:\n            re_phase_weighted = re_phase_weighted[0]\n\n        mopt = np.linalg.lstsq(bperp_meaned_weighted, re_phase_weighted)[0][0]\n        # In StaMPS k0\n        k_0 = k_0 + mopt\n\n        phase_residual = np.multiply(phase, np.exp(-1j * (k_0 * bperp_meaned)))\n        phase_residual_sum = MatlabUtils.sum(phase_residual)\n        # In StaMPS c0\n        static_offset = np.angle(phase_residual_sum)\n        # In StaMPS coh0\n        coherence_0 = np.abs(phase_residual_sum) / MatlabUtils.sum(np.abs(phase_residual))\n\n        return phase_residual, coherence_0, static_offset, k_0'"
scripts/funs/__init__.py,0,b''
scripts/processes/CreateLonLat.py,7,"b'import os\nfrom pathlib import Path\n\nimport numpy as np\nfrom snappy import ProductIO\n\nfrom scripts.MetaSubProcess import MetaSubProcess\nfrom scripts.utils.internal.FolderConstants import FolderConstants\nfrom scripts.utils.internal.LoggerFactory import LoggerFactory\n\nfrom scripts.utils.internal.ProcessDataSaver import ProcessDataSaver\n\n\nclass CreateLonLat(MetaSubProcess):\n    __ARRAY_TYPE = np.float32\n\n    # Needed in PsFiles process to load data\n    pscands_ij = None\n    lonlat = None\n\n    def __init__(self, path: str, geo_ref_product: str):\n        self.__FILE_NAME = ""lonlat_process""\n        self.__geo_ref_product = geo_ref_product\n\n        self.__PATCH_FOLDER = Path(path, FolderConstants.PATCH_FOLDER_NAME)\n\n        self.__logger = LoggerFactory.create(\'CreateLonLat\')\n\n        self.__logger.debug(""PATCH_FOLDER {0}"".format(self.__PATCH_FOLDER))\n\n    def start_process(self):\n        self.__logger.debug(""Start"")\n\n        product_with_geo_ref = ProductIO.readProduct(self.__geo_ref_product)\n        lon_band, lat_band = self.__get_lon_bands(product_with_geo_ref)\n\n        if lon_band is None or lat_band is None:\n            raise FileNotFoundError(""lon_band, lat_band missing"")\n\n        lonlat = []\n        with self.__load_pscands() as pscands:\n            for row in pscands:\n                if row == \'\':\n                    break\n\n                line = row.split(\' \')\n                y = int(line[1])\n                x = int(line[2])\n\n                # tmp__pixel_array is needed because readPixels returns x-size that much what is set\n                # in third parameter. But there isn\'t any limiter for y-size and this means it takes\n                # how much it can.\n                # This needs optimization. That you load all rows in one take and set them to lonlat\n                tmp__pixel_array = np.zeros((1, 1), dtype=self.__ARRAY_TYPE)\n                tmp_lonlat = np.zeros((1, 2), dtype=self.__ARRAY_TYPE)\n                self.__read_pixel(x, y, lon_band, tmp__pixel_array)\n                tmp_lonlat[0, 0] = tmp__pixel_array[0]\n                self.__read_pixel(x, y, lat_band, tmp__pixel_array)\n                tmp_lonlat[0, 1] = tmp__pixel_array[0]\n\n                lonlat.append(tmp_lonlat)\n\n                self.__add_to_pscands_array(int(line[0]), int(line[1]), int(line[2]))\n\n        self.pscands_ij = np.reshape(self.pscands_ij, (len(self.pscands_ij), 3))\n\n        self.__logger.debug(""Done"")\n\n        self.lonlat = np.reshape(lonlat, (len(lonlat), 2))\n\n    def save_results(self, save_path: str):\n        if self.pscands_ij is None:\n            raise ValueError(""pscands is None"")\n        if self.lonlat is None:\n            raise ValueError(""pscands is None"")\n\n        ProcessDataSaver(save_path, self.__FILE_NAME).save_data(\n            pscands_ij_array=self.pscands_ij,\n            lonlat=self.lonlat)\n\n    def load_results(self, load_path:str):\n        file_with_path = os.path.join(load_path, self.__FILE_NAME + "".npz"")\n        data = np.load(file_with_path)\n\n        self.pscands_ij = data[""pscands_ij_array""]\n        self.lonlat = data[""lonlat""]\n\n    # TODO slowest part\n    # noinspection PyMethodMayBeStatic\n    def __read_pixel(self, x, y, band, tmp_array):\n        band.readPixels(x, y, 1, 1, tmp_array)\n\n    def __add_to_pscands_array(self, arr1: int, arr2: int, arr3: int):\n        """"""When we process the list, we append initial values to pscands""""""\n        if (self.pscands_ij is None):\n            self.pscands_ij = []\n\n        self.pscands_ij.append(np.array([arr1, arr2, arr3]))\n\n    # noinspection PyMethodMayBeStatic\n    def __get_lon_bands(self, product_with_geo_ref):\n        lon_band = product_with_geo_ref.getBand(\'lon_band\')\n        lat_band = product_with_geo_ref.getBand(\'lat_band\')\n\n        return lon_band, lat_band\n\n    def __load_pscands(self):\n        if self.__PATCH_FOLDER.is_dir():\n            # TODO Check if it is in this folder\n            path_to_pscands = Path(self.__PATCH_FOLDER, ""pscands.1.ij"")\n            if path_to_pscands.exists():\n                return path_to_pscands.open()\n            else:\n                raise FileNotFoundError(""Path {0}"".format(path_to_pscands))\n'"
scripts/processes/PhaseCorrection.py,9,"b'import numpy as np\nimport numpy.matlib\nimport os\n\nfrom scripts.MetaSubProcess import MetaSubProcess\nfrom scripts.processes.PsFiles import PsFiles\nfrom scripts.processes.PsWeed import PsWeed\nfrom scripts.utils.internal.LoggerFactory import LoggerFactory\nfrom scripts.utils.internal.ProcessDataSaver import ProcessDataSaver\n\n\nclass PhaseCorrection(MetaSubProcess):\n    """"""In StaMPS is \'ps_correct_phase\' file""""""\n\n    __FILE_NAME = ""phase_correction""\n\n    def __init__(self, ps_files: PsFiles, ps_weed: PsWeed):\n        self.__logger = LoggerFactory.create(""PhaseCorrection"")\n\n        self.__ps_files = ps_files\n        self.__ps_weed = ps_weed\n\n    class __DataDTO(object):\n        def __init__(self, master_nr: int, nr_ifgs: int, bperp: np.ndarray, ph: np.ndarray,\n                     k_ps: np.ndarray,\n                     c_ps: np.ndarray, ph_patch: np.ndarray):\n            self.master_nr = master_nr\n            self.nr_ifgs = nr_ifgs\n            self.bperp = bperp\n            self.ph = ph\n            self.k_ps = k_ps\n            self.c_ps = c_ps\n            self.ph_patch = ph_patch\n\n    def start_process(self):\n        self.__logger.info(""Start"")\n\n        data = self.__load_ps_params()\n\n        self.ph_rc = self.__get_ph_rc(data)\n        self.__logger.debug(""ph_rc.len {0}"".format(len(self.ph_rc)))\n\n        self.ph_reref = self.__get_ph_reref(data)\n        self.__logger.debug(""ph_reref.len {0}"".format(len(self.ph_reref)))\n\n        self.__logger.info(""End"")\n\n    def save_results(self, save_path: str):\n        ProcessDataSaver(save_path, self.__FILE_NAME).save_data(\n            ph_rc = self.ph_rc,\n            ph_reref = self.ph_reref\n        )\n\n    def load_results(self, load_path: str):\n        file_with_path = os.path.join(load_path, self.__FILE_NAME + "".npz"")\n        data = np.load(file_with_path)\n\n        self.ph_rc = data[\'ph_rc\']\n        self.ph_reref = data[\'ph_reref\']\n\n    def __load_ps_params(self) -> __DataDTO:\n        master_nr = self.__ps_files.master_nr - 1  # In Stamps this is master_ix\n\n        nr_ifgs = len(self.__ps_files.ifgs)\n\n        _, k_ps, c_ps, ph_patch, ph, _, _, _, _, bperp, _ = self.__ps_weed.get_filtered_results()\n\n        return self.__DataDTO(master_nr, nr_ifgs, bperp, ph, k_ps, c_ps, ph_patch)\n\n    def __get_ph_rc(self, data: __DataDTO):\n        bperp = data.bperp\n        master_nr = data.master_nr\n        # Insert zeros filled column into bperp array. This represents master image data.\n        bperp_master_col_zeros = np.insert(bperp, master_nr, values=0, axis=1)\n\n        nr_ifgs = data.nr_ifgs\n        repmated_bperp = np.multiply(np.matlib.repmat(data.k_ps, 1, nr_ifgs),\n                                     bperp_master_col_zeros)\n        repmated_c_ps = np.matlib.repmat(data.c_ps, 1, nr_ifgs)\n        ph_rc = np.multiply(data.ph, np.exp(-1j * (repmated_bperp + repmated_c_ps)))\n\n        return ph_rc\n\n    def __get_ph_reref(self, data: __DataDTO):\n        ph_patch = data.ph_patch\n        master_nr = data.master_nr\n\n        ph_reref = np.insert(ph_patch, master_nr, values=1, axis=1)\n\n        return ph_reref\n'"
scripts/processes/PsEstGamma.py,90,"b'import math\nimport os\n\nimport pydsm.relab\nimport sys\n\nimport scipy.signal\n\nfrom scripts.MetaSubProcess import MetaSubProcess\nfrom scripts.funs.PsTopofit import PsTopofit\nfrom scripts.processes.PsFiles import PsFiles\n\nimport numpy as np\n\nfrom scripts.utils.ArrayUtils import ArrayUtils\nfrom scripts.utils.internal.LoggerFactory import LoggerFactory\nfrom scripts.utils.MatlabUtils import MatlabUtils\nfrom scripts.utils.MatrixUtils import MatrixUtils\nfrom scripts.utils.internal.ProcessCache import ProcessCache\nfrom scripts.utils.internal.ProcessDataSaver import ProcessDataSaver\n\n\nclass PsEstGamma(MetaSubProcess):\n    """"""In this process we analize potential phasenoise Anal\xc3\xbc\xc3\xbcsitakse v\xc3\xb5imalike p\xc3\xbcsivpeegeldajate faasim\xc3\xbcra""""""\n\n    low_pass = np.ndarray\n    weights = np.ndarray\n    weights_org = np.ndarray\n    rand_dist = np.ndarray\n    nr_max_nz_ind = -1\n\n    __FILE_NAME = ""ps_est_gamma""\n\n    def __init__(self, ps_files: PsFiles, rand_dist_cached_file=False,\n                 outter_rand_dist=np.array([])) -> None:\n        """"""rand_dist_cached_file= when True loads array of random numbers \'tmp_rand_dist\' from cache\n        (see function \'self.__make_random_dist\')\n        outter_rand_dist = array of random numbers that are usually if found in function\n        \'self.__make_random_dist\'. This is used for testing""""""\n\n        self.__logger = LoggerFactory.create(""PsEstGamma"")\n\n        self.__ps_files = ps_files\n        self.__set_internal_params()\n        self.rand_dist_cached = rand_dist_cached_file\n        self.outter_rand_dist = outter_rand_dist\n\n        # In StaMPS this is called \'coh_bins\'\n        self.coherence_bins = ArrayUtils.arange_include_last(0.005, 0.995, 0.01)\n\n    def __set_internal_params(self):\n        """"""In StaMPS these where loaded to Matlab environment using setparam. All values are from\n        ps_params_default file. Explantions are from Hooper\'s StaMPS/MTI Manual (Version 3.3b1)""""""\n\n        # Pixel size of the grid (in meters)\n        self.__filter_grid_size = 50\n        # The weighting scheme (PS probability squared)\n        self.__filter_weighting = \'P-square\'\n        # CLAP (Combined Low-pass and Adaptive Phase).\n        self.__clap_win = 32\n        # The wavelenghts that are greater than that are passed through\n        self.__clap_low_pass_wavelength = 800\n\n        self.__clap_alpha = 1\n        self.__clap_beta = 0.3\n        # Maximum uncorrelated DEM error (in meters).\n        # Any value greater than this is not accepted\n        self.__max_topo_err = 5\n        # Threshold for change in change in mean value of \xce\xb3(coherence like value)\n        self.__gamma_change_convergence = 0.005\n        # mean range - need only be approximately correct\n        self.__mean_range = 830000\n\n        self.__low_coherence_thresh = 31  # Equal to 31/100\n\n    def start_process(self):\n        self.__logger.info(""Started"")\n\n        self.low_pass = self.__get_low_pass()\n        self.__logger.debug(""low_pass.len: {0}"".format(len(self.low_pass)))\n\n        ph, bperp_meaned, bperp, nr_ifgs, nr_ps, xy, da, sort_ind_meaned = self.__load_ps_params()\n\n        self.nr_trial_wraps = self.__get_nr_trial_wraps(bperp_meaned, sort_ind_meaned)\n        self.__logger.debug(""nr_trial_wraps: {0}"".format(self.nr_trial_wraps))\n\n        # self.rand_dist in Stamps is named \'Nr\'\n        self.rand_dist, self.nr_max_nz_ind = self.__make_random_dist(nr_ps, nr_ifgs, bperp_meaned,\n                                                                     self.nr_trial_wraps)\n        self.__logger.debug(""rand_dist.len: {0}, self.nr_max_nz_ind: {1}""\n                            .format(len(self.rand_dist), self.nr_max_nz_ind))\n\n        self.grid_ij = self.__get_grid_ij(xy)\n        self.__logger.debug(""grid_ij.len: {0}"".format(len(self.grid_ij)))\n\n        self.weights_org = self.__get_weights(da)\n        self.__logger.debug(""weights_org.len: {0}"".format(len(self.weights_org)))\n\n        # Eelnev oli sisuliselt eel\xc3\xb6\xc3\xb6 selleks mis n\xc3\xbc\xc3\xbcd hakkab.\n        self.ph_patch, self.k_ps, self.c_ps, self.coh_ps, self.n_opt, \\\n        self.ph_res, self.ph_grid, self.low_pass = \\\n            self.__sw_loop(\n                ph,\n                self.weights_org.copy(),\n                self.low_pass,\n                bperp,\n                nr_ifgs,\n                nr_ps,\n                self.nr_trial_wraps)\n\n        self.__logger.info(""End"")\n\n    def save_results(self, save_path: str):\n        ProcessDataSaver(save_path, self.__FILE_NAME).save_data(\n            ph_patch=self.ph_patch,\n            k_ps=self.k_ps,\n            c_ps=self.c_ps,\n            coh_ps=self.coh_ps,\n            n_opt=self.n_opt,\n            ph_res=self.ph_res,\n            ph_grid=self.ph_grid,\n            low_pass=self.low_pass,\n            coherence_bins=self.coherence_bins,\n            grid_ij=self.grid_ij,\n            nr_trial_wraps=self.nr_trial_wraps,\n            rand_dist=self.rand_dist,\n        )\n\n    def load_results(self, load_path: str):\n        file_with_path = os.path.join(load_path, self.__FILE_NAME + "".npz"")\n        data = np.load(file_with_path)\n\n        self.ph_patch = data[\'ph_patch\']\n        self.k_ps = data[\'k_ps\']\n        self.c_ps = data[\'c_ps\']\n        self.coh_ps = data[\'coh_ps\']\n        self.n_opt = data[\'n_opt\']\n        self.ph_res = data[\'ph_res\']\n        self.ph_grid = data[\'ph_grid\']\n        self.low_pass = data[\'low_pass\']\n        self.coherence_bins = data[\'coherence_bins\']\n        self.grid_ij = data[\'grid_ij\']\n        self.nr_trial_wraps = data[\'nr_trial_wraps\'].astype(np.float64)\n        self.rand_dist = data[\'rand_dist\']\n\n    def __get_low_pass(self):\n        start = -(self.__clap_win) / self.__filter_grid_size / self.__clap_win / 2\n        stop = (self.__clap_win - 2) / self.__filter_grid_size / self.__clap_win / 2\n        step = 1 / self.__filter_grid_size / self.__clap_win\n        freg_i = ArrayUtils.arange_include_last(start, stop, step)\n\n        freg_0 = 1 / self.__clap_low_pass_wavelength\n\n        subtract = 1 + np.power(freg_i / freg_0, 10)\n        butter_i = np.divide(1, subtract)\n\n        return np.fft.fftshift(np.asmatrix(butter_i).conj().transpose() * butter_i)\n\n    def __load_ps_params(self):\n        """"""Loads needed parameters from ps_files object and takes what it needs""""""\n\n        ph, bperp, nr_ifgs, nr_ps, xy, da = self.__ps_files.get_ps_variables()\n        # In StaMPS small_basline=n\n        nr_ifgs -= 1 # This is only for this process. In other proecesses nr_ifgs must remain unchanged\n\n        ph = MatrixUtils.delete_master_col(ph, self.__ps_files.master_nr)\n        ph_abs = np.abs(ph)\n        ph_abs[np.where(ph_abs == 0)] = 1 # Excluding the possibility of division by zero\n        ph = np.divide(ph, ph_abs)\n\n        # bprep_meaned is an array of rows (not columns), therefore usual\n        # MatixUtils.delete_master_col function does not work\n        bprep_meaned = np.delete(self.__ps_files.bperp_meaned, self.__ps_files.master_nr - 1)\n\n        # In Stamps there is 0.052 instead of math.radians(3). Variable is named \'inc_mean\'\n        sort_ind_meaned = np.mean(self.__ps_files.sort_ind) + math.radians(3)\n\n        return ph, bprep_meaned, bperp, nr_ifgs, nr_ps, xy, da, sort_ind_meaned\n\n    def __get_nr_trial_wraps(self, bperp_meaned, sort_ind_meaned) -> np.float64:\n        # todo what is k?\n        k = self.__ps_files.wavelength * self.__mean_range * np.sin(sort_ind_meaned) / 4 / math.pi\n        max_k = self.__max_topo_err / k\n\n        bperp_range = MatlabUtils.max(bperp_meaned) - MatlabUtils.min(bperp_meaned)\n\n        # todo why such formula?\n        return bperp_range * max_k / (2 * math.pi)\n\n    def __make_random_dist(self, nr_ps, nr_ifgs, bperp_meaned, nr_trial_wraps):\n        CACHE_FILE_NAME = ""tmp_rand_dist""\n\n        def use_cached_from_file():\n            try:\n                loaded = ProcessCache.get_from_cache(CACHE_FILE_NAME, \'rand_dist\', \'nr_max_nz_ind\')\n                rand_dist = loaded[\'rand_dist\']\n                nr_max_nz_ind = loaded[\'nr_max_nz_ind\']\n\n            except FileNotFoundError:\n                self.__logger.info(""No cache"")\n\n                rand_dist, nr_max_nz_ind = random_dist()\n                cache(rand_dist, nr_max_nz_ind)\n\n            return rand_dist, nr_max_nz_ind\n\n        def cache(rand_dist: np.ndarray, nr_max_nz_ind: int):\n            ProcessCache.save_to_cache(CACHE_FILE_NAME,\n                                       rand_dist=rand_dist,\n                                       nr_max_nz_ind=nr_max_nz_ind)\n\n        def use_outter_array(outter_array: np.ndarray):\n            rand_dist = outter_array\n            nr_max_nz_ind = np.count_nonzero(rand_dist)\n\n            return rand_dist, nr_max_nz_ind\n\n        def random_dist():\n            NR_RAND_IFGS = nr_ps  # In StaMPS it is 300000\n            random = np.random.RandomState(2005)\n\n            rnd_ifgs = 2 * math.pi * random.rand(NR_RAND_IFGS, nr_ifgs)\n\n            random_coherence = np.zeros((NR_RAND_IFGS, 1))\n            for i in range(NR_RAND_IFGS - 1, 0, -1):\n                phase = np.exp(1j * rnd_ifgs[i])\n                # We need only coherence here\n                _, coherence_0, _, _ = PsTopofit.ps_topofit_fun(phase, bperp_meaned, nr_trial_wraps)\n                random_coherence[i] = coherence_0[0]\n\n            del rnd_ifgs\n\n            hist, _ = MatlabUtils.hist(random_coherence, self.coherence_bins)\n\n            rand_dist = hist\n\n            return rand_dist, np.count_nonzero(hist)\n\n        if self.rand_dist_cached:\n            self.__logger.info(""Using cache from file"")\n            return use_cached_from_file()\n        elif len(self.outter_rand_dist) > 0:\n            self.__logger.info(""Using cache parameter. self.outter_rand_dist.len: {0}""\n                               .format(len(self.outter_rand_dist)))\n            return use_outter_array(self.outter_rand_dist)\n        else:\n            return random_dist()\n\n    def __get_grid_ij(self, xy: np.ndarray):\n\n        def fill_cols_with_xy_values(xy_col: np.ndarray):\n            # Float32 is needed because with default type you get too many decimal places. But when\n            # there is too many decimal places round up(ceil) makes 2224.00001 to 2225 which is the\n            # wrong value\n            col_formula = lambda x: np.ceil((x - np.amin(x) + 1e-6).astype(np.float32) / self.__filter_grid_size)\n\n            grid_ij_col = col_formula(xy_col)\n            max_ind = np.where(grid_ij_col == np.amax(grid_ij_col))\n            grid_ij_col[max_ind] -= 1\n\n            return grid_ij_col\n\n        grid_ij = np.zeros((len(xy), 2), np.int32)\n\n        grid_ij[:, 0] = fill_cols_with_xy_values(xy[:, 1])\n        grid_ij[:, 1] = fill_cols_with_xy_values(xy[:, 0])\n\n        return grid_ij\n\n    def __get_weights(self, da: np.ndarray):\n        return ArrayUtils.to_col_matrix(np.divide(1, da))\n\n    def __sw_loop(self, ph: np.ndarray, weights: np.ndarray,\n                  low_pass: np.ndarray, bprep: np.ndarray, nr_ifgs: int, nr_ps: int,\n                  nr_trial_wraps: float):\n\n        SW_ARRAY_SHAPE = (nr_ps, 1)\n\n        def zero_ps_array_cont():\n            """"""Konstruktor t\xc3\xbchja pusivpeegeladajate info massiivi loomiseks""""""\n            return np.zeros(SW_ARRAY_SHAPE)\n\n        def get_ph_weight(bprep, k_ps, nr_ifgs, ph, weights):\n            exped = np.exp(np.multiply((-1j * bprep), np.tile(k_ps, (1, nr_ifgs))))\n            exp_tiled_weight_multi = np.multiply(exped, np.tile(weights, (1, nr_ifgs)))\n            return np.multiply(ph, exp_tiled_weight_multi)\n\n        def is_gamma_in_change_delta():\n            return abs(gamma_change_delta) < self.__gamma_change_convergence\n\n        def make_ph_grid(ph_grid_shape: tuple, grid_ij: np.ndarray, weights: np.ndarray,\n                         loop_nr: int) -> np.ndarray:\n            # np.complex128 is needed because this is the type that pydsm.relab.shiftdim returns.\n            # ph_grid and ph_filt are needed to make again. Otherwise there are old values in those\n            # arrays\n            ph_grid = np.zeros(ph_grid_shape, np.complex128)\n            for id in range(loop_nr):\n                x_ind = int(grid_ij[id, 0]) - 1\n                y_ind = int(grid_ij[id, 1]) - 1\n                ph_grid[x_ind, y_ind, :] += pydsm.relab.shiftdim(weights[id, :], -1, nargout=1)[0]\n\n            return ph_grid\n\n        def make_ph_filt(ph_grid_shape: tuple, ph_grid: np.ndarray, loop_nr: int,\n                         low_pass: np.ndarray) -> np.ndarray:\n            ph_filt = np.zeros(ph_grid_shape, np.complex128)\n            for i in range(loop_nr):\n                ph_filt[:, :, i] = self.__clap_filt(ph_grid[:, :, i], low_pass)\n\n            return ph_filt\n\n        def make_ph_path(ph_patch: np.ndarray, ph_filt: np.ndarray, grid_ij: np.ndarray,\n                         loop_nr: int) -> np.ndarray:\n            for i in range(loop_nr):\n                x_ind = int(grid_ij[i, 0]) - 1\n                y_ind = int(grid_ij[i, 1]) - 1\n                ph_patch[i, :nr_ifgs] = np.squeeze(ph_filt[x_ind, y_ind, :])\n\n            not_zero_patches_ind = np.nonzero(ph_patch)\n            ph_patch[not_zero_patches_ind] = np.divide(ph_patch[not_zero_patches_ind],\n                                                       np.abs(ph_patch[not_zero_patches_ind]))\n\n            return ph_patch\n\n        nr_i = int(np.max(self.grid_ij[:, 0]))\n        nr_j = int(np.max(self.grid_ij[:, 1]))\n        PH_GRID_SHAPE = (nr_i, nr_j, nr_ifgs)\n\n        coh_ps_result = zero_ps_array_cont()\n        gamma_change = 0\n        gamma_change_delta = np.inf\n\n        ph_patch = np.zeros(ph.shape, np.complex128)\n\n        k_ps = zero_ps_array_cont()\n\n        # Est topo error\n        # Initializing variables that are returned in the end\n        c_ps = zero_ps_array_cont()\n        n_opt = zero_ps_array_cont()\n        ph_res = np.zeros((nr_ps, nr_ifgs))\n\n        log_i = 0 # Used for logging to see how many cycles we have done\n        self.__logger.debug(""is_gamma_in_change_delta loop begin"")\n        while not is_gamma_in_change_delta():\n            log_i += 1\n            self.__logger.debug(""gamma change loop i "" + str(log_i))\n            ph_weight = get_ph_weight(bprep, k_ps, nr_ifgs, ph, weights)\n\n            ph_grid = make_ph_grid(PH_GRID_SHAPE, self.grid_ij, ph_weight, nr_ps)\n            ph_filt = make_ph_filt(PH_GRID_SHAPE, ph_grid, nr_ifgs, low_pass)\n\n            self.__logger.debug(""ph_filt found. first row: {0}, last row: {1}""\n                                .format(ph_filt[0], ph_filt[len(ph_filt) - 1]))\n\n            ph_patch = make_ph_path(ph_patch, ph_filt, self.grid_ij, nr_ps)\n\n            self.__logger.debug(""ph_patch found. first row: {0}, last row: {1}""\n                                .format(ph_patch[0], ph_patch[len(ph_patch) - 1]))\n\n            del ph_filt\n\n            # This is the slowest part in this process\n            topofit = PsTopofit(SW_ARRAY_SHAPE, nr_ps, nr_ifgs)\n            topofit.ps_topofit_loop(ph, ph_patch, bprep, nr_trial_wraps)\n            k_ps = topofit.k_ps.copy()\n            c_ps = topofit.c_ps.copy()\n            coh_ps = topofit.coh_ps.copy()\n            n_opt = topofit.n_opt.copy()\n            ph_res = topofit.ph_res.copy()\n\n            del topofit\n\n            self.__logger.debug(""topofit found"")\n\n            gamma_change_rms = np.sqrt(np.sum(np.power(coh_ps - coh_ps_result, 2) / nr_ps))\n            gamma_change_delta = gamma_change_rms - gamma_change\n            # Saving gamma and coherence that are returned later to temp variables\n            gamma_change = gamma_change_rms\n            coh_ps_result = coh_ps\n\n            self.__logger.debug(""is_gamma_in_change_delta() and self.__filter_weighting: ""\n                                + str(not is_gamma_in_change_delta() and\n                                      self.__filter_weighting == \'P-square\'))\n            if not is_gamma_in_change_delta() and self.__filter_weighting == \'P-square\':\n                # In Stamps it is named \'Na\'\n                hist, _ = MatlabUtils.hist(coh_ps, self.coherence_bins)\n                self.__logger.debug(""hist[0:3] "" + str(hist[:3]))\n                # The random values are transformed into real values here\n                low_coh_thresh_ind = self.__low_coherence_thresh\n                real_distr = np.sum(hist[:low_coh_thresh_ind]) / np.sum(\n                    self.rand_dist[:low_coh_thresh_ind])\n                self.rand_dist = self.rand_dist * real_distr\n\n                hist[hist == 0] = 1\n                p_rand = np.divide(self.rand_dist, hist)\n                p_rand[:low_coh_thresh_ind] = 1\n                p_rand[self.nr_max_nz_ind:] = 0 # In Stamps nr_max_nz_ind is incremented by one\n                p_rand[p_rand > 1] = 1\n                p_rand_added_ones = np.append(np.ones(7), p_rand)\n                filtered = scipy.signal.lfilter(MatlabUtils.gausswin(7), [1], p_rand_added_ones)\n                p_rand = filtered / np.sum(MatlabUtils.gausswin(7))\n                p_rand = p_rand[7:]\n\n                # Found that \'quadratic\' is bit more accurate than \'cubic\'\n                p_rand = MatlabUtils.interp(np.append([1.0], p_rand), 10, \'quadratic\')[:-9]\n\n                # Here we covert coh_ps to indexes array. astype is needed because in Numpy all\n                # indexes must be int type.\n                # reshape is needed because coh_ps is array of arrays.\n                coh_ps_as_ind = np.round(coh_ps * 1000).astype(np.int)\n                if len(coh_ps_as_ind.shape) > 1:\n                    coh_ps_as_ind = np.squeeze(coh_ps_as_ind)\n                # In Stamps this is \'Prand_ps\'\n                ps_rand = p_rand[coh_ps_as_ind].conj().transpose()\n\n                weights = np.reshape(np.power(1 - ps_rand, 2), SW_ARRAY_SHAPE)\n\n        return ph_patch, k_ps, c_ps, coh_ps_result, n_opt, ph_res, ph_grid, low_pass\n\n    def __clap_filt(self, ph: np.ndarray, low_pass: np.ndarray):\n        """"""CLAP_FILT Combined Low-pass Adaptive Phase filtering.\n        Variables nr_win, nr_pad where inputs in StaMPS but these were multiplied before inputing\n        into function. Here it is done internally.\n        Also clap_alpha ja clap_beta where inputs but in this case those are global class variables\n        so we can use them and don\'t need for inputs""""""\n\n        def create_grid(nr_win: int):\n            grid_array = ArrayUtils.arange_include_last(0, (nr_win / 2) - 1)\n            grid_x, grid_y = np.meshgrid(grid_array, grid_array)\n            grid = grid_x + grid_y\n\n            return grid\n\n        # todo What does wind_func mean? This isn\'t array of functions\n        def make_wind_func(grid: np.ndarray):\n            WIND_FUNC_TYPE = np.float64\n            wind_func = np.array(np.append(grid, np.fliplr(grid), axis=1), WIND_FUNC_TYPE)\n            wind_func = np.array(np.append(wind_func, np.flipud(wind_func), axis=0), WIND_FUNC_TYPE)\n            # In order to prevent zeros in corners\n            wind_func += 1e-6\n\n            return wind_func\n\n        def get_indexes(loop_index: int, inc: int, nr_win: int) -> (int, int):\n            i1 = loop_index * inc\n            # We don\'t do -1 because otherwise last element in array is not selected\n            i2 = i1 + nr_win\n\n            return i1, i2\n\n        FILTERED_TYPE = np.complex128\n        filtered = np.zeros(ph.shape, FILTERED_TYPE)\n\n        ph = np.nan_to_num(ph)\n\n        nr_win = int(self.__clap_win * 0.75)\n        nr_pad = int(self.__clap_win * 0.25)\n\n        ph_i_len = ph.shape[0] - 1\n        ph_j_len = ph.shape[1] - 1\n        nr_inc = int(np.floor(nr_win / 4))\n        # Indices begin from zero on Python. That\'s why those values are greater than StaMPS\n        nr_win_i = int(np.ceil(ph_i_len / nr_inc) - 3)\n        nr_win_j = int(np.ceil(ph_j_len / nr_inc) - 3) + 1\n\n        wind_func = make_wind_func(create_grid(nr_win))\n\n        # To make transpose work like Matlab we need to convert those to matrix\n        # todo: PsSelect has similar thing\n        B = np.multiply(np.asmatrix(MatlabUtils.gausswin(7)),\n                        np.asmatrix(MatlabUtils.gausswin(7)).transpose())\n\n        nr_win_pad_sum = (nr_win + nr_pad)\n        ph_bit = np.zeros((nr_win_pad_sum, nr_win_pad_sum), FILTERED_TYPE)\n        # Todo: Refactor\n        for i in range(nr_win_i):\n            w_f = wind_func.copy()\n            i1, i2 = get_indexes(i, nr_inc, nr_win)\n\n            if i2 > ph_i_len:\n                i_shift = i2 - ph_i_len - 1\n                i2 = ph_i_len + 1\n                i1 = ph_i_len - nr_win + 1\n                w_f = np.append(np.zeros((i_shift, nr_win)), w_f[:nr_win - i_shift, :],\n                                axis=0).astype(FILTERED_TYPE)\n\n            for j in range(nr_win_j):\n                w_f2 = w_f\n                j1, j2 = get_indexes(j, nr_inc, nr_win)\n\n                if j2 > ph_j_len:\n                    j_shift = j2 - ph_j_len - 1\n                    # Because array lenghts, ph_i_len and ph_j_len, are already smaller and Numpy\n                    # does not take last index when selecting, then we need to add one more\n                    j2 = ph_j_len + 1\n                    j1 = ph_j_len - nr_win + 1\n                    w_f2 = np.append(np.zeros((nr_win, j_shift)), w_f2[:, :nr_win - j_shift],\n                                     axis=1).astype(FILTERED_TYPE)\n\n                ph_bit[:nr_win, :nr_win] = ph[i1: i2, j1: j2]\n\n                ph_fft = np.fft.fft2(ph_bit) # todo Todo from fifth decimal point the values are not equal to Stamps result\n                # ph_fft = fftw.interfaces.numpy_fft.fft2(ph_bit) #  todo Todo from fifth decimalpoint the values are not equal to Stamps result\n                smooth_resp = np.abs(ph_fft) # \'H\' in Stamps\n                smooth_resp = np.fft.ifftshift(\n                    MatlabUtils.filter2(B, np.fft.ifftshift(smooth_resp)))\n                # smooth_resp = fftw.interfaces.numpy_fft.ifftshift(\n                #     MatlabUtils.filter2(B, fftw.interfaces.numpy_fft.ifftshift(smooth_resp)))\n                mean_smooth_resp = np.median(smooth_resp)\n\n                if mean_smooth_resp != 0:\n                    smooth_resp /= mean_smooth_resp\n\n                smooth_resp = np.power(smooth_resp, self.__clap_alpha)\n\n                # todo Values under median to zero. Why that?\n                smooth_resp -= 1\n                smooth_resp[smooth_resp < 0] = 0\n\n                # todo What is G?\n                G = smooth_resp * self.__clap_beta + low_pass\n                ph_filt = np.fft.ifft2(np.multiply(ph_fft, G))\n                # ph_filt = fftw.interfaces.numpy_fft.ifft2(np.multiply(ph_fft, G))\n                ph_filt = np.multiply(ph_filt[:nr_win, :nr_win], w_f2)\n\n                filtered[i1:i2, j1:j2] += ph_filt\n\n        return filtered\n'"
scripts/processes/PsFiles.py,48,"b'import os\nfrom datetime import date\nfrom pathlib import Path\n\nimport re\nfrom typing import Callable\n\nfrom numpy import matlib\n\nfrom scripts.MetaSubProcess import MetaSubProcess\nfrom scripts.processes.CreateLonLat import CreateLonLat\nfrom scripts.utils.ArrayUtils import ArrayUtils\nfrom scripts.utils.internal.FolderConstants import FolderConstants\n\nimport numpy as np\nimport math\n\nfrom scripts.utils.internal.LoggerFactory import LoggerFactory\nfrom scripts.utils.MatlabUtils import MatlabUtils\nfrom scripts.utils.MatrixUtils import MatrixUtils\nfrom scripts.utils.internal.ProcessDataSaver import ProcessDataSaver\n\n\nclass PsFiles(MetaSubProcess):\n    """"""Here we initialize and fill all variables that are needed later.\n    Based on StaMPS ps_load_inital_gamma.""""""\n\n    heading: float = 0.0\n    mean_range: float = 0.0\n    wavelength: float = 0.0\n    mean_incidence: float = 0.0\n    master_nr: int = -1  # \'master_ix\' in Stamps\n    bperp_meaned: np.ndarray\n    bperp: np.ndarray  # \'bperp_mat\' in Stamps\n    ph: np.ndarray\n    ll: np.ndarray\n    xy: np.ndarray\n    da: np.ndarray\n    sort_ind: np.matrix  # In Stamps this is la from la1.mat\n    master_date: date\n    ifgs: np.ndarray  # todo to private variable?\n    hgt: np.ndarray\n    ifg_dates: list = []  # \'day\' in Stamps\n\n    __FILE_NAME = ""ps_files""\n\n    def __init__(self, path: str, create_lonlat: CreateLonLat):\n        # Parameters that are read from different files and are needed in other processes\n\n        self.__path = Path(path)\n        self.__patch_path = Path(path, FolderConstants.PATCH_FOLDER_NAME)\n\n        # Because there are only two parameters to load we can do it here, in constructor\n        self.pscands_ij = np.asmatrix(create_lonlat.pscands_ij)\n        self.lonlat = np.asmatrix(create_lonlat.lonlat)\n\n        if not self.__path.exists():\n            raise FileNotFoundError(""No PATCH folder. Load abs.path \'{0}\'"".format(\n                str(self.__path.absolute())))\n        if not self.__patch_path.exists():\n            raise FileNotFoundError(\n                ""No PATCH folder. Load abs.path \'{0}\'"".format(\n                    str(self.__patch_path.absolute())))\n        if self.pscands_ij is None:\n            raise AttributeError(""pscands_ij_array is None"")\n\n        self.__logger = self.__logger = LoggerFactory.create(""PsFiles"")\n\n    def start_process(self):\n        self.__logger.info(""Start"")\n\n        params = self.__load_params_from_rsc_file()\n\n        # In Stamps these where loaded to Matlab params\n        self.heading = float(params[\'heading\'])\n        self.mean_range = float(params[\'center_range_slc\'])\n\n        self.wavelength = self.__get_wavelength(params)\n\n        self.ifgs = self.__load_ifg_info_from_pscphase()\n\n        self.master_date = self.__get_master_date(params)\n        self.master_nr = self.__get_nr_ifgs_less_than_master(self.master_date, self.ifgs)\n\n        self.ifg_dates = self.__get_ifg_dates()\n\n        rg = self.__get_rg(params)\n\n        sat_look_angle = self.__get_look_angle(rg, params)\n\n        self.bperp_meaned, self.bperp = self.__get_bprep(self.ifgs, sat_look_angle, params)\n\n        self.mean_incidence = self.__get_meaned_incidence(rg, params)\n\n        self.ph = self.__get_ph(len(self.ifgs))\n\n        self.ll = self.__get_ll_array()\n\n        self.xy, sort_ind = self.__get_xy()\n\n        self.da = self.__get_da()\n\n        self.hgt = self.__get_hgt()\n\n        self.__sort_results(sort_ind, sat_look_angle)\n\n        self.__logger.info(""End"")\n\n    def save_results(self, save_path: str):\n        ProcessDataSaver(save_path, self.__FILE_NAME).save_data(\n            heading=self.heading,\n            mean_range=self.mean_range,\n            wavelength=self.wavelength,\n            mean_incidence=self.mean_incidence,\n            master_nr=self.master_nr,\n            bprep_meaned=self.bperp_meaned,\n            bperp=self.bperp,\n            ph=self.ph,\n            ll=self.ll,\n            xy=self.xy,\n            da=self.da,\n            sort_ind=self.sort_ind,\n            master_date=self.master_date,\n            ifgs=self.ifgs,\n            hgt=self.hgt,\n            ifg_dates=self.ifg_dates)\n\n    def load_results(self, load_path: str):\n        file_with_path = os.path.join(load_path, self.__FILE_NAME + "".npz"")\n        data = np.load(file_with_path)\n\n        self.heading = data[\'heading\']\n        self.mean_range = data[\'mean_range\']\n        self.wavelength = data[\'wavelength\']\n        self.mean_incidence = data[\'mean_incidence\']\n        self.master_nr = data[\'master_nr\']\n        self.bperp_meaned = data[\'bprep_meaned\']\n        self.bperp = data[\'bperp\']\n        self.ph = data[\'ph\']\n        self.ll = data[\'ll\']\n        self.xy = data[\'xy\']\n        self.da = data[\'da\']\n        self.sort_ind = data[\'sort_ind\']\n        self.master_date = data[\'master_date\']\n        self.ifgs = data[\'ifgs\']\n        self.hgt = data[\'hgt\']\n        self.ifg_dates = data[\'ifg_dates\']\n\n    def __get_wavelength(self, params: dict):\n        velocity = 299792458  # Speed of signal (m/s)\n        freg = float(params[\'radar_frequency\']) * math.pow(10, 9)  # Signal frequency (GHz)\n        return velocity / freg\n\n    def __get_bprep(self, ifgs: np.ndarray, sat_look_angle: np.ndarray, params: dict):\n        """"""Here we find bprep_meaned and bprep_arr that were in Stamps accordingly bperp\n        and bperp_mat. Saving both of variables just in case.\n\n        In StaMPS ij file where loaded locally and calculations where done with matrix third column.\n        In Python this process is too slow (about 30 seconds).""""""\n        ARRAY_TYPE = np.float64\n\n        cos_sat_look_angle = np.cos(sat_look_angle)\n        sin_sat_look_angle = np.sin(sat_look_angle)\n\n        mean_azimuth_line = float(params[\'azimuth_lines\']) / 2 - 0.5\n\n        ij_lon = self.pscands_ij[:, 1]\n        nr_ifgs = len(ifgs)\n        bperp = matlib.zeros((len(self.pscands_ij), nr_ifgs), dtype=ARRAY_TYPE)\n\n        bc_bn_formula = lambda tcn, baseline_rate: tcn + baseline_rate * (\n                ij_lon - mean_azimuth_line) / float(params[\'prf\'])\n\n        for i in range(nr_ifgs):\n            tcn, baseline_rate = self.__get_baseline_params(ifgs[i])\n\n            bc = bc_bn_formula(tcn[1], baseline_rate[1])\n            bn = bc_bn_formula(tcn[2], baseline_rate[2])\n            bprep_line = np.multiply(bc, cos_sat_look_angle) - np.multiply(bn, sin_sat_look_angle)\n            bperp[:, i] = bprep_line\n\n        bprep_meaned = np.mean(bperp, 0).transpose()\n        # Removing master column (column where are persistent scatterers)\n        bperp = MatrixUtils.delete_master_col(bperp, self.master_nr)\n\n        # Return array not matrix\n        return ArrayUtils.matrix_to_array(bprep_meaned), ArrayUtils.matrix_to_array(bperp)\n\n    def __get_ph(self, nr_ifgs):\n        """"""pscands.1.ph file load. In this file there are complex binary numbers""""""\n        BINARY_COMPLEX_TYPE = np.dtype(\'>c8\')  # ""big-endian"" 64bit complex\n\n        COMPLEX_TYPE = np.complex64\n\n        path_to_ph = self.__patch_path.joinpath(""pscands.1.ph"")\n\n        with path_to_ph.open(""rb"") as file:\n            imag_array_raw = np.fromfile(file, BINARY_COMPLEX_TYPE)\n\n        imag_mx_len = int(len(imag_array_raw) / nr_ifgs)\n        imag_list = []\n        count = 0\n        for i in range(0, len(imag_array_raw), imag_mx_len):\n            matrix_row = imag_array_raw[i:i + imag_mx_len]\n            if count == self.master_nr - 1:\n                matrix_row = np.ones((imag_mx_len), dtype=COMPLEX_TYPE)\n            imag_list.append(matrix_row)\n\n            count += 1\n\n        return np.asarray(imag_list, COMPLEX_TYPE).transpose()\n\n    def __get_meaned_incidence(self, rg: np.ndarray, params: dict):\n        sar_to_earth_center_sq = math.pow(float(params[\'sar_to_earth_center\']), 2)\n        earth_radius_below_sensor_sq = math.pow(float(params[\'earth_radius_below_sensor\']),\n                                                2)\n\n        incidence = np.arccos(\n            np.divide(\n                (sar_to_earth_center_sq - earth_radius_below_sensor_sq - np.power(rg, 2)),\n                (2 * float(params[\'earth_radius_below_sensor\']) * rg)))\n        return incidence.mean()\n\n    def __get_baseline_params(self, ifg_name: np.str_):\n        """"""Returns two parameters: tcn (initial baseline) ja baseline_rate.\n        These are find in .base files. For every interferogram there is one file.\n        There is array sized three each one of these.""""""\n\n        name_and_ext = ifg_name.split(""."")\n        base_file_name = name_and_ext[0] + "".base""\n        path = Path(base_file_name)\n\n        if path.exists():\n            tcn = None\n            baseline_rate = None\n            with path.open() as basefile:\n                for line in basefile:\n                    splited = line.split(\'\t\')\n                    if splited[0] == ""initial_baseline(TCN):"":\n                        tcn = np.array((\n                            splited[1], splited[2], splited[3]), dtype=np.float64)\n                    elif splited[0] == ""initial_baseline_rate:"":\n                        baseline_rate = np.array((\n                            splited[1], splited[2], splited[3]), dtype=np.float64)\n                    else:\n                        break\n\n            return tcn, baseline_rate\n        else:\n            raise FileNotFoundError(base_file_name + "" not found."")\n\n    def __load_params_from_rsc_file(self) -> dict:\n        """"""From this file we read satellite metadata. Loaded params are put into dict and returned""""""\n\n        params = {}\n\n        ALLOWED_PARAMS = [""azimuth_lines"",\n                          ""heading"",\n                          ""range_pixel_spacing"",\n                          ""azimuth_pixel_spacing"",\n                          ""radar_frequency"",\n                          ""prf"",\n                          ""sar_to_earth_center"",\n                          ""earth_radius_below_sensor"",\n                          ""near_range_slc"",\n                          ""center_range_slc"",\n                          ""date""]\n\n        value_regex = re.compile(r""-?[\\d*.]+"")\n        with self.__load_file(""rsc.txt"", self.__path) as rsc_file:\n            rsc_par_file_abs_path = rsc_file.read().strip()\n\n            rsc_par_file = Path(rsc_par_file_abs_path)\n            if rsc_par_file.exists():\n                with rsc_par_file.open() as rsc_par:\n                    for line in rsc_par:\n                        # This is last parameter. After that we can stop processing\n                        if line == ""state_vector_position_1"":\n                            break\n\n                        splited = line.split(\':\')\n                        key = splited[0]\n\n                        if key in ALLOWED_PARAMS:\n                            if key == \'date\':\n                                # If not seprated with coma or is not string then removes spaces\n                                value = re.sub(""[\\t\\n\\v]"", """", splited[1])\n                            else:\n                                value = value_regex.findall(splited[1])[0]\n\n                            params[key] = value\n            else:\n                raise FileNotFoundError(\n                    ""No file. Abs.path \'"" + str(rsc_par_file.absolute()) + ""\'"")\n\n            return params\n\n    def __get_master_date(self, params: dict):\n        """"""\'date\' is from load_params_from_rsc_file and is master date. We split that string here\n        and make it datetime""""""\n        date_arr = params[""date""].split(\'  \')\n        return date(int(date_arr[0]), int(date_arr[1]), int(date_arr[2]))\n\n    def __load_file(self, name: str, path: Path):\n        file_path = Path(path, name)\n\n        if file_path.exists():\n            return file_path.open()\n        else:\n            raise FileNotFoundError(""No file "" + name + "". Abs.path "" + str(file_path.absolute()))\n\n    def __load_ifg_info_from_pscphase(self):\n        """"""In pscphase.in file there are paths to inteferograms. Those are returned in this\n        function. In filename there is master date and inteferogram date.""""""\n\n        path = self.__path.joinpath(""pscphase.in"")\n        if path.exists():\n            pscphase = np.genfromtxt(str(path), dtype=str, skip_header=True)\n            return pscphase\n        else:\n            raise FileNotFoundError(""pscphase.in not found. AbsPath {0}"".format(\n                str(path.absolute())))\n\n    def __get_nr_ifgs_less_than_master(self, master_date: date, ifgs: np.ndarray):\n        """"""How many inteferograms there are before master""""""\n        comp_fun = lambda x, y: x > y\n        return self.get_nr_ifgs_copared_to_master(comp_fun, ifgs, master_date)\n\n    def __get_ll_array(self):\n        return (MatlabUtils.max(self.lonlat) + MatlabUtils.min(self.lonlat)) / 2\n\n    def __get_xy(self):\n\n        """"""ij array is taken last two columns that are x an y.\n        This is multiplied with scalar, fixes data by rotating image and later sorted by y column.\n        Here we additionally also add sorting index column that other arrays can use.""""""\n        xy = np.fliplr(self.pscands_ij.copy())[:, 0:2]\n        xy[:, 0] *= 20\n        xy[:, 1] *= 4\n\n        xy = self.__scene_rotate(xy)\n\n        # Return value is array. Make it correct here\n        xy = ArrayUtils.matrix_to_array(xy)\n\n        sort_ind = np.lexsort((xy[:, 0], xy[:, 1]))\n        sorted_xy = xy[sort_ind]\n\n        # TODO Multiply to closest millimeter. But why it is already int\n        sorted_xy = np.around(sorted_xy * 1000) / 1000\n\n        return sorted_xy, sort_ind\n\n    def __scene_rotate(self, xy: np.matrix):\n        # TODO find better name for this variable\n        theta = (180 - self.heading) * math.pi / 180\n        if theta > math.pi:\n            theta -= 2 * math.pi\n\n        rotm = np.array([[math.cos(theta), math.sin(theta)], [-math.sin(theta), math.cos(theta)]])\n        xy = xy.H\n\n        rotated_xy = rotm * xy\n        # We need maximum element, that\'s why we don\'t use axis parameter\n        is_improved = np.amax(rotated_xy[0]) - np.amin(rotated_xy[0]) < np.amax(xy[0]) - np.amin(\n            xy[0]) and np.amax(rotated_xy[1]) - np.amin(rotated_xy[1]) < np.amax(xy[1]) - np.amin(\n            xy[1])\n        if is_improved:\n            xy = rotated_xy\n\n        xy = xy.H\n        return xy\n\n    def __sort_results(self, sort_ind: np.ndarray, sat_look_angle: np.ndarray):\n        self.ph = self.ph[sort_ind]\n        self.bperp = self.bperp[sort_ind]\n        self.da = self.da[sort_ind]\n\n        self.pscands_ij = MatrixUtils.sort_matrix_with_sort_array(self.pscands_ij, sort_ind)\n        self.lonlat = MatrixUtils.sort_matrix_with_sort_array(self.lonlat, sort_ind)\n\n        self.sort_ind = sat_look_angle[sort_ind]\n        self.hgt = self.hgt[sort_ind]\n\n    def __get_da(self):\n        # Because the file is small (only one column) then loadtxt function is quick enough\n        return np.loadtxt(str(Path(self.__patch_path, ""pscands.1.da"")))\n\n    def __get_look_angle(self, rg: np.ndarray, params):\n        sar_to_earth_center_sq = math.pow(float(params[\'sar_to_earth_center\']), 2)\n        earth_radius_below_sensor_sq = math.pow(float(params[\'earth_radius_below_sensor\']),\n                                                2)\n        return np.arccos(np.divide(\n            sar_to_earth_center_sq + np.power(rg, 2) - earth_radius_below_sensor_sq,\n            2 * float(params[\'sar_to_earth_center\']) * rg))\n\n    def __get_hgt(self):\n        FLOAT_TYPE = "">f4""  # ""big-endian"" float32\n        path_to_hgt = self.__patch_path.joinpath(""pscands.1.hgt"")\n\n        with path_to_hgt.open(""rb"") as file:\n            hgt_raw = np.fromfile(file, FLOAT_TYPE)\n\n        hgt = hgt_raw.conj().transpose()\n\n        return hgt\n\n    def __get_rg(self, params: dict):\n        ij_lat = self.pscands_ij[:, 2]\n        return float(params[\'near_range_slc\']) + ij_lat * float(params[\'range_pixel_spacing\'])\n\n    def __get_ifg_dates(self) -> []:\n        ifgs = self.ifgs\n\n        ifg_dates = []\n        for ifg_path in ifgs:\n            ifg_date_str_yyyymmdd = ifg_path[-13:-5]\n            ifg_datetime = date(int(ifg_date_str_yyyymmdd[:4]),\n                                int(ifg_date_str_yyyymmdd[4:6]),\n                                int(ifg_date_str_yyyymmdd[6:8]))\n\n            ifg_dates.append(ifg_datetime)\n\n        return ifg_dates\n\n    def get_ps_variables(self):\n        """"""For exporting variables that are used in PsEstGamma and PsSelect""""""\n\n        nr_ifgs = len(self.ifgs)\n        nr_ps = len(self.pscands_ij)\n\n        return self.ph, self.bperp, nr_ifgs, nr_ps, self.xy, self.da\n\n    def get_nr_ifgs_copared_to_master(self, comp_fun: Callable[[date, date], bool],\n                                      ifgs=np.array([]), master_date: date=None):\n        """"""\n        How many images there are after or before master image plus one. Dates are parsed are from\n        filename.\n\n        :param comp_fun: Comparison function. Example: x > y (two params, returns boolean)\n        :param ifgs: File paths that are used to get date\n        :param master_date: Master date (optional). If not set then self.master_date is used.\n        :return: integer, number of images\n        """"""\n\n        if ifgs is None or len(ifgs) == 0:\n            ifgs = self.ifgs\n\n        if master_date is None:\n            master_date = self.master_date\n\n        result = 1  # In StaMPS they added one after this processing, in return\n        for ifg_path in ifgs:\n            ifg_date_str_yyyymmdd = ifg_path[-13:-5]\n            ifg_datetime = date(int(ifg_date_str_yyyymmdd[:4]),\n                                int(ifg_date_str_yyyymmdd[4:6]),\n                                int(ifg_date_str_yyyymmdd[6:8]))\n\n            if comp_fun(ifg_datetime, master_date):\n                result += 1\n        return result\n'"
scripts/processes/PsSelect.py,70,"b'import enum\n\nimport numpy as np\nimport os\n\nfrom scripts.MetaSubProcess import MetaSubProcess\nfrom scripts.funs.PsTopofit import PsTopofit\nfrom scripts.processes.PsEstGamma import PsEstGamma\nfrom scripts.processes.PsFiles import PsFiles\nfrom scripts.utils.ArrayUtils import ArrayUtils\nfrom scripts.utils.internal.LoggerFactory import LoggerFactory\nfrom scripts.utils.MatlabUtils import MatlabUtils\nfrom scripts.utils.internal.ProcessCache import ProcessCache\nfrom scripts.utils.internal.ProcessDataSaver import ProcessDataSaver\n\n\nclass PsSelect(MetaSubProcess):\n    """"""Select stabile pixels that become persistent scatterer""""""\n\n\n    __B = np.array([])\n\n    __FILE_NAME = ""ps_select""\n\n    def __init__(self, ps_files: PsFiles, ps_est_gamma: PsEstGamma):\n        self.__PH_PATCH_CACHE = True\n        self.__ps_files = ps_files\n        self.__ps_est_gamma = ps_est_gamma\n\n        self.__logger = LoggerFactory.create(""PsSelect"")\n\n        self.__set_internal_params()\n\n    def __set_internal_params(self):\n        """"""In StaMPS these where saved with setparam and getparam.\n        All values are that small_baseline_flag = \'N\'.\n\n        In StaMPS max_desinty_rand ja max_percent_rand where two seperate varaibles, there we get\n        them using function __get_max_rand.\n        """"""\n        self.__slc_osf = 1\n        self.__clap_alpha = 1\n        self.__clap_beta = 0.3\n        self.__clap_win = 32\n        self.__select_method = self._SelectMethod.DESINTY  # DESINITY or PERCENT\n        # todo Why is this here\n        self.__gamma_stdev_reject = 0\n        # TODO This is [] in Stamps\n        self.__drop_ifg_index = np.array([])\n        self.__low_coh_tresh = 31  # 31/100\n\n        self.__gaussian_window = np.multiply(np.asmatrix(MatlabUtils.gausswin(7)),\n                                             np.asmatrix(MatlabUtils.gausswin(7)).conj().transpose())\n\n    class __DataDTO(object):\n        """"""This is inner data transfer object. It is because some functions take very many\n        parameters, so we use this class. It is filled in load_ps_params function""""""\n\n        def __init__(self, ph: np.ndarray, nr_ifgs: int, xy: np.ndarray,\n                     da: np.ndarray, ifg_ind: np.ndarray, da_max: np.ndarray,\n                     rand_dist: np.ndarray):\n            self.ph = ph\n            self.nr_ifgs = nr_ifgs\n            self.xy = xy\n            self.da = da\n            self.ifg_ind = ifg_ind\n            self.da_max = da_max\n            self.rand_dist = rand_dist\n\n    @enum.unique\n    class _SelectMethod(enum.Enum):\n        """"""Internal varaible \'select_method\' possible values""""""\n        DESINTY = 1\n        PERCENT = 2\n\n    def start_process(self):\n        """"""Please note that min_coh, coh_thresh and coh_thresh_ind params must be precise as\n        possible. Because 0.0001 offset may ruin coh_threh result""""""\n\n        self.__logger.info(""Start"")\n\n        data = self.__load_ps_params()\n\n        max_rand = self.__get_max_rand(data.da_max, data.xy)\n        self.__logger.debug(""max_rand: {0}"".format(max_rand))\n\n        min_coh, da_mean, is_min_coh_nan_array = self.__get_min_coh_and_da_mean(\n            self.__ps_est_gamma.coh_ps, max_rand, data)\n        self.__logger.debug(""min_coh.len: {0} ; da_mean.len: {1}""\n                            .format(len(min_coh), len(da_mean)))\n\n        coh_thresh = self.__get_coh_thresh(min_coh, da_mean, is_min_coh_nan_array, data.da)\n        self.__logger.debug(""coh_thresh.len: {0}"".format(len(coh_thresh)))\n\n        coh_thresh_ind = self.__get_coh_thresh_ind(coh_thresh, data)\n        self.__logger.debug(""coh_thresh_ind.len: {0}"".format(len(coh_thresh_ind)))\n\n        ph_patch = self.__get_ph_patch(coh_thresh_ind, data)\n        self.__logger.debug(""ph_patch.shape: {0}"".format(ph_patch.shape))\n\n        coh_ps, topofit = self.__topofit(ph_patch, coh_thresh_ind, data)\n        self.__logger.debug(""coh_ps.len: {0}"".format(len(coh_ps)))\n\n        # And now we find coh_thresh again using new coh_os. For that we also need to find min_coh\n        # and da_mean.\n\n        min_coh, da_mean, is_min_coh_nan_array = self.__get_min_coh_and_da_mean(\n            coh_ps, max_rand, data)\n        self.__logger.debug(""Second run min_coh.len: {0} ; da_mean.len: {1}""\n                            .format(len(min_coh), len(da_mean)))\n\n        # Please note that da array is filtered by coh_thresh_ind\n        coh_thresh = self.__get_coh_thresh(min_coh, da_mean, is_min_coh_nan_array,\n                                           data.da[coh_thresh_ind])\n        self.__logger.debug(""Second run coh_thresh.len: {0}"".format(len(coh_thresh)))\n\n        # todo Maybe filter when you find those results\n        keep_ind = self.__get_keep_ind(topofit.coh_ps, coh_thresh, coh_thresh_ind,\n                                                   topofit.k_ps)\n        self.__logger.debug(""keep_ind.len: {0}""\n                            .format(len(keep_ind)))\n\n        # Results to class variables\n        self.coh_thresh = coh_thresh\n        self.ph_patch = ph_patch\n        self.coh_thresh_ind = coh_thresh_ind\n        self.keep_ind = keep_ind\n        self.coh_ps = coh_ps # In StaMPS this result is overriden from last process\n        self.coh_ps2 = topofit.coh_ps # Find better name\n        self.ph_res = topofit.ph_res\n        self.k_ps = topofit.k_ps\n        self.c_ps = topofit.c_ps\n        self.ifg_ind = data.ifg_ind\n\n        self.__logger.debug(""End"")\n\n    def save_results(self, save_path: str):\n        ProcessDataSaver(save_path, self.__FILE_NAME).save_data(\n            coh_thresh=self.coh_thresh,\n            ph_patch=self.ph_patch,\n            coh_thresh_ind=self.coh_thresh_ind,\n            keep_ind=self.keep_ind,\n            coh_ps=self.coh_ps,\n            coh_ps2=self.coh_ps2,\n            ph_res=self.ph_res,\n            k_ps=self.k_ps,\n            c_ps=self.c_ps,\n            ifg_ind=self.ifg_ind\n        )\n\n    def load_results(self, load_path: str):\n        file_with_path = os.path.join(load_path, self.__FILE_NAME + "".npz"")\n        data = np.load(file_with_path)\n\n        self.coh_thresh = data[\'coh_thresh\']\n        self.ph_patch = data[\'ph_patch\']\n        self.coh_thresh_ind = data[\'coh_thresh_ind\']\n        self.keep_ind = data[\'keep_ind\']\n        self.coh_ps = data[\'coh_ps\']\n        self.coh_ps2 = data[\'coh_ps2\']\n        self.ph_res = data[\'ph_res\']\n        self.k_ps = data[\'k_ps\']\n        self.c_ps = data[\'c_ps\']\n        self.ifg_ind = data[\'ifg_ind\']\n\n    def __load_ps_params(self) -> __DataDTO:\n        """"""Finds values that are needed from ps_files and changes them a bit. It is similar to\n        load_ps_params method in PsEstGamma function.""""""\n\n        def get_da_max(da):\n            # todo miks 10000?\n            if da.size >= 10000:\n                da_sorted = np.sort(da, axis=0)\n                if da.size >= 50000:\n                    bin_size = 10000\n                else:\n                    bin_size = 2000\n\n                # bin_size - 1 is for that to take elements with correct indexes that are in Matlab\n                da_max = np.concatenate(\n                    (np.zeros(1), da_sorted[bin_size - 1: -bin_size - 1: bin_size],\n                     np.array([da_sorted[-1]])))\n            else:\n                da_max = np.array([0], [1])\n                da = np.ones(len(self.__ps_est_gamma.coh_ps))\n\n            return da_max, da\n\n        def filter_params_based_on_ifgs_and_master(ph: np.ndarray, bperp: np.ndarray, nr_ifgs: int):\n            """"""Filter out master row form ph and bperp arrays""""""\n\n            comp_fun = lambda x, y: x < y\n\n            no_master_ix = np.setdiff1d(np.arange(0, nr_ifgs),\n                                        self.__ps_files.master_nr - 1)\n\n            ifg_ind = np.setdiff1d(np.arange(0, nr_ifgs), self.__drop_ifg_index)\n            ifg_ind = np.setdiff1d(ifg_ind, self.__ps_files.master_nr)\n            master_ix = self.__ps_files.get_nr_ifgs_copared_to_master(comp_fun) - 1\n            ifg_ind[ifg_ind > master_ix] -= 1\n\n            ph = ph[:, no_master_ix]\n            bperp = bperp[no_master_ix]\n            nr_ifgs = len(no_master_ix)\n\n            return ifg_ind, ph, bperp, nr_ifgs\n\n        ph, bperp, nr_ifgs, _, xy, da = self.__ps_files.get_ps_variables()\n\n        # In StaMPS this is done when small_base_line flag is not \'y\'. Beacause this process is\n        # made as small_baseline_flag value is \'n\' we also make this always\n        ifg_ind, ph, bperp, nr_ifgs = filter_params_based_on_ifgs_and_master(ph, bperp, nr_ifgs)\n\n        da_max, da = get_da_max(da)\n\n        # nr_dist in StaMPS\n        rand_dist = self.__ps_est_gamma.rand_dist\n\n        data_dto = self.__DataDTO(ph, nr_ifgs, xy, da, ifg_ind, da_max, rand_dist)\n        return data_dto\n\n    def __get_max_rand(self, da_max: np.ndarray, xy: np.ndarray):\n        """"""This function finds variable that in StaMPS is called \'max_percent_rand\'.\n\n        In StaMPS this variable is read in parameters. But in this process we also change it a bit\n        we calculate this here""""""\n\n        DEF_VAL = 20\n\n        if self.__select_method is self._SelectMethod.DESINTY:\n            # In Stamps min and max values are in separate arrays with a single element.\n            patch_area = np.prod(MatlabUtils.max(xy) - MatlabUtils.min(xy)) / 1e6  # In km\n            max_rand = DEF_VAL * patch_area / (len(da_max) -1)\n        else:\n            max_rand = DEF_VAL\n\n        return max_rand\n\n    def __get_min_coh_and_da_mean(self, coh_ps: np.ndarray, max_rand: float, data: __DataDTO) -> (\n            np.ndarray, np.ndarray, bool):\n\n        # Internal parameters because full names are bad to write and read all the time\n        coherence_bins = self.__ps_est_gamma.coherence_bins\n        rand_dist = self.__ps_est_gamma.rand_dist\n\n        array_size = data.da_max.size - 1\n\n        min_coh = np.zeros(array_size)\n        # In StaMPS this is size(da_max, 1) what is same as length(da_max)\n        da_mean = np.zeros(array_size)\n        for i in range(array_size):\n            # You can use np.all or np.logical here too. Bitwize isn\'t must\n            coh_chunk = coh_ps[(data.da > data.da_max[i]) & (data.da <= data.da_max[i + 1])]\n\n            da_mean[i] = np.mean(\n                data.da[(data.da > data.da_max[i]) & (data.da <= data.da_max[i + 1])])\n            # Remove pixels that we could not find coherence\n            coh_chunk = coh_chunk[coh_chunk != 0]\n            # In StaMPS this is called \'Na\'\n            hist, _ = MatlabUtils.hist(coh_chunk, coherence_bins)\n\n            hist_low_coh_sum = MatlabUtils.sum(hist[:self.__low_coh_tresh])\n            rand_dist_low_coh_sum = MatlabUtils.sum(rand_dist[:self.__low_coh_tresh])\n            nr = rand_dist * hist_low_coh_sum / rand_dist_low_coh_sum  # todo What does this \'nr\' mean?\n\n            # In StaMPS here is also possibility to make graph\n\n            hist[hist == 0] = 1\n\n            # Percent_rand calculate\n            # np.flip allows to use one-dimencional arrays, thats why we don\'t use np.fliplr\n            nr_cumsum = np.cumsum(np.flip(nr, axis=0), axis=0)\n            if self.__select_method is self._SelectMethod.PERCENT:\n                hist_cumsum = np.cumsum(np.flip(hist, axis=0), axis=0) * 100\n                percent_rand = np.flip(np.divide(nr_cumsum, hist_cumsum), axis=0)\n            else:\n                percent_rand = np.flip(nr_cumsum, axis=0)\n\n            ok_ind = np.where(percent_rand < max_rand)[0]\n\n            if len(ok_ind) == 0:\n                # When coherence is over limit\n                min_coh[i] = 1\n            else:\n                # Here we don\'t need to add one to indexes because on \'ok_ind\' array it is already\n                # done. This means that all those \'magical constants\' are that where in StaMPS\n\n                min_fit_ind = MatlabUtils.min(ok_ind) - 3  # todo Why 3?\n\n                if min_fit_ind <= 0:\n                    min_coh[i] = np.nan\n                else:\n                    max_fit_ind = MatlabUtils.min(ok_ind) + 2  # todo Why 2?\n\n                    # In StaMPS this is just constant 100. Not length of array.\n                    if max_fit_ind > len(percent_rand) - 1:\n                        max_fit_ind = len(percent_rand) - 1\n\n                    x_cordinates = percent_rand[min_fit_ind:max_fit_ind + 1]\n\n                    y_cordinates = ArrayUtils.arange_include_last((min_fit_ind + 1) * 0.01,\n                                                                  (max_fit_ind + 1) * 0.01, 0.01)\n                    min_coh[i] = MatlabUtils.polyfit_polyval(x_cordinates, y_cordinates, 3,\n                                                             max_rand)\n\n        # Check if min_coh is unusable (full of nan\'s\n        # This is bit different on StaMPS. I find min_coh\'i ja da_mean in same method and in\n        # same time\n        not_nan_ind = np.where(min_coh != np.nan)[0]\n        is_min_coh_nan_array = sum(not_nan_ind) == 0\n        # When there isn\'t differences then we don\'t need to take subsets of arrays\n        if not is_min_coh_nan_array or (not_nan_ind == array_size):\n            min_coh = min_coh[not_nan_ind]\n            da_mean = da_mean[not_nan_ind]\n\n        return min_coh, da_mean, is_min_coh_nan_array\n\n    def __get_coh_thresh(self, min_coh: np.ndarray, da_mean: np.ndarray,\n                         is_min_coh_nan_array: bool, da: np.ndarray):\n        """"""Here we don\'t return coh_tresh_coffs\'i because it is used only for graphs""""""\n        DEF_COH_THRESH = 0.3\n\n        if is_min_coh_nan_array:\n            self.__logger.warn(\n                \'Not enough random phase pixels to set gamma threshold - using default threshold of \'\n                + str(DEF_COH_THRESH))\n            # Default value is put into array for others to use. Other functions expect array\n            # that\'s why we can\'t use just float\n            coh_thresh = np.array([DEF_COH_THRESH])\n        else:\n            # Because we have already changed min_coh ja da_mean arrays\n            if len(min_coh) > 1:\n                coh_thresh_coffs = np.polyfit(da_mean, min_coh, 1)\n\n                if coh_thresh_coffs[0] > 0:\n                    # todo mida t\xc3\xa4hendab ""positive slope""?\n                    coh_thresh = np.polyval(coh_thresh_coffs, da)\n                else:\n                    # todo mida t\xc3\xa4hendab ""unable to ascertain correct slope""\n                    coh_thresh = np.polyval(coh_thresh_coffs, 0.35)\n            else:\n                coh_thresh = min_coh\n\n        return coh_thresh\n\n    def __is_select_method_percent(self):\n        return self.__select_method is self._SelectMethod.PERCENT\n\n    def __get_coh_thresh_ind(self, coh_thresh: np.ndarray, data: __DataDTO):\n\n        def make_coh_thresh_ind_array(make_function):\n            function_result = make_function()\n\n            return function_result\n\n        coh_ps = self.__ps_est_gamma.coh_ps\n        ph_res = self.__ps_est_gamma.ph_res\n\n        # We use reshape because this array is bit different\n        # [0] is needed because where function returns tuple\n        coh_thresh_ind_fun = lambda: np.where(coh_ps.reshape(len(coh_ps)) > coh_thresh)[0]\n        # \'ix\' in StaMPS\n        coh_thresh_ind = make_coh_thresh_ind_array(coh_thresh_ind_fun)\n\n        if self.__gamma_stdev_reject > 0:\n            ph_res_cpx = np.exp(1j * ph_res[:, data.ifg_ind])\n\n            coh_std = np.zeros(len(coh_thresh_ind))\n            for i in range(len(coh_thresh_ind)):\n                # todo Who to make bootstrp\'i in Numpy?\n                # bootstrap = np.boots\n                # coh_std[i] = MatlabUtils.std()\n                pass\n\n            coh_thresh_filter_fun = lambda: coh_thresh_ind[coh_std < self.__gamma_stdev_reject]\n            coh_thresh_ind = make_coh_thresh_ind_array(coh_thresh_filter_fun)\n\n            # todo In StaMPS here is logic rest_flag. Is it needed?\n            # for i in range(self.__drop_ifg_index):\n            # Because this process is made as small_baseline_flag = \'N\' we don\'t have more here.\n\n        return coh_thresh_ind\n\n    def __get_ph_patch(self, coh_thresh_ind: np.ndarray, data: __DataDTO):\n\n        CACHE_FILE_NAME = ""tmp_ph_patch""\n\n        def get_max_min(ps_ij_col: np.ndarray, nr_ij: int):\n            min_val = max(ps_ij_col - self.__clap_win / 2, 0)\n            max_val = min_val + self.__clap_win - 1\n\n            if max_val >= nr_ij:\n                min_val = min_val - max_val + nr_ij - 1\n                max_val = nr_ij - 1\n\n            return int(min_val), int(max_val)\n\n        def get_ph_bit_ind_array(ps_bit_col: int, ph_bit_len):\n            slc_osf = self.__slc_osf - 1\n            ind_array = ArrayUtils.arange_include_last(start=ps_bit_col - slc_osf,\n                                                       end=ps_bit_col + slc_osf).astype(np.int32)\n            ind_array = ind_array[(ind_array > 0) & (0 <= ph_bit_len)]\n\n            # Python can\'t take anything from empty/ no values list\n            if len(ind_array) == 0:\n                ind_array = np.zeros(1).astype(np.int16)\n\n            return ind_array\n\n        def ph_path_loop():\n            # In StaMPS this is the place where to delete \'ph_res\' and \'ph_patch\' that were found\n            # from last process\n\n            NR_PS = len(coh_thresh_ind)\n            ph_patch = self.__zero_ph_array(NR_PS, data.nr_ifgs)\n\n            # Similar logic with \'nr_i\' ja \'nr_j\' already exists in PsEstGamma process\n            nr_i = MatlabUtils.max(self.__ps_est_gamma.grid_ij[:, 0])\n            nr_j = MatlabUtils.max(self.__ps_est_gamma.grid_ij[:, 1])\n\n            # In StaMPS this variable had \'2\' at the end of the name\n            ph_filt = np.zeros((self.__clap_win, self.__clap_win, data.nr_ifgs), np.complex128)\n\n            for i in range(ph_patch.shape[0]):\n                ps_ij = self.__ps_est_gamma.grid_ij[coh_thresh_ind[i], :]\n\n                i_min, i_max = get_max_min(ps_ij[0] - 1, nr_i)\n                j_min, j_max = get_max_min(ps_ij[1] - 1, nr_j)\n\n                # If you don\'t make copy then changes are made also in ph_grid variable\n                ph_bit = np.copy(self.__ps_est_gamma.ph_grid[i_min:i_max + 1, j_min:j_max + 1, :])\n\n                ps_bit_i = int(ps_ij[0] - i_min - 1)\n                ps_bit_j = int(ps_ij[1] - j_min - 1)\n                ph_bit[ps_bit_i, ps_bit_j, :] = 0\n\n                # todo Some kind of JJS oversample update\n                ph_bit_len = len(ph_bit) + 1\n                ph_bit_ind_i = get_ph_bit_ind_array(ps_bit_i, ph_bit_len)\n                ph_bit_ind_j = get_ph_bit_ind_array(ps_bit_j, ph_bit_len)\n                ph_bit[ph_bit_ind_i, ph_bit_ind_j, 0] = 0\n\n                # It is similar with PsEstGammas ph_flit process but still not the same\n                for j in range(ph_patch.shape[1]):\n                    ph_filt[:, :, j] = self.__clap_filt_for_patch(ph_bit[:, :, j],\n                                                                  self.__ps_est_gamma.low_pass)\n\n                ph_patch[i, :] = np.squeeze(ph_filt[ps_bit_i, ps_bit_j, :])\n\n            return ph_patch\n\n        if self.__PH_PATCH_CACHE:\n            try:\n                self.__logger.debug(""Trying to use cache"")\n                loaded = ProcessCache.get_from_cache(CACHE_FILE_NAME, \'ph_patch\', \'coh_thresh_ind\')\n                if np.array_equal(coh_thresh_ind, loaded[\'coh_thresh_ind\']):\n                    self.__logger.debug(""Using cache"")\n                    ph_patch = loaded[\'ph_patch\']\n                else:\n                    self.__logger.debug(""No usable cache"")\n                    ph_patch = ph_path_loop()\n                    ProcessCache.save_to_cache(CACHE_FILE_NAME,\n                                               ph_patch=ph_patch,\n                                               coh_thresh_ind=coh_thresh_ind)\n            except FileNotFoundError:\n                self.__logger.debug(""No cache"")\n                ph_patch = ph_path_loop()\n                ProcessCache.save_to_cache(CACHE_FILE_NAME,\n                                           ph_patch=ph_patch,\n                                           coh_thresh_ind=coh_thresh_ind)\n        else:\n            self.__logger.debug(""Not using cache"")\n            ph_patch = ph_path_loop()\n\n        return ph_patch\n\n    def __clap_filt_for_patch(self, ph, low_pass):\n        """"""Combined Low-pass Adaptive Phase filtering on 1 patch.\n        In StaMPS this is in separate function clap_filt_patch""""""\n\n        alpha = self.__clap_alpha\n        beta = self.__clap_beta\n\n        if len(low_pass) == 0:\n            low_pass = np.zeros(len(ph))\n\n        ph = np.nan_to_num(ph)\n\n        # todo This ph_fft its very similar with PhEstGamma function clap_filt\n        # todo There where problems (incorrect value) with this part when calling third time\n        ph_fft = np.fft.fft2(ph)\n        smooth_resp = np.abs(ph_fft)\n        smooth_resp = np.fft.ifftshift(\n            MatlabUtils.filter2(self.__gaussian_window, np.fft.fftshift(smooth_resp)))\n        smooth_resp_mean = np.median(smooth_resp.flatten())\n\n        if smooth_resp_mean != 0:\n            smooth_resp /= smooth_resp_mean\n\n        smooth_resp = np.power(smooth_resp, alpha)\n\n        smooth_resp -= 1\n        smooth_resp[smooth_resp < 0] = 0\n\n        G = smooth_resp * beta + low_pass\n        ph_filt = np.fft.ifft2(np.multiply(ph_fft, G))\n\n        return ph_filt\n\n    def __topofit(self, ph_patch, coh_thresh_ind, data) -> (np.ndarray, PsTopofit):\n        NR_PS = len(coh_thresh_ind)\n        SW_ARRAY_SHAPE = (NR_PS, 1)\n\n        ph = data.ph[coh_thresh_ind, :]\n        bperp = self.__ps_files.bperp[coh_thresh_ind]\n\n        topofit = PsTopofit(SW_ARRAY_SHAPE, NR_PS, data.nr_ifgs)\n        topofit.ps_topofit_loop(ph, ph_patch, bperp, self.__ps_est_gamma.nr_trial_wraps,\n                                data.ifg_ind)\n\n        # In StaMPS old value is overridden here\n        coh_ps = self.__ps_est_gamma.coh_ps.copy()\n        coh_ps[coh_thresh_ind] = topofit.coh_ps\n\n        return coh_ps, topofit\n\n    def __get_keep_ind(self, coh_ps : np.ndarray, coh_thresh : np.ndarray,\n                       coh_thresh_ind : np.ndarray, k_ps2: np.ndarray) -> np.ndarray:\n        """"""In Stamps variable is named \'keep_ix\'""""""\n\n        bperp_meaned = self.__ps_files.bperp_meaned\n        k_ps = self.__ps_est_gamma.k_ps[coh_thresh_ind]\n        bperp_delta = np.max(bperp_meaned) - np.min(bperp_meaned)\n\n        # Reshape is needed because otherwise we get array of arrays\n        coh_ps_len = len(coh_ps)\n        coh_ps_reshaped = coh_ps.reshape(coh_ps_len)\n        delta = (np.abs(k_ps - k_ps2) < 2 * np.pi / bperp_delta).reshape(coh_ps_len) #todo parem nimi\n        keep_ind = np.where((coh_ps_reshaped > coh_thresh) & delta)[0]\n\n        return keep_ind\n\n    # todo Maybe some other solution here? PsEstGamma has already this kind of logic.\n    def __zero_ps_array(self, shape):\n        """"""Constuctor for making empty array for persistent scatterers data""""""\n        return np.zeros(shape)\n\n    # TODO: Why not the same as in PsEstGamma?\n    def __zero_ph_array(self, nr_ps, nr_ifgs):\n        return np.zeros((nr_ps, nr_ifgs), np.complex128)\n'"
scripts/processes/PsWeed.py,79,"b'import os\n\nfrom datetime import datetime\nimport numpy as np\nimport numpy.matlib\nimport sys\nimport math\nfrom pathlib import Path\n\nfrom scripts import RESOURCES_PATH\nfrom scripts.MetaSubProcess import MetaSubProcess\nfrom scripts.processes.PsEstGamma import PsEstGamma\nfrom scripts.processes.PsFiles import PsFiles\nfrom scripts.processes.PsSelect import PsSelect\nfrom scripts.utils.ArrayUtils import ArrayUtils\nfrom scripts.utils.internal.ConfigUtils import ConfigUtils\nfrom scripts.utils.internal.FolderConstants import FolderConstants\nfrom scripts.utils.internal.LoggerFactory import LoggerFactory\nfrom scripts.utils.MatlabUtils import MatlabUtils\nfrom scripts.utils.internal.ProcessDataSaver import ProcessDataSaver\n\n\nclass PsWeed(MetaSubProcess):\n    """"""Pixels filtering/ weeding from around others. Select only best/ clearest""""""\n\n    __IND_ARRAY_TYPE = np.int32\n    __DEF_NEIGHBOUR_VAL = -1\n    __FILE_NAME = ""ps_weed""\n\n    selectable_ps = np.array([])\n\n    def __init__(self, path_to_patch: str, ps_files: PsFiles, ps_est_gamma: PsEstGamma,\n                 ps_select: PsSelect):\n        self.__ps_files = ps_files\n        self.__ps_select = ps_select\n        self.__ps_est_gamma = ps_est_gamma\n\n        self.__logger = LoggerFactory.create(""PsWeed"")\n\n        self.__time_win = 730\n        self.__weed_standard_dev = 1\n        self.__weed_max_noise = sys.maxsize  # In StaMPS this is inf\n        self.__weed_zero_elevation = False\n        self.__weed_neighbours = True\n        # todo drop_ifg_index on juba PsSelect\'is\n        self.__drop_ifg_index = np.array([])\n\n        self.__ps_weed_edge_data = self.__load_psweed_edge_file(path_to_patch)\n        self.__logger.debug(""self.__ps_weed_edge_data.len: "" + str(len(self.__ps_weed_edge_data)))\n\n    def __load_psweed_edge_file(self, path: str) -> (int, np.ndarray):\n        """"""We load this file here because our process may not reach in this step and this file\'s\n        data is needed only here.\n\n\n        In StaMPS also where read how large is array (for header) but I don\'t see a point for that""""""\n        # todo Maybe use @lazy and put this to PsFiles class\n\n        file_name = ""psweed.2.edge""\n        psweed_path = Path(path, FolderConstants.PATCH_FOLDER_NAME, file_name)\n        self.__logger.debug(""Path to psweed edge file: "" + str(psweed_path))\n        if psweed_path.exists():\n            data = np.genfromtxt(psweed_path, skip_header=True, dtype=self.__IND_ARRAY_TYPE)\n            return data\n        else:\n            raise FileNotFoundError(""File named \'{1}\' not found. AbsPath \'{0}\'"".format(\n                str(psweed_path.absolute()), file_name))\n\n    class __DataDTO(object):\n\n        def __init__(self, ind: np.ndarray, ph_res: np.ndarray, coh_thresh_ind: np.ndarray,\n                     k_ps: np.ndarray, c_ps: np.ndarray, coh_ps: np.ndarray, pscands_ij: np.matrix,\n                     xy: np.ndarray, lonlat: np.matrix, hgt: np.ndarray, ph: np.ndarray,\n                     ph_patch_org: np.ndarray, bperp_meaned: np.ndarray, nr_ifgs: int,\n                     nr_ps: int, master_date: datetime, master_nr: int, ifg_dates: []):\n            self.ind = ind\n            self.ph_res = ph_res\n            self.coh_thresh_ind = coh_thresh_ind\n            self.k_ps = k_ps\n            self.c_ps = c_ps\n            self.coh_ps = coh_ps\n            self.pscands_ij = pscands_ij\n            self.xy = xy\n            self.lonlat = lonlat\n            self.hgt = hgt\n            self.ph_patch_org = ph_patch_org\n            self.ph = ph\n            self.bperp_meaned = bperp_meaned\n            self.nr_ifgs = nr_ifgs\n            self.nr_ps = nr_ps\n            self.master_date = master_date\n            self.master_nr = master_nr\n            self.ifg_dates = ifg_dates\n\n    def start_process(self):\n        self.__logger.info(""Start"")\n\n        data = self.__load_ps_params()\n        # In Stamps this is called \'nr_ps\' but we already have that named variable\n        coh_thresh_ind_len = len(data.coh_thresh_ind)\n        if coh_thresh_ind_len == 0:\n            self.__logger.warn(""coh_thresh_ind is empty"")\n        self.__logger.debug(""Loaded data. coh_thresh_ind.len: {0}, data.nr_ps: {1}""\n                            .format(coh_thresh_ind_len, data.nr_ps))\n\n        ij_shift = self.__get_ij_shift(data.pscands_ij, coh_thresh_ind_len)\n        self.__logger.debug(""ij_shift.len: {0}"".format(len(ij_shift)))\n\n        neighbour_ind = self.__init_neighbours(ij_shift, coh_thresh_ind_len)\n        self.__logger.debug(""neighbours.len: {0}"".format(len(neighbour_ind)))\n\n        neighbour_ps = self.__find_neighbours(ij_shift, coh_thresh_ind_len, neighbour_ind)\n        # todo kas saab logida ka t\xc3\xbchjade arvu?\n        self.__logger.debug(""neighbour_ps.len: {0}"".format(len(neighbour_ps)))\n\n        # \'ix_weed\' in StaMPS\n        selectable_ps = self.__select_best(neighbour_ps, coh_thresh_ind_len, data.coh_ps, data.hgt)\n        self.__logger.debug(""selectable_ps.len: {0}, true vals: {1}""\n                            .format(len(selectable_ps), np.count_nonzero(selectable_ps)))\n        del neighbour_ps\n\n        selectable_ps = self.__filter_xy(data.xy, selectable_ps, data.coh_ps)\n\n        # In PsWeed we make our own interferograms array.\n        # In Stamps this variable is called \'ifg_index\'\n        ifg_ind = np.arange(0, data.nr_ifgs, dtype=self.__IND_ARRAY_TYPE)\n        if len(self.__drop_ifg_index) > 0:\n            self.__logger.debug(""Dropping indexes {0}"".format(self.__drop_ifg_index))\n            np.setdiff1d(ifg_ind, self.__drop_ifg_index)\n\n        # In Stamps there is parameter \'no_weed_noisy\' that is calculated similarly\n        if not (self.__weed_standard_dev >= math.pi and self.__weed_max_noise >= math.pi):\n            edge_std, edge_max = self.__drop_noisy(data, selectable_ps, ifg_ind,\n                                                   self.__ps_weed_edge_data)\n            self.__logger.debug(""edge_std.len: {0}, edge_std.len: {1}""\n                                .format(len(edge_std), len(edge_std)))\n            ps_std, ps_max = self.__get_ps_arrays(edge_std, edge_max,\n                                                  np.count_nonzero(selectable_ps),\n                                                  self.__ps_weed_edge_data)\n            self.__logger.debug(""ps_std.len: {0}, ps_max.len: {1}""\n                                .format(len(ps_std), len(ps_max)))\n            selectable_ps, selectable_ps2 = self.__estimate_max_noise(ps_std, ps_max, selectable_ps)\n            self.__logger.debug(""selectable_ps.len: {0}, selectable_ps2.len: {1}""\n                                .format(len(selectable_ps), len(selectable_ps2)))\n        else:\n            self.__logger.error(""weed_standard_dev or weed_max_noise where bigger than pi"")\n            raise NotImplemented(""weed_standard_dev or weed_max_noise where bigger than pi"")\n\n        # Results to class variables\n        self.selectable_ps = selectable_ps\n        self.selectable_ps2 = selectable_ps2 # todo parem nimi\n        self.ifg_ind = ifg_ind\n        self.ps_max = ps_max\n        self.ps_std = ps_std\n\n        self.__logger.info(""End"")\n\n    def save_results(self, save_path: str):\n        ProcessDataSaver(save_path, self.__FILE_NAME).save_data(\n            selectable_ps = self.selectable_ps,\n            selectable_ps2 = self.selectable_ps2,\n            ifg_ind = self.ifg_ind,\n            ps_max = self.ps_max,\n            ps_std = self.ps_std\n        )\n\n    def load_results(self, load_path: str):\n        file_with_path = os.path.join(load_path, self.__FILE_NAME + "".npz"")\n        data = np.load(file_with_path)\n\n        self.selectable_ps = data[""selectable_ps""]\n        self.selectable_ps2 = data[""selectable_ps2""]\n        self.ifg_ind = data[""ifg_ind""]\n        self.ps_max = data[""ps_max""]\n        self.ps_std = data[""ps_std""]\n\n    def get_filtered_results(self, load_path: str = None):\n        """"""Because filtering is made using selectable_ps values and we already have all those\n        parameters (also class privates and parameters that are loaded only or this process) that\n        are filtered here we can do that filtering in this class.\n\n        In StaMPS they made new .mat files for saving results.""""""\n\n        self.__logger.info(""Finding filtered results"")\n\n        if len(self.selectable_ps) == 0:\n            self.__logger.debug(""Load results"")\n            if load_path is None:\n                load_path = ConfigUtils(RESOURCES_PATH).get_default_section(""save_load_path"")\n                self.__logger.info(""Using default load/save path from config: \'{0}\'"".format(\n                    load_path))\n\n            self.load_results(load_path)\n\n        data = self.__load_ps_params()\n\n        coh_ps = data.coh_ps[self.selectable_ps]\n        k_ps = data.k_ps[self.selectable_ps]\n        c_ps = data.c_ps[self.selectable_ps]\n        ph_patch = data.ph_patch_org[self.selectable_ps]\n        ph = data.ph[self.selectable_ps]\n        xy = data.xy[self.selectable_ps]\n        pscands_ij = data.pscands_ij[self.selectable_ps]\n        lonlat = data.lonlat[self.selectable_ps]\n        hgt = data.hgt[self.selectable_ps]\n\n        bperp = self.__ps_files.bperp[data.coh_thresh_ind]\n        bperp = bperp[self.selectable_ps]\n\n        sort_ind = self.__ps_files.sort_ind[data.coh_thresh_ind]\n        sort_ind = sort_ind[self.selectable_ps]\n\n        return coh_ps, k_ps, c_ps, ph_patch, ph, xy, pscands_ij, lonlat, hgt, bperp, sort_ind\n\n    def __load_ps_params(self):\n\n        def get_from_ps_select(ps_select: PsSelect):\n            ind = ps_select.keep_ind\n            ph_res = ps_select.ph_res[ind]\n\n            if len(ind) > 0:\n                coh_thresh_ind = ps_select.coh_thresh_ind[ind]\n                c_ps = ps_select.c_ps[ind]\n                k_ps = ps_select.k_ps[ind]\n                coh_ps = ps_select.coh_ps2[ind]\n            else:\n                coh_thresh_ind = ps_select.coh_thresh_ind\n                c_ps = ps_select.c_ps\n                k_ps = ps_select.k_ps\n                coh_ps = ps_select.coh_ps2\n\n            return ind, ph_res, coh_thresh_ind, k_ps, c_ps, coh_ps\n\n        def get_from_ps_files(ps_files: PsFiles, coh_thresh_ind: np.ndarray):\n            # Lets use get_variables function to get parameters\n            ph, _, nr_ifgs, nr_ps, xy, _ = ps_files.get_ps_variables()\n\n            # And then filter based on coh_thresh\n            pscands_ij = ps_files.pscands_ij[coh_thresh_ind]\n            xy = xy[coh_thresh_ind]\n            ph = ph[coh_thresh_ind]\n            lonlat = ps_files.lonlat[coh_thresh_ind]\n            hgt = ps_files.hgt[coh_thresh_ind]\n\n            # And then get parameters that are not filtered\n            master_nr = ps_files.master_nr\n            ifg_dates = ps_files.ifg_dates\n            bperp_meaned = ps_files.bperp_meaned\n            master_date = ps_files.master_date\n\n            return pscands_ij, xy, ph, lonlat, hgt, nr_ifgs, nr_ps, master_nr, ifg_dates, \\\n                   bperp_meaned, master_date\n\n        def get_from_ps_est_gamma(ps_est_gamma: PsEstGamma):\n            ph_patch = ps_est_gamma.ph_patch[coh_thresh_ind, :]\n\n            return ph_patch\n\n        ind, ph_res, coh_thresh_ind, k_ps, c_ps, coh_ps = get_from_ps_select(self.__ps_select)\n\n        pscands_ij, xy, ph, lonlat, hgt, nr_ifgs, nr_ps, master_nr, ifg_dates, bperp_meaned,\\\n        master_date = get_from_ps_files(self.__ps_files, coh_thresh_ind)\n\n        ph_patch_org = get_from_ps_est_gamma(self.__ps_est_gamma)\n\n        # In Stamps there also is param \'all_da_flag\' and found variables k_ps, c_ps, coh_ps,\n        # ph_patch_org, ph_res\n\n        return self.__DataDTO(ind, ph_res, coh_thresh_ind, k_ps, c_ps, coh_ps, pscands_ij, xy,\n                              lonlat, hgt, ph, ph_patch_org, bperp_meaned, nr_ifgs, nr_ps,\n                              master_date, master_nr, ifg_dates)\n\n    def __get_ij_shift(self, pscands_ij: np.matrix, coh_ps_len: int) -> np.ndarray:\n        ij = np.asarray(pscands_ij[:, 1:3])\n        repmated = np.matlib.repmat(np.array([2, 2]) - ij.min(axis=0), coh_ps_len, 1)\n        ij_shift = ij + repmated\n\n        return ij_shift\n\n    def __init_neighbours(self, ij_shift: np.ndarray, coh_ps_len: int) -> np.ndarray:\n        """"""In StaMPS the init value is zero, I use -1 (DEF_NEIGHBOUR_VAL). Because 0 is correct\n        index value in Python, but not in Matlab. -1 is not index in Python""""""\n\n        def arange_neighbours_select_arr(i, ind):\n            return ArrayUtils.arange_include_last(ij_shift[i, ind] - 2, ij_shift[i, ind])\n\n        def make_miss_middle_mask():\n            miss_middle = np.ones((3, 3), dtype=bool)\n            miss_middle[1, 1] = False\n\n            return miss_middle\n\n        neighbour_ind = np.ones((MatlabUtils.max(ij_shift[:, 0]) + 1,\n                                 MatlabUtils.max(ij_shift[:, 1]) + 1),\n                                self.__IND_ARRAY_TYPE) * self.__DEF_NEIGHBOUR_VAL\n        miss_middle = make_miss_middle_mask()\n\n        for i in range(coh_ps_len):\n            start = arange_neighbours_select_arr(i, 0)\n            end = arange_neighbours_select_arr(i, 1)\n\n            # To get len(start) * len(end) array in Numpy we need to select it like that.\n            # You can use neighbour_ind[start, :][:, end] but then you need to add values some other\n            # way\n            neighbours_val = neighbour_ind[np.ix_(start, end)]\n            neighbours_val[(neighbours_val == self.__DEF_NEIGHBOUR_VAL) & (miss_middle == True)] = i\n\n            neighbour_ind[np.ix_(start, end)] = neighbours_val\n\n        return neighbour_ind\n\n    def __find_neighbours(self, ij_shift: np.ndarray, coh_thresh_ind_len: int,\n                          neighbour_ind: np.ndarray) -> np.ndarray:\n        # List of empty Numpy arrays\n        neighbour_ps = [np.array([], self.__IND_ARRAY_TYPE)] * (coh_thresh_ind_len + 1)\n        for i in range(coh_thresh_ind_len):\n            ind = neighbour_ind[ij_shift[i, 0] - 1, ij_shift[i, 1] - 1]\n            if ind != self.__DEF_NEIGHBOUR_VAL:\n                neighbour_ps[ind] = np.append(neighbour_ps[ind], [i])\n\n        return np.array(neighbour_ps)\n\n    def __select_best(self, neighbour_ps: np.ndarray, coh_thresh_ind_len: int,\n                      coh_ps: np.ndarray, htg: np.ndarray) -> np.ndarray:\n        """"""\n        Returns boolean array what is used to filter other arrays. In StaMPS it is array of int\'s.\n        """"""\n\n        selectable_ps = np.ones(coh_thresh_ind_len, dtype=bool)\n\n        for i in range(coh_thresh_ind_len):\n            ps_ind = neighbour_ps[i]\n            if len(ps_ind) != 0:\n                j = 0\n                while j < len(ps_ind):\n                    ps_i = ps_ind[j]\n                    ps_ind = np.append(ps_ind, neighbour_ps[ps_i]).astype(self.__IND_ARRAY_TYPE)\n                    neighbour_ps[ps_i] = np.array([]) # Empty the read array elements\n                    j += 1\n\n                ps_ind = np.unique(ps_ind)\n                highest_coh_ind = coh_ps[ps_ind].argmax()\n\n                low_coh_ind = np.ones(len(ps_ind), dtype=bool)\n                low_coh_ind[highest_coh_ind] = False\n\n                ps_ind = ps_ind[low_coh_ind]\n                selectable_ps[ps_ind] = False\n\n        self.__logger.debug(""self.__weed_zero_elevation: {0}, len(htg): {1}"".format(\n            self.__weed_zero_elevation, len(htg)))\n        if self.__weed_zero_elevation and len(htg) > 0:\n            self.__logger.debug(""Fiding sea evel"")\n            sea_ind = htg < 1e-6\n            selectable_ps[sea_ind] = False\n\n        return selectable_ps\n\n    def __filter_xy(self, xy: np.ndarray, selectable_ps: np.ndarray, coh_ps: np.ndarray) -> np.ndarray:\n        """"""Find xy array filtered.\n        In StaMPS there is also logic to find if duplicates array is empty and when it is\n        it found weeded_xy array again. Here that kind of logic isn\'t because I didn\'t find point\n        for that""""""\n\n        weeded_xy = xy[selectable_ps] # \'xy_weed\' Stamps\n\n        weed_ind = np.flatnonzero(selectable_ps) # \'ix_weed_num\' in StaMPS\n        unique_rows = np.unique(weeded_xy, return_index=True, axis=0)[1].astype(self.__IND_ARRAY_TYPE)\n        # In Stamps there is also additional transposing but in this case this does not do anything\n        last = np.arange(0, len(weed_ind))\n        # In Stamps this is called \'dps\'. Pixels that have same lon/ lat\n        duplicates = np.setxor1d(unique_rows, last)\n\n        for duplicate in duplicates:\n            weeded_duplicates_ind = np.where((weeded_xy[:, 0] == weeded_xy[duplicate, 0]) &\n                                      ((weeded_xy[:, 1]) == weeded_xy[duplicate, 1])) # \'dups_ix_weed\' in StaMPS\n            duplicates_ind = weed_ind[weeded_duplicates_ind]\n            high_coh_ind = coh_ps[duplicates_ind].argmax()\n            selectable_ps[duplicates_ind != high_coh_ind] = False\n\n        return selectable_ps\n\n    def __drop_noisy(self, data: __DataDTO, selectable_ps: np.ndarray, ifg_ind: np.ndarray,\n                     edges: np.ndarray) -> (np.ndarray, np.ndarray):\n\n        def get_ph_weed(bperp: np.ndarray, k_ps: np.ndarray, ph: np.ndarray, c_ps: np.ndarray,\n                        master_nr: int):\n            exped = np.exp(-1j * (k_ps * bperp.conj().transpose()))\n            ph_weed = np.multiply(ph, exped)\n            ph_weed = np.divide(ph_weed, np.abs(ph_weed))\n            # Adding master noise. It is done when small_baseline_flag != \'y\'. Reshape is needed\n            # because \'c_ps\' is array of array\'s\n            ph_weed[:, (master_nr - 1)] = np.exp(1j * c_ps).reshape(len(ph_weed))\n\n            return ph_weed\n\n        def get_time_deltas_in_days(index: int) -> np.ndarray:\n            """"""For getting days in ints from date object""""""\n            return np.array([(ifg_dates[index] - ifg_dates[x]).days for x in np.nditer(ifg_ind)])\n\n        def get_dph_mean(dph_space, edges_len, weight_factor):\n            repmat = np.matlib.repmat(weight_factor, edges_len, 1)\n            dph_mean = np.sum(np.multiply(dph_space, repmat), axis=1)\n\n            return dph_mean\n\n        ph_filtered = data.ph[selectable_ps]\n        k_ps_filtered = data.k_ps[selectable_ps]\n        c_ps_filtered = data.c_ps[selectable_ps]\n        bperp_meaned = data.bperp_meaned\n        master_nr = data.master_nr\n        ifg_dates = data.ifg_dates\n\n        ph_weed = get_ph_weed(bperp_meaned, k_ps_filtered, ph_filtered, c_ps_filtered, master_nr)\n\n        dph_space = np.multiply(ph_weed[edges[:, 2] - 1], ph_weed[edges[:, 1] - 1].conj())\n        dph_space = dph_space[:, ifg_ind]\n\n        #todo drop_ifg_index logic\n\n        # This all is made when small_baseline_flag != \'y\'\n\n        dph_shape = (len(edges), len(ifg_ind))\n        dph_smooth = np.zeros(dph_shape).astype(np.complex128)\n        dph_smooth2 = np.zeros(dph_shape).astype(np.complex128)\n        for i in range(len(ifg_ind)):\n            time_delta = get_time_deltas_in_days(i)\n            weight_factor = np.exp(-(np.power(time_delta, 2)) / 2 / math.pow(self.__time_win, 2))\n            weight_factor = weight_factor / np.sum(weight_factor)\n\n            dph_mean = get_dph_mean(dph_space, len(edges), weight_factor)\n\n            repmat = np.matlib.repmat(ArrayUtils.to_col_matrix(dph_mean).conj(), 1, len(ifg_ind))\n            dph_mean_adj = np.angle(np.multiply(dph_space, repmat))\n\n            G = np.array([np.ones(len(ifg_ind)), time_delta]).transpose()\n            # \'m\' in Stamps\n            weighted_least_sqrt = MatlabUtils.lscov(G, dph_mean_adj.conj().transpose(),\n                                                    weight_factor)\n            #todo Find better name\n            least_sqrt_G = np.asarray((np.asmatrix(G) * np.asmatrix(weighted_least_sqrt))\n                                      .conj().transpose())\n            dph_mean_adj = np.angle(np.exp(1j * (dph_mean_adj - least_sqrt_G)))\n            # \'m2\' in Stamps\n            weighted_least_sqrt2 = MatlabUtils.lscov(G, dph_mean_adj.conj().transpose(),\n                                                     weight_factor)\n\n            # We don\'t make transpose for weighted_least_sqrt because it doesn\'t\n            # do anything in this case\n            dph_smooth_val_exp = np.exp(1j * (weighted_least_sqrt[0, :] + weighted_least_sqrt2[0, :]))\n            dph_smooth[:, i] = np.multiply(dph_mean, dph_smooth_val_exp)\n            weight_factor[i] = 0 # Let\'s make ourselves as zero\n\n            dph_smooth2[:, i] = get_dph_mean(dph_space, len(edges), weight_factor)\n\n        dph_noise = np.angle(np.multiply(dph_space, dph_smooth2.conj()))\n        ifg_var = np.var(dph_noise, 0)\n\n        dph_noise = np.angle(np.multiply(dph_space, dph_smooth.conj()))\n        K_weights = np.divide(1, ifg_var)\n        K = MatlabUtils.lscov(bperp_meaned, dph_noise.conj().transpose(), K_weights).conj().transpose()\n        dph_noise -= K * bperp_meaned.transpose()\n\n        edge_std = MatlabUtils.std(dph_noise, axis=1)\n        edge_max = np.max(np.abs(dph_noise), axis=1)\n\n        return edge_std, edge_max\n\n    def __get_ps_arrays(self, edge_std: np.ndarray, edge_max: np.ndarray,\n                        selectable_ps_true_count: int, edges: np.ndarray) -> (np.ndarray, np.ndarray):\n        def get_min(ps_array: np.ndarray, edge_array: np.ndarray, edge_ind: np.ndarray, index: int):\n            array = np.array(\n                [ps_array[edge_ind], [edge_array[index], edge_array[index]]]).transpose()\n            return np.min(array, axis=1)\n\n        ps_std = np.full(selectable_ps_true_count, np.inf)\n        ps_max = np.full(selectable_ps_true_count, np.inf)\n        for i in range(len(edges)):\n            edge = edges[i, 1:3] - 1\n            ps_std[edge] = get_min(ps_std, edge_std, edge, i)\n            ps_max[edge] = get_min(ps_max, edge_max, edge, i)\n\n        return ps_std, ps_max\n\n    def __estimate_max_noise(self, ps_std: np.ndarray, ps_max: np.ndarray,\n                             selectable_ps: np.ndarray) -> (np.ndarray, np.ndarray):\n\n        weeded = np.logical_and(ps_std < self.__weed_standard_dev, ps_max < self.__weed_max_noise)\n        selectable_ps[selectable_ps] = weeded\n\n        return selectable_ps, weeded\n\n\n'"
scripts/processes/__init__.py,0,b''
scripts/utils/ArrayUtils.py,8,"b'import numpy as np\n\n\nclass ArrayUtils:\n    @staticmethod\n    def arange_include_last(start: float, end: float, step: float = 1.0):\n        """"""Fixes np.arange function. np.arange function does not guarentee that you have that\n        last element in the end. Using this function you have that.""""""\n\n        # You need to do it like that, otherwise you get return type float64\n        if step == 1.0:\n            aranged = np.arange(start, end)\n        else:\n            aranged = np.arange(start, end, step)\n\n        if len(aranged) == 0 or aranged[len(aranged) - 1] != end:\n            aranged = np.append(aranged, [end])\n\n        return aranged\n\n    @staticmethod\n    def to_col_matrix(array: np.array):\n        """"""Input array is transposed and made to column matrix.\n        There isn\'t check if it is col - or row matrix.""""""\n\n        return array[np.newaxis].transpose()\n\n    @staticmethod\n    def matrix_to_array(matrix: np.matrix) -> np.ndarray:\n        return np.squeeze(np.asarray(matrix))'"
scripts/utils/MatlabUtils.py,30,"b'import scipy.interpolate\nimport scipy.signal\nfrom builtins import staticmethod\n\nimport numpy as np\n\nfrom scripts.utils.ArrayUtils import ArrayUtils\n\n\nclass MatlabUtils:\n    @staticmethod\n    def max(array: np.ndarray):\n        if len(array) > 1:\n            return np.amax(array, axis=0)\n        else:\n            return np.amax(array)\n\n    @staticmethod\n    def min(array: np.ndarray):\n        if len(array) > 1:\n            return np.amin(array, axis=0)\n        else:\n            return np.amin(array)\n\n    @staticmethod\n    def sum(array: np.ndarray):\n        if len(array.shape) > 1:\n            return np.sum(array, axis=0)\n        else:\n            return np.sum(array)\n\n    @staticmethod\n    def gausswin(M: int, alpha=2.5):\n        """"""\n        This function works like Matlab\'s Gaussian function. In SciPy (scipy.signal.gaussian) it\n        originally works bit differently.\n\n        Idea: https://github.com/openworm/open-worm-analysis-toolbox/blob/master/open_worm_analysis_toolbox/utils.py\n        """"""\n\n        N = M - 1\n        n = np.arange(start=0, stop=M) - N / 2\n        w = np.exp(-0.5 * np.power((alpha * n / (N / 2)), 2))\n\n        return w\n\n    @staticmethod\n    def hist(a: np.ndarray, bins: np.ndarray, density=False):\n        """"""Adds np.Inf to the bins end to make Numpy histograms equal to Matlab\'s.\n        Density helps with decimal values in response.""""""\n\n        new_bins = np.r_[-np.Inf, 0.5 * (bins[:-1] + bins[1:]), np.Inf]\n        return np.histogram(a, new_bins, density=density)\n\n    @staticmethod\n    def interp(vector: np.ndarray, interp_factor: int, kind: str = \'cubic\'):\n        vector_len = len(vector)\n\n        arange = np.linspace(0, .1, vector_len)\n        interp_fun = scipy.interpolate.interp1d(arange, vector, kind=kind)\n\n        xnew = np.linspace(0, .1, vector_len * interp_factor)\n        return interp_fun(xnew)\n\n    @staticmethod\n    def std(array: np.ndarray, axis=None):\n        """"""https://stackoverflow.com/questions/27600207/why-does-numpy-std-give-a-different-result-to-matlab-std""""""\n        return np.std(array, axis, ddof=1)\n\n    @staticmethod\n    def polyfit_polyval(x: np.ndarray, y: np.ndarray, deg: int, max_desinty_or_percent_rand: float):\n        """"""\n        Function that works like polyfit and polyval where polyfit returns three values.\n\n        https://stackoverflow.com/questions/45338872/matlab-polyval-function-with-three-outputs-equivalent-in-python-numpy/45339206#45339206\n        """"""\n        mu = np.mean(x)\n        std = MatlabUtils.std(y)\n\n        c_scaled = np.polyfit((x - mu) / std, y, deg)\n        p_scaled = np.poly1d(c_scaled)\n\n        polyval = p_scaled((max_desinty_or_percent_rand - mu) / std)\n\n        return polyval\n\n    @staticmethod\n    def filter2(h, x, mode=\'same\'):\n        """"""https://stackoverflow.com/questions/43270274/equivalent-of-matlab-filter2filter-image-valid-in-python""""""\n        return scipy.signal.convolve2d(x, np.rot90(h, 2), mode)\n\n    @staticmethod\n    def lscov(A: np.ndarray, B: np.ndarray, weights: np.ndarray):\n        """"""Least-squares solution in presence of known covariance\n        https://stackoverflow.com/questions/27128688/how-to-use-least-squares-with-weight-matrix-in-python""""""\n\n        W_col_array = weights[:, np.newaxis]\n        Aw = A * np.sqrt(W_col_array)\n        Bw = B * np.sqrt(weights)[:, np.newaxis]\n\n        return np.linalg.lstsq(Aw, Bw)[0]\n'"
scripts/utils/MatrixUtils.py,5,"b'from builtins import staticmethod\n\nimport numpy as np\n\n\nclass MatrixUtils:\n    @staticmethod\n    def sort_matrix_with_sort_array(matrix: np.matrix, sort_ind: np.ndarray):\n        """"""Numpy does not allow to sort matrixes with lexsort. For that we make view of that is\n        array and sort with sort_ind.\n\n        Source: http://stackoverflow.com/questions/13338110/python-matrix-sorting-via-one-column\n        """"""\n\n        tmp = matrix.view(np.ndarray)\n        return np.asmatrix(tmp[sort_ind])\n\n    @staticmethod\n    def delete_master_col(matrix: np.matrix, master_ind: int):\n        return np.delete(matrix, master_ind - 1, axis=1)\n'"
scripts/utils/__init__.py,0,b''
tests/scripts/__init__.py,0,b''
scripts/utils/internal/ConfigUtils.py,0,"b'from configparser import ConfigParser\nimport os\nfrom pathlib import Path\n\n\nclass ConfigUtils:\n    def __init__(self, resources_path):\n        PROPERTIES_FILE = os.path.join(resources_path, \'properties.ini\')\n\n        self.config = ConfigParser()\n        if not Path(PROPERTIES_FILE).exists():\n            raise FileNotFoundError(""No properties file. Path: "" + PROPERTIES_FILE)\n\n        self.config.read(PROPERTIES_FILE)\n\n    def get_default_section(self, key: str):\n        return self.config[\'DEFAULT\'][key]'"
scripts/utils/internal/FolderConstants.py,0,"b'import os\n\nfrom scripts import RESOURCES_PATH\nfrom scripts.utils.internal.ConfigUtils import ConfigUtils\n\n\nclass FolderConstants:\n    PATCH_FOLDER_NAME = ""PATCH_1""\n\n    __SAVE_PATH = ConfigUtils(RESOURCES_PATH).get_default_section(\'save_load_path\')\n\n    CACHE_PATH = os.path.join(__SAVE_PATH, ""tmp"")'"
scripts/utils/internal/LoggerFactory.py,0,"b""import logging\nimport os\nfrom pathlib import Path\n\n\nclass LoggerFactory(object):\n\n    @staticmethod\n    def create(name: str, log_type = None):\n        LOG_FOLDER_PATH = os.path.join(os.path.dirname(os.path.realpath(__file__)),\n                                       '..', '..', '..', 'log')\n\n        if log_type is None:\n            log_type = 'debug'\n\n        logger = logging.getLogger('logger.%s' % name)\n\n        logger.setLevel(logging.DEBUG)\n\n        if not logger.handlers:\n            if not Path(LOG_FOLDER_PATH).exists():\n                Path(LOG_FOLDER_PATH).mkdir()\n\n            log_file = os.path.join(LOG_FOLDER_PATH, '%s.log' % log_type)\n            file_handler = logging.FileHandler(log_file)\n\n            format = logging.Formatter('%(asctime)s %(levelname)s:%(name)s %(message)s')\n            file_handler.setFormatter(format)\n\n            file_handler.setLevel(logging.DEBUG)\n\n            logger.addHandler(file_handler)\n\n        return logger\n\n"""
scripts/utils/internal/ProcessCache.py,1,"b'import os\n\nimport numpy as np\nfrom numpy.lib.npyio import NpzFile\n\nfrom scripts.utils.internal.FolderConstants import FolderConstants\nfrom scripts.utils.internal.ProcessDataSaver import ProcessDataSaver\n\n# todo Is it possible to make this mode dynamical? Return correct things when there are cached\n# parameters to be returned (callback maybe?)\nclass ProcessCache:\n    @staticmethod\n    def get_from_cache(file_name: str, *params: str) -> NpzFile:\n        save_path = os.path.join(FolderConstants.CACHE_PATH, file_name + "".npz"")\n        loaded = np.load(save_path)\n\n        # Check if it is same file by checking if parameters exist\n        for param in params:\n            if not loaded.files.__contains__(param):\n                raise FileNotFoundError\n\n        return loaded\n\n    @staticmethod\n    def save_to_cache(file_name: str, **cachable):\n        ProcessDataSaver(FolderConstants.CACHE_PATH, file_name).save_data(**cachable)\n'"
scripts/utils/internal/ProcessDataSaver.py,4,"b'from pathlib import Path\nimport numpy as np\n\nfrom scripts.utils.internal.LoggerFactory import LoggerFactory\n\n\nclass ProcessDataSaver:\n    def __init__(self, file_path: str, file_name: str, log_level=""debug""):\n        """"""\n        This creates ""saver"" object instance. Uses np.savez function.\n        To load saved files use np.save.\n\n        :param file_path: Where to save (usually FolderConstants.SAVE_FOLDER)\n        :param file_name: File name (usaually some class variable)\n        :param log_level: Log_level for logger. Default value \'debug\'. If you don\'t want logging in\n            saving then set this to None.\n        """"""\n\n        """"""Loob salvestaja. \'File_path\' on koht kuhu fail salvestatake (tavaliselt\n        FolderConstants.SAVE_FOLDER) ja \'file_name\' on faili nimi (tavaliselt klassimuutja, et\n        oleks lihtsam p\xc3\xa4rast salvestatut laadida).\n\n        Loggeri jaoks, \'log_type\'. Kui logida ei taha pole vaja siis muutuja None\'iks.\n        Tavaline v\xc3\xa4\xc3\xa4rtus sellel on \'debug\'.\n\n        Selleks, et salvestatut laadida kasuta np.load*i. Selle jaoks klassi ei ole.""""""\n\n        def check_param(param):\n            return param is None or param == \'\'\n\n        if check_param(file_path):\n            raise AttributeError(""Check file path"")\n        elif check_param(file_name):\n            raise AttributeError(""Check file name"")\n\n        self.file_path_with_name = Path(file_path, file_name)\n\n        if log_level is not None or log_level != \'\':\n            self.__logger = self.make_logger(file_name)\n            self.__logger.info(""ProcessDataSaver created. File path "" + file_path\n                               + "", file_name "" + file_name)\n\n        if not Path(file_path).exists():\n            Path(file_path).mkdir(parents=True)\n            self.__logger.info(""Folders created"")\n\n    def save_data(self, **data):\n        np.savez(str(self.file_path_with_name.absolute()), **data)\n\n        if self.__logger is not None:\n            self.__logger.debug(data)\n\n    # noinspection PyMethodMayBeStatic\n    def make_logger(self, file_name):\n        logger_name = ""LoggerFactory."" + file_name\n        return LoggerFactory.create(logger_name)\n'"
scripts/utils/internal/ProcessHandler.py,1,"b""import numpy as np\n\nfrom typing import Type\n\nfrom scripts.MetaSubProcess import MetaSubProcess\nfrom scripts.processes.CreateLonLat import CreateLonLat\nfrom scripts.processes.PhaseCorrection import PhaseCorrection\nfrom scripts.processes.PsEstGamma import PsEstGamma\nfrom scripts.processes.PsFiles import PsFiles\nfrom scripts.processes.PsSelect import PsSelect\nfrom scripts.processes.PsWeed import PsWeed\n\n\nclass ProcessHandler:\n    process_obj_dict = {}\n    lonlat = np.array([])\n\n    def __init__(self, path: str, geo_file_path: str, save_load_path: str, rand_dist_cached: bool):\n        self.__path = path\n        self.__geo_file_path = geo_file_path\n        self.__save_load_path = save_load_path\n        self.__rand_dist_cached = rand_dist_cached\n\n    def load_results(self, process: Type[MetaSubProcess]):\n        process_obj = self.__init_process(process)\n        process_obj.load_results(self.__save_load_path)\n        self.__set_process_to_dict(process_obj)\n\n    def start_process(self, process_type: Type[MetaSubProcess]):\n        process_obj = self.__init_process(process_type)\n        process_obj.start_process()\n\n        self.__set_process_to_dict(process_obj)\n\n    def save_process(self, process_type: Type[MetaSubProcess]):\n        process_obj = self.__get_process_from_dict(process_type)\n        process_obj.save_results(self.__save_load_path)\n\n    def __set_process_to_dict(self, process_obj: MetaSubProcess):\n        process_type = type(process_obj)\n\n        if process_type is CreateLonLat:\n            self.process_obj_dict['LonLat'] = process_obj\n        elif process_type is PsFiles:\n            self.process_obj_dict['PsFiles'] = process_obj\n        elif process_type is PsEstGamma:\n            self.process_obj_dict['PsEstGamma'] = process_obj\n        elif process_type is PsSelect:\n            self.process_obj_dict['PsSelect'] = process_obj\n        elif process_type is PsWeed:\n            self.process_obj_dict['PsWeed'] = process_obj\n        elif process_type is PhaseCorrection:\n            self.process_obj_dict['PhaseCorrection'] = process_obj\n\n    def __get_process_from_dict(self, process: Type[MetaSubProcess]) -> MetaSubProcess:\n        if process is CreateLonLat:\n            return self.process_obj_dict['LonLat']\n        elif process is PsFiles:\n            return self.process_obj_dict['PsFiles']\n        elif process is PsEstGamma:\n            return self.process_obj_dict['PsEstGamma']\n        elif process is PsSelect:\n            return self.process_obj_dict['PsSelect']\n        elif process is PsWeed:\n            return self.process_obj_dict['PsWeed']\n        elif process is PhaseCorrection:\n            return self.process_obj_dict['PhaseCorrection']\n\n    def __init_process(self, process: Type[MetaSubProcess]) -> MetaSubProcess:\n        if process is CreateLonLat:\n            return process(self.__path, self.__geo_file_path)\n        elif process is PsFiles:\n            return process(self.__path, self.process_obj_dict['LonLat'])\n        elif process is PsEstGamma:\n            return process(self.process_obj_dict['PsFiles'], self.__rand_dist_cached)\n        elif process is PsSelect:\n            return process(self.process_obj_dict['PsFiles'], self.process_obj_dict['PsEstGamma'])\n        elif process is PsWeed:\n            return process(self.__path, self.process_obj_dict['PsFiles'],\n                           self.process_obj_dict['PsEstGamma'], self.process_obj_dict['PsSelect'])\n        elif process is PhaseCorrection:\n            return process(self.process_obj_dict['PsFiles'], self.process_obj_dict['PsWeed'])"""
scripts/utils/internal/__init__.py,0,"b""import os\n\nLOG_FOLDER_PATH = os.path.join(os.path.dirname(os.path.realpath(__file__)), '..', '..', '..', 'log')"""
tests/scripts/funs/__init__.py,0,b''
tests/scripts/funs/test_psTopofit.py,8,"b""from unittest import TestCase\n\nimport numpy as np\n\nfrom scripts.funs.PsTopofit import PsTopofit\n\n\nclass TestPsTopofit(TestCase):\n    def test_ps_topofit_fun(self):\n        phase = np.array(\n            [-0.976699430122930 - 0.214611796501365j, -0.0247590537401134 + 0.999693447641773j,\n             0.564516193510588 + 0.825421993445968j, -0.959108655003691 - 0.283038138590915j,\n             -0.925244947451622 + 0.379370250830564j])\n        bperp_meaned = np.array(\n            [16.9962832291, 63.4369473318, 21.5419811209, 54.5277511008, -47.8618831925])\n        nr_trial_wraps = 0.0413031180032\n\n        actual_phase_residual, actual_coherence_0, actual_static_offset, actual_k_0 = \\\n            PsTopofit.ps_topofit_fun(phase, bperp_meaned, nr_trial_wraps)\n\n        # V\xc3\xa4\xc3\xa4rtused kopeeritud Matlab'ist\n        expected_phase_residual = np.array([-0.956075301670529 - 0.293121165280857j,\n                                            -0.321975606737151 + 0.946747964701400j,\n                                            0.476734083633067 + 0.879047560432619j,\n                                            -0.853853155561476 - 0.520513965939157j,\n                                            -0.815175873258845 + 0.579213514739323j])\n        expected_coherence_0 = 0.587710117439414\n        expected_static_offset = 2.569312122050138\n        expected_k_0 = -0.004777245862620\n\n        np.testing.assert_array_almost_equal(expected_coherence_0, actual_coherence_0[0])\n        np.testing.assert_array_almost_equal(expected_phase_residual,\n                                             np.squeeze(actual_phase_residual))\n        np.testing.assert_array_almost_equal(expected_static_offset, actual_static_offset)\n        np.testing.assert_array_almost_equal(expected_k_0, actual_k_0[0])\n"""
tests/scripts/processes/__init__.py,0,b''
tests/scripts/processes/test_PsSelect.py,19,"b'import os\n\nimport scipy.io\nimport numpy as np\n\nfrom scripts.processes.CreateLonLat import CreateLonLat\nfrom scripts.processes.PsEstGamma import PsEstGamma\nfrom scripts.processes.PsFiles import PsFiles\nfrom scripts.processes.PsSelect import PsSelect\nfrom scripts.utils.ArrayUtils import ArrayUtils\nfrom tests.MetaTestCase import MetaTestCase\n\n\nclass TestPsSelect(MetaTestCase):\n    _GEO_DATA_FILE_NAME = \'subset_8_of_S1A_IW_SLC__1SDV_20160614T043402_20160614T043429_011702_011EEA_F130_Stack_deb_ifg_Geo.dim\'\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n        lonlat_process = CreateLonLat(cls._PATH, cls._GEO_DATA_FILE_NAME)\n        lonlat_process.load_results(cls._SAVE_LOAD_PATH)\n        cls._ps_files = PsFiles(cls._PATH_PATCH_FOLDER, lonlat_process)\n        cls._ps_files.load_results(cls._SAVE_LOAD_PATH)\n\n        cls._est_gamma_process = None\n\n    def test_start_process_with_matlab_data(self):\n        def get_keep_ix():\n            """"""Used to get keep_ix array to use in Numpy arrys.\n            This conversion is needed because in Numpy there is boolean indexing, but on Matlab\n            there are 1/ 0. For that we make array of boolean using np.where.""""""\n            keep_ix = select1_mat[\'keep_ix\']\n            keep_ix = np.reshape(keep_ix, len(select1_mat[\'keep_ix\']))\n            keep_ix = np.where(keep_ix == 1)\n\n            return keep_ix[0]\n\n        self.__fill_est_gamma_with_matlab_data()\n\n        self.__start_process()\n\n        select1_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, \'select1.mat\'))\n\n        # Matlab indexes begin from zero and Numpy arrays from one.\n        # So we need to add one to Numpy\'s array\n        np.testing.assert_array_almost_equal(np.add(self._ps_select.ifg_ind, 1), select1_mat[\'ifg_index\'][0])\n        # Reshape because Matlab\'s array is col-array\n        np.testing.assert_array_almost_equal(np.add(self._ps_select.coh_thresh_ind, 1),\n                                   select1_mat[\'ix\'].reshape(len(select1_mat[\'ix\'])))\n        np.testing.assert_array_almost_equal(self._ps_select.ph_patch, select1_mat[\'ph_patch2\'],\n                                             decimal=self._PLACES)\n        np.testing.assert_array_almost_equal(self._ps_select.k_ps, select1_mat[\'K_ps2\'])\n        np.testing.assert_array_almost_equal(self._ps_select.ph_res, select1_mat[\'ph_res2\'])\n        np.testing.assert_array_almost_equal(self._ps_select.coh_ps2, select1_mat[\'coh_ps2\'])\n        coh_thresh = select1_mat[\'coh_thresh\']\n        np.testing.assert_array_almost_equal(ArrayUtils.to_col_matrix(self._ps_select.coh_thresh),\n                                             coh_thresh)\n        keep_ix = get_keep_ix()\n        np.testing.assert_array_almost_equal(self._ps_select.keep_ind, keep_ix,\n                                             decimal=self._PLACES)\n\n    def test_save_and_load_results(self):\n        self.__fill_est_gamma_with_matlab_data()\n        self.__start_process()\n        self._ps_select.save_results(self._SAVE_LOAD_PATH)\n\n        ps_select_loaded = PsSelect(self._ps_files, self._est_gamma_process)\n        ps_select_loaded.load_results(self._SAVE_LOAD_PATH)\n\n        np.testing.assert_array_equal(self._ps_select.ifg_ind, ps_select_loaded.ifg_ind)\n        np.testing.assert_array_equal(self._ps_select.coh_thresh_ind, ps_select_loaded.coh_thresh_ind)\n        np.testing.assert_array_equal(self._ps_select.keep_ind, ps_select_loaded.keep_ind)\n        np.testing.assert_array_equal(self._ps_select.ph_patch, ps_select_loaded.ph_patch)\n        np.testing.assert_array_equal(self._ps_select.k_ps, ps_select_loaded.k_ps)\n        np.testing.assert_array_equal(self._ps_select.ph_res, ps_select_loaded.ph_res)\n        np.testing.assert_array_equal(self._ps_select.coh_ps2, ps_select_loaded.coh_ps2)\n        np.testing.assert_array_equal(self._ps_select.coh_thresh, ps_select_loaded.coh_thresh)\n\n    def __start_process(self):\n        self._ps_select = PsSelect(self._ps_files, self._est_gamma_process)\n        self._ps_select.start_process()\n\n    def __fill_est_gamma_with_matlab_data(self):\n        pm1_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, \'pm1.mat\'))\n        self._est_gamma_process = PsEstGamma(self._ps_files, False)\n        self._est_gamma_process.coherence_bins = pm1_mat[\'coh_bins\'][0]\n        self._est_gamma_process.grid_ij = pm1_mat[\'grid_ij\']\n        self._est_gamma_process.nr_trial_wraps = pm1_mat[\'n_trial_wraps\'][0][0]\n        self._est_gamma_process.ph_patch = pm1_mat[\'ph_patch\']\n        self._est_gamma_process.k_ps = pm1_mat[\'K_ps\']\n        self._est_gamma_process.c_ps = pm1_mat[\'C_ps\']\n        self._est_gamma_process.coh_ps = pm1_mat[\'coh_ps\']\n        self._est_gamma_process.n_opt = pm1_mat[\'N_opt\']\n        self._est_gamma_process.ph_res = pm1_mat[\'ph_res\']\n        self._est_gamma_process.ph_grid = pm1_mat[\'ph_grid\']\n        self._est_gamma_process.low_pass = pm1_mat[\'low_pass\']\n        self._est_gamma_process.rand_dist = pm1_mat[\'Nr\'][0]'"
tests/scripts/processes/test_createLonLat.py,0,"b'import os\nimport scipy.io\n\nfrom scripts.processes.CreateLonLat import CreateLonLat\nfrom tests.MetaTestCase import MetaTestCase\n\n\nclass TestCreateLonLat(MetaTestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n        cls._GEO_DATA_FILE = os.path.join(cls._PATH,\n                                           \'subset_8_of_S1A_IW_SLC__1SDV_20160614T043402_20160614T043429_011702_011EEA_F130_Stack_deb_ifg_Geo.dim\')\n\n    def test_start_process(self):\n        process = self.__start_process()\n\n        pscands_actual = process.pscands_ij\n        lonlat_actual = process.lonlat\n\n        lonlat_expected = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, \'lonlat.mat\')).get(\n            \'lonlat\')\n\n        self.assertNotEqual(len(lonlat_actual), 0, ""made lonlat is empty"")\n        self.assertIsNotNone(lonlat_expected, ""lonlat.mat not found (is None)"")\n        self.assertEqual(len(lonlat_expected), len(lonlat_actual),\n                         ""Made lonlat does not equal with .mat file"")\n\n        self.assertIsNotNone(pscands_actual)\n        self.assertEqual(len(pscands_actual), len(lonlat_actual))\n\n        for row_num in range(len(lonlat_actual) - 1):\n            self.assertAlmostEqual(lonlat_expected[row_num, 0], lonlat_actual[row_num, 0],\n                                   self._PLACES)\n            self.assertAlmostEqual(lonlat_expected[row_num, 1], lonlat_actual[row_num, 1],\n                                   self._PLACES)\n\n    def test_save_and_load_results(self):\n        process_save = self.__start_process()\n        process_save.save_results(self._SAVE_LOAD_PATH)\n\n        process_load = CreateLonLat(self._PATH_PATCH_FOLDER, self._GEO_DATA_FILE)\n        process_load.load_results(self._SAVE_LOAD_PATH)\n\n        self.assertIsNotNone(process_load.lonlat)\n        self.assertNotEqual(len(process_load.lonlat), 0, ""lonlat is empty"")\n\n        self.assertIsNotNone(process_load.pscands_ij)\n        self.assertNotEqual(len(process_load.pscands_ij), 0, ""pscands_ij_array is empty"")\n\n    def __start_process(self) -> CreateLonLat:\n        process = CreateLonLat(self._PATH_PATCH_FOLDER, self._GEO_DATA_FILE)\n        process.start_process()\n\n        return process\n'"
tests/scripts/processes/test_phaseCorrection.py,4,"b""from unittest import TestCase\n\nimport os\nimport scipy.io\n\nfrom scripts.processes.CreateLonLat import CreateLonLat\nfrom scripts.processes.PhaseCorrection import PhaseCorrection\nfrom scripts.processes.PsEstGamma import PsEstGamma\nfrom scripts.processes.PsFiles import PsFiles\nfrom scripts.processes.PsSelect import PsSelect\nfrom scripts.processes.PsWeed import PsWeed\nfrom tests.MetaTestCase import MetaTestCase\n\nimport numpy as np\n\n\nclass TestPhaseCorrection(MetaTestCase):\n    _GEO_DATA_FILE_NAME = 'subset_8_of_S1A_IW_SLC__1SDV_20160614T043402_20160614T043429_011702_011EEA_F130_Stack_deb_ifg_Geo.dim'\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n        lonlat_process = CreateLonLat(cls._PATH, cls._GEO_DATA_FILE_NAME)\n        lonlat_process.load_results(cls._SAVE_LOAD_PATH)\n        cls.__ps_files = PsFiles(cls._PATH_PATCH_FOLDER, lonlat_process)\n        cls.__ps_files.load_results(cls._SAVE_LOAD_PATH)\n\n        cls.__ps_est_gamma = PsEstGamma(cls.__ps_files)\n\n        self = TestPhaseCorrection() # This is needed to use variables outside @classmethod\n        self.__fill_est_gamma_with_matlab_data()\n\n        # ps_est_gamma may be None because we load it from ps_select\n        cls.__ps_select = PsSelect(cls.__ps_files, cls.__ps_est_gamma)\n        cls.__ps_select.load_results(cls._SAVE_LOAD_PATH)\n\n        cls.__ps_weed = PsWeed(cls._PATH_PATCH_FOLDER, cls.__ps_files, cls.__ps_est_gamma, cls.__ps_select)\n        cls.__ps_weed.load_results(cls._SAVE_LOAD_PATH)\n\n        cls.__phase_correction = None\n\n    def test_start_process(self):\n        self.__start_process()\n\n        rc_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, 'rc2.mat'))\n\n        np.testing.assert_allclose(self.__phase_correction.ph_rc, rc_mat['ph_rc'], atol=0.05)\n        np.testing.assert_array_almost_equal(self.__phase_correction.ph_reref, rc_mat['ph_reref'])\n\n    def test_save_and_load_results(self):\n        self.__start_process()\n        self.__phase_correction.save_results(self._SAVE_LOAD_PATH)\n\n        phase_correction_loaded = PhaseCorrection(self.__ps_files, self.__ps_weed)\n        phase_correction_loaded.load_results(self._SAVE_LOAD_PATH)\n\n        np.testing.assert_array_almost_equal(self.__phase_correction.ph_rc,\n                                             phase_correction_loaded.ph_rc)\n        np.testing.assert_array_almost_equal(self.__phase_correction.ph_reref,\n                                             phase_correction_loaded.ph_reref)\n\n    def __start_process(self):\n        self.__phase_correction = PhaseCorrection(self.__ps_files, self.__ps_weed)\n        self.__phase_correction.start_process()\n\n    # todo Same as test_psSelect\n    def __fill_est_gamma_with_matlab_data(self):\n        pm1_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, 'pm1.mat'))\n        self.__ps_est_gamma.coherence_bins = pm1_mat['coh_bins'][0]\n        self.__ps_est_gamma.grid_ij = pm1_mat['grid_ij']\n        self.__ps_est_gamma.nr_trial_wraps = pm1_mat['n_trial_wraps']\n        self.__ps_est_gamma.ph_patch = pm1_mat['ph_patch']\n        self.__ps_est_gamma.k_ps = pm1_mat['K_ps']\n        self.__ps_est_gamma.c_ps = pm1_mat['C_ps']\n        self.__ps_est_gamma.coh_ps = pm1_mat['coh_ps']\n        self.__ps_est_gamma.n_opt = pm1_mat['N_opt']\n        self.__ps_est_gamma.ph_res = pm1_mat['ph_res']\n        self.__ps_est_gamma.ph_grid = pm1_mat['ph_grid']\n        self.__ps_est_gamma.low_pass = pm1_mat['low_pass']\n        self.__ps_est_gamma.rand_dist = pm1_mat['Nr'][0]\n"""
tests/scripts/processes/test_psEstGamma.py,36,"b'import os\nimport scipy.io\n\nfrom scripts.processes.CreateLonLat import CreateLonLat\nfrom scripts.processes.PsEstGamma import PsEstGamma\nfrom scripts.processes.PsFiles import PsFiles\nfrom tests.MetaTestCase import MetaTestCase\n\nimport numpy as np\n\n\nclass TestPsEstGamma(MetaTestCase):\n    _TEST_RESOUCES_PATH = \'\'\n\n    _GEO_DATA_FILE_NAME = \'subset_8_of_S1A_IW_SLC__1SDV_20160614T043402_20160614T043429_011702_011EEA_F130_Stack_deb_ifg_Geo.dim\'\n    _PLACES = 5\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n        lonlat_process = CreateLonLat(cls._PATH_PATCH_FOLDER, cls._GEO_DATA_FILE_NAME)\n        lonlat_process.load_results(cls._SAVE_LOAD_PATH)\n        cls.ps_files = PsFiles(cls._PATH_PATCH_FOLDER, lonlat_process)\n        cls.ps_files.load_results(cls._SAVE_LOAD_PATH)\n\n        # We use this in the other tests\n        cls._est_gamma_process = None\n\n    def test_start_process_rand_dist_cached_file(self):\n        self.__start_process()\n\n        self.assertIsNotNone(self._est_gamma_process.grid_ij)\n        self.assertIsNotNone(self._est_gamma_process.coherence_bins)\n\n        pm1_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, \'pm1.mat\'))\n\n        np.testing.assert_array_almost_equal(\n            self._est_gamma_process.coherence_bins,\n            pm1_mat[\'coh_bins\'][0])\n\n        np.testing.assert_array_equal(self._est_gamma_process.grid_ij, pm1_mat[\'grid_ij\'])\n        # math.radians makes we can\'t use default five places after decimal\n        np.testing.assert_array_almost_equal(\n            self._est_gamma_process.nr_trial_wraps, pm1_mat[\'n_trial_wraps\'], 4)\n\n        est_gamma_process_expected = np.load(os.path.join(self._PATH, \'ps_est_gamma_save.npz\'))\n\n        np.testing.assert_array_equal(self._est_gamma_process.ph_patch,\n                                      est_gamma_process_expected[\'ph_patch\'])\n        np.testing.assert_array_equal(self._est_gamma_process.k_ps,\n                                      est_gamma_process_expected[\'k_ps\'])\n        np.testing.assert_array_equal(self._est_gamma_process.c_ps,\n                                      est_gamma_process_expected[\'c_ps\'])\n        np.testing.assert_array_equal(self._est_gamma_process.n_opt,\n                                      est_gamma_process_expected[\'n_opt\'])\n        np.testing.assert_array_equal(self._est_gamma_process.ph_res,\n                                      est_gamma_process_expected[\'ph_res\'])\n        np.testing.assert_array_equal(self._est_gamma_process.ph_grid,\n                                      est_gamma_process_expected[\'ph_grid\'])\n        np.testing.assert_array_equal(self._est_gamma_process.low_pass,\n                                      est_gamma_process_expected[\'low_pass\'])\n\n    def test_start_process_outter_rand_dist(self):\n        """"""In this test we use array of random numbers what is made by StaMPS""""""\n        org_Nr = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, \'org_Nr.mat\'))[\'Nr\'][0]\n\n        self._est_gamma_process = PsEstGamma(self.ps_files, False, org_Nr)\n        self._est_gamma_process.start_process()\n\n        self.assertIsNotNone(self._est_gamma_process.grid_ij)\n        self.assertIsNotNone(self._est_gamma_process.coherence_bins)\n\n        pm1_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, \'pm1.mat\'))\n\n        np.testing.assert_array_almost_equal(\n            self._est_gamma_process.coherence_bins,\n            pm1_mat[\'coh_bins\'][0])\n\n        np.testing.assert_array_equal(self._est_gamma_process.grid_ij, pm1_mat[\'grid_ij\'])\n        # Because we use math.radians not exact value it doesn\'t match as well\n        np.testing.assert_array_almost_equal(\n            self._est_gamma_process.nr_trial_wraps, pm1_mat[\'n_trial_wraps\'], 4)\n\n        np.testing.assert_allclose(self._est_gamma_process.rand_dist, pm1_mat[\'Nr\'][0], atol=1.8)\n        # np.testing.assert_allclose(self._est_gamma_process.rand_dist, nr, atol=2)\n        np.testing.assert_allclose(self._est_gamma_process.ph_patch, pm1_mat[\'ph_patch\'],\n                                   rtol=0.2, atol=0.4)\n        np.testing.assert_allclose(self._est_gamma_process.k_ps, pm1_mat[\'K_ps\'], atol=0.1)\n        np.testing.assert_allclose(self._est_gamma_process.c_ps, pm1_mat[\'C_ps\'], rtol=1, atol=3.15)\n        np.testing.assert_allclose(self._est_gamma_process.coh_ps, pm1_mat[\'coh_ps\'], atol=0.7)\n        np.testing.assert_allclose(self._est_gamma_process.n_opt, pm1_mat[\'N_opt\'])\n        np.testing.assert_allclose(self._est_gamma_process.ph_res, pm1_mat[\'ph_res\'],\n                                   rtol=1, atol=3.15)\n        np.testing.assert_allclose(self._est_gamma_process.ph_grid, pm1_mat[\'ph_grid\'],\n                                   rtol=0.2, atol=0.4)\n        np.testing.assert_allclose(self._est_gamma_process.low_pass, pm1_mat[\'low_pass\'])\n\n    def test_save_and_load_results(self):\n        self.__start_process()\n\n        self._est_gamma_process.save_results(self._SAVE_LOAD_PATH)\n\n        # New object where to put saved files\n        est_gamma_loaded = PsEstGamma(self.ps_files)\n        est_gamma_loaded.load_results(self._SAVE_LOAD_PATH)\n\n        np.testing.assert_array_equal(self._est_gamma_process.ph_patch, est_gamma_loaded.ph_patch)\n        np.testing.assert_array_equal(self._est_gamma_process.k_ps, est_gamma_loaded.k_ps)\n        np.testing.assert_array_equal(self._est_gamma_process.c_ps, est_gamma_loaded.c_ps)\n        np.testing.assert_array_equal(self._est_gamma_process.n_opt, est_gamma_loaded.n_opt)\n        np.testing.assert_array_equal(self._est_gamma_process.ph_res, est_gamma_loaded.ph_res)\n        np.testing.assert_array_equal(self._est_gamma_process.ph_grid, est_gamma_loaded.ph_grid)\n        np.testing.assert_array_equal(self._est_gamma_process.low_pass, est_gamma_loaded.low_pass)\n        np.testing.assert_array_equal(self._est_gamma_process.coherence_bins, est_gamma_loaded.coherence_bins)\n        np.testing.assert_array_equal(self._est_gamma_process.nr_trial_wraps, est_gamma_loaded.nr_trial_wraps)\n        np.testing.assert_array_equal(self._est_gamma_process.rand_dist, est_gamma_loaded.rand_dist)\n        np.testing.assert_array_equal(self._est_gamma_process.grid_ij, est_gamma_loaded.grid_ij)\n        np.testing.assert_array_equal(self._est_gamma_process.coh_ps, est_gamma_loaded.coh_ps)\n\n    def __start_process(self):\n        self._est_gamma_process = PsEstGamma(self.ps_files, True)\n        self._est_gamma_process.start_process()\n'"
tests/scripts/processes/test_psFiles.py,23,"b'import os\nimport scipy.io\nimport h5py\nimport numpy as np\nfrom datetime import date\n\nfrom scripts.processes.CreateLonLat import CreateLonLat\nfrom scripts.processes.PsFiles import PsFiles\nfrom scripts.utils.ArrayUtils import ArrayUtils\nfrom tests.MetaTestCase import MetaTestCase\n\n\nclass TestPsFiles(MetaTestCase):\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n        cls._GEO_DATA_FILE = os.path.join(cls._PATH_PATCH_FOLDER,\n                                           \'subset_8_of_S1A_IW_SLC__1SDV_20160614T043402_20160614T043429_011702_011EEA_F130_Stack_deb_ifg_Geo.dim\')\n\n        cls.lonlat_process = CreateLonLat(cls._PATH_PATCH_FOLDER, cls._GEO_DATA_FILE)\n        cls.lonlat = cls.lonlat_process.load_results(cls._SAVE_LOAD_PATH)\n\n        cls._ps_files = None\n\n    def test_load_files(self):\n        self.__start_process()\n\n        ps1_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, \'ps1.mat\'))\n        # These are saved using Matlab 7.3\n        ph1 = self.__load_mat73(os.path.join(self._PATCH_1_FOLDER, \'ph1.mat\'), \'ph\')\n        bp1 = self.__load_mat73(os.path.join(self._PATCH_1_FOLDER, \'bp1.mat\'), \'bperp_mat\')\n        da1 = self.__load_mat73(os.path.join(self._PATCH_1_FOLDER, \'da1.mat\'), \'D_A\')\n        la1 = self.__load_mat73(os.path.join(self._PATCH_1_FOLDER, \'la1.mat\'), \'la\')\n        hgt1 = self.__load_mat73(os.path.join(self._PATCH_1_FOLDER, \'hgt1.mat\'), \'hgt\')\n\n        self.assertEqual(len(self._ps_files.bperp), len(bp1))\n        np.testing.assert_allclose(self._ps_files.bperp, bp1)\n\n        self.assertEqual(len(self._ps_files.da), len(da1))\n        # Loadmat results are array of arrays\n        np.testing.assert_allclose(np.reshape(self._ps_files.da, (len(self._ps_files.da), 1)), da1)\n\n        ps1_mat_bperp = np.reshape(ps1_mat[\'bperp\'], len(ps1_mat[\'bperp\']))\n        np.testing.assert_allclose(self._ps_files.bperp_meaned, ps1_mat_bperp)\n        np.testing.assert_allclose(self._ps_files.pscands_ij.view(np.ndarray), ps1_mat[\'ij\'])\n        # In our process there isn\'t first column. That\'s why we take last two\n        np.testing.assert_allclose(self._ps_files.xy, ps1_mat[\'xy\'][:, 1:])\n\n        self.assertAlmostEqual(self._ps_files.mean_range, ps1_mat[\'mean_range\'])\n\n        np.testing.assert_allclose(self._ps_files.mean_incidence.view(np.ndarray),\n                                   ps1_mat[\'mean_incidence\'])\n\n        np.testing.assert_allclose(self._ps_files.ll, ps1_mat[\'ll0\'])\n\n        np.testing.assert_allclose(self._ps_files.lonlat, ps1_mat[\'lonlat\'])\n\n        # Because those values aren\'t added to .mat files so we can only check if these are filled\n        self.assertNotEqual(self._ps_files.wavelength, 0)\n        self.assertIsNotNone(self._ps_files.heading)\n\n        master_date_days = date.toordinal(self._ps_files.master_date) + 366\n        self.assertEqual(master_date_days, ps1_mat[\'master_day\'][0])\n        self.assertEqual(self._ps_files.master_nr, ps1_mat[\'master_ix\'])\n\n        ifg_date_days = ArrayUtils.to_col_matrix(\n            np.array([date.toordinal(x) + 366 for x in self._ps_files.ifg_dates]))\n        np.testing.assert_array_equal(ifg_date_days, ps1_mat[\'day\'])\n\n        np.testing.assert_allclose(self._ps_files.sort_ind.view(np.ndarray), la1)\n\n        self.assertEqual(len(self._ps_files.ifgs), ps1_mat[\'n_ifg\'])\n\n        self.assertEqual(len(self._ps_files.pscands_ij), ps1_mat[\'n_ps\'])\n\n        # hgt1 is array of arrays, need to reshape\n        np.testing.assert_allclose(self._ps_files.hgt, np.reshape(hgt1, len(hgt1)))\n\n        self.assertEqual(len(self._ps_files.ph), len(ph1))\n        self.assert_ph(self._ps_files.ph, ph1)\n\n    def assert_ph(self, ph_actual, ph_expected):\n        """"""Those Matlab complex digits aren\'t defined same way as Numpy\'s. That\'s why we can\'t\n        compare two arrays the same way""""""\n        for row_num in range(len(ph_expected) - 1):\n            row_actual = ph_actual[row_num]\n            row_expected = ph_expected[row_num]\n            for col_num in range(len(row_actual) - 1):\n                self.assertAlmostEqual(row_actual[col_num].real, row_expected[col_num][\'real\'],\n                                       self._PLACES,\n                                       ""Error real row "" + str(row_num) + "" col "" + str(col_num))\n                self.assertAlmostEqual(row_actual[col_num].imag, row_expected[col_num][\'imag\'],\n                                       self._PLACES,\n                                       ""Error imag row "" + str(row_num) + "" col "" + str(col_num))\n\n    def __load_mat73(self, path_with_file_name: str, dataset: str):\n        with h5py.File(path_with_file_name) as hdf5_file:\n            return hdf5_file[dataset][:].conjugate().transpose()\n\n    def test_save_and_load_results(self):\n        self.__start_process()\n        self._ps_files.save_results(self._SAVE_LOAD_PATH)\n\n        ps_files_load = PsFiles(self._PATH_PATCH_FOLDER, self.lonlat_process)\n        ps_files_load.load_results(self._SAVE_LOAD_PATH)\n\n        self.assertIsNotNone(ps_files_load.heading)\n        self.assertEquals(ps_files_load.mean_range, self._ps_files.mean_range)\n        self.assertEquals(ps_files_load.wavelength, self._ps_files.wavelength)\n        self.assertEquals(ps_files_load.mean_incidence, self._ps_files.mean_incidence)\n        self.assertEquals(ps_files_load.master_nr, self._ps_files.master_nr)\n        np.testing.assert_array_equal(ps_files_load.bperp_meaned, self._ps_files.bperp_meaned)\n        np.testing.assert_array_equal(ps_files_load.bperp, self._ps_files.bperp)\n        np.testing.assert_array_equal(ps_files_load.ph, self._ps_files.ph)\n        np.testing.assert_array_equal(ps_files_load.ll, self._ps_files.ll)\n        np.testing.assert_array_equal(ps_files_load.xy, self._ps_files.xy)\n        np.testing.assert_array_equal(ps_files_load.da, self._ps_files.da)\n        np.testing.assert_array_equal(ps_files_load.sort_ind, self._ps_files.sort_ind)\n        self.assertEquals(ps_files_load.master_date, self._ps_files.master_date)\n        np.testing.assert_array_equal(ps_files_load.ifgs, self._ps_files.ifgs)\n        np.testing.assert_array_equal(ps_files_load.hgt, self._ps_files.hgt)\n        np.testing.assert_array_equal(ps_files_load.ifg_dates, self._ps_files.ifg_dates)\n\n    def __start_process(self):\n        self._ps_files = PsFiles(self._PATH_PATCH_FOLDER, self.lonlat_process)\n        self._ps_files.start_process()\n'"
tests/scripts/processes/test_psWeed.py,25,"b""import os\n\nimport scipy.io\nimport numpy as np\n\nfrom scripts.processes.CreateLonLat import CreateLonLat\nfrom scripts.processes.PsEstGamma import PsEstGamma\nfrom scripts.processes.PsFiles import PsFiles\nfrom scripts.processes.PsSelect import PsSelect\nfrom scripts.processes.PsWeed import PsWeed\nfrom tests.MetaTestCase import MetaTestCase\n\n\nclass TestPsWeed(MetaTestCase):\n    _GEO_DATA_FILE_NAME = 'subset_8_of_S1A_IW_SLC__1SDV_20160614T043402_20160614T043429_011702_011EEA_F130_Stack_deb_ifg_Geo.dim'\n\n    # noinspection PyUnresolvedReferences\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n        lonlat_process = CreateLonLat(cls._PATH, cls._GEO_DATA_FILE_NAME)\n        lonlat_process.load_results(cls._SAVE_LOAD_PATH)\n        cls.__ps_files = PsFiles(cls._PATH_PATCH_FOLDER, lonlat_process)\n        cls.__ps_files.load_results(cls._SAVE_LOAD_PATH)\n\n        cls.__est_gamma_process: PsEstGamma = None\n\n        # ps_est_gamma may be None because we load it from ps_select\n        cls.__ps_select = PsSelect(cls.__ps_files, cls.__est_gamma_process)\n        cls.__ps_select.load_results(cls._SAVE_LOAD_PATH)\n\n        cls.__ps_weed_process = None\n\n    def test_start_process_with_matlab_data(self):\n        def bool_to_int_array(bool_array: np.ndarray):\n            return np.where(bool_array == 1)[0]\n\n        self.__fill_est_gamma_with_matlab_data()\n        self.__start_process()\n\n        weed_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, 'weed1.mat'))\n\n        np.testing.assert_array_almost_equal(np.where(self.__ps_weed_process.selectable_ps)[0],\n                                             bool_to_int_array(weed_mat['ix_weed']))\n        np.testing.assert_array_almost_equal(np.where(self.__ps_weed_process.selectable_ps2)[0],\n                                             bool_to_int_array(weed_mat['ix_weed2']))\n\n        # Because 'drop_noisy' result 'weighted_least_sqrt2' differs a bit than in Snap so those\n        # arrays are also different and needs to checked like this. But this error does not go\n        # further to selectable_ps and selectable_ps2\n        PS_RTOL = 0.28\n        PS_ATOL = 0.055\n        np.testing.assert_allclose(self.__ps_weed_process.ps_std, np.squeeze(weed_mat['ps_std']),\n                                   PS_RTOL, PS_ATOL)\n        np.testing.assert_allclose(self.__ps_weed_process.ps_max, np.squeeze(weed_mat['ps_max']),\n                                   PS_RTOL, PS_ATOL)\n\n        np.testing.assert_array_almost_equal(np.add(self.__ps_weed_process.ifg_ind, 1),\n                                             np.reshape(weed_mat['ifg_index'], len(self.__ps_weed_process.ifg_ind)))\n\n    def test_save_and_load_results(self):\n        self.__fill_est_gamma_with_matlab_data()\n        self.__start_process()\n\n        self.__ps_weed_process.save_results(self._SAVE_LOAD_PATH)\n\n        ps_weed_loaded = PsWeed(self._PATH, self.__ps_files, self.__est_gamma_process, self.__ps_select)\n\n        ps_weed_loaded.load_results(self._SAVE_LOAD_PATH)\n\n        np.testing.assert_array_equal(self.__ps_weed_process.selectable_ps, ps_weed_loaded.selectable_ps)\n        np.testing.assert_array_equal(self.__ps_weed_process.selectable_ps2, ps_weed_loaded.selectable_ps2)\n        np.testing.assert_array_equal(self.__ps_weed_process.ps_std, ps_weed_loaded.ps_std)\n        np.testing.assert_array_equal(self.__ps_weed_process.ps_max, ps_weed_loaded.ps_max)\n        np.testing.assert_array_equal(self.__ps_weed_process.ifg_ind, ps_weed_loaded.ifg_ind)\n\n    def test_get_filtered_results(self):\n        self.__fill_est_gamma_with_matlab_data()\n        self.__ps_weed_process = PsWeed(self._PATH_PATCH_FOLDER, self.__ps_files,\n                                        self.__est_gamma_process, self.__ps_select)\n        coh_ps, k_ps, c_ps, ph_patch, ph, xy, pscands_ij, lonlat, hgt, bperp, sort_ind =\\\n            self.__ps_weed_process.get_filtered_results(self._SAVE_LOAD_PATH)\n\n        pm_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, 'pm2.mat'))\n\n        np.testing.assert_array_almost_equal(coh_ps, pm_mat['coh_ps'])\n        np.testing.assert_array_almost_equal(k_ps, pm_mat['K_ps'])\n        np.testing.assert_array_almost_equal(c_ps, pm_mat['C_ps'])\n        np.testing.assert_array_almost_equal(ph_patch, pm_mat['ph_patch'])\n\n        ph_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, 'ph2.mat'))\n\n        np.testing.assert_array_almost_equal(ph, ph_mat['ph'])\n\n        ps = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, 'ps2.mat'))\n\n        # Just like PsFiles test we check only last two columns\n        np.testing.assert_array_almost_equal(xy, ps['xy'][:, 1:])\n        np.testing.assert_array_almost_equal(pscands_ij, ps['ij'])\n        np.testing.assert_array_almost_equal(lonlat.view(np.ndarray), ps['lonlat'], self._PLACES)\n        np.testing.assert_array_almost_equal(len(ph), ps['n_ps'][0])\n\n        hgt_mat= scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, 'hgt2.mat'))\n        np.testing.assert_array_almost_equal(hgt, np.reshape(hgt_mat['hgt'], len(hgt)))\n\n        bp_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, 'bp2.mat'))\n\n        np.testing.assert_array_almost_equal(bperp, bp_mat['bperp_mat'], self._PLACES)\n\n        la_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, 'la2.mat'))\n\n        np.testing.assert_array_almost_equal(sort_ind, la_mat['la'])\n\n    def __start_process(self):\n        self.__ps_weed_process = PsWeed(self._PATH_PATCH_FOLDER, self.__ps_files, self.__est_gamma_process, self.__ps_select)\n        self.__ps_weed_process.start_process()\n\n    # todo Sama as in PsSelect\n    def __fill_est_gamma_with_matlab_data(self):\n        pm1_mat = scipy.io.loadmat(os.path.join(self._PATCH_1_FOLDER, 'pm1.mat'))\n        self.__est_gamma_process = PsEstGamma(self.__ps_files, False)\n        self.__est_gamma_process.coherence_bins = pm1_mat['coh_bins'][0]\n        self.__est_gamma_process.grid_ij = pm1_mat['grid_ij']\n        self.__est_gamma_process.nr_trial_wraps = pm1_mat['n_trial_wraps']\n        self.__est_gamma_process.ph_patch = pm1_mat['ph_patch']\n        self.__est_gamma_process.k_ps = pm1_mat['K_ps']\n        self.__est_gamma_process.c_ps = pm1_mat['C_ps']\n        self.__est_gamma_process.coh_ps = pm1_mat['coh_ps']\n        self.__est_gamma_process.n_opt = pm1_mat['N_opt']\n        self.__est_gamma_process.ph_res = pm1_mat['ph_res']\n        self.__est_gamma_process.ph_grid = pm1_mat['ph_grid']\n        self.__est_gamma_process.low_pass = pm1_mat['low_pass']\n        self.__est_gamma_process.rand_dist = pm1_mat['Nr'][0]"""
tests/scripts/utils/__init__.py,0,b''
tests/scripts/utils/test_matlabUtils.py,5,"b'import numpy as np\n\nfrom unittest import TestCase\n\nfrom scripts.utils.MatlabUtils import MatlabUtils\n\n\nclass TestMatlabUtils(TestCase):\n    __multi_row_array = np.array([[1, 2, 3], [4, 5, 6]])\n    __single_row_array = np.array([1, 2, 3])\n\n    def test_max_multi(self):\n        np.testing.assert_array_equal(MatlabUtils.max(self.__multi_row_array), np.array([4, 5, 6]))\n\n    def test_max_single(self):\n        self.assertEqual(MatlabUtils.max(self.__single_row_array), 3)\n\n    def test_min_multi(self):\n        np.testing.assert_array_equal(MatlabUtils.min(self.__multi_row_array), np.array([1, 2, 3]))\n\n    def test_min_single(self):\n        self.assertEqual(MatlabUtils.min(self.__single_row_array), 1)\n\n    def test_sum_multi(self):\n        np.testing.assert_array_equal(MatlabUtils.sum(self.__multi_row_array), np.array([5, 7, 9]))\n\n    def test_sum_single(self):\n        self.assertEqual(MatlabUtils.sum(self.__single_row_array), 6)\n'"
