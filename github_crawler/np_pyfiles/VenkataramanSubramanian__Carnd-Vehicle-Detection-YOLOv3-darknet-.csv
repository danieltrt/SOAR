file_path,api_count,code
abstract.py,0,"b'from darknet import *\nfrom moviepy.editor import VideoFileClip\nimport sys\n\n#Video launch code\nyellow_output = sys.argv[2]\nclip2 = VideoFileClip(sys.argv[1])\nyellow_clip = clip2.fl_image(detect)\nyellow_clip.write_videofile(yellow_output, audio=False)'"
darknet.py,12,"b'from ctypes import *\nimport math\nimport random\nimport cv2\nimport time\nfrom PIL import Image\nfrom moviepy.editor import VideoFileClip\nimport os\nimport numpy as np\n\ncolour_dct={0:\'STOP\',1:\'GO\'}\ncolor = { \'person\':(255,0,0), \'car\':(255,255,0), \'bicycle\':(0,255,0),\'truck\':(0,0,255),\'bus\':(0,255,255),\'motorbike\':(255,0,0),\'traffic light\':(128,128,128)}\n\ndef sample(probs):\n    s = sum(probs)\n    probs = [a/s for a in probs]\n    r = random.uniform(0, 1)\n    for i in range(len(probs)):\n        r = r - probs[i]\n        if r <= 0:\n            return i\n    return len(probs)-1\n\ndef c_array(ctype, values):\n    arr = (ctype*len(values))()\n    arr[:] = values\n    return arr\n\nclass BOX(Structure):\n    _fields_ = [(""x"", c_float),\n                (""y"", c_float),\n                (""w"", c_float),\n                (""h"", c_float)]\n\nclass DETECTION(Structure):\n    _fields_ = [(""bbox"", BOX),\n                (""classes"", c_int),\n                (""prob"", POINTER(c_float)),\n                (""mask"", POINTER(c_float)),\n                (""objectness"", c_float),\n                (""sort_class"", c_int)]\n\n\nclass IMAGE(Structure):\n    _fields_ = [(""w"", c_int),\n                (""h"", c_int),\n                (""c"", c_int),\n                (""data"", POINTER(c_float))]\n\nclass METADATA(Structure):\n    _fields_ = [(""classes"", c_int),\n                (""names"", POINTER(c_char_p))]\n\n    \npath=os.getcwd()\nlib = CDLL(path+""/libdarknet.so"", RTLD_GLOBAL)\nlib.network_width.argtypes = [c_void_p]\nlib.network_width.restype = c_int\nlib.network_height.argtypes = [c_void_p]\nlib.network_height.restype = c_int\n\npredict = lib.network_predict\npredict.argtypes = [c_void_p, POINTER(c_float)]\npredict.restype = POINTER(c_float)\n\nset_gpu = lib.cuda_set_device\nset_gpu.argtypes = [c_int]\n\nmake_image = lib.make_image\nmake_image.argtypes = [c_int, c_int, c_int]\nmake_image.restype = IMAGE\n\nget_network_boxes = lib.get_network_boxes\nget_network_boxes.argtypes = [c_void_p, c_int, c_int, c_float, c_float, POINTER(c_int), c_int, POINTER(c_int)]\nget_network_boxes.restype = POINTER(DETECTION)\n\nmake_network_boxes = lib.make_network_boxes\nmake_network_boxes.argtypes = [c_void_p]\nmake_network_boxes.restype = POINTER(DETECTION)\n\nfree_detections = lib.free_detections\nfree_detections.argtypes = [POINTER(DETECTION), c_int]\n\nfree_ptrs = lib.free_ptrs\nfree_ptrs.argtypes = [POINTER(c_void_p), c_int]\n\nnetwork_predict = lib.network_predict\nnetwork_predict.argtypes = [c_void_p, POINTER(c_float)]\n\nreset_rnn = lib.reset_rnn\nreset_rnn.argtypes = [c_void_p]\n\nload_net = lib.load_network\nload_net.argtypes = [c_char_p, c_char_p, c_int]\nload_net.restype = c_void_p\n\ndo_nms_obj = lib.do_nms_obj\ndo_nms_obj.argtypes = [POINTER(DETECTION), c_int, c_int, c_float]\n\ndo_nms_sort = lib.do_nms_sort\ndo_nms_sort.argtypes = [POINTER(DETECTION), c_int, c_int, c_float]\n\nfree_image = lib.free_image\nfree_image.argtypes = [IMAGE]\n\nletterbox_image = lib.letterbox_image\nletterbox_image.argtypes = [IMAGE, c_int, c_int]\nletterbox_image.restype = IMAGE\n\nload_meta = lib.get_metadata\nlib.get_metadata.argtypes = [c_char_p]\nlib.get_metadata.restype = METADATA\n\nload_image = lib.load_image_color\nload_image.argtypes = [c_char_p, c_int, c_int]\nload_image.restype = IMAGE\n\nndarray_image = lib.ndarray_to_image\nndarray_image.argtypes = [POINTER(c_ubyte), POINTER(c_long), POINTER(c_long)]\nndarray_image.restype = IMAGE\n\nrgbgr_image = lib.rgbgr_image\nrgbgr_image.argtypes = [IMAGE]\n\npredict_image = lib.network_predict_image\npredict_image.argtypes = [c_void_p, IMAGE]\npredict_image.restype = POINTER(c_float)\n\ndef classify(net, meta, im):\n    out = predict_image(net, im)\n    res = []\n    for i in range(meta.classes):\n        res.append((meta.names[i], out[i]))\n    res = sorted(res, key=lambda x: -x[1])\n    return res\n\ndef traffic_light(traf_img):\n    \n    img_hsv=cv2.cvtColor(traf_img, cv2.COLOR_BGR2HSV)\n  \n    #Finding the low saturation value based on image \n    sum_saturation = np.sum(img_hsv[:,:,1]) \n    area = traf_img.shape[0]*traf_img.shape[1]\n    sat_low = int(sum_saturation / area * 1.3)\n      \n    #Getting the red pixels in an image using red mask\n    lower_red = np.array([150,sat_low,140])\n    upper_red = np.array([180,255,255])\n    mask_red = cv2.inRange(img_hsv, lower_red, upper_red)\n    \n    mask_red = mask_red\n    \n    #Getting the yellow pixels in an image using red mask\n    lower_yellow = np.array([10,sat_low,140])\n    upper_yellow = np.array([20,255,255])\n    mask_yel = cv2.inRange(img_hsv, lower_yellow, upper_yellow)\n\n    mask_yellow = mask_yel\n    \n    mask_stop=mask_red+mask_yellow\n\n    output_hsv_stop = img_hsv.copy()\n    output_hsv_stop[np.where(mask_stop==0)] = 0\n    \n\n    #Getting the green pixels in an image using red mask\n    lower_green = np.array([30,sat_low,140])\n    upper_green = np.array([80,255,255])\n    mask_green = cv2.inRange(img_hsv, lower_green, upper_green)\n\n    mask_green = mask_green\n\n    output_hsv_go = img_hsv.copy()\n    output_hsv_go[np.where(mask_green==0)] = 0\n\n    #Getting the output colour of the traffic light\n    value_stop=np.count_nonzero(output_hsv_stop)\n    value_go=np.count_nonzero(output_hsv_go)\n    value=np.argmax([value_stop,value_go])\n\n    return colour_dct[value]\n    \ndef detect(image, thresh=.51, hier_thresh=.5, nms=.45):\n    data = image.ctypes.data_as(POINTER(c_ubyte))\n    im = ndarray_image(data, image.ctypes.shape, image.ctypes.strides)\n    \n    num = c_int(0)\n    pnum = pointer(num)\n    predict_image(net, im)\n    dets = get_network_boxes(net, im.w, im.h, thresh, hier_thresh, None, 0, pnum)\n    num = pnum[0]\n    if (nms): do_nms_obj(dets, num, meta.classes, nms);\n    res = []\n    for j in range(num):\n        for i in range(meta.classes):\n            if dets[j].prob[i] > 0:\n                b = dets[j].bbox\n                res.append((meta.names[i], dets[j].prob[i], (b.x, b.y, b.w, b.h)))\n    res = sorted(res, key=lambda x: -x[1])\n\n    traffic_img=image.copy()\n    for i in res:\n        detection=i[0].decode(\'utf-8\')\n        if(detection in (\'person\',\'bicycle\',\'car\',\'truck\',\'bus\',\'motorbike\',\'traffic light\')):\n           color_local = color[detection]\n           upper = (int(i[2][0]-i[2][2]/2),int(i[2][1]-i[2][3]/2))\n           lower = (int(i[2][0]+i[2][2]/2),int(i[2][1]+i[2][3]/2))\n           cv2.rectangle(image, upper, lower , color_local, thickness = 4)\n           cv2.rectangle(image, (int(i[2][0]-i[2][2]/2),int(i[2][1]-i[2][3]/2-20)), \n                                (int(i[2][0]-i[2][2]/2 + 120),int(i[2][1]-i[2][3]/2)), color_local, thickness = -1)\n\n           if(detection==\'traffic light\'):\n              traf_img=traffic_img[int(i[2][1]-i[2][3]/2):int(i[2][1]+i[2][3]/2), int(i[2][0]-i[2][2]/2):int(i[2][0]+i[2][2]/2)]\n              try:\n                 colour= traffic_light(traf_img)                 \n              except:\n                 continue\n              cv2.putText(image, \'{0}\'.format(colour),(int(i[2][0]-i[2][2]/2), \n                       int(i[2][1]-i[2][3]/2)  -6),cv2.FONT_HERSHEY_SIMPLEX,0.6, (0, 0, 0),1,cv2.LINE_AA)\n           else:        \n              cv2.putText(image, \'{0}\'.format(i[0].decode(\'utf-8\')),(int(i[2][0]-i[2][2]/2), \n                       int(i[2][1]-i[2][3]/2)  -6),cv2.FONT_HERSHEY_SIMPLEX,0.6, (0, 0, 0),1,cv2.LINE_AA)              \n     \n\n    free_image(im) \n    free_detections(dets, num)\n    return image\n    \n\n\t\nnet = load_net(b""cfg/yolov3.cfg"",b""yolov3.weights"", 0)\nmeta = load_meta(b""cfg/coco.data"")\n\n\n\n    \n    \n\n'"
