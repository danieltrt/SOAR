file_path,api_count,code
setup.py,0,"b'from __future__ import print_function\n\nimport os\nimport sys\nimport warnings\nfrom setuptools import setup, extension\nfrom setuptools.command.build_ext import build_ext\nfrom setuptools.command.test import test as TestCommand\n\nsetup_kwargs = {}\n\n\ndef error(*lines):\n    for line in lines:\n        print(line, file=sys.stderr)\n\n\ntry:\n    from stl import stl\n    if not hasattr(stl, \'BaseStl\'):\n        error(\'ERROR\',\n              \'You have an incompatible stl package installed\'\n              \'Please run ""pip uninstall -y stl"" first\')\n        sys.exit(1)\nexcept ImportError:\n    pass\n\n\nclass PyTest(TestCommand):\n    def finalize_options(self):\n        TestCommand.finalize_options(self)\n        self.test_args = []\n        self.test_suite = True\n\n    def run_tests(self):\n        # import here, cause outside the eggs aren\'t loaded\n        import pytest\n        errno = pytest.main(self.test_args)\n        sys.exit(errno)\n\n\nif sys.version_info.major == 2 or sys.platform.lower() != \'win32\':\n    try:\n        import numpy\n        from Cython import Build\n\n        setup_kwargs[\'ext_modules\'] = Build.cythonize([\n            extension.Extension(\n                \'stl._speedups\',\n                [\'stl/_speedups.pyx\'],\n                include_dirs=[numpy.get_include()],\n            ),\n        ])\n    except ImportError:\n        error(\'WARNING\',\n              \'Cython and Numpy is required for building extension.\',\n              \'Falling back to pure Python implementation.\')\n\n# To prevent importing about and thereby breaking the coverage info we use this\n# exec hack\nabout = {}\nwith open(\'stl/__about__.py\') as fh:\n    exec(fh.read(), about)\n\n\nif os.path.isfile(\'README.rst\'):\n    with open(\'README.rst\') as fh:\n        long_description = fh.read()\nelse:\n    long_description = \'See http://pypi.python.org/pypi/%s/\' % (\n        about[\'__package_name__\'])\n\ninstall_requires = [\n    \'numpy\',\n    \'python-utils>=1.6.2\',\n]\n\ntry:\n    import enum\n    assert enum\nexcept ImportError:\n    install_requires.append(\'enum34\')\n\n\ntests_require = [\'pytest\']\n\n\nclass BuildExt(build_ext):\n\n    def run(self):\n        try:\n            build_ext.run(self)\n        except Exception as e:\n            warnings.warn(\'\'\'\n            Unable to build speedups module, defaulting to pure Python. Note\n            that the pure Python version is more than fast enough in most cases\n            %r\n            \'\'\' % e)\n\n\nif __name__ == \'__main__\':\n    setup(\n        name=about[\'__package_name__\'],\n        version=about[\'__version__\'],\n        author=about[\'__author__\'],\n        author_email=about[\'__author_email__\'],\n        description=about[\'__description__\'],\n        url=about[\'__url__\'],\n        license=\'BSD\',\n        packages=[\'stl\'],\n        long_description=long_description,\n        tests_require=tests_require,\n        entry_points={\n            \'console_scripts\': [\n                \'stl = %s.main:main\' % about[\'__import_name__\'],\n                \'stl2ascii = %s.main:to_ascii\' % about[\'__import_name__\'],\n                \'stl2bin = %s.main:to_binary\' % about[\'__import_name__\'],\n            ],\n        },\n        classifiers=[\n            \'Development Status :: 6 - Mature\',\n            \'Intended Audience :: Developers\',\n            \'License :: OSI Approved :: BSD License\',\n            \'Operating System :: OS Independent\',\n            \'Natural Language :: English\',\n            \'Programming Language :: Python\',\n            \'Programming Language :: Python :: 2\',\n            \'Programming Language :: Python :: 2.7\',\n            \'Programming Language :: Python :: 3\',\n            \'Programming Language :: Python :: 3.4\',\n            \'Programming Language :: Python :: 3.5\',\n            \'Programming Language :: Python :: 3.6\',\n            \'Programming Language :: Python :: 3.7\',\n            \'Topic :: Software Development :: Libraries :: Python Modules\',\n        ],\n        install_requires=install_requires,\n        cmdclass=dict(\n            build_ext=BuildExt,\n            test=PyTest,\n        ),\n        **setup_kwargs\n    )\n\n'"
docs/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Documentation build configuration file, created by\n# sphinx-quickstart on Thu Feb 27 20:00:23 2014.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport os\nimport sys\nimport datetime\n\ntry:\n    import numpy\n    assert numpy\nexcept ImportError:\n    # From the readthedocs manual\n    # http://read-the-docs.readthedocs.org/en/latest/faq.html?highlight=numpy\n    print >>sys.stderr, \'Unable to import numpy, falling back to mock\'\n    import mock\n\n    MOCK_MODULES = [\'pygtk\', \'gtk\', \'gobject\', \'argparse\', \'numpy\', \'pandas\']\n    for mod_name in MOCK_MODULES:\n        sys.modules[mod_name] = mock.Mock()\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\nsys.path.insert(0, os.path.abspath(\'..\'))\nfrom stl import __about__ as metadata\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.doctest\',\n    \'sphinx.ext.intersphinx\',\n    \'sphinx.ext.todo\',\n    \'sphinx.ext.coverage\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.ifconfig\',\n    \'sphinx.ext.viewcode\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix of source filenames.\nsource_suffix = \'.rst\'\n\n# The encoding of source files.\n#source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = metadata.__package_name__.replace(\'-\', \' \').capitalize()\ncopyright = u\'%s,  <a href=""http://wol.ph/"">%s</a>\' % (\n    datetime.date.today().year,\n    metadata.__author__,\n)\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = metadata.__version__\n# The full version, including alpha/beta/rc tags.\nrelease = metadata.__version__\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\'_build\']\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n#default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\n# If true, keep warnings as ""system message"" paragraphs in the built documents.\n#keep_warnings = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \'wolph\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\nhtml_theme_path = [\'_theme\']\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\n# html_static_path = [\'_static\']\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n#html_extra_path = []\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\n#html_domain_indices = True\n\n# If false, no index is generated.\n#html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n#html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = metadata.__package_name__ + \'-doc\'\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n# The paper size (\'letterpaper\' or \'a4paper\').\n#\'papersize\': \'letterpaper\',\n\n# The font size (\'10pt\', \'11pt\' or \'12pt\').\n#\'pointsize\': \'10pt\',\n\n# Additional stuff for the LaTeX preamble.\n#\'preamble\': \'\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).\nlatex_documents = [(\n    \'index\',\n    \'%s.tex\' % metadata.__package_name__,\n    u\'%s Documentation\' % metadata.__package_name__.replace(\'-\', \' \').capitalize(),\n   metadata.__author__,\n   \'manual\',\n)]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n#latex_logo = None\n\n# For ""manual"" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n#latex_use_parts = False\n\n# If true, show page references after internal links.\n#latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n#latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n\n# If false, no module index is generated.\n#latex_domain_indices = True\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(\n    \'index\',\n    metadata.__package_name__,\n    u\'%s Documentation\' % metadata.__package_name__.replace(\'-\', \' \').capitalize(),\n    [metadata.__author__],\n    1,\n)]\n\n# If true, show URL addresses after external links.\n#man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [(\n    \'index\',\n    metadata.__package_name__,\n    u\'%s Documentation\' % metadata.__package_name__.replace(\'-\', \' \').capitalize(),\n    metadata.__author__,\n    metadata.__package_name__,\n    metadata.__description__,\n    \'Miscellaneous\',\n)]\n\n# Documents to append as an appendix to all manuals.\n#texinfo_appendices = []\n\n# If false, no module index is generated.\n#texinfo_domain_indices = True\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n#texinfo_show_urls = \'footnote\'\n\n# If true, do not generate a @detailmenu in the ""Top"" node\'s menu.\n#texinfo_no_detailmenu = False\n\n\n# -- Options for Epub output ----------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = metadata.__package_name__.replace(\'-\', \' \').capitalize()\nepub_author = metadata.__author__\nepub_publisher = metadata.__author__\nepub_copyright = copyright\n\n# The HTML theme for the epub output. Since the default themes are not optimized\n# for small screen space, using the same theme for HTML and epub output is\n# usually not wise. This defaults to \'epub\', a theme designed to save visual\n# space.\n#epub_theme = \'epub\'\n\n# The language of the text. It defaults to the language option\n# or en if the language is not set.\n#epub_language = \'\'\n\n# The scheme of the identifier. Typical schemes are ISBN or URL.\n#epub_scheme = \'\'\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#epub_identifier = \'\'\n\n# A unique identification for the text.\n#epub_uid = \'\'\n\n# A tuple containing the cover image and cover page html template filenames.\n#epub_cover = ()\n\n# A sequence of (type, uri, title) tuples for the guide element of content.opf.\n#epub_guide = ()\n\n# HTML files that should be inserted before the pages created by sphinx.\n# The format is a list of tuples containing the path and title.\n#epub_pre_files = []\n\n# HTML files shat should be inserted after the pages created by sphinx.\n# The format is a list of tuples containing the path and title.\n#epub_post_files = []\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\'search.html\']\n\n# The depth of the table of contents in toc.ncx.\n#epub_tocdepth = 3\n\n# Allow duplicate toc entries.\n#epub_tocdup = True\n\n# Choose between \'default\' and \'includehidden\'.\n#epub_tocscope = \'default\'\n\n# Fix unsupported image types using the PIL.\n#epub_fix_images = False\n\n# Scale large images.\n#epub_max_image_width = 0\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n#epub_show_urls = \'inline\'\n\n# If false, no index is generated.\n#epub_use_index = True\n\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {\n    \'python\': (\'http://docs.python.org/2\', None),\n    \'pythonutils\': (\'http://python-utils.readthedocs.org/en/latest/\', None),\n    \'numpy\': (\'http://docs.scipy.org/doc/numpy/\', None),\n    \'scipy\': (\'http://docs.scipy.org/doc/scipy/reference/\', None),\n    \'matplotlib\': (\'http://matplotlib.sourceforge.net/\', None),\n}\n'"
stl/__about__.py,0,"b""__package_name__ = 'numpy-stl'\n__import_name__ = 'stl'\n__version__ = '2.11.2'\n__author__ = 'Rick van Hattem'\n__author_email__ = 'Wolph@Wol.ph'\n__description__ = ' '.join('''\nLibrary to make reading, writing and modifying both binary and ascii STL files\neasy.\n'''.split())\n__url__ = 'https://github.com/WoLpH/numpy-stl/'\n\n"""
stl/__init__.py,0,"b""from .stl import BUFFER_SIZE\nfrom .stl import HEADER_SIZE\nfrom .stl import COUNT_SIZE\nfrom .stl import MAX_COUNT\n\nfrom .stl import Mode\nfrom .base import Dimension\nfrom .base import RemoveDuplicates\nfrom .mesh import Mesh\n\n__all__ = [\n    'BUFFER_SIZE',\n    'HEADER_SIZE',\n    'COUNT_SIZE',\n    'MAX_COUNT',\n    'Mode',\n    'Dimension',\n    'RemoveDuplicates',\n    'Mesh',\n]\n"""
stl/base.py,0,"b'from __future__ import (absolute_import, division, print_function,\n                        unicode_literals)\nimport enum\nimport math\nimport numpy\nimport logging\ntry:  # pragma: no cover\n    from collections import abc\nexcept ImportError:  # pragma: no cover\n    import collections as abc\n\nfrom python_utils import logger\n\nfrom .utils import s\n\n#: When removing empty areas, remove areas that are smaller than this\nAREA_SIZE_THRESHOLD = 0\n#: Vectors in a point\nVECTORS = 3\n#: Dimensions used in a vector\nDIMENSIONS = 3\n\n\nclass Dimension(enum.IntEnum):\n    #: X index (for example, `mesh.v0[0][X]`)\n    X = 0\n    #: Y index (for example, `mesh.v0[0][Y]`)\n    Y = 1\n    #: Z index (for example, `mesh.v0[0][Z]`)\n    Z = 2\n\n\n# For backwards compatibility, leave the original references\nX = Dimension.X\nY = Dimension.Y\nZ = Dimension.Z\n\n\nclass RemoveDuplicates(enum.Enum):\n    \'\'\'\n    Choose whether to remove no duplicates, leave only a single of the\n    duplicates or remove all duplicates (leaving holes).\n    \'\'\'\n    NONE = 0\n    SINGLE = 1\n    ALL = 2\n\n    @classmethod\n    def map(cls, value):\n        if value is True:\n            value = cls.SINGLE\n        elif value and value in cls:\n            pass\n        else:\n            value = cls.NONE\n\n        return value\n\n\ndef logged(class_):\n    # For some reason the Logged baseclass is not properly initiated on Linux\n    # systems while this works on OS X. Please let me know if you can tell me\n    # what silly mistake I made here\n\n    logger_name = logger.Logged._Logged__get_name(\n        __name__,\n        class_.__name__,\n    )\n\n    class_.logger = logging.getLogger(logger_name)\n\n    for key in dir(logger.Logged):\n        if not key.startswith(\'__\'):\n            setattr(class_, key, getattr(class_, key))\n\n    return class_\n\n\n@logged\nclass BaseMesh(logger.Logged, abc.Mapping):\n    \'\'\'\n    Mesh object with easy access to the vectors through v0, v1 and v2.\n    The normals, areas, min, max and units are calculated automatically.\n\n    :param numpy.array data: The data for this mesh\n    :param bool calculate_normals: Whether to calculate the normals\n    :param bool remove_empty_areas: Whether to remove triangles with 0 area\n            (due to rounding errors for example)\n\n    :ivar str name: Name of the solid, only exists in ASCII files\n    :ivar numpy.array data: Data as :func:`BaseMesh.dtype`\n    :ivar numpy.array points: All points (Nx9)\n    :ivar numpy.array normals: Normals for this mesh, calculated automatically\n        by default (Nx3)\n    :ivar numpy.array vectors: Vectors in the mesh (Nx3x3)\n    :ivar numpy.array attr: Attributes per vector (used by binary STL)\n    :ivar numpy.array x: Points on the X axis by vertex (Nx3)\n    :ivar numpy.array y: Points on the Y axis by vertex (Nx3)\n    :ivar numpy.array z: Points on the Z axis by vertex (Nx3)\n    :ivar numpy.array v0: Points in vector 0 (Nx3)\n    :ivar numpy.array v1: Points in vector 1 (Nx3)\n    :ivar numpy.array v2: Points in vector 2 (Nx3)\n\n    >>> data = numpy.zeros(10, dtype=BaseMesh.dtype)\n    >>> mesh = BaseMesh(data, remove_empty_areas=False)\n    >>> # Increment vector 0 item 0\n    >>> mesh.v0[0] += 1\n    >>> mesh.v1[0] += 2\n\n    >>> # Check item 0 (contains v0, v1 and v2)\n    >>> assert numpy.array_equal(\n    ...     mesh[0],\n    ...     numpy.array([1., 1., 1., 2., 2., 2., 0., 0., 0.]))\n    >>> assert numpy.array_equal(\n    ... mesh.vectors[0],\n    ... numpy.array([[1., 1., 1.],\n    ...     [2., 2., 2.],\n    ...     [0., 0., 0.]]))\n    >>> assert numpy.array_equal(\n    ...     mesh.v0[0],\n    ...     numpy.array([1., 1., 1.]))\n    >>> assert numpy.array_equal(\n    ...     mesh.points[0],\n    ...     numpy.array([1., 1., 1., 2., 2., 2., 0., 0., 0.]))\n    >>> assert numpy.array_equal(\n    ...     mesh.data[0],\n    ...     numpy.array((\n    ...             [0., 0., 0.],\n    ...             [[1., 1., 1.], [2., 2., 2.], [0., 0., 0.]],\n    ...             [0]),\n    ...         dtype=BaseMesh.dtype))\n    >>> assert numpy.array_equal(mesh.x[0], numpy.array([1., 2., 0.]))\n\n    >>> mesh[0] = 3\n    >>> assert numpy.array_equal(\n    ...     mesh[0],\n    ...     numpy.array([3., 3., 3., 3., 3., 3., 3., 3., 3.]))\n\n    >>> len(mesh) == len(list(mesh))\n    True\n    >>> (mesh.min_ < mesh.max_).all()\n    True\n    >>> mesh.update_normals()\n    >>> mesh.units.sum()\n    0.0\n    >>> mesh.v0[:] = mesh.v1[:] = mesh.v2[:] = 0\n    >>> mesh.points.sum()\n    0.0\n\n    >>> mesh.v0 = mesh.v1 = mesh.v2 = 0\n    >>> mesh.x = mesh.y = mesh.z = 0\n\n    >>> mesh.attr = 1\n    >>> (mesh.attr == 1).all()\n    True\n\n    >>> mesh.normals = 2\n    >>> (mesh.normals == 2).all()\n    True\n\n    >>> mesh.vectors = 3\n    >>> (mesh.vectors == 3).all()\n    True\n\n    >>> mesh.points = 4\n    >>> (mesh.points == 4).all()\n    True\n    \'\'\'\n    #: - normals: :func:`numpy.float32`, `(3, )`\n    #: - vectors: :func:`numpy.float32`, `(3, 3)`\n    #: - attr: :func:`numpy.uint16`, `(1, )`\n    dtype = numpy.dtype([\n        (s(\'normals\'), numpy.float32, (3, )),\n        (s(\'vectors\'), numpy.float32, (3, 3)),\n        (s(\'attr\'), numpy.uint16, (1, )),\n    ])\n    dtype = dtype.newbyteorder(\'<\')  # Even on big endian arches, use little e.\n\n    def __init__(self, data, calculate_normals=True,\n                 remove_empty_areas=False,\n                 remove_duplicate_polygons=RemoveDuplicates.NONE,\n                 name=\'\', speedups=True, **kwargs):\n        super(BaseMesh, self).__init__(**kwargs)\n        self.speedups = speedups\n        if remove_empty_areas:\n            data = self.remove_empty_areas(data)\n\n        if RemoveDuplicates.map(remove_duplicate_polygons).value:\n            data = self.remove_duplicate_polygons(data,\n                                                  remove_duplicate_polygons)\n\n        self.name = name\n        self.data = data\n\n        if calculate_normals:\n            self.update_normals()\n\n    @property\n    def attr(self):\n        return self.data[\'attr\']\n\n    @attr.setter\n    def attr(self, value):\n        self.data[\'attr\'] = value\n\n    @property\n    def normals(self):\n        return self.data[\'normals\']\n\n    @normals.setter\n    def normals(self, value):\n        self.data[\'normals\'] = value\n\n    @property\n    def vectors(self):\n        return self.data[\'vectors\']\n\n    @vectors.setter\n    def vectors(self, value):\n        self.data[\'vectors\'] = value\n\n    @property\n    def points(self):\n        return self.vectors.reshape(self.data.size, 9)\n\n    @points.setter\n    def points(self, value):\n        self.points[:] = value\n\n    @property\n    def v0(self):\n        return self.vectors[:, 0]\n\n    @v0.setter\n    def v0(self, value):\n        self.vectors[:, 0] = value\n\n    @property\n    def v1(self):\n        return self.vectors[:, 1]\n\n    @v1.setter\n    def v1(self, value):\n        self.vectors[:, 1] = value\n\n    @property\n    def v2(self):\n        return self.vectors[:, 2]\n\n    @v2.setter\n    def v2(self, value):\n        self.vectors[:, 2] = value\n\n    @property\n    def x(self):\n        return self.points[:, Dimension.X::3]\n\n    @x.setter\n    def x(self, value):\n        self.points[:, Dimension.X::3] = value\n\n    @property\n    def y(self):\n        return self.points[:, Dimension.Y::3]\n\n    @y.setter\n    def y(self, value):\n        self.points[:, Dimension.Y::3] = value\n\n    @property\n    def z(self):\n        return self.points[:, Dimension.Z::3]\n\n    @z.setter\n    def z(self, value):\n        self.points[:, Dimension.Z::3] = value\n\n    @classmethod\n    def remove_duplicate_polygons(cls, data, value=RemoveDuplicates.SINGLE):\n        value = RemoveDuplicates.map(value)\n        polygons = data[\'vectors\'].sum(axis=1)\n        # Get a sorted list of indices\n        idx = numpy.lexsort(polygons.T)\n        # Get the indices of all different indices\n        diff = numpy.any(polygons[idx[1:]] != polygons[idx[:-1]], axis=1)\n\n        if value is RemoveDuplicates.SINGLE:\n            # Only return the unique data, the True is so we always get at\n            # least the originals\n            return data[numpy.sort(idx[numpy.concatenate(([True], diff))])]\n        elif value is RemoveDuplicates.ALL:\n            # We need to return both items of the shifted diff\n            diff_a = numpy.concatenate(([True], diff))\n            diff_b = numpy.concatenate((diff, [True]))\n            diff = numpy.concatenate((diff, [False]))\n\n            # Combine both unique lists\n            filtered_data = data[numpy.sort(idx[diff_a & diff_b])]\n            if len(filtered_data) <= len(data) / 2:\n                return data[numpy.sort(idx[diff_a])]\n            else:\n                return data[numpy.sort(idx[diff])]\n        else:\n            return data\n\n    @classmethod\n    def remove_empty_areas(cls, data):\n        vectors = data[\'vectors\']\n        v0 = vectors[:, 0]\n        v1 = vectors[:, 1]\n        v2 = vectors[:, 2]\n        normals = numpy.cross(v1 - v0, v2 - v0)\n        squared_areas = (normals ** 2).sum(axis=1)\n        return data[squared_areas > AREA_SIZE_THRESHOLD ** 2]\n\n    def update_normals(self, update_areas=True):\n        \'\'\'Update the normals and areas for all points\'\'\'\n        normals = numpy.cross(self.v1 - self.v0, self.v2 - self.v0)\n\n        if update_areas:\n            self.update_areas(normals)\n\n        normal = numpy.linalg.norm(normals, axis=1)\n        non_zero = normal > 0\n        if non_zero.any():\n            normals[non_zero] /= normal[non_zero][:, None]\n        self.normals[:] = normals\n\n    def update_min(self):\n        self._min = self.vectors.min(axis=(0, 1))\n\n    def update_max(self):\n        self._max = self.vectors.max(axis=(0, 1))\n\n    def update_areas(self, normals=None):\n        if normals is None:\n            normals = numpy.cross(self.v1 - self.v0, self.v2 - self.v0)\n\n        areas = .5 * numpy.sqrt((normals ** 2).sum(axis=1))\n        self.areas = areas.reshape((areas.size, 1))\n\n    def check(self):\n        \'\'\'Check the mesh is valid or not\'\'\'\n        return self.is_closed()\n\n    def is_closed(self):  # pragma: no cover\n        """"""Check the mesh is closed or not""""""\n        if numpy.isclose(self.normals.sum(axis=0), 0, atol=1e-4).all():\n            return True\n        else:\n            self.warning(\'\'\'\n            Your mesh is not closed, the mass methods will not function\n            correctly on this mesh.  For more info:\n            https://github.com/WoLpH/numpy-stl/issues/69\n            \'\'\'.strip())\n            return False\n\n    def get_mass_properties(self):\n        \'\'\'\n        Evaluate and return a tuple with the following elements:\n          - the volume\n          - the position of the center of gravity (COG)\n          - the inertia matrix expressed at the COG\n\n        Documentation can be found here:\n        http://www.geometrictools.com/Documentation/PolyhedralMassProperties.pdf\n        \'\'\'\n        self.check()\n\n        def subexpression(x):\n            w0, w1, w2 = x[:, 0], x[:, 1], x[:, 2]\n            temp0 = w0 + w1\n            f1 = temp0 + w2\n            temp1 = w0 * w0\n            temp2 = temp1 + w1 * temp0\n            f2 = temp2 + w2 * f1\n            f3 = w0 * temp1 + w1 * temp2 + w2 * f2\n            g0 = f2 + w0 * (f1 + w0)\n            g1 = f2 + w1 * (f1 + w1)\n            g2 = f2 + w2 * (f1 + w2)\n            return f1, f2, f3, g0, g1, g2\n\n        x0, x1, x2 = self.x[:, 0], self.x[:, 1], self.x[:, 2]\n        y0, y1, y2 = self.y[:, 0], self.y[:, 1], self.y[:, 2]\n        z0, z1, z2 = self.z[:, 0], self.z[:, 1], self.z[:, 2]\n        a1, b1, c1 = x1 - x0, y1 - y0, z1 - z0\n        a2, b2, c2 = x2 - x0, y2 - y0, z2 - z0\n        d0, d1, d2 = b1 * c2 - b2 * c1, a2 * c1 - a1 * c2, a1 * b2 - a2 * b1\n\n        f1x, f2x, f3x, g0x, g1x, g2x = subexpression(self.x)\n        f1y, f2y, f3y, g0y, g1y, g2y = subexpression(self.y)\n        f1z, f2z, f3z, g0z, g1z, g2z = subexpression(self.z)\n\n        intg = numpy.zeros((10))\n        intg[0] = sum(d0 * f1x)\n        intg[1:4] = sum(d0 * f2x), sum(d1 * f2y), sum(d2 * f2z)\n        intg[4:7] = sum(d0 * f3x), sum(d1 * f3y), sum(d2 * f3z)\n        intg[7] = sum(d0 * (y0 * g0x + y1 * g1x + y2 * g2x))\n        intg[8] = sum(d1 * (z0 * g0y + z1 * g1y + z2 * g2y))\n        intg[9] = sum(d2 * (x0 * g0z + x1 * g1z + x2 * g2z))\n        intg /= numpy.array([6, 24, 24, 24, 60, 60, 60, 120, 120, 120])\n        volume = intg[0]\n        cog = intg[1:4] / volume\n        cogsq = cog ** 2\n        inertia = numpy.zeros((3, 3))\n        inertia[0, 0] = intg[5] + intg[6] - volume * (cogsq[1] + cogsq[2])\n        inertia[1, 1] = intg[4] + intg[6] - volume * (cogsq[2] + cogsq[0])\n        inertia[2, 2] = intg[4] + intg[5] - volume * (cogsq[0] + cogsq[1])\n        inertia[0, 1] = inertia[1, 0] = -(intg[7] - volume * cog[0] * cog[1])\n        inertia[1, 2] = inertia[2, 1] = -(intg[8] - volume * cog[1] * cog[2])\n        inertia[0, 2] = inertia[2, 0] = -(intg[9] - volume * cog[2] * cog[0])\n        return volume, cog, inertia\n\n    def update_units(self):\n        units = self.normals.copy()\n        non_zero_areas = self.areas > 0\n        areas = self.areas\n\n        if non_zero_areas.shape[0] != areas.shape[0]:  # pragma: no cover\n            self.warning(\'Zero sized areas found, \'\n                         \'units calculation will be partially incorrect\')\n\n        if non_zero_areas.any():\n            non_zero_areas.shape = non_zero_areas.shape[0]\n            areas = numpy.hstack((2 * areas[non_zero_areas],) * DIMENSIONS)\n            units[non_zero_areas] /= areas\n\n        self.units = units\n\n    @classmethod\n    def rotation_matrix(cls, axis, theta):\n        \'\'\'\n        Generate a rotation matrix to Rotate the matrix over the given axis by\n        the given theta (angle)\n\n        Uses the `Euler-Rodrigues\n        <https://en.wikipedia.org/wiki/Euler%E2%80%93Rodrigues_formula>`_\n        formula for fast rotations.\n\n        :param numpy.array axis: Axis to rotate over (x, y, z)\n        :param float theta: Rotation angle in radians, use `math.radians` to\n                     convert degrees to radians if needed.\n        \'\'\'\n        axis = numpy.asarray(axis)\n        # No need to rotate if there is no actual rotation\n        if not axis.any():\n            return numpy.identity(3)\n\n        theta = 0.5 * numpy.asarray(theta)\n\n        axis = axis / numpy.linalg.norm(axis)\n\n        a = math.cos(theta)\n        b, c, d = - axis * math.sin(theta)\n        angles = a, b, c, d\n        powers = [x * y for x in angles for y in angles]\n        aa, ab, ac, ad = powers[0:4]\n        ba, bb, bc, bd = powers[4:8]\n        ca, cb, cc, cd = powers[8:12]\n        da, db, dc, dd = powers[12:16]\n\n        return numpy.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n                            [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n                            [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n\n    def rotate(self, axis, theta=0, point=None):\n        \'\'\'\n        Rotate the matrix over the given axis by the given theta (angle)\n\n        Uses the :py:func:`rotation_matrix` in the background.\n\n        .. note:: Note that the `point` was accidentaly inverted with the\n           old version of the code. To get the old and incorrect behaviour\n           simply pass `-point` instead of `point` or `-numpy.array(point)` if\n           you\'re passing along an array.\n\n        :param numpy.array axis: Axis to rotate over (x, y, z)\n        :param float theta: Rotation angle in radians, use `math.radians` to\n                            convert degrees to radians if needed.\n        :param numpy.array point: Rotation point so manual translation is not\n                                  required\n        \'\'\'\n        # No need to rotate if there is no actual rotation\n        if not theta:\n            return\n\n        self.rotate_using_matrix(self.rotation_matrix(axis, theta), point)\n\n    def rotate_using_matrix(self, rotation_matrix, point=None):\n        identity = numpy.identity(rotation_matrix.shape[0])\n        # No need to rotate if there is no actual rotation\n        if not rotation_matrix.any() or (identity == rotation_matrix).all():\n            return\n\n        if isinstance(point, (numpy.ndarray, list, tuple)) and len(point) == 3:\n            point = numpy.asarray(point)\n        elif point is None:\n            point = numpy.array([0, 0, 0])\n        elif isinstance(point, (int, float)):\n            point = numpy.asarray([point] * 3)\n        else:\n            raise TypeError(\'Incorrect type for point\', point)\n\n        def _rotate(matrix):\n            if point.any():\n                # Translate while rotating\n                return (matrix - point).dot(rotation_matrix) + point\n            else:\n                # Simply apply the rotation\n                return matrix.dot(rotation_matrix)\n\n        # Rotate the normals\n        self.normals[:] = _rotate(self.normals[:])\n\n        # Rotate the vectors\n        for i in range(3):\n            self.vectors[:, i] = _rotate(self.vectors[:, i])\n\n    def translate(self, translation):\n        \'\'\'\n        Translate the mesh in the three directions\n\n        :param numpy.array translation: Translation vector (x, y, z)\n        \'\'\'\n        assert len(translation) == 3, ""Translation vector must be of length 3""\n        self.x += translation[0]\n        self.y += translation[1]\n        self.z += translation[2]\n\n    def transform(self, matrix):\n        \'\'\'\n        Transform the mesh with a rotation and a translation stored in a\n        single 4x4 matrix\n\n        :param numpy.array matrix: Transform matrix with shape (4, 4), where\n                                   matrix[0:3, 0:3] represents the rotation\n                                   part of the transformation\n                                   matrix[0:3, 3] represents the translation\n                                   part of the transformation\n        \'\'\'\n        is_a_4x4_matrix = matrix.shape == (4, 4)\n        assert is_a_4x4_matrix, ""Transformation matrix must be of shape (4, 4)""\n        rotation = matrix[0:3, 0:3]\n        unit_det_rotation = numpy.allclose(numpy.linalg.det(rotation), 1.0)\n        assert unit_det_rotation, ""Rotation matrix has not a unit determinant""\n        for i in range(3):\n            self.vectors[:, i] = numpy.dot(rotation, self.vectors[:, i].T).T\n        self.x += matrix[0, 3]\n        self.y += matrix[1, 3]\n        self.z += matrix[2, 3]\n\n    def _get_or_update(key):\n        def _get(self):\n            if not hasattr(self, \'_%s\' % key):\n                getattr(self, \'update_%s\' % key)()\n            return getattr(self, \'_%s\' % key)\n\n        return _get\n\n    def _set(key):\n        def _set(self, value):\n            setattr(self, \'_%s\' % key, value)\n\n        return _set\n\n    min_ = property(_get_or_update(\'min\'), _set(\'min\'),\n                    doc=\'Mesh minimum value\')\n    max_ = property(_get_or_update(\'max\'), _set(\'max\'),\n                    doc=\'Mesh maximum value\')\n    areas = property(_get_or_update(\'areas\'), _set(\'areas\'),\n                     doc=\'Mesh areas\')\n    units = property(_get_or_update(\'units\'), _set(\'units\'),\n                     doc=\'Mesh unit vectors\')\n\n    def __getitem__(self, k):\n        return self.points[k]\n\n    def __setitem__(self, k, v):\n        self.points[k] = v\n\n    def __len__(self):\n        return self.points.shape[0]\n\n    def __iter__(self):\n        for point in self.points:\n            yield point\n\n\n'"
stl/main.py,0,"b""import sys\nimport random\nimport argparse\n\nfrom . import stl\n\n\ndef _get_parser(description):\n    parser = argparse.ArgumentParser(description=description)\n    parser.add_argument('infile', nargs='?', type=argparse.FileType('rb'),\n                        default=sys.stdin, help='STL file to read')\n    parser.add_argument('outfile', nargs='?', type=argparse.FileType('wb'),\n                        default=sys.stdout, help='STL file to write')\n    parser.add_argument('--name', nargs='?', help='Name of the mesh')\n    parser.add_argument(\n        '-n', '--use-file-normals', action='store_true',\n        help='Read the normals from the file instead of recalculating them')\n    parser.add_argument(\n        '-r', '--remove-empty-areas', action='store_true',\n        help='Remove areas with 0 surface areas to prevent errors during '\n        'normal calculation')\n    parser.add_argument('-s', '--disable-speedups', action='store_true',\n                        help='Disable Cython speedups')\n    return parser\n\n\ndef _get_name(args):\n    names = [\n        args.name,\n        getattr(args.outfile, 'name', None),\n        getattr(args.infile, 'name', None),\n        'numpy-stl-%06d' % random.randint(0, 1e6),\n    ]\n\n    for name in names:  # pragma: no branch\n        if name and isinstance(name, str) and not name.startswith('<'):\n            return name\n\n\ndef main():\n    parser = _get_parser('Convert STL files from ascii to binary and back')\n    parser.add_argument('-a', '--ascii', action='store_true',\n                        help='Write ASCII file (default is binary)')\n    parser.add_argument('-b', '--binary', action='store_true',\n                        help='Force binary file (for TTYs)')\n\n    args = parser.parse_args()\n    name = _get_name(args)\n    stl_file = stl.StlMesh(filename=name,\n                           fh=args.infile,\n                           calculate_normals=False,\n                           remove_empty_areas=args.remove_empty_areas,\n                           speedups=not args.disable_speedups)\n\n    if args.binary:\n        mode = stl.BINARY\n    elif args.ascii:\n        mode = stl.ASCII\n    else:\n        mode = stl.AUTOMATIC\n\n    stl_file.save(name, args.outfile, mode=mode,\n                  update_normals=not args.use_file_normals)\n\n\ndef to_ascii():\n    parser = _get_parser('Convert STL files to ASCII (text) format')\n    args = parser.parse_args()\n    name = _get_name(args)\n    stl_file = stl.StlMesh(filename=name, fh=args.infile,\n                           calculate_normals=False,\n                           remove_empty_areas=args.remove_empty_areas,\n                           speedups=not args.disable_speedups)\n    stl_file.save(name, args.outfile, mode=stl.ASCII,\n                  update_normals=not args.use_file_normals)\n\n\ndef to_binary():\n    parser = _get_parser('Convert STL files to binary format')\n    args = parser.parse_args()\n    name = _get_name(args)\n    stl_file = stl.StlMesh(filename=name, fh=args.infile,\n                           calculate_normals=False,\n                           remove_empty_areas=args.remove_empty_areas,\n                           speedups=not args.disable_speedups)\n    stl_file.save(name, args.outfile, mode=stl.BINARY,\n                  update_normals=not args.use_file_normals)\n\n"""
stl/mesh.py,0,b'from . import stl\n\n\nclass Mesh(stl.BaseStl):\n    pass\n\n'
stl/stl.py,0,"b""from __future__ import (absolute_import, division, print_function,\n                        unicode_literals)\n\nimport io\nimport os\nimport enum\nimport numpy\nimport struct\nimport datetime\n\nfrom . import base\nfrom . import __about__ as metadata\nfrom .utils import b\nfrom .utils import s\n\ntry:\n    from . import _speedups\nexcept ImportError:  # pragma: no cover\n    _speedups = None\n\n\nclass Mode(enum.IntEnum):\n    #: Automatically detect whether the output is a TTY, if so, write ASCII\n    #: otherwise write BINARY\n    AUTOMATIC = 0\n    #: Force writing ASCII\n    ASCII = 1\n    #: Force writing BINARY\n    BINARY = 2\n\n\n# For backwards compatibility, leave the original references\nAUTOMATIC = Mode.AUTOMATIC\nASCII = Mode.ASCII\nBINARY = Mode.BINARY\n\n\n#: Amount of bytes to read while using buffered reading\nBUFFER_SIZE = 4096\n#: The amount of bytes in the header field\nHEADER_SIZE = 80\n#: The amount of bytes in the count field\nCOUNT_SIZE = 4\n#: The maximum amount of triangles we can read from binary files\nMAX_COUNT = 1e8\n#: The header format, can be safely monkeypatched. Limited to 80 characters\nHEADER_FORMAT = '{package_name} ({version}) {now} {name}'\n\n\nclass BaseStl(base.BaseMesh):\n\n    @classmethod\n    def load(cls, fh, mode=AUTOMATIC, speedups=True):\n        '''Load Mesh from STL file\n\n        Automatically detects binary versus ascii STL files.\n\n        :param file fh: The file handle to open\n        :param int mode: Automatically detect the filetype or force binary\n        '''\n        header = fh.read(HEADER_SIZE)\n        if not header:\n            return\n\n        if isinstance(header, str):  # pragma: no branch\n            header = b(header)\n\n        name = ''\n\n        if mode in (AUTOMATIC, ASCII) and header[:5].lower() == b('solid'):\n            try:\n                name, data = cls._load_ascii(\n                    fh, header, speedups=speedups)\n            except RuntimeError as exception:\n                # Disable fallbacks in ASCII mode\n                if mode is ASCII:\n                    raise\n\n                (recoverable, e) = exception.args\n                # If we didn't read beyond the header the stream is still\n                # readable through the binary reader\n                if recoverable:\n                    name, data = cls._load_binary(fh, header, check_size=False)\n                else:\n                    # Apparently we've read beyond the header. Let's try\n                    # seeking :)\n                    # Note that this fails when reading from stdin, we can't\n                    # recover from that.\n                    fh.seek(HEADER_SIZE)\n\n                    # Since we know this is a seekable file now and we're not\n                    # 100% certain it's binary, check the size while reading\n                    name, data = cls._load_binary(fh, header, check_size=True)\n        else:\n            name, data = cls._load_binary(fh, header)\n\n        return name, data\n\n    @classmethod\n    def _load_binary(cls, fh, header, check_size=False):\n        # Read the triangle count\n        count_data = fh.read(COUNT_SIZE)\n        if len(count_data) != COUNT_SIZE:\n            count = 0\n        else:\n            count, = struct.unpack(s('<i'), b(count_data))\n        # raise RuntimeError()\n        assert count < MAX_COUNT, ('File too large, got %d triangles which '\n                                   'exceeds the maximum of %d') % (\n                                       count, MAX_COUNT)\n\n        if check_size:\n            try:\n                # Check the size of the file\n                fh.seek(0, os.SEEK_END)\n                raw_size = fh.tell() - HEADER_SIZE - COUNT_SIZE\n                expected_count = int(raw_size / cls.dtype.itemsize)\n                assert expected_count == count, ('Expected %d vectors but '\n                                                 'header indicates %d') % (\n                                                     expected_count, count)\n                fh.seek(HEADER_SIZE + COUNT_SIZE)\n            except IOError:  # pragma: no cover\n                pass\n\n        name = header.strip()\n\n        # Read the rest of the binary data\n        return name, numpy.fromfile(fh, dtype=cls.dtype, count=count)\n\n    @classmethod\n    def _ascii_reader(cls, fh, header):\n        if b'\\n' in header:\n            recoverable = [True]\n        else:\n            recoverable = [False]\n            header += b(fh.read(BUFFER_SIZE))\n\n        lines = b(header).split(b('\\n'))\n\n        def get(prefix=''):\n            prefix = b(prefix).lower()\n\n            if lines:\n                raw_line = lines.pop(0)\n            else:\n                raise RuntimeError(recoverable[0], 'Unable to find more lines')\n\n            if not lines:\n                recoverable[0] = False\n\n                # Read more lines and make sure we prepend any old data\n                lines[:] = b(fh.read(BUFFER_SIZE)).split(b('\\n'))\n                raw_line += lines.pop(0)\n\n            raw_line = raw_line.strip()\n            line = raw_line.lower()\n            if line == b(''):\n                return get(prefix)\n\n            if prefix:\n                if line.startswith(prefix):\n                    values = line.replace(prefix, b(''), 1).strip().split()\n                elif line.startswith(b('endsolid')):\n                    # go back to the beginning of new solid part\n                    size_unprocessedlines = sum(len(l) + 1 for l in lines) - 1\n                    if size_unprocessedlines > 0:\n                        position = fh.tell()\n                        fh.seek(position - size_unprocessedlines)\n                    raise StopIteration()\n                else:\n                    raise RuntimeError(recoverable[0],\n                                       '%r should start with %r' % (line,\n                                                                    prefix))\n\n                if len(values) == 3:\n                    return [float(v) for v in values]\n                else:  # pragma: no cover\n                    raise RuntimeError(recoverable[0],\n                                       'Incorrect value %r' % line)\n            else:\n                return b(raw_line)\n\n        line = get()\n        if not lines:\n            raise RuntimeError(recoverable[0],\n                               'No lines found, impossible to read')\n\n        # Yield the name\n        yield line[5:].strip()\n\n        while True:\n            # Read from the header lines first, until that point we can recover\n            # and go to the binary option. After that we cannot due to\n            # unseekable files such as sys.stdin\n            #\n            # Numpy doesn't support any non-file types so wrapping with a\n            # buffer and/or StringIO does not work.\n            try:\n                normals = get('facet normal')\n                assert get() == b('outer loop')\n                v0 = get('vertex')\n                v1 = get('vertex')\n                v2 = get('vertex')\n                assert get() == b('endloop')\n                assert get() == b('endfacet')\n                attrs = 0\n                yield (normals, (v0, v1, v2), attrs)\n            except AssertionError as e:  # pragma: no cover\n                raise RuntimeError(recoverable[0], e)\n            except StopIteration:\n                return\n\n    @classmethod\n    def _load_ascii(cls, fh, header, speedups=True):\n        # The speedups module is covered by travis but it can't be tested in\n        # all environments, this makes coverage checks easier\n        if _speedups and speedups:  # pragma: no cover\n            return _speedups.ascii_read(fh, header)\n        else:\n            iterator = cls._ascii_reader(fh, header)\n            name = next(iterator)\n            return name, numpy.fromiter(iterator, dtype=cls.dtype)\n\n    def save(self, filename, fh=None, mode=AUTOMATIC, update_normals=True):\n        '''Save the STL to a (binary) file\n\n        If mode is :py:data:`AUTOMATIC` an :py:data:`ASCII` file will be\n        written if the output is a TTY and a :py:data:`BINARY` file otherwise.\n\n        :param str filename: The file to load\n        :param file fh: The file handle to open\n        :param int mode: The mode to write, default is :py:data:`AUTOMATIC`.\n        :param bool update_normals: Whether to update the normals\n        '''\n        assert filename, 'Filename is required for the STL headers'\n        if update_normals:\n            self.update_normals()\n\n        if mode is AUTOMATIC:\n            if fh and os.isatty(fh.fileno()):  # pragma: no cover\n                write = self._write_ascii\n            else:\n                write = self._write_binary\n        elif mode is BINARY:\n            write = self._write_binary\n        elif mode is ASCII:\n            write = self._write_ascii\n        else:\n            raise ValueError('Mode %r is invalid' % mode)\n\n        name = os.path.split(filename)[-1]\n        try:\n            if fh:\n                write(fh, name)\n            else:\n                with open(filename, 'wb') as fh:\n                    write(fh, filename)\n        except IOError:  # pragma: no cover\n            pass\n\n    def _write_ascii(self, fh, name):\n        if _speedups and self.speedups:  # pragma: no cover\n            _speedups.ascii_write(fh, b(name), self.data)\n        else:\n            def p(s, file):\n                file.write(b('%s\\n' % s))\n\n            p('solid %s' % name, file=fh)\n\n            for row in self.data:\n                vectors = row['vectors']\n                p('facet normal %f %f %f' % tuple(row['normals']), file=fh)\n                p('  outer loop', file=fh)\n                p('    vertex %f %f %f' % tuple(vectors[0]), file=fh)\n                p('    vertex %f %f %f' % tuple(vectors[1]), file=fh)\n                p('    vertex %f %f %f' % tuple(vectors[2]), file=fh)\n                p('  endloop', file=fh)\n                p('endfacet', file=fh)\n\n            p('endsolid %s' % name, file=fh)\n\n    def get_header(self, name):\n        # Format the header\n        header = HEADER_FORMAT.format(\n            package_name=metadata.__package_name__,\n            version=metadata.__version__,\n            now=datetime.datetime.now(),\n            name=name,\n        )\n\n        # Make it exactly 80 characters\n        return header[:80].ljust(80, ' ')\n\n    def _write_binary(self, fh, name):\n        header = self.get_header(name)\n        packed = struct.pack(s('<i'), self.data.size)\n\n        if isinstance(fh, io.TextIOWrapper):  # pragma: no cover\n            packed = str(packed)\n        else:\n            header = b(header)\n            packed = b(packed)\n\n        fh.write(header)\n        fh.write(packed)\n        self.data.tofile(fh)\n\n        if self.data.size:  # pragma: no cover\n            assert fh.tell() > 84, (\n                'numpy silently refused to write our file. Note that writing '\n                'to `StringIO` objects is not supported by `numpy`')\n\n    @classmethod\n    def from_file(cls, filename, calculate_normals=True, fh=None,\n                  mode=Mode.AUTOMATIC, speedups=True, **kwargs):\n        '''Load a mesh from a STL file\n\n        :param str filename: The file to load\n        :param bool calculate_normals: Whether to update the normals\n        :param file fh: The file handle to open\n        :param dict kwargs: The same as for :py:class:`stl.mesh.Mesh`\n\n        '''\n        if fh:\n            name, data = cls.load(\n                fh, mode=mode, speedups=speedups)\n        else:\n            with open(filename, 'rb') as fh:\n                name, data = cls.load(\n                    fh, mode=mode, speedups=speedups)\n\n        return cls(data, calculate_normals, name=name,\n                   speedups=speedups, **kwargs)\n\n    @classmethod\n    def from_multi_file(cls, filename, calculate_normals=True, fh=None,\n                        mode=Mode.ASCII, speedups=True, **kwargs):\n        '''Load multiple meshes from a STL file\n\n        Note: mode is hardcoded to ascii since binary stl files do not support\n        the multi format\n\n        :param str filename: The file to load\n        :param bool calculate_normals: Whether to update the normals\n        :param file fh: The file handle to open\n        :param dict kwargs: The same as for :py:class:`stl.mesh.Mesh`\n        '''\n        if fh:\n            close = False\n        else:\n            fh = open(filename, 'rb')\n            close = True\n\n        try:\n            raw_data = cls.load(fh, mode=mode, speedups=speedups)\n            while raw_data:\n                name, data = raw_data\n                yield cls(data, calculate_normals, name=name,\n                          speedups=speedups, **kwargs)\n                raw_data = cls.load(fh, mode=ASCII,\n                                    speedups=speedups)\n\n        finally:\n            if close:\n                fh.close()\n\n    @classmethod\n    def from_files(cls, filenames, calculate_normals=True, mode=Mode.AUTOMATIC,\n                   speedups=True, **kwargs):\n        '''Load multiple meshes from a STL file\n\n        Note: mode is hardcoded to ascii since binary stl files do not support\n        the multi format\n\n        :param list(str) filenames: The files to load\n        :param bool calculate_normals: Whether to update the normals\n        :param file fh: The file handle to open\n        :param dict kwargs: The same as for :py:class:`stl.mesh.Mesh`\n        '''\n        meshes = []\n        for filename in filenames:\n            meshes.append(cls.from_file(\n                filename,\n                calculate_normals=calculate_normals,\n                mode=mode,\n                speedups=speedups,\n                **kwargs))\n\n        data = numpy.concatenate([mesh.data for mesh in meshes])\n        return cls(data, calculate_normals=calculate_normals, **kwargs)\n\n\nStlMesh = BaseStl.from_file\n\n"""
stl/utils.py,0,"b""from __future__ import (absolute_import, division, print_function,\n                        unicode_literals)\nimport sys\n\n\nIS_PYTHON2 = (sys.version_info[0] == 2)\n\n\ndef b(s, encoding='ascii', errors='replace'):  # pragma: no cover\n    if IS_PYTHON2:\n        return bytes(s)\n    else:\n        if isinstance(s, str):\n            return bytes(s, encoding, errors)\n        else:\n            return s\n        # return bytes(s, encoding, errors)\n\n\ndef s(s):  # pragma: no cover\n    if IS_PYTHON2:\n        return bytes(s)\n    else:\n        return s\n"""
tests/__init__.py,0,b''
tests/conftest.py,0,"b""import py\nimport pytest\n\n\ndef pytest_generate_tests(metafunc):\n    # Run all tests both with and without speedups\n    metafunc.fixturenames.append('speedups')\n    metafunc.parametrize('speedups', [False, True])\n\n\n@pytest.fixture(scope='session')\ndef cwd():\n    return py.path.local(__file__).dirpath()\n\n\n@pytest.fixture(scope='session')\ndef ascii_path(cwd):\n    return cwd.join('stl_ascii')\n\n\n@pytest.fixture(scope='session')\ndef binary_path(cwd):\n    return cwd.join('stl_binary')\n\n\n@pytest.fixture(scope='session', params=['ascii', 'binary'])\ndef binary_ascii_path(request, ascii_path, binary_path):\n    return ascii_path if request.param == 'ascii' else binary_path\n\n\n@pytest.fixture(scope='session')\ndef ascii_file(ascii_path):\n    return str(ascii_path.join('HalfDonut.stl'))\n\n\n@pytest.fixture(scope='session')\ndef binary_file(binary_path):\n    return str(binary_path.join('HalfDonut.stl'))\n"""
tests/stl_corruption.py,0,"b""from __future__ import print_function\nimport numpy\nimport pytest\nimport struct\n\nfrom stl import mesh\n\n_STL_FILE = '''\nsolid test.stl\nfacet normal -0.014565 0.073223 -0.002897\n  outer loop\n    vertex 0.399344 0.461940 1.044090\n    vertex 0.500000 0.500000 1.500000\n    vertex 0.576120 0.500000 1.117320\n  endloop\nendfacet\nendsolid test.stl\n'''.lstrip()\n\n\ndef test_valid_ascii(tmpdir, speedups):\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('w+') as fh:\n        fh.write(_STL_FILE)\n        fh.seek(0)\n        mesh.Mesh.from_file(str(tmp_file), fh=fh, speedups=speedups)\n\n\ndef test_ascii_with_missing_name(tmpdir, speedups):\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('w+') as fh:\n        # Split the file into lines\n        lines = _STL_FILE.splitlines()\n\n        # Remove everything except solid\n        lines[0] = lines[0].split()[0]\n\n        # Join the lines to test files that start with solid without space\n        fh.write('\\n'.join(lines))\n        fh.seek(0)\n        mesh.Mesh.from_file(str(tmp_file), fh=fh, speedups=speedups)\n\n\ndef test_ascii_with_blank_lines(tmpdir, speedups):\n    _stl_file = '''\n    solid test.stl\n\n\n      facet normal -0.014565 0.073223 -0.002897\n\n        outer loop\n\n          vertex 0.399344 0.461940 1.044090\n          vertex 0.500000 0.500000 1.500000\n\n          vertex 0.576120 0.500000 1.117320\n\n        endloop\n\n      endfacet\n\n    endsolid test.stl\n    '''.lstrip()\n\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('w+') as fh:\n        fh.write(_stl_file)\n        fh.seek(0)\n        mesh.Mesh.from_file(str(tmp_file), fh=fh, speedups=speedups)\n\n\ndef test_incomplete_ascii_file(tmpdir, speedups):\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('w+') as fh:\n        fh.write('solid some_file.stl')\n        fh.seek(0)\n        with pytest.raises(AssertionError):\n            mesh.Mesh.from_file(str(tmp_file), fh=fh, speedups=speedups)\n\n    for offset in (-20, 82, 100):\n        with tmp_file.open('w+') as fh:\n            fh.write(_STL_FILE[:-offset])\n            fh.seek(0)\n            with pytest.raises(AssertionError):\n                mesh.Mesh.from_file(str(tmp_file), fh=fh, speedups=speedups)\n\n\ndef test_corrupt_ascii_file(tmpdir, speedups):\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('w+') as fh:\n        fh.write(_STL_FILE)\n        fh.seek(40)\n        print('####\\n' * 100, file=fh)\n        fh.seek(0)\n        with pytest.raises(AssertionError):\n            mesh.Mesh.from_file(str(tmp_file), fh=fh, speedups=speedups)\n\n    with tmp_file.open('w+') as fh:\n        fh.write(_STL_FILE)\n        fh.seek(40)\n        print(' ' * 100, file=fh)\n        fh.seek(80)\n        fh.write(struct.pack('<i', 10).decode('utf-8'))\n        fh.seek(0)\n        with pytest.raises(AssertionError):\n            mesh.Mesh.from_file(str(tmp_file), fh=fh, speedups=speedups)\n\n\ndef test_corrupt_binary_file(tmpdir, speedups):\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('w+') as fh:\n        fh.write('#########\\n' * 8)\n        fh.write('#\\0\\0\\0')\n        fh.seek(0)\n        mesh.Mesh.from_file(str(tmp_file), fh=fh, speedups=speedups)\n\n    with tmp_file.open('w+') as fh:\n        fh.write('#########\\n' * 9)\n        fh.seek(0)\n        with pytest.raises(AssertionError):\n            mesh.Mesh.from_file(str(tmp_file), fh=fh, speedups=speedups)\n\n    with tmp_file.open('w+') as fh:\n        fh.write('#########\\n' * 8)\n        fh.write('#\\0\\0\\0')\n        fh.seek(0)\n        fh.write('solid test.stl')\n        fh.seek(0)\n        mesh.Mesh.from_file(str(tmp_file), fh=fh, speedups=speedups)\n\n\ndef test_duplicate_polygons():\n    data = numpy.zeros(3, dtype=mesh.Mesh.dtype)\n    data['vectors'][0] = numpy.array([[0, 0, 0],\n                                      [1, 0, 0],\n                                      [0, 1, 1.]])\n    data['vectors'][0] = numpy.array([[0, 0, 0],\n                                      [2, 0, 0],\n                                      [0, 2, 1.]])\n    data['vectors'][0] = numpy.array([[0, 0, 0],\n                                      [3, 0, 0],\n                                      [0, 3, 1.]])\n\n    assert not mesh.Mesh(data, remove_empty_areas=False).check()\n"""
tests/test_ascii.py,0,"b""import os\nimport sys\nimport pytest\nimport warnings\nimport subprocess\n\nfrom stl.utils import b\nfrom stl import mesh\n\n\ndef test_long_name(tmpdir, speedups):\n    name = 'just some very long name which will not fit within the standard'\n    name += name\n    _stl_file = ('''\n    solid %s\n      facet normal -0.014565 0.073223 -0.002897\n        outer loop\n          vertex 0.399344 0.461940 1.044090\n          vertex 0.500000 0.500000 1.500000\n          vertex 0.576120 0.500000 1.117320\n        endloop\n      endfacet\n    endsolid\n    ''' % name).lstrip()\n\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('wb+') as fh:\n        fh.write(b(_stl_file))\n        fh.seek(0)\n        test_mesh = mesh.Mesh.from_file(str(tmp_file), fh=fh,\n                                        speedups=speedups)\n        assert test_mesh.name == b(name)\n\n\ndef test_scientific_notation(tmpdir, speedups):\n    name = 'just some very long name which will not fit within the standard'\n    name += name\n    _stl_file = ('''\n    solid %s\n      facet normal 1.014565e-10 7.3223e-5 -10\n        outer loop\n          vertex 0.399344 0.461940 1.044090e-5\n          vertex 5.00000e-5 5.00000e-5 1.500000e-3\n          vertex 0 2.22045e-15 -10\n        endloop\n      endfacet\n    endsolid\n    ''' % name).lstrip()\n\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('wb+') as fh:\n        fh.write(b(_stl_file))\n        fh.seek(0)\n        test_mesh = mesh.Mesh.from_file(str(tmp_file), fh=fh,\n                                        speedups=speedups)\n        assert test_mesh.name == b(name)\n\n\n@pytest.mark.skipif(sys.platform.startswith('win'),\n                    reason='Only makes sense on Unix')\ndef test_use_with_qt_with_custom_locale_decimal_delimeter(speedups):\n    if not speedups:\n        pytest.skip('Only makes sense with speedups')\n\n    venv = os.environ.get('VIRTUAL_ENV', '')\n    if (3, 6) == sys.version_info[:2] and venv.startswith('/home/travis/'):\n        pytest.skip('PySide2/PyQt5 tests are broken on Travis Python 3.6')\n\n    try:\n        from PySide2 import QtWidgets\n    except ImportError:\n        try:\n            from PyQt5 import QtWidgets\n        except ImportError:\n            warnings.warn(\n                'Unable to import PySide2/PyQt5, skipping locale tests',\n                ImportWarning,\n            )\n            pytest.skip('PySide2/PyQt5 missing')\n    assert QtWidgets\n\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    script_path = os.path.join(dir_path, 'qt-lc_numeric-reproducer')\n\n    env = os.environ.copy()\n    env['LC_NUMERIC'] = 'cs_CZ.utf-8'\n\n    prefix = tuple()\n    if sys.platform.startswith('linux'):\n        prefix = ('xvfb-run', '-a')\n\n    p = subprocess.Popen(prefix + (sys.executable, script_path),\n                         env=env,\n                         universal_newlines=True,\n                         stdout=subprocess.PIPE,\n                         stderr=subprocess.PIPE)\n    out, err = p.communicate()\n\n    # Unable to read the file with speedups, retrying\n    # https://github.com/WoLpH/numpy-stl/issues/52\n    sys.stdout.write(out)\n    sys.stderr.write(err)\n\n    assert 'File too large' not in out\n    assert 'File too large' not in err\n    assert p.returncode == 0\n"""
tests/test_binary.py,0,"b""import pytest\nfrom stl import mesh, Mode\n\n\n@pytest.mark.parametrize('mode', [Mode.BINARY, Mode.AUTOMATIC])\ndef test_ascii_like_binary(tmpdir, speedups, mode):\n    _test(tmpdir, speedups, mode, False)\n    _test(tmpdir, speedups, mode, True)\n\n\ndef test_binary_in_ascii_mode(tmpdir, speedups):\n    with pytest.raises(RuntimeError):\n        _test(tmpdir, speedups, mode=Mode.ASCII, use_filehandle=False)\n\n    with pytest.raises(RuntimeError):\n        _test(tmpdir, speedups, mode=Mode.ASCII, use_filehandle=True)\n\n\ndef _test(tmpdir, speedups, mode, use_filehandle=True):\n    if use_filehandle:\n        with open('tests/stl_binary/rear_case.stl', 'rb') as fh:\n            mesh.Mesh.from_file('rear_case.stl', fh=fh, speedups=speedups,\n                                mode=mode)\n    else:\n        mesh.Mesh.from_file('tests/stl_binary/rear_case.stl',\n                            speedups=speedups, mode=mode)\n"""
tests/test_commandline.py,0,"b""import sys\n\nfrom stl import main\n\n\ndef test_main(ascii_file, binary_file, tmpdir, speedups):\n    original_argv = sys.argv[:]\n    args_pre = ['stl']\n    args_post = [str(tmpdir.join('output.stl'))]\n\n    if not speedups:\n        args_pre.append('-s')\n\n    try:\n        sys.argv[:] = args_pre + [ascii_file] + args_post\n        main.main()\n        sys.argv[:] = args_pre + ['-r', ascii_file] + args_post\n        main.main()\n        sys.argv[:] = args_pre + ['-a', binary_file] + args_post\n        main.main()\n        sys.argv[:] = args_pre + ['-b', ascii_file] + args_post\n        main.main()\n    finally:\n        sys.argv[:] = original_argv\n\n\ndef test_args(ascii_file, tmpdir):\n    parser = main._get_parser('')\n\n    def _get_name(*args):\n        return main._get_name(parser.parse_args(list(map(str, args))))\n\n    assert _get_name('--name', 'foobar') == 'foobar'\n    assert _get_name('-', tmpdir.join('binary.stl')).endswith('binary.stl')\n    assert _get_name(ascii_file, '-').endswith('HalfDonut.stl')\n    assert _get_name('-', '-')\n\n\ndef test_ascii(binary_file, tmpdir, speedups):\n    original_argv = sys.argv[:]\n    try:\n        sys.argv[:] = [\n            'stl',\n            '-s' if not speedups else '',\n            binary_file,\n            str(tmpdir.join('ascii.stl')),\n        ]\n        try:\n            main.to_ascii()\n        except SystemExit:\n            pass\n    finally:\n        sys.argv[:] = original_argv\n\n\ndef test_binary(ascii_file, tmpdir, speedups):\n    original_argv = sys.argv[:]\n    try:\n        sys.argv[:] = [\n            'stl',\n            '-s' if not speedups else '',\n            ascii_file,\n            str(tmpdir.join('binary.stl')),\n        ]\n        try:\n            main.to_binary()\n        except SystemExit:\n            pass\n    finally:\n        sys.argv[:] = original_argv\n"""
tests/test_convert.py,0,"b""# import os\nimport pytest\nimport tempfile\n\nfrom stl import stl\n\n\ndef _test_conversion(from_, to, mode, speedups):\n\n    for name in from_.listdir():\n        source_file = from_.join(name)\n        expected_file = to.join(name)\n        if not expected_file.exists():\n            continue\n\n        mesh = stl.StlMesh(source_file, speedups=speedups)\n        with open(str(expected_file), 'rb') as expected_fh:\n            expected = expected_fh.read()\n            # For binary files, skip the header\n            if mode is stl.BINARY:\n                expected = expected[80:]\n\n            with tempfile.TemporaryFile() as dest_fh:\n                mesh.save(name, dest_fh, mode)\n                # Go back to the beginning to read\n                dest_fh.seek(0)\n                dest = dest_fh.read()\n                # For binary files, skip the header\n                if mode is stl.BINARY:\n                    dest = dest[80:]\n\n                assert dest.strip() == expected.strip()\n\n\ndef test_ascii_to_binary(ascii_path, binary_path, speedups):\n    _test_conversion(ascii_path, binary_path, mode=stl.BINARY,\n                     speedups=speedups)\n\n\ndef test_binary_to_ascii(ascii_path, binary_path, speedups):\n    _test_conversion(binary_path, ascii_path, mode=stl.ASCII,\n                     speedups=speedups)\n\n\ndef test_stl_mesh(ascii_file, tmpdir, speedups):\n    tmp_file = tmpdir.join('tmp.stl')\n\n    mesh = stl.StlMesh(ascii_file, speedups=speedups)\n    with pytest.raises(ValueError):\n        mesh.save(filename=str(tmp_file), mode='test')\n\n    mesh.save(str(tmp_file))\n    mesh.save(str(tmp_file), update_normals=False)\n"""
tests/test_mesh.py,0,"b""import numpy\n\nfrom stl.mesh import Mesh\nfrom stl.base import BaseMesh\nfrom stl.base import RemoveDuplicates\n\nfrom . import utils\n\n\ndef test_units_1d():\n    data = numpy.zeros(1, dtype=Mesh.dtype)\n    data['vectors'][0] = numpy.array([[0, 0, 0],\n                                      [1, 0, 0],\n                                      [2, 0, 0]])\n\n    mesh = Mesh(data, remove_empty_areas=False)\n    mesh.update_units()\n\n    assert mesh.areas == 0\n    utils.array_equals(mesh.normals, [0, 0, 0])\n    utils.array_equals(mesh.units, [0, 0, 0])\n\n\ndef test_units_2d():\n    data = numpy.zeros(2, dtype=Mesh.dtype)\n    data['vectors'][0] = numpy.array([[0, 0, 0],\n                                      [1, 0, 0],\n                                      [0, 1, 0]])\n    data['vectors'][1] = numpy.array([[1, 0, 0],\n                                      [0, 1, 0],\n                                      [1, 1, 0]])\n\n    mesh = Mesh(data, remove_empty_areas=False)\n    mesh.update_units()\n\n    assert numpy.allclose(mesh.areas, [0.5, 0.5])\n    assert numpy.allclose(mesh.normals, [\n                          [0.0, 0.0, 1.0],\n                          [0.0, 0.0, -1.0]])\n    assert numpy.allclose(mesh.units, [[0, 0, 1], [0, 0, -1]])\n\n\ndef test_units_3d():\n    data = numpy.zeros(1, dtype=Mesh.dtype)\n    data['vectors'][0] = numpy.array([[0, 0, 0],\n                                      [1, 0, 0],\n                                      [0, 1, 1.]])\n\n    mesh = Mesh(data, remove_empty_areas=False)\n    mesh.update_units()\n\n    assert (mesh.areas - 2 ** .5) < 0.0001\n    assert numpy.allclose(mesh.normals, [0.0, -0.70710677, 0.70710677])\n    assert numpy.allclose(mesh.units[0], [0.0, -0.5, 0.5])\n\n\ndef test_duplicate_polygons():\n    data = numpy.zeros(6, dtype=Mesh.dtype)\n    data['vectors'][0] = numpy.array([[1, 0, 0],\n                                      [0, 0, 0],\n                                      [0, 0, 0]])\n    data['vectors'][1] = numpy.array([[2, 0, 0],\n                                      [0, 0, 0],\n                                      [0, 0, 0]])\n    data['vectors'][2] = numpy.array([[0, 0, 0],\n                                      [0, 0, 0],\n                                      [0, 0, 0]])\n    data['vectors'][3] = numpy.array([[2, 0, 0],\n                                      [0, 0, 0],\n                                      [0, 0, 0]])\n    data['vectors'][4] = numpy.array([[1, 0, 0],\n                                      [0, 0, 0],\n                                      [0, 0, 0]])\n    data['vectors'][5] = numpy.array([[0, 0, 0],\n                                      [0, 0, 0],\n                                      [0, 0, 0]])\n\n    mesh = Mesh(data)\n    assert mesh.data.size == 6\n\n    mesh = Mesh(data, remove_duplicate_polygons=0)\n    assert mesh.data.size == 6\n\n    mesh = Mesh(data, remove_duplicate_polygons=False)\n    assert mesh.data.size == 6\n\n    mesh = Mesh(data, remove_duplicate_polygons=None)\n    assert mesh.data.size == 6\n\n    mesh = Mesh(data, remove_duplicate_polygons=RemoveDuplicates.NONE)\n    assert mesh.data.size == 6\n\n    mesh = Mesh(data, remove_duplicate_polygons=RemoveDuplicates.SINGLE)\n    assert mesh.data.size == 3\n\n    mesh = Mesh(data, remove_duplicate_polygons=True)\n    assert mesh.data.size == 3\n\n    assert numpy.allclose(mesh.vectors[0], numpy.array([[1, 0, 0],\n                                                        [0, 0, 0],\n                                                        [0, 0, 0]]))\n    assert numpy.allclose(mesh.vectors[1], numpy.array([[2, 0, 0],\n                                                        [0, 0, 0],\n                                                        [0, 0, 0]]))\n    assert numpy.allclose(mesh.vectors[2], numpy.array([[0, 0, 0],\n                                                        [0, 0, 0],\n                                                        [0, 0, 0]]))\n\n    mesh = Mesh(data, remove_duplicate_polygons=RemoveDuplicates.ALL)\n    assert mesh.data.size == 3\n\n    assert numpy.allclose(mesh.vectors[0], numpy.array([[1, 0, 0],\n                                                        [0, 0, 0],\n                                                        [0, 0, 0]]))\n    assert numpy.allclose(mesh.vectors[1], numpy.array([[2, 0, 0],\n                                                        [0, 0, 0],\n                                                        [0, 0, 0]]))\n    assert numpy.allclose(mesh.vectors[2], numpy.array([[0, 0, 0],\n                                                        [0, 0, 0],\n                                                        [0, 0, 0]]))\n\n\ndef test_remove_all_duplicate_polygons():\n    data = numpy.zeros(5, dtype=Mesh.dtype)\n    data['vectors'][0] = numpy.array([[0, 0, 0],\n                                      [0, 0, 0],\n                                      [0, 0, 0]])\n    data['vectors'][1] = numpy.array([[1, 0, 0],\n                                      [0, 0, 0],\n                                      [0, 0, 0]])\n    data['vectors'][2] = numpy.array([[2, 0, 0],\n                                      [0, 0, 0],\n                                      [0, 0, 0]])\n    data['vectors'][3] = numpy.array([[3, 0, 0],\n                                      [0, 0, 0],\n                                      [0, 0, 0]])\n    data['vectors'][4] = numpy.array([[3, 0, 0],\n                                      [0, 0, 0],\n                                      [0, 0, 0]])\n\n    mesh = Mesh(data, remove_duplicate_polygons=False)\n    assert mesh.data.size == 5\n    Mesh.remove_duplicate_polygons(mesh.data, RemoveDuplicates.NONE)\n\n    mesh = Mesh(data, remove_duplicate_polygons=RemoveDuplicates.ALL)\n    assert mesh.data.size == 3\n\n    assert (mesh.vectors[0] == numpy.array([[0, 0, 0],\n                                            [0, 0, 0],\n                                            [0, 0, 0]])).all()\n    assert (mesh.vectors[1] == numpy.array([[1, 0, 0],\n                                            [0, 0, 0],\n                                            [0, 0, 0]])).all()\n    assert (mesh.vectors[2] == numpy.array([[2, 0, 0],\n                                            [0, 0, 0],\n                                            [0, 0, 0]])).all()\n\n\ndef test_empty_areas():\n    data = numpy.zeros(3, dtype=Mesh.dtype)\n    data['vectors'][0] = numpy.array([[0, 0, 0],\n                                      [1, 0, 0],\n                                      [0, 1, 0]])\n    data['vectors'][1] = numpy.array([[1, 0, 0],\n                                      [0, 1, 0],\n                                      [1, 0, 0]])\n    data['vectors'][2] = numpy.array([[1, 0, 0],\n                                      [0, 1, 0],\n                                      [1, 0, 0]])\n\n    mesh = Mesh(data, calculate_normals=False, remove_empty_areas=False)\n    assert mesh.data.size == 3\n\n    # Test the normals recalculation which also calculates the areas by default\n    mesh.areas[1] = 1\n    mesh.areas[2] = 2\n    assert numpy.allclose(mesh.areas, [[0.5], [1.0], [2.0]])\n\n    mesh.update_normals(update_areas=False)\n    assert numpy.allclose(mesh.areas, [[0.5], [1.0], [2.0]])\n\n    mesh.update_normals(update_areas=True)\n    assert numpy.allclose(mesh.areas, [[0.5], [0.0], [0.0]])\n\n    mesh = Mesh(data, remove_empty_areas=True)\n    assert mesh.data.size == 1\n\n\ndef test_base_mesh():\n    data = numpy.zeros(10, dtype=BaseMesh.dtype)\n    mesh = BaseMesh(data, remove_empty_areas=False)\n    # Increment vector 0 item 0\n    mesh.v0[0] += 1\n    mesh.v1[0] += 2\n\n    # Check item 0 (contains v0, v1 and v2)\n    assert (mesh[0] == numpy.array(\n        [1., 1., 1., 2., 2., 2., 0., 0., 0.], dtype=numpy.float32)\n    ).all()\n    assert (mesh.vectors[0] == numpy.array([\n            [1., 1., 1.],\n            [2., 2., 2.],\n            [0., 0., 0.]], dtype=numpy.float32)).all()\n    assert (mesh.v0[0] == numpy.array([1., 1., 1.], dtype=numpy.float32)).all()\n    assert (mesh.points[0] == numpy.array(\n        [1., 1., 1., 2., 2., 2., 0., 0., 0.], dtype=numpy.float32)\n    ).all()\n    assert (\n        mesh.x[0] == numpy.array([1., 2., 0.], dtype=numpy.float32)).all()\n\n    mesh[0] = 3\n    assert (mesh[0] == numpy.array(\n        [3., 3., 3., 3., 3., 3., 3., 3., 3.], dtype=numpy.float32)\n    ).all()\n\n    assert len(mesh) == len(list(mesh))\n    assert (mesh.min_ < mesh.max_).all()\n    mesh.update_normals()\n    assert mesh.units.sum() == 0.0\n    mesh.v0[:] = mesh.v1[:] = mesh.v2[:] = 0\n    assert mesh.points.sum() == 0.0\n"""
tests/test_meshProperties.py,0,"b'import numpy\nimport pytest\n\nfrom stl import stl\n\n\ntolerance = 1e-6\n\n\ndef test_mass_properties_for_half_donut(binary_ascii_path, speedups):\n    """"""\n    Checks the results of method get_mass_properties() on\n    STL ASCII and binary files HalfDonut.stl\n    One checks the results obtained with stl\n    with the ones obtained with meshlab\n    """"""\n    filename = binary_ascii_path.join(\'HalfDonut.stl\')\n    mesh = stl.StlMesh(str(filename), speedups=speedups)\n    volume, cog, inertia = mesh.get_mass_properties()\n    assert(abs(volume - 2.343149) < tolerance)\n    assert(numpy.allclose(cog,\n           numpy.array([1.500001, 0.209472, 1.500001]),\n           atol=tolerance))\n    assert(numpy.allclose(inertia,\n           numpy.array([[+1.390429, +0.000000, +0.000000],\n                        [+0.000000, +2.701025, +0.000000],\n                        [+0.000000, +0.000000, +1.390429]]),\n           atol=tolerance))\n\n\ndef test_mass_properties_for_moon(binary_ascii_path, speedups):\n    """"""\n    Checks the results of method get_mass_properties() on\n    STL ASCII and binary files Moon.stl\n    One checks the results obtained with stl\n    with the ones obtained with meshlab\n    """"""\n    filename = binary_ascii_path.join(\'Moon.stl\')\n    mesh = stl.StlMesh(str(filename), speedups=speedups)\n    volume, cog, inertia = mesh.get_mass_properties()\n    assert(abs(volume - 0.888723) < tolerance)\n    assert(numpy.allclose(cog,\n           numpy.array([0.906913, 0.170731, 1.500001]),\n           atol=tolerance))\n    assert(numpy.allclose(inertia,\n           numpy.array([[+0.562097, -0.000457, +0.000000],\n                        [-0.000457, +0.656851, +0.000000],\n                        [+0.000000, +0.000000, +0.112465]]),\n           atol=tolerance))\n\n\n@pytest.mark.parametrize(\'filename\', (\'Star.stl\', \'StarWithEmptyHeader.stl\'))\ndef test_mass_properties_for_star(binary_ascii_path, filename, speedups):\n    """"""\n    Checks the results of method get_mass_properties() on\n    STL ASCII and binary files Star.stl and\n    STL binary file StarWithEmptyHeader.stl (with no header)\n    One checks the results obtained with stl\n    with the ones obtained with meshlab\n    """"""\n    filename = binary_ascii_path.join(filename)\n    if not filename.exists():\n        pytest.skip(\'STL file does not exist\')\n    mesh = stl.StlMesh(str(filename), speedups=speedups)\n    volume, cog, inertia = mesh.get_mass_properties()\n    assert(abs(volume - 1.416599) < tolerance)\n    assert(numpy.allclose(cog,\n           numpy.array([1.299040, 0.170197, 1.499999]),\n           atol=tolerance))\n    assert(numpy.allclose(inertia,\n           numpy.array([[+0.509549, +0.000000, -0.000000],\n                        [+0.000000, +0.991236, +0.000000],\n                        [-0.000000, +0.000000, +0.509550]]),\n           atol=tolerance))\n'"
tests/test_multiple.py,0,"b""from stl import mesh\nfrom stl.utils import b\n\n_STL_FILE = b('''\nsolid test.stl\nfacet normal -0.014565 0.073223 -0.002897\n  outer loop\n    vertex 0.399344 0.461940 1.044090\n    vertex 0.500000 0.500000 1.500000\n    vertex 0.576120 0.500000 1.117320\n  endloop\nendfacet\nendsolid test.stl\n'''.lstrip())\n\n\ndef test_single_stl(tmpdir, speedups):\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('wb+') as fh:\n        fh.write(_STL_FILE)\n        fh.seek(0)\n        for m in mesh.Mesh.from_multi_file(\n                str(tmp_file), fh=fh, speedups=speedups):\n            pass\n\n\ndef test_multiple_stl(tmpdir, speedups):\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('wb+') as fh:\n        for _ in range(10):\n            fh.write(_STL_FILE)\n        fh.seek(0)\n        for i, m in enumerate(mesh.Mesh.from_multi_file(\n                str(tmp_file), fh=fh, speedups=speedups)):\n            assert m.name == b'test.stl'\n\n        assert i == 9\n\n\ndef test_single_stl_file(tmpdir, speedups):\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('wb+') as fh:\n        fh.write(_STL_FILE)\n        fh.seek(0)\n        for m in mesh.Mesh.from_multi_file(\n                str(tmp_file), speedups=speedups):\n            pass\n\n\ndef test_multiple_stl_file(tmpdir, speedups):\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('wb+') as fh:\n        for _ in range(10):\n            fh.write(_STL_FILE)\n\n        fh.seek(0)\n        for i, m in enumerate(mesh.Mesh.from_multi_file(\n                str(tmp_file), speedups=speedups)):\n            assert m.name == b'test.stl'\n\n        assert i == 9\n\n\ndef test_multiple_stl_files(tmpdir, speedups):\n    tmp_file = tmpdir.join('tmp.stl')\n    with tmp_file.open('wb+') as fh:\n        fh.write(_STL_FILE)\n        fh.seek(0)\n\n        filenames = [str(tmp_file)] * 10\n\n        m = mesh.Mesh.from_files(filenames, speedups=speedups)\n        assert m.data.size == 10\n\n\n"""
tests/test_rotate.py,0,"b""import math\nimport numpy\nimport pytest\n\nfrom stl.mesh import Mesh\n\nfrom . import utils\n\n\ndef test_rotation():\n    # Create 6 faces of a cube\n    data = numpy.zeros(6, dtype=Mesh.dtype)\n\n    # Top of the cube\n    data['vectors'][0] = numpy.array([[0, 1, 1],\n                                      [1, 0, 1],\n                                      [0, 0, 1]])\n    data['vectors'][1] = numpy.array([[1, 0, 1],\n                                      [0, 1, 1],\n                                      [1, 1, 1]])\n    # Right face\n    data['vectors'][2] = numpy.array([[1, 0, 0],\n                                      [1, 0, 1],\n                                      [1, 1, 0]])\n    data['vectors'][3] = numpy.array([[1, 1, 1],\n                                      [1, 0, 1],\n                                      [1, 1, 0]])\n    # Left face\n    data['vectors'][4] = numpy.array([[0, 0, 0],\n                                      [1, 0, 0],\n                                      [1, 0, 1]])\n    data['vectors'][5] = numpy.array([[0, 0, 0],\n                                      [0, 0, 1],\n                                      [1, 0, 1]])\n\n    mesh = Mesh(data, remove_empty_areas=False)\n\n    # Since the cube faces are from 0 to 1 we can move it to the middle by\n    # substracting .5\n    data['vectors'] -= .5\n\n    # Rotate 90 degrees over the X axis followed by the Y axis followed by the\n    # X axis\n    mesh.rotate([0.5, 0.0, 0.0], math.radians(90))\n    mesh.rotate([0.0, 0.5, 0.0], math.radians(90))\n    mesh.rotate([0.5, 0.0, 0.0], math.radians(90))\n\n    # Since the cube faces are from 0 to 1 we can move it to the middle by\n    # substracting .5\n    data['vectors'] += .5\n\n    # We use a slightly higher absolute tolerance here, for ppc64le\n    # https://github.com/WoLpH/numpy-stl/issues/78\n    assert numpy.allclose(mesh.vectors, numpy.array([\n        [[1, 0, 0], [0, 1, 0], [0, 0, 0]],\n        [[0, 1, 0], [1, 0, 0], [1, 1, 0]],\n        [[0, 1, 1], [0, 1, 0], [1, 1, 1]],\n        [[1, 1, 0], [0, 1, 0], [1, 1, 1]],\n        [[0, 0, 1], [0, 1, 1], [0, 1, 0]],\n        [[0, 0, 1], [0, 0, 0], [0, 1, 0]],\n    ]), atol=1e-07)\n\n\ndef test_rotation_over_point():\n    # Create a single face\n    data = numpy.zeros(1, dtype=Mesh.dtype)\n\n    data['vectors'][0] = numpy.array([[1, 0, 0],\n                                      [0, 1, 0],\n                                      [0, 0, 1]])\n\n    mesh = Mesh(data, remove_empty_areas=False)\n\n    mesh.rotate([1, 0, 0], math.radians(180), point=[1, 2, 3])\n    utils.array_equals(\n        mesh.vectors,\n        numpy.array([[[1., 4., 6.],\n                      [0., 3., 6.],\n                      [0., 4., 5.]]]))\n\n    mesh.rotate([1, 0, 0], math.radians(-180), point=[1, 2, 3])\n    utils.array_equals(\n        mesh.vectors,\n        numpy.array([[[1, 0, 0],\n                      [0, 1, 0],\n                      [0, 0, 1]]]))\n\n    mesh.rotate([1, 0, 0], math.radians(180), point=0.0)\n    utils.array_equals(\n        mesh.vectors,\n        numpy.array([[[1., 0., -0.],\n                      [0., -1., -0.],\n                      [0., 0., -1.]]]))\n\n    with pytest.raises(TypeError):\n        mesh.rotate([1, 0, 0], math.radians(180), point='x')\n\n\ndef test_double_rotation():\n    # Create a single face\n    data = numpy.zeros(1, dtype=Mesh.dtype)\n\n    data['vectors'][0] = numpy.array([[1, 0, 0],\n                                      [0, 1, 0],\n                                      [0, 0, 1]])\n\n    mesh = Mesh(data, remove_empty_areas=False)\n\n    rotation_matrix = mesh.rotation_matrix([1, 0, 0], math.radians(180))\n    combined_rotation_matrix = numpy.dot(rotation_matrix, rotation_matrix)\n\n    mesh.rotate_using_matrix(combined_rotation_matrix)\n    utils.array_equals(\n        mesh.vectors,\n        numpy.array([[[1., 0., 0.],\n                      [0., 1., 0.],\n                      [0., 0., 1.]]]))\n\n\ndef test_no_rotation():\n    # Create a single face\n    data = numpy.zeros(1, dtype=Mesh.dtype)\n\n    data['vectors'][0] = numpy.array([[0, 1, 1],\n                                      [1, 0, 1],\n                                      [0, 0, 1]])\n\n    mesh = Mesh(data, remove_empty_areas=False)\n\n    # Rotate by 0 degrees\n    mesh.rotate([0.5, 0.0, 0.0], math.radians(0))\n    assert numpy.allclose(mesh.vectors, numpy.array([\n        [[0, 1, 1], [1, 0, 1], [0, 0, 1]]]))\n\n    # Use a zero rotation matrix\n    mesh.rotate([0.0, 0.0, 0.0], math.radians(90))\n    assert numpy.allclose(mesh.vectors, numpy.array([\n        [[0, 1, 1], [1, 0, 1], [0, 0, 1]]]))\n\n\ndef test_no_translation():\n    # Create a single face\n    data = numpy.zeros(1, dtype=Mesh.dtype)\n    data['vectors'][0] = numpy.array([[0, 1, 1],\n                                      [1, 0, 1],\n                                      [0, 0, 1]])\n\n    mesh = Mesh(data, remove_empty_areas=False)\n    assert numpy.allclose(mesh.vectors, numpy.array([\n        [[0, 1, 1], [1, 0, 1], [0, 0, 1]]]))\n\n    # Translate mesh with a zero vector\n    mesh.translate([0.0, 0.0, 0.0])\n    assert numpy.allclose(mesh.vectors, numpy.array([\n        [[0, 1, 1], [1, 0, 1], [0, 0, 1]]]))\n\n\ndef test_translation():\n    # Create a single face\n    data = numpy.zeros(1, dtype=Mesh.dtype)\n    data['vectors'][0] = numpy.array([[0, 1, 1],\n                                      [1, 0, 1],\n                                      [0, 0, 1]])\n\n    mesh = Mesh(data, remove_empty_areas=False)\n    assert numpy.allclose(mesh.vectors, numpy.array([\n        [[0, 1, 1], [1, 0, 1], [0, 0, 1]]]))\n\n    # Translate mesh with vector [1, 2, 3]\n    mesh.translate([1.0, 2.0, 3.0])\n    assert numpy.allclose(mesh.vectors, numpy.array([\n        [[1, 3, 4], [2, 2, 4], [1, 2, 4]]]))\n\n\ndef test_no_transformation():\n    # Create a single face\n    data = numpy.zeros(1, dtype=Mesh.dtype)\n    data['vectors'][0] = numpy.array([[0, 1, 1],\n                                      [1, 0, 1],\n                                      [0, 0, 1]])\n\n    mesh = Mesh(data, remove_empty_areas=False)\n    assert numpy.allclose(mesh.vectors, numpy.array([\n        [[0, 1, 1], [1, 0, 1], [0, 0, 1]]]))\n\n    # Transform mesh with identity matrix\n    mesh.transform(numpy.eye(4))\n    assert numpy.allclose(mesh.vectors, numpy.array([\n        [[0, 1, 1], [1, 0, 1], [0, 0, 1]]]))\n    assert numpy.allclose(mesh.areas, 0.5)\n\n\ndef test_transformation():\n    # Create a single face\n    data = numpy.zeros(1, dtype=Mesh.dtype)\n    data['vectors'][0] = numpy.array([[0, 1, 1],\n                                      [1, 0, 1],\n                                      [0, 0, 1]])\n\n    mesh = Mesh(data, remove_empty_areas=False)\n    assert numpy.allclose(mesh.vectors, numpy.array([\n        [[0, 1, 1], [1, 0, 1], [0, 0, 1]]]))\n\n    # Transform mesh with identity matrix\n    tr = numpy.zeros((4, 4))\n    tr[0:3, 0:3] = Mesh.rotation_matrix([0, 0, 1], 0.5 * numpy.pi)\n    tr[0:3, 3] = [1, 2, 3]\n    mesh.transform(tr)\n    assert numpy.allclose(mesh.vectors, numpy.array([\n        [[0, 2, 4], [1, 3, 4], [1, 2, 4]]]))\n    assert numpy.allclose(mesh.areas, 0.5)\n"""
tests/utils.py,0,"b""import numpy\n\n\ndef to_array(array, round):\n    __tracebackhide__ = True\n\n    if not isinstance(array, numpy.ndarray):\n        array = numpy.array(array)\n\n    if round:\n        array = array.round(round)\n\n    return array\n\n\ndef array_equals(left, right, round=6):\n    __tracebackhide__ = True\n    left = to_array(left, round)\n    right = to_array(right, round)\n\n    message = 'Arrays are unequal:\\n%s\\n%s' % (left, right)\n    if left.size == right.size:\n        message += '\\nDifference:\\n%s' % (left - right)\n\n    assert (left == right).all(), message\n"""
docs/_theme/flask_theme_support.py,0,"b'# flasky extensions.  flasky pygments style based on tango style\nfrom pygments.style import Style\nfrom pygments.token import Keyword, Name, Comment, String, Error, \\\n    Number, Operator, Generic, Whitespace, Punctuation, Other, Literal\n\n\nclass FlaskyStyle(Style):\n    background_color = ""#f8f8f8""\n    default_style = """"\n\n    styles = {\n        # No corresponding class for the following:\n        # Text:                     """", # class:  \'\'\n        Whitespace:                ""underline #f8f8f8"",      # class: \'w\'\n        Error:                     ""#a40000 border:#ef2929"",  # class: \'err\'\n        Other:                     ""#000000"",                # class \'x\'\n\n        Comment:                   ""italic #8f5902"",  # class: \'c\'\n        Comment.Preproc:           ""noitalic"",       # class: \'cp\'\n\n        Keyword:                   ""bold #004461"",   # class: \'k\'\n        Keyword.Constant:          ""bold #004461"",   # class: \'kc\'\n        Keyword.Declaration:       ""bold #004461"",   # class: \'kd\'\n        Keyword.Namespace:         ""bold #004461"",   # class: \'kn\'\n        Keyword.Pseudo:            ""bold #004461"",   # class: \'kp\'\n        Keyword.Reserved:          ""bold #004461"",   # class: \'kr\'\n        Keyword.Type:              ""bold #004461"",   # class: \'kt\'\n\n        Operator:                  ""#582800"",   # class: \'o\'\n        Operator.Word:             ""bold #004461"",   # class: \'ow\' - like keywords\n\n        Punctuation:               ""bold #000000"",   # class: \'p\'\n\n        # because special names such as Name.Class, Name.Function, etc.\n        # are not recognized as such later in the parsing, we choose them\n        # to look the same as ordinary variables.\n        Name:                      ""#000000"",        # class: \'n\'\n        Name.Attribute:            ""#c4a000"",        # class: \'na\' - to be revised\n        Name.Builtin:              ""#004461"",        # class: \'nb\'\n        Name.Builtin.Pseudo:       ""#3465a4"",        # class: \'bp\'\n        Name.Class:                ""#000000"",        # class: \'nc\' - to be revised\n        Name.Constant:             ""#000000"",        # class: \'no\' - to be revised\n        Name.Decorator:            ""#888"",           # class: \'nd\' - to be revised\n        Name.Entity:               ""#ce5c00"",        # class: \'ni\'\n        Name.Exception:            ""bold #cc0000"",   # class: \'ne\'\n        Name.Function:             ""#000000"",        # class: \'nf\'\n        Name.Property:             ""#000000"",        # class: \'py\'\n        Name.Label:                ""#f57900"",        # class: \'nl\'\n        Name.Namespace:            ""#000000"",        # class: \'nn\' - to be revised\n        Name.Other:                ""#000000"",        # class: \'nx\'\n        Name.Tag:                  ""bold #004461"",   # class: \'nt\' - like a keyword\n        Name.Variable:             ""#000000"",        # class: \'nv\' - to be revised\n        Name.Variable.Class:       ""#000000"",        # class: \'vc\' - to be revised\n        Name.Variable.Global:      ""#000000"",        # class: \'vg\' - to be revised\n        Name.Variable.Instance:    ""#000000"",        # class: \'vi\' - to be revised\n\n        Number:                    ""#990000"",        # class: \'m\'\n\n        Literal:                   ""#000000"",        # class: \'l\'\n        Literal.Date:              ""#000000"",        # class: \'ld\'\n\n        String:                    ""#4e9a06"",        # class: \'s\'\n        String.Backtick:           ""#4e9a06"",        # class: \'sb\'\n        String.Char:               ""#4e9a06"",        # class: \'sc\'\n        String.Doc:                ""italic #8f5902"",  # class: \'sd\' - like a comment\n        String.Double:             ""#4e9a06"",        # class: \'s2\'\n        String.Escape:             ""#4e9a06"",        # class: \'se\'\n        String.Heredoc:            ""#4e9a06"",        # class: \'sh\'\n        String.Interpol:           ""#4e9a06"",        # class: \'si\'\n        String.Other:              ""#4e9a06"",        # class: \'sx\'\n        String.Regex:              ""#4e9a06"",        # class: \'sr\'\n        String.Single:             ""#4e9a06"",        # class: \'s1\'\n        String.Symbol:             ""#4e9a06"",        # class: \'ss\'\n\n        Generic:                   ""#000000"",        # class: \'g\'\n        Generic.Deleted:           ""#a40000"",        # class: \'gd\'\n        Generic.Emph:              ""italic #000000"",  # class: \'ge\'\n        Generic.Error:             ""#ef2929"",        # class: \'gr\'\n        Generic.Heading:           ""bold #000080"",   # class: \'gh\'\n        Generic.Inserted:          ""#00A000"",        # class: \'gi\'\n        Generic.Output:            ""#888"",           # class: \'go\'\n        Generic.Prompt:            ""#745334"",        # class: \'gp\'\n        Generic.Strong:            ""bold #000000"",   # class: \'gs\'\n        Generic.Subheading:        ""bold #800080"",   # class: \'gu\'\n        Generic.Traceback:         ""bold #a40000"",   # class: \'gt\'\n    }\n'"
