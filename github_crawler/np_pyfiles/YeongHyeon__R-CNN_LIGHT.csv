file_path,api_count,code
LEGACY/custom_convnet.py,12,"b'# coding: utf-8\nimport sys, os\nsys.path.append(os.pardir)\nimport pickle\nimport numpy as np\nfrom collections import OrderedDict\nfrom common.layers import *\nfrom common.gradient import numerical_gradient\nfrom common.util import *\n\ndef he_stdev(node_num):\n    return np.sqrt(2)/np.sqrt(node_num)\n\nclass ConvNet:\n    """"""ConvNet class\n\n    < Model structure >\n    conv - relu - pool -\n    conv - relu - pool -\n    conv - relu - pool -\n    affine - softmax\n\n    Parameters\n    ----------\n    input_size : 784 (like MNIST\xef\xbc\x89\n    hidden_size_list : number of hidden neurans\xef\xbc\x88e.g. [100, 100, 100]\xef\xbc\x89\n    output_size : classes\n    activation : \'relu\' or \'sigmoid\'\n    weight_init_std : specifies the standard deviation of the weight (eg 0.01)\n    """"""\n    def __init__(self, input_dim=(3, 28, 28),\n                 conv_param={\'filter_num\':30, \'filter_size\':5, \'pad\':0, \'stride\':1},\n                 pool_size=2,\n                 hidden_size=100, output_size=10, weight_init_std=0.01):\n        print(""\\n***** Network *****"")\n        print("" Input  : ""+ str(input_dim))\n        print("" Output : (1, ""+ str(output_size)+"")\\n"")\n\n        # extract patameter from conv_param dictionary\n        filter_num = conv_param[\'filter_num\']\n        filter_size = conv_param[\'filter_size\']\n        filter_pad = conv_param[\'pad\'] # padding\n        filter_stride = conv_param[\'stride\']\n        input_size = input_dim[1]\n\n        # output_height = ((input_size - filter_size + 2*filter_pad) / filter_stride) + 1\n        # deep learning from scratch p.234\n        # Layer1\n        layer1_filter_num = filter_num*1\n        conv1_output_size = int(conv_out_size(input_size=input_size, filter_size=filter_size, filter_pad=filter_pad, filter_stride=filter_stride))\n        pool1_output_size = int(pool_out_size(conv_output_size=conv1_output_size, filter_pad=filter_pad, pool_size=pool_size))\n        # Layer2\n        layer2_filter_num = filter_num*2\n        conv2_output_size = int(conv_out_size(input_size=pool1_output_size, filter_size=filter_size, filter_pad=filter_pad, filter_stride=filter_stride))\n        pool2_output_size = int(pool_out_size(conv_output_size=conv2_output_size, filter_pad=filter_pad, pool_size=pool_size))\n        # Layer3\n        layer3_filter_num = filter_num*1\n        conv3_output_size = int(conv_out_size(input_size=pool2_output_size, filter_size=filter_size, filter_pad=filter_pad, filter_stride=filter_stride))\n        pool3_output_size = int(pool_out_size(conv_output_size=conv3_output_size, filter_pad=filter_pad, pool_size=pool_size))\n        # Laye4\n        layer4_input_size = int(layer3_filter_num * pool3_output_size * pool3_output_size)\n        # weight initialize with normal distribution\n        self.params = {}\n\n        # Layer1\n        # layer1_filter_num: number of weight filter (output tensor)\n        # input_dim[0]: channel (input tensor)\n        # filter_size: weight width and height\n        print("" Layer1: conv - relu - pool"")\n        print("" filter: %d x %d | input_dim: %d | output_dim: %d"" %(filter_size, filter_size, input_dim[0], layer1_filter_num))\n        self.params[\'W1\'] = np.random.randn(layer1_filter_num, input_dim[0], filter_size, filter_size) * he_stdev(input_dim[0])\n        self.params[\'b1\'] = np.zeros(layer1_filter_num)\n\n        # Layer2\n        # layer2_filter_num: number of weight filter (output tensor)\n        # layer1_filter_num: input tensor\n        # filter_size: weight width and height\n        print(""\\n Layer2: conv - relu - pool"")\n        print("" filter: %d x %d | input_dim: %d | output_dim: %d"" %(filter_size, filter_size, layer1_filter_num, layer2_filter_num))\n        self.params[\'W2\'] = np.random.randn(layer2_filter_num, layer1_filter_num, filter_size, filter_size) * he_stdev(layer1_filter_num)\n        self.params[\'b2\'] = np.zeros(layer2_filter_num)\n\n        # Layer3\n        # layer3_filter_num: number of weight filter (output tensor)\n        # layer2_filter_num: input tensor\n        # filter_size: weight width and height\n        print(""\\n Layer3: conv - relu - pool"")\n        print("" filter: %d x %d | input_dim: %d | output_dim: %d"" %(filter_size, filter_size, layer2_filter_num, layer3_filter_num))\n        self.params[\'W3\'] = np.random.randn(layer3_filter_num, layer2_filter_num, filter_size, filter_size) * he_stdev(layer2_filter_num)\n        self.params[\'b3\'] = np.zeros(layer3_filter_num)\n        # Layer4\n        # layer4_input_size: fully connected size (input matrix)\n        # output_size: output (output matrix)\n        print(""\\n Layer4: affine"")\n        print("" input: %d | output: %d"" %(layer4_input_size, output_size))\n        self.params[\'W4\'] = weight_init_std * np.random.randn(layer4_input_size, output_size)\n        self.params[\'b4\'] = np.zeros(output_size)\n\n        # Last layer is softmax\n        print(""\\n Last layer: softmax"")\n\n        # define layers\n        # Layer1\n        self.layers = OrderedDict()\n        self.layers[\'Conv1\'] = Convolution(self.params[\'W1\'], self.params[\'b1\'], conv_param[\'stride\'], conv_param[\'pad\'])\n        self.layers[\'Relu1\'] = Relu()\n        self.layers[\'Pool1\'] = Pooling(pool_h=pool_size, pool_w=pool_size, stride=2)\n        # Layer2\n        self.layers[\'Conv2\'] = Convolution(self.params[\'W2\'], self.params[\'b2\'], conv_param[\'stride\'], conv_param[\'pad\'])\n        self.layers[\'Relu2\'] = Relu()\n        self.layers[\'Pool2\'] = Pooling(pool_h=pool_size, pool_w=pool_size, stride=2)\n        # Layer3\n        self.layers[\'Conv3\'] = Convolution(self.params[\'W3\'], self.params[\'b3\'], conv_param[\'stride\'], conv_param[\'pad\'])\n        self.layers[\'Relu3\'] = Relu()\n        self.layers[\'Pool3\'] = Pooling(pool_h=pool_size, pool_w=pool_size, stride=2)\n        # Layer4\n        self.layers[\'Affine1\'] = Affine(self.params[\'W4\'], self.params[\'b4\'])\n        # Last Layer\n        self.last_layer = SoftmaxWithLoss()\n\n    def predict(self, x): # It used for predict loss and accuracy.\n        for layer in self.layers.values():\n            #print(""Input size: ""+str(x.shape)+"" | ""+str(x.shape))\n            x = layer.forward(x)\n\n        return x\n\n    # Compute loss\n    # x : input data\n    # t : input label\n    def loss(self, x, t):\n\n        y = self.predict(x)\n        return self.last_layer.forward(y, t)\n\n    # Compute accuracy\n    # x : input data\n    # t : input label\n    # batch_size : default value is 100\n    def accuracy(self, x, t, batch_size=100):\n        if t.ndim != 1 : t = np.argmax(t, axis=1)\n\n        acc = 0.0\n        for i in range(int(x.shape[0] / batch_size)):\n            tx = x[i*batch_size:(i+1)*batch_size]\n            tt = t[i*batch_size:(i+1)*batch_size]\n            y = self.predict(tx)\n            y = np.argmax(y, axis=1)\n            acc += np.sum(y == tt)\n\n        return acc / x.shape[0]\n\n    # Find Weight and Bias with Numerical differentiation method\n    # x : input data\n    # t : input label\n    def numerical_gradient(self, x, t):\n\n        loss_w = lambda w: self.loss(x, t)\n\n        grads = {}\n        for idx in (1, 2, 3):\n            grads[\'W\' + str(idx)] = numerical_gradient(loss_w, self.params[\'W\' + str(idx)])\n            grads[\'b\' + str(idx)] = numerical_gradient(loss_w, self.params[\'b\' + str(idx)])\n\n        return grads\n\n    # Find Weight and Bias with back propagation method\n    # x : input data\n    # t : input label\n    def gradient(self, x, t):\n\n        # forward\n        self.loss(x, t)\n\n        # backward\n        # last_layer: Softmax layer with loss\n        dout = 1\n        dout = self.last_layer.backward(dout)\n\n        layers = list(self.layers.values()) # return dictionary keywords\n        layers.reverse() # list upside down\n\n        # backward method compute each layer\'s Weight and Bias - dW, db\n        for layer in layers:\n            dout = layer.backward(dout)\n\n        # set gradients\n        grads = {}\n        # Layer1\n        grads[\'W1\'] = self.layers[\'Conv1\'].dW\n        grads[\'b1\'] = self.layers[\'Conv1\'].db\n        # Layer2\n        grads[\'W2\'] = self.layers[\'Conv2\'].dW\n        grads[\'b2\'] = self.layers[\'Conv2\'].db\n        # Layer3\n        grads[\'W3\'] = self.layers[\'Conv3\'].dW\n        grads[\'b3\'] = self.layers[\'Conv3\'].db\n        # Layer4\n        grads[\'W4\'] = self.layers[\'Affine1\'].dW\n        grads[\'b4\'] = self.layers[\'Affine1\'].db\n\n        return grads\n\n    def save_params(self, file_name=""params.pkl""):\n        # make dictionary\n        # params is not self.params\n        params = {}\n\n        # extract key and values from self.params and initialize dictionary\n        # .values : return key only\n        # .items(): return key and value\n        for key, val in self.params.items():\n            params[key] = val\n\n        # save dictionary to file\n        with open(file_name, \'wb\') as f:\n            pickle.dump(params, f)\n\n    def load_params(self, file_name=""params.pkl""):\n        # load dictionary to file\n        with open(file_name, \'rb\') as f:\n            params = pickle.load(f)\n\n        # extract key and values from params and set to self.params\n        # .values : return key only\n        # .items(): return key and value\n        for key, val in params.items():\n            self.params[key] = val\n\n        # initialize layers with Weight and Bias\n        # [\'Conv1\', \'Conv2\', \'Affine1\'] are not in pkl file\n        for i, key in enumerate([\'Conv1\', \'Conv2\', \'Conv3\', \'Affine1\']):\n            self.layers[key].W = self.params[\'W\' + str(i+1)]\n            self.layers[key].b = self.params[\'b\' + str(i+1)]\n'"
LEGACY/dataset_loader.py,15,"b'from datetime import datetime\nimport hashlib\nimport inspect, os\nimport random\nimport re\nimport struct\nimport sys\nimport shutil\n\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow as tf\n\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.util import compat\n\nimport cv2\nimport matplotlib.image as mpimg\n\nMAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1  # ~134M\n\ndef create_image_lists(image_dir, testing_percentage, validation_percentage):\n    """"""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py""""""\n\n    """"""Builds a list of training images from the file system.\n    Analyzes the sub folders in the image directory, splits them into stable\n    training, testing, and validation sets, and returns a data structure\n    describing the lists of images for each label and their paths.\n    Args:\n    image_dir: String path to a folder containing subfolders of images.\n    testing_percentage: Integer percentage of the images to reserve for tests.\n    validation_percentage: Integer percentage of images reserved for validation.\n    Returns:\n    A dictionary containing an entry for each label subfolder, with images split\n    into training, testing, and validation sets within each label.\n    """"""\n    print(""\\n***** Create image lists *****"")\n\n    if not gfile.Exists(image_dir):\n        print(""Image directory \'"" + image_dir + ""\' not found."")\n        return None\n    result = {}\n    sub_dirs = [x[0] for x in gfile.Walk(image_dir)]\n    # The root directory comes first, so skip it.\n    is_root_dir = True\n    for sub_dir in sub_dirs:\n        if is_root_dir:\n            is_root_dir = False\n            continue\n        extensions = [\'jpg\', \'jpeg\', \'JPG\', \'JPEG\']\n        file_list = []\n        dir_name = os.path.basename(sub_dir)\n        if dir_name == image_dir:\n            continue\n        print("" Looking for images in \'"" + dir_name + ""\'"")\n        for extension in extensions:\n            file_glob = os.path.join(image_dir, dir_name, \'*.\' + extension)\n            file_list.extend(gfile.Glob(file_glob))\n        if not file_list:\n            print(\' No files found\')\n            continue\n        if len(file_list) < 20:\n            print(\' WARNING: Folder has less than 20 images, which may cause issues.\')\n        elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n            print(\' WARNING: Folder {} has more than {} images. Some images will \'\n                \'never be selected.\'.format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n        label_name = re.sub(r\'[^a-z0-9]+\', \' \', dir_name.lower())\n        training_images = []\n        testing_images = []\n        validation_images = []\n        for file_name in file_list:\n            base_name = os.path.basename(file_name)\n            # We want to ignore anything after \'_nohash_\' in the file name when\n            # deciding which set to put an image in, the data set creator has a way of\n            # grouping photos that are close variations of each other. For example\n            # this is used in the plant disease data set to group multiple pictures of\n            # the same leaf.\n            hash_name = re.sub(r\'_nohash_.*$\', \'\', file_name)\n            # This looks a bit magical, but we need to decide whether this file should\n            # go into the training, testing, or validation sets, and we want to keep\n            # existing files in the same set even if more files are subsequently\n            # added.\n            # To do that, we need a stable way of deciding based on just the file name\n            # itself, so we do a hash of that and then use that to generate a\n            # probability value that we use to assign it.\n            hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n            percentage_hash = ((int(hash_name_hashed, 16) %\n                              (MAX_NUM_IMAGES_PER_CLASS + 1)) *\n                             (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n            if percentage_hash < validation_percentage:\n                validation_images.append(base_name)\n            elif percentage_hash < (testing_percentage + validation_percentage):\n                testing_images.append(base_name)\n            else:\n                training_images.append(base_name)\n        result[label_name] = {\n            \'dir\': dir_name,\n            \'training\': training_images,\n            \'testing\': testing_images,\n            \'validation\': validation_images,\n        }\n    return result\n\ndef key_from_dictionary(dictionary):\n    print(""\\n***** Extract keys *****"")\n    master_key = list(dictionary.keys())\n    sub_key = list(dictionary[master_key[0]].keys())\n\n    print("" Master Key is..."")\n    print("" ""+str(master_key))\n    print("" Sub Key is..."")\n    print("" ""+str(sub_key))\n\n    return master_key, sub_key\n\ndef image_save(path, imagename, matrix):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    cv2.imwrite(path+imagename, matrix)\n\ndef imagelist_to_dataset(image_dir, image_lists, imsize=28):\n    master_key, sub_key = key_from_dictionary(image_lists)\n\n    print(""\\n***** Make image list *****"")\n    result_dir = ""dataset/""\n    if not os.path.exists(result_dir):\n        os.makedirs(result_dir)\n    else:\n        shutil.rmtree(result_dir)\n        os.makedirs(result_dir)\n\n    x_train = []\n    t_train = np.empty((0), int)\n    x_test = []\n    t_test = np.empty((0), int)\n    x_valid = []\n    t_valid = np.empty((0), int)\n    for key_i in [0, 1, 3]:\n        if key_i == 0:\n            result_name = ""train""\n        elif key_i == 1:\n            result_name = ""test""\n        else:\n            result_name = ""valid""\n        sys.stdout.write("" Make \\\'""+result_name+"" list\\\'..."")\n        # m: class\n        for m in master_key:\n\n                for i in range(len(image_lists[m][sub_key[key_i]])):\n                    # m: category\n                    # image_lists[m][sub_key[key_i]][i]: image name\n                    image_path = ""./""+image_dir+""/""+m+""/""+image_lists[m][sub_key[key_i]][i]\n                    # Read jpg images and resizing it.\n                    origin_image = cv2.imread(image_path)\n                    resized_image = cv2.resize(origin_image, (imsize, imsize))\n                    grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n\n                    image_save(result_dir+""origin/""+result_name+""/"", image_lists[m][sub_key[key_i]][i], origin_image)\n                    image_save(result_dir+""resize/""+result_name+""/"", image_lists[m][sub_key[key_i]][i], resized_image)\n                    image_save(result_dir+""gray/""+result_name+""/"", image_lists[m][sub_key[key_i]][i], grayscale_image)\n\n                    if key_i == 0:\n                        x_train.append(resized_image)\n                        t_train = np.append(t_train, np.array([int(np.asfarray(m))]), axis=0)\n                    elif key_i == 1:\n                        x_test.append(resized_image)\n                        t_test = np.append(t_test, np.array([int(np.asfarray(m))]), axis=0)\n                    else:\n                        x_valid.append(resized_image)\n                        t_valid = np.append(t_valid, np.array([int(np.asfarray(m))]), axis=0)\n\n        print("" complete."")\n    #print("" x_train shape: "" + str(np.array(x_train).shape))\n    #print("" t_train shape: "" + str(np.array(t_train).shape))\n    #print("" x_test shape: "" + str(np.array(x_test).shape))\n    #print("" t_test shape: "" + str(np.array(t_test).shape))\n    x_train = np.asarray(x_train)\n    t_train = np.asarray(t_train)\n    x_test = np.asarray(x_test)\n    t_test = np.asarray(t_test)\n    return (x_train, t_train), (x_test, t_test), len(master_key)\n\ndef imagelist_to_tensor(image_dir, image_lists, imsize=28):\n    X_data = []\n    files = glob.glob (""*.jpg"")\n    for myFile in files:\n        image = cv2.imread (myFile)\n        X_data.append (image)\n\n    print(\'X_data shape:\', np.array(X_data).shape)\n\ndef dataset(image_dir, test_percentage, validation_percentage, imsize=28):\n    test_percentage = 10\n    validation_percentage = 10\n    # Look at the folder structure, and create lists of all the images.\n    image_lists = create_image_lists(image_dir, test_percentage, validation_percentage)\n\n    (x_train, t_train), (x_test, t_test), classes = imagelist_to_dataset(image_dir=image_dir, image_lists=image_lists, imsize=imsize)\n    print(""\\n Data set is ready!"")\n    print("" Data for train : "" + str(x_train.shape[0]))\n    print("" Data for test  : "" + str(x_test.shape[0]))\n\n    return (x_train, t_train), (x_test, t_test), classes\n\n#=========================================\n#              *** main ***\n#=========================================\nif __name__ == ""__main__"":\n    dataset(""images"", 10, 10)\n'"
LEGACY/developed.py,0,"b'stamp=""""""\nDeveloped by...\n  _ _ __ __  _ _ ____   _  _ _ _ __ __  _ _\n | | | _|   \\ \\ |  __| | || | | | _|   \\ \\ |\n |  / _| () |   | |_ | |    |  / _| () |   |  _\n|__/____|__ /_|_|____| |_||_/_/____|__ /_|_| (_)\n""""""\n\ndef print_stamp():\n    print(stamp)\n    print(""https://github.com/YeongHyeon/R-CNN_LIGHT"")\n'"
LEGACY/run_r-cnn.py,11,"b'import developed\ndeveloped.print_stamp()\n\n# coding: utf-8\nimport sys, os, inspect, argparse\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nsys.path.append(os.pardir)\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom dataset_loader import dataset\nfrom custom_convnet import ConvNet # import convolution neural network class\nfrom common.trainer import Trainer # import trainer class\nfrom common.functions import *\nfrom common.util import shuffle_dataset\nimport cv2\nfrom scipy.spatial import distance as dist\nfrom datetime import datetime\nimport time\n""""""\nThis project is designed to detect user\'s blinking in the video.\nIf you want to fix it, you can do it.(You want to detect something else ...)\nIt should be noted that the complexity of CNN has been reduced for real-time processing.\nSo please understand if you have a little lack of accuracy.\n\nAlthough tensorflow api is required in this project, tensorflow is not used at all in training.\nTensorflow only uses images to distinguish them for testing validation for training, and also reveals the source of the function.\nTensorflow used in the \'dataset_loader\' module.\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py\n""""""\n\n""""""\n\'PACK_PATH\' is a variable that tells you where your package is located.\nPlease use it well.\nFor example, when saving an image ...\n""""""\nPACK_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n\nnetwork = None\nimsize = 32\n\nclasses = 0 # I recommend that you do not modify the dataset because it is automatically updated during the configuration process.\n""""""\nThe first data I provide is features of the face such as eyes, nose, and mouth.\nIf you are reorganizing the data, please modify the strings in this list. (The \'class_name\')\n""""""\nclass_name = [\'Close\', \'Open\', \'Eyebrow\', \'Nose\', \'Mouth\', \'Hair\', \'Background\']\n\nframe = None\nstd_time = 0\n\ndef chenneling(x):\n    """"""\n    This function makes the dataset suitable for training.\n    Especially, gray scale image does not have channel information.\n    This function forces one channel to be created for gray scale images.\n    """"""\n\n    # if grayscale image\n    if(len(x.shape) == 3):\n        C = 1\n        N, H, W = x.shape\n        x = np.asarray(x).reshape((N, H, W, C))\n    else: # color image\n        pass\n\n    x = x.transpose(0, 3, 1, 2)\n\n    x = x.astype(float)\n\n    return x\n\ndef frame_predict(origin_image, network, imsize=28):\n    """"""\n    It takes an image similar to each class and returns the most similar class value.\n    """"""\n\n    resized_image = cv2.resize(origin_image, (imsize, imsize))\n\n    if(len(resized_image.shape) == 2):\n        N = 1\n        C = 1\n        H, W = resized_image.shape\n        resized_image = np.asarray(resized_image).reshape((N, H, W, C))\n    else:\n        N = 1\n        H, W, C = resized_image.shape\n        resized_image = np.asarray(resized_image).reshape((N, H, W, C))\n\n    resized_image = resized_image.transpose(0, 3, 1, 2)\n    resized_image = resized_image.astype(float)\n\n    img_predict = network.predict(resized_image)\n    predict_sm = softmax(img_predict)\n\n    predict_list = []\n    for idx in range(len(predict_sm[0])):\n        predict_list.append(predict_sm[0][idx])\n\n    max_class = predict_list.index(max(predict_list))\n    return max_class, max(predict_list)\n\n# Image save Function\ndef image_save(label=None, matrix=None):\n    """"""\n    You can use it to check if the image is well classified.\n    You will be hard categorized in the place where you saved the package, so check it in.\n    """"""\n\n    now = datetime.now()\n    filename = now.strftime(\'%Y%m%d_%H%M%S%f\')+"".jpg""\n    directory = PACK_PATH+\'/frames/\'\n    if(label!=None):\n        directory += \'/\'+str(label)+\'/\'\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    cv2.imwrite(directory+filename, matrix)\n    return directory+filename\n\ndef draw_classification(frame=None, x=0, y=0, w=0, h=0, result=None, acc=None, txt_color=(0,0,0)):\n    cv2.rectangle(frame,(x,y),(x+w,y+h),(255, 255, 255),1)\n    cv2.putText(frame, class_name[result]+"" ""+str(int(acc*100))+""%"", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 3)\n    cv2.putText(frame, class_name[result]+"" ""+str(int(acc*100))+""%"", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, txt_color, 2)\n\ndef erosion(binary_img=None, k_size=5, iterations=1):\n\n    kernel = np.ones((k_size, k_size),np.uint8)\n\n    return cv2.erode(binary_img, kernel, iterations=iterations)\n\ndef dilation(binary_img=None, k_size=5, iterations=1):\n\n    kernel = np.ones((k_size, k_size),np.uint8)\n\n    return cv2.dilate(binary_img, kernel, iterations=iterations)\n\ndef custom_opeing(binary_img=None, ero_size=5, dil_size=5, iterations=1):\n\n    ero_kernel = np.ones((ero_size, ero_size),np.uint8)\n    dil_kernel = np.ones((dil_size, dil_size),np.uint8)\n\n    tmp_ero = cv2.erode(binary_img, ero_kernel, iterations=iterations)\n\n    return cv2.dilate(tmp_ero, dil_kernel, iterations=iterations)\n\ndef custom_closing(binary_img=None, ero_size=5, dil_size=5, iterations=1):\n\n    ero_kernel = np.ones((ero_size, ero_size),np.uint8)\n    dil_kernel = np.ones((dil_size, dil_size),np.uint8)\n\n    tmp_dil = cv2.dilate(binary_img, dil_kernel, iterations=iterations)\n\n    return cv2.erode(tmp_dil, ero_kernel, iterations=iterations)\n\ndef classification_by_contour(origin, imsize=28):\n    """"""\n    Referenced by http://docs.opencv.org/trunk/d7/d4d/tutorial_py_thresholding.html\n    """"""\n\n    global frame, network, std_time\n    kernel, closing = None, None\n    gray = cv2.cvtColor(origin, cv2.COLOR_BGR2GRAY)\n\n    gray_blur = cv2.GaussianBlur(gray, (11, 11), 0)\n    thresh = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 5, 1)\n\n    opened = custom_opeing(binary_img=thresh, ero_size=3, dil_size=7, iterations=1)\n\n    contours, hierarchy = cv2.findContours(opened, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n\n    boxes = []\n    pad = 15\n    std_time = time.time()\n    pre_cnt = 0\n    for cnt in contours:\n        area = cv2.contourArea(cnt)\n        if((area < 50) or (area > 2500)):\n            continue\n        x, y, w, h = cv2.boundingRect(cnt)\n        x, y, w, h = x-pad, y-pad, w+pad, h+pad\n        if((x > 0) and (y > 0)):\n            if((x < origin.shape[1]) and (y < origin.shape[0])):\n                if(w > h*1.2):\n                    result, acc = frame_predict(origin[y:y+h, x:x+w], network, imsize=imsize)\n                    pre_cnt += 1\n                    if(acc > 0.80):\n                        """"""Try annotating when you want to check if the classification is working.""""""\n                        #image_save(label=result, matrix=origin[y:y+h, x:x+w])\n                        boxes.append([x, y, w, h, result, acc])\n\n    #print("" %.3f [classify/sec]"" %(pre_cnt/(time.time() - std_time)))\n    sys.stdout.write(\' %.3f [classify/sec]\\r\' %(pre_cnt/(time.time() - std_time)))\n    sys.stdout.flush()\n\n    txt_color=(0, 0, 0)\n    eye_cnt = 0\n    boxes = sorted(boxes, key=lambda l:l[4], reverse=True)\n    boxes = sorted(boxes, key=lambda l:l[5], reverse=True)\n    for b in boxes:\n        x, y, w, h, result, acc = b\n        #cv2.rectangle(frame, (x,y-15), (x+w,y), (255, 255, 255), cv2.cv.CV_FILLED)\n\n        if((result == 0) or ((result == 1))):\n\n            eye_cnt += 1\n            #if(eye_cnt > 2):\n            #    break\n\n            if(result == 0):\n                txt_color=(0, 0, 255)\n            elif(result == 1):\n                txt_color=(255, 0, 0)\n            draw_classification(frame=frame, x=x, y=y, w=w, h=h, result=result, acc=acc, txt_color=txt_color)\n\n        elif(not((result == 0) or ((result == 1)))):\n\n            txt_color=(100, 100, 100)\n            draw_classification(frame=frame, x=x, y=y, w=w, h=h, result=result, acc=acc, txt_color=txt_color)\n\n    #cv2.imshow(""Thresh"", thresh)\n    #cv2.imshow(""Closing"", closing)\n\n\ndef cnn_constructor():\n    """"""\n    Referenced by https://github.com/oreilly-japan/deep-learning-from-scratch\n    common modules referenced there too.\n    """"""\n\n    global network, classes, imsize\n\n    (x_train, t_train), (x_test, t_test), classes = dataset(image_dir=""images"", test_percentage=10, validation_percentage=10, imsize=imsize)\n\n    x_train = chenneling(x_train)\n    x_test = chenneling(x_test)\n\n    train_num = x_train.shape[0]\n    test_num = x_test.shape[0]\n\n    x_train, t_train = shuffle_dataset(x_train, t_train)\n    x_test, t_test = shuffle_dataset(x_test, t_test)\n\n    net_param = ""cnn_params""+str(imsize)+"".pkl""\n    if not os.path.exists(""params/""):\n        os.makedirs(""params/"")\n\n    # make convolution eural network\n    # x_train.shape[1:] returns channel, height, width\n    network = ConvNet(input_dim=(x_train.shape[1:]),\n                            conv_param = {\'filter_num\': 20, \'filter_size\': 3, \'pad\': 0, \'stride\': 1},\n                            hidden_size=32, output_size=classes, weight_init_std=0.001)\n\n    trainer = Trainer(network, x_train, t_train, x_test, t_test,\n                      epochs=1, mini_batch_size=FLAGS.batch_size,\n                      optimizer=\'Adam\', optimizer_param={\'lr\': 0.001},\n                      evaluate_sample_num_per_epoch=train_num)\n\n    params_loaded = False\n    if not os.path.exists(""params/""):\n        os.makedirs(""params/"")\n    if(os.path.exists(""params/""+net_param)):\n        network.load_params(""params/""+net_param)\n        params_loaded = True\n        print(""\\n* Loaded Network Parameters!  -  ""+net_param)\n    if((FLAGS.train_epochs > 0) or (params_loaded == False)):\n        if(FLAGS.train_epochs <= 0):\n            FLAGS.train_epochs = 10\n        # Training\n        for ep in range(FLAGS.train_epochs):\n            trainer.train()\n            # Save parameters\n            network.save_params(""params/""+net_param)\n\n            # plot graphs\n            # Grpah 1: Accuracy\n            markers = {\'train\': \'o\', \'test\': \'s\', \'loss\': \'d\'}\n            x1 = np.arange(len(trainer.train_acc_list))\n            plt.clf()\n            plt.plot(x1, trainer.train_acc_list, marker=\'o\', label=\'train\', markevery=1)\n            plt.plot(x1, trainer.test_acc_list, marker=\'s\', label=\'test\', markevery=1)\n            plt.xlabel(""epochs"")\n            plt.ylabel(""accuracy"")\n            plt.ylim(0, 1.1)\n            plt.legend(loc=\'lower right\')\n            plt.title(""Accuracy"")\n            now = datetime.now()\n            filename = ""params/""+now.strftime(\'%Y%m%d_%H%M%S%f\')+""_""+""ep""+"".png""\n            plt.savefig(filename)\n            #plt.show()\n\n            # Graph 2: Loss\n            x2 = np.arange(len(trainer.train_loss_list))\n            plt.clf()\n            plt.plot(x2, trainer.train_loss_list, marker=\'o\', label=\'loss\', markevery=1)\n            plt.xlabel(""iter"")\n            plt.ylabel(""loss"")\n            plt.legend(loc=\'lower right\')\n            plt.title(""Cross entropy loss"")\n            now = datetime.now()\n            filename = ""params/""+now.strftime(\'%Y%m%d_%H%M%S%f\')+""_""+""ep""+"".png""\n            plt.savefig(filename)\n            #plt.show()\n        print(""\\n* Saved Network Parameters!  -  ""+net_param)\n\ndef main(source=0):\n    global frame\n\n    width_half = 25\n    height_half = 25\n\n    print(""Video source: ""+str(source))\n    camera = cv2.VideoCapture(source)\n\n    cv2.namedWindow(""frame"")\n\n    while True:\n\n        (grabbed, frame) = camera.read()\n\n        if((source == 0) or (source == 1)):\n            frame = cv2.flip(frame,1)\n\n        if not grabbed:\n            break\n\n        classification_by_contour(frame, imsize=imsize)\n\n        cv2.imshow(""frame"", frame)\n\n        key = cv2.waitKey(1) & 0xFF\n        # press \'p\' to Pause\n        if(key == ord(""p"")):\n            cv2.waitKey(0)\n        # press \'q\' to Quit\n        elif(key == ord(""q"")):\n    \t\tprint(""\\nQUIT"")\n    \t\tbreak\n\n    # cleanup the camera and close any open windows\n    camera.release()\n    cv2.destroyAllWindows()\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--train_epochs\', type=int, default=0, help=\'Default: 0. If you enter a value greater than 0, training proceeds.\')\n    parser.add_argument(\'--batch_size\', type=int, default=10, help=\'Default: 10. Batches per iteration, the number of data to be training and testing.\')\n    parser.add_argument(\'--source\', type=str, default="""", help=\'Default is webcam streaming. You can enter the path of the vedio for run it.\')\n    FLAGS, unparsed = parser.parse_known_args()\n\n    if(len(FLAGS.source) <= 0):\n        FLAGS.source = 0\n    elif(len(FLAGS.source) == 1):\n        FLAGS.source = int(FLAGS.source)\n\n    cnn_constructor()\n\n    main(source=FLAGS.source)\n'"
Refactoring/run.py,0,"b'import sys, os, inspect, argparse\nPACK_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\nsys.path.append(PACK_PATH+""/source"")\n\nimport developed\ndeveloped.print_stamp()\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# custom modules\nimport utility\nimport data_handler\nimport model\nimport sub_procedure\nimport webcam\n\ndef main():\n\n    extensions = [\'jpg\', \'jpeg\', \'JPG\', \'JPEG\']\n\n    print("""")\n\n    if((not(data_handler.check())) or (FLAGS.make)):\n        path = raw_input(""Enter the source path: "")\n        data_handler.make(path=path, height=32, width=32, extensions=extensions, clone=FLAGS.boost)\n\n    dataset = data_handler.load()\n\n    sess = tf.InteractiveSession()\n\n    data_size, height, width, channel = dataset.train.data_size\n    classes = dataset.train.class_num\n\n    data = tf.placeholder(tf.float32, shape=[None, data_size])\n    label = tf.placeholder(tf.float32, shape=[None, classes])\n    training = tf.placeholder(tf.bool)\n\n    train_step, accuracy, loss, prediction = model.convolution_neural_network(x=data, y_=label, training=training, height=height, width=width, channel=channel, classes=classes)\n\n    sess.run(tf.global_variables_initializer())\n\n    saver = tf.train.Saver()\n\n    print("""")\n    user_need_train = raw_input(""Do you want to train? Y/N: "")\n    if((user_need_train == ""Y"") or (user_need_train == ""y"")):\n        sub_procedure.training_process(sess=sess, dataset=dataset, x=data, y_=label, training=training, train_step=train_step, accuracy=accuracy, loss=loss, saver=saver, batch_size=FLAGS.batch, epochs=FLAGS.epochs)\n\n    print("""")\n    user_need_valid = raw_input(""Do you want to validation? Y/N: "")\n    if((user_need_valid == ""Y"") or (user_need_valid == ""y"")):\n        sub_procedure.prediction_process(sess=sess, dataset=dataset, x=data, y_=label, training=training, prediction=prediction, saver=saver, validation=FLAGS.validation)\n\n    if(os.path.exists(PACK_PATH+""/checkpoint/checker.index"")):\n        webcam.webcam_main(sess=sess, x_holder=data, training=training, prediction=prediction, saver=saver)\n    else:\n        print(""You must training first!"")\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--make\', type=bool, default=False, help=\'Default: False. Enter True to update the dataset.\')\n    parser.add_argument(\'--boost\', type=int, default=0, help=\'Default: 0. \')\n    parser.add_argument(\'--batch\', type=int, default=10, help=\'Default: 10. Batches per iteration, the number of data to be training and testing.\')\n    parser.add_argument(\'--epochs\', type=int, default=100, help=\'Default: 100\')\n    parser.add_argument(\'--validation\', type=int, default=0, help=\'Default: 0\')\n    FLAGS, unparsed = parser.parse_known_args()\n\n    main()\n'"
LEGACY/common/__init__.py,0,b''
LEGACY/common/functions.py,15,"b'# coding: utf-8\nimport numpy as np\nfrom scipy.special import expit, logit\n\ndef identity_function(x):\n    return x\n\n\ndef step_function(x):\n    return np.array(x > 0, dtype=np.int)\n\n\ndef sigmoid(x):\n    #return 1 / (1 + np.expit(-x))\n    return expit(x) # expit (x) = 1 / (1 + exp (-x))\n\n\ndef sigmoid_grad(x):\n    return (1.0 - sigmoid(x)) * sigmoid(x)\n\n\ndef relu(x):\n    return np.maximum(0, x)\n\ndef relu_grad(x):\n    #grad = np.zeros(x) # origin\n    grad = np.zeros(x.shape) # modify\n    grad[x>=0] = 1\n    return grad\n\n\ndef softmax(x):\n    if x.ndim == 2:\n        x = x.T\n        x = x - np.max(x, axis=0)\n        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n        return y.T\n\n    x = x - np.max(x) # Prevent overflow\n    return np.exp(x) / np.sum(np.exp(x))\n\n\ndef mean_squared_error(y, t):\n    return 0.5 * np.sum((y-t)**2)\n\n\ndef cross_entropy_error(y, t):\n\n    if y.ndim == 1:\n        t = t.reshape(1, t.size)\n        y = y.reshape(1, y.size)\n\n    if t.size == y.size:\n        t = t.argmax(axis=1)\n\n    batch_size = y.shape[0]\n    # y[np.arange(batch_size), t] -> [0, t[0]], [1, t[1]], [2, t[2]], [3, t[3]]...\n    """"""\n    numpy.log(x) means ln(x)\n    ln(x) = log(x) * log(e)\n    e = lim(1+x)^(1/x)  -(when x->0)\n    """"""\n    # np.log(y) -> np.log([n, m]) -> [np.log(n), np.log(m)]\n    # np.sum(log) -> np.log(n) + np.log(m) + ...\n    delta = 1e-7 #prevent infinite value\n    nn_out = y[np.arange(batch_size), t]\n    return -np.sum(np.log(nn_out+delta)) / batch_size\n\ndef softmax_loss(X, t):\n    y = softmax(X)\n    return cross_entropy_error(y, t)\n'"
LEGACY/common/gradient.py,4,"b""# coding: utf-8\nimport numpy as np\n\ndef _numerical_gradient_1d(f, x):\n    h = 1e-4 # 0.0001\n    grad = np.zeros_like(x)\n    \n    for idx in range(x.size):\n        tmp_val = x[idx]\n        x[idx] = float(tmp_val) + h\n        fxh1 = f(x) # f(x+h)\n        \n        x[idx] = tmp_val - h \n        fxh2 = f(x) # f(x-h)\n        grad[idx] = (fxh1 - fxh2) / (2*h)\n        \n        x[idx] = tmp_val # \xe5\x80\xa4\xe3\x82\x92\xe5\x85\x83\xe3\x81\xab\xe6\x88\xbb\xe3\x81\x99\n        \n    return grad\n\n\ndef numerical_gradient_2d(f, X):\n    if X.ndim == 1:\n        return _numerical_gradient_1d(f, X)\n    else:\n        grad = np.zeros_like(X)\n        \n        for idx, x in enumerate(X):\n            grad[idx] = _numerical_gradient_1d(f, x)\n        \n        return grad\n\n\ndef numerical_gradient(f, x):\n    h = 1e-4 # 0.0001\n    grad = np.zeros_like(x)\n    \n    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n    while not it.finished:\n        idx = it.multi_index\n        tmp_val = x[idx]\n        x[idx] = float(tmp_val) + h\n        fxh1 = f(x) # f(x+h)\n        \n        x[idx] = tmp_val - h \n        fxh2 = f(x) # f(x-h)\n        grad[idx] = (fxh1 - fxh2) / (2*h)\n        \n        x[idx] = tmp_val # \xe5\x80\xa4\xe3\x82\x92\xe5\x85\x83\xe3\x81\xab\xe6\x88\xbb\xe3\x81\x99\n        it.iternext()   \n        \n    return grad"""
LEGACY/common/layers.py,22,"b'# coding: utf-8\nimport numpy as np\nfrom common.functions import *\nfrom common.util import im2col, col2im\n\n\nclass Relu:\n    def __init__(self):\n        self.mask = None\n\n    def forward(self, x):\n        self.mask = (x <= 0)\n        out = x.copy()\n        out[self.mask] = 0\n\n        return out\n\n    def backward(self, dout):\n        dout[self.mask] = 0\n        dx = dout\n\n        return dx\n\n\nclass Sigmoid:\n    def __init__(self):\n        self.out = None\n\n    def forward(self, x):\n        out = sigmoid(x)\n        self.out = out\n        return out\n\n    def backward(self, dout):\n        dx = dout * (1.0 - self.out) * self.out\n\n        return dx\n\n\nclass Affine:\n    def __init__(self, W, b):\n        self.W =W\n        self.b = b\n\n        self.x = None\n        self.original_x_shape = None\n\n        # Differential Weight and Bias parameter\n        self.dW = None\n        self.db = None\n\n    def forward(self, x):\n        self.original_x_shape = x.shape\n        x = x.reshape(x.shape[0], -1)\n        self.x = x\n        out = np.dot(self.x, self.W) + self.b\n\n        return out\n\n    def backward(self, dout):\n        # inner product dout with transpose\n        dx = np.dot(dout, self.W.T)\n        self.dW = np.dot(self.x.T, dout)\n        self.db = np.sum(dout, axis=0)\n\n        # Restoration in the form of input data (tensor correspondence)\n        dx = dx.reshape(*self.original_x_shape)\n        return dx\n\n\nclass SoftmaxWithLoss:\n    def __init__(self):\n        self.loss = None\n        self.y = None # softmax output\n        self.t = None # label\n\n    def forward(self, x, t):\n        self.t = t\n        self.y = softmax(x)\n        self.loss = cross_entropy_error(self.y, self.t)\n\n        return self.loss\n\n    def backward(self, dout=1):\n        batch_size = self.t.shape[0]\n        if self.t.size == self.y.size: # if label is one-hot-vector style\n            dx = (self.y - self.t) / batch_size\n        else:\n            dx = self.y.copy()\n            dx[np.arange(batch_size), self.t] -= 1\n            dx = dx / batch_size\n\n        return dx\n\n\nclass Dropout:\n    """"""\n    http://arxiv.org/abs/1207.0580\n    """"""\n    def __init__(self, dropout_ratio=0.5):\n        self.dropout_ratio = dropout_ratio\n        self.mask = None\n\n    def forward(self, x, train_flg=True):\n        if train_flg:\n            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n            return x * self.mask\n        else:\n            return x * (1.0 - self.dropout_ratio)\n\n    def backward(self, dout):\n        return dout * self.mask\n\n\nclass BatchNormalization:\n    """"""\n    http://arxiv.org/abs/1502.03167\n    """"""\n    def __init__(self, gamma, beta, momentum=0.9, running_mean=None, running_var=None):\n        self.gamma = gamma\n        self.beta = beta\n        self.momentum = momentum\n\n        # 4d in conv layer, others are 2d\n        self.input_shape = None\n\n        # test variables: mean, variance\n        self.running_mean = running_mean\n        self.running_var = running_var\n\n        # middle data used when backward\n        self.batch_size = None\n        self.xc = None\n        self.std = None\n        self.dgamma = None\n        self.dbeta = None\n\n    def forward(self, x, train_flg=True):\n        self.input_shape = x.shape\n        if x.ndim != 2:\n            N, C, H, W = x.shape\n            x = x.reshape(N, -1)\n\n        out = self.__forward(x, train_flg)\n\n        return out.reshape(*self.input_shape)\n\n    def __forward(self, x, train_flg):\n        if self.running_mean is None:\n            N, D = x.shape\n            self.running_mean = np.zeros(D)\n            self.running_var = np.zeros(D)\n\n        if train_flg:\n            mu = x.mean(axis=0)\n            xc = x - mu\n            var = np.mean(xc**2, axis=0)\n            std = np.sqrt(var + 10e-7)\n            xn = xc / std\n\n            self.batch_size = x.shape[0]\n            self.xc = xc\n            self.xn = xn\n            self.std = std\n            self.running_mean = self.momentum * self.running_mean + (1-self.momentum) * mu\n            self.running_var = self.momentum * self.running_var + (1-self.momentum) * var\n        else:\n            xc = x - self.running_mean\n            xn = xc / ((np.sqrt(self.running_var + 10e-7)))\n\n        out = self.gamma * xn + self.beta\n        return out\n\n    def backward(self, dout):\n        if dout.ndim != 2:\n            N, C, H, W = dout.shape\n            dout = dout.reshape(N, -1)\n\n        dx = self.__backward(dout)\n\n        dx = dx.reshape(*self.input_shape)\n        return dx\n\n    def __backward(self, dout):\n        dbeta = dout.sum(axis=0)\n        dgamma = np.sum(self.xn * dout, axis=0)\n        dxn = self.gamma * dout\n        dxc = dxn / self.std\n        dstd = -np.sum((dxn * self.xc) / (self.std * self.std), axis=0)\n        dvar = 0.5 * dstd / self.std\n        dxc += (2.0 / self.batch_size) * self.xc * dvar\n        dmu = np.sum(dxc, axis=0)\n        dx = dxc - dmu / self.batch_size\n\n        self.dgamma = dgamma\n        self.dbeta = dbeta\n\n        return dx\n\n\nclass Convolution:\n    def __init__(self, W, b, stride=1, pad=0):\n        self.W = W\n        self.b = b\n        self.stride = stride\n        self.pad = pad\n\n        # Middle data used when backward\n        self.x = None\n        self.col = None\n        self.col_W = None\n\n        # Differential data\n        self.dW = None\n        self.db = None\n\n    def forward(self, x):\n        FN, C, FH, FW = self.W.shape # 30, 1, 5, 5\n        N, C, H, W = x.shape\n        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n\n        """"""\n        im2col method 4d to 2d\n        input: (batch size, input_filternum, input height, input width)\n        output: (output height * output width * batch size, filter_h * filter_w * input_filternum)\n\n        input_filternum == channel num\n        """"""\n        col = im2col(x, FH, FW, self.stride, self.pad)\n        col_W = self.W.reshape(FN, -1).T\n        out = np.dot(col, col_W) + self.b\n        # reshape to tensor\n        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n\n        self.x = x\n        self.col = col\n        self.col_W = col_W\n\n        return out\n\n    def backward(self, dout):\n        FN, C, FH, FW = self.W.shape\n        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n\n        self.db = np.sum(dout, axis=0)\n        self.dW = np.dot(self.col.T, dout)\n        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n\n        dcol = np.dot(dout, self.col_W.T)\n        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n\n        return dx\n\n\nclass Pooling:\n    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n        self.pool_h = pool_h\n        self.pool_w = pool_w\n        self.stride = stride\n        self.pad = pad\n\n        self.x = None\n        self.arg_max = None\n\n    def forward(self, x):\n        N, C, H, W = x.shape\n        out_h = int(1 + (H - self.pool_h) / self.stride)\n        out_w = int(1 + (W - self.pool_w) / self.stride)\n\n        """"""\n        im2col method 4d to 2d\n        input: (batch size, input_filternum, input height, input width)\n        output: (output height * output width * batch size, pool_h * pool_w * input_filternum)\n\n        input_filternum == channel num\n        """"""\n        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n        col = col.reshape(-1, self.pool_h*self.pool_w)\n\n        arg_max = np.argmax(col, axis=1)\n        out = np.max(col, axis=1)\n        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n\n        self.x = x\n        self.arg_max = arg_max\n        return out\n\n    def backward(self, dout):\n        dout = dout.transpose(0, 2, 3, 1)\n\n        pool_size = self.pool_h * self.pool_w\n        dmax = np.zeros((dout.size, pool_size))\n        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n        dmax = dmax.reshape(dout.shape + (pool_size,))\n\n        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n\n        return dx\n'"
LEGACY/common/multi_layer_net.py,8,"b'# coding: utf-8\nimport sys, os\nsys.path.append(os.pardir)  # \xe8\xa6\xaa\xe3\x83\x87\xe3\x82\xa3\xe3\x83\xac\xe3\x82\xaf\xe3\x83\x88\xe3\x83\xaa\xe3\x81\xae\xe3\x83\x95\xe3\x82\xa1\xe3\x82\xa4\xe3\x83\xab\xe3\x82\x92\xe3\x82\xa4\xe3\x83\xb3\xe3\x83\x9d\xe3\x83\xbc\xe3\x83\x88\xe3\x81\x99\xe3\x82\x8b\xe3\x81\x9f\xe3\x82\x81\xe3\x81\xae\xe8\xa8\xad\xe5\xae\x9a\nimport numpy as np\nfrom collections import OrderedDict\nfrom common.layers import *\nfrom common.gradient import numerical_gradient\n\n\nclass MultiLayerNet:\n    """"""\xe5\x85\xa8\xe7\xb5\x90\xe5\x90\x88\xe3\x81\xab\xe3\x82\x88\xe3\x82\x8b\xe5\xa4\x9a\xe5\xb1\xa4\xe3\x83\x8b\xe3\x83\xa5\xe3\x83\xbc\xe3\x83\xa9\xe3\x83\xab\xe3\x83\x8d\xe3\x83\x83\xe3\x83\x88\xe3\x83\xaf\xe3\x83\xbc\xe3\x82\xaf\n\n    Parameters\n    ----------\n    input_size : \xe5\x85\xa5\xe5\x8a\x9b\xe3\x82\xb5\xe3\x82\xa4\xe3\x82\xba\xef\xbc\x88MNIST\xe3\x81\xae\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf784\xef\xbc\x89\n    hidden_size_list : \xe9\x9a\xa0\xe3\x82\x8c\xe5\xb1\xa4\xe3\x81\xae\xe3\x83\x8b\xe3\x83\xa5\xe3\x83\xbc\xe3\x83\xad\xe3\x83\xb3\xe3\x81\xae\xe6\x95\xb0\xe3\x81\xae\xe3\x83\xaa\xe3\x82\xb9\xe3\x83\x88\xef\xbc\x88e.g. [100, 100, 100]\xef\xbc\x89\n    output_size : \xe5\x87\xba\xe5\x8a\x9b\xe3\x82\xb5\xe3\x82\xa4\xe3\x82\xba\xef\xbc\x88MNIST\xe3\x81\xae\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf10\xef\xbc\x89\n    activation : \'relu\' or \'sigmoid\'\n    weight_init_std : \xe9\x87\x8d\xe3\x81\xbf\xe3\x81\xae\xe6\xa8\x99\xe6\xba\x96\xe5\x81\x8f\xe5\xb7\xae\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xef\xbc\x88e.g. 0.01\xef\xbc\x89\n        \'relu\'\xe3\x81\xbe\xe3\x81\x9f\xe3\x81\xaf\'he\'\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xe3\x81\x97\xe3\x81\x9f\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf\xe3\x80\x8cHe\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\xe3\x80\x8d\xe3\x82\x92\xe8\xa8\xad\xe5\xae\x9a\n        \'sigmoid\'\xe3\x81\xbe\xe3\x81\x9f\xe3\x81\xaf\'xavier\'\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xe3\x81\x97\xe3\x81\x9f\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf\xe3\x80\x8cXavier\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\xe3\x80\x8d\xe3\x82\x92\xe8\xa8\xad\xe5\xae\x9a\n    weight_decay_lambda : Weight Decay\xef\xbc\x88L2\xe3\x83\x8e\xe3\x83\xab\xe3\x83\xa0\xef\xbc\x89\xe3\x81\xae\xe5\xbc\xb7\xe3\x81\x95\n    """"""\n    def __init__(self, input_size, hidden_size_list, output_size,\n                 activation=\'relu\', weight_init_std=\'relu\', weight_decay_lambda=0):\n        self.input_size = input_size\n        self.output_size = output_size\n        self.hidden_size_list = hidden_size_list\n        self.hidden_layer_num = len(hidden_size_list)\n        self.weight_decay_lambda = weight_decay_lambda\n        self.params = {}\n\n        # \xe9\x87\x8d\xe3\x81\xbf\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x8c\x96\n        self.__init_weight(weight_init_std)\n\n        # \xe3\x83\xac\xe3\x82\xa4\xe3\x83\xa4\xe3\x81\xae\xe7\x94\x9f\xe6\x88\x90\n        activation_layer = {\'sigmoid\': Sigmoid, \'relu\': Relu}\n        self.layers = OrderedDict()\n        for idx in range(1, self.hidden_layer_num+1):\n            self.layers[\'Affine\' + str(idx)] = Affine(self.params[\'W\' + str(idx)],\n                                                      self.params[\'b\' + str(idx)])\n            self.layers[\'Activation_function\' + str(idx)] = activation_layer[activation]()\n\n        idx = self.hidden_layer_num + 1\n        self.layers[\'Affine\' + str(idx)] = Affine(self.params[\'W\' + str(idx)],\n            self.params[\'b\' + str(idx)])\n\n        self.last_layer = SoftmaxWithLoss()\n\n    def __init_weight(self, weight_init_std):\n        """"""\xe9\x87\x8d\xe3\x81\xbf\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\xe8\xa8\xad\xe5\xae\x9a\n\n        Parameters\n        ----------\n        weight_init_std : \xe9\x87\x8d\xe3\x81\xbf\xe3\x81\xae\xe6\xa8\x99\xe6\xba\x96\xe5\x81\x8f\xe5\xb7\xae\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xef\xbc\x88e.g. 0.01\xef\xbc\x89\n            \'relu\'\xe3\x81\xbe\xe3\x81\x9f\xe3\x81\xaf\'he\'\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xe3\x81\x97\xe3\x81\x9f\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf\xe3\x80\x8cHe\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\xe3\x80\x8d\xe3\x82\x92\xe8\xa8\xad\xe5\xae\x9a\n            \'sigmoid\'\xe3\x81\xbe\xe3\x81\x9f\xe3\x81\xaf\'xavier\'\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xe3\x81\x97\xe3\x81\x9f\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf\xe3\x80\x8cXavier\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\xe3\x80\x8d\xe3\x82\x92\xe8\xa8\xad\xe5\xae\x9a\n        """"""\n        all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]\n        for idx in range(1, len(all_size_list)):\n            scale = weight_init_std\n            if str(weight_init_std).lower() in (\'relu\', \'he\'):\n                scale = np.sqrt(2.0 / all_size_list[idx - 1])  # ReLU\xe3\x82\x92\xe4\xbd\xbf\xe3\x81\x86\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xab\xe6\x8e\xa8\xe5\xa5\xa8\xe3\x81\x95\xe3\x82\x8c\xe3\x82\x8b\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\n            elif str(weight_init_std).lower() in (\'sigmoid\', \'xavier\'):\n                scale = np.sqrt(1.0 / all_size_list[idx - 1])  # sigmoid\xe3\x82\x92\xe4\xbd\xbf\xe3\x81\x86\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xab\xe6\x8e\xa8\xe5\xa5\xa8\xe3\x81\x95\xe3\x82\x8c\xe3\x82\x8b\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\n\n            self.params[\'W\' + str(idx)] = scale * np.random.randn(all_size_list[idx-1], all_size_list[idx])\n            self.params[\'b\' + str(idx)] = np.zeros(all_size_list[idx])\n\n    def predict(self, x):\n        for layer in self.layers.values():\n            x = layer.forward(x)\n\n        return x\n\n    def loss(self, x, t):\n        """"""\xe6\x90\x8d\xe5\xa4\xb1\xe9\x96\xa2\xe6\x95\xb0\xe3\x82\x92\xe6\xb1\x82\xe3\x82\x81\xe3\x82\x8b\n\n        Parameters\n        ----------\n        x : \xe5\x85\xa5\xe5\x8a\x9b\xe3\x83\x87\xe3\x83\xbc\xe3\x82\xbf\n        t : \xe6\x95\x99\xe5\xb8\xab\xe3\x83\xa9\xe3\x83\x99\xe3\x83\xab\n\n        Returns\n        -------\n        \xe6\x90\x8d\xe5\xa4\xb1\xe9\x96\xa2\xe6\x95\xb0\xe3\x81\xae\xe5\x80\xa4\n        """"""\n        y = self.predict(x)\n\n        weight_decay = 0\n        for idx in range(1, self.hidden_layer_num + 2):\n            W = self.params[\'W\' + str(idx)]\n            weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W ** 2)\n\n        return self.last_layer.forward(y, t) + weight_decay\n\n    def accuracy(self, x, t):\n        y = self.predict(x)\n        y = np.argmax(y, axis=1)\n        if t.ndim != 1 : t = np.argmax(t, axis=1)\n\n        accuracy = np.sum(y == t) / float(x.shape[0])\n        return accuracy\n\n    def numerical_gradient(self, x, t):\n        """"""\xe5\x8b\xbe\xe9\x85\x8d\xe3\x82\x92\xe6\xb1\x82\xe3\x82\x81\xe3\x82\x8b\xef\xbc\x88\xe6\x95\xb0\xe5\x80\xa4\xe5\xbe\xae\xe5\x88\x86\xef\xbc\x89\n\n        Parameters\n        ----------\n        x : \xe5\x85\xa5\xe5\x8a\x9b\xe3\x83\x87\xe3\x83\xbc\xe3\x82\xbf\n        t : \xe6\x95\x99\xe5\xb8\xab\xe3\x83\xa9\xe3\x83\x99\xe3\x83\xab\n\n        Returns\n        -------\n        \xe5\x90\x84\xe5\xb1\xa4\xe3\x81\xae\xe5\x8b\xbe\xe9\x85\x8d\xe3\x82\x92\xe6\x8c\x81\xe3\x81\xa3\xe3\x81\x9f\xe3\x83\x87\xe3\x82\xa3\xe3\x82\xaf\xe3\x82\xb7\xe3\x83\xa7\xe3\x83\x8a\xe3\x83\xaa\xe5\xa4\x89\xe6\x95\xb0\n            grads[\'W1\']\xe3\x80\x81grads[\'W2\']\xe3\x80\x81...\xe3\x81\xaf\xe5\x90\x84\xe5\xb1\xa4\xe3\x81\xae\xe9\x87\x8d\xe3\x81\xbf\n            grads[\'b1\']\xe3\x80\x81grads[\'b2\']\xe3\x80\x81...\xe3\x81\xaf\xe5\x90\x84\xe5\xb1\xa4\xe3\x81\xae\xe3\x83\x90\xe3\x82\xa4\xe3\x82\xa2\xe3\x82\xb9\n        """"""\n        loss_W = lambda W: self.loss(x, t)\n\n        grads = {}\n        for idx in range(1, self.hidden_layer_num+2):\n            grads[\'W\' + str(idx)] = numerical_gradient(loss_W, self.params[\'W\' + str(idx)])\n            grads[\'b\' + str(idx)] = numerical_gradient(loss_W, self.params[\'b\' + str(idx)])\n\n        return grads\n\n    def gradient(self, x, t):\n        """"""\xe5\x8b\xbe\xe9\x85\x8d\xe3\x82\x92\xe6\xb1\x82\xe3\x82\x81\xe3\x82\x8b\xef\xbc\x88\xe8\xaa\xa4\xe5\xb7\xae\xe9\x80\x86\xe4\xbc\x9d\xe6\x90\xac\xe6\xb3\x95\xef\xbc\x89\n\n        Parameters\n        ----------\n        x : \xe5\x85\xa5\xe5\x8a\x9b\xe3\x83\x87\xe3\x83\xbc\xe3\x82\xbf\n        t : \xe6\x95\x99\xe5\xb8\xab\xe3\x83\xa9\xe3\x83\x99\xe3\x83\xab\n\n        Returns\n        -------\n        \xe5\x90\x84\xe5\xb1\xa4\xe3\x81\xae\xe5\x8b\xbe\xe9\x85\x8d\xe3\x82\x92\xe6\x8c\x81\xe3\x81\xa3\xe3\x81\x9f\xe3\x83\x87\xe3\x82\xa3\xe3\x82\xaf\xe3\x82\xb7\xe3\x83\xa7\xe3\x83\x8a\xe3\x83\xaa\xe5\xa4\x89\xe6\x95\xb0\n            grads[\'W1\']\xe3\x80\x81grads[\'W2\']\xe3\x80\x81...\xe3\x81\xaf\xe5\x90\x84\xe5\xb1\xa4\xe3\x81\xae\xe9\x87\x8d\xe3\x81\xbf\n            grads[\'b1\']\xe3\x80\x81grads[\'b2\']\xe3\x80\x81...\xe3\x81\xaf\xe5\x90\x84\xe5\xb1\xa4\xe3\x81\xae\xe3\x83\x90\xe3\x82\xa4\xe3\x82\xa2\xe3\x82\xb9\n        """"""\n        # forward\n        self.loss(x, t)\n\n        # backward\n        dout = 1\n        dout = self.last_layer.backward(dout)\n\n        layers = list(self.layers.values())\n        layers.reverse()\n        for layer in layers:\n            dout = layer.backward(dout)\n\n        # \xe8\xa8\xad\xe5\xae\x9a\n        grads = {}\n        for idx in range(1, self.hidden_layer_num+2):\n            grads[\'W\' + str(idx)] = self.layers[\'Affine\' + str(idx)].dW + self.weight_decay_lambda * self.layers[\'Affine\' + str(idx)].W\n            grads[\'b\' + str(idx)] = self.layers[\'Affine\' + str(idx)].db\n\n        return grads\n'"
LEGACY/common/multi_layer_net_extend.py,10,"b'# coding: utf-8\nimport sys, os\nsys.path.append(os.pardir) # \xe8\xa6\xaa\xe3\x83\x87\xe3\x82\xa3\xe3\x83\xac\xe3\x82\xaf\xe3\x83\x88\xe3\x83\xaa\xe3\x81\xae\xe3\x83\x95\xe3\x82\xa1\xe3\x82\xa4\xe3\x83\xab\xe3\x82\x92\xe3\x82\xa4\xe3\x83\xb3\xe3\x83\x9d\xe3\x83\xbc\xe3\x83\x88\xe3\x81\x99\xe3\x82\x8b\xe3\x81\x9f\xe3\x82\x81\xe3\x81\xae\xe8\xa8\xad\xe5\xae\x9a\nimport numpy as np\nfrom collections import OrderedDict\nfrom common.layers import *\nfrom common.gradient import numerical_gradient\n\nclass MultiLayerNetExtend:\n    """"""\xe6\x8b\xa1\xe5\xbc\xb5\xe7\x89\x88\xe3\x81\xae\xe5\x85\xa8\xe7\xb5\x90\xe5\x90\x88\xe3\x81\xab\xe3\x82\x88\xe3\x82\x8b\xe5\xa4\x9a\xe5\xb1\xa4\xe3\x83\x8b\xe3\x83\xa5\xe3\x83\xbc\xe3\x83\xa9\xe3\x83\xab\xe3\x83\x8d\xe3\x83\x83\xe3\x83\x88\xe3\x83\xaf\xe3\x83\xbc\xe3\x82\xaf\n    \n    Weiht Decay\xe3\x80\x81Dropout\xe3\x80\x81Batch Normalization\xe3\x81\xae\xe6\xa9\x9f\xe8\x83\xbd\xe3\x82\x92\xe6\x8c\x81\xe3\x81\xa4\n\n    Parameters\n    ----------\n    input_size : \xe5\x85\xa5\xe5\x8a\x9b\xe3\x82\xb5\xe3\x82\xa4\xe3\x82\xba\xef\xbc\x88MNIST\xe3\x81\xae\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf784\xef\xbc\x89\n    hidden_size_list : \xe9\x9a\xa0\xe3\x82\x8c\xe5\xb1\xa4\xe3\x81\xae\xe3\x83\x8b\xe3\x83\xa5\xe3\x83\xbc\xe3\x83\xad\xe3\x83\xb3\xe3\x81\xae\xe6\x95\xb0\xe3\x81\xae\xe3\x83\xaa\xe3\x82\xb9\xe3\x83\x88\xef\xbc\x88e.g. [100, 100, 100]\xef\xbc\x89\n    output_size : \xe5\x87\xba\xe5\x8a\x9b\xe3\x82\xb5\xe3\x82\xa4\xe3\x82\xba\xef\xbc\x88MNIST\xe3\x81\xae\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf10\xef\xbc\x89\n    activation : \'relu\' or \'sigmoid\'\n    weight_init_std : \xe9\x87\x8d\xe3\x81\xbf\xe3\x81\xae\xe6\xa8\x99\xe6\xba\x96\xe5\x81\x8f\xe5\xb7\xae\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xef\xbc\x88e.g. 0.01\xef\xbc\x89\n        \'relu\'\xe3\x81\xbe\xe3\x81\x9f\xe3\x81\xaf\'he\'\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xe3\x81\x97\xe3\x81\x9f\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf\xe3\x80\x8cHe\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\xe3\x80\x8d\xe3\x82\x92\xe8\xa8\xad\xe5\xae\x9a\n        \'sigmoid\'\xe3\x81\xbe\xe3\x81\x9f\xe3\x81\xaf\'xavier\'\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xe3\x81\x97\xe3\x81\x9f\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf\xe3\x80\x8cXavier\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\xe3\x80\x8d\xe3\x82\x92\xe8\xa8\xad\xe5\xae\x9a\n    weight_decay_lambda : Weight Decay\xef\xbc\x88L2\xe3\x83\x8e\xe3\x83\xab\xe3\x83\xa0\xef\xbc\x89\xe3\x81\xae\xe5\xbc\xb7\xe3\x81\x95\n    use_dropout: Dropout\xe3\x82\x92\xe4\xbd\xbf\xe7\x94\xa8\xe3\x81\x99\xe3\x82\x8b\xe3\x81\x8b\xe3\x81\xa9\xe3\x81\x86\xe3\x81\x8b\n    dropout_ration : Dropout\xe3\x81\xae\xe5\x89\xb2\xe3\x82\x8a\xe5\x90\x88\xe3\x81\x84\n    use_batchNorm: Batch Normalization\xe3\x82\x92\xe4\xbd\xbf\xe7\x94\xa8\xe3\x81\x99\xe3\x82\x8b\xe3\x81\x8b\xe3\x81\xa9\xe3\x81\x86\xe3\x81\x8b\n    """"""\n    def __init__(self, input_size, hidden_size_list, output_size,\n                 activation=\'relu\', weight_init_std=\'relu\', weight_decay_lambda=0, \n                 use_dropout = False, dropout_ration = 0.5, use_batchnorm=False):\n        self.input_size = input_size\n        self.output_size = output_size\n        self.hidden_size_list = hidden_size_list\n        self.hidden_layer_num = len(hidden_size_list)\n        self.use_dropout = use_dropout\n        self.weight_decay_lambda = weight_decay_lambda\n        self.use_batchnorm = use_batchnorm\n        self.params = {}\n\n        # \xe9\x87\x8d\xe3\x81\xbf\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x8c\x96\n        self.__init_weight(weight_init_std)\n\n        # \xe3\x83\xac\xe3\x82\xa4\xe3\x83\xa4\xe3\x81\xae\xe7\x94\x9f\xe6\x88\x90\n        activation_layer = {\'sigmoid\': Sigmoid, \'relu\': Relu}\n        self.layers = OrderedDict()\n        for idx in range(1, self.hidden_layer_num+1):\n            self.layers[\'Affine\' + str(idx)] = Affine(self.params[\'W\' + str(idx)],\n                                                      self.params[\'b\' + str(idx)])\n            if self.use_batchnorm:\n                self.params[\'gamma\' + str(idx)] = np.ones(hidden_size_list[idx-1])\n                self.params[\'beta\' + str(idx)] = np.zeros(hidden_size_list[idx-1])\n                self.layers[\'BatchNorm\' + str(idx)] = BatchNormalization(self.params[\'gamma\' + str(idx)], self.params[\'beta\' + str(idx)])\n                \n            self.layers[\'Activation_function\' + str(idx)] = activation_layer[activation]()\n            \n            if self.use_dropout:\n                self.layers[\'Dropout\' + str(idx)] = Dropout(dropout_ration)\n\n        idx = self.hidden_layer_num + 1\n        self.layers[\'Affine\' + str(idx)] = Affine(self.params[\'W\' + str(idx)], self.params[\'b\' + str(idx)])\n\n        self.last_layer = SoftmaxWithLoss()\n\n    def __init_weight(self, weight_init_std):\n        """"""\xe9\x87\x8d\xe3\x81\xbf\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\xe8\xa8\xad\xe5\xae\x9a\n\n        Parameters\n        ----------\n        weight_init_std : \xe9\x87\x8d\xe3\x81\xbf\xe3\x81\xae\xe6\xa8\x99\xe6\xba\x96\xe5\x81\x8f\xe5\xb7\xae\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xef\xbc\x88e.g. 0.01\xef\xbc\x89\n            \'relu\'\xe3\x81\xbe\xe3\x81\x9f\xe3\x81\xaf\'he\'\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xe3\x81\x97\xe3\x81\x9f\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf\xe3\x80\x8cHe\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\xe3\x80\x8d\xe3\x82\x92\xe8\xa8\xad\xe5\xae\x9a\n            \'sigmoid\'\xe3\x81\xbe\xe3\x81\x9f\xe3\x81\xaf\'xavier\'\xe3\x82\x92\xe6\x8c\x87\xe5\xae\x9a\xe3\x81\x97\xe3\x81\x9f\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xaf\xe3\x80\x8cXavier\xe3\x81\xae\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\xe3\x80\x8d\xe3\x82\x92\xe8\xa8\xad\xe5\xae\x9a\n        """"""\n        all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]\n        for idx in range(1, len(all_size_list)):\n            scale = weight_init_std\n            if str(weight_init_std).lower() in (\'relu\', \'he\'):\n                scale = np.sqrt(2.0 / all_size_list[idx - 1])  # ReLU\xe3\x82\x92\xe4\xbd\xbf\xe3\x81\x86\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xab\xe6\x8e\xa8\xe5\xa5\xa8\xe3\x81\x95\xe3\x82\x8c\xe3\x82\x8b\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\n            elif str(weight_init_std).lower() in (\'sigmoid\', \'xavier\'):\n                scale = np.sqrt(1.0 / all_size_list[idx - 1])  # sigmoid\xe3\x82\x92\xe4\xbd\xbf\xe3\x81\x86\xe5\xa0\xb4\xe5\x90\x88\xe3\x81\xab\xe6\x8e\xa8\xe5\xa5\xa8\xe3\x81\x95\xe3\x82\x8c\xe3\x82\x8b\xe5\x88\x9d\xe6\x9c\x9f\xe5\x80\xa4\n            self.params[\'W\' + str(idx)] = scale * np.random.randn(all_size_list[idx-1], all_size_list[idx])\n            self.params[\'b\' + str(idx)] = np.zeros(all_size_list[idx])\n\n    def predict(self, x, train_flg=False):\n        for key, layer in self.layers.items():\n            if ""Dropout"" in key or ""BatchNorm"" in key:\n                x = layer.forward(x, train_flg)\n            else:\n                x = layer.forward(x)\n\n        return x\n\n    def loss(self, x, t, train_flg=False):\n        """"""\xe6\x90\x8d\xe5\xa4\xb1\xe9\x96\xa2\xe6\x95\xb0\xe3\x82\x92\xe6\xb1\x82\xe3\x82\x81\xe3\x82\x8b\n        \xe5\xbc\x95\xe6\x95\xb0\xe3\x81\xaex\xe3\x81\xaf\xe5\x85\xa5\xe5\x8a\x9b\xe3\x83\x87\xe3\x83\xbc\xe3\x82\xbf\xe3\x80\x81t\xe3\x81\xaf\xe6\x95\x99\xe5\xb8\xab\xe3\x83\xa9\xe3\x83\x99\xe3\x83\xab\n        """"""\n        y = self.predict(x, train_flg)\n\n        weight_decay = 0\n        for idx in range(1, self.hidden_layer_num + 2):\n            W = self.params[\'W\' + str(idx)]\n            weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n\n        return self.last_layer.forward(y, t) + weight_decay\n\n    def accuracy(self, X, T):\n        Y = self.predict(X, train_flg=False)\n        Y = np.argmax(Y, axis=1)\n        if T.ndim != 1 : T = np.argmax(T, axis=1)\n\n        accuracy = np.sum(Y == T) / float(X.shape[0])\n        return accuracy\n\n    def numerical_gradient(self, X, T):\n        """"""\xe5\x8b\xbe\xe9\x85\x8d\xe3\x82\x92\xe6\xb1\x82\xe3\x82\x81\xe3\x82\x8b\xef\xbc\x88\xe6\x95\xb0\xe5\x80\xa4\xe5\xbe\xae\xe5\x88\x86\xef\xbc\x89\n\n        Parameters\n        ----------\n        X : \xe5\x85\xa5\xe5\x8a\x9b\xe3\x83\x87\xe3\x83\xbc\xe3\x82\xbf\n        T : \xe6\x95\x99\xe5\xb8\xab\xe3\x83\xa9\xe3\x83\x99\xe3\x83\xab\n\n        Returns\n        -------\n        \xe5\x90\x84\xe5\xb1\xa4\xe3\x81\xae\xe5\x8b\xbe\xe9\x85\x8d\xe3\x82\x92\xe6\x8c\x81\xe3\x81\xa3\xe3\x81\x9f\xe3\x83\x87\xe3\x82\xa3\xe3\x82\xaf\xe3\x82\xb7\xe3\x83\xa7\xe3\x83\x8a\xe3\x83\xaa\xe5\xa4\x89\xe6\x95\xb0\n            grads[\'W1\']\xe3\x80\x81grads[\'W2\']\xe3\x80\x81...\xe3\x81\xaf\xe5\x90\x84\xe5\xb1\xa4\xe3\x81\xae\xe9\x87\x8d\xe3\x81\xbf\n            grads[\'b1\']\xe3\x80\x81grads[\'b2\']\xe3\x80\x81...\xe3\x81\xaf\xe5\x90\x84\xe5\xb1\xa4\xe3\x81\xae\xe3\x83\x90\xe3\x82\xa4\xe3\x82\xa2\xe3\x82\xb9\n        """"""\n        loss_W = lambda W: self.loss(X, T, train_flg=True)\n\n        grads = {}\n        for idx in range(1, self.hidden_layer_num+2):\n            grads[\'W\' + str(idx)] = numerical_gradient(loss_W, self.params[\'W\' + str(idx)])\n            grads[\'b\' + str(idx)] = numerical_gradient(loss_W, self.params[\'b\' + str(idx)])\n            \n            if self.use_batchnorm and idx != self.hidden_layer_num+1:\n                grads[\'gamma\' + str(idx)] = numerical_gradient(loss_W, self.params[\'gamma\' + str(idx)])\n                grads[\'beta\' + str(idx)] = numerical_gradient(loss_W, self.params[\'beta\' + str(idx)])\n\n        return grads\n        \n    def gradient(self, x, t):\n        # forward\n        self.loss(x, t, train_flg=True)\n\n        # backward\n        dout = 1\n        dout = self.last_layer.backward(dout)\n\n        layers = list(self.layers.values())\n        layers.reverse()\n        for layer in layers:\n            dout = layer.backward(dout)\n\n        # \xe8\xa8\xad\xe5\xae\x9a\n        grads = {}\n        for idx in range(1, self.hidden_layer_num+2):\n            grads[\'W\' + str(idx)] = self.layers[\'Affine\' + str(idx)].dW + self.weight_decay_lambda * self.params[\'W\' + str(idx)]\n            grads[\'b\' + str(idx)] = self.layers[\'Affine\' + str(idx)].db\n\n            if self.use_batchnorm and idx != self.hidden_layer_num+1:\n                grads[\'gamma\' + str(idx)] = self.layers[\'BatchNorm\' + str(idx)].dgamma\n                grads[\'beta\' + str(idx)] = self.layers[\'BatchNorm\' + str(idx)].dbeta\n\n        return grads'"
LEGACY/common/optimizer.py,11,"b'# coding: utf-8\nimport numpy as np\n\nclass SGD:\n\n    """"""\xe7\xa2\xba\xe7\x8e\x87\xe7\x9a\x84\xe5\x8b\xbe\xe9\x85\x8d\xe9\x99\x8d\xe4\xb8\x8b\xe6\xb3\x95\xef\xbc\x88Stochastic Gradient Descent\xef\xbc\x89""""""\n\n    def __init__(self, lr=0.01):\n        self.lr = lr\n        \n    def update(self, params, grads):\n        for key in params.keys():\n            params[key] -= self.lr * grads[key] \n\n\nclass Momentum:\n\n    """"""Momentum SGD""""""\n\n    def __init__(self, lr=0.01, momentum=0.9):\n        self.lr = lr\n        self.momentum = momentum\n        self.v = None\n        \n    def update(self, params, grads):\n        if self.v is None:\n            self.v = {}\n            for key, val in params.items():                                \n                self.v[key] = np.zeros_like(val)\n                \n        for key in params.keys():\n            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key] \n            params[key] += self.v[key]\n\n\nclass Nesterov:\n\n    """"""Nesterov\'s Accelerated Gradient (http://arxiv.org/abs/1212.0901)""""""\n\n    def __init__(self, lr=0.01, momentum=0.9):\n        self.lr = lr\n        self.momentum = momentum\n        self.v = None\n        \n    def update(self, params, grads):\n        if self.v is None:\n            self.v = {}\n            for key, val in params.items():\n                self.v[key] = np.zeros_like(val)\n            \n        for key in params.keys():\n            self.v[key] *= self.momentum\n            self.v[key] -= self.lr * grads[key]\n            params[key] += self.momentum * self.momentum * self.v[key]\n            params[key] -= (1 + self.momentum) * self.lr * grads[key]\n\n\nclass AdaGrad:\n\n    """"""AdaGrad""""""\n\n    def __init__(self, lr=0.01):\n        self.lr = lr\n        self.h = None\n        \n    def update(self, params, grads):\n        if self.h is None:\n            self.h = {}\n            for key, val in params.items():\n                self.h[key] = np.zeros_like(val)\n            \n        for key in params.keys():\n            self.h[key] += grads[key] * grads[key]\n            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n\n\nclass RMSprop:\n\n    """"""RMSprop""""""\n\n    def __init__(self, lr=0.01, decay_rate = 0.99):\n        self.lr = lr\n        self.decay_rate = decay_rate\n        self.h = None\n        \n    def update(self, params, grads):\n        if self.h is None:\n            self.h = {}\n            for key, val in params.items():\n                self.h[key] = np.zeros_like(val)\n            \n        for key in params.keys():\n            self.h[key] *= self.decay_rate\n            self.h[key] += (1 - self.decay_rate) * grads[key] * grads[key]\n            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n\n\nclass Adam:\n\n    """"""Adam (http://arxiv.org/abs/1412.6980v8)""""""\n\n    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n        self.lr = lr\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.iter = 0\n        self.m = None\n        self.v = None\n        \n    def update(self, params, grads):\n        if self.m is None:\n            self.m, self.v = {}, {}\n            for key, val in params.items():\n                self.m[key] = np.zeros_like(val)\n                self.v[key] = np.zeros_like(val)\n        \n        self.iter += 1\n        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \n        \n        for key in params.keys():\n            #self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]\n            #self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)\n            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\n            \n            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n            \n            #unbias_m += (1 - self.beta1) * (grads[key] - self.m[key]) # correct bias\n            #unbisa_b += (1 - self.beta2) * (grads[key]*grads[key] - self.v[key]) # correct bias\n            #params[key] += self.lr * unbias_m / (np.sqrt(unbisa_b) + 1e-7)\n'"
LEGACY/common/trainer.py,1,"b'# coding: utf-8\nimport sys, os\nsys.path.append(os.pardir)\nimport numpy as np\nfrom common.optimizer import *\nimport matplotlib.pyplot as plt\n\n# Train neural network class\nclass Trainer:\n\n    def __init__(self, network, x_train, t_train, x_test, t_test,\n                 epochs=20, mini_batch_size=100,\n                 optimizer=\'SGD\', optimizer_param={\'lr\':0.01},\n                 evaluate_sample_num_per_epoch=None, verbose=True):\n        self.network = network\n        self.verbose = verbose # true: print all step, false: print nothing\n        self.x_train = x_train\n        self.t_train = t_train\n        self.x_test = x_test\n        self.t_test = t_test\n        self.epochs = epochs\n        self.batch_size = mini_batch_size\n        self.evaluate_sample_num_per_epoch = evaluate_sample_num_per_epoch\n\n        # optimzer\n        optimizer_class_dict = {\'sgd\':SGD, \'momentum\':Momentum, \'nesterov\':Nesterov,\n                                \'adagrad\':AdaGrad, \'rmsprpo\':RMSprop, \'adam\':Adam}\n        self.optimizer = optimizer_class_dict[optimizer.lower()](**optimizer_param)\n\n        self.train_size = x_train.shape[0]\n        self.iter_per_epoch = max(self.train_size / mini_batch_size, 1)\n        self.max_iter = int(epochs * self.iter_per_epoch)\n        self.current_iter = 0\n        self.current_epoch = 0\n\n        self.train_loss_list = []\n        self.train_acc_list = []\n        self.test_acc_list = []\n\n    def train_step(self):\n        batch_mask = np.random.choice(self.train_size, self.batch_size)\n        x_batch = self.x_train[batch_mask]\n        t_batch = self.t_train[batch_mask]\n\n        # Select method in ConvNet class- numerical_gradient or gradient\n        grads = self.network.gradient(x_batch, t_batch)\n        self.optimizer.update(self.network.params, grads)\n\n        loss = self.network.loss(x_batch, t_batch)\n        self.train_loss_list.append(loss)\n        #if self.verbose: print("" train loss:"" + str(loss))\n\n        if self.current_iter % self.iter_per_epoch == 0:\n            self.current_epoch += 1\n\n            x_train_sample, t_train_sample = self.x_train, self.t_train\n            x_test_sample, t_test_sample = self.x_test, self.t_test\n            if not self.evaluate_sample_num_per_epoch is None:\n                t = self.evaluate_sample_num_per_epoch\n                x_train_sample, t_train_sample = self.x_train[:t], self.t_train[:t]\n                x_test_sample, t_test_sample = self.x_test[:t], self.t_test[:t]\n\n            # default accuracy methos\'s batch_size = 100\n            train_acc = self.network.accuracy(x_train_sample, t_train_sample, batch_size=self.batch_size)\n            test_acc = self.network.accuracy(x_test_sample, t_test_sample, batch_size=self.batch_size)\n            self.train_acc_list.append(train_acc)\n            self.test_acc_list.append(test_acc)\n\n            if self.verbose: print(""* epoch:"" + str(self.current_epoch) + "", train acc: %.5f, test acc: %.5f"" %(train_acc, test_acc))\n        self.current_iter += 1\n\n    def train(self):\n        print(""\\n***** Training start *****"")\n        print("" Batch size: ""+str(self.batch_size))\n        for i in range(self.max_iter):\n            self.train_step()\n\n        test_acc = self.network.accuracy(self.x_test, self.t_test, batch_size=self.batch_size)\n\n        if self.verbose:\n            print(""\\n***** Final Test Accuracy *****"")\n            print("" test acc:"" + str(test_acc))\n'"
LEGACY/common/util.py,7,"b'# coding: utf-8\nimport numpy as np\n\ndef smooth_curve(x):\n    """""" Used to smooth the graph of the loss function\n\n    reference:http://glowingpython.blogspot.jp/2012/02/convolution-with-numpy.html\n    """"""\n    window_len = 11\n    s = np.r_[x[window_len-1:0:-1], x, x[-1:-window_len:-1]]\n    w = np.kaiser(window_len, 2)\n    y = np.convolve(w/w.sum(), s, mode=\'valid\')\n    return y[5:len(y)-5]\n\n\ndef shuffle_dataset(x, t):\n    """"""\n    Parameters\n    ----------\n    x : Image\n    t : Label\n\n    Returns\n    -------\n    x, t : Image and Label\n    """"""\n    permutation = np.random.permutation(x.shape[0])\n    x = x[permutation,:] if x.ndim == 2 else x[permutation,:,:,:]\n    t = t[permutation]\n\n    return x, t\n\ndef conv_output_size(input_size, filter_size, stride=1, pad=0):\n    return (input_size + 2*pad - filter_size) / stride + 1\n\n\ndef im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n    """"""\n\n    Parameters\n    ----------\n    input_data : 4d array (N, C, H, W)\n    filter_h : filter height\n    filter_w : filter width\n    stride\n    pad\n\n    Returns\n    -------\n    col : 2d array (N, Data)\n    """"""\n\n    N, C, H, W = input_data.shape\n    out_h = conv_out_size(H, filter_h, pad, stride)\n    out_w = conv_out_size(W, filter_w, pad, stride)\n    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], \'constant\')\n    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n\n    # y: filter height index\n    # x: filter width index\n    for y in range(filter_h): # 5\n        y_max = y + stride*out_h\n        for x in range(filter_w): # 5\n            x_max = x + stride*out_w\n            # get y to y_max (stride(interval) = 1)\n            # get x to x_max (stride(interval) = 1)\n            # 0 to 24 and (0 to 24, 1 to 25, 2 to 26, 3 to 27, 4 to 28)\n            # 1 to 25 and (0 to 24, 1 to 25, 2 to 26, 3 to 27, 4 to 28)\n            # 2 to 26 and (0 to 24, 1 to 25, 2 to 26, 3 to 27, 4 to 28)\n            # 3 to 27 and (0 to 24, 1 to 25, 2 to 26, 3 to 27, 4 to 28)\n            # 4 to 28 and (0 to 24, 1 to 25, 2 to 26, 3 to 27, 4 to 28)\n            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n\n    # col.transpose(0, 4, 5, 1, 2, 3):\n    # (N, C, filter_h, filter_w, out_h, out_w) -> (N, out_h, out_w, C, filter_h, filter_w)\n    # ------------------------------------------------------------------------------------\n    # reshape(N*out_h*out_w, -1):\n    # (N, out_h, out_w, C, filter_h, filter_w) -> (N * out_h * out_w, C * filter_h * filter_w)\n    # -1 means auto shaping (others)\n    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n\n    return col\n\n\ndef col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n    """"""\n\n    Parameters\n    ----------\n    col :\n    input_shape : input data (example: (10, 1, 28, 28))\n    filter_h : filter height\n    filter_w : filter width\n    stride\n    pad\n\n    Returns\n    -------\n\n    """"""\n    N, C, H, W = input_shape\n    out_h = (H + 2*pad - filter_h)//stride + 1\n    out_w = (W + 2*pad - filter_w)//stride + 1\n    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n\n    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n    for y in range(filter_h):\n        y_max = y + stride*out_h\n        for x in range(filter_w):\n            x_max = x + stride*out_w\n            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n\n    return img[:, :, pad:H + pad, pad:W + pad]\n\ndef conv_out_size(input_size, filter_size, filter_pad, filter_stride):\n    #output_height = ((input_size + 2*filter_pad - filter_size) / filter_stride) + 1\n    # deep learning from scratch p.234\n    return ((input_size - filter_size + 2*filter_pad) / filter_stride) + 1\n\ndef pool_out_size(conv_output_size, filter_pad, pool_size):\n    return (conv_output_size-2*filter_pad)/pool_size\n'"
Refactoring/source/constructor.py,5,"b'import numpy as np\nimport os, random, inspect\n\nfrom tensorflow.contrib.learn.python.learn.datasets import base\n\nPACK_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))+""/..""\n\nclass DataSet(object):\n\n    def __init__(self, who_am_i, class_len, data_len, height, width, chennel):\n\n        self._who_am_i = who_am_i\n        self._class_len = class_len\n        self._data_len = data_len\n        self._height = height\n        self._width = width\n        self._chennel = chennel\n\n    @property\n    def amount(self):\n        count = 0\n\n        f = open(PACK_PATH+""/dataset/""+str(self._who_am_i)+"".csv"", \'r\')\n        while True:\n            line = f.readline()\n            if not line: break\n            count = count + 1\n        f.close()\n\n        return count\n\n    @property\n    def class_num(self):\n        return self._class_len\n\n    @property\n    def data_size(self):\n        return self._data_len, self._height, self._width, self._chennel\n\n\n    def next_batch(self, batch_size=10, start=-1, end=-1, nth=-1):\n        data = np.empty((0, self._data_len), float)\n        label = np.empty((0, self._class_len), int)\n\n        with open(PACK_PATH+""/dataset/""+str(self._who_am_i)+"".csv"") as f:\n            lines = f.readlines()\n\n        if(nth == -1):\n            if((start == -1) and (end == -1)):\n                datas = random.sample(lines, batch_size)\n            else:\n                datas = lines[start:end]\n        else:\n            datas = []\n            datas.append(lines[nth])\n\n        for d in datas:\n            sv_data = d.split(\',\')\n            tmp_label = sv_data[0]\n            tmp_data = sv_data[1:len(sv_data)-1]\n\n            tmp_data = np.asarray(tmp_data).reshape((1, len(tmp_data)))\n\n            label = np.append(label, np.eye(self._class_len)[int(np.asfarray(tmp_label))].reshape(1, self._class_len), axis=0)\n            data = np.append(data, tmp_data, axis=0)\n\n        return data, label\n\ndef dataset_constructor():\n\n    f = open(PACK_PATH+""/dataset/format.txt"", \'r\')\n    class_len = int(f.readline())\n    data_len = int(f.readline())\n    height = int(f.readline())\n    width = int(f.readline())\n    chennel = int(f.readline())\n    f.close()\n\n    train = DataSet(who_am_i=""train"", class_len=class_len, data_len=data_len, height=height, width=width, chennel=chennel)\n    test = DataSet(who_am_i=""test"", class_len=class_len, data_len=data_len, height=height, width=width, chennel=chennel)\n    valid = DataSet(who_am_i=""valid"", class_len=class_len, data_len=data_len, height=height, width=width, chennel=chennel)\n\n    return base.Datasets(train=train, test=test, validation=valid)\n'"
Refactoring/source/cv_functions.py,8,"b'import cv2\n\nimport numpy as np\n\ndef rgb2gray(rgb=None):\n\n    return cv2.cvtColor(rgb, cv2.COLOR_BGR2GRAY)\n\ndef bluring(gray=None, k_size=11):\n\n    return cv2.GaussianBlur(gray, (k_size, k_size), 0)\n\ndef adaptiveThresholding(gray=None, neighbor=5, blur=False, k_size=3):\n\n    if(blur):\n        gray = cv2.GaussianBlur(gray, (k_size, k_size), 0)\n    return cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, neighbor, 1)\n\ndef erosion(binary_img=None, k_size=5, iterations=1):\n\n    kernel = np.ones((k_size, k_size),np.uint8)\n\n    return cv2.erode(binary_img, kernel, iterations=iterations)\n\ndef dilation(binary_img=None, k_size=5, iterations=1):\n\n    kernel = np.ones((k_size, k_size),np.uint8)\n\n    return cv2.dilate(binary_img, kernel, iterations=iterations)\n\ndef custom_opeing(binary_img=None, ero_size=5, dil_size=5, iterations=1):\n\n    ero_kernel = np.ones((ero_size, ero_size),np.uint8)\n    dil_kernel = np.ones((dil_size, dil_size),np.uint8)\n\n    tmp_ero = cv2.erode(binary_img, ero_kernel, iterations=iterations)\n\n    return cv2.dilate(tmp_ero, dil_kernel, iterations=iterations)\n\ndef custom_closing(binary_img=None, ero_size=5, dil_size=5, iterations=1):\n\n    ero_kernel = np.ones((ero_size, ero_size),np.uint8)\n    dil_kernel = np.ones((dil_size, dil_size),np.uint8)\n\n    tmp_dil = cv2.dilate(binary_img, dil_kernel, iterations=iterations)\n\n    return cv2.erode(tmp_dil, ero_kernel, iterations=iterations)\n\ndef opening(binary_img=None, k_size=2, iterations=1):\n\n    kernel = np.ones((k_size, k_size), np.uint8)\n\n    return cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, kernel, iterations=iterations) # iteration = loop\n\ndef closing(binary_img=None, k_size=2, iterations=1):\n\n    kernel = np.ones((k_size, k_size), np.uint8)\n\n    return cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel, iterations=iterations) # iteration = loop\n\ndef contouring(binary_img=None):\n\n    # return two values: contours, hierarchy\n    # cv2.RETR_EXTERNAL\n\n    return cv2.findContours(binary_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n\ndef contour2box(contours=None, padding=15):\n\n    boxes =[]\n    for cnt in contours:\n\n        area = cv2.contourArea(cnt)\n        if((area < 50) or (area > 2500)):\n            continue\n\n        x, y, w, h = cv2.boundingRect(cnt)\n        x, y, w, h = x-padding, y-padding, w+padding, h+padding\n        boxes.append([x, y, w, h])\n\n    return boxes\n'"
Refactoring/source/data_handler.py,0,"b'import os, glob, random, inspect, shutil\n\nimport cv2\nimport numpy as np\n\n# custom modules\nimport utility\nimport constructor\n\nPACK_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))+""/..""\n\ndef split_data(path=None, directories=None, extensions=None, clone=0):\n\n    print(""\\n** Split whole datas"")\n\n    if(not(os.path.exists(path))):\n        print(""Path not exists \\"""" + str(path) + ""\\"""")\n        return\n\n    for di in directories:\n        if(not(os.path.exists(PACK_PATH+""/train/""+di))):\n            os.mkdir(PACK_PATH+""/train/""+di)\n        if(not(os.path.exists(PACK_PATH+""/test/""+di))):\n            os.mkdir(PACK_PATH+""/test/""+di)\n        if(not(os.path.exists(PACK_PATH+""/valid/""+di))):\n            os.mkdir(PACK_PATH+""/valid/""+di)\n\n    for di in directories:\n        fi_list = utility.get_filelist(directory=path+""/""+di, extensions=extensions)\n\n        fi_list = random.sample(fi_list, len(fi_list))\n\n        tr_point = int(len(fi_list)*0.8)\n        te_point = int(len(fi_list)*0.9)\n        va_point = int(len(fi_list)*1.0)\n\n        train = fi_list[:tr_point]\n        test = fi_list[tr_point:te_point]\n        valid = fi_list[te_point:va_point]\n\n        utility.copy_file(train, PACK_PATH+""/train/""+di, clone=clone)\n        utility.copy_file(test, PACK_PATH+""/test/""+di, clone=clone)\n        utility.copy_file(valid, PACK_PATH+""/valid/""+di, clone=clone)\n\n    print(""Split the datas!"")\n\ndef make_dataset(category=None, dirlist=None, height=32, width=32, extensions=None):\n\n    print(""\\n** Make ""+category+"".csv"")\n\n    class_len = len(dirlist)\n    io_mode = ""w""\n    label_number = 0\n\n    for di in dirlist:\n        fi_list = utility.get_filelist(directory=PACK_PATH+""/""+category+""/""+di, extensions=extensions)\n\n        for fi in fi_list:\n\n            image = cv2.imread(fi)\n            resized_image = cv2.resize(image, (height, width))\n            height, width, chennel = resized_image.shape\n            resized_image = resized_image.reshape((height*width*chennel))\n\n            utility.save_dataset_to_csv(save_as=category, label=label_number, data=resized_image, mode=io_mode)\n            io_mode = ""a""\n\n        label_number += 1\n\n    if(os.path.exists(PACK_PATH+""/""+category)): # management storage\n        shutil.rmtree(PACK_PATH+""/""+category)\n\n    f = open(PACK_PATH+""/dataset/format.txt"", ""w"")\n    f.write(str(label_number))\n    f.write(""\\n"")\n    f.write(str(height*width*chennel))\n    f.write(""\\n"")\n    f.write(str(height))\n    f.write(""\\n"")\n    f.write(str(width))\n    f.write(""\\n"")\n    f.write(str(chennel))\n    f.close()\n\ndef check():\n\n    print(""\\n** Check dataset"")\n\n    check_path = PACK_PATH+""/dataset""\n    print(check_path)\n    in_data = 0\n    if(utility.check_directory(dir_name=check_path)):\n        for fi in glob.glob(check_path+""/*""):\n            in_data += 1\n\n    if(in_data >= 5):\n        return True\n    else:\n        return False\n\ndef make(path=None, height=32, width=32, extensions=None, clone=0):\n\n    print(""\\n** Make dataset"")\n\n    check_list = [""dataset"", ""train"", ""test"", ""valid""]\n    cate_list = [""train"", ""test"", ""valid""]\n    shuffle_list = [""train"", ""test""]\n\n    for ch in check_list:\n        utility.refresh_directory(PACK_PATH+""/""+ch)\n\n    dirlist = utility.get_dirlist(path=path)\n    split_data(path=path, directories=dirlist, extensions=extensions, clone=clone)\n\n    for di in dirlist:\n        fi_list = utility.get_filelist(directory=path+""/""+di, extensions=extensions)\n    print(""I got the standard shape!"")\n\n    for ca in cate_list:\n        make_dataset(category=ca, dirlist=dirlist, height=height, width=width, extensions=extensions)\n\n    for shu in shuffle_list:\n        utility.shuffle_csv(filename=PACK_PATH+""/dataset/""+shu)\n\ndef load():\n\n    print(""\\n** Load dataset"")\n\n    dataset = constructor.dataset_constructor()\n\n    print(""Num of Train datas : ""+str(dataset.train.amount))\n    print(""Num of Test  datas : ""+str(dataset.test.amount))\n    print(""Num of Valid datas : ""+str(dataset.validation.amount))\n\n    return dataset\n'"
Refactoring/source/developed.py,0,"b'stamp=""""""\nDeveloped by...\n  _ _ __ __  _ _ ____   _  _ _ _ __ __  _ _\n | | | _|   \\ \\ |  __| | || | | | _|   \\ \\ |\n |  / _| () |   | |_ | |    |  / _| () |   |  _\n|__/____|__ /_|_|____| |_||_/_/____|__ /_|_| (_)\n""""""\n\ndef print_stamp():\n    print(stamp)\n    print(""https://github.com/YeongHyeon/R-CNN_LIGHT"")\n'"
Refactoring/source/model.py,1,"b'import os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf\n\ndef convolution(inputs=None, filters=32, k_size=3, stride=1, padding=""same""):\n\n    """"""https://www.tensorflow.org/api_docs/python/tf/layers/conv1d""""""\n\n    # initializers.xavier_initializer()\n    # tf.contrib.keras.initializers.he_normal()\n\n    conv = tf.contrib.layers.conv2d(\n    inputs=inputs,\n    num_outputs=filters,\n    kernel_size=k_size,\n    stride=stride,\n    padding=padding,\n    data_format=None,\n    rate=1,\n    activation_fn=tf.nn.relu,\n    normalizer_fn=None,\n    normalizer_params=None,\n    weights_initializer=tf.contrib.keras.initializers.he_normal(),\n    weights_regularizer=None,\n    biases_initializer=tf.zeros_initializer(),\n    biases_regularizer=None,\n    reuse=None,\n    variables_collections=None,\n    outputs_collections=None,\n    trainable=True,\n    scope=None\n    )\n\n    print(""Convolution: ""+str(conv.shape))\n    return conv\n\ndef relu(inputs=None):\n\n    """"""https://www.tensorflow.org/api_docs/python/tf/nn/relu""""""\n\n    re = tf.nn.relu(\n    features=inputs,\n    name=None\n    )\n\n    print(""ReLU: ""+str(re.shape))\n    return re\n\ndef maxpool(inputs=None, pool_size=2):\n\n    """"""https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling1d""""""\n\n    maxp = tf.contrib.layers.max_pool2d(\n    inputs=inputs,\n    kernel_size=pool_size,\n    stride=pool_size,\n    padding=\'VALID\',\n    outputs_collections=None,\n    scope=None\n    )\n\n    print(""Max Pool: ""+str(maxp.shape))\n    return maxp\n\ndef avgpool(inputs=None, pool_size=2):\n\n    """"""https://www.tensorflow.org/api_docs/python/tf/layers/average_pooling1d""""""\n\n    avg = tf.contrib.layers.avg_pool2d(\n    inputs=inputs,\n    kernel_size=pool_size,\n    stride=pool_size,\n    padding=\'VALID\',\n    outputs_collections=None,\n    scope=None\n    )\n\n    print(""Average Pool: ""+str(avg.shape))\n    return avg\n\ndef flatten(inputs=None):\n\n    """"""https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten""""""\n\n    flat = tf.contrib.layers.flatten(inputs=inputs)\n\n    print(""Flatten: ""+str(flat.shape))\n    return flat\n\ndef fully_connected(inputs=None, num_outputs=None, activate_fn=None):\n\n    """"""https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected""""""\n\n    full_con = tf.contrib.layers.fully_connected(inputs=inputs, num_outputs=num_outputs, activation_fn=activate_fn)\n\n    print(""Fully Connected: ""+str(full_con.shape))\n    return full_con\n\ndef dropout(inputs=None, ratio=0.5, train=None):\n\n    """"""https://www.tensorflow.org/api_docs/python/tf/layers/dropout""""""\n\n    drop = tf.layers.dropout(\n    inputs=inputs,\n    rate=ratio,\n    noise_shape=None,\n    seed=None,\n    training=train,\n    name=None\n    )\n\n    print(""Dropout: ""+str(ratio))\n    return drop\n\ndef convolution_neural_network(x, y_, training=None, height=None, width=None, channel=None, classes=None):\n\n    print(""\\n** Initialize CNN Layers"")\n\n    channel = 3\n    x_data = tf.reshape(x, [-1, height, width, channel])\n    print(""Input: ""+str(x_data.shape))\n\n    conv_1 = convolution(inputs=x_data, filters=16, k_size=5, stride=1, padding=""same"")\n    maxpool_1 = maxpool(inputs=conv_1, pool_size=2)\n\n    conv_2 = convolution(inputs=maxpool_1, filters=32, k_size=5, stride=1, padding=""same"")\n    maxpool_2 = maxpool(inputs=conv_2, pool_size=2)\n\n    conv_3 = convolution(inputs=maxpool_2, filters=64, k_size=5, stride=1, padding=""same"")\n    maxpool_3 = maxpool(inputs=conv_3, pool_size=2)\n    drop_1 = dropout(inputs=maxpool_3, ratio=0.5, train=training)\n\n    flatten_layer = flatten(inputs=drop_1)\n\n    full_con = fully_connected(inputs=flatten_layer, num_outputs=classes, activate_fn=None)\n\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=full_con, labels=y_)\n    mean_loss = tf.reduce_mean(cross_entropy) # Equivalent to np.mean\n\n    train_step = tf.train.AdamOptimizer(0.0001, beta1=0.5).minimize(mean_loss)\n\n    prediction = tf.contrib.layers.softmax(full_con) # Want to prediction Use this!\n    correct_pred = tf.equal(tf.argmax(full_con, 1), tf.argmax(y_, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n    return train_step, accuracy, mean_loss, prediction\n'"
Refactoring/source/sub_procedure.py,8,"b'import os, sys, inspect, shutil\n\nimport tensorflow as tf\nimport numpy as np\n\nimport utility\n\nPACK_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))+""/..""\n\ndef training_process(sess=None, dataset=None,\n                     x=None, y_=None, training=None,\n                     train_step=None, accuracy=None, loss=None, saver=None,\n                     batch_size=0, epochs=0):\n\n    print(""\\n** Training process start!"")\n\n    te_am = dataset.test.amount\n    if(batch_size > te_am):\n        batch_size = te_am\n\n    epoch_step = 1\n    if(epochs < 100):\n        epoch_step = 1\n    elif(epochs < 1000):\n        epoch_step = 10\n    else:\n        epoch_step = int(epochs/100)\n\n    train_acc_list = []\n    test_acc_list = []\n    train_loss_list = []\n    test_loss_list = []\n\n    print(""\\n Training to ""+str(epochs)+"" epochs | Batch size: %d\\n"" %(batch_size))\n\n    tra_am = dataset.train.amount\n    for i in range(epochs):\n\n        start = 0\n        end = start + batch_size\n\n        if(i%epoch_step == 0): # compute accuracy and loss\n            if(start == 0):\n                train_batch = dataset.train.next_batch(batch_size=batch_size)\n            test_batch = dataset.test.next_batch(batch_size=batch_size)\n\n            sys.stdout.write("" Evaluation        \\r"")\n            sys.stdout.flush()\n\n            train_accuracy = accuracy.eval(feed_dict={x:train_batch[0], y_:train_batch[1], training:False})\n            test_accuracy = accuracy.eval(feed_dict={x:test_batch[0], y_:test_batch[1], training:False})\n            train_loss = loss.eval(feed_dict={x:train_batch[0], y_:train_batch[1], training:False})\n            test_loss = loss.eval(feed_dict={x:test_batch[0], y_:test_batch[1], training:False})\n\n            train_acc_list.append(train_accuracy)\n            test_acc_list.append(test_accuracy)\n            train_loss_list.append(train_loss)\n            test_loss_list.append(test_loss)\n\n            print("" Epoch [ %d / %d ]\\n Accuracy  train: %.5f  |  test: %.5f"" %(i, epochs, train_accuracy, test_accuracy))\n            print("" CE loss   train: %.5f  |  test: %.5f"" %(train_loss, test_loss))\n            print("""")\n\n        while(True): # 1 epoch\n            sys.stdout.write("" Loading next batch\\r"")\n            sys.stdout.flush()\n            train_batch = dataset.train.next_batch(batch_size=batch_size, start=start, end=end)\n\n            sys.stdout.write("" Training          \\r"")\n            sys.stdout.flush()\n            sess.run(train_step, feed_dict={x:train_batch[0], y_:train_batch[1], training:True})\n\n            start = end\n            end = start + batch_size\n            if(start >= tra_am):\n                break\n\n    utility.save_graph_as_image(train_list=train_acc_list, test_list=test_acc_list, ylabel=""accuracy"")\n    utility.save_graph_as_image(train_list=train_loss_list, test_list=test_loss_list, ylabel=""loss"")\n\n    test_batch = dataset.test.next_batch(batch_size=batch_size)\n    test_accuracy = accuracy.eval(feed_dict={x:test_batch[0], y_:test_batch[1], training:False})\n    test_loss = loss.eval(feed_dict={x:test_batch[0], y_:test_batch[1], training:False})\n    print(""\\n Final Test accuracy, loss  | %.5f\\t %.5f\\n"" %(test_accuracy, test_loss))\n\n    utility.refresh_directory(PACK_PATH+""/checkpoint"")\n    saver.save(sess, PACK_PATH+""/checkpoint/checker"")\n\ndef prediction_process(sess=None, dataset=None,\n                       x=None, y_=None, training=None,\n                       prediction=None, saver=None,\n                       validation=0):\n\n    print(""\\n** Prediction process start!"")\n\n    val_am = dataset.validation.amount\n    if(validation == 0):\n        val_loop = val_am\n    else:\n        val_loop = validation\n        if(val_loop > val_am):\n            val_loop = val_am\n\n    correct = 0\n    if(os.path.exists(PACK_PATH+""/checkpoint/checker.index"")):\n        saver.restore(sess, PACK_PATH+""/checkpoint/checker"")\n\n        f = open(PACK_PATH+""/dataset/labels.txt"", \'r\')\n        content = f.readlines()\n        f.close()\n        for idx in range(len(content)):\n            content[idx] = content[idx][:len(content[idx])-1] # rid \\n\n\n        print(""\\n Prediction to ""+str(val_loop)+"" times"")\n\n        prob_list = []\n        prob_matrix = np.empty((0, dataset.validation.class_num), float)\n\n        line_cnt = 0\n        tmp_label = 0\n        for i in range(val_loop):\n            valid_batch = dataset.validation.next_batch(batch_size=1, nth=line_cnt)\n            line_cnt += 1\n\n            if(tmp_label != int(np.argmax(valid_batch[1]))):\n                prob_list.append(prob_matrix)\n                prob_matrix = np.empty((0, dataset.validation.class_num), float)\n                tmp_label = int(np.argmax(valid_batch[1]))\n\n            prob = sess.run(prediction, feed_dict={x:valid_batch[0], training:False})\n            prob_matrix = np.append(prob_matrix, np.asarray(prob), axis=0)\n\n            print(""\\n Prediction"")\n            print("" Real:   ""+str(content[int(np.argmax(valid_batch[1]))]))\n            print("" Guess:  ""+str(content[int(np.argmax(prob))])+""  %.2f %%"" %(np.amax(prob)*100))\n\n            if(content[int(np.argmax(valid_batch[1]))] == content[int(np.argmax(prob))]):\n                correct = correct + 1\n        prob_list.append(prob_matrix)\n\n        print(""\\n Accuracy: %.5f"" %(float(correct)/float(val_loop)))\n        utility.save_confusion(save_as=""confusion"", labels=content, lists=prob_list, size=dataset.validation.class_num)\n    else:\n        print(""You must training first!"")\n'"
Refactoring/source/utility.py,8,"b'import os, sys, glob, shutil, psutil, inspect, random\nimport scipy.misc\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom datetime import datetime\n\nPACK_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))+""/..""\n\ndef check_directory(dir_name):\n    if(os.path.exists(dir_name)):\n        return True\n    else:\n        return False\n\ndef check_file(file_path):\n    if(os.path.isfile(file_path)):\n        return True\n    else:\n        return False\n\ndef check_memory():\n    pid = os.getpid()\n    proc = psutil.Process(pid)\n    used_mem = proc.memory_info()[0]\n\n    print(""Memory Used: %.2f GB\\t( %.2f MB )"" %(used_mem/(2**30), used_mem/(2**20)))\n\n    return used_mem\n\ndef refresh_directory(dir_name):\n    if(os.path.exists(dir_name)):\n        shutil.rmtree(dir_name)\n        os.mkdir(dir_name)\n    else:\n        os.mkdir(dir_name)\n\ndef get_dirlist(path=None): # make directory list from path\n\n    directories = []\n    for dirname in os.listdir(path):\n        directories.append(dirname)\n\n    directories.sort()\n\n    f = open(PACK_PATH+""/dataset/labels.txt"", ""w"")\n    for di in directories:\n        f.write(str(di))\n        f.write(""\\n"")\n    f.close()\n\n    return directories\n\ndef get_filelist(directory=None, extensions=None): # make directory list from directory with path\n\n    file_list = []\n    for ext in extensions:\n        for fi in glob.glob(directory+""/*.""+ext):\n            file_list.append(fi)\n\n    print(str(len(file_list))+"" files in ""+directory)\n\n    return file_list\n\ndef copy_file(origin, copy, clone=0):\n    count = 0\n    for ori in origin:\n        if(clone == 0):\n            shutil.copy(ori, copy+""/""+str(count)+"".jpg"")\n        else:\n            for c in range(clone):\n                shutil.copy(ori, copy+""/""+str(count)+""_clone_""+str(c)+"".jpg"")\n        count = count + 1\n\ndef shuffle_csv(filename=None):\n    f = open(filename+"".csv"", ""r"")\n    lines = f.readlines()\n    f.close()\n\n    random.shuffle(lines)\n\n    f = open(filename+"".csv"", ""w"")\n    f.writelines(lines)\n    f.close()\n\ndef save_dataset_to_csv(save_as=""sample"", label=None, data=None, mode=\'w\'):\n\n    f = open(PACK_PATH+""/dataset/""+save_as+"".csv"", mode)\n\n    f.write(str(label))\n    f.write("","")\n\n    for da in data:\n        f.write(str(da))\n        f.write("","")\n\n    f.write(""\\n"")\n\n    f.close()\n\ndef save_graph_as_image(train_list, test_list, ylabel=""""):\n\n    print("" Save ""+ylabel+"" graph in ./graph"")\n\n    x = np.arange(len(train_list))\n    plt.clf()\n    plt.plot(x, train_list, label=""train ""+ylabel)\n    plt.plot(x, test_list, label=""test ""+ylabel, linestyle=\'--\')\n    plt.xlabel(""step"")\n    plt.ylabel(ylabel)\n    plt.ylim(-0.1, max([1, max(train_list), max(test_list)])*1.1)\n    if(ylabel == ""accuracy""):\n        plt.legend(loc=\'lower right\')\n    else:\n        plt.legend(loc=\'upper right\')\n    #plt.show()\n\n    if(not(os.path.exists(""./graph""))):\n        os.mkdir(""./graph"")\n    else:\n        pass\n    now = datetime.now()\n\n    plt.savefig(""./graph/""+now.strftime(\'%Y%m%d_%H%M%S%f\')+""_""+ylabel+"".png"")\n\ndef save_confusion(save_as=""sample"", labels=None, lists=None, size=None):\n\n    print("" Save confusion in ./confusion"")\n\n    confusion = np.empty((0, size), float)\n\n    for li in lists:\n        tmp_confu = li[0]\n\n        for idx in range(li.shape[0]):\n            if(idx == 0):\n                pass\n            else:\n                tmp_confu = np.sum((tmp_confu, li[idx]), axis=0) # sum the same label probs\n\n        tmp_confu = tmp_confu / li.shape[0] # divide total prob\n\n        confusion = np.append(confusion, np.asarray(tmp_confu).reshape((1, len(tmp_confu))), axis=0)\n\n    if(not(check_directory(PACK_PATH+""/confusion""))):\n        os.mkdir(PACK_PATH+""/confusion"")\n\n    result = np.kron(confusion, np.ones((confusion.shape[0]*100, confusion.shape[1]*100))) # pump the matrix for save image\n\n    now = datetime.now()\n\n    # save as csv\n    f = open(PACK_PATH+""/confusion/""+now.strftime(\'%Y%m%d_%H%M%S%f\')+""_""+save_as+"".csv"", ""w"")\n\n    f.write(""X"")\n    f.write("","")\n    for la in labels:\n        f.write(la)\n        f.write("","")\n    f.write(""Classification overall"")\n    f.write("","")\n    f.write(""Producer Accuracy (Precision)"")\n    f.write("","")\n    f.write(""\\n"")\n\n    for row in range(confusion.shape[0]):\n        f.write(labels[row])\n        f.write("","")\n\n        overall_cla = np.sum(confusion[row])\n        precision = confusion[row][row] / overall_cla\n        for con_elm in confusion[row]:\n            f.write(str(round(con_elm, 5)))\n            f.write("","")\n        f.write(str(round(overall_cla, 5)))\n        f.write("","")\n        f.write(str(round(precision, 5)))\n        f.write("","")\n        f.write(""\\n"")\n\n    confusion_t = np.transpose(confusion)\n\n    f.write(""Truth overall"")\n    f.write("","")\n    for row in range(confusion_t.shape[0]):\n        overall_tru = confusion_t[row].shape[0]\n        f.write(str(round(overall_cla, 5)))\n        f.write("","")\n    f.write(""\\n"")\n\n    f.write(""User Accuracy (Recall)"")\n    f.write("","")\n    for row in range(confusion_t.shape[0]):\n        overall_tru = np.sum(confusion_t[row])\n        recall = confusion[row][row] / confusion_t[row].shape[0]\n        f.write(str(round(precision, 5)))\n        f.write("","")\n    f.write(""\\n"")\n\n    f.close()\n\n    result[0][0] = 1\n    # save as image\n    scipy.misc.imsave(PACK_PATH+""/confusion/""+now.strftime(\'%Y%m%d_%H%M%S%f\')+""_""+save_as+"".jpg"", result)\n'"
Refactoring/source/webcam.py,3,"b'import os, sys, inspect, time\nimport cv2\n\nimport tensorflow as tf\nimport numpy as np\n\nimport cv_functions\n\nPACK_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))+""/..""\n\nframe = None\nheight, width, chennel = None, None, None\ncontent = None\n\ndef draw_boxes(boxes=None):\n\n    global frame\n\n    for b in boxes:\n        x, y, w, h = b\n\n        cv2.rectangle(frame,(x,y),(x+w,y+h),(255, 255, 255),1)\n\ndef draw_predict_boxes(boxes=None):\n\n    global frame\n\n    eye = 0\n    for b in boxes:\n        x, y, w, h, result, acc = b\n\n        txt_color = (100, 100, 100)\n        if((result == ""open"") or (result == ""close"")):\n            eye += 1\n            # if(eye > 2):\n                # break\n            if(result == ""open""):\n                txt_color = (255, 0, 0)\n            elif(result == ""close""):\n                txt_color = (0, 0, 255)\n\n            cv2.rectangle(frame,(x,y),(x+w,y+h),(255, 255, 255),1)\n            cv2.putText(frame, result+"" ""+str(int(acc*100))+""%"", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 3)\n            cv2.putText(frame, result+"" ""+str(int(acc*100))+""%"", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, txt_color, 2)\n        # else:\n            # cv2.rectangle(frame,(x,y),(x+w,y+h),(255, 255, 255),1)\n            # cv2.putText(frame, result+"" ""+str(int(acc*100))+""%"", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 3)\n            # cv2.putText(frame, result+"" ""+str(int(acc*100))+""%"", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, txt_color, 2)\n            # cv2.putText(frame, ""Others ""+str(int(acc*100))+""%"", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 3)\n            # cv2.putText(frame, ""Others ""+str(int(acc*100))+""%"", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, txt_color, 2)\n\ndef load_format():\n\n    global height, width, chennel, content\n\n    f = open(PACK_PATH+""/dataset/format.txt"", \'r\')\n    class_len = int(f.readline())\n    data_len = int(f.readline())\n    height = int(f.readline())\n    width = int(f.readline())\n    chennel = int(f.readline())\n    f.close()\n\n    f = open(PACK_PATH+""/dataset/labels.txt"", \'r\')\n    content = f.readlines()\n    f.close()\n    for idx in range(len(content)):\n        content[idx] = content[idx][:len(content[idx])-1] # rid \\n\n\ndef img_predict(image=None):\n\n    global height, width, chennel\n\n    resized_image = cv2.resize(image, (height, width))\n\n    return np.asarray(resized_image).reshape((1, height*width*chennel))\n\ndef region_predict(origin=None, contours=None, sess=None, x_holder=None, training=None, prediction=None, saver=None):\n\n    global content\n\n    boxes = []\n    pad = 15\n    std_time = time.time()\n    classification_counter = 0\n    for cnt in contours:\n\n        area = cv2.contourArea(cnt)\n        if((area < 200) or (area > 5000)):\n            continue\n\n        x, y, w, h = cv2.boundingRect(cnt)\n        x, y, w, h = x-pad, y-pad, w+pad, h+pad\n\n        if((x > 0) and (y > 0)):\n\n            if((x < frame.shape[1]) and (y < frame.shape[0])): # check: box in the region\n\n                prob = sess.run(prediction, feed_dict={x_holder:img_predict(image=frame[y:y+h, x:x+w]), training:False})\n                classification_counter += 1\n\n                result = str(content[int(np.argmax(prob))])\n                acc = np.max(prob)\n\n                if(acc > 0.85):\n                    boxes.append([x, y, w, h, result, acc])\n\n    sys.stdout.write(\'%.3f [classify/sec]\\r\' %(classification_counter/(time.time() - std_time)))\n    sys.stdout.flush()\n\n    boxes = sorted(boxes, key=lambda l:l[4], reverse=True) # sort by result\n    boxes = sorted(boxes, key=lambda l:l[5], reverse=True) # sort by acc\n    return boxes\n\ndef webcam_main(sess=None, x_holder=None, training=None, prediction=None, saver=None):\n\n    global frame\n\n    print("""")\n\n    load_format()\n\n    if(os.path.exists(PACK_PATH+""/checkpoint/checker.index"")):\n        saver.restore(sess, PACK_PATH+""/checkpoint/checker"")\n\n        camera = cv2.VideoCapture(0)\n\n        cv2.namedWindow(""frame"")\n\n        while True:\n\n            (grabbed, frame) = camera.read()\n\n            frame = cv2.flip(frame,1)\n\n            if not grabbed:\n                break\n\n            gray = cv_functions.rgb2gray(rgb=frame)\n            # cv2.imshow(""gray"", gray)\n\n            binary_img = cv_functions.adaptiveThresholding(gray=gray, neighbor=5, blur=True, k_size=7)\n            # cv2.imshow(""binary_img"", binary_img)\n\n            # opened = cv_functions.opening(binary_img=binary_img, k_size=2, iterations=1)\n            # cv2.imshow(""opened"", opened)\n\n            # closed = cv_functions.closing(binary_img=opened, k_size=4, iterations=2)\n            # cv2.imshow(""closed"", closed)\n\n            cus_opened = cv_functions.custom_opeing(binary_img=binary_img, ero_size=3, dil_size=7, iterations=1)\n            # cv2.imshow(""cus_opened"", cus_opened)\n\n            # cus_closed = cv_functions.custom_closing(binary_img=binary_img, ero_size=3, dil_size=5, iterations=1)\n            # cv2.imshow(""cus_closed"", cus_closed)\n\n            contours, _ = cv_functions.contouring(binary_img=cus_opened)\n\n            boxes = cv_functions.contour2box(contours=contours, padding=15)\n            # draw_boxes(boxes=boxes)\n\n            boxes_pred = region_predict(origin=frame, contours=contours, sess=sess, x_holder=x_holder, training=training, prediction=prediction, saver=saver)\n\n            draw_predict_boxes(boxes=boxes_pred)\n\n            cv2.imshow(""frame"", frame)\n\n            key = cv2.waitKey(1) & 0xFF\n            # press \'p\' to Pause\n            if(key == ord(""p"")):\n                cv2.waitKey(0)\n            # press \'q\' to Quit\n            elif(key == ord(""q"")):\n                print(""\\n\\nQUIT"")\n                break\n\n        # cleanup the camera and close any open windows\n        camera.release()\n        cv2.destroyAllWindows()\n'"
