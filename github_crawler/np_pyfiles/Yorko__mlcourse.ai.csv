file_path,api_count,code
jupyter_russian/topic06_features/demo.py,2,"b'import numpy as np\nimport pandas as pd\nimport json\nfrom sklearn.base import TransformerMixin\n\nEPSILON = 1e-5\n\n\nclass FeatureEngineer(TransformerMixin):\n\n    def apply(self, df, k, condition):\n        df[k] = df[\'features\'].apply(condition)\n        df[k] = df[k].astype(np.int8)\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n\n    def transform(self, X, y=None):\n        df = X.copy()\n\n        df.features = df.features.apply(lambda x: \' \'.join([y.replace(\' \', \'_\') for y in x]))\n        df.features = df.features.apply(lambda x: x.lower())\n        df.features = df.features.apply(lambda x: x.replace(\'-\', \'_\'))\n\n        for k, condition in ((\'dishwasher\', lambda x: \'dishwasher\' in x),\n                             (\'doorman\', lambda x: \'doorman\' in x or \'concierge\' in x),\n                             (\'pets\', lambda x: ""pets"" in x or ""pet"" in x or ""dog"" in x or ""cats"" in x and ""no_pets"" not in x),\n                             (\'air_conditioning\', lambda x: \'air_conditioning\' in x or \'central\' in x),\n                             (\'parking\', lambda x: \'parking\' in x),\n                             (\'balcony\', lambda x: \'balcony\' in x or \'deck\' in x or \'terrace\' in x or \'patio\' in x),\n                             (\'bike\', lambda x: \'bike\' in x),\n                             (\'storage\', lambda x: \'storage\' in x),\n                             (\'outdoor\', lambda x: \'outdoor\' in x or \'courtyard\' in x or \'garden\' in x),\n                             (\'roof\', lambda x: \'roof\' in x),\n                             (\'gym\', lambda x: \'gym\' in x or \'fitness\' in x),\n                             (\'pool\', lambda x: \'pool\' in x),\n                             (\'backyard\', lambda x: \'backyard\' in x),\n                             (\'laundry\', lambda x: \'laundry\' in x),\n                             (\'hardwood_floors\', lambda x: \'hardwood_floors\' in x),\n                             (\'new_construction\', lambda x: \'new_construction\' in x),\n                             (\'dryer\', lambda x: \'dryer\' in x),\n                             (\'elevator\', lambda x: \'elevator\' in x),\n                             (\'garage\', lambda x: \'garage\' in x),\n                             (\'pre_war\', lambda x: \'pre_war\' in x or \'prewar\' in x),\n                             (\'post_war\', lambda x: \'post_war\' in x or \'postwar\' in x),\n                             (\'no_fee\', lambda x: \'no_fee\' in x),\n                             (\'low_fee\', lambda x: \'reduced_fee\' in x or \'low_fee\' in x),\n                             (\'fire\', lambda x: \'fireplace\' in x),\n                             (\'private\', lambda x: \'private\' in x),\n                             (\'wheelchair\', lambda x: \'wheelchair\' in x),\n                             (\'internet\', lambda x: \'wifi\' in x or \'wi_fi\' in x or \'internet\' in x),\n                             (\'yoga\', lambda x: \'yoga\' in x),\n                             (\'furnished\', lambda x: \'furnished\' in x),\n                             (\'multi_level\', lambda x: \'multi_level\' in x),\n                             (\'exclusive\', lambda x: \'exclusive\' in x),\n                             (\'high_ceil\', lambda x: \'high_ceil\' in x),\n                             (\'green\', lambda x: \'green_b\' in x),\n                             (\'stainless\', lambda x: \'stainless_\' in x),\n                             (\'simplex\', lambda x: \'simplex\' in x),\n                             (\'public\', lambda x: \'public\' in x),\n                             ):\n            self.apply(df, k, condition)\n\n        df[\'bathrooms\'] = df[\'bathrooms\'].apply(lambda x: x if x < 5 else 5)\n        df[\'bedrooms\'] = df[\'bedrooms\'].apply(lambda x: x if x < 5 else 5)\n        df[""num_photos""] = df[""photos""].apply(len)\n        df[""num_features""] = df[""features""].apply(len)\n        created = pd.to_datetime(df.pop(""created""))\n        df[""listing_age""] = (pd.to_datetime(\'today\') - created).apply(lambda x: x.days)\n        df[""room_dif""] = df[""bedrooms""] - df[""bathrooms""]\n        df[""room_sum""] = df[""bedrooms""] + df[""bathrooms""]\n        df[""price_per_room""] = df[""price""] / df[""room_sum""].apply(lambda x: max(x, .5))\n        df[""bedrooms_share""] = df[""bedrooms""] / df[""room_sum""].apply(lambda x: max(x, .5))\n        df[\'price\'] = df[\'price\'].apply(lambda x: np.log(x + EPSILON))\n\n        key_types = df.dtypes.to_dict()\n        for k in key_types:\n            if key_types[k].name not in (\'int64\', \'float64\', \'int8\'):\n                df.pop(k)\n\n        for k in (\'latitude\', \'longitude\', \'listing_id\'):\n            df.pop(k)\n        return df\n\n\ndef encode(x):\n    if x == \'low\':\n        return 0\n    elif x == \'medium\':\n        return 1\n    elif x == \'high\':\n        return 2\n\n\ndef get_data():\n    with open(\'train.json\', \'r\') as raw_data:\n        data = json.load(raw_data)\n\n    df = pd.DataFrame(data)\n    target = df.pop(\'interest_level\').apply(encode)\n\n    df = FeatureEngineer().fit_transform(df)\n    return df, target\n'"
jupyter_russian/tutorials/arules_shared/apriori.py,0,"b'#!/usr/bin/env python\n\n""""""\na simple implementation of Apriori algorithm by Python.\n""""""\n\nimport sys\nimport csv\nimport argparse\nimport json\nimport os\nfrom collections import namedtuple\nfrom itertools import combinations\nfrom itertools import chain\n\n\n# Meta informations.\n__version__ = \'1.1.1\'\n__author__ = \'Yu Mochizuki\'\n__author_email__ = \'ymoch.dev@gmail.com\'\n\n\n################################################################################\n# Data structures.\n################################################################################\nclass TransactionManager(object):\n    """"""\n    Transaction managers.\n    """"""\n\n    def __init__(self, transactions):\n        """"""\n        Initialize.\n\n        Arguments:\n            transactions -- A transaction iterable object\n                            (eg. [[\'A\', \'B\'], [\'B\', \'C\']]).\n        """"""\n        self.__num_transaction = 0\n        self.__items = []\n        self.__transaction_index_map = {}\n\n        for transaction in transactions:\n            self.add_transaction(transaction)\n\n    def add_transaction(self, transaction):\n        """"""\n        Add a transaction.\n\n        Arguments:\n            transaction -- A transaction as an iterable object (eg. [\'A\', \'B\']).\n        """"""\n        for item in transaction:\n            if item not in self.__transaction_index_map:\n                self.__items.append(item)\n                self.__transaction_index_map[item] = set()\n            self.__transaction_index_map[item].add(self.__num_transaction)\n        self.__num_transaction += 1\n\n    def calc_support(self, items):\n        """"""\n        Returns a support for items.\n\n        Arguments:\n            items -- Items as an iterable object (eg. [\'A\', \'B\']).\n        """"""\n        # Empty items is supported by all transactions.\n        if not items:\n            return 1.0\n\n        # Empty transactions supports no items.\n        if not self.num_transaction:\n            return 0.0\n\n        # Create the transaction index intersection.\n        sum_indexes = None\n        for item in items:\n            indexes = self.__transaction_index_map.get(item)\n            if indexes is None:\n                # No support for any set that contains a not existing item.\n                return 0.0\n\n            if sum_indexes is None:\n                # Assign the indexes on the first time.\n                sum_indexes = indexes\n            else:\n                # Calculate the intersection on not the first time.\n                sum_indexes = sum_indexes.intersection(indexes)\n\n        # Calculate and return the support.\n        return float(len(sum_indexes)) / self.__num_transaction\n\n    def initial_candidates(self):\n        """"""\n        Returns the initial candidates.\n        """"""\n        return [frozenset([item]) for item in self.items]\n\n    @property\n    def num_transaction(self):\n        """"""\n        Returns the number of transactions.\n        """"""\n        return self.__num_transaction\n\n    @property\n    def items(self):\n        """"""\n        Returns the item list that the transaction is consisted of.\n        """"""\n        return sorted(self.__items)\n\n    @staticmethod\n    def create(transactions):\n        """"""\n        Create the TransactionManager with a transaction instance.\n        If the given instance is a TransactionManager, this returns itself.\n        """"""\n        if isinstance(transactions, TransactionManager):\n            return transactions\n        return TransactionManager(transactions)\n\n\n# Ignore name errors because these names are namedtuples.\nSupportRecord = namedtuple( # pylint: disable=C0103\n    \'SupportRecord\', (\'items\', \'support\'))\nRelationRecord = namedtuple( # pylint: disable=C0103\n    \'RelationRecord\', SupportRecord._fields + (\'ordered_statistics\',))\nOrderedStatistic = namedtuple( # pylint: disable=C0103\n    \'OrderedStatistic\', (\'items_base\', \'items_add\', \'confidence\', \'lift\',))\n\n\n################################################################################\n# Inner functions.\n################################################################################\ndef create_next_candidates(prev_candidates, length):\n    """"""\n    Returns the apriori candidates as a list.\n\n    Arguments:\n        prev_candidates -- Previous candidates as a list.\n        length -- The lengths of the next candidates.\n    """"""\n    # Solve the items.\n    item_set = set()\n    for candidate in prev_candidates:\n        for item in candidate:\n            item_set.add(item)\n    items = sorted(item_set)\n\n    # Create the temporary candidates. These will be filtered below.\n    tmp_next_candidates = (frozenset(x) for x in combinations(items, length))\n\n    # Return all the candidates if the length of the next candidates is 2\n    # because their subsets are the same as items.\n    if length < 3:\n        return list(tmp_next_candidates)\n\n    # Filter candidates that all of their subsets are\n    # in the previous candidates.\n    next_candidates = [\n        candidate for candidate in tmp_next_candidates\n        if all(\n            True if frozenset(x) in prev_candidates else False\n            for x in combinations(candidate, length - 1))\n    ]\n    return next_candidates\n\n\ndef gen_support_records(transaction_manager, min_support, **kwargs):\n    """"""\n    Returns a generator of support records with given transactions.\n\n    Arguments:\n        transaction_manager -- Transactions as a TransactionManager instance.\n        min_support -- A minimum support (float).\n\n    Keyword arguments:\n        max_length -- The maximum length of relations (integer).\n    """"""\n    # Parse arguments.\n    max_length = kwargs.get(\'max_length\')\n\n    # For testing.\n    _create_next_candidates = kwargs.get(\n        \'_create_next_candidates\', create_next_candidates)\n\n    # Process.\n    candidates = transaction_manager.initial_candidates()\n    length = 1\n    while candidates:\n        relations = set()\n        for relation_candidate in candidates:\n            support = transaction_manager.calc_support(relation_candidate)\n            if support < min_support:\n                continue\n            candidate_set = frozenset(relation_candidate)\n            relations.add(candidate_set)\n            yield SupportRecord(candidate_set, support)\n        length += 1\n        if max_length and length > max_length:\n            break\n        candidates = _create_next_candidates(relations, length)\n\n\ndef gen_ordered_statistics(transaction_manager, record):\n    """"""\n    Returns a generator of ordered statistics as OrderedStatistic instances.\n\n    Arguments:\n        transaction_manager -- Transactions as a TransactionManager instance.\n        record -- A support record as a SupportRecord instance.\n    """"""\n    items = record.items\n    for combination_set in combinations(sorted(items), len(items) - 1):\n        items_base = frozenset(combination_set)\n        items_add = frozenset(items.difference(items_base))\n        confidence = (\n            record.support / transaction_manager.calc_support(items_base))\n        lift = confidence / transaction_manager.calc_support(items_add)\n        yield OrderedStatistic(\n            frozenset(items_base), frozenset(items_add), confidence, lift)\n\n\ndef filter_ordered_statistics(ordered_statistics, **kwargs):\n    """"""\n    Filter OrderedStatistic objects.\n\n    Arguments:\n        ordered_statistics -- A OrderedStatistic iterable object.\n\n    Keyword arguments:\n        min_confidence -- The minimum confidence of relations (float).\n        min_lift -- The minimum lift of relations (float).\n    """"""\n    min_confidence = kwargs.get(\'min_confidence\', 0.0)\n    min_lift = kwargs.get(\'min_lift\', 0.0)\n\n    for ordered_statistic in ordered_statistics:\n        if ordered_statistic.confidence < min_confidence:\n            continue\n        if ordered_statistic.lift < min_lift:\n            continue\n        yield ordered_statistic\n\n\n################################################################################\n# API function.\n################################################################################\ndef apriori(transactions, **kwargs):\n    """"""\n    Executes Apriori algorithm and returns a RelationRecord generator.\n\n    Arguments:\n        transactions -- A transaction iterable object\n                        (eg. [[\'A\', \'B\'], [\'B\', \'C\']]).\n\n    Keyword arguments:\n        min_support -- The minimum support of relations (float).\n        min_confidence -- The minimum confidence of relations (float).\n        min_lift -- The minimum lift of relations (float).\n        max_length -- The maximum length of the relation (integer).\n    """"""\n    # Parse the arguments.\n    min_support = kwargs.get(\'min_support\', 0.1)\n    min_confidence = kwargs.get(\'min_confidence\', 0.0)\n    min_lift = kwargs.get(\'min_lift\', 0.0)\n    max_length = kwargs.get(\'max_length\', None)\n\n    # Check arguments.\n    if min_support <= 0:\n        raise ValueError(\'minimum support must be > 0\')\n\n    # For testing.\n    _gen_support_records = kwargs.get(\n        \'_gen_support_records\', gen_support_records)\n    _gen_ordered_statistics = kwargs.get(\n        \'_gen_ordered_statistics\', gen_ordered_statistics)\n    _filter_ordered_statistics = kwargs.get(\n        \'_filter_ordered_statistics\', filter_ordered_statistics)\n\n    # Calculate supports.\n    transaction_manager = TransactionManager.create(transactions)\n    support_records = _gen_support_records(\n        transaction_manager, min_support, max_length=max_length)\n\n    # Calculate ordered stats.\n    for support_record in support_records:\n        ordered_statistics = list(\n            _filter_ordered_statistics(\n                _gen_ordered_statistics(transaction_manager, support_record),\n                min_confidence=min_confidence,\n                min_lift=min_lift,\n            )\n        )\n        if not ordered_statistics:\n            continue\n        yield RelationRecord(\n            support_record.items, support_record.support, ordered_statistics)\n\n\n################################################################################\n# Application functions.\n################################################################################\ndef parse_args(argv):\n    """"""\n    Parse commandline arguments.\n\n    Arguments:\n        argv -- An argument list without the program name.\n    """"""\n    output_funcs = {\n        \'json\': dump_as_json,\n        \'tsv\': dump_as_two_item_tsv,\n    }\n    default_output_func_key = \'json\'\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'-v\', \'--version\', action=\'version\',\n        version=\'%(prog)s {0}\'.format(__version__))\n    parser.add_argument(\n        \'input\', metavar=\'inpath\', nargs=\'*\',\n        help=\'Input transaction file (default: stdin).\',\n        type=argparse.FileType(\'r\'), default=[sys.stdin])\n    parser.add_argument(\n        \'-o\', \'--output\', metavar=\'outpath\',\n        help=\'Output file (default: stdout).\',\n        type=argparse.FileType(\'w\'), default=sys.stdout)\n    parser.add_argument(\n        \'-l\', \'--max-length\', metavar=\'int\',\n        help=\'Max length of relations (default: infinite).\',\n        type=int, default=None)\n    parser.add_argument(\n        \'-s\', \'--min-support\', metavar=\'float\',\n        help=\'Minimum support ratio (must be > 0, default: 0.1).\',\n        type=float, default=0.1)\n    parser.add_argument(\n        \'-c\', \'--min-confidence\', metavar=\'float\',\n        help=\'Minimum confidence (default: 0.5).\',\n        type=float, default=0.5)\n    parser.add_argument(\n        \'-t\', \'--min-lift\', metavar=\'float\',\n        help=\'Minimum lift (default: 0.0).\',\n        type=float, default=0.0)\n    parser.add_argument(\n        \'-d\', \'--delimiter\', metavar=\'str\',\n        help=\'Delimiter for items of transactions (default: tab).\',\n        type=str, default=\'\\t\')\n    parser.add_argument(\n        \'-f\', \'--out-format\', metavar=\'str\',\n        help=\'Output format ({0}; default: {1}).\'.format(\n            \', \'.join(output_funcs.keys()), default_output_func_key),\n        type=str, choices=output_funcs.keys(), default=default_output_func_key)\n    args = parser.parse_args(argv)\n\n    args.output_func = output_funcs[args.out_format]\n    return args\n\n\ndef load_transactions(input_file, **kwargs):\n    """"""\n    Load transactions and returns a generator for transactions.\n\n    Arguments:\n        input_file -- An input file.\n\n    Keyword arguments:\n        delimiter -- The delimiter of the transaction.\n    """"""\n    delimiter = kwargs.get(\'delimiter\', \'\\t\')\n    for transaction in csv.reader(input_file, delimiter=delimiter):\n        yield transaction if transaction else [\'\']\n\n\ndef dump_as_json(record, output_file):\n    """"""\n    Dump an relation record as a json value.\n\n    Arguments:\n        record -- A RelationRecord instance to dump.\n        output_file -- A file to output.\n    """"""\n    def default_func(value):\n        """"""\n        Default conversion for JSON value.\n        """"""\n        if isinstance(value, frozenset):\n            return sorted(value)\n        raise TypeError(repr(value) + "" is not JSON serializable"")\n\n    converted_record = record._replace(\n        ordered_statistics=[x._asdict() for x in record.ordered_statistics])\n    json.dump(\n        converted_record._asdict(), output_file,\n        default=default_func, ensure_ascii=False)\n    output_file.write(os.linesep)\n\n\ndef dump_as_two_item_tsv(record, output_file):\n    """"""\n    Dump a relation record as TSV only for 2 item relations.\n\n    Arguments:\n        record -- A RelationRecord instance to dump.\n        output_file -- A file to output.\n    """"""\n    for ordered_stats in record.ordered_statistics:\n        if len(ordered_stats.items_base) != 1:\n            continue\n        if len(ordered_stats.items_add) != 1:\n            continue\n        output_file.write(\'{0}\\t{1}\\t{2:.8f}\\t{3:.8f}\\t{4:.8f}{5}\'.format(\n            list(ordered_stats.items_base)[0], list(ordered_stats.items_add)[0],\n            record.support, ordered_stats.confidence, ordered_stats.lift,\n            os.linesep))\n\n\ndef main(**kwargs):\n    """"""\n    Executes Apriori algorithm and print its result.\n    """"""\n    # For tests.\n    _parse_args = kwargs.get(\'_parse_args\', parse_args)\n    _load_transactions = kwargs.get(\'_load_transactions\', load_transactions)\n    _apriori = kwargs.get(\'_apriori\', apriori)\n\n    args = _parse_args(sys.argv[1:])\n    transactions = _load_transactions(\n        chain(*args.input), delimiter=args.delimiter)\n    result = _apriori(\n        transactions,\n        max_length=args.max_length,\n        min_support=args.min_support,\n        min_confidence=args.min_confidence)\n    for record in result:\n        args.output_func(record, args.output)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
jupyter_russian/tutorials/multi-armed_bandits_ololo/graph_utils.py,0,"b""import pydot\n\nimport random \n\ndef add_recurse(g, parent, tree):\n    if isinstance(tree, (list, set)):\n        for node in tree:\n            name = '%s_%03d' % (node, random.randint(0, 999))\n            n = pydot.Node(name=name, label=node)\n            g.add_node(n)\n            g.add_edge(pydot.Edge(parent, n))\n        return\n\n    for node, children in tree.items():\n        name = '%s_%03d' % (node, random.randint(0, 999))\n        n = pydot.Node(name=name, label=node)\n        g.add_node(n)\n        g.add_edge(pydot.Edge(parent, n))\n        add_recurse(g, n, children)\n\ndef tree_to_dot(tree):\n    g = pydot.Dot(graph_type='digraph')\n\n    for node, children in tree.items():\n        name = '%s_%03d' % (node, random.randint(0, 999))\n        n = pydot.Node(name=name, label=node)\n        g.add_node(n)\n        add_recurse(g, n, children)\n\n    return g"""
jupyter_russian/tutorials/scrapy_tourism/scrapy_tourism/__init__.py,0,b''
jupyter_russian/tutorials/scrapy_tourism/scrapy_tourism/pipelines.py,0,"b""import urllib.request\nimport requests\n\nclass GeocoderPipeline(object):\n    def process_item(self, item, spider):\n        address = item['address']\n        print(address)\n        geocode_url = 'https://geocode-maps.yandex.ru/1.x/?format=json&geocode={0}'.format(\n            urllib.request.quote(address))\n        response = requests.get(geocode_url)\n\n        lat, lon = None, None\n        if response.status_code == 200:\n            data = response.json()\n            geocoder_objects = data['response']['GeoObjectCollection']['featureMember']\n            if geocoder_objects:\n                coordinates = geocoder_objects[0]['GeoObject']['Point']['pos'].split()\n                lat, lon = float(coordinates[1]), float(coordinates[0])\n\n        item['lat'] = lat\n        item['lon'] = lon\n\n        return item\n\n"""
jupyter_russian/tutorials/scrapy_tourism/scrapy_tourism/settings.py,0,"b""BOT_NAME = 'scrapy_tourism'\n\nSPIDER_MODULES = ['scrapy_tourism.spiders']\nNEWSPIDER_MODULE = 'scrapy_tourism.spiders'\n\nROBOTSTXT_OBEY = True\n\nDOWNLOAD_DELAY = 0.25\n\n# ITEM_PIPELINES = {\n#    'scrapy_tourism.pipelines.GeocoderPipeline': 300,\n# }\n\n"""
jupyter_russian/tutorials/scrapy_tourism/scrapy_tourism/spiders/__init__.py,0,b'# This package will contain the spiders of your Scrapy project\n#\n# Please refer to the documentation for information on how to create and manage\n# your spiders.\n'
jupyter_russian/tutorials/scrapy_tourism/scrapy_tourism/spiders/beach_spider_0.py,0,"b'import scrapy\n\nclass TourismBeachSpider0(scrapy.Spider):\n    name = ""beach_0""\n    start_urls = [\n        \'http://www.classification-tourism.ru/index.php/displayBeach/index\',\n    ]\n\n    def parse(self, response):\n        for obj in response.css(\'a.field.object-title\'):\n            yield {\n                \'title\': obj.css(\'::text\').extract_first()\n            }\n\n'"
jupyter_russian/tutorials/scrapy_tourism/scrapy_tourism/spiders/beach_spider_1.py,0,"b'import scrapy\n\nclass TourismBeachSpider1(scrapy.Spider):\n    name = ""beach_1""\n    start_urls = [\n        \'http://www.classification-tourism.ru/index.php/displayBeach/index\',\n    ]\n\n    def parse(self, response):\n        for obj in response.css(\'a.field.object-title\'):\n            yield {\n                \'title\': obj.css(\'::text\').extract_first()\n            }\n\n        next_page_href = response.css(\'li.next a::attr(""href"")\').extract_first()\n        if next_page_href is not None:\n            next_page_url = response.urljoin(next_page_href)\n            yield scrapy.Request(next_page_url, self.parse)\n\n'"
jupyter_russian/tutorials/scrapy_tourism/scrapy_tourism/spiders/beach_spider_2.py,0,"b'import scrapy\n\nclass TourismBeachSpider2(scrapy.Spider):\n    name = ""beach_2""\n    start_urls = [\n        \'http://www.classification-tourism.ru/index.php/displayBeach/index\',\n    ]\n\n    def parse_item(self, response):\n        fields = {}\n        for obj in response.css(\'div.detail-field\'):\n            field_name = obj.css(\'span.detail-label::text\').extract_first()\n            field_value = obj.css(\'span.detail-value::text\').extract_first()\n            fields[field_name] = field_value\n\n        yield {\n            \'reg_id\': fields[\'\xd0\xa0\xd0\xb5\xd0\xb3\xd0\xb8\xd1\x81\xd1\x82\xd1\x80\xd0\xb0\xd1\x86\xd0\xb8\xd0\xbe\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb9 \xd0\xbd\xd0\xbe\xd0\xbc\xd0\xb5\xd1\x80 \xd0\xb2 \xd0\xa4\xd0\xb5\xd0\xb4\xd0\xb5\xd1\x80\xd0\xb0\xd0\xbb\xd1\x8c\xd0\xbd\xd0\xbe\xd0\xbc \xd0\xbf\xd0\xb5\xd1\x80\xd0\xb5\xd1\x87\xd0\xbd\xd0\xb5:\'],\n            \'full_name\': fields[\'\xd0\x9f\xd0\xbe\xd0\xbb\xd0\xbd\xd0\xbe\xd0\xb5 \xd0\xbd\xd0\xb0\xd0\xb8\xd0\xbc\xd0\xb5\xd0\xbd\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd0\xb5 \xd0\xba\xd0\xbb\xd0\xb0\xd1\x81\xd1\x81\xd0\xb8\xd1\x84\xd0\xb8\xd1\x86\xd0\xb8\xd1\x80\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xbd\xd0\xbe\xd0\xb3\xd0\xbe \xd0\xbe\xd0\xb1\xd1\x8a\xd0\xb5\xd0\xba\xd1\x82\xd0\xb0:\'],\n            \'name\': fields[\'C\xd0\xbe\xd0\xba\xd1\x80\xd0\xb0\xd1\x89\xd0\xb5\xd0\xbd\xd0\xbd\xd0\xbe\xd0\xb5 \xd0\xbd\xd0\xb0\xd0\xb8\xd0\xbc\xd0\xb5\xd0\xbd\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd0\xb5 \xd0\xba\xd0\xbb\xd0\xb0\xd1\x81\xd1\x81\xd0\xb8\xd1\x84\xd0\xb8\xd1\x86\xd0\xb8\xd1\x80\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xbd\xd0\xbe\xd0\xb3\xd0\xbe \xd0\xbe\xd0\xb1\xd1\x8a\xd0\xb5\xd0\xba\xd1\x82\xd0\xb0:\'],\n            \'category\': fields[\'\xd0\x9f\xd1\x80\xd0\xb8\xd1\x81\xd0\xb2\xd0\xbe\xd0\xb5\xd0\xbd\xd0\xbd\xd0\xb0\xd1\x8f \xd0\xba\xd0\xb0\xd1\x82\xd0\xb5\xd0\xb3\xd0\xbe\xd1\x80\xd0\xb8\xd1\x8f:\'],\n            \'address\': fields[\'\xd0\x90\xd0\xb4\xd1\x80\xd0\xb5\xd1\x81:\'],\n        }\n\n\n    def parse(self, response):\n        for obj in response.css(\'a.field.object-title\'):\n            item_href = obj.css(\'::attr(""href"")\').extract_first()\n            yield scrapy.Request(response.urljoin(item_href), self.parse_item)\n\n        next_page_href = response.css(\'li.next a::attr(""href"")\').extract_first()\n        if next_page_href is not None:\n            next_page_url = response.urljoin(next_page_href)\n            yield scrapy.Request(next_page_url, self.parse)\n\n'"
