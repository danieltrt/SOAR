file_path,api_count,code
main.py,6,"b'\'\'\'AUTHOR: ZAIN UL MUSTAFA\'\'\'\n\'\'\'http://www.github.com/ZainUlMustafa\'\'\'\n\nprint(\'STOCK PREDICTION USING RNN LSTM\')\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Activation\nfrom keras.layers.recurrent import LSTM\nfrom keras.layers import  Dropout\nfrom keras.models import model_from_json\nfrom keras.models import load_model\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nfmt = \'$%.0f\'\ntick = mtick.FormatStrFormatter(fmt)\n\nimport stockproc\n\n#########################################################################\n\'\'\'Path and filename\'\'\'\n\npath = \'Data/KSE/\'\n# make the boolean false if you want to read data offline and true for online from Quandl\ndata_csv = stockproc.getStockData(path,\'hbl\',True)\ndata_csv[[\'Last Day Close\']].plot()\nplt.show()\nplt.clf()\n#########################################################################\n\'\'\'Defining how much data to use\'\'\'\n# Data to be used\n# The more frequent this is, the better\n\npercentage_of_data = 1.0\ndata_to_use = int(percentage_of_data*(len(data_csv)-1))\n\n# 80% of data will be of training\ntrain_end = int(data_to_use*0.8)\n\ntotal_data = len(data_csv)\nprint(""total_data:"", total_data)\n\n#########################################################################\n\'\'\'Making a dataset\'\'\'\n# Start from 0\nstart = total_data - data_to_use\n\n# Currently doing prediction only for 1 step ahead\nsteps_to_predict = 1\n\nyt,yt1,yt2,yt3,vt = stockproc.feature_engineering(start,total_data,data_csv)\n# Order -> 5,2,3,4,6\n\nprint(""yt head :"")\nprint(yt.head())\n\n#########################################################################\n\'\'\'Shifting the closed price column by 1\'\'\'\nyt_ = yt.shift(-1)\n\ndata = pd.concat([yt, yt_, vt, yt1, yt2, yt3], axis=1)\ndata.columns = [\'yt\', \'yt_\', \'vt\', \'yt1\', \'yt2\', \'yt3\']\n     \ndata = data.dropna()\n     \nprint(data)\n\n#########################################################################\n\'\'\'Renaming the columns\'\'\'     \n# target variable - closed price\n# after shifting\ny = data[\'yt_\']\n\n#   closed, volume, open, high, low    \ncols = [\'yt\', \'vt\', \'yt1\', \'yt2\', \'yt3\']\nx = data[cols]\n\n#########################################################################\n\'\'\'Preprocessing the data\'\'\'\nscaler_x = preprocessing.MinMaxScaler (feature_range=(-1, 1))\nx = np.array(x).reshape((len(x) ,len(cols)))\nx = scaler_x.fit_transform(x)\n\nscaler_y = preprocessing.MinMaxScaler (feature_range=(-1, 1))\ny = np.array (y).reshape ((len( y), 1))\ny = scaler_y.fit_transform (y)\n\n#########################################################################\n\'\'\'Making the train and test dataset\'\'\'\nX_train = x[0 : train_end,]\nX_test = x[train_end+1 : len(x),]    \ny_train = y[0 : train_end] \ny_test = y[train_end+1 : len(y)]  \n\nX_train = X_train.reshape (X_train. shape + (1,)) \nX_test = X_test.reshape(X_test.shape + (1,))\n\n#########################################################################\n\'\'\'RNN and LSTM model\'\'\'\nbatch_size = 32\nnb_epoch = 25\nneurons = 512\n\nseed = 2016\nnp.random.seed(seed)\nmodel = Sequential ()\nmodel.add(LSTM(neurons, return_sequences=True, activation=\'tanh\', inner_activation=\'hard_sigmoid\', input_shape=(len(cols), 1)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(neurons, return_sequences=True,  activation=\'tanh\'))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(neurons, activation=\'tanh\'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(output_dim=1, activation=\'linear\'))\nmodel.add(Activation(\'tanh\'))\n\nmodel.compile(loss=\'mean_squared_error\' , optimizer=\'adam\')\nmodel.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_split=0.2)\n\nprint(model.summary())\n\n#########################################################################\n\'\'\'Calculating the score\'\'\'\nscore_train = model.evaluate(X_train, y_train, batch_size =1)\nscore_test = model.evaluate(X_test, y_test, batch_size =1)\nprint(""in train MSE = "", round( score_train ,4)) \nprint(""in test MSE = "", score_test )\n\n#########################################################################\n\'\'\'Saving the model\'\'\'\n# serialize model to JSON\nmodel_json = model.to_json()\nwith open(""model_adam25e.json"", ""w"") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(""model_adam25e.h5"")\nprint(""Saved model to disk"")\n\n#########################################################################\n\'\'\'Printing the predictions\'\'\'\npred = model.predict(X_test) \npred = scaler_y.inverse_transform(np.array(pred).reshape((len(pred), 1)))\n\nprediction_data = pred[-1]     \n\nmodel.summary()\nprint (""Inputs: {}"".format(model.input_shape))\nprint (""Outputs: {}"".format(model.output_shape))\nprint (""Actual input: {}"".format(X_test.shape))\nprint (""Actual output: {}"".format(y_test.shape))\n\nprint (""prediction data:"")\nprint (prediction_data)\n\nprint (""actual data"")\nX_test = scaler_x.inverse_transform(np.array(X_test).reshape((len(X_test), len(cols))))\nprint (X_test)\n\n#########################################################################\n\'\'\'Plotting\'\'\'\nplt.plot(pred, label=""predictions"")\n\ny_test = scaler_y.inverse_transform(np.array(y_test).reshape((len( y_test), 1)))\nplt.plot([row[0] for row in y_test], label=""actual"")\n\nplt.legend(loc=\'upper center\', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=2)\n\nax = plt.axes()\nax.yaxis.set_major_formatter(tick)\nplt.show()\nplt.clf()\n\n#########################################################################\n'"
stockproc.py,0,"b""from sklearn import preprocessing\nimport quandl\n# enter your API key for Quandl here\n# for limited use, comment it out\n#quandl.ApiConfig.api_key = ''\nimport pandas as pd\n\nonline = False\n\ndef getStockData(path,stockName,Type):\n\tglobal online\n\tonline = Type\n\tif online == True:\n\t\treturn quandl.get('PSX/'+stockName.upper())\n\tif online == False:\n\t\treturn pd.read_csv(path+stockName.upper()+'_01092003_12102018.csv')\n\ndef feature_engineering(From,To,data):\n\tglobal online\n\tif online == True:\n\t\treturn data.iloc[From:To,4],data.iloc[From:To,0],data.iloc[From:To,1],data.iloc[From:To,2],data.iloc[From:To,3]\n\tif online == False:\n\t\t#close,open,high,low,volume\n\t\treturn data.iloc[From:To,5],data.iloc[From:To,2],data.iloc[From:To,3],data.iloc[From:To,4],data.iloc[From:To,6]\n\n"""
