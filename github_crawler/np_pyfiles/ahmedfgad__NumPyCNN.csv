file_path,api_count,code
cnn.py,0,"b'import numpy\r\nimport functools\r\n\r\n""""""\r\nConvolutional neural network implementation using NumPy\r\nA tutorial that helps to get started (Building Convolutional Neural Network using NumPy from Scratch) available in these links: \r\n    https://www.linkedin.com/pulse/building-convolutional-neural-network-using-numpy-from-ahmed-gad\r\n    https://towardsdatascience.com/building-convolutional-neural-network-using-numpy-from-scratch-b30aac50e50a\r\n    https://www.kdnuggets.com/2018/04/building-convolutional-neural-network-numpy-scratch.html\r\nIt is also translated into Chinese: http://m.aliyun.com/yunqi/articles/585741\r\n""""""\r\n\r\n# Supported activation functions by the cnn.py module.\r\nsupported_activation_functions = (""sigmoid"", ""relu"", ""softmax"")\r\n\r\ndef sigmoid(sop):\r\n\r\n    """"""\r\n    Applies the sigmoid function.\r\n\r\n    sop: The input to which the sigmoid function is applied.\r\n\r\n    Returns the result of the sigmoid function.\r\n    """"""\r\n\r\n    if type(sop) in [list, tuple]:\r\n        sop = numpy.array(sop)\r\n\r\n    return 1.0 / (1 + numpy.exp(-1 * sop))\r\n\r\ndef relu(sop):\r\n\r\n    """"""\r\n    Applies the rectified linear unit (ReLU) function.\r\n\r\n    sop: The input to which the relu function is applied.\r\n\r\n    Returns the result of the ReLU function.\r\n    """"""\r\n\r\n    if not (type(sop) in [list, tuple, numpy.ndarray]):\r\n        if sop < 0:\r\n            return 0\r\n        else:\r\n            return sop\r\n    elif type(sop) in [list, tuple]:\r\n        sop = numpy.array(sop)\r\n\r\n    result = sop\r\n    result[sop < 0] = 0\r\n\r\n    return result\r\n\r\ndef softmax(layer_outputs):\r\n\r\n    """"""\r\n    Applies the sotmax function.\r\n\r\n    sop: The input to which the softmax function is applied.\r\n\r\n    Returns the result of the softmax function.\r\n    """"""\r\n    return layer_outputs / (numpy.sum(layer_outputs) + 0.000001)\r\n\r\ndef layers_weights(model, initial=True):\r\n\r\n    """"""\r\n    Creates a list holding the weights of all layers in the CNN.\r\n\r\n    model: A reference to the instance from the cnn.Model class.\r\n    initial: When True, the function returns the initial weights of the layers. When False, the trained weights of the layers are returned. The initial weights are only needed before network training starts. The trained weights are needed to predict the network outputs.\r\n\r\n    Returns a list (network_weights) holding the weights of the layers in the CNN.\r\n    """"""\r\n\r\n    network_weights = []\r\n\r\n    layer = model.last_layer\r\n    while ""previous_layer"" in layer.__init__.__code__.co_varnames:\r\n        if type(layer) in [Conv2D, Dense]:\r\n            # If the \'initial\' parameter is True, append the initial weights. Otherwise, append the trained weights.\r\n            if initial == True:\r\n                network_weights.append(layer.initial_weights)\r\n            elif initial == False:\r\n                network_weights.append(layer.trained_weights)\r\n            else:\r\n                raise ValueError(""Unexpected value to the \'initial\' parameter: {initial}."".format(initial=initial))\r\n\r\n        # Go to the previous layer.\r\n        layer = layer.previous_layer\r\n\r\n    # If the first layer in the network is not an input layer (i.e. an instance of the Input2D class), raise an error.\r\n    if not (type(layer) is Input2D):\r\n        raise TypeError(""The first layer in the network architecture must be an input layer."")\r\n\r\n    # Currently, the weights of the layers are in the reverse order. In other words, the weights of the first layer are at the last index of the \'network_weights\' list while the weights of the last layer are at the first index.\r\n    # Reversing the \'network_weights\' list to order the layers\' weights according to their location in the network architecture (i.e. the weights of the first layer appears at index 0 of the list).\r\n    network_weights.reverse()\r\n    return numpy.array(network_weights)\r\n\r\ndef layers_weights_as_matrix(model, vector_weights):\r\n\r\n    """"""\r\n    Converts the network weights from vectors to matrices.\r\n\r\n    model: A reference to the instance from the cnn.Model class.\r\n    vector_weights: The network weights as vectors where the weights of each layer form a single vector.\r\n\r\n    Returns a list (network_weights) holding the weights of the CNN layers as matrices.\r\n    """"""\r\n\r\n    network_weights = []\r\n\r\n    start = 0\r\n    layer = model.last_layer\r\n    vector_weights = vector_weights[::-1]\r\n    while ""previous_layer"" in layer.__init__.__code__.co_varnames:\r\n        if type(layer) in [Conv2D, Dense]:\r\n            layer_weights_shape = layer.initial_weights.shape\r\n            layer_weights_size = layer.initial_weights.size\r\n    \r\n            weights_vector=vector_weights[start:start + layer_weights_size]\r\n    #        matrix = pygad.nn.DenseLayer.to_array(vector=weights_vector, shape=layer_weights_shape)\r\n            matrix = numpy.reshape(weights_vector, newshape=(layer_weights_shape))\r\n            network_weights.append(matrix)\r\n    \r\n            start = start + layer_weights_size\r\n    \r\n        # Go to the previous layer.\r\n        layer = layer.previous_layer\r\n\r\n    # If the first layer in the network is not an input layer (i.e. an instance of the Input2D class), raise an error.\r\n    if not (type(layer) is Input2D):\r\n        raise TypeError(""The first layer in the network architecture must be an input layer."")\r\n\r\n    # Currently, the weights of the layers are in the reverse order. In other words, the weights of the first layer are at the last index of the \'network_weights\' list while the weights of the last layer are at the first index.\r\n    # Reversing the \'network_weights\' list to order the layers\' weights according to their location in the network architecture (i.e. the weights of the first layer appears at index 0 of the list).\r\n    network_weights.reverse()\r\n    return numpy.array(network_weights)\r\n\r\ndef layers_weights_as_vector(model, initial=True):\r\n\r\n    """"""\r\n    Creates a list holding the weights of each layer (Conv and Dense) in the CNN as a vector.\r\n\r\n    model: A reference to the instance from the cnn.Model class.\r\n    initial: When True, the function returns the initial weights of the CNN. When False, the trained weights of the CNN layers are returned. The initial weights are only needed before network training starts. The trained weights are needed to predict the network outputs.\r\n    \r\n    Returns a list (network_weights) holding the weights of the CNN layers as a vector.\r\n    """"""\r\n\r\n    network_weights = []\r\n\r\n    layer = model.last_layer\r\n    while ""previous_layer"" in layer.__init__.__code__.co_varnames:\r\n        if type(layer) in [Conv2D, Dense]:\r\n            # If the \'initial\' parameter is True, append the initial weights. Otherwise, append the trained weights.\r\n            if initial == True:\r\n                vector = numpy.reshape(layer.initial_weights, newshape=(layer.initial_weights.size))\r\n    #            vector = pygad.nn.DenseLayer.to_vector(matrix=layer.initial_weights)\r\n                network_weights.extend(vector)\r\n            elif initial == False:\r\n                vector = numpy.reshape(layer.trained_weights, newshape=(layer.trained_weights.size))\r\n    #            vector = pygad.nn.DenseLayer.to_vector(array=layer.trained_weights)\r\n                network_weights.extend(vector)\r\n            else:\r\n                raise ValueError(""Unexpected value to the \'initial\' parameter: {initial}."".format(initial=initial))\r\n\r\n        # Go to the previous layer.\r\n        layer = layer.previous_layer\r\n\r\n    # If the first layer in the network is not an input layer (i.e. an instance of the Input2D class), raise an error.\r\n    if not (type(layer) is Input2D):\r\n        raise TypeError(""The first layer in the network architecture must be an input layer."")\r\n\r\n    # Currently, the weights of the layers are in the reverse order. In other words, the weights of the first layer are at the last index of the \'network_weights\' list while the weights of the last layer are at the first index.\r\n    # Reversing the \'network_weights\' list to order the layers\' weights according to their location in the network architecture (i.e. the weights of the first layer appears at index 0 of the list).\r\n    network_weights.reverse()\r\n    return numpy.array(network_weights)\r\n\r\ndef update_layers_trained_weights(model, final_weights):\r\n\r\n    """"""\r\n    After the network weights are trained, the \'trained_weights\' attribute of each layer is updated by the weights calculated after passing all the epochs (such weights are passed in the \'final_weights\' parameter).\r\n    By just passing a reference to the last layer in the network (i.e. output layer) in addition to the final weights, this function updates the \'trained_weights\' attribute of all layers.\r\n\r\n    model: A reference to the instance from the cnn.Model class.\r\n    final_weights: An array of layers weights as matrices after passing through all the epochs.\r\n    """"""\r\n\r\n    layer = model.last_layer\r\n    layer_idx = len(final_weights) - 1\r\n    while ""previous_layer"" in layer.__init__.__code__.co_varnames:\r\n        if type(layer) in [Conv2D, Dense]:\r\n            layer.trained_weights = final_weights[layer_idx]\r\n    \r\n            layer_idx = layer_idx - 1\r\n\r\n        # Go to the previous layer.\r\n        layer = layer.previous_layer\r\n\r\nclass Input2D:\r\n\r\n    """"""\r\n    Implementing the input layer of a CNN.\r\n    The CNN architecture must start with an input layer.\r\n    """"""\r\n\r\n    def __init__(self, input_shape):\r\n\r\n        """"""\r\n        input_shape: Shape of the input sample to the CNN.\r\n        """"""\r\n\r\n        # If the input sample has less than 2 dimensions, then an exception is raised.\r\n        if len(input_shape) < 2:\r\n            raise ValueError(""The Input2D class creates an input layer for data inputs with at least 2 dimensions but ({num_dim}) dimensions found."".format(num_dim=len(input_shape)))\r\n        # If the input sample has exactly 2 dimensions, the third dimension is set to 1.\r\n        elif len(input_shape) == 2:\r\n            input_shape = (input_shape[0], input_shape[1], 1)\r\n\r\n        for dim_idx, dim in enumerate(input_shape):\r\n            if dim <= 0:\r\n                raise ValueError(""The dimension size of the inputs cannot be <= 0. Please pass a valid value to the \'input_size\' parameter."")\r\n\r\n        self.input_shape = input_shape # Shape of the input sample.\r\n        self.layer_output_size = input_shape # Shape of the output from the current layer. For an input layer, it is the same as the shape of the input sample.\r\n\r\nclass Conv2D:\r\n\r\n    """"""\r\n    Implementing the convolution layer.\r\n    """"""\r\n\r\n    def __init__(self, num_filters, kernel_size, previous_layer, activation_function=None):\r\n\r\n        """"""\r\n        num_filters: Number of filters in the convolution layer.\r\n        kernel_size: Kernel size of the filter.\r\n        previous_layer: A reference to the previous layer.\r\n        activation_function=None: The name of the activation function to be used in the conv layer. If None, then no activation function is applied besides the convolution operation. The activation function can be applied by a separate layer.\r\n        """"""\r\n\r\n        if num_filters <= 0:\r\n            raise ValueError(""Number of filters cannot be <= 0. Please pass a valid value to the \'num_filters\' parameter."")\r\n        # Number of filters in the conv layer.\r\n        self.num_filters = num_filters\r\n\r\n        if kernel_size <= 0:\r\n            raise ValueError(""The kernel size cannot be <= 0. Please pass a valid value to the \'kernel_size\' parameter."")\r\n        # Kernel size of each filter.\r\n        self.kernel_size = kernel_size\r\n\r\n        # Validating the activation function\r\n        if (activation_function is None):\r\n            self.activation = None\r\n        elif (activation_function == ""relu""):\r\n            self.activation = relu\r\n        elif (activation_function == ""sigmoid""):\r\n            self.activation = sigmoid\r\n        elif (activation_function == ""softmax""):\r\n            raise ValueError(""The softmax activation function cannot be used in a conv layer."")\r\n        else:\r\n            raise ValueError(""The specified activation function \'{activation_function}\' is not among the supported activation functions {supported_activation_functions}. Please use one of the supported functions."".format(activation_function=activation_function, supported_activation_functions=supported_activation_functions))\r\n\r\n        # The activation function used in the current layer.\r\n        self.activation_function = activation_function\r\n\r\n        if previous_layer is None:\r\n            raise TypeError(""The previous layer cannot be of Type \'None\'. Please pass a valid layer to the \'previous_layer\' parameter."")\r\n        # A reference to the layer that preceeds the current layer in the network architecture.\r\n        self.previous_layer = previous_layer\r\n        \r\n        # A reference to the bank of filters.\r\n        self.filter_bank_size = (self.num_filters,\r\n                                 self.kernel_size, \r\n                                 self.kernel_size, \r\n                                 self.previous_layer.layer_output_size[-1])\r\n\r\n        # Initializing the filters of the conv layer.\r\n        self.initial_weights = numpy.random.uniform(low=-0.1,\r\n                                                    high=0.1,\r\n                                                    size=self.filter_bank_size)\r\n\r\n        # The trained filters of the conv layer. Only assigned a value after the network is trained (i.e. the train_network() function completes).\r\n        # Just initialized to be equal to the initial filters\r\n        self.trained_weights = self.initial_weights.copy()\r\n\r\n        # Size of the input to the layer.\r\n        self.layer_input_size = self.previous_layer.layer_output_size\r\n\r\n        # Size of the output from the layer.\r\n        # Later, it must conider strides and paddings\r\n        self.layer_output_size = (self.previous_layer.layer_output_size[0] - self.kernel_size + 1, \r\n                                  self.previous_layer.layer_output_size[1] - self.kernel_size + 1, \r\n                                  num_filters)\r\n\r\n        # The layer_output attribute holds the latest output from the layer.\r\n        self.layer_output = None\r\n\r\n    def conv_(self, input2D, conv_filter):\r\n        \r\n        """"""\r\n        Convolves the input (input2D) by a single filter (conv_filter).\r\n        \r\n        input2D: The input to be convolved by a single filter.\r\n        conv_filter: The filter convolving the input.\r\n        \r\n        Returns the result of convolution.\r\n        """"""\r\n\r\n        result = numpy.zeros(shape=(input2D.shape[0], input2D.shape[1], conv_filter.shape[0]))\r\n        # Looping through the image to apply the convolution operation.\r\n        for r in numpy.uint16(numpy.arange(self.filter_bank_size[1]/2.0, \r\n                              input2D.shape[0]-self.filter_bank_size[1]/2.0+1)):\r\n            for c in numpy.uint16(numpy.arange(self.filter_bank_size[1]/2.0, \r\n                                               input2D.shape[1]-self.filter_bank_size[1]/2.0+1)):\r\n                """"""\r\n                Getting the current region to get multiplied with the filter.\r\n                How to loop through the image and get the region based on \r\n                the image and filer sizes is the most tricky part of convolution.\r\n                """"""\r\n                if len(input2D.shape) == 2:\r\n                    curr_region = input2D[r-numpy.uint16(numpy.floor(self.filter_bank_size[1]/2.0)):r+numpy.uint16(numpy.ceil(self.filter_bank_size[1]/2.0)), \r\n                                          c-numpy.uint16(numpy.floor(self.filter_bank_size[1]/2.0)):c+numpy.uint16(numpy.ceil(self.filter_bank_size[1]/2.0))]\r\n                else:\r\n                    curr_region = input2D[r-numpy.uint16(numpy.floor(self.filter_bank_size[1]/2.0)):r+numpy.uint16(numpy.ceil(self.filter_bank_size[1]/2.0)), \r\n                                          c-numpy.uint16(numpy.floor(self.filter_bank_size[1]/2.0)):c+numpy.uint16(numpy.ceil(self.filter_bank_size[1]/2.0)), :]\r\n                # Element-wise multipliplication between the current region and the filter.\r\n                \r\n                for filter_idx in range(conv_filter.shape[0]):\r\n                    curr_result = curr_region * conv_filter[filter_idx]\r\n                    conv_sum = numpy.sum(curr_result) # Summing the result of multiplication.\r\n    \r\n                    if self.activation is None:\r\n                        result[r, c, filter_idx] = conv_sum # Saving the SOP in the convolution layer feature map.\r\n                    else:\r\n                        result[r, c, filter_idx] = self.activation(conv_sum) # Saving the activation function result in the convolution layer feature map.\r\n\r\n        # Clipping the outliers of the result matrix.\r\n        final_result = result[numpy.uint16(self.filter_bank_size[1]/2.0):result.shape[0]-numpy.uint16(self.filter_bank_size[1]/2.0), \r\n                              numpy.uint16(self.filter_bank_size[1]/2.0):result.shape[1]-numpy.uint16(self.filter_bank_size[1]/2.0), :]\r\n        return final_result\r\n\r\n    def conv(self, input2D):\r\n\r\n        """"""\r\n        Convolves the input (input2D) by a filter bank.\r\n        \r\n        input2D: The input to be convolved by the filter bank.\r\n\r\n        The conv() method saves the result of convolving the input by the filter bank in the layer_output attribute.\r\n        """"""\r\n\r\n        if len(input2D.shape) != len(self.initial_weights.shape) - 1: # Check if there is a match in the number of dimensions between the image and the filters.\r\n            raise ValueError(""Number of dimensions in the conv filter and the input do not match."")  \r\n        if len(input2D.shape) > 2 or len(self.initial_weights.shape) > 3: # Check if number of image channels matches the filter depth.\r\n            if input2D.shape[-1] != self.initial_weights.shape[-1]:\r\n                raise ValueError(""Number of channels in both the input and the filter must match."")\r\n        if self.initial_weights.shape[1] != self.initial_weights.shape[2]: # Check if filter dimensions are equal.\r\n            raise ValueError(\'A filter must be a square matrix. I.e. number of rows and columns must match.\')\r\n        if self.initial_weights.shape[1]%2==0: # Check if filter diemnsions are odd.\r\n            raise ValueError(\'A filter must have an odd size. I.e. number of rows and columns must be odd.\')\r\n\r\n        self.layer_output = self.conv_(input2D, self.trained_weights)\r\n\r\nclass AveragePooling2D:\r\n\r\n    """"""\r\n    Implementing the average pooling layer.\r\n    """"""\r\n\r\n    def __init__(self, pool_size, previous_layer, stride=2):\r\n\r\n        """"""\r\n        pool_size: Pool size.\r\n        previous_layer: Reference to the previous layer in the CNN architecture.\r\n        stride=2: Stride\r\n        """"""\r\n\r\n        if not (type(pool_size) is int):\r\n            raise ValueError(""The expected type of the pool_size is int but {pool_size_type} found."".format(pool_size_type=type(pool_size)))\r\n\r\n        if pool_size <= 0:\r\n            raise ValueError(""The passed value to the pool_size parameter cannot be <= 0."")\r\n        self.pool_size = pool_size\r\n\r\n        if stride <= 0:\r\n            raise ValueError(""The passed value to the stride parameter cannot be <= 0."")\r\n        self.stride = stride\r\n\r\n        if previous_layer is None:\r\n            raise TypeError(""The previous layer cannot be of Type \'None\'. Please pass a valid layer to the \'previous_layer\' parameter."")\r\n        # A reference to the layer that preceeds the current layer in the network architecture.\r\n        self.previous_layer = previous_layer\r\n\r\n        # Size of the input to the layer.\r\n        self.layer_input_size = self.previous_layer.layer_output_size\r\n\r\n        # Size of the output from the layer.\r\n        self.layer_output_size = (numpy.uint16((self.previous_layer.layer_output_size[0] - self.pool_size + 1)/stride + 1), \r\n                                  numpy.uint16((self.previous_layer.layer_output_size[1] - self.pool_size + 1)/stride + 1), \r\n                                  self.previous_layer.layer_output_size[-1])\r\n\r\n        # The layer_output attribute holds the latest output from the layer.\r\n        self.layer_output = None\r\n\r\n    def average_pooling(self, input2D):\r\n\r\n        """"""\r\n        Applies the average pooling operation.\r\n        \r\n        input2D: The input to which the average pooling operation is applied.\r\n\r\n        The average_pooling() method saves its result in the layer_output attribute.\r\n        """"""\r\n\r\n        # Preparing the output of the pooling operation.\r\n        pool_out = numpy.zeros((numpy.uint16((input2D.shape[0]-self.pool_size+1)/self.stride+1),\r\n                                numpy.uint16((input2D.shape[1]-self.pool_size+1)/self.stride+1),\r\n                                input2D.shape[-1]))\r\n        for map_num in range(input2D.shape[-1]):\r\n            r2 = 0\r\n            for r in numpy.arange(0,input2D.shape[0]-self.pool_size+1, self.stride):\r\n                c2 = 0\r\n                for c in numpy.arange(0, input2D.shape[1]-self.pool_size+1, self.stride):\r\n                    pool_out[r2, c2, map_num] = numpy.mean([input2D[r:r+self.pool_size,  c:c+self.pool_size, map_num]])\r\n                    c2 = c2 + 1\r\n                r2 = r2 +1\r\n\r\n        self.layer_output = pool_out\r\n\r\nclass MaxPooling2D:\r\n\r\n    """"""\r\n    Similar to the AveragePooling2D class except that it implements max pooling.\r\n    """"""\r\n\r\n    def __init__(self, pool_size, previous_layer, stride=2):\r\n        \r\n        """"""\r\n        pool_size: Pool size.\r\n        previous_layer: Reference to the previous layer in the CNN architecture.\r\n        stride=2: Stride\r\n        """"""\r\n        \r\n        if not (type(pool_size) is int):\r\n            raise ValueError(""The expected type of the pool_size is int but {pool_size_type} found."".format(pool_size_type=type(pool_size)))\r\n\r\n        if pool_size <= 0:\r\n            raise ValueError(""The passed value to the pool_size parameter cannot be <= 0."")\r\n        self.pool_size = pool_size\r\n\r\n        if stride <= 0:\r\n            raise ValueError(""The passed value to the stride parameter cannot be <= 0."")\r\n        self.stride = stride\r\n\r\n        if previous_layer is None:\r\n            raise TypeError(""The previous layer cannot be of Type \'None\'. Please pass a valid layer to the \'previous_layer\' parameter."")\r\n        # A reference to the layer that preceeds the current layer in the network architecture.\r\n        self.previous_layer = previous_layer\r\n\r\n        # Size of the input to the layer.\r\n        self.layer_input_size = self.previous_layer.layer_output_size\r\n\r\n        # Size of the output from the layer.\r\n        self.layer_output_size = (numpy.uint16((self.previous_layer.layer_output_size[0] - self.pool_size + 1)/stride + 1), \r\n                                  numpy.uint16((self.previous_layer.layer_output_size[1] - self.pool_size + 1)/stride + 1), \r\n                                  self.previous_layer.layer_output_size[-1])\r\n\r\n        # The layer_output attribute holds the latest output from the layer.\r\n        self.layer_output = None\r\n\r\n    def max_pooling(self, input2D):\r\n        \r\n        """"""\r\n        Applies the max pooling operation.\r\n        \r\n        input2D: The input to which the max pooling operation is applied.\r\n\r\n        The max_pooling() method saves its result in the layer_output attribute.\r\n        """"""\r\n        \r\n        # Preparing the output of the pooling operation.\r\n        pool_out = numpy.zeros((numpy.uint16((input2D.shape[0]-self.pool_size+1)/self.stride+1),\r\n                                numpy.uint16((input2D.shape[1]-self.pool_size+1)/self.stride+1),\r\n                                input2D.shape[-1]))\r\n        for map_num in range(input2D.shape[-1]):\r\n            r2 = 0\r\n            for r in numpy.arange(0,input2D.shape[0]-self.pool_size+1, self.stride):\r\n                c2 = 0\r\n                for c in numpy.arange(0, input2D.shape[1]-self.pool_size+1, self.stride):\r\n                    pool_out[r2, c2, map_num] = numpy.max([input2D[r:r+self.pool_size,  c:c+self.pool_size, map_num]])\r\n                    c2 = c2 + 1\r\n                r2 = r2 +1\r\n\r\n        self.layer_output = pool_out\r\n\r\nclass ReLU:\r\n\r\n    """"""\r\n    Implementing the ReLU layer.\r\n    """"""\r\n\r\n    def __init__(self, previous_layer):\r\n\r\n        """"""\r\n        previous_layer: Reference to the previous layer.\r\n        """"""\r\n\r\n        if previous_layer is None:\r\n            raise TypeError(""The previous layer cannot be of Type \'None\'. Please pass a valid layer to the \'previous_layer\' parameter."")\r\n\r\n        # A reference to the layer that preceeds the current layer in the network architecture.\r\n        self.previous_layer = previous_layer\r\n\r\n        # Size of the input to the layer.\r\n        self.layer_input_size = self.previous_layer.layer_output_size\r\n\r\n        # Size of the output from the layer.\r\n        self.layer_output_size = self.previous_layer.layer_output_size\r\n\r\n        # The layer_output attribute holds the latest output from the layer.\r\n        self.layer_output = None\r\n\r\n    def relu_layer(self, layer_input):\r\n\r\n        """"""\r\n        Applies the ReLU function over all elements in input to the ReLU layer.\r\n        \r\n        layer_input: The input to which the ReLU function is applied.\r\n\r\n        The relu_layer() method saves its result in the layer_output attribute.\r\n        """"""\r\n\r\n        self.layer_output_size = layer_input.size\r\n        self.layer_output = relu(layer_input)\r\n\r\nclass Sigmoid:\r\n\r\n    """"""\r\n    Implementing the sigmoid layer.\r\n    """"""\r\n\r\n    def __init__(self, previous_layer):\r\n\r\n        """"""\r\n        previous_layer: Reference to the previous layer.\r\n        """"""\r\n\r\n        if previous_layer is None:\r\n            raise TypeError(""The previous layer cannot be of Type \'None\'. Please pass a valid layer to the \'previous_layer\' parameter."")\r\n        # A reference to the layer that preceeds the current layer in the network architecture.\r\n        self.previous_layer = previous_layer\r\n\r\n        # Size of the input to the layer.\r\n        self.layer_input_size = self.previous_layer.layer_output_size\r\n\r\n        # Size of the output from the layer.\r\n        self.layer_output_size = self.previous_layer.layer_output_size\r\n\r\n        # The layer_output attribute holds the latest output from the layer.\r\n        self.layer_output = None\r\n\r\n    def sigmoid_layer(self, layer_input):\r\n\r\n        """"""\r\n        Applies the sigmoid function over all elements in input to the sigmoid layer.\r\n        \r\n        layer_input: The input to which the sigmoid function is applied.\r\n\r\n        The sigmoid_layer() method saves its result in the layer_output attribute.\r\n        """"""\r\n\r\n        self.layer_output_size = layer_input.size\r\n        self.layer_output = sigmoid(layer_input)\r\n\r\nclass Flatten:\r\n\r\n    """"""\r\n    Implementing the flatten layer.\r\n    """"""\r\n\r\n    def __init__(self, previous_layer):\r\n        \r\n        """"""\r\n        previous_layer: Reference to the previous layer.\r\n        """"""\r\n\r\n        if previous_layer is None:\r\n            raise TypeError(""The previous layer cannot be of Type \'None\'. Please pass a valid layer to the \'previous_layer\' parameter."")\r\n        # A reference to the layer that preceeds the current layer in the network architecture.\r\n        self.previous_layer = previous_layer\r\n\r\n        # Size of the input to the layer.\r\n        self.layer_input_size = self.previous_layer.layer_output_size\r\n\r\n        # Size of the output from the layer.\r\n        self.layer_output_size = functools.reduce(lambda x, y: x*y, self.previous_layer.layer_output_size)\r\n\r\n        # The layer_output attribute holds the latest output from the layer.\r\n        self.layer_output = None\r\n\r\n    def flatten(self, input2D):\r\n        \r\n        """"""\r\n        Reshapes the input into a 1D vector.\r\n        \r\n        input2D: The input to the Flatten layer that will be converted into a 1D vector.\r\n\r\n        The flatten() method saves its result in the layer_output attribute.\r\n        """"""\r\n\r\n        self.layer_output_size = input2D.size\r\n        self.layer_output = numpy.ravel(input2D)\r\n\r\nclass Dense:\r\n\r\n    """"""\r\n    Implementing the input dense (fully connected) layer of a CNN.\r\n    """"""\r\n\r\n    def __init__(self, num_neurons, previous_layer, activation_function=""relu""):\r\n\r\n        """"""\r\n        num_neurons: Number of neurons in the dense layer.\r\n        previous_layer: Reference to the previous layer.\r\n        activation_function: Name of the activation function to be used in the current layer.\r\n        """"""\r\n\r\n        if num_neurons <= 0:\r\n            raise ValueError(""Number of neurons cannot be <= 0. Please pass a valid value to the \'num_neurons\' parameter."")\r\n\r\n        # Number of neurons in the dense layer.\r\n        self.num_neurons = num_neurons\r\n\r\n        # Validating the activation function\r\n        if (activation_function == ""relu""):\r\n            self.activation = relu\r\n        elif (activation_function == ""sigmoid""):\r\n            self.activation = sigmoid\r\n        elif (activation_function == ""softmax""):\r\n            self.activation = softmax\r\n        else:\r\n            raise ValueError(""The specified activation function \'{activation_function}\' is not among the supported activation functions {supported_activation_functions}. Please use one of the supported functions."".format(activation_function=activation_function, supported_activation_functions=supported_activation_functions))\r\n\r\n        self.activation_function = activation_function\r\n\r\n        if previous_layer is None:\r\n            raise TypeError(""The previous layer cannot be of Type \'None\'. Please pass a valid layer to the \'previous_layer\' parameter."")\r\n        # A reference to the layer that preceeds the current layer in the network architecture.\r\n        self.previous_layer = previous_layer\r\n        \r\n        if type(self.previous_layer.layer_output_size) in [list, tuple, numpy.ndarray] and len(self.previous_layer.layer_output_size) > 1:\r\n            raise ValueError(""The input to the dense layer must be of type int but {sh} found."".format(sh=type(self.previous_layer.layer_output_size)))\r\n        # Initializing the weights of the layer.\r\n        self.initial_weights = numpy.random.uniform(low=-0.1,\r\n                                                    high=0.1,\r\n                                                    size=(self.previous_layer.layer_output_size, self.num_neurons))\r\n\r\n        # The trained weights of the layer. Only assigned a value after the network is trained (i.e. the train_network() function completes).\r\n        # Just initialized to be equal to the initial weights\r\n        self.trained_weights = self.initial_weights.copy()\r\n\r\n        # Size of the input to the layer.\r\n        self.layer_input_size = self.previous_layer.layer_output_size\r\n\r\n        # Size of the output from the layer.\r\n        self.layer_output_size = num_neurons\r\n\r\n        # The layer_output attribute holds the latest output from the layer.\r\n        self.layer_output = None\r\n\r\n    def dense_layer(self, layer_input):\r\n\r\n        """"""\r\n        Calculates the output of the dense layer.\r\n        \r\n        layer_input: The input to the dense layer\r\n\r\n        The dense_layer() method saves its result in the layer_output attribute.\r\n        """"""\r\n\r\n        if self.trained_weights is None:\r\n            raise TypeError(""The weights of the dense layer cannot be of Type \'None\'."")\r\n\r\n        sop = numpy.matmul(layer_input, self.trained_weights)\r\n\r\n        self.layer_output = self.activation(sop)\r\n\r\nclass Model:\r\n\r\n    """"""\r\n    Creating a CNN model.\r\n    """"""\r\n\r\n    def __init__(self, last_layer, epochs=10, learning_rate=0.01):\r\n        \r\n        """"""\r\n        last_layer: A reference to the last layer in the CNN architecture.\r\n        epochs=10: Number of epochs.\r\n        learning_rate=0.01: Learning rate.\r\n        """"""\r\n\r\n        self.last_layer = last_layer\r\n        self.epochs = epochs\r\n        self.learning_rate = learning_rate\r\n\r\n        # The network_layers attribute is a list holding references to all CNN layers.\r\n        self.network_layers = self.get_layers()\r\n\r\n    def get_layers(self):\r\n\r\n        """"""\r\n        Prepares a  list of all layers in the CNN model.\r\n        Returns the list.\r\n        """"""\r\n\r\n        network_layers = []\r\n\r\n        # The last layer in the network archietcture.\r\n        layer = self.last_layer\r\n\r\n        while ""previous_layer"" in layer.__init__.__code__.co_varnames:\r\n            network_layers.insert(0, layer)\r\n            layer = layer.previous_layer\r\n\r\n        return network_layers\r\n\r\n    def train(self, train_inputs, train_outputs):\r\n        \r\n        """"""\r\n        Trains the CNN model.\r\n        It is important to note that no learning algorithm is used for training the CNN. Just the learning rate is used for making some changes which is better than leaving the weights unchanged.\r\n        \r\n        train_inputs: Training data inputs.\r\n        train_outputs: Training data outputs. \r\n        """"""\r\n        \r\n        if (train_inputs.ndim != 4):\r\n            raise ValueError(""The training data input has {num_dims} but it must have 4 dimensions. The first dimension is the number of training samples, the second & third dimensions represent the width and height of the sample, and the fourth dimension represents the number of channels in the sample."".format(num_dims=train_inputs.ndim))    \r\n\r\n        if (train_inputs.shape[0] != len(train_outputs)):\r\n            raise ValueError(""Mismatch between the number of input samples and number of labels: {num_samples_inputs} != {num_samples_outputs}."".format(num_samples_inputs=train_inputs.shape[0], num_samples_outputs=len(train_outputs)))\r\n\r\n        network_predictions = []\r\n        network_error = 0\r\n    \r\n        for epoch in range(self.epochs):\r\n            print(""Epoch {epoch}"".format(epoch=epoch))\r\n            for sample_idx in range(train_inputs.shape[0]):\r\n                # print(""Sample {sample_idx}"".format(sample_idx=sample_idx))\r\n                self.feed_sample(train_inputs[sample_idx, :])\r\n    \r\n                try:\r\n                    predicted_label = numpy.where(numpy.max(self.last_layer.layer_output) == self.last_layer.layer_output)[0][0]\r\n                except IndexError:\r\n                    print(self.last_layer.layer_output)\r\n                    raise IndexError(""Index out of range"")\r\n                network_predictions.append(predicted_label)\r\n    \r\n                network_error = network_error + abs(predicted_label - train_outputs[sample_idx])\r\n\r\n            self.update_weights(network_error)\r\n\r\n    def feed_sample(self, sample):\r\n        \r\n        """"""\r\n        Feeds a sample in the CNN layers.\r\n        \r\n        sample: The samples to be fed to the CNN layers.\r\n        \r\n        Returns results of the last layer in the CNN.\r\n        """"""\r\n\r\n        last_layer_outputs = sample\r\n        for layer in self.network_layers:\r\n            if type(layer) is Conv2D:\r\n#                import time\r\n#                time1 = time.time()\r\n                layer.conv(input2D=last_layer_outputs)\r\n#                time2 = time.time()\r\n#                print(time2 - time1)\r\n            elif type(layer) is Dense:\r\n                layer.dense_layer(layer_input=last_layer_outputs)\r\n            elif type(layer) is MaxPooling2D:\r\n                layer.max_pooling(input2D=last_layer_outputs)\r\n            elif type(layer) is AveragePooling2D:\r\n                layer.average_pooling(input2D=last_layer_outputs)\r\n            elif type(layer) is ReLU:\r\n                layer.relu_layer(layer_input=last_layer_outputs)\r\n            elif type(layer) is Sigmoid:\r\n                layer.sigmoid_layer(layer_input=last_layer_outputs)\r\n            elif type(layer) is Flatten:\r\n                layer.flatten(input2D=last_layer_outputs)\r\n            elif type(layer) is Input2D:\r\n                pass\r\n            else:\r\n                print(""Other"")\r\n                raise TypeError(""The layer of type {layer_type} is not supported yet."".format(layer_type=type(layer)))\r\n\r\n            last_layer_outputs = layer.layer_output\r\n        return self.network_layers[-1].layer_output\r\n\r\n    def update_weights(self, network_error):\r\n        \r\n        """"""\r\n        Updates the weights of the CNN.\r\n        It is important to note that no learning algorithm is used for training the CNN. Just the learning rate is used for making some changes which is better than leaving the weights unchanged.\r\n        \r\n        This method loops through the layers and updates their weights.\r\n\r\n        network_error: The network error in the last epoch.\r\n        """"""\r\n        \r\n        for layer in self.network_layers:\r\n            if ""trained_weights"" in vars(layer).keys():\r\n                layer.trained_weights = layer.trained_weights - network_error * self.learning_rate * layer.trained_weights\r\n\r\n    def predict(self, data_inputs):\r\n\r\n        """"""\r\n        Uses the trained CNN for making predictions.\r\n        \r\n        data_inputs: The inputs to predict their label.\r\n\r\n        Returns a list holding the samples predictions.\r\n        """"""\r\n\r\n        if (data_inputs.ndim != 4):\r\n            raise ValueError(""The data input has {num_dims} but it must have 4 dimensions. The first dimension is the number of training samples, the second & third dimensions represent the width and height of the sample, and the fourth dimension represents the number of channels in the sample."".format(num_dims=data_inputs.ndim))\r\n\r\n        predictions = []\r\n        for sample in data_inputs:\r\n            probs = self.feed_sample(sample=sample)\r\n            predicted_label = numpy.where(numpy.max(probs) == probs)[0][0]\r\n            predictions.append(predicted_label)\r\n        return predictions\r\n\r\n    def summary(self):\r\n\r\n        """"""\r\n        Prints a summary of the CNN architecture.\r\n        """"""\r\n\r\n        print(""\\n----------Network Architecture----------"")\r\n        for layer in self.network_layers:\r\n            print(type(layer))\r\n        print(""----------------------------------------\\n"")\r\n'"
example.py,0,"b'import numpy\r\nimport pygad.cnn\r\n\r\n""""""\r\nConvolutional neural network implementation using NumPy\r\nA tutorial that helps to get started (Building Convolutional Neural Network using NumPy from Scratch) available in these links: \r\n    https://www.linkedin.com/pulse/building-convolutional-neural-network-using-numpy-from-ahmed-gad\r\n    https://towardsdatascience.com/building-convolutional-neural-network-using-numpy-from-scratch-b30aac50e50a\r\n    https://www.kdnuggets.com/2018/04/building-convolutional-neural-network-numpy-scratch.html\r\nIt is also translated into Chinese: http://m.aliyun.com/yunqi/articles/585741\r\n""""""\r\n\r\ntrain_inputs = numpy.load(""dataset_inputs.npy"")\r\ntrain_outputs = numpy.load(""dataset_outputs.npy"")\r\n\r\nsample_shape = train_inputs.shape[1:]\r\nnum_classes = 4\r\n\r\ninput_layer = pygad.cnn.Input2D(input_shape=sample_shape)\r\nconv_layer1 = pygad.cnn.Conv2D(num_filters=2,\r\n                               kernel_size=3,\r\n                               previous_layer=input_layer,\r\n                               activation_function=None)\r\nrelu_layer1 = pygad.cnn.Sigmoid(previous_layer=conv_layer1)\r\naverage_pooling_layer = pygad.cnn.AveragePooling2D(pool_size=2, \r\n                                                   previous_layer=relu_layer1,\r\n                                                   stride=2)\r\n\r\nconv_layer2 = pygad.cnn.Conv2D(num_filters=3,\r\n                               kernel_size=3,\r\n                               previous_layer=average_pooling_layer,\r\n                               activation_function=None)\r\nrelu_layer2 = pygad.cnn.ReLU(previous_layer=conv_layer2)\r\nmax_pooling_layer = pygad.cnn.MaxPooling2D(pool_size=2, \r\n                                           previous_layer=relu_layer2,\r\n                                           stride=2)\r\n\r\nconv_layer3 = pygad.cnn.Conv2D(num_filters=1,\r\n                               kernel_size=3,\r\n                               previous_layer=max_pooling_layer,\r\n                               activation_function=None)\r\nrelu_layer3 = pygad.cnn.ReLU(previous_layer=conv_layer3)\r\npooling_layer = pygad.cnn.AveragePooling2D(pool_size=2, \r\n                                           previous_layer=relu_layer3,\r\n                                           stride=2)\r\n\r\nflatten_layer = pygad.cnn.Flatten(previous_layer=pooling_layer)\r\ndense_layer1 = pygad.cnn.Dense(num_neurons=100, \r\n                               previous_layer=flatten_layer,\r\n                               activation_function=""relu"")\r\ndense_layer2 = pygad.cnn.Dense(num_neurons=num_classes, \r\n                               previous_layer=dense_layer1,\r\n                               activation_function=""softmax"")\r\n\r\nmodel = pygad.cnn.Model(last_layer=dense_layer2,\r\n                        epochs=1,\r\n                        learning_rate=0.01)\r\n\r\nmodel.summary()\r\n\r\nmodel.train(train_inputs=train_inputs, \r\n            train_outputs=train_outputs)\r\n\r\npredictions = model.predict(data_inputs=train_inputs)\r\nprint(predictions)\r\n\r\nnum_wrong = numpy.where(predictions != train_outputs)[0]\r\nnum_correct = train_outputs.size - num_wrong.size\r\naccuracy = 100 * (num_correct/train_outputs.size)\r\nprint(""Number of correct classifications : {num_correct}."".format(num_correct=num_correct))\r\nprint(""Number of wrong classifications : {num_wrong}."".format(num_wrong=num_wrong.size))\r\nprint(""Classification accuracy : {accuracy}."".format(accuracy=accuracy))\r\n'"
TutorialProject/NumPyCNN.py,0,"b'import numpy\r\nimport sys\r\n\r\n""""""\r\nConvolutional neural network implementation using NumPy.\r\nAn article describing this project is titled ""Building Convolutional Neural Network using NumPy from Scratch"". It is available in these links: https://www.linkedin.com/pulse/building-convolutional-neural-network-using-numpy-from-ahmed-gad/\r\nhttps://www.kdnuggets.com/2018/04/building-convolutional-neural-network-numpy-scratch.html\r\nIt is also translated into Chinese: http://m.aliyun.com/yunqi/articles/585741\r\n\r\nThe project is tested using Python 3.5.2 installed inside Anaconda 4.2.0 (64-bit)\r\nNumPy version used is 1.14.0\r\n\r\nFor more info., contact me:\r\n    Ahmed Fawzy Gad\r\n    KDnuggets: https://www.kdnuggets.com/author/ahmed-gad\r\n    LinkedIn: https://www.linkedin.com/in/ahmedfgad\r\n    Facebook: https://www.facebook.com/ahmed.f.gadd\r\n    ahmed.f.gad@gmail.com\r\n    ahmed.fawzy@ci.menofia.edu.eg\r\n""""""\r\n\r\ndef conv_(img, conv_filter):\r\n    filter_size = conv_filter.shape[1]\r\n    result = numpy.zeros((img.shape))\r\n    #Looping through the image to apply the convolution operation.\r\n    for r in numpy.uint16(numpy.arange(filter_size/2.0, \r\n                          img.shape[0]-filter_size/2.0+1)):\r\n        for c in numpy.uint16(numpy.arange(filter_size/2.0, \r\n                                           img.shape[1]-filter_size/2.0+1)):\r\n            """"""\r\n            Getting the current region to get multiplied with the filter.\r\n            How to loop through the image and get the region based on \r\n            the image and filer sizes is the most tricky part of convolution.\r\n            """"""\r\n            curr_region = img[r-numpy.uint16(numpy.floor(filter_size/2.0)):r+numpy.uint16(numpy.ceil(filter_size/2.0)), \r\n                              c-numpy.uint16(numpy.floor(filter_size/2.0)):c+numpy.uint16(numpy.ceil(filter_size/2.0))]\r\n            #Element-wise multipliplication between the current region and the filter.\r\n            curr_result = curr_region * conv_filter\r\n            conv_sum = numpy.sum(curr_result) #Summing the result of multiplication.\r\n            result[r, c] = conv_sum #Saving the summation in the convolution layer feature map.\r\n            \r\n    #Clipping the outliers of the result matrix.\r\n    final_result = result[numpy.uint16(filter_size/2.0):result.shape[0]-numpy.uint16(filter_size/2.0), \r\n                          numpy.uint16(filter_size/2.0):result.shape[1]-numpy.uint16(filter_size/2.0)]\r\n    return final_result\r\ndef conv(img, conv_filter):\r\n\r\n    if len(img.shape) != len(conv_filter.shape) - 1: # Check whether number of dimensions is the same\r\n        print(""Error: Number of dimensions in conv filter and image do not match."")  \r\n        exit()\r\n    if len(img.shape) > 2 or len(conv_filter.shape) > 3: # Check if number of image channels matches the filter depth.\r\n        if img.shape[-1] != conv_filter.shape[-1]:\r\n            print(""Error: Number of channels in both image and filter must match."")\r\n            sys.exit()\r\n    if conv_filter.shape[1] != conv_filter.shape[2]: # Check if filter dimensions are equal.\r\n        print(\'Error: Filter must be a square matrix. I.e. number of rows and columns must match.\')\r\n        sys.exit()\r\n    if conv_filter.shape[1]%2==0: # Check if filter diemnsions are odd.\r\n        print(\'Error: Filter must have an odd size. I.e. number of rows and columns must be odd.\')\r\n        sys.exit()\r\n\r\n    # An empty feature map to hold the output of convolving the filter(s) with the image.\r\n    feature_maps = numpy.zeros((img.shape[0]-conv_filter.shape[1]+1, \r\n                                img.shape[1]-conv_filter.shape[1]+1, \r\n                                conv_filter.shape[0]))\r\n\r\n    # Convolving the image by the filter(s).\r\n    for filter_num in range(conv_filter.shape[0]):\r\n        print(""Filter "", filter_num + 1)\r\n        curr_filter = conv_filter[filter_num, :] # getting a filter from the bank.\r\n        """""" \r\n        Checking if there are mutliple channels for the single filter.\r\n        If so, then each channel will convolve the image.\r\n        The result of all convolutions are summed to return a single feature map.\r\n        """"""\r\n        if len(curr_filter.shape) > 2:\r\n            conv_map = conv_(img[:, :, 0], curr_filter[:, :, 0]) # Array holding the sum of all feature maps.\r\n            for ch_num in range(1, curr_filter.shape[-1]): # Convolving each channel with the image and summing the results.\r\n                conv_map = conv_map + conv_(img[:, :, ch_num], \r\n                                  curr_filter[:, :, ch_num])\r\n        else: # There is just a single channel in the filter.\r\n            conv_map = conv_(img, curr_filter)\r\n        feature_maps[:, :, filter_num] = conv_map # Holding feature map with the current filter.\r\n    return feature_maps # Returning all feature maps.\r\n    \r\n\r\ndef pooling(feature_map, size=2, stride=2):\r\n    #Preparing the output of the pooling operation.\r\n    pool_out = numpy.zeros((numpy.uint16((feature_map.shape[0]-size+1)/stride+1),\r\n                            numpy.uint16((feature_map.shape[1]-size+1)/stride+1),\r\n                            feature_map.shape[-1]))\r\n    for map_num in range(feature_map.shape[-1]):\r\n        r2 = 0\r\n        for r in numpy.arange(0,feature_map.shape[0]-size+1, stride):\r\n            c2 = 0\r\n            for c in numpy.arange(0, feature_map.shape[1]-size+1, stride):\r\n                pool_out[r2, c2, map_num] = numpy.max([feature_map[r:r+size,  c:c+size, map_num]])\r\n                c2 = c2 + 1\r\n            r2 = r2 +1\r\n    return pool_out\r\n\r\ndef relu(feature_map):\r\n    #Preparing the output of the ReLU activation function.\r\n    relu_out = numpy.zeros(feature_map.shape)\r\n    for map_num in range(feature_map.shape[-1]):\r\n        for r in numpy.arange(0,feature_map.shape[0]):\r\n            for c in numpy.arange(0, feature_map.shape[1]):\r\n                relu_out[r, c, map_num] = numpy.max([feature_map[r, c, map_num], 0])\r\n    return relu_out\r\n'"
TutorialProject/example.py,0,"b'import skimage.data\r\nimport numpy\r\nimport matplotlib\r\nimport NumPyCNN as numpycnn\r\n\r\n""""""\r\nConvolutional neural network implementation using NumPy\r\nAn article describing this project is titled ""Building Convolutional Neural Network using NumPy from Scratch"". It is available in these links: https://www.linkedin.com/pulse/building-convolutional-neural-network-using-numpy-from-ahmed-gad/\r\nhttps://www.kdnuggets.com/2018/04/building-convolutional-neural-network-numpy-scratch.html\r\nIt is also translated into Chinese: http://m.aliyun.com/yunqi/articles/585741\r\n\r\nThe project is tested using Python 3.5.2 installed inside Anaconda 4.2.0 (64-bit)\r\nNumPy version used is 1.14.0\r\n\r\nFor more info., contact me:\r\n    Ahmed Fawzy Gad\r\n    KDnuggets: https://www.kdnuggets.com/author/ahmed-gad\r\n    LinkedIn: https://www.linkedin.com/in/ahmedfgad\r\n    Facebook: https://www.facebook.com/ahmed.f.gadd\r\n    ahmed.f.gad@gmail.com\r\n    ahmed.fawzy@ci.menofia.edu.eg\r\n""""""\r\n\r\n# Reading the image\r\n#img = skimage.io.imread(""test.jpg"")\r\n#img = skimage.data.checkerboard()\r\nimg = skimage.data.chelsea()\r\n#img = skimage.data.camera()\r\n\r\n# Converting the image into gray.\r\nimg = skimage.color.rgb2gray(img)\r\n\r\n# First conv layer\r\n#l1_filter = numpy.random.rand(2,7,7)*20 # Preparing the filters randomly.\r\nl1_filter = numpy.zeros((2,3,3))\r\nl1_filter[0, :, :] = numpy.array([[[-1, 0, 1], \r\n                                   [-1, 0, 1], \r\n                                   [-1, 0, 1]]])\r\nl1_filter[1, :, :] = numpy.array([[[1,   1,  1], \r\n                                   [0,   0,  0], \r\n                                   [-1, -1, -1]]])\r\n\r\nprint(""\\n**Working with conv layer 1**"")\r\nl1_feature_map = numpycnn.conv(img, l1_filter)\r\nprint(""\\n**ReLU**"")\r\nl1_feature_map_relu = numpycnn.relu(l1_feature_map)\r\nprint(""\\n**Pooling**"")\r\nl1_feature_map_relu_pool = numpycnn.pooling(l1_feature_map_relu, 2, 2)\r\nprint(""**End of conv layer 1**\\n"")\r\n\r\n# Second conv layer\r\nl2_filter = numpy.random.rand(3, 5, 5, l1_feature_map_relu_pool.shape[-1])\r\nprint(""\\n**Working with conv layer 2**"")\r\nl2_feature_map = numpycnn.conv(l1_feature_map_relu_pool, l2_filter)\r\nprint(""\\n**ReLU**"")\r\nl2_feature_map_relu = numpycnn.relu(l2_feature_map)\r\nprint(""\\n**Pooling**"")\r\nl2_feature_map_relu_pool = numpycnn.pooling(l2_feature_map_relu, 2, 2)\r\nprint(""**End of conv layer 2**\\n"")\r\n\r\n# Third conv layer\r\nl3_filter = numpy.random.rand(1, 7, 7, l2_feature_map_relu_pool.shape[-1])\r\nprint(""\\n**Working with conv layer 3**"")\r\nl3_feature_map = numpycnn.conv(l2_feature_map_relu_pool, l3_filter)\r\nprint(""\\n**ReLU**"")\r\nl3_feature_map_relu = numpycnn.relu(l3_feature_map)\r\nprint(""\\n**Pooling**"")\r\nl3_feature_map_relu_pool = numpycnn.pooling(l3_feature_map_relu, 2, 2)\r\nprint(""**End of conv layer 3**\\n"")\r\n\r\n# Graphing results\r\nfig0, ax0 = matplotlib.pyplot.subplots(nrows=1, ncols=1)\r\nax0.imshow(img).set_cmap(""gray"")\r\nax0.set_title(""Input Image"")\r\nax0.get_xaxis().set_ticks([])\r\nax0.get_yaxis().set_ticks([])\r\nmatplotlib.pyplot.savefig(""in_img.png"", bbox_inches=""tight"")\r\nmatplotlib.pyplot.close(fig0)\r\n\r\n# Layer 1\r\nfig1, ax1 = matplotlib.pyplot.subplots(nrows=3, ncols=2)\r\nax1[0, 0].imshow(l1_feature_map[:, :, 0]).set_cmap(""gray"")\r\nax1[0, 0].get_xaxis().set_ticks([])\r\nax1[0, 0].get_yaxis().set_ticks([])\r\nax1[0, 0].set_title(""L1-Map1"")\r\n\r\nax1[0, 1].imshow(l1_feature_map[:, :, 1]).set_cmap(""gray"")\r\nax1[0, 1].get_xaxis().set_ticks([])\r\nax1[0, 1].get_yaxis().set_ticks([])\r\nax1[0, 1].set_title(""L1-Map2"")\r\n\r\nax1[1, 0].imshow(l1_feature_map_relu[:, :, 0]).set_cmap(""gray"")\r\nax1[1, 0].get_xaxis().set_ticks([])\r\nax1[1, 0].get_yaxis().set_ticks([])\r\nax1[1, 0].set_title(""L1-Map1ReLU"")\r\n\r\nax1[1, 1].imshow(l1_feature_map_relu[:, :, 1]).set_cmap(""gray"")\r\nax1[1, 1].get_xaxis().set_ticks([])\r\nax1[1, 1].get_yaxis().set_ticks([])\r\nax1[1, 1].set_title(""L1-Map2ReLU"")\r\n\r\nax1[2, 0].imshow(l1_feature_map_relu_pool[:, :, 0]).set_cmap(""gray"")\r\nax1[2, 0].get_xaxis().set_ticks([])\r\nax1[2, 0].get_yaxis().set_ticks([])\r\nax1[2, 0].set_title(""L1-Map1ReLUPool"")\r\n\r\nax1[2, 1].imshow(l1_feature_map_relu_pool[:, :, 1]).set_cmap(""gray"")\r\nax1[2, 0].get_xaxis().set_ticks([])\r\nax1[2, 0].get_yaxis().set_ticks([])\r\nax1[2, 1].set_title(""L1-Map2ReLUPool"")\r\n\r\nmatplotlib.pyplot.savefig(""L1.png"", bbox_inches=""tight"")\r\nmatplotlib.pyplot.close(fig1)\r\n\r\n# Layer 2\r\nfig2, ax2 = matplotlib.pyplot.subplots(nrows=3, ncols=3)\r\nax2[0, 0].imshow(l2_feature_map[:, :, 0]).set_cmap(""gray"")\r\nax2[0, 0].get_xaxis().set_ticks([])\r\nax2[0, 0].get_yaxis().set_ticks([])\r\nax2[0, 0].set_title(""L2-Map1"")\r\n\r\nax2[0, 1].imshow(l2_feature_map[:, :, 1]).set_cmap(""gray"")\r\nax2[0, 1].get_xaxis().set_ticks([])\r\nax2[0, 1].get_yaxis().set_ticks([])\r\nax2[0, 1].set_title(""L2-Map2"")\r\n\r\nax2[0, 2].imshow(l2_feature_map[:, :, 2]).set_cmap(""gray"")\r\nax2[0, 2].get_xaxis().set_ticks([])\r\nax2[0, 2].get_yaxis().set_ticks([])\r\nax2[0, 2].set_title(""L2-Map3"")\r\n\r\nax2[1, 0].imshow(l2_feature_map_relu[:, :, 0]).set_cmap(""gray"")\r\nax2[1, 0].get_xaxis().set_ticks([])\r\nax2[1, 0].get_yaxis().set_ticks([])\r\nax2[1, 0].set_title(""L2-Map1ReLU"")\r\n\r\nax2[1, 1].imshow(l2_feature_map_relu[:, :, 1]).set_cmap(""gray"")\r\nax2[1, 1].get_xaxis().set_ticks([])\r\nax2[1, 1].get_yaxis().set_ticks([])\r\nax2[1, 1].set_title(""L2-Map2ReLU"")\r\n\r\nax2[1, 2].imshow(l2_feature_map_relu[:, :, 2]).set_cmap(""gray"")\r\nax2[1, 2].get_xaxis().set_ticks([])\r\nax2[1, 2].get_yaxis().set_ticks([])\r\nax2[1, 2].set_title(""L2-Map3ReLU"")\r\n\r\nax2[2, 0].imshow(l2_feature_map_relu_pool[:, :, 0]).set_cmap(""gray"")\r\nax2[2, 0].get_xaxis().set_ticks([])\r\nax2[2, 0].get_yaxis().set_ticks([])\r\nax2[2, 0].set_title(""L2-Map1ReLUPool"")\r\n\r\nax2[2, 1].imshow(l2_feature_map_relu_pool[:, :, 1]).set_cmap(""gray"")\r\nax2[2, 1].get_xaxis().set_ticks([])\r\nax2[2, 1].get_yaxis().set_ticks([])\r\nax2[2, 1].set_title(""L2-Map2ReLUPool"")\r\n\r\nax2[2, 2].imshow(l2_feature_map_relu_pool[:, :, 2]).set_cmap(""gray"")\r\nax2[2, 2].get_xaxis().set_ticks([])\r\nax2[2, 2].get_yaxis().set_ticks([])\r\nax2[2, 2].set_title(""L2-Map3ReLUPool"")\r\n\r\nmatplotlib.pyplot.savefig(""L2.png"", bbox_inches=""tight"")\r\nmatplotlib.pyplot.close(fig2)\r\n\r\n# Layer 3\r\nfig3, ax3 = matplotlib.pyplot.subplots(nrows=1, ncols=3)\r\nax3[0].imshow(l3_feature_map[:, :, 0]).set_cmap(""gray"")\r\nax3[0].get_xaxis().set_ticks([])\r\nax3[0].get_yaxis().set_ticks([])\r\nax3[0].set_title(""L3-Map1"")\r\n\r\nax3[1].imshow(l3_feature_map_relu[:, :, 0]).set_cmap(""gray"")\r\nax3[1].get_xaxis().set_ticks([])\r\nax3[1].get_yaxis().set_ticks([])\r\nax3[1].set_title(""L3-Map1ReLU"")\r\n\r\nax3[2].imshow(l3_feature_map_relu_pool[:, :, 0]).set_cmap(""gray"")\r\nax3[2].get_xaxis().set_ticks([])\r\nax3[2].get_yaxis().set_ticks([])\r\nax3[2].set_title(""L3-Map1ReLUPool"")\r\n\r\nmatplotlib.pyplot.savefig(""L3.png"", bbox_inches=""tight"")\r\nmatplotlib.pyplot.close(fig3)\r\n'"
