file_path,api_count,code
cap07/heroku-app/app.py,2,"b'import json\nimport sqlite3\nimport requests\nimport pickle\nimport string\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import ItalianStemmer\nfrom nltk import word_tokenize\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom tflearn import input_data, fully_connected, regression, DNN\n\nfrom flask import Flask, request\n\nTOKEN = """"\n\napp = Flask(__name__)\n\nd = pickle.load(open(""corpus.p"", ""rb""))\ntemi = d[\'temi\']\nclassi = d[\'classi\']\ndocumenti = d[\'documenti\']\n\ndatabase = ""bot.db""\nconn = sqlite3.connect(database)\ncursor = conn.cursor()\n\nstemmer = ItalianStemmer()\nstop = set(stopwords.words(\'italian\'))\n\n\ndef genera_temi(testo):\n    stop = set(stopwords.words(\'italian\'))\n    lista_parole = word_tokenize(testo)\n    temi = [\n        stemmer.stem(p.lower()) for p in lista_parole\n        if p not in stop and p not in string.punctuation\n    ]\n    return temi\n\n\ndef genera_input(lista_temi):\n    lista_input = [0] * len(temi)\n    for tema in lista_temi:\n        for i, t in enumerate(temi):\n            if t == tema:\n                lista_input[i] = 1\n    return (np.array(lista_input))\n\n\ndef BotANN():\n    tf.reset_default_graph()\n\n    rete = input_data(shape=[None, len(temi)])\n    rete = fully_connected(rete, 8)\n    rete = fully_connected(rete, 8)\n    rete = fully_connected(rete, len(classi), activation=\'softmax\')\n    rete = regression(rete)\n\n    model = DNN(rete, tensorboard_dir=\'logs\')\n    return model\n\n\nmodello = BotANN()\nmodello.load(""./rete"")\n\n\nSOGLIA_ERRORE = 0.25\n\n\ndef classifica(modello, array):\n    # genera le probabilit\xc3\xa0\n    prob = modello.predict([array])[0]\n    # filtro quelle che superano la soglia\n    risultati = [\n        [i,p] for i,p in enumerate(prob)\n        if p > SOGLIA_ERRORE\n    ]\n    # ordino per le classi pi\xc3\xb9 probabili\n    risultati.sort(key=lambda x: x[1], reverse=True)\n    lista_classi = []\n    for r in risultati:\n        lista_classi.append((list(classi)[r[0]], r[1]))\n    return lista_classi\n\n\n@app.route(\'/\', methods=[\'GET\', \'POST\'])\ndef risponditore():\n    if request.method == \'GET\':\n        # Quando registriamo un endpoint a un webhook, dobbiamo\n        # restituire la \'hub.challenge\', un parametro che\n        # serve a Facebook.\n        if request.args.get(""hub.mode"") == ""subscribe"" and \\\n                request.args.get(""hub.challenge""):\n            if not request.args.get(""hub.verify_token"") == TOKEN:\n                return ""Token errato"", 403\n            return request.args[""hub.challenge""], 200\n\n        return ""Sono un bot, non un sito web"", 200\n    elif request.method == \'POST\':\n        # \xc3\xa8 appena arrivato un messaggio\n        data = request.get_json()\n        if data[""object""] == ""page"":\n            for entry in data[""entry""]:\n                for messaging_event in entry[""messaging""]:\n                    utente = messaging_event[""sender""][""id""]\n                    domanda = messaging_event[""message""][""text""]\n                    risposta = elabora_risposta(domanda, utente)\n                    invia(utente, risposta)\n        return ""ho risposto"", 200\n\n\ndef invia(utente, messaggio):\n    params = {\n        ""access_token"": TOKEN\n    }\n    headers = {\n        ""Content-Type"": ""application/json""\n    }\n    data = json.dumps({\n        ""recipient"": {\n            ""id"": utente\n        },\n        ""message"": {\n            ""text"": messaggio\n        }\n    })\n    requests.post(""https://graph.facebook.com/v2.6/me/messages"", params=params, headers=headers, data=data)\n\n\ncontesti = {}\n\n\ndef elabora_risposta(frase, utente=""utente_prova""):\n    temi_frase = genera_temi(frase)\n    X = genera_input(temi_frase)\n    classi_predette = classifica(modello, X)\n    # tolgo le probabilit\xc3\xa0\n    classi_predette = [c[0] for c in classi_predette]\n\n    if classi_predette:\n        # ho un contesto settato?\n        if contesti.get(utente):\n            contesto = contesti[utente]\n\n            # quali classi hanno questo contesto?\n            q = """"""\n                SELECT classe FROM classi\n                INNER JOIN contesti ON (classi.id = contesti.id_classe)\n                WHERE classe IN ({})\n            """""".format("","".join(\n                ""\'{}\'"".format(classe) for classe in classi_predette\n            )\n            )\n            filtro_classi = [c[0] for c in cursor.execute(q).fetchall()]\n            if filtro_classi:\n                # ho almeno una classe predetta che usa un contesto\n                classi_predette = [c for c in classi_predette]\n\n        # leggo le risposte\n        q = """"""\n            SELECT risposta \n            FROM risposte\n            INNER JOIN classi ON (risposte.id_classe = classi.id)\n            WHERE classe = \'{0}\'\n        """""".format(classi_predette[0])\n        risposte = [r[0] for r in cursor.execute(q).fetchall()]\n\n        # scelgo una risposta\n        risposta = np.random.choice(risposte)\n\n        # imposto il contesto, se c\'\xc3\xa8\n        q = """"""\n            SELECT contesto from contesti\n            INNER JOIN classi ON (contesti.id_classe = classi.id)\n            INNER JOIN risposte ON (risposte.id_classe = classi.id)\n            WHERE risposta = ""{}""\n        """""".format(risposta)\n        contesto = cursor.execute(q).fetchone()\n        contesti[utente] = contesto[0] if contesto else None\n\n        return risposta\n\n\nif __name__ == \'__main__\':\n    app.run(debug=True)'"
