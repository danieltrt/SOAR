file_path,api_count,code
Case Study - Product Survey Analysis/TestDataGenerator.py,1,"b'# -*- coding: utf-8 -*-\n""""""\nThis module generates test data in .CSV format for the Case Study.\nThe data generated uses a random number generator to generate values and so the\noutput would be different between runs.\n\n\n@author: Allen Thomas Varghese\n@date: Mon Mar 28 07:57:59 2016\n""""""\nimport csv\nimport random\nimport numpy\nimport datetime\n\n\n# Define the list of products to be used in the test data file\nPRODUCT_LIST = [\'Product1\', \'Product2\', \'Product3\', \'Product4\', \'Product5\']\n\n\n# Set the seed for the random number generator to generate same results in\n# every run. The seed can be any arbitary integer.\n# Uncomment the below lines during testing/development\n# RANDOM_NUMBER_SEED = 1000\n# random.seed(RANDOM_NUMBER_SEED)\n# np.random.seed(RANDOM_NUMBER_SEED)\n\n\ndef some_random_number():\n    return random.randint(0, 1000)\n\n\ndef get_user_ids():\n    """"""\n    Use a choice distribution to generate a list of random unique values\n    i.e. without replacement of values\n    """"""\n    TOTAL_USERS = 50\n    return list(numpy.random.choice(\n        TOTAL_USERS, random.randint(1, TOTAL_USERS), replace=False\n    ))\n\n\ndef get_value_list():\n    """"""\n    Returns a list of values filled with random numbers.\n    The number of elements changes each time the function is called\n    """"""\n    return [some_random_number() for _ in range(some_random_number())]\n\n\ndef generate_test_data():\n    """"""\n    Create the test data file having the following information:\n    Row_ID: Unique ID for each row in the file\n    User_ID: A pre-defined set of user IDs\n    Product: The name of the product\n    Entry_Date: Date at which the data was entered\n    """"""\n    print(""Test data generation started..."")\n    processing_start_time = datetime.datetime.now()\n    \n    SURVEY_DURATION = 90   # In days    \n    today_date = datetime.datetime.today()\n    start_date = today_date - datetime.timedelta(days=SURVEY_DURATION)\n\n    with open(\'product_test_data.csv\', \'w\') as test_file:\n        file_writer = csv.writer(test_file, quoting=csv.QUOTE_ALL)\n        \n        # Write the file header\n        file_writer.writerow([\n            ""Row_ID"", ""User_ID"", ""Product"", ""Amount"", ""Entry_Date""\n        ])\n        \n        row_id = 1   # A Row ID to keep track of how many records were created\n        for day in range(SURVEY_DURATION):   # Data for each day of the survey\n            # Extract the date portion        \n            data_entry_date = str(\n                start_date + datetime.timedelta(days=day)\n            ).split()[0]\n            for user_id in get_user_ids():   # The user IDs change for each day\n                for product in PRODUCT_LIST:\n                    file_writer.writerow([\n                        row_id,\n                        user_id,\n                        product,\n                        get_value_list(),\n                        data_entry_date\n                    ])\n                    row_id += 1\n\n        processing_end_time = datetime.datetime.now()\n        print(""Test data file generated in %s min %s seconds with %s records"" % (\n            (processing_end_time - processing_start_time).seconds / 60,\n            (processing_end_time - processing_start_time).seconds,\n            row_id\n        ))\n\n\nif __name__ == \'__main__\':\n    generate_test_data()'"
DataMunging/DataMunging.py,0,"b'""""""\nCreated for Dublin Data Science Beginners Meetup session on 11-Aug-2015\n\nThis is an example to showcase the results of Data Munging in Python\nwith Pandas using wxPython GUI toolkit. The results are shown in a\nGrid for easy visualization of data.\n\n@author: Allen Thomas Varghese\n@email: allentv4u@gmail.com\n""""""\nimport wx\nimport wx.grid as wg\n\nimport os\nimport pandas as pd\n\n\nclass DataMungingUI(wx.Frame):\n    """""" Class to create the GUI """"""\n    def __init__(self):\n        super(DataMungingUI, self).__init__(\n            None, -1, ""Data Munging UI"", wx.DefaultPosition, wx.Size(800, 600)\n        )\n\n        # Constants for positioning controls\n        LEFT_MARGIN = 30\n        TOP_MARGIN = 30\n        DEFAULT_SPACING = 20\n\n        # Parameters: Parent, ID\n        panel = wx.Panel(self, -1)\n\n        # Parameters: Parent, ID, title, position\n        wx.StaticText(panel, -1, \'Choose CSV file to process:\', (LEFT_MARGIN, TOP_MARGIN))\n\n        # Parameters: Parent, ID, placeholder text, position, (width, height)\n        self.file_path_ctrl = wx.TextCtrl(panel, -1, \'\', (LEFT_MARGIN, TOP_MARGIN + DEFAULT_SPACING), (500, -1))\n\n        # Parameters: Parent, ID, label, position\n        wx.Button(panel, 9, \'Choose\', (LEFT_MARGIN + 520, TOP_MARGIN + DEFAULT_SPACING))\n\n        # Attaching event handler to the \'Choose\' button\n        # Parameters: Type of event, event handler function, ID of the control\n        self.Bind(wx.EVT_BUTTON, self.get_file_path, id=9)\n\n        wx.Button(panel, 10, \'Process File\', (LEFT_MARGIN, TOP_MARGIN + 3 * DEFAULT_SPACING))\n        # Attaching event handler to the \'Process File\' button\n        self.Bind(wx.EVT_BUTTON, self.process_csv_file, id=10)\n\n        # Creating the Grid to display information from the CSV file\n        self.data_grid = wg.Grid(panel, -1, (LEFT_MARGIN, TOP_MARGIN + 5 * DEFAULT_SPACING), (500, 150))\n        # Parameters: rows, columns\n        self.data_grid.CreateGrid(5, 5)\n        # Disable editing of values in the Grid\n        self.data_grid.EnableEditing(False)\n        # Set default alignment for all cells\n        # Parameters: Horizontal alignment, Vertical alignment\n        self.data_grid.SetDefaultCellAlignment(wx.ALIGN_RIGHT, wx.ALIGN_CENTRE)\n\n        self.status_bar = self.CreateStatusBar()\n        self.Centre()\n        self.Show(True)\n\n    def get_file_path(self, event):\n        """""" Show the File Dialog """"""\n        wcd = \'All files (*)|*|CSV files (*.csv)|*.csv|Text files (*.txt)|*.txt\'\n        dir = os.getcwd()\n        open_dlg = wx.FileDialog(\n            self, message=\'Choose a file\', defaultDir=dir, defaultFile=\'\',\n            wildcard=wcd, style=wx.OPEN|wx.CHANGE_DIR\n        )\n        path = """"\n        if open_dlg.ShowModal() == wx.ID_OK:\n            path = open_dlg.GetPath()\n        open_dlg.Destroy()\n        self.file_path_ctrl.SetValue(path)\n        self.status_bar.SetStatusText(\'CSV file path loaded\')\n\n    def perform_data_munging(self):\n        """""" Data Munging happens here. Return a Pandas DataFrame. """"""\n        # TODO: Add file loading code here\n        data = {\n            \'col1\': [1, 2, 3, 4, 5],\n            \'col2\': [\'v1\', \'v2\', \'v3\', \'v4\', \'v5\'],\n            \'col3\': [0.01, 0.25, 1.23, 25.03, 100.00]\n        }\n\n        # TODO: \n        # Add file processing code here\n        # ...\n        # ...\n        # ...\n\n        # Return only the top 1,000 records to avoid memory problems\n        df = pd.DataFrame(data).head(1000)\n        return df  # Change the return value based on above code\n\n    def process_csv_file(self, event):\n        """""" Processing the selected CSV file """"""\n        self.status_bar.SetStatusText(\'CSV file processing started...\')\n        df = self.perform_data_munging()\n        no_of_rows = len(df)\n        no_of_columns = len(df.columns)\n        self.data_grid.ClearGrid()  # Clear existing data in the grid\n        self.data_grid.DeleteCols(0, self.data_grid.GetNumberCols())  # Delete all the columns\n        self.data_grid.DeleteRows(0, self.data_grid.GetNumberRows())  # Delete all the rows\n        self.data_grid.InsertCols(0, no_of_columns)  # Add new columns\n        self.data_grid.InsertRows(0, no_of_rows)  # Add new rows\n        for col_index, col in enumerate(df.columns):\n            # Set the column label to match the value for the column in the CSV file\n            self.data_grid.SetColLabelValue(col_index, col)\n            for row_index, value in enumerate(df[col]):\n                self.data_grid.SetCellValue(row_index, col_index, str(value))\n        self.status_bar.SetStatusText(\'CSV file processing completed!\')\n\n\n# Display the GUI\napp = wx.App()\nDataMungingUI()\napp.MainLoop()\n'"
DataMunging/DataProcessing.py,0,"b'import pandas as pd\n\n\ndef sum_of_digits(str_value):\n    """"""\n    Sum up all the digits in a number till it is single digit\n    Eg:\n          1 => 1\n         11 => 2\n        123 => 6\n       1235 => 2\n         98 => 8\n    """"""\n    total = 0\n    for num in str_value:\n        total += int(num)\n    if total > 9:\n        return sum_of_digits(str(total))\n    return total\n\n    \ndef do_processing(file_name):\n    # Read an excel file. Make sure it is in in XLSX format and\n    # you have XlsxWriter package installed.\n    # Pandas uses this package to read excel files.\n    df = pd.read_excel(file_name)\n    # Split the name into first name and last name\n    # You will get a pandas Series which has 1 column with a list in each row\n    fn_ln_list = df[\'Name\'].str.split(\' \')\n    # Use list comprehension to build a list for the first name and last name\n    df[\'first_name\'] = [name[0] for name in fn_ln_list]\n    df[\'last_name\'] = [name[1] for name in fn_ln_list]\n\n    # Pandas DataFrame automatically recognizes the date field and converts\n    # it into a datetime object. Using strftime to convert the datetime object\n    # to a string in the format DDMMYYYY\n    df[\'dob\'] = df[\'Date Of Birth\'].apply(lambda x: x.strftime(\'%d%m%Y\'))\n    # Sum the numbers in DOB to a single digit\n    # Create a new field to save the sum of digits\n    df[\'sum_dob\'] = df[\'dob\'].apply(sum_of_digits)\n    print ""\\n\\n\\nDataFrame:\\n""\n    print ""----------\\n"", df\n    print ""\\n\\n\\nDataFrame Columns:\\n""\n    print ""------------------\\n"", df.columns\n    print ""\\n\\n\\nDataFrame Data Types:\\n""\n    print ""---------------------\\n"", df.dtypes\n\n\nif __name__ == \'__main__\':\n    file_name = \'person_details.xlsx\'\n    do_processing(file_name)'"
Database_Operations/python_mysql.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nThis is a tutorial for interacting with a database in python.\nBefore you execute this script, make sure you have MySQL database and its drivers installed.\nCreate a test database with a test table having some records.\n\nCreated on Wed Jul 15 13:22:10 2015\n@author: Allen Thomas Varghese\n""""""\n\nimport MySQLdb  # On error, try pip install mysql-python\n\n\ndef test_mysql():\n    # Connect to the MySQL database with the specified parameters\n    db = MySQLdb.connect(host=\'localhost\', user=\'root\', passwd=\'root\', db=\'tutorial\')\n\n    # Get access to a cursor object for interacting with the database\n    cursor = db.cursor()\n\n    # Execute a query to get the number of records from a table\n    print ""Executing the query to get the record count in \'test_table\'""\n    cursor.execute(\'SELECT COUNT(*) AS rec_count FROM test_table\')\n    # The result is a tuple with only one value. So get the value at index 0\n    print ""Number of records is %s"" % cursor.fetchone()[0]\n\n\n    # Execute a query to print out all the records from the table\n    cursor.execute(""SELECT * FROM test_table"")\n    for rec in cursor.fetchall():\n        print rec\n        # print rec[0], rec[1], rec[2]\n\n\n    # Using a dictionary cursor\n    cursor = db.cursor(MySQLdb.cursors.DictCursor)\n    print ""Executing the query to get the record count in \'test_table\'""\n    cursor.execute(\'SELECT COUNT(*) AS rec_count FROM test_table\')\n    print ""Number of records is %s"" % cursor.fetchone()[\'rec_count\']\n\n    cursor.execute(""SELECT * FROM test_table"")\n    for rec in cursor.fetchall():\n        print rec\n        # print rec[\'PK\'], rec[\'random_number\'], rec[\'comment\']\n\n    # Close the database connection\n    db.close()\n\n\nif __name__ == \'__main__\':\n    test_mysql()\n'"
Database_Operations/python_sqlite.py,0,"b'# -*- coding: utf-8 -*-\n""""""\nThis is a tutorial for interacting with a database in python.\nBefore you execute this script, make sure you have a sqlite database.\nCreate a test database with a test table having some records.\n\nCreated on Wed Jul 15 13:22:10 2015\n@author: Allen Thomas Varghese\n""""""\n\nimport sqlite3  # Bundled with Python\n\n\ndef create_sqlite_db():\n    # Connect to the sqlite database with the specified parameters\n    db = sqlite3.connect(\'test_sqlite.db\')\n    cursor = db.cursor()\n    try:\n        # If table exists, drop it\n        cursor.execute(""DROP TABLE `test_table`"")\n    except sqlite3.OperationalError:\n        pass\n\n    # Create the table\n    cursor.execute(""""""\n        CREATE TABLE `test_table` (\n          PK int(11) NOT NULL PRIMARY KEY,\n          random_number int(11) DEFAULT NULL,\n          comment varchar(45) DEFAULT NULL\n        )\n    """""")\n\n    # Insert 10 records in the table\n    for number in range(1, 11):\n        cursor.execute(\n            ""INSERT INTO test_table VALUES (?, ?, ?)"",\n            (number, number * 10, \'c%s\' % number)\n        )\n\n    # Save all the changes\n    db.commit()\n    db.close()\n\n\ndef test_sqlite():\n    # Connect to the sqlite database with the specified parameters\n    db = sqlite3.connect(\'test_sqlite.db\')\n\n    # Get access to a cursor object for interacting with the database\n    cursor = db.cursor()\n\n    # Execute a query to get the number of records from a table\n    print ""Executing the query to get the record count in \'test_table\'""\n    cursor.execute(\'SELECT COUNT(*) AS rec_count FROM test_table\')\n    # The result is a tuple with only one value. So get the value at index 0\n    print ""Number of records is %s"" % cursor.fetchone()[0]\n\n\n    # Execute a query to print out all the records from the table\n    cursor.execute(""SELECT * FROM test_table"")\n    for rec in cursor.fetchall():\n        print rec\n        # print rec[0], rec[1], rec[2]\n\n    # Close the database connection\n    db.close()\n\n\nif __name__ == \'__main__\':\n    create_sqlite_db()\n    test_sqlite()\n'"
Decision_Trees/decision_trees_classifier.py,0,"b'# -*- coding: utf-8 -*- #\n""""""\nCreated on Mon Jul 06 22:16:03 2015\n\n@author: Allen Thomas Varghese\n""""""\nimport pandas as pd\nfrom sklearn import tree\nfrom sklearn.externals.six import StringIO\n#import pydot\n\n\n# Convert strings to integer values with a lookup dictionary\noutlook_values = {\'sunny\': 1, \'overcast\': 2, \'rain\': 3}\ntemperature_values = {\'hot\': 1, \'mild\': 2, \'cool\': 3}\nhumidity_values = {\'high\': 1, \'normal\': 2}\nwindy_values = {False: 1, True: 2}\n\n\ndef create_decision_tree():\n    print ""\\nCreating Decision Tree...""\n    # Read CSV values into a pandas DataFrame.\n    # Use skipinitial space to remove the leading space\n    df = pd.read_csv(\'weather.csv\', skipinitialspace=True)\n\n    df[\'outlook\'] = map(lambda x: outlook_values[x], df[\'outlook\'])\n    df[\'temperature\'] = map(lambda x: temperature_values[x], df[\'temperature\'])\n    df[\'humidity\'] = map(lambda x: humidity_values[x], df[\'humidity\'])\n    df[\'windy\'] = map(lambda x: windy_values[x], df[\'windy\'])\n\n    print ""Input Data from CSV:\\n"", df\n\n    # Create the feature set\n    X = map(list, df[[\'outlook\', \'temperature\', \'humidity\', \'windy\']].values)    \n    print X\n\n    # Create the output values\n    Y = df[\'class\'].tolist()\n    print Y\n\n    # Reference: http://scikit-learn.org/stable/modules/tree.html    \n    # Default criteria for quality of split is \'gini\'\n    # clf = tree.DecisionTreeClassifier()\n\n    # Setting the criteria for quality of split to \'entropy\'    \n    clf = tree.DecisionTreeClassifier(criterion=\'entropy\')\n    \n    clf = clf.fit(X, Y)\n    \n    print ""Decision Tree created!""\n\n    make_predictions(clf)\n\n    return clf\n\n\ndef make_predictions(clf):\n    print ""\\nRunning predictions...""\n    # Verification: Check if a prediction matches with an existing value\n    # Expected Output: \'N\'\n    print ""Input Values: [\'sunny\', \'hot\', \'high\', False]""\n    print ""Prediction: "", clf.predict([\n        [\n            outlook_values[\'sunny\'],\n            temperature_values[\'hot\'],\n            humidity_values[\'high\'],\n            windy_values[False]\n        ]\n    ])\n    \n    # Predict a value that is not available in the input data\n    # Expected Output: \'P\'\n    print ""Input Values: [\'overcast\', \'mild\', \'normal\', True]""    \n    print ""Prediction: "", clf.predict([\n        [\n            outlook_values[\'overcast\'],\n            temperature_values[\'mild\'],\n            humidity_values[\'normal\'],\n            windy_values[True]\n        ]\n    ])\n    print ""Predictions generated!""\n\n\ndef generate_plot(clf):\n    # Run this only afer Graphviz is installed\n    print ""\\nGenerating plot...""\n    dot_data = StringIO()\n    tree.export_graphviz(clf, out_file=dot_data)\n    graph = pydot.graph_from_dot_data(dot_data.getvalue())\n    graph.write_pdf(""weather_forecast.pdf"")\n    print ""Plot generated!""\n\n\nif __name__ == \'__main__\':\n    print ""Staring execution...""\n    classifier = create_decision_tree()\n    # If you are on Windows, comment the below line out.\n    # Generating the plot requires Graphviz which in turn has dependencies on\n    # other python modules. I had to tweak the source of those modules to get\n    # the graph generation working.\n    # So use with discretion!\n    # Some of the guys reported everything to work in Ubuntu.\n    # You might get lucky if you try a Linux shell.\n    # generate_plot(classifier)\n    print ""\\nExecution Completed!""'"
Decision_Trees/decision_trees_regression.py,4,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Jul 07 20:42:01 2015\n\n@author: Allen Thomas Varghese\n""""""\nimport numpy as np\nfrom sklearn.tree import DecisionTreeRegressor\nimport matplotlib.pyplot as plt\n\n# Create a random dataset\nrng = np.random.RandomState(1)\nX = np.sort(5 * rng.rand(80, 1), axis=0)\ny = np.sin(X).ravel()\ny[::5] += 3 * (0.5 - rng.rand(16))\n\n# Fit regression model\nclf_1 = DecisionTreeRegressor(max_depth=2)\nclf_2 = DecisionTreeRegressor(max_depth=5)\nclf_3 = DecisionTreeRegressor(max_depth=3)\nclf_4 = DecisionTreeRegressor(max_depth=4)\n\nclf_1.fit(X, y)\nclf_2.fit(X, y)\nclf_3.fit(X, y)\nclf_4.fit(X, y)\n\n# Predict\nX_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\ny_1 = clf_1.predict(X_test)\ny_2 = clf_2.predict(X_test)\ny_3 = clf_3.predict(X_test)\ny_4 = clf_4.predict(X_test)\n\n# Plot the results\nplt.figure()\nplt.scatter(X, y, c=""k"", label=""data"")\n#plt.plot(X_test, y_1, c=""g"", label=""max_depth=2"", linewidth=2)\nplt.plot(X_test, y_2, c=""r"", label=""max_depth=5"", linewidth=2)\n#plt.plot(X_test, y_3, c=""b"", label=""max_depth=3"", linewidth=2)\n#plt.plot(X_test, y_4, c=""y"", label=""max_depth=4"", linewidth=2)\nplt.xlabel(""data"")\nplt.ylabel(""target"")\nplt.title(""Decision Tree Regression"")\nplt.legend()\nplt.show()'"
Persistence/Learning.py,2,"b'\nimport pickle\nimport h5py\nimport numpy as np\n\nm1 = np.random.random(size=(1000, 2000))\n\ndef save_hdf5(RandomData):\n    # Save the data in HDF5 format\n    with h5py.File(""TEST.h5"", ""w"") as hf:\n        group1 = hf.create_group(""M1Test"")\n        group1.create_dataset(""M1TestData"", data = RandomData)    \n        print(""Saving object to file hdf5"")\n\n\ndef save_binary(RandomData):\n    # Save the data in binary format\n    with open(""TEST.obj"", ""wb"") as file:\n        print(""Saving object to binary file"")\n        pickle.dump(RandomData, file)\n\n\ndef save_text(RandomData):\n    # Save the data in Text format\n    with open(""TEST.txt"", ""w"") as file:\n        print(""Saving object to file as text"")\n        np.savetxt(""TEST.txt"", RandomData, delimiter="","")\n\n\nif __name__ == ""__main__"":\n\n    save_hdf5(m1)\n    save_binary(m1)\n    save_text(m1)'"
Persistence/hdf5_exercises.py,4,"b'""""""\nThis module has examples for reading and writing from a HDF5 file.\nThe below code has examples for reading and writing Numpy arrays & Pandas dataframes.\n\nData in HDF5 files are saved using a key-value format. The keys can be grouped for \neasier access and is not always required. Data is stored in a HDF5 file just like it\nis done in the file system with the same hierarchial structure.\n\n\nReferences:\n-----------\n1) https://www.getdatajoy.com/learn/Read_and_Write_HDF5_from_Python\n2) http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_hdf.html\n3) http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_hdf.html\n""""""\nimport h5py\nimport numpy as np\nimport pandas as pd\n\n\ndef save_numpy():\n    m1 = np.random.random(size=(1000, 20))\n    m2 = np.random.random(size=(1000, 200))\n    m3 = np.random.random(size=(1000, 200))\n    \n    with h5py.File(""data.h5"", ""w"") as hf:\n        group1 = hf.create_group(""Group 1"")\n        group1.create_dataset(""grp1_dataset1"", data=m1)\n        \n        group2 = hf.create_group(""Group 2"")\n        group2.create_dataset(""grp2_dataset2"", data=m2)\n        \n        hf.create_dataset(""dataset3"", data=m3)\n    \n    with h5py.File(""data.h5"", ""r"") as hf:\n        print(""Keys: %s"" % list(hf.keys()))\n        print(""All Items: %s"" % list(hf.items()))\n        \n        group1 = hf.get(""Group 1"")\n        print(""Group 1 Items: %s"" % list(group1.items()))\n        \n        m1 = np.array(group1.get(""grp1_dataset1""))\n        print(""Dataset1: %s,  Size: %s"" % (type(m1), m1.size))\n\n\ndef save_pandas():\n    data = {\n        \'c1\': [1, 2, 3],\n        \'c2\': [\'a\', \'b\', \'c\']\n    }\n    df = pd.DataFrame(data)\n    print(""\\n\\nDataFrame\\n%r"" % df)\n\n    df.to_hdf(""data.h5"", ""dataframe_object"")\n\n    df = pd.read_hdf(""data.h5"", ""dataframe_object"")\n    print(""\\n\\nDataFrame from file\\n%r"" % df)\n\n\nif __name__ == ""__main__"":\n    save_numpy()\n    save_pandas()\n'"
Persistence/numpy_save.py,3,"b'""""""\nSave and restore numpy data\n""""""\nimport numpy as np\n\n\ndef save_data():\n    data = np.matrix((\n        [1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]\n    ))\n    with open(""numpy_obj.npy"", ""wb"") as npy_file:\n        np.save(npy_file, data)\n        print(""\\n\\nSave data to file : \'numpy_obj.npy\'"")\n\ndef load_data():\n    data = np.load(""numpy_obj.npy"")\n    print(""\\n\\nNumpy Array from file: %r"" % data)\n\n\nif __name__ == ""__main__"":\n    save_data()\n    load_data()\n'"
Persistence/pickling_exercises.py,0,"b'""""""\nThis module has examples of pickling in python.\n\nPickling is the process in which a python object is written to file in\nbinary format. Reading the object back from file is called ""Unpickling""\n\n\nReferences:\n-----------\n1) https://docs.python.org/3/library/pickle.html\n""""""\nimport pickle\n\n\ndef save():\n    some_data = {\'key\': [1, 2, 3, [\'a\', \'b\']]}\n    \n    # Save the data in binary format\n    with open(""pickle_data.obj"", ""wb"") as file:\n        print(""Saving object to file..."")\n        pickle.dump(some_data, file)\n    \n    with open(""pickle_data.obj"", ""rb"") as file:\n        pickled_obj = pickle.load(file)\n        print(""Load pickled object: %s"" % pickled_obj)\n\n\nif __name__ == ""__main__"":\n    save()\n'"
