file_path,api_count,code
setup.py,0,"b""from setuptools import setup, find_packages\n\n# To test locally: python setup.py sdist bdist_wheel\n# To upload to pypi: twine upload dist/*\n\nsetup(\n  name='facemorpher',\n  version='5.2.dev0',\n  author='Alyssa Quek',\n  author_email='alyssaquek@gmail.com',\n  description=('Warp, morph and average human faces!'),\n  keywords='face morphing, averaging, warping',\n  url='https://github.com/alyssaq/face_morpher',\n  license='MIT',\n  packages=find_packages(),\n  install_requires=[\n    'docopt',\n    'numpy',\n    'scipy',\n    'matplotlib',\n    'dlib'\n  ],\n  entry_points={'console_scripts': [\n      'facemorpher=facemorpher.morpher:main',\n      'faceaverager=facemorpher.averager:main'\n    ]\n  },\n  data_files=[('readme', ['README.rst'])],\n  long_description=open('README.rst').read(),\n)\n"""
facemorpher/__init__.py,0,"b'""""""\nFace Morpher module init code\n""""""\nfrom .morpher import morpher, list_imgpaths\nfrom .averager import averager\n\n__all__ = [\'list_imgpaths\',\n           \'morpher\',\n           \'averager\']\n'"
facemorpher/aligner.py,4,"b'""""""\nAlign face and image sizes\n""""""\nimport cv2\nimport numpy as np\n\ndef positive_cap(num):\n  """""" Cap a number to ensure positivity\n\n  :param num: positive or negative number\n  :returns: (overflow, capped_number)\n  """"""\n  if num < 0:\n    return 0, abs(num)\n  else:\n    return num, 0\n\ndef roi_coordinates(rect, size, scale):\n  """""" Align the rectangle into the center and return the top-left coordinates\n  within the new size. If rect is smaller, we add borders.\n\n  :param rect: (x, y, w, h) bounding rectangle of the face\n  :param size: (width, height) are the desired dimensions\n  :param scale: scaling factor of the rectangle to be resized\n  :returns: 4 numbers. Top-left coordinates of the aligned ROI.\n    (x, y, border_x, border_y). All values are > 0.\n  """"""\n  rectx, recty, rectw, recth = rect\n  new_height, new_width = size\n  mid_x = int((rectx + rectw/2) * scale)\n  mid_y = int((recty + recth/2) * scale)\n  roi_x = mid_x - int(new_width/2)\n  roi_y = mid_y - int(new_height/2)\n\n  roi_x, border_x = positive_cap(roi_x)\n  roi_y, border_y = positive_cap(roi_y)\n  return roi_x, roi_y, border_x, border_y\n\ndef scaling_factor(rect, size):\n  """""" Calculate the scaling factor for the current image to be\n      resized to the new dimensions\n\n  :param rect: (x, y, w, h) bounding rectangle of the face\n  :param size: (width, height) are the desired dimensions\n  :returns: floating point scaling factor\n  """"""\n  new_height, new_width = size\n  rect_h, rect_w = rect[2:]\n  height_ratio = rect_h / new_height\n  width_ratio = rect_w / new_width\n  scale = 1\n  if height_ratio > width_ratio:\n    new_recth = 0.8 * new_height\n    scale = new_recth / rect_h\n  else:\n    new_rectw = 0.8 * new_width\n    scale = new_rectw / rect_w\n  return scale\n\ndef resize_image(img, scale):\n  """""" Resize image with the provided scaling factor\n\n  :param img: image to be resized\n  :param scale: scaling factor for resizing the image\n  """"""\n  cur_height, cur_width = img.shape[:2]\n  new_scaled_height = int(scale * cur_height)\n  new_scaled_width = int(scale * cur_width)\n\n  return cv2.resize(img, (new_scaled_width, new_scaled_height))\n\ndef resize_align(img, points, size):\n  """""" Resize image and associated points, align face to the center\n    and crop to the desired size\n\n  :param img: image to be resized\n  :param points: *m* x 2 array of points\n  :param size: (height, width) tuple of new desired size\n  """"""\n  new_height, new_width = size\n\n  # Resize image based on bounding rectangle\n  rect = cv2.boundingRect(np.array([points], np.int32))\n  scale = scaling_factor(rect, size)\n  img = resize_image(img, scale)\n\n  # Align bounding rect to center\n  cur_height, cur_width = img.shape[:2]\n  roi_x, roi_y, border_x, border_y = roi_coordinates(rect, size, scale)\n  roi_h = np.min([new_height-border_y, cur_height-roi_y])\n  roi_w = np.min([new_width-border_x, cur_width-roi_x])\n\n  # Crop to supplied size\n  crop = np.zeros((new_height, new_width, 3), img.dtype)\n  crop[border_y:border_y+roi_h, border_x:border_x+roi_w] = (\n     img[roi_y:roi_y+roi_h, roi_x:roi_x+roi_w])\n\n  # Scale and align face points to the crop\n  points[:, 0] = (points[:, 0] * scale) + (border_x - roi_x)\n  points[:, 1] = (points[:, 1] * scale) + (border_y - roi_y)\n\n  return (crop, points)\n'"
facemorpher/averager.py,6,"b'""""""\n::\n\n  Face averager\n\n  Usage:\n    averager.py --images=<images_folder> [--blur] [--plot]\n              [--background=(black|transparent|average)]\n              [--width=<width>] [--height=<height>]\n              [--out=<filename>] [--destimg=<filename>]\n\n  Options:\n    -h, --help             Show this screen.\n    --images=<folder>      Folder to images (.jpg, .jpeg, .png)\n    --blur                 Flag to blur edges of image [default: False]\n    --width=<width>        Custom width of the images/video [default: 500]\n    --height=<height>      Custom height of the images/video [default: 600]\n    --out=<filename>       Filename to save the average face [default: result.png]\n    --destimg=<filename>   Destination face image to overlay average face\n    --plot                 Flag to display the average face [default: False]\n    --background=<bg>      Background of image to be one of (black|transparent|average) [default: black]\n    --version              Show version.\n""""""\n\nfrom docopt import docopt\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom facemorpher import locator\nfrom facemorpher import aligner\nfrom facemorpher import warper\nfrom facemorpher import blender\nfrom facemorpher import plotter\n\ndef list_imgpaths(imgfolder):\n  for fname in os.listdir(imgfolder):\n    if (fname.lower().endswith(\'.jpg\') or\n       fname.lower().endswith(\'.png\') or\n       fname.lower().endswith(\'.jpeg\')):\n      yield os.path.join(imgfolder, fname)\n\ndef sharpen(img):\n  blured = cv2.GaussianBlur(img, (0, 0), 2.5)\n  return cv2.addWeighted(img, 1.4, blured, -0.4, 0)\n\ndef load_image_points(path, size):\n  img = cv2.imread(path)\n  points = locator.face_points(img)\n\n  if len(points) == 0:\n    print(\'No face in %s\' % path)\n    return None, None\n  else:\n    return aligner.resize_align(img, points, size)\n\ndef averager(imgpaths, dest_filename=None, width=500, height=600, background=\'black\',\n             blur_edges=False, out_filename=\'result.png\', plot=False):\n\n  size = (height, width)\n\n  images = []\n  point_set = []\n  for path in imgpaths:\n    img, points = load_image_points(path, size)\n    if img is not None:\n      images.append(img)\n      point_set.append(points)\n\n  if len(images) == 0:\n    raise FileNotFoundError(\'Could not find any valid images.\' +\n                            \' Supported formats are .jpg, .png, .jpeg\')\n\n  if dest_filename is not None:\n    dest_img, dest_points = load_image_points(dest_filename, size)\n    if dest_img is None or dest_points is None:\n      raise Exception(\'No face or detected face points in dest img: \' + dest_filename)\n  else:\n    dest_img = np.zeros(images[0].shape, np.uint8)\n    dest_points = locator.average_points(point_set)\n\n  num_images = len(images)\n  result_images = np.zeros(images[0].shape, np.float32)\n  for i in range(num_images):\n    result_images += warper.warp_image(images[i], point_set[i],\n                                       dest_points, size, np.float32)\n\n  result_image = np.uint8(result_images / num_images)\n  face_indexes = np.nonzero(result_image)\n  dest_img[face_indexes] = result_image[face_indexes]\n\n  mask = blender.mask_from_points(size, dest_points)\n  if blur_edges:\n    blur_radius = 10\n    mask = cv2.blur(mask, (blur_radius, blur_radius))\n\n  if background in (\'transparent\', \'average\'):\n    dest_img = np.dstack((dest_img, mask))\n\n    if background == \'average\':\n      average_background = locator.average_points(images)\n      dest_img = blender.overlay_image(dest_img, mask, average_background)\n\n  print(\'Averaged {} images\'.format(num_images))\n  plt = plotter.Plotter(plot, num_images=1, out_filename=out_filename)\n  plt.save(dest_img)\n  plt.plot_one(dest_img)\n  plt.show()\n\ndef main():\n  args = docopt(__doc__, version=\'Face Averager 1.0\')\n  try:\n    averager(list_imgpaths(args[\'--images\']), args[\'--destimg\'],\n             int(args[\'--width\']), int(args[\'--height\']),\n             args[\'--background\'], args[\'--blur\'], args[\'--out\'], args[\'--plot\'])\n  except Exception as e:\n    print(e)\n\n\nif __name__ == ""__main__"":\n  main()\n'"
facemorpher/blender.py,10,"b'import cv2\nimport numpy as np\nimport scipy.sparse\n\ndef mask_from_points(size, points):\n  """""" Create a mask of supplied size from supplied points\n  :param size: tuple of output mask size\n  :param points: array of [x, y] points\n  :returns: mask of values 0 and 255 where\n            255 indicates the convex hull containing the points\n  """"""\n  radius = 10  # kernel size\n  kernel = np.ones((radius, radius), np.uint8)\n\n  mask = np.zeros(size, np.uint8)\n  cv2.fillConvexPoly(mask, cv2.convexHull(points), 255)\n  mask = cv2.erode(mask, kernel)\n\n  return mask\n\ndef overlay_image(foreground_image, mask, background_image):\n  """""" Overlay foreground image onto the background given a mask\n  :param foreground_image: foreground image points\n  :param mask: [0-255] values in mask\n  :param background_image: background image points\n  :returns: image with foreground where mask > 0 overlaid on background image\n  """"""\n  foreground_pixels = mask > 0\n  background_image[..., :3][foreground_pixels] = foreground_image[..., :3][foreground_pixels]\n  return background_image\n\ndef apply_mask(img, mask):\n  """""" Apply mask to supplied image\n  :param img: max 3 channel image\n  :param mask: [0-255] values in mask\n  :returns: new image with mask applied\n  """"""\n  masked_img = np.copy(img)\n  num_channels = 3\n  for c in range(num_channels):\n    masked_img[..., c] = img[..., c] * (mask / 255)\n\n  return masked_img\n\ndef weighted_average(img1, img2, percent=0.5):\n  if percent <= 0:\n    return img2\n  elif percent >= 1:\n    return img1\n  else:\n    return cv2.addWeighted(img1, percent, img2, 1-percent, 0)\n\ndef alpha_feathering(src_img, dest_img, img_mask, blur_radius=15):\n  mask = cv2.blur(img_mask, (blur_radius, blur_radius))\n  mask = mask / 255.0\n\n  result_img = np.empty(src_img.shape, np.uint8)\n  for i in range(3):\n    result_img[..., i] = src_img[..., i] * mask + dest_img[..., i] * (1-mask)\n\n  return result_img\n\ndef poisson_blend(img_source, dest_img, img_mask, offset=(0, 0)):\n  # http://opencv.jp/opencv2-x-samples/poisson-blending\n  img_target = np.copy(dest_img)\n  import pyamg\n  # compute regions to be blended\n  region_source = (\n    max(-offset[0], 0),\n    max(-offset[1], 0),\n    min(img_target.shape[0] - offset[0], img_source.shape[0]),\n    min(img_target.shape[1] - offset[1], img_source.shape[1]))\n  region_target = (\n    max(offset[0], 0),\n    max(offset[1], 0),\n    min(img_target.shape[0], img_source.shape[0] + offset[0]),\n    min(img_target.shape[1], img_source.shape[1] + offset[1]))\n  region_size = (region_source[2] - region_source[0],\n                 region_source[3] - region_source[1])\n\n  # clip and normalize mask image\n  img_mask = img_mask[region_source[0]:region_source[2],\n                      region_source[1]:region_source[3]]\n\n  # create coefficient matrix\n  coff_mat = scipy.sparse.identity(np.prod(region_size), format=\'lil\')\n  for y in range(region_size[0]):\n    for x in range(region_size[1]):\n      if img_mask[y, x]:\n        index = x + y * region_size[1]\n        coff_mat[index, index] = 4\n        if index + 1 < np.prod(region_size):\n          coff_mat[index, index + 1] = -1\n        if index - 1 >= 0:\n          coff_mat[index, index - 1] = -1\n        if index + region_size[1] < np.prod(region_size):\n          coff_mat[index, index + region_size[1]] = -1\n        if index - region_size[1] >= 0:\n          coff_mat[index, index - region_size[1]] = -1\n  coff_mat = coff_mat.tocsr()\n\n  # create poisson matrix for b\n  poisson_mat = pyamg.gallery.poisson(img_mask.shape)\n  # for each layer (ex. RGB)\n  for num_layer in range(img_target.shape[2]):\n    # get subimages\n    t = img_target[region_target[0]:region_target[2],\n                   region_target[1]:region_target[3], num_layer]\n    s = img_source[region_source[0]:region_source[2],\n                   region_source[1]:region_source[3], num_layer]\n    t = t.flatten()\n    s = s.flatten()\n\n    # create b\n    b = poisson_mat * s\n    for y in range(region_size[0]):\n      for x in range(region_size[1]):\n        if not img_mask[y, x]:\n          index = x + y * region_size[1]\n          b[index] = t[index]\n\n    # solve Ax = b\n    x = pyamg.solve(coff_mat, b, verb=False, tol=1e-10)\n\n    # assign x to target image\n    x = np.reshape(x, region_size)\n    x[x > 255] = 255\n    x[x < 0] = 0\n    x = np.array(x, img_target.dtype)\n    img_target[region_target[0]:region_target[2],\n               region_target[1]:region_target[3], num_layer] = x\n\n  return img_target\n'"
facemorpher/locator.py,7,"b'""""""\nLocate face points\n""""""\n\nimport cv2\nimport numpy as np\nimport os.path as path\nimport dlib\nimport os\n\n\nDATA_DIR = os.environ.get(\n  \'DLIB_DATA_DIR\',\n  path.join(path.dirname(path.dirname(path.realpath(__file__))), \'data\')\n)\ndlib_detector = dlib.get_frontal_face_detector()\ndlib_predictor = dlib.shape_predictor(path.join(DATA_DIR, \'shape_predictor_68_face_landmarks.dat\'))\n\ndef boundary_points(points, width_percent=0.1, height_percent=0.1):\n  """""" Produce additional boundary points\n  :param points: *m* x 2 array of x,y points\n  :param width_percent: [-1, 1] percentage of width to taper inwards. Negative for opposite direction\n  :param height_percent: [-1, 1] percentage of height to taper downwards. Negative for opposite direction\n  :returns: 2 additional points at the top corners\n  """"""\n  x, y, w, h = cv2.boundingRect(np.array([points], np.int32))\n  spacerw = int(w * width_percent)\n  spacerh = int(h * height_percent)\n  return [[x+spacerw, y+spacerh],\n          [x+w-spacerw, y+spacerh]]\n\n\ndef face_points(img, add_boundary_points=True):\n  return face_points_dlib(img, add_boundary_points)\n\ndef face_points_dlib(img, add_boundary_points=True):\n  """""" Locates 68 face points using dlib (http://dlib.net)\n    Requires shape_predictor_68_face_landmarks.dat to be in face_morpher/data\n    Download at: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n  :param img: an image array\n  :param add_boundary_points: bool to add additional boundary points\n  :returns: Array of x,y face points. Empty array if no face found\n  """"""\n  try:\n    points = []\n    rgbimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    rects = dlib_detector(rgbimg, 1)\n\n    if rects and len(rects) > 0:\n      # We only take the first found face\n      shapes = dlib_predictor(rgbimg, rects[0])\n      points = np.array([(shapes.part(i).x, shapes.part(i).y) for i in range(68)], np.int32)\n\n      if add_boundary_points:\n        # Add more points inwards and upwards as dlib only detects up to eyebrows\n        points = np.vstack([\n          points,\n          boundary_points(points, 0.1, -0.03),\n          boundary_points(points, 0.13, -0.05),\n          boundary_points(points, 0.15, -0.08),\n          boundary_points(points, 0.33, -0.12)])\n\n    return points\n  except Exception as e:\n    print(e)\n    return []\n\ndef face_points_stasm(img, add_boundary_points=True):\n  import stasm\n  """""" Locates 77 face points using stasm (http://www.milbo.users.sonic.net/stasm)\n\n  :param img: an image array\n  :param add_boundary_points: bool to add 2 additional points\n  :returns: Array of x,y face points. Empty array if no face found\n  """"""\n  try:\n    points = stasm.search_single(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n  except Exception as e:\n    print(\'Failed finding face points: \', e)\n    return []\n\n  points = points.astype(np.int32)\n  if len(points) == 0:\n    return points\n\n  if add_boundary_points:\n    return np.vstack([points, boundary_points(points)])\n\n  return points\n\ndef average_points(point_set):\n  """""" Averages a set of face points from images\n\n  :param point_set: *n* x *m* x 2 array of face points. \\\\\n  *n* = number of images. *m* = number of face points per image\n  """"""\n  return np.mean(point_set, 0).astype(np.int32)\n\ndef weighted_average_points(start_points, end_points, percent=0.5):\n  """""" Weighted average of two sets of supplied points\n\n  :param start_points: *m* x 2 array of start face points.\n  :param end_points: *m* x 2 array of end face points.\n  :param percent: [0, 1] percentage weight on start_points\n  :returns: *m* x 2 array of weighted average points\n  """"""\n  if percent <= 0:\n    return end_points\n  elif percent >= 1:\n    return start_points\n  else:\n    return np.asarray(start_points*percent + end_points*(1-percent), np.int32)\n'"
facemorpher/morpher.py,3,"b'""""""\n::\n\n  Morph from source to destination face or\n  Morph through all images in a folder\n\n  Usage:\n    morpher.py (--src=<src_path> --dest=<dest_path> | --images=<folder>)\n              [--width=<width>] [--height=<height>]\n              [--num=<num_frames>] [--fps=<frames_per_second>]\n              [--out_frames=<folder>] [--out_video=<filename>]\n              [--plot] [--background=(black|transparent|average)]\n\n  Options:\n    -h, --help              Show this screen.\n    --src=<src_imgpath>     Filepath to source image (.jpg, .jpeg, .png)\n    --dest=<dest_imgpath>   Filepath to destination image (.jpg, .jpeg, .png)\n    --images=<folder>       Folderpath to images\n    --width=<width>         Custom width of the images/video [default: 500]\n    --height=<height>       Custom height of the images/video [default: 600]\n    --num=<num_frames>      Number of morph frames [default: 20]\n    --fps=<fps>             Number frames per second for the video [default: 10]\n    --out_frames=<folder>   Folder path to save all image frames\n    --out_video=<filename>  Filename to save a video\n    --plot                  Flag to plot images to result.png [default: False]\n    --background=<bg>       Background of images to be one of (black|transparent|average) [default: black]\n    --version               Show version.\n""""""\nfrom docopt import docopt\nimport os\nimport numpy as np\nimport cv2\n\nfrom facemorpher import locator\nfrom facemorpher import aligner\nfrom facemorpher import warper\nfrom facemorpher import blender\nfrom facemorpher import plotter\nfrom facemorpher import videoer\n\ndef verify_args(args):\n  if args[\'--images\'] is None:\n    valid = os.path.isfile(args[\'--src\']) & os.path.isfile(args[\'--dest\'])\n    if not valid:\n      print(\'--src=%s or --dest=%s file does not exist. Double check the supplied paths\' % (\n        args[\'--src\'], args[\'--dest\']))\n      exit(1)\n  else:\n    valid = os.path.isdir(args[\'--images\'])\n    if not valid:\n      print(\'--images=%s is not a valid directory\' % args[\'--images\'])\n      exit(1)\n\ndef load_image_points(path, size):\n  img = cv2.imread(path)\n  points = locator.face_points(img)\n\n  if len(points) == 0:\n    print(\'No face in %s\' % path)\n    return None, None\n  else:\n    return aligner.resize_align(img, points, size)\n\ndef load_valid_image_points(imgpaths, size):\n  for path in imgpaths:\n    img, points = load_image_points(path, size)\n    if img is not None:\n      print(path)\n      yield (img, points)\n\ndef list_imgpaths(images_folder=None, src_image=None, dest_image=None):\n  if images_folder is None:\n    yield src_image\n    yield dest_image\n  else:\n    for fname in os.listdir(images_folder):\n      if (fname.lower().endswith(\'.jpg\') or\n         fname.lower().endswith(\'.png\') or\n         fname.lower().endswith(\'.jpeg\')):\n        yield os.path.join(images_folder, fname)\n\ndef morph(src_img, src_points, dest_img, dest_points,\n          video, width=500, height=600, num_frames=20, fps=10,\n          out_frames=None, out_video=None, plot=False, background=\'black\'):\n  """"""\n  Create a morph sequence from source to destination image\n\n  :param src_img: ndarray source image\n  :param src_points: source image array of x,y face points\n  :param dest_img: ndarray destination image\n  :param dest_points: destination image array of x,y face points\n  :param video: facemorpher.videoer.Video object\n  """"""\n  size = (height, width)\n  stall_frames = np.clip(int(fps*0.15), 1, fps)  # Show first & last longer\n  plt = plotter.Plotter(plot, num_images=num_frames, out_folder=out_frames)\n  num_frames -= (stall_frames * 2)  # No need to process src and dest image\n\n  plt.plot_one(src_img)\n  video.write(src_img, 1)\n\n  # Produce morph frames!\n  for percent in np.linspace(1, 0, num=num_frames):\n    points = locator.weighted_average_points(src_points, dest_points, percent)\n    src_face = warper.warp_image(src_img, src_points, points, size)\n    end_face = warper.warp_image(dest_img, dest_points, points, size)\n    average_face = blender.weighted_average(src_face, end_face, percent)\n\n    if background in (\'transparent\', \'average\'):\n      mask = blender.mask_from_points(average_face.shape[:2], points)\n      average_face = np.dstack((average_face, mask))\n\n      if background == \'average\':\n        average_background = blender.weighted_average(src_img, dest_img, percent)\n        average_face = blender.overlay_image(average_face, mask, average_background)\n\n    plt.plot_one(average_face)\n    plt.save(average_face)\n    video.write(average_face)\n\n  plt.plot_one(dest_img)\n  video.write(dest_img, stall_frames)\n  plt.show()\n\ndef morpher(imgpaths, width=500, height=600, num_frames=20, fps=10,\n            out_frames=None, out_video=None, plot=False, background=\'black\'):\n  """"""\n  Create a morph sequence from multiple images in imgpaths\n\n  :param imgpaths: array or generator of image paths\n  """"""\n  video = videoer.Video(out_video, fps, width, height)\n  images_points_gen = load_valid_image_points(imgpaths, (height, width))\n  src_img, src_points = next(images_points_gen)\n  for dest_img, dest_points in images_points_gen:\n    morph(src_img, src_points, dest_img, dest_points, video,\n          width, height, num_frames, fps, out_frames, out_video, plot, background)\n    src_img, src_points = dest_img, dest_points\n  video.end()\n\ndef main():\n  args = docopt(__doc__, version=\'Face Morpher 1.0\')\n  verify_args(args)\n\n  morpher(list_imgpaths(args[\'--images\'], args[\'--src\'], args[\'--dest\']),\n          int(args[\'--width\']), int(args[\'--height\']),\n          int(args[\'--num\']), int(args[\'--fps\']),\n          args[\'--out_frames\'], args[\'--out_video\'],\n          args[\'--plot\'], args[\'--background\'])\n\n\nif __name__ == ""__main__"":\n  main()\n'"
facemorpher/plotter.py,3,"b'""""""\nPlot and save images\n""""""\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport os.path\nimport numpy as np\nimport cv2\n\ndef bgr2rgb(img):\n  # OpenCV\'s BGR to RGB\n  rgb = np.copy(img)\n  rgb[..., 0], rgb[..., 2] = img[..., 2], img[..., 0]\n  return rgb\n\ndef check_do_plot(func):\n  def inner(self, *args, **kwargs):\n    if self.do_plot:\n      func(self, *args, **kwargs)\n\n  return inner\n\ndef check_do_save(func):\n  def inner(self, *args, **kwargs):\n    if self.do_save:\n      func(self, *args, **kwargs)\n\n  return inner\n\nclass Plotter(object):\n  def __init__(self, plot=True, rows=0, cols=0, num_images=0, out_folder=None, out_filename=None):\n    self.save_counter = 1\n    self.plot_counter = 1\n    self.do_plot = plot\n    self.do_save = out_filename is not None\n    self.out_filename = out_filename\n    self.set_filepath(out_folder)\n\n    if (rows + cols) == 0 and num_images > 0:\n      # Auto-calculate the number of rows and cols for the figure\n      self.rows = np.ceil(np.sqrt(num_images / 2.0))\n      self.cols = np.ceil(num_images / self.rows)\n    else:\n      self.rows = rows\n      self.cols = cols\n\n  def set_filepath(self, folder):\n    if folder is None:\n      self.filepath = None\n      return\n\n    if not os.path.exists(folder):\n      os.makedirs(folder)\n    self.filepath = os.path.join(folder, \'frame{0:03d}.png\')\n    self.do_save = True\n\n  @check_do_save\n  def save(self, img, filename=None):\n    if self.filepath:\n      filename = self.filepath.format(self.save_counter)\n      self.save_counter += 1\n    elif filename is None:\n      filename = self.out_filename\n\n    mpimg.imsave(filename, bgr2rgb(img))\n    print(filename + \' saved\')\n\n  @check_do_plot\n  def plot_one(self, img):\n    p = plt.subplot(self.rows, self.cols, self.plot_counter)\n    p.axes.get_xaxis().set_visible(False)\n    p.axes.get_yaxis().set_visible(False)\n    plt.imshow(bgr2rgb(img))\n    self.plot_counter += 1\n\n  @check_do_plot\n  def show(self):\n    plt.gcf().subplots_adjust(hspace=0.05, wspace=0,\n                              left=0, bottom=0, right=1, top=0.98)\n    plt.axis(\'off\')\n    #plt.show()\n    plt.savefig(\'result.png\')\n\n  @check_do_plot\n  def plot_mesh(self, points, tri, color=\'k\'):\n    """""" plot triangles """"""\n    for tri_indices in tri.simplices:\n      t_ext = [tri_indices[0], tri_indices[1], tri_indices[2], tri_indices[0]]\n      plt.plot(points[t_ext, 0], points[t_ext, 1], color)\n'"
facemorpher/videoer.py,0,"b'""""""\nCreate a video with image frames\n""""""\n\nimport cv2\nimport numpy as np\n\n\ndef check_write_video(func):\n  def inner(self, *args, **kwargs):\n    if self.video:\n      return func(self, *args, **kwargs)\n    else:\n      pass\n  return inner\n\n\nclass Video(object):\n  def __init__(self, filename, fps, w, h):\n    self.filename = filename\n\n    if filename is None:\n      self.video = None\n    else:\n      fourcc = cv2.VideoWriter_fourcc(*\'MJPG\')\n      self.video = cv2.VideoWriter(filename, fourcc, fps, (w, h), True)\n\n  @check_write_video\n  def write(self, img, num_times=1):\n    for i in range(num_times):\n      self.video.write(img[..., :3])\n\n  @check_write_video\n  def end(self):\n    print(self.filename + \' saved\')\n    self.video.release()\n'"
facemorpher/warper.py,15,"b'import numpy as np\nimport scipy.spatial as spatial\n\ndef bilinear_interpolate(img, coords):\n  """""" Interpolates over every image channel\n  http://en.wikipedia.org/wiki/Bilinear_interpolation\n\n  :param img: max 3 channel image\n  :param coords: 2 x _m_ array. 1st row = xcoords, 2nd row = ycoords\n  :returns: array of interpolated pixels with same shape as coords\n  """"""\n  int_coords = np.int32(coords)\n  x0, y0 = int_coords\n  dx, dy = coords - int_coords\n\n  # 4 Neighour pixels\n  q11 = img[y0, x0]\n  q21 = img[y0, x0+1]\n  q12 = img[y0+1, x0]\n  q22 = img[y0+1, x0+1]\n\n  btm = q21.T * dx + q11.T * (1 - dx)\n  top = q22.T * dx + q12.T * (1 - dx)\n  inter_pixel = top * dy + btm * (1 - dy)\n\n  return inter_pixel.T\n\ndef grid_coordinates(points):\n  """""" x,y grid coordinates within the ROI of supplied points\n\n  :param points: points to generate grid coordinates\n  :returns: array of (x, y) coordinates\n  """"""\n  xmin = np.min(points[:, 0])\n  xmax = np.max(points[:, 0]) + 1\n  ymin = np.min(points[:, 1])\n  ymax = np.max(points[:, 1]) + 1\n  return np.asarray([(x, y) for y in range(ymin, ymax)\n                     for x in range(xmin, xmax)], np.uint32)\n\ndef process_warp(src_img, result_img, tri_affines, dst_points, delaunay):\n  """"""\n  Warp each triangle from the src_image only within the\n  ROI of the destination image (points in dst_points).\n  """"""\n  roi_coords = grid_coordinates(dst_points)\n  # indices to vertices. -1 if pixel is not in any triangle\n  roi_tri_indices = delaunay.find_simplex(roi_coords)\n\n  for simplex_index in range(len(delaunay.simplices)):\n    coords = roi_coords[roi_tri_indices == simplex_index]\n    num_coords = len(coords)\n    out_coords = np.dot(tri_affines[simplex_index],\n                        np.vstack((coords.T, np.ones(num_coords))))\n    x, y = coords.T\n    result_img[y, x] = bilinear_interpolate(src_img, out_coords)\n\n  return None\n\ndef triangular_affine_matrices(vertices, src_points, dest_points):\n  """"""\n  Calculate the affine transformation matrix for each\n  triangle (x,y) vertex from dest_points to src_points\n\n  :param vertices: array of triplet indices to corners of triangle\n  :param src_points: array of [x, y] points to landmarks for source image\n  :param dest_points: array of [x, y] points to landmarks for destination image\n  :returns: 2 x 3 affine matrix transformation for a triangle\n  """"""\n  ones = [1, 1, 1]\n  for tri_indices in vertices:\n    src_tri = np.vstack((src_points[tri_indices, :].T, ones))\n    dst_tri = np.vstack((dest_points[tri_indices, :].T, ones))\n    mat = np.dot(src_tri, np.linalg.inv(dst_tri))[:2, :]\n    yield mat\n\ndef warp_image(src_img, src_points, dest_points, dest_shape, dtype=np.uint8):\n  # Resultant image will not have an alpha channel\n  num_chans = 3\n  src_img = src_img[:, :, :3]\n\n  rows, cols = dest_shape[:2]\n  result_img = np.zeros((rows, cols, num_chans), dtype)\n\n  delaunay = spatial.Delaunay(dest_points)\n  tri_affines = np.asarray(list(triangular_affine_matrices(\n    delaunay.simplices, src_points, dest_points)))\n\n  process_warp(src_img, result_img, tri_affines, dest_points, delaunay)\n\n  return result_img\n\ndef test_local():\n  from functools import partial\n  import cv2\n  import scipy.misc\n  import locator\n  import aligner\n  from matplotlib import pyplot as plt\n\n  # Load source image\n  face_points_func = partial(locator.face_points, \'../data\')\n  base_path = \'../females/Screenshot 2015-03-04 17.11.12.png\'\n  src_path = \'../females/BlDmB5QCYAAY8iw.jpg\'\n  src_img = cv2.imread(src_path)\n\n  # Define control points for warps\n  src_points = face_points_func(src_path)\n  base_img = cv2.imread(base_path)\n  base_points = face_points_func(base_path)\n\n  size = (600, 500)\n  src_img, src_points = aligner.resize_align(src_img, src_points, size)\n  base_img, base_points = aligner.resize_align(base_img, base_points, size)\n  result_points = locator.weighted_average_points(src_points, base_points, 0.2)\n\n  # Perform transform\n  dst_img1 = warp_image(src_img, src_points, result_points, size)\n  dst_img2 = warp_image(base_img, base_points, result_points, size)\n\n  import blender\n  ave = blender.weighted_average(dst_img1, dst_img2, 0.6)\n  mask = blender.mask_from_points(size, result_points)\n  blended_img = blender.poisson_blend(dst_img1, dst_img2, mask)\n\n  plt.subplot(2, 2, 1)\n  plt.imshow(ave)\n  plt.subplot(2, 2, 2)\n  plt.imshow(dst_img1)\n  plt.subplot(2, 2, 3)\n  plt.imshow(dst_img2)\n  plt.subplot(2, 2, 4)\n\n  plt.imshow(blended_img)\n  plt.show()\n\n\nif __name__ == ""__main__"":\n  test_local()\n'"
