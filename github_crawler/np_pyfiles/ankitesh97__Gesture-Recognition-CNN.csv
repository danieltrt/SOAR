file_path,api_count,code
cnn_model.py,101,"b'import numpy as np\nimport json\nimport pickle\nfrom img_preprocess import Preprocess\nfrom scipy.optimize import minimize,fmin_tnc\nimport time\nfrom joblib import Parallel, delayed\nimport multiprocessing\n\nparams_file  = open(\'params.json\',\'r\')\nparams = json.load(params_file)\nparams_file.close()\n#architecture\n#two black boxes i.e cnn->relu->max_pooling\n#fully connected with two hidden layers\nLAYER_1 = 0\nLAYER_2 = 1\nLAYER_3 = 2\nstart = time.time()\n\n\ndef backpropBodyParllel(self,X_pool,y_pool):\n\n    weight_layer_3_grads = np.zeros(self.weights[LAYER_3].shape)\n    weight_layer_2_grads = np.zeros(self.weights[LAYER_2].shape)\n    weight_layer_1_grads = np.zeros(self.weights[LAYER_1].shape)\n    kernel_layer_1_grads = np.zeros((self.n_filter_layer_1,self.filter_size_layer_1[0],self.filter_size_layer_1[1]))\n    kernel_layer_2_grads = np.zeros((self.n_filter_layer_2,)+self.filter_size_layer_2)\n    bias_layer_2_grads = np.zeros((self.n_filter_layer_2))\n    bias_layer_1_grads = np.zeros((self.n_filter_layer_1))\n    #get the batches\n    J = 0\n    for im_index in range(len(X_pool)):\n        # print ""im_index ""+str(im_index)\n        # raw_input()\n        X_curr = X_pool[im_index]\n        y_curr = y_pool[im_index]\n        layer_1_conv_box, layer_1_pooling, layer_2_conv_box, layer_2_pooling, fully_connected  = self.feedForward(X_curr,y_curr,training=False) #out vector\n        a_last_layer = fully_connected[\'a3\']\n        loss_curr = self.softmaxLoss(a_last_layer,y_curr)\n        J += loss_curr\n        #backprop in neural network\n\n        # last layer error for softmax function and log likelihood\n        d3 = (a_last_layer - y_curr).flatten()\n        #update weight error matrix make a coulmn vector and multiply\n        a2 = fully_connected[\'a2\']\n        weight_layer_3_grads += d3.reshape((d3.shape[0],1)) * a2\n        #propogate the error\n        z2 = fully_connected[\'z2\']\n        d2 = (np.dot(self.weights[LAYER_3].T,d3) * self.reluDerivative(z2))[1:] #350 X 1\n        a1 = fully_connected[\'a1\']\n        weight_layer_2_grads += d2.reshape((d2.shape[0],1)) * a1\n        # 1st hidden layer error\n        z1 = fully_connected[\'z1\']\n        d1 = (np.dot(self.weights[LAYER_2].T,d2) * self.reluDerivative(z1))[1:]\n        a0 = fully_connected[\'a0\']\n        weight_layer_1_grads += d1.reshape((d1.shape[0],1)) * a0\n        z0 = fully_connected[\'z0\']\n        # error in the input layer i,e the layer after the convnet box\n        d0 = (np.dot(self.weights[LAYER_1].T,d1) * self.reluDerivative(z0))[1:] #since the 1st is bias\n        # now propogate to convnet layer\n        # X_max_pooling_layer_2 this is nd matrix which contains last layer pixels\n        # X_relu_layer_2 will contain relu layer pixels\n        # max_x_pooling_layer_2,max_y_pooling_layer_2\n        X_max_pooling_layer_2 = layer_2_pooling[\'pooling_val\']\n        X_relu_layer_2 = layer_2_conv_box[\'relu\']\n        d_pooling_layer_2 = d0.reshape(X_max_pooling_layer_2.shape)\n        d_relu_layer_2 = np.zeros(X_relu_layer_2.shape)\n        #for each channel\n        max_x_pooling_layer_2 = layer_2_pooling[\'max_indexes_x\']\n        max_y_pooling_layer_2 = layer_2_pooling[\'max_indexes_y\']\n        for ch in range(d_relu_layer_2.shape[0]):\n            d_relu_layer_2[ch,max_x_pooling_layer_2[ch],max_y_pooling_layer_2[ch]] = d_pooling_layer_2[ch]\n\n        conv_layer_1_pooling_op = layer_1_pooling[\'pooling_val\']\n            #rotate dell and apply covolution with the previous layer output to get the errors\n        conv_layer_1_pooling_op_shape = conv_layer_1_pooling_op[0].shape\n\n        rotated_dell = np.flip(np.flip(d_relu_layer_2,-2),-1)\n        bias_layer_2_grads = np.sum(rotated_dell,axis=(-1,-2))\n        rotated_dell = rotated_dell.reshape((self.n_filter_layer_2,1,rotated_dell.shape[-2],rotated_dell.shape[-1]))\n        conv_layer_1_pooling_op_reshaped = conv_layer_1_pooling_op.reshape((1,conv_layer_1_pooling_op.shape[0],conv_layer_1_pooling_op.shape[1],conv_layer_1_pooling_op.shape[2]))\n        grads = self.convOpOpti(conv_layer_1_pooling_op_reshaped,rotated_dell,conv_layer_1_pooling_op_reshaped.shape[-2:],rotated_dell.shape[-2:],self.filter_size_layer_2[1:] ,backpass=1)\n        grads = np.flip(np.flip(grads,-2),-1)\n        kernel_layer_2_grads += grads\n        #at this point we have all grads for all kernel of conv layer 2, now we have to propogate error backwards\n        dell_pooled_layer_1 = np.zeros(conv_layer_1_pooling_op.shape)\n        stacked_kernel_2 = np.array(self.filters_layer_2)\n        stacked_kernel_2 = np.flip(np.flip(stacked_kernel_2,-2),-1)\n        d_relu_layer_2_reshaped = d_relu_layer_2.reshape((d_relu_layer_2.shape[0],1)+d_relu_layer_2.shape[1:])\n\n        dell_pooled_layer_1 = self.convOpOpti(d_relu_layer_2_reshaped,stacked_kernel_2, d_relu_layer_2_reshaped.shape[-2:],stacked_kernel_2.shape[-2:],-1,convType=""full"")\n        conv_layer_1_pooling_op_non_activated = layer_1_pooling[\'pooled_non_activated\']\n\n        dell_pooling_layer_1 = dell_pooled_layer_1 * self.reluDerivative(conv_layer_1_pooling_op_non_activated)\n        #at this point i have all the dell in the maxed_pooled layer now to propogate to layer before it\n        X_relu_layer_1 = layer_1_conv_box[\'relu\']\n        dell_relu_layer_1 = np.zeros(X_relu_layer_1.shape)\n        max_x_pooling_layer_1 = layer_1_pooling[\'max_indexes_x\']\n        max_y_pooling_layer_1 = layer_1_pooling[\'max_indexes_y\']\n        for ch in range(dell_relu_layer_1.shape[0]):\n            dell_relu_layer_1[ch,max_x_pooling_layer_1[ch],max_y_pooling_layer_1[ch]] = dell_pooling_layer_1[ch]\n\n        bias_layer_1_grads = np.sum(dell_relu_layer_1,axis=(-2,-1))\n        #now to get change in weights\n        rotated_dell = np.flip(np.flip(dell_relu_layer_1,-2),-1)\n        # bias_layer_1_grads = np.sum(rotated_dell,axis=(-1,-2))\n        X_curr_reshaped = X_curr.reshape((1,)+X_curr.shape)\n        grads = self.convOpOpti(X_curr_reshaped,rotated_dell,self.input_dim,rotated_dell.shape[-2:],self.filter_size_layer_1)\n        grads = np.flip(np.flip(grads,-2),-1)\n        kernel_layer_1_grads += grads\n\n    # at this point all the grads are calculated now just to stack it up into 1d array\n    #will stack up in forward fashion\n    all_grads = np.array([])\n    # 1 st conv layer all kernel\'s biases, all_kernels\n    all_grads = np.concatenate((all_grads,bias_layer_1_grads,kernel_layer_1_grads.flatten()))\n    #2nd conv layer params\n    all_grads = np.concatenate((all_grads,bias_layer_2_grads,np.array(kernel_layer_2_grads).flatten()))\n    #fully connected now\n    all_grads = np.concatenate((all_grads, weight_layer_1_grads.flatten(), weight_layer_2_grads.flatten(),weight_layer_3_grads.flatten()))\n    # self.gradientCheck(""conv_2"",X_pool,y_pool,kernel_layer_1_grads.flatten(),bias = bias_layer_1_grads)\n    # print ""type any char to move forward""\n    # raw_input()\n    return J, all_grads\n\n\nclass CNN:\n\n    def __init__(self):\n        self.obj = Preprocess() #this will return all images i.e X values and the expected output\n        #layer 1 params\n        self.input_dim = params[\'input_dim\'][\'val\']\n        self.n_padding_bits = params[\'n_padding_bits\'][\'val\']\n        self.n_filter_layer_1 = params[\'n_filter_layer_1\'][\'val\']\n        self.filter_size_layer_1 = params[\'filter_size_layer_1\'][\'val\']\n        self.filter_stride = params[\'filter_stride\'][\'val\']\n        temp_dim = (self.input_dim[0] - self.filter_size_layer_1[0] + 2*self.n_padding_bits)/self.filter_stride + 1\n        self.conv_op_layer_1_out_dim = [temp_dim, temp_dim] #output dimension after 1st layer convolution operation by default 50x50\n        tmp_dim_pooling = (temp_dim - params[\'pooling_filter_size_layer_1\'][\'val\'][0])/params[""pooling_stride_layer_1""][""val""] + 1\n        self.pooling_layer_1_out_dim = [tmp_dim_pooling,tmp_dim_pooling]\n        self.filters_layer_1 = []\n        self.bias_layer_1 = []\n        #layer 2 params\n        self.n_filter_layer_2 = params[\'n_filter_layer_2\'][""val""]\n        self.filter_size_layer_2 = tuple([self.n_filter_layer_1,params[\'filter_size_layer_2\'][\'val\'][0],params[\'filter_size_layer_2\'][\'val\'][1]])\n        self.filters_layer_2 = []\n        self.bias_layer_2 = []\n        tmp_dim = (self.pooling_layer_1_out_dim[0] - self.filter_size_layer_2[1])/self.filter_stride + 1 #by default this will be 23*23\n        self.conv_op_layer_2_out_dim =  [tmp_dim,tmp_dim]\n        tmp_dim_pooling = (tmp_dim - params[\'pooling_filter_size_layer_2\'][\'val\'][0])/params[""pooling_stride_layer_2""][""val""] + 1\n        self.pooling_layer_2_out_dim = [tmp_dim_pooling,tmp_dim_pooling] #by default 22\n        self.out_nodes_after_conv = self.pooling_layer_2_out_dim[0]*self.pooling_layer_2_out_dim[1]*self.n_filter_layer_2 #1452 by defailt\n        #fully connected layers\n        self.n_hidden_layers = params[\'n_hidden_layers\'][""val""]\n        self.weights = [] #will contain the weights of the network total 3\n        self.n_nodes_hidden_layer_1 = params[""n_nodes_hidden_layer_1""][""val""]\n        self.n_nodes_hidden_layer_2 = params[""n_nodes_hidden_layer_2""][""val""]\n        self.output_classes = params[""output_classes""][""val""]\n        self.dropout_percent_layer_1 = params[""dropout_percent_layer_1""][""val""]\n        self.dropout_percent_layer_2 = params[""dropout_percent_layer_2""][""val""]\n        self.intermediate_results = {}\n        self.count = 0\n        self.losses = []\n\n    def train(self):\n        #flow\n        #train -> gradient descent -> backward_prop -> feed_forward to calculate values\n        self.obj = self.obj.process()\n        X_train,y_train = self.obj.X_train, self.obj.y_train\n        # X_train = np.array([X[0:18,0:18] for X in X_train])\n        print len(X_train)\n        X_train = self.padBits(X_train,self.n_padding_bits) #will return the all images after padding\n        #make random weights i.e filters\n        self.randomFilterValues()\n        #make params vector\n        theta = self.makeThetaVector()\n        # print theta, len(theta)\n        print ""training starting""\n        vals = self.gradientDescent(theta,X_train,y_train)\n        n_epochs = params[\'n_epochs\']\n        learning_rate = params[\'learning_rate\']\n        mini_batch_size = params[\'batch_size\']\n        # vals = self.MiniBatchGd(theta,X_train,y_train,n_epochs=n_epochs, mini_batch_size=mini_batch_size,learning_rate=learning_rate)\n        self.fromThetaVectorToWeights(vals.x)\n        #pickle the object\n\n\n\n\n    @staticmethod\n    def padBits(X,n_bits):\n        #(before the number, after the number)\n        #((along depth) , (along rows) , (along col))\n        npad = ((0,0),(n_bits,n_bits),(n_bits,n_bits))\n        X = np.pad(X, pad_width=npad, mode=\'constant\', constant_values = 0)\n        return X\n\n\n    def randomFilterValues(self):\n        mean = params[""mean""]\n        std = params[""std""]\n        #for conv layer box\n        self.bias_layer_1 = list(np.random.randn(self.n_filter_layer_1)+1)\n        #filter values for layer 1\n        l1 = np.sqrt(2.0/np.product(self.filter_size_layer_1))\n        for i in range(self.n_filter_layer_1):\n            self.filters_layer_1.append(np.random.randn(self.filter_size_layer_1[0],self.filter_size_layer_1[1])*l1)\n            #filter values for layer 2\n        self.bias_layer_2 = list(np.random.randn(self.n_filter_layer_2)+1)\n        l2 = np.sqrt(2.0/np.product(self.filter_size_layer_2))\n        for i in range(self.n_filter_layer_2):\n            self.filters_layer_2.append(np.random.randn(self.filter_size_layer_2[0],self.filter_size_layer_2[1],self.filter_size_layer_2[2])*l2)\n        #for fully connected layers\n        # +1 for bias\n        shape_weight_layer_1 = (self.n_nodes_hidden_layer_1,self.out_nodes_after_conv+1)\n        shape_weight_layer_2 = (self.n_nodes_hidden_layer_2,self.n_nodes_hidden_layer_1+1)\n        shape_weight_layer_3 = (self.output_classes,self.n_nodes_hidden_layer_2+1)\n        self.weights.append((1.0/np.sqrt(self.out_nodes_after_conv/2.0))*np.random.randn(shape_weight_layer_1[0],shape_weight_layer_1[1]))\n        self.weights.append((1.0/np.sqrt(self.n_nodes_hidden_layer_1/2.0))*np.random.randn(shape_weight_layer_2[0],shape_weight_layer_2[1]))\n        self.weights.append((1.0/np.sqrt(self.n_nodes_hidden_layer_2/2.0))*np.random.randn(shape_weight_layer_3[0],shape_weight_layer_3[1]))\n\n\n    #this function does a feed forward\n    def feedForward(self, X, y, training=False, g_check=False):\n        #layer 1\n        #this is to store intermediate results just for training thing\n        layer_1_conv_box = {}\n        X = self.convulationOp(X,layer=1) # 50X50X4\n        layer_1_conv_box[""convOp""] = X\n        X = self.relu(X)\n        layer_1_conv_box[""relu""] = X\n        layer_1_pooling = {}\n        X,max_indexes_x, max_indexes_y = self.maxPooling(X,params[""pooling_stride_layer_1""][""val""],params[""pooling_filter_size_layer_1""][""val""])\n        pooling_non_activated = np.zeros(X.shape)\n        for ch in range(X.shape[0]):\n            pooling_non_activated[ch] = layer_1_conv_box[""convOp""][ch,max_indexes_x[ch],max_indexes_y[ch]]\n        layer_1_pooling[\'pooled_non_activated\'] = pooling_non_activated\n        layer_1_pooling[""pooling_val""] = X\n        layer_1_pooling[""max_indexes_x""] = max_indexes_x\n        layer_1_pooling[""max_indexes_y""] = max_indexes_y\n\n        #layer 2\n        layer_2_conv_box = {}\n        X = self.convulationOp(X,layer=2) #of dimension 23X23X3\n        layer_2_conv_box[""convOp""] = X\n        X = self.relu(X)\n        layer_2_conv_box[""relu""] = X\n        layer_2_pooling = {}\n        X,max_indexes_x_layer_2,max_indexes_y_layer_2 = self.maxPooling(X,params[""pooling_stride_layer_2""][""val""],params[""pooling_filter_size_layer_2""][""val""])\n        layer_2_pooling[""pooling_val""] = X\n        layer_2_pooling[""max_indexes_x""] = max_indexes_x_layer_2\n        layer_2_pooling[""max_indexes_y""] = max_indexes_y_layer_2\n        z0_tensor =np.zeros(X.shape)\n        # now i have total 22 X 22 X 3 image there total neurons = 1452\n        for ch in range(X.shape[0]):\n            z0_tensor[ch] =layer_2_conv_box[""convOp""][ch,max_indexes_x_layer_2[ch],max_indexes_y_layer_2[ch]]\n\n        fully_connected = {}\n        fully_connected[\'z0\'] =np.concatenate((np.array([1]),z0_tensor.flatten()))\n        #fully connected\n        X = self.flattenLayer(X) #this flattens the layer to make a column vector and adds 1 as a bias\n        fully_connected[\'a0\'] = X\n        X = self.fullyConnected(X,layer=1)\n        fully_connected[\'z1\'] = np.concatenate((np.array([1]),X))\n        X = self.relu(X)\n        #at the 1st hidden layer\n        X = self.flattenLayer(X) #add one as bias\n        fully_connected[\'a1\'] = X\n        #perform dropout\n        # if(training):\n        #     X = self.dropout(X,self.dropout_percent_layer_1)\n\n        X = self.fullyConnected(X,layer=2)\n        fully_connected[\'z2\'] = np.concatenate((np.array([1]),X))\n        X = self.relu(X)\n        X = self.flattenLayer(X) #add one as bias\n        fully_connected[\'a2\'] = X\n        # if(training):\n        #     X = self.dropout(X,self.dropout_percent_layer_2)\n\n        X = self.fullyConnected(X,layer=3)\n        fully_connected[\'z3\'] = np.concatenate((np.array([1]),X))\n        #now X contains the output now have to just squash the stuff\n        X = self.softmax(X)\n        fully_connected[\'a3\'] = X\n        print ""gott""\n        print X\n        print y\n        if g_check:\n            return X\n        return layer_1_conv_box, layer_1_pooling, layer_2_conv_box, layer_2_pooling, fully_connected\n\n\n\n    def convulationOp(self, X, layer):\n        #apply layer 1 filters\n        if(layer==1):\n            #here there will be the naive image\n            convolved_2d_img = []\n            i=0\n            #stack kernel\n            k_shape = self.filters_layer_1[0].shape\n            stacked_kernels = np.dstack(self.filters_layer_1)\n            stacked_kernels = np.rollaxis(stacked_kernels,-1)\n            shape = X.shape\n            X = X.reshape((1,X.shape[0],X.shape[1]))\n            #depth = #kernels\n            bias = np.array(self.bias_layer_1)\n            convolved = self.convOpOpti(X,stacked_kernels,shape,k_shape,self.conv_op_layer_1_out_dim)\n            convolved = convolved + bias.reshape((bias.shape[0],1,1))\n            return convolved\n        #layer 2\n        else:\n            #here input will be 25X25X4 after pooling\n            #filter here must be of same depth as that of input\n            k_shape = self.filters_layer_2[0].shape[1:]\n            shape = X.shape[1:]\n            X = X.reshape((1,X.shape[0],X.shape[1],X.shape[2]))\n            kernels = np.array(self.filters_layer_2)\n            bias = np.array(self.bias_layer_2)\n            convolved = self.convOpOpti(X,kernels,shape,k_shape,self.conv_op_layer_2_out_dim,layer=2)\n            convolved = convolved + bias.reshape((bias.shape[0],1,1))\n            return convolved\n\n\n    @staticmethod\n    def convOpOpti(X, kernel, x_dim, kernel_dim, output_dim,layer=1, backpass=0,convType=""valid""):   #kernel will be all kernels\n\n        padded_dim = np.array(x_dim) + np.array(kernel_dim) - 1\n        output_dim = np.array(output_dim)\n\n        fft_result = np.fft.fft2(X,padded_dim,axes=(-2,-1)) * np.fft.fft2(kernel, padded_dim, axes=(-2,-1))\n        target = np.fft.ifft2(fft_result).real\n\n        if(convType==""full""):\n            return np.sum(target,axis=0)\n\n        start_i = (padded_dim -output_dim ) // 2\n        end_i = start_i + output_dim\n\n        if(layer==2):\n            target = np.sum(target,axis=(1))\n        if(backpass==1):\n            return target[:,:,start_i[0]:end_i[0], start_i[1]:end_i[1]]\n        return target[:,start_i[0]:end_i[0], start_i[1]:end_i[1]]\n\n\n    @staticmethod\n    def convOp(X, kernel, x_dim, kernel_dim, output_dim,conv_type=\'valid\'):\n        #to make the dimension equal\n        padded_dim = np.array(x_dim) + np.array(kernel_dim) - 1\n        output_dim = np.array(output_dim)\n        #applying convolution theorem\n        fft_result = np.fft.fft2(X, padded_dim) * np.fft.fft2(kernel, padded_dim)\n        target = np.fft.ifft2(fft_result).real\n\n        if(conv_type==\'full\'):\n            return target\n        #now to extract the convolution\n        #here convolution is correlation with the flipped filter\n        start_i = (padded_dim -output_dim ) // 2\n        end_i = start_i + output_dim\n        convolution = target[start_i[0]:end_i[0], start_i[1]:end_i[1]]\n        return convolution\n\n    def relu(self,X):\n        X[X<0] = 0\n        return X\n\n    def maxPooling(self,X,stride,size):\n        #layer 1, X = (50,50,4) and output will be after pooling (25X25X4)\n        max_indexes_x = [] #this will be same as the dimension of output of max pooling, just to use in backprop\n        max_indexes_y = []\n        all_pooled_channels = []#to store all pooled stuffs\n        ch_rows, ch_cols = X[0].shape #cols 50\n        kernel_rows, kernel_cols = size\n        output_rows = (ch_rows - kernel_rows)/stride + 1\n        output_cols = (ch_cols - kernel_cols)/stride + 1\n        for channel in X:\n            #to store pooled values\n            pooled_channel = np.zeros((output_rows,output_cols))\n            max_i = np.zeros((output_rows,output_cols), dtype=int)\n            max_j = np.zeros((output_rows,output_cols), dtype=int)\n            curr_x, curr_y = 0,0 #variables to keep track of current pool value to be filled\n            #channel is a 2 d stuff\n            #loop over the matrix with a stride 2\n            for i in range(0,ch_rows - kernel_rows + 1,stride):\n                for j in range(0,ch_cols - kernel_cols + 1,stride):\n                    start_i, start_j = i, j\n                    end_i = start_i + kernel_rows\n                    end_j = start_j + kernel_cols\n                    patch = channel[start_i:end_i, start_j:end_j]\n                    max_val_index_in_patch = np.argmax(patch)\n                    #get the coordinates in the patch then shift the origin to get the actual coordinates\n                    y_in_patch  = max_val_index_in_patch % kernel_cols\n                    x_in_patch = int((max_val_index_in_patch - y_in_patch)/kernel_cols)\n                    x_in_ch = start_i + x_in_patch\n                    y_in_ch = start_j + y_in_patch\n                    max_i[curr_x][curr_y] = x_in_ch\n                    max_j[curr_x][curr_y] = y_in_ch\n                    pooled_channel[curr_x][curr_y] = patch[x_in_patch][y_in_patch]\n                    curr_x, curr_y = self.modifyCo(curr_x,curr_y,output_rows,output_cols)\n\n            all_pooled_channels.append(pooled_channel)\n            max_indexes_x.append(max_i)\n            max_indexes_y.append(max_j)\n\n        all_pooled_channels = np.rollaxis(np.dstack(all_pooled_channels),-1)\n        max_indexes_x = np.rollaxis(np.dstack(max_indexes_x),-1)\n        max_indexes_y = np.rollaxis(np.dstack(max_indexes_y),-1)\n        return all_pooled_channels,max_indexes_x,max_indexes_y\n\n\n    @staticmethod\n    def modifyCo(curr_x, curr_y, rows, cols):\n        if(curr_y == cols-1):\n            return curr_x + 1, 0\n        else:\n            return curr_x,curr_y+1\n\n    @staticmethod\n    def flattenLayer(X):\n        # also add bias\n        return np.insert(X.flatten(),0,1)\n\n    def fullyConnected(self,X,layer):\n        Z = np.dot(self.weights[layer-1],X)\n        return Z\n\n    @staticmethod\n    def dropout(X,p):\n        mask = np.random.binomial(1,p,X.shape)\n        return X*mask\n\n    @staticmethod\n    def softmax(X):\n        X -= np.max(X) #for numeric stability\n        expo = np.exp(X)\n        return expo/np.sum(expo,axis=0)\n\n    def makeThetaVector(self):\n        all_theta = np.array([])\n        #first bias of all kernels\n        all_theta = np.concatenate((all_theta,np.array(self.bias_layer_1),np.array(self.filters_layer_1).flatten()))\n        #2nd conv layer\n        all_theta = np.concatenate((all_theta,np.array(self.bias_layer_2),np.array(self.filters_layer_2).flatten()))\n        #fully connected\n        all_theta = np.concatenate((all_theta, self.weights[0].flatten(), self.weights[1].flatten(), self.weights[2].flatten()))\n        return all_theta\n\n\n        pass\n\n    def gradientCheck(self,layer,X,y,actual,bias=None):\n        epsilon = params[\'epsilon\']\n        if layer== \'conv_2\':\n            curr_weight = np.array(self.filters_layer_1)\n            shape = curr_weight.shape\n            flattened = curr_weight.flatten()\n            approx = []\n            approx_bias = []\n            for i in range(len(bias)):\n                J1 = 0\n                J2 = 0\n                self.bias_layer_1[i] =   self.bias_layer_1[i] + epsilon\n                for im in range(len(X)):\n                    a = self.feedForward(X[im],y[im],g_check=True)\n                    J1 += self.softmaxLoss(a,y[im],False)\n                self.bias_layer_1[i] =   self.bias_layer_1[i] - epsilon\n                self.bias_layer_1[i] =   self.bias_layer_1[i] - epsilon\n                for im in range(len(X)):\n                    J2 += self.softmaxLoss(self.feedForward(X[im],y[im],g_check=True),y[im],False)\n                self.bias_layer_1[i] =   self.bias_layer_1[i] + epsilon\n                approx_bias.append((1.0 * (J1-J2))/(2*epsilon))\n\n            for i in range(len(flattened)):\n                J1 = 0\n                J2 = 0\n                flattened[i] = flattened[i] + epsilon\n                self.filters_layer_1 = flattened.reshape((shape))\n                for im in range(len(X)):\n                    a = self.feedForward(X[im],y[im],g_check=True)\n                    # print ""got here""\n                    # print a\n                    J1 += self.softmaxLoss(a,y[im],False)\n                flattened[i] = flattened[i] - epsilon #make as the previous\n                flattened[i] = flattened[i] - epsilon #modify\n                self.filters_layer_1 = flattened.reshape((shape))\n                for im in range(len(X)):\n                    J2 += self.softmaxLoss(self.feedForward(X[im],y[im],g_check=True),y[im],False)\n                flattened[i] = flattened[i] + epsilon #modify to previous state\n                approx.append((1.0 * (J1-J2))/(2*epsilon))\n\n\n        print ""-------------------------------""\n        print approx_bias\n        print bias\n        print ""-------------------------------""\n        approx = np.array(approx)\n        print approx\n        print actual\n        nume = np.linalg.norm(approx-actual)\n        deno = np.linalg.norm(actual) + np.linalg.norm(approx)\n        print ""ratio is "" +  str(nume/deno)\n\n\n\n\n\n\n    def gradientDescent(self,theta,X,y):\n        X = X[:5]\n        y = y[:5]\n        method = params[\'method\']\n        fmin = minimize(fun=self.backprop,x0=theta,args=(X,y),method=method,jac=True,options={""maxiter"":200})\n        return fmin\n\n    def MiniBatchGd(self,theta,X,y,n_epochs,mini_batch_size,learning_rate):\n        zipped = zip(X,y)\n        for epoch in xrange(n_epochs):\n            np.random.shuffle(zipped)\n            X,y = zip(*zipped)\n            X = np.array(X)\n            y = np.array(y)\n            loss_total = 0\n            for i in xrange(0,X.shape[0],mini_batch_size):\n                X_mini = X[i:i+mini_batch_size]\n                y_mini = y[i:i+mini_batch_size]\n                grads, loss = self.backprop(theta, X_mini, y_mini)\n                loss_total += loss\n                theta += learning_rate * grads\n            print ""iteration ""+str(epoch+1)+"" loss ""+str(loss_total)\n\n            self.losses.append(loss_total)\n\n        return theta\n\n    def backprop(self,theta,X,y):\n        if self.count%5 == 0:\n            print ""-------------------------------------------------------""\n            print(str(self.count)+"" times the function is called time taken in seconds ""+str(time.time()-start) )\n            print ""-------------------------------------------------------""\n        self.count += 1\n        # batch_co = np.random.choice(X.shape[0],size=params[\'batch_size\'],replace=False)\n        # # X_batch =\n        # X = X[batch_co]\n        # y = y[batch_co]\n        #this function will make from one d to weights\n        self.fromThetaVectorToWeights(theta) #now all weights loaded in the self object\n        J = 0\n        #initialze grad matrix\n        weight_layer_3_grads = np.zeros(self.weights[LAYER_3].shape)\n        weight_layer_2_grads = np.zeros(self.weights[LAYER_2].shape)\n        weight_layer_1_grads = np.zeros(self.weights[LAYER_1].shape)\n        kernel_layer_2_grads = [np.zeros(self.filter_size_layer_2) for k in range(self.n_filter_layer_2)]\n        kernel_layer_1_grads = np.zeros((self.n_filter_layer_1,self.filter_size_layer_1[0],self.filter_size_layer_1[1]))\n        bias_layer_2_grads = np.zeros((self.n_filter_layer_2))\n        bias_layer_1_grads = np.zeros((self.n_filter_layer_1))\n\n        #for all image\n        pool_size = params[\'pool_size\']\n        # num_cores = multiprocessing.cpu_count()\n        # ite = [delayed(backpropBodyParllel)(self,X[im:im+pool_size],y[im:im+pool_size]) for im in range(0,len(X),pool_size)]\n        # all_return_values = Parallel(n_jobs=num_cores)(ite)\n        # all_return_values.append(backpropBodyParllel(self,X,y))\n        all_return_values = []\n        all_return_values.append(backpropBodyParllel(self,X,y))\n\n        print ""enter to continue""\n        raw_input()\n\n        J = 0\n        all_grads = np.zeros(all_return_values[0][1].shape)\n        for i in range(len(all_return_values)):\n            J += all_return_values[i][0]\n            all_grads += all_return_values[i][1]\n\n\n        print ""loss ""+str(J)+"" at iteration ""+str(self.count)\n\n        return J, all_grads\n\n    def fromThetaVectorToWeights(self, theta):\n        #transforming logic\n        # kernel_layer_1,kernel_layer_2,biases_layer_1,biases_layer_2,weights variables\n        #1st conv params\n        self.bias_layer_1 = list(theta[0:self.n_filter_layer_1])\n        self.filters_layer_1 = []\n        elements_in_filter_1 = np.product(self.filter_size_layer_1)\n        prev = self.n_filter_layer_1\n        for i in range(self.n_filter_layer_1):\n            get_curr_filter = theta[prev:prev+elements_in_filter_1]\n            # print get_curr_filter\n            self.filters_layer_1.append(np.reshape(get_curr_filter,self.filter_size_layer_1))\n            prev = prev + elements_in_filter_1\n\n        theta = theta[prev:]\n        #2nd conv params\n        self.bias_layer_2 = list(theta[0:self.n_filter_layer_2])\n        self.filters_layer_2 = []\n        prev = self.n_filter_layer_2\n        elements_in_filter_2 = np.product(self.filter_size_layer_2)\n        for i in range(self.n_filter_layer_2):\n            get_curr_filter = theta[prev:prev+elements_in_filter_2]\n            self.filters_layer_2.append(np.reshape(get_curr_filter,self.filter_size_layer_2))\n            prev = prev + elements_in_filter_2\n\n        theta = theta[prev:]\n        #now get fully connected stuffs\n        shape_weight_layer_1 = (self.n_nodes_hidden_layer_1,self.out_nodes_after_conv+1)\n        shape_weight_layer_2 = (self.n_nodes_hidden_layer_2,self.n_nodes_hidden_layer_1+1)\n        shape_weight_layer_3 = (self.output_classes,self.n_nodes_hidden_layer_2+1)\n        self.weights = []\n        self.weights.append(np.reshape(theta[:np.product(shape_weight_layer_1)],shape_weight_layer_1))\n        theta = theta[np.product(shape_weight_layer_1):]\n        self.weights.append(np.reshape(theta[:np.product(shape_weight_layer_2)],shape_weight_layer_2))\n        theta = theta[np.product(shape_weight_layer_2):]\n        self.weights.append(np.reshape(theta[:np.product(shape_weight_layer_3)],shape_weight_layer_3))\n        #all params done\n\n\n    @staticmethod\n    def softmaxLoss(a,y_curr,prints=True):\n        return np.sum(-y_curr * np.log(a+1e-10))\n\n    @staticmethod\n    def reluDerivative(z):\n        z[z>0] = 1\n        z[z<=0] = 0\n        return z\n\n\n\nif __name__ == \'__main__\':\n    cnn = CNN()\n    cnn.train()\n    pickle_file_cnn_object = open(\'pickle_models/cnn_object_11_\', \'w\')\n    pickle.dump(cnn, pickle_file_cnn_object)\n    pickle_file_cnn_object.close()\n    print(""--- %s completed in seconds ---"" % (time.time() - start))\n'"
cnn_predict.py,2,"b'\nimport numpy as np\nfrom img_preprocess import Preprocess\nimport pickle\nfrom cnn_model import CNN\nimport json\nimport time\n\nMODEL_FILE = \'pickle_models/cnn_object_15_\'\nCLASSES = [""FIST"",""HAND"",""ONE"",""PEACE""] #change here if you want to add new gesture\nparams_file  = open(\'params.json\',\'r\')\nparams = json.load(params_file)\nparams_file.close()\nstart = time.time()\n\nclass CNNLite():\n    def __init__(self):\n        self.cnn_obj = pickle.load(open(MODEL_FILE,\'r\'))\n\n\n    #this function does a feed forward\n    def feedForward(self, X, training=True):\n        #layer 1\n        #this is to store intermediate results just for training thing\n        X = self.cnn_obj.convulationOp(X,layer=1) # 50X50X4\n        X = self.cnn_obj.relu(X)\n        X,max_indexes_x, max_indexes_y = self.cnn_obj.maxPooling(X,params[""pooling_stride_layer_1""][""val""],params[""pooling_filter_size_layer_1""][""val""])\n        #layer 2\n        X = self.cnn_obj.convulationOp(X,layer=2) #of dimension 23X23X3\n        X = self.cnn_obj.relu(X)\n        X,max_indexes_x_layer_2,max_indexes_y_layer_2 = self.cnn_obj.maxPooling(X,params[""pooling_stride_layer_2""][""val""],params[""pooling_filter_size_layer_2""][""val""])\n        X = self.cnn_obj.flattenLayer(X) #this flattens the layer to make a column vector and adds 1 as a bias\n        X = self.cnn_obj.fullyConnected(X,layer=1)\n        X = self.cnn_obj.relu(X)\n        X = self.cnn_obj.flattenLayer(X) #add one as bias\n        #perform dropout\n        if(training):\n            X = self.cnn_obj.dropout(X,self.cnn_obj.dropout_percent_layer_1)\n        X = self.cnn_obj.fullyConnected(X,layer=2)\n        X = self.cnn_obj.relu(X)\n        X = self.cnn_obj.flattenLayer(X) #add one as bias\n        if(training):\n            X = self.cnn_obj.dropout(X,self.cnn_obj.dropout_percent_layer_2)\n        X = self.cnn_obj.fullyConnected(X,layer=3)\n        X = self.cnn_obj.softmax(X)\n        return X\n\n\n    #give one image point\n    def predict(self,X):\n        probabilities = self.feedForward(X,training=False)\n        print probabilities\n        max_index = np.argmax(probabilities)\n        print CLASSES[max_index]\n        return CLASSES[max_index],probabilities[max_index]\n\n\n    def test(self,X,y):\n        accuracy = []\n        print ""testing started""\n        for im_index in range(len(X)):\n            if(im_index%10==0):\n                print ""done for images ""+str(im_index)\n                print ""time taken ------------------- ""+str(time.time()-start)\n            predicted_class, predicted_probab = self.predict(X[im_index])\n            # for row in X[im_index]:\n                # print row\n            print y[im_index]\n\n            if predicted_class == CLASSES[np.argmax(y[im_index])]:\n                accuracy.append(1)\n            else:\n                accuracy.append(0)\n\n\n\n        return (1.0 * sum(accuracy)/len(accuracy))*100\n\n\n\n\ndef main():\n    process_obj = Preprocess()\n    cnn_obj = CNNLite()\n    process_obj = process_obj.process()\n    X,y = process_obj.X_validation, process_obj.y_validation\n    acc =  cnn_obj.test(X[:100],y[:100])\n    print(""accuracy is, ""+str(acc)+"" %"")\n    print ""time taken ------------------- ""+str(time.time()-start)\n\n\n\nif __name__ == \'__main__\':\n    main()\n'"
converter.py,1,"b'\nimport sys\nimport numpy as np\nimport cv2\n\n# blue = sys.argv[1]\n# green = sys.argv[2]\n# red = sys.argv[3]\n\ncolor = np.uint8([[[120, 105, 103]]])\nhsv_color = cv2.cvtColor(color, cv2.COLOR_BGR2GRAY)\nprint hsv_color\n# hue = hsv_color[0][0][0]\n\n# print(""Lower bound is :""),\n# print(""["" + str(hue-10) + "", 100, 100]\\n"")\n\n# print(""Upper bound is :""),\n# print(""["" + str(hue + 10) + "", 255, 255]"")\n'"
image_data_maker.py,2,"b""\nimport numpy as np\nimport cv2\n\ncap = cv2.VideoCapture(0)\ncount = 1\nobj = CNNLite()\nwhile count != 1001:\n    ret, frame = cap.read()\n    cv2.rectangle(frame, (300,300), (100,100), (0,255,0),0)\n    crop_img = frame[100:300, 100:300]\n    value = (33, 33)\n    hsv = cv2.cvtColor(crop_img,cv2.COLOR_BGR2HSV)\n    blur = cv2.GaussianBlur(hsv,value,0)\n    # blurred = cv2.GaussianBlur(grey, value, 0)\n    lower_green = np.array([80,50,30])\n    upper_green = np.array([255,255,255])\n    mask = cv2.inRange(hsv, lower_green, upper_green)\n    gaussian = cv2.GaussianBlur(mask, (11,11), 0)\n    # image, contours, hierarchy = cv2.findContours(thresh1.copy(),cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n    # cnt = max(contours, key = lambda x: cv2.contourArea(x))\n    # x, y, w, h = cv2.boundingRect(cnt)\n    # cv2.rectangle(crop_img, (x, y), (x+w, y+h), (0, 255, 255), 0)\n    erosion = cv2.erode(mask, None, iterations = 1)\n    dilated = cv2.dilate(erosion,None,iterations = 1)\n    median = cv2.medianBlur(dilated, 7)\n    cv2.imshow('cropped', frame)\n    cv2.imshow('mask', median)\n    # #\n    # write_img = cv2.resize(median, (50,50))\n    # cv2.imwrite('images_data/peace/'+str(count)+'.jpg',write_img)\n    # print count\n    # count += 1\n    k = cv2.waitKey(5) & 0xFF\n    if k == 27:\n        break\n\ncv2.destroyAllWindows()\ncap.release()\n"""
img_preprocess.py,23,"b'\nimport numpy as np\nimport cv2\nimport random\nimport json\nimport os\nimport pickle\n\n\nparams_file  = open(\'params.json\',\'r\')\nparams = json.load(params_file)\nparams_file.close()\npreprocess_params = params[\'preprocess\']\nBASE_FOLDER = preprocess_params[\'BASE\']\nFIST = preprocess_params[\'FIST\']\nHAND = preprocess_params[\'HAND\']\n# NONE = preprocess_params[\'NONE\']\nONE = preprocess_params[\'ONE\']\nPEACE = preprocess_params[\'PEACE\']\nALL_IMAGES_PATHS = [FIST,HAND,ONE,PEACE] #change here if you want to add new gesture\n\nrandom.seed(0)\n\nclass Preprocess():\n\n    def __init__(self):\n        self.images = []    #this will contain list of all images preprocessed\n        self.n_types = preprocess_params[\'n_types\']\n        self.X_train = None\n        self.y_train = None\n        self.X_test = None\n        self.y_test = None\n        self.X_validation = None\n        self.y_validation = None\n        self.path_train = None\n        self.path_test = None\n        self.path_validation = None\n\n        #total in normal arrays\n\n\n\n    #controller function this will return preprocessed value of X and also their outputs\n    #data type is train or test or validation\n    def process(self):\n        #if the sampled data exists then simply read and return\n        try:\n            pickle_file_sampled_data = open(\'pickle_models/sampled_data4\',\'r\')\n            processed_obj = pickle.load(pickle_file_sampled_data)\n            pickle_file_sampled_data.close()\n            return processed_obj\n        #basically this will sample and save it then read from there and return it\n        except Exception as e:\n            print ""the pickled file not found pickling now .......""\n        tX_train = []\n        tX_test = []\n        tX_validation = []\n        ty_train = []\n        ty_test = []\n        ty_validate = []\n        tpath_train = []\n        tpath_test = []\n        tpath_validate = []\n\n        #for all types\n        for curr_type in range(self.n_types):\n            print curr_type\n            local_X, local_y, local_path = self.loadAllImages(ALL_IMAGES_PATHS[curr_type],curr_type)\n\n            lX_train,lX_test,lX_validate,ly_train,ly_test,ly_validate,lpath_train, lpath_test, lpath_validate = self.shuffleAndSplit(local_X,local_y,local_path)\n            #adds to main array\n            [tX_train.append(x) for x in lX_train]\n            [tX_test.append(x) for x in lX_test]\n            [tX_validation.append(x) for x in lX_validate]\n            [ty_train.append(x) for x in ly_train]\n            [ty_test.append(x) for x in ly_test]\n            [ty_validate.append(x) for x in ly_validate]\n            [tpath_train.append(x) for x in lpath_train]\n            [tpath_test.append(x) for x in lpath_test]\n            [tpath_validate.append(x) for x in lpath_validate]\n\n\n        #convert into numpy array\n        self.X_train = np.dstack(tX_train)\n        self.X_test = np.dstack(tX_test)\n        self.X_validation = np.dstack(tX_validation)\n        self.y_train = np.dstack(ty_train)\n        self.y_test = np.dstack(ty_test)\n        self.y_validation = np.dstack(ty_validate)\n        self.path_train = np.dstack(tpath_train)\n        self.path_test = np.dstack(tpath_test)\n        self.path_validation = np.dstack(tpath_validate)\n\n        #rotate the axis\n        self.X_train = np.rollaxis(self.X_train,-1)\n        self.X_test = np.rollaxis(self.X_test,-1)\n        self.X_validation = np.rollaxis(self.X_validation,-1)\n        self.y_train = np.rollaxis(self.y_train,-1)\n        self.y_test = np.rollaxis(self.y_test,-1)\n        self.y_validation = np.rollaxis(self.y_validation,-1)\n        self.path_train = np.rollaxis(self.path_train,-1)\n        self.path_test = np.rollaxis(self.path_test,-1)\n        self.path_validation = np.rollaxis(self.path_validation,-1)\n\n        #now just shuffle\n        self.shuffleAll()\n\n        return None\n\n\n\n    def shuffleAll(self):\n        train = np.random.permutation(len(self.X_train))\n        self.X_train, self.y_train, self.path_train = self.X_train[train],self.y_train[train], self.path_train[train]\n        test = np.random.permutation(len(self.X_test))\n        self.X_test, self.y_test, self.path_test = self.X_test[test],self.y_test[test], self.path_test[test]\n        validation = np.random.permutation(len(self.X_validation))\n        self.X_validation, self.y_validation, self.path_validation = self.X_validation[validation],self.y_validation[validation], self.path_validation[validation]\n\n\n\n    #returns all images in a given folder\n    @staticmethod\n    def loadAllImages(path,curr_type):\n\n        file_y = open(path+\'y.txt\',\'r\')\n        y_to_append = map(int,file_y.read().strip().split(\' \'))\n        file_y.close()\n        temp_X = []\n        temp_y = []\n        temp_path = []\n        for f in os.listdir(path):\n            if(f!=\'y.txt\'):\n                img = cv2.imread(path+str(f),cv2.COLOR_BGR2GRAY).astype(float)\n                img -= np.mean(img)\n                # ret,binary_img = cv2.threshold(img,120,255,cv2.THRESH_BINARY)\n                # binary_img[binary_img==255] = 1 #replace 255 with 1 for easy calc, 1 means white , 0 means black\n                temp_X.append(img)\n                temp_y.append(y_to_append)\n                temp_path.append(path+str(f))\n\n\n        return temp_X, temp_y, temp_path\n\n    @staticmethod\n    def shuffleAndSplit(X,y,path):\n        l = len(X)\n        together = zip(X,y,path)\n        random.shuffle(together)\n        X,y,path = zip(*together)\n        X = list(X)\n        y = list(y)\n        path = list(path)\n        l_train = int(preprocess_params[\'train\']*l)\n        l_test = int(preprocess_params[\'test\']*l)\n        upper = l_train + l_test\n        return X[0:l_train], X[l_train:upper], X[upper:], y[0:l_train], y[l_train:upper], y[upper:],path[0:l_train], path[l_train:upper],path[upper:]\n\n\n\nmatch_dict = {""fist"":0, ""hand"":1, \'one\':2, ""piece"":3, ""none"":4}\ncount_dict = {""fist"":0, ""hand"":0, ""one"":0, ""piece"":0, ""none"":0}\n\nif __name__ == \'__main__\':\n    process_obj = Preprocess()\n    obj = process_obj.process()\n    if(obj == None):\n        pickle_file_sampled_data = open(\'pickle_models/sampled_data4\',\'w\')\n        pickle.dump(process_obj,pickle_file_sampled_data)\n        pickle_file_sampled_data.close()\n    else:\n        print(""stuff loaded"")\n        for ele in obj.y_train:\n            for keys in match_dict.keys():\n                if np.argmax(ele) == match_dict[keys]:\n                    count_dict[keys] += 1\n                    break\n        print obj.y_train[0]\n        print count_dict\n        # print obj.path_train[:20]\n        # img =  obj.X_validation[0]\n        # img[img == 1] = 255\n        # for i in range(50):\n        #     print img[i]\n        #     print """"\n        # print obj.y_validation[0]\n        # cv2.imshow(""image"",img)\n        # cv2.waitKey(0)\n        # cv2.destroyAllWindows()\n'"
