file_path,api_count,code
Hadoop/wordcount_mapper.py,0,"b""#!/usr/bin/env python   \n#the above just indicates to use python to intepret this file\n\n# ---------------------------------------------------------------\n#This mapper code will input a line of text and output <word, 1>\n# \n# ---------------------------------------------------------------\n\nimport sys             #a python module with system functions for this OS\n\n# ------------------------------------------------------------\n#  this 'for loop' will set 'line' to an input line from system \n#    standard input file\n# ------------------------------------------------------------\nfor line in sys.stdin:  \n\n#-----------------------------------\n#sys.stdin call 'sys' to read a line from standard input, \n# note that 'line' is a string object, ie variable, and it has methods that you can apply to it,\n# as in the next line\n# ---------------------------------\n    line = line.strip()  #strip is a method, ie function, associated\n                         #  with string variable, it will strip \n                         #   the carriage return (by default)\n    keys = line.split()  #split line at blanks (by default), \n                         #   and return a list of keys\n    for key in keys:     #a for loop through the list of keys\n        value = 1        \n        print('{0}\\t{1}'.format(key, value) ) #the {} is replaced by 0th,1st items in format list\n                            #also, note that the Hadoop default is 'tab' separates key from the value\n"""
Hadoop/wordcount_reducer.py,0,"b'#!/usr/bin/env python\n\n# ---------------------------------------------------------------\n#This reducer code will input a line of text and \n#    output <word, total-count>\n# ---------------------------------------------------------------\nimport sys\n\nlast_key      = None              #initialize these variables\nrunning_total = 0\n\n# -----------------------------------\n# Loop thru file\n#  --------------------------------\nfor input_line in sys.stdin:\n    input_line = input_line.strip()\n\n    # --------------------------------\n    # Get Next Word    # --------------------------------\n    this_key, value = input_line.split(""\\t"", 1)  #the Hadoop default is tab separates key value\n                          #the split command returns a list of strings, in this case into 2 variables\n    value = int(value)           #int() will convert a string to integer (this program does no error checking)\n \n    # ---------------------------------\n    # Key Check part\n    #    if this current key is same \n    #          as the last one Consolidate\n    #    otherwise  Emit\n    # ---------------------------------\n    if last_key == this_key:     #check if key has changed (\'==\' is                                   #      logical equalilty check\n        running_total += value   # add value to running total\n\n    else:\n        if last_key:             #if this key that was just read in\n                                 #   is different, and the previous \n                                 #   (ie last) key is not empy,\n                                 #   then output \n                                 #   the previous <key running-count>\n            print( ""{0}\\t{1}"".format(last_key, running_total) )\n                                 # hadoop expects tab(ie \'\\t\') \n                                 #    separation\n        running_total = value    #reset values\n        last_key = this_key\n\nif last_key == this_key:\n    print( ""{0}\\t{1}"".format(last_key, running_total)) \n\t\n'"
