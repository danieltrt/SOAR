file_path,api_count,code
MP_1_Lin.py,1,"b""import matplotlib.pyplot as plt\nimport numpy as np\nx = np.linspace(0, 5, 10)\ny = x ** 2\n\nplt.figure()\nplt.plot(x, y, 'r')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('title')\nplt.show()"""
MP_2_Sub.py,1,"b""from pylab import *\nimport numpy as np\nx = np.linspace(0, 5, 10)\ny = x ** 2\n\n#instead of one by one import pylab\nsubplot(1,2,1)\nplot(x, y, 'r--')\nsubplot(1,2,2)\nplot(y, x, 'g*-');\nshow()"""
NP_10_Stack.py,7,"b'import numpy as np\n\na = np.array([[1, 2], [3, 4]])\n\n# repeat each element 3 times\n#print(np.repeat(a, 3))\n# tile the matrix 3 times\n#print(np.tile(a, 3))\n#\nb = np.array([[5, 6]])\n#print(np.concatenate((a, b), axis=0)) #axis=0 !!!\nprint(np.vstack((a,b))) #vertical stack\nprint(np.hstack((a,b.T))) #horizontal stack'"
NP_11_Cond.py,2,"b'import numpy as np\n\nA = np.array([[n+m*10 for n in range(5)] for m in range(5)])\nM=np.matrix(A)\nprint(M)\n\nif (M > 20).any():\n    print(""at least one element in M is larger than 20"")\nelse:\n    print(""None"")\n\nif (M > 5).all():\n    print(""all elements in M are larger than 5"")\nelse:\n    print(""all elements in M are not larger than 5"")'"
NP_1_intro.py,2,"b""import numpy as np\n#they're both ndarray.\n#the only difference is shape\na = np.array([0,1,2,3])\nb = np.array([[1,2],[3,4]])\nprint(a,a.shape)\nprint(b,b.shape)"""
NP_2_complex.py,5,"b'import numpy as np\n\n################### ARANGE ############################\n#create a range\nx1 = np.arange(0,10,1) #arguments:start,stop,step\nx2 = np.arange(-1,1,0.1)\n#print(x1)\n#print(x2)\n\n################### LINSPACE - LOGSPACE ###############\nl1 = np.linspace(0,10,10) #starts and end points are included\nl2 = np.logspace(0,10,10,base=2)\n#print(l1)\n#print(l2)\n\n################### MGRID ############################\n#mesh grid\nx,y = np.mgrid[0:5, 0:5]\n\nprint(x)\nprint(y)'"
NP_3_random.py,0,"b'from numpy import random\n\nr1 = random.rand(5) # uniform in [0, 1]\nr2 = random.rand(4,5)\nr4 = random.randn(8)\nr3 = random.random_integers(0,100)\n\nprint(r3)'"
NP_4_matrix.py,4,"b'import numpy as np\n\nd1 = np.diag([1,2,3])  # a diagonal matrix\nd2 = np.diag([1,2,3], k=1) #diagonal with offset from the main diagonal\n\nm1 = np.zeros((5,4))\nm2 = np.ones((2,3))\n\nprint(m2)'"
NP_5_IO.py,3,"b'import numpy as np\nimport matplotlib.pyplot as plt\n\n# data = np.genfromtxt(\'stockholm_td_adj.dat\')\n# #print(data.shape)\n#\n# fig, ax = plt.subplots(figsize=(14,4))\n#\n# ax.plot(data[:,0]+data[:,1]/12.0+data[:,2]/365, data[:,5])\n# ax.axis(\'tight\')\n# ax.set_title(\'tempeatures in Stockholm\')\n# ax.set_xlabel(\'year\')\n# ax.set_ylabel(\'temperature (C)\')\n# plt.show(fig)\n\nm = np.random.rand(3,4)\nnp.savetxt(""deneme.csv"", m)\n\nprint(m)\nprint(m.itemsize) #bytes per element\nprint(m.nbytes) #number of bytes\nprint(m.ndim) #number of dimensions'"
NP_6_ManipArr.py,4,"b'import numpy as np\n\nM = np.random.rand(3,3)\n\n#print(M)\n#print(M[1])\n#print(M[1,1])\n#print(M[1,:]) #row 1\n#print(M[:,1]) #column 1\n#\nA = np.array([1,2,3,4,5])\n#print(A[1:3])\n#print(A[::2])\n#print(A[-1])\n\n\n############### FANCY INDEXING #####################\n\n# A = np.array([[n+m*10 for n in range(5)] for m in range(5)])\n# print(A)\n# row_indices = [1, 2, 3]\n# print(A[row_indices])\n# col_indices = [1, 2, -1]\n# print(A[row_indices,col_indices])\n#\nwhich = [1, 0, 1, 0,2]\nchoices = [[-2,-2,-2,3,8], [5,5,4,5,8],[9,9,9,9,9]]\n# # #Constructs an array by picking elements from several arrays\nprint(np.choose(which, choices))'"
NP_7_MatrixAlg.py,6,"b""import numpy as np\n\nA = np.array([[n+m*10 for n in range(5)] for m in range(5)])\n\nv1 = np.arange(0, 5)\n\n#print(np.dot(A, A)) #array uzerinden matris carpimi\n#print(np.dot(A, v1)) #alignment'i kendisi yaparak matris carpimi\n#\nM = np.matrix(A) #change the behaviour of A\nv = np.matrix(v1).T # make it a column vector\n#print(A*A)\nprint(M*v)"""
NP_8_CompSubset.py,4,"b'import numpy as np\nimport matplotlib.pyplot as plt\n\n#The dataformat is: year, month, day, daily average temperature, low, high, location.\n\ndata = np.genfromtxt(\'stockholm_td_adj.dat\')\n\n#If we are interested in the average temperature only in a particular month, say February,\n                # then we can create a index mask and use it to select only the data for\n# that month using:\n\nprint(np.unique(data[:,1]))   # the month column takes values from 1 to 12\n\nmask_feb = data[:,1] == 2\n\n# the temperature data is in column 3\nmonths = np.arange(1,13)\nmonthly_mean = [np.mean(data[data[:,1] == month, 3]) for month in months]\nfig, ax = plt.subplots()\nax.bar(months, monthly_mean)\nax.set_xlabel(""Month"")\nax.set_ylabel(""Monthly avg. temp."")\nplt.show(fig)\n'"
NP_9_CalcHighDim.py,2,"b'import numpy as np\n\n#m = np.random.rand(3,3)\n#print(m)\n#print(m.max())\n#print(m.max(axis=0)) #column\n#print(m.max(axis=1)) #row\n\nA = np.array([[n+m*10 for n in range(5)] for m in range(5)])\n# #\nn, m = A.shape\n#\nB = A.reshape((1,n*m))\n#print(B)\n#B[0,0:5] = 5 # modify the array\nprint(B)\nprint(A)\n# #\nC = A.flatten()\nprint(C)'"
hmm_viterbi.py,4,"b'from __future__ import division\nimport numpy as np\nfrom hmmlearn import hmm\n\nstates = [""Rainy"", ""Sunny""]\nn_states = len(states)\n\nobservations = [""walk"", ""shop"", ""clean""]\nn_observations = len(observations)\n\nstart_probability = np.array([0.6, 0.4])\n\ntransition_probability = np.array([\n  [0.7, 0.3],\n  [0.4, 0.6]\n])\n\nemission_probability = np.array([\n  [0.1, 0.4, 0.5],\n  [0.6, 0.3, 0.1]\n])\n\nmodel = hmm.MultinomialHMM(n_components=n_states)\nmodel.startprob=start_probability\nmodel.transmat=transition_probability\nmodel.emissionprob=emission_probability\n\n# predict a sequence of hidden states based on visible states\nbob_says = np.array([[0, 2, 1, 1, 2, 0]]).T\nmodel = model.fit(bob_says)\nlogprob, alice_hears = model.decode(bob_says, algorithm=""viterbi"")\n\nprint(""Bob says:"", "", "".join(map(lambda x: observations[x], bob_says.T[0])))\nprint(""Alice hears:"", "", "".join(map(lambda x: states[x], alice_hears)))'"
knn_iris.py,2,"b'from sklearn import neighbors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nimport pandas as pd\n\n# define column names\nnames = [\'sepal_length\', \'sepal_width\', \'petal_length\',\n         \'petal_width\', \'class\']\n\ndf = pd.read_table(\'iris.data\', header=None, names=names, sep="","")\n# Separate four data attributes and class data (the 5th attribute)\n#  Slice data-frame column wise. When slicing the data frame using iloc,\n#    the start bound (0) is included, while the upper bound (4) is excluded.\n\nX = np.array(df.ix[:,0:4]) #input\ny = np.array(df[\'class\']) #label\n\n# split into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,\n                                                    random_state=42)\n\nclf = neighbors.KNeighborsClassifier(n_neighbors=9)\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\n\naccuracy=accuracy_score(y_test, pred)\nprint(""Predicted model accuracy: ""+ str(accuracy))'"
knn_iris_DS.py,1,"b'from sklearn import datasets, neighbors\nimport numpy as np\n\n# Load iris data from \'datasets module\'\niris = datasets.load_iris()\n\n#   Get data-records and record-labels in arrays X and y\nX = iris.data\ny = iris.target\n\n# Create an instance of KNeighborsClassifier and then fit training data\nclf = neighbors.KNeighborsClassifier()\nclf.fit(X, y)\n\n# Make class predictions for all observations in X\nZ = clf.predict(X)\n\n# Compare predicted class labels with actual class label\naccuracy = clf.score(X, y)\nprint (""Predicted model accuracy: ""+ str(accuracy))\n# Add a row of predicted classes to y-array for ease of comparison\nA = np.vstack([y, Z])\nprint(A)'"
