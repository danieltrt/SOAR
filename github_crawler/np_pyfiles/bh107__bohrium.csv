file_path,api_count,code
test/python/run.py,3,"b'# -*- coding: utf-8 -*-\nfrom __future__ import print_function\nimport argparse\nimport time\nimport sys\nimport os\nimport imp\n\nimport numpy\nimport bohrium\nimport bh107\n\n# basestring is not available in Python 3\ntry:\n  basestring\nexcept NameError:\n  basestring = str\n\n# Never run test with the \'-m bohrium\' switch\nassert (numpy != bohrium)\n\n# Terminal colors\nHEADER  = \'\\033[35m\'\nOKBLUE  = \'\\033[34m\'\nOKGREEN = \'\\033[32m\'\nWARNING = \'\\033[33m\'\nFAIL    = \'\\033[31m\'\nENDC    = \'\\033[0m\'\n\n\ndef get_test_object_names(obj):\n    """""" Returns all attribute names that starts with ""test_"" """"""\n    ret = []\n\n    for o in dir(obj):\n        if o.startswith(""test_""):\n            ret.append(o)\n\n    return ret\n\n\ndef check_result(res_np, res_bh):\n    if isinstance(res_np, type):\n        return res_np is res_bh\n    if isinstance(res_np, basestring):\n        return res_np == res_bh\n\n    if bohrium.is_scalar(res_np):\n        if not bohrium.is_scalar(res_bh):\n            return False\n    elif res_np.size == 0 and res_bh.size == 0:\n        return True  # Empty arrays are considered equal\n    elif res_bh.shape != res_np.shape:\n        return False\n    try:\n        return numpy.allclose(res_np, res_bh, equal_nan=True)\n    except TypeError:\n        # Old versions of NumPy do not have the \'equal_nan\' option\n        return numpy.allclose(res_np, res_bh)\n\n\ndef run(args):\n    for filename in args.files:\n        if not filename.endswith(""py""):\n            # Ignore non-python files\n            continue\n\n        # Remove "".py""\n        module_name = os.path.basename(filename)[:-3]\n        m = imp.load_source(module_name, filename)\n\n        if len(args.class_list) > 0:\n            cls_name_list = args.class_list\n        else:\n            cls_name_list = get_test_object_names(m)\n\n        for cls_name in cls_name_list:\n            if cls_name in args.exclude_class:\n                continue\n\n            cls_obj = getattr(m, cls_name)\n            cls_inst = cls_obj()\n\n            for mth_name in get_test_object_names(cls_obj):\n                mth_obj = getattr(cls_inst, mth_name)\n                name = ""%s/%s/%s"" % (filename, cls_name[5:], mth_name[5:])\n\n                print(""Testing %s%s%s "" % (OKGREEN, name, ENDC), end="""")\n                sys.stdout.flush()\n\n                start_time = time.time()\n\n                for ret in getattr(cls_inst, ""init"")():\n                    # Let\'s retrieve the NumPy and Bohrium commands\n                    cmd = mth_obj(ret)\n                    cmd_bh107 = None\n                    if len(cmd) == 3:\n                        (cmd_np, cmd_bh, cmd_bh107) = cmd\n                    elif len(cmd) == 2:\n                        (cmd_np, cmd_bh) = cmd\n                    else:\n                        # If not returning a tuple, the NumPy and Bohrium command are identical and bh107n is ignored\n                        cmd_np = cmd\n                        cmd_bh = cmd\n\n                    # For convenient, we replace ""M"" and ""BH"" in the command to represent NumPy or Bohrium\n                    cmd_np = cmd_np.replace(""M"", ""np"").replace(""BH"", ""False"")\n                    cmd_bh = cmd_bh.replace(""M"", ""bh"").replace(""BH"", ""True"")\n                    if cmd_bh107 is not None:\n                        cmd_bh107 = cmd_bh107.replace(""M"", ""bh107"")\n                    if args.verbose:\n                        print(""\\n%s  [NP CMD] %s%s"" % (OKBLUE, cmd_np, ENDC))\n                        print(""%s  [BH CMD] %s%s"" % (OKBLUE, cmd_bh, ENDC))\n                        if cmd_bh107 is not None:\n                            print(""%s  [BH107 CMD] %s%s"" % (OKBLUE, cmd_bh107, ENDC))\n\n                    # Let\'s execute the NumPy commands\n                    env = {""np"": numpy, ""bh"": bohrium}\n                    exec (cmd_np, env)\n                    res_np = env[\'res\']\n                    if bohrium.check(res_np):\n                        print(""\\n"")\n                        print(""%s  [Error]  The NumPy command returns a Bohrium array!%s"" % (FAIL, ENDC))\n                        print(""%s  [NP CMD] %s%s"" % (OKBLUE, cmd_np, ENDC))\n                        print(""%s  [NP RES]\\n%s%s"" % (OKGREEN, res_np, ENDC))\n                        if not args.cont_on_error:\n                            sys.exit(1)\n\n                    # Let\'s execute the Bohrium commands\n                    env = {""np"": numpy, ""bh"": bohrium}\n                    exec (cmd_bh, env)\n\n                    if bohrium.check(env[\'res\']):\n                        res_bh = env[\'res\'].copy2numpy()\n                    else:\n                        res_bh = env[\'res\']\n\n                    if not check_result(res_np, res_bh):\n                        print(""\\n"")\n                        print(""%s  [Error]  %s%s"" % (FAIL, name, ENDC))\n                        print(""%s  [NP CMD] %s%s"" % (OKBLUE, cmd_np, ENDC))\n                        print(""%s  [NP RES]\\n%s%s"" % (OKGREEN, res_np, ENDC))\n                        print(""%s  [BH CMD] %s%s"" % (OKBLUE, cmd_bh, ENDC))\n                        print(""%s  [BH RES]\\n%s%s"" % (FAIL, res_bh, ENDC))\n\n                        if not args.cont_on_error:\n                            sys.exit(1)\n\n                    # Let\'s execute the bh107 commands\n                    if cmd_bh107 is not None:\n                        env = {""np"": numpy, ""bh"": bohrium, ""bh107"": bh107}\n                        exec (cmd_bh107, env)\n                        res_bh107 = env[\'res\']\n                        if bohrium.check(res_bh107):\n                            print(""\\n"")\n                            print(""%s  [Error]  The bh107 command returns a Bohrium array!%s"" % (FAIL, ENDC))\n                            print(""%s  [bh107 CMD] %s%s"" % (OKBLUE, cmd_np, ENDC))\n                            print(""%s  [bh107 RES]\\n%s%s"" % (OKGREEN, res_bh107, ENDC))\n                            if not args.cont_on_error:\n                                sys.exit(1)\n                        if isinstance(res_bh107, bh107.BhArray):\n                            res_bh107 = res_bh107.copy2numpy()\n\n                        if not check_result(res_np, res_bh107):\n                            print(""\\n"")\n                            print(""%s  [Error]  %s%s"" % (FAIL, name, ENDC))\n                            print(""%s  [NP CMD] %s%s"" % (OKBLUE, cmd_np, ENDC))\n                            print(""%s  [NP RES]\\n%s%s"" % (OKGREEN, res_np, ENDC))\n                            print(""%s  [BH107 CMD] %s%s"" % (OKBLUE, cmd_bh107, ENDC))\n                            print(""%s  [BH107 RES]\\n%s%s"" % (FAIL, res_bh107, ENDC))\n\n                            if not args.cont_on_error:\n                                sys.exit(1)\n\n                print(""%s(%.2fs) %s\xe2\x9c\x93%s"" % (OKBLUE, time.time() - start_time, OKGREEN, ENDC))\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'Runs the test suite\')\n    parser.add_argument(\n        \'files\',\n        type=str,\n        nargs=\'+\',\n        help=\'The test files to run\'\n    )\n\n    parser.add_argument(\n        \'--verbose\',\n        action=\'store_true\',\n        help=""Print test CMD""\n    )\n\n    parser.add_argument(\n        \'--cont-on-error\',\n        action=\'store_true\',\n        help=""Continue on failed tests""\n    )\n\n    parser.add_argument(\n        \'--class\',\n        type=str,\n        action=\'append\',\n        default=[],\n        help=""Choose specific test class (the prefix \'test_\' is ignored) "" \\\n             ""(supports multiple use of this argument)""\n    )\n\n    parser.add_argument(\n        \'--exclude-class\',\n        type=str,\n        action=\'append\',\n        default=[],\n        metavar=\'CLASS\',\n        help=""Ignore specific test class (the prefix \'test_\' is ignored) "" \\\n             ""(supports multiple use of this argument)""\n    )\n    args = parser.parse_args()\n\n    # We need to rename class since it\'s a Python keyword\n    args.class_list = getattr(args, ""class"")\n    delattr(args, ""class"")\n\n    # And make sure that all class names starts with ""test_""\n    for i in range(len(args.class_list)):\n        if not args.class_list[i].startswith(""test_""):\n            args.class_list[i] = ""test_%s"" % args.class_list[i]\n\n    for i in range(len(args.exclude_class)):\n        if not args.exclude_class[i].startswith(""test_""):\n            args.exclude_class[i] = ""test_%s"" % args.exclude_class[i]\n\n    time_start = time.time()\n    run(args)\n\n    print(""%s***%s Finished in: %s%.2fs%s %s***%s"" % (OKGREEN, ENDC, OKBLUE, time.time() - time_start, ENDC, OKGREEN, ENDC))\n'"
test/python/util.py,8,"b'from __future__ import print_function\nimport numpy as np\nimport random\nimport operator\nimport functools\n\n\nclass TYPES:\n    NORMAL_INT = [\'np.int32\', \'np.int64\', \'np.uint32\', \'np.uint64\']\n    ALL_INT = NORMAL_INT + [\'np.int8\', \'np.int16\', \'np.uint8\', \'np.uint16\']\n    SIGNED_INT = [\'np.int8\', \'np.int16\', \'np.int32\', \'np.int64\']\n    UNSIGNED_INT = list(set(ALL_INT) - set(SIGNED_INT))\n    COMPLEX = [\'np.complex64\', \'np.complex128\']\n    FLOAT = [\'np.float32\', \'np.float64\']\n    ALL_SIGNED = SIGNED_INT + FLOAT + COMPLEX\n    NORMAL = NORMAL_INT + FLOAT\n    ALL = ALL_INT + FLOAT + COMPLEX\n\n\ndef gen_shapes(max_ndim, max_dim, iters=0, min_ndim=1):\n    for ndim in range(min_ndim, max_ndim + 1):\n        shape = [1] * ndim\n\n        if iters:\n            # Min shape\n            yield shape\n            # Max shape\n            yield [max_dim] * (ndim)\n\n            for _ in range(iters):\n                for d in range(len(shape)):\n                    if max_dim == 1:\n                        shape[d] = 1\n                    else:\n                        shape[d] = np.random.randint(1, max_dim)\n                yield shape\n        else:\n            finished = False\n            while not finished:\n                yield shape\n                # Find next shape\n                d = ndim - 1\n                while True:\n                    shape[d] += 1\n                    if shape[d] > max_dim:\n                        shape[d] = 1\n                        d -= 1\n                        if d < 0:\n                            finished = True\n                            break\n                    else:\n                        break\n\n\ndef gen_arrays(random_state_name, max_ndim, max_dim=10, min_ndim=1, samples_in_each_ndim=3, dtype=""np.float32"",\n               bh_arg=""BH""):\n    for shape in gen_shapes(max_ndim, max_dim, samples_in_each_ndim, min_ndim):\n        cmd = ""%s.random_of_dtype(shape=%s, dtype=%s, bohrium=%s)"" % (random_state_name, shape, dtype, bh_arg)\n        yield (cmd, shape)\n\n\nclass ViewOfDim:\n    def __init__(self, start, step, end):\n        self.start = start\n        self.step = step\n        self.end = end\n\n    def size(self):\n        ret = 0\n        i = self.start\n\n        assert self.step != 0\n\n        if self.step > 0:\n            while i < self.end:\n                ret += 1\n                i += self.step\n        else:\n            i += self.step\n            while i > self.end:\n                ret += 1\n                i += self.step\n        return ret\n\n    def write(self):\n        return ""%d:%d:%d"" % (self.start, self.end, self.step)\n\n\ndef write_subscription(view):\n    ret = ""[""\n\n    for dim in view[:-1]:\n        ret += ""%s, "" % dim.write()\n\n    ret += ""%s]"" % view[-1].write()\n    return ret\n\n\ndef random_subscription(shape):\n    view = []\n    view_shape = []\n\n    for dim in shape:\n        start = random.randint(0, dim - 1)\n        if dim > 3:\n            step = random.randint(1, dim // 3)\n        else:\n            step = 1\n\n        if start + 1 < dim - 1:\n            end = random.randint(start + 1, dim - 1)\n        else:\n            end = start + 1\n\n        # Let\'s reverse the stride sometimes\n        if random.randint(0, 2) == 0:\n            (start, end) = (end, start)\n            step *= -1\n\n        v = ViewOfDim(start, step, end)\n        view.append(v)\n        view_shape.append(v.size())\n    return write_subscription(view), view_shape\n\n\ndef gen_random_arrays(random_state_name, max_ndim, max_dim=30, min_ndim=1, samples_in_each_ndim=3,\n                      dtype=""np.float32"", bh_arg=""BH"", no_views=False):\n    for cmd, shape in gen_arrays(random_state_name, max_ndim, max_dim, min_ndim, samples_in_each_ndim, dtype, bh_arg):\n        yield (""%s"" % cmd, shape)\n\n        if functools.reduce(operator.mul, shape) > 1 and not no_views:\n            sub_tried = set()\n\n            for _ in range(samples_in_each_ndim):\n                sub, vshape = random_subscription(shape)\n\n                if sub not in sub_tried:\n                    yield (""%s%s"" % (cmd, sub), vshape)\n                    sub_tried.add(sub)\n\n\ndef prod(a):\n    """"""Returns the product of the elements in `a`""""""\n    return functools.reduce(operator.mul, a)\n\n\ndef add_bh107_cmd(func):\n    """"""Duplicates the test command into three copies, which enables bh107 test.\n       This is tor tests that only generates one command""""""\n\n    def inner(self, args):\n        cmd = func(self, args)\n        assert (len(cmd) > 3)\n        return (cmd, cmd,\n                cmd.replace(""bh.random.RandomState"", ""bh107.random.RandomState"").replace("", bohrium=BH"", """"))\n\n    return inner\n'"
bridge/bh107/bh107/_dtype_util.py,84,"b'# -*- coding: utf-8 -*-\n""""""\n==========================\nUseful Data Type Functions\n==========================\n""""""\n\nimport numpy as np\nfrom bohrium_api import _bh_api\n\n_size_of_dtype_in_bytes = {\n    np.bool: 1,\n    np.int8: 1,\n    np.int16: 2,\n    np.int32: 4,\n    np.int64: 8,\n    np.uint8: 1,\n    np.uint16: 2,\n    np.uint32: 4,\n    np.uint64: 8,\n    np.float32: 4,\n    np.float64: 8,\n    np.complex64: 8,\n    np.complex128: 16,\n}\n\n_dtype_np2bh_enum = {\n    np.bool: _bh_api.bool,\n    np.int8: _bh_api.int8,\n    np.int16: _bh_api.int16,\n    np.int32: _bh_api.int32,\n    np.int64: _bh_api.int64,\n    np.uint8: _bh_api.uint8,\n    np.uint16: _bh_api.uint16,\n    np.uint32: _bh_api.uint32,\n    np.uint64: _bh_api.uint64,\n    np.float32: _bh_api.float32,\n    np.float64: _bh_api.float64,\n    np.complex64: _bh_api.complex64,\n    np.complex128: _bh_api.complex128,\n}\n\n_dtype_type_to_dtype = {\n    np.bool: np.bool,\n    np.int8: np.int8,\n    np.int16: np.int16,\n    np.int32: np.int32,\n    np.int64: np.int64,\n    np.uint8: np.uint8,\n    np.uint16: np.uint16,\n    np.uint32: np.uint32,\n    np.uint64: np.uint64,\n    np.float32: np.float32,\n    np.float64: np.float64,\n    np.complex64: np.complex64,\n    np.complex128: np.complex128,\n    ""bool"": np.bool,\n    ""int8"": np.int8,\n    ""int16"": np.int16,\n    ""int32"": np.int32,\n    ""int64"": np.int64,\n    ""uint8"": np.uint8,\n    ""uint16"": np.uint16,\n    ""uint32"": np.uint32,\n    ""uint64"": np.uint64,\n    ""float32"": np.float32,\n    ""float64"": np.float64,\n    ""complex64"": np.complex64,\n    ""complex128"": np.complex128,\n    np.dtype(""bool""): np.bool,\n    np.dtype(""int8""): np.int8,\n    np.dtype(""int16""): np.int16,\n    np.dtype(""int32""): np.int32,\n    np.dtype(""int64""): np.int64,\n    np.dtype(""uint8""): np.uint8,\n    np.dtype(""uint16""): np.uint16,\n    np.dtype(""uint32""): np.uint32,\n    np.dtype(""uint64""): np.uint64,\n    np.dtype(""float32""): np.float32,\n    np.dtype(""float64""): np.float64,\n    np.dtype(""complex64""): np.complex64,\n    np.dtype(""complex128""): np.complex128,\n    _bh_api.bool: np.bool,\n    _bh_api.int8: np.int8,\n    _bh_api.int16: np.int16,\n    _bh_api.int32: np.int32,\n    _bh_api.int64: np.int64,\n    _bh_api.uint8: np.uint8,\n    _bh_api.uint16: np.uint16,\n    _bh_api.uint32: np.uint32,\n    _bh_api.uint64: np.uint64,\n    _bh_api.float32: np.float32,\n    _bh_api.float64: np.float64,\n    _bh_api.complex64: np.complex64,\n    _bh_api.complex128: np.complex128,\n    bool: np.bool,\n    int: np.int64,\n    float: np.float64,\n    complex: np.complex128,\n}\n\n# In Python 2.7 we should also map the `long` type\ntry:\n    _dtype_type_to_dtype[long] = np.int64\nexcept NameError:\n    pass\n\n# In Python 3 `str` is the basestring\ntry:\n    # noinspection PyCompatibility\n    basestring\nexcept NameError:\n    # noinspection PyShadowingBuiltins\n    basestring = str\n\ntry:\n    integers = (int, long)\nexcept NameError:\n    integers = (int,)  # `long` is not int Python3\n\n\ndef type_to_dtype(any_type):\n    return _dtype_type_to_dtype[any_type]\n\n\ndef obj_to_dtype(obj):\n    if isinstance(obj, (np.dtype, basestring, type)):\n        return type_to_dtype(obj)\n    elif hasattr(obj, ""dtype""):\n        return type_to_dtype(obj.dtype)\n    else:\n        return type_to_dtype(type(obj))\n\n\ndef size_of(dtype):\n    return _size_of_dtype_in_bytes[dtype]\n\n\ndef np2bh_enum(dtype):\n    """"""Convert data type from Bohrium to NumPy""""""\n    return _dtype_np2bh_enum[dtype]\n'"
bridge/bh107/bh107/array_create.py,9,"b'""""""\nArray Creation Routines\n=======================\n""""""\nimport math\nimport numpy as np\nfrom . import bharray, _dtype_util\nfrom bohrium_api import _bh_api, _info\n\n__all__ = [\'array\', \'empty\', \'zeros\', \'ones\', \'empty_like\', \'zeros_like\', \'ones_like\', \'arange\']\n\n\ndef array(obj, dtype=None, copy=False):\n    """"""\n    Create an BhArray.\n\n    Parameters\n    ----------\n    obj : array_like\n        An array, any object exposing the array interface, an\n        object whose __array__ method returns an array, or any\n        (nested) sequence.\n    dtype : data-type, optional\n        The desired data-type for the array.  If not given, then\n        the type will be determined as the minimum type required\n        to hold the objects in the sequence.  This argument can only\n        be used to \'upcast\' the array.  For downcasting, use the\n        .astype(t) method.\n    copy : bool, optional\n        If true, then the object is copied.  Otherwise, a copy\n        will only be made if obj isn\'t a BhArray of the correct dtype already\n\n    Returns\n    -------\n    out : BhArray\n        An array of dtype.\n\n    See Also\n    --------\n    empty, empty_like, zeros, zeros_like, ones, ones_like, fill\n\n    Examples\n    --------\n    >>> bh.array([1, 2, 3])\n    array([1, 2, 3])\n\n    Upcasting:\n\n    >>> bh.array([1, 2, 3.0])\n    array([ 1.,  2.,  3.])\n\n    More than one dimension:\n\n    >>> bh.array([[1, 2], [3, 4]])\n    array([[1, 2],\n           [3, 4]])\n\n    Type provided:\n\n    >>> bh.array([1, 2, 3], dtype=complex)\n    array([ 1.+0.j,  2.+0.j,  3.+0.j])\n    """"""\n\n    if isinstance(obj, bharray.BhArray):\n        if dtype is None:\n            dtype = obj.dtype\n        return obj.astype(dtype, always_copy=copy)\n    else:\n        return bharray.BhArray.from_object(obj)\n\n\ndef empty(shape, dtype=np.float64):\n    """"""\n    Return a new matrix of given shape and type, without initializing entries.\n\n    Parameters\n    ----------\n    shape : int or tuple of int\n        Shape of the empty matrix.\n    dtype : data-type, optional\n        Desired output data-type.\n\n    See Also\n    --------\n    empty_like, zeros\n\n    Notes\n    -----\n    The order of the data in memory is always row-major (C-style).\n\n    `empty`, unlike `zeros`, does not set the matrix values to zero,\n    and may therefore be marginally faster.  On the other hand, it requires\n    the user to manually set all the values in the array, and should be\n    used with caution.\n    """"""\n\n    return bharray.BhArray(shape, dtype=dtype)\n\n\ndef zeros(shape, dtype=float):\n    """"""\n    Array of zeros.\n\n    Return an array of given shape and type, filled with zeros.\n\n    Parameters\n    ----------\n    shape : {sequence of ints, int}\n        Shape of the array\n    dtype : data-type, optional\n        The desired data-type for the array, default is np.float64.\n\n    Returns\n    -------\n    out : bharray\n        Array of zeros of given shape, dtype, and order.\n    """"""\n    ret = empty(shape, dtype)\n    ret.fill(0)\n    return ret\n\n\ndef ones(shape, dtype=np.float64):\n    """"""\n    Array of ones.\n\n    Return an array of given shape and type, filled with ones.\n\n    Parameters\n    ----------\n    shape : {sequence of ints, int}\n        Shape of the array\n    dtype : data-type, optional\n        The desired data-type for the array, default is np.float64.\n\n    Returns\n    -------\n    out : bharray\n        Array of ones of given shape, dtype, and order.\n    """"""\n    ret = empty(shape, dtype)\n    ret.fill(1)\n    return ret\n\n\ndef empty_like(a, dtype=None):\n    """"""\n    Return a new array with the same shape and type as a given array.\n\n    Parameters\n    ----------\n    a : array_like\n        The shape and data-type of `a` define these same attributes of the\n        returned array.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n\n    Returns\n    -------\n    out : ndarray\n        Array of uninitialized (arbitrary) data with the same\n        shape and type as `a`.\n\n    See Also\n    --------\n    ones_like : Return an array of ones with shape and type of input.\n    zeros_like : Return an array of zeros with shape and type of input.\n    empty : Return a new uninitialized array.\n    ones : Return a new array setting values to one.\n    zeros : Return a new array setting values to zero.\n\n    Notes\n    -----\n    The order of the data in memory is always row-major (C-style).\n\n    This function does *not* initialize the returned array; to do that use\n    `zeros_like` or `ones_like` instead.  It may be marginally faster than\n    the functions that do set the array values.\n\n    Examples\n    --------\n    >>> a = ([1,2,3], [4,5,6])                         # a is array-like\n    >>> bh.empty_like(a)\n    array([[-1073741821, -1073741821,           3],    #random\n           [          0,           0, -1073741821]])\n    >>> a = np.array([[1., 2., 3.],[4.,5.,6.]])\n    >>> bh.empty_like(a)\n    array([[ -2.00000715e+000,   1.48219694e-323,  -2.00000572e+000],#random\n           [  4.38791518e-305,  -2.00000715e+000,   4.17269252e-309]])\n    """"""\n    if dtype is None:\n        dtype = a.dtype\n    return empty(a.shape, dtype)\n\n\ndef zeros_like(a, dtype=None):\n    """"""\n    Return an array of zeros with the same shape and type as a given array.\n\n    With default parameters, is equivalent to ``a.copy().fill(0)``.\n\n    Parameters\n    ----------\n    a : array_like\n        The shape and data-type of `a` define these same attributes of\n        the returned array.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n\n    Returns\n    -------\n    out : ndarray\n        Array of zeros with the same shape and type as `a`.\n\n    See Also\n    --------\n    ones_like : Return an array of ones with shape and type of input.\n    empty_like : Return an empty array with shape and type of input.\n    zeros : Return a new array setting values to zero.\n    ones : Return a new array setting values to one.\n    empty : Return a new uninitialized array.\n\n    Notes\n    -----\n    The order of the data in memory is always row-major (C-style).\n\n    Examples\n    --------\n    >>> x = bh.arange(6)\n    >>> x = x.reshape((2, 3))\n    >>> x\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> bh.zeros_like(x)\n    array([[0, 0, 0],\n           [0, 0, 0]])\n\n    >>> y = bh.arange(3, dtype=bh.float)\n    >>> y\n    array([ 0.,  1.,  2.])\n    >>> bh.zeros_like(y)\n    array([ 0.,  0.,  0.])\n\n    """"""\n    ret = empty_like(a, dtype=dtype)\n    ret.fill(0)\n    return ret\n\n\ndef ones_like(a, dtype=None):\n    """"""Return an array of ones with the same shape and type as a given array.\n\n    With default parameters, is equivalent to ``a.copy().fill(1)``.\n\n    Parameters\n    ----------\n    a : array_like\n        The shape and data-type of `a` define these same attributes of\n        the returned array.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n\n    Returns\n    -------\n    out : ndarray\n        Array of zeros with the same shape and type as `a`.\n\n    See Also\n    --------\n    zeros_like : Return an array of zeros with shape and type of input.\n    empty_like : Return an empty array with shape and type of input.\n    zeros : Return a new array setting values to zero.\n    ones : Return a new array setting values to one.\n    empty : Return a new uninitialized array.\n\n    Notes\n    -----\n    The order of the data in memory is always row-major (C-style).\n\n    Examples\n    --------\n    >>> x = bh.arange(6)\n    >>> x = x.reshape((2, 3))\n    >>> x\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> bh.ones_like(x)\n    array([[1, 1, 1],\n           [1, 1, 1]])\n\n    >>> y = bh.arange(3, dtype=bh.float)\n    >>> y\n    array([ 0.,  1.,  2.])\n    >>> bh.ones_like(y)\n    array([ 1.,  1.,  1.])\n\n    """"""\n    ret = empty_like(a, dtype=dtype)\n    ret.fill(0)\n    return ret\n\n\ndef simply_range(size, dtype=np.uint64):\n    if not isinstance(size, _dtype_util.integers):\n        raise ValueError(""size must be an integer"")\n\n    if size < 1:\n        raise ValueError(""size must be greater than 0"")\n\n    if _dtype_util.size_of(dtype) > 4:\n        ret = empty((size,), dtype=np.uint64)\n    else:\n        ret = empty((size,), dtype=np.uint32)\n\n    _bh_api.op(_info.op[""range""][""id""], [_dtype_util.np2bh_enum(ret.dtype)], [ret._bhc_handle])\n    return ret.astype(dtype, always_copy=False)\n\n\ndef arange(start, stop=None, step=1, dtype=None):\n    """"""Return evenly spaced values within a given interval.\n\n    Values are generated within the half-open interval ``[start, stop)``\n    (in other words, the interval including `start` but excluding `stop`).\n    For integer arguments the function is equivalent to the Python built-in\n    `range <http://docs.python.org/lib/built-in-funcs.html>`_ function,\n    but returns a ndarray rather than a list.\n\n    When using a non-integer step, such as 0.1, the results will often not\n    be consistent.  It is better to use ``linspace`` for these cases.\n\n    Parameters\n    ----------\n    start : number, optional\n        Start of interval.  The interval includes this value.  The default\n        start value is 0.\n    stop : number\n        End of interval.  The interval does not include this value, except\n        in some cases where `step` is not an integer and floating point\n        round-off affects the length of `out`.\n    step : number, optional\n        Spacing between values.  For any output `out`, this is the distance\n        between two adjacent values, ``out[i+1] - out[i]``.  The default\n        step size is 1.  If `step` is specified, `start` must also be given.\n    dtype : dtype\n        The type of the output array.  If `dtype` is not given, infer the data\n        type from the other input arguments.\n\n    Returns\n    -------\n    out : ndarray\n        Array of evenly spaced values.\n\n        For floating point arguments, the length of the result is\n        ``ceil((stop - start)/step)``.  Because of floating point overflow,\n        this rule may result in the last element of `out` being greater\n        than `stop`.\n\n    See Also\n    --------\n    linspace : Evenly spaced numbers with careful handling of endpoints.\n    ogrid: Arrays of evenly spaced numbers in N-dimensions\n    mgrid: Grid-shaped arrays of evenly spaced numbers in N-dimensions\n\n    Examples\n    --------\n    >>> bh.arange(3)\n    array([0, 1, 2])\n    >>> bh.arange(3.0)\n    array([ 0.,  1.,  2.])\n    >>> bh.arange(3,7)\n    array([3, 4, 5, 6])\n    >>> bh.arange(3,7,2)\n    array([3, 5])\n\n    """"""\n    if stop is None:\n        stop = start\n        start = type(stop)(0)\n\n    if not (isinstance(stop, _dtype_util.integers) and isinstance(start, _dtype_util.integers)):\n        raise ValueError(""arange(): start and stop must be integers"")\n\n    if step == 0:\n        raise ValueError(""arange(): step cannot be zero"")\n\n    # Let\'s make sure that \'step\' is always positive\n    swap_back = False\n    if step < 0:\n        step *= -1\n        (start, stop) = (stop, start)\n        swap_back = True\n\n    if start >= stop:\n        return empty((0,), dtype=dtype)\n\n    size = int(math.ceil((float(stop) - float(start)) / float(step)))\n    if dtype is None:\n        dtype = np.int64\n\n    result = simply_range(size, dtype=dtype)\n    if swap_back:\n        step *= -1\n        (start, stop) = (stop, start)\n\n    if step != 1:\n        result *= step\n\n    if start != 0:\n        result += start\n    return result\n'"
bridge/bh107/bh107/bharray.py,17,"b'# -*- coding: utf-8 -*-\nimport math\nimport numpy as np\n# noinspection PyProtectedMember,PyUnresolvedReferences\nfrom bohrium_api import _bh_api\nfrom . import _dtype_util, util\n\n\ndef _obj_contains_a_list_or_ary(obj):\n    """"""Help function that checks if `obj` contains a list or an array""""""\n    if isinstance(obj, (BhArray, list)):\n        return True\n    if isinstance(obj, tuple):\n        for o in obj:\n            if isinstance(o, (BhArray, list)):\n                return True\n    return False\n\n\nclass BhBase(object):\n    """"""A base array that represent a block of memory.\n    A base array is always the sole owner of a complete memory allocation.\n    """"""\n\n    def __init__(self, dtype, nelem):\n        #: The data type of the base array\n        self.dtype = _dtype_util.type_to_dtype(dtype)\n        #: The backend enum that corresponds to `self.dtype`\n        self._bh_dtype_enum = _dtype_util.np2bh_enum(self.dtype)\n        #: Number of elements\n        self.nelem = nelem\n        #: Size of an element in bytes\n        self.itemsize = _dtype_util.size_of(self.dtype)\n        #: Total size of the base array in bytes\n        self.nbytes = nelem * self.itemsize\n        if self.nelem == 0:\n            self._bhc_handle = None\n        else:\n            self._bhc_handle = _bh_api.new(self._bh_dtype_enum, self.nelem)\n\n    def __del__(self):\n        if hasattr(self, \'_bhc_handle\') and self._bhc_handle is not None:\n            _bh_api.destroy(self._bh_dtype_enum, self._bhc_handle)\n\n\nclass BhArray(object):\n    """"""A array that represent a *view* of a base array. Multiple array views can point to the same base array.""""""\n\n    def __init__(self, shape, dtype, strides=None, offset=0, base=None, is_scalar=False):\n        if np.isscalar(shape):\n            shape = (shape,)\n        dtype = _dtype_util.type_to_dtype(dtype)\n        if strides is None:\n            strides = util.get_contiguous_strides(shape)\n        if is_scalar:\n            assert (len(shape) == 0)\n            self.nelem = 1\n        else:\n            self.nelem = util.total_size(shape)\n        #: The base array\n        self.base = BhBase(dtype, self.nelem) if base is None else base\n        if self.dtype != self.base.dtype:\n            raise ValueError(""dtype must be identical to base.dtype (%s)"" % self.base.dtype)\n        self._shape = tuple(shape)\n        # NB: `_strides` is in elements and not in bytes, which is different from NumPy.\n        self._strides = tuple(strides)\n        self.offset = offset\n        if self.nelem == 0:\n            self._bhc_handle = None\n        else:\n            if is_scalar:  # BhArray can be a scalar but the underlying bhc array is always an array\n                shape = (1,)\n                strides = (1,)\n            self._bhc_handle = _bh_api.view(self.base._bh_dtype_enum, self.base._bhc_handle, len(shape),\n                                            int(offset), list(shape), list(strides))\n\n    @classmethod\n    def from_scalar(cls, scalar):\n        ret = cls(shape=(1,), dtype=_dtype_util.obj_to_dtype(scalar), is_scalar=True)\n        ret.fill(scalar)\n        return ret\n\n    @classmethod\n    def from_numpy(cls, numpy_array):\n        numpy_array = np.require(numpy_array, requirements=[\'C_CONTIGUOUS\', \'ALIGNED\', \'OWNDATA\'])\n        ret = cls(numpy_array.shape, numpy_array.dtype,\n                  strides=[s // numpy_array.itemsize for s in numpy_array.strides],\n                  is_scalar=numpy_array.ndim == 0)\n        _bh_api.copy_from_memory_view(ret.base._bh_dtype_enum, ret._bhc_handle, memoryview(numpy_array))\n        return ret\n\n    @classmethod\n    def from_object(cls, obj):\n        return cls.from_numpy(np.array(obj))\n\n    def __del__(self):\n        if hasattr(self, \'_bhc_handle\') and self._bhc_handle is not None:\n            _bh_api.destroy(self.base._bh_dtype_enum, self._bhc_handle)\n\n    def __str__(self):\n        if self.nelem == 0:\n            return ""[]""\n        else:\n            return str(self.asnumpy())\n\n    @property\n    def dtype(self):\n        return self.base.dtype\n\n    @property\n    def ndim(self):\n        return len(self._shape)\n\n    @property\n    def shape(self):\n        return tuple(self._shape)\n\n    @property\n    def size(self):\n        return self.nelem\n\n    @shape.setter\n    def shape(self, shape):\n        if self.isscalar():\n            raise ValueError(""Cannot reshape a scalar"")\n        if util.total_size(shape) != util.total_size(self.shape):\n            raise ValueError(""Cannot reshape array of size %d into shape %s"" % (util.total_size(self.shape), shape))\n        if not self.iscontiguous():\n            raise ValueError(""Cannot reshape a non-contiguous array"")\n        self._shape = tuple(shape)\n        self._strides = util.get_contiguous_strides(shape)\n\n    @property\n    def strides_in_bytes(self):\n        """"""Gets the strides in bytes""""""\n        return tuple([s * self.base.itemsize for s in self._strides])\n\n    @property\n    def strides(self):\n        """"""Gets the strides in elements""""""\n        return tuple(self._strides)\n\n    @strides.setter\n    def strides(self, strides):\n        """"""Sets the strides in elements""""""\n        if self.isscalar():\n            raise ValueError(""Scalars does not have `strides`"")\n        if len(strides) != len(self.shape):\n            raise ValueError(""Strides must be same length as shape (%d)"" % len(self.shape))\n        self._strides = tuple(strides)\n\n    @property\n    def __array_interface__(self):\n        """"""Exposing the The Array Interface <https://docs.scipy.org/doc/numpy/reference/arrays.interface.html>""""""\n        if self.nelem == 0:\n            raise RuntimeError(""The size of the zero!"")\n        _bh_api.flush()\n        typestr = np.dtype(self.base.dtype).str\n        shape = self.shape\n        strides = tuple(s * self.base.itemsize for s in self.strides)\n        data_ptr = _bh_api.data_get(self.base._bh_dtype_enum, self._bhc_handle, True, True, False, self.base.nbytes)\n        data = (data_ptr + self.offset * self.base.itemsize, False)  # read-only is false\n        return dict(typestr=typestr, shape=shape, strides=strides, data=data, version=0)\n\n    def asnumpy(self):\n        """"""Returns a NumPy array that points to the same memory as this BhArray""""""\n        return np.array(self, copy=False)\n\n    def copy2numpy(self):\n        """"""Returns a NumPy array that is a copy of this BhArray""""""\n        if self.nelem == 0:\n            return np.array([], self.dtype)\n        else:\n            return self.asnumpy().copy()\n\n    def view(self):\n        """"""Returns a new view that points to the same base as this BhArray""""""\n        return BhArray(self._shape, self.dtype, self._strides, self.offset, self.base, is_scalar=self.isscalar())\n\n    def fill(self, value):\n        """"""Fill the array with a scalar value.\n\n            Parameters\n            ----------\n            value : scalar\n                All elements of `a` will be assigned this value.\n\n            Examples\n            --------\n            >>> a = bh107.array([1, 2])\n            >>> a.fill(0)\n            >>> a\n            array([0, 0])\n            >>> a = bh107.empty(2)\n            >>> a.fill(1)\n            >>> a\n            array([ 1.,  1.])\n            """"""\n        from .ufuncs import assign\n        assign(value, self)\n\n    def astype(self, dtype, always_copy=True):\n        from .ufuncs import assign\n        if not always_copy and self.dtype == dtype:\n            return self\n        ret = BhArray(self._shape, dtype, is_scalar=self.isscalar())\n        assign(self, ret)\n        return ret\n\n    def isscalar(self):\n        return len(self._shape) == 0 and self.nelem == 1\n\n    def isbehaving(self):\n        return self.offset == 0 and self.iscontiguous()\n\n    def empty(self):\n        return self.nelem == 0 and not self.isscalar()\n\n    def iscontiguous(self):\n        acc = 1\n        for shape, stride in zip(reversed(self._shape), reversed(self._strides)):\n            if shape > 1 and stride != acc:\n                return False\n            else:\n                acc *= shape\n        return True\n\n    def copy(self):\n        """"""Return a copy of the array.\n\n        Returns\n        -------\n        out : BhArray\n            Copy of `self`\n        """"""\n        return self.astype(self.dtype, always_copy=True)\n\n    def transpose(self, axes=None):\n        """"""Permute the dimensions of an array.\n\n        Parameters\n        ----------\n        axes : list of ints, optional\n            By default, reverse the dimensions, otherwise permute the axes\n            according to the values given.\n        """"""\n        if axes is None:\n            axes = list(reversed(range(len(self._shape))))\n\n        ret = self.view()\n        ret._shape = tuple([self._shape[i] for i in axes])\n        ret._strides = tuple([self._strides[i] for i in axes])\n        return ret\n\n    def flatten(self, always_copy=True):\n        """""" Return a copy of the array collapsed into one dimension.\n\n        Parameters\n        ----------\n        always_copy : boolean\n            When False, a copy is only made when necessary\n\n        Returns\n        -------\n        y : ndarray\n            A copy of the array, flattened to one dimension.\n\n        Notes\n        -----\n        The order of the data in memory is always row-major (C-style).\n\n        Examples\n        --------\n        >>> a = np.array([[1,2], [3,4]])\n        >>> a.flatten()\n        array([1, 2, 3, 4])\n        """"""\n        shape = (self.nelem,)\n        if not self.iscontiguous():\n            assert (self.copy().iscontiguous())\n            ret = self.copy().flatten(always_copy=False)  # copy() makes the array contiguous\n            assert (ret.iscontiguous())\n            return ret\n        else:\n            ret = BhArray(shape, self.dtype, offset=self.offset, base=self.base)\n            if always_copy:\n                return ret.copy()\n            else:\n                return ret\n\n    def ravel(self):\n        """""" Return a contiguous flattened array.\n\n        A 1-D array, containing the elements of the input, is returned. A copy is made only if needed.\n\n        Returns\n        -------\n        y : ndarray\n            A copy or view of the array, flattened to one dimension.\n        """"""\n        return self.flatten(always_copy=False)\n\n    def reshape(self, shape):\n        length = util.total_size(shape)\n        if length != self.nelem:\n            raise RuntimeError(""Total size cannot change when reshaping"")\n\n        flat = self.flatten()\n        return BhArray(shape, flat.dtype, base=flat.base)\n\n    @property\n    def T(self):\n        return self.transpose()\n\n    def __getitem_at_dim(self, dim, key):\n        if np.isscalar(key):\n            if not isinstance(key, _dtype_util.integers):\n                raise IndexError(""Only integers, slices (`:`), ellipsis (`...`), np.newaxis (`None`) and ""\n                                 ""integer or boolean arrays are valid indices"")\n            if key < 0:\n                key += self._shape[dim]\n            if len(self._shape) <= dim or key >= self._shape[dim]:\n                raise IndexError(""Index out of bound"")\n            shape = list(self._shape)\n            shape.pop(dim)\n            strides = list(self._strides)\n            strides.pop(dim)\n            offset = self.offset + key * self._strides[dim]\n            return BhArray(shape, self.dtype, offset=offset, strides=strides, base=self.base, is_scalar=len(shape) == 0)\n        elif isinstance(key, slice):\n            if len(self._shape) <= dim:\n                raise IndexError(""IndexError: too many indices for array"")\n            length = self._shape[dim]\n            # complete missing slice information\n            step = 1 if key.step is None else key.step\n            if key.start is None:\n                start = length - 1 if step < 0 else 0\n            else:\n                start = key.start\n                if start < 0:\n                    start += length\n                if start < 0:\n                    start = -1 if step < 0 else 0\n                if start >= length:\n                    start = length - 1 if step < 0 else length\n            if key.stop is None:\n                stop = -1 if step < 0 else length\n            else:\n                stop = key.stop\n                if stop < 0:\n                    stop += length\n                if stop < 0:\n                    stop = -1\n                if stop > length:\n                    stop = length\n            new_length = int(math.ceil(abs(stop - start) / float(abs(step))))\n            # noinspection PyTypeChecker\n            shape = list(self._shape[:dim]) + [new_length] + list(self._shape[dim + 1:])\n            strides = list(self._strides[:dim]) + [step * self._strides[dim]] + list(self._strides[dim + 1:])\n            offset = self.offset + start * self._strides[dim]\n            return BhArray(shape, self.dtype, offset=offset, strides=strides, base=self.base)\n        elif key is None:\n            shape = list(self._shape)\n            shape.insert(dim, 1)\n            strides = list(self._strides)\n            strides.insert(dim, 0)\n            return BhArray(shape, self.dtype, offset=self.offset, strides=strides, base=self.base)\n        else:\n            raise IndexError(""Only integers, slices (`:`), ellipsis (`...`), np.newaxis (`None`) and ""\n                             ""integer or boolean arrays are valid indices"")\n\n    def __getitem__(self, key):\n        if np.isscalar(key) or isinstance(key, slice) or key is None or key is Ellipsis:\n            key = (key,)\n\n        if getattr(key, ""dtype"", None) == np.bool and key.shape == self.shape:\n            from .reorganization import nonzero\n            return self[nonzero(key)]\n\n        if _obj_contains_a_list_or_ary(key):\n            # Generally, we do not support indexing with arrays\n            # But when indexing array with an index array for each dimension in the array,\n            # it corresponds to take_using_index_tuple()\n            if isinstance(key, tuple) and len(key) == self.ndim:\n                from .reorganization import take_using_index_tuple\n                return take_using_index_tuple(self, key)\n            # And when indexing a vector, it corresponds to np.take()\n            if isinstance(key, (BhArray, list)) and self.ndim == 1:\n                from .reorganization import take\n                return take(self, key)\n            raise NotImplementedError(\n                ""For now, fancy indexing requires an Bohrium array per dimension (%d) got key: %s"" % (self.ndim, key))\n\n        if isinstance(key, tuple):\n            key = list(key)\n            if Ellipsis in key:\n                if key.count(Ellipsis) > 1:\n                    raise IndexError(""An index can only have a single ellipsis (\'...\')"")\n\n                # We inserts `slice(None, None, None)` at the position of the ellipsis\n                # until `key` has the size of the number of dimension.\n                idx = key.index(Ellipsis)\n                while len(key) < len(self._shape) + 1:\n                    key.insert(idx + 1, slice(None, None, None))\n                key.pop(idx)\n                assert (len(key) == len(self._shape))\n\n            for i, k in enumerate(key):\n                if k != slice(None, None, None):\n                    ret = self.__getitem_at_dim(i, k)\n                    key.pop(i)\n                    if not np.isscalar(k):\n                        key.insert(i, slice(None, None, None))\n                    return ret.__getitem__(tuple(key))\n            else:\n                return self.view()\n\n        raise IndexError(""Only integers, slices (`:`), ellipsis (`...`), np.newaxis (`None`) and ""\n                         ""integer or boolean arrays are valid indices"")\n\n    def __setitem__(self, key, value):\n\n        if getattr(key, ""dtype"", None) == np.bool and key.shape == self.shape:\n            from .reorganization import nonzero\n            self[nonzero(key)] = value\n            return\n\n        if _obj_contains_a_list_or_ary(key):\n            # Generally, we do not support indexing with arrays\n            # But when indexing array with an index array for each dimension in the array,\n            # it corresponds to take_using_index_tuple()\n            if isinstance(key, tuple) and len(key) == self.ndim:\n                from .reorganization import put_using_index_tuple\n                return put_using_index_tuple(self, key, value)\n            # And when indexing a vector, it corresponds to np.put()\n            if isinstance(key, (BhArray, list)) and self.ndim == 1:\n                from .reorganization import put\n                return put(self, key, value)\n            raise NotImplementedError(\n                ""For now, fancy indexing requires an Bohrium array per dimension got key: %s"" % key)\n\n        from .ufuncs import assign\n        assign(value, self.__getitem__(key))\n\n    # Binary Operators\n    def __add__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'add\'](self, other)\n\n    def __iadd__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'add\'](self, other, self)\n\n    def __sub__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'subtract\'](self, other)\n\n    def __isub__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'subtract\'](self, other, self)\n\n    def __mul__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'multiply\'](self, other)\n\n    def __imul__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'multiply\'](self, other, self)\n\n    def __floordiv__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'floor_divide\'](self, other)\n\n    def __ifloordiv__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'floor_divide\'](self, other, self)\n\n    def __truediv__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'true_divide\'](self, other)\n\n    def __div__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'divide\'](self, other)\n\n    def __idiv__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'divide\'](self, other, self)\n\n    def __mod__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'mod\'](self, other)\n\n    def __imod__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'mod\'](self, other, self)\n\n    def __pow__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'power\'](self, other)\n\n    def __ipow__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'power\'](self, other, self)\n\n    def __and__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'bitwise_and\'](self, other)\n\n    def __iand__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'bitwise_and\'](self, other, self)\n\n    def __xor__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'bitwise_xor\'](self, other)\n\n    def __ixor__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'bitwise_xor\'](self, other, self)\n\n    def __or__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'bitwise_or\'](self, other)\n\n    def __ior__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'bitwise_or\'](self, other, self)\n\n    # Unary Operators\n    def __neg__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'negative\'](self, other)\n\n    def __abs__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'absolute\'](self, other)\n\n    def __invert__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'invert\'](self, other)\n\n    # Comparison\n    def __lt__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'less\'](self, other)\n\n    def __le__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'less_equal\'](self, other)\n\n    def __eq__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'equal\'](self, other)\n\n    def __ne__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'not_equal\'](self, other)\n\n    def __gt__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'greater\'](self, other)\n\n    def __ge__(self, other):\n        from .ufuncs import ufunc_dict\n        return ufunc_dict[\'greater_equal\'](self, other)\n\n    def __int__(self):\n        return int(self.asnumpy())\n\n    def __float__(self):\n        return float(self.asnumpy())\n'"
bridge/bh107/bh107/random.py,34,"b'# -*- coding: utf-8 -*-\nimport os\nimport datetime\nimport numpy as np\nfrom . import bharray, _dtype_util, util\nfrom .ufuncs import ufunc_dict\nfrom bohrium_api import _bh_api\n\n\nclass RandomState:\n    def __init__(self, seed=None):\n        """"""Container for the Random123 pseudo-random number generator.\n\n        `RandomState` exposes a number of methods for generating random numbers\n        drawn from a variety of probability distributions. In addition to the\n        distribution-specific arguments, each method takes a keyword argument\n        `size` that defaults to ``None``. If `size` is ``None``, then a single\n        value is generated and returned. If `size` is an integer, then a 1-D\n        array filled with generated values is returned. If `size` is a tuple,\n        then an array with that shape is filled and returned.\n\n        Parameters\n        ----------\n        seed : int, optional\n            Random seed initializing the pseudo-random number generator.\n            Can be an integer or ``None`` (the default).\n            If `seed` is ``None``, then `RandomState` will try to read data from\n            ``/dev/urandom`` (or the Windows analogue) if available or seed from\n            the clock otherwise.\n\n        """"""\n\n        self.key = None\n        self.index = None\n        self.has_gauss = None\n        self.seed(seed)\n\n    def seed(self, seed=None):\n        """"""Seed the generator.\n\n        This method is called when `RandomState` is initialized. It can be\n        called again to re-seed the generator. For details, see `RandomState`.\n\n        Parameters\n        ----------\n        seed : int or array_like, optional\n            Seed for `RandomState`.\n\n        See Also\n        --------\n        RandomState\n\n        """"""\n        if seed is None:\n            try:\n                self.key = np.uint32(hash(os.urandom(8)))\n            except NotImplementedError:\n                self.key = np.uint32(hash(datetime.datetime.now()))\n        else:\n            self.key = np.uint32(seed)\n        self.index = 0\n        self.has_gauss = False\n\n    def get_state(self):\n        """"""Return a tuple representing the internal state of the generator.\n\n        For more details, see `set_state`.\n\n        Returns\n        -------\n        out : tuple(str, np.uint64, np.uint32)\n            The returned tuple has the following items:\n\n            1. the string \'Random123\'.\n            2. an integer ``index``.\n            3. an integer ``key``.\n\n\n        See Also\n        --------\n        set_state\n\n        Notes\n        -----\n        `set_state` and `get_state` are not needed to work with any of the\n        random distributions in Bohrium. If the internal state is manually altered,\n        the user should know exactly what he/she is doing.\n\n        """"""\n        return (\'Random123\', self.index, self.key)\n\n    def set_state(self, state):\n        """"""Set the internal state of the generator from a tuple.\n\n        For use if one has reason to manually (re-)set the internal state of the\n        ""Mersenne Twister""[1]_ pseudo-random number generating algorithm.\n\n        Parameters\n        ----------\n        state : tuple(str, np.uint64, np.uint32)\n            The returned tuple has the following items:\n\n            1. the string \'Random123\'.\n            2. an integer ``index``.\n            3. an integer ``key``.\n\n        Returns\n        -------\n        out : None\n            Returns \'None\' on success.\n\n        See Also\n        --------\n        get_state\n\n        Notes\n        -----\n        `set_state` and `get_state` are not needed to work with any of the\n        random distributions in Bohrium. If the internal state is manually altered,\n        the user should know exactly what he/she is doing.\n        """"""\n        if len(state) != 3:\n            raise ValueError(""state must contain 3 elements"")\n        if state[0] != \'Random123\':\n            raise ValueError(""algorithm must be \'Random123\'"")\n        try:\n            self.index = state[1]\n            self.key = state[2]\n        except TypeError:\n            raise ValueError(""state is not a valid Random123 state"")\n\n    def random123(self, shape):\n        """"""New array of uniform pseudo numbers based on the random123 philox2x32 algorithm.\n        NB: dtype is np.uint64 always\n\n        Parameters\n        ----------\n        shape       : int or tuple of ints\n        Defines the shape of the returned array of random floats.\n\n        Returns\n        -------\n        out : Array of uniform pseudo numbers\n        """"""\n        if np.isscalar(shape):\n            shape = (shape,)\n\n        length = util.total_size(shape)\n        flat = bharray.BhArray(length, np.uint64)\n\n        if length > 0:\n            _bh_api.random123(flat._bhc_handle, self.index, self.key)\n            self.index += flat.nelem\n        return flat.reshape(shape)\n\n    def random_sample(self, shape):\n        """"""Return random floats in the half-open interval [0.0, 1.0).\n\n        Results are from the ""continuous uniform"" distribution over the\n        stated interval.  To sample :math:`Unif[a, b), b > a` multiply\n        the output of `random_sample` by `(b-a)` and add `a`::\n\n          (b - a) * random() + a\n\n        Parameters\n        ----------\n        shape : int or tuple of ints\n            Defines the shape of the returned array of random floats.\n\n        Returns\n        -------\n        out : BhArray of floats\n            Array of random floats of shape `shape`.\n\n        Examples\n        --------\n        >>> np.random.random((5,))\n        array([ 0.30220482,  0.86820401,  0.1654503 ,  0.11659149,  0.54323428])\n\n        Three-by-two array of random numbers from [-5, 0):\n\n        >>> 5 * np.random.random((3, 2)) - 5\n        array([[-3.99149989, -0.52338984],\n               [-2.99091858, -0.79479508],\n               [-1.23204345, -1.75224494]])\n        """"""\n        # Generate random numbers as uint\n        r_uint = self.random123(shape)\n        # Convert random numbers to float in the interval [0.0, 1.0) and return.\n        return r_uint.astype(np.float64) / np.iinfo(np.uint64).max\n\n    def randint(self, low, high=None, shape=None):\n        """"""Return random integers from `low` (inclusive) to `high` (exclusive).\n\n        Return random integers from the ""discrete uniform"" distribution in the\n        ""half-open"" interval [`low`, `high`). If `high` is None (the default),\n        then results are from [0, `low`).\n\n        Parameters\n        ----------\n        low : int\n            Lowest (signed) integer to be drawn from the distribution (unless\n            ``high=None``, in which case this parameter is the *highest* such\n            integer).\n        high : int, optional\n            If provided, one above the largest (signed) integer to be drawn\n            from the distribution (see above for behavior if ``high=None``).\n        shape : int or tuple of ints, optional\n            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n            ``m * n * k`` samples are drawn.  Default is None, in which case a\n            single value is returned.\n\n        Returns\n        -------\n        out : BhArray of ints\n            `size`-shaped array of random integers from the appropriate\n            distribution, or a single such random int if `size` not provided.\n\n        See Also\n        --------\n        random.random_integers : similar to `randint`, only for the closed\n            interval [`low`, `high`], and 1 is the lowest value if `high` is\n            omitted. In particular, this other one is the one to use to generate\n            uniformly distributed discrete non-integers.\n\n        Examples\n        --------\n        >>> np.random.randint(2, size=10)\n        array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0])\n        >>> np.random.randint(1, size=10)\n        array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n        Generate a 2 x 4 array of ints between 0 and 4, inclusive:\n\n        >>> np.random.randint(5, size=(2, 4))\n        array([[4, 0, 2, 1],\n               [3, 2, 2, 0]])\n\n        """"""\n        if high is None:\n            high = low\n            low = 0\n        if low >= high:\n            raise ValueError(""low >= high"")\n        diff = high - low\n        return self.random123(shape) % diff + low\n\n    def uniform(self, low=0.0, high=1.0, shape=None):\n        """"""Draw samples from a uniform distribution.\n\n        Samples are uniformly distributed over the half-open interval\n        ``[low, high)`` (includes low, but excludes high).  In other words,\n        any value within the given interval is equally likely to be drawn\n        by `uniform`.\n\n        Parameters\n        ----------\n        low : float, optional\n            Lower boundary of the output interval.  All values generated will be\n            greater than or equal to low.  The default value is 0.\n        high : float\n            Upper boundary of the output interval.  All values generated will be\n            less than high.  The default value is 1.0.\n        shape : int or tuple of ints, optional\n            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n            ``m * n * k`` samples are drawn.  Default is None, in which case a\n            single value is returned.\n\n        Returns\n        -------\n        out : BhArray\n            Drawn samples, with shape `shape`.\n\n        See Also\n        --------\n        randint : Discrete uniform distribution, yielding integers.\n        random_integers : Discrete uniform distribution over the closed\n                          interval ``[low, high]``.\n        random_sample : Floats uniformly distributed over ``[0, 1)``.\n        random : Alias for `random_sample`.\n        rand : Convenience function that accepts dimensions as input, e.g.,\n               ``rand(2,2)`` would generate a 2-by-2 array of floats,\n               uniformly distributed over ``[0, 1)``.\n\n        Notes\n        -----\n        The probability density function of the uniform distribution is\n\n        .. math:: p(x) = \\\\frac{1}{b - a}\n\n        anywhere within the interval ``[a, b)``, and zero elsewhere.\n\n        same as:\n        random_sample(size) * (high - low) + low\n\n        Examples\n        --------\n        Draw samples from the distribution:\n\n        >>> s = np.random.uniform(-1,0,1000)\n\n        All values are within the given interval:\n\n        >>> np.all(s >= -1)\n        True\n        >>> np.all(s < 0)\n        True\n\n        Display the histogram of the samples, along with the\n        probability density function:\n\n        >>> import matplotlib.pyplot as plt\n        >>> count, bins, ignored = plt.hist(s, 15, normed=True)\n        >>> plt.plot(bins, np.ones_like(bins), linewidth=2, color=\'r\')\n        >>> plt.show()\n\n        """"""\n        return self.random_sample(shape).astype(np.float64) * (high - low) + low\n\n    def rand(self, *shape):\n        """"""Random values in a given shape.\n\n        Create an array of the given shape and propagate it with\n        random samples from a uniform distribution\n        over ``[0, 1)``.\n\n        Parameters\n        ----------\n        d0, d1, ..., dn : int, optional\n            The dimensions of the returned array, should all be positive.\n            If no argument is given a single Python float is returned.\n\n        Returns\n        -------\n        out : BhArray, shape ``(d0, d1, ..., dn)``\n            Random values.\n\n        See Also\n        --------\n        random\n\n        Notes\n        -----\n        This is a convenience function. If you want an interface that\n        takes a shape-tuple as the first argument, refer to\n        np.random.random_sample .\n\n        Examples\n        --------\n        >>> np.random.rand(3,2)\n        array([[ 0.14022471,  0.96360618],  #random\n               [ 0.37601032,  0.25528411],  #random\n               [ 0.49313049,  0.94909878]]) #random\n\n        """"""\n        return self.random_sample(shape)\n\n    def random_integers(self, low, high=None, shape=None):\n        """"""Return random integers between `low` and `high`, inclusive.\n\n        Return random integers from the ""discrete uniform"" distribution in the\n        closed interval [`low`, `high`].  If `high` is None (the default),\n        then results are from [1, `low`].\n\n        Parameters\n        ----------\n        low : int\n            Lowest (signed) integer to be drawn from the distribution (unless\n            ``high=None``, in which case this parameter is the *highest* such\n            integer).\n        high : int, optional\n            If provided, the largest (signed) integer to be drawn from the\n            distribution (see above for behavior if ``high=None``).\n        shape : tuple of ints, optional\n            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n            ``m * n * k`` samples are drawn.  Default is None, in which case a\n            single value is returned.\n\n        Returns\n        -------\n        out : BhArray of ints\n            `size`-shaped array of random integers from the appropriate\n            distribution.\n\n        See Also\n        --------\n        random.randint : Similar to `random_integers`, only for the half-open\n            interval [`low`, `high`), and 0 is the lowest value if `high` is\n            omitted.\n\n        Notes\n        -----\n        To sample from N evenly spaced floating-point numbers between a and b,\n        use::\n\n          a + (b - a) * (bh107.random.random_integers(N) - 1) / (N - 1.)\n\n        Examples\n        --------\n        >>> np.random.random_integers(5)\n        4\n        >>> type(np.random.random_integers(5))\n        <type \'int\'>\n        >>> np.random.random_integers(5, size=(3.,2.))\n        array([[5, 4],\n               [3, 3],\n               [4, 5]])\n\n        Choose five random numbers from the set of five evenly-spaced\n        numbers between 0 and 2.5, inclusive (*i.e.*, from the set\n        :math:`{0, 5/8, 10/8, 15/8, 20/8}`):\n\n        >>> 2.5 * (np.random.random_integers(5, size=(5,)) - 1) / 4.\n        array([ 0.625,  1.25 ,  0.625,  0.625,  2.5  ])\n\n        Roll two six sided dice 1000 times and sum the results:\n\n        >>> d1 = np.random.random_integers(1, 6, 1000)\n        >>> d2 = np.random.random_integers(1, 6, 1000)\n        >>> dsums = d1 + d2\n\n        Display results as a histogram:\n\n        >>> import matplotlib.pyplot as plt\n        >>> count, bins, ignored = plt.hist(dsums, 11, normed=True)\n        >>> plt.show()\n\n        """"""\n        if high is None:\n            high = low\n            low = 1\n        return self.randint(low, high + 1, shape)\n\n    def standard_exponential(self, shape=None):\n        """""" Draw samples from the standard exponential distribution.\n\n        `standard_exponential` is identical to the exponential distribution\n        with a scale parameter of 1.\n\n        Parameters\n        ----------\n        shape : int or tuple of ints, optional\n            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n            ``m * n * k`` samples are drawn.  Default is None, in which case a\n            single value is returned.\n\n        Returns\n        -------\n        out : BhArray\n            Drawn samples.\n\n        Examples\n        --------\n        Output a 3x8000 array:\n\n        >>> n = np.random.standard_exponential((3, 8000))\n\n        """"""\n        # We use -log(1-U) since U is [0, 1) */\n        return -1 * ufunc_dict[\'log\'](1 - self.random_sample(shape))\n\n    def exponential(self, scale=1.0, shape=None):\n        """""" Exponential distribution.\n\n        Its probability density function is\n\n        .. math:: f(x; \\\\frac{1}{\\\\beta}) = \\\\frac{1}{\\\\beta} \\\\exp(-\\\\frac{x}{\\\\beta}),\n\n        for ``x > 0`` and 0 elsewhere. :math:`\\\\beta` is the scale parameter,\n        which is the inverse of the rate parameter :math:`\\\\lambda = 1/\\\\beta`.\n        The rate parameter is an alternative, widely used parameterization\n        of the exponential distribution [3]_.\n\n        The exponential distribution is a continuous analogue of the\n        geometric distribution.  It describes many common situations, such as\n        the size of raindrops measured over many rainstorms [1]_, or the time\n        between page requests to Wikipedia [2]_.\n\n        Parameters\n        ----------\n        scale : float\n            The scale parameter, :math:`\\\\beta = 1/\\\\lambda`.\n        shape : int or tuple of ints, optional\n            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n            ``m * n * k`` samples are drawn.\n\n        Returns\n        -------\n        out : BhArray\n            Drawn samples.\n\n        References\n        ----------\n        .. [1] Peyton Z. Peebles Jr., ""Probability, Random Variables and\n               Random Signal Principles"", 4th ed, 2001, p. 57.\n        .. [2] ""Poisson Process"", Wikipedia,\n               http://en.wikipedia.org/wiki/Poisson_process\n        .. [3] ""Exponential Distribution, Wikipedia,\n               http://en.wikipedia.org/wiki/Exponential_distribution\n\n        """"""\n\n        if scale <= 0:\n            raise ValueError(""The `scale` must be greater than zero"")\n        return self.standard_exponential(shape) * scale\n\n    def random(self, shape=None):\n        """"""Return random floats in the half-open interval [0.0, 1.0).\n\n        Alias for `random_sample`\n        """"""\n        return self.random_sample(shape)\n\n    def sample(self, shape=None):\n        """"""Return random floats in the half-open interval [0.0, 1.0).\n\n        Alias for `random_sample`\n        """"""\n        return self.random_sample(shape)\n\n    def ranf(self, shape=None):\n        """"""Return random floats in the half-open interval [0.0, 1.0).\n\n        Alias for `random_sample`\n        """"""\n        return self.random_sample(shape)\n\n    def random_of_dtype(self, dtype, shape=None):\n        """"""Return random array of `dtype`. The values are in the interval of the `dtype`.\n\n        Parameters\n        ----------\n        dtype : data-type\n            The desired data-type for the array.\n\n        shape : int or tuple of ints\n            Defines the shape of the returned array of random floats.\n\n        Returns\n        -------\n        out : BhArray of floats\n            Array of random floats of shape `shape`.\n        """"""\n\n        dtype = _dtype_util.obj_to_dtype(dtype)\n        if dtype is np.bool:\n            res = self.random_integers(0, 1, shape)\n        elif dtype in [np.int8, np.uint8]:\n            res = self.random_integers(1, 3, shape)\n        elif dtype is np.int16:\n            res = self.random_integers(1, 5, shape)\n        elif dtype is np.uint16:\n            res = self.random_integers(1, 6, shape)\n        elif dtype in [np.float32, np.float64]:\n            res = self.random_sample(shape)\n        elif dtype in [np.complex64, np.complex128]:\n            res = self.random_sample(shape=shape) + self.random_sample(shape=shape) * 1j\n        else:\n            res = self.random_integers(1, 8, shape)\n        if len(res.shape) == 0:  # Make sure scalars is arrays.\n            res = bharray.BhArray.from_object(res)\n            res.shape = shape\n        return res.astype(dtype)\n\n\n# The default random object\n_inst = RandomState()\nseed = _inst.seed\nget_state = _inst.get_state\nset_state = _inst.set_state\nrandom_sample = _inst.random_sample\nrandom = _inst.random\nsample = _inst.sample\nranf = _inst.ranf\nrandint = _inst.randint\nuniform = _inst.uniform\nrand = _inst.rand\nrandom_integers = _inst.random_integers\nstandard_exponential = _inst.standard_exponential\nexponential = _inst.exponential\nrandom_of_dtype = _inst.random_of_dtype\n'"
bridge/bh107/bh107/reorganization.py,11,"b'import numpy as np\nfrom . import bharray, ufuncs, array_create\nfrom bohrium_api import _bh_api, _info\n\n\ndef gather(ary, indexes):\n    """"""Gather elements from \'ary\' selected by \'indexes\'.\n\n    The values of \'indexes\' are absolute indexed into a flatten \'ary\'\n    The shape of the returned array equals indexes.shape.\n\n    Parameters\n    ----------\n    ary  : BhArray\n        The array to gather elements from.\n    indexes : array_like, interpreted as integers\n        Array or list of indexes that will be gather from \'array\'\n\n    Returns\n    -------\n    r : BhArray\n        The gathered array freshly-allocated.\n    """"""\n\n    # NB: The code cache in Bohrium doesn\'t support views in GATHER.\n    #     This could be fixed but it is more efficient to do a copy.\n    ary = ary.flatten(always_copy=not ary.isbehaving())\n\n    # Convert a scalar index to a 1-element array\n    if np.isscalar(indexes):\n        indexes = [indexes]\n\n    # Make sure that indexes is BhArray of type `uint64`\n    indexes = array_create.array(indexes, dtype=np.uint64, copy=False)\n\n    if ary.nelem == 0 or indexes.nelem == 0:\n        return bharray.BhArray(shape=0, dtype=ary.dtype)\n\n    ret = bharray.BhArray(indexes.shape, dtype=ary.dtype)\n\n    # BH_GATHER: Gather elements from IN selected by INDEX into OUT. NB: OUT.shape == INDEX.shape\n    #            and IN can have any shape but must be contiguous.\n    #            gather(OUT, IN, INDEX)\n    ufuncs._call_bh_api_op(_info.op[\'gather\'][\'id\'], ret, (ary, indexes), broadcast_to_output_shape=False)\n    return ret\n\n\ndef take(a, indices, axis=None, mode=\'raise\'):\n    """"""Take elements from an array along an axis.\n\n    This function does the same thing as ""fancy"" indexing (indexing arrays\n    using arrays); however, it can be easier to use if you need elements\n    along a given axis.\n\n    Parameters\n    ----------\n    a : array_like\n        The source array.\n    indices : array_like, interpreted as integers\n        The indices of the values to extract.\n        Also allow scalars for indices.\n    axis : int, optional\n        The axis over which to select values. By default, the flattened\n        input array is used.\n    mode : {\'raise\', \'wrap\', \'clip\'}, optional\n        Specifies how out-of-bounds indices will behave.\n\n        * \'raise\' -- raise an error (default)\n        * \'wrap\' -- wrap around\n        * \'clip\' -- clip to the range\n\n        \'clip\' mode means that all indices that are too large are replaced\n        by the index that addresses the last element along that axis. Note\n        that this disables indexing with negative numbers.\n\n    Returns\n    -------\n    r : BhArray\n        The returned array has the same type as `a`.\n    """"""\n\n    a = array_create.array(a)\n\n    if mode != ""raise"":\n        raise NotImplementedError(""Bohrium only supports the \'raise\' mode not \'%s\'"" % mode)\n\n    if axis is not None and a.ndim > 1:\n        raise NotImplementedError(""Bohrium does not support the \'axis\' argument"")\n\n    return gather(a, indices)\n\n\ndef take_using_index_tuple(a, index_tuple):\n    """"""Take elements from the array \'a\' specified by \'index_tuple\'\n    This function is very similar to take(), but takes a tuple of index arrays rather than a single index array\n\n    Parameters\n    ----------\n    a : array_like\n        The source array.\n    index_tuple : tuple of array_like, interpreted as integers\n        Each array in the tuple specified the indices of the values to extract for that axis.\n        The number of arrays in \'index_tuple\' must equal the number of dimension in \'a\'\n\n    Returns\n    -------\n    r : BhArray\n        The returned array has the same type as `a`.\n    """"""\n    a = array_create.array(a)\n\n    if len(index_tuple) != a.ndim:\n        raise ValueError(""length of `index_tuple` must equal the number of dimension in `a`"")\n\n    # Make sure that all index arrays are uint64 bohrium arrays\n    index_list = []\n    for index in index_tuple:\n        index_list.append(array_create.array(index, dtype=np.uint64))\n        if index_list[-1].size == 0:\n            return array_create.empty(index_list[0].shape, dtype=a.dtype)\n\n    if a.size == 0:\n        return array_create.empty(index_list[0].shape, dtype=a.dtype)\n\n    if a.ndim == 1:\n        return take(a, index_tuple[0])\n\n    # And then broadcast them into the same shape\n    index_list = ufuncs.broadcast_arrays(index_list)\n\n    # Let\'s find the absolute index\n    abs_index = index_list[-1].copy()\n    stride = a.shape[-1]\n    for i in range(len(index_list) - 2, -1, -1):  # Iterate backwards from index_list[-2]\n        abs_index += index_list[i] * stride\n        stride *= a.shape[i]\n\n    # take() support absolute indices\n    return take(a, abs_index).reshape(index_list[0].shape)\n\n\ndef scatter(ary, indexes, values):\n    """"""Scatter \'values\' into \'ary\' selected by \'indexes\'.\n    The values of \'indexes\' are absolute indexed into a flatten \'ary\'\n    The shape of \'indexes\' and \'value\' must be equal.\n\n    Parameters\n    ----------\n    ary  : BhArray\n        The target array to write the values to.\n    indexes : array_like, interpreted as integers\n        Array or list of indexes that will be written to in \'ary\'\n    values : array_like\n        Values to write into \'ary""\n    """"""\n\n    # Make sure that indexes is BhArray of type `uint64` and flatten\n    indexes = array_create.array(indexes, dtype=np.uint64).flatten(always_copy=False)\n    values = array_create.array(values, dtype=ary.dtype).flatten(always_copy=False)\n\n    assert indexes.shape == values.shape\n    if ary.size == 0 or indexes.size == 0:\n        return\n\n    # In order to ensure a contiguous array, we do the scatter on a flatten copy\n    flat = ary.flatten(always_copy=True)\n\n    # BH_SCATTER: Scatter all elements of IN into OUT selected by INDEX. NB: IN.shape == INDEX.shape\n    #             and OUT can have any shape but must be contiguous.\n    #             scatter(OUT, IN, INDEX)\n    ufuncs._call_bh_api_op(_info.op[\'scatter\'][\'id\'], flat, (values, indexes), broadcast_to_output_shape=False)\n    ary[...] = flat.reshape(ary.shape)\n\n\ndef cond_scatter(ary, indexes, values, mask):\n    """""" Scatter \'values\' into \'ary\' selected by \'indexes\' where \'mask\' is true.\n    The values of \'indexes\' are absolute indexed into a flatten \'ary\'\n    The shape of \'indexes\', \'value\', and \'mask\' must be equal.\n\n\n    Parameters\n    ----------\n    ary  : BhArray\n        The target array to write the values to.\n    indexes : array_like, interpreted as integers\n        Array or list of indexes that will be written to in \'ary\'\n    values : array_like\n        Values to write into \'ary\'\n    mask : array_like, interpreted as booleans\n        A mask that specifies which indexes and values to include and exclude\n    """"""\n    indexes = array_create.array(indexes, dtype=np.uint64).flatten(always_copy=False)\n    values = array_create.array(values, dtype=ary.dtype).flatten(always_copy=False)\n    mask = array_create.array(mask, dtype=np.bool).flatten(always_copy=False)\n    assert (indexes.shape == values.shape and values.shape == mask.shape)\n    if ary.size == 0 or indexes.size == 0:\n        return\n\n    # In order to ensure a contiguous array, we do the scatter on a flatten copy\n    flat = ary.flatten(always_copy=True)\n\n    # BH_COND_SCATTER: Conditional scatter elements of IN where COND is true into OUT selected by INDEX.\n    #                  NB: IN.shape == INDEX.shape and OUT can have any shape but must be contiguous.\n    #                  cond_scatter(OUT, IN, INDEX, COND)\n    ufuncs._call_bh_api_op(_info.op[\'cond_scatter\'][\'id\'], flat, (values, indexes, mask),\n                           broadcast_to_output_shape=False)\n    ary[...] = flat.reshape(ary.shape)\n\n\ndef put(a, ind, v, mode=\'raise\'):\n    """"""Replaces specified elements of an array with given values.\n\n    The indexing works on the flattened target array. `put` is roughly\n    equivalent to:\n\n        a.flat[ind] = v\n\n    Parameters\n    ----------\n    a : BhArray\n        Target array.\n    ind : array_like\n        Target indices, interpreted as integers.\n    v : array_like\n        Values to place in `a` at target indices. If `v` is shorter than\n        `ind` it will be repeated as necessary.\n    mode : {\'raise\', \'wrap\', \'clip\'}, optional\n        Specifies how out-of-bounds indices will behave.\n\n        * \'raise\' -- raise an error (default)\n        * \'wrap\' -- wrap around\n        * \'clip\' -- clip to the range\n\n        \'clip\' mode means that all indices that are too large are replaced\n        by the index that addresses the last element along that axis. Note\n        that this disables indexing with negative numbers.\n    """"""\n\n    if ind.size == 0:\n        return  # Nothing to insert!\n\n    if mode != ""raise"":\n        raise NotImplementedError(""Bohrium only supports the \'raise\' mode not \'%s\'"" % mode)\n\n    # Make sure that indexes is BhArray of type `uint64` and flatten\n    indexes = array_create.array(ind, dtype=np.uint64).flatten(always_copy=False)\n    values = array_create.array(v, dtype=a.dtype).flatten(always_copy=False)\n\n    # Now let\'s make the shape of \'indexes\' and \'values\' match\n    if indexes.size > values.size:\n        if values.size == 1:\n            # When \'values\' is a scalar, we can broadcast it to match \'indexes\'\n            values = bharray.BhArray(indexes.shape, values.dtype, strides=(0,), base=values.base, offset=values.offset)\n        else:  # else we repeat \'values\' enough times to be larger than \'indexes\'\n            values = bharray.BhArray((indexes.size // values.size + 2, values.size), values.dtype, strides=(0, 1),\n                                     base=values.base, offset=values.offset)\n            values = values.flatten(always_copy=False)\n\n    # When \'values\' is too large, we simple cut the end off\n    if values.size > indexes.size:\n        values = values[0:indexes.size]\n\n    # Now that \'indexes\' and \'values\' have the same shape, we can call \'scatter\'\n    scatter(a, indexes, values)\n\n\ndef put_using_index_tuple(a, index_tuple, v):\n    """"""Replaces specified elements of an array with given values.\n    This function is very similar to put(), but takes a tuple of index arrays rather than a single index array.\n    The indexing works like fancy indexing:\n\n        a[index_tuple] = v\n\n    Parameters\n    ----------\n    a : BhArray\n        The source array.\n    index_tuple : tuple of array_like, interpreted as integers\n        Each array in the tuple specified the indices of the values to extract for that axis.\n        The number of arrays in \'index_tuple\' must equal the number of dimension in \'a\'\n    v : array_like\n        Values to place in `a`.\n    """"""\n\n    v = array_create.array(v)\n    assert len(index_tuple) == a.ndim\n\n    if a.size == 0:\n        return\n\n    if a.ndim == 1:\n        return put(a, index_tuple[0], v)\n\n    # Make sure that all index arrays are uint64 bohrium arrays\n    index_list = []\n    for index in index_tuple:\n        index_list.append(array_create.array(index, dtype=np.uint64))\n        if index_list[-1].size == 0:\n            return\n\n    # And then broadcast them into the same shape\n    index_list = ufuncs.broadcast_arrays(index_list)\n\n    # Let\'s find the absolute index\n    abs_index = index_list[-1].copy()\n    stride = a.shape[-1]\n    for i in range(len(index_list) - 2, -1, -1):  # Iterate backwards from index_list[-2]\n        abs_index += index_list[i] * stride\n        stride *= a.shape[i]\n\n    # put() support absolute indices\n    put(a, abs_index, v)\n\n\ndef pack(ary, mask):\n    """"""Packing the elements of \'ary\' specified by \'mask\' into new array that are contiguous\n    The values of \'indexes\' are absolute indexed into a flatten \'ary\'\n    The shape of \'mask\' and \'ary\' must be equal.\n\n    Parameters\n    ----------\n    ary  : array_like, read flatten\n        The array to read from.\n    mask : array_like, interpreted as a flatten boolean array\n        A mask that specifies which indexes of \'ary\' to read\n\n    Returns\n    -------\n    res : BhArray\n        The packed array.\n    """"""\n\n    ary = array_create.array(ary).flatten(always_copy=True)\n    mask = array_create.array(mask, dtype=np.bool).flatten(always_copy=True)\n    assert (ary.shape == mask.shape)\n    if ary.size == 0 or mask.size == 0:\n        return\n\n    true_indexes = ufuncs.ufunc_dict[\'add\'].accumulate(mask)\n    true_count = int(true_indexes[-1])\n    if true_count == 0:\n        return array_create.empty((0,), dtype=ary.dtype)\n    else:\n        ret = array_create.empty((true_count,), dtype=ary.dtype)\n        cond_scatter(ret, true_indexes - 1, ary, mask)\n        return ret\n\n\ndef flatnonzero(a):\n    """"""Return indices that are non-zero in the flattened version of a.\n    This is equivalent to a.ravel().nonzero()[0].\n\n    Parameters\n    ----------\n    a : BhArray\n        Input array.\n\n    Returns\n    -------\n    res : BhArray\n        Output array, containing the indices of the elements of `a.ravel()`\n        that are non-zero.\n    """"""\n\n    if a.dtype is not np.bool:\n        a = a != 0\n    new_indexes = array_create.arange(a.size, dtype=np.uint64)\n    return pack(new_indexes, a)\n\n\ndef nonzero(a):\n    """"""Return the indices of the elements that are non-zero.\n    Returns a tuple of arrays, one for each dimension of `a`,\n    containing the indices of the non-zero elements in that\n    dimension. The values in `a` are always tested and returned in\n    row-major, C-style order. The corresponding non-zero\n    values can be obtained with::\n        a[nonzero(a)]\n    To group the indices by element, rather than dimension, use::\n        transpose(nonzero(a))\n    The result of this is always a 2-D array, with a row for\n    each non-zero element.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n\n    Returns\n    -------\n    tuple_of_arrays : tuple\n        Indices of elements that are non-zero.\n    """"""\n\n    a = array_create.array(a)\n\n    if a.ndim == 1:\n        return (flatnonzero(a),)\n\n    if not a.iscontiguous():\n        a = a.copy()\n\n    nz = flatnonzero(a)\n    ret = []\n    for stride in a.strides:\n        tmp = nz // stride\n        ret.append(tmp)\n        nz -= tmp * stride\n    return tuple(ret)\n'"
bridge/bh107/bh107/ufuncs.py,36,"b'# -*- coding: utf-8 -*-\nimport sys\nimport numbers\nimport numpy as np\nfrom bohrium_api import _bh_api, _info\nfrom . import bharray, _dtype_util\n\n\nclass InvalidArgumentError(Exception):\n    pass\n\n\ndef _result_dtype(op_name, inputs):\n    """"""Returns the type signature (output, input) to use with the given operation.\n    NB: we only returns the type of the first input thus all input types must\n        be identical\n    """"""\n\n    func = _info.op[op_name]\n    # Note that we first use the dtype before the array as inputs to result_type()\n    inputs = [getattr(t, \'dtype\', t) for t in inputs]\n    dtype = np.result_type(*inputs)\n    for sig in func[\'type_sig\']:\n        if dtype.name == sig[1]:\n            return (_dtype_util.type_to_dtype(sig[0]), _dtype_util.type_to_dtype(dtype))\n\n    # Let\'s try use a float signature for the integer input\n    if np.issubdtype(dtype, np.integer):\n        for sig in func[\'type_sig\']:\n            if \'float\' in sig[1]:\n                return (_dtype_util.type_to_dtype(sig[0]), _dtype_util.type_to_dtype(sig[1]))\n\n    raise TypeError(""%s() does not support input data type: %s."" % (op_name, dtype.name))\n\n\ndef _result_shape(shape_list):\n    """"""Return the result of broadcasting `shapes` against each other""""""\n\n    # Find the number of dimensions of the broadcasted shape\n    ret_ndim = 0\n    for shape in shape_list:\n        if len(shape) > ret_ndim:\n            ret_ndim = len(shape)\n\n    # A zero dimension makes the result shape all zeros\n    for shape in shape_list:\n        for dim in shape:\n            if dim == 0:\n                return tuple([0] * ret_ndim)\n\n    # Make sure that all shapes has the same length by pre-pending ones\n    for i in range(len(shape_list)):\n        shape_list[i] = [1] * (ret_ndim - len(shape_list[i])) + list(shape_list[i])\n\n    # The resulting shape is the max of each dimension\n    ret = []\n    for i in range(ret_ndim):\n        greatest = 0\n        for shape in shape_list:\n            if shape[i] > greatest:\n                greatest = shape[i]\n        ret.append(greatest)\n    return tuple(ret)\n\n\ndef broadcast_to(ary, shape):\n    """"""Return a new view of `ary` that is broadcasted to `shape`\n\n    We use the term broadcast as defined by NumPy. Let `ret` be the broadcasted view of `ary`:\n     1) One-sized dimensions are prepended to `ret.shape()` until it has the same number of dimension as `ary`.\n     2) The strides of each one-sized dimension in `ret` is set to zero.\n     3) The shape of `ary` is set to `shape`\n\n    \\note See: <https://docs.scipy.org/doc/numpy-1.15.0/user/basics.broadcasting.html>\n\n    Parameters\n    ----------\n    ary : BhArray\n        The array to broadcast\n    shape : tuple\n        New shape\n\n    Returns\n    -------\n    r : BhArray\n         The broadcasted array\n    """"""\n\n    if len(ary.shape) > len(shape):\n        raise InvalidArgumentError(\n            ""When broadcasting, the number of dimension of array cannot be greater than in the new shape"")\n\n    # Prepend ones to shape and zeros to strides in order to make them the same lengths as `shape`\n    ret_shape = [1] * (len(shape) - len(ary.shape)) + list(ary.shape)\n    ret_strides = [0] * (len(shape) - len(ary.shape)) + list(ary.strides)\n\n    # Broadcast each dimension by setting ret_stride to zero and ret_shape to `shape`\n    for i in range(len(ret_shape)):\n        if ret_shape[i] != shape[i]:\n            if ret_shape[i] == 1:\n                ret_shape[i] = shape[i]\n                ret_strides[i] = 0\n            else:\n                raise InvalidArgumentError(""Cannot broadcast shape %s to %s"" % (ary.shape, shape))\n    return bharray.BhArray(ret_shape, ary.dtype, strides=ret_strides, offset=ary.offset, base=ary.base)\n\n\ndef broadcast_arrays(array_list):\n    """"""Broadcast any number of arrays against each other.\n\n    Parameters\n    ----------\n    `array_list` : BhArray\n        The arrays to broadcast.\n\n    Returns\n    -------\n    broadcasted : list of bhArrays\n        These arrays are views on the original arrays or the untouched originals.\n        They are typically not contiguous.  Furthermore, more than one element of a\n        broadcasted array may refer to a single memory location.  If you\n        need to write to the arrays, make copies first.\n    """"""\n\n    result_shape = _result_shape([getattr(x, \'shape\', (1,)) for x in array_list])\n    ret = []\n    for ary in array_list:\n        ret.append(broadcast_to(ary, result_shape))\n    return ret\n\n\ndef _call_bh_api_op(op_id, out_operand, in_operand_list, broadcast_to_output_shape=True, cast_input_to_dtype=None):\n    dtype_enum_list = [_dtype_util.np2bh_enum(out_operand.dtype)]\n\n    if cast_input_to_dtype is not None:\n        in_operand_list = list(in_operand_list)\n        for i in range(len(in_operand_list)):\n            if _dtype_util.obj_to_dtype(in_operand_list[i]) != cast_input_to_dtype:\n                if np.isscalar(in_operand_list[i]):\n                    in_operand_list[i] = cast_input_to_dtype(in_operand_list[i])\n                else:\n                    in_operand_list[i] = in_operand_list[i].astype(cast_input_to_dtype, always_copy=False)\n\n    handle_list = [out_operand._bhc_handle]\n    for op in in_operand_list:\n        if isinstance(op, numbers.Number):\n            dtype_enum_list.append(_dtype_util.np2bh_enum(_dtype_util.type_to_dtype(type(op))))\n            if isinstance(op, (int, float, complex)):\n                handle_list.append(op)\n            elif isinstance(op, bool):\n                handle_list.append(int(op))\n            elif np.issubdtype(op, np.integer):\n                handle_list.append(int(op))\n            elif np.issubdtype(op, np.floating):\n                handle_list.append(float(op))\n            elif np.issubdtype(op, np.complex):\n                handle_list.append(complex(op))\n            else:\n                raise InvalidArgumentError(""NumPy scalar type must be an integer, float, or complex"")\n        else:\n            dtype_enum_list.append(_dtype_util.np2bh_enum(op.dtype))\n            assert (op._bhc_handle is not None)\n            if op.shape != out_operand.shape and broadcast_to_output_shape:\n                op = broadcast_to(op, out_operand.shape)\n            handle_list.append(op._bhc_handle)\n    _bh_api.op(op_id, dtype_enum_list, handle_list)\n\n\ndef is_same_view(a, b):\n    """"""Return True when a and b is the same view. Their bases and dtypes might differ""""""\n    return a.offset == b.offset and a.shape == b.shape and a.strides == b.strides\n\n\ndef overlap_conflict(out, inputs):\n    """"""Return True when there is a possible memory conflict between the output and the inputs.""""""\n\n    for i in inputs:\n        # Scalars, different bases, or identical views can never conflict\n        if not np.isscalar(i) and i.base is out.base and not is_same_view(out, i):\n            o_low = out.offset\n            i_low = i.offset\n            o_high = o_low + 1\n            i_high = i_low + 1\n            for o_shape, o_stride, i_shape, i_stride in zip(out.shape, out.strides, i.shape, i.strides):\n                if o_stride < 0:\n                    o_low += (o_shape - 1) * o_stride\n                else:\n                    o_high += (o_shape - 1) * o_stride\n                if i_stride < 0:\n                    i_low += (i_shape - 1) * i_stride\n                else:\n                    i_high += (i_shape - 1) * i_stride\n\n            if not (i_low >= o_high or o_low >= i_high):\n                return True\n    return False\n\n\ndef assign(src, dst):\n    if dst.nelem > 0:\n        if overlap_conflict(dst, [src]):  # We use a tmp array if the in-/out-put has memory conflicts\n            tmp = bharray.BhArray(dst.shape, dst.dtype)\n            _call_bh_api_op(_info.op[""identity""][""id""], tmp, [src])\n            _call_bh_api_op(_info.op[""identity""][""id""], dst, [tmp])\n        else:\n            _call_bh_api_op(_info.op[""identity""][""id""], dst, [src])\n\n\nclass Ufunc(object):\n    def __init__(self, info):\n        """"""A Bohrium Universal Function""""""\n        self.info = info\n        if sys.version_info.major >= 3:\n            self.__name__ = info[\'name\']\n        else:\n            # Scipy complains if \'__name__\' is unicode\n            self.__name__ = info[\'name\'].encode(\'latin_1\')\n\n    def __str__(self):\n        return ""<bohrium Ufunc \'%s\'>"" % self.info[\'name\']\n\n    def __call__(self, *operand_list):\n        if len(operand_list) == self.info[\'nop\']:\n            out_operand = operand_list[-1]\n            in_operands = list(operand_list[:-1])\n            if not isinstance(out_operand, bharray.BhArray):\n                raise InvalidArgumentError(""Output must be of type `BhArray` is `%s`"" % type(out_operand))\n        elif len(operand_list) == self.info[\'nop\'] - 1:\n            out_operand = None\n            in_operands = list(operand_list)\n        else:\n            raise InvalidArgumentError(""The ufunc `%s` takes %d input arguments followed by an ""\n                                       ""optional output argument"" % (self.info[\'name\'], self.info[\'nop\'] - 1))\n\n        out_shape = _result_shape([getattr(x, \'shape\', (1,)) for x in operand_list])\n        if out_operand is not None and out_shape != out_operand.shape:\n            raise InvalidArgumentError(\n                ""Shape mismatch, the output shape %s should have been %s"" % (out_operand.shape, out_shape))\n\n        out_dtype, in_dtype = _result_dtype(self.info[\'name\'], in_operands)\n\n        # If the output is specified, its shape must match `out_shape`\n        if out_operand is None:\n            out_operand = bharray.BhArray(out_shape, out_dtype)\n        elif out_operand.shape != out_shape:\n            raise InvalidArgumentError(""The output argument should have the shape: %s"" % out_shape)\n\n        if out_operand.nelem > 0:\n            if out_dtype == out_operand.dtype and not overlap_conflict(out_operand, in_operands):\n                _call_bh_api_op(self.info[""id""], out_operand, in_operands, cast_input_to_dtype=in_dtype)\n            else:  # We use a tmp array if the in-/out-put has memory conflicts or different dtypes\n                tmp_out = bharray.BhArray(out_shape, out_dtype)\n                _call_bh_api_op(self.info[""id""], tmp_out, in_operands, cast_input_to_dtype=in_dtype)\n                assign(tmp_out, out_operand)\n        return out_operand\n\n    def reduce(self, ary, axis=0, out=None):\n        """"""Reduces `ary`\'s dimension by len(\'axis\'), by applying ufunc along the\n        axes in \'axis\'.\n\n        Let :math:`ary.shape = (N_0, ..., N_i, ..., N_{M-1})`.  Then\n        :math:`ufunc.reduce(ary, axis=i)[k_0, ..,k_{i-1}, k_{i+1}, .., k_{M-1}]` =\n        the result of iterating `j` over :math:`range(N_i)`, cumulatively applying\n        ufunc to each :math:`ary[k_0, ..,k_{i-1}, j, k_{i+1}, .., k_{M-1}]`.\n\n        For a one-dimensional array, reduce produces results equivalent to:\n          r = op.identity # op = ufunc\n          for i in range(len(A)):\n              r = op(r, A[i])\n          return r\n\n        For example, add.reduce() is equivalent to sum().\n\n        Parameters\n        ----------\n        ary : BhArray\n            The array to act on.\n        axis : None or int or tuple of ints, optional\n            Axis or axes along which a reduction is performed.\n            The default (`axis` = 0) is perform a reduction over the first\n            dimension of the input array. `axis` may be negative, in\n            which case it counts from the last to the first axis.\n            If this is `None`, a reduction is performed over all the axes.\n            If this is a tuple of ints, a reduction is performed on multiple\n            axes, instead of a single axis or all the axes as before.\n        out : ndarray, optional\n            A location into which the result is stored. If not provided, a\n            freshly-allocated array is returned.\n\n        Returns\n        -------\n        r : BhArray      The reduced array. If `out` was supplied, `r` is a reference to it.\n\n        Examples\n        --------\n        >>> np.multiply.reduce([2,3,5])\n        30\n        A multi-dimensional array example:\n        >>> X = np.arange(8).reshape((2,2,2))\n        >>> X\n        array([[[0, 1],\n                [2, 3]],\n               [[4, 5],\n                [6, 7]]])\n        >>> np.add.reduce(X, 0)\n        array([[ 4,  6],\n               [ 8, 10]])\n        >>> np.add.reduce(X) # confirm: default axis value is 0\n        array([[ 4,  6],\n               [ 8, 10]])\n        >>> np.add.reduce(X, 1)\n        array([[ 2,  4],\n               [10, 12]])\n        >>> np.add.reduce(X, 2)\n        array([[ 1,  5],\n               [ 9, 13]])\n        """"""\n\n        # Make sure that \'axis\' is a list of dimensions to reduce\n        if axis is None:\n            # We reduce all dimensions\n            axis = range(len(ary.shape))\n        elif np.isscalar(axis):\n            # We reduce one dimension\n            axis = [axis]\n        else:\n            # We reduce multiple dimensions\n            axis = list(axis)\n\n        # Check for out of bounds and convert negative axis values\n        if len(axis) > len(ary.shape):\n            raise ValueError(""number of \'axes\' to reduce is out of bounds"")\n        for i in range(len(axis)):\n            if axis[i] < 0:\n                axis[i] = len(ary.shape) + axis[i]\n            if axis[i] >= len(ary.shape):\n                raise ValueError(""\'axis\' is out of bounds"")\n\n        # No axis should be reduced multiple times\n        if len(axis) != len(set(axis)):\n            raise ValueError(""duplicate value in \'axis\'"")\n\n        if not isinstance(ary, bharray.BhArray):\n            raise InvalidArgumentError(""Input must be of type `BhArray` is `%s`"" % type(ary))\n\n        if out is not None and not isinstance(out, bharray.BhArray):\n            raise InvalidArgumentError(""Output must be of type `BhArray` is `%s`"" % type(out))\n\n        # When reducing booleans numerically, we count the number of True values\n        if (not self.info[\'name\'].startswith(""logical"")) and ary.dtype == np.bool:\n            ary = ary.astype(np.uint64)\n\n        if len(axis) == 1:  # One axis reduction we can handle directly\n            axis = axis[0]\n\n            # Find the output shape\n            if len(ary.shape) == 1:\n                shape = []\n            else:\n                shape = tuple(s for i, s in enumerate(ary.shape) if i != axis)\n                if out is not None and out.shape != shape:\n                    raise ValueError(""output dimension mismatch expect ""\n                                     ""shape \'%s\' got \'%s\'"" % (shape, out.shape))\n\n            tmp = bharray.BhArray(shape, ary.dtype, is_scalar=len(shape) == 0)\n\n            # NumPy compatibility: when the axis dimension size is zero NumPy just returns the neutral value\n            if ary.shape[axis] == 0:\n                tmp[...] = getattr(getattr(np, self.info[\'name\']), ""identity"")\n            elif len(ary.shape) == 1 and ary.shape[0] == 1:  # Single element, no need to reduce\n                tmp[...] = ary[0]\n            elif ary.empty():\n                tmp = ary\n            else:\n                _call_bh_api_op(_info.op[""%s_reduce"" % self.info[\'name\']][\'id\'], tmp, [ary, np.int64(axis)],\n                                broadcast_to_output_shape=False)\n            if out is not None:\n                out[...] = tmp\n            else:\n                out = tmp\n            return out\n        else:\n            # If we are reducing to a scalar across several dimensions, reshape to a vector\n            if len(ary.shape) == len(axis) and ary.iscontiguous():\n                ary = ary.flatten(always_copy=False)\n                ary = self.reduce(ary)\n            else:\n                # Let\'s reduce the last axis\n                # TODO: Flatten as many inner dimensions as possible!\n                ary = self.reduce(ary, axis[-1])\n                ary = self.reduce(ary, axis[:-1])\n\n            # Finally, we may have to copy the result to \'out\'\n            if out is not None:\n                out[...] = ary\n            else:\n                out = ary\n        return out\n\n    def accumulate(self, ary, axis=0, out=None):\n        """"""Accumulate the result of applying the operator to all elements.\n\n        For a one-dimensional array, accumulate produces results equivalent to::\n\n          r = np.empty(len(A))\n          t = op.identity        # op = the ufunc being applied to A\'s  elements\n          for i in range(len(A)):\n              t = op(t, A[i])\n              r[i] = t\n          return r\n\n        For example, add.accumulate() is equivalent to np.cumsum().\n\n        For a multi-dimensional array, accumulate is applied along only one\n        axis (axis zero by default; see Examples below) so repeated use is\n        necessary if one wants to accumulate over multiple axes.\n\n        Parameters\n        ----------\n        ary : array_like\n            The array to act on.\n        axis : int, optional\n            The axis along which to apply the accumulation; default is zero.\n        out : ndarray, optional\n            A location into which the result is stored. If not provided a\n            freshly-allocated array is returned.\n\n        Returns\n        -------\n        r : ndarray\n            The accumulated values. If `out` was supplied, `r` is a reference to\n            `out`.\n\n        Examples\n        --------\n        1-D array examples:\n\n        >>> np.add.accumulate([2, 3, 5])\n        array([ 2,  5, 10])\n        >>> np.multiply.accumulate([2, 3, 5])\n        array([ 2,  6, 30])\n\n        2-D array examples:\n\n        >>> I = np.eye(2)\n        >>> I\n        array([[ 1.,  0.],\n               [ 0.,  1.]])\n\n        Accumulate along axis 0 (rows), down columns:\n\n        >>> np.add.accumulate(I, 0)\n        array([[ 1.,  0.],\n               [ 1.,  1.]])\n        >>> np.add.accumulate(I) # no axis specified = axis zero\n        array([[ 1.,  0.],\n               [ 1.,  1.]])\n\n        Accumulate along axis 1 (columns), through rows:\n\n        >>> np.add.accumulate(I, 1)\n        array([[ 1.,  1.],\n               [ 0.,  1.]])\n        """"""\n        # Check for out of bounds and convert negative axis values\n        if axis < 0:\n            axis = ary.ndim + axis\n        if axis >= ary.ndim:\n            raise ValueError(""\'axis\' is out of bounds"")\n\n        if not isinstance(ary, bharray.BhArray):\n            raise InvalidArgumentError(""Input must be of type `BhArray` is `%s`"" % type(ary))\n\n        # When accumulate booleans numerically, we count the number of True values\n        if (not self.info[\'name\'].startswith(""logical"")) and ary.dtype == np.bool:\n            ary = ary.astype(np.uint64)\n\n        if out is None:\n            out = bharray.BhArray(shape=ary.shape, dtype=ary.dtype)\n        else:\n            if not isinstance(out, bharray.BhArray):\n                raise InvalidArgumentError(""Output must be of type `BhArray` is `%s`"" % type(out))\n        if ary.nelem > 0:\n            _call_bh_api_op(_info.op[""%s_accumulate"" % self.info[\'name\']][\'id\'], out, [ary, np.int64(axis)],\n                            broadcast_to_output_shape=False)\n        return out\n\n\ndef generate_ufuncs():\n    ufuncs = {}\n    for op in _info.op.values():\n        if op[\'elementwise\'] and op[\'name\'] != \'identity\':\n            f = Ufunc(op)\n            ufuncs[f.info[\'name\']] = f\n\n    # Bohrium divide is like division in C/C++ where floats are like\n    # `true_divide` and integers are like `floor_divide` in NumPy\n    ufuncs[\'bh_divide\'] = ufuncs[\'divide\']\n\n    # NOTE: We have to add ufuncs that doesn\'t map to Bohrium operations directly\n    #       such as ""negative"" which can be done like below.\n    class Negative(Ufunc):\n        def __call__(self, a, out=None):\n            if out is None:\n                return ufuncs[\'mul\'](a, -1)\n            else:\n                return ufuncs[\'mul\'](a, -1, out)\n\n    ufuncs[""negative""] = Negative({\'name\': \'negative\', \'nop\': 2})\n\n    class TrueDivide(Ufunc):\n        def __call__(self, a1, a2, out=None):\n            if np.issubdtype(_dtype_util.obj_to_dtype(a1), np.inexact) or \\\n                    np.issubdtype(_dtype_util.obj_to_dtype(a2), np.inexact):\n                ret = ufuncs[""bh_divide""](a1, a2)\n            else:\n                if _dtype_util.size_of(_dtype_util.obj_to_dtype(a1)) > 4 or \\\n                        _dtype_util.size_of(_dtype_util.obj_to_dtype(a2)) > 4:\n                    dtype = np.float64\n                else:\n                    dtype = np.float32\n                if not np.isscalar(a1):\n                    a1 = a1.astype(dtype, always_copy=False)\n                if not np.isscalar(a2):\n                    a2 = a2.astype(dtype, always_copy=False)\n                ret = ufuncs[\'bh_divide\'](a1, a2)\n            if out is None:\n                return ret\n            else:\n                assign(ret, out)\n                return out\n\n    ufuncs[""true_divide""] = TrueDivide({\'name\': \'true_divide\', \'nop\': 3})\n\n    # NumPy in Python v3 uses ""true"" division\n    # NB: the Numpy docs says it uses ""true"" division always, but that is not the case.\n    #     On Python 2 is uses C-style division\n    if sys.version_info.major >= 3:\n        ufuncs[""divide""] = TrueDivide({\'name\': \'divide\', \'nop\': 3})\n\n    class FloorDivide(Ufunc):\n        def __call__(self, a1, a2, out=None):\n            if np.issubdtype(_dtype_util.obj_to_dtype(a1), np.inexact) or \\\n                    np.issubdtype(_dtype_util.obj_to_dtype(a2), np.inexact):\n                ret = ufuncs[\'floor\'](ufuncs[""bh_divide""](a1, a2))\n            else:\n                ret = ufuncs[\'bh_divide\'](a1, a2)\n            if out is None:\n                return ret\n            else:\n                assign(ret, out)\n                return out\n\n    ufuncs[""floor_divide""] = FloorDivide({\'name\': \'floor_divide\', \'nop\': 3})\n    return ufuncs\n\n\ndef generate_bh_operations():\n    ret = {}\n    for op in _info.op.values():\n        f = Ufunc(op)\n        ret[f.info[\'name\']] = f\n    return ret\n\n\n# Generate all ufuncs\nufunc_dict = generate_ufuncs()\n'"
bridge/bh107/bh107/user_kernel.py,6,"b'import numpy as np\nfrom bohrium_api import stack_info, _bh_api\nfrom . import bharray, _dtype_util\n\n_default_compiler_command = None\n\n\ndef get_default_compiler_command():\n    """""" Returns the default compiler command, which is the one typically extended with extra link commands """"""\n    global _default_compiler_command\n    if _default_compiler_command is None:\n        import re\n        from bohrium_api import stack_info\n        m = re.search(""JIT Command: \\""([^\\""]*)\\"""", stack_info.info()[\'runtime_info\'])\n        if m is None:\n            raise RuntimeError(""\'JIT Command\' not found in the Bohrium backend"")\n        _default_compiler_command = m.group(1)\n    return _default_compiler_command\n\n\ndef execute(kernel_source, operand_list, compiler_command=None, tag=""openmp"", param=None, only_behaving_operands=True):\n    """""" Compile and execute the function `execute()` with the arguments in `operand_list`\n\n    Parameters\n    ----------\n    kernel_source : str\n        The kernel source code that most define the function `execute()` that should take arguments corresponding\n        to the `operand_list`\n    operand_list : list of bohrium arrays\n        The arrays given to the `execute()` function defined in `kernel_source`\n    compiler_command : str, optional\n        The compiler command to use when comping the kernel. `{OUT}` and `{IN}` in the command are replaced with the\n        name of the binary and source path.\n        When this options isn\'t specified, the default command are used see `get_default_compiler_command()`.\n    tag : str, optional\n        Name of the backend that should handle this kernel.\n    param : dict, optional\n        Backend specific parameters (e.g. OpenCL needs `global_work_size` and `local_work_size`).\n    only_behaving_operands : bool, optional\n        Set to False in order to allow non-behaving operands. Requirements for a behaving array:\n             * Is a bohrium array\n             * Is C-style contiguous\n             * Points to the first element in the underlying base array (no offset)\n             * Has the same total length as its base\n        See `make_behaving()`\n\n    Examples\n    --------\n    # Simple addition kernel\n    import bohrium as bh\n    kernel = r\'\'\'\n    #include <stdint.h>\n    void execute(double *a, double *b, double *c) {\n        for(uint64_t i=0; i<100; ++i) {\n            c[i] = a[i] + b[i] + i;\n        }\n    }\'\'\'\n    a = bh107.ones(100, np.double)\n    b = bh107.ones(100, np.double)\n    res = bh107.empty_like(a)\n    bh107.user_kernel.execute(kernel, [a, b, res])\n\n    """"""\n    if stack_info.is_proxy_in_stack():\n        raise RuntimeError(""The proxy backend does not support user kernels"")\n    if compiler_command is None:\n        compiler_command = get_default_compiler_command()\n\n    op_handle_list = []\n    for op in operand_list:\n        if not isinstance(op, bharray.BhArray):\n            raise TypeError(""All operands in `operand_list` must be BhArrays"")\n        if only_behaving_operands and not op.isbehaving():\n            raise TypeError(""Operand is not behaving set `only_behaving_operands=False` or use `make_behaving()`"")\n        op_handle_list.append(op._bhc_handle)\n\n    if param is None:\n        param = {}\n\n    def parse_param():\n        import collections\n        for key, value in param.items():\n            if isinstance(value, collections.Iterable) and not isinstance(value, str):\n                value = "" "".join(str(subvalue) for subvalue in value)\n            yield ""%s: %s"" % (key, value)\n\n    param_str = ""; "".join(parse_param())\n\n    _bh_api.flush()\n    ret_msg = _bh_api.user_kernel(kernel_source, op_handle_list, compiler_command, tag, param_str)\n    if len(ret_msg) > 0:\n        raise RuntimeError(ret_msg)\n\n\ndef dtype_to_c99(dtype):\n    """""" Returns the C99 name of `dtype` """"""\n    dtype = _dtype_util.obj_to_dtype(dtype)\n    if isinstance(dtype, _dtype_util.integers):\n        return ""%s_t"" % str(dtype)\n    elif dtype == np.float32:\n        return ""float""\n    elif dtype == np.float64:\n        return ""double""\n    elif dtype == np.complex64:\n        return ""float complex""\n    elif dtype == np.complex128:\n        return ""double complex""\n    raise TypeError(""dtype \'%s\' unsupported"" % str(dtype))\n\n\ndef gen_function_prototype(operand_list, operand_name_list=None):\n    """""" Returns the `execute() definition based on the arrays in `operand_list` """"""\n    dtype_list = [dtype_to_c99(t.dtype) for t in operand_list]\n    ret = ""#include <stdint.h>\\n#include <complex.h>\\n""\n    ret += ""void execute(""\n    for i in range(len(dtype_list)):\n        ret += ""%s *"" % dtype_list[i]\n        if operand_name_list is None:\n            ret += ""a%d, "" % i\n        else:\n            ret += ""%s, "" % operand_name_list[i]\n    return ""%s)\\n"" % ret[:-2]\n\n\ndef make_behaving(ary, dtype=None):\n    """""" Make sure that `ary` is a ""behaving"" bohrium array of type `dtype`.\n\n    Requirements for a behaving array:\n     * Is a bohrium array\n     * Points to the first element in the underlying base array (no offset)\n     * Has the same total length as its base\n\n    Parameters\n    ----------\n    ary : BhArray\n        The array to make behaving\n    dtype : boolean, optional\n        The return array is converted to `dtype` if not None\n    \n    Returns\n    -------\n    A behaving BhArray that might be a copy of `ary`\n\n    Note\n    ----\n    Use this function to make sure that operands given to `execute()` is ""behaving"" that is\n    the kernel can access the arrays without worrying about offset and stride.\n    """"""\n\n    if ary.isbehaving():\n        ret = ary\n    else:\n        ret = ary.flatten(always_copy=True)\n    if dtype is not None:\n        ret = ret.astype(dtype)\n    return ret\n'"
bridge/npbackend/bohrium/__main__.py,1,"b'#!/usr/bin/env python\n\n# In this module we implement an ""as numpy"" hack which makes it possible to\n# utilize Bohrium using the command line argument ""python -m bohrium.as_numpy""\n\nimport sys\nimport os\nimport argparse\nimport bohrium\nimport bohrium_api\nfrom . import version\n\n\n@bohrium.replace_numpy\ndef execfile_wrapper(path):\n    """"""execfile() does not exist in Python 3""""""\n\n    # We need this ugly code in order to avoid wrapping the script execution in a try/except construct\n    try:\n        execfile\n    except NameError:\n        import runpy\n        return runpy.run_path(path, init_globals={}, run_name=""__main__"")\n    return execfile(path, {""__name__"": ""__main__"", ""__file__"": path})\n\n\nif len(sys.argv) <= 1:\n    sys.stderr.write(\n        \'ERR: the ""-m bohrium"" does not support interactive mode. Use `-m bohrium --info` for Bohrium info\\n\')\n    sys.exit(-1)\n\nparser = argparse.ArgumentParser(add_help=False)\nparser.add_argument(\n    \'--info\',\n    action=""store_true"",\n    default=False,\n    help=\'Print Runtime Info\'\n)\n(args, argv) = parser.parse_known_args()\n\n# If there are more arguments than parsed, we are running a regular script\n# Else we are running one of the build-in Bohrium scripts\nif len(argv) > 0:\n    # Set the module search path to the dir of the script\n    sys.argv.pop(0)\n    if len(sys.argv) > 0:\n        sys.path[0] = os.path.dirname(os.path.abspath(sys.argv[0]))\n    else:\n        sys.path[0] = """"\n    execfile_wrapper(sys.argv[0])\nelse:\n    if args.info:\n        print(""----\\nBohrium version: %s"" % version.__version__)\n        print(bohrium_api.stack_info.pprint())\n\n        cmd = ""import bohrium as bh; import numpy as np; assert((bh.arange(10) == np.arange(10)).all())""\n        sys.stdout.write(\'Sanity Check: ""%s""\' % cmd)\n        try:\n            exec (cmd)\n            sys.stdout.write(\' - success!\\n\')\n        except AssertionError as e:\n            sys.stdout.write(\'\\n\')\n            sys.stderr.write(""ERROR - the sanity checked failed!\\n"")\n'"
bridge/npbackend/bohrium/array_create.py,40,"b'""""""\nArray Creation Routines\n=======================\n""""""\nimport math\nimport warnings\nimport collections\nfrom . import bhary\nfrom bohrium_api import _info\nfrom .bhary import fix_biclass_wrapper\nimport numpy_force as numpy\nfrom ._util import dtype_equal, dtype_in, dtype_support\n\n\ndef _warn_dtype(dtype, stacklevel):\n    """"""Raise a dtype-not-supported warning """"""\n    warnings.warn(""Bohrium does not support the dtype \'%s\', the new array will be a regular NumPy array.""\n                  % dtype, UserWarning, stacklevel)\n\n\n# Notice, array() is not decorated with @fix_biclass_wrapper() since @fix_biclass_wrapper() calls bohrium.array(), which\n# would result in an infinite recursion. Similarly, when calling numpy.array() we set the \'fix_biclass=False\'\n# argument, which prevent any further calls to bohrium.array().\ndef array(obj, dtype=None, copy=False, order=None, subok=False, ndmin=0, bohrium=True):\n    """"""\n    Create an array -- Bohrium or NumPy ndarray.\n\n    Parameters\n    ----------\n    obj : array_like\n        An array, any object exposing the array interface, an\n        object whose __array__ method returns an array, or any\n        (nested) sequence.\n    dtype : data-type, optional\n        The desired data-type for the array.  If not given, then\n        the type will be determined as the minimum type required\n        to hold the objects in the sequence.  This argument can only\n        be used to \'upcast\' the array.  For downcasting, use the\n        .astype(t) method.\n    copy : bool, optional\n        If true, then the object is copied.  Otherwise, a copy\n        will only be made if __array__ returns a copy, if obj is a\n        nested sequence, or if a copy is needed to satisfy any of the other\n        requirements (`dtype`, `order`, etc.).\n    order : {\'C\', \'F\', \'A\'}, optional\n        Specify the order of the array.  If order is \'C\' (default), then the\n        array will be in C-contiguous order (last-index varies the\n        fastest).  If order is \'F\', then the returned array\n        will be in Fortran-contiguous order (first-index varies the\n        fastest).  If order is \'A\', then the returned array may\n        be in any order (either C-, Fortran-contiguous, or even\n        discontiguous).\n    subok : bool, optional\n        If True, then sub-classes will be passed-through, otherwise\n        the returned array will be forced to be a base-class array (default).\n    ndmin : int, optional\n        Specifies the minimum number of dimensions that the resulting\n        array should have.  Ones will be pre-pended to the shape as\n        needed to meet this requirement.\n    bohrium : boolean, optional\n        Determines whether it is a Bohrium array (bohrium.ndarray) or a\n        regular NumPy array (numpy.ndarray)\n\n    Returns\n    -------\n    out : ndarray\n        An array object satisfying the specified requirements.\n\n    See Also\n    --------\n    empty, empty_like, zeros, zeros_like, ones, ones_like, fill\n\n    Examples\n    --------\n    >>> np.array([1, 2, 3])\n    array([1, 2, 3])\n\n    Upcasting:\n\n    >>> np.array([1, 2, 3.0])\n    array([ 1.,  2.,  3.])\n\n    More than one dimension:\n\n    >>> np.array([[1, 2], [3, 4]])\n    array([[1, 2],\n           [3, 4]])\n\n    Minimum dimensions 2:\n\n    >>> np.array([1, 2, 3], ndmin=2)\n    array([[1, 2, 3]])\n\n    Type provided:\n\n    >>> np.array([1, 2, 3], dtype=complex)\n    array([ 1.+0.j,  2.+0.j,  3.+0.j])\n\n    Data-type consisting of more than one element:\n\n    >>> x = np.array([(1,2),(3,4)],dtype=[(\'a\',\'<i4\'),(\'b\',\'<i4\')])\n    >>> x[\'a\']\n    array([1, 3])\n\n    Creating an array from sub-classes:\n\n    >>> np.array(np.mat(\'1 2; 3 4\'))\n    array([[1, 2],\n           [3, 4]])\n\n    >>> np.array(np.mat(\'1 2; 3 4\'), subok=True)\n    matrix([[1, 2],\n            [3, 4]])\n\n    """"""\n    ary = obj\n    if bohrium:\n        if bhary.check(ary):\n            if order == \'F\':\n                raise ValueError(""Cannot convert a Bohrium array to column-major (\'F\') memory representation"")\n            elif order == \'C\' and not ary.flags[\'C_CONTIGUOUS\']:\n                copy = True  # We need to copy in order to make the returned array contiguous\n\n            if copy:\n                t = empty_like(ary)\n                t[...] = ary\n                ary = t\n\n            if dtype is not None and not dtype_equal(dtype, ary.dtype):\n                t = empty_like(ary, dtype=dtype)\n                t[...] = ary\n                ary = t\n\n            for i in range(ary.ndim, ndmin):\n                ary = numpy.expand_dims(ary, i)\n\n            return ary\n        else:\n            # Let\'s convert the array using regular NumPy.\n            # When `ary` is not a regular NumPy array, we make sure that `ary` contains no Bohrium arrays\n            if isinstance(ary, collections.Sequence) and \\\n                    not (isinstance(ary, numpy.ndarray) and ary.dtype.isbuiltin == 1):\n                ary = list(ary)  # Let\'s make sure that `ary` is mutable\n                for i in range(len(ary)):  # Converting 1-element Bohrium arrays to NumPy scalars\n                    if bhary.check(ary[i]):\n                        ary[i] = ary[i].copy2numpy()\n            ary = numpy.array(ary, dtype=dtype, copy=copy, order=order, subok=subok, ndmin=ndmin, fix_biclass=False)\n\n            # In any case, the array must meet some requirements\n            ary = numpy.require(ary, requirements=[\'C_CONTIGUOUS\', \'ALIGNED\', \'OWNDATA\'])\n\n            if bohrium and not dtype_support(ary.dtype):\n                _warn_dtype(ary.dtype, 3)\n                return ary\n\n            ret = empty(ary.shape, dtype=ary.dtype)\n            if ret.size > 0:\n                ret._data_fill(ary)\n            return ret\n    else:\n        if bhary.check(ary):\n            ret = ary.copy2numpy()\n            return numpy.array(ret, dtype=dtype, copy=copy, order=order, subok=subok, ndmin=ndmin, fix_biclass=False)\n        else:\n            return numpy.array(ary, dtype=dtype, copy=copy, order=order, subok=subok, ndmin=ndmin, fix_biclass=False)\n\n\n@fix_biclass_wrapper\ndef empty(shape, dtype=float, bohrium=True):\n    """"""\n    Return a new matrix of given shape and type, without initializing entries.\n\n    Parameters\n    ----------\n    shape : int or tuple of int\n        Shape of the empty matrix.\n    dtype : data-type, optional\n        Desired output data-type.\n\n    See Also\n    --------\n    empty_like, zeros\n\n    Notes\n    -----\n    The order of the data in memory is always row-major (C-style).\n\n    `empty`, unlike `zeros`, does not set the matrix values to zero,\n    and may therefore be marginally faster.  On the other hand, it requires\n    the user to manually set all the values in the array, and should be\n    used with caution.\n\n    Examples\n    --------\n    >>> import numpy.matlib\n    >>> np.matlib.empty((2, 2))    # filled with random data\n    matrix([[  6.76425276e-320,   9.79033856e-307],\n            [  7.39337286e-309,   3.22135945e-309]])        #random\n    >>> np.matlib.empty((2, 2), dtype=int)\n    matrix([[ 6600475,        0],\n            [ 6586976, 22740995]])                          #random\n\n    """"""\n\n    if bohrium and not dtype_support(dtype):\n        _warn_dtype(dtype, 3)\n        bohrium = False\n\n    if not bohrium:\n        return numpy.ndarray(shape, dtype=dtype)\n\n    from . import _bh\n    return _bh.ndarray(shape, dtype=dtype)\n\n\n@fix_biclass_wrapper\ndef ones(shape, dtype=float, bohrium=True):\n    """"""\n    Matrix of ones.\n\n    Return a matrix of given shape and type, filled with ones.\n\n    Parameters\n    ----------\n    shape : {sequence of ints, int}\n        Shape of the matrix\n    dtype : data-type, optional\n        The desired data-type for the matrix, default is np.float64.\n    bohrium : boolean, optional\n        Determines whether it is a Bohrium-enabled array or a regular NumPy array\n\n    Returns\n    -------\n    out : matrix\n        Matrix of ones of given shape, dtype, and order.\n\n    See Also\n    --------\n    ones : Array of ones.\n    matlib.zeros : Zero matrix.\n\n    Notes\n    -----\n    The order of the data in memory is always row-major (C-style).\n\n    If `shape` has length one i.e. ``(N,)``, or is a scalar ``N``,\n    `out` becomes a single row matrix of shape ``(1,N)``.\n\n    Examples\n    --------\n    >>> np.matlib.ones((2,3))\n    matrix([[ 1.,  1.,  1.],\n            [ 1.,  1.,  1.]])\n\n    >>> np.matlib.ones(2)\n    matrix([[ 1.,  1.]])\n\n    """"""\n\n    if bohrium and not dtype_support(dtype):\n        _warn_dtype(dtype, 3)\n        return numpy.ones(shape, dtype=dtype)\n\n    A = empty(shape, dtype=dtype, bohrium=bohrium)\n    A[...] = A.dtype.type(1)\n    return A\n\n\n@fix_biclass_wrapper\ndef zeros(shape, dtype=float, bohrium=True):\n    """"""\n    Return a matrix of given shape and type, filled with zeros.\n\n    Parameters\n    ----------\n    shape : int or sequence of ints\n        Shape of the matrix\n    dtype : data-type, optional\n        The desired data-type for the matrix, default is float.\n    bohrium : boolean, optional\n        Determines whether it is a Bohrium-enabled array or a regular NumPy array\n\n    Returns\n    -------\n    out : matrix\n        Zero matrix of given shape, dtype, and order.\n\n    See Also\n    --------\n    numpy.zeros : Equivalent array function.\n    matlib.ones : Return a matrix of ones.\n\n    Notes\n    -----\n    The order of the data in memory is always row-major (C-style).\n\n    If `shape` has length one i.e. ``(N,)``, or is a scalar ``N``,\n    `out` becomes a single row matrix of shape ``(1,N)``.\n\n    Examples\n    --------\n    >>> import numpy.matlib\n    >>> np.matlib.zeros((2, 3))\n    matrix([[ 0.,  0.,  0.],\n            [ 0.,  0.,  0.]])\n\n    >>> np.matlib.zeros(2)\n    matrix([[ 0.,  0.]])\n\n    """"""\n    if bohrium and not dtype_support(dtype):\n        _warn_dtype(dtype, 3)\n        return numpy.zeros(shape, dtype=dtype)\n\n    a = empty(shape, dtype=dtype, bohrium=bohrium)\n    a[...] = a.dtype.type(0)\n    return a\n\n\n@fix_biclass_wrapper\ndef empty_like(a, dtype=None, bohrium=None):\n    """"""\n    Return a new array with the same shape and type as a given array.\n\n    Parameters\n    ----------\n    a : array_like\n        The shape and data-type of `a` define these same attributes of the\n        returned array.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n    bohrium : boolean, optional\n        Determines whether it is a Bohrium-enabled array or a regular NumPy array\n\n    Returns\n    -------\n    out : ndarray\n        Array of uninitialized (arbitrary) data with the same\n        shape and type as `a`.\n\n    See Also\n    --------\n    ones_like : Return an array of ones with shape and type of input.\n    zeros_like : Return an array of zeros with shape and type of input.\n    empty : Return a new uninitialized array.\n    ones : Return a new array setting values to one.\n    zeros : Return a new array setting values to zero.\n\n    Notes\n    -----\n    The order of the data in memory is always row-major (C-style).\n\n    This function does *not* initialize the returned array; to do that use\n    `zeros_like` or `ones_like` instead.  It may be marginally faster than\n    the functions that do set the array values.\n\n    Examples\n    --------\n    >>> a = ([1,2,3], [4,5,6])                         # a is array-like\n    >>> np.empty_like(a)\n    array([[-1073741821, -1073741821,           3],    #random\n           [          0,           0, -1073741821]])\n    >>> a = np.array([[1., 2., 3.],[4.,5.,6.]])\n    >>> np.empty_like(a)\n    array([[ -2.00000715e+000,   1.48219694e-323,  -2.00000572e+000],#random\n           [  4.38791518e-305,  -2.00000715e+000,   4.17269252e-309]])\n    """"""\n    if dtype is None:\n        dtype = a.dtype\n\n    if bohrium is None:\n        bohrium = bhary.check(a)\n\n    if bohrium and not dtype_support(dtype):\n        _warn_dtype(dtype, 3)\n        return numpy.empty_like(a, dtype=dtype, subok=False)\n\n    return empty(a.shape, dtype, bohrium)\n\n\n@fix_biclass_wrapper\ndef zeros_like(a, dtype=None, bohrium=None):\n    """"""\n    Return an array of zeros with the same shape and type as a given array.\n\n    With default parameters, is equivalent to ``a.copy().fill(0)``.\n\n    Parameters\n    ----------\n    a : array_like\n        The shape and data-type of `a` define these same attributes of\n        the returned array.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n    bohrium : boolean, optional\n        Determines whether it is a Bohrium-enabled array or a regular NumPy array\n\n    Returns\n    -------\n    out : ndarray\n        Array of zeros with the same shape and type as `a`.\n\n    See Also\n    --------\n    ones_like : Return an array of ones with shape and type of input.\n    empty_like : Return an empty array with shape and type of input.\n    zeros : Return a new array setting values to zero.\n    ones : Return a new array setting values to one.\n    empty : Return a new uninitialized array.\n\n    Notes\n    -----\n    The order of the data in memory is always row-major (C-style).\n\n    Examples\n    --------\n    >>> x = np.arange(6)\n    >>> x = x.reshape((2, 3))\n    >>> x\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> np.zeros_like(x)\n    array([[0, 0, 0],\n           [0, 0, 0]])\n\n    >>> y = np.arange(3, dtype=np.float)\n    >>> y\n    array([ 0.,  1.,  2.])\n    >>> np.zeros_like(y)\n    array([ 0.,  0.,  0.])\n\n    """"""\n    if dtype is None:\n        dtype = a.dtype\n\n    if bohrium is None:\n        bohrium = bhary.check(a)\n\n    if bohrium and not dtype_support(dtype):\n        _warn_dtype(dtype, 3)\n        return numpy.zeros_like(a, dtype=dtype)\n\n    b = empty_like(a, dtype=dtype, bohrium=bohrium)\n    b[...] = b.dtype.type(0)\n\n    return b\n\n\n@fix_biclass_wrapper\ndef ones_like(a, dtype=None, bohrium=None):\n    """"""\n    Return an array of ones with the same shape and type as a given array.\n\n    With default parameters, is equivalent to ``a.copy().fill(1)``.\n\n    Parameters\n    ----------\n    a : array_like\n        The shape and data-type of `a` define these same attributes of\n        the returned array.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n    bohrium : boolean, optional\n        Determines whether it is a Bohrium-enabled array or a regular NumPy array\n\n    Returns\n    -------\n    out : ndarray\n        Array of zeros with the same shape and type as `a`.\n\n    See Also\n    --------\n    zeros_like : Return an array of zeros with shape and type of input.\n    empty_like : Return an empty array with shape and type of input.\n    zeros : Return a new array setting values to zero.\n    ones : Return a new array setting values to one.\n    empty : Return a new uninitialized array.\n\n    Notes\n    -----\n    The order of the data in memory is always row-major (C-style).\n\n    Examples\n    --------\n    >>> x = np.arange(6)\n    >>> x = x.reshape((2, 3))\n    >>> x\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> np.ones_like(x)\n    array([[1, 1, 1],\n           [1, 1, 1]])\n\n    >>> y = np.arange(3, dtype=np.float)\n    >>> y\n    array([ 0.,  1.,  2.])\n    >>> np.ones_like(y)\n    array([ 1.,  1.,  1.])\n\n    """"""\n    if dtype is None:\n        dtype = a.dtype\n\n    if bohrium is None:\n        bohrium = bhary.check(a)\n\n    if bohrium and not dtype_support(dtype):\n        _warn_dtype(dtype, 3)\n        return numpy.ones_like(a, dtype=dtype)\n\n    b = empty_like(a, dtype=dtype, bohrium=bohrium)\n    b[...] = b.dtype.type(1)\n\n    return b\n\n\n@fix_biclass_wrapper\ndef arange(start, stop=None, step=1, dtype=None, bohrium=True):\n    """"""\n    arange([start,] stop[, step,], dtype=None)\n\n    Return evenly spaced values within a given interval.\n\n    Values are generated within the half-open interval ``[start, stop)``\n    (in other words, the interval including `start` but excluding `stop`).\n    For integer arguments the function is equivalent to the Python built-in\n    `range <http://docs.python.org/lib/built-in-funcs.html>`_ function,\n    but returns a ndarray rather than a list.\n\n    When using a non-integer step, such as 0.1, the results will often not\n    be consistent.  It is better to use ``linspace`` for these cases.\n\n    Parameters\n    ----------\n    start : number, optional\n        Start of interval.  The interval includes this value.  The default\n        start value is 0.\n    stop : number\n        End of interval.  The interval does not include this value, except\n        in some cases where `step` is not an integer and floating point\n        round-off affects the length of `out`.\n    step : number, optional\n        Spacing between values.  For any output `out`, this is the distance\n        between two adjacent values, ``out[i+1] - out[i]``.  The default\n        step size is 1.  If `step` is specified, `start` must also be given.\n    dtype : dtype\n        The type of the output array.  If `dtype` is not given, infer the data\n        type from the other input arguments.\n\n    Returns\n    -------\n    out : ndarray\n        Array of evenly spaced values.\n\n        For floating point arguments, the length of the result is\n        ``ceil((stop - start)/step)``.  Because of floating point overflow,\n        this rule may result in the last element of `out` being greater\n        than `stop`.\n\n    See Also\n    --------\n    linspace : Evenly spaced numbers with careful handling of endpoints.\n    ogrid: Arrays of evenly spaced numbers in N-dimensions\n    mgrid: Grid-shaped arrays of evenly spaced numbers in N-dimensions\n\n    Examples\n    --------\n    >>> np.arange(3)\n    array([0, 1, 2])\n    >>> np.arange(3.0)\n    array([ 0.,  1.,  2.])\n    >>> np.arange(3,7)\n    array([3, 4, 5, 6])\n    >>> np.arange(3,7,2)\n    array([3, 5])\n\n    """"""\n    if not bohrium:\n        return numpy.arange(start, stop, step, dtype)\n\n    if stop is None:\n        stop = start\n        start = type(stop)(0)\n\n    try:\n        integers = (int, long)\n    except:\n        integers = (int,)\n    if not (isinstance(stop, integers) and isinstance(start, integers)):\n        raise ValueError(""arange(): start and stop must be integers"")\n\n    if step == 0:\n        raise ValueError(""arange(): step cannot be zero"")\n\n    # Let\'s make sure that \'step\' is always positive\n    swap_back = False\n    if step < 0:\n        step *= -1\n        (start, stop) = (stop, start)\n        swap_back = True\n\n    if start >= stop:\n        return array([], dtype=dtype, bohrium=bohrium)\n\n    size = int(math.ceil((float(stop) - float(start)) / float(step)))\n    if dtype is None:\n        dtype = numpy.int64\n    else:\n        start = numpy.dtype(dtype).type(start)\n        stop = numpy.dtype(dtype).type(stop)\n        step = numpy.dtype(dtype).type(step)\n\n    result = simply_range(size, dtype=dtype)\n    if swap_back:\n        step *= -1\n        (start, stop) = (stop, start)\n\n    if step != 1:\n        result *= step\n\n    if start != 0:\n        result += start\n\n    return result\n\n\n@fix_biclass_wrapper\ndef simply_range(size, dtype=numpy.uint64):\n    from . import _bh\n    try:\n        integers = (int, long)\n    except:\n        integers = (int,)\n\n    if not isinstance(size, integers):\n        raise ValueError(""size must be an integer"")\n\n    if size < 1:\n        raise ValueError(""size must be greater than 0"")\n\n    if dtype_in(dtype, [numpy.int8,\n                        numpy.int16,\n                        numpy.int32,\n                        numpy.uint8,\n                        numpy.uint16,\n                        numpy.uint32,\n                        numpy.float16,\n                        numpy.float32,\n                        numpy.complex64]):\n        A = empty((size,), dtype=numpy.uint32, bohrium=True)\n    else:\n        A = empty((size,), dtype=numpy.uint64, bohrium=True)\n\n    _bh.ufunc(_info.op[""range""][\'id\'], (A,))\n\n    if not dtype_equal(dtype, A.dtype):\n        B = empty_like(A, dtype=dtype)\n        B[...] = A[...]\n        return B\n    else:\n        return A\n\n\n@fix_biclass_wrapper\ndef linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=float, bohrium=True):\n    """"""\n    Return evenly spaced numbers over a specified interval.\n\n    Returns `num` evenly spaced samples, calculated over the\n    interval [`start`, `stop` ].\n\n    The endpoint of the interval can optionally be excluded.\n\n    Parameters\n    ----------\n    start : scalar\n        The starting value of the sequence.\n    stop : scalar\n        The end value of the sequence, unless `endpoint` is set to False.\n        In that case, the sequence consists of all but the last of ``num + 1``\n        evenly spaced samples, so that `stop` is excluded.  Note that the step\n        size changes when `endpoint` is False.\n    num : int, optional\n        Number of samples to generate. Default is 50.\n    endpoint : bool, optional\n        If True, `stop` is the last sample. Otherwise, it is not included.\n        Default is True.\n    retstep : bool, optional\n        If True, return (`samples`, `step`), where `step` is the spacing\n        between samples.\n\n    Returns\n    -------\n    samples : ndarray\n        There are `num` equally spaced samples in the closed interval\n        ``[start, stop]`` or the half-open interval ``[start, stop)``\n        (depending on whether `endpoint` is True or False).\n    step : float (only if `retstep` is True)\n        Size of spacing between samples.\n\n\n    See Also\n    --------\n    arange : Similiar to `linspace`, but uses a step size (instead of the\n             number of samples).\n    logspace : Samples uniformly distributed in log space.\n\n    Examples\n    --------\n    >>> np.linspace(2.0, 3.0, num=5)\n        array([ 2.  ,  2.25,  2.5 ,  2.75,  3.  ])\n    >>> np.linspace(2.0, 3.0, num=5, endpoint=False)\n        array([ 2. ,  2.2,  2.4,  2.6,  2.8])\n    >>> np.linspace(2.0, 3.0, num=5, retstep=True)\n        (array([ 2.  ,  2.25,  2.5 ,  2.75,  3.  ]), 0.25)\n\n    Graphical illustration:\n\n    >>> import matplotlib.pyplot as plt\n    >>> N = 8\n    >>> y = np.zeros(N)\n    >>> x1 = np.linspace(0, 10, N, endpoint=True)\n    >>> x2 = np.linspace(0, 10, N, endpoint=False)\n    >>> plt.plot(x1, y, \'o\')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.plot(x2, y + 0.5, \'o\')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.ylim([-0.5, 1])\n    (-0.5, 1)\n    >>> plt.show()\n\n    """"""\n    if not bohrium:\n        # TODO: add copy=False to .astype()\n        return numpy.linspace(start, stop, num=num, endpoint=endpoint, retstep=retstep).astype(dtype)\n\n    num = int(num)\n    if num <= 0:\n        return array([], dtype=dtype)\n\n    if endpoint:\n        if num == 1:\n            return array([numpy.dtype(dtype).type(start)])\n        step = (stop - start) / float((num - 1))\n    else:\n        step = (stop - start) / float(num)\n\n    y = arange(num, dtype=dtype)\n    if step != 1: y *= step\n    if start != 0: y += start\n\n    if retstep:\n        return y, step\n    else:\n        return y\n\n\n@bhary.fix_biclass_wrapper\ndef copy(a, order=\'K\'):\n    """"""\n    Return an array copy of the given object.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    order : {\'C\', \'F\', \'A\', \'K\'}, optional\n        Controls the memory layout of the copy. \'C\' means C-order,\n        \'F\' means F-order, \'A\' means \'F\' if `a` is Fortran contiguous,\n        \'C\' otherwise. \'K\' means match the layout of `a` as closely\n        as possible. (Note that this function and :meth:ndarray.copy are very\n        similar, but have different default values for their order=\n        arguments.)\n\n    Returns\n    -------\n    arr : ndarray\n        Array interpretation of `a`.\n\n    Notes\n    -----\n    This is equivalent to\n\n    >>> np.array(a, copy=True)                              #doctest: +SKIP\n\n    Examples\n    --------\n    Create an array x, with a reference y and a copy z:\n\n    >>> x = np.array([1, 2, 3])\n    >>> y = x\n    >>> z = np.copy(x)\n\n    Note that, when we modify x, y changes, but not z:\n\n    >>> x[0] = 10\n    >>> x[0] == y[0]\n    True\n    >>> x[0] == z[0]\n    False\n\n    """"""\n    return array(a, order=order, copy=True)\n\n\ndef identity(n, dtype=float, bohrium=True):\n    """"""\n    Return the identity array.\n    The identity array is a square array with ones on\n    the main diagonal.\n\n    Parameters\n    ----------\n    n : int\n        Number of rows (and columns) in `n` x `n` output.\n    dtype : data-type, optional\n        Data-type of the output.  Defaults to ``float``.\n    bohrium : boolean, optional\n        Determines whether it is a Bohrium-enabled array or a regular NumPy array\n\n    Returns\n    -------\n    out : ndarray\n        `n` x `n` array with its main diagonal set to one,\n        and all other elements 0.\n    Examples\n    --------\n    >>> np.identity(3)\n    array([[ 1.,  0.,  0.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0.,  1.]])\n    """"""\n    from .array_manipulation import diagonal\n\n    ret = zeros((n, n), dtype=dtype, bohrium=bohrium)\n    diagonal(ret)[:] = 1\n    return ret\n'"
bridge/npbackend/bohrium/array_manipulation.py,28,"b'""""""\nArray manipulation routines\n===========================\n""""""\nfrom copy import deepcopy\nfrom . import array_create\nimport numpy_force as numpy\nfrom . import bhary\nfrom . import _util\nfrom .bhary import fix_biclass_wrapper\nfrom . import numpy_backport\nfrom . import loop\n\n\n@fix_biclass_wrapper\ndef flatten(ary, order=\'C\', always_copy=True):\n    """"""\n    Return a copy of the array collapsed into one dimension.\n\n    Parameters\n    ----------\n    ary : array_like\n        Array from which to retrieve the flattened data from.\n    order : {\'C\', \'F\', \'A\', \'K\'}, optional\n        \'C\' means to flatten in row-major (C-style) order.\n        \'F\' means to flatten in column-major (Fortran-\n        style) order. \'A\' means to flatten in column-major\n        order if `a` is Fortran *contiguous* in memory,\n        row-major order otherwise. \'K\' means to flatten\n        `a` in the order the elements occur in memory.\n        The default is \'C\'.\n    always_copy : boolean\n        When False, a copy is only made when necessary\n\n    Returns\n    -------\n    y : ndarray\n        A copy of the input array, flattened to one dimension.\n\n    Notes\n    -----\n    The order of the data in memory is always row-major (C-style).\n\n    Examples\n    --------\n    >>> a = np.array([[1,2], [3,4]])\n    >>> np.flatten(a)\n    array([1, 2, 3, 4])\n    """"""\n\n    if order == \'F\' or (order == \'A\' and not ary.flags[\'F_CONTIGUOUS\']):\n        ary = numpy.transpose(ary)\n\n    ret = ary.reshape(_util.totalsize(ary))\n    if always_copy:\n        return ret.copy()\n    else:\n        return ret\n\n\n@fix_biclass_wrapper\ndef diagonal(ary, offset=0, axis1=0, axis2=1):\n    """"""\n    Return specified diagonals.\n\n    If `a` is 2-D, returns the diagonal of `a` with the given offset,\n    i.e., the collection of elements of the form ``a[i, i+offset]``.\n    If `a` has more than two dimensions, then the axes specified by\n    `axis1` and `axis2` are used to determine the 2-D sub-array whose\n    diagonal is returned. The shape of the resulting array can be\n    determined by removing `axis1` and `axis2` and appending an index\n    to the right equal to the size of the resulting diagonals.\n\n    Parameters\n    ----------\n    ary : array_like\n        Array from which the diagonals are taken.\n    offset : int, optional\n        Offset of the diagonal from the main diagonal.  Can be positive or\n        negative.  Defaults to main diagonal (0).\n    axis1 : int, optional\n        Axis to be used as the first axis of the 2-D sub-arrays from which\n        the diagonals should be taken. Defaults to first axis (0).\n    axis2 : int, optional\n        Axis to be used as the second axis of the 2-D sub-arrays from which\n        the diagonals should be taken. Defaults to second axis (1).\n\n    Returns\n    -------\n    array_of_diagonals : ndarray\n        If `a` is 2-D, a 1-D array containing the diagonal is returned.\n        If the dimension of `a` is larger, then an array of diagonals is\n        returned, ""packed"" from left-most dimension to right-most (e.g.,\n        if `a` is 3-D, then the diagonals are ""packed"" along rows).\n\n    Raises\n    ------\n    ValueError\n        If the dimension of `a` is less than 2.\n\n    See Also\n    --------\n    diag : MATLAB work-a-like for 1-D and 2-D arrays.\n    diagflat : Create diagonal arrays.\n    trace : Sum along diagonals.\n\n    Examples\n    --------\n    >>> a = np.arange(4).reshape(2,2); a\n    array([[0, 1],\n           [2, 3]])\n    >>> a.diagonal()\n    array([0, 3])\n    >>> a.diagonal(1)\n    array([1])\n\n    A 3-D example:\n\n    >>> a = np.arange(8).reshape(2,2,2); a\n    array([[[0, 1],\n            [2, 3]],\n\n           [[4, 5],\n            [6, 7]]])\n    >>> a.diagonal()\n    array([[0, 6],\n           [1, 7]])\n    """"""\n    if axis1 == axis2:\n        raise Exception(""axis1 and axis2 cannot be the same\\n"")\n    if ary.ndim < 2:\n        raise Exception(""diagonal requires an array of at least two dimensions\\n"")\n\n    # Get all axes except the two which has the diagonal we seek;\n    # these are added later\n    min_axis, max_axis = sorted([axis1, axis2])\n    tr = list(range(ary.ndim))\n    del tr[max_axis]\n    del tr[min_axis]\n\n    # Positive offset means upper diagonals, negative is lower, so we switch\n    # the axes around if negative\n    if offset >= 0:\n        ary = ary.transpose(tr + [axis1, axis2])\n    else:\n        ary = ary.transpose(tr + [axis2, axis1])\n        offset = -offset\n\n    # Calculate how many elements will be in the diagonal\n    diag_size = max(0, min(ary.shape[-2], ary.shape[-1] - offset))\n    ret_shape = ary.shape[:-2] + (diag_size,)\n\n    # Return empty array if the diagonal has zero elements\n    if diag_size == 0:\n        return array_create.empty(ret_shape, dtype=ary.dtype, bohrium=bhary.check(ary))\n\n    ary = ary[..., :diag_size, offset:(offset + diag_size)]\n\n    ret_strides = ary.strides[:-2] + (ary.strides[-1] + ary.strides[-2],)\n    return numpy_backport.as_strided(ary, shape=ret_shape, strides=ret_strides)\n\n\n@fix_biclass_wrapper\ndef diagflat(d, k=0):\n    """"""\n    Create a two-dimensional array with the flattened input as a diagonal.\n\n    Parameters\n    ----------\n    d : array_like\n        Input data, which is flattened and set as the `k`-th\n        diagonal of the output.\n    k : int, optional\n        Diagonal to set; 0, the default, corresponds to the ""main"" diagonal,\n        a positive (negative) `k` giving the number of the diagonal above\n        (below) the main.\n\n    Returns\n    -------\n    out : ndarray\n        The 2-D output array.\n\n    See Also\n    --------\n    diag : MATLAB work-alike for 1-D and 2-D arrays.\n    diagonal : Return specified diagonals.\n    trace : Sum along diagonals.\n\n    Examples\n    --------\n    >>> np.diagflat([[1,2], [3,4]])\n    array([[1, 0, 0, 0],\n           [0, 2, 0, 0],\n           [0, 0, 3, 0],\n           [0, 0, 0, 4]])\n\n    >>> np.diagflat([1,2], 1)\n    array([[0, 1, 0],\n           [0, 0, 2],\n           [0, 0, 0]])\n\n    """"""\n    d = flatten(d)\n    size = d.size + abs(k)\n    A = array_create.zeros((size, size), dtype=d.dtype, bohrium=bhary.check(d))\n    Ad = diagonal(A, offset=k)\n    Ad[...] = d\n    return A\n\n\n@fix_biclass_wrapper\ndef diag(v, k=0):\n    """"""\n    Extract a diagonal or construct a diagonal array.\n\n    Parameters\n    ----------\n    v : array_like\n        If `v` is a 2-D array, return a copy of its `k`-th diagonal.\n        If `v` is a 1-D array, return a 2-D array with `v` on the `k`-th\n        diagonal.\n    k : int, optional\n        Diagonal in question. The default is 0. Use `k>0` for diagonals\n        above the main diagonal, and `k<0` for diagonals below the main\n        diagonal.\n\n    Returns\n    -------\n    out : ndarray\n        The extracted diagonal or constructed diagonal array.\n\n    See Also\n    --------\n    diagonal : Return specified diagonals.\n    diagflat : Create a 2-D array with the flattened input as a diagonal.\n    trace : Sum along diagonals.\n    triu : Upper triangle of an array.\n    tril : Lower triange of an array.\n\n    Examples\n    --------\n    >>> x = np.arange(9).reshape((3,3))\n    >>> x\n    array([[0, 1, 2],\n           [3, 4, 5],\n           [6, 7, 8]])\n\n    >>> np.diag(x)\n    array([0, 4, 8])\n    >>> np.diag(x, k=1)\n    array([1, 5])\n    >>> np.diag(x, k=-1)\n    array([3, 7])\n\n    >>> np.diag(np.diag(x))\n    array([[0, 0, 0],\n           [0, 4, 0],\n           [0, 0, 8]])\n    """"""\n\n    if v.ndim == 1:\n        return diagflat(v, k)\n    elif v.ndim == 2:\n        return diagonal(v, k)\n    else:\n        raise ValueError(""Input must be 1- or 2-d."")\n\n\n@fix_biclass_wrapper\ndef reshape(a, *newshape, **kwargs):\n    """"""\n    Gives a new shape to an array without changing its data.\n\n    Parameters\n    ----------\n    a : array_like\n        Array to be reshaped.\n    newshape : int or tuple of ints\n        The new shape should be compatible with the original shape. If\n        an integer, then the result will be a 1-D array of that length.\n        One shape dimension can be -1. In this case, the value is inferred\n        from the length of the array and remaining dimensions.\n    order : {`C`, `F`, `A`}, optional\n        Read the elements of a using this index order, and place the elements\n        into the reshaped array using this index order.\n        `C` means to read / write the elements using C-like index order,\n        with the last axis index changing fastest, back to the first axis\n        index changing slowest. `F` means to read / write the elements using\n        Fortran-like index order, with the first index changing fastest,\n        and the last index changing slowest. Note that the `C` and `F` options\n        take no account of the memory layout of the underlying array,\n        and only refer to the order of indexing. `A` means to read / write\n        the elements in Fortran-like index order if a is Fortran contiguous\n        in memory, C-like order otherwise.\n\n    Returns\n    -------\n    reshaped_array : ndarray\n        This will be a new view object if possible; otherwise, it will\n        be a copy.  Note there is no guarantee of the *memory layout* (C- or\n        Fortran- contiguous) of the returned array.\n\n    See Also\n    --------\n    ndarray.reshape : Equivalent method.\n\n    Notes\n    -----\n    It is not always possible to change the shape of an array without\n    copying the data. If you want an error to be raise if the data is copied,\n    you should assign the new shape to the shape attribute of the array::\n\n     >>> a = np.zeros((10, 2))\n     # A transpose make the array non-contiguous\n     >>> b = a.T\n     # Taking a view makes it possible to modify the shape without modifying the\n     # initial object.\n     >>> c = b.view()\n     >>> c.shape = (20)\n     AttributeError: incompatible shape for a non-contiguous array\n\n    The `order` keyword gives the index ordering both for *fetching* the values\n    from `a`, and then *placing* the values into the output array.  For example,\n    let\'s say you have an array:\n\n    >>> a = np.arange(6).reshape((3, 2))\n    >>> a\n    array([[0, 1],\n           [2, 3],\n           [4, 5]])\n\n    You can think of reshaping as first raveling the array (using the given\n    index order), then inserting the elements from the raveled array into the\n    new array using the same kind of index ordering as was used for the\n    raveling.\n\n    >>> np.reshape(a, (2, 3)) # C-like index ordering\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> np.reshape(np.ravel(a), (2, 3)) # equivalent to C ravel then C reshape\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> np.reshape(a, (2, 3), order=\'F\') # Fortran-like index ordering\n    array([[0, 4, 3],\n           [2, 1, 5]])\n    >>> np.reshape(np.ravel(a, order=\'F\'), (2, 3), order=\'F\')\n    array([[0, 4, 3],\n           [2, 1, 5]])\n\n    Examples\n    --------\n    >>> a = np.array([[1,2,3], [4,5,6]])\n    >>> np.reshape(a, 6)\n    array([1, 2, 3, 4, 5, 6])\n    >>> np.reshape(a, 6, order=\'F\')\n    array([1, 4, 2, 5, 3, 6])\n\n    >>> np.reshape(a, (3,-1))       # the unspecified value is inferred to be 2\n    array([[1, 2],\n           [3, 4],\n           [5, 6]])\n    """"""\n    # Let\'s make sure that newshape is a flat sequence\n    if len(newshape) == 1:\n        # The item is a sequence\n        if hasattr(newshape[0], ""__getitem__""):\n            newshape = newshape[0]\n\n    if not a.flags[\'C_CONTIGUOUS\']:\n        t = array_create.empty_like(a)\n        t[...] = a\n        a = t\n\n    return numpy.ndarray.reshape(a, newshape, **kwargs)\n\n\n@fix_biclass_wrapper\ndef trace(ary, offset=0, axis1=0, axis2=1, dtype=None):\n    """"""\n    Return the sum along diagonals of the array.\n\n    If `a` is 2-D, the sum along its diagonal with the given offset\n    is returned, i.e., the sum of elements ``a[i,i+offset]`` for all i.\n\n    If `a` has more than two dimensions, then the axes specified by axis1 and\n    axis2 are used to determine the 2-D sub-arrays whose traces are returned.\n    The shape of the resulting array is the same as that of `a` with `axis1`\n    and `axis2` removed.\n\n    Parameters\n    ----------\n    ary : array_like\n        Input array, from which the diagonals are taken.\n    offset : int, optional\n        Offset of the diagonal from the main diagonal. Can be both positive\n        and negative. Defaults to 0.\n    axis1, axis2 : int, optional\n        Axes to be used as the first and second axis of the 2-D sub-arrays\n        from which the diagonals should be taken. Defaults are the first two\n        axes of `a`.\n    dtype : dtype, optional\n        Determines the data-type of the returned array and of the accumulator\n        where the elements are summed. If dtype has the value None and `a` is\n        of integer type of precision less than the default integer\n        precision, then the default integer precision is used. Otherwise,\n        the precision is the same as that of `a`.\n    out : ndarray, optional\n        Array into which the output is placed. Its type is preserved and\n        it must be of the right shape to hold the output.\n\n    Returns\n    -------\n    sum_along_diagonals : ndarray\n        If `a` is 2-D, the sum along the diagonal is returned.  If `a` has\n        larger dimensions, then an array of sums along diagonals is returned.\n\n    See Also\n    --------\n    diag, diagonal, diagflat\n\n    Examples\n    --------\n    >>> np.trace(np.eye(3))\n    3.0\n    >>> a = np.arange(8).reshape((2,2,2))\n    >>> np.trace(a)\n    array([6, 8])\n\n    >>> a = np.arange(24).reshape((2,2,2,3))\n    >>> np.trace(a).shape\n    (2, 3)\n\n    """"""\n    D = diagonal(ary, offset=offset, axis1=axis1, axis2=axis2)\n\n    if dtype:\n        D = D.astype(dtype)\n\n    return D.sum(axis=-1)\n\n\n@fix_biclass_wrapper\ndef broadcast_arrays(*args):\n    """"""\n    Broadcast any number of arrays against each other.\n\n    .. note:: This function is very similar to NumPy\'s  `broadcast_arrays()`\n\n    Parameters\n    ----------\n    `array_list` : array_likes\n        The arrays to broadcast.\n\n    Returns\n    -------\n    broadcasted : list of arrays\n        These arrays are views on the original arrays or the untouched originals.\n        They are typically not contiguous.  Furthermore, more than one element of a\n        broadcasted array may refer to a single memory location.  If you\n        need to write to the arrays, make copies first.\n    shape : tuple\n        The shape the arrays are broadcasted to\n    """"""\n    try:\n        if len(args) == 0:\n            return ([], [])\n\n        if len(args) == 1:\n            if numpy.isscalar(args[0]):  # It is possible that `args[0]` is a scalar\n                shape = (1,)\n            else:\n                shape = args[0].shape\n            return (args, shape)\n\n        # Common case where nothing needs to be broadcasted.\n        bcast = numpy.broadcast(*args)\n        if all(array.shape == bcast.shape for array in args if not numpy.isscalar(array)):\n            return (args, bcast.shape)\n\n        ret = []\n        # We use NumPy\'s broadcast_arrays() to broadcast the views.\n        # Notice that the \'subok\' argument is first introduced in version 10 of NumPy\n        try:\n            bargs = numpy.broadcast_arrays(*args, subok=True)\n        except TypeError as err:\n            if ""subok"" in err.message:\n                bargs = numpy.broadcast_arrays(*args)\n            else:\n                raise\n\n        # The broadcasted view inherits dynamic changes if there are any.\n        # Used for broadcasting dynamic views within a do_while loop\n        bcast_array = args[0]\n        bcast_dvi = bcast_array.bhc_dynamic_view_info\n        for a, b in zip(args, bargs):\n            # If the broadcast view changes shape between iterations,\n            # force the same change to the views being broadcasted.\n            # Used in regard to iterators within do_while loops.\n            a_dvi = a.bhc_dynamic_view_info\n\n            # If array that is broadcasted has dynamic changes, the\n            # broadcasted array must inherit these\n            if a_dvi:\n                b_dvi = deepcopy(a_dvi)\n            else:\n                b_dvi = loop.DynamicViewInfo({}, a.shape, a.strides)\n\n            # If the array that is broadcasted from has changes in shape\n            # must these changes also be inherited by the broadcasted array\n            if bcast_dvi:\n                # If the view contains a slide in a broadcasted dimension,\n                # the slide must be inherited\n                for dim in bcast_dvi.dims_with_changes():\n                    # If the array, which is broadcasted from, does not have\n                    # dynamic changes, there are no changes to add\n                    if bcast_dvi.dim_shape_change(dim) == 0:\n                        continue\n\n                    # The array, which is broadcasted from, has dynamic changes\n                    # while the broadcasted array does not. Add the changes to the\n                    # broadcasted array\n                    elif b_dvi.dim_shape_change(dim) == 0:\n                        for (_, shape_change, step_delay, shape, stride) in bcast_dvi.changes_in_dim(dim):\n                            # No reason to add a change of 0 in the dimension\n                            if shape_change == 0:\n                                continue\n                            b_dvi.add_dynamic_change(dim, 0, shape_change, step_delay, shape, stride)\n\n                    # Both array, which is broadcasted from, and the broadcasted array has\n                    # dynamic changes. Make sure they are the same. If not the change cannot\n                    # be guessed, which results in an error.\n                    elif b_dvi.dim_shape_change(dim) != 0 and \\\n                            b_dvi.dim_shape_change(dim) != bcast_dvi.dim_shape_change(dim):\n                        raise loop.IteratorIllegalBroadcast(\n                            dim, a.shape, a_dvi.dim_shape_change(dim),\n                            bcast_array.shape, bcast_dvi.dim_shape_change(dim))\n\n            # Add the dynamic changes, if any\n            if b_dvi.has_changes():\n                b.bhc_dynamic_view_info = b_dvi\n\n            # Append the broadcasted array\n            ret.append(b)\n\n    except ValueError as msg:\n        if str(msg).find(""shape mismatch: objects cannot be broadcast to a single shape"") != -1:\n            shapes = [arg.shape for arg in args]\n            raise ValueError(""shape mismatch: objects cannot be broadcasted to a single shape: %s"" % shapes)\n        raise\n    return (ret, bcast.shape)\n\n\n@fix_biclass_wrapper\ndef fill(a, value):\n    """"""\n    a.fill(value)\n\n    Fill the array with a scalar value.\n\n    Parameters\n    ----------\n        a : array_like\n        Array to fill\n    value : scalar\n        All elements of `a` will be assigned this value.\n\n    Examples\n    --------\n    >>> a = np.array([1, 2])\n    >>> a.fill(0)\n    >>> a\n    array([0, 0])\n    >>> a = np.empty(2)\n    >>> a.fill(1)\n    >>> a\n    array([ 1.,  1.])\n\n    """"""\n    a[...] = value\n'"
bridge/npbackend/bohrium/disk_io.py,26,"b'""""""\nDisk IO\n=======================\n""""""\n\nimport warnings\nimport numpy_force as numpy\nfrom . import array_create\nfrom .bhary import fix_biclass_wrapper\n\n\n@fix_biclass_wrapper\ndef load(file, mmap_mode=None, allow_pickle=True, fix_imports=True, encoding=\'ASCII\', bohrium=True):\n    """"""\n    Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n\n    Parameters\n    ----------\n    file : file-like object or string\n        The file to read. File-like objects must support the\n        ``seek()`` and ``read()`` methods. Pickled files require that the\n        file-like object support the ``readline()`` method as well.\n    mmap_mode : {None, \'r+\', \'r\', \'w+\', \'c\'}, optional\n        If not None, then memory-map the file, using the given mode (see\n        `numpy.memmap` for a detailed description of the modes).  A\n        memory-mapped array is kept on disk. However, it can be accessed\n        and sliced like any ndarray.  Memory mapping is especially useful\n        for accessing small fragments of large files without reading the\n        entire file into memory.\n    allow_pickle : bool, optional\n        Allow loading pickled object arrays stored in npy files. Reasons for\n        disallowing pickles include security, as loading pickled data can\n        execute arbitrary code. If pickles are disallowed, loading object\n        arrays will fail.\n        Default: True\n    fix_imports : bool, optional\n        Only useful when loading Python 2 generated pickled files on Python 3,\n        which includes npy/npz files containing object arrays. If `fix_imports`\n        is True, pickle will try to map the old Python 2 names to the new names\n        used in Python 3.\n    encoding : str, optional\n        What encoding to use when reading Python 2 strings. Only useful when\n        loading Python 2 generated pickled files on Python 3, which includes\n        npy/npz files containing object arrays. Values other than \'latin1\',\n        \'ASCII\', and \'bytes\' are not allowed, as they can corrupt numerical\n        data. Default: \'ASCII\'\n\n    Returns\n    -------\n    result : array, tuple, dict, etc.\n        Data stored in the file. For ``.npz`` files, the returned instance\n        of NpzFile class must be closed to avoid leaking file descriptors.\n\n    Raises\n    ------\n    IOError\n        If the input file does not exist or cannot be read.\n    ValueError\n        The file contains an object array, but allow_pickle=False given.\n\n    See Also\n    --------\n    save, savez, savez_compressed, loadtxt\n    memmap : Create a memory-map to an array stored in a file on disk.\n\n    Notes\n    -----\n    - If the file contains pickle data, then whatever object is stored\n      in the pickle is returned.\n    - If the file is a ``.npy`` file, then a single array is returned.\n    - If the file is a ``.npz`` file, then a dictionary-like object is\n      returned, containing ``{filename: array}`` key-value pairs, one for\n      each file in the archive.\n    - If the file is a ``.npz`` file, the returned value supports the\n      context manager protocol in a similar fashion to the open function::\n\n        with load(\'foo.npz\') as data:\n            a = data[\'a\']\n\n      The underlying file descriptor is closed when exiting the \'with\'\n      block.\n\n    Examples\n    --------\n    Store data to disk, and load it again:\n\n    >>> np.save(\'/tmp/123\', np.array([[1, 2, 3], [4, 5, 6]]))\n    >>> np.load(\'/tmp/123.npy\')\n    array([[1, 2, 3],\n           [4, 5, 6]])\n\n    Store compressed data to disk, and load it again:\n\n    >>> a=np.array([[1, 2, 3], [4, 5, 6]])\n    >>> b=np.array([1, 2])\n    >>> np.savez(\'/tmp/123.npz\', a=a, b=b)\n    >>> data = np.load(\'/tmp/123.npz\')\n    >>> data[\'a\']\n    array([[1, 2, 3],\n           [4, 5, 6]])\n    >>> data[\'b\']\n    array([1, 2])\n    >>> data.close()\n\n    Mem-map the stored array, and then access the second row\n    directly from disk:\n\n    >>> X = np.load(\'/tmp/123.npy\', mmap_mode=\'r\')\n    >>> X[1, :]\n    memmap([4, 5, 6])\n\n    """"""\n\n    f = numpy.load(file, mmap_mode, allow_pickle, fix_imports, encoding)\n\n    if mmap_mode is not None:\n        warnings.warn(""Bohrium does not support the mmap_mode argument in load()"")\n        return f\n    else:\n        return array_create.array(f, bohrium=bohrium)\n\n\n@fix_biclass_wrapper\ndef save(file, arr, allow_pickle=True, fix_imports=True):\n    """"""\n    Save an array to a binary file in NumPy ``.npy`` format.\n\n    Parameters\n    ----------\n    file : file or str\n        File or filename to which the data is saved.  If file is a file-object,\n        then the filename is unchanged.  If file is a string, a ``.npy``\n        extension will be appended to the file name if it does not already\n        have one.\n    allow_pickle : bool, optional\n        Allow saving object arrays using Python pickles. Reasons for disallowing\n        pickles include security (loading pickled data can execute arbitrary\n        code) and portability (pickled objects may not be loadable on different\n        Python installations, for example if the stored objects require libraries\n        that are not available, and not all pickled data is compatible between\n        Python 2 and Python 3).\n        Default: True\n    fix_imports : bool, optional\n        Only useful in forcing objects in object arrays on Python 3 to be\n        pickled in a Python 2 compatible way. If `fix_imports` is True, pickle\n        will try to map the new Python 3 names to the old module names used in\n        Python 2, so that the pickle data stream is readable with Python 2.\n    arr : array_like\n        Array data to be saved.\n\n    See Also\n    --------\n    savez : Save several arrays into a ``.npz`` archive\n    savetxt, load\n\n    Notes\n    -----\n    For a description of the ``.npy`` format, see the module docstring\n    of `numpy.lib.format` or the Numpy Enhancement Proposal\n    http://docs.scipy.org/doc/numpy/neps/npy-format.html\n\n    Examples\n    --------\n    >>> from tempfile import TemporaryFile\n    >>> outfile = TemporaryFile()\n\n    >>> x = np.arange(10)\n    >>> np.save(outfile, x)\n\n    >>> outfile.seek(0) # Only needed here to simulate closing & reopening file\n    >>> np.load(outfile)\n    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    """"""\n\n    return numpy.save(file, array_create.array(arr, bohrium=False), allow_pickle, fix_imports)\n\n\n@fix_biclass_wrapper\ndef _savez(file, args, kwds, compress, allow_pickle=True, pickle_kwargs=None):\n    ary_list = []\n    for a in args:\n        ary_list.append(array_create.array(a, bohrium=False))\n\n    return numpy.save(file, array_create.array(arr, bohrium=False), allow_pickle, fix_imports)\n\n    # Import is postponed to here since zipfile depends on gzip, an optional\n    # component of the so-called standard library.\n    import zipfile\n    # Import deferred for startup time improvement\n    import tempfile\n\n    if isinstance(file, basestring):\n        if not file.endswith(\'.npz\'):\n            file = file + \'.npz\'\n\n    namedict = kwds\n    for i, val in enumerate(args):\n        key = \'arr_%d\' % i\n        if key in namedict.keys():\n            raise ValueError(\n                ""Cannot use un-named variables and keyword %s"" % key)\n        namedict[key] = val\n\n    if compress:\n        compression = zipfile.ZIP_DEFLATED\n    else:\n        compression = zipfile.ZIP_STORED\n\n    zipf = zipfile_factory(file, mode=""w"", compression=compression)\n\n    # Stage arrays in a temporary file on disk, before writing to zip.\n    fd, tmpfile = tempfile.mkstemp(suffix=\'-numpy.npy\')\n    os.close(fd)\n    try:\n        for key, val in namedict.items():\n            fname = key + \'.npy\'\n            fid = open(tmpfile, \'wb\')\n            try:\n                format.write_array(fid, np.asanyarray(val),\n                                   allow_pickle=allow_pickle,\n                                   pickle_kwargs=pickle_kwargs)\n                fid.close()\n                fid = None\n                zipf.write(tmpfile, arcname=fname)\n            finally:\n                if fid:\n                    fid.close()\n    finally:\n        os.remove(tmpfile)\n\n    zipf.close()\n\n\n@fix_biclass_wrapper\ndef savez(file, *args, **kwds):\n    """"""\n    Save several arrays into a single file in uncompressed ``.npz`` format.\n\n    If arguments are passed in with no keywords, the corresponding variable\n    names, in the ``.npz`` file, are \'arr_0\', \'arr_1\', etc. If keyword\n    arguments are given, the corresponding variable names, in the ``.npz``\n    file will match the keyword names.\n\n    Parameters\n    ----------\n    file : str or file\n        Either the file name (string) or an open file (file-like object)\n        where the data will be saved. If file is a string, the ``.npz``\n        extension will be appended to the file name if it is not already there.\n    args : Arguments, optional\n        Arrays to save to the file. Since it is not possible for Python to\n        know the names of the arrays outside `savez`, the arrays will be saved\n        with names ""arr_0"", ""arr_1"", and so on. These arguments can be any\n        expression.\n    kwds : Keyword arguments, optional\n        Arrays to save to the file. Arrays will be saved in the file with the\n        keyword names.\n\n    Returns\n    -------\n    None\n\n    See Also\n    --------\n    save : Save a single array to a binary file in NumPy format.\n    savetxt : Save an array to a file as plain text.\n    savez_compressed : Save several arrays into a compressed ``.npz`` archive\n\n    Notes\n    -----\n    The ``.npz`` file format is a zipped archive of files named after the\n    variables they contain.  The archive is not compressed and each file\n    in the archive contains one variable in ``.npy`` format. For a\n    description of the ``.npy`` format, see `numpy.lib.format` or the\n    Numpy Enhancement Proposal\n    http://docs.scipy.org/doc/numpy/neps/npy-format.html\n\n    When opening the saved ``.npz`` file with `load` a `NpzFile` object is\n    returned. This is a dictionary-like object which can be queried for\n    its list of arrays (with the ``.files`` attribute), and for the arrays\n    themselves.\n\n    Examples\n    --------\n    >>> from tempfile import TemporaryFile\n    >>> outfile = TemporaryFile()\n    >>> x = np.arange(10)\n    >>> y = np.sin(x)\n\n    Using `savez` with \\\\*args, the arrays are saved with default names.\n\n    >>> np.savez(outfile, x, y)\n    >>> outfile.seek(0) # Only needed here to simulate closing & reopening file\n    >>> npzfile = np.load(outfile)\n    >>> npzfile.files\n    [\'arr_1\', \'arr_0\']\n    >>> npzfile[\'arr_0\']\n    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    Using `savez` with \\\\**kwds, the arrays are saved with the keyword names.\n\n    >>> outfile = TemporaryFile()\n    >>> np.savez(outfile, x=x, y=y)\n    >>> outfile.seek(0)\n    >>> npzfile = np.load(outfile)\n    >>> npzfile.files\n    [\'y\', \'x\']\n    >>> npzfile[\'x\']\n    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    """"""\n\n    ary_list = []\n    for a in args:\n        ary_list.append(array_create.array(a, bohrium=False))\n    return numpy.savez(file, *ary_list, **kwds)\n\n\n@fix_biclass_wrapper\ndef savez_compressed(file, *args, **kwds):\n    """"""\n    Save several arrays into a single file in compressed ``.npz`` format.\n\n    If keyword arguments are given, then filenames are taken from the keywords.\n    If arguments are passed in with no keywords, then stored file names are\n    arr_0, arr_1, etc.\n\n    Parameters\n    ----------\n    file : str\n        File name of ``.npz`` file.\n    args : Arguments\n        Function arguments.\n    kwds : Keyword arguments\n        Keywords.\n\n    See Also\n    --------\n    numpy.savez : Save several arrays into an uncompressed ``.npz`` file format\n    numpy.load : Load the files created by savez_compressed.\n\n    """"""\n\n    ary_list = []\n    for a in args:\n        ary_list.append(array_create.array(a, bohrium=False))\n    return numpy.savez_compressed(file, *ary_list, **kwds)\n\n\n@fix_biclass_wrapper\ndef loadtxt(fname, dtype=float, comments=\'#\', delimiter=None,\n            converters=None, skiprows=0, usecols=None, unpack=False,\n            ndmin=0, bohrium=True):\n    """"""\n    Load data from a text file.\n\n    Each row in the text file must have the same number of values.\n\n    Parameters\n    ----------\n    fname : file or str\n        File, filename, or generator to read.  If the filename extension is\n        ``.gz`` or ``.bz2``, the file is first decompressed. Note that\n        generators should return byte strings for Python 3k.\n    dtype : data-type, optional\n        Data-type of the resulting array; default: float.  If this is a\n        structured data-type, the resulting array will be 1-dimensional, and\n        each row will be interpreted as an element of the array.  In this\n        case, the number of columns used must match the number of fields in\n        the data-type.\n    comments : str or sequence, optional\n        The characters or list of characters used to indicate the start of a\n        comment;\n        default: \'#\'.\n    delimiter : str, optional\n        The string used to separate values.  By default, this is any\n        whitespace.\n    converters : dict, optional\n        A dictionary mapping column number to a function that will convert\n        that column to a float.  E.g., if column 0 is a date string:\n        ``converters = {0: datestr2num}``.  Converters can also be used to\n        provide a default value for missing data (but see also `genfromtxt`):\n        ``converters = {3: lambda s: float(s.strip() or 0)}``.  Default: None.\n    skiprows : int, optional\n        Skip the first `skiprows` lines; default: 0.\n    usecols : sequence, optional\n        Which columns to read, with 0 being the first.  For example,\n        ``usecols = (1,4,5)`` will extract the 2nd, 5th and 6th columns.\n        The default, None, results in all columns being read.\n    unpack : bool, optional\n        If True, the returned array is transposed, so that arguments may be\n        unpacked using ``x, y, z = loadtxt(...)``.  When used with a structured\n        data-type, arrays are returned for each field.  Default is False.\n    ndmin : int, optional\n        The returned array will have at least `ndmin` dimensions.\n        Otherwise mono-dimensional axes will be squeezed.\n        Legal values: 0 (default), 1 or 2.\n\n        .. versionadded:: 1.6.0\n\n    Returns\n    -------\n    out : ndarray\n        Data read from the text file.\n\n    See Also\n    --------\n    load, fromstring, fromregex\n    genfromtxt : Load data with missing values handled as specified.\n    scipy.io.loadmat : reads MATLAB data files\n\n    Notes\n    -----\n    This function aims to be a fast reader for simply formatted files.  The\n    `genfromtxt` function provides more sophisticated handling of, e.g.,\n    lines with missing values.\n\n    .. versionadded:: 1.10.0\n\n    The strings produced by the Python float.hex method can be used as\n    input for floats.\n\n    Examples\n    --------\n    >>> from io import StringIO   # StringIO behaves like a file object\n    >>> c = StringIO(""0 1\\\\n2 3"")\n    >>> np.loadtxt(c)\n    array([[ 0.,  1.],\n           [ 2.,  3.]])\n\n    >>> d = StringIO(""M 21 72\\\\nF 35 58"")\n    >>> np.loadtxt(d, dtype={\'names\': (\'gender\', \'age\', \'weight\'),\n    ...                      \'formats\': (\'S1\', \'i4\', \'f4\')})\n    array([(\'M\', 21, 72.0), (\'F\', 35, 58.0)],\n          dtype=[(\'gender\', \'|S1\'), (\'age\', \'<i4\'), (\'weight\', \'<f4\')])\n\n    >>> c = StringIO(""1,0,2\\\\n3,0,4"")\n    >>> x, y = np.loadtxt(c, delimiter=\',\', usecols=(0, 2), unpack=True)\n    >>> x\n    array([ 1.,  3.])\n    >>> y\n    array([ 2.,  4.])\n\n    """"""\n\n    f = numpy.loadtxt(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\n    return array_create.array(f, bohrium=bohrium)\n\n\n@fix_biclass_wrapper\ndef savetxt(fname, X, fmt=\'%.18e\', delimiter=\' \', newline=\'\\n\', header=\'\',\n            footer=\'\', comments=\'# \'):\n    """"""\n    Save an array to a text file.\n\n    Parameters\n    ----------\n    fname : filename or file handle\n        If the filename ends in ``.gz``, the file is automatically saved in\n        compressed gzip format.  `loadtxt` understands gzipped files\n        transparently.\n    X : array_like\n        Data to be saved to a text file.\n    fmt : str or sequence of strs, optional\n        A single format (%10.5f), a sequence of formats, or a\n        multi-format string, e.g. \'Iteration %d -- %10.5f\', in which\n        case `delimiter` is ignored. For complex `X`, the legal options\n        for `fmt` are:\n            a) a single specifier, `fmt=\'%.4e\'`, resulting in numbers formatted\n                like `\' (%s+%sj)\' % (fmt, fmt)`\n            b) a full string specifying every real and imaginary part, e.g.\n                `\' %.4e %+.4j %.4e %+.4j %.4e %+.4j\'` for 3 columns\n            c) a list of specifiers, one per column - in this case, the real\n                and imaginary part must have separate specifiers,\n                e.g. `[\'%.3e + %.3ej\', \'(%.15e%+.15ej)\']` for 2 columns\n    delimiter : str, optional\n        String or character separating columns.\n    newline : str, optional\n        String or character separating lines.\n\n        .. versionadded:: 1.5.0\n    header : str, optional\n        String that will be written at the beginning of the file.\n\n        .. versionadded:: 1.7.0\n    footer : str, optional\n        String that will be written at the end of the file.\n\n        .. versionadded:: 1.7.0\n    comments : str, optional\n        String that will be prepended to the ``header`` and ``footer`` strings,\n        to mark them as comments. Default: \'# \',  as expected by e.g.\n        ``numpy.loadtxt``.\n\n        .. versionadded:: 1.7.0\n\n\n    See Also\n    --------\n    save : Save an array to a binary file in NumPy ``.npy`` format\n    savez : Save several arrays into an uncompressed ``.npz`` archive\n    savez_compressed : Save several arrays into a compressed ``.npz`` archive\n\n    Notes\n    -----\n    Further explanation of the `fmt` parameter\n    (``%[flag]width[.precision]specifier``):\n\n    flags:\n        ``-`` : left justify\n\n        ``+`` : Forces to precede result with + or -.\n\n        ``0`` : Left pad the number with zeros instead of space (see width).\n\n    width:\n        Minimum number of characters to be printed. The value is not truncated\n        if it has more characters.\n\n    precision:\n        - For integer specifiers (eg. ``d,i,o,x``), the minimum number of\n          digits.\n        - For ``e, E`` and ``f`` specifiers, the number of digits to print\n          after the decimal point.\n        - For ``g`` and ``G``, the maximum number of significant digits.\n        - For ``s``, the maximum number of characters.\n\n    specifiers:\n        ``c`` : character\n\n        ``d`` or ``i`` : signed decimal integer\n\n        ``e`` or ``E`` : scientific notation with ``e`` or ``E``.\n\n        ``f`` : decimal floating point\n\n        ``g,G`` : use the shorter of ``e,E`` or ``f``\n\n        ``o`` : signed octal\n\n        ``s`` : string of characters\n\n        ``u`` : unsigned decimal integer\n\n        ``x,X`` : unsigned hexadecimal integer\n\n    This explanation of ``fmt`` is not complete, for an exhaustive\n    specification see [1]_.\n\n    References\n    ----------\n    .. [1] `Format Specification Mini-Language\n           <http://docs.python.org/library/string.html#\n           format-specification-mini-language>`_, Python Documentation.\n\n    Examples\n    --------\n    >>> x = y = z = np.arange(0.0,5.0,1.0)\n    >>> np.savetxt(\'test.out\', x, delimiter=\',\')   # X is an array\n    >>> np.savetxt(\'test.out\', (x,y,z))   # x,y,z equal sized 1D arrays\n    >>> np.savetxt(\'test.out\', x, fmt=\'%1.4e\')   # use exponential notation\n\n    """"""\n\n    return numpy.savetxt(fname, array_create.array(X, bohrium=False), fmt=fmt, delimiter=delimiter,\n                         newline=newline, header=header, footer=footer, comments=comments)\n\n\n@fix_biclass_wrapper\ndef fromregex(file, regexp, dtype, bohrium=True):\n    """"""\n    Construct an array from a text file, using regular expression parsing.\n\n    The returned array is always a structured array, and is constructed from\n    all matches of the regular expression in the file. Groups in the regular\n    expression are converted to fields of the structured array.\n\n    Parameters\n    ----------\n    file : str or file\n        File name or file object to read.\n    regexp : str or regexp\n        Regular expression used to parse the file.\n        Groups in the regular expression correspond to fields in the dtype.\n    dtype : dtype or list of dtypes\n        Dtype for the structured array.\n\n    Returns\n    -------\n    output : ndarray\n        The output array, containing the part of the content of `file` that\n        was matched by `regexp`. `output` is always a structured array.\n\n    Raises\n    ------\n    TypeError\n        When `dtype` is not a valid dtype for a structured array.\n\n    See Also\n    --------\n    fromstring, loadtxt\n\n    Notes\n    -----\n    Dtypes for structured arrays can be specified in several forms, but all\n    forms specify at least the data type and field name. For details see\n    `doc.structured_arrays`.\n\n    Examples\n    --------\n    >>> f = open(\'test.dat\', \'w\')\n    >>> f.write(""1312 foo\\\\n1534  bar\\\\n444   qux"")\n    >>> f.close()\n\n    >>> regexp = r""(\\\\d+)\\\\s+(...)""  # match [digits, whitespace, anything]\n    >>> output = np.fromregex(\'test.dat\', regexp,\n    ...                       [(\'num\', np.int64), (\'key\', \'S3\')])\n    >>> output\n    array([(1312L, \'foo\'), (1534L, \'bar\'), (444L, \'qux\')],\n          dtype=[(\'num\', \'<i8\'), (\'key\', \'|S3\')])\n    >>> output[\'num\']\n    array([1312, 1534,  444], dtype=int64)\n\n    """"""\n\n    return array_create.array(numpy.fromregex(file, regexp, dtype), bohrium=bohrium)\n\n\n@fix_biclass_wrapper\ndef print_to_file(arr, fid, sep="""", format=""%s""):\n    """"""\n    a.tofile(arr, fid, sep="""", format=""%s"")\n\n    Write array \'arr\' to a file as text or binary (default).\n\n    Data is always written in \'C\' order, independent of the order of `a`.\n    The data produced by this method can be recovered using the function\n    fromfile().\n\n    Parameters\n    ----------\n    arr : array_like\n        Array data to be saved.\n    fid : file or str\n        An open file object, or a string containing a filename.\n    sep : str\n        Separator between array items for text output.\n        If """" (empty), a binary file is written, equivalent to\n        ``file.write(a.tobytes())``.\n    format : str\n        Format string for text file output.\n        Each entry in the array is formatted to text by first converting\n        it to the closest Python type, and then using ""format"" % item.\n\n    Notes\n    -----\n    This is a convenience function for quick storage of array data.\n    Information on endianness and precision is lost, so this method is not a\n    good choice for files intended to archive data or transport data between\n    machines with different endianness. Some of these problems can be overcome\n    by outputting the data as text files, at the expense of speed and file\n    size.\n    """"""\n\n    f = array_create.array(arr, bohrium=False)\n    return f.tofile(fid, sep=sep, format=format)\n'"
bridge/npbackend/bohrium/linalg.py,50,"b'""""""\nLinAlg\n~~~~~~\n\nCommon linear algebra functions\n\n""""""\nimport bohrium as np\nimport bohrium.blas as blas\nimport numpy_force.linalg as la\nimport numpy_force as numpy\n\n# We import all of NumPy LinAlg and overwrite with the objects we implement ourself\nfrom numpy_force.linalg import *\n\nfrom . import bhary\nfrom . import ufuncs\nfrom . import array_create\nfrom . import user_kernel\nfrom ._util import dtype_equal\nfrom .bhary import fix_biclass_wrapper\n\n\n@fix_biclass_wrapper\ndef gauss(a):\n    """"""\n    Performe Gausian elimination on matrix a without pivoting\n    """"""\n    for c in range(1, a.shape[0]):\n        a[c:, c - 1:] = a[c:, c - 1:] - (a[c:, c - 1] / a[c - 1, c - 1:c])[:, None] * a[c - 1, c - 1:]\n        np.flush()\n    a /= np.diagonal(a)[:, None]\n    return a\n\n\n@fix_biclass_wrapper\ndef lu(a):\n    """"""\n    Performe LU decomposition on the matrix a so A = L*U\n    """"""\n    u = a.copy()\n    l = np.zeros_like(a)\n    np.diagonal(l)[:] = 1.0\n    for c in range(1, u.shape[0]):\n        l[c:, c - 1] = (u[c:, c - 1] / u[c - 1, c - 1:c])\n        u[c:, c - 1:] = u[c:, c - 1:] - l[c:, c - 1][:, None] * u[c - 1, c - 1:]\n        np.flush()\n    return (l, u)\n\n\n@fix_biclass_wrapper\ndef solve(a, b):\n    """"""\n    Solve a linear matrix equation, or system of linear scalar equations\n    using Gausian elimination.\n\n    :param a: Coefficient matrix\n    :type a:  array_like, shape (M, M)\n    :param b: Ordinate or ""dependent variable"" values\n    :type b:  array_like, shape (M,) or (M, N)\n\n    :return:  Solution to the system a x = b\n    :rtype:   ndarray, shape (M,) or (M, N) depending on b\n\n    :raises: :py:exc:`LinAlgError` If `a` is singular or not square.\n\n    **Examples:**\n    Solve the system of equations ``3 * x0 + x1 = 9`` and ``x0 + 2 * x1 = 8``:\n\n    >>> import bohrium as np\n    >>> a = np.array([[3.,1.], [1.,2.]])\n    >>> b = np.array([9.,8.])\n    >>> x = np.linalg.solve(a, b)\n    >>> x\n    array([ 2.,  3.])\n\n    Check that the solution is correct:\n\n    >>> (np.dot(a, x) == b).all()\n    True\n    """"""\n    if not (len(a.shape) == 2 and a.shape[0] == a.shape[1]):\n        raise la.LinAlgError(""a is not square"")\n\n    w = gauss(np.hstack((a, b[:, np.newaxis])))\n    lc = w.shape[1] - 1\n    x = w[:, lc].copy()\n    for c in range(lc - 1, 0, -1):\n        x[:c] -= w[:c, c] * x[c:c + 1]\n        np.flush()\n    return x\n\n\n@fix_biclass_wrapper\ndef jacobi(a, b, tol=0.0005):\n    """"""\n    Solve a linear matrix equation, or system of linear scalar equations\n    using the Jacobi Method.\n\n    :param a: Coefficient matrix\n    :type a:  array_like, shape (M, M)\n    :param b: Ordinate or ""dependent variable"" values\n    :type b:  array_like, shape (M,) or (M, N)\n\n    :return:  Solution to the system a x = b\n    :rtype:   ndarray, shape (M,) or (M, N) depending on b\n\n    :raises: :py:exc:`LinAlgError` If `a` is singular or not square.\n\n    **Examples:**\n    Solve the system of equations ``3 * x0 + x1 = 9`` and ``x0 + 2 * x1 = 8``:\n\n    >>> import bohrium as np\n    >>> a = np.array([[3,1], [1,2]])\n    >>> b = np.array([9,8])\n    >>> x = np.linalg.jacobi(a, b)\n    >>> x\n    array([ 2.,  3.])\n\n    Check that the solution is correct:\n\n    >>> (np.dot(a, x) == b).all()\n    True\n    """"""\n    x = np.ones_like(b)\n    D = 1 / np.diag(a)\n    R = np.diag(np.diag(a)) - a\n    T = D[:, np.newaxis] * R\n    C = D * b\n    error = tol + 1\n    while error > tol:\n        xo = x\n        x = np.add.reduce(T * x, -1) + C\n        error = norm(x - xo) / norm(x)\n    return x\n\n\n@fix_biclass_wrapper\ndef matmul(a, b, no_blas=False):\n    """"""\n    Matrix multiplication of two 2-D arrays.\n\n    Parameters\n    ----------\n    a : array_like\n        First argument.\n    b : array_like\n        Second argument.\n\n    Returns\n    -------\n    output : ndarray\n        Returns the matrix multiplication of `a` and `b`.\n\n    Raises\n    ------\n    ValueError\n        If the last dimension of `a` is not the same size as\n        the second-to-last dimension of `b`.\n\n    See Also\n    --------\n    dot : Dot product of two arrays.\n\n    Examples\n    --------\n    >>> np.matmul(np.array([[1,2],[3,4]]),np.array([[5,6],[7,8]]))\n    array([[19, 22],\n           [43, 50]])\n    """"""\n    if not dtype_equal(a, b):\n        raise ValueError(""Input must be of same type"")\n\n    if a.ndim != 2 and b.ndim != 2:\n        raise ValueError(""Input must be 2-D."")\n\n    if not (bhary.check(a) or bhary.check(b)):  # Both are regular numpy arrays\n        return numpy.dot(a, b)\n    else:\n        a = array_create.array(a)\n        b = array_create.array(b)\n\n    # If the dtypes are both float, we can use BLAS to calculate\n    # the dot-product, if BLAS is present.\n    if not no_blas and a.dtype.kind in np.typecodes[""AllFloat""] and b.dtype.kind in np.typecodes[""AllFloat""]:\n        try:\n            return blas.gemm(a, b)\n        except:\n            pass\n\n    return ufuncs.add.reduce(a[:, numpy.newaxis] * numpy.transpose(b), -1)\n\n\n@fix_biclass_wrapper\ndef dot(a, b, no_blas=False):\n    """"""\n    Dot product of two arrays.\n\n    For 2-D arrays it is equivalent to matrix multiplication, and for 1-D\n    arrays to inner product of vectors (without complex conjugation). For\n    N dimensions it is a sum product over the last axis of `a` and\n    the second-to-last of `b`::\n\n        dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n\n    Parameters\n    ----------\n    a : array_like\n        First argument.\n    b : array_like\n        Second argument.\n\n    Returns\n    -------\n    output : ndarray\n        Returns the dot product of `a` and `b`.  If `a` and `b` are both\n        scalars or both 1-D arrays then a scalar is returned; otherwise\n        an array is returned.\n\n    Raises\n    ------\n    ValueError\n        If the last dimension of `a` is not the same size as\n        the second-to-last dimension of `b`.\n\n    See Also\n    --------\n    vdot : Complex-conjugating dot product.\n    tensordot : Sum products over arbitrary axes.\n    einsum : Einstein summation convention.\n\n    Examples\n    --------\n    >>> np.dot(3, 4)\n    12\n\n    Neither argument is complex-conjugated:\n\n    >>> np.dot([2j, 3j], [2j, 3j])\n    (-13+0j)\n\n    For 2-D arrays it\'s the matrix product:\n\n    >>> a = [[1, 0], [0, 1]]\n    >>> b = [[4, 1], [2, 2]]\n    >>> np.dot(a, b)\n    array([[4, 1],\n           [2, 2]])\n\n    >>> a = np.arange(3*4*5*6).reshape((3,4,5,6))\n    >>> b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))\n    >>> np.dot(a, b)[2,3,2,1,2,2]\n    499128\n    >>> sum(a[2,3,2,:] * b[1,2,:,2])\n    499128\n\n    """"""\n    if not (bhary.check(a) or bhary.check(b)):  # Both are regular numpy arrays\n        return numpy.dot(a, b)\n    else:\n        a = array_create.array(a)\n        b = array_create.array(b)\n\n    if b.ndim == 1:\n        return ufuncs.add.reduce(a * b, -1)\n\n    if a.ndim == 1:\n        return ufuncs.add.reduce(a * numpy.transpose(b), -1)\n\n    if not no_blas and a.ndim == 2 and b.ndim == 2:\n        # If the dtypes are both float, we can use BLAS to calculate\n        # the dot-product, if BLAS is present.\n        if a.dtype.kind in np.typecodes[""AllFloat""] and b.dtype.kind in np.typecodes[""AllFloat""]:\n            try:\n                return blas.gemm(a, b)\n            except:\n                pass\n\n    return ufuncs.add.reduce(a[:, numpy.newaxis] * numpy.transpose(b), -1)\n\n\n@fix_biclass_wrapper\ndef norm(x, ord=None, axis=None):\n    """"""\n    This version of norm is not fully compliant with the NumPy version,\n    it only supports computing 2-norm of a vector.\n    """"""\n\n    if ord != None:\n        raise NotImplementedError(""Unsupported value param ord=%s"" % ord)\n    if axis != None:\n        raise NotImplementedError(""Unsupported value of param ord=%s"" % axis)\n\n    r = np.sum(x * x)\n    if issubclass(np.dtype(r.dtype).type, np.integer):\n        r_f32 = np.empty(r.shape, dtype=np.float32)\n        r_f32[:] = r\n        r = r_f32\n    return np.sqrt(r)\n\n\n@fix_biclass_wrapper\ndef tensordot(a, b, axes=2):\n    """"""\n    Compute tensor dot product along specified axes for arrays >= 1-D.\n\n    Given two tensors (arrays of dimension greater than or equal to one),\n    `a` and `b`, and an array_like object containing two array_like\n    objects, ``(a_axes, b_axes)``, sum the products of `a`\'s and `b`\'s\n    elements (components) over the axes specified by ``a_axes`` and\n    ``b_axes``. The third argument can be a single non-negative\n    integer_like scalar, ``N``; if it is such, then the last ``N``\n    dimensions of `a` and the first ``N`` dimensions of `b` are summed\n    over.\n\n    Parameters\n    ----------\n    a, b : array_like, len(shape) >= 1\n        Tensors to ""dot"".\n    axes : variable type\n        * integer_like scalar\n          Number of axes to sum over (applies to both arrays); or\n        * (2,) array_like, both elements array_like of the same length\n          List of axes to be summed over, first sequence applying to `a`,\n          second to `b`.\n\n    See Also\n    --------\n    dot, einsum\n\n    Notes\n    -----\n    When there is more than one axis to sum over - and they are not the last\n    (first) axes of `a` (`b`) - the argument `axes` should consist of\n    two sequences of the same length, with the first axis to sum over given\n    first in both sequences, the second axis second, and so forth.\n\n    Examples\n    --------\n    A ""traditional"" example:\n\n    >>> a = np.arange(60.).reshape(3,4,5)\n    >>> b = np.arange(24.).reshape(4,3,2)\n    >>> c = np.tensordot(a,b, axes=([1,0],[0,1]))\n    >>> c.shape\n    (5, 2)\n    >>> c\n    array([[ 4400.,  4730.],\n           [ 4532.,  4874.],\n           [ 4664.,  5018.],\n           [ 4796.,  5162.],\n           [ 4928.,  5306.]])\n    >>> # A slower but equivalent way of computing the same...\n    >>> d = np.zeros((5,2))\n    >>> for i in range(5):\n    ...   for j in range(2):\n    ...     for k in range(3):\n    ...       for n in range(4):\n    ...         d[i,j] += a[k,n,i] * b[n,k,j]\n    >>> c == d\n    array([[ True,  True],\n           [ True,  True],\n           [ True,  True],\n           [ True,  True],\n           [ True,  True]], dtype=bool)\n\n    An extended example taking advantage of the overloading of + and \\\\*:\n\n    >>> a = np.array(range(1, 9))\n    >>> a.shape = (2, 2, 2)\n    >>> A = np.array((\'a\', \'b\', \'c\', \'d\'), dtype=object)\n    >>> A.shape = (2, 2)\n    >>> a; A\n    array([[[1, 2],\n            [3, 4]],\n           [[5, 6],\n            [7, 8]]])\n    array([[a, b],\n           [c, d]], dtype=object)\n\n    >>> np.tensordot(a, A) # third argument default is 2\n    array([abbcccdddd, aaaaabbbbbbcccccccdddddddd], dtype=object)\n\n    >>> np.tensordot(a, A, 1)\n    array([[[acc, bdd],\n            [aaacccc, bbbdddd]],\n           [[aaaaacccccc, bbbbbdddddd],\n            [aaaaaaacccccccc, bbbbbbbdddddddd]]], dtype=object)\n\n    >>> np.tensordot(a, A, 0) # ""Left for reader"" (result too long to incl.)\n    array([[[[[a, b],\n              [c, d]],\n              ...\n\n    >>> np.tensordot(a, A, (0, 1))\n    array([[[abbbbb, cddddd],\n            [aabbbbbb, ccdddddd]],\n           [[aaabbbbbbb, cccddddddd],\n            [aaaabbbbbbbb, ccccdddddddd]]], dtype=object)\n\n    >>> np.tensordot(a, A, (2, 1))\n    array([[[abb, cdd],\n            [aaabbbb, cccdddd]],\n           [[aaaaabbbbbb, cccccdddddd],\n            [aaaaaaabbbbbbbb, cccccccdddddddd]]], dtype=object)\n\n    >>> np.tensordot(a, A, ((0, 1), (0, 1)))\n    array([abbbcccccddddddd, aabbbbccccccdddddddd], dtype=object)\n\n    >>> np.tensordot(a, A, ((2, 1), (1, 0)))\n    array([acccbbdddd, aaaaacccccccbbbbbbdddddddd], dtype=object)\n\n    """"""\n    try:\n        iter(axes)\n    except:\n        axes_a = list(range(-axes, 0))\n        axes_b = list(range(0, axes))\n    else:\n        axes_a, axes_b = axes\n    try:\n        na = len(axes_a)\n        axes_a = list(axes_a)\n    except TypeError:\n        axes_a = [axes_a]\n        na = 1\n    try:\n        nb = len(axes_b)\n        axes_b = list(axes_b)\n    except TypeError:\n        axes_b = [axes_b]\n        nb = 1\n\n    a, b = np.array(a), np.array(b)\n    as_ = a.shape\n    nda = len(a.shape)\n    bs = b.shape\n    ndb = len(b.shape)\n    equal = True\n    if (na != nb):\n        equal = False\n    else:\n        for k in range(na):\n            if as_[axes_a[k]] != bs[axes_b[k]]:\n                equal = False\n                break\n            if axes_a[k] < 0:\n                axes_a[k] += nda\n            if axes_b[k] < 0:\n                axes_b[k] += ndb\n    if not equal:\n        raise ValueError(""shape-mismatch for sum"")\n\n    # Move the axes to sum over to the end of ""a""\n    # and to the front of ""b""\n    notin = [k for k in range(nda) if k not in axes_a]\n    newaxes_a = notin + axes_a\n    N2 = 1\n    for axis in axes_a:\n        N2 *= as_[axis]\n    newshape_a = (-1, N2)\n    olda = [as_[axis] for axis in notin]\n\n    notin = [k for k in range(ndb) if k not in axes_b]\n    newaxes_b = axes_b + notin\n    N2 = 1\n    for axis in axes_b:\n        N2 *= bs[axis]\n    newshape_b = (N2, -1)\n    oldb = [bs[axis] for axis in notin]\n\n    at = a.transpose(newaxes_a).reshape(newshape_a)\n    bt = b.transpose(newaxes_b).reshape(newshape_b)\n    res = dot(at, bt)\n    return res.reshape(olda + oldb)\n\n\ndef _solve_tridiagonal_omp(a, b, c, rhs):\n    from string import Template\n    from textwrap import dedent\n\n    KERNEL = Template(dedent(\'\'\'\n        #include <stddef.h>\n\n        void execute(\n            const ${DTYPE} *a,\n            const ${DTYPE} *b,\n            const ${DTYPE} *c,\n            const ${DTYPE} *d,\n            ${DTYPE} *solution\n        ){\n            const size_t m = ${SYS_DEPTH};\n            const size_t total_size = ${SIZE};\n\n            #pragma omp parallel for\n            for(ptrdiff_t idx = 0; idx < total_size; idx += m) {\n                ${DTYPE} cp[${SYS_DEPTH}];\n                ${DTYPE} dp[${SYS_DEPTH}];\n                cp[0] = c[idx] / b[idx];\n                dp[0] = d[idx] / b[idx];\n                for (ptrdiff_t j = 1; j < m; ++j) {\n                    const ${DTYPE} norm_factor = b[idx+j] - a[idx+j] * cp[j-1];\n                    cp[j] = c[idx+j] / norm_factor;\n                    dp[j] = (d[idx+j] - a[idx+j] * dp[j-1]) / norm_factor;\n                }\n                solution[idx + m-1] = dp[m-1];\n                for (ptrdiff_t j=m-2; j >= 0; --j) {\n                    solution[idx + j] = dp[j] - cp[j] * solution[idx + j+1];\n                }\n            }\n        }\n    \'\'\'))\n    \n    kernel = KERNEL.substitute(\n        DTYPE=user_kernel.dtype_to_c99(a.dtype),\n        SYS_DEPTH=a.shape[-1],\n        SIZE=a.size\n    )\n\n    res = array_create.empty_like(a)\n    user_kernel.execute(\n        kernel,\n        [user_kernel.make_behaving(v) for v in (a, b, c, rhs, res)]\n    )\n    return res\n\n\ndef _solve_tridiagonal_ocl(a, b, c, rhs, local_work_size=32):\n    from string import Template\n    from textwrap import dedent\n\n    KERNEL = Template(dedent(\'\'\'\n        #pragma OPENCL EXTENSION cl_khr_fp64 : enable\n\n        kernel void execute(\n            const global ${DTYPE} *a,\n            const global ${DTYPE} *b,\n            const global ${DTYPE} *c,\n            const global ${DTYPE} *d,\n            global ${DTYPE} *solution\n        ){\n            const size_t m = ${SYS_DEPTH};\n            const size_t total_size = ${SIZE};\n            const size_t idx = get_global_id(0) * m;\n\n            if (idx >= total_size) {\n                return;\n            }\n\n            private ${DTYPE} cp[${SYS_DEPTH}];\n            private ${DTYPE} dp[${SYS_DEPTH}];\n            cp[0] = c[idx] / b[idx];\n            dp[0] = d[idx] / b[idx];\n            for (ptrdiff_t j = 1; j < m; ++j) {\n                const ${DTYPE} norm_factor = b[idx+j] - a[idx+j] * cp[j-1];\n                cp[j] = c[idx+j] / norm_factor;\n                dp[j] = (d[idx+j] - a[idx+j] * dp[j-1]) / norm_factor;\n            }\n            solution[idx + m-1] = dp[m-1];\n            for (ptrdiff_t j=m-2; j >= 0; --j) {\n                solution[idx + j] = dp[j] - cp[j] * solution[idx + j+1];\n            }\n        }\n    \'\'\'))\n    \n    kernel = KERNEL.substitute(\n        DTYPE=user_kernel.dtype_to_c99(a.dtype),\n        SYS_DEPTH=a.shape[-1],\n        SIZE=a.size\n    )\n\n    res = array_create.empty_like(a)\n\n    # assemble work group size\n    global_size = res.size // res.shape[-1]\n    global_size = local_work_size * (global_size // local_work_size + 1)\n\n    user_kernel.execute(\n        kernel,\n        [user_kernel.make_behaving(v) for v in (a, b, c, rhs, res)],\n        tag=""opencl"",\n        param={""global_work_size"": global_size, ""local_work_size"": local_work_size}\n    )\n    return res\n\n\n@fix_biclass_wrapper\ndef solve_tridiagonal(a, b, c, rhs, backend=None, **kwargs):\n    """"""\n    Solver for tridiagonal systems,\n\n    ..math::\n\n        A x = b\n\n    based on the Thomas algorithm (not unconditionally stable).\n\n    If the input arrays have more than one dimension, this function vectorizes over all\n    but the last axis in parallel. All inputs must have equal shape.\n\n    :param a: Lower diagonal elements. a[..., 0] is not used.\n    :param b: Main diagonal elements.\n    :param c: Upper diagonal elements. c[..., -1] is not used.\n    :param rhs: Right-hand side vector.\n    :param backend: Computational backend to use (openmp, opencl).\n    :param kwargs: Additional argument to backend-specific solver. The opencl backend accepts\n       an argument ""local_work_size"" specifying the local work group size.\n    :returns: Solution of the tridiagonal system(s). Has the same shape as the input arrays.\n    """"""\n    if not (a.shape == b.shape == c.shape == rhs.shape):\n        raise ValueError(""All inputs must have equal shapes"")\n\n    if a.shape[-1] < 2:\n        raise ValueError(""Last axis must contain at least 2 elements"")\n    \n    # Cast to common dtype\n    common_dtype = numpy.find_common_type([v.dtype for v in (a, b, c, rhs)], [])\n\n    if not numpy.issubdtype(common_dtype, numpy.floating):\n        common_dtype = numpy.float64\n\n    a, b, c, rhs = (v.astype(common_dtype, copy=False) for v in (a, b, c, rhs))\n\n    if backend is None:\n        import bohrium_api\n        if bohrium_api.stack_info.is_opencl_in_stack():\n            backend = ""opencl""\n        else:\n            backend = ""openmp""\n\n    if backend == ""openmp"":\n        return _solve_tridiagonal_omp(a, b, c, rhs, **kwargs)\n\n    if backend == ""opencl"":\n        return _solve_tridiagonal_ocl(a, b, c, rhs, **kwargs)\n\n    raise ValueError(""unknown backend \'%s\' (must be \'openmp\' or \'opencl\')"" % backend)\n\n\n@fix_biclass_wrapper\ndef cg(A, b, x=None, tol=1e-5, force_niter=None):\n    """"""\n    Conjugate Gradient (CG) solver\n\n    Implemented as example MATLAB code from <https://en.wikipedia.org/wiki/Conjugate_gradient_method>\n    """"""\n    # If no guess is given, set an empty guess\n    if x is None:\n        x = array_create.zeros_like(b)\n\n    r = b - dot(A, x)\n    p = r.copy()\n    r_squared = r * r\n    rsold = np.sum(r_squared)\n\n    tol_squared = tol * tol\n    i = 0\n    while np.max(r_squared) > tol_squared or force_niter is not None:\n        Ap = dot(A, p)\n        alpha = rsold / dot(p, Ap)\n        x = x + alpha * p\n        r = r - alpha * Ap\n        r_squared = r * r\n        rsnew = np.sum(r_squared)\n\n        p = r + (rsnew / rsold) * p\n        rsold = rsnew\n        if force_niter is not None and i >= force_niter:\n            break\n        i += 1\n    return x\n'"
bridge/npbackend/bohrium/masking.py,8,"b'""""""\nMasking routines\n===========================\n\n""""""\nimport warnings\nfrom . import array_create\nfrom . import bhary\nfrom . import reorganization\nfrom . import array_manipulation\nfrom . import ufuncs\nfrom . import summations\nimport numpy_force as numpy\nfrom .bhary import fix_biclass_wrapper\n\n\n@fix_biclass_wrapper\ndef where(condition, x=None, y=None):\n    """"""\n    where(condition, [x, y])\n\n    Return elements, either from `x` or `y`, depending on `condition`.\n\n    If only `condition` is given, return ``condition.nonzero()``.\n\n    Parameters\n    ----------\n    condition : array_like, bool\n        When True, yield `x`, otherwise yield `y`.\n    x, y : array_like, optional\n        Values from which to choose. `x` and `y` need to have the same\n        shape as `condition`.\n\n    Returns\n    -------\n    out : ndarray or tuple of ndarrays\n        If both `x` and `y` are specified, the output array contains\n        elements of `x` where `condition` is True, and elements from\n        `y` elsewhere.\n\n        If only `condition` is given, return the tuple\n        ``condition.nonzero()``, the indices where `condition` is True.\n\n    See Also\n    --------\n    nonzero, choose\n\n    Notes\n    -----\n    If `x` and `y` are given and input arrays are 1-D, `where` is\n    equivalent to::\n\n        [xv if c else yv for (c,xv,yv) in zip(condition,x,y)]\n\n    Examples\n    --------\n    >>> np.where([[True, False], [True, True]],\n    ...          [[1, 2], [3, 4]],\n    ...          [[9, 8], [7, 6]])\n    array([[1, 8],\n           [3, 4]])\n\n    >>> np.where([[0, 1], [1, 0]])\n    (array([0, 1]), array([1, 0]))\n\n    >>> x = np.arange(9.).reshape(3, 3)\n    >>> np.where( x > 5 )\n    (array([2, 2, 2]), array([0, 1, 2]))\n    >>> x[np.where( x > 3.0 )]               # Note: result is 1D.\n    array([ 4.,  5.,  6.,  7.,  8.])\n    >>> np.where(x < 5, x, -1)               # Note: broadcasting.\n    array([[ 0.,  1.,  2.],\n           [ 3.,  4., -1.],\n           [-1., -1., -1.]])\n\n    Find the indices of elements of `x` that are in `goodvalues`.\n\n    >>> goodvalues = [3, 4, 7]\n    >>> ix = np.in1d(x.ravel(), goodvalues).reshape(x.shape)\n    >>> ix\n    array([[False, False, False],\n           [ True,  True, False],\n           [False,  True, False]], dtype=bool)\n    >>> np.where(ix)\n    (array([1, 1, 2]), array([0, 1, 1]))\n\n    """"""\n    if x is None or y is None:\n        warnings.warn(""Bohrium only supports where() when \'x\' and \'y\' are specified"", stacklevel=2)\n        return numpy.where(condition)\n\n    if not (bhary.check(condition) or bhary.check(x) or bhary.check(y)):\n        return numpy.where(condition, x, y)\n\n    # Make sure that non-scalars are Bohrium arrays\n    if numpy.isscalar(condition):\n        condition = bool(condition)\n    else:\n        condition = array_create.array(condition).astype(""bool"")\n\n    if not numpy.isscalar(x):\n        x = array_create.array(x)\n\n    if not numpy.isscalar(y):\n        y = array_create.array(y)\n\n    # Shortcut if all arguments are scalars\n    if all(numpy.isscalar(k) or k.size == 1 for k in (x, y, condition)):\n        return x if condition else y\n\n    # Find appropriate output type\n    array_types = []\n    scalar_types = []\n    for v in (x, y):\n        if numpy.isscalar(v):\n            scalar_types.append(type(v))\n        else:\n            array_types.append(v.dtype)\n    out_type = numpy.find_common_type(array_types, scalar_types)\n\n    # Shortcut if input arrays are finite\n    if ufuncs.isfinite(x).all() and ufuncs.isfinite(y).all():\n        if numpy.isscalar(condition):\n            res = condition * x + (not condition) * y\n        else:\n            res = condition * x + ufuncs.logical_not(condition) * y\n        if numpy.isscalar(res):\n            return out_type(res)\n        else:\n            return res.astype(out_type)\n\n    # General case: use fancy indexing\n    (condition, x, y), newshape = array_manipulation.broadcast_arrays(condition, x, y)\n    ret = array_create.zeros(newshape, dtype=out_type)\n    ret[condition] = x if numpy.isscalar(x) else x[condition]\n    ret[~condition] = y if numpy.isscalar(y) else y[~condition]\n    return ret\n\n\ndef masked_get(ary, bool_mask):\n    """"""\n    Get the elements of \'ary\' specified by \'bool_mask\'.\n    """"""\n\n    return ary[reorganization.nonzero(bool_mask)]\n\n\ndef masked_set(ary, bool_mask, value):\n    """"""\n    Set the \'value\' into \'ary\' at the location specified through \'bool_mask\'.\n    """"""\n\n    if numpy.isscalar(value) and ufuncs.isfinite(value):\n        ary *= ~bool_mask\n        ary += bool_mask * value\n    else:\n        ary[reorganization.nonzero(bool_mask)] = value\n'"
bridge/npbackend/bohrium/reorganization.py,17,"b'""""""\nReorganization of Array Elements Routines\n===========================\n""""""\nimport warnings\nimport numpy_force as numpy\nfrom . import bhary\nfrom bohrium_api import _info\nfrom ._util import is_scalar\nfrom .bhary import fix_biclass_wrapper\nfrom . import array_create\nfrom . import array_manipulation\nfrom . import ufuncs\nfrom . import numpy_backport\n\n\n@fix_biclass_wrapper\ndef gather(ary, indexes):\n    """"""\n    gather(ary, indexes)\n\n    Gather elements from \'ary\' selected by \'indexes\'.\n    The values of \'indexes\' are absolute indexed into a flatten \'ary\'\n    The shape of the returned array equals indexes.shape.\n\n    Parameters\n    ----------\n    ary  : array_like\n        The array to gather elements from.\n    indexes : array_like, interpreted as integers\n        Array or list of indexes that will be gather from \'array\'\n\n    Returns\n    -------\n    r : ndarray\n        The gathered array freshly-allocated.\n    """"""\n    from . import _bh\n\n    ary = array_manipulation.flatten(array_create.array(ary))\n\n    # Convert a scalar index to a 1-element array\n    if is_scalar(indexes):\n        indexes = [indexes]\n        \n    indexes = array_create.array(indexes, dtype=numpy.uint64, bohrium=True)\n    ret = array_create.empty(indexes.shape, dtype=ary.dtype, bohrium=True)\n    if ary.size == 0 or indexes.size == 0:\n        return array_create.array([])\n\n    _bh.ufunc(_info.op[\'gather\'][\'id\'], (ret, ary, indexes))\n    return ret\n\n\n@fix_biclass_wrapper\ndef take(a, indices, axis=None, out=None, mode=\'raise\'):\n    """"""\n    Take elements from an array along an axis.\n\n    This function does the same thing as ""fancy"" indexing (indexing arrays\n    using arrays); however, it can be easier to use if you need elements\n    along a given axis.\n\n    Parameters\n    ----------\n    a : array_like\n        The source array.\n    indices : array_like, interpreted as integers\n        The indices of the values to extract.\n\n        .. versionadded:: 1.8.0\n\n        Also allow scalars for indices.\n    axis : int, optional\n        The axis over which to select values. By default, the flattened\n        input array is used.\n    out : ndarray, optional\n        If provided, the result will be placed in this array. It should\n        be of the appropriate shape and dtype.\n    mode : {\'raise\', \'wrap\', \'clip\'}, optional\n        Specifies how out-of-bounds indices will behave.\n\n        * \'raise\' -- raise an error (default)\n        * \'wrap\' -- wrap around\n        * \'clip\' -- clip to the range\n\n        \'clip\' mode means that all indices that are too large are replaced\n        by the index that addresses the last element along that axis. Note\n        that this disables indexing with negative numbers.\n\n    Returns\n    -------\n    subarray : ndarray\n        The returned array has the same type as `a`.\n\n    See Also\n    --------\n    compress : Take elements using a boolean mask\n    ndarray.take : equivalent method\n\n    Examples\n    --------\n    >>> a = [4, 3, 5, 7, 6, 8]\n    >>> indices = [0, 1, 4]\n    >>> np.take(a, indices)\n    array([4, 3, 6])\n\n    In this example if `a` is an ndarray, ""fancy"" indexing can be used.\n\n    >>> a = np.array(a)\n    >>> a[indices]\n    array([4, 3, 6])\n\n    If `indices` is not one dimensional, the output also has these dimensions.\n\n    >>> np.take(a, [[0, 1], [2, 3]])\n    array([[4, 3],\n           [5, 7]])\n    """"""\n\n    if not bhary.check(a):\n        indices = array_create.array(indices, bohrium=False)\n        return numpy.take(a, indices, axis=axis, out=out, mode=mode)\n\n    if mode != ""raise"":\n        warnings.warn(""Bohrium only supports the \'raise\' mode not \'%s\', ""\n                      ""it will be handled by the original NumPy."" % mode, UserWarning, 2)\n        a = array_create.array(a, bohrium=False)\n        indices = array_create.array(indices, bohrium=False)\n        return numpy.take(a, indices, axis=axis, out=out, mode=mode)\n\n    if axis is not None and a.ndim > 1:\n        warnings.warn(""Bohrium does not support the \'axis\' argument, ""\n                      ""it will be handled by the original NumPy."", UserWarning, 2)\n        a = array_create.array(a, bohrium=False)\n        indices = array_create.array(indices, bohrium=False)\n        return numpy.take(a, indices, axis=axis, out=out, mode=mode)\n\n    ret = gather(a, indices)\n    if out is not None:\n        out[...] = ret\n        return out\n    else:\n        return ret\n\n\n@fix_biclass_wrapper\ndef take_using_index_tuple(a, index_tuple, out=None):\n    """"""\n    Take elements from the array \'a\' specified by \'index_tuple\'\n    This function is very similar to take(), but takes a tuple of index arrays rather than a single index array\n    \n    Parameters\n    ----------\n    a : array_like\n        The source array.\n    index_tuple : tuple of array_like, interpreted as integers\n        Each array in the tuple specified the indices of the values to extract for that axis. \n        The number of arrays in \'index_tuple\' must equal the number of dimension in \'a\'\n\n    out : ndarray, optional\n        If provided, the result will be placed in this array. It should\n        be of the appropriate shape and dtype.\n\n\n    Returns\n    -------\n    subarray : ndarray\n        The returned array has the same type as `a`.\n\n    """"""\n\n    if not bhary.check(a):\n        ret = a[index_tuple]\n        if out is not None:\n            out[...] = ret\n            return out\n        else:\n            return ret\n\n    assert len(index_tuple) == a.ndim\n\n    if a.size == 0:\n        return array_create.array([], dtype=a.dtype)\n\n    if a.ndim == 1:\n        return take(a, index_tuple[0], out=out)\n\n    # Make sure that all index arrays are uint64 bohrium arrays\n    index_list = []\n    for index in index_tuple:\n        index_list.append(array_create.array(index, dtype=numpy.uint64, bohrium=True))\n        if index_list[-1].size == 0:\n            return array_create.empty((0,), dtype=a.dtype)\n\n    # And then broadcast them into the same shape\n    index_list = array_manipulation.broadcast_arrays(*index_list)[0]\n\n    # Let\'s find the absolute index\n    abs_index = index_list[-1].copy()\n    stride = a.shape[-1]\n    for i in range(len(index_list) - 2, -1, -1):  # Iterate backwards from index_list[-2]\n        abs_index += index_list[i] * stride\n        stride *= a.shape[i]\n\n    # take() support absolute indices\n    ret = take(a, abs_index).reshape(index_list[0].shape)\n    if out is not None:\n        out[...] = ret\n        return out\n    else:\n        return ret\n\n\n@fix_biclass_wrapper\ndef scatter(ary, indexes, values):\n    """"""\n    scatter(ary, indexes, values)\n\n    Scatter \'values\' into \'ary\' selected by \'indexes\'.\n    The values of \'indexes\' are absolute indexed into a flatten \'ary\'\n    The shape of \'indexes\' and \'value\' must be equal.\n\n    Parameters\n    ----------\n    ary  : array_like\n        The target array to write the values to.\n    indexes : array_like, interpreted as integers\n        Array or list of indexes that will be written to in \'ary\'\n    values : array_like\n        Values to write into \'ary""\n    """"""\n    from . import _bh\n\n    indexes = array_manipulation.flatten(array_create.array(indexes, dtype=numpy.uint64), always_copy=False)\n    values = array_manipulation.flatten(array_create.array(values, dtype=ary.dtype), always_copy=False)\n\n    assert indexes.shape == values.shape\n    if ary.size == 0 or indexes.size == 0:\n        return\n\n    # In order to ensure a contiguous array, we do the scatter on a flatten copy\n    flat = array_manipulation.flatten(ary, always_copy=True)\n    _bh.ufunc(_info.op[\'scatter\'][\'id\'], (flat, values, indexes))\n    ary[...] = flat.reshape(ary.shape)\n\n\n@fix_biclass_wrapper\ndef put(a, ind, v, mode=\'raise\'):\n    """"""\n    Replaces specified elements of an array with given values.\n\n    The indexing works on the flattened target array. `put` is roughly\n    equivalent to:\n\n    ::\n\n        a.flat[ind] = v\n\n    Parameters\n    ----------\n    a : ndarray\n        Target array.\n    ind : array_like\n        Target indices, interpreted as integers.\n    v : array_like\n        Values to place in `a` at target indices. If `v` is shorter than\n        `ind` it will be repeated as necessary.\n    mode : {\'raise\', \'wrap\', \'clip\'}, optional\n        Specifies how out-of-bounds indices will behave.\n\n        * \'raise\' -- raise an error (default)\n        * \'wrap\' -- wrap around\n        * \'clip\' -- clip to the range\n\n        \'clip\' mode means that all indices that are too large are replaced\n        by the index that addresses the last element along that axis. Note\n        that this disables indexing with negative numbers.\n\n    See Also\n    --------\n    putmask, place, take\n\n    Examples\n    --------\n    >>> a = np.arange(5)\n    >>> np.put(a, [0, 2], [-44, -55])\n    >>> a\n    array([-44,   1, -55,   3,   4])\n\n    >>> a = np.arange(5)\n    >>> np.put(a, 22, -5, mode=\'clip\')\n    >>> a\n    array([ 0,  1,  2,  3, -5])\n\n    """"""\n\n    if ind.size == 0:\n        return  # Nothing to insert!\n\n    if not bhary.check(a):\n        return numpy.put(a, ind.astype(numpy.int64), v, mode=mode)\n\n    if mode != ""raise"":\n        warnings.warn(""Bohrium only supports the \'raise\' mode not \'%s\', ""\n                      ""it will be handled by the original NumPy."" % mode, UserWarning, 2)\n        return numpy.put(a, ind, v, mode=mode)\n\n    indexes = array_manipulation.flatten(array_create.array(ind, dtype=numpy.uint64), always_copy=False)\n    values = array_manipulation.flatten(array_create.array(v, dtype=a.dtype), always_copy=False)\n\n    # Now let\'s make the shape of \'indexes\' and \'values\' match\n    if indexes.size > values.size:\n        if values.size == 1:\n            # When \'values\' is a scalar, we can broadcast it to match \'indexes\'\n            values = numpy_backport.as_strided(values, shape=indexes.shape, strides=(0,))\n        else:  # else we repeat \'values\' enough times to be larger than \'indexes\'\n            values = numpy_backport.as_strided(values,\n                                               shape=(indexes.size // values.size + 2, values.size),\n                                               strides=(0, values.itemsize))\n            values = array_manipulation.flatten(values, always_copy=False)\n\n    # When \'values\' is too large, we simple cut the end off\n    if values.size > indexes.size:\n        values = values[0:indexes.size]\n\n    # Now that \'indexes\' and \'values\' have the same shape, we can call \'scatter\'\n    scatter(a, indexes, values)\n\n\n@fix_biclass_wrapper\ndef put_using_index_tuple(a, index_tuple, v):\n    """"""\n    Replaces specified elements of an array with given values.\n    This function is very similar to put(), but takes a tuple of index arrays rather than a single index array.\n    The indexing works like fancy indexing:\n    \n    ::\n\n        a[index_tuple] = v\n\n    Parameters\n    ----------\n    a : array_like\n        The source array.\n    index_tuple : tuple of array_like, interpreted as integers\n        Each array in the tuple specified the indices of the values to extract for that axis. \n        The number of arrays in \'index_tuple\' must equal the number of dimension in \'a\'\n    v : array_like\n        Values to place in `a`.\n\n    Returns\n    -------\n    subarray : ndarray\n        The returned array has the same type as `a`.\n    """"""\n\n    if not bhary.check(a):\n        a[index_tuple] = array_create.array(v, bohrium=False)\n        return\n\n    v = array_create.array(v, bohrium=True)\n    assert len(index_tuple) == a.ndim\n\n    if a.size == 0:\n        return\n\n    if a.ndim == 1:\n        return put(a, index_tuple[0], v)\n\n    # Make sure that all index arrays are uint64 bohrium arrays\n    index_list = []\n    for index in index_tuple:\n        index_list.append(array_create.array(index, dtype=numpy.uint64, bohrium=True))\n        if index_list[-1].size == 0:\n            return array_create.empty((0,), dtype=a.dtype)\n\n    # And then broadcast them into the same shape\n    index_list = array_manipulation.broadcast_arrays(*index_list)[0]\n\n    # Let\'s find the absolute index\n    abs_index = index_list[-1].copy()\n    stride = a.shape[-1]\n    for i in range(len(index_list) - 2, -1, -1):  # Iterate backwards from index_list[-2]\n        abs_index += index_list[i] * stride\n        stride *= a.shape[i]\n\n    # put() support absolute indices\n    put(a, abs_index, v)\n\n\n@fix_biclass_wrapper\ndef cond_scatter(ary, indexes, values, mask):\n    """"""\n    scatter(ary, indexes, values, mask)\n\n    Scatter \'values\' into \'ary\' selected by \'indexes\' where \'mask\' is true.\n    The values of \'indexes\' are absolute indexed into a flatten \'ary\'\n    The shape of \'indexes\', \'value\', and \'mask\' must be equal.\n\n\n    Parameters\n    ----------\n    ary  : array_like\n        The target array to write the values to.\n    indexes : array_like, interpreted as integers\n        Array or list of indexes that will be written to in \'ary\'\n    values : array_like\n        Values to write into \'ary\'\n    mask : array_like, interpreted as booleans\n        A mask that specifies which indexes and values to include and exclude\n    """"""\n    from . import _bh\n\n    indexes = array_manipulation.flatten(array_create.array(indexes, dtype=numpy.uint64), always_copy=False)\n    values = array_manipulation.flatten(array_create.array(values, dtype=ary.dtype), always_copy=False)\n    mask = array_manipulation.flatten(array_create.array(mask, dtype=numpy.bool), always_copy=False)\n\n    assert (indexes.shape == values.shape and values.shape == mask.shape)\n    if ary.size == 0 or indexes.size == 0:\n        return\n\n    # In order to ensure a contiguous array, we do the scatter on a flatten copy\n    flat = array_manipulation.flatten(ary, always_copy=True)\n    _bh.ufunc(_info.op[\'cond_scatter\'][\'id\'], (flat, values, indexes, mask))\n    ary[...] = flat.reshape(ary.shape)\n\n\n@fix_biclass_wrapper\ndef pack(ary, mask):\n    """"""\n    pack(ary, mask)\n\n    Packing the elements of \'ary\' specified by \'mask\' into new array that are contiguous\n    The values of \'indexes\' are absolute indexed into a flatten \'ary\'\n    The shape of \'mask\' and \'ary\' must be equal.\n\n\n    Parameters\n    ----------\n    ary  : array_like, read flatten\n        The array to read from.\n    mask : array_like, interpreted as a flatten boolean array\n        A mask that specifies which indexes of \'ary\' to read\n    """"""\n\n    ary = array_manipulation.flatten(array_create.array(ary), always_copy=False)\n    mask = array_manipulation.flatten(array_create.array(mask, dtype=numpy.bool), always_copy=False)\n    assert (ary.shape == mask.shape)\n    if ary.size == 0 or mask.size == 0:\n        return\n\n    true_indexes = ufuncs.add.accumulate(mask)\n    true_count = int(true_indexes[-1])\n    if true_count == 0:\n        return array_create.empty((0,), dtype=ary.dtype)\n    else:\n        ret = array_create.empty((true_count,), dtype=ary.dtype)\n        cond_scatter(ret, true_indexes - 1, ary, mask)\n        return ret\n\n\n@fix_biclass_wrapper\ndef flatnonzero(a):\n    """"""\n    Return indices that are non-zero in the flattened version of a.\n    This is equivalent to a.ravel().nonzero()[0].\n    Parameters\n    ----------\n    a : ndarray\n        Input array.\n    Returns\n    -------\n    res : ndarray\n        Output array, containing the indices of the elements of `a.ravel()`\n        that are non-zero.\n    See Also\n    --------\n    nonzero : Return the indices of the non-zero elements of the input array.\n    ravel : Return a 1-D array containing the elements of the input array.\n    Examples\n    --------\n    >>> x = np.arange(-2, 3)\n    >>> x\n    array([-2, -1,  0,  1,  2])\n    >>> np.flatnonzero(x)\n    array([0, 1, 3, 4])\n    Use the indices of the non-zero elements as an index array to extract\n    these elements:\n    >>> x.ravel()[np.flatnonzero(x)]\n    array([-2, -1,  1,  2])\n    """"""\n\n    if a.dtype is not numpy.bool:\n        a = a != 0\n    new_indexes = array_create.arange(a.size, dtype=numpy.uint64)\n    return pack(new_indexes, a)\n\n\n@fix_biclass_wrapper\ndef nonzero(a):\n    """"""\n    Return the indices of the elements that are non-zero.\n    Returns a tuple of arrays, one for each dimension of `a`,\n    containing the indices of the non-zero elements in that\n    dimension. The values in `a` are always tested and returned in\n    row-major, C-style order. The corresponding non-zero\n    values can be obtained with::\n        a[nonzero(a)]\n    To group the indices by element, rather than dimension, use::\n        transpose(nonzero(a))\n    The result of this is always a 2-D array, with a row for\n    each non-zero element.\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    Returns\n    -------\n    tuple_of_arrays : tuple\n        Indices of elements that are non-zero.\n    See Also\n    --------\n    flatnonzero :\n        Return indices that are non-zero in the flattened version of the input\n        array.\n    ndarray.nonzero :\n        Equivalent ndarray method.\n    count_nonzero :\n        Counts the number of non-zero elements in the input array.\n    Examples\n    --------\n    >>> x = np.eye(3)\n    >>> x\n    array([[ 1.,  0.,  0.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0.,  1.]])\n    >>> np.nonzero(x)\n    (array([0, 1, 2]), array([0, 1, 2]))\n    >>> x[np.nonzero(x)]\n    array([ 1.,  1.,  1.])\n    >>> np.transpose(np.nonzero(x))\n    array([[0, 0],\n           [1, 1],\n           [2, 2]])\n    A common use for ``nonzero`` is to find the indices of an array, where\n    a condition is True.  Given an array `a`, the condition `a` > 3 is a\n    boolean array and since False is interpreted as 0, np.nonzero(a > 3)\n    yields the indices of the `a` where the condition is true.\n    >>> a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n    >>> a > 3\n    array([[False, False, False],\n           [ True,  True,  True],\n           [ True,  True,  True]], dtype=bool)\n    >>> np.nonzero(a > 3)\n    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))\n    The ``nonzero`` method of the boolean array can also be called.\n    >>> (a > 3).nonzero()\n    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))\n    """"""\n\n    if a.ndim == 1:\n        return (flatnonzero(a),)\n\n    if not a.flags[\'C_CONTIGUOUS\']:\n        a = a.copy(order=\'C\')\n\n    nz = flatnonzero(a)\n    ret = []\n    for stride_in_bytes in a.strides:\n        stride = stride_in_bytes // a.itemsize\n        assert stride_in_bytes % a.itemsize == 0\n        tmp = nz // stride\n        ret.append(tmp)\n        nz -= tmp * stride\n    return tuple(ret)\n'"
bridge/npbackend/bohrium/summations.py,47,"b'""""""\nSummations and products\n~~~~~~~~~~~~~~~~~~~~~~~\n""""""\nimport warnings\nfrom . import ufuncs\nfrom . import array_create\nfrom . import bhary\nfrom . import reorganization\nfrom . import array_manipulation\nimport numpy_force as numpy\n\n\n@bhary.fix_biclass_wrapper\ndef sum(a, axis=None, dtype=None, out=None):\n    """"""\n    Sum of array elements over a given axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Elements to sum.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which a sum is performed.\n        The default (`axis` = `None`) is perform a sum over all\n        the dimensions of the input array. `axis` may be negative, in\n        which case it counts from the last to the first axis.\n\n        .. versionadded:: 1.7.0\n\n        If this is a tuple of ints, a sum is performed on multiple\n        axes, instead of a single axis or all the axes as before.\n    dtype : dtype, optional\n        The type of the returned array and of the accumulator in which the\n        elements are summed.  The dtype of `a` is used by default unless `a`\n        has an integer dtype of less precision than the default platform\n        integer.  In that case, if `a` is signed then the platform integer\n        is used while if `a` is unsigned then an unsigned integer of the\n        same precision as the platform integer is used.\n    out : ndarray, optional\n        Array into which the output is placed.  By default, a new array is\n        created.  If `out` is given, it must be of the appropriate shape\n        (the shape of `a` with `axis` removed, i.e.,\n        ``numpy.delete(a.shape, axis)``).  Its type is preserved. See\n        `doc.ufuncs` (Section ""Output arguments"") for more details.\n\n    Returns\n    -------\n    sum_along_axis : ndarray\n        An array with the same shape as `a`, with the specified\n        axis removed.   If `a` is a 0-d array, or if `axis` is None, a scalar\n        is returned.  If an output array is specified, a reference to\n        `out` is returned.\n\n    See Also\n    --------\n    ndarray.sum : Equivalent method.\n\n    cumsum : Cumulative sum of array elements.\n\n    trapz : Integration of array values using the composite trapezoidal rule.\n\n    mean, average\n\n    Notes\n    -----\n    Arithmetic is modular when using integer types, and no error is\n    raised on overflow.\n\n    Examples\n    --------\n    >>> np.sum([0.5, 1.5])\n    2.0\n    >>> np.sum([0.5, 0.7, 0.2, 1.5], dtype=np.int32)\n    1\n    >>> np.sum([[0, 1], [0, 5]])\n    6\n    >>> np.sum([[0, 1], [0, 5]], axis=0)\n    array([0, 6])\n    >>> np.sum([[0, 1], [0, 5]], axis=1)\n    array([1, 5])\n\n    If the accumulator is too small, overflow occurs:\n\n    >>> np.ones(128, dtype=np.int8).sum(dtype=np.int8)\n    -128\n\n    """"""\n\n    if not bhary.check(a) and not bhary.check(out):\n        return numpy.sum(a, axis=axis, dtype=dtype, out=out)\n    else:\n        if dtype is not None:\n            a = array_create.array(a, dtype=dtype)\n        return ufuncs.add.reduce(a, axis=axis, out=out)\n\n\n@bhary.fix_biclass_wrapper\ndef prod(a, axis=None, dtype=None, out=None):\n    """"""\n    Product of array elements over a given axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Elements to multiply.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which a multiply is performed.\n        The default (`axis` = `None`) is perform a multiply over all\n        the dimensions of the input array. `axis` may be negative, in\n        which case it counts from the last to the first axis.\n\n        .. versionadded:: 1.7.0\n\n        If this is a tuple of ints, a multiply is performed on multiple\n        axes, instead of a single axis or all the axes as before.\n    dtype : dtype, optional\n        The type of the returned array and of the accumulator in which the\n        elements are summed.  The dtype of `a` is used by default unless `a`\n        has an integer dtype of less precision than the default platform\n        integer.  In that case, if `a` is signed then the platform integer\n        is used while if `a` is unsigned then an unsigned integer of the\n        same precision as the platform integer is used.\n    out : ndarray, optional\n        Array into which the output is placed.  By default, a new array is\n        created.  If `out` is given, it must be of the appropriate shape\n        (the shape of `a` with `axis` removed, i.e.,\n        ``numpy.delete(a.shape, axis)``).  Its type is preserved. See\n        `doc.ufuncs` (Section ""Output arguments"") for more details.\n\n    Returns\n    -------\n    protuct_along_axis : ndarray\n        An array with the same shape as `a`, with the specified\n        axis removed.   If `a` is a 0-d array, or if `axis` is None, a scalar\n        is returned.  If an output array is specified, a reference to\n        `out` is returned.\n\n    Examples\n    --------\n    >>> np.prod([0.5, 1.5])\n    2.0\n    >>> np.prod([0.5, 0.7, 0.2, 1.5], dtype=np.int32)\n    1\n    >>> np.prod([[0, 1], [0, 5]])\n    6\n    >>> np.prod([[0, 1], [0, 5]], axis=0)\n    array([0, 6])\n    >>> np.prod([[0, 1], [0, 5]], axis=1)\n    array([1, 5])\n\n    If the accumulator is too small, overflow occurs:\n\n    >>> np.ones(128, dtype=np.int8).prod(dtype=np.int8)\n    -128\n\n    """"""\n\n    if not bhary.check(a) and not bhary.check(out):\n        return numpy.prod(a, axis=axis, dtype=dtype, out=out)\n    else:\n        if dtype is not None:\n            a = array_create.array(a, dtype=dtype)\n        return ufuncs.multiply.reduce(a, axis=axis, out=out)\n\n\n@bhary.fix_biclass_wrapper\ndef max(a, axis=None, out=None):\n    """"""\n    Return the maximum of an array or maximum along an axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which a max is performed.\n        The default (`axis` = `None`) is perform a max over all\n        the dimensions of the input array. `axis` may be negative, in\n        which case it counts from the last to the first axis.\n        If this is a tuple of ints, a max is performed on multiple\n        axes, instead of a single axis or all the axes as before.\n    out : ndarray, optional\n        Alternative output array in which to place the result.  Must\n        be of the same shape and buffer length as the expected output.\n        See `doc.ufuncs` (Section ""Output arguments"") for more details.\n\n    Returns\n    -------\n    max : ndarray or scalar\n        Maximum of `a`. If `axis` is None, the result is a scalar value.\n        If `axis` is given, the result is an array of dimension\n        ``a.ndim - 1``.\n\n    See Also\n    --------\n    min :\n        The minimum value of an array along a given axis, propagating any NaNs.\n    nanmax :\n        The maximum value of an array along a given axis, ignoring any NaNs.\n    maximum :\n        Element-wise maximum of two arrays, propagating any NaNs.\n    fmax :\n        Element-wise maximum of two arrays, ignoring any NaNs.\n    argmax :\n        Return the indices of the maximum values.\n\n    nanmin, minimum, fmin\n\n    Notes\n    -----\n    NaN values are propagated, that is if at least one item is NaN, the\n    corresponding max value will be NaN as well. To ignore NaN values\n    (MATLAB behavior), please use nanmax.\n\n    Don\'t use `max` for element-wise comparison of 2 arrays; when\n    ``a.shape[0]`` is 2, ``maximum(a[0], a[1])`` is faster than\n    ``max(a, axis=0)``.\n\n    Examples\n    --------\n    >>> a = np.arange(4).reshape((2,2))\n    >>> a\n    array([[0, 1],\n           [2, 3]])\n    >>> np.max(a)           # Maximum of the flattened array\n    3\n    >>> np.max(a, axis=0)   # Maxima along the first axis\n    array([2, 3])\n    >>> np.max(a, axis=1)   # Maxima along the second axis\n    array([1, 3])\n\n    >>> b = np.arange(5, dtype=np.float)\n    >>> b[2] = np.NaN\n    >>> np.max(b)\n    nan\n    >>> np.nanmax(b)\n    4.0\n\n    """"""\n\n    if not bhary.check(a) and not bhary.check(out):\n        return numpy.max(a, axis=axis, out=out)  # NumPy 1.6 doesn\'t support axis=None\n    else:\n        return ufuncs.maximum.reduce(a, axis=axis, out=out)\n\n\n@bhary.fix_biclass_wrapper\ndef min(a, axis=None, out=None):\n    """"""\n    Return the minimum of an array or minimum along an axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which a min is performed.\n        The default (`axis` = `None`) is perform a min over all\n        the dimensions of the input array. `axis` may be negative, in\n        which case it counts from the last to the first axis.\n        If this is a tuple of ints, a min is performed on multiple\n        axes, instead of a single axis or all the axes as before.\n    out : ndarray, optional\n        Alternative output array in which to place the result.  Must\n        be of the same shape and buffer length as the expected output.\n        See `doc.ufuncs` (Section ""Output arguments"") for more details.\n\n    Returns\n    -------\n    min : ndarray or scalar\n        minimum of `a`. If `axis` is None, the result is a scalar value.\n        If `axis` is given, the result is an array of dimension\n        ``a.ndim - 1``.\n\n    See Also\n    --------\n    min :\n        The minimum value of an array along a given axis, propagating any NaNs.\n    nanmin :\n        The minimum value of an array along a given axis, ignoring any NaNs.\n    minimum :\n        Element-wise minimum of two arrays, propagating any NaNs.\n    fmin :\n        Element-wise minimum of two arrays, ignoring any NaNs.\n    argmin :\n        Return the indices of the minimum values.\n\n    nanmin, minimum, fmin\n\n    Notes\n    -----\n    NaN values are propagated, that is if at least one item is NaN, the\n    corresponding min value will be NaN as well. To ignore NaN values\n    (MATLAB behavior), please use nanmin.\n\n    Don\'t use `min` for element-wise comparison of 2 arrays; when\n    ``a.shape[0]`` is 2, ``minimum(a[0], a[1])`` is faster than\n    ``min(a, axis=0)``.\n\n    Examples\n    --------\n    >>> a = np.arange(4).reshape((2,2))\n    >>> a\n    array([[0, 1],\n           [2, 3]])\n    >>> np.min(a)           # minimum of the flattened array\n    3\n    >>> np.min(a, axis=0)   # minima along the first axis\n    array([2, 3])\n    >>> np.min(a, axis=1)   # minima along the second axis\n    array([1, 3])\n\n    >>> b = np.arange(5, dtype=np.float)\n    >>> b[2] = np.NaN\n    >>> np.min(b)\n    nan\n    >>> np.nanmin(b)\n    4.0\n\n    """"""\n\n    if not bhary.check(a) and not bhary.check(out):\n        return numpy.min(a, axis=axis, out=out)  # NumPy 1.6 doesn\'t support axis=None\n    else:\n        return ufuncs.minimum.reduce(a, axis=axis, out=out)\n\n\n@bhary.fix_biclass_wrapper\ndef any(a, axis=None, out=None, keepdims=None):\n    if not bhary.check(a) and not bhary.check(out):\n        return numpy.any(a, axis=axis, out=out)\n    else:\n        return ufuncs.logical_or.reduce(a.astype(bool), axis=axis, out=out)\n\n\n@bhary.fix_biclass_wrapper\ndef all(a, axis=None, out=None, keepdims=None):\n    if not bhary.check(a) and not bhary.check(out):\n        return numpy.all(a, axis=axis, out=out)\n    else:\n        return ufuncs.logical_and.reduce(a.astype(bool), axis=axis, out=out)\n\n\n@bhary.fix_biclass_wrapper\ndef argmax(a, axis=None, out=None):\n    """"""\n    Returns the indices of the maximum values along an axis.\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    axis : int, optional\n        By default, the index is into the flattened array, otherwise\n        along the specified axis.\n    out : array, optional\n        If provided, the result will be inserted into this array. It should\n        be of the appropriate shape and dtype.\n    Returns\n    -------\n    index_array : ndarray of ints\n        Array of indices into the array. It has the same shape as `a.shape`\n        with the dimension along `axis` removed.\n    See Also\n    --------\n    ndarray.argmax, argmin\n    amax : The maximum value along a given axis.\n    unravel_index : Convert a flat index into an index tuple.\n    Notes\n    -----\n    In case of multiple occurrences of the maximum values, the indices\n    corresponding to the first occurrence are returned.\n    Examples\n    --------\n    >>> a = np.arange(6).reshape(2,3)\n    >>> a\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> np.argmax(a)\n    5\n    >>> np.argmax(a, axis=0)\n    array([1, 1, 1])\n    >>> np.argmax(a, axis=1)\n    array([2, 2])\n    >>> b = np.arange(6)\n    >>> b[1] = 5\n    >>> b\n    array([0, 5, 2, 3, 4, 5])\n    >>> np.argmax(b) # Only the first occurrence is returned.\n    1\n    """"""\n\n    if not bhary.check(a):\n        return numpy.argmax(a, axis=axis, out=out)\n\n    if axis is None or (a.ndim == 1 and axis == 0):\n        a = array_manipulation.flatten(a, always_copy=False)\n        ret = reorganization.flatnonzero(a == max(a))[0]\n    else:\n        warnings.warn(""Bohrium does not support the \'axis\' argument, ""\n                      ""it will be handled by the original NumPy."", UserWarning, 2)\n        return numpy.argmax(a.copy2numpy(), axis=axis)\n\n    if out is None:\n        return ret\n    else:\n        out[...] = ret\n        return out\n\n\n@bhary.fix_biclass_wrapper\ndef argmin(a, axis=None, out=None):\n    """"""\n    Returns the indices of the minimum values along an axis.\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    axis : int, optional\n        By default, the index is into the flattened array, otherwise\n        along the specified axis.\n    out : array, optional\n        If provided, the result will be inserted into this array. It should\n        be of the appropriate shape and dtype.\n    Returns\n    -------\n    index_array : ndarray of ints\n        Array of indices into the array. It has the same shape as `a.shape`\n        with the dimension along `axis` removed.\n    See Also\n    --------\n    ndarray.argmin, argmax\n    amin : The minimum value along a given axis.\n    unravel_index : Convert a flat index into an index tuple.\n    Notes\n    -----\n    In case of multiple occurrences of the minimum values, the indices\n    corresponding to the first occurrence are returned.\n    Examples\n    --------\n    >>> a = np.arange(6).reshape(2,3)\n    >>> a\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> np.argmin(a)\n    0\n    >>> np.argmin(a, axis=0)\n    array([0, 0, 0])\n    >>> np.argmin(a, axis=1)\n    array([0, 0])\n    >>> b = np.arange(6)\n    >>> b[4] = 0\n    >>> b\n    array([0, 1, 2, 3, 0, 5])\n    >>> np.argmin(b) # Only the first occurrence is returned.\n    0\n    """"""\n\n    if not bhary.check(a):\n        return numpy.argmin(a, axis=axis, out=out)\n\n    if axis is None or (a.ndim == 1 and axis == 0):\n        a = array_manipulation.flatten(a, always_copy=False)\n        ret = reorganization.flatnonzero(a == min(a))[0]\n    else:\n        warnings.warn(""Bohrium does not support the \'axis\' argument, ""\n                      ""it will be handled by the original NumPy."", UserWarning, 2)\n        return numpy.argmin(a.copy2numpy(), axis=axis)\n\n    if out is None:\n        return ret\n    else:\n        out[...] = ret\n        return out\n\n\ndef mean(a, axis=None, dtype=None, out=None):\n    """"""\n    Compute the arithmetic mean along the specified axis.\n    Returns the average of the array elements.  The average is taken over\n    the flattened array by default, otherwise over the specified axis.\n    `float64` intermediate and return values are used for integer inputs.\n    Parameters\n    ----------\n    a : array_like\n        Array containing numbers whose mean is desired. If `a` is not an\n        array, a conversion is attempted.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which the means are computed. The default is to\n        compute the mean of the flattened array.\n        .. versionadded:: 1.7.0\n        If this is a tuple of ints, a mean is performed over multiple axes,\n        instead of a single axis or all the axes as before.\n    dtype : data-type, optional\n        Type to use in computing the mean.  For integer inputs, the default\n        is `float64`; for floating point inputs, it is the same as the\n        input dtype.\n    out : ndarray, optional\n        Alternate output array in which to place the result.  The default\n        is ``None``; if provided, it must have the same shape as the\n        expected output, but the type will be cast if necessary.\n        See `doc.ufuncs` for details.\n\n    Returns\n    -------\n    m : ndarray, see dtype parameter above\n        If `out=None`, returns a new array containing the mean values,\n        otherwise a reference to the output array is returned.\n    See Also\n    --------\n    average : Weighted average\n    std, var, nanmean, nanstd, nanvar\n    Notes\n    -----\n    The arithmetic mean is the sum of the elements along the axis divided\n    by the number of elements.\n    Note that for floating-point input, the mean is computed using the\n    same precision the input has.  Depending on the input data, this can\n    cause the results to be inaccurate, especially for `float32` (see\n    example below).  Specifying a higher-precision accumulator using the\n    `dtype` keyword can alleviate this issue.\n    By default, `float16` results are computed using `float32` intermediates\n    for extra precision.\n    Examples\n    --------\n    >>> a = np.array([[1, 2], [3, 4]])\n    >>> np.mean(a)\n    2.5\n    >>> np.mean(a, axis=0)\n    array([ 2.,  3.])\n    >>> np.mean(a, axis=1)\n    array([ 1.5,  3.5])\n    In single precision, `mean` can be inaccurate:\n    >>> a = np.zeros((2, 512*512), dtype=np.float32)\n    >>> a[0, :] = 1.0\n    >>> a[1, :] = 0.1\n    >>> np.mean(a)\n    0.54999924\n    Computing the mean in float64 is more accurate:\n    >>> np.mean(a, dtype=np.float64)\n    0.55000000074505806\n    """"""\n\n    def _count_reduce_items(arr, axis):\n        if axis is None:\n            axis = tuple(range(arr.ndim))\n        if not isinstance(axis, tuple):\n            axis = (axis,)\n        items = 1\n        for ax in axis:\n            items *= arr.shape[ax]\n        return items\n\n    def _mean(a, axis=None, dtype=None, out=None):\n        arr = array_create.array(a)\n        is_float16_result = False\n        rcount = _count_reduce_items(arr, axis)\n        # Make this warning show up first\n        if rcount == 0:\n            warnings.warn(""Mean of empty slice."", RuntimeWarning, stacklevel=2)\n\n        # Cast bool, unsigned int, and int to float64 by default\n        if dtype is None:\n            if issubclass(arr.dtype.type, (numpy.integer, numpy.bool_)):\n                dtype = numpy.dtype(\'f8\')\n            elif issubclass(arr.dtype.type, numpy.float16):\n                dtype = numpy.dtype(\'f4\')\n                is_float16_result = True\n\n        ret = sum(arr, axis, dtype, out)\n        if isinstance(ret, numpy.ndarray):\n            ret = ufuncs.true_divide(ret, rcount, out=ret)\n            if is_float16_result and out is None:\n                ret = a.dtype.type(ret)\n        elif hasattr(ret, \'dtype\'):\n            if is_float16_result:\n                ret = a.dtype.type(ret / rcount)\n            else:\n                ret = ret.dtype.type(ret / rcount)\n        else:\n            ret = ret / rcount\n        return ret\n    return _mean(a, axis=axis, dtype=dtype, out=out)\n\n\naverage = mean\n'"
bridge/npbackend/bohrium/user_kernel.py,5,"b'import numpy_force as np\nfrom bohrium_api import stack_info\nfrom . import _bh, bhary, _util, array_create\n\n_default_compiler_command = None\n\n\ndef get_default_compiler_command():\n    """""" Returns the default compiler command, which is the one typically extended with extra link commands """"""\n    global _default_compiler_command\n    if _default_compiler_command is None:\n        import re\n        from bohrium_api import stack_info\n        m = re.search(""JIT Command: \\""([^\\""]*)\\"""", stack_info.info()[\'runtime_info\'])\n        if m is None:\n            raise RuntimeError(""\'JIT Command\' not found in the Bohrium backend"")\n        _default_compiler_command = m.group(1)\n    return _default_compiler_command\n\n\ndef execute(kernel_source, operand_list, compiler_command=None, tag=""openmp"", param=None, only_behaving_operands=True):\n    """""" Compile and execute the function `execute()` with the arguments in `operand_list`\n\n    Parameters\n    ----------\n    kernel_source : str\n        The kernel source code that most define the function `execute()` that should take arguments corresponding\n        to the `operand_list`\n    operand_list : list of bohrium arrays\n        The arrays given to the `execute()` function defined in `kernel_source`\n    compiler_command : str, optional\n        The compiler command to use when comping the kernel. `{OUT}` and `{IN}` in the command are replaced with the\n        name of the binary and source path.\n        When this options isn\'t specified, the default command are used see `get_default_compiler_command()`.\n    tag : str, optional\n        Name of the backend that should handle this kernel.\n    param : dict, optional\n        Backend specific parameters (e.g. OpenCL needs `global_work_size` and `local_work_size`).\n    only_behaving_operands : bool, optional\n        Set to False in order to allow non-behaving operands. Requirements for a behaving array:\n             * Is a bohrium array\n             * Is C-style contiguous\n             * Points to the first element in the underlying base array (no offset)\n             * Has the same total length as its base\n        See `make_behaving()`\n\n    Examples\n    --------\n    # Simple addition kernel\n    import bohrium as bh\n    kernel = r\'\'\'\n    #include <stdint.h>\n    void execute(double *a, double *b, double *c) {\n        for(uint64_t i=0; i<100; ++i) {\n            c[i] = a[i] + b[i] + i;\n        }\n    }\'\'\'\n    a = bh.ones(100, bh.double)\n    b = bh.ones(100, bh.double)\n    res = bh.empty_like(a)\n    bh.user_kernel.execute(kernel, [a, b, res])\n    """"""\n    if stack_info.is_proxy_in_stack():\n        raise RuntimeError(""The proxy backend does not support user kernels"")\n    if compiler_command is None:\n        compiler_command = get_default_compiler_command()\n    for op in operand_list:\n        if not bhary.check(op):\n            raise TypeError(""All operands in `operand_list` must be Bohrium arrays"")\n        if only_behaving_operands and not _bh.is_array_behaving(op):\n            raise TypeError(""Operand is not behaving set `only_behaving_operands=False` or use `make_behaving()`"")\n\n    if param is None:\n        param = {}\n\n    def parse_param():\n        import collections\n        for key, value in param.items():\n            if isinstance(value, collections.Iterable) and not isinstance(value, str):\n                value = "" "".join(str(subvalue) for subvalue in value)\n            yield ""%s: %s"" % (key, value)\n\n    param_str = ""; "".join(parse_param())\n\n    _bh.flush()\n    ret_msg = _bh.user_kernel(kernel_source, operand_list, compiler_command, tag, param_str)\n    if len(ret_msg) > 0:\n        raise RuntimeError(ret_msg)\n\n\ndef dtype_to_c99(dtype):\n    """""" Returns the C99 name of `dtype` """"""\n    if np.issubdtype(dtype, np.integer):\n        return ""%s_t"" % str(dtype)\n    elif _util.dtype_equal(dtype, np.float32):\n        return ""float""\n    elif _util.dtype_equal(dtype, np.float64):\n        return ""double""\n    elif _util.dtype_equal(dtype, np.complex64):\n        return ""float complex""\n    elif _util.dtype_equal(dtype, np.complex128):\n        return ""double complex""\n    raise TypeError(""dtype \'%s\' unsupported"" % str(dtype))\n\n\ndef gen_function_prototype(operand_list, operand_name_list=None):\n    """""" Returns the `execute() definition based on the arrays in `operand_list` """"""\n    dtype_list = [dtype_to_c99(t.dtype) for t in operand_list]\n    ret = ""#include <stdint.h>\\n#include <complex.h>\\n""\n    ret += ""void execute(""\n    for i in range(len(dtype_list)):\n        ret += ""%s *"" % dtype_list[i]\n        if operand_name_list is None:\n            ret += ""a%d, "" % i\n        else:\n            ret += ""%s, "" % operand_name_list[i]\n    return ""%s)\\n"" % ret[:-2]\n\n\ndef make_behaving(ary, dtype=None):\n    """""" Make sure that `ary` is a ""behaving"" bohrium array of type `dtype`.\n    Requirements for a behaving array:\n     * Is a bohrium array\n     * Is C-style contiguous\n     * Points to the first element in the underlying base array (no offset)\n     * Has the same total length as its base\n\n    Parameters\n    ----------\n    ary : array_like\n        The array to make behaving\n    dtype : boolean, optional\n        The return array is converted to `dtype` if not None\n    \n    Returns\n    -------\n    A behaving Bohrium array that might be a copy of `ary`\n\n    Note\n    ----\n    Use this function to make sure that operands given to `execute()` is ""behaving"" that is\n    the kernel can access the arrays without worrying about offset and stride.\n    """"""\n\n    ary = array_create.array(ary, dtype=dtype, order=\'C\')\n    if not _bh.is_array_behaving(ary):\n        ary = array_create.array(ary, copy=True)\n    return ary\n'"
test/python/tests/test_boolean.py,1,"b'import util\nimport bohrium\nfrom bohrium_api import _info\n\n\nclass test_mix_types:\n    def init(self):\n        for dtype in _info.numpy_types():\n            dtype = ""np.%s""%dtype.name\n            for cmd, shape in util.gen_random_arrays(""R"", 1, min_ndim=1, samples_in_each_ndim=1,\n                                                     dtype=dtype, no_views=True):\n                cmd = ""R = bh.random.RandomState(42); res=%s; "" % cmd\n                yield cmd\n\n    def test_assign(self, cmd):\n        return cmd + ""res[...] = False""\n\n    def test_add(self, cmd):\n        return cmd + ""res = res + False""\n\n    def test_mul(self, cmd):\n        return cmd + ""res = res * True""\n\n'"
test/python/tests/test_mask.py,9,"b'import bohrium\nimport util\nimport functools\nimport operator\nfrom bohrium_api import _info\n\n\nclass test_set_bool_mask_scalar:\n    def init(self):\n        for dtype in _info.numpy_types():\n            dtype = ""np.%s""%dtype.name\n            for cmd, shape in util.gen_random_arrays(""R"", 2, min_ndim=1, samples_in_each_ndim=1,\n                                                     dtype=dtype, no_views=True):\n                cmd = ""R = bh.random.RandomState(42); res=%s; "" \\\n                      ""m = R.random_integers(0, 1, res.shape, bohrium=BH).astype(np.bool); "" % cmd\n                yield (cmd, dtype)\n\n    @util.add_bh107_cmd\n    def test_set_scalar(self, arg):\n        (cmd, dtype) = arg\n        cmd += ""res[m] = %s(42)"" % dtype\n        return cmd\n\n    @util.add_bh107_cmd\n    def test_set_scalar_nan(self, arg):\n        (cmd, dtype) = arg\n        if dtype in util.TYPES.FLOAT:\n            cmd += ""res[m] = np.nan""\n        else:\n            cmd = ""res = 0""\n        return cmd\n\n\nclass test_set_bool_mask:\n    def init(self):\n        for cmd, shape in util.gen_random_arrays(""R"", 3, max_dim=50, dtype=""np.float64""):\n            nelem = functools.reduce(operator.mul, shape)\n            if nelem == 0:\n                continue\n            cmd = ""R = bh.random.RandomState(42); res=%s; "" \\\n                  ""m = R.random_integers(0, 1, res.shape, bohrium=BH).astype(np.bool); "" % cmd\n            yield (cmd)\n\n    @util.add_bh107_cmd\n    def test_set(self, cmd):\n        cmd += ""res[m] = res.copy()[m] * 42""\n        return cmd\n\n\nclass test_get_bool_mask:\n    def init(self):\n        for ary, shape in util.gen_random_arrays(""R"", 3, max_dim=50, dtype=""np.float64""):\n            nelem = functools.reduce(operator.mul, shape)\n            if nelem == 0:\n                continue\n            cmd = ""R = bh.random.RandomState(42); a=%s; "" % ary\n            cmd += ""m = R.random_integers(0, 1, a.shape, bohrium=BH).astype(np.bool); ""\n            yield (cmd)\n\n    @util.add_bh107_cmd\n    def test_get(self, cmd):\n        cmd += ""res = a[m]""\n        return cmd\n\n\nclass test_where:\n    def init(self):\n        for dtype in _info.numpy_types():\n            dtype = ""np.%s"" % dtype.name\n            for cmd, shape in util.gen_random_arrays(""R"", 2, min_ndim=1, samples_in_each_ndim=1,\n                                                     dtype=dtype, no_views=True):\n                nelem = functools.reduce(operator.mul, shape)\n                # NumPy returns some fucked up shapes when working on 1-sized arrays\n                # thus we will ignore them\n                if nelem > 1:\n                    cmd = ""R = bh.random.RandomState(42); a = %s; "" % cmd\n                    cmd += ""b = R.random(%s, dtype=%s, bohrium=BH); "" % (shape, dtype)\n                    cmd += ""m = R.random_integers(0, 1, size=a.shape, dtype=np.bool, bohrium=BH); ""\n                    yield (cmd, dtype)\n\n    def test_scalar_condition(self, arg):\n        (cmd, dtype) = arg\n        cmd += ""res = M.where(%s(True), a, b)"" % dtype\n        return cmd\n\n    def test_scalar1(self, arg):\n        (cmd, dtype) = arg\n        cmd += ""res = M.where(m, %s(42), a)"" % dtype\n        return cmd\n\n    def test_scalar2(self, arg):\n        (cmd, dtype) = arg\n        cmd += ""res = M.where(m, a, %s(42))"" % dtype\n        return cmd\n\n    def test_array(self, arg):\n        (cmd, dtype) = arg\n        cmd += ""res = M.where(m, a, b)""\n        return cmd\n\n    def test_nan_array(self, arg):\n        (cmd, dtype) = arg\n        if dtype in util.TYPES.FLOAT:\n            cmd += ""a[0] = M.nan;""\n            cmd += ""res = M.where(M.isnan(a), M.ones_like(a), a)""\n            return cmd\n        else:\n            return ""res = 0""\n\n    def test_nan_scalar1(self, arg):\n        (cmd, dtype) = arg\n        cmd += ""res = M.where(m, M.nan, a)""\n        return cmd\n\n    def test_nan_scalar2(self, arg):\n        (cmd, dtype) = arg\n        cmd += ""res = M.where(m, a, M.nan)""\n        return cmd\n'"
test/python/tests/test_primitives.py,10,"b'import numpy\nfrom bohrium_api import _info\nimport util\n\n\nclass test_bh_opcodes:\n    def init(self):\n        for op in _info.op.values():\n            if op[""name""] not in [""identity""] and op[\'elementwise\']:\n                for type_sig in op[""type_sig""]:\n                    yield (op, type_sig)\n\n    @util.add_bh107_cmd\n    def test_ufunc(self, arg):\n        (op, type_sig) = arg\n\n        cmd = ""R = bh.random.RandomState(42); ""\n\n        for i, dtype in enumerate(type_sig[1:]):\n            cmd += ""a%d = R.random_of_dtype(shape=10, dtype=np.%s, bohrium=BH); "" % (i, dtype)\n\n        if op[""name""] == ""arccosh"":\n            cmd += ""a%d += 1;"" % i\n\n        cmd += ""res = M.%s("" % (op[""name""])\n\n        for i in range(op[""nop""]-1):\n            cmd += ""a%d, "" % i\n\n        cmd = cmd[:-2] + "");""\n        return cmd\n\n\nclass test_bh_operators:\n    def init(self):\n        for op in [\'+\', \'-\', \'*\', \'/\', \'//\', \'%\', \'==\', \'<=\', \'>=\', \'!=\', \'<\', \'>\']:\n            for dtype in [\'float64\', \'int64\']:\n                yield (op, dtype)\n\n    @util.add_bh107_cmd\n    def test_arrays(self, arg):\n        (op, dtype) = arg\n        cmd = ""R = bh.random.RandomState(42); ""\n        cmd += ""a1 = R.random_of_dtype(shape=10, dtype=np.%s, bohrium=BH); "" % dtype\n        cmd += ""a2 = R.random_of_dtype(shape=10, dtype=np.%s, bohrium=BH) + 1; "" % dtype\n        cmd += ""res = a1 %s a2"" % op\n        return cmd\n\n    @util.add_bh107_cmd\n    def test_scalar_rhs(self, arg):\n        (op, dtype) = arg\n        cmd = ""R = bh.random.RandomState(42); ""\n        cmd += ""a1 = R.random_of_dtype(shape=10, dtype=np.%s, bohrium=BH); "" % dtype\n        cmd += ""a2 = np.%s(42); "" % dtype\n        cmd += ""res = a1 %s a2"" % op\n        return cmd\n\n\nclass test_bh_operators_lhs:\n    def init(self):\n        if numpy.__version__ >= ""1.13"":\n            for op in [\'+\', \'-\', \'*\', \'/\', \'//\', \'%\', \'==\', \'<=\', \'>=\', \'!=\', \'<\', \'>\']:\n                for dtype in [\'float64\', \'int64\']:\n                    yield (op, dtype)\n        else:\n            print(""The version of NumPy is too old (<= 1.13), ignoring test"")\n\n    @util.add_bh107_cmd\n    def test_scalar_lhs(self, arg):\n        (op, dtype) = arg\n        cmd = ""R = bh.random.RandomState(42); ""\n        cmd += ""a1 = np.%s(42); "" % dtype\n        cmd += ""a2 = R.random_of_dtype(shape=10, dtype=np.%s, bohrium=BH) + 1; "" % dtype\n        cmd += ""res = a1 %s a2"" % op\n        return cmd\n\n\nclass test_extra_binary_ops:\n    def init(self):\n        for op in [""true_divide"", ""floor_divide""]:\n            for dtype in [""float64"", ""int64"", ""uint64""]:\n                yield (op, dtype)\n\n    @util.add_bh107_cmd\n    def test_ufunc(self, arg):\n        (op, dtype) = arg\n\n        cmd =  ""R = bh.random.RandomState(42); ""\n        cmd += ""a0 = R.random_of_dtype(shape=10, dtype=np.%s, bohrium=BH); "" % dtype\n        cmd += ""a1 = R.random_of_dtype(shape=10, dtype=np.%s, bohrium=BH); "" % dtype\n        cmd += ""res = M.%s(a0, a1)"" % op\n        return cmd\n\n\nclass test_power:\n    def init(self):\n        for op in [""power""]:\n            for dtype in [""float32"", ""float64""]:\n                yield (op, dtype)\n\n    @util.add_bh107_cmd\n    def test_ufunc(self, arg):\n        (op, dtype) = arg\n\n        cmd =  ""R = bh.random.RandomState(42); ""\n        cmd += ""a0 = R.random_of_dtype(shape=10, dtype=np.%s, bohrium=BH); "" % dtype\n        cmd += ""res = M.%s(a0, 1.42)"" % op\n        return cmd\n'"
bridge/npbackend/bohrium/nobh/bincount.py,21,"b'import math\nimport numpy_force as np\nfrom bohrium_api import stack_info\nfrom .. import interop_pyopencl\nfrom .. import interop_pycuda\nfrom .. import array_create\nfrom .bincount_cython import bincount_cython\n\n\ndef bincount(x, weights=None, minlength=None):\n    """"""Count number of occurrences of each value in array of non-negative ints.\n\n    The number of bins (of size 1) is one larger than the largest value in\n    `x`. If `minlength` is specified, there will be at least this number\n    of bins in the output array (though it will be longer if necessary,\n    depending on the contents of `x`).\n    Each bin gives the number of occurrences of its index value in `x`.\n    If `weights` is specified the input array is weighted by it, i.e. if a\n    value ``n`` is found at position ``i``, ``out[n] += weight[i]`` instead\n    of ``out[n] += 1``.\n\n    Parameters\n    ----------\n    x : array_like, 1 dimension, nonnegative ints\n        Input array.\n    weights : array_like, optional\n        Weights, array of the same shape as `x`.\n    minlength : int, optional\n        A minimum number of bins for the output array.\n\n        .. versionadded:: 1.6.0\n\n    Returns\n    -------\n    out : ndarray of ints\n        The result of binning the input array.\n        The length of `out` is equal to ``np.amax(x)+1``.\n\n    Raises\n    ------\n    ValueError\n        If the input is not 1-dimensional, or contains elements with negative\n        values, or if `minlength` is non-positive.\n    TypeError\n        If the type of the input is float or complex.\n\n    See Also\n    --------\n    histogram, digitize, unique\n\n    Examples\n    --------\n    >>> np.bincount(np.arange(5))\n    array([1, 1, 1, 1, 1])\n    >>> np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))\n    array([1, 3, 1, 1, 0, 0, 0, 1])\n\n    >>> x = np.array([0, 1, 1, 3, 2, 1, 7, 23])\n    >>> np.bincount(x).size == np.amax(x)+1\n    True\n\n    The input array needs to be of integer dtype, otherwise a\n    TypeError is raised:\n\n    >>> np.bincount(np.arange(5, dtype=np.float))\n    Traceback (most recent call last):\n      File ""<stdin>"", line 1, in <module>\n    TypeError: array cannot be safely cast to required type\n\n    A possible use of ``bincount`` is to perform sums over\n    variable-size chunks of an array, using the ``weights`` keyword.\n\n    >>> w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # weights\n    >>> x = np.array([0, 1, 1, 2, 2, 2])\n    >>> np.bincount(x,  weights=w)\n    array([ 0.3,  0.7,  1.1])\n\n    """"""\n\n    # Let\'s find the backend to handle the bincount\n    x = array_create.array(x)\n    assert(np.issubdtype(x.dtype.type, np.integer))\n    assert(np.issubdtype(x.dtype.type, np.integer))\n\n    if stack_info.is_proxy_in_stack():  # Cannot directly access array data through a proxy\n        return np.bincount(x.copy2numpy(), weights=weights, minlength=minlength)\n\n    try:\n        if weights is not None:\n            raise NotImplementedError(""OpenCL doesn\'t support the `weights` argument"")\n        return bincount_pyopencl(x, minlength=minlength)\n    except NotImplementedError:\n        try:\n            if weights is not None:\n                raise NotImplementedError(""CUDA doesn\'t support the `weights` argument"")\n            return bincount_pycuda(x, minlength=minlength)\n        except NotImplementedError:\n            try:\n                return bincount_cython(x, weights=weights, minlength=minlength)\n            except NotImplementedError:\n                return np.bincount(x.copy2numpy(), weights=weights, minlength=minlength)\n\n\ndef bincount_pyopencl(x, minlength=None):\n    """"""PyOpenCL implementation of `bincount()`""""""\n\n    if not interop_pyopencl.available():\n        raise NotImplementedError(""OpenCL not available"")\n\n    import pyopencl as cl\n    ctx = interop_pyopencl.get_context()\n    queue = cl.CommandQueue(ctx)\n\n    x_max = int(x.max())\n    if x_max < 0:\n        raise RuntimeError(""bincount(): first argument must be a 1 dimensional, non-negative int array"")\n    if x_max > np.iinfo(np.uint32).max:\n        raise NotImplementedError(""OpenCL: the elements in the first argument must fit in a 32bit integer"")\n    if minlength is not None:\n        x_max = max(x_max, minlength)\n\n    # TODO: handle large max element by running multiple bincount() on a range\n    if x_max >= interop_pyopencl.max_local_memory(queue.device) // x.itemsize:\n        raise NotImplementedError(""OpenCL: max element is too large for the GPU"")\n\n    # Let\'s create the output array and retrieve the in-/output OpenCL buffers\n    # NB: we always return uint32 array\n    ret = array_create.empty((x_max+1, ), dtype=np.uint32)\n    x_buf = interop_pyopencl.get_buffer(x)\n    ret_buf = interop_pyopencl.get_buffer(ret)\n\n    # OpenCL kernel is based on the book ""OpenCL Programming Guide"" by Aaftab Munshi at al.\n    source = """"""\n    kernel void histogram_partial(\n        global DTYPE *input,\n        global uint *partial_histo,\n        uint input_size\n    ){\n        int local_size = (int)get_local_size(0);\n        int group_indx = get_group_id(0) * HISTO_SIZE;\n        int gid = get_global_id(0);\n        int tid = get_local_id(0);\n\n        local uint tmp_histogram[HISTO_SIZE];\n\n        int j = HISTO_SIZE;\n        int indx = 0;\n\n        // clear the local buffer that will generate the partial histogram\n        do {\n            if (tid < j)\n                tmp_histogram[indx+tid] = 0;\n            j -= local_size;\n            indx += local_size;\n        } while (j > 0);\n\n        barrier(CLK_LOCAL_MEM_FENCE);\n\n        if (gid < input_size) {\n            atomic_inc(&tmp_histogram[input[gid]]);\n        }\n\n        barrier(CLK_LOCAL_MEM_FENCE);\n\n        // copy the partial histogram to appropriate location in\n        // histogram given by group_indx\n        if (local_size >= HISTO_SIZE){\n            if (tid < HISTO_SIZE)\n                partial_histo[group_indx + tid] = tmp_histogram[tid];\n        }else{\n            j = HISTO_SIZE;\n            indx = 0;\n            do {\n                if (tid < j)\n                    partial_histo[group_indx + indx + tid] = tmp_histogram[indx + tid];\n\n                j -= local_size;\n                indx += local_size;\n            } while (j > 0);\n        }\n    }\n\n    kernel void histogram_sum_partial_results(\n        global uint *partial_histogram,\n        int num_groups,\n        global uint *histogram\n    ){\n        int gid = (int)get_global_id(0);\n        int group_indx;\n        int n = num_groups;\n        local uint tmp_histogram[HISTO_SIZE];\n\n        tmp_histogram[gid] = partial_histogram[gid];\n        group_indx = HISTO_SIZE;\n        while (--n > 0) {\n            tmp_histogram[gid] += partial_histogram[group_indx + gid];\n            group_indx += HISTO_SIZE;\n        }\n        histogram[gid] = tmp_histogram[gid];\n    }\n    """"""\n    source = source.replace(""HISTO_SIZE"", ""%d"" % ret.shape[0])\n    source = source.replace(""DTYPE"", interop_pyopencl.type_np2opencl_str(x.dtype))\n    prg = cl.Program(ctx, source).build()\n\n    # Calculate sizes for the kernel execution\n    local_size = interop_pyopencl.kernel_info(prg.histogram_partial, queue)[0]  # Max work-group size\n    num_groups = int(math.ceil(x.shape[0] / float(local_size)))\n    global_size = local_size * num_groups\n\n    # First we compute the partial histograms\n    partial_res_g = cl.Buffer(ctx, cl.mem_flags.WRITE_ONLY, num_groups * ret.nbytes)\n    prg.histogram_partial(queue, (global_size,), (local_size,), x_buf, partial_res_g, np.uint32(x.shape[0]))\n\n    # Then we sum the partial histograms into the final histogram\n    prg.histogram_sum_partial_results(queue, ret.shape, None, partial_res_g, np.uint32(num_groups), ret_buf)\n    return ret\n\n\ndef bincount_pycuda(x, minlength=None):\n    """"""PyCUDA implementation of `bincount()`""""""\n\n    if not interop_pycuda.available():\n        raise NotImplementedError(""CUDA not available"")\n\n    import pycuda\n    from pycuda.compiler import SourceModule\n\n    interop_pycuda.init()\n\n    x_max = int(x.max())\n    if x_max < 0:\n        raise RuntimeError(""bincount(): first argument must be a 1 dimensional, non-negative int array"")\n    if x_max > np.iinfo(np.uint32).max:\n        raise NotImplementedError(""CUDA: the elements in the first argument must fit in a 32bit integer"")\n    if minlength is not None:\n        x_max = max(x_max, minlength)\n\n    # TODO: handle large max element by running multiple bincount() on a range\n    if x_max >= interop_pycuda.max_local_memory() // x.itemsize:\n        raise NotImplementedError(""CUDA: max element is too large for the GPU"")\n\n    # Let\'s create the output array and retrieve the in-/output OpenCL buffers\n    # NB: we always return uint32 array\n    ret = array_create.ones((x_max+1, ), dtype=np.uint32)\n    x_buf = interop_pycuda.get_gpuarray(x)\n    ret_buf = interop_pycuda.get_gpuarray(ret)\n\n    # CUDA kernel is based on the book ""OpenCL Programming Guide"" by Aaftab Munshi at al.\n    source = """"""\n    __global__ void histogram_partial(\n        DTYPE *input,\n        uint *partial_histo,\n        uint input_size\n    ){\n        int local_size = blockDim.x;\n        int group_indx = blockIdx.x * HISTO_SIZE;\n        int gid = (blockIdx.x * blockDim.x + threadIdx.x);\n        int tid = threadIdx.x;\n\n        __shared__ uint tmp_histogram[HISTO_SIZE];\n\n        int j = HISTO_SIZE;\n        int indx = 0;\n\n        // clear the local buffer that will generate the partial histogram\n        do {\n            if (tid < j)\n                tmp_histogram[indx+tid] = 0;\n            j -= local_size;\n            indx += local_size;\n        } while (j > 0);\n\n        __syncthreads();\n\n        if (gid < input_size) {\n            atomicAdd(&tmp_histogram[input[gid]], 1);\n        }\n\n        __syncthreads();\n\n        // copy the partial histogram to appropriate location in\n        // histogram given by group_indx\n        if (local_size >= HISTO_SIZE){\n            if (tid < HISTO_SIZE)\n                partial_histo[group_indx + tid] = tmp_histogram[tid];\n        }else{\n            j = HISTO_SIZE;\n            indx = 0;\n            do {\n                if (tid < j)\n                    partial_histo[group_indx + indx + tid] = tmp_histogram[indx + tid];\n\n                j -= local_size;\n                indx += local_size;\n            } while (j > 0);\n        }\n    }\n\n    __global__ void histogram_sum_partial_results(\n        uint *partial_histogram,\n        int num_groups,\n        uint *histogram\n    ){\n        int gid = (blockIdx.x * blockDim.x + threadIdx.x);\n        int group_indx;\n        int n = num_groups;\n        __shared__ uint tmp_histogram[HISTO_SIZE];\n\n        tmp_histogram[gid] = partial_histogram[gid];\n        group_indx = HISTO_SIZE;\n        while (--n > 0) {\n            tmp_histogram[gid] += partial_histogram[group_indx + gid];\n            group_indx += HISTO_SIZE;\n        }\n        histogram[gid] = tmp_histogram[gid];\n    }\n    """"""\n    source = source.replace(""HISTO_SIZE"", ""%d"" % ret.shape[0])\n    source = source.replace(""DTYPE"", interop_pycuda.type_np2cuda_str(x.dtype))\n    prg = SourceModule(source)\n\n    # Calculate sizes for the kernel execution\n    kernel = prg.get_function(""histogram_partial"")\n    local_size = kernel.get_attribute(pycuda.driver.function_attribute.MAX_THREADS_PER_BLOCK)  # Max work-group size\n    num_groups = int(math.ceil(x.shape[0] / float(local_size)))\n    global_size = local_size * num_groups\n\n    # First we compute the partial histograms\n    partial_res_g = pycuda.driver.mem_alloc(num_groups * ret.nbytes)\n    kernel(x_buf, partial_res_g, np.uint32(x.shape[0]), block=(local_size, 1, 1), grid=(num_groups, 1))\n\n    # Then we sum the partial histograms into the final histogram\n    kernel = prg.get_function(""histogram_sum_partial_results"")\n    kernel(partial_res_g, np.uint32(num_groups), ret_buf, block=(1, 1, 1), grid=(ret.shape[0], 1))\n    return ret  \n\n\n'"
