file_path,api_count,code
COMPARISON_MODELS/MLP.py,4,"b'import numpy as np\r\nimport sklearn.neural_network\r\nimport pandas\r\nfrom sklearn.metrics import mean_squared_error\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\n\r\nxs =pandas.read_csv(""data.csv"", usecols =[""field_soil_temp_c"",""field_air_temp_c"",""field_rh""],dtype=np.float64)\r\nys = pandas.read_csv(""data.csv"", usecols =[""field_soil_wc""],dtype=np.float64).values.ravel()\r\n\r\n\r\nmodel=sklearn.neural_network.MLPRegressor(\r\n    activation=\'logistic\',\r\n    learning_rate_init=0.001,\r\n    solver=\'sgd\',\r\n    learning_rate=\'invscaling\',\r\n    hidden_layer_sizes=(200,),\r\n    verbose=True,\r\n    max_iter=2000,\r\n    tol=1e-6\r\n)\r\n\r\nx=model.fit(xs,ys)\r\nprint(\'Accuracy training : {:.3f}\'.format(model.score(xs, ys)))\r\nprint(\'\\nprediction:\')\r\npredicted_scale=model.predict(xs)\r\nprint(predicted_scale)\r\nprint(""RMSE"", mean_squared_error(ys,predicted_scale))\r\np1=np.polyfit(predicted_scale,ys,1)\r\nplt.plot(np.polyval(p1,predicted_scale),predicted_scale,\'r--\',label=\'Expected_Output\')\r\nplt.xlabel(\'target\')\r\nplt.ylabel(\'output\')\r\n#plt.ylim((0,1))\r\nplt.scatter(ys,predicted_scale)\r\nplt.plot(ys,ys,label=\'Output\')\r\nplt.legend(loc=\'upper left\')\r\nplt.show()'"
COMPARISON_MODELS/sequential.py,3,"b'from keras.models import Sequential\r\nfrom keras.layers.core import Dense , Dropout , Activation\r\nfrom keras.optimizers import SGD\r\nimport numpy as np\r\nimport pandas \r\nimport matplotlib.pyplot as plt\r\n\r\nX =pandas.read_csv(""data.csv"", usecols =[""field_soil_temp_c"",""field_air_temp_c"",""field_rh""])\r\nY = pandas.read_csv(""data.csv"", usecols =[""field_soil_wc""])\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(8, input_dim=3))\r\nmodel.add(Activation(\'tanh\'))\r\nmodel.add(Dense(1))\r\nmodel.add(Activation(\'sigmoid\'))\r\n\r\nsgd = SGD(lr=0.6, momentum=0.6)\r\nmodel.compile(loss= \'mean_squared_error\', optimizer=sgd)\r\n\r\nmodel.fit(X,Y,verbose=1,batch_size=4,nb_epoch=100)\r\nprint(model.predict_proba(X))\r\nloss = np.subtract(Y,model.predict_proba(X))\r\nprint(\'Loss:\\n\',loss)\r\nsquare= np.square(loss)\r\nRMSE=np.std(square)\r\nprint(\'\\nRMSE:\',RMSE)\r\n\r\nplt.xlabel(\'target\')\r\nplt.ylabel(\'output\')\r\n#plt.ylim((0,1))\r\nplt.scatter(Y,model.predict(X))\r\nplt.plot(Y,Y)\r\nplt.show()'"
COMPARISON_MODELS/svm.py,3,"b'import numpy as np\r\nfrom sklearn.svm import SVR\r\nimport pandas\r\nfrom sklearn.metrics import mean_squared_error\r\nimport matplotlib.pyplot as plt\r\n\r\ndataset1= pandas.read_csv(""data.csv"")\r\n\r\nX=dataset1.iloc[:,:-1].values # REJECTING THE LAST COLUMN\r\ny=dataset1.iloc[:,3].values\r\n\r\nfrom sklearn.model_selection import train_test_split  \r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\r\n\r\nsvr_poly = SVR(kernel=\'poly\', C=1e3, degree=2)\r\n\r\n\r\nfrom sklearn.preprocessing import StandardScaler \r\nscaler = StandardScaler()  \r\nscaler.fit(X_train)\r\n\r\nX_train = scaler.transform(X_train)  \r\nX_test = scaler.transform(X_test) \r\n\r\ny_poly = svr_poly.fit(X_train, y_train).predict(X_test)\r\n\r\n\r\nprint(""\\n||MODEL SCORE||\\n"")\r\nprint(\'MODEL_POLY:\',svr_poly.score(X_train,y_train))\r\n\r\nz=np.std(np.square(np.subtract(y_test,y_poly)))\r\n\r\nprint(""\\n||MODEL RMSE||\\n"")\r\nprint(\'RMSE_POLY::\',z)\r\np1=np.polyfit(y_poly,y_test,1)\r\nplt.plot(y_poly,np.polyval(p1,y_poly),\'r:\',label=\'Expected_Output\')\r\nplt.xlabel(\'target\')\r\nplt.ylabel(\'output\')\r\n#plt.ylim((0,1))\r\nplt.scatter(y_test,y_poly)\r\nplt.plot(y_test,y_test,label=\'Output\')\r\nplt.legend(loc=\'upper left\')\r\nplt.show()'"
DE_MODEL/driver.py,21,"b'import numpy as np\r\nimport csv\r\nimport math\r\nimport matplotlib.pyplot as plt\r\n\r\nfeature_1 = feature_2 = feature_3 = expected_output = np.zeros((2024))\r\ni = 0\r\nwith open(\'data.csv\') as csvfile:\r\n\treader = csv.DictReader(csvfile)\r\n\tfor row in reader:\r\n\t\tfeature_1[i] = float(row[\'field_soil_temp_c\'])\r\n\t\tfeature_2[i] = float(row[\'field_air_temp_c\'])\r\n\t\tfeature_3[i] = float(row[\'field_rh\'])\r\n\t\texpected_output[i] = float(row[\'field_soil_wc\']) \r\n\t\ti = i + 1\r\n\r\ndef obj(array_of_weights, nodes_in_hidden_layer):\r\n\tann_outputs = np.zeros(2024)\r\n\tann_outputs = ann(array_of_weights, nodes_in_hidden_layer)\r\n\tfor i in range(0, 2024):\r\n\t\tann_outputs[i]=(expected_output[i]-ann_outputs[i])*(expected_output[i]-ann_outputs[i])\r\n\trmse=math.sqrt(np.sum(ann_outputs)/2024)\r\n\treturn rmse\r\n\r\ndef ann(array_of_weights, nodes_in_hidden_layer):\r\n\tann_outputs = np.zeros(2024)\r\n\tfor j in range(0, 2024):\t\r\n\t\tnode = np.zeros(nodes_in_hidden_layer + 4)\r\n\t\tnode[0] = feature_1[j]\r\n\t\tnode[1] = feature_2[j]\r\n\t\tnode[2] = feature_3[j]\r\n\t\tweight_number = 0\r\n\t\tfor i in range(3, (nodes_in_hidden_layer + 3)):\r\n\t\t\tnode[i] = (node[0] * array_of_weights[weight_number]) + (node[1] * array_of_weights[weight_number + nodes_in_hidden_layer]) + (node[2] * array_of_weights[weight_number + 2 * nodes_in_hidden_layer])\r\n\t\t\tweight_number+=1\r\n\t\tfor i in range(3, (nodes_in_hidden_layer + 3)):\r\n\t\t\tnode[nodes_in_hidden_layer + 3] = node[nodes_in_hidden_layer + 3] + (node[i] * array_of_weights[weight_number])\r\n\t\t\tweight_number+=1\r\n\t\tann_outputs[j] = node[nodes_in_hidden_layer + 3]\r\n\t\t#ann_outputs[j] = 1/(1+np.exp(-ann_outputs[j]))\r\n\treturn ann_outputs\r\n\r\ndef de(bounds, popsize, hidden_nodes, mut=0.8, crossp=0.7, its=50):\r\n\tdimensions = len(bounds)\r\n\tpop = np.random.rand(popsize, dimensions)\r\n\tmin_b, max_b = np.asarray(bounds).T\r\n\tdiff = np.fabs(min_b - max_b)\r\n\tpop_denorm = min_b + pop * diff\r\n\tfitness = np.asarray([obj(ind,hidden_nodes) for ind in pop_denorm])\r\n\tbest_idx = np.argmin(fitness)\r\n\tbest = pop_denorm[best_idx]\r\n\tret_fit = np.zeros(its)\r\n\tfor i in range(its):\r\n\t\tprint(i)\r\n\t\tfor j in range(popsize):\r\n\t\t\tidxs = [idx for idx in range(popsize) if idx != j]\r\n\t\t\ta, b, c = pop[np.random.choice(idxs, 3, replace = False)]\r\n\t\t\tmutant = np.clip(a + mut * (b - c), 0, 1)\r\n\t\t\tcross_points = np.random.rand(dimensions) < crossp\r\n\t\t\tif not np.any(cross_points):\r\n\t\t\t\tcross_points[np.random.randint(0, dimensions)] = True\r\n\t\t\ttrial = np.where(cross_points, mutant, pop[j])\r\n\t\t\ttrial_denorm = min_b + trial * diff\r\n\t\t\tf = obj(trial_denorm,hidden_nodes)\r\n\t\t\tif f < fitness[j]:\r\n\t\t\t\tfitness[j] = f\r\n\t\t\t\tpop[j] = trial\r\n\t\t\t\tif f < fitness[best_idx]:\r\n\t\t\t\t\tbest_idx = j\r\n\t\t\t\t\tbest = trial_denorm\r\n\t\tret_fit[i]=fitness[best_idx];\r\n\treturn ret_fit, best\r\n\r\n\r\nnumber_of_ann = int(input(""Enter the number of ANNs : ""))\r\nnodes_in_hidden_layer = int(input(""Enter the number of nodes in hidden layer : ""))\r\n\r\nf,b = de(bounds=[(-5,5)] * (3 * nodes_in_hidden_layer + nodes_in_hidden_layer) , popsize=number_of_ann, hidden_nodes=nodes_in_hidden_layer)\r\nprint(b)\r\nplt.xlabel(\'ITERATION\')\r\nplt.ylabel(\'FITNESS\')\r\nplt.title(\'Evolution of fitness on 50 iterations\')\r\nplt.grid()\r\nplt.plot(f)\r\nplt.show()\r\noutput = ann(b, nodes_in_hidden_layer)\r\nplt.xlabel(\'target\')\r\nplt.ylabel(\'output\')\r\np1=np.polyfit(expected_output,output,1)\r\nplt.plot(np.polyval(p1,output),output,\'r:\',label=\'Expected_Output\')\r\nplt.plot(np.polyval(p1,output),output,\'r:\')\r\nplt.scatter(expected_output, output)\r\nplt.plot(expected_output,expected_output,label=\'Output\')\r\nplt.legend(loc=\'upper left\')\r\nplt.show()\r\n'"
