file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\nfrom setuptools import setup, find_packages, Extension\nimport os\nimport subprocess\nimport sys\nimport glob\nimport numpy\n\n\ndef package_files(directory):\n    paths = []\n    for (path, directories, filenames) in os.walk(directory):\n        for filename in filenames:\n            if \'.so\' in filename:\n                paths.append(os.path.join(path, filename))\n    return paths\n\n\ndef cmake_build():\n    import re\n    c_bind_re = re.compile(""--c_binding=*"")\n    try:\n        c_binding_path_opt = next(arg for arg in sys.argv if (re.match(""--c_binding=*"", arg)))\n        c_binding_path = re.search(""--c_binding=(.*)"", c_binding_path_opt).groups()[0]\n        sys.argv.remove(c_binding_path_opt)\n    except (IndexError, StopIteration):\n        c_binding_path=None\n\n    try:\n        cmake_args=[""cmake"", ""-H./hecuba_core"", ""-B./build""]\n        if c_binding_path:\n            cmake_args=cmake_args + [ ""-DC_BINDING_INSTALL_PREFIX={}"".format(c_binding_path)]\n        if subprocess.call(cmake_args) != 0:\n            raise EnvironmentError(""error calling cmake"")\n    except OSError as e:\n        if e.errno == os.errno.ENOENT:\n            # CMake not found error.\n            raise OSError(os.errno.ENOENT, os.strerror(os.errno.ENOENT), \'cmake\')\n        else:\n            # Different error\n            raise e\n\n    if subprocess.call([""make"", ""-j4"", ""-C"", ""./build""]) != 0:\n        raise EnvironmentError(""error calling make build"")\n\n    if c_binding_path and subprocess.call([""make"", ""-j4"", ""-C"", ""./build"", ""install""]) != 0:\n        raise EnvironmentError(""error calling make install"")\n\ndef get_var(var):\n    value = os.environ.get(var,\'\')\n    return [p for p in value.split(\':\') if p != \'\']\n\n\nPATH_LIBS = get_var(\'LD_LIBRARY_PATH\')\nPATH_INCLUDE = get_var(\'CPATH\') + get_var(\'CPLUS_INCLUDE_PATH\') + get_var(\'C_INCLUDE_PATH\')\n\nextensions = [\n    Extension(\n        ""hfetch"",\n        sources=glob.glob(""hecuba_core/src/py_interface/*.cpp""),\n        include_dirs=[\'hecuba_core/src/\', \'build/include\', numpy.get_include()] + PATH_INCLUDE,\n        libraries=[\'hfetch\', \'cassandra\'],\n        library_dirs=[\'build/lib\', \'build/lib64\'] + PATH_LIBS,\n        extra_compile_args=[\'-std=c++11\'],\n        extra_link_args=[\'-Wl,-rpath=$ORIGIN\']\n    ),\n]\n\n\ndef setup_packages():\n    # We first build C++ libraries\n    if \'build\' in sys.argv:\n        cmake_build()\n\n    extra_files = package_files(\'build/lib\') + package_files(\'build/lib64\')\n\n    # TODO use some flag to detect that build has already been done instead of this\n    if \'install\' in sys.argv:\n        cmake_build()\n        extra_files = package_files(\'build/lib\') + package_files(\'build/lib64\')\n\n    # compute which libraries were built\n    metadata = dict(name=""Hecuba"",\n                    version=""0.1.3.post1"",\n                    package_dir={\'hecuba\': \'hecuba_py/hecuba\', \'storage\': \'storageAPI/storage\'},\n                    packages=[\'hecuba\', \'storage\'],  # find_packages(),\n                    install_requires=[\'cassandra-driver>=3.7.1\', \'numpy>=1.16\'],\n                    zip_safe=False,\n                    data_files=[(\'\', extra_files)],\n\n                    # metadata for upload to PyPI\n                    license=""Apache License Version 2.0"",\n                    keywords=""key-value, scientific computing"",\n                    description=\'Hecuba\',\n                    author=\'Guillem Alomar, Yolanda Becerra, Cesare Cugnasco, Adri\xc3\xa1n Espejo, Pol Santamaria\',\n                    author_email=\'yolanda.becerra@bsc.es,cesare.cugnasco@bsc.es\',\n                    url=\'https://www.bsc.es\',\n                    long_description=\'\'\'Hecuba.\'\'\',\n                    #   test_suite=\'nose.collector\',\n                    #    tests_require=[\'nose\'],\n                    ext_modules=extensions\n\n                    )\n\n    setup(**metadata)\n    return\n\n\nif __name__ == \'__main__\':\n    setup_packages()\n'"
hecuba_py/hecuba/IStorage.py,0,"b'import uuid\nfrom . import log\nfrom .tools import extract_ks_tab, build_remotely, storage_id_from_name, get_istorage_attrs, generate_token_ring_ranges\n\n\nclass AlreadyPersistentError(RuntimeError):\n    pass\n\n\nclass IStorage(object):\n\n    @property\n    def storage_id(self):\n        return self.__storage_id\n\n    @storage_id.setter\n    def storage_id(self, st_id):\n        if st_id is not None and not isinstance(st_id, uuid.UUID):\n            raise TypeError(""Storage ID must be an instance of UUID"")\n        self.__storage_id = st_id\n\n    def __init__(self, *args, **kwargs):\n        super().__init__()\n        self._ksp = None\n        self._table = None\n        given_name = kwargs.pop(""name"", None)\n        if given_name:\n            self._ksp, self._table = extract_ks_tab(given_name)\n            name = self._ksp + \'.\' + self._table\n            self._set_name(name)\n\n        if not getattr(self, ""storage_id"", None):\n            self.storage_id = kwargs.pop(""storage_id"", None)\n        self._built_remotely = kwargs.pop(""built_remotely"", False)\n        self._tokens = kwargs.pop(""tokens"", None)\n        self._is_persistent = False\n\n    @classmethod\n    def get_by_alias(cls, alias=""""):\n        return cls(name=alias)\n\n    def __eq__(self, other):\n        """"""\n        Method to compare a IStorage object with another one.\n        Args:\n            other: IStorage to be compared with.\n        Returns:\n            boolean (true - equals, false - not equals).\n        """"""\n        return self.__class__ == other.__class__ and self.storage_id == other.storage_id\n\n    def make_persistent(self, name):\n        if self._is_persistent:\n            raise AlreadyPersistentError(""This Object is already persistent [Before:{}.{}][After:{}]"",\n                                         self._ksp, self._table, name)\n\n        self._ksp, self._table = extract_ks_tab(name)\n        name = self._ksp + \'.\' + self._table\n        self._set_name(name)\n\n        if not self.storage_id:\n            self.storage_id = storage_id_from_name(name)\n\n        # If found data, replace the constructor data\n        if self._tokens is None:\n            metas = get_istorage_attrs(self.storage_id)\n            try:\n                self._tokens = metas[0].tokens\n            except IndexError:\n                self._tokens = generate_token_ring_ranges()\n\n        self._is_persistent = True\n\n    def stop_persistent(self):\n        if not self._is_persistent:\n            raise RuntimeError(""This Object is not persistent"")\n\n        self._is_persistent = False\n\n    def delete_persistent(self):\n        if not self._is_persistent:\n            raise RuntimeError(""This Object is not persistent"")\n\n        self._is_persistent = False\n\n    def _set_name(self, name):\n        if not isinstance(name, str):\n            raise TypeError(""Name -{}-  should be an instance of str"".format(str(name)))\n        self._name = name\n\n    def _get_name(self):\n        try:\n            return self._name\n        except AttributeError:\n            return \'\'\n\n    def _flush_to_storage(self):\n        if not self._is_persistent:\n            raise RuntimeError(""Can\'t send the data to storage if the object is not persistent"")\n\n    def getID(self):\n        """"""\n        Method to retrieve the storage id as string. Used by PyCOMPSs solely.\n        :return: Storage_id as str\n        """"""\n        return str(self.storage_id)\n\n    def split(self):\n        """"""\n        Method used to divide an object into sub-objects.\n        Returns:\n            a subobject everytime is called\n        """"""\n        from .tools import tokens_partitions\n        try:\n            tokens = self._build_args.tokens\n        except AttributeError as ex:\n            raise RuntimeError(""Object {} does not have tokens"".format(self._get_name()))\n\n        self._flush_to_storage()\n\n        for token_split in tokens_partitions(self._ksp, self._table, tokens):\n            storage_id = uuid.uuid4()\n            log.debug(\'assigning to {} num tokens {}\'.format(str(storage_id), len(token_split)))\n            new_args = self._build_args._replace(tokens=token_split, storage_id=storage_id)\n            args_dict = new_args._asdict()\n            args_dict[""built_remotely""] = True\n            yield build_remotely(args_dict)\n'"
hecuba_py/hecuba/__init__.py,0,"b'import logging\nimport os\n\nfrom cassandra.cluster import Cluster\nfrom cassandra.policies import RetryPolicy, RoundRobinPolicy, TokenAwarePolicy\n\n# Set default log.handler to avoid ""No handler found"" warnings.\n\nstderrLogger = logging.StreamHandler()\nf = \'%(filename)s: %(levelname)s: %(funcName)s(): %(lineno)d:\\t%(message)s\'\nstderrLogger.setFormatter(logging.Formatter(f))\n\nlog = logging.getLogger(\'hecuba\')\nlog.addHandler(stderrLogger)\n\nif \'DEBUG\' in os.environ and os.environ[\'DEBUG\'].lower() == ""true"":\n    log.setLevel(logging.DEBUG)\nelif \'HECUBA_LOG\' in os.environ:\n    log.setLevel(os.environ[\'HECUBA_LOG\'].upper())\nelse:\n    log.setLevel(logging.ERROR)\n\n\nclass _NRetry(RetryPolicy):\n    def __init__(self, time_to_retry=5):\n        self.time_to_retry = time_to_retry\n\n    def on_unavailable(self, query, consistency, required_replicas, alive_replicas, retry_num):\n        if retry_num > self.time_to_retry:\n            return self.RETHROW, None\n        else:\n            return self.RETHROW, None\n\n    def on_write_timeout(self, query, consistency, write_type, required_responses, received_responses, retry_num):\n        if retry_num > self.time_to_retry:\n            return self.RETHROW, None\n        else:\n            return self.RETHROW, None\n\n    def on_read_timeout(self, query, consistency, required_responses, received_responses, data_retrieved, retry_num):\n        if retry_num > self.time_to_retry:\n            return self.RETHROW, None\n        else:\n            return self.RETHROW, None\n\n\nclass Config:\n    class __Config:\n        def __init__(self):\n            self.configured = False\n\n    instance = __Config()\n\n    def __getattr__(self, item):\n        return getattr(Config.instance, item)\n\n    def __init__(self):\n        singleton = Config.instance\n        if singleton.configured:\n            log.info(\'setting down\')\n            return\n\n        singleton.configured = True\n\n        if \'CREATE_SCHEMA\' in os.environ:\n            singleton.id_create_schema = int(os.environ[\'CREATE_SCHEMA\'])\n        else:\n            singleton.id_create_schema = -1\n\n        try:\n            singleton.nodePort = int(os.environ[\'NODE_PORT\'])\n            log.info(\'NODE_PORT: %d\', singleton.nodePort)\n        except KeyError:\n            log.warn(\'using default NODE_PORT 9042\')\n            singleton.nodePort = 9042\n\n        try:\n            singleton.contact_names = os.environ[\'CONTACT_NAMES\'].split("","")\n            log.info(\'CONTACT_NAMES: %s\', str.join("" "", singleton.contact_names))\n        except KeyError:\n            log.warn(\'using default contact point localhost\')\n            singleton.contact_names = [\'127.0.0.1\']\n\n        if hasattr(singleton, \'session\'):\n            log.warn(\'Shutting down pre-existent sessions and cluster\')\n            try:\n                singleton.session.shutdown()\n                singleton.cluster.shutdown()\n            except Exception:\n                log.warn(\'error shutting down\')\n        try:\n            singleton.replication_factor = int(os.environ[\'REPLICA_FACTOR\'])\n            log.info(\'REPLICA_FACTOR: %d\', singleton.replication_factor)\n        except KeyError:\n            singleton.replication_factor = 1\n            log.warn(\'using default REPLICA_FACTOR: %d\', singleton.replication_factor)\n\n        try:\n            user_defined_execution_name = os.environ[\'EXECUTION_NAME\']\n            if user_defined_execution_name == \'hecuba\':\n                raise RuntimeError(\'Error: the application keyspace cannot be \\\'hecuba\\\'. \'\n                                   \'This keyspace is reserved for storing metadata.\')\n            singleton.execution_name = user_defined_execution_name\n            log.info(\'EXECUTION_NAME: %s\', singleton.execution_name)\n        except KeyError:\n            singleton.execution_name = \'my_app\'\n            log.warn(\'using default EXECUTION_NAME: %s\', singleton.execution_name)\n        try:\n            singleton.splits_per_node = int(os.environ[\'SPLITS_PER_NODE\'])\n            log.info(\'SPLITS_PER_NODE: %d\', singleton.splits_per_node)\n        except KeyError:\n            singleton.splits_per_node = 32\n            log.warn(\'using default SPLITS_PER_NODE: %d\', singleton.splits_per_node)\n\n        try:\n            singleton.token_range_size = int(os.environ[\'TOKEN_RANGE_SIZE\'])\n            log.info(\'TOKEN_RANGE_SIZE: %d\', singleton.token_range_size)\n            singleton.target_token_range_size = None\n        except KeyError:\n            singleton.token_range_size = None\n\n            try:\n                singleton.target_token_range_size = int(os.environ[\'TARGET_TOKEN_RANGE_SIZE\'])\n                log.info(\'TARGET_TOKEN_RANGE_SIZE: %d\', singleton.target_token_range_size)\n            except KeyError:\n                singleton.target_token_range_size = 64 * 1024\n                log.warn(\'using default TARGET_TOKEN_RANGE_SIZE: %d\', singleton.target_token_range_size)\n\n        try:\n            singleton.max_cache_size = int(os.environ[\'MAX_CACHE_SIZE\'])\n            log.info(\'MAX_CACHE_SIZE: %d\', singleton.max_cache_size)\n        except KeyError:\n            singleton.max_cache_size = 1000\n            log.warn(\'using default MAX_CACHE_SIZE: %d\', singleton.max_cache_size)\n\n        try:\n            singleton.replication_strategy = os.environ[\'REPLICATION_STRATEGY\']\n            log.info(\'REPLICATION_STRATEGY: %s\', singleton.replication_strategy)\n        except KeyError:\n            singleton.replication_strategy = ""SimpleStrategy""\n            log.warn(\'using default REPLICATION_STRATEGY: %s\', singleton.replication_strategy)\n\n        try:\n            singleton.replication_strategy_options = os.environ[\'REPLICATION_STRATEGY_OPTIONS\']\n            log.info(\'REPLICATION_STRATEGY_OPTIONS: %s\', singleton.replication_strategy_options)\n        except KeyError:\n            singleton.replication_strategy_options = """"\n            log.warn(\'using default REPLICATION_STRATEGY_OPTIONS: %s\', singleton.replication_strategy_options)\n\n        if singleton.replication_strategy is ""SimpleStrategy"":\n            singleton.replication = ""{\'class\' : \'SimpleStrategy\', \'replication_factor\': %d}"" % \\\n                                    singleton.replication_factor\n        else:\n            singleton.replication = ""{\'class\' : \'%s\', %s}"" % (\n                singleton.replication_strategy, singleton.replication_strategy_options)\n        try:\n            singleton.hecuba_print_limit = int(os.environ[\'HECUBA_PRINT_LIMIT\'])\n            log.info(\'HECUBA_PRINT_LIMIT: %s\', singleton.hecuba_print_limit)\n        except KeyError:\n            singleton.hecuba_print_limit = 1000\n            log.warn(\'using default HECUBA_PRINT_LIMIT: %s\', singleton.hecuba_print_limit)\n\n        try:\n            singleton.prefetch_size = int(os.environ[\'PREFETCH_SIZE\'])\n            log.info(\'PREFETCH_SIZE: %s\', singleton.prefetch_size)\n        except KeyError:\n            singleton.prefetch_size = 10000\n            log.warn(\'using default PREFETCH_SIZE: %s\', singleton.prefetch_size)\n\n        try:\n            singleton.write_buffer_size = int(os.environ[\'WRITE_BUFFER_SIZE\'])\n            log.info(\'WRITE_BUFFER_SIZE: %s\', singleton.write_buffer_size)\n        except KeyError:\n            singleton.write_buffer_size = 1000\n            log.warn(\'using default WRITE_BUFFER_SIZE: %s\', singleton.write_buffer_size)\n\n        try:\n            singleton.write_callbacks_number = int(os.environ[\'WRITE_CALLBACKS_NUMBER\'])\n            log.info(\'WRITE_CALLBACKS_NUMBER: %s\', singleton.write_callbacks_number)\n        except KeyError:\n            singleton.write_callbacks_number = 16\n            log.warn(\'using default WRITE_CALLBACKS_NUMBER: %s\', singleton.write_callbacks_number)\n\n        try:\n            env_var = os.environ[\'TIMESTAMPED_WRITES\'].lower()\n            singleton.timestamped_writes = False if env_var == \'no\' or env_var == \'false\' else True\n            log.info(\'TIMESTAMPED WRITES ENABLED? {}\'.format(singleton.timestamped_writes))\n        except KeyError:\n            singleton.timestamped_writes = True\n            log.warn(\'using default TIMESTAMPED_WRITES: %s\', singleton.timestamped_writes)\n\n        if singleton.max_cache_size < singleton.write_buffer_size:\n            import warnings\n            message = ""Defining a MAX_CACHE_SIZE smaller than WRITE_BUFFER_SIZE can result "" \\\n                      ""in reading outdated results from the persistent storage""\n            warnings.warn(message)\n\n        log.info(\'Initializing global session\')\n\n        singleton.cluster = Cluster(contact_points=singleton.contact_names,\n                                    load_balancing_policy=TokenAwarePolicy(RoundRobinPolicy()),\n                                    port=singleton.nodePort,\n                                    default_retry_policy=_NRetry(5))\n        singleton.session = singleton.cluster.connect()\n        singleton.session.encoder.mapping[tuple] = singleton.session.encoder.cql_encode_tuple\n        if singleton.id_create_schema == -1:\n            queries = [\n                ""CREATE KEYSPACE IF NOT EXISTS hecuba  WITH replication = %s"" % singleton.replication,\n                """"""CREATE TYPE IF NOT EXISTS hecuba.q_meta(\n                mem_filter text, \n                from_point frozen<list<double>>,\n                to_point frozen<list<double>>,\n                precision float);\n                """""",\n                """"""CREATE TYPE IF NOT EXISTS hecuba.np_meta (flags int, elem_size int, partition_type tinyint,\n                dims list<int>, strides list<int>, typekind text, byteorder text)"""""",\n                """"""CREATE TABLE IF NOT EXISTS hecuba\n                .istorage (storage_id uuid, \n                class_name text,name text, \n                istorage_props map<text,text>, \n                tokens list<frozen<tuple<bigint,bigint>>>,\n                indexed_on list<text>,\n                qbeast_random text,\n                qbeast_meta frozen<q_meta>,\n                numpy_meta frozen<np_meta>,\n                block_id int,\n                base_numpy uuid,\n                primary_keys list<frozen<tuple<text,text>>>,\n                columns list<frozen<tuple<text,text>>>,\n                PRIMARY KEY(storage_id));\n                """"""]\n            for query in queries:\n                try:\n                    singleton.session.execute(query)\n                except Exception as e:\n                    log.error(""Error executing query %s"" % query)\n                    raise e\n\n        from hfetch import connectCassandra, HArrayMetadata\n        # connecting c++ bindings\n        connectCassandra(singleton.contact_names, singleton.nodePort)\n\n        singleton.cluster.register_user_type(\'hecuba\', \'np_meta\', HArrayMetadata)\n\n\nglobal config\nconfig = Config()\n\nfrom .parser import Parser\nfrom .storageobj import StorageObj\nfrom .hdict import StorageDict\nfrom .hnumpy import StorageNumpy\nfrom .hfilter import hfilter\n\nif not filter == hfilter:\n    import builtins\n\n    builtins.python_filter = filter\n    builtins.filter = hfilter\n\n__all__ = [\'StorageObj\', \'StorageDict\', \'StorageNumpy\', \'Parser\']\n'"
hecuba_py/hecuba/hdict.py,3,"b'import uuid\nfrom collections import Iterable, defaultdict\nfrom collections import Mapping\nfrom collections import namedtuple\n\nfrom cassandra import OperationTimedOut\n\nimport numpy as np\nfrom . import config, log, Parser\nfrom .storageiter import NamedItemsIterator, NamedIterator\nfrom .hnumpy import StorageNumpy\nfrom hfetch import Hcache\n\nfrom .IStorage import IStorage\nfrom .tools import get_istorage_attrs, count_name_collision, build_remotely, basic_types, _min_token, _max_token\n\n\nclass EmbeddedSet(set):\n    \'\'\'\n    father is the dictionary containing the set\n    keys are the keys names of the set in the dictionary\n    values is the initializing set\n    \'\'\'\n\n    def __init__(self, father, keys, values=None):\n        super(EmbeddedSet, self).__init__()\n        self._father = father\n        self._keys = keys\n        if values is not None:\n            if len(self) != 0:\n                self.clear()\n            if isinstance(values, set):\n                for value in values:\n                    self.add(value)\n            else:\n                raise Exception(""Set expected."")\n\n    def add(self, value):\n        keys = self._keys[:]\n        if not isinstance(value, Iterable) or isinstance(value, str):\n            keys.append(value)\n        else:\n            keys += list(value)\n        return self._father.__setitem__(keys, [])\n\n    def remove(self, value):\n        if value in self:\n            keys = self._keys[:]\n            if not isinstance(value, Iterable) or isinstance(value, str):\n                keys.append(value)\n            else:\n                keys += list(value)\n            return self._father.__delitem__(keys)\n        else:\n            raise KeyError\n\n    def discard(self, value):\n        try:\n            if value in self:\n                keys = self._keys[:]\n                if not isinstance(value, Iterable) or isinstance(value, str):\n                    keys.append(value)\n                else:\n                    keys += list(value)\n                return self._father.__delitem__(keys)\n        except KeyError as ex:\n            pass\n\n    def __len__(self):\n        query = ""SELECT COUNT(*) FROM %s.%s WHERE "" % (self._father._ksp, self._father._table)\n        query = \'\'.join([query, self._join_keys_query()])\n\n        try:\n            result = config.session.execute(query)\n            return result[0][0]\n        except Exception as ir:\n            log.error(""Unable to execute %s"", query)\n            raise ir\n\n    def __contains__(self, value):\n        keys = self._keys[:]\n        if not isinstance(value, Iterable) or isinstance(value, str):\n            keys.append(value)\n        else:\n            keys += list(value)\n        return self._father.__contains__(keys)\n\n    def __iter__(self):\n        keys_set = """"\n        for key in self._father._get_set_types():\n            keys_set += key[0] + "", ""\n        query = ""SELECT %s FROM %s.%s WHERE "" % (keys_set[:-2], self._father._ksp, self._father._table)\n        query = \'\'.join([query, self._join_keys_query()])\n\n        try:\n            result = config.session.execute(query)\n            if len(self._father._get_set_types()) == 1:\n                result = map(lambda x: x[0], result)\n            else:\n                result = map(lambda x: tuple(x), result)\n            return iter(result)\n        except Exception as ir:\n            log.error(""Unable to execute %s"", query)\n            raise ir\n\n    def _join_keys_query(self):\n        keys = []\n        for pkey, key in zip(self._father._primary_keys, self._keys):\n            if pkey[""type""] == ""text"":\n                actual_key = ""\'%s\'"" % key\n            else:\n                actual_key = ""%s"" % key\n            keys.append("" = "".join([pkey[""name""], actual_key]))\n        all_keys = "" and "".join(keys)\n\n        return all_keys\n\n    def union(self, *others):\n        result = set()\n        for value in self:\n            result.add(value)\n        for other in others:\n            for value in other:\n                result.add(value)\n        return result\n\n    def intersection(self, *others):\n        result = set()\n        for value in self:\n            in_all_others = True\n            for other in others:\n                try:\n                    if value not in other:\n                        in_all_others = False\n                        break\n                except KeyError:\n                    in_all_others = False\n                    break\n            if in_all_others:\n                result.add(value)\n        return result\n\n    def difference(self, *others):\n        result = set()\n        for value in self:\n            in_any_other = False\n            for other in others:\n                try:\n                    if value in other:\n                        in_any_other = True\n                        break\n                except KeyError:\n                    pass\n            if not in_any_other:\n                result.add(value)\n        return result\n\n    def update(self, *others):\n        for other in others:\n            for value in other:\n                self.add(value)\n        return self\n\n    def issubset(self, other):\n        if len(self) > len(other):\n            return False\n        for value in self:\n            if value not in other:\n                return False\n        return True\n\n    def issuperset(self, other):\n        if len(self) < len(other):\n            return False\n        for value in other:\n            if value not in self:\n                return False\n        return True\n\n    def __eq__(self, other):\n        return self._father.__eq__(other._father) and self._keys == other._keys\n\n    def __ne__(self, other):\n        return not (self.__eq__(other))\n\n    def __lt__(self, other):\n        return self.__ne__(other) and self.issubset(other)\n\n    def __le__(self, other):\n        return self.issubset(other)\n\n    def __gt__(self, other):\n        return self.__ne__(other) and self.issuperset(other)\n\n    def __ge__(self, other):\n        return self.issuperset(other)\n\n    def clear(self):\n        for value in self._father[tuple(self._keys)]:\n            self.remove(value)\n\n\nclass StorageDict(IStorage, dict):\n    # """"""\n    # Object used to access data from workers.\n    # """"""\n\n    args_names = [""name"", ""primary_keys"", ""columns"", ""tokens"", ""storage_id"", ""indexed_on"", ""class_name"",\n                  ""built_remotely""]\n    args = namedtuple(\'StorageDictArgs\', args_names)\n    _prepared_store_meta = config.session.prepare(\'INSERT INTO hecuba.istorage\'\n                                                  \'(storage_id, class_name, name, tokens, \'\n                                                  \'primary_keys, columns, indexed_on)\'\n                                                  \'VALUES (?,?,?,?,?,?,?)\')\n\n    @staticmethod\n    def _store_meta(storage_args):\n        """"""\n        Method to update the info about the StorageDict in the DB metadata table\n        Args:\n            storage_args: structure with all data needed to update the metadata\n        """"""\n        log.debug(""StorageDict: storing metas %s"", storage_args)\n\n        try:\n            config.session.execute(StorageDict._prepared_store_meta,\n                                   [storage_args.storage_id, storage_args.class_name,\n                                    storage_args.name,\n                                    storage_args.tokens, storage_args.primary_keys,\n                                    storage_args.columns, storage_args.indexed_on])\n        except Exception as ex:\n            log.error(""Error creating the StorageDict metadata: %s %s"", storage_args, ex)\n            raise ex\n\n    def __init__(self, name=\'\', primary_keys=None, columns=None, indexed_on=None, storage_id=None, **kwargs):\n        """"""\n        Creates a new StorageDict.\n\n        Args:\n            name (string): the name of the collection/table (keyspace is optional)\n            primary_keys (list(tuple)): a list of (key,type) primary keys (primary + clustering).\n            columns (list(tuple)): a list of (key,type) columns\n            tokens (list): list of tokens\n            storage_id (string): the storage id identifier\n            indexed_on (list): values that will be used as index\n            kwargs: other parameters\n        """"""\n\n        super().__init__((), name=name, storage_id=storage_id, **kwargs)\n\n        log.debug(""CREATED StorageDict(%s,%s)"", primary_keys, columns)\n\n        if self.__doc__ is not None:\n            self._persistent_props = self._parse_comments(self.__doc__)\n            self._primary_keys = self._persistent_props[\'primary_keys\']\n            self._columns = self._persistent_props[\'columns\']\n            self._indexed_on = self._persistent_props.get(\'indexed_on\', indexed_on)\n        else:\n            self._primary_keys = primary_keys\n            set_pks = []\n            normal_columns = []\n            for column_name, column_type in columns:\n                if column_name.find(""_set_"") != -1:\n                    set_pks.append((column_name.replace(""_set_"", """"), column_type))\n                else:\n                    normal_columns.append((column_name, column_type))\n            if set_pks:\n                self._columns = [{""type"": ""set"", ""columns"": set_pks}]\n            else:\n                self._columns = columns\n            self._indexed_on = indexed_on\n\n        self._has_embedded_set = False\n        build_column = []\n        columns = []\n        for col in self._columns:\n            if isinstance(col, dict):\n                types = col[""columns""]\n                if col[""type""] == ""set"":\n                    self._has_embedded_set = True\n                    for t in types:\n                        build_column.append((""_set_"" + t[0], t[1]))\n                else:\n                    build_column.append((col[""name""], col[""type""]))\n                columns.append(col)\n            else:\n                columns.append({""type"": col[1], ""name"": col[0]})\n                build_column.append(col)\n\n        self._columns = columns[:]\n        self._primary_keys = [{""type"": key[1], ""name"": key[0]} if isinstance(key, tuple) else key\n                              for key in self._primary_keys]\n        build_keys = [(key[""name""], key[""type""]) for key in self._primary_keys]\n\n        key_names = [col[""name""] for col in self._primary_keys]\n        column_names = [col[""name""] for col in self._columns]\n\n        self._item_builder = namedtuple(\'row\', key_names + column_names)\n\n        if len(key_names) > 1:\n            self._key_builder = namedtuple(\'row\', key_names)\n        else:\n            self._key_builder = None\n        if self._has_embedded_set:\n            set_names = [colname for (colname, dt) in self._get_set_types()]\n            self._column_builder = namedtuple(\'row\', set_names)\n        elif len(column_names) > 1:\n            self._column_builder = namedtuple(\'row\', column_names)\n        else:\n            self._column_builder = None\n\n        self._k_size = len(key_names)\n\n        class_name = \'%s.%s\' % (self.__class__.__module__, self.__class__.__name__)\n\n        if build_column is None:\n            build_column = self._columns[:]\n\n        self._build_args = self.args(self._get_name(), build_keys, build_column, self._tokens,\n                                     self.storage_id, self._indexed_on, class_name, self._built_remotely)\n\n        if storage_id and not name:\n            name = get_istorage_attrs(storage_id)[0].name\n\n        if name or storage_id:\n            self.make_persistent(name)\n\n    @classmethod\n    def _parse_comments(self, comments):\n        parser = Parser(""TypeSpec"")\n        return parser._parse_comments(comments)\n\n    def __contains__(self, key):\n        """"""\n        Method that checks if a given key exists in a StorageDict.\n        Args:\n            key: the position that we want to check if exists.\n        Returns:\n            boolean (true - exists, false - doesn\'t exist).\n        """"""\n        if not self.storage_id:\n            return dict.__contains__(self, key)\n        else:\n            try:\n                # TODO we should save this value in a cache\n                self._hcache.get_row(self._make_key(key))\n                return True\n            except Exception as ex:\n                log.warn(""persistentDict.__contains__ ex %s"", ex)\n                return False\n\n    def _create_tables(self):\n        # Prepare data\n        persistent_keys = [(key[""name""], ""tuple<"" + "","".join(key[""columns""]) + "">"") if key[""type""] == ""tuple""\n                           else (key[""name""], key[""type""]) for key in self._primary_keys] + self._get_set_types()\n        persistent_values = []\n        if not self._has_embedded_set:\n            for col in self._columns:\n                if col[""type""] == ""tuple"":\n                    persistent_values.append({""name"": col[""name""], ""type"": ""tuple<"" + "","".join(col[""columns""]) + "">""})\n                elif col[""type""] not in basic_types:\n                    persistent_values.append({""name"": col[""name""], ""type"": ""uuid""})\n                else:\n                    persistent_values.append({""name"": col[""name""], ""type"": col[""type""]})\n\n        key_names = [col[0] if isinstance(col, tuple) else col[""name""] for col in persistent_keys]\n\n        query_keyspace = ""CREATE KEYSPACE IF NOT EXISTS %s WITH replication = %s"" % (self._ksp, config.replication)\n        try:\n            log.debug(\'MAKE PERSISTENCE: %s\', query_keyspace)\n            config.session.execute(query_keyspace)\n        except Exception as ex:\n            log.warn(""Error creating the StorageDict keyspace %s, %s"", (query_keyspace), ex)\n            raise ex\n\n        persistent_columns = [(col[""name""], col[""type""]) for col in persistent_values]\n\n        query_table = ""CREATE TABLE IF NOT EXISTS %s.%s (%s, PRIMARY KEY (%s));"" \\\n                      % (self._ksp,\n                         self._table,\n                         "","".join(""%s %s"" % tup for tup in persistent_keys + persistent_columns),\n                         str.join(\',\', key_names))\n        try:\n            log.debug(\'MAKE PERSISTENCE: %s\', query_table)\n            config.session.execute(query_table)\n        except Exception as ex:\n            log.warn(""Error creating the StorageDict table: %s %s"", query_table, ex)\n            raise ex\n\n        if hasattr(self, \'_indexed_on\') and self._indexed_on is not None:\n            index_query = \'CREATE CUSTOM INDEX IF NOT EXISTS \' + self._table + \'_idx ON \'\n            index_query += self._ksp + \'.\' + self._table + \' (\' + str.join(\',\', self._indexed_on) + \') \'\n            index_query += ""using \'es.bsc.qbeast.index.QbeastIndex\';""\n            try:\n                config.session.execute(index_query)\n            except Exception as ex:\n                log.error(""Error creating the Qbeast custom index: %s %s"", index_query, ex)\n                raise ex\n            trigger_query = ""CREATE TRIGGER IF NOT EXISTS %s%s_qtr ON %s.%s USING \'es.bsc.qbeast.index.QbeastTrigger\';"" % \\\n                            (self._ksp, self._table, self._ksp, self._table)\n            try:\n                config.session.execute(trigger_query)\n            except Exception as ex:\n                log.error(""Error creating the Qbeast trigger: %s %s"", trigger_query, ex)\n                raise ex\n\n    def _persist_data_from_memory(self):\n        for k, v in super().items():\n            self[k] = v\n        super().clear()\n\n    def _flush_to_storage(self):\n        super()._flush_to_storage()\n        self._hcache.flush()\n\n    def _setup_hcache(self):\n        key_names = [key[""name""] for key in self._primary_keys]\n        key_names = key_names + [name for name, dt in self._get_set_types()]\n\n        persistent_values = []\n        if not self._has_embedded_set:\n            persistent_values = [{""name"": col[""name""]} for col in self._columns]\n        if self._tokens is None:\n            raise RuntimeError(""Tokens for object {} are null"".format(self._get_name()))\n        self._hcache_params = (self._ksp, self._table,\n                               self.storage_id,\n                               self._tokens, key_names, persistent_values,\n                               {\'cache_size\': config.max_cache_size,\n                                \'writer_par\': config.write_callbacks_number,\n                                \'writer_buffer\': config.write_buffer_size,\n                                \'timestamped_writes\': config.timestamped_writes})\n        log.debug(""HCACHE params %s"", self._hcache_params)\n        self._hcache = Hcache(*self._hcache_params)\n\n    def _make_key(self, key):\n        """"""\n        Method used to pass the key data to the StorageDict cache in a proper way.\n        Args:\n            key: the data that needs to get the correct format\n        """"""\n        if isinstance(key, str) or not isinstance(key, Iterable):\n            if len(self._primary_keys) == 1:\n                return [key]\n            else:\n                raise Exception(\'missing a primary key\')\n\n        if isinstance(key, Iterable) and len(key) == len(self._primary_keys):\n            return list(key)\n        elif self._has_embedded_set and isinstance(key, Iterable) and len(key) == (\n                len(self._primary_keys) + len(self._get_set_types())):\n            return list(key)\n        else:\n            raise Exception(\'wrong primary key\')\n\n    @staticmethod\n    def _make_value(value):\n        """"""\n        Method used to pass the value data to the StorageDict cache in a proper way.\n        Args:\n            value: the data that needs to get the correct format\n        """"""\n        if issubclass(value.__class__, IStorage):\n            return [value.storage_id]\n        elif isinstance(value, str) or not isinstance(value, Iterable) or isinstance(value, np.ndarray):\n            return [value]\n        elif isinstance(value, tuple):\n            return [value]\n        elif isinstance(value, Iterable):\n            val = []\n            for v in value:\n                if isinstance(v, IStorage):\n                    val.append(v.storage_id)\n                else:\n                    val.append(v)\n            return val\n        else:\n            return list(value)\n\n    def _count_elements(self, query):\n        try:\n            result = config.session.execute(query)\n            return result[0][0]\n        except OperationTimedOut as ex:\n            import warnings\n            warnings.warn(""len() operation on {} from class {} failed by timeout.""\n                          ""Use len() on split() results if you must"".format(self._get_name(), self.__class__.__name__))\n            raise ex\n        except Exception as ir:\n            log.error(""Unable to execute %s"", query)\n            raise ir\n\n    def __iter__(self):\n        """"""\n        Method that overloads the python dict basic iteration, which returns\n        an iterator over the dictionary keys.\n        """"""\n        return self.keys()\n\n    def make_persistent(self, name):\n        """"""\n        Method to transform a StorageDict into a persistent object.\n        This will make it use a persistent DB as the main location\n        of its data.\n        Args:\n            name:\n        """"""\n        super().make_persistent(name)\n        # Update local StorageDict metadata\n        self._build_args = self._build_args._replace(storage_id=self.storage_id, name=self._ksp + ""."" + self._table,\n                                                     tokens=self._tokens)\n\n        if not self._built_remotely:\n            self._create_tables()\n\n        self._setup_hcache()\n\n        self._persist_data_from_memory()\n\n        StorageDict._store_meta(self._build_args)\n\n    def stop_persistent(self):\n        """"""\n        Method to turn a StorageDict into non-persistent.\n        """"""\n        super().stop_persistent()\n        log.debug(\'STOP PERSISTENCE: %s\', self._table)\n        self._hcache = None\n        self.storage_id = None\n\n    def delete_persistent(self):\n        """"""\n        Method to empty all data assigned to a StorageDict.\n        """"""\n        self._flush_to_storage()\n        super().delete_persistent()\n        log.debug(\'DELETE PERSISTENT: %s\', self._table)\n        query = ""TRUNCATE TABLE %s.%s;"" % (self._ksp, self._table)\n        config.session.execute(query)\n\n        query = ""DELETE FROM hecuba.istorage where storage_id={}"".format(self.storage_id)\n        config.session.execute(query)\n        self.storage_id = None\n\n    def __delitem__(self, key):\n        """"""\n        Method to delete a specific entry in the dict in the key position.\n        Args:\n            key: position of the entry that we want to delete\n        """"""\n        if not self.storage_id:\n            dict.__delitem__(self, key)\n        elif self._has_embedded_set:\n            self._hcache.delete_row(key)\n        elif isinstance(key, Iterable) and not isinstance(key, str):\n            self._hcache.delete_row(list(key))\n        else:\n            self._hcache.delete_row([key])\n\n    def __create_embeddedset(self, key, val=None):\n        if not isinstance(key, Iterable) or isinstance(key, str):\n            return EmbeddedSet(self, [key], val)\n        else:\n            return EmbeddedSet(self, list(key), val)\n\n    def __getitem__(self, key):\n        """"""\n        If the object is persistent, each request goes to the hfetch.\n        Args:\n             key: the dictionary key\n        Returns\n             item: value found in position key\n        """"""\n        log.debug(\'GET ITEM %s\', key)\n\n        if not self.storage_id:\n            return dict.__getitem__(self, key)\n        elif self._has_embedded_set:\n            return self.__create_embeddedset(key=key)\n        else:\n            # Returns always a list with a single entry for the key\n            persistent_result = self._hcache.get_row(self._make_key(key))\n            log.debug(""GET ITEM %s[%s]"", persistent_result, persistent_result.__class__)\n\n            # we need to transform UUIDs belonging to IStorage objects and rebuild them\n            # TODO hcache should return objects of the class uuid, not str\n            final_results = []\n            for index, col in enumerate(self._columns):\n                col_type = col[""type""]\n                element = persistent_result[index]\n                if col_type not in basic_types:\n                    # element is not a built-in type\n                    info = {""storage_id"": element, ""tokens"": self._build_args.tokens, ""class_name"": col_type}\n                    element = build_remotely(info)\n\n                final_results.append(element)\n\n            if self._column_builder is not None:\n                return self._column_builder(*final_results)\n            else:\n                return final_results[0]\n\n    def __make_val_persistent(self, val, col=0):\n        if isinstance(val, list):\n            for index, element in enumerate(val):\n                val[index] = self.__make_val_persistent(element, index)\n        elif isinstance(val, IStorage) and not val._is_persistent:\n            val.storage_id = uuid.uuid4()\n            attribute = self._columns[col][""name""]\n            count = count_name_collision(self._ksp, self._table, attribute)\n            if count == 0:\n                name = self._ksp + ""."" + self._table + ""_"" + attribute\n            else:\n                name = self._ksp + ""."" + self._table + ""_"" + attribute + ""_"" + str(count - 1)\n            # new name as ksp+table+obj_class_name\n            val.make_persistent(name)\n        return val\n\n    def __setitem__(self, key, val):\n        """"""\n           Method to insert values in the StorageDict\n           Args:\n               key: the position of the value that we want to save\n               val: the value that we want to save in that position\n        """"""\n        if isinstance(val, list):\n            vals_istorage = []\n            for element in val:\n                if isinstance(element, np.ndarray):\n                    val_istorage = StorageNumpy(element)\n                else:\n                    val_istorage = element\n                vals_istorage.append(val_istorage)\n\n            val = vals_istorage\n        elif isinstance(val, np.ndarray):\n            val = StorageNumpy(val)\n        elif isinstance(val, set):\n            val = self.__create_embeddedset(key=key, val=val)\n\n        log.debug(\'SET ITEM %s->%s\', key, val)\n        if self.storage_id is None:\n            dict.__setitem__(self, key, val)\n        elif not isinstance(val, EmbeddedSet):\n            # Not needed because it is made persistent and inserted to hcache when calling to self.__create_embeddedset\n            val = self.__make_val_persistent(val)\n            self._hcache.put_row(self._make_key(key), self._make_value(val))\n\n    def __len__(self):\n        if not self.storage_id:\n            return super().__len__()\n\n        self._flush_to_storage()\n        if self._tokens[0][0] == _min_token and self._tokens[-1][1] == _max_token:\n            query = f""SELECT COUNT(*) FROM {self._ksp}.{self._table}""\n            return self._count_elements(query)\n\n        else:\n            keys = []\n            for pkey in self._primary_keys:\n                template = ""\'{}\'"" if pkey[""type""] == ""text"" else ""{}""\n                keys.append(template.format(pkey[""name""]))\n            all_keys = "","".join(keys)\n\n            total = 0\n            for (token_start, token_end) in self._tokens:\n                query = f""SELECT COUNT(*) FROM {self._ksp}.{self._table} "" \\\n                    f""WHERE token({all_keys})>={token_start} AND token({all_keys})<{token_end}""\n\n                total = total + self._count_elements(query)\n            return total\n\n    def __repr__(self):\n        """"""\n        Overloads the method used by print to show a StorageDict\n        Returns: The representation of the data stored in the StorageDict\n\n        """"""\n        to_return = {}\n        for item in self.items():\n            to_return[item[0]] = item[1]\n            if len(to_return) == config.hecuba_print_limit:\n                return str(to_return)\n        if len(to_return) > 0:\n            return str(to_return)\n        return """"\n\n    def update(self, other=None, **kwargs):\n        """"""\n        Updates the current dict with a new dictionary or set of attr,value pairs\n        (those must follow the current dict data model).\n        Args:\n            other: python dictionary or StorageDict. All key,val values in it will\n            be inserted in the current dict.\n            **kwargs: set of attr:val pairs, to be treated as key,val and inserted\n            in the current dict.\n        """"""\n        if other is not None:\n            if isinstance(other, StorageDict):\n                for k, v in other.items():\n                    self[k] = v\n            else:\n                for k, v in other.items() if isinstance(other, Mapping) else other:\n                    self[k] = v\n        for k, v in kwargs.items():\n            self[k] = v\n\n    def keys(self):\n        """"""\n        Obtains the iterator for the keys of the StorageDict\n        Returns:\n            if persistent:\n                iterkeys(self): list of keys\n            if not persistent:\n                dict.keys(self)\n        """"""\n        if self.storage_id:\n            self._flush_to_storage()\n            ik = self._hcache.iterkeys(config.prefetch_size)\n            iterator = NamedIterator(ik, self._key_builder, self)\n            if self._has_embedded_set:\n                iterator = iter(set(iterator))\n\n            return iterator\n        else:\n            return dict.keys(self)\n\n    def items(self):\n        """"""\n        Obtains the iterator for the key,val pairs of the StorageDict\n        Returns:\n            if persistent:\n                NamedItemsIterator(self): list of key,val pairs\n            if not persistent:\n                dict.items(self)\n        """"""\n        if self.storage_id:\n            self._flush_to_storage()\n            ik = self._hcache.iteritems(config.prefetch_size)\n            iterator = NamedItemsIterator(self._key_builder,\n                                          self._column_builder,\n                                          self._k_size,\n                                          ik,\n                                          self)\n            if self._has_embedded_set:\n                d = defaultdict(set)\n                # iteritems has the set values in different rows, this puts all the set values in the same row\n                if len(self._get_set_types()) == 1:\n                    for row in iterator:\n                        d[row.key].add(row.value[0])\n                else:\n                    for row in iterator:\n                        d[row.key].add(tuple(row.value))\n\n                iterator = d.items()\n\n            return iterator\n        else:\n            return dict.items(self)\n\n    def values(self):\n        """"""\n        Obtains the iterator for the values of the StorageDict\n        Returns:\n            if persistent:\n                NamedIterator(self): list of valuesStorageDict\n            if not persistent:\n                dict.values(self)\n        """"""\n        if self.storage_id:\n            self._flush_to_storage()\n            if self._has_embedded_set:\n                items = self.items()\n                return dict(items).values()\n            else:\n                ik = self._hcache.itervalues(config.prefetch_size)\n                return NamedIterator(ik, self._column_builder, self)\n        else:\n            return dict.values(self)\n\n    def get(self, key, default=None):\n        try:\n            value = self.__getitem__(key)\n        except KeyError:\n            value = default\n        return value\n\n    def _get_set_types(self):\n        if self._has_embedded_set:\n            set_types = [col.get(""columns"", []) for col in self._columns if isinstance(col, dict)]\n            return sum(set_types, [])\n        else:\n            return []\n'"
hecuba_py/hecuba/hfilter.py,0,"b'from collections import Iterable\n\nimport re\nimport inspect\nfrom . import config\nfrom .qbeast import QbeastIterator, QbeastMeta\n\nfrom .IStorage import IStorage\nfrom .storageiter import NamedItemsIterator\n\nmagical_regex = re.compile(r\'(?:\\d+(?:\\.\\d+)?|\\w|""\\w+""|\\\'\\w+\\\')+|[^\\s\\w\\_]\')\nis_numerical = re.compile(r\'\\d+(\\.\\d+)?\')\n\n\ndef func_to_str(func):\n    func_string = inspect.getsourcelines(func)[0][0]\n    start, end = func_string.find(""lambda""), func_string.rfind("","")\n    func_string = func_string[start:end]\n    func_vars = func_string[7:func_string.find(\':\')].replace("" "", """").split(\',\')\n    clean_string = func_string[func_string.find(\':\') + 1:].replace(""\\\\n"", \'\')\n    return func_vars, clean_string\n\n\ndef substit_var(final_list, func_vars, dictv):\n    list_with_values = []\n    for elem in final_list:\n        if not isinstance(elem, str) and isinstance(elem, Iterable):\n            list_with_values.append(elem)\n        elif (elem != \'in\' and not isinstance(elem, int) and not re.match(r\'[^\\s\\w]\', elem)) and not elem.isdigit():\n            i = elem.find(\'.\')\n            if i > 0:\n                elem_var = elem[:i]\n                if elem_var not in func_vars:\n                    elemm = elem[i:]\n                    get_ele = dictv.get(str(elemm))\n                    if get_ele is None:\n                        list_with_values.append(elem)\n                    else:\n                        list_with_values.append(dictv.get(str(elem)))\n                else:\n                    list_with_values.append(elem[i + 1:])\n            else:\n                get_elem = dictv.get(str(elem), elem)\n                list_with_values.append(get_elem)\n        else:\n            list_with_values.append(elem)\n\n    return list_with_values\n\n\ndef is_float(var):\n    return is_numerical.match(var) is not None\n\n\ndef transform_to_correct_type(final_list, dictv):\n    final = []\n    reverse_comparison = {"">="": ""<="", ""<="": "">="", "">"": ""<"", ""<"": "">""}\n    for elem in final_list:\n        aux = []\n        for i, value in enumerate(elem):\n            if isinstance(value, (int, float, Iterable)) and not isinstance(value, str):\n                aux.append(value)\n            elif not value.find(\'""\') == -1:\n                aux.append(value.replace(\'""\', \'\'))\n            elif not value.find(""\'"") == -1:\n                aux.append(value.replace(""\'"", """"))\n            elif value.isdigit() and value not in dictv.values():\n                aux.append(int(value))\n            elif is_float(value) and value not in dictv.values():\n                aux.append(float(value))\n            elif value == ""True"":\n                aux.append(True)\n            elif value == ""False"":\n                aux.append(False)\n            else:\n                aux.append(value)\n\n        if (isinstance(aux[0], str) and aux[0].isdigit()) or isinstance(aux[0], int):\n            aux.reverse()\n            aux[1] = reverse_comparison[aux[1]]\n\n        final.append(aux)\n\n    return final\n\n\ndef parse_lambda(func):\n    func_vars, clean_string = func_to_str(func)\n    parsed_string = magical_regex.findall(clean_string)\n    simplified_filter = []\n\n    for i, elem in enumerate(parsed_string):\n        if i > 0:\n            if elem == \'=\' and simplified_filter[-1] == ""="":\n                pass\n            elif elem == \'=\' and (simplified_filter[-1] == ""<"" or simplified_filter[-1] == "">""):\n                simplified_filter[-1] = simplified_filter[-1] + ""=""\n            elif simplified_filter[-1][-1] == ""."":\n                simplified_filter[-1] += elem\n            elif elem == ""."":\n                simplified_filter[-1] = simplified_filter[-1] + elem\n            else:\n                simplified_filter.append(elem)\n        else:\n            simplified_filter.append(elem)\n\n    # Getting variables\n    dictv = {}\n    for i, elem in enumerate(func.__code__.co_freevars):\n        dictv[elem] = func.__closure__[i].cell_contents\n\n    # Combine set or tuple\n    for i, elem in enumerate(simplified_filter):\n        if elem == ""["":\n            index = simplified_filter[i:].index(\']\')\n            c = \'\'.join(simplified_filter[i:index + i + 1])\n            simplified_filter[i:index + i + 1] = [eval(c)]\n        elif elem == \'(\':\n            index = simplified_filter[i:].index(\')\')\n            c = \'\'.join(simplified_filter[i:index + i + 1])\n            joined_tuple = eval(c)\n            if len(joined_tuple) > 0:\n                simplified_filter[i:index + i + 1] = [joined_tuple]\n            else:\n                simplified_filter[i:index + i + 1] = []\n                simplified_filter[i - 1] += ""()""\n\n    final_list = []\n    while \'and\' in simplified_filter:\n        i = simplified_filter.index(\'and\')\n        sublist = simplified_filter[:i]\n        sublist = substit_var(sublist, func_vars, dictv)\n        final_list.append(sublist)\n        simplified_filter[:i + 1] = []\n    else:\n        sublist = substit_var(simplified_filter, func_vars, dictv)\n        final_list.append(sublist)\n\n    # Replace types for correct ones\n    final_list = transform_to_correct_type(final_list, dictv)\n    return final_list\n\n\ndef hfilter(lambda_filter, iterable):\n    if not isinstance(iterable, IStorage):\n        try:\n            iterable = iterable._storage_father\n        except AttributeError:\n            return python_filter(lambda_filter, iterable)\n\n    parsed_lambda = parse_lambda(lambda_filter)\n\n    if hasattr(iterable, \'_indexed_on\') and iterable._indexed_on is not None:\n        non_index_arguments = """"\n        # initialize lists of the same size as indexed_on\n        from_p = [None] * len(iterable._indexed_on)\n        to_p = [None] * len(iterable._indexed_on)\n        precision = None\n\n        for expression in parsed_lambda:\n            if expression[0] in iterable._indexed_on:\n                index = iterable._indexed_on.index(expression[0])\n                if expression[1] == "">"":\n                    from_p[index] = expression[2]\n                elif expression[1] == ""<"":\n                    to_p[index] = expression[2]\n                elif expression[1] == ""in"":\n                    raise Exception(""Cannot use <in> on a QbeastIterator"")\n                else:\n                    non_index_arguments += ""%s %s %s AND "" % (expression[0], expression[1], expression[2])\n            elif expression[0].find(""random"") > -1:\n                precision = expression[2]\n            else:\n                non_index_arguments += ""%s %s %s AND "" % (expression[0], expression[1], expression[2])\n\n        if precision is None:\n            precision = 1.0\n        name = ""%s.%s"" % (iterable._ksp, iterable._table)\n\n        qbeast_meta = QbeastMeta(non_index_arguments[:-5], from_p, to_p, precision)\n        new_iterable = QbeastIterator(primary_keys=iterable._primary_keys, columns=iterable._columns,\n                                      indexed_on=iterable._indexed_on, name=name, qbeast_meta=qbeast_meta,\n                                      tokens=iterable._tokens)\n        return new_iterable\n\n    predicate = Predicate(iterable)\n    for expression in parsed_lambda:\n        if expression[1] in ("">"", ""<"", ""="", "">="", ""<=""):\n            predicate = predicate.comp(col=expression[0], comp=expression[1], value=expression[2])\n        elif expression[1] == ""in"":\n            predicate = predicate.inside(col=expression[0], values=expression[2])\n        else:\n            raise Exception(""Bad expression."")\n\n    return predicate.execute()\n\n\nclass Predicate:\n    def __init__(self, father):\n        self.father = father\n        self.primary_keys = [col[0] if isinstance(col, tuple) else col[""name""] for col in self.father._primary_keys]\n        self.columns = [col[0] if isinstance(col, tuple) else col[""name""] for col in self.father._columns]\n        self.predicate = None\n\n    def comp(self, col, value, comp):\n        \'\'\'\n        Select all rows where col (==, >=, <=, >, <) value\n        \'\'\'\n        if col not in self.columns + self.primary_keys:\n            raise Exception(""Wrong column."")\n\n        if self.predicate is not None:\n            self.predicate += "" AND ""\n        else:\n            self.predicate = """"\n\n        if isinstance(value, str):\n            value = ""\'{}\'"".format(value)\n\n        self.predicate += "" {} {} {}"".format(col, comp, value)\n        return self\n\n    def inside(self, col, values):\n        \'\'\'\n        Select all rows where col in values\n        \'\'\'\n        if col not in self.primary_keys:\n            raise Exception(""Column not in primary key."")\n\n        if self.predicate is not None:\n            self.predicate += "" AND ""\n        else:\n            self.predicate = """"\n\n        self.predicate += "" {} IN ("".format(col)\n        for value in values:\n            if isinstance(value, str):\n                value = ""\'{}\'"".format(value)\n            self.predicate += ""{}, "".format(value)\n        self.predicate = self.predicate[:-2] + "")""\n        return self\n\n    def execute(self):\n        \'\'\'\n        Execute the CQL query\n        Returns an iterator over the rows\n        \'\'\'\n        conditions = self.predicate + "" ALLOW FILTERING""\n\n        hiter = self.father._hcache.iteritems({\'custom_select\': conditions, \'prefetch_size\': config.prefetch_size})\n        iterator = NamedItemsIterator(self.father._key_builder,\n                                      self.father._column_builder,\n                                      self.father._k_size,\n                                      hiter,\n                                      self.father)\n\n        return iterator\n'"
hecuba_py/hecuba/hnumpy.py,19,"b'import itertools as it\nimport uuid\nfrom collections import namedtuple\nfrom typing import Tuple\n\nimport numpy as np\nfrom hfetch import HNumpyStore, HArrayMetadata\n\nfrom . import config, log\nfrom .IStorage import IStorage\nfrom .tools import extract_ks_tab, get_istorage_attrs, storage_id_from_name\n\n\nclass StorageNumpy(IStorage, np.ndarray):\n    _build_args = None\n    _prepared_store_meta = config.session.prepare(\'INSERT INTO hecuba.istorage\'\n                                                  \'(storage_id, class_name, name, numpy_meta, block_id, base_numpy)\'\n                                                  \'VALUES (?,?,?,?,?,?)\')\n\n    args_names = [""storage_id"", ""class_name"", ""name"", ""metas"", ""block_id"", ""base_numpy""]\n    args = namedtuple(\'StorageNumpyArgs\', args_names)\n\n    def np_split(self, block_size: Tuple[int, int]):\n        # For now, only split in two dimensions is supported\n        bn, bm = block_size\n        for block_id, i in enumerate(range(0, self.shape[0], bn)):\n            block = [self[i: i + bn, j:j + bm] for j in range(0, self.shape[1], bm)]\n            obj = StorageNumpy(input_array=block, name=self.name, storage_id=uuid.uuid4(), block_id=block_id)\n            yield obj\n\n    def __new__(cls, input_array=None, name=None, storage_id=None, block_id=None, **kwargs):\n        if input_array is None and (name is not None or storage_id is not None):\n            if not storage_id:\n                (ksp, table) = extract_ks_tab(name)\n                name = ksp + ""."" + table\n                storage_id = storage_id_from_name(name)\n\n            # Load metadata\n            istorage_metas = get_istorage_attrs(storage_id)\n            name = name or istorage_metas[0].name\n            numpy_metadata = istorage_metas[0].numpy_meta\n            base_metas = numpy_metadata\n            base_numpy = istorage_metas[0].base_numpy\n            if base_numpy is not None:\n                storage_id = base_numpy\n                base_metas = get_istorage_attrs(storage_id)[0].numpy_meta\n\n            # Load array\n            result = cls.reserve_numpy_array(storage_id, name, base_metas)\n            input_array = result[0]\n            obj = np.asarray(input_array).view(cls)\n            (obj._ksp, obj._table) = extract_ks_tab(name)\n            obj._hcache = result[1]\n            obj.storage_id = storage_id\n            if base_numpy is not None:\n                obj._partition_dims = numpy_metadata.dims\n        else:\n            obj = np.asarray(input_array).view(cls)\n\n        obj._numpy_full_loaded = False\n        obj._loaded_coordinates = []\n        obj.name = name\n        if getattr(obj, ""_block_id"", None) is None:\n            obj._block_id = block_id\n        # Finally, we must return the newly created object:\n        obj._class_name = \'%s.%s\' % (cls.__module__, cls.__name__)\n        return obj\n\n    def __init__(self, input_array=None, name=None, storage_id=None, **kwargs):\n        IStorage.__init__(self, storage_id=storage_id, name=name, **kwargs)\n        metas = HArrayMetadata(list(self.shape), list(self.strides), self.dtype.kind, self.dtype.byteorder,\n                               self.itemsize, self.flags.num, 0)\n        self._build_args = self.args(self.storage_id, self._class_name, self._get_name(), metas, self._block_id, None)\n\n        if self._get_name() or self.storage_id:\n            if input_array is not None:\n                self.make_persistent(self._get_name())\n            self._row_elem = self._hcache.get_elements_per_row(self.storage_id, metas)[0]\n            self._is_persistent = True\n\n    # used as copy constructor\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        self.storage_id = getattr(obj, \'storage_id\', None)\n        self._name = getattr(obj, \'_name\', None)\n        self._hcache = getattr(obj, \'_hcache\', None)\n        self._row_elem = getattr(obj, \'_row_elem\', None)\n        self._loaded_coordinates = getattr(obj, \'_loaded_coordinates\', None)\n        self._numpy_full_loaded = getattr(obj, \'_numpy_full_loaded\', None)\n        self._is_persistent = getattr(obj, \'_is_persistent\', None)\n        self._block_id = getattr(obj, \'_block_id\', None)\n        try:\n            self._build_args = obj._build_args\n        except AttributeError:\n            self._build_args = HArrayMetadata(list(self.shape), list(self.strides), self.dtype.kind,\n                                              self.dtype.byteorder, self.itemsize, self.flags.num, 0)\n\n    @staticmethod\n    def _create_tables(name):\n        (ksp, table) = extract_ks_tab(name)\n        query_keyspace = ""CREATE KEYSPACE IF NOT EXISTS %s WITH replication = %s"" % (ksp, config.replication)\n        config.session.execute(query_keyspace)\n\n        config.session.execute(\n            \'CREATE TABLE IF NOT EXISTS \' + ksp + \'.\' + table + \'(storage_id uuid , \'\n                                                                \'cluster_id int, \'\n                                                                \'block_id int, \'\n                                                                \'payload blob, \'\n                                                                \'PRIMARY KEY((storage_id,cluster_id),block_id))\')\n\n    @staticmethod\n    def _create_hcache(name):\n        (ksp, table) = extract_ks_tab(name)\n        hcache_params = (ksp, table,\n                         {\'cache_size\': config.max_cache_size,\n                          \'writer_par\': config.write_callbacks_number,\n                          \'write_buffer\': config.write_buffer_size,\n                          \'timestamped_writes\': False})\n\n        return HNumpyStore(*hcache_params)\n\n    @staticmethod\n    def _store_meta(storage_args):\n        """"""\n            Saves the information of the object in the istorage table.\n            Args:.\n                storage_args (object): contains all data needed to restore the object from the workers\n        """"""\n        log.debug(""StorageObj: storing media %s"", storage_args)\n        try:\n            config.session.execute(StorageNumpy._prepared_store_meta,\n                                   [storage_args.storage_id, storage_args.class_name,\n                                    storage_args.name, storage_args.metas, storage_args.block_id,\n                                    storage_args.base_numpy])\n\n        except Exception as ex:\n            log.warn(""Error creating the StorageNumpy metadata with args: %s"" % str(storage_args))\n            raise ex\n\n    @staticmethod\n    def reserve_numpy_array(storage_id, name, metas):\n        \'\'\'Provides a numpy array with the number of elements obtained through storage_id\'\'\'\n\n        hcache = StorageNumpy._create_hcache(name)\n        result = hcache.allocate_numpy(storage_id, metas)\n        if len(result) == 1:\n            return [result[0], hcache]\n        else:\n            raise KeyError\n\n    def __getitem__(self, sliced_coord):\n        log.info(""RETRIEVING NUMPY"")\n        if self._is_persistent and not self._numpy_full_loaded:\n            if sliced_coord == slice(None, None, None):\n                new_coords = []\n            else:\n                try:\n                    all_coords = np.argwhere(self.view(np.ndarray) == self.view(np.ndarray)).reshape(\n                        *self.view(np.ndarray).shape, self.view(np.ndarray).ndim) // self._row_elem\n                    new_coords = all_coords[sliced_coord].reshape(-1, self.view(np.ndarray).ndim)\n                except IndexError:\n                    return super(StorageNumpy, self).__getitem__(sliced_coord)\n                new_coords = [tuple(coord) for coord in new_coords]\n                new_coords = list(dict.fromkeys(new_coords))\n            # coordinates is the union between the loaded coordiantes and the new ones\n            coordinates = list(set(it.chain.from_iterable((self._loaded_coordinates, new_coords))))\n\n            # checks if we already loaded the coordinates\n\n            if ((len(coordinates) != len(self._loaded_coordinates)) and not self._numpy_full_loaded) or (\n                    not self._numpy_full_loaded and not coordinates):\n                if not coordinates:\n                    self._numpy_full_loaded = True\n                    new_coords = None\n\n                self._hcache.load_numpy_slices([self.storage_id], self._build_args.metas, [self.base.view(np.ndarray)],\n                                               new_coords)\n                self._loaded_coordinates = coordinates\n        return super(StorageNumpy, self).__getitem__(sliced_coord)\n\n    def __setitem__(self, sliced_coord, values):\n        log.info(""WRITING NUMPY"")\n        if self._is_persistent:\n            if sliced_coord == slice(None, None, None):\n                new_coords = []\n            else:\n                try:\n                    all_coords = np.argwhere(self.view(np.ndarray) == self.view(np.ndarray)).reshape(\n                        *self.view(np.ndarray).shape, self.view(np.ndarray).ndim) // self._row_elem\n                    new_coords = all_coords[sliced_coord].reshape(-1, self.view(np.ndarray).ndim)\n                except IndexError:\n                    return super(StorageNumpy, self).__getitem__(sliced_coord)\n                new_coords = [tuple(coord) for coord in new_coords]\n                new_coords = list(dict.fromkeys(new_coords))\n            # coordinates is the union between the loaded coordiantes and the new ones\n            coordinates = list(set(it.chain.from_iterable((self._loaded_coordinates, new_coords))))\n            self._hcache.store_numpy_slices([self.storage_id], self._build_args.metas, [self.base.view(np.ndarray)],\n                                            coordinates)\n        return super(StorageNumpy, self).__setitem__(sliced_coord, values)\n\n    def make_persistent(self, name):\n        super().make_persistent(name)\n\n        if not self._built_remotely:\n            self._create_tables(name)\n\n        if not getattr(self, \'_hcache\', None):\n            self._hcache = self._create_hcache(name)\n\n        if None in self or not self.ndim:\n            raise NotImplemented(""Empty array persistance"")\n\n        hfetch_metas = HArrayMetadata(list(self.shape), list(self.strides), self.dtype.kind, self.dtype.byteorder,\n                                      self.itemsize, self.flags.num, 0)\n        self._build_args = self.args(self.storage_id, self._class_name, self._get_name(), hfetch_metas, self._block_id,\n                                     None)\n\n        if len(self.shape) != 0:\n            self._hcache.store_numpy_slices([self.storage_id], self._build_args.metas, [self.base.view(np.ndarray)],\n                                            None)\n        StorageNumpy._store_meta(self._build_args)\n\n    def stop_persistent(self):\n        super().stop_persistent()\n\n        self.storage_id = None\n\n    def delete_persistent(self):\n        """"""\n            Deletes the Cassandra table where the persistent StorageObj stores data\n        """"""\n        super().delete_persistent()\n\n        clusters_query = ""SELECT cluster_id FROM %s WHERE storage_id = %s ALLOW FILTERING;"" % (\n            self._name, self.storage_id)\n        clusters = config.session.execute(clusters_query)\n        clusters = "","".join([str(cluster[0]) for cluster in clusters])\n\n        query = ""DELETE FROM %s WHERE storage_id = %s AND cluster_id in (%s);"" % (self._name, self.storage_id, clusters)\n        query2 = ""DELETE FROM hecuba.istorage WHERE storage_id = %s;"" % self.storage_id\n        log.debug(""DELETE PERSISTENT: %s"", query)\n        config.session.execute(query)\n        config.session.execute(query2)\n        self.storage_id = None\n\n    def __iter__(self):\n        if self._numpy_full_loaded:\n            return iter(self.view(np.ndarray))\n        else:\n            return iter(self[:].view(np.ndarray))\n\n    def __contains__(self, item):\n        return item in self.view(np.ndarray)\n\n    def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):\n        args = []\n        for input_ in inputs:\n            if isinstance(input_, StorageNumpy):\n                args.append(input_.view(np.ndarray))\n            else:\n                args.append(input_)\n\n        outputs = kwargs.pop(\'out\', None)\n        if outputs:\n            out_args = []\n            for output in outputs:\n                if isinstance(output, StorageNumpy):\n                    out_args.append(output.view(np.ndarray))\n                else:\n                    out_args.append(output)\n            kwargs[\'out\'] = tuple(out_args)\n        else:\n            outputs = (None,) * ufunc.nout\n        if self._is_persistent and len(self.shape) and self._numpy_full_loaded is False:\n            self._hcache.load_numpy_slices([self.storage_id], self._build_args.metas, [self.base.view(np.ndarray)],\n                                           None)\n\n        results = super(StorageNumpy, self).__array_ufunc__(ufunc, method,\n                                                            *args, **kwargs)\n        if results is NotImplemented:\n            return NotImplemented\n\n        if method == \'at\':\n            return\n\n        if self._is_persistent and len(self.shape):\n            self._hcache.store_numpy_slices([self.storage_id], self._build_args.metas, [self.base.view(np.ndarray)],\n                                            None)\n\n        if ufunc.nout == 1:\n            results = (results,)\n\n        results = tuple((result\n                         if output is None else output)\n                        for result, output in zip(results, outputs))\n\n        return results[0] if len(results) == 1 else results\n'"
hecuba_py/hecuba/parser.py,0,"b'import re\nfrom itertools import count\n\nfrom .tools import process_path\n\n_conversions = {\'atomicint\': \'counter\',\n                \'str\': \'text\',\n                \'bool\': \'boolean\',\n                \'decimal\': \'decimal\',\n                \'float\': \'float\',\n                \'int\': \'int\',\n                \'tuple\': \'tuple\',\n                \'list\': \'list\',\n                \'generator\': \'list\',\n                \'frozenset\': \'set\',\n                \'set\': \'set\',\n                \'dict\': \'map\',\n                \'long\': \'bigint\',\n                \'buffer\': \'blob\',\n                \'bytearray\': \'blob\',\n                \'counter\': \'counter\',\n                \'double\': \'double\',\n                \'StorageDict\': \'dict\',\n                \'ndarray\': \'hecuba.hnumpy.StorageNumpy\',\n                \'numpy.ndarray\': \'hecuba.hnumpy.StorageNumpy\',\n                \'date\': \'date\',\n                \'time\': \'time\',\n                \'datetime\': \'timestamp\'}\n\n\nclass Parser(object):\n    args_names = [""type_parser""]\n    split_dtypes_regex = re.compile(\'^(tuple|set)<(.*)>$\')\n\n    def _append_values_to_list_after_replace(self, vals):\n        """"""\n        Receives a list of data types. Strips the outermost data type.\n        Returns:\n            typev: list of the outer data types, with the keyword ""simple"" if not found\n            finalvars: list of the corresponding internal data types\n        """"""\n        typev = []\n        finalvars = []\n        for var in vals:\n            res = self.split_dtypes_regex.search(var)\n            if res:\n                typev.append(res.group(1))\n                finalvars.append(res.group(2))\n            else:\n                typev.append(""simple"")\n                finalvars.append(var)\n        return typev, finalvars\n\n    def _get_str_primary_keys_values(self, pk):\n        pk = pk.replace(""dict"", """", 1).strip()\n\n        # Find point to split keys from values\n        n_brackets = 0\n        pos = 0\n        for pos, c in enumerate(pk):\n            if c == \'<\':\n                n_brackets = n_brackets + 1\n            elif c == \'>\':\n                n_brackets = n_brackets - 1\n                if n_brackets == 1:\n                    break\n\n        keys = pk[2:pos]\n        values = pk[pos + 2:len(pk) - 1]\n\n        if not keys:\n            raise SyntaxError(""Can\'t detect the keys in the TypeSpec"")\n\n        # We get the variables\n\n        varsk = re.findall(r""\\w+:"", keys)  # var keys\n        varsv = re.findall(r""\\w+:"", values)  # var values\n\n        # Now we clean the variables\n\n        varskc = [v.replace(\':\', \'\') for v in varsk]\n        varsvc = [v.replace(\':\', \'\') for v in varsv]\n\n        # We get the valuesk\n\n        for var in varsk:\n            keys = keys.replace(var, \' \')\n\n        valsc = keys[1:].split(\', \')  # all valuesk separated by comma\n\n        typevk, finalvarsk = self._append_values_to_list_after_replace(valsc)\n\n        for var in varsv:\n            values = values.replace(var, \' \', 1)\n\n        valsc1 = values[1:].split(\', \')  # all valuesk separated by comma\n\n        typevv, finalvarsv = self._append_values_to_list_after_replace(valsc1)\n        return varskc, varsvc, finalvarsk, finalvarsv, typevk, typevv\n\n    def _set_or_tuple(self, type, pk_col, t, t1):\n        string_str = """"\n        t = t.split(\',\')\n        converted_primary_keys = "", "".join([_conversions.get(w, w) for w in t])\n        converted_primary_keys = converted_primary_keys.split(\',\')\n        converted_primary_keys = [w.replace(\' \', \'\') for w in converted_primary_keys]\n        aux_list = []  # stores ((var_1, val),(var_2, val),...)\n        if len(converted_primary_keys) > 1:\n            counter = count(0)\n            for type_val in converted_primary_keys:\n                if type == ""set"":\n                    aux_list.append((t1 + \'_\' + str(next(counter)), type_val))\n                else:\n                    aux_list.append(type_val)\n                # string_str = \',{""name"": ""%s"", ""type"": ""%s"", ""%s"": [""%s""]}\' % (t1, type, pk_col, \'"",""\'.join(aux_list))\n                string_str = \',{""name"": ""%s"", ""type"": ""%s"", ""%s"": %s}\' % (t1, type, pk_col, aux_list)\n        else:\n            aux_list.append((t1, converted_primary_keys[0]))\n            string_str = \',{""name"": ""%s"", ""type"": ""%s"", ""%s"": %s}\' % (t1, type, pk_col, aux_list)\n        return string_str\n\n    def _get_dict_str(self, varsk, cleank, typek):\n        concatenated_keys = """"\n        values = """"\n        string_str = """"\n        for t, t1, t2 in zip(cleank, varsk, typek):  # first keys\n            if t2 == \'set\':\n                string_str = self._set_or_tuple(\'set\', \'columns\', t, t1)\n            elif t2 == \'tuple\':\n                string_str = self._set_or_tuple(\'tuple\', \'columns\', t, t1)\n            else:\n                if t not in _conversions:\n                    route = t\n                    cname, module = process_path(route)\n                    try:\n                        mod = __import__(module, globals(), locals(), [cname], 0)\n                    except (ImportError, ValueError) as ex:\n                        if cname in _conversions:\n                            raise Exception(""Error parsing the TypeSpec. Maybe you forgot a comma between the columns."")\n                        raise ImportError(""Can\'t import class {} from module {}"".format(cname, module))\n                    string_str = \',(""%s"", ""%s"")\' % (t1, t)\n                else:\n                    type = _conversions[t]\n                    string_str = \',(""%s"", ""%s"")\' % (t1, type)\n            concatenated_keys = concatenated_keys + string_str\n        concatenated_keys = concatenated_keys[1:]\n        return concatenated_keys\n\n    def _parse_dict(self, line, this):\n        split_line = line.split()\n        if len(split_line) == 2:\n            pk = split_line[1]\n            table = None\n        else:\n            pk = split_line[2]\n            table = split_line[1]\n        varsk, varsv, cleank, cleanv, typek, typevv = self._get_str_primary_keys_values(pk)\n        pks = self._get_dict_str(varsk, cleank, typek)\n        values = self._get_dict_str(varsv, cleanv, typevv)\n        if table == None:\n\n            final_dict = \'{""primary_keys"": [%s], ""columns"": [%s], ""type"": ""StorageDict""}\' % (pks, values)\n        else:\n            final_dict = \'{""%s"": {""primary_keys"": [%s], ""columns"": [%s], ""type"": ""StorageDict""}}\' % (table, pks, values)\n        final_dict = eval(final_dict)\n        aux = \'{""primary_keys"": [%s], ""columns"": [%s], ""type"": ""StorageDict""}\' % (pks, values)\n        if table in this:\n            this[table].update(eval(aux))\n            return this\n        return final_dict\n\n    def _parse_set_or_tuple(self, type, line, pk_or_col, this):\n        split_line = line.split()\n        table = split_line[1]\n        line = re.sub(\'[<>, ]\', \' \', split_line[2].replace(str(type), """"))\n        primary_keys = line.split()\n        converted_primary_keys = "", "".join([_conversions.get(w, w) for w in primary_keys])\n        if len(primary_keys) == 1:\n            string_str = \'{""%s"":{""%s"": ""%s"",""type"": ""%s""}}\' % (table, pk_or_col, converted_primary_keys, str(type))\n            final_string = eval(string_str)\n            aux = \'{""%s"": ""%s"",""type"": ""%s""}\' % (pk_or_col, converted_primary_keys, str(type))\n        else:\n            string_str = \'{""%s"":{""%s"": ""%s"",""type"": ""%s""}}\' % (table, pk_or_col, converted_primary_keys, str(type))\n            final_string = eval(string_str)\n            aux = \'{""%s"": {""%s""},""type"": ""%s""}\' % (pk_or_col, converted_primary_keys, str(type))\n        if table in this:\n            this[table].update(eval(aux))\n            return this\n        return final_string\n\n    def _parse_index(self, line, this):\n        \'\'\'Def: parses index declaration, checking for the introduced vars.\n                                Returns: a dict structure with the parsed dict.\'\'\'\n\n        if self.type_parser == ""TypeSpec"":\n            table = ""indexed_on""\n            atributes = line.split(\' \', 2)\n            atributes = atributes[1].replace("" "", \'\')\n        else:\n            table = line.split()[1]\n            atributes = line.split(\' \', 2)\n            atributes = atributes[2].replace("" "", \'\')\n\n        atributes = atributes.split(\',\')\n        converted_atributes = "", "".join([_conversions.get(w, w) for w in atributes])\n        converted_atributes = converted_atributes.split(\',\')\n        converted_atributes = [w.replace("" "", """") for w in converted_atributes]\n\n        if self.type_parser == ""TypeSpec"":\n            this[table] = converted_atributes\n        else:\n            if table in this:\n                this[table].update({\'indexed_on\': converted_atributes})\n            else:\n                this[table] = {\'indexed_on\': converted_atributes}\n\n        return this\n\n    def _parse_file(self, line, new):\n        \'\'\'Def: Checks if the file declaration is correct.\n                Returns: the file declaration with a dict structure\'\'\'\n        line = line.split("" "")\n        output = {}\n        table_name = line[1]\n        route = line[2]\n        cname, module = process_path(route)\n        try:\n            mod = __import__(module, globals(), locals(), [cname], 0)\n        except (ImportError, ValueError) as ex:\n            raise ImportError(""Can\'t import class {} from module {}"".format(cname, module))\n        output[""type""] = str(route)\n        if table_name in new:\n            new[table_name].update(output)\n        else:\n            new[table_name] = output\n        return new\n\n    def _parse_set_tuple_list(self, line, this):\n        if line.count(\'set\') > 0:\n            return self._parse_set_or_tuple(\'set\', line, \'primary_keys\', this)\n        elif line.count(\'tuple\') > 0:\n            return self._parse_set_or_tuple(\'tuple\', line, \'columns\', this)\n        elif line.count(\'list\') > 0:\n            return self._parse_set_or_tuple(\'list\', line, \'columns\', this)\n\n    def _parse_simple(self, line, this):\n        split_line = line.split()\n        table = split_line[1]\n        try:\n            type = _conversions[split_line[2]]\n        except KeyError as ex:\n            raise Exception(f""Type \'{split_line[2]}\' not identified."")\n        simple = \'{""%s"":{""type"":""%s""}}\' % (table, type)\n        simple = eval(simple)\n        if table in this:\n            this[table].update(simple)\n        return simple\n\n    def _input_type(self, line, this):\n        if line.count(\'<\') == 1:  # is tuple, set, list\n            aux = self._parse_set_tuple_list(line, this)\n        elif line.count(\'<\') == 0 and line.count(\'Index_on\') == 0 and line.count(\'.\') == 0 or (\n                line.count(\'numpy.ndarray\') and line.count(\'dict\') == 0):  # is simple type\n            aux = self._parse_simple(line, this)\n        elif line.count(\'Index_on\') == 1:\n            aux = self._parse_index(line, this)\n        elif line.count(\'.\') > 0 and line.count(\'dict\') == 0:\n            aux = self._parse_file(line, this)\n        else:  # is dict\n            aux = self._parse_dict(line, this)\n        return aux\n\n    def _remove_spaces_from_line(self, line):\n        \'\'\'Def: Remove all the spaces of the line splitted from comments\n                Returns: same line with no spaces.\'\'\'\n        line = re.sub(\' +\', \'*\', line)\n        if line.find(\'@Index_on\') == -1:\n            line = line[line.find(self.type_parser):]\n\n        if line.count(\'tuple\') == 1 and line.count(\'dict\') == 0:\n            pos = re.search(r\'\\b(tuple)\\b\', line)\n            pos = pos.start()\n        elif line.count(\'set\') == 1 and line.count(\'dict\') == 0:\n            pos = re.search(r\'\\b(set)\\b\', line)\n            pos = pos.start()\n        elif line.count(\'@Index_on\') == 1:\n            pos = line.find(\'@Index_on\')\n            line = line[pos:]\n            return line.replace(\'*\', \' \')\n        elif line.count(\'dict\') > 0:\n            pos = re.search(r\'\\b(dict)\\b\', line)\n            pos = pos.start()\n        elif line.count(\'list\') > 0:\n            pos = re.search(r\'\\b(list)\\b\', line)\n            pos = pos.start()\n        else:\n            return line.replace(\'*\', \' \')\n\n        line = line[0:pos].replace(\'*\', \' \') + line[pos:].replace(""*"", \'\')\n        return line\n\n    def _parse_comments(self, comments):\n        \'\'\'Def: Parses the comments param to a ClassField or TypeSpec type and checks if the comments are in the correct\n                format.\n                Returns: an structure with all the parsed comments.\'\'\'\n        this = {}\n        \'\'\'Erasing first and last line\'\'\'\n        str_splitted = comments.split(\'\\n\', 1)[-1]\n        lines = str_splitted.rsplit(\'\\n\', 1)[0]\n        \'\'\'\'\'\'\n        self.detect_errors_before(lines, self.type_parser)\n        if self.type_parser == ""TypeSpec"":\n            for line in lines.split(\'\\n\'):\n                this = self._input_type(self._remove_spaces_from_line(line), this)\n        if self.type_parser == ""ClassField"":\n            for line in lines.split(\'\\n\'):\n                this.update(self._input_type(self._remove_spaces_from_line(line), this))\n        self.detect_errors_after(this, self.type_parser)\n        return this\n\n    @staticmethod\n    def detect_errors_before(lines, type_parser):\n        bad_characters = ("";"", ""&"", ""("", "")"", ""["", ""]"", ""="", ""?"", ""\xc2\xbf"", ""!"", ""\xc2\xa1"")\n        # re.escape will escape \'|\' too, but it shouldn\'t be escaped, so \'a\' is a replacement\n        bad_characters = re.escape(""a"".join(bad_characters)).replace(""a"", ""|"")\n        bad_found = re.findall(bad_characters, lines)\n        if len(bad_found) > 0:\n            raise Exception(f""One or more bad character detected: [{\', \'.join(bad_found)}]."")\n\n        if type_parser == ""TypeSpec"":\n            if len(lines.split(""\\n"")) != 1:\n                raise Exception(""StorageDicts should only have one TypeSpec line."")\n            if lines.count(""<"") < 2 or lines.count("">"") < 2:\n                raise Exception(""The TypeSpec should have at least two \'<\' and two \'>\'. Format: ""\n                                ""@TypeSpec dict<<key:type>, value:type>."")\n        elif type_parser == ""ClassField"":\n            for line in lines.split(""\\n""):\n                if "":"" in line and ""dict"" not in line:\n                    line_error = line.replace(""    "", """")\n                    raise Exception(\n                        f""The ClassField {line_error} should only have the character \':\' if it is in a dict."")\n\n    @staticmethod\n    def detect_errors_after(output, type_parser):\n        if type_parser == ""TypeSpec"":\n            if ""primary_keys"" not in output:\n                raise Exception(""No detected keys. Maybe you forgot to set a primary key or ""\n                                ""there is a missing \'dict\' after the TypeSpec."")\n            elif ""columns"" not in output:\n                raise Exception(""No detected non-key columns."")\n        elif type_parser == ""ClassField"":\n            pass\n\n    def __init__(self, type_parser):\n        \'\'\'Initializes the Parser class with the type_parser that can be @ClassField or @TypeSpec.\'\'\'\n        self.type_parser = type_parser\n'"
hecuba_py/hecuba/qbeast.py,0,"b'import random\nimport string\nimport uuid\nfrom collections import namedtuple\n\nfrom hfetch import Hcache\n\nfrom . import config, log\nfrom .IStorage import IStorage\nfrom .storageiter import NamedItemsIterator\n\n\nclass QbeastMeta(object):\n    def __init__(self, mem_filter, from_point, to_point, precision):\n        self.precision = precision\n        self.from_point = from_point\n        self.to_point = to_point\n        self.mem_filter = mem_filter\n\n\nconfig.cluster.register_user_type(\'hecuba\', \'q_meta\', QbeastMeta)\n\n\nclass QbeastIterator(IStorage):\n    """"""\n    Object used to access data from workers.\n    """"""\n\n    args_names = [\'primary_keys\', \'columns\', \'indexed_on\', \'name\', \'qbeast_meta\', \'qbeast_random\',\n                  \'storage_id\', \'tokens\', \'class_name\', \'built_remotely\']\n    _building_args = namedtuple(\'QbeastArgs\', args_names)\n    _prepared_store_meta = config.session.prepare(\'INSERT INTO hecuba.istorage\'\n                                                  \'(primary_keys, columns, indexed_on, name, qbeast_meta,\'\n                                                  \' qbeast_random, storage_id, tokens, class_name)\'\n                                                  \'VALUES (?,?,?,?,?,?,?,?,?)\')\n    _prepared_set_qbeast_meta = config.session.prepare(\'INSERT INTO hecuba.istorage (storage_id, qbeast_meta) \'\n                                                       \'VALUES (?,?)\')\n\n    @staticmethod\n    def _store_meta(storage_args):\n        log.debug(""QbeastIterator: storing metas %s"", \'\')\n\n        try:\n            config.session.execute(QbeastIterator._prepared_store_meta,\n                                   [storage_args.primary_keys,\n                                    storage_args.columns,\n                                    storage_args.indexed_on,\n                                    storage_args.name,\n                                    storage_args.qbeast_meta,\n                                    storage_args.qbeast_random,\n                                    storage_args.storage_id,\n                                    storage_args.tokens,\n                                    storage_args.class_name])\n        except Exception as ex:\n            log.error(""Error creating the StorageDictIx metadata: %s %s"", storage_args, ex)\n            raise ex\n\n    def __init__(self, primary_keys, columns, indexed_on, name, qbeast_meta=None, qbeast_random=None,\n                 storage_id=None, tokens=None, **kwargs):\n        """"""\n        Creates a new block.\n        Args:\n            primary_keys (list(tuple)): a list of (key,type) primary keys (primary + clustering).\n            columns (list(tuple)): a list of (key,type) columns\n            indexed_on (list(str)): a list of the names of the indexed columns\n            name (string): keyspace.table of the Cassandra collection\n            qbeast_random (str): qbeast random string, when selecting in different nodes this must have the same value\n            storage_id (uuid): the storage id identifier\n            tokens (list): list of tokens\n        """"""\n        super().__init__((), name=name, storage_id=storage_id, **kwargs)\n\n        log.debug(""CREATED QbeastIterator(%s,%s,%s,%s)"", storage_id, tokens, )\n\n        self._qbeast_meta = qbeast_meta\n        self._primary_keys = primary_keys\n        self._columns = columns\n        self._indexed_on = indexed_on\n\n        if qbeast_random is None:\n            self._qbeast_random = \'\'.join(random.choice(string.ascii_letters + string.digits) for _ in range(5))\n        else:\n            self._qbeast_random = qbeast_random\n\n        class_name = \'%s.%s\' % (self.__class__.__module__, self.__class__.__name__)\n\n        self._primary_keys = [{""type"": key[1], ""name"": key[0]} if isinstance(key, tuple) else key\n                              for key in self._primary_keys]\n        self._columns = [{""type"": col[1], ""name"": col[0]} if isinstance(col, tuple) else col\n                         for col in self._columns]\n\n        key_names = [col[""name""] for col in self._primary_keys]\n        column_names = [col[""name""] for col in self._columns]\n        if len(key_names) > 1:\n            self._key_builder = namedtuple(\'row\', key_names)\n        else:\n            self._key_builder = None\n        if len(column_names) > 1:\n            self._column_builder = namedtuple(\'row\', column_names)\n        else:\n            self._column_builder = None\n\n        self._k_size = len(primary_keys)\n\n        build_keys = [(key[""name""], key[""type""]) for key in self._primary_keys]\n        build_columns = [(col[""name""], col[""type""]) for col in self._columns]\n\n        self._build_args = self._building_args(\n            build_keys,\n            build_columns,\n            self._indexed_on,\n            self._ksp + ""."" + self._table,\n            self._qbeast_meta,\n            self._qbeast_random,\n            self.storage_id,\n            self._tokens,\n            class_name,\n            self._built_remotely)\n\n        if name or storage_id:\n            self.make_persistent(name)\n\n    def make_persistent(self, name):\n        # Update local QbeastIterator metadata\n        super().make_persistent(name)\n        self._build_args = self._build_args._replace(storage_id=self.storage_id, name=self._ksp + ""."" + self._table,\n                                                     tokens=self._tokens)\n\n        self._setup_hcache()\n\n        QbeastIterator._store_meta(self._build_args)\n\n    def _setup_hcache(self):\n        key_names = [key[""name""] for key in self._primary_keys]\n        persistent_values = [{""name"": col[""name""]} for col in self._columns]\n\n        if self._tokens is None:\n            raise RuntimeError(""Tokens for object {} are null"".format(self._get_name()))\n\n        self._hcache_params = (self._ksp, self._table,\n                               self.storage_id,\n                               self._tokens, key_names, persistent_values,\n                               {\'cache_size\': config.max_cache_size,\n                                \'writer_par\': config.write_callbacks_number,\n                                \'writer_buffer\': config.write_buffer_size,\n                                \'timestamped_writes\': config.timestamped_writes})\n        log.debug(""HCACHE params %s"", self._hcache_params)\n        self._hcache = Hcache(*self._hcache_params)\n\n    def _set_qbeast_meta(self, qbeast_meta):\n        self._qbeast_meta = qbeast_meta\n        self._build_args = self._build_args._replace(qbeast_meta=qbeast_meta)\n        config.session.execute(QbeastIterator._prepared_set_qbeast_meta, [self.storage_id, qbeast_meta])\n\n    def __len__(self):\n        return len([row for row in self.__iter__()])\n\n    def __iter__(self):\n        if hasattr(self, ""_qbeast_meta"") and self._qbeast_meta is not None:\n            conditions = """"\n            for index, (from_p, to_p) in enumerate(zip(self._qbeast_meta.from_point, self._qbeast_meta.to_point)):\n                conditions += ""{0} > {1} AND {0} < {2} AND "".format(self._indexed_on[index], from_p, to_p)\n\n            conditions = conditions[:-5] + self._qbeast_meta.mem_filter\n\n            conditions += "" AND expr(%s_idx, \'precision=%s:%s\') ALLOW FILTERING"" \\\n                          % (self._table, self._qbeast_meta.precision, self._qbeast_random)\n\n            hiter = self._hcache.iteritems({\'custom_select\': conditions, \'prefetch_size\': config.prefetch_size})\n        else:\n            hiter = self._hcache.iteritems(config.prefetch_size)\n\n        return NamedItemsIterator(self._key_builder, self._column_builder, self._k_size, hiter, self)\n'"
hecuba_py/hecuba/storageiter.py,0,"b""from collections import namedtuple\n\n\nclass NamedIterator:\n    # Class that allows to iterate over the keys or the values of a dict\n    def __init__(self, hiterator, builder, father):\n        self.hiterator = hiterator\n        self.builder = builder\n        self._storage_father = father\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        n = self.hiterator.get_next()\n        if self.builder is not None:\n            if self._storage_father._get_set_types() is not None:\n                nkeys = len(n) - len(self._storage_father._get_set_types())\n                n = n[:nkeys]\n            return self.builder(*n)\n        else:\n            return n[0]\n\n\nclass NamedItemsIterator:\n    # Class that allows to iterate over the keys and the values of a dict\n    builder = namedtuple('row', 'key, value')\n\n    def __init__(self, key_builder, column_builder, k_size, hiterator, father):\n        self.key_builder = key_builder\n        self.k_size = k_size\n        self.column_builder = column_builder\n        self.hiterator = hiterator\n        self._storage_father = father\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        n = self.hiterator.get_next()\n        if self.key_builder is None:\n            k = n[0]\n        else:\n            k = self.key_builder(*n[0:self.k_size])\n        if self.column_builder is None:\n            v = n[self.k_size]\n        else:\n            v = self.column_builder(*n[self.k_size:])\n        return self.builder(k, v)\n"""
hecuba_py/hecuba/storageobj.py,1,"b'from collections import namedtuple\n\nimport numpy as np\nfrom . import config, log, Parser\n\nfrom .hnumpy import StorageNumpy\nfrom .IStorage import IStorage\n\nfrom .tools import count_name_collision, get_istorage_attrs, build_remotely, storage_id_from_name, basic_types, \\\n    valid_types\n\n\nclass StorageObj(IStorage):\n    args_names = [""name"", ""tokens"", ""storage_id"", ""class_name"", ""built_remotely""]\n    args = namedtuple(\'StorageObjArgs\', args_names)\n    _prepared_store_meta = config.session.prepare(\'INSERT INTO hecuba.istorage\'\n                                                  \'(storage_id, class_name, name, tokens) \'\n                                                  \' VALUES (?,?,?,?)\')\n\n    """"""\n    This class is where information will be stored in Hecuba.\n    The information can be in memory, stored in a python dictionary or local variables, or saved in a\n    DB(Cassandra), depending on if it\'s persistent or not.\n    """"""\n\n    @staticmethod\n    def _store_meta(storage_args):\n        """"""\n            Saves the information of the object in the istorage table.\n            Args:\n                storage_args (object): contains all data needed to restore the object from the workers\n        """"""\n        log.debug(""StorageObj: storing media %s"", storage_args)\n        try:\n\n            config.session.execute(StorageObj._prepared_store_meta,\n                                   [storage_args.storage_id,\n                                    storage_args.class_name,\n                                    storage_args.name,\n                                    storage_args.tokens])\n        except Exception as ex:\n            log.warn(""Error creating the StorageDict metadata: %s, %s"", str(storage_args), ex)\n            raise ex\n\n    @classmethod\n    def _parse_comments(cls, comments):\n        parser = Parser(""ClassField"")\n        return parser._parse_comments(comments)\n\n    def __init__(self, name=\'\', storage_id=None, *args, **kwargs):\n        """"""\n            Creates a new storageobj.\n            Args:\n                name (string): the name of the Cassandra Keyspace + table where information can be found\n                tokens (list of tuples): token ranges assigned to the new StorageObj\n                storage_id (string):  an unique storageobj identifier\n                kwargs: more optional parameters\n        """"""\n\n        # Assign private attributes\n        self._persistent_props = StorageObj._parse_comments(self.__doc__)\n        self._persistent_attrs = self._persistent_props.keys()\n        self._class_name = \'%s.%s\' % (self.__class__.__module__, self.__class__.__name__)\n\n        super().__init__(*args, **kwargs)\n\n        self._build_args = self.args(\'\', [], None, self._class_name, self._built_remotely)\n\n        if storage_id and not name:\n            name = get_istorage_attrs(storage_id)[0].name\n\n        if name or storage_id:\n            self.make_persistent(name)\n        log.debug(""CREATED StorageObj(%s)"", self._get_name())\n\n    def __eq__(self, other):\n        return self.__class__ == other.__class__ and self.getID() == other.getID()\n\n    def _persist_attributes(self):\n        """"""\n        Persist in-memory attributes to the data store\n        """"""\n        for attribute in self._persistent_props.keys():\n            try:\n                val = super().__getattribute__(attribute)\n                setattr(self, attribute, val)\n            except AttributeError:\n                pass\n\n    def _build_is_attribute(self, attribute, persistence_name, storage_id):\n        # Build the IStorage obj\n        info = {""tokens"": self._tokens, ""storage_id"": storage_id}\n        info.update(self._persistent_props[attribute])\n        info[""built_remotely""] = self._built_remotely\n        info[\'name\'] = persistence_name\n        return build_remotely(info)\n\n    def _create_tables(self):\n        """"""\n            Setups the python structures used to communicate with the backend.\n            Creates the necessary tables on the backend to store the object data.\n        """"""\n\n        log.info(""CREATING KEYSPACE AND TABLE %s %s"", self._ksp, self._table)\n\n        query_keyspace = ""CREATE KEYSPACE IF NOT EXISTS %s WITH replication = %s"" % (self._ksp, config.replication)\n        config.session.execute(query_keyspace)\n\n        query_simple = \'CREATE TABLE IF NOT EXISTS \' + self._ksp + \'.\' + self._table + \\\n                       \'( storage_id uuid PRIMARY KEY, \'\n        for key, entry in self._persistent_props.items():\n            query_simple += str(key) + \' \'\n            if entry[\'type\'] != \'dict\' and entry[\'type\'] in valid_types:\n                if entry[\'type\'] == \'list\' or entry[\'type\'] == \'tuple\':\n                    query_simple += entry[\'type\'] + \'<\' + entry[\'columns\'] + \'>, \'\n                else:\n                    query_simple += entry[\'type\'] + \', \'\n            else:\n                query_simple += \'uuid, \'\n        try:\n            config.session.execute(query_simple[:-2] + \' )\')\n        except Exception as ir:\n            log.error(""Unable to execute %s"", query_simple)\n            raise ir\n\n    def _flush_to_storage(self):\n        super()._flush_to_storage()\n\n        for attr_name in self._persistent_attrs:\n            attr = getattr(super(), attr_name, None)\n            if isinstance(attr, IStorage):\n                attr._flush_to_storage()\n\n    def make_persistent(self, name):\n        """"""\n            Once a StorageObj has been created, it can be made persistent. This function retrieves the information about\n            the Object class schema, and creates a Cassandra table with those parameters, where information will be\n            saved from now on, until execution finishes or StorageObj is no longer persistent.\n            It also inserts into the new table all information that was in memory assigned to the StorageObj prior to\n            this call.\n            Args:\n                name (string): name with which the table in the DB will be created\n        """"""\n        # Update name\n\n        super().make_persistent(name)\n\n        self._table = self.__class__.__name__.lower()\n\n        # Arguments used to build objects remotely\n        self._build_args = self.args(self._get_name(),\n                                     self._tokens,\n                                     self.storage_id,\n                                     self._class_name,\n                                     self._built_remotely)\n\n        # If never existed, must create the tables and register\n        if not self._built_remotely:\n            self._create_tables()\n\n        # Iterate over the objects the user has requested to be persistent\n        # retrieve them from memory and make them persistent\n        self._persist_attributes()\n\n        StorageObj._store_meta(self._build_args)\n\n    def stop_persistent(self):\n        """"""\n            The StorageObj stops being persistent, but keeps the information already stored in Cassandra\n        """"""\n        log.debug(""STOP PERSISTENT"")\n\n        for obj_name in self._persistent_attrs:\n            try:\n                attr = object.__getattribute__(self, obj_name)\n            except AttributeError:\n                attr = None\n\n            if isinstance(attr, IStorage):\n                attr.stop_persistent()\n\n        super().stop_persistent()\n        self.storage_id = None\n\n    def delete_persistent(self):\n        """"""\n            Deletes the Cassandra table where the persistent StorageObj stores data\n        """"""\n        log.debug(""DELETE PERSISTENT: %s"", self._table)\n\n        for obj_name in self._persistent_attrs:\n            attr = getattr(self, obj_name, None)\n            if isinstance(attr, IStorage):\n                attr.delete_persistent()\n\n        query = ""TRUNCATE TABLE %s.%s;"" % (self._ksp, self._table)\n        config.session.execute(query)\n\n        query = ""DELETE FROM hecuba.istorage where storage_id={}"".format(self.storage_id)\n        config.session.execute(query)\n\n        super().delete_persistent()\n        self.storage_id = None\n\n    def __getattr__(self, attribute):\n        """"""\n            Given an attribute, this function returns the value, obtaining it from either:\n            a) memory\n            b) the Database\n            Args:\n                attribute: name of the value that we want to obtain\n            Returns:\n                value: obtained value\n        """"""\n        if attribute.startswith(\'_\') or attribute not in self._persistent_attrs:\n            return super().__getattribute__(attribute)\n\n        if not self.storage_id:\n            if self._persistent_props[attribute][""type""] not in basic_types:\n                value = self._build_is_attribute(attribute, persistence_name=\'\', storage_id=None)\n                super().__setattr__(attribute, value)\n            return super().__getattribute__(attribute)\n\n        \'\'\'\n        StorageObj is persistent.\n        If the attribute is not a built-in object, we might have it in memory. \n        Since python works using references any modification from another reference will affect this attribute,\n        which is the expected behaviour. Therefore, is safe to store in-memory the Hecuba objects.\n        \'\'\'\n        try:\n            return super().__getattribute__(attribute)\n        except AttributeError as ex:\n            # Not present in memory, we will need to rebuild it\n            pass\n\n        query = ""SELECT %s FROM %s.%s WHERE storage_id = %s;"" % (attribute, self._ksp, self._table, self.storage_id)\n        log.debug(""GETATTR: %s"", query)\n        try:\n            result = config.session.execute(query)\n        except Exception as ex:\n            log.warn(""GETATTR ex %s"", ex)\n            raise ex\n\n        is_istorage_attr = self._persistent_props[attribute][""type""] not in basic_types\n\n        try:\n            value = result[0][0]\n            # if exists but is set to None, the current behaviour is raising AttributeError\n            if not is_istorage_attr and value is None:\n                raise AttributeError(\'value not found\')\n        except IndexError as ex:\n            if not is_istorage_attr:\n                raise AttributeError(\'value not found\')\n            value = None\n        except TypeError as ex:\n            log.warn(""ERROR ON QUERY RESULT {}"".format(str(result)))\n            raise ex\n\n        if is_istorage_attr:\n            # Value is uuid or None, because it was not found\n\n            attr_name = attribute.lower()\n            my_name = self._get_name()\n            trailing_name = my_name[my_name.rfind(\'.\') + 1:]\n\n            count = count_name_collision(self._ksp, trailing_name, attr_name)\n            attr_name = self._ksp + \'.\' + trailing_name + \'_\' + attr_name\n            if count > 1:\n                attr_name += \'_\' + str(count - 2)\n\n            if value is None:\n                value = storage_id_from_name(attr_name)\n\n            value = self._build_is_attribute(attribute, persistence_name=attr_name, storage_id=value)\n\n        super().__setattr__(attribute, value)\n        return value\n\n    def __setattr__(self, attribute, value):\n        """"""\n            Given a key and its value, this function saves it (depending on if it\'s persistent or not):\n                a) In memory\n                b) In the DB\n            Args:\n                attribute: name of the value that we want to set\n                value: value that we want to save\n        """"""\n        if attribute[0] is \'_\' or attribute not in self._persistent_attrs:\n            super().__setattr__(attribute, value)\n            return\n\n        # Transform numpy.ndarrays and python dicts to StorageNumpy and StorageDicts\n        if not isinstance(value, IStorage):\n            if isinstance(value, np.ndarray):\n                value = StorageNumpy(value)\n            elif isinstance(value, dict):\n                per_dict = self._persistent_props[attribute]\n                info = {""name"": \'\', ""tokens"": self._build_args.tokens, ""storage_id"": None,\n                        ""built_remotely"": self._built_remotely}\n                info.update(per_dict)\n                new_value = build_remotely(info)\n                new_value.update(value)\n                value = new_value\n\n        if self.storage_id:\n            # Write attribute to the storage\n            if isinstance(value, IStorage):\n                if not value.storage_id:\n                    attr_name = attribute.lower()\n                    my_name = self._get_name()\n                    trailing_name = my_name[my_name.rfind(\'.\') + 1:]\n\n                    count = count_name_collision(self._ksp, trailing_name, attr_name)\n                    attr_name = self._ksp + \'.\' + trailing_name + \'_\' + attr_name\n                    if count != 0:\n                        attr_name += \'_\' + str(count - 1)\n                    value.make_persistent(attr_name)\n                # We store the storage_id when the object belongs to an Hecuba class\n                values = [self.storage_id, value.storage_id]\n                # We store the IStorage object in memory, to avoid rebuilding when it is not necessary\n            else:\n                values = [self.storage_id, value]\n\n            query = ""INSERT INTO %s.%s (storage_id,%s)"" % (self._ksp, self._table, attribute)\n            query += "" VALUES (%s,%s)""\n\n            log.debug(""SETATTR: "" + query)\n            config.session.execute(query, values)\n\n        # We store all the attributes in memory\n        super().__setattr__(attribute, value)\n\n    def __delattr__(self, name):\n        """"""\n        Method that deletes a given attribute from a StorageObj\n        Args:\n            item: the name of the attribute to be deleted\n        """"""\n        super().__delattr__(name)\n\n        if self.storage_id and name in self._persistent_attrs:\n            query = ""UPDATE %s.%s SET %s = null WHERE storage_id = %s"" % (\n                self._ksp, self._table, name, self.storage_id)\n            config.session.execute(query)\n'"
hecuba_py/hecuba/tools.py,0,"b'import uuid\nfrom . import config\n\nvalid_types = [\'counter\', \'text\', \'boolean\', \'decimal\', \'double\', \'int\', \'list\', \'set\', \'map\', \'bigint\', \'blob\',\n               \'tuple\', \'dict\', \'float\', \'timestamp\', \'time\', \'date\', \'numpy.ndarray\']\n\nbasic_types = valid_types[:-1]\n\n\ndef storage_id_from_name(name):\n    return uuid.uuid3(uuid.NAMESPACE_DNS, name)\n\n\ndef process_path(module_path):\n    """"""\n    Method to obtain module and class_name from a module path\n    Args:\n        module_path(String): path in the format module.class_name\n    Returns:\n        tuple containing class_name and module\n    """"""\n\n    if module_path == \'numpy.ndarray\':\n        return \'StorageNumpy\', \'hecuba.hnumpy\'\n    if module_path == \'StorageDict\':\n        return \'StorageDict\', \'hecuba.hdict\'\n    last = 0\n    for key, i in enumerate(module_path):\n        if i == \'.\' and key > last:\n            last = key\n    module = module_path[:last]\n    class_name = module_path[last + 1:]\n    return class_name, module\n\n\n""""""\n Cassandra related methods\n""""""\n\n_size_estimates = config.session.prepare((""SELECT mean_partition_size, partitions_count ""\n                                          ""FROM system.size_estimates WHERE keyspace_name=? and table_name=?""))\n_max_token = int(((2 ** 63) - 1))  # type: int\n_min_token = int(-2 ** 63)  # type: int\n\n_select_istorage_meta = config.session.prepare(""SELECT * FROM hecuba.istorage WHERE storage_id = ?"")\n\n\ndef extract_ks_tab(name):\n    """"""\n    Method used to obtain keyspace and table from a given name\n    Args:\n        name: a string containing keyspace name and table name, or only table name\n    Returns:\n        a tuple containing keyspace name and table name\n    """"""\n    if not name:\n        return None, None\n\n    sp = name.split(""."")\n    if len(sp) == 2:\n        ksp = sp[0]\n        table = sp[1]\n    else:\n        ksp = config.execution_name\n        table = name\n    return ksp.lower(), table.lower()\n\n\ndef tokens_partitions(ksp, table, tokens_ranges):\n    """"""\n    Method that calculates the new token partitions for a given object\n    Args:\n        tokens: current number of tokens of the object\n        min_tokens_per_worker: defined minimum number of tokens\n        number_of_workers: defined\n    Returns:\n        a partition every time it\'s called\n        :type tokens_ranges: list[(long,long)]\n    """"""\n    from collections import defaultdict\n    from bisect import bisect_right\n    from cassandra.metadata import Murmur3Token\n\n    splits_per_node = config.splits_per_node\n    token_range_size = config.token_range_size\n    target_token_range_size = config.target_token_range_size\n\n    tm = config.cluster.metadata.token_map\n    tmap = tm.tokens_to_hosts_by_ks.get(ksp, None)\n\n    tokens_murmur3 = map(lambda a: (Murmur3Token(a[0]), a[1]), tokens_ranges)\n    if not tmap:\n        tm.rebuild_keyspace(ksp, build_if_absent=True)\n        tmap = tm.tokens_to_hosts_by_ks[ksp]\n\n    tokens_per_node = defaultdict(list)\n    for tmumur, t_to in tokens_murmur3:\n        point = bisect_right(tm.ring, tmumur)\n        if point == len(tm.ring):\n            tokens_per_node[tmap[tm.ring[0]][0]].append((tmumur.value, t_to))\n        else:\n            tokens_per_node[tmap[tm.ring[point]][0]].append((tmumur.value, t_to))\n\n    n_nodes = len(tokens_per_node)\n    step_size = _max_token // (splits_per_node * n_nodes)\n    if token_range_size:\n        step_size = token_range_size\n    elif target_token_range_size:\n        one = config.session.execute(_size_estimates, [ksp, table]).one()\n        if one:\n            (mean_p_size, p_count) = one\n            estimated_size = mean_p_size * p_count\n            if estimated_size > 0:\n                step_size = _max_token // int(\n                    max(estimated_size / target_token_range_size,\n                        splits_per_node * n_nodes)\n                )\n\n    for tokens_in_node in tokens_per_node.values():\n        partition = []\n        for fraction, to in tokens_in_node:\n            while fraction < to - step_size:\n                partition.append((fraction, fraction + step_size))\n                fraction += step_size\n            partition.append((fraction, to))\n        group_size = max(len(partition) // splits_per_node, 1)\n        for i in range(0, len(partition), group_size):\n            yield partition[i:i + group_size]\n\n\ndef generate_token_ring_ranges():\n    ring = config.cluster.metadata.token_map.ring\n    tokens = [token.value for token in ring]\n    return discrete_token_ranges(tokens)\n\n\ndef discrete_token_ranges(tokens):\n    """"""\n    Makes proper tokens ranges ensuring that in a tuple (a,b) a <= b\n    Args:\n        tokens:  a list of tokens [1, 0, 10]\n    Returns:\n         a rationalized list [(-1, 0),(0,10),(10, max)]\n    """"""\n    tokens.sort()\n    if len(tokens) == 0:\n        return tokens\n    if tokens[0] > _min_token:\n        token_ranges = [(_min_token, tokens[0])]\n    else:\n        token_ranges = []\n    n_tns = len(tokens)\n    for i in range(0, n_tns - 1):\n        token_ranges.append((tokens[i], tokens[i + 1]))\n    token_ranges.append((tokens[n_tns - 1], _max_token))\n    return token_ranges\n\n\ndef count_name_collision(ksp, table, attribute):\n    import re\n    m = re.compile(""^%s_%s(_[0-9]+)?$"" % (table, attribute))\n    q = config.session.execute(""SELECT table_name FROM  system_schema.tables WHERE keyspace_name = %s"",\n                               [ksp])\n    return sum(1 for elem in q if m.match(elem[0]))\n\n\ndef get_istorage_attrs(storage_id):\n    return list(config.session.execute(_select_istorage_meta, [storage_id]))\n\n\ndef build_remotely(args):\n    """"""\n    Takes the information which consists of at least the type,\n    :raises TypeError if the object class doesn\'t subclass IStorage\n    :param obj_info: Contains the information to be used to create the IStorage obj\n    :return: An IStorage object\n    """"""\n    if ""built_remotely"" not in args.keys():\n        built_remotely = True\n    else:\n        built_remotely = args[""built_remotely""]\n\n    obj_type = args.get(\'class_name\', args.get(\'type\', None))\n    if obj_type is None:\n        raise TypeError(""Trying to build an IStorage obj without giving the type"")\n\n    # Import the class defined by obj_type\n    cname, module = process_path(obj_type)\n\n    \'\'\'\n    if obj_type == str(StorageNumpy.__class__):\n        return StorageNumpy(name=args[""name""], storage_id=args[""storage_id""])\n    \'\'\'\n    try:\n        mod = __import__(module, globals(), locals(), [cname], 0)\n    except ValueError:\n        raise ValueError(""Can\'t import class {} from module {}"".format(cname, module))\n\n    imported_class = getattr(mod, cname)\n\n    args = {k: v for k, v in args.items() if k in imported_class.args_names}\n    args.pop(\'class_name\', None)\n    args[""built_remotely""] = built_remotely\n\n    return imported_class(**args)\n'"
hecuba_py/tests/__init__.py,0,"b'import atexit\nimport ccmlib.cluster\nimport os\nimport sys\nimport tempfile\nimport logging\nfrom distutils.util import strtobool\n\n\nclass TestConfig:\n    pass\n\n\ntest_config = TestConfig()\ntest_config.n_nodes = int(os.environ.get(\'TEST_CASSANDRA_N_NODES\', \'2\'))\nTEST_DEBUG = strtobool(os.environ.get(""TEST_DEBUG"", ""False"").lower())\nif TEST_DEBUG:\n    logging.warning((""You are using TEST_DEBUG=True, a Cassandra cluster must be already running. ""\n                     ""Keep in mind that the results of the test might be altered by data already existing.""))\n\n\ndef set_ccm_cluster():\n    global test_config\n    test_config.ccm_cluster = ccmlib.cluster.Cluster(\n        tempfile.mkdtemp(""tmp_data""),\n        \'hecuba_test\',\n        cassandra_version=os.environ.get(\'TEST_CASSANDRA_VERSION\', \'3.11.4\'))\n\n\ndef set_up_default_cassandra():\n    global test_config\n    if hasattr(test_config, ""ccm_cluster"") and any(\n            map(lambda node: node.is_live(), test_config.ccm_cluster.nodes.values())):\n        return\n\n    set_ccm_cluster()\n    try:\n        test_config.ccm_cluster.populate(test_config.n_nodes).start(allow_root=True,jvm_args=[""-Xss512k""])\n    except Exception as a:\n        if TEST_DEBUG:\n            logging.warning(""TEST_DEBUG: ignoring exception"")\n        else:\n            raise a\n\n    if \'hecuba\' in sys.modules:\n        import importlib\n        import hecuba\n        importlib.reload(hecuba)\n\n\n@atexit.register\ndef turning_down_cassandra():\n    global test_config\n    if test_config is None or not hasattr(test_config, ""ccm_cluster""):\n        return\n\n    print(""Turning down Cassandra"")\n    from hfetch import disconnectCassandra\n    disconnectCassandra()\n    test_config.ccm_cluster.stop()\n    test_config.ccm_cluster.clear()\n\n\nset_up_default_cassandra()\n'"
hecuba_py/tests/block_tests.py,0,"b'import unittest\nimport uuid\n\nfrom mock import Mock\nfrom .app.words import Words\nfrom hecuba.IStorage import build_remotely\n\n\nclass MockStorageObj:\n    pass\n\n\nclass BlockTest(unittest.TestCase):\n    def test_astatic_creation(self):\n        # TODO This test passes StorageDict arguments (results) to a StorageObj. Fix this test.\n\n        results = {""built_remotely"": False, ""storage_id"": uuid.uuid4(), ""class_name"": \'tests.app.words.Words\',\n                   ""name"": \'ksp1.tab1\',\n                   ""columns"": [(\'val1\', \'str\')], ""entry_point"": \'localhost\', ""primary_keys"": [(\'pk1\', \'int\')],\n                   ""istorage_props"": {}, ""tokens"": [(1, 2), (2, 3), (3, 4), (3, 5)]}\n\n        words_mock_methods = Words._create_tables, Words._persist_attributes, Words._store_meta\n\n        Words._create_tables = Mock(return_value=None)\n        Words._persist_attributes = Mock(return_value=None)\n        Words._store_meta = Mock(return_value=None)\n\n        from hecuba import StorageDict\n        sdict_mock_methods = StorageDict.make_persistent\n        StorageDict.make_persistent = Mock(return_value=None)\n\n        b = build_remotely(results)\n        self.assertIsInstance(b, Words)\n        Words._create_tables.assert_called_once()\n        Words._persist_attributes.assert_called_once()\n        assert (b._ksp == ""ksp1"")\n        assert (b._table == b.__class__.__name__.lower())\n\n        Words._create_tables, Words._persist_attributes, Words._store_meta = words_mock_methods\n        StorageDict.make_persistent = sdict_mock_methods\n\n    def test_iter_and_get_sets(self):\n        """"""\n        The iterator should read the same elements I can get with a __getitem__\n        :return:\n        """"""\n        from hecuba.hdict import StorageDict\n        b = StorageDict(None, [(\'pk1\', \'str\')], [(\'val\', \'int\')])\n\n        b[\'test1\'] = 123124\n        self.assertEqual(123124, b[\'test1\'])\n\n    def test_getID(self):\n        """"""\n        Checks that the id is the same\n        :return:\n        """"""\n        from hecuba.hdict import StorageDict\n        old = StorageDict.__init__\n        StorageDict.__init__ = Mock(return_value=None)\n        bl = StorageDict()\n        u = uuid.uuid4()\n        bl.storage_id = u\n        self.assertEquals(u, bl.storage_id)\n        StorageDict.__init__ = old\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
hecuba_py/tests/hdict_tests.py,0,"b""import unittest\n\nfrom hecuba import StorageDict\n\n\nclass TestHdict(StorageDict):\n    '''\n        @TypeSpec dict<<position:int>,text:str>\n    '''\n    pass\n\n\nclass HdictTest(unittest.TestCase):\n\n    # TEST POSSIBLE WRONG INPUTS\n\n    ######################################################################\n\n    # SAME AS STORAGEOBJ\n\n    ######################################################################\n\n    # IMPLEMENTATION\n\n    # PARSE X DATA\n\n    def test_parse_2(self):\n        comment = '''\n            @TypeSpec dict<<partid:int>,x:int,y:int,z:int>\n            '''\n        pd = StorageDict(None,\n                         [('pk1', 'int')],\n                         [('val1', 'text')])\n        p = pd._parse_comments(comment)\n        should_be = {\n            'columns': [('x', 'int'), ('y', 'int'), ('z', 'int')],\n            'primary_keys': [('partid', 'int')],\n            'type': 'StorageDict'\n        }\n        self.assertEquals(p, should_be)\n"""
hecuba_py/tests/storagedict_tests.py,0,"b""import unittest\n\nfrom hecuba import Config\nfrom hecuba.hdict import StorageDict\n\n\nclass StorageDict_Tests(unittest.TestCase):\n\n    def test_init(self):\n        pass\n\n    def inmemory_contains_test(self):\n        pd = StorageDict(None,\n                         [('pk1', 'int')],\n                         [('val1', 'text')])\n        pd[3] = '4'\n        self.assertEqual(True, 3 in pd)\n        self.assertEqual('4', pd[3])\n\n    def inmemory_keys_test(self):\n        pd = StorageDict(None,\n                         [('pk1', 'int'), ('pk2', 'int')],\n                         [('val1', 'text')])\n\n        pd[0] = '1'\n        pd[1] = '2'\n        pd[2] = '3'\n        pd[3] = '4'\n        self.assertEqual({0, 1, 2, 3}, set(pd.keys()))\n\n    def inmemory_composed_keys_test(self):\n        pd = StorageDict(None,\n                         [('pk1', 'int'), ('pk2', 'int')],\n                         [('val1', 'text')])\n\n        pd[0, 1] = '1'\n        pd[1, 1] = '2'\n        pd[2, 0] = '3'\n        pd[3, 1] = '4'\n        self.assertEqual({(0, 1), (1, 1), (2, 0), (3, 1)}, set(pd.keys()))\n\n    def inmemory_getitem_setitem_test(self):\n        pd = StorageDict(None,\n                         [('pk1', 'int'), ('pk2', 'int')],\n                         [('val1', 'text')])\n\n        import random\n        types = [random.randint(0, 100), random.random(),\n                 float(random.random()), 'string_rand_' + str(random.random())\n                 ]\n        typeskeys = types[:]\n        typeskeys.append([i for i in range(random.randint(0, 100))])\n        typeskeys.append(False)\n\n        for key in types:\n            for value in typeskeys:\n                pd[key] = value\n                self.assertEqual(pd[key], value)\n"""
hecuba_py/tests/storageobj_tests.py,0,"b'import unittest\n\nfrom hecuba import config, Config\nfrom hecuba.storageobj import StorageObj\nfrom mock import Mock\n\nfrom .app.words import Words\n\n\nclass TestStorageObj(StorageObj):\n    \'\'\'\n       @ClassField test dict<<position:int>,text:str>\n    \'\'\'\n    pass\n\n\nclass StorageObjTest(unittest.TestCase):\n    def test_parse_comments(self):\n        result = {\'instances\': {\'columns\': [(\'instances\',\n                                             \'counter\')],\n                                \'primary_keys\': [(\'word\',\n                                                  \'text\')],\n                                \'type\': \'StorageDict\'}}\n        result_comment = "" @ClassField instances dict<<word:str>,instances:atomicint> ""\n\n        p = StorageObj._parse_comments(result_comment)\n        self.assertEqual(result, p)\n\n        words = {\'wordinfo\': {\'columns\': [(\'wordinfo\', \'text\')],\n                              \'primary_keys\': [(\'position\',\n                                                \'int\')],\n                              \'type\': \'StorageDict\'}}\n        words_comment = \'  @ClassField wordinfo dict<<position:int>,wordinfo:str> \'\n        p = StorageObj._parse_comments(words_comment)\n        self.assertEqual(words, p)\n\n        both = {\'wordinfo\': {\'columns\': [(\'wordinfo\', \'text\')],\n                             \'primary_keys\': [(\'position\',\n                                               \'int\')],\n                             \'type\': \'StorageDict\'},\n                \'instances\': {\'columns\': [(\'instances\',\n                                           \'counter\')],\n                              \'primary_keys\': [(\'word\',\n                                                \'text\')],\n                              \'type\': \'StorageDict\'}\n                }\n        both_comment = ""\'\'\'\\n@ClassField wordinfo dict<<position:int>,wordinfo:str>\\n "" + \\\n                       ""@ClassField instances dict<<word:str>,instances:atomicint>\\n\'\'\' ""\n        p = StorageObj._parse_comments(both_comment)\n        self.assertEqual(both, p)\n\n        both2 = {\'wordinfo\': {\'columns\': [(\'wordinfo\', \'text\')],\n                              \'primary_keys\': [(\'position\',\n                                                \'int\')],\n                              \'type\': \'StorageDict\'},\n                 \'instances\': {\'columns\': [(\'instances\',\n                                            \'counter\')],\n                               \'primary_keys\': [(\'word\',\n                                                 \'text\')],\n                               \'type\': \'StorageDict\'\n                               }\n                 }\n        both_comment = ""\'\'\'\\n@ClassField wordinfo dict<<position:int>,wordinfo:str>\\n "" + \\\n                       ""  @ClassField instances dict<<word:str>,instances:atomicint>\\n\'\'\'""\n        p = StorageObj._parse_comments(both_comment)\n        self.assertEqual(both2, p)\n\n    def test_parse_2(self):\n        comment = ""     @ClassField particles dict<<partid:int>,x:int,y:int,z:int>""\n        p = StorageObj._parse_comments(comment)\n        should_be = {\'particles\': {\n            \'columns\': [(\'x\', \'int\'), (\'y\', \'int\'), (\'z\', \'int\')],\n            \'primary_keys\': [(\'partid\', \'int\')],\n            \'type\': \'StorageDict\'\n        }}\n        self.assertEquals(p, should_be)\n\n    def test_parse_3(self):\n        comment = ""     @ClassField particles dict<<partid:int,part2:str>,x:int,y:int,z:int>""\n        p = StorageObj._parse_comments(comment)\n        should_be = {\'particles\': {\n            \'columns\': [(\'x\', \'int\'), (\'y\', \'int\'), (\'z\', \'int\')],\n            \'primary_keys\': [(\'partid\', \'int\'), (\'part2\', \'text\')],\n            \'type\': \'StorageDict\'\n        }}\n        self.assertEquals(p, should_be)\n\n    def test_init(self):\n        # still in development\n        original_execute = config.session.execute\n        config.session.execute = Mock(return_value=None)\n        nopars = Words()\n        config.session.execute.assert_not_called()\n        config.session.execute = original_execute\n\n    def test_init_pdict(self):\n        t = TestStorageObj()\n        t.test = {1: \'ciao\'}\n        # its not persistent, so in memory it is still a dict\n        # hecuba converts the dicts to StorageDicts when the StorageObj is made persistent\n        self.assertTrue(issubclass(t.test.__class__, dict))\n'"
storageAPI/storage/__init__.py,0,b''
storageAPI/storage/api.py,0,"b'\n\ndef init(config_file_path=None):\n    """"""\n    Function that can be useful when running the application with COMPSs >= 2.0\n    It is executed at the beginning of the application\n    """"""\n    pass\n\n\ndef finish():\n    """"""\n    Function that can be useful when running the application with COMPSs >= 2.0\n    It is executed at the end of the application\n    """"""\n    pass\n\n\ndef initWorker(config_file_path=None):\n    """"""\n    Function that can be useful when running the application with COMPSs >= 2.0\n    It is executed at the beginning of the application\n    """"""\n    pass\n\n\ndef finishWorker():\n    """"""\n    Function that can be useful when running the application with COMPSs >= 2.0\n    It is executed at the end of the application\n    """"""\n    pass\n\n\ndef start_task(params):\n    """"""\n    Initializes, if needed, the global vars for prefetch and batch, and starts the context if batch is activated\n    Args:\n        params: a list of objects (Blocks, StorageObjs, strings, ints, ...)\n    """"""\n    pass\n\n\ndef end_task(params):\n    """"""\n    Terminates, if needed, the context (to save all data remaining in the batch) and the prefetch. It also prints\n    the statistics of the StorageObjs if desired.\n    Args:\n        params: a list of objects (Blocks, StorageObjs, strings, ints, ...)\n    """"""\n    pass\n\n\nclass TaskContext(object):\n    def __init__(self, logger, values, **kwargs):\n        self.logger = logger\n        self.values = values\n\n    def __enter__(self):\n        # Do something prolog\n        start_task(self.values)\n        # Ready to start the task\n        self.logger.info(""Prolog finished"")\n        pass\n\n    def __exit__(self, type, value, traceback):\n        # Do something epilog\n        end_task(self.values)\n        # Finished\n        self.logger.info(""Epilog finished"")\n        pass\n\n\ndef getByID(objid):\n    """"""\n    We rebuild the object from its id.\n\n    Args:\n        objid (str):  object identifier\n\n    Returns:\n         Hecuba Object\n\n    """"""\n    """"""\n               TODO\n               Args:\n                   objid (str):  object identifier\n               Returns:\n                    (Block| Storageobj)\n               """"""\n    from hecuba import log\n    from hecuba.IStorage import build_remotely\n    from hecuba import config\n    from hecuba import StorageNumpy, StorageDict\n    from hecuba import StorageObj as StorageObject\n    import uuid\n\n    query = ""SELECT * FROM hecuba.istorage WHERE storage_id = %s""\n\n    if isinstance(objid, str):\n        objid = uuid.UUID(objid)\n\n    results = config.session.execute(query, [objid])\n    if not results:\n        raise RuntimeError(""Object {} not found on hecuba.istorage"".format(objid))\n\n    results = results[0]\n\n    log.debug(""IStorage API:getByID(%s) of class %s"", objid, results.class_name)\n    return build_remotely(results._asdict())\n'"
hecuba_py/tests/app/__init__.py,0,b''
hecuba_py/tests/app/result.py,0,"b""from hecuba.storageobj import StorageObj\n\nclass Result(StorageObj):\n    '''\n    @ClassField instances dict<<word:str>,instances:int>\n    '''\n    pass\n"""
hecuba_py/tests/app/words.py,0,"b""from hecuba.storageobj import StorageObj\n\n\nclass Words(StorageObj):\n    '''\n    @ClassField words dict<<position:int>, wordinfo:str>\n    '''\n    pass\n"""
hecuba_py/tests/withQbeast/__init__.py,0,b''
hecuba_py/tests/withQbeast/qbeast_storagedict_tests.py,0,"b'import random\nfrom random import random\nimport time\nimport unittest\n\nfrom hecuba import config, StorageDict\nfrom hecuba.tools import build_remotely\n\n\nclass TestIndexObj(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<partid:int, time:double>, x:double,y:double,z:double>\n    @Index_on x,y,z\n    \'\'\'\n\n\nclass QbeastStorageDictTest(unittest.TestCase):\n\n    def testSimple(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.indexed_dict"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app_qbeast.indexed_dict_indexed_dict_idx_d8tree"")\n        d = TestIndexObj(""my_app.indexed_dict"")\n        for i in range(0, 30):\n            d[i, i+1.0] = [i*0.1/9.0, i*0.2/9.0, i*0.3/9.0]\n\n        time.sleep(1)\n\n        tree_dict = config.session.execute(""SELECT * FROM my_app_qbeast.indexed_dict_indexed_dict_idx_d8tree"")\n        res = [[(row.partid, row.time), (row.x, row.y, row.z)] for row in tree_dict]\n        self.assertEqual(30, len(res))\n\n    def testIterator(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.indexed_dict"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app_qbeast.indexed_dict_indexed_dict_idx_d8tree"")\n        d = TestIndexObj(""my_app.indexed_dict"")\n        what_should_be = dict()\n        for i in range(0, 30):\n            what_should_be[i, i+1.0] = [i*0.1/9.0, i*0.2/9.0, i*0.3/9.0]\n            d[i, i+1.0] = [i*0.1/9.0, i*0.2/9.0, i*0.3/9.0]\n\n        it = d.items()\n        for k, v in it:\n            self.assertEqual(what_should_be[k], list(v))\n\n    def testFilter(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.indexed_dict"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app_qbeast.indexed_dict_indexed_dict_idx_d8tree"")\n        d = TestIndexObj(""my_app.indexed_dict"")\n        what_should_be = dict()\n        for i in range(0, 30):\n            what_should_be[i, i + 1.0] = [i*0.1/9.0, i*0.2/9.0, i*0.3/9.0]\n            d[i, i + 1.0] = [i*0.1/9.0, i*0.2/9.0, i*0.3/9.0]\n\n        time.sleep(1)\n\n        filtered = filter(lambda row: row.x > 0.02 and row.x < 0.25 and row.y > 0.26 and row.y < 0.45 and row.z > 0.58 and row.z < 0.9, d.items())\n        normal_filtered = list(python_filter(lambda row: row[1][0] > 0.02 and row[1][0] < 0.25 and row[1][1] > 0.26 and row[1][1] < 0.45 and row[1][2] > 0.58 and row[1][2] < 0.9, what_should_be.items()))\n\n        filtered_list = [row for row in filtered]\n        self.assertEqual(len(filtered_list), len(normal_filtered))\n        for row in filtered_list:\n            self.assertTrue((tuple(row.key), list(row.value)) in normal_filtered)\n\n    def testCanBeRebuilt(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.indexed_dict"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app_qbeast.indexed_dict_indexed_dict_idx_d8tree"")\n        d = TestIndexObj(""my_app.indexed_dict"")\n        for i in range(0, 30):\n            d[i, i + 1.0] = [i * 0.1 / 9.0, i * 0.2 / 9.0, i * 0.3 / 9.0]\n\n        time.sleep(1)\n        filtered = filter(lambda row: row.x > 0.02 and row.x < 0.25 and row.y > 0.26 and row.y < 0.45 and row.z > 0.58 and row.z < 0.9, d.items())\n        from storage.api import getByID\n        for partition in filtered.split():\n            it2 = getByID(partition.storage_id)\n            self.assertEqual(filtered._qbeast_random, it2._qbeast_random)\n\n    def testBuildRemotely(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.indexed_dict"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app_qbeast.indexed_dict_indexed_dict_idx_d8tree"")\n        d = TestIndexObj(""my_app.indexed_dict"")\n        what_should_be = dict()\n        for i in range(0, 30):\n            what_should_be[i, i + 1.0] = [i*0.1/9.0, i*0.2/9.0, i*0.3/9.0]\n            d[i, i + 1.0] = [i*0.1/9.0, i*0.2/9.0, i*0.3/9.0]\n\n        res = config.session.execute(\n            \'SELECT storage_id, primary_keys, columns, class_name, name, tokens, istorage_props,indexed_on \' +\n            \'FROM hecuba.istorage WHERE storage_id = %s\', [d.storage_id])[0]\n\n        self.assertEqual(res.storage_id, d.storage_id)\n        self.assertEqual(res.class_name, TestIndexObj.__module__ + ""."" + TestIndexObj.__name__)\n\n        rebuild = build_remotely(res._asdict())\n        self.assertEqual(rebuild._ksp, \'my_app\')\n        self.assertEqual(rebuild._table, \'indexed_dict\')\n\n        self.assertEqual(len(what_should_be), len([row for row in rebuild.items()]))\n        filtered = filter(lambda row: row.x > 0.0 and row.x < 1.0 and row.y > 0.0 and row.y < 1.0 and row.z > 0.0 and row.z < 1.0, rebuild.items())\n        for k, v in filtered:\n            self.assertEqual(what_should_be[k], list(v))\n\n    def testSplitBuildRemotely(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.indexed_dict"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app_qbeast.indexed_dict_indexed_dict_idx_d8tree"")\n        d = TestIndexObj(""my_app.indexed_dict"")\n        what_should_be = dict()\n        for i in range(0, 30):\n            what_should_be[i, i + 1.0] = [i * 0.1 / 9.0, i * 0.2 / 9.0, i * 0.3 / 9.0]\n            d[i, i + 1.0] = [i * 0.1 / 9.0, i * 0.2 / 9.0, i * 0.3 / 9.0]\n\n        for partition in d.split():\n            rebuild = build_remotely(partition._build_args._asdict())\n            for k, v in rebuild.items():\n                self.assertEqual(what_should_be[k], list(v))\n\n    def test_precision(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.indexed_dict"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app_qbeast.indexed_dict_indexed_dict_idx_d8tree"")\n        d = TestIndexObj(""my_app.indexed_dict"")\n        what_should_be = dict()\n        for i in range(0, 30):\n            what_should_be[i, i + 1.0] = [i * 0.1 / 9.0, i * 0.2 / 9.0, i * 0.3 / 9.0]\n            d[i, i + 1.0] = [i * 0.1 / 9.0, i * 0.2 / 9.0, i * 0.3 / 9.0]\n\n        time.sleep(1)\n\n        filtered = filter(lambda row: row.x > 0.02 and row.x < 0.25 and row.y > 0.26 and row.y < 0.45 and row.z > 0.58 and row.z < 0.9 and random.random() < 1, d.items())\n        normal_filtered = list(python_filter(lambda row: row[1][0] > 0.02 and row[1][0] < 0.25 and row[1][1] > 0.26 and row[1][1] < 0.45 and row[1][2] > 0.58 and row[1][2] < 0.9, what_should_be.items()))\n\n        filtered_list = [row for row in filtered]\n        self.assertEqual(len(filtered_list), len(normal_filtered))\n        for row in filtered_list:\n            self.assertTrue((tuple(row.key), list(row.value)) in normal_filtered)\n\n        filtered = filter(lambda row: row.x > 0.02 and row.x < 0.25 and row.y > 0.26 and row.y < 0.45 and row.z > 0.58 and row.z < 0.9 and random() < 1, d.items())\n\n        filtered_list = [row for row in filtered]\n        self.assertEqual(len(filtered_list), len(normal_filtered))\n        for row in filtered_list:\n            self.assertTrue((tuple(row.key), list(row.value)) in normal_filtered)\n\n    def testSplit(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.indexed_dict"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app_qbeast.indexed_dict_indexed_dict_idx_d8tree"")\n        d = TestIndexObj(""my_app.indexed_dict"")\n        what_should_be = dict()\n        for i in range(0, 30):\n            what_should_be[i, i + 1.0] = [i*0.1/9.0, i*0.2/9.0, i*0.3/9.0]\n            d[i, i + 1.0] = [i*0.1/9.0, i*0.2/9.0, i*0.3/9.0]\n\n        time.sleep(1)\n\n        qbeast_filtered = filter(lambda row: row.x > 0.02 and row.x < 0.25 and row.y > 0.26 and row.y < 0.45 and row.z > 0.58 and row.z < 0.9, d.items())\n\n        for partition in qbeast_filtered.split():\n            # with qbeast, a split returns all the data of the node where is iterated\n            for k, v in partition:\n                self.assertEqual(what_should_be[k], list(v))\n            self.assertEqual(qbeast_filtered._qbeast_random, partition._qbeast_random)\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/__init__.py,0,b''
hecuba_py/tests/withcassandra/embeddedset_tests.py,0,"b'import time\nimport unittest\n\nfrom hecuba import StorageDict\nfrom hecuba import config\nfrom hecuba.IStorage \\\n    import build_remotely\n\n\nclass DictSet(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<k1:str, k2:int>, s1:set<int, int>>\n    \'\'\'\n\n\nclass DictSet2(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<k1:str, k2:int>, s1:set<str>>\n    \'\'\'\n\n\nclass DictSet3(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<k1:str, k2:int>, s1:set<int>>\n    \'\'\'\n\n\nclass DictSet4(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<k1:str>, s1:set<int>>\n    \'\'\'\n\n\nclass EmbeddedSetTest(unittest.TestCase):\n    def testAddRemove(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset"")\n        d = DictSet2(""pruebas0.dictset"")\n        d[""1"", 1] = {""1""}\n        d[""2"", 2] = {""1"", ""2"", ""3""}\n\n        self.assertTrue(""1"" in d[""1"", 1])\n        for i in range(1, 4):\n            self.assertTrue(str(i) in d[""2"", 2])\n\n        d[""2"", 2].remove(""2"")\n        self.assertEqual(False, d[""2"", 2].__contains__(""2""))\n\n        d[""2"", 2].add(""2"")\n        self.assertTrue(""2"" in d[""2"", 2])\n        self.assertEqual(1, len(d[""1"", 1]))\n        self.assertEqual(3, len(d[""2"", 2]))\n\n    def testDoNotCollide(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset"")\n        d = DictSet2(""pruebas0.dictset"")\n        d[""1"", 1] = {""1""}\n        d[""2"", 2] = {""1"", ""2"", ""3""}\n\n        self.assertTrue(""1"" in d[""1"", 1])\n        for i in range(1, 4):\n            self.assertTrue(str(i) in d[""2"", 2])\n\n        del d\n        d2 = DictSet2(""pruebas0.dictset"")\n        self.assertTrue(""1"" in d2[""1"", 1])\n        for i in range(1, 4):\n            self.assertTrue(str(i) in d2[""2"", 2])\n\n    def testDoNotCollideEmptySet(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset"")\n        d = DictSet2(""pruebas0.dictset"")\n        d[""1"", 1] = {""1"", ""2"", ""3""}\n        d[""2"", 2] = {""4"", ""5"", ""6""}\n\n        del d\n        d2 = DictSet2(""pruebas0.dictset"")\n\n        d2[""1"", 1].add(""4"")\n        d2[""2"", 2].add(""7"")\n        self.assertTrue(""4"" in d2[""1"", 1])\n        self.assertTrue(""7"" in d2[""2"", 2])\n\n        d2[""1"", 1] = {""1""}\n        d2[""2"", 2] = {""1"", ""2"", ""3""}\n        self.assertTrue(""1"" in d2[""1"", 1])\n        for i in range(1, 4):\n            self.assertTrue(str(i) in d2[""2"", 2])\n\n        self.assertEqual(len(d2[""1"", 1]), 1)\n        self.assertEqual(len(d2[""2"", 2]), 3)\n\n    def testAddRemove2(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset"")\n        d = DictSet4(""pruebas0.dictset"")\n        d[""10""] = {1}\n        d[""20""] = {1, 2, 3}\n\n        self.assertTrue(1 in d[""10""])\n        for i in range(1, 4):\n            self.assertTrue(i in d[""20""])\n\n        d[""20""].remove(2)\n        self.assertEqual(False, d[""20""].__contains__(""2""))\n\n        d[""20""].add(2)\n        self.assertTrue(2 in d[""20""])\n        self.assertEqual(1, len(d[""10""]))\n        self.assertEqual(3, len(d[""20""]))\n\n    def testAddRemoveInt(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset"")\n        d = DictSet3(""pruebas0.dictset"")\n        d[""1"", 1] = {1}\n        d[""2"", 2] = {1, 2, 3}\n\n        self.assertTrue(1 in d[""1"", 1])\n        for i in range(1, 4):\n            self.assertTrue(i in d[""2"", 2])\n\n        d[""2"", 2].remove(2)\n\n        self.assertEqual(False, d[""2"", 2].__contains__(2))\n\n        d[""2"", 2].add(2)\n        self.assertTrue(2 in d[""2"", 2])\n        self.assertEqual(1, len(d[""1"", 1]))\n        self.assertEqual(3, len(d[""2"", 2]))\n\n    def testIter(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset"")\n        d = DictSet2(""pruebas0.dictset"")\n\n        d[""2"", 2] = set()\n        for i in range(0, 10):\n            d[""2"", 2].add(str(i))\n        time.sleep(1)\n        l = []\n        for value in d[""2"", 2]:\n            l.append(value)\n        for i in range(0, 10):\n            self.assertTrue(str(i) in l)\n\n        self.assertEqual(len(l), len(d[""2"", 2]))\n\n    def testAddRemoveTuple(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset"")\n        d = DictSet(""pruebas0.dictset"")\n        d[""1"", 1] = {(1, 1)}\n        d[""2"", 2] = {(1, 1), (2, 2), (3, 3)}\n\n        self.assertTrue((1, 1) in d[""1"", 1])\n        for i in range(1, 4):\n            self.assertTrue((i, i) in d[""2"", 2])\n\n        d[""2"", 2].remove((2, 2))\n        self.assertEqual(False, d[""2"", 2].__contains__((2, 2)))\n\n        d[""2"", 2].add((2, 2))\n        self.assertTrue((2, 2) in d[""2"", 2])\n        self.assertEqual(1, len(d[""1"", 1]))\n        self.assertEqual(3, len(d[""2"", 2]))\n\n    def testIterTuple(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset"")\n        d = DictSet(""pruebas0.dictset"")\n\n        d[""2"", 2] = set()\n        for i in range(0, 10):\n            d[""2"", 2].add((i, i))\n        time.sleep(1)\n        l = []\n        for value in d[""2"", 2]:\n            l.append(value)\n        for i in range(0, 10):\n            self.assertTrue((i, i) in l)\n\n        self.assertEqual(len(l), len(d[""2"", 2]))\n\n    def testUnion(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset2"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n        d2 = DictSet2(""pruebas0.dictset2"")\n\n        d1[""0"", 0] = set()\n        d2[""1"", 1] = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add(str(i))\n        for i in range(10, 20):\n            d2[""1"", 1].add(str(i))\n\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset3"")\n        d3 = DictSet2(""pruebas0.dictset3"")\n        d3[""2"", 2] = d1[""0"", 0].union(d2[""1"", 1])\n        time.sleep(3)\n        for i in range(0, 20):\n            self.assertTrue(str(i) in d3[""2"", 2])\n        self.assertEqual(20, len(d3[""2"", 2]))\n\n    def testIntersection(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset2"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n        d2 = DictSet2(""pruebas0.dictset2"")\n\n        d1[""0"", 0] = set()\n        d2[""1"", 1] = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add(str(i))\n            if i < 5:\n                d2[""1"", 1].add(str(i))\n\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset3"")\n        d3 = DictSet2(""pruebas0.dictset3"")\n        d3[""2"", 2] = d1[""0"", 0].intersection(d2[""1"", 1])\n        for i in range(0, 5):\n            self.assertTrue(str(i) in d3[""2"", 2])\n        self.assertEqual(5, len(d3[""2"", 2]))\n\n    def testDifference(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset2"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n        d2 = DictSet2(""pruebas0.dictset2"")\n\n        d1[""0"", 0] = set()\n        d2[""1"", 1] = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add(str(i))\n            if i < 5:\n                d2[""1"", 1].add(str(i))\n\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset3"")\n        d3 = DictSet2(""pruebas0.dictset3"")\n        d3[""2"", 2] = d1[""0"", 0].difference(d2[""1"", 1])\n        for i in range(5, 10):\n            self.assertTrue(str(i) in d3[""2"", 2])\n        self.assertEqual(5, len(d3[""2"", 2]))\n\n    def testUnionWithTuples(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset2"")\n        d1 = DictSet(""pruebas0.dictset1"")\n        d2 = DictSet(""pruebas0.dictset2"")\n\n        d1[""0"", 0] = set()\n        d2[""1"", 1] = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add((i, i))\n        for i in range(10, 20):\n            d2[""1"", 1].add((i, i))\n\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset3"")\n        d3 = DictSet(""pruebas0.dictset3"")\n        d3[""2"", 2] = d1[""0"", 0].union(d2[""1"", 1])\n        time.sleep(3)\n        for i in range(0, 20):\n            self.assertTrue((i, i) in d3[""2"", 2])\n        self.assertEqual(20, len(d3[""2"", 2]))\n\n    def testIntersectionWithTuples(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset2"")\n        d1 = DictSet(""pruebas0.dictset1"")\n        d2 = DictSet(""pruebas0.dictset2"")\n\n        d1[""0"", 0] = set()\n        d2[""1"", 1] = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add((i, i))\n            if i < 5:\n                d2[""1"", 1].add((i, i))\n\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset3"")\n        d3 = DictSet(""pruebas0.dictset3"")\n        d3[""2"", 2] = d1[""0"", 0].intersection(d2[""1"", 1])\n        for i in range(0, 5):\n            self.assertTrue((i, i) in d3[""2"", 2])\n        self.assertEqual(5, len(d3[""2"", 2]))\n\n    def testDifferenceWithTuples(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset2"")\n        d1 = DictSet(""pruebas0.dictset1"")\n        d2 = DictSet(""pruebas0.dictset2"")\n\n        d1[""0"", 0] = set()\n        d2[""1"", 1] = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add((i, i))\n            if i < 5:\n                d2[""1"", 1].add((i, i))\n\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset3"")\n        d3 = DictSet(""pruebas0.dictset3"")\n        d3[""2"", 2] = d1[""0"", 0].difference(d2[""1"", 1])\n        for i in range(5, 10):\n            self.assertTrue((i, i) in d3[""2"", 2])\n        self.assertEqual(5, len(d3[""2"", 2]))\n\n    def testUnionWithSet(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n\n        d1[""0"", 0] = set()\n        s1 = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add(str(i))\n            s1.add(str(i + 10))\n\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset3"")\n        d3 = DictSet2(""pruebas0.dictset3"")\n        d3[""2"", 2] = d1[""0"", 0].union(s1)\n        time.sleep(3)\n        for i in range(0, 20):\n            self.assertTrue(str(i) in d3[""2"", 2])\n        self.assertEqual(20, len(d3[""2"", 2]))\n\n    def testIntersectionWithSet(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n\n        d1[""0"", 0] = set()\n        s1 = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add(str(i))\n            if i < 5:\n                s1.add(str(i))\n\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset3"")\n        d3 = DictSet2(""pruebas0.dictset3"")\n        d3[""2"", 2] = d1[""0"", 0].intersection(s1)\n        for i in range(0, 5):\n            self.assertTrue(str(i) in d3[""2"", 2])\n        self.assertEqual(5, len(d3[""2"", 2]))\n\n    def testDifferenceWithSet(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n\n        d1[""0"", 0] = set()\n        s1 = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add(str(i))\n            if i < 5:\n                s1.add(str(i))\n\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset3"")\n        d3 = DictSet2(""pruebas0.dictset3"")\n        d3[""2"", 2] = d1[""0"", 0].difference(s1)\n        for i in range(5, 10):\n            self.assertTrue(str(i) in d3[""2"", 2])\n        self.assertEqual(5, len(d3[""2"", 2]))\n\n    def testIterKeys(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet3(""pruebas0.dictset1"")\n\n        d1[""0"", 0] = {1, 2, 3, 4}\n        d1[""0"", 1] = {1, 2, 3, 4}\n        d1[""1"", 0] = {1, 2, 3, 4}\n        d1[""1"", 1] = {1, 2, 3, 4}\n        time.sleep(1)\n        l = list()\n        for keys in d1.keys():\n            l.append(keys)\n\n        self.assertTrue((""0"", 0) in l)\n        self.assertTrue((""0"", 1) in l)\n        self.assertTrue((""1"", 0) in l)\n        self.assertTrue((""1"", 1) in l)\n        self.assertEqual(4, len(l))\n\n    def testItems(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet3(""pruebas0.dictset1"")\n\n        d1[""0"", 0] = {1, 2, 3, 4}\n        d1[""0"", 1] = {1, 2, 3, 4}\n        d1[""1"", 0] = {1, 2, 3, 4}\n        d1[""1"", 1] = {1, 2, 3, 4}\n        time.sleep(1)\n        d = dict()\n        for keys, value in d1.items():\n            d[keys] = value\n        self.assertTrue((""0"", 0) in d)\n        self.assertTrue((""0"", 1) in d)\n        self.assertTrue((""1"", 0) in d)\n        self.assertTrue((""1"", 1) in d)\n        self.assertEqual(4, len(d))\n        self.assertEqual({1, 2, 3, 4}, d[""0"", 0])\n        self.assertEqual({1, 2, 3, 4}, d[""0"", 1])\n        self.assertEqual({1, 2, 3, 4}, d[""1"", 0])\n        self.assertEqual({1, 2, 3, 4}, d[""1"", 1])\n\n    def testIterValues(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet3(""pruebas0.dictset1"")\n\n        d1[""0"", 0] = {1, 2, 3, 4}\n        d1[""0"", 1] = {5, 6, 7, 8}\n        d1[""1"", 0] = {8, 7, 6, 5}\n        d1[""1"", 1] = {4, 3, 2, 1}\n        time.sleep(1)\n        l = list()\n        for value in d1.values():\n            l.append(value)\n\n        self.assertEqual(4, len(l))\n        self.assertTrue({1, 2, 3, 4} in l)\n        self.assertTrue({5, 6, 7, 8} in l)\n        self.assertTrue({8, 7, 6, 5} in l)\n        self.assertTrue({4, 3, 2, 1} in l)\n\n    def testItemsWithTuples(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet(""pruebas0.dictset1"")\n\n        d1[""key0"", 15] = {(0, 1), (2, 3), (4, 5)}\n        d1[""key1"", 30] = {(10, 11), (12, 13), (14, 15)}\n        time.sleep(1)\n        d = dict()\n        for keys, value in d1.items():\n            d[keys] = value\n        self.assertTrue((""key0"", 15) in d)\n        self.assertTrue((""key1"", 30) in d)\n        self.assertEqual(2, len(d))\n        self.assertEqual({(0, 1), (2, 3), (4, 5)}, d[""key0"", 15])\n        self.assertEqual({(10, 11), (12, 13), (14, 15)}, d[""key1"", 30])\n\n    def testUpdate(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset2"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n        d2 = DictSet2(""pruebas0.dictset2"")\n\n        d1[""0"", 0] = set()\n        d2[""1"", 1] = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add(str(i))\n        for i in range(5, 20):\n            d2[""1"", 1].add(str(i))\n\n        time.sleep(2)\n        d1[""0"", 0].update(d2[""1"", 1])\n        time.sleep(3)\n        for i in range(0, 20):\n            self.assertTrue(str(i) in d1[""0"", 0])\n        self.assertEqual(20, len(d1[""0"", 0]))\n\n    def testIsSubset(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset2"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n        d2 = DictSet2(""pruebas0.dictset2"")\n\n        d1[""0"", 0] = set()\n        d2[""1"", 1] = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add(str(i))\n            d2[""1"", 1].add(str(i))\n        for i in range(10, 20):\n            d2[""1"", 1].add(str(i))\n\n        b = d1[""0"", 0].issubset(d2[""1"", 1])\n        self.assertTrue(b)\n\n        b = d2[""1"", 1].issubset(d1[""0"", 0])\n        self.assertFalse(b)\n\n    def testIsSuperset(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset2"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n        d2 = DictSet2(""pruebas0.dictset2"")\n\n        d1[""0"", 0] = set()\n        d2[""1"", 1] = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add(str(i))\n            d2[""1"", 1].add(str(i))\n        for i in range(10, 20):\n            d2[""1"", 1].add(str(i))\n\n        time.sleep(2)\n        b = d2[""1"", 1].issuperset(d1[""0"", 0])\n        self.assertTrue(b)\n\n        b = d1[""0"", 0].issuperset(d2[""1"", 1])\n        self.assertFalse(b)\n\n    def testIsSubsetWithSet(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n\n        d1[""0"", 0] = set()\n        s = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add(str(i))\n            s.add(str(i))\n        for i in range(10, 20):\n            s.add(str(i))\n\n        b = d1[""0"", 0].issubset(s)\n        self.assertTrue(b)\n\n        b = s.issubset(d1[""0"", 0])\n        self.assertFalse(b)\n\n    def testIsSupersetWithSet(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n\n        d1[""0"", 0] = set()\n        s = set()\n        for i in range(0, 10):\n            d1[""0"", 0].add(str(i))\n            s.add(str(i))\n        for i in range(10, 20):\n            s.add(str(i))\n\n        b = s.issuperset(d1[""0"", 0])\n        self.assertTrue(b)\n\n        b = d1[""0"", 0].issuperset(s)\n        self.assertFalse(b)\n\n    def testRemoveKeyError(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n\n        d1[""0"", 0] = {""0"", ""1"", ""2""}\n        d1[""0"", 0].remove(""0"")\n        self.assertRaises(Exception, d1[""0"", 0].remove, ""3"")\n        self.assertTrue(""1"" in d1[""0"", 0])\n        self.assertTrue(""2"" in d1[""0"", 0])\n        self.assertEqual(False, d1[""0"", 0].__contains__(""0""))\n\n    def testDiscard(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet2(""pruebas0.dictset1"")\n\n        d1[""0"", 0] = {""0"", ""1"", ""2""}\n        d1[""0"", 0].discard(""0"")\n        d1[""0"", 0].discard(""3"")\n        self.assertTrue(""1"" in d1[""0"", 0])\n        self.assertTrue(""2"" in d1[""0"", 0])\n        self.assertEqual(False, d1[""0"", 0].__contains__(""0""))\n\n    def testClear(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d1 = DictSet3(""pruebas0.dictset1"")\n\n        d1[""0"", 0] = {1, 2}\n        time.sleep(1)\n        self.assertEqual(2, len(d1[""0"", 0]))\n        d1[""0"", 0].clear()\n        self.assertEqual(0, len(d1[""0"", 0]))\n\n    def testSplit(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d = DictSet3(""pruebas0.dictset1"")\n        for i in range(0, 10):\n            for j in range(0, 3):\n                d[str(i), j] = {0, 1, 2, 3, 4, 5}\n\n        d2 = dict()\n        for partition in d.split():\n            for ((key0, key1), val) in partition.items():\n                d2[key0, key1] = val\n\n        for i in range(0, 10):\n            for j in range(0, 3):\n                self.assertEqual(d2[str(i), j], {0, 1, 2, 3, 4, 5})\n\n    def testBuildRemotely(self):\n        config.session.execute(""DROP TABLE IF EXISTS pruebas0.dictset1"")\n        d = DictSet(""pruebas0.dictset1"")\n        for i in range(0, 10):\n            d[str(i), i] = {(0, 0), (1, 1), (2, 2)}\n\n        self.assertEqual(\'dictset1\', d._table)\n        self.assertEqual(\'pruebas0\', d._ksp)\n\n        res = config.session.execute(\n            \'SELECT storage_id, primary_keys, columns, class_name, name, tokens, istorage_props,indexed_on \' +\n            \'FROM hecuba.istorage WHERE storage_id = %s\', [d.storage_id])[0]\n\n        self.assertEqual(res.storage_id, d.storage_id)\n        self.assertEqual(res.class_name, DictSet.__module__ + ""."" + DictSet.__name__)\n        self.assertEqual(res.name, \'pruebas0.dictset1\')\n\n        rebuild = build_remotely(res._asdict())\n        self.assertEqual(rebuild._built_remotely, True)\n        self.assertEqual(\'dictset1\', rebuild._table)\n        self.assertEqual(\'pruebas0\', rebuild._ksp)\n        self.assertEqual(res.storage_id, rebuild.storage_id)\n\n        self.assertEqual(d._is_persistent, rebuild._is_persistent)\n\n        for i in range(0, 10):\n            # rebuild[str(i), i] does not return data, we must iterate over it\n            self.assertEqual({i for i in rebuild[str(i), i]}, {(0, 0), (1, 1), (2, 2)})\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/hfetch_flush_tests.py,0,"b'import unittest\n\nfrom hecuba import config\nfrom hecuba.hdict import StorageDict\n\n\nclass StorageDictTest(unittest.TestCase):\n    @staticmethod\n    def setUpClass():\n        config.session.execute(\n            ""CREATE KEYSPACE IF NOT EXISTS ksp WITH replication = {\'class\': \'SimpleStrategy\', \'replication_factor\': 1};"")\n\n    def test_flush_items_100(self):\n        config.session.execute(""DROP TABLE IF EXISTS ksp.tb1"")\n        config.session.execute(""CREATE TABLE ksp.tb1(pk1 int, val1 text,PRIMARY KEY(pk1))"")\n        pd = StorageDict(\'ksp.tb1\', [(\'pk1\', \'int\')], [(\'val1\', \'text\')])\n        num_inserts = 100\n        for i in range(num_inserts):\n            pd[i] = \'ciao\' + str(i)\n        del pd  # To force hfetch to flush data\n        import gc\n        gc.collect()\n        count, = config.session.execute(""SELECT count(*) FROM ksp.tb1"")[0]\n\n        self.assertEqual(count, num_inserts)\n\n    def test_flush_items_10K(self):\n        config.session.execute(""DROP TABLE IF EXISTS ksp.tb1"")\n        config.session.execute(""CREATE TABLE ksp.tb1(pk1 int, val1 text,PRIMARY KEY(pk1))"")\n        pd = StorageDict(\'ksp.tb1\', [(\'pk1\', \'int\')], [(\'val1\', \'text\')])\n        num_inserts = 10000\n        for i in range(num_inserts):\n            pd[i] = \'ciao\' + str(i)\n        del pd  # To force hfetch to flush data\n        import gc\n        gc.collect()\n        count, = config.session.execute(""SELECT count(*) FROM ksp.tb1 LIMIT "" + str(num_inserts + 1))[0]\n        self.assertEqual(count, num_inserts)\n\n    \'\'\'\n    def test_flush_items_1M(self):\n        config.session.execute(""DROP KEYSPACE IF EXISTS ksp"")\n        config.session.execute(""CREATE KEYSPACE ksp WITH replication = {\'class\': \'SimpleStrategy\', \'replication_factor\': 1};"")\n        config.session.execute(""CREATE TABLE ksp.tb1(pk1 int, val1 text,PRIMARY KEY(pk1))"")\n        pd = StorageDict(\'ksp.tb1\', [(\'pk1\', \'int\')], [(\'val1\', \'text\')])\n        num_inserts = 1000000\n        for i in range(num_inserts):\n            pd[i] = \'ciao\' + str(i)\n        del pd  # To force hfetch to flush data\n        count, = config.session.execute(""SELECT count(*) FROM ksp.tb1"")[0]\n\n        self.assertEqual(count, num_inserts)\n    \'\'\'\n\n    def test_write_and_then_read(self):\n        config.session.execute(""DROP TABLE IF EXISTS ksp.tb1"")\n        config.session.execute(""CREATE TABLE ksp.tb1(pk1 int, val1 text,PRIMARY KEY(pk1))"")\n        pd = StorageDict(\'ksp.tb1\', [(\'pk1\', \'int\')], [(\'val1\', \'text\')])\n        for i in range(100):\n            pd[i] = \'ciao\' + str(i)\n        del pd  # To force hfetch to flush data\n        import gc\n        gc.collect()\n        count, = config.session.execute(""SELECT count(*) FROM ksp.tb1"")[0]\n\n        self.assertEqual(count, 100)\n        pd = StorageDict(\'ksp.tb1\', [(\'pk1\', \'int\')], [(\'val1\', \'text\')])\n        for i in range(100):\n            self.assertEqual(pd[i], u\'ciao\' + str(i))\n\n    def test_write_and_then_read_named_tuple(self):\n        config.session.execute(""DROP TABLE IF EXISTS ksp.tb1"")\n        config.session.execute(""CREATE TABLE ksp.tb1(pk1 int, name text,age int,PRIMARY KEY(pk1))"")\n        pd = StorageDict(\'ksp.tb1\', [(\'pk1\', \'int\')], [(\'name\', \'text\'), (\'age\', \'int\')])\n        for i in range(100):\n            pd[i] = [\'ciao\' + str(i), i]\n        del pd  # To force hfetch to flush data\n        import gc\n        gc.collect()\n        count, = config.session.execute(""SELECT count(*) FROM ksp.tb1"")[0]\n\n        self.assertEqual(count, 100)\n        pd = StorageDict(\'ksp.tb1\', [(\'pk1\', \'int\')], [(\'name\', \'text\'), (\'age\', \'int\')])\n        for i in range(100):\n            name, age = pd[i]\n            self.assertEqual(name, u\'ciao\' + str(i))\n            self.assertEqual(age, i)\n\n            self.assertEqual(pd[i].name, u\'ciao\' + str(i))\n            self.assertEqual(pd[i].age, i)\n'"
hecuba_py/tests/withcassandra/hfetch_tests.py,2,"b'import unittest\nimport numpy as np\n\nfrom hecuba import config, StorageDict\nfrom hfetch import HArrayMetadata\n\n\nclass ConcurrentDict(StorageDict):\n    \'\'\'\n    @TypeSpec <<key:int>,value:int>\n    \'\'\'\n\n\nclass HfetchTests(unittest.TestCase):\n    def test_timestamped_writes(self):\n        previous_cfg = config.timestamped_writes\n        config.timestamped_writes = ""True""\n\n        my_dict = ConcurrentDict(""concurrent_dict"")\n        last_value = 1000\n        for value in range(last_value):\n            my_dict[0] = value\n\n        del my_dict\n        import gc\n        gc.collect()\n\n        my_dict = ConcurrentDict(""concurrent_dict"")\n\n        retrieved = my_dict[0]\n\n        config.timestamped_writes = previous_cfg\n\n        self.assertEqual(retrieved, last_value - 1)\n\n    def test_harray_metadata_init(self):\n        base = np.arange(7 * 8 * 9 * 10).reshape((7, 8, 9, 10))\n\n        args = (list(base.shape), list(base.strides), base.dtype.kind, base.dtype.byteorder,\n                base.itemsize, base.flags.num, 0)\n\n        obj = HArrayMetadata(*args)\n\n        with self.assertRaises(TypeError):\n            obj = HArrayMetadata()\n\n        with self.assertRaises(TypeError):\n            obj = HArrayMetadata(args[1:])\n\n    def test_harray_metadata_refs(self):\n        base = np.arange(10)\n        args = (list(base.shape), list(base.strides), base.dtype.kind, base.dtype.byteorder,\n                base.itemsize, base.flags.num, 0)\n\n        obj = HArrayMetadata(*args)\n        import gc\n        gc.collect()\n        import sys\n        # The test has the first ref, the method getrefcount has the second reference\n        self.assertEqual(sys.getrefcount(obj), 2)\n\n    def test_register(self):\n        from hfetch import HArrayMetadata\n        # connecting c++ bindings\n        from hecuba import config\n        config.session.execute(""DROP KEYSPACE IF EXISTS test_np_meta;"")\n\n        config.session.execute(""CREATE KEYSPACE IF NOT EXISTS test_np_meta ""\n                               ""WITH replication = {\'class\': \'SimpleStrategy\', \'replication_factor\': 1};"")\n\n        config.session.execute(""""""CREATE TYPE IF NOT EXISTS test_np_meta.np_meta (flags int, elem_size int, \n        partition_type tinyint, dims list<int>, strides list<int>, typekind text, byteorder text)"""""")\n\n        config.cluster.register_user_type(\'test_np_meta\', \'np_meta\', HArrayMetadata)\n'"
hecuba_py/tests/withcassandra/hfilter_tests.py,0,"b'import time\nimport unittest\nfrom hecuba import StorageDict, config\n\n\nclass SimpleDict(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<key0:int>, val0:int>\n    \'\'\'\n\n\nclass ComplexDict(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<key0:str, key1:int>, val0:str, val1:int, val2:float, val3:bool>\n    \'\'\'\n\n\nclass LambdaParserTest(unittest.TestCase):\n\n    def test_simple_filter(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.simpledict"")\n        simple_dict = SimpleDict(""hfilter_tests.simpledict"")\n        res = filter(lambda x: x.key0 == 5, simple_dict.items())\n        res = [i for i in res]\n        self.assertEqual(0, len(res))\n\n    def test_greater(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.simpledict"")\n        simple_dict = SimpleDict(""hfilter_tests.simpledict"")\n        for i in range(0, 10):\n            simple_dict[i] = i\n        time.sleep(1)\n\n        res = filter(lambda x: x.key0 > 5, simple_dict.items())\n        res = [i for i in res]\n        self.assertEqual(4, len(res))\n        self.assertTrue((6, 6) in res)\n        self.assertTrue((7, 7) in res)\n        self.assertTrue((8, 8) in res)\n        self.assertTrue((9, 9) in res)\n\n    def test_column_not_exist(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.simpledict"")\n        simple_dict = SimpleDict(""hfilter_tests.simpledict"")\n\n        def filter_nonexisting_key():\n            return filter(lambda x: x.key1 == 5, simple_dict.items())\n\n        self.assertRaises(Exception, filter_nonexisting_key)\n\n    def test_not_persistent_object(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.simpledict"")\n        simple_dict = SimpleDict()\n        for i in range(0, 10):\n            simple_dict[i] = i\n\n        res = filter(lambda x: x[0] > 5, simple_dict.items())\n        res = [i for i in res]\n        self.assertEqual(4, len(res))\n        self.assertTrue((6, 6) in res)\n        self.assertTrue((7, 7) in res)\n        self.assertTrue((8, 8) in res)\n        self.assertTrue((9, 9) in res)\n\n    def test_filter_equal(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.simpledict"")\n        simple_dict = SimpleDict(""hfilter_tests.simpledict"")\n        for i in range(0, 10):\n            simple_dict[i] = i\n        time.sleep(1)\n\n        res = filter(lambda x: x.key0 == 5, simple_dict.items())\n        res = [i for i in res]\n        self.assertEqual(1, len(res))\n        self.assertEqual((5, 5), res[0])\n\n    def test_filter_inside(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.simpledict"")\n        simple_dict = SimpleDict(""hfilter_tests.simpledict"")\n        for i in range(0, 10):\n            simple_dict[i] = i\n        time.sleep(1)\n\n        res = filter(lambda x: x.key0 in [1, 3], simple_dict.items())\n        res = [i for i in res]\n        self.assertEqual(2, len(res))\n        self.assertTrue((1, 1) in res)\n        self.assertTrue((3, 3) in res)\n\n    def test_different_columns(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.simpledict"")\n        simple_dict = SimpleDict(""hfilter_tests.simpledict"")\n        for i in range(0, 10):\n            simple_dict[i] = i\n        time.sleep(1)\n\n        res = filter(lambda x: x.key0 in [1, 2, 3, 5, 6, 9] and x.val0 >= 0 and x.val0 <= 5, simple_dict.items())\n        res = [i for i in res]\n        self.assertEqual(4, len(res))\n        self.assertTrue((1, 1) in res)\n        self.assertTrue((2, 2) in res)\n        self.assertTrue((3, 3) in res)\n        self.assertTrue((5, 5) in res)\n\n    def test_complex_filter(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.complexdict"")\n        complex_dict = ComplexDict(""hfilter_tests.complexdict"")\n        for i in range(0, 20):\n            complex_dict[str(i), i] = [str(i), i, float(i), True]\n        time.sleep(2)\n\n        res = filter(lambda x: x.key0 in [""1"", ""2"", ""3"", ""4"", ""5""] and x.val1 >= 1 and x.val1 <= 5 and x.val2 >= 1.0 and x.val2 <= 4.0 and x.val3 == True, complex_dict.items())\n        res = [tuple(i) for i in res]\n        self.assertEqual(4, len(res))\n        self.assertTrue(((""1"", 1), (""1"", 1, 1.0, True)) in res)\n        self.assertTrue(((""2"", 2), (""2"", 2, 2.0, True)) in res)\n        self.assertTrue(((""3"", 3), (""3"", 3, 3.0, True)) in res)\n        self.assertTrue(((""4"", 4), (""4"", 4, 4.0, True)) in res)\n\n    def test_bad_type(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.simpledict"")\n        simple_dict = SimpleDict(""hfilter_tests.simpledict"")\n        for i in range(0, 10):\n            simple_dict[i] = i\n        time.sleep(1)\n\n        def execute_bad_type():\n            res = filter(lambda x: x.key0 == ""1"", simple_dict.items())\n\n        self.assertRaises(Exception, execute_bad_type)\n\n    def test_several_operators(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.simpledict"")\n        simple_dict = SimpleDict(""hfilter_tests.simpledict"")\n        for i in range(0, 10):\n            simple_dict[i] = i\n        time.sleep(1)\n\n        res = filter(lambda x: x.key0 < 5 and x.key0 >= 3, simple_dict.items())\n        res = [i for i in res]\n        self.assertEqual(2, len(res))\n        self.assertTrue((3, 3) in res)\n        self.assertTrue((4, 4) in res)\n\n    def test_reversed_operations(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.simpledict"")\n        simple_dict = SimpleDict(""hfilter_tests.simpledict"")\n        for i in range(0, 10):\n            simple_dict[i] = i\n        time.sleep(1)\n\n        res = filter(lambda x: 5 > x.key0 and 3 <= x.key0, simple_dict.items())\n        res = [i for i in res]\n        self.assertEqual(2, len(res))\n        self.assertTrue((3, 3) in res)\n        self.assertTrue((4, 4) in res)\n\n    def test_non_hecuba_filter(self):\n        l = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n        res = list(filter(lambda x: x >= 5, l))\n        self.assertEqual(res, [5, 6, 7, 8, 9])\n\n    def test_split_filter(self):\n        config.session.execute(""DROP TABLE IF EXISTS hfilter_tests.simpledict"")\n        simple_dict = SimpleDict(""hfilter_tests.simpledict"")\n        what_should_be = dict()\n        for i in range(0, 10):\n            what_should_be[i] = i\n            simple_dict[i] = i\n        time.sleep(1)\n\n        filtered = []\n        normal_filtered = list(python_filter(lambda x: x[0] > 3, simple_dict.items()))\n\n        i = 0\n        for partition in simple_dict.split():\n            # aggregation of filtering on each partition should be equal to a filter on the whole object\n            res = filter(lambda x: x.key0 > 3, partition.items())\n            for row in res:\n                filtered.append(row)\n\n            for k, v in partition.items():\n                # self.assertTrue((tuple(row.key), list(row.value)) in f2)\n                self.assertEqual(what_should_be[k], v)\n                i += 1\n\n        self.assertEqual(len(what_should_be), i)\n        self.assertEqual(len(filtered), len(normal_filtered))\n        for row in filtered:\n            self.assertTrue(row in normal_filtered)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/istorage_split_locality.py,0,"b'import unittest\n\nfrom collections import defaultdict\n\nfrom hecuba import config\nfrom hecuba.tools import tokens_partitions, discrete_token_ranges\n\nfrom .. import test_config\n\n\n@unittest.skip(""Disabled until token partition gets fixed"")\nclass IStorageSplitLocalityTest(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        config.session.execute(""CREATE KEYSPACE IF NOT EXISTS test_ksp  WITH replication = ""\n                               ""{\'class\': \'SimpleStrategy\', \'replication_factor\': 1};"")\n\n        config.session.execute(""CREATE TABLE IF NOT EXISTS test_ksp.tab(k int PRIMARY KEY,v int)"")\n\n    def test_enough_token(self):\n        original_cfg = config.__dict__\n        config.__dict__.update(splits_per_node=10, token_range_size=None, target_token_range_size=64 * 1024 * 1024)\n        all_tokens = discrete_token_ranges(list(map(lambda a: a.value, config.cluster.metadata.token_map.ring)))\n        tkns_p = list(tokens_partitions(""test_ksp"", ""tab"", all_tokens))\n        self.check_all(tkns_p, 10, 20)\n        config.__dict__ = original_cfg\n\n    def test_too_little_tokens(self):\n        original_cfg = config.__dict__\n        config.__dict__.update(splits_per_node=1000, token_range_size=None, target_token_range_size=64 * 1024)\n        all_tokens = discrete_token_ranges(list(map(lambda a: a.value, config.cluster.metadata.token_map.ring)))\n        tkns_p = list(tokens_partitions(""test_ksp"", ""tab"", all_tokens))\n        self.check_all(tkns_p, 1000, 1000)\n        config.__dict__ = original_cfg\n\n    def test_splitting_tokens(self):\n        original_cfg = config.__dict__\n        config.__dict__.update(splits_per_node=1,\n                               token_range_size=int((2 ** 64) / 1000),\n                               target_token_range_size=None)\n        all_tokens = discrete_token_ranges(list(map(lambda a: a.value, config.cluster.metadata.token_map.ring)))\n        tkns_p = list(tokens_partitions(""test_ksp"", ""tab"", all_tokens))\n        self.check_all(tkns_p, 1, 1000)\n        config.__dict__ = original_cfg\n\n    def test_using_size_estimates(self):\n        for i in range(100000):\n            config.session.execute(""INSERT INTO test_ksp.tab(k,v) values(%s,%s)"", [i, i])\n        original_cfg = config.__dict__\n        config.__dict__.update(splits_per_node=1,\n                               token_range_size=None,\n                               target_token_range_size=64)\n        test_config.ccm_cluster.flush()\n        test_config.ccm_cluster.compact()\n        all_tokens = discrete_token_ranges(list(map(lambda a: a.value, config.cluster.metadata.token_map.ring)))\n        tkns_p = list(tokens_partitions(""test_ksp"", ""tab"", all_tokens))\n        config.__dict__ = original_cfg\n        # self.check_all(tkns_p, 1, 1000)\n\n    def check_all(self, tkns_p, split_per_node, expected_total_tkns):\n        self.assertGreaterEqual(len(tkns_p), len(test_config.ccm_cluster.nodes) * split_per_node)\n        self.assertGreaterEqual(sum(map(len, tkns_p)), expected_total_tkns)\n        self.check_full_range([i for split_tokens in tkns_p for i in split_tokens])\n\n        hosts = [self.checkToken(worker_partition) for worker_partition in tkns_p]\n        self.assertEqual(len(set(hosts)), len(test_config.ccm_cluster.nodes))\n        self.ensure_balance(tkns_p)\n\n    def check_full_range(self, list_of_ranges):\n        list_of_ranges.sort()\n        start = list(map(lambda a: a[0], list_of_ranges))\n        counts = list(filter(lambda size: size[1] > 1, map(lambda number: (number, start.count(number)), start)))\n        self.assertEqual(0, len(counts), ""duplicated starts"")\n        end = list(map(lambda a: a[0], list_of_ranges))\n        counts = list(filter(lambda size: size[1] > 1, map(lambda number: (number, end.count(number)), end)))\n        self.assertEqual(0, len(counts), ""duplicated ends"")\n\n        first, last = list_of_ranges[0]\n        self.assertEqual(-(2 ** 63), first, ""first token should always be -2^63"")\n        for s, e in list_of_ranges[1:]:\n            self.assertEqual(last, s, ""broken range %d -> %d"" % (last, s))\n            last = e\n        self.assertEqual((2 ** 63) - 1, last, ""last token should always be (2^63)-1"")\n\n    def ensure_balance(self, tokens_per_split):\n        from cassandra.metadata import Token\n        tm = config.cluster.metadata.token_map\n        node_loads = defaultdict(int)\n        for split in tokens_per_split:\n            for f, t in split:\n                host = tm.get_replicas(""test_ksp"", Token(f))[0]\n                node_loads[host] += t - f\n\n        print(node_loads)\n        node_loads = node_loads.values()\n        avg_delta = sum(node_loads) // len(node_loads)\n        max_delta = max(node_loads)\n        min_delta = min(node_loads)\n        self.assertLessEqual(max_delta, avg_delta * 2)\n        self.assertGreaterEqual(min_delta, avg_delta / 2)\n\n    def checkToken(self, tokens):\n        # type : (List[Long]) -> Host\n        from cassandra.metadata import Token\n        tm = config.cluster.metadata.token_map\n        hosts = set(map(lambda token: tm.get_replicas(""test_ksp"", token)[0],\n                        map(lambda a: Token(a[0]), tokens)))\n        self.assertEqual(len(hosts), 1, ""A token range is local in 2 nodes"")\n        return list(hosts)[0]\n\n\nclass IStorageSplitLocalityTestVnodes(IStorageSplitLocalityTest):\n    @classmethod\n    def setUpClass(cls):\n        from hfetch import disconnectCassandra\n        disconnectCassandra()\n        from .. import set_ccm_cluster\n        test_config.ccm_cluster.clear()\n        set_ccm_cluster()\n        from .. import TEST_DEBUG\n        try:\n            test_config.ccm_cluster.populate(3, use_vnodes=True).start()\n        except Exception as ex:\n            if not TEST_DEBUG:\n                raise ex\n\n        import hfetch\n        import hecuba\n        import importlib\n        importlib.reload(hfetch)\n        import importlib\n        importlib.reload(hecuba)\n        super(IStorageSplitLocalityTest, cls).setUpClass()\n\n    @classmethod\n    def tearDownClass(cls):\n        from hfetch import disconnectCassandra\n        disconnectCassandra()\n\n        test_config.ccm_cluster.clear()\n        from .. import set_up_default_cassandra\n        set_up_default_cassandra()\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/istorage_tests.py,0,"b'import unittest\n\nfrom hecuba import config, StorageDict\nfrom hecuba.IStorage import IStorage\n\n\nclass PersistentDict(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<key:int>, value:double>\n    \'\'\'\n\n\nclass IStorageTests(unittest.TestCase):\n    def stop_persistent_method_test(self):\n        from hecuba.tools import storage_id_from_name\n        config.session.execute(\n            ""DROP TABLE IF  EXISTS test.istorage_pers;"")\n        config.session.execute(\n            ""DELETE FROM hecuba.istorage WHERE storage_id = {}"".format(storage_id_from_name(""test.istorage_pers"")))\n\n        key = 123\n        value = 456\n        name = \'test.istorage_pers\'\n\n        base_dict = PersistentDict()\n\n        def check_stop_pers():\n            assert (isinstance(base_dict, IStorage))\n            base_dict.stop_persistent()\n\n        self.assertRaises(RuntimeError, check_stop_pers)\n        # PyCOMPSs requires uuid of type str\n\n        base_dict.make_persistent(name)\n\n        base_dict[key] = value\n\n        base_dict.stop_persistent()\n\n        self.assertIsNone(base_dict.storage_id)\n        self.assertIsNone(base_dict.storage_id)\n\n        self.assertRaises(RuntimeError, check_stop_pers)\n\n        base_dict.make_persistent(name)\n\n        self.assertEqual(base_dict[key], value)\n\n        base_dict.stop_persistent()\n\n        self.assertRaises(RuntimeError, check_stop_pers)\n\n        external_dict = PersistentDict(name)\n        self.assertEqual(external_dict[key], value)\n\n    def delete_persistent_method_test(self):\n        from hecuba.tools import storage_id_from_name\n        config.session.execute(\n            ""DROP TABLE IF  EXISTS test.istorage_pers;"")\n        config.session.execute(\n            ""DELETE FROM hecuba.istorage WHERE storage_id = {}"".format(storage_id_from_name(""test.istorage_pers"")))\n\n        key = 123\n        value = 456\n        name = \'test.istorage_pers\'\n\n        base_dict = PersistentDict()\n\n        def check_stop_pers():\n            assert (isinstance(base_dict, IStorage))\n            base_dict.stop_persistent()\n\n        def check_del_pers():\n            assert (isinstance(base_dict, IStorage))\n            base_dict.delete_persistent()\n\n        self.assertRaises(RuntimeError, check_del_pers)\n        # PyCOMPSs requires uuid of type str\n\n        base_dict.make_persistent(name)\n\n        base_dict[key] = value\n\n        base_dict.delete_persistent()\n\n        self.assertIsNone(base_dict.storage_id)\n        self.assertIsNone(base_dict.storage_id)\n\n        self.assertRaises(RuntimeError, check_del_pers)\n        self.assertRaises(RuntimeError, check_stop_pers)\n\n        base_dict.make_persistent(name)\n\n        def get_key():\n            res = base_dict[key]\n\n        self.assertRaises(KeyError, get_key)\n\n        base_dict.delete_persistent()\n\n        self.assertRaises(RuntimeError, check_del_pers)\n        self.assertRaises(RuntimeError, check_stop_pers)\n\n        external_dict = PersistentDict(name)\n\n        def get_key_ext():\n            res = external_dict[key]\n\n        self.assertRaises(KeyError, get_key_ext)\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/parser_hints_tests.py,0,"b'import unittest\n\nfrom hecuba import StorageObj, StorageDict\n\n\n# no dict\nclass Dict1(StorageDict):\n    \'\'\'\n    @TypeSpec <<a:int>, b:int, c:str>\n    \'\'\'\n\n\n# missing comma\nclass Dict2(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<a:int>, b:int c:int>\n    \'\'\'\n\n\n# bad characters\nclass Dict3(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<a:int>, b:int, c:int!?\xc2\xbf>\n    \'\'\'\n\n\n# two lines\nclass Dict4(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<a:int>, b:int, c:int>\n    @TypeSpec dict<<a:int>, b:int, c:int>\n    \'\'\'\n\n\n# no <<key>, value> format\nclass Dict5(StorageDict):\n    \'\'\'\n    @TypeSpec <a:int, b:int>\n    \'\'\'\n\n\n# bad character :\nclass Obj1(StorageObj):\n    \'\'\'\n    @ClassField a int\n    @ClassField b:int\n    \'\'\'\n\n\n# possible character :\nclass Obj2(StorageObj):\n    \'\'\'\n    @ClassField a int\n    @ClassField dictField dict<<key0:int>, val0:str>\n    \'\'\'\n\n\n# two values in one ClassField\nclass Obj3(StorageObj):\n    \'\'\'\n    @ClassField a int, b str\n    \'\'\'\n\n\ndef try_parser(constructor):\n    try:\n        constructor()\n    except Exception as ex:\n        return str(ex)\n    return None\n\n\nclass ParserHintsTest(unittest.TestCase):\n\n    def test_no_dict(self):\n        error = \\\n            ""No detected keys. Maybe you forgot to set a primary key or there is a missing \'dict\' after the TypeSpec.""\n        self.assertEqual(try_parser(Dict1), error)\n\n    def test_missing_coma_dict(self):\n        error = ""Error parsing the TypeSpec. Maybe you forgot a comma between the columns.""\n        self.assertEqual(try_parser(Dict2), error)\n\n    def test_bad_characters_dict(self):\n        error = ""One or more bad character detected: [!, ?, \xc2\xbf].""\n        self.assertEqual(try_parser(Dict3), error)\n\n    def test_two_lines_dict(self):\n        error = ""StorageDicts should only have one TypeSpec line.""\n        self.assertEqual(try_parser(Dict4), error)\n\n    def test_bad_format_dict(self):\n        error = ""The TypeSpec should have at least two \'<\' and two \'>\'. Format: @TypeSpec dict<<key:type>, value:type>.""\n        self.assertEqual(try_parser(Dict5), error)\n\n    def test_bad_colon_obj(self):\n        error = ""The ClassField @ClassField b:int should only have the character \':\' if it is in a dict.""\n        self.assertEqual(try_parser(Obj1), error)\n\n    def test_good_colon_obj(self):\n        error = None\n        self.assertEqual(try_parser(Obj2), error)\n\n    def test_two_values_one_classfield_obj(self):\n        error = ""Type \'int,\' not identified.""\n        self.assertEqual(try_parser(Obj3), error)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/storage_api_tests.py,0,"b'import unittest\n\nfrom storage.api import getByID\nfrom ..app.words import Words\nfrom storage.api import StorageDict, StorageObject, StorageNumpy\n\n\nclass ApiTestSDict(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<key:int>, value:double>\n    \'\'\'\n\n\nclass ApiTestSObject(StorageObject):\n    \'\'\'\n    @ClassField attr int\n    @ClassField attr2 str\n    \'\'\'\n\n\nclass StorageApi_Tests(unittest.TestCase):\n    def class_type_test(self):\n        base_dict = ApiTestSDict(\'test.api_sdict\')\n        # PyCOMPSs requires uuid of type str\n        storage_id = str(base_dict.storage_id)\n        del base_dict\n\n        rebuild_dict = getByID(storage_id)\n        self.assertTrue(isinstance(rebuild_dict, ApiTestSDict))\n\n    def object_id_is_str_test(self):\n        memory_obj = ApiTestSDict()\n\n        self.assertTrue(hasattr(memory_obj, \'getID\'))\n        self.assertIsInstance(memory_obj.getID(), str, ""PyCOMPSs specs states that getID should return a string"")\n\n        pers_dict = ApiTestSDict(\'test.api_id_str\')\n        self.assertTrue(hasattr(pers_dict, \'getID\'))\n        self.assertIsInstance(pers_dict.getID(), str, ""PyCOMPSs specs states that getID should return a string"")\n\n    def test_getByID_block(self):\n        # ki = KeyIter(\'testspace\', \'tt\', \'app.words.Words\', \'fake-id\', [\'position\'])\n        from hecuba import config\n        config.session.execute(""DROP TABLE IF EXISTS my_app.so"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.so_0"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.so_1"")\n        SO = Words(\'so\')\n        b = next(SO.split())\n        new_block = getByID(b.storage_id)\n        self.assertEqual(b.storage_id, new_block.storage_id)\n        self.assertEqual(b, new_block)\n\n    def test_getByID_storage_obj(self):\n        b = Words(\'testspace.tt\')\n        new_block = getByID(b.storage_id)\n        self.assertEqual(b, new_block)\n\n    def test_get_by_alias(self):\n        attr = 123\n        attr2 = ""textattribute""\n        obj = ApiTestSObject(\'test.api_by_alias\')\n        obj.attr = attr\n        obj.attr2 = attr2\n        del obj\n        rebuild = ApiTestSObject.get_by_alias(\'test.api_by_alias\')\n        self.assertEqual(rebuild.attr, attr)\n        self.assertEqual(rebuild.attr2, attr2)\n\n        obj2 = ApiTestSDict(\'test.api_by_alias2\')\n        rebuild = ApiTestSDict.get_by_alias(\'test.api_by_alias2\')\n        self.assertEqual(obj2, rebuild)\n'"
hecuba_py/tests/withcassandra/storagedict_split_tests.py,0,"b'import unittest\n\nfrom hecuba import config\nfrom hecuba.hdict import StorageDict\nfrom hecuba.storageobj import StorageObj\n\n\nclass SObj_Basic(StorageObj):\n    \'\'\'\n    @ClassField attr1 int\n    @ClassField attr2 double\n    @ClassField attr3 str\n    \'\'\'\n\n\nclass SDict_SimpleTypeSpec(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<id:int>, info:str>\n    \'\'\'\n\n\nclass SDict_ComplexTypeSpec(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<id:int>, state:tests.withcassandra.storagedict_split_tests.SObj_Basic>\n    \'\'\'\n\n\nclass SObj_SimpleClassField(StorageObj):\n    \'\'\'\n    @ClassField attr1 int\n    @ClassField mydict dict<<key:str>, value:double>\n    @ClassField attr3 double\n    \'\'\'\n\n\nclass SObj_ComplexClassField(StorageObj):\n    \'\'\'\n    @ClassField attr1 int\n    @ClassField mydict dict<<key:str>, val:tests.withcassandra.storagedict_split_tests.SObj_Basic>\n    @ClassField attr3 double\n    \'\'\'\n\n\nclass StorageDictSplitTestbase(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        config.session.execute(""DROP KEYSPACE IF EXISTS my_app"", timeout=60)\n        config.session.execute(\n            ""CREATE KEYSPACE IF NOT EXISTS my_app WITH ""\n            ""replication = {\'class\': \'SimpleStrategy\', \'replication_factor\': 1};"",\n            timeout=60)\n\n    def test_simple_iterkeys_split(self):\n        config.session.execute(\n            ""CREATE TABLE IF NOT EXISTS my_app.tab30(position int, value text, PRIMARY KEY(position))"")\n        tablename = ""tab30""\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        num_inserts = 10000\n        what_should_be = set()\n        for i in range(num_inserts):\n            pd[i] = \'ciao\' + str(i)\n            what_should_be.add(i)\n\n        count = 0\n        res = set()\n        for partition in pd.split():\n            for val in partition.keys():\n                res.add(val)\n                count += 1\n        self.assertEqual(count, num_inserts)\n        self.assertEqual(what_should_be, res)\n\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.tab30\')[0]\n        self.assertEqual(count, num_inserts)\n\n    def test_remote_build_iterkeys_split(self):\n        config.session.execute(\n            ""CREATE TABLE IF NOT EXISTS my_app.tab_b0(position int, value text, PRIMARY KEY(position))"")\n        tablename = ""tab_b0""\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        num_inserts = 10000\n        what_should_be = set()\n        for i in range(num_inserts):\n            pd[i] = \'ciao\' + str(i)\n            what_should_be.add(i)\n\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        count = 0\n        res = set()\n        for partition in pd.split():\n            id = partition.storage_id\n            from storage.api import getByID\n            rebuild = getByID(id)\n            for val in rebuild.keys():\n                res.add(val)\n                count += 1\n        self.assertEqual(count, num_inserts)\n        self.assertEqual(what_should_be, res)\n\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.tab_b0\')[0]\n        self.assertEqual(count, num_inserts)\n\n    def test_composed_iteritems(self):\n        config.session.execute(\n            ""CREATE TABLE IF NOT EXISTS my_app.tab_b1(pid int,time int, value text,x float,y float,z float, PRIMARY KEY(pid,time))"")\n        tablename = ""tab_b1""\n        pd = StorageDict(tablename,\n                         [(\'pid\', \'int\'), (\'time\', \'int\')],\n                         [(\'value\', \'text\'), (\'x\', \'double\'), (\'y\', \'double\'), (\'z\', \'double\')])\n        num_inserts = 10000\n        what_should_be = {}\n        for i in range(num_inserts):\n            pd[i, i + 100] = [\'ciao\' + str(i), i * 0.1, i * 0.2, i * 0.3]\n            what_should_be[i, i + 100] = (\'ciao\' + str(i), i * 0.1, i * 0.2, i * 0.3)\n\n        count = 0\n        res = {}\n        for partition in pd.split():\n            for key, val in partition.items():\n                res[key] = val\n                count += 1\n        self.assertEqual(count, num_inserts)\n\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.tab_b1\')[0]\n        self.assertEqual(count, num_inserts)\n\n        delta = 0.0001\n        for i in range(num_inserts):\n            a = what_should_be[i, i + 100]\n            b = res[i, i + 100]\n            self.assertEqual(a[0], b.value)\n            self.assertAlmostEquals(a[1], b.x, delta=delta)\n            self.assertAlmostEquals(a[2], b.y, delta=delta)\n            self.assertAlmostEquals(a[3], b.z, delta=delta)\n\n    def computeItems(self, SDict):\n        counter = 0\n        for item in SDict.keys():\n            counter = counter + 1\n        # self.assertEqual(counter, expected)\n        return counter\n\n    def test_split_type_spec_basic(self):\n        nitems = 1000\n        mybook = SDict_SimpleTypeSpec(""test_records"")\n        for id in range(0, nitems):\n            mybook[id] = \'someRandomText\' + str(id)\n\n        del mybook\n        import gc\n        gc.collect()\n        # verify all data has been written\n        myotherbook = SDict_SimpleTypeSpec(""test_records"")\n        self.assertEqual(nitems, self.computeItems(myotherbook))\n        # we don\'t want anything in memory\n        del myotherbook\n\n        myfinalbook = SDict_SimpleTypeSpec(""test_records"")\n        # split the dict and assert all the dicts generated contain the expected data\n        acc = 0\n        nsplits = 0\n        for b in myfinalbook.split():  # this split fails\n            acc = acc + self.computeItems(b)\n            nsplits = nsplits + 1\n\n        self.assertEqual(acc, nitems)\n\n    def test_split_type_spec_complex(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.SObj_ComplexClassField"")\n        nitems = 10\n        mybook = SDict_ComplexTypeSpec(""experimentx"")\n        for id in range(0, nitems):\n            mybook[id] = SObj_Basic()\n            mybook[id].attr1 = id\n            mybook[id].attr2 = id / nitems\n            mybook[id].attr3 = ""basicobj"" + str(id)\n\n        del mybook\n\n        # verify all data has been written\n        myotherbook = SDict_ComplexTypeSpec(""experimentx"")\n        self.assertEqual(nitems, self.computeItems(myotherbook))\n        # we don\'t want anything in memory\n        del myotherbook\n\n        myfinalbook = SDict_ComplexTypeSpec(""experimentx"")\n        # split the dict and assert all the dicts generated contain the expected data\n        acc = 0\n        nsplits = 0\n        for b in myfinalbook.split():  # this split fails\n            acc = acc + self.computeItems(b)\n            nsplits = nsplits + 1\n\n        self.assertEqual(acc, nitems)\n\n    def test_split_class_field_simple(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.SObj_SimpleClassField"")\n        nitems = 80\n        mybook = SObj_SimpleClassField(""so_split_dict_simple"")\n        mybook.attr1 = nitems\n        mybook.attr3 = nitems / 100\n        for id in range(0, nitems):\n            key_text = \'so_split_dict_simple\' + str(id)\n            mybook.mydict[key_text] = id / nitems\n\n        del mybook\n\n        # verify all data has been written\n        myotherbook = SObj_SimpleClassField(""so_split_dict_simple"")\n        self.assertEqual(nitems, self.computeItems(myotherbook.mydict))\n        # we don\'t want anything in memory\n        del myotherbook\n\n        myfinalbook = SObj_SimpleClassField(""so_split_dict_simple"")\n        # split the dict and assert all the dicts generated contain the expected data\n        acc = 0\n        nsplits = 0\n        for b in myfinalbook.mydict.split():  # this split fails\n            acc = acc + self.computeItems(b)\n            nsplits = nsplits + 1\n\n        self.assertEqual(acc, nitems)\n\n    def test_split_class_field_complex(self):\n        nitems = 50\n        mybook = SObj_ComplexClassField(""so_split_dict_complex"")\n        mybook.attr1 = nitems\n        mybook.attr3 = nitems / 100\n        for id in range(0, nitems):\n            key_text = \'so_split_dict_simple\' + str(id)\n            so = SObj_Basic()\n            so.attr1 = id\n            so.attr2 = id / nitems\n            so.attr3 = \'someInnerRandomText\' + str(id)\n            mybook.mydict[key_text] = so\n\n        del mybook\n\n        # verify all data has been written\n        myotherbook = SObj_ComplexClassField(""so_split_dict_complex"")\n        self.assertEqual(nitems, self.computeItems(myotherbook.mydict))\n        # we don\'t want anything in memory\n        del myotherbook\n\n        myfinalbook = SObj_ComplexClassField(""so_split_dict_complex"")\n        # split the dict and assert all the dicts generated contain the expected data\n        acc = 0\n        nsplits = 0\n        for b in myfinalbook.mydict.split():  # this split fails\n            acc = acc + self.computeItems(b)\n            nsplits = nsplits + 1\n\n        self.assertEqual(acc, nitems)\n\n    def test_len_on_split(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test_split_len"")\n        ninserts = 100\n        obj = SDict_SimpleTypeSpec(""test_split_len"")\n        for i in range(ninserts):\n            obj[i] = str(f""test_split_len{i}"")\n        nin = len(obj)\n\n        count = 0\n        for chunk in obj.split():\n            count = count + len(chunk)\n\n        self.assertEqual(count, ninserts)\n\n    \'\'\'\n    def test_remote_build_composed_iteritems(self):\n         config.session.execute(\n            ""CREATE TABLE IF NOT EXISTS my_app.tab_b2(pid int,time int, value text,x float,y float,z float, PRIMARY KEY(pid,time))"")\n        tablename = ""tab_b2""\n        pd = StorageDict(tablename,\n                         [(\'pid\', \'int\'), (\'time\', \'int\')],\n                         [(\'value\', \'text\'), (\'x\', \'float\'), (\'y\', \'float\'), (\'z\', \'float\')])\n\n        what_should_be = {}\n        for i in range(10000):\n            pd[i, i + 100] = (\'ciao\' + str(i), i * 0.1, i * 0.2, i * 0.3)\n            what_should_be[i, i + 100] = (\'ciao\' + str(i), i * 0.1, i * 0.2, i * 0.3)\n\n        del pd\n\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.tab_b2\')[0]\n        self.assertEqual(count, 10000)\n        pd = StorageDict(tablename,\n                         [(\'pid\', \'int\'), (\'time\', \'int\')],\n                         [(\'value\', \'text\'), (\'x\', \'float\'), (\'y\', \'float\'), (\'z\', \'float\')])\n        count = 0\n        res = {}\n        for partition in pd.split():\n            id = partition.storage_id\n            from storage.api import getByID\n            rebuild = getByID(id)\n            for key, val in rebuild.items():\n                res[key] = val\n                count += 1\n        self.assertEqual(count, 10000)\n        delta = 0.0001\n        for i in range(10000):\n            a = what_should_be[i, i + 100]\n            b = res[i, i + 100]\n            self.assertEqual(a[0], b.value)\n            self.assertAlmostEquals(a[1], b.x, delta=delta)\n            self.assertAlmostEquals(a[2], b.y, delta=delta)\n            self.assertAlmostEquals(a[3], b.z, delta=delta)\n    \'\'\'\n\n\nclass StorageDictSlitTestVnodes(StorageDictSplitTestbase):\n    @classmethod\n    def setUpClass(cls):\n        from hfetch import disconnectCassandra\n        disconnectCassandra()\n        from .. import test_config, set_ccm_cluster\n        test_config.ccm_cluster.clear()\n        set_ccm_cluster()\n        from .. import TEST_DEBUG\n        try:\n            test_config.ccm_cluster.populate(3, use_vnodes=True).start()\n        except Exception as ex:\n            if not TEST_DEBUG:\n                raise ex\n\n        import hfetch\n        import hecuba\n        import importlib\n        importlib.reload(hfetch)\n        import importlib\n        importlib.reload(hecuba)\n        config.session.execute(""DROP KEYSPACE IF EXISTS my_app"")\n        config.session.execute(\n            ""CREATE KEYSPACE IF NOT EXISTS my_app WITH replication = {\'class\': \'SimpleStrategy\', \'replication_factor\': 1};"")\n        super(StorageDictSplitTestbase, cls).setUpClass()\n\n    @classmethod\n    def tearDownClass(cls):\n        from .. import test_config\n        from hfetch import disconnectCassandra\n        disconnectCassandra()\n\n        test_config.ccm_cluster.clear()\n        from .. import set_up_default_cassandra\n        set_up_default_cassandra()\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/storagedict_tests.py,0,"b'import unittest\nimport uuid\nimport datetime\nimport time\nfrom random import randint\n\nfrom hecuba import config, StorageObj, StorageDict\nfrom hecuba.IStorage import build_remotely\nfrom ..app.words import Words\n\n\nclass MyStorageDict(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<position:int>, val:int>\n    \'\'\'\n    pass\n\n\nclass MyStorageDict2(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<position:int, position2:str>, val:int>\n    \'\'\'\n    pass\n\n\nclass MyStorageDict3(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<key:str>, val:int>\n    \'\'\'\n\n\nclass MyStorageObjC(StorageObj):\n    \'\'\'\n    @ClassField mona dict<<a:str>, b:int>\n    \'\'\'\n\n\nclass MyStorageDictA(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<a:str>, b:int>\n    \'\'\'\n\n\nclass mydict(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<key0:int>, val0:tests.withcassandra.storagedict_tests.myobj2>\n    \'\'\'\n\n\nclass myobj2(StorageObj):\n    \'\'\'\n    @ClassField attr1 int\n    @ClassField attr2 str\n    \'\'\'\n\n\nclass DictWithTuples(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<key:int>, val:tuple<int,int>>\n    \'\'\'\n\n\nclass DictWithTuples2(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<key0:tuple<int,int>, key1:int>, val:str>\n    \'\'\'\n\n\nclass DictWithTuples3(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<key:int>, val0:int, val1:tuple<long,int>, val2:str, val3:tuple<str,float>>\n    \'\'\'\n\n\nclass MultiTuples(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<time:int, lat:double, lon:double, ilev:int>, m_cloudfract:tuple<float,float,float,int>, m_humidity:tuple<float,float,float,int>, m_icewater:tuple<float,float,float,int>, m_liquidwate:tuple<float,float,float,int>, m_ozone:tuple<float,float,float,int>, m_pot_vorticit:tuple<float,float,float,int>, m_rain:tuple<float,float,float,int>, m_snow:tuple<float,float,float,int>>\n    \'\'\'\n\n\nclass Test2StorageObj(StorageObj):\n    \'\'\'\n       @ClassField name str\n       @ClassField age int\n    \'\'\'\n    pass\n\n\nclass TestDictOfStorageObj(StorageDict):\n    \'\'\'\n        @TypeSpec dict<<key0:int>, val:tests.withcassandra.storageobj_tests.Test2StorageObj>\n    \'\'\'\n\n\nclass DictWithDates(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<date1:date>, date4:date>\n    \'\'\'\n\n\nclass DictWithTimes(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<date1:time>, date4:time>\n    \'\'\'\n\n\nclass DictWithDateTimes(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<date1:datetime>, date4:datetime>\n    \'\'\'\n\n\nclass DictWithDateTimes2(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<k:int>, v:datetime>\n    \'\'\'\n\n\nclass MyStorageDictB(StorageDict):\n    \'\'\'\n    @TypeSpec dict<<a:str, b:int>, c:int>\n    \'\'\'\n\n\nclass StorageDictTest(unittest.TestCase):\n    def test_init_empty(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab1"")\n        tablename = ""ksp.tab1""\n        tokens = [(1, 2), (2, 3), (3, 4)]\n        nopars = StorageDict(tablename,\n                             [(\'position\', \'int\')],\n                             [(\'value\', \'int\')],\n                             tokens=tokens)\n        self.assertEqual(""tab1"", nopars._table)\n        self.assertEqual(""ksp"", nopars._ksp)\n\n        res = config.session.execute(\n            \'SELECT storage_id, primary_keys, columns, class_name, name, tokens, istorage_props,indexed_on \' +\n            \'FROM hecuba.istorage WHERE storage_id = %s\', [nopars.storage_id])[0]\n\n        self.assertEqual(uuid.uuid3(uuid.NAMESPACE_DNS, tablename), nopars.storage_id)\n        self.assertEqual(nopars.__class__.__module__, \'hecuba.hdict\')\n        self.assertEqual(nopars.__class__.__name__, \'StorageDict\')\n\n        rebuild = build_remotely(res._asdict())\n        self.assertEqual(rebuild._built_remotely, True)\n        self.assertEqual(\'tab1\', rebuild._table)\n        self.assertEqual(""ksp"", rebuild._ksp)\n        self.assertEqual(uuid.uuid3(uuid.NAMESPACE_DNS, tablename), rebuild.storage_id)\n\n        self.assertEqual(nopars.storage_id, rebuild.storage_id)\n\n    def test_init_empty_def_keyspace(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab1"")\n        tablename = ""tab1""\n        tokens = [(1, 2), (2, 3), (3, 4)]\n        nopars = StorageDict(tablename,\n                             [(\'position\', \'int\')],\n                             [(\'value\', \'int\')],\n                             tokens=tokens)\n        self.assertEqual(""tab1"", nopars._table)\n        self.assertEqual(config.execution_name, nopars._ksp)\n\n        res = config.session.execute(\n            \'SELECT storage_id, primary_keys, columns, class_name, name, tokens, istorage_props,indexed_on \' +\n            \'FROM hecuba.istorage WHERE storage_id = %s\', [nopars.storage_id])[0]\n\n        self.assertEqual(uuid.uuid3(uuid.NAMESPACE_DNS, config.execution_name + \'.\' + tablename), nopars.storage_id)\n        self.assertEqual(nopars.__class__.__module__, \'hecuba.hdict\')\n        self.assertEqual(nopars.__class__.__name__, \'StorageDict\')\n\n        rebuild = build_remotely(res._asdict())\n        self.assertEqual(rebuild._built_remotely, True)\n        self.assertEqual(\'tab1\', rebuild._table)\n        self.assertEqual(config.execution_name, rebuild._ksp)\n        self.assertEqual(uuid.uuid3(uuid.NAMESPACE_DNS, config.execution_name + \'.\' + tablename), rebuild.storage_id)\n\n        self.assertEqual(nopars.storage_id, rebuild.storage_id)\n\n    def test_simple_insertions(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab10"")\n        tablename = ""tab10""\n        tokens = [(1, 2), (2, 3), (3, 4)]\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')],\n                         tokens=tokens)\n\n        for i in range(100):\n            pd[i] = \'ciao\' + str(i)\n        del pd\n        import gc\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.tab10\')[0]\n        self.assertEqual(count, 100)\n\n    def test_dict_print(self):\n        tablename = ""tab10""\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename)\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n\n        self.assertEquals(pd.__repr__(), """")\n\n        pd[0] = \'a\'\n        self.assertEquals(pd.__repr__(), ""{0: \'a\'}"")\n\n        pd[1] = \'b\'\n        self.assertEquals(pd.__repr__(), ""{1: \'b\', 0: \'a\'}"")\n\n        for i in range(1100):\n            pd[i] = str(i)\n        self.assertEquals(pd.__repr__().count(\':\'), 1000)\n\n    def test_get_strs(self):\n        tablename = ""tab10""\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename)\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        pd[0] = \'str1\'\n        self.assertEquals(pd[0], \'str1\')\n\n    def test_len_memory(self):\n        config.session.execute(""DROP TABLE IF EXISTS test.test_dict_len"")\n        config.session.execute(""DROP TABLE IF EXISTS test.test_dict_len_words"")\n        ninserts = 1500\n        nopars = Words()\n        self.assertIsNone(nopars.storage_id)\n        nopars.ciao = 1\n        nopars.ciao2 = ""1""\n        nopars.ciao3 = [1, 2, 3]\n        nopars.ciao4 = (1, 2, 3)\n        for i in range(ninserts):\n            nopars.words[i] = \'ciao\' + str(i)\n\n        self.assertEqual(len(nopars.words), ninserts)\n\n        nopars.make_persistent(\'test.test_dict_len\')\n        self.assertEqual(len(nopars.words), ninserts)\n\n    def test_len_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS test.test_dict_len"")\n        config.session.execute(""DROP TABLE IF EXISTS test.test_dict_len_words"")\n        ninserts = 1500\n        nopars = Words(\'test.test_dict_len\')\n        nopars.ciao = 1\n        nopars.ciao2 = ""1""\n        nopars.ciao3 = [1, 2, 3]\n        nopars.ciao4 = (1, 2, 3)\n        for i in range(ninserts):\n            nopars.words[i] = \'ciao\' + str(i)\n\n        self.assertEqual(len(nopars.words), ninserts)\n\n        rebuild = Words(\'test.test_dict_len\')\n        self.assertEqual(len(rebuild.words), ninserts)\n\n    def test_make_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.t_make"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.t_make_words"")\n        nopars = Words()\n        self.assertIsNone(nopars.storage_id)\n        nopars.ciao = 1\n        nopars.ciao2 = ""1""\n        nopars.ciao3 = [1, 2, 3]\n        nopars.ciao4 = (1, 2, 3)\n        for i in range(10):\n            nopars.words[i] = \'ciao\' + str(i)\n\n        count, = config.session.execute(\n            ""SELECT count(*) FROM system_schema.tables WHERE keyspace_name = \'my_app\' and table_name = \'Words_words\'"")[\n            0]\n        self.assertEqual(0, count)\n\n        nopars.make_persistent(""t_make"")\n\n        del nopars\n        import gc\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.t_make_words\')[0]\n        self.assertEqual(10, count)\n\n    def test_none_value(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Words"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Words_words"")\n        mydict = MyStorageDict(\'somename\')\n        mydict[0] = None\n        self.assertEqual(mydict[0], None)\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Words"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Words_words"")\n\n    def test_none_keys(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.somename"")\n        mydict = MyStorageDict(\'somename\')\n\n        def set_none_key():\n            mydict[None] = 1\n\n        self.assertRaises(TypeError, set_none_key)\n        config.session.execute(""DROP TABLE IF EXISTS my_app.somename"")\n\n    def test_paranoid_setitem_nonpersistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.mydict"")\n        pd = StorageDict(""mydict"",\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        pd[0] = \'bla\'\n        self.assertEquals(pd[0], \'bla\')\n\n        def set_wrong_val_1():\n            pd[0] = 1\n\n        self.assertRaises(TypeError, set_wrong_val_1)\n\n        def set_wrong_val_2():\n            pd[\'bla\'] = \'bla\'\n\n        self.assertRaises(TypeError, set_wrong_val_2)\n\n    def test_paranoid_setitem_multiple_nonpersistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.mydict"")\n        pd = StorageDict(""mydict"",\n                         [(\'position1\', \'int\'), (\'position2\', \'text\')],\n                         [(\'value1\', \'text\'), (\'value2\', \'int\')])\n        pd[0, \'pos1\'] = [\'bla\', 1]\n        self.assertEquals(pd[0, \'pos1\'], (\'bla\', 1))\n\n        def set_wrong_val_1():\n            pd[0, \'pos1\'] = [1, \'bla\']\n\n        self.assertRaises(TypeError, set_wrong_val_1)\n\n        def set_wrong_val_2():\n            pd[\'pos1\', 0] = [\'bla\', 1]\n\n        self.assertRaises(TypeError, set_wrong_val_2)\n\n    def test_paranoid_setitem_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab_a1"")\n        pd = StorageDict(""tab_a1"",\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        pd[0] = \'bla\'\n        result = config.session.execute(\'SELECT value FROM my_app.tab_a1 WHERE position = 0\')\n        for row in result:\n            self.assertEquals(row.value, \'bla\')\n\n        def set_wrong_val_test():\n            pd[0] = 1\n\n        self.assertRaises(TypeError, set_wrong_val_test)\n\n    def test_paranoid_setitem_multiple_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab_a2"")\n        pd = StorageDict(""tab_a2"",\n                         [(\'position1\', \'int\'), (\'position2\', \'text\')],\n                         [(\'value1\', \'text\'), (\'value2\', \'int\')])\n        pd[0, \'pos1\'] = [\'bla\', 1]\n        for result in pd.values():\n            self.assertEquals(result.value1, \'bla\')\n            self.assertEquals(result.value2, 1)\n\n        def set_wrong_val():\n            pd[0, \'pos1\'] = [\'bla\', \'bla1\']\n\n        self.assertRaises(TypeError, set_wrong_val)\n\n        def set_wrong_key():\n            pd[\'bla\', \'pos1\'] = [\'bla\', 1]\n\n        self.assertRaises(TypeError, set_wrong_key)\n\n    def test_paranoid_setitemdouble_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab_a3"")\n        pd = StorageDict(""tab_a3"",\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'double\')])\n        pd[0] = 2.0\n        result = config.session.execute(\'SELECT value FROM my_app.tab_a3 WHERE position = 0\')\n        for row in result:\n            self.assertEquals(row.value, 2.0)\n\n        def set_wrong_val_test():\n            pd[0] = 1\n\n        set_wrong_val_test()\n\n    def test_paranoid_setitemdouble_multiple_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab_a4"")\n        pd = StorageDict(""tab_a4"",\n                         [(\'position1\', \'int\'), (\'position2\', \'text\')],\n                         [(\'value1\', \'text\'), (\'value2\', \'double\')])\n        pd[0, \'pos1\'] = [\'bla\', 1.0]\n        time.sleep(2)\n        self.assertEquals(pd[0, \'pos1\'], (\'bla\', 1.0))\n\n    def test_empty_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.wordsso"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.wordsso_words"")\n        so = Words()\n        so.make_persistent(""wordsso"")\n        so.ciao = ""an attribute""\n        so.another = 123\n        config.batch_size = 1\n        config.cache_activated = False\n        for i in range(10):\n            so.words[i] = str.join(\',\', map(lambda a: ""ciao"", range(i)))\n\n        del so\n        import gc\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.wordsso_words\')[0]\n        self.assertEqual(10, count)\n\n        so = Words(""wordsso"")\n        so.delete_persistent()\n\n        def delete_already_deleted():\n            so.words.delete_persistent()\n\n        self.assertRaises(RuntimeError, delete_already_deleted)\n\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.wordsso_words\')[0]\n        self.assertEqual(0, count)\n\n    def test_simple_items_test(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab_a1"")\n\n        pd = StorageDict(""tab_a1"",\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n\n        what_should_be = {}\n        for i in range(100):\n            pd[i] = \'ciao\' + str(i)\n            what_should_be[i] = \'ciao\' + str(i)\n        del pd\n        import gc\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.tab_a1\')[0]\n        self.assertEqual(count, 100)\n        pd = StorageDict(""tab_a1"",\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        count = 0\n        res = {}\n        for key, val in pd.items():\n            res[key] = val\n            count += 1\n        self.assertEqual(count, 100)\n        self.assertEqual(what_should_be, res)\n\n    def test_simple_values_test(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab_a2"")\n        tablename = ""tab_a2""\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n\n        what_should_be = set()\n        for i in range(100):\n            pd[i] = \'ciao\' + str(i)\n            what_should_be.add(\'ciao\' + str(i))\n        del pd\n        import gc\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.tab_a2\')[0]\n\n        self.assertEqual(count, 100)\n\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        count = 0\n        res = set()\n        for val in pd.values():\n            res.add(val)\n            count += 1\n        self.assertEqual(count, 100)\n        self.assertEqual(what_should_be, res)\n\n    def test_simple_keys_test(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab_a3"")\n        tablename = ""tab_a3""\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n\n        what_should_be = set()\n        for i in range(100):\n            pd[i] = \'ciao\' + str(i)\n            what_should_be.add(i)\n        del pd\n        import gc\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.tab_a3\')[0]\n        self.assertEqual(count, 100)\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        count = 0\n        res = set()\n        for val in pd.keys():\n            res.add(val)\n            count += 1\n        self.assertEqual(count, 100)\n        self.assertEqual(what_should_be, res)\n\n    def test_simple_contains(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab_a4"")\n        tablename = ""tab_a4""\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n\n        for i in range(100):\n            pd[i] = \'ciao\' + str(i)\n        del pd\n        import gc\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.tab_a4\')[0]\n        self.assertEqual(count, 100)\n\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        for i in range(100):\n            self.assertTrue(i in pd)\n\n    def test_deleteitem_nonpersistent(self):\n        pd = StorageDict(None,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        pd[0] = \'to_delete\'\n        del pd[0]\n\n        def del_val():\n            val = pd[0]\n\n        self.assertRaises(KeyError, del_val)\n\n        pd = StorageDict(None,\n                         [(\'position\', \'text\')],\n                         [(\'value\', \'int\')])\n        pd[\'pos0\'] = 0\n        del pd[\'pos0\']\n\n        def del_val():\n            val = pd[\'pos0\']\n\n        self.assertRaises(KeyError, del_val)\n\n    def test_deleteitem_persistent(self):\n        tablename = ""tab_a5""\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename)\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        pd[0] = \'to_delete\'\n        del pd[0]\n\n        def del_val():\n            val = pd[0]\n\n        self.assertRaises(KeyError, del_val)\n\n        tablename = ""tab_a6""\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename)\n        pd = StorageDict(tablename,\n                         [(\'position\', \'text\')],\n                         [(\'value\', \'int\')])\n        pd[\'pos1\'] = 0\n        del pd[\'pos1\']\n\n        def del_val():\n            val = pd[\'pos1\']\n\n        self.assertRaises(KeyError, del_val)\n\n    def test_delete_two_keys(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dict"")\n        o = MyStorageDictB(""dict"")\n        o[""0"", 0] = 0\n        o[""1"", 1] = 1\n\n        del o[""0"", 0]\n\n        self.assertEqual(o[""1"", 1], 1)\n        self.assertEqual(o.get((""0"", 0), None), None)\n\n    def test_composed_items_test(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab12"")\n        tablename = ""tab12""\n        pd = StorageDict(tablename,\n                         primary_keys=[(\'pid\', \'int\'), (\'time\', \'int\')],\n                         columns=[(\'value\', \'text\'), (\'x\', \'double\'), (\'y\', \'double\'), (\'z\', \'double\')])\n\n        what_should_be = {}\n        for i in range(100):\n            pd[i, i + 100] = [\'ciao\' + str(i), i * 0.1, i * 0.2, i * 0.3]\n            what_should_be[i, i + 100] = [\'ciao\' + str(i), i * 0.1, i * 0.2, i * 0.3]\n\n        del pd\n        import gc\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.tab12\')[0]\n        self.assertEqual(count, 100)\n        pd = StorageDict(tablename,\n                         [(\'pid\', \'int\'), (\'time\', \'int\')],\n                         [(\'value\', \'text\'), (\'x\', \'double\'), (\'y\', \'double\'), (\'z\', \'double\')])\n        count = 0\n        res = {}\n        for key, val in pd.items():\n            res[key] = val\n            count += 1\n        self.assertEqual(count, 100)\n        delta = 0.000001\n        for i in range(100):\n            a = what_should_be[i, i + 100]\n            b = res[i, i + 100]\n            self.assertEqual(a[0], b.value)\n            self.assertAlmostEquals(a[1], b.x, delta=delta)\n            self.assertAlmostEquals(a[2], b.y, delta=delta)\n            self.assertAlmostEquals(a[3], b.z, delta=delta)\n\n    def test_composed_key_return_list_items_test(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab13"")\n        tablename = ""tab13""\n        pd = StorageDict(tablename,\n                         primary_keys=[(\'pid\', \'int\'), (\'time\', \'double\')],\n                         columns=[(\'value\', \'text\'), (\'x\', \'double\'), (\'y\', \'double\'), (\'z\', \'double\')])\n\n        what_should_be = {}\n        for i in range(100):\n            pd[i, i + 100.0] = [\'ciao\' + str(i), i * 0.1, i * 0.2, i * 0.3]\n            what_should_be[i, i + 100.0] = [\'ciao\' + str(i), i * 0.1, i * 0.2, i * 0.3]\n\n        del pd\n        import gc\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.tab13\')[0]\n        self.assertEqual(count, 100)\n        pd = StorageDict(tablename,\n                         [(\'pid\', \'int\')],\n                         [(\'time\', \'double\'), (\'value\', \'text\'), (\'x\', \'double\'), (\'y\', \'double\'), (\'z\', \'double\')])\n        count = 0\n        res = {}\n        for key, val in pd.items():\n            self.assertTrue(isinstance(key, int))\n            self.assertTrue(isinstance(val[0], float))\n            res[key] = val\n            count += 1\n        self.assertEqual(count, 100)\n        # casting to avoid 1.0000001 float python problem\n        data = set([(key, int(val.time), val.value, int(val.x), int(val.y), int(val.z)) for key, val in pd.items()])\n        data2 = set([(key[0], int(key[1]), val[0], int(val[1]), int(val[2]), int(val[3])) for key, val in\n                     what_should_be.items()])\n        self.assertEqual(data, data2)\n\n    def test_storagedict_newinterface_localmemory(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.my_dict"")\n\n        my_dict = MyStorageDict()\n        my_dict[0] = 1\n        error = False\n        try:\n            result = config.session.execute(\'SELECT * FROM my_app.my_dict\')[0]\n        except Exception as e:\n            error = True\n        self.assertEquals(True, error)\n\n    def test_storagedict_newinterface_memorytopersistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.my_dict"")\n\n        my_dict = MyStorageDict()\n        my_dict[0] = 1\n        error = False\n        try:\n            result = config.session.execute(\'SELECT * FROM my_app.my_dict\')[0]\n        except Exception as e:\n            error = True\n        self.assertEquals(True, error)\n\n        my_dict.make_persistent(\'my_dict\')\n\n        del my_dict\n        import gc\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.my_dict\')[0]\n        self.assertEquals(1, count)\n\n    def test_storagedict_newinterface_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.my_dict"")\n\n        my_dict = MyStorageDict()\n        my_dict[0] = 1\n        my_dict.make_persistent(\'my_dict\')\n        time.sleep(1)\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.my_dict\')[0]\n        self.assertEquals(1, count)\n\n        my_dict[1] = 2\n        time.sleep(1)\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.my_dict\')[0]\n        self.assertEquals(2, count)\n\n        my_dict2 = MyStorageDict(\'my_dict\')\n        self.assertEquals(1, my_dict2[0])\n        self.assertEquals(2, my_dict2[1])\n\n    def test_update(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab_a4"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab_a5"")\n        tablename = ""tab_a4""\n        pd = StorageDict(tablename,\n                         [(\'position\', \'int\')],\n                         [(\'value\', \'text\')])\n        pd[0] = \'prev_a\'\n        pd[1] = \'prev_b\'\n        self.assertEquals(pd[0], \'prev_a\')\n        self.assertEquals(pd[1], \'prev_b\')\n        pd.update({0: \'a\', 1: \'b\'})\n        time.sleep(1)\n        self.assertEquals(pd[0], \'a\')\n        self.assertEquals(pd[1], \'b\')\n        pd.update({2: \'c\', 3: \'d\'})\n        time.sleep(1)\n        self.assertEquals(pd[0], \'a\')\n        self.assertEquals(pd[1], \'b\')\n        self.assertEquals(pd[2], \'c\')\n        self.assertEquals(pd[3], \'d\')\n        tablename = ""tab_a5""\n        pd2 = StorageDict(tablename,\n                          [(\'position\', \'int\')],\n                          [(\'value\', \'text\')])\n        pd2[0] = \'final_a\'\n        pd2[4] = \'final_4\'\n        pd.update(pd2)\n        time.sleep(1)\n        self.assertEquals(pd[0], \'final_a\')\n        self.assertEquals(pd[4], \'final_4\')\n\n    def test_update_kwargs(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tab_a6"")\n        tablename = ""tab_a6""\n        pd = StorageDict(tablename,\n                         [(\'position\', \'text\')],\n                         [(\'value\', \'text\')])\n        pd[\'val1\'] = \'old_a\'\n        pd[\'val2\'] = \'old_b\'\n        time.sleep(2)\n        self.assertEquals(pd[\'val1\'], \'old_a\')\n        self.assertEquals(pd[\'val2\'], \'old_b\')\n        pd.update(val1=\'new_a\', val2=\'new_b\')\n        time.sleep(2)\n        self.assertEquals(pd[\'val1\'], \'new_a\')\n        self.assertEquals(pd[\'val2\'], \'new_b\')\n\n    def test_get_persistent(self):\n        table_name = \'tab_a7\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + table_name)\n        my_text = MyStorageDict3(\'my_app.\' + table_name)\n        self.assertEquals(0, my_text.get(\'word\', 0))\n        my_text[\'word\'] = my_text.get(\'word\', 0) + 1\n        time.sleep(2)\n        self.assertEquals(1, my_text.get(\'word\', 0))\n\n    def test_get_notpersistent(self):\n        my_text = MyStorageDict3()\n        self.assertEquals(0, my_text.get(\'word\', 0))\n        my_text[\'word\'] = my_text.get(\'word\', 0) + 1\n        time.sleep(2)\n        self.assertEquals(1, my_text.get(\'word\', 0))\n\n    def test_keys(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test_keys"")\n        my_dict = MyStorageDict2(\'test_keys\')\n        # int,text - int\n        nitems = 100\n        # write nitems to the dict\n        for id in range(0, nitems):\n            text_id = \'someText\'\n            # force some clash on second keys\n            if id % 2 == 0:\n                text_id = \'someText\' + str(id)\n            my_dict[(id, text_id)] = id\n\n        del my_dict  # force sync\n        my_dict = MyStorageDict2(\'test_keys\')\n        total_items = list(my_dict.items())\n\n        self.assertEqual(len(total_items), nitems)\n\n        # del my_dict\n\n        my_second_dict = MyStorageDict2()\n\n        for id in range(nitems, 2 * nitems):\n            text_id = \'someText\'\n            # force some clash on second keys\n            if id % 2 == 0:\n                text_id = \'someText\' + str(id)\n            my_second_dict[(id, text_id)] = id\n\n        my_second_dict.make_persistent(\'test_keys\')\n        del my_second_dict  # force sync\n        my_second_dict = MyStorageDict2()\n        my_second_dict.make_persistent(\'test_keys\')\n\n        total_items = list(my_second_dict.items())\n        self.assertEqual(len(total_items), 2 * nitems)\n        del my_dict\n        del my_second_dict\n\n        my_third_dict = MyStorageDict2(\'test_keys\')\n        total_items = list(my_third_dict.items())\n        self.assertEqual(len(total_items), 2 * nitems)\n\n        del my_third_dict\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test_keys"")\n\n    def test_values(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test_values"")\n        my_dict = MyStorageDict2(\'test_values\')\n        # int,text - int\n        nitems = 100\n        # write nitems to the dict\n        for id in range(0, nitems):\n            text_id = \'someText\'\n            # force some clash on second keys\n            if id % 2 == 0:\n                text_id = \'someText\' + str(id)\n            my_dict[(id, text_id)] = id\n\n        del my_dict  # force sync\n        my_dict = MyStorageDict2(\'test_values\')\n        total_items = my_dict.items()\n\n        self.assertEqual(len(list(total_items)), nitems)\n\n        # del my_dict\n\n        my_second_dict = MyStorageDict2()\n\n        for id in range(nitems, 2 * nitems):\n            text_id = \'someText\'\n            # force some clash on second keys\n            if id % 2 == 0:\n                text_id = \'someText\' + str(id)\n            my_second_dict[(id, text_id)] = id\n\n        my_second_dict.make_persistent(\'test_values\')\n        del my_second_dict  # force sync\n        my_second_dict = MyStorageDict2()\n        my_second_dict.make_persistent(\'test_values\')\n\n        total_items = list(my_second_dict.items())\n        self.assertEqual(len(total_items), 2 * nitems)\n        del my_dict\n        del my_second_dict\n\n        my_third_dict = MyStorageDict2(\'test_values\')\n        total_items = list(my_third_dict.items())\n        self.assertEqual(len(total_items), 2 * nitems)\n\n        del my_third_dict\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test_values"")\n\n    def test_items(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test_items"")\n        my_dict = MyStorageDict2(\'test_items\')\n        # int,text - int\n        nitems = 100\n        # write nitems to the dict\n        for id in range(0, nitems):\n            text_id = \'someText\'\n            # force some clash on second keys\n            if id % 2 == 0:\n                text_id = \'someText\' + str(id)\n            my_dict[(id, text_id)] = id\n\n        del my_dict  # force sync\n        my_dict = MyStorageDict2(\'test_items\')\n        total_items = list(my_dict.items())\n\n        self.assertEqual(len(total_items), nitems)\n\n        # del my_dict\n\n        my_second_dict = MyStorageDict2()\n\n        for id in range(nitems, 2 * nitems):\n            text_id = \'someText\'\n            # force some clash on second keys\n            if id % 2 == 0:\n                text_id = \'someText\' + str(id)\n            my_second_dict[(id, text_id)] = id\n\n        my_second_dict.make_persistent(\'test_items\')\n        del my_second_dict  # force sync\n        my_second_dict = MyStorageDict2()\n        my_second_dict.make_persistent(\'test_items\')\n\n        total_items = list(my_second_dict.items())\n        self.assertEqual(len(total_items), 2 * nitems)\n        del my_dict\n        del my_second_dict\n\n        my_third_dict = MyStorageDict2(\'test_items\')\n        total_items = list(my_third_dict.items())\n        self.assertEqual(len(total_items), 2 * nitems)\n\n        del my_third_dict\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test_items"")\n\n    def test_iterator_sync(self):\n        \'\'\'\n        check that the prefetch returns the exact same number of elements as inserted \n        \'\'\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test_iterator_sync"")\n        my_dict = MyStorageDict2(\'test_iterator_sync\')\n        # int,text - int\n        nitems = 5000\n        # write nitems to the dict\n        for id in range(0, nitems):\n            text_id = \'someText\'\n            # force some clash on second keys\n            if id % 2 == 0:\n                text_id = \'someText\' + str(id)\n            my_dict[(id, text_id)] = id\n\n        total_items = list(my_dict.items())\n\n        self.assertEqual(len(total_items), nitems)\n        del my_dict\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test_iterator_sync"")\n\n    def test_assign_and_replace(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.MyStorageObjC"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.MyStorageObjC_mona"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.MyStorageObjC_mona_0"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.MyStorageObjC_mona_1"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.second_name"")\n\n        first_storagedict = MyStorageDictA()\n        my_storageobj = MyStorageObjC(""first_name"")\n        self.assertIsNotNone(my_storageobj.mona.storage_id)\n        self.assertTrue(isinstance(my_storageobj.mona.storage_id, uuid.UUID))\n\n        # Creates the \'my_app.mystorageobjc_mona\' table\n        my_storageobj.mona[\'uno\'] = 123\n\n        # empty dict no persistent assigned to persistent object\n        # creates the \'my_app.mystorageobjc_mona_0\' table\n        my_storageobj.mona = first_storagedict\n\n        self.assertIsNotNone(my_storageobj.mona.storage_id)\n        self.assertTrue(isinstance(my_storageobj.mona.storage_id, uuid.UUID))\n        nitems = list(my_storageobj.mona.items())\n        self.assertEqual(len(nitems), 0)\n        # it was assigned to a persistent storage obj, it should be persistent\n        self.assertIsNotNone(first_storagedict.storage_id)\n        self.assertTrue(isinstance(first_storagedict.storage_id, uuid.UUID))\n        # create another non persistent dict\n        my_storagedict = MyStorageDictA()\n        my_storagedict[\'due\'] = 12341321\n        # store the second non persistent dict into the StorageObj attribute\n        my_storageobj.mona = my_storagedict\n        # contents should not be merged, the contents should be the same as in the last storage_dict\n        elements = list(my_storageobj.mona.items())\n        self.assertEqual(len(elements), 1)\n        my_storagedict = MyStorageDictA(\'second_name\')\n        last_key = \'some_key\'\n        last_value = 123\n\n        my_storagedict[last_key] = last_value\n        # my_storageobj.mona\n        my_storageobj.mona = my_storagedict\n        self.assertTrue(last_key in my_storageobj.mona)\n\n        last_items = list(my_storageobj.mona.items())\n        self.assertEqual(len(last_items), 1)\n        self.assertEqual(my_storagedict[last_key], last_value)\n\n        config.session.execute(""DROP TABLE IF EXISTS my_app.MyStorageObjC"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.MyStorageObjC_mona"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.MyStorageObjC_mona_0"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.MyStorageObjC_mona_1"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.second_name"")\n\n    def test_make_persistent_with_persistent_obj(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.obj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dict"")\n        o2 = myobj2(""obj"")\n        o2.attr1 = 1\n        o2.attr2 = ""2""\n\n        d = mydict()\n        d[0] = o2\n        try:\n            d.make_persistent(""dict"")\n        except Exception as ex:\n            self.fail(""Raised exception unexpectedly.\\n"" + str(ex))\n\n    def test_int_tuples(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dictwithtuples"")\n        d = DictWithTuples(""my_app.dictwithtuples"")\n\n        what_should_be = dict()\n        for i in range(0, 10):\n            what_should_be[i] = (i, i + 10)\n            d[i] = (i, i + 10)\n\n        time.sleep(1)\n        for i in range(0, 10):\n            self.assertEqual(d[i], (i, i + 10))\n\n        self.assertEqual(len(list(d.keys())), 10)\n\n        res = dict()\n        count = 0\n        for key, item in d.items():\n            res[key] = item\n            count += 1\n\n        self.assertEqual(count, len(what_should_be))\n        self.assertEqual(what_should_be, res)\n\n    def test_values_tuples(self):\n        # @TypeSpec dict<<key:int>, val0:int, val1:tuple<long,int>, val2:str, val3:tuple<str,float>>\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dictwithtuples3"")\n        d = DictWithTuples3(""my_app.dictwithtuples3"")\n\n        what_should_be = set()\n        for i in range(0, 20):\n            what_should_be.add((i, (5500000000000000, i + 10), ""hola"", (""adios"", (i + 20.5))))\n            d[i] = [i, (5500000000000000, i + 10), ""hola"", (""adios"", (i + 20.5))]\n\n        time.sleep(1)\n        res = set()\n        count = 0\n        for item in d.values():\n            res.add(tuple(item))\n            count += 1\n\n        self.assertEqual(count, len(what_should_be))\n        self.assertEqual(what_should_be, res)\n        self.assertEqual(what_should_be, res)\n\n    def test_tuples_in_key(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dictwithtuples2"")\n        d = DictWithTuples2(""my_app.dictwithtuples2"")\n\n        for i in range(0, 10):\n            d[(i, i), i + 1] = str(i)\n\n        time.sleep(1)\n        for i in range(0, 10):\n            self.assertEqual(d[(i, i), i + 1], str(i))\n\n        self.assertEqual(len(list(d.keys())), 10)\n\n    def test_keys_tuples(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dictwithtuples2"")\n        d = DictWithTuples2(""my_app.dictwithtuples2"")\n\n        what_should_be = set()\n        for i in range(0, 10):\n            what_should_be.add(((i, i), i + 1))\n            d[(i, i), i + 1] = str(i)\n\n        time.sleep(1)\n\n        res = set()\n        count = 0\n        for key in d.keys():\n            res.add(tuple(key))\n            count += 1\n\n        self.assertEqual(count, len(what_should_be))\n        self.assertEqual(what_should_be, res)\n\n    def test_multiple_tuples(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dictmultipletuples"")\n        d = DictWithTuples3(""my_app.dictmultipletuples"")\n\n        what_should_be = dict()\n        for i in range(0, 10):\n            what_should_be[i] = [i, (5500000000000000, i + 10), ""hola"", (""adios"", (i + 20.5))]\n            d[i] = [i, (5500000000000000, i + 10), ""hola"", (""adios"", (i + 20.5))]\n\n        time.sleep(2)\n        for i in range(0, 10):\n            self.assertEqual(list(d[i]), [i, (5500000000000000, i + 10), ""hola"", (""adios"", (i + 20.5))])\n        self.assertEqual(len(list(d.keys())), 10)\n\n        res = dict()\n        count = 0\n        for key, item in d.items():\n            res[key] = list(item)\n            count += 1\n\n        self.assertEqual(count, len(what_should_be))\n        self.assertEqual(what_should_be, res)\n\n    def test_int_tuples_null_values(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dictwithtuples"")\n        d = DictWithTuples(""my_app.dictwithtuples"")\n\n        for i in range(0, 10):\n            if i % 2 == 0:\n                d[i] = (None, i + 10)\n            else:\n                d[i] = (i, i + 10)\n\n        d = DictWithTuples(""my_app.dictwithtuples"")\n        for i in range(0, 10):\n            if i % 2 == 0:\n                self.assertEqual(d[i], (None, i + 10))\n            else:\n                self.assertEqual(d[i], (i, i + 10))\n\n    def test_multi_tuples(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.multituples"")\n        d = MultiTuples(""my_app.multituples"")\n        what_should_be = dict()\n\n        for i in range(0, 10):\n            d[(i, i, i, i)] = [(i, i, i, i), (i, i, i, i), (i, i, i, i), (i, i, i, i), (i, i, i, i), (i, i, i, i),\n                               (i, i, i, i), (i, i, i, i)]\n            what_should_be[(i, i, i, i)] = [(i, i, i, i), (i, i, i, i), (i, i, i, i), (i, i, i, i), (i, i, i, i),\n                                            (i, i, i, i),\n                                            (i, i, i, i), (i, i, i, i)]\n        for i in range(0, 10):\n            self.assertEqual(list(d[(i, i, i, i)]),\n                             [(float(i), float(i), float(i), i), (float(i), float(i), float(i), i),\n                              (float(i), float(i), float(i), i), (float(i), float(i), float(i), i),\n                              (float(i), float(i), float(i), i), (float(i), float(i), float(i), i),\n                              (float(i), float(i), float(i), i), (float(i), float(i), float(i), i)])\n\n    def test_multiple_tuples_NULL(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dictmultipletuples"")\n        d = DictWithTuples3(""my_app.dictmultipletuples"")\n\n        what_should_be = dict()\n        for i in range(0, 10):\n            if i % 2 == 0:\n                what_should_be[i] = [i, (5500000000000000, i + 10), ""hola"", (""adios"", (i + 20.5))]\n                d[i] = [i, (5500000000000000, i + 10), ""hola"", (""adios"", (i + 20.5))]\n            else:\n                what_should_be[i] = [i, (5500000000000000, None), ""hola"", (None, (i + 20.5))]\n                d[i] = [i, (5500000000000000, None), ""hola"", (None, (i + 20.5))]\n\n        d = DictWithTuples3(""my_app.dictmultipletuples"")\n        for i in range(0, 10):\n            if i % 2 == 0:\n                self.assertEqual(list(d[i]), [i, (5500000000000000, i + 10), ""hola"", (""adios"", (i + 20.5))])\n            else:\n                self.assertEqual(list(d[i]), [i, (5500000000000000, None), ""hola"", (None, (i + 20.5))])\n\n        self.assertEqual(len(list(d.keys())), 10)\n\n        res = dict()\n        count = 0\n        for key, item in d.items():\n            res[key] = list(item)\n            count += 1\n\n        self.assertEqual(count, len(what_should_be))\n        self.assertEqual(what_should_be, res)\n\n    def test_storagedict_objs_same_table(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.my_dict"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        d = TestDictOfStorageObj(""my_app.my_dict"")\n        for i in range(0, 10):\n            o = Test2StorageObj()\n            o.name = ""adri"" + str(i)\n            o.age = i\n            d[i] = o\n\n        n = len(d)\n        for i in range(0, n):\n            self.assertEqual(d[i]._ksp.lower(), ""my_app"")\n            self.assertEqual(d[i]._table.lower(), ""test2storageobj"")\n\n    def gen_random_date(self):\n        return datetime.date(year=randint(2000, 2019), month=randint(1, 12), day=randint(1, 28))\n\n    def gen_random_datetime(self):\n        return datetime.datetime(year=randint(2000, 2019), month=randint(1, 12), day=randint(1, 28),\n                                 hour=randint(0, 23), minute=randint(0, 59), second=randint(0, 59))\n\n    def gen_random_time(self):\n        return datetime.time(hour=randint(0, 23), minute=randint(0, 59), second=randint(0, 59),\n                             microsecond=randint(0, 59))\n\n    def test_multiple_dates(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dictwithdates"")\n        d = DictWithDates(""my_app.dictwithdates"")\n        what_should_be = dict()\n        for i in range(0, 50):\n            keys = self.gen_random_date()\n            cols = self.gen_random_date()\n            what_should_be[keys] = [cols]\n            d[keys] = [cols]\n\n        d = DictWithDates(""my_app.dictwithdates"")\n\n        self.assertEqual(len(list(d.keys())), len(what_should_be.keys()))\n\n        count = 0\n        for k in what_should_be.keys():\n            count += 1\n            self.assertEqual(what_should_be[k], [d[k]])\n\n        self.assertEqual(count, len(list(d)))\n\n    def test_multiple_times(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dictwithtimes"")\n        d = DictWithTimes(""my_app.dictwithtimes"")\n        what_should_be = dict()\n        for i in range(0, 50):\n            keys = self.gen_random_time()\n            cols = self.gen_random_time()\n            what_should_be[keys] = [cols]\n            d[keys] = [cols]\n\n        d = DictWithTimes(""my_app.dictwithtimes"")\n\n        self.assertEqual(len(list(d.keys())), len(what_should_be.keys()))\n\n        count = 0\n        for k in what_should_be.keys():\n            count += 1\n            self.assertEqual(what_should_be[k], [d[k]])\n\n        self.assertEqual(count, len(list(d)))\n\n    def test_datetimes(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dictwithdatetimes"")\n        d = DictWithDateTimes(""my_app.dictwithdatetimes"")\n        what_should_be = dict()\n        for i in range(0, 50):\n            keys = self.gen_random_datetime()\n            cols = self.gen_random_datetime()\n            what_should_be[keys] = [cols]\n            d[keys] = [cols]\n\n        d = DictWithDateTimes(""my_app.dictwithdatetimes"")\n        self.assertEqual(len(list(d.keys())), len(what_should_be.keys()))\n        count = 0\n        for k in what_should_be.keys():\n            count += 1\n            self.assertEqual(what_should_be[k], [d[k]])\n\n        self.assertEqual(count, len(list(d)))\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/storagenumpy_tests.py,53,"b'import gc\nimport unittest\n\nfrom hecuba import config, StorageNumpy\nimport uuid\nimport numpy as np\n\nfrom storageAPI.storage.api import getByID\n\n\nclass StorageNumpyTest(unittest.TestCase):\n    table = \'numpy_test\'\n    ksp = \'my_app\'\n\n    def test_init_empty(self):\n        tablename = None\n\n        base_array = np.arange(4096).reshape((64, 64))\n        storage_id = None\n\n        basic_init = StorageNumpy(base_array)\n        self.assertTrue(np.array_equal(basic_init, base_array))\n\n        complete_init = StorageNumpy(base_array, storage_id, tablename)\n        self.assertTrue(np.array_equal(complete_init, base_array))\n\n    def test_types_in_memory(self):\n        base_array = np.arange(256)\n\n        for typecode in np.typecodes[\'Integer\']:\n            typed_array = StorageNumpy(base_array.astype(typecode))\n            self.assertTrue(np.array_equal(typed_array, base_array.astype(typecode)))\n\n        for typecode in np.typecodes[\'UnsignedInteger\']:\n            typed_array = StorageNumpy(base_array.astype(typecode))\n            self.assertTrue(np.array_equal(typed_array, base_array.astype(typecode)))\n\n    def test_reconstruct(self):\n        base_array = np.arange(256)\n        tablename = self.ksp + \'.\' + self.table\n\n        typecode = \'mytype\'\n        niter = 2\n\n        for _ in range(niter):\n            # Build array and store\n            typed_array = StorageNumpy(base_array, tablename)\n            self.assertTrue(np.array_equal(typed_array, base_array))\n\n            # Load array\n            typed_array = StorageNumpy(None, tablename)\n            self.assertTrue(np.allclose(typed_array, base_array))\n            typed_array.delete_persistent()\n\n    def test_types_persistence(self):\n        base_array = np.arange(256)\n        tablename = self.ksp + \'.\' + self.table\n\n        for typecode in np.typecodes[\'Integer\']:\n            if typecode == \'p\':\n                # TODO For now skip arrays made of pointers\n                pass\n            typed_array = StorageNumpy(base_array.astype(typecode), tablename)\n            self.assertTrue(np.array_equal(typed_array, base_array.astype(typecode)))\n\n            typed_array = StorageNumpy(None, tablename)\n            self.assertTrue(np.allclose(typed_array, base_array.astype(typecode)))\n            typed_array.delete_persistent()\n\n        for typecode in np.typecodes[\'UnsignedInteger\']:\n            if typecode == \'P\':\n                # TODO For now skip arrays made of pointers\n                pass\n            typed_array = StorageNumpy(base_array.astype(typecode), tablename)\n            self.assertTrue(np.allclose(typed_array, base_array.astype(typecode)))\n\n            typed_array = StorageNumpy(None, tablename)\n            self.assertTrue(np.allclose(typed_array, base_array.astype(typecode)))\n            typed_array.delete_persistent()\n\n    def test_read_all(self):\n        from cassandra import InvalidRequest\n        try:\n            config.session.execute(""TRUNCATE TABLE testing_arrays.first_test;"")\n        except InvalidRequest:\n            pass\n        try:\n            config.session.execute(""TRUNCATE TABLE testing_arrays.first_test_numpies;"")\n        except InvalidRequest:\n            pass\n\n        nelem = 2 ** 21\n        elem_dim = 2 ** 7\n\n        base_array = np.arange(nelem).reshape((elem_dim, elem_dim, elem_dim))\n        casted = StorageNumpy(input_array=base_array, name=""testing_arrays.first_test"")\n\n        test_numpy = np.arange(nelem).reshape((elem_dim, elem_dim, elem_dim))\n        casted = StorageNumpy(name=""testing_arrays.first_test"")\n        chunk = casted[slice(None, None, None)]\n        self.assertTrue(np.allclose(chunk.view(np.ndarray), test_numpy))\n        casted.delete_persistent()\n\n    def test_numpy_reserved_5d_read_all(self):\n        from cassandra import InvalidRequest\n        try:\n            config.session.execute(""TRUNCATE TABLE testing_arrays.first_test;"")\n        except InvalidRequest:\n            pass\n        try:\n            config.session.execute(""TRUNCATE TABLE testing_arrays.first_test_numpies;"")\n        except InvalidRequest:\n            pass\n\n        nelem = 100000\n        elem_dim = 10\n\n        base_array = np.arange(nelem).reshape((elem_dim, elem_dim, elem_dim, elem_dim, elem_dim))\n        casted = StorageNumpy(input_array=base_array, name=""testing_arrays.first_test"")\n\n        test_numpy = np.arange(nelem).reshape((elem_dim, elem_dim, elem_dim, elem_dim, elem_dim))\n        casted = StorageNumpy(name=""testing_arrays.first_test"")\n        chunk = casted[slice(None, None, None)]\n        self.assertTrue(np.allclose(chunk.view(np.ndarray), test_numpy))\n        casted.delete_persistent()\n\n    def test_explicit_construct(self):\n        # From an explicit constructor - e.g. InfoArray():\n        #    obj is None\n        #    (we\'re in the middle of the InfoArray.__new__\n        #    constructor, and self.info will be set when we return to\n        #    InfoArray.__new__)\n\n        basic_init = StorageNumpy()\n\n    def test_view_cast(self):\n        # From view casting - e.g arr.view(InfoArray):\n        #    obj is arr\n        #    (type(obj) can be InfoArray)\n\n        base_array = np.arange(4096).reshape((64, 64))\n        view_cast = base_array.view(StorageNumpy)\n\n    def test_new_from_template(self):\n        # From new-from-template - e.g infoarr[:3]\n        #    type(obj) is InfoArray\n        base_array = np.arange(4096).reshape((64, 64))\n        basic_init = StorageNumpy(base_array)\n        new_from_template = basic_init[:32]\n\n    def test_new2_from_template(self):\n        # From new-from-template - e.g infoarr[:3]\n        #    type(obj) is InfoArray\n        base_array = np.arange(4096).reshape((64, 64))\n        basic_init = StorageNumpy(base_array)\n        new_from_template = basic_init[32:]\n\n    def test_get_subarray(self):\n        base = np.arange(8 * 8 * 4).reshape((8, 8, 4))\n        hecu_p = StorageNumpy(input_array=base, name=\'my_array\')\n        hecu_r2 = StorageNumpy(name=""my_array"")\n        res = hecu_r2[:3, :2]\n        sum = res.sum()\n        res = hecu_r2[:3, :2]\n        avg = res.mean()\n        self.assertGreater(sum, 0)\n        self.assertGreater(avg, 0)\n\n    def test_slicing_3d(self):\n        base = np.arange(8 * 8 * 4).reshape((8, 8, 4))\n        hecu = StorageNumpy(input_array=base, name=\'my_array\')\n        res_hecu = hecu[6:7, 4:]\n        res = base[6:7, 4:]\n        self.assertTrue(np.array_equal(res, res_hecu))\n\n        hecu = StorageNumpy(name=""my_array"")\n        res_hecu = hecu[6:7, 4:]\n        self.assertTrue(np.array_equal(res, res_hecu))\n\n        hecu.delete_persistent()\n\n    def test_slicing_ndims(self):\n        import random\n        ndims = 10\n        max_elements = 2048\n        for dims in range(1, ndims):\n            elem_per_dim = int(max_elements ** (1 / dims))\n            select = (slice(random.randint(0, elem_per_dim)),) * dims\n            base = np.arange(elem_per_dim ** dims).reshape((elem_per_dim,) * dims)\n\n            hecu = StorageNumpy(input_array=base, name=\'my_array\')\n            res_hecu = hecu[select]\n            res = base[select]\n            self.assertTrue(np.array_equal(res, res_hecu))\n\n            hecu = StorageNumpy(name=""my_array"")\n            res_hecu = hecu[select]\n            res = base[select]\n            self.assertTrue(np.array_equal(res, res_hecu))\n            hecu.delete_persistent()\n            del res_hecu\n            del hecu\n\n    def test_slice_ops(self):\n        obj = np.arange(8 * 8 * 8).reshape((8, 8, 8))\n        hecu = StorageNumpy(input_array=obj, name=\'some_name\')\n        hecu_sub = hecu[:2, 3:, 4:]\n        sum = hecu_sub.sum()\n        self.assertGreater(sum, 0)\n        description = repr(hecu_sub)\n        self.assertIsInstance(description, str)\n        hecu.delete_persistent()\n\n    def test_slice_ops2(self):\n        obj = np.arange(8 * 8 * 8).reshape((8, 8, 8))\n        hecu = StorageNumpy(input_array=obj, name=\'some_name\')\n        hecu_sub = hecu[:2, 3:, 4:]\n        hecu_sub2 = hecu_sub[:1, 2:, 3:]\n        sum = hecu_sub2.sum()\n        self.assertGreater(sum, 0)\n        description = repr(hecu_sub2)\n        self.assertIsInstance(description, str)\n        hecu.delete_persistent()\n\n    def test_iter_numpy(self):\n        obj = np.arange(8 * 8 * 8).reshape((8, 8, 8))\n        hecu = StorageNumpy(input_array=obj, name=\'some_name\')\n        acc = 0\n        for i in hecu:\n            acc = acc + 1\n\n        hecu_sub = hecu[:2, 3:, 4:]\n\n        acc2 = 0\n        for i in hecu_sub:\n            acc2 = acc2 + 1\n\n        self.assertGreater(acc, acc2)\n        hecu.delete_persistent()\n\n    def test_assign_slice(self):\n        base = np.arange(8 * 8 * 4).reshape((8, 8, 4))\n        hecu_p = StorageNumpy(input_array=base, name=\'my_array\')\n        sub_hecu = hecu_p[:2, 3:]\n        sub_hecu[0][2:] = 0\n        hecu_p_load = StorageNumpy(name=""my_array"")\n        rep = repr(hecu_p_load)\n        self.assertIsInstance(rep, str)\n        load_sub_arr = hecu_p_load[:]\n        self.assertTrue(np.array_equal(load_sub_arr, np.arange(8 * 8 * 4).reshape((8, 8, 4))))\n        hecu_p_load.delete_persistent()\n\n    def test_assign_element(self):\n        base = np.arange(8 * 8 * 4).reshape((8, 8, 4))\n        hecu_p = StorageNumpy(input_array=base, name=\'my_array2\')\n        sub_hecu = hecu_p[:2, 3:]\n        sub_hecu[0][1][0] = 0\n        hecu_p_load = StorageNumpy(name=""my_array2"")\n        rep = repr(hecu_p_load)\n        self.assertIsInstance(rep, str)\n        load_sub_arr = hecu_p_load[:]\n        self.assertTrue(np.array_equal(load_sub_arr, np.arange(8 * 8 * 4).reshape((8, 8, 4))))\n        hecu_p_load.delete_persistent()\n\n    def test_load_2_dif_clusters_same_instance(self):\n        base = np.arange(50 * 50).reshape((50, 50))\n        hecu_p = StorageNumpy(input_array=base, name=\'my_array3\')\n        hecu_p_load = StorageNumpy(name=""my_array3"")\n        hecu_p_load[0:1, 0:1]\n        self.assertTrue(np.array_equal(hecu_p_load[40:50, 40:50], base[40:50, 40:50]))\n\n    def test_split_by_rows(self):\n        """"""\n        Tests iterating through the rows of the Hecuba array\n        """"""\n        config.session.execute(""DROP TABLE IF EXISTS hecuba_dislib.test_array"")\n        config.session.execute(""TRUNCATE TABLE hecuba.istorage"")\n\n        bn, bm = (1, 10)\n        x = np.arange(100).reshape(10, -1)\n        blocks = []\n        for i in range(0, x.shape[0], bn):\n            row = [x[i: i + bn, j: j + bm] for j in range(0, x.shape[1], bm)]\n            blocks.append(row)\n\n        data = StorageNumpy(input_array=x, name=""hecuba_dislib.test_array"")\n\n        for i, chunk in enumerate(data.np_split(block_size=(bn, bm))):\n            storage_id = chunk.storage_id\n            del chunk\n            chunk = getByID(storage_id)\n            self.assertTrue(np.array_equal(list(chunk), blocks[i]))\n\n        self.assertEqual(i + 1, len(blocks))\n\n    def test_split_by_columns(self):\n        """"""\n        Tests iterating through the columns of the Hecuba array\n        """"""\n        config.session.execute(""DROP TABLE IF EXISTS hecuba_dislib.test_array"")\n        config.session.execute(""TRUNCATE TABLE hecuba.istorage"")\n\n        bn, bm = (10, 1)\n        x = np.arange(100).reshape(10, -1)\n        blocks = []\n        for i in range(0, x.shape[0], bn):\n            row = [x[i: i + bn, j: j + bm] for j in range(0, x.shape[1], bm)]\n            blocks.append(row)\n\n        data = StorageNumpy(input_array=x, name=""hecuba_dislib.test_array"")\n\n        for i, chunk in enumerate(data.np_split(block_size=(bn, bm))):\n            storage_id = chunk.storage_id\n            del chunk\n            chunk = getByID(storage_id)\n            self.assertTrue(np.array_equal(list(chunk), blocks[i]))\n\n        self.assertEqual(i + 1, len(blocks))\n\n    def test_split_rows_and_columns(self):\n        config.session.execute(""DROP TABLE IF EXISTS hecuba_dislib.test_array"")\n        config.session.execute(""TRUNCATE TABLE hecuba.istorage"")\n\n        bn, bm = (2, 1)\n        x = np.arange(100).reshape(10, -1)\n        blocks = []\n        for i in range(0, x.shape[0], bn):\n            row = [x[i: i + bn, j: j + bm] for j in range(0, x.shape[1], bm)]\n            blocks.append(row)\n\n        data = StorageNumpy(input_array=x, name=""hecuba_dislib.test_array"")\n\n        for i, chunk in enumerate(data.np_split(block_size=(bn, bm))):\n            storage_id = chunk.storage_id\n            del chunk\n            chunk = getByID(storage_id)\n            self.assertTrue(np.array_equal(list(chunk), blocks[i]))\n\n        self.assertEqual(i + 1, len(blocks))\n\n    def test_split_already_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS hecuba_dislib.test_array"")\n        config.session.execute(""TRUNCATE TABLE hecuba.istorage"")\n\n        bn, bm = (2, 1)\n        x = np.arange(100).reshape(10, -1)\n        blocks = []\n        for i in range(0, x.shape[0], bn):\n            row = [x[i: i + bn, j: j + bm] for j in range(0, x.shape[1], bm)]\n            blocks.append(row)\n\n        data = StorageNumpy(input_array=x, name=""hecuba_dislib.test_array"")\n\n        for i, chunk in enumerate(data.np_split(block_size=(bn, bm))):\n            storage_id = chunk.storage_id\n            del chunk\n            chunk = getByID(storage_id)\n            self.assertTrue(np.array_equal(list(chunk), blocks[i]))\n\n        del data\n        gc.collect()\n\n        data = StorageNumpy(name=""hecuba_dislib.test_array"")\n        self.assertTrue(np.array_equal(list(data), x))\n\n        for i, chunk in enumerate(data.np_split(block_size=(bn, bm))):\n            storage_id = chunk.storage_id\n            del chunk\n            chunk = getByID(storage_id)\n            self.assertTrue(np.array_equal(list(chunk), blocks[i]))\n\n        self.assertEqual(i + 1, len(blocks))\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/storageobj_split_tests.py,0,"b'import unittest\nimport gc\n\nfrom hecuba import config\nfrom hecuba.storageobj import StorageObj\n\n\nclass TestSimple(StorageObj):\n    \'\'\'\n    @ClassField words dict<<position:int>,value:str>\n    \'\'\'\n    pass\n\n\nN_CASS_NODES = 2\n\n\nclass StorageObjSplitTest(unittest.TestCase):\n    def test_simple_keys_split_test(self):\n        tablename = ""tab30""\n        config.session.execute(""DROP TABLE IF EXISTS my_app.{}"".format(tablename))\n        config.session.execute(""DROP TABLE IF EXISTS my_app.{}_words"".format(tablename))\n        sto = TestSimple(tablename)\n        pd = sto.words\n        num_inserts = 1000\n        what_should_be = set()\n        for i in range(num_inserts):\n            pd[i] = \'ciao\' + str(i)\n            what_should_be.add(i)\n        del pd, sto\n\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.{}_words\'.format(tablename))[0]\n        self.assertEqual(count, num_inserts)\n\n        sto = TestSimple(tablename)\n        pd = sto.words\n\n        count = 0\n        res = set()\n        splits = 0\n        for partition in pd.split():\n            splits += 1\n            for val in partition.keys():\n                res.add(val)\n                count += 1\n        pd.delete_persistent()\n        del pd\n        self.assertTrue(splits >= config.splits_per_node * N_CASS_NODES)\n        self.assertEqual(count, num_inserts)\n        self.assertEqual(what_should_be, res)\n\n    def test_build_remotely_keys_split_test(self):\n        tablename = \'tab30\'\n        config.session.execute(\'DROP TABLE IF EXISTS my_app.{}\'.format(tablename))\n        config.session.execute(\'DROP TABLE IF EXISTS my_app.{}_words\'.format(tablename))\n        sto = TestSimple(tablename)\n        pd = sto.words\n        num_inserts = 1000\n\n        what_should_be = set()\n        for i in range(num_inserts):\n            pd[i] = \'ciao\' + str(i)\n            what_should_be.add(i)\n        del pd, sto\n\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.{}_words\'.format(tablename))[0]\n        self.assertEqual(count, num_inserts)\n\n        sto = TestSimple(tablename)\n        pd = sto.words\n\n        count = 0\n        res = set()\n        splits = 0\n        for partition in pd.split():\n            id = partition.storage_id\n            from storage.api import getByID\n            rebuild = getByID(id)\n            splits += 1\n            for val in rebuild.keys():\n                res.add(val)\n                count += 1\n        pd.delete_persistent()\n        del pd\n        self.assertTrue(splits >= config.splits_per_node * N_CASS_NODES)\n        self.assertEqual(count, num_inserts)\n        self.assertEqual(what_should_be, res)\n\n    def test_simple_keys_split_fromSO_test(self):\n        tablename = ""tab31""\n        config.session.execute(\'DROP TABLE IF EXISTS my_app.{}\'.format(tablename))\n        config.session.execute(\'DROP TABLE IF EXISTS my_app.{}_words\'.format(tablename))\n        sto = TestSimple(tablename)\n        pd = sto.words\n        num_inserts = 1000\n        what_should_be = set()\n        for i in range(num_inserts):\n            pd[i] = \'ciao\' + str(i)\n            what_should_be.add(i)\n        del pd, sto\n\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.{}_words\'.format(tablename))[0]\n        self.assertEqual(count, num_inserts)\n\n        sto = TestSimple(tablename)\n        count = 0\n        res = set()\n        splits = 0\n        for partition in sto.split():\n            splits += 1\n            for val in partition.words.keys():\n                res.add(val)\n                count += 1\n        sto.delete_persistent()\n        del sto\n        self.assertTrue(splits >= config.splits_per_node * N_CASS_NODES)\n        self.assertEqual(count, num_inserts)\n        self.assertEqual(what_should_be, res)\n\n    def test_build_remotely_keys_split_fromSO_test(self):\n        tablename = ""tab32""\n        config.session.execute(\'DROP TABLE IF EXISTS my_app.{}\'.format(tablename))\n        config.session.execute(\'DROP TABLE IF EXISTS my_app.{}_words\'.format(tablename))\n        sto = TestSimple(tablename)\n        pd = sto.words\n        num_inserts = 1000\n        what_should_be = set()\n        for i in range(num_inserts):\n            pd[i] = \'ciao\' + str(i)\n            what_should_be.add(i)\n        del pd, sto\n\n        gc.collect()\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.{}_words\'.format(tablename))[0]\n        self.assertEqual(count, num_inserts)\n\n        sto = TestSimple(tablename)\n        count = 0\n        res = set()\n        splits = 0\n        for partition in sto.split():\n            splits += 1\n            id = partition.storage_id\n            from storage.api import getByID\n            rebuild = getByID(id)\n            for val in rebuild.words.keys():\n                res.add(val)\n                count += 1\n        sto.delete_persistent()\n        del sto\n        self.assertTrue(splits >= config.splits_per_node * N_CASS_NODES)\n        self.assertEqual(count, num_inserts)\n        self.assertEqual(what_should_be, res)\n\n    def test_split_with_different_storage_ids(self):\n        tablename = ""tab33""\n        config.session.execute(\'DROP TABLE IF EXISTS my_app.{}\'.format(tablename))\n        config.session.execute(\'DROP TABLE IF EXISTS my_app.{}_words\'.format(tablename))\n        sto = TestSimple(tablename)\n        pd = sto.words\n\n        ids = len(set(map(lambda x: x.storage_id, pd.split())))\n        self.assertTrue(ids >= config.splits_per_node * N_CASS_NODES)\n        sto.delete_persistent()\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/storageobj_tests.py,25,"b'import time\nimport unittest\nimport uuid\nimport datetime\n\nimport cassandra\nimport numpy as np\nfrom hecuba import config\nfrom hecuba.tools import discrete_token_ranges\nfrom hecuba.storageobj import StorageObj\nfrom storage.api import getByID\nfrom hecuba.IStorage import build_remotely\n\nfrom ..app.words import Words\n\n\nclass Test2StorageObj(StorageObj):\n    \'\'\'\n       @ClassField name str\n       @ClassField age int\n    \'\'\'\n    pass\n\n\nclass Result(StorageObj):\n    \'\'\'\n    @ClassField instances dict<<word:str>, numinstances:int>\n    \'\'\'\n    pass\n\n\nclass TestStorageObj(StorageObj):\n    \'\'\'\n       @ClassField test dict<<position:int>, text:str>\n    \'\'\'\n    pass\n\n\nclass TestStorageIndexedArgsObj(StorageObj):\n    \'\'\'\n       @ClassField test dict<<position:int>, x:float, y:float, z:float>\n       @Index_on test x,y,z\n    \'\'\'\n    pass\n\n\nclass Test2StorageObjFloat(StorageObj):\n    \'\'\'\n       @ClassField name str\n       @ClassField age float\n    \'\'\'\n    pass\n\n\nclass Test3StorageObj(StorageObj):\n    \'\'\'\n       @ClassField myso tests.withcassandra.storageobj_tests.Test2StorageObj\n       @ClassField myso2 tests.withcassandra.storageobj_tests.TestStorageObj\n       @ClassField myint int\n       @ClassField mystr str\n    \'\'\'\n    pass\n\n\nclass Test4StorageObj(StorageObj):\n    \'\'\'\n       @ClassField myotherso tests.withcassandra.storageobj_tests.Test2StorageObj\n    \'\'\'\n    pass\n\n\nclass Test4bStorageObj(StorageObj):\n    \'\'\'\n       @ClassField myotherso tests.withcassandra.test2storageobj.Test2StorageObj\n    \'\'\'\n    pass\n\n\nclass Test5StorageObj(StorageObj):\n    \'\'\'\n       @ClassField test2 dict<<position:int>, myso:tests.withcassandra.storageobj_tests.Test2StorageObj>\n    \'\'\'\n    pass\n\n\nclass Test6StorageObj(StorageObj):\n    \'\'\'\n       @ClassField test3 dict<<key0:int>, val0:str, val1:str>\n    \'\'\'\n    pass\n\n\nclass Test7StorageObj(StorageObj):\n    \'\'\'\n       @ClassField test2 dict<<key0:int>, val0:tests.withcassandra.storageobj_tests.Test2StorageObj>\n    \'\'\'\n    pass\n\n\nclass TestStorageObjNumpy(StorageObj):\n    \'\'\'\n       @ClassField mynumpy numpy.ndarray\n    \'\'\'\n    pass\n\n\nclass TestStorageObjNumpyDict(StorageObj):\n    \'\'\'\n       @ClassField mynumpydict dict<<key:int>, val:numpy.ndarray>\n    \'\'\'\n    pass\n\n\nclass TestAttributes(StorageObj):\n    \'\'\'\n       @ClassField key int\n    \'\'\'\n\n    value = None\n\n    def do_nothing_at_all(self):\n        pass\n\n    def setvalue(self, v):\n        self.value = v\n\n    def getvalue(self):\n        return self.value\n\n\nclass mixObj(StorageObj):\n    \'\'\'\n    @ClassField floatfield float\n    @ClassField intField int\n    @ClassField strField str\n    @ClassField intlistField list<int>\n    @ClassField floatlistField list<float>\n    @ClassField strlistField list<str>\n    @ClassField dictField dict<<key0:int>, val0:str>\n    @ClassField inttupleField tuple<int,int>\n    \'\'\'\n\n\nclass TestDate(StorageObj):\n    \'\'\'\n    @ClassField attr date\n    \'\'\'\n\n\nclass TestTime(StorageObj):\n    \'\'\'\n    @ClassField attr time\n    \'\'\'\n\n\nclass TestDateTime(StorageObj):\n    \'\'\'\n    @ClassField attr datetime\n    \'\'\'\n\n\nclass StorageObjTest(unittest.TestCase):\n    def test_build_remotely(self):\n        config.session.execute(""DROP TABLE IF EXISTS "" + config.execution_name + "".TestStorageObj"")\n        obj = TestStorageObj(config.execution_name + "".tt1"")\n        r = {""built_remotely"": False, ""storage_id"": uuid.uuid3(uuid.NAMESPACE_DNS, config.execution_name + \'.tt1\'),\n             ""ksp"": config.execution_name,\n             ""class_name"": str(TestStorageObj.__module__) + ""."" + TestStorageObj.__name__, ""name"": \'tt1\',\n             ""columns"": [(\'val1\', \'str\')], ""entry_point"": \'localhost\', ""primary_keys"": [(\'pk1\', \'int\')],\n             ""istorage_props"": {},\n             ""tokens"": discrete_token_ranges([token.value for token in config.cluster.metadata.token_map.ring])}\n\n        nopars = build_remotely(r)\n        self.assertEqual(\'TestStorageObj\'.lower(), nopars._table)\n        self.assertEqual(config.execution_name, nopars._ksp)\n        self.assertEqual(uuid.uuid3(uuid.NAMESPACE_DNS, config.execution_name + \'.tt1\'), nopars.storage_id)\n        name, tkns = \\\n            config.session.execute(""SELECT name, tokens FROM hecuba.istorage WHERE storage_id = %s"",\n                                   [nopars.storage_id])[\n                0]\n\n        self.assertEqual(name, config.execution_name + \'.tt1\')\n        self.assertEqual(tkns, r[\'tokens\'])\n\n    def test_init_create_pdict(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestStorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestStorageObj_instances"")\n        config.session.execute(""DROP TABLE IF EXISTS "" + config.execution_name + \'.TestStorageObj\')\n\n        r = {""built_remotely"": False, ""storage_id"": uuid.uuid3(uuid.NAMESPACE_DNS, config.execution_name + \'.tt1\'),\n             ""ksp"": config.execution_name,\n             ""class_name"": str(TestStorageObj.__module__) + ""."" + TestStorageObj.__name__, ""name"": \'tt1\',\n             ""columns"": [(\'val1\', \'str\')], ""entry_point"": \'localhost\', ""primary_keys"": [(\'pk1\', \'int\')],\n             ""istorage_props"": {},\n             ""tokens"": discrete_token_ranges([token.value for token in config.cluster.metadata.token_map.ring])}\n\n        nopars = build_remotely(r)\n        self.assertEqual(nopars._built_remotely, False)\n        self.assertEqual(\'TestStorageObj\'.lower(), nopars._table)\n        self.assertEqual(config.execution_name, nopars._ksp)\n        self.assertEqual(uuid.uuid3(uuid.NAMESPACE_DNS, config.execution_name + \'.tt1\'), nopars.storage_id)\n        name, tkns = \\\n            config.session.execute(""SELECT name,tokens FROM hecuba.istorage WHERE storage_id = %s"",\n                                   [nopars.storage_id])[0]\n        self.assertEqual(name, config.execution_name + \'.\' + r[\'name\'])\n        self.assertEqual(tkns, r[\'tokens\'])\n\n        tkns = discrete_token_ranges(\n            [8508619251581300691, 8514581128764531689, 8577968535836399533, 8596162846302799189,\n             8603491526474728284, 8628291680139169981, 8687301163739303017, 9111581078517061776])\n        config.session.execute(""DROP TABLE IF EXISTS "" + config.execution_name + \'.tt2\')\n        nopars = Result(name=\'tt2\',\n                        tokens=tkns)\n        self.assertEqual(\'Result\'.lower(), nopars._table)\n        self.assertEqual(config.execution_name, nopars._ksp)\n        self.assertEqual(uuid.uuid3(uuid.NAMESPACE_DNS, config.execution_name + \'.tt2\'), nopars.storage_id)\n        self.assertEqual(True, nopars._is_persistent)\n        self.assertTrue(hasattr(nopars, \'instances\'))\n        name, read_tkns = config.session.execute(""SELECT name,tokens FROM hecuba.istorage WHERE storage_id = %s"",\n                                                 [nopars.storage_id])[0]\n\n        self.assertEqual(name, config.execution_name + \'.tt2\')\n        self.assertEqual(tkns, read_tkns)\n\n    def test_mixed_class(self):\n        config.session.execute(""DROP TABLE IF EXISTS hecuba_test.mixObj"")\n        myObj = mixObj()\n\n        myObj.make_persistent(""hecuba_test.bla"")\n\n        myObj.floatfield = 5.0\n        myObj.intField = 5\n        myObj.strField = ""6""\n        myObj.intlistField = [7, 8, 9]\n        myObj.floatlistField = [10.0, 11.0, 12.0]\n        myObj.strlistField = [""13.0"", ""14.0"", ""15.0""]\n        myObj.inttupleField = (1, 2)\n\n        floatfield, intField, strField, intlistField, floatlistField, strlistField, inttupleField = \\\n            config.session.execute(""SELECT floatField, ""\n                                   ""intField, ""\n                                   ""strField, ""\n                                   ""intlistField, ""\n                                   ""floatlistField, ""\n                                   ""strlistField, ""\n                                   ""inttupleField ""\n                                   ""FROM hecuba_test.mixObj WHERE storage_id ="" + str(myObj.storage_id))[0]\n\n        self.assertEquals(floatfield, myObj.floatfield)\n        self.assertEquals(intField, myObj.intField)\n        self.assertEquals(strField, myObj.strField)\n        self.assertEquals(intlistField, myObj.intlistField)\n        self.assertEquals(floatlistField, myObj.floatlistField)\n        self.assertEquals(strlistField, myObj.strlistField)\n        self.assertEquals(inttupleField, myObj.inttupleField)\n\n    def test_init_empty(self):\n        config.session.execute(""DROP TABLE IF EXISTS ksp1.TestStorageObj"")\n        nopars = TestStorageObj(\'ksp1.ttta\')\n        self.assertEqual(\'TestStorageObj\'.lower(), nopars._table)\n        self.assertEqual(\'ksp1\', nopars._ksp)\n\n        res = config.session.execute(\n            \'SELECT storage_id, class_name, name, tokens, istorage_props FROM hecuba.istorage WHERE storage_id = %s\',\n            [nopars.storage_id])[0]\n\n        storage_id, storageobj_classname, name, tokens, istorage_props = res\n        self.assertEqual(storage_id, nopars.storage_id)\n        self.assertEqual(storageobj_classname, TestStorageObj.__module__ + ""."" + TestStorageObj.__name__)\n        self.assertEqual(name, \'ksp1.ttta\')\n\n        rebuild = build_remotely(res._asdict())\n        self.assertEqual(rebuild._built_remotely, True)\n        self.assertEqual(\'TestStorageObj\'.lower(), rebuild._table)\n        self.assertEqual(\'ksp1\'.lower(), rebuild._ksp)\n        self.assertEqual(storage_id, rebuild.storage_id)\n\n        self.assertEqual(nopars._is_persistent, rebuild._is_persistent)\n        # self.assertEqual(vars(nopars), vars(rebuild))\n\n    def test_make_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS hecuba_test.nonames"")\n        config.session.execute(""DROP TABLE IF EXISTS hecuba_test.words"")\n        config.session.execute(""DROP TABLE IF EXISTS hecuba_test.words_words"")\n        config.session.execute(""DROP TABLE IF EXISTS hecuba_test.nonames_test3"")\n        nopars = Words()\n        self.assertFalse(nopars._is_persistent)\n        nopars.ciao = 1\n        nopars.ciao2 = ""1""\n        nopars.ciao3 = [1, 2, 3]\n        nopars.ciao4 = (1, 2, 3)\n        for i in range(10):\n            nopars.words[i] = \'ciao\' + str(i)\n\n        count, = config.session.execute(\n            ""SELECT count(*) FROM system_schema.tables WHERE keyspace_name = \'hecuba_test\' and table_name = \'words\'"")[0]\n        self.assertEqual(0, count)\n\n        nopars.make_persistent(""hecuba_test.wordsso"")\n        del nopars\n\n        count, = config.session.execute(\'SELECT count(*) FROM hecuba_test.wordsso_words\')[0]\n        self.assertEqual(10, count)\n\n        nopars2 = Test6StorageObj(""hecuba_test.nonames"")\n        nopars2.test3[0] = [\'1\', \'2\']\n        time.sleep(2)\n        result = config.session.execute(""SELECT val0, val1 FROM hecuba_test.nonames_test3 WHERE key0 = 0"")\n\n        rval0 = None\n        rval1 = None\n        for row in result:\n            rval0 = row.val0\n            rval1 = row.val1\n\n        self.assertEqual(\'1\', rval0)\n        self.assertEqual(\'2\', rval1)\n\n    def test_empty_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Words_words"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Words"")\n        so = Words()\n        so.make_persistent(""my_app.wordsso"")\n        so.ciao = ""an attribute""\n        so.another = 123\n        config.batch_size = 1\n        config.cache_activated = False\n        for i in range(10):\n            so.words[i] = str.join(\',\', map(lambda a: ""ciao"", range(i)))\n\n        del so\n        import gc\n        gc.collect()\n\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.wordsso_words\')[0]\n        self.assertEqual(10, count)\n        so = Words()\n        so.make_persistent(""my_app.wordsso"")\n        so.delete_persistent()\n\n        count, = config.session.execute(\'SELECT count(*) FROM my_app.wordsso_words\')[0]\n        self.assertEqual(0, count)\n\n    def test_simple_stores_after_make_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        so = Test2StorageObj()\n        so.name = \'caio\'\n        so.age = 1000\n        so.make_persistent(""t2"")\n        count, = config.session.execute(""SELECT COUNT(*) FROM my_app.Test2StorageObj"")[0]\n        self.assertEqual(count, 1)\n        self.assertEqual(so.name, \'caio\')\n        self.assertEqual(so.age, 1000)\n\n    def test_simple_attributes(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        so = Test2StorageObj()\n        so.make_persistent(""t2"")\n        so.name = \'caio\'\n        so.age = 1000\n        count, = config.session.execute(""SELECT COUNT(*) FROM my_app.Test2StorageObj"")[0]\n        self.assertEqual(count, 1)\n        self.assertEqual(so.name, \'caio\')\n        self.assertEqual(so.age, 1000)\n\n    def test_modify_simple_attributes(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        so = Test2StorageObj()\n        so.make_persistent(""t2"")\n        so.name = \'caio\'\n        so.age = 1000\n        count, = config.session.execute(""SELECT COUNT(*) FROM my_app.Test2StorageObj"")[0]\n        self.assertEqual(count, 1)\n        self.assertEqual(so.name, \'caio\')\n        self.assertEqual(so.age, 1000)\n        so.name = \'addio\'\n        so.age = 2000\n        self.assertEqual(so.name, \'addio\')\n        self.assertEqual(so.age, 2000)\n\n    def test_delattr_nonpersistent(self):\n        so = Test2StorageObj()\n        so.name = \'caio\'\n        del so.name\n\n        def del_attr():\n            my_val = so.name\n\n        self.assertRaises(AttributeError, del_attr)\n\n    def test_delattr_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        so = Test2StorageObj(""t3"")\n        so.name = \'caio\'\n        del so.name\n\n        def del_attr1():\n            my_val = so.name\n\n        self.assertRaises(AttributeError, del_attr1)\n\n        def del_attr2():\n            my_val = so.random_val\n\n        self.assertRaises(AttributeError, del_attr1)\n\n    def test_delattr_persistent_nested(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test3StorageObj"")\n        so = Test3StorageObj(""t4"")\n        nestedSo = Test2StorageObj()\n        nestedSo.name = \'caio\'\n        so.myint = 123\n        so.myso = nestedSo\n        # Make sure the inner object has been made persistent\n        self.assertTrue(nestedSo._is_persistent)\n        # Delete the attribute\n        del so.myint\n\n        def del_attr1():\n            my_val = so.myint\n\n        # Accessing deleted attr of type StorageOb should raise AttrErr\n        self.assertRaises(AttributeError, del_attr1)\n\n        # We assign again, nestedSo still existed (no one called delete on it)\n        so.myso = nestedSo\n\n        # Delete a nested attribute of the shared StorageObj\n        del so.myso.name\n\n        # Make sure that the nested attribute deleted has been successfully deleted from both objects\n        def del_attr2():\n            my_val = nestedSo.name\n\n        def del_attr3():\n            my_val = so.myso.name\n\n        self.assertRaises(AttributeError, del_attr2)\n        self.assertRaises(AttributeError, del_attr3)\n\n    def test_modify_simple_before_mkp_attributes(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        so = Test2StorageObj()\n        so.name = \'caio\'\n        so.age = 1000\n        so.make_persistent(""t2"")\n        count, = config.session.execute(""SELECT COUNT(*) FROM my_app.Test2StorageObj"")[0]\n        self.assertEqual(count, 1)\n        self.assertEqual(so.name, \'caio\')\n        self.assertEqual(so.age, 1000)\n        so.name = \'addio\'\n        so.age = 2000\n        self.assertEqual(so.name, \'addio\')\n        self.assertEqual(so.age, 2000)\n\n    def test_paranoid_setattr_nonpersistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        so = Test2StorageObj(""myobj"")\n        so.name = \'my_name\'\n        self.assertEquals(so.name, \'my_name\')\n\n        def set_name_test():\n            so.name = 1\n\n        self.assertRaises(cassandra.InvalidRequest, set_name_test)\n        so.age = 1\n        self.assertEquals(so.age, 1)\n\n        def set_age_test():\n            so.age = \'my_name\'\n\n        self.assertRaises(cassandra.InvalidRequest, set_age_test)\n\n    def test_paranoid_setattr_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        so = Test2StorageObj(""t2"")\n        so.name = \'my_name\'\n        result = config.session.execute(""SELECT name FROM my_app.Test2StorageObj"")\n        for row in result:\n            cass_name = row.name\n        self.assertEquals(cass_name, \'my_name\')\n\n        def setNameTest():\n            so.name = 1\n\n        self.assertRaises(cassandra.InvalidRequest, setNameTest)\n        so.age = 1\n        result = config.session.execute(""SELECT age FROM my_app.Test2StorageObj"")\n        for row in result:\n            cass_age = row.age\n        self.assertEquals(cass_age, 1)\n\n        def setAgeTest():\n            so.age = \'my_name\'\n\n        self.assertRaises(cassandra.InvalidRequest, setAgeTest)\n\n    def test_paranoid_setattr_float(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        so = Test2StorageObjFloat(""t2_2"")\n        so.age = 2.0\n\n    def test_nestedso_notpersistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test3StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test4bstorageobj"")\n\n        my_nested_so = Test3StorageObj()\n\n        my_nested_so.myso.name = \'Link\'\n        self.assertEquals(\'Link\', my_nested_so.myso.name)\n        my_nested_so.myso.age = 10\n        self.assertEquals(10, my_nested_so.myso.age)\n\n        error = False\n        try:\n            config.session.execute(\'SELECT * FROM my_app.Test3StorageObj\')\n        except cassandra.InvalidRequest:\n            error = True\n        self.assertEquals(True, error)\n\n        my_nested_so.myso2.test[0] = \'position0\'\n        self.assertEquals(\'position0\', my_nested_so.myso2.test[0])\n\n        my_nested_so2 = Test4StorageObj()\n\n        my_nested_so2.myotherso.name = \'Link\'\n        self.assertEquals(\'Link\', my_nested_so2.myotherso.name)\n        my_nested_so2.myotherso.age = 10\n        self.assertEquals(10, my_nested_so2.myotherso.age)\n\n        error = False\n        try:\n            config.session.execute(\'SELECT * FROM my_app.myso\')\n        except cassandra.InvalidRequest:\n            error = True\n        self.assertEquals(True, error)\n\n        my_nested_so3 = Test4bStorageObj(\'mynested\')\n        my_nested_subso = my_nested_so3.myotherso\n\n        my_other_nested = getByID(my_nested_subso.storage_id)\n        my_other_nested.name = \'bla\'\n        my_other_nested.age = 5\n        error = False\n        try:\n            result = config.session.execute(\'SELECT * FROM my_app.Test2StorageObj\')\n        except cassandra.InvalidRequest:\n            error = True\n        self.assertEquals(False, error)\n        for row in result:\n            query_res = row\n        self.assertEquals(5, query_res.age)\n        self.assertEquals(\'bla\', query_res.name)\n\n    def test_nestedso_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test3StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test2storageobj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj_test"")\n\n        my_nested_so = Test3StorageObj(\'mynewso\')\n        self.assertEquals(True, my_nested_so._is_persistent)\n        self.assertEquals(True, my_nested_so.myso._is_persistent)\n        self.assertEquals(True, my_nested_so.myso2._is_persistent)\n\n        my_nested_so.myso.name = \'Link\'\n        my_nested_so.myso.age = 10\n        error = False\n        try:\n            result = config.session.execute(\'SELECT * FROM my_app.test2storageobj\')\n        except cassandra.InvalidRequest:\n            error = True\n        self.assertEquals(False, error)\n        for row in result:\n            query_res = row\n        self.assertEquals(10, query_res.age)\n        self.assertEquals(\'Link\', query_res.name)\n\n        my_nested_so.myso2.name = \'position0\'\n        self.assertEquals(\'position0\', my_nested_so.myso2.name)\n\n    def test_nestedso_topersistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test3StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test2storageobj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj_test"")\n\n        my_nested_so = Test3StorageObj()\n\n        my_nested_so.myso.name = \'Link\'\n        self.assertEquals(\'Link\', my_nested_so.myso.name)\n        my_nested_so.myso.age = 10\n        self.assertEquals(10, my_nested_so.myso.age)\n        error = False\n        try:\n            result = config.session.execute(\'SELECT * FROM my_app.test2storageobj\')\n        except cassandra.InvalidRequest:\n            error = True\n        self.assertEquals(True, error)\n\n        my_nested_so.make_persistent(\'mynewso\')\n\n        error = False\n        try:\n            result = config.session.execute(\'SELECT * FROM my_app.test2storageobj\')\n        except cassandra.InvalidRequest:\n            error = True\n        self.assertEquals(False, error)\n        for row in result:\n            query_res = row\n        self.assertEquals(10, query_res.age)\n        self.assertEquals(\'Link\', query_res.name)\n\n    def test_nestedso_sets_gets(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test3StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test2storageobj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj_test"")\n\n        my_nested_so = Test3StorageObj()\n\n        my_nested_so.myso.name = \'Link\'\n        self.assertEquals(\'Link\', my_nested_so.myso.name)\n        my_nested_so.myso.age = 10\n        self.assertEquals(10, my_nested_so.myso.age)\n        my_nested_so.myso.weight = 70\n        self.assertEquals(70, my_nested_so.myso.weight)\n        error = False\n        try:\n            result = config.session.execute(\'SELECT * FROM my_app.mynewso_myso\')\n        except cassandra.InvalidRequest:\n            error = True\n        self.assertEquals(True, error)\n\n        my_nested_so.make_persistent(\'mynewso\')\n\n        error = False\n        try:\n            result = config.session.execute(\'SELECT * FROM my_app.Test2StorageObj\')\n        except cassandra.InvalidRequest:\n            error = True\n        self.assertEquals(False, error)\n        for row in result:\n            query_res = row\n        self.assertEquals(10, query_res.age)\n        self.assertEquals(\'Link\', query_res.name)\n        error = False\n        try:\n            _ = query_res.weight\n        except:\n            error = True\n        self.assertEquals(True, error)\n        my_nested_so.myso.weight = 50\n        self.assertEquals(50, my_nested_so.myso.weight)\n        result = config.session.execute(\'SELECT * FROM my_app.Test2StorageObj\')\n        for row in result:\n            query_res = row\n        error = False\n        try:\n            _ = query_res.weight\n        except:\n            error = True\n        self.assertEquals(True, error)\n\n    def test_nestedso_sets_gets_complex(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test3StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test2storageobj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tnsgc"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tnsgc_test"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tnsgc_test_0"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tnsgc_test_1"")\n\n        my_nested_so = Test3StorageObj()\n\n        error = False\n        try:\n            _ = config.session.execute(\'SELECT * FROM my_app.TestStorageObj\')\n        except cassandra.InvalidRequest:\n            error = True\n        self.assertEquals(True, error)\n\n        my_nested_so.make_persistent(\'tnsgc\')\n\n        # We create the nested persistent objects only after they are accessed by the first time\n        error = False\n        try:\n            _ = config.session.execute(\'SELECT * FROM my_app.TestStorageObj\')\n        except cassandra.InvalidRequest:\n            error = True\n        self.assertEquals(True, error)\n\n        for i in range(0, 100):\n            my_nested_so.myso2.test[i] = \'position\' + str(i)\n        time.sleep(5)\n        count, = config.session.execute(""SELECT COUNT(*) FROM my_app.tnsgc_myso2_test"")[0]\n        self.assertEquals(100, count)\n\n    def test_nestedso_deletepersistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test3StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test2storageobj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.tndp"")\n\n        my_nested_so = Test3StorageObj(\'tndp\')\n\n        self.assertEquals(True, my_nested_so._is_persistent)\n        my_nested_so.myso.name = \'Link\'\n        self.assertEquals(\'Link\', my_nested_so.myso.name)\n        my_nested_so.myso.age = 10\n        self.assertEquals(10, my_nested_so.myso.age)\n\n        my_nested_so.delete_persistent()\n\n        self.assertEquals(False, my_nested_so._is_persistent)\n        entries = 0\n        try:\n            _ = config.session.execute(\'SELECT * FROM my_app.test2storageobj\')\n        except cassandra.InvalidRequest:\n            entries += 1\n        self.assertEquals(0, entries)\n\n    def test_nestedso_dictofsos(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test5storageobj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test5storageobj_test2"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        my_nested_so = Test5StorageObj()\n        my_nested_so.test2[0] = Test2StorageObj()\n        my_nested_so.make_persistent(\'topstorageobj\')\n        self.assertEquals(True, my_nested_so._is_persistent)\n        self.assertEquals(True, my_nested_so.test2._is_persistent)\n        self.assertEquals(True, my_nested_so.test2[0]._is_persistent)\n\n        my_nested_so.test2[0].name = \'Link\'\n        self.assertEquals(\'Link\', my_nested_so.test2[0].name)\n        my_nested_so.test2[0].age = 10\n        self.assertEquals(10, my_nested_so.test2[0].age)\n\n    def test_nestedso_dictofsos_noname(self):\n        \'\'\'\n        this test similar to test_nestedso_dictofsos with the difference that the StorageDict\n        used as an attribute in Test7StorageObj has the form <int,StorageObj> where no name has been given for the\n        StorageObj nor the Integer. In this case, a default name is used (key0,val0).\n        \'\'\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test2storageobj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test7storageobj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test7storageobj_test2"")\n\n        my_nested_so = Test7StorageObj()\n        my_nested_so.test2[0] = Test2StorageObj()\n        my_nested_so.make_persistent(\'topstorageobj2\')\n        self.assertEquals(True, my_nested_so._is_persistent)\n        self.assertEquals(True, my_nested_so.test2._is_persistent)\n        self.assertEquals(True, my_nested_so.test2[0]._is_persistent)\n\n        my_nested_so.test2[0].name = \'Link\'\n        self.assertEquals(\'Link\', my_nested_so.test2[0].name)\n        my_nested_so.test2[0].age = 10\n        self.assertEquals(10, my_nested_so.test2[0].age)\n\n    def test_nestedso_retrievedata(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test5StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.test5storageobj_test2"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n\n        my_nested_so = Test5StorageObj(\'tnr\')\n        my_nested_so.test2[0] = Test2StorageObj(\'something\')\n        self.assertEquals(True, my_nested_so._is_persistent)\n        self.assertEquals(True, my_nested_so.test2._is_persistent)\n        self.assertEquals(True, my_nested_so.test2[0]._is_persistent)\n\n        my_nested_so.test2[0].name = \'Link\'\n        self.assertEquals(\'Link\', my_nested_so.test2[0].name)\n        my_nested_so.test2[0].age = 10\n        self.assertEquals(10, my_nested_so.test2[0].age)\n\n        del my_nested_so\n\n        my_nested_so2 = Test5StorageObj(\'tnr\')\n\n        self.assertEquals(\'Link\', my_nested_so2.test2[0].name)\n        self.assertEquals(10, my_nested_so2.test2[0].age)\n\n    def test_numpy_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestStorageObjNumpy"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobjnumpy_mynumpy"")\n        my_so = TestStorageObjNumpy(\'tnp\')\n\n    def test_numpy_set(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestStorageObjNumpy"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobjnumpy_mynumpy"")\n        my_so = TestStorageObjNumpy()\n        my_so.mynumpy = np.random.rand(3, 2)\n        my_so.make_persistent(\'mynewso\')\n\n    def test_numpy_get(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestStorageObjNumpy"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestStorageObjNumpy_mynumpy"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobjnumpy_mynumpy"")\n        my_so = TestStorageObjNumpy(\'mynewso\')\n        mynumpy = np.random.rand(3, 2)\n        my_so.mynumpy = mynumpy\n        time.sleep(2)\n        self.assertTrue(np.array_equal(mynumpy, my_so.mynumpy))\n\n    def test_numpy_topersistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestStorageObjNumpy"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobjnumpy_mynumpy"")\n        my_so = TestStorageObjNumpy()\n        my_so.mynumpy = np.random.rand(3, 2)\n        my_so.make_persistent(\'mynewso\')\n\n    def test_numpydict_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestStorageObjNumpy"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobjnumpy_mynumpy"")\n        my_so = TestStorageObjNumpyDict(\'mynewso\')\n\n    def test_numpydict_set(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestStorageObjNumpy"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobjnumpy_mynumpy"")\n        my_so = TestStorageObjNumpyDict(\'mynewso\')\n        my_so.mynumpydict[0] = np.random.rand(3, 2)\n\n    def test_numpydict_to_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestStorageObjNumpy"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobjnumpy_mynumpy"")\n        my_so = TestStorageObjNumpyDict()\n        my_so.mynumpydict[0] = np.random.rand(3, 2)\n        my_so.make_persistent(\'mynewso\')\n\n    def test_numpydict_get(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestStorageObjNumpy"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobjnumpy_mynumpy"")\n        my_so = TestStorageObjNumpyDict()\n        mynumpydict = np.random.rand(3, 2)\n        my_so.mynumpydict[0] = mynumpydict\n        my_so.make_persistent(\'mynewso\')\n        import time\n        time.sleep(2)\n        self.assertTrue(np.allclose(mynumpydict, my_so.mynumpydict[0]))\n\n    def test_numpy_operations(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.mynewso"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.mynewso_mynumpy"")\n        my_so = TestStorageObjNumpy()\n        base_numpy = np.arange(2048)\n        my_so.mynumpy = np.arange(2048)\n        my_so.make_persistent(\'mynewso\')\n        time.sleep(2)\n        self.assertTrue(np.array_equal(base_numpy, my_so.mynumpy))\n        base_numpy += 1\n        my_so.mynumpy += 1\n        self.assertTrue(np.array_equal(base_numpy, my_so.mynumpy))\n        self.assertEqual(np.average(base_numpy), np.average(my_so.mynumpy))\n        self.assertEqual(np.mean(base_numpy), np.mean(my_so.mynumpy))\n\n    def test_numpy_ops_persistent(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.mynewso2"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.mynewso2_mynumpy"")\n        my_so = TestStorageObjNumpy()\n        base_numpy = np.arange(2048)\n        my_so.mynumpy = np.arange(2048)\n        my_so.make_persistent(\'my_app.mynewso2\')\n        self.assertTrue(np.array_equal(base_numpy, my_so.mynumpy))\n        base_numpy += 1\n        my_so.mynumpy += 1\n        self.assertTrue(np.array_equal(base_numpy, my_so.mynumpy))\n\n        reloaded_so = TestStorageObjNumpy(\'my_app.mynewso2\')\n        self.assertTrue(np.allclose(reloaded_so.mynumpy, base_numpy))\n        self.assertEqual(np.average(base_numpy), np.average(reloaded_so.mynumpy))\n        self.assertEqual(np.mean(base_numpy), np.mean(reloaded_so.mynumpy))\n\n    def test_numpy_reloading(self):\n        sizea, sizeb = (1000, 1000)\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d_%d"" % (sizea, sizeb))\n        a = np.ones((sizea, sizeb))\n        no.mynumpy = a\n        del no\n        import gc\n        gc.collect()\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d_%d"" % (sizea, sizeb))\n        a = no.mynumpy\n        self.assertEqual(np.shape(a), (sizea, sizeb))\n        self.assertEqual(np.sum(a), sizea * sizeb)\n\n    def test_numpy_reloading_internals(self):\n        sizea, sizeb = (1000, 1000)\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d_%d"" % (sizea, sizeb))\n        a = np.ones((sizea, sizeb))\n        no.mynumpy = a\n        initial_name_so = no._ksp + \'.\' + no._table\n        initial_name_np = no.mynumpy._ksp + \'.\' + no.mynumpy._table\n        del no\n        import gc\n        gc.collect()\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d_%d"" % (sizea, sizeb))\n        a = no.mynumpy\n\n        final_name_so = no._ksp + \'.\' + no._table\n        final_name_np = no.mynumpy._ksp + \'.\' + no.mynumpy._table\n        self.assertEqual(initial_name_so, final_name_so)\n        self.assertEqual(initial_name_np, final_name_np)\n\n    def test_storagedict_assign(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.t2_1"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.t2_1_test"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.t2_1_test_0"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.t2_1_test_1"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.t2_1_test_2"")\n        so = TestStorageObj(""t2_1"")\n        self.assertEquals(\'t2_1_test\', so.test._table)\n        so.test = {}\n        self.assertEquals(\'t2_1_test_0\', so.test._table)\n        so.test = {1: \'a\', 2: \'b\'}\n        self.assertEquals(\'t2_1_test_1\', so.test._table)\n        so.test = {3: \'c\', 4: \'d\'}\n        self.assertEquals(\'t2_1_test_2\', so.test._table)\n\n    def test_storageobj_coherence_basic(self):\n        \'\'\'\n        test that two StorageObjs pointing to the same table work correctly.\n        Changing data on one StorageObj is reflected on the other StorageObj.\n        \'\'\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        so = Test2StorageObj(\'test\')\n        so.name = \'Oliver\'\n        so.age = 21\n        so2 = Test2StorageObj(\'test\')\n        self.assertEqual(so.name, so2.name)\n        self.assertEqual(so.age, so2.age)\n        so.name = \'Benji\'\n        so2 = Test2StorageObj(\'test\')\n        self.assertEqual(so.name, so2.name)\n        self.assertEqual(so.age, so2.age)\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n\n    def test_storageobj_coherence_complex1(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test3StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj_test"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj"")\n        so = Test3StorageObj(\'test\')\n        myso_attr = Test2StorageObj()\n        myso_attr.name = \'Oliver\'\n        myso_attr.age = 21\n        so.myso = myso_attr  # creates my_app.test_myso_0, the original attribute pointed to test_myso\n        self.assertEqual(myso_attr.name, so.myso.name)\n        del myso_attr\n        self.assertEqual(so.myso.age, 21)\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test3StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj_test"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj"")\n\n    def test_storageobj_coherence_complex2(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test3StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj_test"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj"")\n        so = Test3StorageObj(\'test\')\n        myso_attr = Test2StorageObj()\n        myso_attr.name = \'Oliver\'\n        myso_attr.age = 21\n        so.myso = myso_attr  # creates my_app.test_myso_0, the original attribute pointed to test_myso\n        # now my_attr is persistent too, because it has been asigned to a persistent object\n        # Python behaviour, now the attribute points to the object, no copy made\n        self.assertTrue(so.myso is myso_attr)\n        # any change on the nested attribute should change the original and backwards\n        attr_value = 123\n        myso_attr.some_attribute = attr_value\n        myso_attr.name = \'Benji\'\n        self.assertTrue(hasattr(so.myso, \'some_attribute\'))\n        self.assertEqual(so.myso.some_attribute, attr_value)\n        self.assertEqual(so.myso.name, \'Benji\')\n\n        # now we unreference the top persistent object called so which was made persistent as \'test\'\n        del so\n\n        # The object pointed by \'so.myso\' should still exist because we still have one reference called \'myso_attr\'\n\n        self.assertTrue(myso_attr is not None)\n        self.assertTrue(isinstance(myso_attr, Test2StorageObj))\n        self.assertEqual(myso_attr.name, \'Benji\')\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test3StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj_test"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.teststorageobj"")\n\n    def test_get_attr_1(self):\n        storage_obj = TestAttributes()\n        storage_obj.do_nothing_at_all()\n        value = 123\n        storage_obj.setvalue(value)\n        returned = storage_obj.getvalue()\n        self.assertEqual(value, returned)\n\n    def test_get_attr_2(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestAttributes"")\n        storage_obj = TestAttributes()\n        storage_obj.do_nothing_at_all()\n        value = 123\n        storage_obj.setvalue(value)\n        storage_obj.make_persistent(""test_attr"")\n        # check that the in memory attribute is kept\n        returned = storage_obj.getvalue()\n        self.assertEqual(value, returned)\n        # check that the method added by inheritance is correctly called\n        storage_obj.do_nothing_at_all()\n\n        def method_nonexistent():\n            storage_obj.i_dont_exist()\n\n        # check that an attribute method which doesn\'t exist is detected\n        self.assertRaises(AttributeError, method_nonexistent)\n\n        # check for private methods too (starting with underscore)\n        def method_nonexistent_pvt():\n            storage_obj._pvt_dont_exist()\n\n        self.assertRaises(AttributeError, method_nonexistent_pvt)\n\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestAttributes"")\n\n    def test_get_attr_3(self):\n        # the same as test_get_attr_2 but the object is persistent since the beginning\n\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestAttributes"")\n        storage_obj = TestAttributes(""test_attr"")\n        storage_obj.do_nothing_at_all()\n        value = 123\n        storage_obj.setvalue(value)\n        # check that the in memory attribute is kept\n        returned = storage_obj.getvalue()\n        self.assertEqual(value, returned)\n        # check that the method added by inheritance is correctly called\n        storage_obj.do_nothing_at_all()\n\n        def method_nonexistent():\n            storage_obj.i_dont_exist()\n\n        # check that an attribute method which doesn\'t exist is detected\n        self.assertRaises(AttributeError, method_nonexistent)\n\n        # check for private methods too (starting with underscore)\n        def method_nonexistent_pvt():\n            storage_obj._pvt_dont_exist()\n\n        self.assertRaises(AttributeError, method_nonexistent_pvt)\n\n        storage_obj.key = 123\n        returned = storage_obj.key\n        self.assertEqual(storage_obj.key, returned)\n\n        config.session.execute(""DROP TABLE IF EXISTS my_app.TestAttributes"")\n\n    def test_recreation_init(self):\n        """"""\n        New StorageObj\n        Persistent attributes\n        Made persistent on the constructor.\n        """"""\n        sobj_name = ""my_app.test_attr6""\n        config.session.execute(""DROP TABLE IF EXISTS {}"".format(sobj_name))\n        attr1 = \'Test1\'\n        attr2 = 23\n        storage_obj = Test2StorageObj(sobj_name)\n        storage_obj.name = attr1\n        storage_obj.age = attr2\n        uuid_sobj = storage_obj.storage_id\n\n        storage_obj = None\n        result_set = iter(config.session.execute(""SELECT * FROM hecuba.istorage WHERE storage_id={}"".format(uuid_sobj)))\n\n        try:\n            result = result_set.next()\n        except StopIteration as ex:\n            self.fail(""StorageObj istorage data was not saved"")\n\n        self.assertEqual(result.name, sobj_name)\n\n        storage_obj = Test2StorageObj(sobj_name)\n\n        self.assertEqual(storage_obj.name, attr1)\n        self.assertEqual(storage_obj.age, attr2)\n\n    def test_recreation_init2(self):\n        """"""\n        New StorageObj\n        Has persistent and volatile attributes\n        Made persistent on the constructor.\n        """"""\n        sobj_name = ""my_app.test_attr""\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        attr1 = \'Test1\'\n        attr2 = 23\n        storage_obj = Test2StorageObj(sobj_name)\n        storage_obj.name = attr1\n        storage_obj.nonpersistent = attr2\n        uuid_sobj = storage_obj.storage_id\n\n        storage_obj = None\n        result_set = iter(config.session.execute(""SELECT * FROM hecuba.istorage WHERE storage_id={}"".format(uuid_sobj)))\n\n        try:\n            result = result_set.next()\n        except StopIteration as ex:\n            self.fail(""StorageObj istorage data was not saved"")\n\n        self.assertEqual(result.name, sobj_name)\n\n        storage_obj = Test2StorageObj(sobj_name)\n\n        self.assertEqual(storage_obj.name, attr1)\n\n        with self.assertRaises(AttributeError):\n            attr = storage_obj.age\n\n        with self.assertRaises(AttributeError):\n            attr = storage_obj.nonpersistent\n\n    def test_recreation_make_pers(self):\n        """"""\n        New StorageObj\n        Persistent attributes\n        Made persistent with make_persistent.\n        """"""\n        sobj_name = ""my_app.test_attr""\n        config.session.execute(""DROP TABLE IF EXISTS {}"".format(sobj_name))\n        attr1 = \'Test1\'\n        attr2 = 23\n        storage_obj = Test2StorageObj()\n        storage_obj.make_persistent(sobj_name)\n        uuid_sobj = storage_obj.storage_id\n\n        storage_obj = None\n        result_set = iter(config.session.execute(""SELECT * FROM hecuba.istorage WHERE storage_id={}"".format(uuid_sobj)))\n\n        try:\n            result = result_set.next()\n        except StopIteration as ex:\n            self.fail(""StorageObj istorage data was not saved"")\n\n        self.assertEqual(result.name, sobj_name)\n\n        storage_obj = Test2StorageObj()\n\n        storage_obj.name = attr1\n        storage_obj.volatile = attr2\n\n        storage_obj.make_persistent(sobj_name)\n\n        self.assertEqual(storage_obj.name, attr1)\n        self.assertEqual(storage_obj.volatile, attr2)\n\n        with self.assertRaises(AttributeError):\n            attr = storage_obj.age\n\n    def test_recreation_make_pers2(self):\n        """"""\n        New StorageObj\n        Persistent attributes\n        Made persistent with make_persistent.\n        """"""\n        sobj_name = ""my_app.test_attr""\n        config.session.execute(""DROP TABLE IF EXISTS {}"".format(sobj_name))\n        attr1 = \'Test1\'\n        attr2 = 23\n        storage_obj = Test2StorageObj()\n        storage_obj.name = attr1\n        storage_obj.volatile = \'Ofcourse\'\n        storage_obj.make_persistent(sobj_name)\n        uuid_sobj = storage_obj.storage_id\n\n        storage_obj = None\n        result_set = iter(config.session.execute(""SELECT * FROM hecuba.istorage WHERE storage_id={}"".format(uuid_sobj)))\n\n        try:\n            result = result_set.next()\n        except StopIteration as ex:\n            self.fail(""StorageObj istorage data was not saved"")\n\n        self.assertEqual(result.name, sobj_name)\n\n        storage_obj = Test2StorageObj()\n        storage_obj.age = attr2\n        storage_obj.make_persistent(sobj_name)\n\n        self.assertEqual(storage_obj.name, attr1)\n        self.assertEqual(storage_obj.age, attr2)\n\n        with self.assertRaises(AttributeError):\n            attr = storage_obj.volatile\n\n    def test_nested_recreation(self):\n        sobj_name = ""my_app.test_attr""\n        config.session.execute(""DROP TABLE IF EXISTS {}"".format(""my_app.test2storageobj""))\n        config.session.execute(""DROP TABLE IF EXISTS {}"".format(""my_app.test4storageobj""))\n\n        storage_obj = Test2StorageObj()\n        name_attr = \'Test1\'\n        age_attr = 23\n        storage_obj.name = name_attr\n        storage_obj.age = age_attr\n\n        external_sobj = Test4StorageObj(sobj_name)\n        external_sobj.myotherso = storage_obj\n\n        uuid_sobj_internal = storage_obj.storage_id\n        uuid_sobj_external = external_sobj.storage_id\n\n        internal_name = external_sobj.myotherso._get_name()\n        storage_obj = None\n        external_sobj = None\n\n        # Check that they have been correctly stored into hecuba.istorage\n\n        result_set = iter(\n            config.session.execute(""SELECT * FROM hecuba.istorage WHERE storage_id={}"".format(uuid_sobj_external)))\n\n        try:\n            result = result_set.next()\n        except StopIteration as exc:\n            self.fail(""StorageObj istorage data was not saved"")\n\n        self.assertEqual(result.name, sobj_name)\n\n        result_set = iter(\n            config.session.execute(""SELECT * FROM hecuba.istorage WHERE storage_id={}"".format(uuid_sobj_internal)))\n\n        try:\n            result = result_set.next()\n        except StopIteration as exc:\n            self.fail(""StorageObj istorage data was not saved"")\n\n        self.assertEqual(result.name, internal_name)\n\n        # They are both present in hecuba.istorage\n\n        result_set = iter(\n            config.session.execute(\n                ""SELECT * FROM {} WHERE storage_id={}"".format(""my_app.Test4StorageObj"", uuid_sobj_external)))\n\n        try:\n            result = result_set.next()\n        except StopIteration as exc:\n            self.fail(""StorageObj istorage data was not saved"")\n\n        self.assertEqual(result.myotherso, uuid_sobj_internal)\n        # They have been saved with the expected istorage ids\n\n        external_sobj = Test4StorageObj(sobj_name)\n        # Check internal configuration is correct\n        self.assertEqual(external_sobj.storage_id, uuid_sobj_external)\n        self.assertEqual(external_sobj.myotherso.storage_id, uuid_sobj_internal)\n        self.assertEqual(external_sobj._get_name(), sobj_name)\n        self.assertEqual(external_sobj.myotherso._get_name(), internal_name)\n\n        # Check data is correct\n        self.assertEqual(external_sobj.myotherso.name, name_attr)\n        self.assertEqual(external_sobj.myotherso.age, age_attr)\n\n    def test_single_table(self):\n        config.session.execute(""DROP TABLE IF EXISTS hecuba.Test2StorageObj"")\n        my_obj1 = Test2StorageObj(""my_app.my_obj1"")\n        my_obj2 = Test2StorageObj(""my_app.my_obj2"")\n        my_obj1.name, my_obj2.name = ""Adrian"", ""Adri""\n        my_obj1.age, my_obj2.age = 21, 23\n        self.assertEqual(my_obj1._ksp, my_obj2._ksp)\n        self.assertEqual(my_obj1._table, my_obj2._table)\n\n        res = config.session.execute(""SELECT * FROM my_app.Test2StorageObj WHERE storage_id = %s"" % my_obj1.storage_id)\n        res2 = config.session.execute(\n            ""SELECT * FROM my_app.Test2StorageObj WHERE storage_id = %s"" % my_obj2.storage_id)\n        self.assertEqual(res.one().name, ""Adrian"")\n        self.assertEqual(res2.one().name, ""Adri"")\n        self.assertEqual(res.one().age, 21)\n        self.assertEqual(res2.one().age, 23)\n\n    def test_dict_single_table(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.Test2StorageObj"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.my_dict"")\n        my_dict = Test5StorageObj(""my_app.my_dict4"")\n        for i in range(0, 20):\n            aux = Test2StorageObj(""my_app.my_obj"" + str(i))\n            aux.name, aux.age = ""RandomName"" + str(i), 18 + i\n            my_dict.test2[i] = aux\n\n        for i in range(0, 20):\n            self.assertEqual(my_dict.test2[i]._ksp, ""my_app"")\n            self.assertEqual(my_dict.test2[i]._table, ""Test2StorageObj"".lower())\n            res = config.session.execute(\n                ""SELECT * FROM my_app.Test2StorageObj WHERE storage_id = %s"" % my_dict.test2[i].storage_id)\n            self.assertEqual(res.one().name, ""RandomName"" + str(i))\n            self.assertEqual(res.one().age, 18 + i)\n\n    def test_time(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.timeAttrib"")\n        d = TestTime(""my_app.timeAttrib"")\n\n        mytime =datetime.time(hour=11, minute=43, second=2, microsecond=90)\n        d.attr = mytime\n        del d\n        mynew_d = TestTime(""my_app.timeAttrib"")\n        self.assertEqual(mynew_d.attr, mytime)\n\n    def test_date(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dateAttrib"")\n        d = TestDate(""my_app.dateAttrib"")\n        \n        mydate = datetime.date(year=1992, month=7, day=25)\n        d.attr = mydate\n        del d\n        mynew_d = TestDate(""my_app.dateAttrib"")\n\n        self.assertEqual(mynew_d.attr, mydate)\n\n    def test_datetime(self):\n        config.session.execute(""DROP TABLE IF EXISTS my_app.dateTimeAttrib"")\n        d = TestDateTime(""my_app.dateTimeAttrib"")\n        dtime = datetime.datetime(year=1940, month=10, day=16,\n                         hour=23, minute=59, second=59)\n        d.attr = dtime\n        del d\n        mynew_d = TestDateTime(""my_app.dateTimeAttrib"")\n        self.assertEqual(mynew_d.attr, dtime)\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/storageobj_with_numpy_tests.py,106,"b'import unittest\n\nimport numpy as np\nfrom hecuba import config, StorageObj\n\n\nclass TestStorageObjNumpy(StorageObj):\n    \'\'\'\n       @ClassField mynumpy numpy.ndarray\n    \'\'\'\n    pass\n\n\nclass StorageNumpyTest(unittest.TestCase):\n    table = \'numpy_test\'\n    ksp = \'my_app\'\n\n    def test_numpy_reserved_all_cluster_2D(self):\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_0;"")\n        num = 0\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(40000).reshape((200, 200))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[slice(None, None, None)]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(40000).reshape((200, 200))\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_reserved_2d_1cluster(self):\n        coordinates = (slice(0, 50, None), slice(0, 50, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_1;"")\n        num = 1\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000).reshape((100, 100))\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_reserved_2d_2cluster(self):\n        coordinates = (slice(0, 22, None), slice(0, 44, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_2;"")\n        num = 2\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000).reshape((100, 100))\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_reserved_2d_3cluster(self):\n        coordinates = (slice(0, 45, None), slice(0, 22, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_3;"")\n        num = 3\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000).reshape((100, 100))\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_reserved_2d_4cluster(self):\n        coordinates = (slice(0, 45, None), slice(0, 45, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_4;"")\n        num = 4\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000).reshape((100, 100))\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_reserved_3d_1cluster(self):\n        coordinates = (slice(0, 8, None), slice(0, 8, None), slice(0, 8, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_5;"")\n        num = 5\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(1000).reshape((10, 10, 10))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(1000).reshape((10, 10, 10))\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_2D_slice_right(self):\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_5;"")\n        num = 5\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[slice(None, 5, None), slice(None, 5, None)]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000).reshape((100, 100))\n        test_numpy = test_numpy[slice(None, 5, None), slice(None, 5, None)]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_2D_slice_left(self):\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_5;"")\n        num = 6\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[slice(5, None, None), slice(5, None, None)]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000).reshape((100, 100))\n        test_numpy = test_numpy[slice(5, None, None), slice(5, None, None)]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_1D_slice_right(self):\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_5;"")\n        num = 5\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000)\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[slice(None, 5, None)]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000)\n        test_numpy = test_numpy[slice(None, 5, None)]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_1D_slice_left(self):\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_5;"")\n        num = 5\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000)\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[slice(5, None, None)]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000)\n        test_numpy = test_numpy[slice(5, None, None)]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_1D_none_slices(self):\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_5;"")\n        num = 5\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000)\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[slice(None, None, None)]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000)\n        test_numpy = test_numpy[slice(None, None, None)]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_2D_some_none_slices(self):\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_5;"")\n        num = 30\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100,100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[slice(None, None, None), slice(4, 100, None)]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000).reshape((100,100))\n        test_numpy = test_numpy[slice(None, None, None), slice(4, 100, None)]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_1D_none_slice_not_a_list(self):\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_5;"")\n        num = 25\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000)\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[slice(None, None, None)]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000)\n        test_numpy = test_numpy[slice(None, None, None)]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_1D_list_1_slice(self):\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_5;"")\n        num = 26\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000)\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[slice(2, 20, None)]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000)\n        test_numpy = test_numpy[slice(2, 20, None)]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_reserved_4d_1cluster(self):\n        coordinates = (slice(0, 8, None), slice(0, 8, None), slice(0, 8, None), slice(0, 8, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_6;"")\n        num = 6\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((10, 10, 10, 10))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000).reshape((10, 10, 10, 10))\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_reserved_5d_1cluster(self):\n        coordinates = (slice(0, 5, None), slice(0, 5, None), slice(0, 5, None), slice(0, 5, None), slice(0, 5, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_13;"")\n        num = 13\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(100000).reshape((10, 10, 10, 10, 10))\n        import gc\n        del no\n        gc.collect()\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(100000).reshape((10, 10, 10, 10, 10))\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_all_slices_out_of_bounds(self):\n        coordinates = (slice(200, 1000, None), slice(200, 1000, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_1;"")\n        num = 14\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000).reshape((100, 100))\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_all_slices_out_of_bounds2(self):\n        coordinates = (slice(20, 100, None), slice(20, 100, None), slice(20, 100, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_1;"")\n        num = 15\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(1000).reshape((10, 10, 10))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(1000).reshape((10, 10, 10))\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_some_slices_out_of_bounds(self):\n        coordinates = (slice(50, 150, None), slice(50, 150, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_1;"")\n        num = 16\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(10000).reshape((100, 100))\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_numpy_some_slices_out_of_bounds2(self):\n        coordinates = (slice(50, 150, None), slice(50, 150, None), slice(5, 150, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_1;"")\n        num = 16\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(1000).reshape((10, 10, 10))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        result = chunk.view(np.ndarray)\n        test_numpy = np.arange(1000).reshape((10, 10, 10))\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(result, test_numpy))\n\n    def test_write_1value_all_numpy(self):\n        coordinates = (slice(0, 45, None), slice(0, 45, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_7;"")\n        num = 7\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        chunk[:] = 1\n        test_numpy = np.arange(10000).reshape((100, 100))[coordinates[0], coordinates[1]]\n        test_numpy[:] = 1\n        self.assertTrue(np.allclose(chunk.view(np.ndarray), test_numpy))\n\n    def test_write_1value_all_numpy_2coord(self):\n        coordinates = (slice(0, 45, None), slice(0, 45, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_8;"")\n        num = 8\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        set_coord = (slice(0, 10, None), slice(0, 10, None))\n        chunk[set_coord] = 1\n        test_numpy = np.arange(10000).reshape((100, 100))[coordinates[0], coordinates[1]]\n        test_numpy[set_coord] = 1\n        self.assertTrue(np.allclose(chunk.view(np.ndarray), test_numpy))\n\n    def test_write_nvalue_all_numpy_2coord(self):\n        coordinates = (slice(0, 45, None), slice(0, 45, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_9;"")\n        num = 9\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        set_coord = (slice(0, 10, None), slice(0, 10, None))\n        chunk[set_coord] = np.arange(100).reshape((10, 10))\n        test_numpy = np.arange(10000).reshape((100, 100))[coordinates[0], coordinates[1]]\n        test_numpy[set_coord] = np.arange(100).reshape((10, 10))\n        self.assertTrue(np.allclose(chunk.view(np.ndarray), test_numpy))\n\n    def test_write_nvalue2_all_numpy_2coord_rww(self):\n        coordinates = (slice(0, 45, None), slice(0, 45, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_10;"")\n        num = 10\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        set_coord = (slice(0, 10, None), slice(0, 10, None))\n        chunk[set_coord] = np.arange(100).reshape((10, 10))\n        chunk[slice(10, 20, None), slice(10, 20, None)] = np.arange(100).reshape((10, 10))\n        test_numpy = np.arange(10000).reshape((100, 100))[coordinates[0], coordinates[1]]\n        test_numpy[set_coord] = np.arange(100).reshape((10, 10))\n        test_numpy[slice(10, 20, None), slice(10, 20, None)] = np.arange(100).reshape((10, 10))\n        self.assertTrue(np.allclose(chunk.view(np.ndarray), test_numpy))\n\n    def test_write_nvalue2_all_numpy_2coord_rwr(self):\n        coordinates = (slice(0, 45, None), slice(0, 45, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_11;"")\n        num = 11\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.arange(10000).reshape((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy[coordinates]\n        set_coord = (slice(0, 10, None), slice(0, 10, None))\n        chunk[set_coord] = np.arange(100).reshape((10, 10))\n        test_numpy = np.arange(10000).reshape((100, 100))[coordinates[0], coordinates[1]]\n        test_numpy[set_coord] = np.arange(100).reshape((10, 10))\n        coordinates = (slice(0, 20, None), slice(0, 20, None))\n        chunk = chunk[coordinates]\n        test_numpy = test_numpy[coordinates]\n        self.assertTrue(np.allclose(chunk.view(np.ndarray), test_numpy))\n\n    def test_write_nvalue2_all_numpy_2coord_w(self):\n        coordinates = (slice(30, 45, None), slice(30, 45, None))\n        config.session.execute(""DROP TABLE IF EXISTS myapp.numpy_test_12;"")\n        num = 12\n        no = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        no.mynumpy = np.zeros((100, 100))\n        myobj2 = TestStorageObjNumpy(""my_app.numpy_test_%d"" % num)\n        chunk = myobj2.mynumpy\n        chunk[coordinates] = 1\n        test_numpy = np.zeros((100, 100))\n        test_numpy[coordinates] = 1\n        self.assertTrue(np.allclose(chunk.view(np.ndarray), test_numpy))\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
hecuba_py/tests/withcassandra/test2storageobj.py,0,"b""from hecuba.storageobj import StorageObj\n\n\nclass Test2StorageObj(StorageObj):\n    '''\n       @ClassField name str\n       @ClassField age int\n    '''\n    pass\n"""
hecuba_py/tests/withcassandra/tutorial_tests.py,0,"b'import unittest\nfrom hecuba import config\nfrom hecuba.hdict import StorageDict\nfrom hecuba.storageobj import StorageObj\n\n\nclass ExampleStoragedictClass(StorageDict):\n    \'\'\'\n        @TypeSpec dict<<k1:int>, val1:str>\n    \'\'\'\n\n\nclass ExampleStoragedictClassInit(StorageDict):\n    \'\'\'\n        @TypeSpec dict<<k1:int>, val1:str>\n    \'\'\'\n\n    def __init__(self, **kwargs):\n        super(ExampleStoragedictClassInit, self).__init__(**kwargs)\n        self.update({0: \'first position\'})\n\n\nclass ExampleStoragedictClassInitMultiVal(StorageDict):\n    \'\'\'\n        @TypeSpec dict<<k1:int, k2:int>, val1:str, val2:str, val3:int>\n    \'\'\'\n\n    def __init__(self, **kwargs):\n        super(ExampleStoragedictClassInitMultiVal, self).__init__(**kwargs)\n        self.update({(0, 1): [\'first position\', \'second_position\', 1000]})\n\n\nclass ExampleStoragedictClassNames(StorageDict):\n    \'\'\'\n        @TypeSpec dict<<position:int>, value:str>\n    \'\'\'\n\n\nclass ExampleStoragedictClassInitNames(StorageDict):\n    \'\'\'\n        @TypeSpec dict<<position:int>, value:str>\n    \'\'\'\n\n    def __init__(self, **kwargs):\n        super(ExampleStoragedictClassInitNames, self).__init__(**kwargs)\n        self.update({0: \'first position\'})\n\n\nclass ExampleStoragedictClassInitMultiValNames(StorageDict):\n    \'\'\'\n        @TypeSpec dict<<position1:int, position2:int>, value1:str, value2:str, value3:int>\n    \'\'\'\n\n    def __init__(self, **kwargs):\n        super(ExampleStoragedictClassInitMultiValNames, self).__init__(**kwargs)\n        self.update({(0, 1): [\'first position\', \'second_position\', 1000]})\n\n\nclass ExampleStorageObjClass(StorageObj):\n    \'\'\'\n        @ClassField my_dict dict<<k1:int>, val1:str>\n        @ClassField my_release int\n        @ClassField my_version str\n    \'\'\'\n\n\nclass ExampleStorageObjClassInit(StorageObj):\n    \'\'\'\n        @ClassField my_dict dict<<k1:int>, val1:str>\n        @ClassField my_release int\n        @ClassField my_version str\n    \'\'\'\n\n    def __init__(self, **kwargs):\n        super(ExampleStorageObjClassInit, self).__init__(**kwargs)\n        self.my_dict = {0: \'first position\'}\n        self.my_release = 2017\n        self.my_version = \'0.1\'\n\n\nclass ExampleStorageObjClassNames(StorageObj):\n    \'\'\'\n        @ClassField my_dict dict<<position:int>, val1:str>\n        @ClassField my_release int\n        @ClassField my_version str\n    \'\'\'\n\n\nclass TutorialTest(unittest.TestCase):\n\n    def test_init_storagedict_test(self):\n        tablename = \'examplestoragedictclass1\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename)\n        my_example_class = ExampleStoragedictClass()\n        my_example_class.make_persistent(tablename)\n\n    def test_init_storagedictwithinit_test(self):\n        tablename = \'examplestoragedictclass1\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename)\n        my_example_class = ExampleStoragedictClassInit()\n        StorageDict.__init__(my_example_class)\n        my_example_class.make_persistent(tablename)\n\n    def test_init_storagedictwithinitmultival_test(self):\n        tablename = \'examplestoragedictclass1\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename)\n        my_example_class = ExampleStoragedictClassInitMultiVal()\n        StorageDict.__init__(my_example_class)\n        my_example_class.make_persistent(tablename)\n\n    def test_init_storagedictnames_test(self):\n        tablename = \'examplestoragedictclass1\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename)\n        my_example_class = ExampleStoragedictClassNames()\n        my_example_class.make_persistent(tablename)\n\n    def test_init_storagedictwithinitnames_test(self):\n        tablename = \'examplestoragedictclass1\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename)\n        my_example_class = ExampleStoragedictClassInitNames()\n        StorageDict.__init__(my_example_class)\n        my_example_class.make_persistent(tablename)\n\n    def test_init_storagedictwithinitmultivalnames_test(self):\n        tablename = \'examplestoragedictclass1\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename)\n        my_example_class = ExampleStoragedictClassInitMultiValNames()\n        StorageDict.__init__(my_example_class)\n        my_example_class.make_persistent(tablename)\n\n    def test_init_storageobj_test(self):\n        tablename = \'examplestorageobjclass1\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app.ExampleStorageObjClass"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.ExampleStorageObjClass"" + \'_my_dict\')\n        my_example_class = ExampleStorageObjClass()\n        my_example_class.make_persistent(tablename)\n\n    def test_init_storageobjwithinit_test(self):\n        tablename = \'examplestorageobjclass1\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app.ExampleStorageObjClassInit"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.ExampleStorageObjClassInit"" + \'_my_dict\')\n        my_example_class = ExampleStorageObjClassInit()\n        StorageObj.__init__(my_example_class)\n        my_example_class.make_persistent(tablename)\n\n    def test_init_storageobjnames_test(self):\n        tablename = \'test2.examplestorageobjclass1\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app.ExampleStorageObjClassNames"")\n        config.session.execute(""DROP TABLE IF EXISTS my_app.ExampleStorageObjClassNames"" + \'_my_dict\')\n        my_example_class = ExampleStorageObjClassNames()\n        my_example_class.make_persistent(tablename)\n\n    def test_initializestoragedict_test(self):\n        tablename = \'examplestorageobjclass1\'\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename)\n        config.session.execute(""DROP TABLE IF EXISTS my_app."" + tablename + \'_my_dict\')\n        my_persistent_storageDict = StorageDict(tablename, [(\'position\', \'int\')], [(\'value\', \'text\')])\n'"
