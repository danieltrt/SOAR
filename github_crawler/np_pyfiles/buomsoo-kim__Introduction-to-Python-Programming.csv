file_path,api_count,code
Session2/source code/2-1/2-1-1.py,0,"b""def xor(x, y):\r\n\tif x == y:\r\n\t\treturn False\r\n\telse:\r\n\t\treturn True\r\n\r\nprint('True + True = ', xor(True, True))\r\nprint('True + False = ', xor(True, False))\r\nprint('False + True = ', xor(False, True))\r\nprint('False + False = ', xor(False, False))"""
Session2/source code/2-1/2-1-10.py,0,"b""salary = {'John': 30000, 'Jane': 50000, 'Paul': 45000, 'Elizabeth': 70000, 'Seth': 10000}\r\nkeys = salary.keys()\r\nfor key in keys:\r\n    if salary[key] >= 50000:\r\n        print('{}\\'s salary is: '.format(key), salary[key])"""
Session2/source code/2-1/2-1-11.py,0,"b""for i in range(1, 10):\r\n    for j in range(1, 10):\r\n        if j != 9:\r\n            print('{} * {} ='.format(i, j), i*j, end = '  ')\r\n        else:\r\n            print('{} * {} ='.format(i, j), i*j)"""
Session2/source code/2-1/2-1-12.py,0,"b""i = 1\r\nwhile i < 10:\r\n    j = 1\r\n    while j < 10:\r\n        if j != 9:\r\n            print('{} * {} ='.format(i, j), i*j, end = '  ')\r\n        else:\r\n            print('{} * {} ='.format(i, j), i*j)\r\n        j += 1\r\n    i += 1"""
Session2/source code/2-1/2-1-13.py,0,"b'def fibonacci(n):\r\n    i = 0\r\n    a, b = 0, 1\r\n    while i < n:            \r\n        print(a)\r\n        a, b = b, a + b\r\n        i += 1\r\n\r\nfibonacci(10)'"
Session2/source code/2-1/2-1-14.py,0,"b""data = []\r\nwith open('enrollments.csv', 'r') as f:\r\n    lines = f.readlines()[1:]\r\n    for line in lines:\r\n        line = line.split(',')\r\n        dic = {'account_key': line[0], 'status': line[1], 'join_data': line[2], 'cancel_data': line[3], 'days_to_cancel': line[4], 'is_udacity': line[5], 'is_canceled': line[6]}\r\n        data.append(dic)\r\n    f.close()"""
Session2/source code/2-1/2-1-2.py,0,"b'def search_element(l, e):\r\n\tif e in l:\r\n\t\treturn l.index(e)\r\n\telse:\r\n\t\treturn False\r\n\r\nl = [1,2,3]\r\ne1 = 2\r\ne2 = 10\r\n\r\nprint(search_element(l, e1))\r\nprint(search_element(l, e2))'"
Session2/source code/2-1/2-1-3.py,0,"b""def area_expand(w, l):\r\n\tarea_original = w * l\r\n\tw = w + 5\r\n\tl = l * 2\r\n\tarea_expanded = w * l\r\n\tprint('Width = ', w)\r\n\tprint('Length = ', l)\r\n\tprint('Area Ratio = ', area_original/area_expanded)\r\n\r\narea_expand(5, 10)"""
Session2/source code/2-1/2-1-4.py,0,"b'def calculator(i1, i2, i3, i4, i5):\r\n\tl = [i1, i2, i3, i4, i5]\r\n\tsum = 0\r\n\tidx = 0\r\n\tfor i in l:\r\n\t\tif i != 0:\r\n\t\t\tsum += i\r\n\t\t\tidx += 1\r\n\t\telse:\r\n\t\t\tbreak\r\n\treturn (sum, int(sum/idx))\r\n\r\nprint(calculator(1,2,3,4,5))\r\nprint(calculator(1,2,0,4,5))'"
Session2/source code/2-1/2-1-5.py,0,"b""def search_text(word, char):\r\n    if char in word:\r\n        return word.index(char)\r\n    return False\r\n\r\nprint(search_text('name', 'a'))\r\nprint(search_text('name', 'e'))\r\nprint(search_text('jane', 'p'))\r\nprint(search_text('jane', 'n'))"""
Session2/source code/2-1/2-1-6.py,0,"b""def reverse_text(s1, s2, s3, s4, s5):\r\n    c = 0\r\n    ss = [s1, s2, s3, s4, s5]\r\n    for s in ss:\r\n        if len(s)%2 == 1:\r\n            print(s[::-1])\r\n            c += 1\r\n        else:\r\n            print(s)\r\n    return c\r\n\r\nprint(reverse_text('tiger','lion','bear','snake','leopard'))"""
Session2/source code/2-1/2-1-7.py,0,"b""def vowel(s):\r\n    vowels = ['a', 'e', 'i', 'o', 'u']\r\n    s = list(s)\r\n    c = 0\r\n    for alphabet in s:\r\n        if alphabet in vowels:\r\n            c += 1\r\n    return c\r\n\r\nprint(vowel('apples'))\r\nprint(vowel('Her name is Jane'))"""
Session2/source code/2-1/2-1-8.py,0,"b'def sort_score(s1, s2, s3, s4, s5):\r\n    scores = [s1, s2 , s3 , s4, s5]\r\n    scores.sort()\r\n    for s in scores:\r\n        print(s)\r\n\r\nsort_score(5,2,3,1,4)'"
Session2/source code/2-1/2-1-9.py,0,"b""l = [['A', 'B', 'C', 'D', 'E'], ['F', 'G', 'H', 'I', 'J'], ['K', 'L', 'M', 'N', 'O']]\r\nfor row in l:\r\n    for column in row:\r\n        print(column.lower(), end = ' ')\r\n    print('\\n')"""
Session2/source code/2-2/2-2-1.py,0,"b'## implementing Stack ADT\r\n\r\ndef is_empty(stack):\r\n    return bool(len(stack))\r\ndef push(stack, item):\r\n    stack.append(item)\r\ndef pop(stack):\r\n    return stack.pop()\r\ndef top_value(stack):\r\n    return stack[len(stack) - 1]\r\ndef get_size(stack):\r\n    return len(stack)\r\n\r\nstack = [1, 2, 3, 4, 5]\r\nprint(is_empty(stack))\r\npush(stack, 6)\r\nprint(stack)\r\npop(stack)\r\nprint(stack)\r\nprint(top_value(stack))\r\nprint(get_size(stack))'"
Session2/source code/2-2/2-2-2.py,0,"b'## implementing Queue ADT\r\n\r\n# front\xeb\x8a\x94 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x9d\x98 \xeb\x81\x9d, rear\xeb\x8a\x94 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x9d\x98 \xec\x8b\x9c\xec\x9e\x91\r\ndef is_empty(queue):\r\n    return bool(len(queue))\r\ndef enqueue(queue, item):\r\n    queue.append(item)\r\ndef dequeue(queue):\r\n    temp = queue[0]\r\n    for i in range(len(queue)-1):\r\n        queue[i] = queue[i+1]\r\n    queue.pop()\r\n    return temp\r\ndef get_size(queue):\r\n    return len(queue)\r\n\r\nqueue = [1, 2, 3, 4, 5]\r\nprint(is_empty(queue))\r\nenqueue(queue, 6)\r\nprint(queue)\r\ndequeue(queue)\r\nprint(queue)\r\nprint(get_size(queue))\r\n\r\n\r\n## Alternatively,\r\n\r\n# front\xeb\x8a\x94 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x9d\x98 \xec\x8b\x9c\xec\x9e\x91, rear\xeb\x8a\x94 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x9d\x98 \xeb\x81\x9d\r\ndef is_empty(queue):\r\n    return bool(len(queue))\r\ndef enqueue(queue, item):\r\n    queue.append(None)\r\n    for i in range(len(queue) - 1, 0, -1):\r\n        queue[i] = queue[i-1]\r\n    queue[0] = item\r\ndef dequeue(queue):\r\n    return queue.pop()\r\ndef get_size(queue):\r\n    return len(queue)\r\n\r\nqueue = [5, 4, 3, 2, 1]\r\nprint(is_empty(queue))\r\nenqueue(queue, 6)\r\nprint(queue)\r\ndequeue(queue)\r\nprint(queue)\r\nprint(get_size(queue))'"
Session2/source code/2-2/2-2-3.py,0,"b'def insertion_sort(seq):\r\n    for i in range(1,len(seq)):    \r\n        j = i                    \r\n        while j > 0 and seq[j] < seq[j-1]: \r\n            seq[j], seq[j-1] = seq[j-1], seq[j] \r\n            j=j-1 \r\n    return seq\r\n\r\ninsertion_sort([9, 4, 8, 2, 3, 5, 1])'"
Session2/source code/2-2/2-2-4.py,0,"b'def bubble_sort(seq):\r\n    length = len(seq)        \r\n    for a in range(length):\r\n        for b in range(length-1):\r\n            if (seq[a] < seq[b]):\r\n                seq[a], seq[b] = seq[b], seq[a]\r\n    return seq \r\n\r\nbubble_sort([9, 4, 8, 2, 3, 5, 1])'"
Session2/source code/2-2/2-2-5.py,0,"b'# \xec\x9d\xb4\xec\xa7\x84\xed\x83\x90\xec\x83\x89 \xea\xb5\xac\xed\x98\x84\r\ndef binary_search(alist, value):\r\n    lower = 0\r\n    upper = len(alist)\r\n    while lower < upper:\r\n        x = lower + (upper - lower) // 2\r\n        temp = alist[x]\r\n        if value == temp:\r\n            return x\r\n        elif value > temp:\r\n            if lower == x:\r\n                break\r\n            lower = x\r\n        else:\r\n            upper = x\r\n\r\n# \xec\x9d\xb4\xec\xa7\x84 \xed\x83\x90\xec\x83\x89\xec\x9d\x98 \xec\x9d\xb8\xed\x92\x8b\xec\x9d\x80 \xec\xa0\x95\xeb\xa0\xac\xeb\x90\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\xac\xec\x95\xbc \xed\x95\xa8\r\nprint(binary_search([1,5,8,10], 5))\r\nprint(binary_search([1,5,8,10], 0))\r\nprint(binary_search([1,2,9,10,12,15,19], 9))\r\nprint(binary_search([1,2,9,10,12,15,19], 20))'"
Session2/source code/2-3/2-3-1-1.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup \r\nfrom urllib.request import urlopen\r\n\r\n# \xea\xb2\x80\xec\x83\x89\xed\x95\x98\xea\xb3\xa0 \xec\x8b\xb6\xec\x9d\x80 \xeb\x8b\xa8\xec\x96\xb4 \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0\r\nword = 'curiosity'\r\n\r\n# \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xeb\xa0\xa4\xeb\x8a\x94 url \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0 \r\nurl = 'http://dic.daum.net/search.do?q=' + word \t\t\t\t\t\t# \xeb\x94\x94\xed\x8f\xb4\xed\x8a\xb8 url\xec\x97\x90 string \xed\x83\x80\xec\x9e\x85\xec\x9d\x98 word \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xed\x95\xa9\xec\xb3\x90\xec\x84\x9c url \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\r\n\r\n# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\nweb = urlopen(url)\r\n\r\n# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\nweb_page = BeautifulSoup(web, 'html.parser')\r\n\r\n# find \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 \xec\xb0\xbe\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xeb\x8b\xa8\xec\x96\xb4\xec\x99\x80 \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\x9c\xbb\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 HTML \xed\x83\x9c\xea\xb7\xb8\xeb\xa5\xbc \xec\xb0\xbe\xec\x9d\x8c\r\nbox = web_page.find('div', {'class': 'search_cleanword'}).find('span', {'class': 'txt_emph1'}) \t# 'curiosity' \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\r\nbox2 = web_page.find('ul', {'class': 'list_search'})\t\t\t\t\t\t\t\t\t\t\t# \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\x9c\xbb\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\r\n\r\n# get_text \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\xb6\x94\xec\xb6\x9c\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nprint(box.get_text())\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\r\nprint(box2.get_text())"""
Session2/source code/2-3/2-3-1-2.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup \r\nfrom urllib.request import urlopen\r\n\r\n# \xea\xb2\x80\xec\x83\x89\xed\x95\x98\xea\xb3\xa0 \xec\x8b\xb6\xec\x9d\x80 \xeb\x8b\xa8\xec\x96\xb4 \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0\r\nwords = ['curiosity', 'killed', 'the', 'cat']\t\t\t# \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\x97\xac\xeb\x9f\xac \xea\xb0\x9c \xea\xb2\x80\xec\x83\x89\xed\x95\xa0 \xea\xb2\x83\xec\x9d\xb4\xeb\xaf\x80\xeb\xa1\x9c \xeb\xb3\xb5\xec\x88\x98\xec\x9d\x98 \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\r\n# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\x8b\xa8\xec\x96\xb4\xec\x99\x80 \xea\xb7\xb8 \xeb\x9c\xbb\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nfor word in words:\t\t\t\t\t\t\t\t\t\t# \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90\xec\x84\x9c \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xea\xba\xbc\xeb\x83\x84\r\n\turl = 'http://dic.daum.net/search.do?q=' + word\t\t# \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xeb\xa0\xa4\xeb\x8a\x94 url \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0 \r\n\tweb = urlopen(url)\t\t\t\t\t\t\t\t\t# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\t\t\t\t\t\t\t\r\n\tweb_page = BeautifulSoup(web, 'html.parser')\t\t# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\n\t# find \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 \xec\xb0\xbe\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xeb\x8b\xa8\xec\x96\xb4\xec\x99\x80 \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\x9c\xbb\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 HTML \xed\x83\x9c\xea\xb7\xb8\xeb\xa5\xbc \xec\xb0\xbe\xec\x9d\x8c\r\n\tbox = web_page.find('div', {'class': 'search_cleanword'}).find('span',{'class': 'txt_emph1'})\t# \xeb\x8b\xa8\xec\x96\xb4\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\r\n\tbox2 = web_page.findAll('ul', {'class': 'list_search'})[0]\t\t\t\t\t\t\t\t\t\t# \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\x9c\xbb\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\r\n\t# get_text \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\xb6\x94\xec\xb6\x9c\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\tprint(box.get_text())\r\n\tprint(box2.get_text())"""
Session2/source code/2-3/2-3-1-3.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup \r\nfrom urllib.request import urlopen\r\n\r\n# \xea\xb2\x80\xec\x83\x89\xed\x95\x98\xea\xb3\xa0 \xec\x8b\xb6\xec\x9d\x80 \xeb\x8b\xa8\xec\x96\xb4 \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0\r\nwords = ['curiosity', 'killed', 'the', 'cat']\t\t\t\t\t# \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\x97\xac\xeb\x9f\xac \xea\xb0\x9c \xea\xb2\x80\xec\x83\x89\xed\x95\xa0 \xea\xb2\x83\xec\x9d\xb4\xeb\xaf\x80\xeb\xa1\x9c \xeb\xb3\xb5\xec\x88\x98\xec\x9d\x98 \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\r\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-1-1-3.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\nwith open('result-2-3-1-3.txt', 'w', encoding = 'utf-8') as f:\t# \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\n\tfor word in words:\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\x8b\xa8\xec\x96\xb4\xec\x99\x80 \xea\xb7\xb8 \xeb\x9c\xbb\xec\x9d\x84 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\t\turl = 'http://dic.daum.net/search.do?q=' + word \t\t# \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xeb\xa0\xa4\xeb\x8a\x94 url \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0 \r\n\t\tweb = urlopen(url)\t\t\t\t\t\t\t\t\t\t# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\t\r\n\t\tweb_page = BeautifulSoup(web, 'html.parser')\t\t\t# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\n\t\t# find \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 \xec\xb0\xbe\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xeb\x8b\xa8\xec\x96\xb4\xec\x99\x80 \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\x9c\xbb\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 HTML \xed\x83\x9c\xea\xb7\xb8\xeb\xa5\xbc \xec\xb0\xbe\xec\x9d\x8c\r\n\t\tbox = web_page.find('div', {'class': 'search_cleanword'}).find('span',{'class': 'txt_emph1'})\t# \xeb\x8b\xa8\xec\x96\xb4\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\r\n\t\tbox2 = web_page.find('ul', {'class': 'list_search'})\t\t\t\t\t\t\t\t\t\t\t# \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\x9c\xbb\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\r\n\t\t# get_text \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\xb6\x94\xec\xb6\x9c\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\t\t# write \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x93\xb4\xeb\x8b\xa4\r\n\t\tf.write(box.get_text() + '\\n')\t\t\t\t\r\n\t\tf.write(box2.get_text() + '\\n')\r\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4"""
Session2/source code/2-3/2-3-1-4.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup \r\nfrom urllib.request import urlopen\r\n\r\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'data.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xea\xb7\xb8 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xea\xb0\x80\xec\xa0\xb8\xec\x98\xa8\xeb\x8b\xa4\r\nwith open('data.txt', 'r', encoding = 'utf-8') as f:\t\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xec\x9c\xbc\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\n\twords = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 \xec\xa0\x84\xec\xb2\xb4 \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xea\xb0\x80\xec\xa0\xb8\xec\x98\xa8\xeb\x8b\xa4 (\xec\xa4\x84\xeb\xa1\x9c \xea\xb5\xac\xeb\xb6\x84)\r\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\r\n\r\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-1-4.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\nwith open('result-2-3-1-4.txt', 'w', encoding = 'utf-8') as f:\t\t# \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4 \r\n\tfor word in words:\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\x8b\xa8\xec\x96\xb4\xec\x99\x80 \xea\xb7\xb8 \xeb\x9c\xbb\xec\x9d\x84 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\t\turl = 'http://dic.daum.net/search.do?q=' + word \t\t\t# \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xeb\xa0\xa4\xeb\x8a\x94 url \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0\r\n\t\tweb = urlopen(url)\t\t\t\t\t\t\t\t\t\t\t# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\t\r\n\t\tweb_page = BeautifulSoup(web, 'html.parser')\t\t\t\t# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\n\t\tbox = web_page.find('div', {'class': 'search_cleanword'}).find('span',{'class': 'txt_emph1'})\t\t# \xeb\x8b\xa8\xec\x96\xb4\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\r\n\t\tbox2 = web_page.find('ul', {'class': 'list_search'})\t\t\t\t\t\t\t\t\t\t\t\t# \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\x9c\xbb\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\r\n\t\t# get_text \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\xb6\x94\xec\xb6\x9c\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\t\t# write \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x93\xb4\xeb\x8b\xa4\t\t\r\n\t\tf.write(box.get_text() + '\\n')\r\n\t\tf.write(box2.get_text() + '\\n')\r\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4 """
Session2/source code/2-3/2-3-2-1.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup \r\nfrom urllib.request import urlopen\r\n\r\n# \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xeb\xa0\xa4\xeb\x8a\x94 url \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0 - \xec\xbd\x94\xec\x9d\xb8\xeb\xa7\x88\xec\xbc\x93\xec\xba\xa1 \xeb\x8b\xb7\xec\xbb\xb4\r\nurl = 'https://coinmarketcap.com/'\r\n\r\n# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\nweb = urlopen(url)\r\n\r\n# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\nweb_page = BeautifulSoup(web, 'html.parser')\r\n\r\n# \xeb\xb9\x84\xed\x8a\xb8\xec\xbd\x94\xec\x9d\xb8\xea\xb3\xbc \xea\xb4\x80\xeb\xa0\xa8\xeb\x90\x9c \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xec\x9d\x84 \xec\xb0\xbe\xec\x95\x84 bit \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\ntable = web_page.find('table', {'id': 'currencies'})\t# 1\xec\x9c\x84\xeb\xb6\x80\xed\x84\xb0 100\xec\x9c\x84\xea\xb9\x8c\xec\xa7\x80\xec\x9d\x98 cryptocurrency \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\nbit = table.find('tr', {'id': 'id-bitcoin'})\t\t\t# \xeb\xb9\x84\xed\x8a\xb8\xec\xbd\x94\xec\x9d\xb8 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xed\x96\x89(\xec\xb2\xab\xec\xa7\xb8 \xed\x96\x89)\xec\x9d\x98 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\n\r\n# \xeb\xb9\x84\xed\x8a\xb8\xec\xbd\x94\xec\x9d\xb8 \xea\xb4\x80\xeb\xa0\xa8\xeb\x90\x9c \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\ncoinName = bit.find('td', {'class': 'no-wrap currency-name'})\t\t\t\r\nprint('Coin Name: ', coinName.get_text().strip())\t\t\t\t\t\t\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xec\x9d\xb4\xeb\xa6\x84('Bitcoin')\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nmarketCap = bit.find('td', {'class': 'no-wrap market-cap text-right'})\r\nprint('Market Cap: ', marketCap.get_text().strip())\t\t\t\t\t\t\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xec\x8b\x9c\xea\xb0\x80\xec\xb4\x9d\xec\x95\xa1(Market cap)\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nprice = bit.find('a', {'class': 'price'})\t\t\t\t\t\t\t\t\t\r\nprint('Price: ', price.get_text().strip())\t\t\t\t\t\t\t\t\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xea\xb0\x80\xea\xb2\xa9(price)\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nvolume = bit.find('a', {'class': 'volume'})\r\nprint('Volume: ', volume.get_text().strip())\t\t\t\t\t\t\t\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 24\xec\x8b\x9c\xea\xb0\x84 \xeb\xb3\xbc\xeb\xa5\xa8(volume)\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\r\n"""
Session2/source code/2-3/2-3-2-2.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup \r\nfrom urllib.request import urlopen\r\n\r\n# \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xeb\xa0\xa4\xeb\x8a\x94 url \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0 - \xec\xbd\x94\xec\x9d\xb8\xeb\xa7\x88\xec\xbc\x93\xec\xba\xa1 \xeb\x8b\xb7\xec\xbb\xb4\r\nurl = 'https://coinmarketcap.com/'\r\n\r\n# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\nweb = urlopen(url)\r\n\r\n# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\nweb_page = BeautifulSoup(web, 'html.parser')\r\n\r\n# \xec\xbd\x94\xec\x9d\xb8\xea\xb3\xbc \xea\xb4\x80\xeb\xa0\xa8\xeb\x90\x9c \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\ntable = web_page.find('table', {'id': 'currencies'})\t\t\t\t\t\t\t# 1\xec\x9c\x84\xeb\xb6\x80\xed\x84\xb0 100\xec\x9c\x84\xea\xb9\x8c\xec\xa7\x80\xec\x9d\x98 cryptocurrency \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\ncoinNames = table.findAll('td', {'class': 'no-wrap currency-name'})\t\t\t\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xec\x9d\xb4\xeb\xa6\x84(name)\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xeb\x93\xa4\xec\x9d\x84 \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nmarketCaps = table.findAll('td', {'class': 'no-wrap market-cap text-right'})\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xec\x8b\x9c\xea\xb0\x80\xec\xb4\x9d\xec\x95\xa1(market cap)\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xeb\x93\xa4\xec\x9d\x84 \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nprices = table.findAll('a', {'class': 'price'})\t\t\t\t\t\t\t\t\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xea\xb0\x80\xea\xb2\xa9(price)\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xeb\x93\xa4\xec\x9d\x84 \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nvolumes = table.findAll('a', {'class': 'volume'})\t\t\t\t\t\t\t\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 24\xec\x8b\x9c\xea\xb0\x84 \xeb\xb3\xbc\xeb\xa5\xa8(volume)\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xeb\x93\xa4\xec\x9d\x84 \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\r\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-2-2.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\nwith open('result-2-3-2-2.txt', 'w', encoding = 'utf-8') as f:\t\t\t\t\t# \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\n\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xec\x8b\x9c\xea\xb0\x80\xec\xb4\x9d\xec\x95\xa1 1\xec\x9c\x84\xeb\xb6\x80\xed\x84\xb0 100\xec\x9c\x84\xea\xb9\x8c\xec\xa7\x80\xec\x9d\x98 \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xec\xa0\x95\xeb\xb3\xb4\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\tfor i in range(100):\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8 \xec\x9d\xb8\xeb\x8d\xb1\xec\x8a\xa4 \xec\xa0\x91\xea\xb7\xbc\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 0\xeb\xb6\x80\xed\x84\xb0 100\xea\xb9\x8c\xec\xa7\x80 iterate \xed\x95\x9c\xeb\x8b\xa4\r\n\t\t# \xed\x95\x98\xeb\x82\x98\xec\x9d\x98 \xec\xbd\x94\xec\x9d\xb8\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c \xec\xa0\x95\xeb\xb3\xb4\xeb\xa5\xbc row\xec\x97\x90 \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\t\t# \xec\xa4\x91\xea\xb0\x84\xec\xa4\x91\xea\xb0\x84\xec\x97\x90 '\\t'\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xec\x97\xac \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xea\xb5\xac\xeb\xb6\x84\xed\x95\x9c\xeb\x8b\xa4\r\n\t\trow = coinNames[i].get_text().strip() + '\\t' + marketCaps[i].get_text().strip() + '\\t' \\\r\n\t\t\t+ prices[i].get_text().strip() + '\\t' + volumes[i].get_text().strip() + '\\n'\r\n\t\tf.write(row)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# row\xeb\xa5\xbc \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xec\x93\xb4\xeb\x8b\xa4\r\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4"""
Session2/source code/2-3/2-3-2-3.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup \r\nfrom urllib.request import urlopen\r\n\r\n# \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xeb\xa0\xa4\xeb\x8a\x94 url \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0 - \xec\xbd\x94\xec\x9d\xb8\xeb\xa7\x88\xec\xbc\x93\xec\xba\xa1 \xeb\x8b\xb7\xec\xbb\xb4\r\nurl = 'https://coinmarketcap.com/'\r\n\r\n# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\nweb = urlopen(url)\r\n\r\n# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\nweb_page = BeautifulSoup(web, 'html.parser')\r\n\r\n# \xec\xbd\x94\xec\x9d\xb8\xea\xb3\xbc \xea\xb4\x80\xeb\xa0\xa8\xeb\x90\x9c \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\ntable = web_page.find('table', {'id': 'currencies'})\t\t\t\t\t\t\t# 1\xec\x9c\x84\xeb\xb6\x80\xed\x84\xb0 100\xec\x9c\x84\xea\xb9\x8c\xec\xa7\x80\xec\x9d\x98 cryptocurrency \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\ncoinNames = table.findAll('td', {'class': 'no-wrap currency-name'})\t\t\t\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xec\x9d\xb4\xeb\xa6\x84(name)\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xeb\x93\xa4\xec\x9d\x84 \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nmarketCaps = table.findAll('td', {'class': 'no-wrap market-cap text-right'})\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xec\x8b\x9c\xea\xb0\x80\xec\xb4\x9d\xec\x95\xa1(market cap)\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xeb\x93\xa4\xec\x9d\x84 \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nprices = table.findAll('a', {'class': 'price'})\t\t\t\t\t\t\t\t\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xea\xb0\x80\xea\xb2\xa9(price)\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xeb\x93\xa4\xec\x9d\x84 \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nvolumes = table.findAll('a', {'class': 'volume'})\t\t\t\t\t\t\t\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 24\xec\x8b\x9c\xea\xb0\x84 \xeb\xb3\xbc\xeb\xa5\xa8(volume)\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xeb\x93\xa4\xec\x9d\x84 \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\r\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-2-3.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\nwith open('result-2-3-2-3.txt', 'w') as f:\t\t\t\t\t\t\t\t\t\t# \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\n# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xec\x8b\x9c\xea\xb0\x80\xec\xb4\x9d\xec\x95\xa1 1\xec\x9c\x84\xeb\xb6\x80\xed\x84\xb0 100\xec\x9c\x84\xea\xb9\x8c\xec\xa7\x80\xec\x9d\x98 \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4\r\n\tfor i in range(100):\r\n\t\tprice = float(prices[i].get_text().strip().replace('$','').replace(',',''))\t\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xea\xb0\x80\xea\xb2\xa9\xec\x9d\x84 \xea\xb0\x80\xec\xa0\xb8\xec\x98\xa8\xeb\x8b\xa4(float \xed\x83\x80\xec\x9e\x85\xec\x9c\xbc\xeb\xa1\x9c)\r\n\t\tvolume = float(volumes[i].get_text().strip().replace('$','').replace(',',''))\t# \xec\xbd\x94\xec\x9d\xb8\xec\x9d\x98 \xeb\xb3\xbc\xeb\xa5\xa8\xec\x9d\x84 \xea\xb0\x80\xec\xa0\xb8\xec\x98\xa8\xeb\x8b\xa4(float \xed\x83\x80\xec\x9e\x85\xec\x9c\xbc\xeb\xa1\x9c)\r\n\t\t# if\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xec\xa0\x80\xec\x9e\xa5 \xec\xa1\xb0\xea\xb1\xb4\xec\x9d\x84 \xec\xa4\x80\xeb\x8b\xa4\r\n\t\tif volume >= 1000000 and price >= 50:\t\t\t\t\t\t\t\t\t\t\t# \xeb\xb3\xbc\xeb\xa5\xa8\xec\x9d\xb4 1,000,000 \xec\x9d\xb4\xec\x83\x81\xec\x9d\xb4\xea\xb3\xa0 \xea\xb0\x80\xea\xb2\xa9\xec\x9d\xb4 50 \xec\x9d\xb4\xec\x83\x81\xec\x9d\xbc \xea\xb2\xbd\xec\x9a\xb0:\r\n\t\t\t# \xed\x95\x98\xeb\x82\x98\xec\x9d\x98 \xec\xbd\x94\xec\x9d\xb8\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c \xec\xa0\x95\xeb\xb3\xb4\xeb\xa5\xbc row\xec\x97\x90 \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\t\t\t# \xec\xa4\x91\xea\xb0\x84\xec\xa4\x91\xea\xb0\x84\xec\x97\x90 '\\t'\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xec\x97\xac \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xeb\xa5\xbc \xea\xb5\xac\xeb\xb6\x84\xed\x95\x9c\xeb\x8b\xa4\r\n\t\t\trow = coinNames[i].get_text().strip() + '\\t' + marketCaps[i].get_text().strip() + '\\t' \\\r\n\t\t\t\t+ prices[i].get_text().strip() + '\\t' + volumes[i].get_text().strip() + '\\n'\r\n\t\t\tf.write(row)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# row\xeb\xa5\xbc \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xec\x93\xb4\xeb\x8b\xa4\r\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4"""
Session2/source code/2-3/2-3-3-1.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup \r\nfrom urllib.request import urlopen\r\n\r\n# \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xeb\xa0\xa4\xeb\x8a\x94 url \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0 (IMDb - \xed\x8e\x84\xed\x94\x84 \xed\x94\xbd\xec\x85\x98)\r\nurl = 'http://www.imdb.com/title/tt0110912/?ref_=nv_sr_1'\r\n\r\n# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\nweb = urlopen(url)\r\n\r\n# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\nweb_page = BeautifulSoup(web, 'html.parser')\r\n\r\n# \xec\x98\x81\xed\x99\x94 \xec\xa0\x9c\xeb\xaa\xa9\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\ntitleBar = web_page.find('div', {'class': 'titleBar'})\t\t# \xed\x83\x80\xec\x9d\xb4\xed\x8b\x80(\xec\x98\x81\xed\x99\x94 \xec\xa0\x9c\xeb\xaa\xa9)\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xeb\xb0\x94(bar)\xeb\xa5\xbc \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\ntitle = titleBar.find('h1', {'itemprop': 'name'})\t\t\t# \xed\x83\x80\xec\x9d\xb4\xed\x8b\x80\xeb\xb0\x94\xec\x97\x90\xec\x84\x9c \xec\x98\x81\xed\x99\x94 \xec\xa0\x9c\xeb\xaa\xa9\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\nprint('Movie: ' , title.get_text())\t\t\t\t\t\t\t# get_text \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xec\x98\x81\xed\x99\x94 \xec\xa0\x9c\xeb\xaa\xa9\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\r\n# \xea\xb0\x90\xeb\x8f\x85 \xec\x9d\xb4\xeb\xa6\x84\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\ndirector = web_page.find('span', {'itemprop': 'director'})\t# \xea\xb0\x90\xeb\x8f\x85 \xec\x9d\xb4\xeb\xa6\x84\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\nprint('Director: ', director.get_text().strip())\t\t\t# get_text \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xea\xb0\x90\xeb\x8f\x85 \xec\x9d\xb4\xeb\xa6\x84\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\r\n# \xec\xb6\x9c\xec\x97\xb0 \xeb\xb0\xb0\xec\x9a\xb0 \xec\x9d\xb4\xeb\xa6\x84(\xeb\x93\xa4)\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\ntable = web_page.find('table', {'class': 'cast_list'})\t\t# \xec\xba\x90\xec\x8a\xa4\xed\x8c\x85 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\nfind = table.findAll('span', {'class': 'itemprop', 'itemprop': 'name'})\t\t# \xeb\xb0\xb0\xec\x9a\xb0 \xec\x9d\xb4\xeb\xa6\x84\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xeb\x93\xa4\xec\x9d\x84 \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nprint('Cast: ')\r\n# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xeb\xb0\xb0\xec\x9a\xb0\xec\x9d\x98 \xec\x9d\xb4\xeb\xa6\x84\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nfor i in find:\r\n\tprint(i.get_text())"""
Session2/source code/2-3/2-3-3-2.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup \r\nfrom urllib.request import urlopen\r\n\r\n# \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xeb\xa0\xa4\xeb\x8a\x94 url \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0 - \xec\x84\xb8 \xea\xb0\x9c\xec\x9d\x98 url\xec\x9d\xb4 \xec\x9e\x88\xec\x9c\xbc\xeb\xaf\x80\xeb\xa1\x9c \xec\x9d\xb4\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nurls = ['http://www.imdb.com/title/tt0110912/?ref_=nv_sr_1', \\\r\n\t\t'http://www.imdb.com/title/tt0109830/?ref_=tt_rec_tt', \\\r\n\t\t'http://www.imdb.com/title/tt0468569/?ref_=nv_sr_3']\r\n\r\ninfo = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xec\x98\x81\xed\x99\x94\xec\x9d\x98 \xec\xa0\x95\xeb\xb3\xb4\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\n\r\n# \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 url\xec\x97\x90 \xec\xa0\x91\xec\x86\x8d\xed\x95\x98\xeb\xa9\xb4\xec\x84\x9c \xec\x98\x81\xed\x99\x94 \xec\xa0\x95\xeb\xb3\xb4\xeb\xa5\xbc \xea\xb0\x80\xec\xa0\xb8\xec\x98\xa8\xeb\x8b\xa4\r\nfor url in urls:\r\n\tweb = urlopen(url)\t\t\t\t\t\t\t\t\t\t\t# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\n\tweb_page = BeautifulSoup(web, 'html.parser')\t\t\t\t# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\n\ttitleBar = web_page.find('div', {'class': 'titleBar'})\t\t# \xed\x83\x80\xec\x9d\xb4\xed\x8b\x80(\xec\x98\x81\xed\x99\x94 \xec\xa0\x9c\xeb\xaa\xa9)\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xeb\xb0\x94(bar)\xeb\xa5\xbc \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\n\ttitle = titleBar.find('h1', {'itemprop': 'name'})\t\t\t# \xed\x83\x80\xec\x9d\xb4\xed\x8b\x80\xeb\xb0\x94\xec\x97\x90\xec\x84\x9c \xec\x98\x81\xed\x99\x94 \xec\xa0\x9c\xeb\xaa\xa9\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\n\tdirector = web_page.find('span', {'itemprop': 'director'})\t# \xea\xb0\x90\xeb\x8f\x85 \xec\x9d\xb4\xeb\xa6\x84\xec\x9d\xb4 \xec\x9e\x88\xeb\x8a\x94 \xea\xb3\xb3\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\n\r\n\t# info \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xea\xb0\x81 \xec\x98\x81\xed\x99\x94\xec\x9d\x98 \xec\xa0\x95\xeb\xb3\xb4\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n\tinfo.append(title.get_text().strip() + '\\t' + director.get_text().strip()) \r\n\r\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-2.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\nwith open('result-2-3-3-2.txt', 'w', encoding = 'utf-8') as f:\t# \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\n\t# info \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x9d\x98 \xea\xb0\x81 \xec\x9a\x94\xec\x86\x8c\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xec\x93\xb4\xeb\x8b\xa4\r\n\tfor i in info:\r\n\t\tf.write(i + '\\n')\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xec\xa0\x95\xeb\xb3\xb4\xeb\x8a\x94 \xec\x83\x88\xeb\xa1\x9c\xec\x9a\xb4 \xec\xa4\x84('\\n')\xec\x9c\xbc\xeb\xa1\x9c \xea\xb5\xac\xeb\xb6\x84\xed\x95\x9c\xeb\x8b\xa4\r\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4"""
Session2/source code/2-3/2-3-3-3.py,0,"b'# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup\r\nfrom urllib.request import urlopen\r\n\r\n# \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xeb\xa0\xa4\xeb\x8a\x94 url \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0\r\nurl = \'http://www.imdb.com/title/tt0468569/reviews?start=0\'\r\n\r\n# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\nweb = urlopen(url)\r\n\r\n# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\nsource = BeautifulSoup(web, \'html.parser\')\r\n\r\n# \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\ntable = source.find(""div"", {""id"": ""tn15content""})\r\n\r\n# \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94 \xeb\x82\xb4\xec\x9d\x98 \xeb\xaa\xa8\xeb\x93\xa0 paragraph(\'p\')\xeb\xa5\xbc \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\npars = table.findAll(\'p\')\r\n\r\n# \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 paragraph\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nfor par in pars:\r\n\t# \xeb\xa6\xac\xeb\xb7\xb0\xec\x9d\xbc \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\xa7\x8c \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 if \xec\xa1\xb0\xea\xb1\xb4\xeb\xac\xb8\xec\x9d\x84 \xed\x99\x9c\xec\x9a\xa9\xed\x95\x9c\xeb\x8b\xa4\r\n    if (\'This review may contain spoilers\' not in par) and (\'Add another review\' not in par):\r\n        print(par.get_text().replace(\'\\n\', \' \').replace(\'\\r\', \' \'))\r\n        break\r\n'"
Session2/source code/2-3/2-3-3-4.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup\r\nfrom urllib.request import urlopen\r\n\r\n# \xec\x8b\x9c\xec\x9e\x91 URL\xec\x9d\x84 \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nbaseURL = 'http://www.imdb.com/title/tt0468569/reviews?start='\r\n\r\n# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1('0'\xec\x9d\x84 \xeb\x8d\x94\xed\x95\xb4 \xec\xb2\xab \xeb\xb2\x88\xec\xa7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xb6\x80\xed\x84\xb0 \xec\x8b\x9c\xec\x9e\x91\xed\x95\xa8\xec\x9d\x84 \xec\x95\x8c\xeb\xa0\xa4\xec\xa4\x80\xeb\x8b\xa4)\r\nweb = urlopen(baseURL + '0')\r\n\r\n# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\nsource = BeautifulSoup(web, 'html.parser')\r\n\r\n# \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\ntable = source.find('div', {'id': 'tn15content'})\r\n\r\npage_no = 10                    # \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xec\xb4\x9d \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\r\nreviewList = []                 # \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xeb\x8b\xb4\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\nstatus = True                   # while\xeb\xac\xb8\xec\x9d\x84 \xed\x83\x88\xec\xb6\x9c\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xec\xa1\xb0\xea\xb1\xb4\xec\x9d\x84 \xec\x84\xa4\xec\xa0\x95\xed\x95\x98\xeb\x8a\x94 status \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\r\ni = 0                           # \xed\x98\x84\xec\x9e\xac \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c \xeb\xa6\xac\xeb\xb7\xb0 \xec\x88\x98\xeb\xa5\xbc \xea\xb8\xb0\xeb\xa1\x9d\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c i \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\r\n\r\n# while\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 10 \xeb\xb2\x88\xec\xa7\xb8 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xea\xb9\x8c\xec\xa7\x80\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c\xeb\x8b\xa4\r\nwhile status:\r\n    url = baseURL + str(i)      # \xec\x8b\x9c\xec\x9e\x91 URL\xec\x97\x90 i\xeb\xa5\xbc \xeb\x8d\x94\xed\x95\xb4 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n    web = urlopen(url)          # urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1 \r\n    source = BeautifulSoup(web, 'html.parser')          # BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\n    table = source.find('div', {'id': 'tn15content'})   # \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\n    \r\n    pars = table.findAll('p')                           # \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94 \xeb\x82\xb4\xec\x9d\x98 \xeb\xaa\xa8\xeb\x93\xa0 paragraph('p')\xeb\xa5\xbc \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4   \r\n\r\n    # \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 paragraph\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n    for par in pars:\r\n        text = par.get_text().replace('\\n', ' ').replace('\\r', ' ')\r\n        # \xeb\xa6\xac\xeb\xb7\xb0\xec\x9d\xbc \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\xa7\x8c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 if \xec\xa1\xb0\xea\xb1\xb4\xeb\xac\xb8\xec\x9d\x84 \xed\x99\x9c\xec\x9a\xa9\xed\x95\x9c\xeb\x8b\xa4\r\n        if ('This review may contain spoilers' not in text) and ('Add another review' not in text):\r\n            reviewList.append(text)\r\n    i += 10                                         # \xed\x95\x98\xeb\x82\x98\xec\x9d\x98 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xeb\xa5\xbc \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\xa0\xeb\x95\x8c\xeb\xa7\x88\xeb\x8b\xa4 i\xeb\xa5\xbc 10\xec\x94\xa9 \xec\xa6\x9d\xea\xb0\x80\xec\x8b\x9c\xed\x82\xa8\xeb\x8b\xa4\r\n    if i >= page_no * 10:                           # \xeb\xa7\x8c\xec\x95\xbd \xed\x98\x84\xec\x9e\xac \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80 \xea\xb0\x9c\xec\x88\x98\xea\xb0\x80 10\xec\x9d\x84 \xeb\x84\x98\xec\x96\xb4\xea\xb0\x80\xeb\xa9\xb4:\r\n        status = False                              # while\xeb\xac\xb8\xec\x9d\x84 \xed\x83\x88\xec\xb6\x9c\xed\x95\x9c\xeb\x8b\xa4\r\n\r\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-4.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\nwith open('result-2-3-3-4.txt', 'w', encoding = 'utf-8') as f:        # \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\n    for review in reviewList:                                       # for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 reviewList\xec\x9d\x98 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xec\x93\xb4\xeb\x8b\xa4\r\n        f.write(review + '\\n')\r\n    f.close()                                                       # \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\r\n\r\n """
Session2/source code/2-3/2-3-3-5-inception.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup\r\nfrom urllib.request import urlopen\r\n\r\n# \xec\x8b\x9c\xec\x9e\x91 URL\xec\x9d\x84 \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nbaseURL = 'http://www.imdb.com/title/tt1375666/reviews?start='\r\n\r\n# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1('0'\xec\x9d\x84 \xeb\x8d\x94\xed\x95\xb4 \xec\xb2\xab \xeb\xb2\x88\xec\xa7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xb6\x80\xed\x84\xb0 \xec\x8b\x9c\xec\x9e\x91\xed\x95\xa8\xec\x9d\x84 \xec\x95\x8c\xeb\xa0\xa4\xec\xa4\x80\xeb\x8b\xa4)\r\nweb = urlopen(baseURL + '0')\r\n\r\n# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\nsource = BeautifulSoup(web, 'html.parser')\r\n\r\n# \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\ntable = source.find('div', {'id': 'tn15content'})\r\n\r\npage_no = 10                    # \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xec\xb4\x9d \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\r\nreviewList = []                 # \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xeb\x8b\xb4\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\nstatus = True                   # while\xeb\xac\xb8\xec\x9d\x84 \xed\x83\x88\xec\xb6\x9c\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xec\xa1\xb0\xea\xb1\xb4\xec\x9d\x84 \xec\x84\xa4\xec\xa0\x95\xed\x95\x98\xeb\x8a\x94 status \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\r\ni = 0                           # \xed\x98\x84\xec\x9e\xac \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c \xeb\xa6\xac\xeb\xb7\xb0 \xec\x88\x98\xeb\xa5\xbc \xea\xb8\xb0\xeb\xa1\x9d\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c i \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\r\n\r\n# while\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 10 \xeb\xb2\x88\xec\xa7\xb8 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xea\xb9\x8c\xec\xa7\x80\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c\xeb\x8b\xa4\r\nwhile status:\r\n    url = baseURL + str(i)      # \xec\x8b\x9c\xec\x9e\x91 URL\xec\x97\x90 i\xeb\xa5\xbc \xeb\x8d\x94\xed\x95\xb4 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n    web = urlopen(url)          # urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1 \r\n    source = BeautifulSoup(web, 'html.parser')          # BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\n    table = source.find('div', {'id': 'tn15content'})   # \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\n    \r\n    pars = table.findAll('p')                           # \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94 \xeb\x82\xb4\xec\x9d\x98 \xeb\xaa\xa8\xeb\x93\xa0 paragraph('p')\xeb\xa5\xbc \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4   \r\n\r\n    # \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 paragraph\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n    for par in pars:\r\n        text = par.get_text().replace('\\n', ' ').replace('\\r', ' ')\r\n        # \xeb\xa6\xac\xeb\xb7\xb0\xec\x9d\xbc \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\xa7\x8c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 if \xec\xa1\xb0\xea\xb1\xb4\xeb\xac\xb8\xec\x9d\x84 \xed\x99\x9c\xec\x9a\xa9\xed\x95\x9c\xeb\x8b\xa4\r\n        if ('This review may contain spoilers' not in text) and ('Add another review' not in text):\r\n            reviewList.append(text)\r\n    i += 10                                         # \xed\x95\x98\xeb\x82\x98\xec\x9d\x98 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xeb\xa5\xbc \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\xa0\xeb\x95\x8c\xeb\xa7\x88\xeb\x8b\xa4 i\xeb\xa5\xbc 10\xec\x94\xa9 \xec\xa6\x9d\xea\xb0\x80\xec\x8b\x9c\xed\x82\xa8\xeb\x8b\xa4\r\n    if i >= page_no * 10:                           # \xeb\xa7\x8c\xec\x95\xbd \xed\x98\x84\xec\x9e\xac \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80 \xea\xb0\x9c\xec\x88\x98\xea\xb0\x80 10\xec\x9d\x84 \xeb\x84\x98\xec\x96\xb4\xea\xb0\x80\xeb\xa9\xb4:\r\n        status = False                              # while\xeb\xac\xb8\xec\x9d\x84 \xed\x83\x88\xec\xb6\x9c\xed\x95\x9c\xeb\x8b\xa4\r\n\r\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-5-inception.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\nwith open('result-2-3-3-5-inception.txt', 'w', encoding = 'utf-8') as f:          # \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\n    for review in reviewList:                                                   # for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 reviewList\xec\x9d\x98 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xec\x93\xb4\xeb\x8b\xa4\r\n        f.write(review + '\\n')\r\n    f.close()                                                                   # \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\r\n\r\n"""
Session2/source code/2-3/2-3-3-5-old_boy.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup\r\nfrom urllib.request import urlopen\r\n\r\n# \xec\x8b\x9c\xec\x9e\x91 URL\xec\x9d\x84 \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nbaseURL = 'http://www.imdb.com/title/tt0364569/reviews?start='\r\n\r\n# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1('0'\xec\x9d\x84 \xeb\x8d\x94\xed\x95\xb4 \xec\xb2\xab \xeb\xb2\x88\xec\xa7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xb6\x80\xed\x84\xb0 \xec\x8b\x9c\xec\x9e\x91\xed\x95\xa8\xec\x9d\x84 \xec\x95\x8c\xeb\xa0\xa4\xec\xa4\x80\xeb\x8b\xa4)\r\nweb = urlopen(baseURL + '0')\r\n\r\n# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\nsource = BeautifulSoup(web, 'html.parser')\r\n\r\n# \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\ntable = source.find('div', {'id': 'tn15content'})\r\n\r\npage_no = 10                    # \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xec\xb4\x9d \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\r\nreviewList = []                 # \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xeb\x8b\xb4\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\nstatus = True                   # while\xeb\xac\xb8\xec\x9d\x84 \xed\x83\x88\xec\xb6\x9c\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xec\xa1\xb0\xea\xb1\xb4\xec\x9d\x84 \xec\x84\xa4\xec\xa0\x95\xed\x95\x98\xeb\x8a\x94 status \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\r\ni = 0                           # \xed\x98\x84\xec\x9e\xac \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c \xeb\xa6\xac\xeb\xb7\xb0 \xec\x88\x98\xeb\xa5\xbc \xea\xb8\xb0\xeb\xa1\x9d\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c i \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\r\n\r\n# while\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 10 \xeb\xb2\x88\xec\xa7\xb8 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xea\xb9\x8c\xec\xa7\x80\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c\xeb\x8b\xa4\r\nwhile status:\r\n    url = baseURL + str(i)      # \xec\x8b\x9c\xec\x9e\x91 URL\xec\x97\x90 i\xeb\xa5\xbc \xeb\x8d\x94\xed\x95\xb4 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n    web = urlopen(url)          # urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1 \r\n    source = BeautifulSoup(web, 'html.parser')          # BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\n    table = source.find('div', {'id': 'tn15content'})   # \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\n    \r\n    pars = table.findAll('p')                           # \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94 \xeb\x82\xb4\xec\x9d\x98 \xeb\xaa\xa8\xeb\x93\xa0 paragraph('p')\xeb\xa5\xbc \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4   \r\n\r\n    # \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 paragraph\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n    for par in pars:\r\n        text = par.get_text().replace('\\n', ' ').replace('\\r', ' ')\r\n        # \xeb\xa6\xac\xeb\xb7\xb0\xec\x9d\xbc \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\xa7\x8c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 if \xec\xa1\xb0\xea\xb1\xb4\xeb\xac\xb8\xec\x9d\x84 \xed\x99\x9c\xec\x9a\xa9\xed\x95\x9c\xeb\x8b\xa4\r\n        if ('This review may contain spoilers' not in text) and ('Add another review' not in text):\r\n            reviewList.append(text)\r\n    i += 10                                         # \xed\x95\x98\xeb\x82\x98\xec\x9d\x98 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xeb\xa5\xbc \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\xa0\xeb\x95\x8c\xeb\xa7\x88\xeb\x8b\xa4 i\xeb\xa5\xbc 10\xec\x94\xa9 \xec\xa6\x9d\xea\xb0\x80\xec\x8b\x9c\xed\x82\xa8\xeb\x8b\xa4\r\n    if i >= page_no * 10:                           # \xeb\xa7\x8c\xec\x95\xbd \xed\x98\x84\xec\x9e\xac \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80 \xea\xb0\x9c\xec\x88\x98\xea\xb0\x80 10\xec\x9d\x84 \xeb\x84\x98\xec\x96\xb4\xea\xb0\x80\xeb\xa9\xb4:\r\n        status = False                              # while\xeb\xac\xb8\xec\x9d\x84 \xed\x83\x88\xec\xb6\x9c\xed\x95\x9c\xeb\x8b\xa4\r\n\r\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-5-old_boy.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\nwith open('result-2-3-3-5-old_boy.txt', 'w', encoding = 'utf-8') as f:        # \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\n    for review in reviewList:                                               # for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 reviewList\xec\x9d\x98 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xec\x93\xb4\xeb\x8b\xa4\r\n        f.write(review + '\\n')\r\n    f.close()                                                               # \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\r\n\r\n\r\n"""
Session2/source code/2-3/2-3-3-5-whiplash.py,0,"b""# \xec\x9b\xb9 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xec\x97\x90 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa4\xea\xb8\xb0\r\nfrom bs4 import BeautifulSoup\r\nfrom urllib.request import urlopen\r\n\r\n# \xec\x8b\x9c\xec\x9e\x91 URL\xec\x9d\x84 \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\nbaseURL = 'http://www.imdb.com/title/tt2582802/reviews?start='\r\n\r\n# urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1('0'\xec\x9d\x84 \xeb\x8d\x94\xed\x95\xb4 \xec\xb2\xab \xeb\xb2\x88\xec\xa7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xb6\x80\xed\x84\xb0 \xec\x8b\x9c\xec\x9e\x91\xed\x95\xa8\xec\x9d\x84 \xec\x95\x8c\xeb\xa0\xa4\xec\xa4\x80\xeb\x8b\xa4)\r\nweb = urlopen(baseURL + '0')\r\n\r\n# BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\nsource = BeautifulSoup(web, 'html.parser')\r\n\r\n# \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\ntable = source.find('div', {'id': 'tn15content'})\r\n    \r\npage_no = 10                    # \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xec\xb4\x9d \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\r\nreviewList = []                 # \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xeb\x8b\xb4\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\r\nstatus = True                   # while\xeb\xac\xb8\xec\x9d\x84 \xed\x83\x88\xec\xb6\x9c\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xec\xa1\xb0\xea\xb1\xb4\xec\x9d\x84 \xec\x84\xa4\xec\xa0\x95\xed\x95\x98\xeb\x8a\x94 status \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\r\ni = 0                           # \xed\x98\x84\xec\x9e\xac \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c \xeb\xa6\xac\xeb\xb7\xb0 \xec\x88\x98\xeb\xa5\xbc \xea\xb8\xb0\xeb\xa1\x9d\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c i \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\r\n\r\n# while\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 10 \xeb\xb2\x88\xec\xa7\xb8 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xea\xb9\x8c\xec\xa7\x80\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c\xeb\x8b\xa4\r\nwhile status:\r\n    url = baseURL + str(i)      # \xec\x8b\x9c\xec\x9e\x91 URL\xec\x97\x90 i\xeb\xa5\xbc \xeb\x8d\x94\xed\x95\xb4 \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xeb\xa5\xbc \xec\x9e\x85\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n    web = urlopen(url)          # urlopen \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 web \xeb\xb3\x80\xec\x88\x98\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1 \r\n    source = BeautifulSoup(web, 'html.parser')          # BeautifulSoup\xec\x9c\xbc\xeb\xa1\x9c web \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x83\x81\xec\x9d\x98 HTML \xea\xb5\xac\xec\xa1\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x8b\xb1\r\n    table = source.find('div', {'id': 'tn15content'})   # \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94\xec\x9d\x84 \xec\xb0\xbe\xeb\x8a\x94\xeb\x8b\xa4\r\n    \r\n    pars = table.findAll('p')                           # \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94 \xeb\x82\xb4\xec\x9d\x98 \xeb\xaa\xa8\xeb\x93\xa0 paragraph('p')\xeb\xa5\xbc \xec\xb0\xbe\xec\x95\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4   \r\n\r\n    # \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 paragraph\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\r\n    for par in pars:\r\n        text = par.get_text().replace('\\n', ' ').replace('\\r', ' ')\r\n        # \xeb\xa6\xac\xeb\xb7\xb0\xec\x9d\xbc \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\xa7\x8c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 if \xec\xa1\xb0\xea\xb1\xb4\xeb\xac\xb8\xec\x9d\x84 \xed\x99\x9c\xec\x9a\xa9\xed\x95\x9c\xeb\x8b\xa4\r\n        if ('This review may contain spoilers' not in text) and ('Add another review' not in text):\r\n            reviewList.append(text)\r\n    i += 10                                         # \xed\x95\x98\xeb\x82\x98\xec\x9d\x98 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xeb\xa5\xbc \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\xa0\xeb\x95\x8c\xeb\xa7\x88\xeb\x8b\xa4 i\xeb\xa5\xbc 10\xec\x94\xa9 \xec\xa6\x9d\xea\xb0\x80\xec\x8b\x9c\xed\x82\xa8\xeb\x8b\xa4\r\n    if i >= page_no * 10:                           # \xeb\xa7\x8c\xec\x95\xbd \xed\x98\x84\xec\x9e\xac \xed\x81\xac\xeb\xa1\xa4\xeb\xa7\x81\xed\x95\x9c \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80 \xea\xb0\x9c\xec\x88\x98\xea\xb0\x80 10\xec\x9d\x84 \xeb\x84\x98\xec\x96\xb4\xea\xb0\x80\xeb\xa9\xb4:\r\n        status = False                              # while\xeb\xac\xb8\xec\x9d\x84 \xed\x83\x88\xec\xb6\x9c\xed\x95\x9c\xeb\x8b\xa4\r\n\r\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-5-whiplash.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\nwith open('result-2-3-3-5-whiplash.txt', 'w', encoding = 'utf-8') as f:       # \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\r\n    for review in reviewList:                                               # for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 reviewList\xec\x9d\x98 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xec\x93\xb4\xeb\x8b\xa4\r\n        f.write(review + '\\n')\r\n    f.close()                                                               # \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\r\n\r\n"""
Session2/source code/2-4/2-4-1-1.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n\n# \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 String \xeb\xb3\x80\xec\x88\x98\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nsent1 = 'My only regret in life is that I did not drink more wine.'\nsent2 = 'I drink to make other people more interesting.'\nsent3 = 'An intelligent man is sometimes forced to be drunk to spend time with his fools.'\n\n# \xea\xb0\x81 \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xed\x86\xa0\xed\x81\xb0\xed\x99\x94\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint('Tokens of Sentence 1:')\nprint(nltk.word_tokenize(sent1))\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xed\x86\xa0\xed\x81\xb0\xed\x99\x94\xed\x95\xb4 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4 \nprint('Tokens of Sentence 2:')\nprint(nltk.word_tokenize(sent2))\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xed\x86\xa0\xed\x81\xb0\xed\x99\x94\xed\x95\xb4 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4 \nprint('Tokens of Sentence 3:')\nprint(nltk.word_tokenize(sent3))\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xed\x86\xa0\xed\x81\xb0\xed\x99\x94\xed\x95\xb4 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4 \n"""
Session2/source code/2-4/2-4-1-2.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n\n# \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 String \xeb\xb3\x80\xec\x88\x98\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nsent1 = 'My only regret in life is that I did not drink more wine.'\nsent2 = 'I drink to make other people more interesting.'\nsent3 = 'An intelligent man is sometimes forced to be drunk to spend time with his fools.'\n\n# \xea\xb0\x81 \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xed\x86\xa0\xed\x81\xb0\xed\x99\x94\xed\x95\x9c \xed\x9b\x84 \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xec\x9d\x84 \xed\x95\xb4 \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint('POS tagging Sentence 1:')\ntokens1 = nltk.word_tokenize(sent1)\t\t\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xed\x86\xa0\xed\x81\xb0\xed\x99\x94\xed\x95\x9c\xeb\x8b\xa4\nprint(nltk.pos_tag(tokens1))\t\t\t\t\t# \xed\x86\xa0\xed\x81\xb0\xed\x99\x94\xed\x95\x9c \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\xb4 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\n\nprint('POS tagging Sentence 2:')\ntokens2 = nltk.word_tokenize(sent2)\t\t\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xed\x86\xa0\xed\x81\xb0\xed\x99\x94\xed\x95\x9c\xeb\x8b\xa4\nprint(nltk.pos_tag(tokens2))\t\t\t\t\t# \xed\x86\xa0\xed\x81\xb0\xed\x99\x94\xed\x95\x9c \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\xb4 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\n\nprint('POS tagging Sentence 3:')\ntokens3 = nltk.word_tokenize(sent3)\t\t\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xed\x86\xa0\xed\x81\xb0\xed\x99\x94\xed\x95\x9c\xeb\x8b\xa4\nprint(nltk.pos_tag(tokens3))\t\t\t\t\t# \xed\x86\xa0\xed\x81\xb0\xed\x99\x94\xed\x95\x9c \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\xb4 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\n"""
Session2/source code/2-4/2-4-1-3.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n\n# nltk\xec\x9d\x98 WordNetLemmatizer\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 lemmatizer \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nlemmatizer = nltk.wordnet.WordNetLemmatizer()\n\n# \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 String \xeb\xb3\x80\xec\x88\x98\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nsent1 = 'My only regret in life is that I did not drink more wine.'\nsent2 = 'I drink to make other people more interesting.'\nsent3 = 'An intelligent man is sometimes forced to be drunk to spend time with his fools.'\n\n## \xeb\xac\xb8\xec\x9e\xa51 lemmatize\xed\x95\x98\xea\xb8\xb0:\nprint('Lemmatizing Sentence 1:')\nlemma1 = []\t\t\t\t\t\t\t\t\t\t\t# lemmatize\xeb\x90\x9c token\xeb\x93\xa4\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\ntokens1 = nltk.word_tokenize(sent1)\t\t\t\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\nfor token in tokens1:\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 token\xec\x9d\x84 lemmatize\xed\x95\x9c\xeb\x8b\xa4\n\tlemma1.append(lemmatizer.lemmatize(token))\nprint(lemma1)\t\t\t\t\t\t\t\t\t\t# lemmatize\xeb\x90\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\n\n## \xeb\xac\xb8\xec\x9e\xa52 lemmatize\xed\x95\x98\xea\xb8\xb0:\nprint('Lemmatizing Sentence 2:')\nlemma2 = []\t\t\t\t\t\t\t\t\t\t\t# lemmatize\xeb\x90\x9c token\xeb\x93\xa4\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\ntokens2 = nltk.word_tokenize(sent2)\t\t\t\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\nfor token in tokens2:\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 token\xec\x9d\x84 lemmatize\xed\x95\x9c\xeb\x8b\xa4\n\tlemma2.append(lemmatizer.lemmatize(token))\nprint(lemma2)\t\t\t\t\t\t\t\t\t\t# lemmatize\xeb\x90\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\n\n## \xeb\xac\xb8\xec\x9e\xa53 lemmatize\xed\x95\x98\xea\xb8\xb0:\nprint('Lemmatizing Sentence 3:')\nlemma3 = []\t\t\t\t\t\t\t\t\t\t\t# lemmatize\xeb\x90\x9c token\xeb\x93\xa4\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\ntokens3 = nltk.word_tokenize(sent3)\t\t\t\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\nfor token in tokens3:\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 token\xec\x9d\x84 lemmatize\xed\x95\x9c\xeb\x8b\xa4\n\tlemma3.append(lemmatizer.lemmatize(token))\nprint(lemma3)\t\t\t\t\t\t\t\t\t\t# lemmatize\xeb\x90\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\n"""
Session2/source code/2-4/2-4-1-4.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = stopwords.words('english')\n\n# \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x98\xea\xb3\xa0\xec\x9e\x90 \xed\x95\x98\xeb\x8a\x94 \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 String \xeb\xb3\x80\xec\x88\x98\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nsent1 = 'My only regret in life is that I did not drink more wine.'\nsent2 = 'I drink to make other people more interesting.'\nsent3 = 'An intelligent man is sometimes forced to be drunk to spend time with his fools.'\n\n# \xeb\xac\xb8\xec\x9e\xa5 1\xec\x9d\x98 stopwords \xec\xa0\x9c\xea\xb1\xb0\nprint('Removing stopwords in Sentence 1:')\nresult1 = []\t\t\t\t\t\t\t\t\t# stopwords\xea\xb0\x80 \xec\xa0\x9c\xea\xb1\xb0\xeb\x90\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\ntokens1 = nltk.word_tokenize(sent1)\t\t\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\nfor token in tokens1:\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 token\xec\x9d\xb4 stopwords\xec\x9d\xb8\xec\xa7\x80 \xec\x95\x84\xeb\x8b\x8c\xec\xa7\x80\xeb\xa5\xbc \xed\x8c\x90\xeb\xb3\x84\xed\x95\xb4 \xea\xb2\xb0\xea\xb3\xbc\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tif token.lower() not in stopWords:\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c token\xec\x9d\xb4 stopWords \xeb\x82\xb4\xec\x97\x90 \xec\x97\x86\xec\x9c\xbc\xeb\xa9\xb4:\n\t\tresult1.append(token)\t\t\t\t\t# token\xec\x9d\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\nprint(result1)\t\t\t\t\t\t\t\t\t# \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\n\n# \xeb\xac\xb8\xec\x9e\xa5 2\xec\x9d\x98 stopwords \xec\xa0\x9c\xea\xb1\xb0\nprint('Removing stopwords in Sentence 2:')\nresult2 = []\t\t\t\t\t\t\t\t\t# stopwords\xea\xb0\x80 \xec\xa0\x9c\xea\xb1\xb0\xeb\x90\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\ntokens2 = nltk.word_tokenize(sent2)\t\t\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\nfor token in tokens2:\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 token\xec\x9d\xb4 stopwords\xec\x9d\xb8\xec\xa7\x80 \xec\x95\x84\xeb\x8b\x8c\xec\xa7\x80\xeb\xa5\xbc \xed\x8c\x90\xeb\xb3\x84\xed\x95\xb4 \xea\xb2\xb0\xea\xb3\xbc\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tif token.lower() not in stopWords:\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c token\xec\x9d\xb4 stopWords \xeb\x82\xb4\xec\x97\x90 \xec\x97\x86\xec\x9c\xbc\xeb\xa9\xb4:\n\t\tresult2.append(token)\t\t\t\t\t# token\xec\x9d\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\nprint(result2)\t\t\t\t\t\t\t\t\t# \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\n\n# \xeb\xac\xb8\xec\x9e\xa5 3\xec\x9d\x98 stopwords \xec\xa0\x9c\xea\xb1\xb0\nprint('Removing stopwords in Sentence 3:')\nresult3 = []\t\t\t\t\t\t\t\t\t# stopwords \xec\xa0\x9c\xea\xb1\xb0\xeb\x90\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\t\t\ntokens3 = nltk.word_tokenize(sent3)\t\t\t\t# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\nfor token in tokens3:\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 token\xec\x9d\xb4 stopwords\xec\x9d\xb8\xec\xa7\x80 \xec\x95\x84\xeb\x8b\x8c\xec\xa7\x80\xeb\xa5\xbc \xed\x8c\x90\xeb\xb3\x84\xed\x95\xb4 \xea\xb2\xb0\xea\xb3\xbc\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tif token.lower() not in stopWords:\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c token\xec\x9d\xb4 stopWords \xeb\x82\xb4\xec\x97\x90 \xec\x97\x86\xec\x9c\xbc\xeb\xa9\xb4:\n\t\tresult3.append(token)\t\t\t\t\t# token\xec\x9d\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\nprint(result3)\t\t\t\t\t\t\t\t\t# \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\n"""
Session2/source code/2-4/2-4-2-1.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-4.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-4.txt', 'r', encoding = 'utf-8') as f:\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\n\nfirstReview = lines[0]\t\t\t\t\t\t\t\t\t\t\t\t# \xec\xb2\xab \xeb\xb2\x88\xec\xa7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xea\xb0\x80\xec\xa0\xb8\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\ntokens = nltk.word_tokenize(firstReview)\t\t\t\t\t\t\t# \xec\xb2\xab \xeb\xb2\x88\xec\xa7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc tokenize\xed\x95\x9c\xeb\x8b\xa4\ntags = nltk.pos_tag(tokens)\t\t\t\t\t\t\t\t\t\t\t# tokenize\xed\x95\x9c \xec\xb2\xab \xeb\xb2\x88\xec\xa7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85 \xed\x95\x9c\xeb\x8b\xa4\n\nprint('Tokens of first review: ')\t\t\t\t\t\t\t\t\t# \xec\xb2\xab \xeb\xb2\x88\xec\xa7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xec\x9d\x98 \xed\x86\xa0\xed\x81\xb0\xec\x9d\x80:\nprint(tokens)\t\t\t\t\t\t\t\t\t\t\t\t\t\t# token\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint('POS tags of first review: ')\t\t\t\t\t\t\t\t\t# \xec\xb2\xab \xeb\xb2\x88\xec\xa7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xec\x9d\x98 POS tag\xeb\x8a\x94:\nprint(tags)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb7\xb8\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-2-2.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# nltk\xec\x9d\x98 WordNetLemmatizer\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 lemmatizer \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nlemmatizer = nltk.wordnet.WordNetLemmatizer()\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = stopwords.words('english')\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-4.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-4.txt', 'r', encoding = 'utf-8') as f: \t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\nfirstReview = lines[0]\t\t\t\t\t\t\t\t\t\t\t\t# \xec\xb2\xab \xeb\xb2\x88\xec\xa7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xea\xb0\x80\xec\xa0\xb8\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\ntokens = nltk.word_tokenize(firstReview)\t\t\t\t\t\t\t# \xec\xb2\xab \xeb\xb2\x88\xec\xa7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc tokenize\xed\x95\x9c\xeb\x8b\xa4\nlemmas = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# lemmatize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\n# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 stopwords \xec\xa0\x9c\xea\xb1\xb0\xec\x99\x80 lemmatization\xec\x9d\x84 \xec\x88\x98\xed\x96\x89\xed\x95\x9c\xeb\x8b\xa4\nfor token in tokens:\t\t\t\t\t\t\t\t\t\t\t\t\n\tif token.lower() not in stopWords:\t\t\t\t\t\t\t\t# \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c token\xec\x9d\xb4 stopwords\xec\x97\x90 \xec\x97\x86\xec\x9c\xbc\xeb\xa9\xb4:\n\t\tlemmas.append(lemmatizer.lemmatize(token))\t\t\t\t\t# lemmatize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\nprint('Lemmas of the first review: ')\t\t\t\t\t\t\t\t# lemmatize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(lemmas)"""
Session2/source code/2-4/2-4-2-3.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# nltk\xec\x9d\x98 WordNetLemmatizer\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 lemmatizer \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nlemmatizer = nltk.wordnet.WordNetLemmatizer()\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = stopwords.words('english')\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-4.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-4.txt', 'r', encoding = 'utf-8') as f: \t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\n\nreviewProcessedList = []\t\t\t\t\t\t\t\t\t\t\t# \xec\xb2\x98\xeb\xa6\xac\xeb\x90\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\n# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x9c\xeb\x8b\xa4\nfor line in lines:\n\treviewProcessed = ''\t\t\t\t\t\t\t\t\t\t\t# \xed\x95\x9c \xec\xa4\x84\xec\x9d\x84 \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c String \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc tokenize\xed\x95\x9c\xeb\x8b\xa4\n\tfor token in tokens:\n\t\tif token.lower() not in stopWords:\t\t\t\t\t\t\t# \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c token\xec\x9d\xb4 stopwords\xec\x97\x90 \xec\x97\x86\xec\x9c\xbc\xeb\xa9\xb4:\n\t\t\treviewProcessed += ' ' + lemmatizer.lemmatize(token)\t# lemmatize\xed\x95\x9c \xeb\xb6\x99\xec\x9d\xb8\xeb\x8b\xa4\n\treviewProcessedList.append(reviewProcessed)\t\t\t\t\t\t# \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xea\xb0\x80 \xeb\x81\x9d\xeb\x82\x9c \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-4-2-3.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-4-2-3.txt', 'w', encoding = 'utf-8') as f:\t\t# \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tfor reviewProcessed in reviewProcessedList:\t\t\t\t\t\t# \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xec\x93\xb4\xeb\x8b\xa4\n\t\tf.write(reviewProcessed + '\\n')\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xec\xa4\x84\xeb\xb0\x94\xea\xbf\x88('\\n')\xec\x9c\xbc\xeb\xa1\x9c \xea\xb5\xac\xeb\xb6\x84\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-2-4-inception.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# nltk\xec\x9d\x98 WordNetLemmatizer\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 lemmatizer \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nlemmatizer = nltk.wordnet.WordNetLemmatizer()\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = stopwords.words('english')\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-5-inception.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-5-inception.txt', 'r', encoding = 'utf-8') as f:\t\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\n\nreviewProcessedList = []\t\t\t\t\t\t\t\t\t\t\t# \xec\xb2\x98\xeb\xa6\xac\xeb\x90\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\n# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x9c\xeb\x8b\xa4\nfor line in lines:\n\treviewProcessed = ''\t\t\t\t\t\t\t\t\t\t\t# \xed\x95\x9c \xec\xa4\x84\xec\x9d\x84 \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c String \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc tokenize\xed\x95\x9c\xeb\x8b\xa4\n\tfor token in tokens:\n\t\tif token.lower() not in stopWords:\t\t\t\t\t\t\t# \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c token\xec\x9d\xb4 stopwords\xec\x97\x90 \xec\x97\x86\xec\x9c\xbc\xeb\xa9\xb4:\n\t\t\treviewProcessed += ' ' + lemmatizer.lemmatize(token)\t# lemmatize\xed\x95\x9c \xeb\xb6\x99\xec\x9d\xb8\xeb\x8b\xa4\n\treviewProcessedList.append(reviewProcessed)\t\t\t\t\t\t# \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xea\xb0\x80 \xeb\x81\x9d\xeb\x82\x9c \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-4-2-4-inception.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-4-2-4-inception.txt', 'w', encoding = 'utf-8') as f:\t\t\t# \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tfor reviewProcessed in reviewProcessedList:\t\t\t\t\t\t# \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xec\x93\xb4\xeb\x8b\xa4\n\t\tf.write(reviewProcessed + '\\n')\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xec\xa4\x84\xeb\xb0\x94\xea\xbf\x88('\\n')\xec\x9c\xbc\xeb\xa1\x9c \xea\xb5\xac\xeb\xb6\x84\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-2-4-old_boy.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# nltk\xec\x9d\x98 WordNetLemmatizer\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 lemmatizer \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nlemmatizer = nltk.wordnet.WordNetLemmatizer()\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = stopwords.words('english')\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-5-old_boy.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-5-old_boy.txt', 'r', encoding = 'utf-8') as f:\t\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\n\nreviewProcessedList = []\t\t\t\t\t\t\t\t\t\t\t# \xec\xb2\x98\xeb\xa6\xac\xeb\x90\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\n# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x9c\xeb\x8b\xa4\nfor line in lines:\n\treviewProcessed = ''\t\t\t\t\t\t\t\t\t\t\t# \xed\x95\x9c \xec\xa4\x84\xec\x9d\x84 \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c String \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc tokenize\xed\x95\x9c\xeb\x8b\xa4\n\tfor token in tokens:\n\t\tif token.lower() not in stopWords:\t\t\t\t\t\t\t# \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c token\xec\x9d\xb4 stopwords\xec\x97\x90 \xec\x97\x86\xec\x9c\xbc\xeb\xa9\xb4:\n\t\t\treviewProcessed += ' ' + lemmatizer.lemmatize(token)\t# lemmatize\xed\x95\x9c \xeb\xb6\x99\xec\x9d\xb8\xeb\x8b\xa4\n\treviewProcessedList.append(reviewProcessed)\t\t\t\t\t\t# \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xea\xb0\x80 \xeb\x81\x9d\xeb\x82\x9c \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-4-2-4-old_boy.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-4-2-4-old_boy.txt', 'w', encoding = 'utf-8') as f:\t\t# \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tfor reviewProcessed in reviewProcessedList:\t\t\t\t\t\t# \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xec\x93\xb4\xeb\x8b\xa4\n\t\tf.write(reviewProcessed + '\\n')\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xec\xa4\x84\xeb\xb0\x94\xea\xbf\x88('\\n')\xec\x9c\xbc\xeb\xa1\x9c \xea\xb5\xac\xeb\xb6\x84\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-2-4-whiplash.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# nltk\xec\x9d\x98 WordNetLemmatizer\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 lemmatizer \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nlemmatizer = nltk.wordnet.WordNetLemmatizer()\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = stopwords.words('english')\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-5-whiplash.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-5-whiplash.txt', 'r', encoding = 'utf-8') as f:\t\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\n\nreviewProcessedList = []\t\t\t\t\t\t\t\t\t\t\t# \xec\xb2\x98\xeb\xa6\xac\xeb\x90\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\n# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x9c\xeb\x8b\xa4\nfor line in lines:\n\treviewProcessed = ''\t\t\t\t\t\t\t\t\t\t\t# \xed\x95\x9c \xec\xa4\x84\xec\x9d\x84 \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c String \xeb\xb3\x80\xec\x88\x98 \xec\x83\x9d\xec\x84\xb1\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc tokenize\xed\x95\x9c\xeb\x8b\xa4\n\tfor token in tokens:\n\t\tif token.lower() not in stopWords:\t\t\t\t\t\t\t# \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c token\xec\x9d\xb4 stopwords\xec\x97\x90 \xec\x97\x86\xec\x9c\xbc\xeb\xa9\xb4:\n\t\t\treviewProcessed += ' ' + lemmatizer.lemmatize(token)\t# lemmatize\xed\x95\x9c \xeb\xb6\x99\xec\x9d\xb8\xeb\x8b\xa4\n\treviewProcessedList.append(reviewProcessed)\t\t\t\t\t\t# \xec\xa0\x84\xec\xb2\x98\xeb\xa6\xac\xea\xb0\x80 \xeb\x81\x9d\xeb\x82\x9c \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-4-2-4-whiplash.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-4-2-4-whiplash.txt', 'w', encoding = 'utf-8') as f:\t\t# \xec\x93\xb0\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('w')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tfor reviewProcessed in reviewProcessedList:\t\t\t\t\t\t# \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x8c\x8c\xec\x9d\xbc\xec\x97\x90 \xec\x93\xb4\xeb\x8b\xa4\n\t\tf.write(reviewProcessed + '\\n')\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xec\xa4\x84\xeb\xb0\x94\xea\xbf\x88('\\n')\xec\x9c\xbc\xeb\xa1\x9c \xea\xb5\xac\xeb\xb6\x84\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-3-1.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# collections \xed\x8c\xa8\xed\x82\xa4\xec\xa7\x80\xeb\xa1\x9c\xeb\xb6\x80\xed\x84\xb0 Counter\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom collections import Counter\n\n# \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nnounList = []\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-4.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-4.txt', 'r', encoding = 'utf-8') as f:\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\t\t\n\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\ttags = nltk.pos_tag(tokens)\t\t\t\t\t\t\t\t\t\t# tokenize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\x9c\xeb\x8b\xa4\n\tfor word, tag in tags:\t\t\t\t\t\t\t\t\t\t\t# for \xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 (\xeb\x8b\xa8\xec\x96\xb4, \xed\x83\x9c\xea\xb7\xb8) \xec\x8c\x8d\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\n\t\tif tag in ['NN', 'NNS', 'NNP', 'NNPS']:\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\xaa\x85\xec\x82\xac\xec\x9d\xb4\xeb\xa9\xb4:\n\t\t\tnounList.append(word.lower())\t\t\t\t\t\t\t# \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncounts = Counter(nounList)\t\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\xaa\x85\xec\x82\xac\xec\x9d\x98 \xec\x88\xab\xec\x9e\x90\xeb\xa5\xbc \xec\x84\xbc \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(counts.most_common(10))\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x80\xec\x9e\xa5 \xed\x9d\x94\xed\x9e\x88 \xeb\x93\xb1\xec\x9e\xa5\xed\x95\x98\xeb\x8a\x94 10\xea\xb0\x9c \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-3-2.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# collections \xed\x8c\xa8\xed\x82\xa4\xec\xa7\x80\xeb\xa1\x9c\xeb\xb6\x80\xed\x84\xb0 Counter\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom collections import Counter\n\n# \xed\x98\x95\xec\x9a\xa9\xec\x82\xac\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nadjList = []\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-4.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-4.txt', 'r', encoding = 'utf-8') as f:\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\t\t\n\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\ttags = nltk.pos_tag(tokens)\t\t\t\t\t\t\t\t\t\t# tokenize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\x9c\xeb\x8b\xa4\n\tfor word, tag in tags:\t\t\t\t\t\t\t\t\t\t\t# for \xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 (\xeb\x8b\xa8\xec\x96\xb4, \xed\x83\x9c\xea\xb7\xb8) \xec\x8c\x8d\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\t\t\t\t\t\t\t\t\t\t\n\t\tif tag in ['JJ', 'JJR', 'JS']:\t\t\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xed\x98\x95\xec\x9a\xa9\xec\x82\xac\xec\x9d\xb4\xeb\xa9\xb4:\n\t\t\tadjList.append(word.lower())\t\t\t\t\t\t\t# \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncounts = Counter(adjList)\t\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xed\x98\x95\xec\x9a\xa9\xec\x82\xac\xec\x9d\x98 \xec\x88\xab\xec\x9e\x90\xeb\xa5\xbc \xec\x84\xbc \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(counts.most_common(10))\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x80\xec\x9e\xa5 \xed\x9d\x94\xed\x9e\x88 \xeb\x93\xb1\xec\x9e\xa5\xed\x95\x98\xeb\x8a\x94 10\xea\xb0\x9c \xed\x98\x95\xec\x9a\xa9\xec\x82\xac\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-3-3-inception.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# collections \xed\x8c\xa8\xed\x82\xa4\xec\xa7\x80\xeb\xa1\x9c\xeb\xb6\x80\xed\x84\xb0 Counter\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom collections import Counter\n\n# \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nnounList = []\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-5-inception.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-5-inception.txt', 'r', encoding = 'utf-8') as f:\t\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\t\n\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\ttags = nltk.pos_tag(tokens)\t\t\t\t\t\t\t\t\t\t# tokenize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\x9c\xeb\x8b\xa4\n\tfor word, tag in tags:\t\t\t\t\t\t\t\t\t\t\t# for \xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 (\xeb\x8b\xa8\xec\x96\xb4, \xed\x83\x9c\xea\xb7\xb8) \xec\x8c\x8d\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\n\t\tif tag in ['NN', 'NNS', 'NNP', 'NNPS']:\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\xaa\x85\xec\x82\xac\xec\x9d\xb4\xeb\xa9\xb4:\n\t\t\tnounList.append(word.lower())\t\t\t\t\t\t\t# \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncounts = Counter(nounList)\t\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\xaa\x85\xec\x82\xac\xec\x9d\x98 \xec\x88\xab\xec\x9e\x90\xeb\xa5\xbc \xec\x84\xbc \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(counts.most_common(10))\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x80\xec\x9e\xa5 \xed\x9d\x94\xed\x9e\x88 \xeb\x93\xb1\xec\x9e\xa5\xed\x95\x98\xeb\x8a\x94 10\xea\xb0\x9c \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-3-3-old_boy.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# collections \xed\x8c\xa8\xed\x82\xa4\xec\xa7\x80\xeb\xa1\x9c\xeb\xb6\x80\xed\x84\xb0 Counter\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom collections import Counter\n\n# \xeb\xb6\x80\xec\x82\xac\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nadvList = []\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-5-old_boy.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-5-old_boy.txt', 'r', encoding = 'utf-8') as f:\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\t\n\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\ttags = nltk.pos_tag(tokens)\t\t\t\t\t\t\t\t\t\t# tokenize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\x9c\xeb\x8b\xa4\n\tfor word, tag in tags:\t\t\t\t\t\t\t\t\t\t\t# for \xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 (\xeb\x8b\xa8\xec\x96\xb4, \xed\x83\x9c\xea\xb7\xb8) \xec\x8c\x8d\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\n\t\tif tag in ['RB', 'RBR', 'RBS']:\t\t\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\xb6\x80\xec\x82\xac\xec\x9d\xb4\xeb\xa9\xb4:\n\t\t\tadvList.append(word.lower())\t\t\t\t\t\t\t# \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncounts = Counter(advList)\t\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\xaa\x85\xec\x82\xac\xec\x9d\x98 \xec\x88\xab\xec\x9e\x90\xeb\xa5\xbc \xec\x84\xbc \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(counts.most_common(10))\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x80\xec\x9e\xa5 \xed\x9d\x94\xed\x9e\x88 \xeb\x93\xb1\xec\x9e\xa5\xed\x95\x98\xeb\x8a\x94 10\xea\xb0\x9c \xeb\xb6\x80\xec\x82\xac\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-3-3-whiplash.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# collections \xed\x8c\xa8\xed\x82\xa4\xec\xa7\x80\xeb\xa1\x9c\xeb\xb6\x80\xed\x84\xb0 Counter\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom collections import Counter\n\n# \xeb\x8f\x99\xec\x82\xac\xeb\xa5\xbc \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nverbList = []\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-5-whiplash.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-5-whiplash.txt', 'r', encoding = 'utf-8') as f:\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\t\n\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\ttags = nltk.pos_tag(tokens)\t\t\t\t\t\t\t\t\t\t# tokenize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\x9c\xeb\x8b\xa4\n\tfor word, tag in tags:\t\t\t\t\t\t\t\t\t\t\t# for \xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 (\xeb\x8b\xa8\xec\x96\xb4, \xed\x83\x9c\xea\xb7\xb8) \xec\x8c\x8d\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\t\n\t\tif tag in ['VB', 'VBD', 'VBN', 'VBP', 'VBZ']:\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\x8f\x99\xec\x82\xac\xec\x9d\xb4\xeb\xa9\xb4:\n\t\t\tverbList.append(word.lower())\t\t\t\t\t\t\t# \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncounts = Counter(verbList)\t\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\x8f\x99\xec\x82\xac\xec\x9d\x98 \xec\x88\xab\xec\x9e\x90\xeb\xa5\xbc \xec\x84\xbc \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(counts.most_common(10))\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x80\xec\x9e\xa5 \xed\x9d\x94\xed\x9e\x88 \xeb\x93\xb1\xec\x9e\xa5\xed\x95\x98\xeb\x8a\x94 10\xea\xb0\x9c \xeb\x8f\x99\xec\x82\xac\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-4-1.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = set(stopwords.words('english'))\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-4.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-4.txt', 'r', encoding = 'utf-8') as f: \t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\n\ntokens = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# token\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\tline = nltk.word_tokenize(line.lower())\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x84 \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\tfor word in line:\t\t\t\t\t\t\t\t\t\t\t\t# \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x98 \xea\xb0\x81 token\xec\x97\x90 for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\t\tif word not in stopWords:\t\t\t\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd token\xec\x9d\xb4 stopword\xea\xb0\x80 \xec\x95\x84\xeb\x8b\x88\xeb\xa9\xb4:\n\t\t\ttokens.append(word)\t\t\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncorpus = nltk.Text(tokens)\t\t\t\t\t\t\t\t\t\t\t# Text() \xea\xb0\x9d\xec\xb2\xb4\xeb\xa5\xbc corpus \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\nprint(len(corpus.tokens))\t\t\t\t\t\t\t\t\t\t\t# \xec\xa0\x84\xec\xb2\xb4 token\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(len(set(corpus.tokens)))\t\t\t\t\t\t\t\t\t\t# unique\xed\x95\x9c token\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-4-2.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = set(stopwords.words('english'))\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-4.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-4.txt', 'r', encoding = 'utf-8') as f: \t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\n\ntokens = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# token\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\tline = nltk.word_tokenize(line.lower())\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x84 \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\tfor word in line:\t\t\t\t\t\t\t\t\t\t\t\t# \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x98 \xea\xb0\x81 token\xec\x97\x90 for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\t\tif word not in stopWords:\t\t\t\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd token\xec\x9d\xb4 stopword\xea\xb0\x80 \xec\x95\x84\xeb\x8b\x88\xeb\xa9\xb4:\n\t\t\ttokens.append(word)\t\t\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncorpus = nltk.Text(tokens)\t\t\t\t\t\t\t\t\t\t\t# Text() \xea\xb0\x9d\xec\xb2\xb4\xeb\xa5\xbc corpus \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\ncorpus.plot(50)\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x80\xec\x9e\xa5 \xeb\xa7\x8e\xec\x9d\xb4 \xeb\x93\xb1\xec\x9e\xa5\xed\x95\x98\xeb\x8a\x94 50\xea\xb0\x9c \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\xb9\x88\xeb\x8f\x84\xec\x88\x98\xeb\xa5\xbc \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa1\x9c \xed\x91\x9c\xed\x98\x84\xed\x95\xb4 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-4-3.py,0,"b""# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = set(stopwords.words('english'))\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-3-3-4.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-3-3-4.txt', 'r', encoding = 'utf-8') as f: \t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\n\ntokens = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# token\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\tline = nltk.word_tokenize(line.lower())\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x84 \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\tfor word in line:\t\t\t\t\t\t\t\t\t\t\t\t# \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x98 \xea\xb0\x81 token\xec\x97\x90 for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\t\tif word not in stopWords:\t\t\t\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd token\xec\x9d\xb4 stopword\xea\xb0\x80 \xec\x95\x84\xeb\x8b\x88\xeb\xa9\xb4:\n\t\t\ttokens.append(word)\t\t\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncorpus = nltk.Text(tokens)\t\t\t\t\t\t\t\t\t\t\t# Text() \xea\xb0\x9d\xec\xb2\xb4\xeb\xa5\xbc corpus \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\n# 'Batman'\xea\xb3\xbc 'Joker'\xec\x99\x80 \xec\x9c\xa0\xec\x82\xac\xed\x95\x9c \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint('='*50)\nprint('Similar words with Batman: ')\t\t\t\t\t\ncorpus.similar('Batman')\t\t\t\t\t\t\t\t\t\t\t# 'Batman'\xea\xb3\xbc \xec\x9c\xa0\xec\x82\xac\xed\x95\x9c \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint('='*50)\nprint('Similar words with Joker: ')\ncorpus.similar('Joker')\t\t\t\t\t\t\t\t\t\t\t\t# 'Joker'\xec\x99\x80 \xec\x9c\xa0\xec\x82\xac\xed\x95\x9c \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint('='*50)"""
Session2/source code/2-4/2-4-4-4.py,0,"b'# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = set(stopwords.words(\'english\'))\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 \'result-2-3-3-4.txt\' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open(\'result-2-3-3-4.txt\', \'r\', encoding = \'utf-8\') as f: \t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d(\'r\')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 \'utf-8\'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\n\ntokens = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# token\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\tline = nltk.word_tokenize(line.lower())\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x84 \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\tfor word in line:\t\t\t\t\t\t\t\t\t\t\t\t# \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x98 \xea\xb0\x81 token\xec\x97\x90 for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\t\tif word not in stopWords:\t\t\t\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd token\xec\x9d\xb4 stopword\xea\xb0\x80 \xec\x95\x84\xeb\x8b\x88\xeb\xa9\xb4:\n\t\t\ttokens.append(word)\t\t\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncorpus = nltk.Text(tokens)\t\t\t\t\t\t\t\t\t\t\t# Text() \xea\xb0\x9d\xec\xb2\xb4\xeb\xa5\xbc corpus \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\nprint(\'Collocations for reviews of ""The Dark Knight"": \')\ncorpus.collocations()\t\t\t\t\t\t\t\t\t\t\t\t# \xeb\x8b\xa4\xed\x81\xac \xeb\x82\x98\xec\x9d\xb4\xed\x8a\xb8 \xec\x98\x81\xed\x99\x94 \xeb\xa6\xac\xeb\xb7\xb0\xec\x9d\x98 \xec\x97\xb0\xec\x96\xb4\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\n'"
Session2/source code/2-4/2-4-4-5-inception.py,0,"b'# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = set(stopwords.words(\'english\'))\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 \'result-2-3-3-5-inception.txt\' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open(\'result-2-3-3-5-inception.txt\', \'r\', encoding = \'utf-8\') as f: \t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d(\'r\')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 \'utf-8\'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\n\ntokens = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# token\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\tline = nltk.word_tokenize(line.lower())\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x84 \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\tfor word in line:\t\t\t\t\t\t\t\t\t\t\t\t# \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x98 \xea\xb0\x81 token\xec\x97\x90 for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\t\tif word not in stopWords:\t\t\t\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd token\xec\x9d\xb4 stopword\xea\xb0\x80 \xec\x95\x84\xeb\x8b\x88\xeb\xa9\xb4:\n\t\t\ttokens.append(word)\t\t\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncorpus = nltk.Text(tokens)\t\t\t\t\t\t\t\t\t\t\t# Text() \xea\xb0\x9d\xec\xb2\xb4\xeb\xa5\xbc corpus \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\nprint(len(corpus.tokens))\t\t\t\t\t\t\t\t\t\t\t# \xec\xa0\x84\xec\xb2\xb4 token\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(len(set(corpus.tokens)))\t\t\t\t\t\t\t\t\t\t# unique\xed\x95\x9c token\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\ncorpus.plot(50)\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x80\xec\x9e\xa5 \xeb\xa7\x8e\xec\x9d\xb4 \xeb\x93\xb1\xec\x9e\xa5\xed\x95\x98\xeb\x8a\x94 50\xea\xb0\x9c \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\xb9\x88\xeb\x8f\x84\xec\x88\x98\xeb\xa5\xbc \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa1\x9c \xed\x91\x9c\xed\x98\x84\xed\x95\xb4 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(\'=\'*50)\nprint(\'Similar words with Dream: \')\ncorpus.similar(\'Dream\')\t\t\t\t\t\t\t\t\t\t\t\t# \'Dreams\'\xec\x99\x80 \xec\x9c\xa0\xec\x82\xac\xed\x95\x9c \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(\'=\'*50)\nprint(\'Collocations for reviews of ""Inception"": \')\ncorpus.collocations()\t\t\t\t\t\t\t\t\t\t\t\t# \xec\x9d\xb8\xec\x85\x89\xec\x85\x98 \xec\x98\x81\xed\x99\x94\xec\x9d\x98 collocation \xec\xb6\x9c\xeb\xa0\xa5'"
Session2/source code/2-4/2-4-4-5-old_boy.py,0,"b'# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = set(stopwords.words(\'english\'))\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 \'result-2-3-3-5-old_boy.txt\' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open(\'result-2-3-3-5-old_boy.txt\', \'r\', encoding = \'utf-8\') as f:\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d(\'r\')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 \'utf-8\'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\n\ntokens = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# token\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\tline = nltk.word_tokenize(line.lower())\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x84 \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\tfor word in line:\t\t\t\t\t\t\t\t\t\t\t\t# \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x98 \xea\xb0\x81 token\xec\x97\x90 for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\t\tif word not in stopWords:\t\t\t\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd token\xec\x9d\xb4 stopword\xea\xb0\x80 \xec\x95\x84\xeb\x8b\x88\xeb\xa9\xb4:\n\t\t\ttokens.append(word)\t\t\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncorpus = nltk.Text(tokens)\t\t\t\t\t\t\t\t\t\t\t# Text() \xea\xb0\x9d\xec\xb2\xb4\xeb\xa5\xbc corpus \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\nprint(len(corpus.tokens))\t\t\t\t\t\t\t\t\t\t\t# \xec\xa0\x84\xec\xb2\xb4 token\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(len(set(corpus.tokens)))\t\t\t\t\t\t\t\t\t\t# unique\xed\x95\x9c token\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\ncorpus.plot(50)\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x80\xec\x9e\xa5 \xeb\xa7\x8e\xec\x9d\xb4 \xeb\x93\xb1\xec\x9e\xa5\xed\x95\x98\xeb\x8a\x94 50\xea\xb0\x9c \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\xb9\x88\xeb\x8f\x84\xec\x88\x98\xeb\xa5\xbc \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa1\x9c \xed\x91\x9c\xed\x98\x84\xed\x95\xb4 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(\'=\'*50)\t\nprint(\'Similar words with old boy: \')\ncorpus.similar(\'old boy\')\t\t\t\t\t\t\t\t\t\t\t# \'old boy\'\xec\x99\x80 \xec\x9c\xa0\xec\x82\xac\xed\x95\x9c \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(\'=\'*50)\nprint(\'Collocations for reviews of ""Old boy"": \')\ncorpus.collocations()\t\t\t\t\t\t\t\t\t\t\t\t# \xec\x98\xac\xeb\x93\x9c \xeb\xb3\xb4\xec\x9d\xb4\xec\x9d\x98 collocation\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4'"
Session2/source code/2-4/2-4-4-5-whiplash.py,0,"b'# \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\n# nltk \xeb\xaa\xa8\xeb\x93\x88\xec\x97\x90\xec\x84\x9c Stopwords\xeb\xa5\xbc \xec\xa7\x81\xec\xa0\x91 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nfrom nltk.corpus import stopwords\n\n# \xec\x98\x81\xec\x96\xb4\xec\x9d\x98 stopwords\xeb\xa5\xbc \xeb\xb6\x88\xeb\x9f\xac\xec\x99\x80 \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\nstopWords = set(stopwords.words(\'english\'))\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 \'result-2-3-3-5-whiplash.txt\' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open(\'result-2-3-3-5-whiplash.txt\', \'r\', encoding = \'utf-8\') as f:\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d(\'r\')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 \'utf-8\'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\n\ntokens = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# token\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81\xea\xb0\x81\xec\x9d\x98 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\tline = nltk.word_tokenize(line.lower())\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x84 \xec\x86\x8c\xeb\xac\xb8\xec\x9e\x90\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c \xed\x9b\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\tfor word in line:\t\t\t\t\t\t\t\t\t\t\t\t# \xeb\x9d\xbc\xec\x9d\xb8\xec\x9d\x98 \xea\xb0\x81 token\xec\x97\x90 for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\t\tif word not in stopWords:\t\t\t\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd token\xec\x9d\xb4 stopword\xea\xb0\x80 \xec\x95\x84\xeb\x8b\x88\xeb\xa9\xb4:\n\t\t\ttokens.append(word)\t\t\t\t\t\t\t\t\t\t# \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\ncorpus = nltk.Text(tokens)\t\t\t\t\t\t\t\t\t\t\t# Text() \xea\xb0\x9d\xec\xb2\xb4\xeb\xa5\xbc corpus \xeb\xb3\x80\xec\x88\x98\xec\x97\x90 \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\nprint(len(corpus.tokens))\t\t\t\t\t\t\t\t\t\t\t# \xec\xa0\x84\xec\xb2\xb4 token\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(len(set(corpus.tokens)))\t\t\t\t\t\t\t\t\t\t# unique\xed\x95\x9c token\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\ncorpus.plot(50)\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x80\xec\x9e\xa5 \xeb\xa7\x8e\xec\x9d\xb4 \xeb\x93\xb1\xec\x9e\xa5\xed\x95\x98\xeb\x8a\x94 50\xea\xb0\x9c \xeb\x8b\xa8\xec\x96\xb4\xec\x9d\x98 \xeb\xb9\x88\xeb\x8f\x84\xec\x88\x98\xeb\xa5\xbc \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa1\x9c \xed\x91\x9c\xed\x98\x84\xed\x95\xb4 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(\'=\'*50)\nprint(\'Similar words with Drum: \')\ncorpus.similar(\'drum\')\t\t\t\t\t\t\t\t\t\t\t\t# \'drum\'\xea\xb3\xbc \xec\x9c\xa0\xec\x82\xac\xed\x95\x9c \xeb\x8b\xa8\xec\x96\xb4\xeb\xa5\xbc \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4\nprint(\'=\'*50)\nprint(\'Collocations for reviews of ""Whiplash"": \')\ncorpus.collocations()\t\t\t\t\t\t\t\t\t\t\t\t# \xec\x9c\x84\xed\x94\x8c\xeb\x9e\x98\xec\x8b\x9c\xec\x9d\x98 collocation\xec\x9d\x84 \xec\xb6\x9c\xeb\xa0\xa5\xed\x95\x9c\xeb\x8b\xa4'"
Session2/source code/2-4/2-4-4-6.py,1,"b""## \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# unique\xed\x95\x9c \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xec\x85\x8b\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nunqiueNouns = set()\n# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nsentences = []\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-4-2-3.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-4-2-3.txt', 'r', encoding = 'utf-8') as f:\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\t\t\n\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\ttags = nltk.pos_tag(tokens)\t\t\t\t\t\t\t\t\t\t# tokenize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\x9c\xeb\x8b\xa4\n\tsentences.append(tags)\t\t\t\t\t\t\t\t\t\t\t# \xed\x83\x9c\xea\xb7\xb8\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\n\tfor word, tag in tags:\t\t\t\t\t\t\t\t\t\t\t# tags\xec\x9d\x98 (\xeb\x8b\xa8\xec\x96\xb4, \xed\x83\x9c\xea\xb7\xb8)\xec\x8c\x8d\xec\x9d\x84 \xed\x95\x98\xeb\x82\x98\xec\x94\xa9 \xea\xba\xbc\xeb\x82\xb8\xeb\x8b\xa4:\n\t\tif tag in ['NN', 'NNS', 'NNP', 'NNPS']:\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\xaa\x85\xec\x82\xac\xeb\xa9\xb4:\n\t\t\tunqiueNouns.add(word)\t\t\t\t\t\t\t\t\t# \xec\x85\x8b\xec\x97\x90 \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\nunqiueNouns = list(unqiueNouns)\t\t\t\t\t\t\t\t\t\t# uniqueNouns \xec\x85\x8b\xec\x9d\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c\xeb\x8b\xa4\nnounIndex = {noun: i for i, noun in enumerate(unqiueNouns)}\t\t\t# enumerate \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xea\xb0\x81 \xeb\xaa\x85\xec\x82\xac\xec\x9d\x98 index\xeb\xa5\xbc \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\nmatrix = np.zeros([len(sentences), len(unqiueNouns)])\t\t\t\t# [(\xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98) X (unique\xed\x95\x9c \xeb\xaa\x85\xec\x82\xac\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98)]\xed\x81\xac\xea\xb8\xb0\xec\x9d\x98 0\xec\x9c\xbc\xeb\xa1\x9c \xec\x9d\xb4\xeb\xa3\xa8\xec\x96\xb4\xec\xa7\x84 \xed\x96\x89\xeb\xa0\xac\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\nfor i, sentence in enumerate(sentences):\t\t\t\t\t\t\t# enumerate \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xea\xb0\x81 sentence\xec\x9d\x98 index\xeb\xa5\xbc \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tfor word, tag in sentence:\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x98 token\xeb\x93\xa4\xec\x9d\x98 (word, tag) \xec\x8c\x8d\xec\x97\x90\xec\x84\x9c:\n\t\tif tag in ['NN', 'NNS', 'NNP', 'NNPS']:\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\xaa\x85\xec\x82\xac\xeb\xa9\xb4:\n\t\t\tindex = nounIndex[word]\t\t\t\t\t\t\t\t\t\n\t\t\tmatrix[i][index] = 1\t\t\t\t\t\t\t\t\t# \xed\x96\x89\xeb\xa0\xac\xec\x9d\x98 [i],[index] \xeb\xb2\x88\xec\xa7\xb8 \xec\x9b\x90\xec\x86\x8c\xeb\xa5\xbc 1\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\ncoocurMatrix = matrix.T.dot(matrix)\t\t\t\t\t\t\t\t\t# \xed\x96\x89\xeb\xa0\xac\xec\x9d\x98 \xeb\x82\xb4\xec\xa0\x81 \xec\x97\xb0\xec\x82\xb0\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 co-occurence matrix\xeb\xa5\xbc \xea\xb3\x84\xec\x82\xb0\xed\x95\x9c\xeb\x8b\xa4\n\ngraph = nx.Graph()\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\n## co-occurence matrix\xec\x9d\x98 \xea\xb0\x92\xeb\x93\xa4\xeb\xa1\x9c \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xea\xb7\xb8\xeb\xa0\xa4\xea\xb0\x84\xeb\x8b\xa4\nfor i in range(len(unqiueNouns)):\n\tfor j in range(i+1, len(unqiueNouns)):\n\t\tif coocurMatrix[i][j] > 30:\n\t\t\tgraph.add_edge(unqiueNouns[i], unqiueNouns[j])\n\n# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xec\x8b\x9c\xea\xb0\x81\xed\x99\x94\xed\x95\x9c\xeb\x8b\xa4\nplt.figure(figsize=(15, 15))\t\t\t\t\t\t\t\t\t\t# \xec\x82\xac\xec\x9d\xb4\xec\xa6\x88\xeb\x8a\x94 (15,15)\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nlayout = nx.random_layout(graph)\t\t\t\t\t\t\t\t\t# random_layout\xec\x9d\x84 \xec\xa0\x81\xec\x9a\xa9\xed\x95\x9c\xeb\x8b\xa4\nnx.draw(graph, pos=layout, with_labels=True,\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xea\xb7\xb8\xeb\xa6\xb0\xeb\x8b\xa4\n        font_size=20, alpha=0.3, node_size=3000)\nplt.show()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xed\x99\x94\xeb\xa9\xb4\xec\x97\x90 \xeb\x9d\x84\xec\x9a\xb4\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-4-7-inception.py,1,"b""## \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# unique\xed\x95\x9c \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xec\x85\x8b\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nunqiueNouns = set()\n# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nsentences = []\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-4-2-4-inception.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-4-2-4-inception.txt', 'r', encoding = 'utf-8') as f:\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\n\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\ttags = nltk.pos_tag(tokens)\t\t\t\t\t\t\t\t\t\t# tokenize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\x9c\xeb\x8b\xa4\n\tsentences.append(tags)\t\t\t\t\t\t\t\t\t\t\t# \xed\x83\x9c\xea\xb7\xb8\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\n\tfor word, tag in tags:\t\t\t\t\t\t\t\t\t\t\t# tags\xec\x9d\x98 (\xeb\x8b\xa8\xec\x96\xb4, \xed\x83\x9c\xea\xb7\xb8)\xec\x8c\x8d\xec\x9d\x84 \xed\x95\x98\xeb\x82\x98\xec\x94\xa9 \xea\xba\xbc\xeb\x82\xb8\xeb\x8b\xa4:\n\t\tif tag in ['NN', 'NNS', 'NNP', 'NNPS']:\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\xaa\x85\xec\x82\xac\xeb\xa9\xb4:\n\t\t\tunqiueNouns.add(word)\t\t\t\t\t\t\t\t\t# \xec\x85\x8b\xec\x97\x90 \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\nunqiueNouns = list(unqiueNouns)\t\t\t\t\t\t\t\t\t\t# uniqueNouns \xec\x85\x8b\xec\x9d\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c\xeb\x8b\xa4\nnounIndex = {noun: i for i, noun in enumerate(unqiueNouns)}\t\t\t# enumerate \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xea\xb0\x81 \xeb\xaa\x85\xec\x82\xac\xec\x9d\x98 index\xeb\xa5\xbc \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\nmatrix = np.zeros([len(sentences), len(unqiueNouns)])\t\t\t\t# [(\xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98) X (unique\xed\x95\x9c \xeb\xaa\x85\xec\x82\xac\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98)]\xed\x81\xac\xea\xb8\xb0\xec\x9d\x98 0\xec\x9c\xbc\xeb\xa1\x9c \xec\x9d\xb4\xeb\xa3\xa8\xec\x96\xb4\xec\xa7\x84 \xed\x96\x89\xeb\xa0\xac\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\nfor i, sentence in enumerate(sentences):\t\t\t\t\t\t\t# enumerate \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xea\xb0\x81 sentence\xec\x9d\x98 index\xeb\xa5\xbc \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tfor word, tag in sentence:\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x98 token\xeb\x93\xa4\xec\x9d\x98 (word, tag) \xec\x8c\x8d\xec\x97\x90\xec\x84\x9c:\n\t\tif tag in ['NN', 'NNS', 'NNP', 'NNPS']:\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\xaa\x85\xec\x82\xac\xeb\xa9\xb4:\n\t\t\tindex = nounIndex[word]\t\t\t\t\t\t\t\t\t\n\t\t\tmatrix[i][index] = 1\t\t\t\t\t\t\t\t\t# \xed\x96\x89\xeb\xa0\xac\xec\x9d\x98 [i],[index] \xeb\xb2\x88\xec\xa7\xb8 \xec\x9b\x90\xec\x86\x8c\xeb\xa5\xbc 1\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\ncoocurMatrix = matrix.T.dot(matrix)\t\t\t\t\t\t\t\t\t# \xed\x96\x89\xeb\xa0\xac\xec\x9d\x98 \xeb\x82\xb4\xec\xa0\x81 \xec\x97\xb0\xec\x82\xb0\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 co-occurence matrix\xeb\xa5\xbc \xea\xb3\x84\xec\x82\xb0\xed\x95\x9c\xeb\x8b\xa4\n\ngraph = nx.Graph()\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\n## co-occurence matrix\xec\x9d\x98 \xea\xb0\x92\xeb\x93\xa4\xeb\xa1\x9c \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xea\xb7\xb8\xeb\xa0\xa4\xea\xb0\x84\xeb\x8b\xa4\nfor i in range(len(unqiueNouns)):\n\tfor j in range(i+1, len(unqiueNouns)):\n\t\tif coocurMatrix[i][j] > 30:\n\t\t\tgraph.add_edge(unqiueNouns[i], unqiueNouns[j])\n\n# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xec\x8b\x9c\xea\xb0\x81\xed\x99\x94\xed\x95\x9c\xeb\x8b\xa4\nplt.figure(figsize=(15, 15))\t\t\t\t\t\t\t\t\t\t# \xec\x82\xac\xec\x9d\xb4\xec\xa6\x88\xeb\x8a\x94 (15,15)\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nlayout = nx.random_layout(graph)\t\t\t\t\t\t\t\t\t# random_layout\xec\x9d\x84 \xec\xa0\x81\xec\x9a\xa9\xed\x95\x9c\xeb\x8b\xa4\nnx.draw(graph, pos=layout, with_labels=True,\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xea\xb7\xb8\xeb\xa6\xb0\xeb\x8b\xa4\n        font_size=20, alpha=0.3, node_size=3000)\nplt.show()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xed\x99\x94\xeb\xa9\xb4\xec\x97\x90 \xeb\x9d\x84\xec\x9a\xb4\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-4-7-old_boy.py,1,"b""## \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# unique\xed\x95\x9c \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xec\x85\x8b\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nunqiueNouns = set()\n# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nsentences = []\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-4-2-4-old_boy.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-4-2-4-old_boy.txt', 'r', encoding = 'utf-8') as f:\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\t\t\n\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\ttags = nltk.pos_tag(tokens)\t\t\t\t\t\t\t\t\t\t# tokenize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\x9c\xeb\x8b\xa4\n\tsentences.append(tags)\t\t\t\t\t\t\t\t\t\t\t# \xed\x83\x9c\xea\xb7\xb8\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\n\tfor word, tag in tags:\t\t\t\t\t\t\t\t\t\t\t# tags\xec\x9d\x98 (\xeb\x8b\xa8\xec\x96\xb4, \xed\x83\x9c\xea\xb7\xb8)\xec\x8c\x8d\xec\x9d\x84 \xed\x95\x98\xeb\x82\x98\xec\x94\xa9 \xea\xba\xbc\xeb\x82\xb8\xeb\x8b\xa4:\n\t\tif tag in ['NN', 'NNS', 'NNP', 'NNPS']:\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\xaa\x85\xec\x82\xac\xeb\xa9\xb4:\n\t\t\tunqiueNouns.add(word)\t\t\t\t\t\t\t\t\t# \xec\x85\x8b\xec\x97\x90 \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\nunqiueNouns = list(unqiueNouns)\t\t\t\t\t\t\t\t\t\t# uniqueNouns \xec\x85\x8b\xec\x9d\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c\xeb\x8b\xa4\nnounIndex = {noun: i for i, noun in enumerate(unqiueNouns)}\t\t\t# enumerate \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xea\xb0\x81 \xeb\xaa\x85\xec\x82\xac\xec\x9d\x98 index\xeb\xa5\xbc \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\nmatrix = np.zeros([len(sentences), len(unqiueNouns)])\t\t\t\t# [(\xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98) X (unique\xed\x95\x9c \xeb\xaa\x85\xec\x82\xac\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98)]\xed\x81\xac\xea\xb8\xb0\xec\x9d\x98 0\xec\x9c\xbc\xeb\xa1\x9c \xec\x9d\xb4\xeb\xa3\xa8\xec\x96\xb4\xec\xa7\x84 \xed\x96\x89\xeb\xa0\xac\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\nfor i, sentence in enumerate(sentences):\t\t\t\t\t\t\t# enumerate \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xea\xb0\x81 sentence\xec\x9d\x98 index\xeb\xa5\xbc \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tfor word, tag in sentence:\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x98 token\xeb\x93\xa4\xec\x9d\x98 (word, tag) \xec\x8c\x8d\xec\x97\x90\xec\x84\x9c:\n\t\tif tag in ['NN', 'NNS', 'NNP', 'NNPS']:\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\xaa\x85\xec\x82\xac\xeb\xa9\xb4:\n\t\t\tindex = nounIndex[word]\t\t\t\t\t\t\t\t\t\n\t\t\tmatrix[i][index] = 1\t\t\t\t\t\t\t\t\t# \xed\x96\x89\xeb\xa0\xac\xec\x9d\x98 [i],[index] \xeb\xb2\x88\xec\xa7\xb8 \xec\x9b\x90\xec\x86\x8c\xeb\xa5\xbc 1\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\ncoocurMatrix = matrix.T.dot(matrix)\t\t\t\t\t\t\t\t\t# \xed\x96\x89\xeb\xa0\xac\xec\x9d\x98 \xeb\x82\xb4\xec\xa0\x81 \xec\x97\xb0\xec\x82\xb0\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 co-occurence matrix\xeb\xa5\xbc \xea\xb3\x84\xec\x82\xb0\xed\x95\x9c\xeb\x8b\xa4\n\ngraph = nx.Graph()\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\n## co-occurence matrix\xec\x9d\x98 \xea\xb0\x92\xeb\x93\xa4\xeb\xa1\x9c \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xea\xb7\xb8\xeb\xa0\xa4\xea\xb0\x84\xeb\x8b\xa4\nfor i in range(len(unqiueNouns)):\n\tfor j in range(i+1, len(unqiueNouns)):\n\t\tif coocurMatrix[i][j] > 30:\n\t\t\tgraph.add_edge(unqiueNouns[i], unqiueNouns[j])\n\n# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xec\x8b\x9c\xea\xb0\x81\xed\x99\x94\xed\x95\x9c\xeb\x8b\xa4\nplt.figure(figsize=(15, 15))\t\t\t\t\t\t\t\t\t\t# \xec\x82\xac\xec\x9d\xb4\xec\xa6\x88\xeb\x8a\x94 (15,15)\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nlayout = nx.random_layout(graph)\t\t\t\t\t\t\t\t\t# random_layout\xec\x9d\x84 \xec\xa0\x81\xec\x9a\xa9\xed\x95\x9c\xeb\x8b\xa4\nnx.draw(graph, pos=layout, with_labels=True,\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xea\xb7\xb8\xeb\xa6\xb0\xeb\x8b\xa4\n        font_size=20, alpha=0.3, node_size=3000)\nplt.show()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xed\x99\x94\xeb\xa9\xb4\xec\x97\x90 \xeb\x9d\x84\xec\x9a\xb4\xeb\x8b\xa4"""
Session2/source code/2-4/2-4-4-7-whiplash.py,1,"b""## \xeb\xb6\x84\xec\x84\x9d\xec\x9d\x84 \xec\x9c\x84\xed\x95\xb4 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xaa\xa8\xeb\x93\x88\xec\x9d\x84 \xeb\xb6\x88\xeb\x9f\xac\xec\x98\xa8\xeb\x8b\xa4\nimport nltk\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# unique\xed\x95\x9c \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xec\xa0\x80\xec\x9e\xa5\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xec\x85\x8b\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nunqiueNouns = set()\n# \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x84 \xeb\x8b\xb4\xea\xb8\xb0 \xec\x9c\x84\xed\x95\x9c \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\nsentences = []\n\n# open \xed\x95\xa8\xec\x88\x98\xeb\xa5\xbc \xed\x86\xb5\xed\x95\xb4 'result-2-4-2-4-whiplash.txt' \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xec\x97\xb4\xea\xb3\xa0 \xec\x9d\xb4\xeb\xa5\xbc f\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nwith open('result-2-4-2-4-whiplash.txt', 'r', encoding = 'utf-8') as f:\t\t# \xec\x9d\xbd\xea\xb8\xb0 \xed\x98\x95\xec\x8b\x9d('r')\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\x98\xea\xb3\xa0 \xec\x9d\xb8\xec\xbd\x94\xeb\x94\xa9\xec\x9d\x80 'utf-8'\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tlines = f.readlines()\t\t\t\t\t\t\t\t\t\t\t\t\t# readlines \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x98 \xeb\x82\xb4\xec\x9a\xa9\xec\x9d\x84 \xec\x9d\xbd\xec\x96\xb4 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xec\xa0\x80\xec\x9e\xa5\xed\x95\x9c\xeb\x8b\xa4\n\tf.close()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xed\x8c\x8c\xec\x9d\xbc\xec\x9d\x84 \xeb\x8b\xab\xeb\x8a\x94\xeb\x8b\xa4\n\t\nfor line in lines:\t\t\t\t\t\t\t\t\t\t\t\t\t# for\xeb\xac\xb8\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 \xea\xb0\x81 \xec\xa4\x84\xec\x97\x90 \xec\xa0\x91\xea\xb7\xbc\xed\x95\x9c\xeb\x8b\xa4:\n\ttokens = nltk.word_tokenize(line)\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xec\xa4\x84\xec\x9d\x84 tokenize\xed\x95\x9c\xeb\x8b\xa4\n\ttags = nltk.pos_tag(tokens)\t\t\t\t\t\t\t\t\t\t# tokenize\xed\x95\x9c \xea\xb2\xb0\xea\xb3\xbc\xeb\xa5\xbc \xed\x92\x88\xec\x82\xac \xed\x83\x9c\xea\xb9\x85\xed\x95\x9c\xeb\x8b\xa4\n\tsentences.append(tags)\t\t\t\t\t\t\t\t\t\t\t# \xed\x83\x9c\xea\xb7\xb8\xeb\xa5\xbc \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xec\x97\x90 \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\n\tfor word, tag in tags:\t\t\t\t\t\t\t\t\t\t\t# tags\xec\x9d\x98 (\xeb\x8b\xa8\xec\x96\xb4, \xed\x83\x9c\xea\xb7\xb8)\xec\x8c\x8d\xec\x9d\x84 \xed\x95\x98\xeb\x82\x98\xec\x94\xa9 \xea\xba\xbc\xeb\x82\xb8\xeb\x8b\xa4:\n\t\tif tag in ['NN', 'NNS', 'NNP', 'NNPS']:\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\xaa\x85\xec\x82\xac\xeb\xa9\xb4:\n\t\t\tunqiueNouns.add(word)\t\t\t\t\t\t\t\t\t# \xec\x85\x8b\xec\x97\x90 \xeb\xaa\x85\xec\x82\xac\xeb\xa5\xbc \xec\xb2\xa8\xeb\xb6\x80\xed\x95\x9c\xeb\x8b\xa4\n\nunqiueNouns = list(unqiueNouns)\t\t\t\t\t\t\t\t\t\t# uniqueNouns \xec\x85\x8b\xec\x9d\x84 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8\xeb\xa1\x9c \xeb\xb3\x80\xed\x99\x98\xed\x95\x9c\xeb\x8b\xa4\nnounIndex = {noun: i for i, noun in enumerate(unqiueNouns)}\t\t\t# enumerate \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xea\xb0\x81 \xeb\xaa\x85\xec\x82\xac\xec\x9d\x98 index\xeb\xa5\xbc \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\nmatrix = np.zeros([len(sentences), len(unqiueNouns)])\t\t\t\t# [(\xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98) X (unique\xed\x95\x9c \xeb\xaa\x85\xec\x82\xac\xec\x9d\x98 \xea\xb0\x9c\xec\x88\x98)]\xed\x81\xac\xea\xb8\xb0\xec\x9d\x98 0\xec\x9c\xbc\xeb\xa1\x9c \xec\x9d\xb4\xeb\xa3\xa8\xec\x96\xb4\xec\xa7\x84 \xed\x96\x89\xeb\xa0\xac\xec\x9d\x84 \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\nfor i, sentence in enumerate(sentences):\t\t\t\t\t\t\t# enumerate \xed\x95\xa8\xec\x88\x98\xeb\xa1\x9c \xea\xb0\x81 sentence\xec\x9d\x98 index\xeb\xa5\xbc \xec\xa7\x80\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\tfor word, tag in sentence:\t\t\t\t\t\t\t\t\t\t# \xea\xb0\x81 \xeb\xac\xb8\xec\x9e\xa5\xec\x9d\x98 token\xeb\x93\xa4\xec\x9d\x98 (word, tag) \xec\x8c\x8d\xec\x97\x90\xec\x84\x9c:\n\t\tif tag in ['NN', 'NNS', 'NNP', 'NNPS']:\t\t\t\t\t\t# \xeb\xa7\x8c\xec\x95\xbd \xed\x83\x9c\xea\xb7\xb8\xea\xb0\x80 \xeb\xaa\x85\xec\x82\xac\xeb\xa9\xb4:\n\t\t\tindex = nounIndex[word]\t\t\t\t\t\t\t\t\t\n\t\t\tmatrix[i][index] = 1\t\t\t\t\t\t\t\t\t# \xed\x96\x89\xeb\xa0\xac\xec\x9d\x98 [i],[index] \xeb\xb2\x88\xec\xa7\xb8 \xec\x9b\x90\xec\x86\x8c\xeb\xa5\xbc 1\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\n\ncoocurMatrix = matrix.T.dot(matrix)\t\t\t\t\t\t\t\t\t# \xed\x96\x89\xeb\xa0\xac\xec\x9d\x98 \xeb\x82\xb4\xec\xa0\x81 \xec\x97\xb0\xec\x82\xb0\xec\x9d\x84 \xed\x86\xb5\xed\x95\xb4 co-occurence matrix\xeb\xa5\xbc \xea\xb3\x84\xec\x82\xb0\xed\x95\x9c\xeb\x8b\xa4\n\ngraph = nx.Graph()\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xec\x83\x9d\xec\x84\xb1\xed\x95\x9c\xeb\x8b\xa4\n\n## co-occurence matrix\xec\x9d\x98 \xea\xb0\x92\xeb\x93\xa4\xeb\xa1\x9c \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xea\xb7\xb8\xeb\xa0\xa4\xea\xb0\x84\xeb\x8b\xa4\nfor i in range(len(unqiueNouns)):\n\tfor j in range(i+1, len(unqiueNouns)):\n\t\tif coocurMatrix[i][j] > 30:\n\t\t\tgraph.add_edge(unqiueNouns[i], unqiueNouns[j])\n\n# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xec\x8b\x9c\xea\xb0\x81\xed\x99\x94\xed\x95\x9c\xeb\x8b\xa4\nplt.figure(figsize=(15, 15))\t\t\t\t\t\t\t\t\t\t# \xec\x82\xac\xec\x9d\xb4\xec\xa6\x88\xeb\x8a\x94 (15,15)\xeb\xa1\x9c \xec\x84\xa4\xec\xa0\x95\xed\x95\x9c\xeb\x8b\xa4\nlayout = nx.random_layout(graph)\t\t\t\t\t\t\t\t\t# random_layout\xec\x9d\x84 \xec\xa0\x81\xec\x9a\xa9\xed\x95\x9c\xeb\x8b\xa4\nnx.draw(graph, pos=layout, with_labels=True,\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xea\xb7\xb8\xeb\xa6\xb0\xeb\x8b\xa4\n        font_size=20, alpha=0.3, node_size=3000)\nplt.show()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \xea\xb7\xb8\xeb\x9e\x98\xed\x94\x84\xeb\xa5\xbc \xed\x99\x94\xeb\xa9\xb4\xec\x97\x90 \xeb\x9d\x84\xec\x9a\xb4\xeb\x8b\xa4"""
Session3/source code/3-1/3-1-1.py,0,b'n = int(input())\nintegers = [int(i) for i in input().split()]\nm = int(input())\n\ndivisor_sum = 0\nmultiple_sum = 0\nfor i in integers:\n    if m%i == 0:\n        divisor_sum += i\n    # \xec\x95\xbd\xec\x88\x98\xec\x9d\xb4\xeb\xa9\xb4\xec\x84\x9c \xeb\xb0\xb0\xec\x88\x98\xec\x9d\xb8 \xea\xb2\xbd\xec\x9a\xb0(i=m)\xeb\x8f\x84 \xec\x9e\x88\xec\x9c\xbc\xeb\xaf\x80\xeb\xa1\x9c if\xeb\xac\xb8 \xeb\x91\x90\xea\xb0\x9c\xeb\xa5\xbc \xed\x99\x9c\xec\x9a\xa9\xed\x95\x9c\xeb\x8b\xa4\n    if i%m == 0:        \n        multiple_sum += i\n\nprint(divisor_sum)\nprint(multiple_sum)'
Session3/source code/3-1/3-1-2.py,0,"b""def divide_by_two(integer):\n    remainder = integer % 2\n    quotient = int(integer/2)\n    return (quotient, remainder)\n\ndef converter(integer):\n    result = ''\n    while integer != 0:\n        (q, r) = divide_by_two(integer)\n        result = str(r) + result\n        integer = q\n    return int(result)\n\nconverter(24)"""
Session3/source code/3-1/3-1-3.py,0,"b""s = input()\nkoi = 0\nioi = 0\nfor i in range(len(s) - 2):\n    if s[i:i+3] == 'KOI':\n       koi += 1\n    if s[i:i+3] == 'IOI':\n        ioi += 1\n\nprint(koi)\nprint(ioi)"""
Session3/source code/3-1/3-1-4.py,0,"b""def word_printer():\n    status = True\n    word_set = ''\n    while status:\n        words = input()\n        if words == 'END':\n            status = False\n        else:\n            for word in words.split():\n                if word not in word_set:\n                    word_set = word_set + ' ' + word\n            print(word_set)   \n\nprint(word_printer())"""
Session3/source code/3-1/3-1-5.py,0,b'n = int(input())\nscores = [int(i) for i in input().split()]\nmax_score = max(scores)\nsum = 0\nfor score in scores:\n    sum += (score/max_score)*100\navg = sum/len(scores)\nprint(avg)'
Session3/source code/3-1/3-1-6.py,0,"b""def score_calculator(result):\n    sequence = 1\n    score = 0\n    for r in result:\n        if r == 'O':\n            score += sequence\n            sequence += 1\n        else:\n            sequence = 1\n    return score\n\nn = int(input())\nfor i in range(n):\n    print(score_calculator(input()))"""
Session3/source code/3-1/3-1-7.py,0,b'def checker(word):\n    shown = []\n    for i in range(len(word)-1):\n        if word[i] in shown:\n            return False\n        if word[i] == word[i+1]:\n            pass\n        else:\n            shown.append(word[i])\n    if word[-1] in shown:\n        return False\n    return True\n\nn = int(input())\nwords = []\nnum_group_words = 0\nfor i in range(n):\n    words.append(input())\nfor word in words:\n    if checker(word):\n        num_group_words += 1\nprint(num_group_words)'
Session3/source code/3-1/3-1-8.py,0,"b'heights = []\ntotal_heights = 0\nfor i in range(9):\n    height = int(input())\n    heights.append(height)\n    total_heights += height\n\nimport itertools\ncombinations = itertools.combinations(heights, 2)\nfor combination in combinations:\n    height_sum = total_heights\n    for i in combination:\n        height_sum -= i\n    if height_sum == 100:\n        for i in combination:\n            heights.remove(i)\n        break\n\nheights.sort()\nfor height in heights:\n    print(height)'"
Session3/source code/3-2/3-2-1.py,1,b'import numpy as np\n\narr = np.random.random(10)\narr.sort()\n\narr # \xec\x98\xa4\xeb\xa6\x84\xec\xb0\xa8\xec\x88\x9c \xec\xa0\x95\xeb\xa0\xac\n\narr[::-1].sort()\n\narr # \xeb\x82\xb4\xeb\xa6\xbc\xec\xb0\xa8\xec\x88\x9c \xec\xa0\x95\xeb\xa0\xac'
Session3/source code/3-2/3-2-10.py,0,"b""import pandas as pd\n\ndata = pd.read_excel('animals.xlsx')\nprint(data)\n\nanimals = data.loc[:, ['name', 'hair', 'feathers']]\nprint(animals)"""
Session3/source code/3-2/3-2-11.py,0,"b""import pandas as pd\n\ndata = pd.read_excel('animals.xlsx')\nprint(data)\n\nanimals = data.loc[:, ['name', 'hair', 'feathers']]\nprint(animals)\n\nanimals.to_excel('animals_sub.xlsx')"""
Session3/source code/3-2/3-2-2.py,1,"b'arr = np.arange(9)\n\narr = arr.reshape(3,3)\n\nprint(arr)'"
Session3/source code/3-2/3-2-3.py,3,"b'arr = np.arange(9).reshape(3,3)\ndiag = np.diag(arr)\n\nprint(diag)\n\ndiag_mat = np.diag(np.diag(arr))\n\nprint(diag_mat)'"
Session3/source code/3-2/3-2-4.py,1,"b'arr = np.random.randint(1, 100, size =(5,5))\n\nprint(arr)\n\narrMax, arrMin = arr.max(), arr.min()\narr_normalized = (arr - arrMin)/(arrMax - arrMin)\n\nprint(arr_normalized)'"
Session3/source code/3-2/3-2-5.py,3,"b""import numpy as np \n\nA = np.array([[1,2,3],[4,5,6]])\nB = np.array([[1,2], [3,4], [5,6]])\n\nresult = np.dot(A, B)\nprint(result')"""
Session3/source code/3-2/3-2-6.py,1,"b""import numpy as np \n\ndata = np.loadtxt('stock-data.csv', delimiter = ',')\ndata.shape\n\nx_data = data[:,:-1]\ny_data = data[:, -1]\n\nprint(x_data.shape)\nprint(x_data)\n\nprint(y_data.shape)\nprint(y_data)"""
Session3/source code/3-2/3-2-7.py,1,"b""import numpy as np \n\ndata = np.loadtxt('diabetes-data.csv', delimiter = ',')\nprint(data.shape)\n\nx_data = data[:, :-1]\ny_data = data[:, -1]\n\nprint(x_data.shape)\nprint(x_data)\n\nprint(y_data.shape)\nprint(y_data)"""
Session3/source code/3-2/3-2-8.py,0,"b""import pandas as pd\n\ntitle = ['Skyfall', 'Lose Yourself', 'Another Brick in the Wall', 'Use Somebody', 'Treasure']\nartist = ['Adele', 'Eminem', 'Pink Floyd', 'Kings of Leon', 'Bruno Mars']\nlength = ['4:46', '5:26', '3:59', '3:51', '2:58']\nyear = [2012, 2002, 1979, 2008, 2013]\ndata = pd.DataFrame({'Title': title, 'Artist': artist, 'Length': length, 'Year': year})\n\nprint(data)"""
Session3/source code/3-2/3-2-9.py,0,"b""import pandas as pd\n\ntitle = ['Skyfall', 'Lose Yourself', 'Another Brick in the Wall', 'Use Somebody', 'Treasure']\nartist = ['Adele', 'Eminem', 'Pink Floyd', 'Kings of Leon', 'Bruno Mars']\nlength = ['4:46', '5:26', '3:59', '3:51', '2:58']\nyear = [2012, 2002, 1979, 2008, 2013]\ndata = pd.DataFrame({'Title': title, 'Artist': artist, 'Length': length, 'Year': year})\n\ntitle_lowercase = [t.lower() for t in data['Title']]\nprint(title_lowercase)"""
Session3/source code/3-3/3-3-2.py,0,"b""import pymysql\n\nconn = pymysql.connect(host = 'localhost', user = 'buomsoo', password = '12345', \n\tdb = 'company', charset= 'utf8')\n\ncurs = conn.cursor()\n\nsql_query = 'select * from employee'\ncurs.execute(sql_query)\n\nrows = curs.fetchall()\nprint(rows)\n\nconn.close()"""
Session3/source code/3-3/3-3-3.py,0,"b""import pymysql\n\nconn = pymysql.connect(host = 'localhost', user = 'buomsoo', password = '12345', \n\tdb = 'company', charset= 'utf8')\n\ncurs = conn.cursor()\n\nsql_query = 'select fname, lname from employee'\ncurs.execute(sql_query)\n\nrows = curs.fetchall()\nfor row in rows:\n\tprint(row)\n\n# sql_query = 'select * from employee'\n# curs.execute(sql_query)\n\n# rows = curs.fetchall()\n# for row in rows:\n# \tprint('Name of the employee is: ', row[0] + ' ' + row[1])\n\nconn.close()"""
Session3/source code/3-3/3-3-4.py,0,"b'import pymysql\n\nconn = pymysql.connect(host = \'localhost\', user = \'buomsoo\', password = \'12345\', \n\tdb = \'company\', charset= \'utf8\')\n\ncurs = conn.cursor()\n\nsql_query = ""INSERT INTO employee VALUES (\'Daniel\', \'Craig\', \'100006\', \'1968-03-02\', \'M\', \'800000\')""\ncurs.execute(sql_query)\nconn.commit()\n\nconn.close()'"
Session3/source code/3-3/3-3-5.py,0,"b'import pymysql\n\nwith open(\'data.txt\', \'r\') as f:\n\tlines = f.readlines()\n\tf.close()\n\nconn = pymysql.connect(host = \'localhost\', user = \'buomsoo\', password = \'12345\', \n\tdb = \'company\', charset= \'utf8\')\n\ncurs = conn.cursor()\n\nfor line in lines:\n\tline = tuple(line.split())\n\tprint(line)\n\tsql_query = ""INSERT INTO employee VALUES (\'{}\', \'{}\', \'{}\', \'{}\', \'{}\', \'{}\')"".format(*line)\n\tcurs.execute(sql_query)\n\tconn.commit()\n\nconn.close()'"
