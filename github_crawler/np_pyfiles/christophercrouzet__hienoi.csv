file_path,api_count,code
setup.py,0,"b'import io\nimport os\nimport re\nimport setuptools\n\n\ndef _read(*paths, **kwargs):\n    # Credits: https://packaging.python.org/single_source_version.\n    here = os.path.dirname(__file__)\n    encoding = kwargs.get(\'encoding\', \'utf8\')\n    with io.open(os.path.join(here, *paths), encoding=encoding) as f:\n        return f.read()\n\n\ndef _get_metas(*file_paths):\n    data = _read(*file_paths)\n    out = {}\n    metas = (\'author\', \'contact\', \'license\', \'summary\', \'title\', \'url\',\n             \'version\')\n    for meta in metas:\n        pattern = r\'^__%s__ = u?[\\\'""]([^\\\'""]*)[\\\'""]\' % (meta,)\n        match = re.search(pattern, data, re.MULTILINE)\n        if match is None:\n            raise RuntimeError(""Unable to find the metadata \'%s\'."" % (meta,))\n\n        out[meta] = match.group(1)\n\n    return out\n\n\n_METAS = _get_metas(\'hienoi\', \'__init__.py\')\n\nsetuptools.setup(\n    name=_METAS[\'title\'],\n    version=_METAS[\'version\'],\n    description=_METAS[\'summary\'],\n    url=_METAS[\'url\'],\n    author=_METAS[\'author\'],\n    author_email=_METAS[\'contact\'],\n    license=_METAS[\'license\'],\n    keywords=\'2D particles OpenGL nani NumPy\',\n    long_description=_read(\'README.rst\'),\n    classifiers=[\n        \'Development Status :: 4 - Beta\',\n        \'Intended Audience :: Developers\',\n        \'License :: OSI Approved :: MIT License\',\n        \'Programming Language :: Python\',\n        \'Programming Language :: Python :: 2\',\n        \'Programming Language :: Python :: 2.7\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.4\',\n        \'Programming Language :: Python :: 3.5\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Topic :: Software Development :: Libraries :: Python Modules\',\n        \'Topic :: Utilities\',\n    ],\n    install_requires=[\'nani\', \'numpy\', \'PyOpenGL\', \'PySDL2\'],\n    extras_require={\n        \'dev\': [\'coverage\', \'tox\'],\n    },\n    packages=[\n        \'hienoi\',\n    ],\n    include_package_data=True\n)\n'"
benchmarks/__init__.py,0,b''
benchmarks/bench__kdtree.py,0,"b""#!/usr/bin/env python\n\nimport os\nimport sys\nimport timeit\nimport unittest\n\nimport numpy\n\n_HERE = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, os.path.abspath(os.path.join(_HERE, os.pardir)))\n\nfrom hienoi._kdtree import KDTree\n\n\n_clock = timeit.default_timer\n\n\ndef _generate_uniform_2D_data(count, seed):\n    numpy.random.seed(seed=seed)\n    data = numpy.empty(count, dtype=(numpy.float32, 2))\n    data[:, 0] = numpy.random.uniform(-1.0, 1.0, count)\n    data[:, 1] = numpy.random.uniform(-1.0, 1.0, count)\n    return data\n\n\ndef _generate_2D_point(seed):\n    numpy.random.seed(seed=seed)\n    return (numpy.float32(numpy.random.random() * 2.0 - 1.0),\n            numpy.float32(numpy.random.random() * 2.0 - 1.0))\n\n\nclass KDTreeBench(unittest.TestCase):\n\n    @classmethod\n    def setUpClass(cls):\n        cls._trees = {\n            1: KDTree(_generate_uniform_2D_data(1, 391)),\n            10: KDTree(_generate_uniform_2D_data(10, 813)),\n            100: KDTree(_generate_uniform_2D_data(100, 571)),\n            1000: KDTree(_generate_uniform_2D_data(1000, 600)),\n            10000: KDTree(_generate_uniform_2D_data(10000, 427)),\n            100000: KDTree(_generate_uniform_2D_data(100000, 180)),\n            1000000: KDTree(_generate_uniform_2D_data(1000000, 425)),\n        }\n\n    def bench_build_uniform_100(self):\n        data = _generate_uniform_2D_data(100, 968)\n        start = _clock()\n        tree = KDTree(data)\n        return _clock() - start\n\n    def bench_build_uniform_10000(self):\n        data = _generate_uniform_2D_data(10000, 441)\n        start = _clock()\n        tree = KDTree(data)\n        return _clock() - start\n\n    def bench_build_uniform_1000000(self):\n        data = _generate_uniform_2D_data(1000000, 96)\n        start = _clock()\n        tree = KDTree(data)\n        return _clock() - start\n\n    def bench_search_uniform_1_nearests_in_100_points_tree_100_times(self):\n        numpy.random.seed(seed=192)\n        k = 1\n        r = None\n        n = 100\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n    def bench_search_uniform_100_nearests_in_100_points_tree_100_times(self):\n        numpy.random.seed(seed=501)\n        k = 100\n        r = None\n        n = 100\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n    def bench_search_uniform_1_nearests_in_10000_points_tree_100_times(self):\n        numpy.random.seed(seed=495)\n        k = 1\n        r = None\n        n = 10000\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n    def bench_search_uniform_100_nearests_in_10000_points_tree_100_times(self):\n        numpy.random.seed(seed=201)\n        k = 100\n        r = None\n        n = 10000\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n    def bench_search_uniform_1_nearests_in_1000000_points_tree_100_times(self):\n        numpy.random.seed(seed=597)\n        k = 1\n        r = None\n        n = 1000000\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n    def bench_search_uniform_100_nearests_in_1000000_points_tree_100_times(self):\n        numpy.random.seed(seed=109)\n        k = 100\n        r = None\n        n = 1000000\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n    def bench_search_uniform_all_within_0_25_radius_in_100_points_tree_100_times(self):\n        numpy.random.seed(seed=220)\n        k = None\n        r = 0.25\n        n = 100\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n    def bench_search_uniform_all_within_0_75_radius_in_100_points_tree_100_times(self):\n        numpy.random.seed(seed=384)\n        k = None\n        r = 0.75\n        n = 100\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n    def bench_search_uniform_all_within_0_25_radius_in_10000_points_tree_100_times(self):\n        numpy.random.seed(seed=471)\n        k = None\n        r = 0.25\n        n = 10000\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n    def bench_search_uniform_all_within_0_75_radius_in_10000_points_tree_100_times(self):\n        numpy.random.seed(seed=173)\n        k = None\n        r = 0.75\n        n = 10000\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n    def bench_search_uniform_all_within_0_25_radius_in_1000000_points_tree_100_times(self):\n        numpy.random.seed(seed=28)\n        k = None\n        r = 0.25\n        n = 1000000\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n    def bench_search_uniform_all_within_0_75_radius_in_1000000_points_tree_100_times(self):\n        numpy.random.seed(seed=850)\n        k = None\n        r = 0.75\n        n = 1000000\n        count = 100\n        tree = self._trees[n]\n        points = [_generate_2D_point(seed) for seed in numpy.random.randint(999, size=count)]\n        start = _clock()\n        for point in points:\n            tree.search(point, count=k, radius=r, sort=True)\n\n        return _clock() - start\n\n\nif __name__ == '__main__':\n    from benchmarks.run import run\n    run('__main__')\n"""
benchmarks/run.py,0,"b'#!/usr/bin/env python\n\nimport argparse\nimport bisect\nimport collections\nimport os\nimport sys\nimport timeit\nimport unittest\n\n\n_clock = timeit.default_timer\n\n\n# Usage\'s syntax based on docopt.\n_USAGE = ""%(prog)s [<name>...]""\n_DESCRIPTION = (\n    ""Runs the benchmarks that have their name containing either one of the ""\n    ""\'name\' arguments passed. If no \'name\' argument is passed, all the ""\n    ""benchmarks are run.""\n)\n\n\n# Enumerator for the internal messages.\n_MESSAGE_SUITE_SETUP = 0\n_MESSAGE_SUITE_TEARDOWN = 1\n\n\n_Message = collections.namedtuple(\n    \'_Message\', (\n        \'type\',\n        \'value\',\n    )\n)\n\n\nclass DummyResult(object):\n\n    def wasSuccessful(self):\n        return True\n\n\nclass BenchLoader(unittest.TestLoader):\n    testMethodPrefix = \'bench\'\n\n\nclass BenchRunner(object):\n\n    def run(self, bench):\n        stack = collections.deque((bench,))\n        while stack:\n            obj = stack.popleft()\n            if isinstance(obj, _Message):\n                if obj.type == _MESSAGE_SUITE_SETUP:\n                    obj.value.setUpClass()\n                elif obj.type == _MESSAGE_SUITE_TEARDOWN:\n                    obj.value.tearDownClass()\n            elif isinstance(obj, unittest.TestSuite):\n                suites = [suite for suite in obj\n                          if isinstance(suite, unittest.TestSuite)]\n                cases = [case for case in obj\n                         if not isinstance(case, unittest.TestSuite)]\n\n                stack.extend(suites)\n\n                seen = set()\n                classes = [type(case) for case in cases\n                           if type(case) not in seen\n                           and seen.add(type(case)) is None]\n                for cls in classes:\n                    stack.append(_Message(type=_MESSAGE_SUITE_SETUP,\n                                          value=cls))\n                    stack.extend(case for case in cases\n                                 if type(case) is cls)\n                    stack.append(_Message(type=_MESSAGE_SUITE_TEARDOWN,\n                                          value=cls))\n            else:\n                function = getattr(obj, _get_bench_name(obj))\n\n                obj.setUp()\n                start = _clock()\n                elapsed = function()\n                elapsed = _clock() - start if elapsed is None else elapsed\n                obj.tearDown()\n\n                elapsed, unit = _pick_time_unit(elapsed)\n                print(""%s (%s.%s) ... %.3f %s""\n                      % (_get_bench_name(obj), type(obj).__module__,\n                         type(obj).__name__, elapsed, unit))\n\n        return DummyResult()\n\n\ndef _pick_time_unit(value):\n    bounds = (1e-9, 1e-6, 1e-3)\n    units = \'num\'\n    if value >= 1.0:\n        out = (value, \'s\')\n    elif value <= bounds[0] * 1e-3:\n        out = (0.0, \'%ss\' % (units[0],))\n    else:\n        i = max(0, bisect.bisect(bounds, value) - 1)\n        out = (value / bounds[i], \'%ss\' % (units[i],))\n\n    return out\n\n\ndef _find_benchs(path, selectors=None):\n    if selectors is None:\n        def filter(bench):\n            return True\n    else:\n        def filter(bench):\n            return any(selector in _get_bench_full_name(bench)\n                       for selector in selectors)\n\n    out = []\n    loader = BenchLoader()\n    if path == \'__main__\':\n        root_bench = loader.loadTestsFromModule(sys.modules[path])\n    else:\n        root_bench = loader.discover(path, pattern=\'bench*.py\')\n\n    stack = collections.deque((root_bench,))\n    while stack:\n        obj = stack.popleft()\n        if isinstance(obj, unittest.TestSuite):\n            stack.extend(bench for bench in obj)\n        elif type(obj).__name__ == \'ModuleImportFailure\':\n            try:\n                # This should always throw an ImportError exception.\n                getattr(obj, _get_bench_name(obj))()\n            except ImportError as e:\n                sys.exit(e.message.strip())\n        elif filter(obj):\n            out.append(obj)\n\n    return out\n\n\ndef _get_bench_name(bench):\n    return bench._testMethodName\n\n\ndef _get_bench_full_name(bench):\n    return \'%s.%s.%s\' % (type(bench).__module__, type(bench).__name__,\n                         _get_bench_name(bench))\n\n\ndef run(start_path):\n    parser = argparse.ArgumentParser(usage=_USAGE, description=_DESCRIPTION)\n    parser.add_argument(\'name\', nargs=\'*\',\n                        help=\'partial benchmark names to search\')\n    args = parser.parse_args()\n    selectors = args.name if args.name else None\n    benchs = _find_benchs(start_path, selectors)\n    suite = BenchLoader().suiteClass(benchs)\n    BenchRunner().run(suite)\n\n\nif __name__ == ""__main__"":\n    run(os.path.abspath(os.path.dirname(__file__)))\n'"
demos/equilibrium.py,0,"b'#!/usr/bin/env python\n\n""""""Aggregation of particles around the origin.\n\nFeatures:\n\n- simulation callbacks: particles are initialized within a radius from the\n  origin and are, at each simulation step, updated to move towards the origin\n  while keeping a separation distance from each other.\n- GUI event callback: on each left mouse button click, a new particle is added\n  to the simulation under the mouses\'s location.\n- neighbouring: each particle retrieve the neighbours within a radius to keep\n  itself separated from the others.\n""""""\n\nimport math\nimport os\nimport random\nimport sys\n\nimport sdl2\n\n_HERE = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, os.path.abspath(os.path.join(_HERE, os.pardir)))\n\nimport hienoi\nimport hienoi.application\nfrom hienoi import Vector2f, Vector4f\nfrom hienoi.application import Callback\nfrom hienoi.gui import NavigationAction\n\n\nif sys.version_info[0] == 2:\n    _range = xrange\nelse:\n    _range = range\n\n\n# Number of particles.\n_COUNT = 8\n# Radius of the disc used to distribute the particles.\n_RADIUS = 30.0\n# Size of a particle.\n_SIZE = 1.0\n# Strength of the attraction towards the origin.\n_ATTRACTION_FORCE = 1.0\n# Threshold distance below which a particle starts separating from another.\n_SEPARATION_DISTANCE = 5.0\n# Strength of the separation force.\n_SEPARATION_FORCE = 50.0\n\n\ndef _rand(seed=None):\n    """"""Generate a pseudo-random number ranging from 0.0 to 1.0.""""""\n    random.seed(seed)\n    return random.random()\n\n\ndef _rand_0(seed=None):\n    """"""Generate a pseudo-random number around 0, ranging from -1.0 to 1.0.""""""\n    random.seed(seed)\n    return random.random() * 2.0 - 1.0\n\n\ndef _remap_clamped(value, from_1, to_1, from_2, to_2):\n    """"""Remap a value from a range to another.""""""\n    result = ((value - from_1) / (to_1 - from_1)) * (to_2 - from_2) + from_2\n    return sorted((from_2, result, to_2))[1]\n\n\ndef _add_particle(sim, position):\n    """"""Inter-process callback to add a new particle to the simulation.\n\n    The first parameter of inter-process callbacks is always reserved for\n    the object to operate on, here the particle simulation object. Remaining\n    parameters are reserved to the user.\n    """"""\n    sim.add_particle(position=position, size=_SIZE)\n\n\ndef on_gui_event(gui, data, event):\n    """"""Callback to react to GUI events.\n\n    Parameters\n    ----------\n    gui : hienoi.gui.GUI\n        GUI.\n    data : hienoi.application.OnEventData\n        Data.\n    event : sdl2.SDL_Event\n        GUI event.\n    """"""\n    if event.type == sdl2.SDL_MOUSEBUTTONDOWN:\n        button_event = event.button\n        if (button_event.button == sdl2.SDL_BUTTON_LEFT\n                and gui.navigation_action == NavigationAction.NONE):\n            # Create an \'add_particle\' callback to be run by the particle\n            # simulation object.\n            mouse_position = gui.get_mouse_position()\n            position = gui.screen_to_world(mouse_position)\n            callback = Callback(_add_particle, args=(position,))\n            data.callbacks.particle_simulation.append(callback)\n\n\ndef initialize_particle_simulation(sim):\n    """"""Callback to initialize the particle simulation state.\n\n    Parameters\n    ----------\n    sim : hienoi.dynamics.ParticleSimulation\n        Particle simulation.\n    """"""\n    # Add a few particles at random positions within a given radius and with\n    # random velocities having a magnitude ranging from -1.0 to 1.0.\n    for i in _range(_COUNT):\n        r = _rand(seed=i + 0.827) * _RADIUS\n        t = _rand(seed=i + 0.301) * 2.0 * math.pi\n        sim.add_particle(position=Vector2f(r * math.cos(t), r * math.sin(t)),\n                         size=_SIZE)\n\n\ndef update_particle_simulation(sim):\n    """"""Callback to update the particle simulation state.\n\n    Parameters\n    ----------\n    sim : hienoi.dynamics.ParticleSimulation\n        Particle simulation.\n    """"""\n    for particle in sim.particles:\n        # Compute the attractive force.\n        force = -particle.position - particle.velocity\n        force.iscale(_ATTRACTION_FORCE)\n        particle.force += force\n\n        # Compute the separative force.\n        highest_proximity = 0.0\n        radius = _SIZE * 2.0 + _SEPARATION_DISTANCE\n        squared_radius = radius ** 2\n        neighbours = sim.get_neighbour_particles(\n            particle.position, count=None, radius=radius)\n        for neighbour in neighbours:\n            if neighbour.particle.id == particle.id:\n                continue\n\n            if neighbour.squared_distance > squared_radius:\n                continue\n\n            proximity = _remap_clamped(neighbour.distance,\n                                       particle.size, radius,\n                                       1.0, 0.0)\n            highest_proximity = max(proximity, highest_proximity)\n\n            force = particle.position - neighbour.particle.position\n            force.iscale(proximity * _SEPARATION_FORCE)\n            particle.force += force\n\n        # Color the particle according to how near it is to any other particle.\n        particle.color = Vector4f(1.0,\n                                  1.0 - highest_proximity,\n                                  1.0 - highest_proximity,\n                                  1.0)\n\n\ndef run():\n    """"""Run the application.""""""\n    return hienoi.application.run(\n        gui={\n            \'window_title\': \'equilibrium\',\n            \'show_grid\': False,\n            \'on_event_callback\': on_gui_event,\n        },\n        particle_simulation={\n            \'initialize_callback\': initialize_particle_simulation,\n            \'postsolve_callback\': update_particle_simulation,\n        })\n\n\nif __name__ == \'__main__\':\n    sys.exit(run())\n'"
demos/intro.py,0,"b'#!/usr/bin/env python\n\n""""""Introductory demo showing a basic set-up.\n\nFeatures:\n\n- simulation callbacks: spawn a single particle then, at each simulation\n  step, add a force towards the origin proportional to its distance to it.\n""""""\n\nimport os\nimport sys\n\n_HERE = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, os.path.abspath(os.path.join(_HERE, os.pardir)))\n\nimport hienoi.application\nfrom hienoi import Vector2f\n\n\ndef initialize_particle_simulation(sim):\n    """"""Callback to initialize the particle simulation state.\n\n    Parameters\n    ----------\n    sim : hienoi.dynamics.ParticleSimulation\n        Particle simulation.\n    """"""\n    # Let\'s add a single particle to the simulation. Since in the `run()`\n    # function below we override the applications\'s configuration attribute\n    # `view_aperture` with a value of 80.0, then the view is set to initially\n    # show 80 world units in the X axis. By setting the initial X position of\n    # the particle to 30.0, it should spawn at the 3/4th location of the\n    # screen\'s right half.\n    sim.add_particle(position=Vector2f(30.0, 0.0))\n\n\ndef update_particle_simulation(sim):\n    """"""Callback to update the particle simulation state.\n\n    Parameters\n    ----------\n    sim : hienoi.dynamics.ParticleSimulation\n        Particle simulation.\n    """"""\n    # Because this function is passed to the particle simulation\'s\n    # `postsolve_callback`, it runs at the end of each simulation step. As a\n    # result, the changes applied here are rendered as-is until the next\n    # simulation step. If we\'d want to have our changes to the force and\n    # velocity attributes to be immediately solved by the integrator then we\'d\n    # use `presolve_callback` instead.\n\n    # Now let\'s retrieve the particle created during initialization and apply\n    # an attractive force towards the origin to it. But before doing so,\n    # reading some explanations provided with the class\n    # `hienoi.dynamics.ParticleSimulation` might prove useful.\n\n    # To attract the particle to the origin, we need a force, defined as a 2D\n    # vector, that starts at the current particle\'s position and that is\n    # directed towards the origin. An example of such a force is the vector\n    # (origin.x - position.x, origin.y - position.y), which can be simplified\n    # to (-position.x, -position.y) since the origin has coordinates (0, 0).\n    # The vector could be further scaled to increase or decrease its magnitude,\n    # thus influencing how fast the particle moves towards its goal.\n    particle = sim.particles[0]\n    particle.force -= particle.position\n\n\ndef run():\n    """"""Run the application.""""""\n    # Each module in Hienoi provides a configuration object that we can use to\n    # hook our code into the framework but also to override default settings\n    # such as the simulation\'s time step.\n    return hienoi.application.run(\n        gui={\n            \'window_title\': \'intro\',\n            \'view_aperture_x\': 80.0,\n            \'grid_density\': 8.0,\n        },\n        particle_simulation={\n            \'time_step\': 0.01,\n            \'initialize_callback\': initialize_particle_simulation,\n            \'postsolve_callback\': update_particle_simulation,\n        })\n\n\nif __name__ == \'__main__\':\n    sys.exit(run())\n'"
demos/orbit.py,0,"b'#!/usr/bin/env python\n\n""""""Particles orbiting around the origin.\n\nFeatures:\n\n- user attributes: particles are initialized within a radius from the\n  origin and are, at each simulation step, updated to orbit around the origin.\n- NumPy: operations are done directly on the particle data for increased\n  performances.\n""""""\n\nimport math\nimport os\nimport sys\n\nimport numpy\n\n_HERE = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, os.path.abspath(os.path.join(_HERE, os.pardir)))\n\nimport hienoi.application\nfrom hienoi import Vector2f, Vector4f\n\n\n# Mass of the central object around which particles are orbiting.\n_CENTRAL_MASS = 50.0\n# Number of particles.\n_COUNT = 1000\n# Minimum radius of the disc used to distribute the particles.\n_MIN_RADIUS = 2.0\n# Maximum radius of the disc used to distribute the particles.\n_MAX_RADIUS = 30.0\n# Mass of each particle.\n_MASS = 2.0\n# Mass variance for each particle.\n_MASS_VARIANCE = 1.0\n# Size of a particle, relative to its mass.\n_SIZE = 0.2\n# Squared distance to the origin where particles are drawn in the \'far color\'.\n_FAR_SQUARED_DISTANCE = 500.0\n# Color to use for far particles.\n_FAR_COLOR = Vector4f(0.0, 1.0, 1.0, 1.0)\n# Color to use for near particles.\n_NEAR_COLOR = Vector4f(1.0, 0.0, 0.0, 1.0)\n\n\ndef initialize_particle_simulation(sim):\n    """"""Callback to initialize the particle simulation state.\n\n    Parameters\n    ----------\n    sim : hienoi.dynamics.ParticleSimulation\n        Particle simulation.\n    """"""\n    numpy.random.seed(_COUNT + 611)\n\n    # Add a few particles at random positions within a given radius and with\n    # initial velocities suitable for elliptical orbiting.\n    particles = sim.add_particles(_COUNT)\n    data = particles.data\n\n    r = numpy.random.uniform(low=_MIN_RADIUS, high=_MAX_RADIUS, size=_COUNT)\n    t = numpy.random.uniform(high=2.0 * numpy.pi, size=_COUNT)\n\n    data[\'position\'][:, 0] = r * numpy.cos(t)\n    data[\'position\'][:, 1] = r * numpy.sin(t)\n\n    data[\'mass\'] = numpy.random.uniform(low=_MASS - _MASS_VARIANCE,\n                                        high=_MASS + _MASS_VARIANCE,\n                                        size=_COUNT)\n\n    speeds = numpy.sqrt(data[\'mass\'] / r)\n    data[\'velocity\'][:, 0] = data[\'position\'][:, 1] * speeds\n    data[\'velocity\'][:, 1] = -data[\'position\'][:, 0] * speeds\n\n    data[\'size\'] = data[\'mass\'] * _SIZE / _MASS\n\n\ndef update_particle_simulation(sim):\n    """"""Callback to update the particle simulation state.\n\n    Parameters\n    ----------\n    sim : hienoi.dynamics.ParticleSimulation\n        Particle simulation.\n    """"""\n    data = sim.particles.data\n    squared_distances = numpy.sum(data[\'position\'][numpy.newaxis, :] ** 2,\n                                  axis=-1)\n    squared_distances = squared_distances.reshape(-1, 1)\n\n    data[\'force\'] -= (data[\'position\']\n                      * _CENTRAL_MASS\n                      * data[\'mass\'][:, numpy.newaxis]\n                      / squared_distances)\n\n    data[\'color\'] = (_FAR_COLOR - _NEAR_COLOR)\n    data[\'color\'] *= squared_distances / _FAR_SQUARED_DISTANCE\n    data[\'color\'] += _NEAR_COLOR\n\n\ndef run():\n    """"""Run the application.""""""\n    return hienoi.application.run(\n        gui = {\n            \'window_title\': \'orbit\',\n            \'show_grid\': False,\n        },\n        particle_simulation={\n            \'initialize_callback\': initialize_particle_simulation,\n            \'postsolve_callback\': update_particle_simulation,\n        })\n\n\nif __name__ == \'__main__\':\n    sys.exit(run())\n'"
demos/trail.py,0,"b'#!/usr/bin/env python\n\n""""""Emit particles based on the mouse\'s motion.\n\nFeatures:\n\n- user attributes: new attributes are defined both globally at the simulation\n  level and on each particle to respectively define the properties of the\n  emitter and to allow particles to die after a given amount of time.\n- GUI event callback: trigger the spawning of new particles whenever the mouse\n  is in motion.\n- simulation callbacks: initialize the user attributes then, at each simulation\n  step, update the particle ages and colors, and spawn new ones as per the GUI\n  event callback.\n""""""\n\nimport math\nimport os\nimport random\nimport sys\n\nimport sdl2\n\n_HERE = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, os.path.abspath(os.path.join(_HERE, os.pardir)))\n\nimport hienoi.application\nfrom hienoi import Float32, Number, Vector2i, Vector2f, Vector4f\nfrom hienoi.application import Callback\n\n\nif sys.version_info[0] == 2:\n    _range = xrange\nelse:\n    _range = range\n\n\n# Lifespan of each particle.\n_EMITTER_LIFE = 1.0\n# Lifespan variance for each particle.\n_EMITTER_LIFE_VARIANCE = 0.5\n# Strength of the velocity to inherit from the emitter.\n_EMITTER_INHERIT_VELOCITY = 0.25\n# Strength of the random velocity component.\n_EMITTER_RANDOM_VELOCITY = 5.0\n# Strength variance for the random velocity component.\n_EMITTER_RANDOM_VELOCITY_VARIANCE = 2.5\n# Approximate distance between spawn location for long strokes.\n_STEP_LENGTH = 0.5\n# Velocity needed for particles to be painted in the \'fast color\'.\n_FAST_VELOCITY = 100.0\n# Color to use for fast particles.\n_FAST_COLOR = Vector4f(1.0, 1.0, 0.0, 1.0)\n# Color to use for slow particles.\n_SLOW_COLOR = Vector4f(1.0, 0.0, 0.0, 1.0)\n\n\ndef _rand(seed=None):\n    """"""Generate a pseudo-random number ranging from 0.0 to 1.0.""""""\n    random.seed(seed)\n    return random.random()\n\n\ndef _rand_0(seed=None):\n    """"""Generate a pseudo-random number around 0, ranging from -1.0 to 1.0.""""""\n    random.seed(seed)\n    return random.random() * 2.0 - 1.0\n\n\ndef _remap_clamped(value, from_1, to_1, from_2, to_2):\n    """"""Remap a value from a range to another.\n\n    If the resulting value is outside the bounds of the target range, then it\n    is clamped.\n    """"""\n    result = ((value - from_1) / (to_1 - from_1)) * (to_2 - from_2) + from_2\n    return sorted((from_2, result, to_2))[1]\n\n\ndef _get_particle_color(velocity, normalized_age):\n    """"""Color to be applied to a particle depending on its speed and age.""""""\n    speed = min(1.0, velocity.length() / _FAST_VELOCITY)\n    color = Vector4f.lerp(_SLOW_COLOR, _FAST_COLOR, speed)\n    color.iscale(_remap_clamped(normalized_age, 0.0, 1.0, 1.0, 0.5))\n    return color\n\n\ndef _set_emitter_position(sim, position):\n    """"""Inter-process callback to set a new emitter position.\n\n    The first parameter of inter-process callbacks is always reserved for\n    the object to operate on, here the particle simulation object. Remaining\n    parameters are reserved to the user.\n    """"""\n    if position is None:\n        sim.user_data.emitter_position = None\n        sim.user_data.previous_emitter_position = None\n        sim.user_data.previous_emitter_velocity = Vector2f(0.0, 0.0)\n\n    sim.user_data.emitter_position = position\n\n\ndef on_gui_event(gui, data, event):\n    """"""Callback to react to GUI events.\n\n    Parameters\n    ----------\n    gui : hienoi.gui.GUI\n        GUI.\n    data : hienoi.application.OnEventData\n        Data.\n    event : sdl2.SDL_Event\n        GUI event.\n    """"""\n    if gui.has_view_changed:\n        # Passing `None` to the `_set_emitter_position` callback resets the\n        # emitter states, which is what we need here otherwise we might end up\n        # with crazy values coming out of the navigation actions.\n        callback = Callback(_set_emitter_position, args=(None,))\n        data.callbacks.particle_simulation.append(callback)\n    elif event.type == sdl2.SDL_MOUSEMOTION:\n        motion_event = event.motion\n        mouse_position = Vector2i(motion_event.x, motion_event.y)\n        position = gui.screen_to_world(mouse_position)\n        callback = Callback(_set_emitter_position, args=(position,))\n        data.callbacks.particle_simulation.append(callback)\n\n\ndef initialize_particle_simulation(sim):\n    """"""Callback to initialize the particle simulation state.\n\n    Parameters\n    ----------\n    sim : hienoi.dynamics.ParticleSimulation\n        Particle simulation.\n    """"""\n    # Create a new global attribute for the position of the emitter but let\'s\n    # leave it uninitialized until a mouse motion event is recorded.\n    sim.user_data.emitter_position = None\n\n    # And a couple more for its previous position and previous velocity.\n    sim.user_data.previous_emitter_position = None\n    sim.user_data.previous_emitter_velocity = Vector2f(0.0, 0.0)\n\n\ndef update_particle_simulation(sim):\n    """"""Callback to update the particle simulation state.\n\n    Parameters\n    ----------\n    sim : hienoi.dynamics.ParticleSimulation\n        Particle simulation.\n    """"""\n    seed = sim.last_particle_id + 0.293\n\n    # By overriding the `particle_attributes` value for the particle simulation\n    # in the `run()` function below, each particle comes with extras \'age\' and\n    # \'life\' attributes.\n\n    for particle in sim.particles:\n        # At each simulation step, the particles are aged accordingly.\n        particle.age += sim.time_step\n\n        if particle.age > particle.life:\n            # The particle\'s age is greater than its lifespan, kill it.\n            particle.alive = False\n        else:\n            particle.color = _get_particle_color(particle.velocity,\n                                                 particle.age / particle.life)\n\n    # Source any new particles.\n    emitter_position = sim.user_data.emitter_position\n    previous_emitter_position = sim.user_data.previous_emitter_position\n    previous_emitter_velocity = sim.user_data.previous_emitter_velocity\n    if previous_emitter_position is not None:\n        # Retrieve the trajectory of the latests emitter positions recorded,\n        # which are derived from the mouse motions, then spawn new particles\n        # along that trajecotry, with each spawn location being separated from\n        # the previous one by a \'step\' measure.\n        translation = emitter_position - previous_emitter_position\n        emitter_velocity = translation.scale(1.0 / sim.time_step)\n        distance = translation.length()\n        step_count = int(math.ceil(distance / _STEP_LENGTH))\n        for i in _range(step_count):\n            step = float(i) / step_count\n\n            # The age is relative to the current step position. The further the\n            # step is from the latest emitter position, the more the older the\n            # particle should be.\n            age = step * sim.time_step\n            life = (_EMITTER_LIFE\n                    + _EMITTER_LIFE_VARIANCE\n                    * _rand_0(seed=seed + i + 0.084))\n\n            # A random velocity vector is defined with its length set as per\n            # the given constants.\n            velocity = Vector2f(_rand_0(seed=seed + i + 0.318),\n                                _rand_0(seed=seed + i + 0.702))\n            velocity.inormalize()\n            velocity.iscale(_EMITTER_RANDOM_VELOCITY\n                            + _EMITTER_RANDOM_VELOCITY_VARIANCE\n                            * _rand_0(seed=seed + i + 0.775))\n\n            # The final velocity for the particle is computed by adding the\n            # velocity of the emitter, blended with its previous velocity\n            # depending on the current step, to the random velocity.\n            velocity += Vector2f.lerp(\n                emitter_velocity, previous_emitter_velocity, step).iscale(\n                    _EMITTER_INHERIT_VELOCITY)\n\n            # The particle is spawned at the current step position and is then\n            # pushed along its velocity according to its age.\n            position = emitter_position + translation.scale(-step)\n            position += velocity.scale(age)\n\n            # Initialize each particle\'s color relatively to its speed and age.\n            color = _get_particle_color(velocity, age / life)\n\n            sim.add_particle(position=position,\n                             velocity=velocity,\n                             age=age,\n                             life=life,\n                             size=_rand(seed=seed + i + 0.855),\n                             color=color)\n\n        sim.user_data.previous_emitter_velocity = emitter_velocity\n\n    sim.user_data.previous_emitter_position = emitter_position\n\n\ndef run():\n    """"""Run the application.""""""\n    return hienoi.application.run(\n        gui={\n            \'window_title\': \'trail\',\n            \'show_grid\': False,\n            \'on_event_callback\': on_gui_event,\n        },\n        particle_simulation={\n            \'particle_attributes\': (\n                (\'age\', Number(type=Float32, default=0.0)),\n                (\'life\', Number(type=Float32, default=1.0)),\n            ),\n            \'initialize_callback\': initialize_particle_simulation,\n            \'postsolve_callback\': update_particle_simulation,\n        })\n\n\nif __name__ == \'__main__\':\n    sys.exit(run())\n'"
hienoi/__init__.py,0,"b'#    __    __                   __\n#   |  |--|__.-----.-----.-----|__|\n#   |     |  |  -__|     |  _  |  |\n#   |__|__|__|_____|__|__|_____|__|\n#\n\n""""""Playground to experiment with 2D particles.""""""\n\n__title__ = \'hienoi\'\n__version__ = \'0.2.0\'\n__summary__ = ""2D particle playground""\n__url__ = \'https://github.com/christophercrouzet/hienoi\'\n__author__ = ""Christopher Crouzet""\n__contact__ = \'christopher.crouzet@gmail.com\'\n__license__ = ""MIT""\n\nfrom hienoi._common import ParticleDisplay\nfrom hienoi._nani import *\nfrom hienoi._numeric import *\nfrom hienoi._vectors import *\n'"
hienoi/_common.py,0,"b'""""""Common data structures, enumerators, and constants.""""""\n\nimport collections\n\nimport hienoi._nani\nfrom hienoi._numeric import Float32\nfrom hienoi._vectors import VECTOR2F, COLOR4F\n\n\nclass ParticleDisplay(object):\n    """"""Enumerator for the displays available to draw particles.\n\n    Attributes\n    ----------\n    POINT\n    CIRCLE\n    DISC\n    """"""\n\n    POINT = 0\n    CIRCLE = 1\n    DISC = 2\n    _LAST = DISC\n\n\nclass GraphicsAPI(object):\n    """"""Enumerator for the graphics APIs supported.""""""\n\n    OPENGL = 0\n\n\nclass GLProfile(object):\n    """"""Enumerator for the OpenGL profiles supported.""""""\n\n    CORE = 0\n\n\nclass UserData(object):\n    """"""Placeholder for user data.""""""\n    pass\n\n\n_ParticleAttributes = collections.namedtuple(\n    \'ParticleAttributes\', (\n        \'position\',\n        \'size\',\n        \'color\',\n    ))\n\n\nclass ParticleAttributes(_ParticleAttributes):\n    """"""Particle attributes to be used by the renderer.""""""\n\n    __slots__ = ()\n\n\n_Attribute = collections.namedtuple(\n    \'Attribute\', (\n        \'nani\',\n        \'element_type\',\n        \'count\',\n    ))\n\n\nclass Attribute(_Attribute):\n    """"""Attribute.""""""\n\n    __slots__ = ()\n\n\nPARTICLE_ATTRS = ParticleAttributes(\n    position=Attribute(\n        nani=VECTOR2F,\n        element_type=VECTOR2F.element_type.type,\n        count=2),\n    size=Attribute(\n        nani=hienoi._nani.Number(type=Float32, default=1.0),\n        element_type=Float32,\n        count=1),\n    color=Attribute(\n        nani=COLOR4F,\n        element_type=COLOR4F.element_type.type,\n        count=4))\n\nPARTICLE_NANI = hienoi._nani.resolve(\n    hienoi._nani.Structure(\n        fields=[(field, getattr(PARTICLE_ATTRS, field).nani)\n                for field in PARTICLE_ATTRS._fields],\n        name=\'Particle\'))\n'"
hienoi/_dynamicarray.py,0,"b'""""""Dynamic array based on NumPy.""""""\n\nimport math\n\nimport numpy\n\n\n_GROW_FACTOR = 1.5\nassert _GROW_FACTOR > 1.0\n\n\nclass DynamicArray(object):\n    """"""Dynamic array based on NumPy.\n\n    This represents a dynamic contiguous array along the lines of the C++\n    ``std::vector`` container.\n    """"""\n\n    @classmethod\n    def from_buffer(cls, buf, dtype):\n        """"""Unpack a buffer object into a new array.""""""\n        this = DynamicArray(0, dtype)\n        this._array = numpy.frombuffer(buf, dtype)\n        this._size = len(this._array)\n        return this\n\n    def __init__(self, capacity, dtype):\n        self._array = numpy.empty(capacity, dtype=dtype)\n        self._size = 0\n\n    def __len__(self):\n        return self._size\n\n    @property\n    def data(self):\n        return self._array[:self._size]\n\n    @property\n    def capacity(self):\n        return len(self._array)\n\n    @property\n    def dtype(self):\n        return self._array.dtype\n\n    def copy_from(self, data):\n        """"""Replace the data with a copy of some other data.""""""\n        size = len(data)\n        self.grow(size, copy=False)\n        for field in self._array.dtype.fields:\n            self._array[field][:size] = data[field]\n\n        self._size = size\n\n    def grow(self, requested, copy=True):\n        """"""Increase the storage\'s capacity if needed.""""""\n        if requested <= len(self._array):\n            return\n\n        capacity = max(requested,\n                       int(max(len(self._array) * _GROW_FACTOR,\n                               math.ceil(1.0 / (_GROW_FACTOR - 1.0)) * 2)))\n        array = numpy.empty(capacity, dtype=self._array.dtype)\n        if copy:\n            array[:self._size] = self._array[:self._size]\n        else:\n            self._size = 0\n\n        self._array = array\n\n    def resize(self, requested, copy=True):\n        """"""Change the size of the array.""""""\n        self.grow(requested, copy=copy)\n        self._size = requested\n\n    def append(self, data):\n        """"""Append a new element.""""""\n        new_size = self._size + 1\n        self.grow(new_size)\n        self._array[self._size] = data\n        out = self._array[self._size]\n        self._size = new_size\n        return out\n\n    def extend(self, data):\n        """"""Append multiple elements.""""""\n        new_size = self._size + len(data)\n        self.grow(new_size)\n        self._array[self._size:new_size] = data\n        out = self._array[self._size:new_size]\n        self._size = new_size\n        return out\n\n    def clear(self):\n        """"""Clear the data.""""""\n        self._size = 0\n'"
hienoi/_kdtree.py,0,"b'""""""Kd-tree for nearest neighbours queries.\n\nThis implementation currently runs faster than SciPy\'s KDTree but is often\nslower than a brute-force approach in Hienoi\'s use cases, killing the primary\npurpose for such a data structure. Still, it is left here as an educational\nresource.\n""""""\n\nimport collections\nimport heapq\nimport itertools\nimport sys\n\nimport numpy\n\nfrom hienoi._dynamicarray import DynamicArray\n\n\nif sys.version_info[0] == 2:\n    _range = xrange\n    _zip = itertools.izip\nelse:\n    _range = range\n    _zip = zip\n\n_heappushpop = heapq.heappushpop\n_heappush = heapq.heappush\n_npmax = numpy.maximum\n\n\n_INITIAL_NEIGHBOURS_CAPACITY = 32\n\n\nclass KDTree(object):\n    """"""K-d tree.\n\n    Nodes are stored contiguously in memory.\n    """"""\n\n    def __init__(self, data, bucket_size=128):\n        if bucket_size < 1:\n            raise ValueError(""A minimum bucket size of 1 is expected."")\n\n        self._data = data\n        self._n, self._k = self._data.shape\n        self._nodes = None\n        self._buckets = []\n        self._bucket_size = bucket_size\n\n        self._node_dtype = numpy.dtype([\n            (\'size\', numpy.intp),\n            (\'bucket\', numpy.intp),\n            (\'lower_bounds\', (numpy.float_, self._k)),\n            (\'upper_bounds\', (numpy.float_, self._k)),\n        ])\n        self._neighbour_dtype = numpy.dtype([\n            (\'squared_distance\', numpy.float_),\n            (\'index\', numpy.intp),\n        ])\n\n        self._build()\n\n    def search(self, point, count, radius, sort):\n        """"""Retrieve the neighbours to a point.""""""\n        if count is None:\n            count = self._n\n        elif count < 1:\n            return numpy.empty(0, dtype=self._neighbour_dtype)\n\n        if radius is None:\n            radius = numpy.inf\n        elif radius < 0.0:\n            return numpy.empty(0, dtype=self._neighbour_dtype)\n\n        point = numpy.asarray(point, dtype=numpy.float_)\n        if count >= self._n:\n            return self._search_all_within_radius(point, radius, sort)\n        else:\n            return self._search_k_nearests(point, count, radius, sort)\n\n    def _build(self):\n        """"""Build the k-d tree.""""""\n        data = self._data\n        buckets = self._buckets\n        bucket_size = self._bucket_size\n\n        # First pass: build the tree using a DFS ordering.\n        nodes = []\n        parents = []\n        i = 0\n        stack = collections.deque(((numpy.arange(self._n), None),))\n        while stack:\n            indices, parent = stack.popleft()\n            points = data[indices]\n            lower_bounds = numpy.amin(points, axis=0)\n            upper_bounds = numpy.amax(points, axis=0)\n            if len(points) <= bucket_size:\n                bucket = len(buckets)\n                buckets.append(indices)\n            else:\n                bucket = -1\n\n                # Split the longest side of the bounds.\n                side_lengths = upper_bounds - lower_bounds\n                split_axis = numpy.argmax(side_lengths)\n                split_location = (lower_bounds[split_axis]\n                                  + upper_bounds[split_axis]) / 2.0\n                axis_data = points[:, split_axis]\n                left_indices = indices[\n                    numpy.nonzero(axis_data <= split_location)[0]]\n                right_indices = indices[\n                    numpy.nonzero(axis_data > split_location)[0]]\n                stack.appendleft((right_indices, i))\n                stack.appendleft((left_indices, i))\n\n            size = 1\n            nodes.append((size, bucket, lower_bounds, upper_bounds))\n            parents.append(parent)\n            i += 1\n\n        # Second pass: set the \'size\' attribute for each node in the tree.\n        # Iterate over the nodes in reverse order to perform a bottom-up\n        # traversal where the size of each node is added to the size of its\n        # parent.\n        self._nodes = numpy.array(nodes, dtype=self._node_dtype)\n        node_sizes = self._nodes[\'size\']\n        for i in reversed(_range(1, len(self._nodes))):\n            node_sizes[parents[i]] += node_sizes[i]\n\n    def _search_k_nearests(self, point, count, radius, sort):\n        """"""Search the nearest points within a radius.""""""\n        data = self._data\n        nodes = self._nodes\n        buckets = self._buckets\n\n        node_sizes = nodes[\'size\']\n        node_buckets = nodes[\'bucket\']\n        node_lower_bounds = nodes[\'lower_bounds\']\n        node_upper_bounds = nodes[\'upper_bounds\']\n\n        # A max heap would be appropriate to store the nearest points found,\n        # alas Python only provides a min heap as part of the `heapq` module.\n        # As a hacky workaround, nearest distances are negated.\n        nearests = []\n        dist_limit = radius ** 2\n\n        pt_root_dist = _pt_to_node_near_dist(\n            point, node_lower_bounds[0], node_upper_bounds[0])\n        stack = collections.deque(((0, pt_root_dist),))\n        while stack:\n            i, pt_node_dist = stack.popleft()\n            if pt_node_dist > dist_limit:\n                # The node\'s bounds are too far, skip this branch.\n                pass\n            elif node_sizes[i] == 1:\n                # This is a leaf node, see if there are any nearest points.\n                indices = buckets[node_buckets[i]]\n                points = data[indices]\n                dists = numpy.sum(\n                    (point[numpy.newaxis, :] - points) ** 2, axis=-1)\n                for j, dist in _zip(indices, dists):\n                    if dist < dist_limit:\n                        if len(nearests) >= count:\n                            dist_limit = -_heappushpop(nearests, (-dist, j))[0]\n                        else:\n                            _heappush(nearests, (-dist, j))\n            else:\n                # Inspect the child nodes.\n                left_node_idx = i + 1\n                right_node_idx = i + 1 + node_sizes[left_node_idx]\n                pt_left_node_dist = _pt_to_node_near_dist(\n                    point, node_lower_bounds[left_node_idx],\n                    node_upper_bounds[left_node_idx])\n                pt_right_node_dist = _pt_to_node_near_dist(\n                    point, node_lower_bounds[right_node_idx],\n                    node_upper_bounds[right_node_idx])\n                if pt_left_node_dist <= pt_right_node_dist:\n                    stack.appendleft((right_node_idx, pt_right_node_dist))\n                    stack.appendleft((left_node_idx, pt_left_node_dist))\n                else:\n                    stack.appendleft((left_node_idx, pt_left_node_dist))\n                    stack.appendleft((right_node_idx, pt_right_node_dist))\n\n        out = numpy.array(nearests, dtype=self._neighbour_dtype)\n        out[\'squared_distance\'] *= -1.0\n        if sort:\n            # Here is the biggest performance killer. Runs in a single thread.\n            out.sort(order=\'squared_distance\')\n\n        return out\n\n    def _search_all_within_radius(self, point, radius, sort):\n        """"""Search all the points within a radius.""""""\n        data = self._data\n        nodes = self._nodes\n        buckets = self._buckets\n\n        node_sizes = nodes[\'size\']\n        node_buckets = nodes[\'bucket\']\n        node_lower_bounds = nodes[\'lower_bounds\']\n        node_upper_bounds = nodes[\'upper_bounds\']\n\n        radius **= 2\n        neighbours = DynamicArray(_INITIAL_NEIGHBOURS_CAPACITY,\n                                  self._neighbour_dtype)\n\n        pt_root_dist = _pt_to_node_near_dist(\n            point, node_lower_bounds[0], node_upper_bounds[0])\n        stack = collections.deque(((0, pt_root_dist),))\n        while stack:\n            i, pt_node_near_dist = stack.popleft()\n            if pt_node_near_dist > radius:\n                # The node\'s bounds are too far, skip this branch.\n                pass\n            elif (_pt_to_node_far_dist(\n                    point, node_lower_bounds[i], node_upper_bounds[i])\n                  <= radius):\n                # The node\'s bounds are within the radius, recursively retrieve\n                # all the points.\n                children = nodes[i:i + node_sizes[i]]\n                leaves = numpy.extract(children[\'size\'] == 1, children)\n                count = sum(len(buckets[bucket])\n                            for bucket in leaves[\'bucket\'])\n                j = len(neighbours)\n                neighbours.resize(j + count)\n                neighbours.data[\'squared_distance\'][j:] = numpy.nan\n                for bucket in leaves[\'bucket\']:\n                    indices = buckets[bucket]\n                    count = len(indices)\n                    neighbours.data[\'index\'][j:j + count] = indices\n                    j += count\n            elif node_sizes[i] == 1:\n                # This is a leaf node, see if there are any points within the\n                # radius.\n                indices = buckets[node_buckets[i]]\n                points = data[indices]\n                dists = numpy.sum(\n                    (point[numpy.newaxis, :] - points) ** 2, axis=-1)\n                is_within = dists <= radius\n                j = len(neighbours)\n                neighbours.resize(j + numpy.sum(is_within))\n                neighbours.data[\'squared_distance\'][j:] = dists[is_within]\n                neighbours.data[\'index\'][j:] = indices[is_within]\n            else:\n                # Inspect the child nodes.\n                left_node_idx = i + 1\n                right_node_idx = i + 1 + node_sizes[left_node_idx]\n                pt_left_node_dist = _pt_to_node_near_dist(\n                    point, node_lower_bounds[left_node_idx],\n                    node_upper_bounds[left_node_idx])\n                pt_right_node_dist = _pt_to_node_near_dist(\n                    point, node_lower_bounds[right_node_idx],\n                    node_upper_bounds[right_node_idx])\n                if pt_left_node_dist <= pt_right_node_dist:\n                    stack.appendleft((right_node_idx, pt_right_node_dist))\n                    stack.appendleft((left_node_idx, pt_left_node_dist))\n                else:\n                    stack.appendleft((left_node_idx, pt_left_node_dist))\n                    stack.appendleft((right_node_idx, pt_right_node_dist))\n\n        # Compute all the distances.\n        is_nan = numpy.isnan(neighbours.data[\'squared_distance\'])\n        indices = neighbours.data[\'index\'][numpy.nonzero(is_nan)]\n        points = data[indices]\n        dists = numpy.sum((point[numpy.newaxis, :] - points) ** 2, axis=-1)\n        neighbours.data[\'squared_distance\'][is_nan] = dists\n\n        if sort:\n            # Here is the biggest performance killer. Runs in a single thread.\n            neighbours.data.sort(order=\'squared_distance\')\n\n        return neighbours.data\n\n\ndef _pt_to_node_near_dist(point, lower_bounds, upper_bounds):\n    return numpy.sum(\n        _npmax(0.0, _npmax(point - upper_bounds, lower_bounds - point))\n        ** 2)\n\n\ndef _pt_to_node_far_dist(point, lower_bounds, upper_bounds):\n    return numpy.sum(\n        _npmax(0.0, _npmax(upper_bounds - point, point - lower_bounds))\n        ** 2)\n'"
hienoi/_nani.py,0,"b'""""""Glue for the Nani library.""""""\n\n__all__ = [\'Bool\', \'Object\', \'Number\', \'String\', \'Unicode\', \'Array\',\n           \'Structure\', \'Bytes\', \'Str\', \'Field\', \'READ_ONLY\']\n\nimport collections\nimport sys\n\nimport nani\n\nimport hienoi._numeric\n\n\n_PY2 = sys.version_info[0] == 2\n\n\nif _PY2:\n    _BUILTIN_MODULE = \'__builtin__\'\n    _BuiltinString = str\n    _BuiltinUnicode = unicode\n    _range = xrange\nelse:\n    _BUILTIN_MODULE = \'builtins\'\n    _BuiltinString = bytes\n    _BuiltinUnicode = str\n    _range = range\n\n\nassert nani.Bool._fields == (\'default\', \'view\')\nassert nani.Object._fields == (\'default\', \'view\')\nassert nani.Number._fields == (\'type\', \'default\', \'view\')\nassert nani.String._fields == (\'length\', \'default\', \'view\')\nassert nani.Unicode._fields == (\'length\', \'default\', \'view\')\nassert nani.Array._fields == (\'element_type\', \'shape\', \'name\', \'view\')\nassert nani.Structure._fields == (\'fields\', \'name\', \'view\')\nassert nani.Field._fields == (\'name\', \'type\', \'read_only\')\n\n\nclass Bool(nani.Bool):\n    """"""Type corresponding to a boolean.\n\n    Attributes\n    ----------\n    default : bool\n        Default value.\n    view : type or None\n        If ``None``, the owning array returns a direct reference to this\n        boolean value, otherwise it is expected to be a class object wrapping\n        it and accepting 2 parameters: ``data``, the NumPy array owning the\n        boolean value, and ``index``, its position in the array.\n    """"""\n\n    __slots__ = ()\n\n\nBool.__new__.__defaults__ = (False, None)\n\n\nclass Object(nani.Object):\n    """"""Type corresponding to a Python object.\n\n    Attributes\n    ----------\n    default : object\n        Default value.\n    view : type or None\n        If ``None``, the owning array returns a direct reference to this Python\n        object, otherwise it is expected to be a class object wrapping it and\n        accepting 2 parameters: ``data``, the NumPy array owning the Python\n        object, and ``index``, its position in the array.\n    """"""\n\n    __slots__ = ()\n\n\nObject.__new__.__defaults__ = (None, None)\n\n\nclass Number(nani.Number):\n    """"""Type corresponding to a number.\n\n    Attributes\n    ----------\n    type : hienoi numerical type\n        Type of the number. Either one from :class:`Int8`, :class:`UInt8`,\n        :class:`Int16`, :class:`UInt16`, :class:`Int32`, :class:`UInt32`,\n        :class:`Float32`, or :class:`Float64`.\n    default : numbers.Number or numpy.number\n        Default value.\n    view : type or None\n        If ``None``, the owning array returns a direct reference to this\n        numeric value, otherwise it is expected to be a class object wrapping\n        it and accepting 2 parameters: ``data``, the NumPy array owning the\n        numeric value, and ``index``, its position in the array.\n    """"""\n\n    __slots__ = ()\n\n\nNumber.__new__.__defaults__ = (hienoi._numeric.Float32, 0, None)\n\n\nclass String(nani.String):\n    """"""Type corresponding to a string.\n\n    Attributes\n    ----------\n    length : int\n        Number of characters.\n    default : str on PY2 or bytes on PY3\n        Default value.\n    view : type or None\n        If ``None``, the owning array returns a direct reference to this string\n        value, otherwise it is expected to be a class object wrapping it and\n        accepting 2 parameters: ``data``, the NumPy array owning the string\n        value, and ``index``, its position in the array.\n    """"""\n\n    __slots__ = ()\n\n\nString.__new__.__defaults__ = (_BuiltinString(), None)\n\n\nclass Unicode(nani.Unicode):\n    """"""Type corresponding to a unicode string.\n\n    Attributes\n    ----------\n    length : int\n        Number of characters.\n    default : unicode on PY2 or str on PY3\n        Default value.\n    view : type or None\n        If ``None``, the owning array returns a direct reference to this\n        unicode value, otherwise it is expected to be a class object wrapping\n        it and accepting 2 parameters: ``data``, the NumPy array owning the\n        unicode value, and ``index``, its position in the array.\n    """"""\n\n    __slots__ = ()\n\n\nUnicode.__new__.__defaults__ = (_BuiltinUnicode(), None)\n\n\nclass Array(nani.Array):\n    """"""Type corresponding to an array.\n\n    Attributes\n    ----------\n    element_type : hienoi type\n        Type of each element.\n    shape : int or tuple of int\n        Shape of the array. Passing an int defines a 1D array.\n    name : str or None\n        Name for the view type if `view` is ``None``.\n    view : type or None\n        If ``None``, a view for this array is dynamically generated by Nani,\n        otherwise it is expected to be a class object wrapping it and accepting\n        1 parameter: ``data``, the corresponding NumPy array.\n    """"""\n\n    __slots__ = ()\n\n\nArray.__new__.__defaults__ = (None, None)\n\n\nclass Structure(nani.Structure):\n    """"""Type corresponding to a structure.\n\n    Attributes\n    ----------\n    fields : tuple of hienoi.Field or compatible tuple\n        Fields defining the structure.\n    name : str or None\n        Name for the view type if `view` is ``None``.\n    view : type or None\n        If ``None``, a view for this structured array is dynamically generated\n        by Nani, otherwise it is expected to be a class object wrapping it and\n        accepting 1 parameter: ``data``, the corresponding NumPy structured\n        array.\n    """"""\n\n    __slots__ = ()\n\n\nStructure.__new__.__defaults__ = (None, None)\n\n\n# Aliases.\nBytes = String\nif _PY2:\n    Str = String\nelse:\n    Str = Unicode\n\n\n_ALL_TYPES = (Bool, Object, Number, String, Unicode, Array, Structure)\n\n\nclass Field(nani.Field):\n    """"""Describe a field of a structured array.\n\n    Attributes\n    ----------\n    name : str\n        Name of the field.\n    type : nani data type\n        Type of the field.\n    read_only : bool\n        ``True`` to not define a setter property in the structured array view\n        if it is set to be dynamically generated by Nani.\n    """"""\n\n    __slots__ = ()\n\n\nField.__new__.__defaults__ = (False,)\n\n\nREAD_ONLY = nani.READ_ONLY\n\n\n_FIELD_TYPE = Field._fields.index(\'type\')\n_FIELD_ATTR_COUNT = len(Field._fields)\n\n\nNani = collections.namedtuple(\n    \'Nani\', (\n        \'dtype\',\n        \'default\',\n        \'view\',\n        \'element_view\'\n    ))\n\n\nclass PickableNaniStructure(object):\n    """"""Nani structure that can be pickled.""""""\n\n    def __init__(self, fields, name):\n        self._fields = fields\n        self._name = name\n        self._build()\n\n    def __getstate__(self):\n        return {\'_fields\': self._fields, \'_name\': self._name}\n\n    def __setstate__(self, state):\n        self.__dict__.update(state)\n        self._build()\n\n    def _build(self):\n        self._obj = resolve(Structure(fields=self._fields, name=self._name))\n        setattr(self._obj.view, \'data\', property(fget=lambda self: self._data))\n\n    @property\n    def dtype(self):\n        return self._obj.dtype\n\n    @property\n    def default(self):\n        return self._obj.default\n\n    @property\n    def view(self):\n        return self._obj.view\n\n    @property\n    def element_view(self):\n        return self._obj.element_view\n\n\ndef resolve(data_type, name=None):\n    """"""Retrieve the properties of a given data type.""""""\n    _validate(data_type)\n    data_type = _consolidate(data_type)\n    nani.validate(data_type)\n    properties = nani.resolve(data_type, name=name)\n    return Nani(\n        dtype=properties.dtype,\n        default=properties.default,\n        view=properties.view,\n        element_view=nani.get_element_view(properties.view))\n\n\ndef _validate(data_type):\n    """"""Check if the data type is well-formed.""""""\n    if not isinstance(data_type, _ALL_TYPES):\n        raise TypeError(\n            ""The data type \'%s\' isn\'t supported. It is expected to be an ""\n            ""instance object of type %s.""\n            % (type(data_type).__name__, _join_types(_ALL_TYPES, ""or "")))\n\n    if isinstance(data_type, Array):\n        _validate(data_type.element_type)\n    elif isinstance(data_type, Structure):\n        for field in data_type.fields:\n            _validate(field[_FIELD_TYPE])\n\n\ndef _consolidate(data_type):\n    """"""Enforce the structure of the data type.\n\n    Specifically, convert any hienoi type into its NumPy equivalent.\n    """"""\n    def get_field_item(field, i):\n        if i < len(field):\n            return field[i]\n        else:\n            i -= _FIELD_ATTR_COUNT\n            return Field.__new__.__defaults__[i]\n\n    if isinstance(data_type, Number):\n        out = data_type._replace(type=hienoi._numeric.to_numpy(data_type.type))\n    elif isinstance(data_type, Array):\n        out = data_type._replace(\n            element_type=_consolidate(data_type.element_type))\n    elif isinstance(data_type, Structure):\n        fields = tuple(\n            Field(*(_consolidate(get_field_item(field, i))\n                    if i == _FIELD_TYPE else get_field_item(field, i)\n                    for i in _range(_FIELD_ATTR_COUNT)))\n            for field in data_type.fields)\n        out = data_type._replace(fields=fields)\n    else:\n        out = data_type\n\n    return out\n\n\ndef _format_type(cls):\n    """"""Format a type name for printing.""""""\n    if cls.__module__ == _BUILTIN_MODULE:\n        return cls.__name__\n    else:\n        return \'%s.%s\' % (cls.__module__, cls.__name__)\n\n\ndef _format_element(element, count, idx, last_separator):\n    """"""Format an element from a sequence.\n\n    This only prepends a separator for the last element and wraps each element\n    with single quotes.\n    """"""\n    return (""%s\'%s\'"" % (last_separator, element)\n            if count > 1 and idx == count - 1\n            else ""\'%s\'"" % (element,))\n\n\ndef _join_sequence(seq, last_separator=\'\'):\n    """"""Join a sequence into a string.""""""\n    count = len(seq)\n    return \', \'.join(_format_element(element, count, i, last_separator)\n                     for i, element in enumerate(seq))\n\n\ndef _join_types(seq, last_separator=\'\'):\n    """"""Join class object names into a string.""""""\n    class_names = [_format_type(cls) for cls in seq]\n    return _join_sequence(class_names, last_separator)\n'"
hienoi/_numeric.py,0,"b'""""""Glue for numeric data types from different modules.""""""\n\n__all__ = [\'Int8\', \'UInt8\', \'Int16\', \'UInt16\', \'Int32\', \'UInt32\', \'Float32\',\n           \'Float64\']\n\nimport ctypes\n\nimport numpy\nimport OpenGL.GL as gl\n\n\nclass Int8(object):\n    """"""8-bit int type.""""""\n\n    pass\n\n\nclass UInt8(object):\n    """"""8-bit unsigned int type.""""""\n\n    pass\n\n\nclass Int16(object):\n    """"""16-bit int type.""""""\n\n    pass\n\n\nclass UInt16(object):\n    """"""16-bit unsigned int type.""""""\n\n    pass\n\n\nclass Int32(object):\n    """"""32-bit int type.""""""\n\n    pass\n\n\nclass UInt32(object):\n    """"""32-bit unsigned int type.""""""\n\n    pass\n\n\nclass Float32(object):\n    """"""32-bit floating-point type.""""""\n\n    pass\n\n\nclass Float64(object):\n    """"""64-bit floating-point type.""""""\n\n    pass\n\n\n_TYPES_DATA = {\n    Int8: {\n        \'size\': 1,\n        \'literal\': \'b\',\n        \'ctype\': ctypes.c_int8,\n        \'gl\': gl.GL_BYTE,\n        \'numpy\': numpy.int8,\n    },\n    UInt8: {\n        \'size\': 1,\n        \'literal\': \'ub\',\n        \'ctype\': ctypes.c_uint8,\n        \'gl\': gl.GL_UNSIGNED_BYTE,\n        \'numpy\': numpy.uint8,\n    },\n    Int16: {\n        \'size\': 2,\n        \'literal\': \'s\',\n        \'ctype\': ctypes.c_int16,\n        \'gl\': gl.GL_SHORT,\n        \'numpy\': numpy.int16,\n    },\n    UInt16: {\n        \'size\': 2,\n        \'literal\': \'us\',\n        \'ctype\': ctypes.c_uint16,\n        \'gl\': gl.GL_UNSIGNED_SHORT,\n        \'numpy\': numpy.uint16,\n    },\n    Int32: {\n        \'size\': 4,\n        \'literal\': \'i\',\n        \'ctype\': ctypes.c_int32,\n        \'gl\': gl.GL_INT,\n        \'numpy\': numpy.int32,\n    },\n    UInt32: {\n        \'size\': 4,\n        \'literal\': \'ui\',\n        \'ctype\': ctypes.c_uint32,\n        \'gl\': gl.GL_UNSIGNED_INT,\n        \'numpy\': numpy.uint32,\n    },\n    Float32: {\n        \'size\': 4,\n        \'literal\': \'f\',\n        \'ctype\': ctypes.c_float,\n        \'gl\': gl.GL_FLOAT,\n        \'numpy\': numpy.float32,\n    },\n    Float64: {\n        \'size\': 8,\n        \'literal\': \'d\',\n        \'ctype\': ctypes.c_double,\n        \'gl\': gl.GL_DOUBLE,\n        \'numpy\': numpy.float64,\n    },\n}\n\n_TYPES = tuple(_TYPES_DATA.keys())\n\n_CTYPE_TO_THIS = {_TYPES_DATA[this_type][\'ctype\']: this_type\n                  for this_type in _TYPES}\n\n_GL_TO_THIS = {_TYPES_DATA[this_type][\'gl\']: this_type\n               for this_type in _TYPES}\n\n_NUMPY_TO_THIS = {_TYPES_DATA[this_type][\'numpy\']: this_type\n                  for this_type in _TYPES}\n\n\ndef get_types():\n    """"""Retrieve all the numeric types supported by hienoi.""""""\n    return _TYPES\n\n\ndef get_type_size(this_type):\n    """"""Retrieve the size in bytes of a hienoi type.""""""\n    return _TYPES_DATA[this_type][\'size\']\n\n\ndef get_type_literal(this_type):\n    """"""Retrieve the string literal of a hienoi type.""""""\n    return _TYPES_DATA[this_type][\'literal\']\n\n\ndef from_ctype(ctype_type):\n    """"""Convert a C type to its hienoi equivalent.""""""\n    return _CTYPE_TO_THIS[ctype_type]\n\n\ndef from_gl(gl_type):\n    """"""Convert an OpenGL type to its hienoi equivalent.""""""\n    return _GL_TO_THIS[gl_type]\n\n\ndef from_numpy(numpy_type):\n    """"""Convert a NumPy type to its hienoi equivalent.""""""\n    return _NUMPY_TO_THIS[numpy_type]\n\n\ndef to_ctype(this_type):\n    """"""Convert a hienoi type to its ctypes equivalent.""""""\n    return _TYPES_DATA[this_type][\'ctype\']\n\n\ndef to_gl(this_type):\n    """"""Convert a hienoi type to its OpenGL equivalent.""""""\n    return _TYPES_DATA[this_type][\'gl\']\n\n\ndef to_numpy(this_type):\n    """"""Convert a hienoi type to its NumPy equivalent.""""""\n    return _TYPES_DATA[this_type][\'numpy\']\n'"
hienoi/_orderedbuffer.py,0,"b'""""""Bucket buffer based on NumPy.""""""\n\nimport collections\nimport itertools\nimport sys\n\nimport numpy\n\n\nif sys.version_info[0] == 2:\n    _range = xrange\n    _zip = itertools.izip\nelse:\n    _range = range\n    _zip = zip\n\n\n_Bunch = collections.namedtuple(\n    \'_Bunch\', (\n        \'position\',\n        \'data\',\n    ))\n\n\nclass OrderedBuffer(object):\n    """"""Ordered buffer based on NumPy.\n\n    Prevents reallocation and hence invalidation of previously added elements.\n    """"""\n\n    def __init__(self, bucket_capacity, dtype):\n        if bucket_capacity < 1:\n            raise ValueError(""A minimum bucket capacity of 1 is expected."")\n\n        self._dtype = dtype\n\n        self._buckets = []\n        self._bucket_capacity = bucket_capacity\n        self._pos = [0, 0]\n\n        self._bunchs = []\n\n    def __len__(self):\n        return (self._bucket_capacity * self._pos[0] + self._pos[1]\n                + sum(len(bunch.data) for bunch in self._bunchs))\n\n    @property\n    def chunks(self):\n        out = []\n        i, j = (0, 0)\n        bunchs = self._bunchs + [_Bunch(position=self._pos, data=[])]\n        for bunch in bunchs:\n            m, n = bunch.position\n            while i < m:\n                out.append(self._buckets[i][j:])\n                i += 1\n                j = 0\n\n            if j < n:\n                out.append(self._buckets[i][j:n])\n\n            if len(bunch.data):\n                out.append(bunch.data)\n\n            i, j = bunch.position\n\n        return out\n\n    @property\n    def bucket_capacity(self):\n        return self._bucket_capacity\n\n    @property\n    def dtype(self):\n        return self._dtype\n\n    def append(self, data):\n        """"""Append a new element.""""""\n        return self._push(data, 1)[0]\n\n    def extend(self, data):\n        """"""Append a bunch of new elements.""""""\n        size = len(data)\n        if size < 1:\n            return numpy.empty(0, dtype=self._dtype)\n\n        return self._push(numpy.asarray(data, dtype=self._dtype), size)\n\n    def clear(self):\n        """"""Clear the data.""""""\n        self._pos = [0, 0]\n        self._bunchs = []\n\n    def _push(self, data, size):\n        """"""Add new element(s) at the end.""""""\n        i, j = self._pos\n        if self._bucket_capacity - j >= size:\n            if i == len(self._buckets):\n                self._buckets.append(\n                    numpy.empty(self._bucket_capacity, dtype=self._dtype))\n\n            self._buckets[i][j:j + size] = data\n            out = self._buckets[i][j:j + size]\n\n            j = (j + size) % self._bucket_capacity\n            self._pos = [i + 1 if j == 0 else i, j]\n        else:\n            self._bunchs.append(_Bunch(position=self._pos, data=data))\n            out = data\n\n        return out\n'"
hienoi/_vectors.py,0,"b'""""""Vector classes.""""""\n\n__all__ = [\n    \'Vector2b\', \'Vector2ub\', \'Vector2s\', \'Vector2us\',\n    \'Vector2i\', \'Vector2ui\', \'Vector2f\', \'Vector2d\',\n    \'Vector3b\', \'Vector3ub\', \'Vector3s\', \'Vector3us\',\n    \'Vector3i\', \'Vector3ui\', \'Vector3f\', \'Vector3d\',\n    \'Vector4b\', \'Vector4ub\', \'Vector4s\', \'Vector4us\',\n    \'Vector4i\', \'Vector4ui\', \'Vector4f\', \'Vector4d\',\n    \'VECTOR2B\', \'VECTOR2UB\', \'VECTOR2S\', \'VECTOR2US\',\n    \'VECTOR2I\', \'VECTOR2UI\', \'VECTOR2F\', \'VECTOR2D\',\n    \'VECTOR3B\', \'VECTOR3UB\', \'VECTOR3S\', \'VECTOR3US\',\n    \'VECTOR3I\', \'VECTOR3UI\', \'VECTOR3F\', \'VECTOR3D\',\n    \'VECTOR4B\', \'VECTOR4UB\', \'VECTOR4S\', \'VECTOR4US\',\n    \'VECTOR4I\', \'VECTOR4UI\', \'VECTOR4F\', \'VECTOR4D\',\n    \'COLOR3UB\', \'COLOR3F\', \'COLOR4UB\', \'COLOR4F\',\n]\n\nimport math\nimport sys\n\nimport hienoi._nani\nimport hienoi._numeric\n\n\nif sys.version_info[0] == 2:\n    def _iteritems(d, **kwargs):\n        return d.iteritems(**kwargs)\nelse:\n    def _iteritems(d, **kwargs):\n        return iter(d.items(**kwargs))\n\n\n_PATTERN = \'Vector%d\'\n_CTYPE_PATTERN = \'Vector%d%s\'\n_VIEW_PATTERN = \'Vector%d%sView\'\n_TOLERANCE = 1e-6\n\n\nclass _BaseMixin(object):\n    """"""Vector\'s base mixin.""""""\n\n    @classmethod\n    def Vector2_lerp(cls, a, b, blend):\n        return cls._class(a[0] + (b[0] - a[0]) * blend,\n                          a[1] + (b[1] - a[1]) * blend)\n        a + (b - a) * blend\n\n    @classmethod\n    def Vector3_lerp(cls, a, b, blend):\n        return cls._class(a[0] + (b[0] - a[0]) * blend,\n                          a[1] + (b[1] - a[1]) * blend,\n                          a[2] + (b[2] - a[2]) * blend)\n\n    @classmethod\n    def Vector4_lerp(cls, a, b, blend):\n        return cls._class(a[0] + (b[0] - a[0]) * blend,\n                          a[1] + (b[1] - a[1]) * blend,\n                          a[2] + (b[2] - a[2]) * blend,\n                          a[3] + (b[3] - a[3]) * blend)\n\n    def Vector2___repr__(self):\n        return ""%s(%s, %s)"" % (self._class.__name__, self[0], self[1])\n\n    def Vector3___repr__(self):\n        return ""%s(%s, %s, %s)"" % (self._class.__name__,\n                                   self[0], self[1], self[2])\n\n    def Vector4___repr__(self):\n        return ""%s(%s, %s, %s, %s)"" % (self._class.__name__,\n                                       self[0], self[1], self[2], self[3])\n\n    def Vector2___eq__(self, other):\n        return self[0] == other[0] and self[1] == other[1]\n\n    def Vector3___eq__(self, other):\n        return (self[0] == other[0] and self[1] == other[1]\n                and self[2] == other[2])\n\n    def Vector4___eq__(self, other):\n        return (self[0] == other[0] and self[1] == other[1]\n                and self[2] == other[2] and self[3] == other[3])\n\n    def Vector2___ne__(self, other):\n        return self[0] != other[0] or self[1] != other[1]\n\n    def Vector3___ne__(self, other):\n        return (self[0] != other[0] or self[1] != other[1]\n                or self[2] != other[2])\n\n    def Vector4___ne__(self, other):\n        return (self[0] != other[0] or self[1] != other[1]\n                or self[2] != other[2] or self[3] != other[3])\n\n    def Vector2___add__(self, other):\n        return self._class(self[0] + other[0], self[1] + other[1])\n\n    def Vector3___add__(self, other):\n        return self._class(self[0] + other[0], self[1] + other[1],\n                           self[2] + other[2])\n\n    def Vector4___add__(self, other):\n        return self._class(self[0] + other[0], self[1] + other[1],\n                           self[2] + other[2], self[3] + other[3])\n\n    def Vector2___sub__(self, other):\n        return self._class(self[0] - other[0], self[1] - other[1])\n\n    def Vector3___sub__(self, other):\n        return self._class(self[0] - other[0], self[1] - other[1],\n                           self[2] - other[2])\n\n    def Vector4___sub__(self, other):\n        return self._class(self[0] - other[0], self[1] - other[1],\n                           self[2] - other[2], self[3] - other[3])\n\n    def Vector2___mul__(self, other):\n        return self._class(self[0] * other[0], self[1] * other[1])\n\n    def Vector3___mul__(self, other):\n        return self._class(self[0] * other[0], self[1] * other[1],\n                           self[2] * other[2])\n\n    def Vector4___mul__(self, other):\n        return self._class(self[0] * other[0], self[1] * other[1],\n                           self[2] * other[2], self[3] * other[3])\n\n    def Vector2___truediv__(self, other):\n        return self._class(self[0] / other[0], self[1] / other[1])\n\n    def Vector3___truediv__(self, other):\n        return self._class(self[0] / other[0], self[1] / other[1],\n                           self[2] / other[2])\n\n    def Vector4___truediv__(self, other):\n        return self._class(self[0] / other[0], self[1] / other[1],\n                           self[2] / other[2], self[3] / other[3])\n\n    def Vector2___floordiv__(self, other):\n        return self._class(self[0] // other[0], self[1] // other[1])\n\n    def Vector3___floordiv__(self, other):\n        return self._class(self[0] // other[0], self[1] // other[1],\n                           self[2] // other[2])\n\n    def Vector4___floordiv__(self, other):\n        return self._class(self[0] // other[0], self[1] // other[1],\n                           self[2] // other[2], self[3] // other[3])\n\n    Vector2___div__ = Vector2___truediv__\n    Vector3___div__ = Vector3___truediv__\n    Vector4___div__ = Vector4___truediv__\n\n    Vector2___radd__ = Vector2___add__\n    Vector3___radd__ = Vector3___add__\n    Vector4___radd__ = Vector4___add__\n\n    def Vector2___rsub__(self, other):\n        return self._class(other[0] - self[0], other[1] - self[1])\n\n    def Vector3___rsub__(self, other):\n        return self._class(other[0] - self[0], other[1] - self[1],\n                           other[2] - self[2])\n\n    def Vector4___rsub__(self, other):\n        return self._class(other[0] - self[0], other[1] - self[1],\n                           other[2] - self[2], other[3] - self[3])\n\n    Vector2___rmul__ = Vector2___mul__\n    Vector3___rmul__ = Vector3___mul__\n    Vector4___rmul__ = Vector4___mul__\n\n    def Vector2___rtruediv__(self, other):\n        return self._class(other[0] / self[0], other[1] / self[1])\n\n    def Vector3___rtruediv__(self, other):\n        return self._class(other[0] / self[0], other[1] / self[1],\n                           other[2] / self[2])\n\n    def Vector4___rtruediv__(self, other):\n        return self._class(other[0] / self[0], other[1] / self[1],\n                           other[2] / self[2], other[3] / self[3])\n\n    def Vector2___rfloordiv__(self, other):\n        return self._class(other[0] // self[0], other[1] // self[1])\n\n    def Vector3___rfloordiv__(self, other):\n        return self._class(other[0] // self[0], other[1] // self[1],\n                           other[2] // self[2])\n\n    def Vector4___rfloordiv__(self, other):\n        return self._class(other[0] // self[0], other[1] // self[1],\n                           other[2] // self[2], other[3] // self[3])\n\n    Vector2___rdiv__ = Vector2___rtruediv__\n    Vector3___rdiv__ = Vector3___rtruediv__\n    Vector4___rdiv__ = Vector4___rtruediv__\n\n    def Vector2___iadd__(self, other):\n        self[0] += other[0]\n        self[1] += other[1]\n        return self\n\n    def Vector3___iadd__(self, other):\n        self[0] += other[0]\n        self[1] += other[1]\n        self[2] += other[2]\n        return self\n\n    def Vector4___iadd__(self, other):\n        self[0] += other[0]\n        self[1] += other[1]\n        self[2] += other[2]\n        self[3] += other[3]\n        return self\n\n    def Vector2___isub__(self, other):\n        self[0] -= other[0]\n        self[1] -= other[1]\n        return self\n\n    def Vector3___isub__(self, other):\n        self[0] -= other[0]\n        self[1] -= other[1]\n        self[2] -= other[2]\n        return self\n\n    def Vector4___isub__(self, other):\n        self[0] -= other[0]\n        self[1] -= other[1]\n        self[2] -= other[2]\n        self[3] -= other[3]\n        return self\n\n    def Vector2___imul__(self, other):\n        self[0] *= other[0]\n        self[1] *= other[1]\n        return self\n\n    def Vector3___imul__(self, other):\n        self[0] *= other[0]\n        self[1] *= other[1]\n        self[2] *= other[2]\n        return self\n\n    def Vector4___imul__(self, other):\n        self[0] *= other[0]\n        self[1] *= other[1]\n        self[2] *= other[2]\n        self[3] *= other[3]\n        return self\n\n    def Vector2___itruediv__(self, other):\n        self[0] /= other[0]\n        self[1] /= other[1]\n        return self\n\n    def Vector3___itruediv__(self, other):\n        self[0] /= other[0]\n        self[1] /= other[1]\n        self[2] /= other[2]\n        return self\n\n    def Vector4___itruediv__(self, other):\n        self[0] /= other[0]\n        self[1] /= other[1]\n        self[2] /= other[2]\n        self[3] /= other[3]\n        return self\n\n    def Vector2___ifloordiv__(self, other):\n        self[0] //= other[0]\n        self[1] //= other[1]\n        return self\n\n    def Vector3___ifloordiv__(self, other):\n        self[0] //= other[0]\n        self[1] //= other[1]\n        self[2] //= other[2]\n        return self\n\n    def Vector4___ifloordiv__(self, other):\n        self[0] //= other[0]\n        self[1] //= other[1]\n        self[2] //= other[2]\n        self[3] //= other[3]\n        return self\n\n    Vector2___idiv__ = Vector2___itruediv__\n    Vector3___idiv__ = Vector3___itruediv__\n    Vector4___idiv__ = Vector4___itruediv__\n\n    def Vector2___neg__(self):\n        return self._class(-self[0], -self[1])\n\n    def Vector3___neg__(self):\n        return self._class(-self[0], -self[1], -self[2])\n\n    def Vector4___neg__(self):\n        return self._class(-self[0], -self[1], -self[2], -self[3])\n\n    def Vector2___pos__(self):\n        return self._class(+self[0], +self[1])\n\n    def Vector3___pos__(self):\n        return self._class(+self[0], +self[1], +self[2])\n\n    def Vector4___pos__(self):\n        return self._class(+self[0], +self[1], +self[2], +self[3])\n\n    def Vector2___abs__(self):\n        return self._class(abs(self[0]), abs(self[1]))\n\n    def Vector3___abs__(self):\n        return self._class(abs(self[0]), abs(self[1]), abs(self[2]))\n\n    def Vector4___abs__(self):\n        return self._class(abs(self[0]), abs(self[1]), abs(self[2]),\n                           abs(self[3]))\n\n    def Vector2_offset(self, value):\n        return self._class(self[0] + value, self[1] + value)\n\n    def Vector3_offset(self, value):\n        return self._class(self[0] + value, self[1] + value, self[2] + value)\n\n    def Vector4_offset(self, value):\n        return self._class(self[0] + value, self[1] + value, self[2] + value,\n                           self[3] + value)\n\n    def Vector2_scale(self, value):\n        return self._class(self[0] * value, self[1] * value)\n\n    def Vector3_scale(self, value):\n        return self._class(self[0] * value, self[1] * value, self[2] * value)\n\n    def Vector4_scale(self, value):\n        return self._class(self[0] * value, self[1] * value, self[2] * value,\n                           self[3] * value)\n\n    def Vector2_ioffset(self, value):\n        self[0] += value\n        self[1] += value\n        return self\n\n    def Vector3_ioffset(self, value):\n        self[0] += value\n        self[1] += value\n        self[2] += value\n        return self\n\n    def Vector4_ioffset(self, value):\n        self[0] += value\n        self[1] += value\n        self[2] += value\n        self[3] += value\n        return self\n\n    def Vector2_iscale(self, value):\n        self[0] *= value\n        self[1] *= value\n        return self\n\n    def Vector3_iscale(self, value):\n        self[0] *= value\n        self[1] *= value\n        self[2] *= value\n        return self\n\n    def Vector4_iscale(self, value):\n        self[0] *= value\n        self[1] *= value\n        self[2] *= value\n        self[3] *= value\n        return self\n\n    def Vector2_length(self):\n        return math.sqrt(self[0] ** 2 + self[1] ** 2)\n\n    def Vector3_length(self):\n        return math.sqrt(self[0] ** 2 + self[1] ** 2 + self[2] ** 2)\n\n    def Vector4_length(self):\n        return math.sqrt(self[0] ** 2 + self[1] ** 2 + self[2] ** 2\n                         + self[3] ** 2)\n\n    def Vector2_squared_length(self):\n        return self[0] ** 2 + self[1] ** 2\n\n    def Vector3_squared_length(self):\n        return self[0] ** 2 + self[1] ** 2 + self[2] ** 2\n\n    def Vector4_squared_length(self):\n        return self[0] ** 2 + self[1] ** 2 + self[2] ** 2 + self[3] ** 2\n\n    def Vector2_dot(self, other):\n        return self[0] * other[0] + self[1] * other[1]\n\n    def Vector3_dot(self, other):\n        return self[0] * other[0] + self[1] * other[1] + self[2] * other[2]\n\n    def Vector4_dot(self, other):\n        return (self[0] * other[0] + self[1] * other[1] + self[2] * other[2]\n                + self[3] * other[3])\n\n\nclass _FloatingPointMixin(object):\n    """"""Vector\'s floating-point mixin.""""""\n\n    def Vector2_is_almost_equal(self, other, tolerance=_TOLERANCE):\n        return (abs(self[0] - other[0]) <= tolerance\n                and abs(self[1] - other[1]) <= tolerance)\n\n    def Vector3_is_almost_equal(self, other, tolerance=_TOLERANCE):\n        return (abs(self[0] - other[0]) <= tolerance\n                and abs(self[1] - other[1]) <= tolerance\n                and abs(self[2] - other[2]) <= tolerance)\n\n    def Vector4_is_almost_equal(self, other, tolerance=_TOLERANCE):\n        return (abs(self[0] - other[0]) <= tolerance\n                and abs(self[1] - other[1]) <= tolerance\n                and abs(self[2] - other[2]) <= tolerance\n                and abs(self[3] - other[3]) <= tolerance)\n\n    def Vector2_normalize(self):\n        length = self.length()\n        if abs(length) <= _TOLERANCE:\n            return self._class(self[0], self[1])\n\n        return self._class(self[0] / length, self[1] / length)\n\n    def Vector3_normalize(self):\n        length = self.length()\n        if abs(length) <= _TOLERANCE:\n            return self._class(self[0], self[1], self[2])\n\n        return self._class(self[0] / length, self[1] / length,\n                           self[2] / length)\n\n    def Vector4_normalize(self):\n        length = self.length()\n        if abs(length) <= _TOLERANCE:\n            return self._class(self[0], self[1], self[2], self[3])\n\n        return self._class(self[0] / length, self[1] / length,\n                           self[2] / length, self[3] / length)\n\n    def Vector2_inormalize(self):\n        length = self.length()\n        if abs(length) <= _TOLERANCE:\n            return self\n\n        self[0] /= length\n        self[1] /= length\n        return self\n\n    def Vector3_inormalize(self):\n        length = self.length()\n        if abs(length) <= _TOLERANCE:\n            return self\n\n        self[0] /= length\n        self[1] /= length\n        self[2] /= length\n        return self\n\n    def Vector4_inormalize(self):\n        length = self.length()\n        if abs(length) <= _TOLERANCE:\n            return self\n\n        self[0] /= length\n        self[1] /= length\n        self[2] /= length\n        self[3] /= length\n        return self\n\n\nclass _CtypeMixin(object):\n    """"""Vector\'s ctype mixin.""""""\n\n    @property\n    def Vector2_x(self):\n        return self[0]\n\n    @property\n    def Vector3_x(self):\n        return self[0]\n\n    @property\n    def Vector4_x(self):\n        return self[0]\n\n    @Vector2_x.setter\n    def Vector2_x(self, value):\n        self[0] = value\n\n    @Vector3_x.setter\n    def Vector3_x(self, value):\n        self[0] = value\n\n    @Vector4_x.setter\n    def Vector4_x(self, value):\n        self[0] = value\n\n    @property\n    def Vector2_y(self):\n        return self[1]\n\n    @property\n    def Vector3_y(self):\n        return self[1]\n\n    @property\n    def Vector4_y(self):\n        return self[1]\n\n    @Vector2_y.setter\n    def Vector2_y(self, value):\n        self[1] = value\n\n    @Vector3_y.setter\n    def Vector3_y(self, value):\n        self[1] = value\n\n    @Vector4_y.setter\n    def Vector4_y(self, value):\n        self[1] = value\n\n    @property\n    def Vector3_z(self):\n        return self[2]\n\n    @property\n    def Vector4_z(self):\n        return self[2]\n\n    @Vector3_z.setter\n    def Vector3_z(self, value):\n        self[2] = value\n\n    @Vector4_z.setter\n    def Vector4_z(self, value):\n        self[2] = value\n\n    @property\n    def Vector4_w(self):\n        return self[3]\n\n    @Vector4_w.setter\n    def Vector4_w(self, value):\n        self[3] = value\n\n    Vector3_r = Vector3_x\n    Vector4_r = Vector4_x\n\n    Vector3_g = Vector3_y\n    Vector4_g = Vector4_y\n\n    Vector3_b = Vector3_z\n    Vector4_b = Vector4_z\n\n    Vector4_a = Vector4_w\n\n    def Vector2_assign(self, other):\n        self[0] = other[0]\n        self[1] = other[1]\n\n    def Vector3_assign(self, other):\n        self[0] = other[0]\n        self[1] = other[1]\n        self[2] = other[2]\n\n    def Vector4_assign(self, other):\n        self[0] = other[0]\n        self[1] = other[1]\n        self[2] = other[2]\n        self[3] = other[3]\n\n    def Vector2_set(self, x, y):\n        self[:] = (x, y)\n\n    def Vector3_set(self, x, y, z):\n        self[:] = (x, y, z)\n\n    def Vector4_set(self, x, y, z, w):\n        self[:] = (x, y, z, w)\n\n\nclass _ViewMixin(object):\n    """"""Vector\'s view mixin.""""""\n\n    Vector2___slots__ = (\'_data\',)\n    Vector3___slots__ = (\'_data\',)\n    Vector4___slots__ = (\'_data\',)\n\n    def Vector2___init__(self, data):\n        self._data = data\n\n    def Vector3___init__(self, data):\n        self._data = data\n\n    def Vector4___init__(self, data):\n        self._data = data\n\n    def Vector2___len__(self):\n        return 2\n\n    def Vector3___len__(self):\n        return 3\n\n    def Vector4___len__(self):\n        return 4\n\n    def Vector2___getitem__(self, idx):\n        return self._data[idx]\n\n    def Vector3___getitem__(self, idx):\n        return self._data[idx]\n\n    def Vector4___getitem__(self, idx):\n        return self._data[idx]\n\n    def Vector2___setitem__(self, idx, value):\n        self._data[idx] = value\n\n    def Vector3___setitem__(self, idx, value):\n        self._data[idx] = value\n\n    def Vector4___setitem__(self, idx, value):\n        self._data[idx] = value\n\n    @property\n    def Vector2_x(self):\n        return self._data[0]\n\n    @property\n    def Vector3_x(self):\n        return self._data[0]\n\n    @property\n    def Vector4_x(self):\n        return self._data[0]\n\n    @Vector2_x.setter\n    def Vector2_x(self, value):\n        self._data[0] = value\n\n    @Vector3_x.setter\n    def Vector3_x(self, value):\n        self._data[0] = value\n\n    @Vector4_x.setter\n    def Vector4_x(self, value):\n        self._data[0] = value\n\n    @property\n    def Vector2_y(self):\n        return self._data[1]\n\n    @property\n    def Vector3_y(self):\n        return self._data[1]\n\n    @property\n    def Vector4_y(self):\n        return self._data[1]\n\n    @Vector2_y.setter\n    def Vector2_y(self, value):\n        self._data[1] = value\n\n    @Vector3_y.setter\n    def Vector3_y(self, value):\n        self._data[1] = value\n\n    @Vector4_y.setter\n    def Vector4_y(self, value):\n        self._data[1] = value\n\n    @property\n    def Vector3_z(self):\n        return self._data[2]\n\n    @property\n    def Vector4_z(self):\n        return self._data[2]\n\n    @Vector3_z.setter\n    def Vector3_z(self, value):\n        self._data[2] = value\n\n    @Vector4_z.setter\n    def Vector4_z(self, value):\n        self._data[2] = value\n\n    @property\n    def Vector4_w(self):\n        return self._data[3]\n\n    @Vector4_w.setter\n    def Vector4_w(self, value):\n        self._data[3] = value\n\n    Vector3_r = Vector3_x\n    Vector4_r = Vector4_x\n\n    Vector3_g = Vector3_y\n    Vector4_g = Vector4_y\n\n    Vector3_b = Vector3_z\n    Vector4_b = Vector4_z\n\n    Vector4_a = Vector4_w\n\n    def Vector2_assign(self, other):\n        self._data[:] = other._data\n\n    def Vector3_assign(self, other):\n        self._data[:] = other._data\n\n    def Vector4_assign(self, other):\n        self._data[:] = other._data\n\n    def Vector2_set(self, x, y):\n        self._data[:] = (x, y)\n\n    def Vector3_set(self, x, y, z):\n        self._data[:] = (x, y, z)\n\n    def Vector4_set(self, x, y, z, w):\n        self._data[:] = (x, y, z, w)\n\n\n_VECTOR_MIXINS = {\n    hienoi._numeric.Int8: (_BaseMixin,),\n    hienoi._numeric.UInt8: (_BaseMixin,),\n    hienoi._numeric.Int16: (_BaseMixin,),\n    hienoi._numeric.UInt16: (_BaseMixin,),\n    hienoi._numeric.Int32: (_BaseMixin,),\n    hienoi._numeric.UInt32: (_BaseMixin,),\n    hienoi._numeric.Float32: (_BaseMixin, _FloatingPointMixin),\n    hienoi._numeric.Float64: (_BaseMixin, _FloatingPointMixin),\n}\n\n\ndef _define_vectors(size):\n    """"""Define a triplet of objects describing a vector.""""""\n    out = {}\n    for element_type in hienoi._numeric.get_types():\n        mixins = _VECTOR_MIXINS[type] = _VECTOR_MIXINS[element_type]\n        literal = hienoi._numeric.get_type_literal(element_type)\n        ctype_name = _CTYPE_PATTERN % (size, literal)\n        ctype = _define_ctype(ctype_name, element_type, mixins, size)\n        view_name = _VIEW_PATTERN % (size, literal)\n        view = _define_view(view_name, ctype, mixins, size)\n        nani = _define_nani(element_type, view, size)\n        out[element_type] = (ctype, view, nani)\n\n    return out\n\n\ndef _define_ctype(name, element_type, mixins, size):\n    """"""Define a vector\'s ctype.""""""\n    element_type = hienoi._numeric.to_ctype(element_type)\n    mixins = (_CtypeMixin,) + mixins\n    definition = _get_definition(mixins, size)\n\n    # Required for Python 2.\n    definition.update({\n        \'_length_\': size,\n        \'_type_\': element_type,\n    })\n\n    out = type(name, (element_type * size,), definition)\n    out._class = out\n    return out\n\n\ndef _define_view(name, ctype, mixins, size):\n    """"""Define a vector\'s view.""""""\n    mixins = (_ViewMixin,) + mixins\n    definition = _get_definition(mixins, size)\n    out = type(name, (), definition)\n    out._class = ctype\n    return out\n\n\ndef _define_nani(element_type, view, size):\n    """"""Define a vector\'s nani.""""""\n    return hienoi._nani.Array(\n        element_type=hienoi._nani.Number(type=element_type),\n        shape=size,\n        view=view)\n\n\ndef _get_definition(mixins, size):\n    """"""Retrieve a vector\'s definition.""""""\n    out = {}\n    prefix = _PATTERN % (size,)\n    prefix_length = len(prefix)\n    for mixin in mixins:\n        out.update({key[prefix_length + 1:]: value\n                    for key, value in _iteritems(mixin.__dict__)\n                    if key.startswith(prefix)})\n\n    return out\n\n\n_VECTORS2 = _define_vectors(2)\nVector2b, Vector2bView, VECTOR2B = _VECTORS2[hienoi._numeric.Int8]\nVector2ub, Vector2ubView, VECTOR2UB = _VECTORS2[hienoi._numeric.UInt8]\nVector2s, Vector2sView, VECTOR2S = _VECTORS2[hienoi._numeric.Int16]\nVector2us, Vector2usView, VECTOR2US = _VECTORS2[hienoi._numeric.UInt16]\nVector2i, Vector2iView, VECTOR2I = _VECTORS2[hienoi._numeric.Int32]\nVector2ui, Vector2uiView, VECTOR2UI = _VECTORS2[hienoi._numeric.UInt32]\nVector2f, Vector2fView, VECTOR2F = _VECTORS2[hienoi._numeric.Float32]\nVector2d, Vector2dView, VECTOR2D = _VECTORS2[hienoi._numeric.Float64]\n\n_VECTORS3 = _define_vectors(3)\nVector3b, Vector3bView, VECTOR3B = _VECTORS3[hienoi._numeric.Int8]\nVector3ub, Vector3ubView, VECTOR3UB = _VECTORS3[hienoi._numeric.UInt8]\nVector3s, Vector3sView, VECTOR3S = _VECTORS3[hienoi._numeric.Int16]\nVector3us, Vector3usView, VECTOR3US = _VECTORS3[hienoi._numeric.UInt16]\nVector3i, Vector3iView, VECTOR3I = _VECTORS3[hienoi._numeric.Int32]\nVector3ui, Vector3uiView, VECTOR3UI = _VECTORS3[hienoi._numeric.UInt32]\nVector3f, Vector3fView, VECTOR3F = _VECTORS3[hienoi._numeric.Float32]\nVector3d, Vector3dView, VECTOR3D = _VECTORS3[hienoi._numeric.Float64]\n\n_VECTORS4 = _define_vectors(4)\nVector4b, Vector4bView, VECTOR4B = _VECTORS4[hienoi._numeric.Int8]\nVector4ub, Vector4ubView, VECTOR4UB = _VECTORS4[hienoi._numeric.UInt8]\nVector4s, Vector4sView, VECTOR4S = _VECTORS4[hienoi._numeric.Int16]\nVector4us, Vector4usView, VECTOR4US = _VECTORS4[hienoi._numeric.UInt16]\nVector4i, Vector4iView, VECTOR4I = _VECTORS4[hienoi._numeric.Int32]\nVector4ui, Vector4uiView, VECTOR4UI = _VECTORS4[hienoi._numeric.UInt32]\nVector4f, Vector4fView, VECTOR4F = _VECTORS4[hienoi._numeric.Float32]\nVector4d, Vector4dView, VECTOR4D = _VECTORS4[hienoi._numeric.Float64]\n\n# Color aliases.\nCOLOR3UB = VECTOR3UB._replace(\n    element_type=VECTOR3UB.element_type._replace(default=255))\nCOLOR3F = VECTOR3F._replace(\n    element_type=VECTOR3F.element_type._replace(default=1.0))\nCOLOR4UB = VECTOR4UB._replace(\n    element_type=VECTOR4UB.element_type._replace(default=255))\nCOLOR4F = VECTOR4F._replace(\n    element_type=VECTOR4F.element_type._replace(default=1.0))\n'"
hienoi/application.py,0,"b'""""""Glue for the different parts of the application.\n\nGets the modules running, connects them together through inter-process\nmessaging, and orchestrates the whole.\n""""""\n\nimport bisect\nimport collections\nimport cProfile\nimport logging\nimport multiprocessing\nimport os\nimport pstats\nimport sys\nimport tempfile\nimport timeit\nimport traceback\n\nimport hienoi._common\nimport hienoi.dynamics\nimport hienoi.gui\nimport hienoi.renderer\nfrom hienoi._dynamicarray import DynamicArray\n\n\nif sys.version_info[0] == 2:\n    import Queue as queue\n\n    def _iteritems(d, **kwargs):\n        return d.iteritems(**kwargs)\n\n    _range = xrange\nelse:\n    import queue\n\n    def _iteritems(d, **kwargs):\n        return iter(d.items(**kwargs))\n\n    _range = range\n\n\n_clock = timeit.default_timer\n\n\nclass LoggingLevel(object):\n    """"""Enumerator for the logging levels.\n\n    Attributes\n    ----------\n    CRITICAL\n    ERROR\n    WARNING\n    INFO\n    DEBUG\n    NOTSET\n    """"""\n\n    CRITICAL = logging.CRITICAL\n    ERROR = logging.ERROR\n    WARNING = logging.WARNING\n    INFO = logging.INFO\n    DEBUG = logging.DEBUG\n    NOTSET = logging.NOTSET\n\n\nclass Status(object):\n    """"""Enumerator for the return status codes.\n\n    Attributes\n    ----------\n    Success\n    Failure\n    """"""\n\n    SUCCESS = 0\n    FAILURE = 1\n\n\n_Configs = collections.namedtuple(\n    \'_Configs\', (\n        \'application\',\n        \'gui\',\n        \'particle_simulation\',\n    ))\n\n\n_InitialSimulationStates = collections.namedtuple(\n    \'_InitialSimulationStates\', (\n        \'particle\',\n    ))\n\n\n_Buffer = collections.namedtuple(\n    \'_Buffer\', (\n        \'data\',\n        \'metadata\',\n    ))\n\n\n_BufferMetadata = collections.namedtuple(\n    \'_BufferMetadata\', (\n        \'dtype\',\n    ))\n\n\n_OnEventData = collections.namedtuple(\n    \'OnEventData\', (\n        \'callbacks\',\n    ))\n\n\nclass OnEventData(_OnEventData):\n    """"""Data to pass to the GUI\'s \'on event\' callback.\n\n    Attributes\n    ----------\n    callbacks : hienoi.application.Callbacks\n        Inter-process callbacks.\n    """"""\n\n    __slots__ = ()\n\n\n_Callbacks = collections.namedtuple(\n    \'Callbacks\', (\n        \'particle_simulation\',\n    ))\n\n\nclass Callbacks(_Callbacks):\n    """"""Inter-process callbacks.\n\n    Attributes\n    ----------\n    particle_simulation : sequence of hienoi.application.Callback\n        Callbacks to run just before the method\n        :meth:`hienoi.dynamics.ParticleSimulation.step` is called.\n    """"""\n\n    __slots__ = ()\n\n    def __new__(cls):\n        base = super(Callbacks, cls)\n        return base.__new__(cls, *([] for _ in base._fields))\n\n\n_Callback = collections.namedtuple(\n    \'Callback\', (\n        \'function\',\n        \'args\',\n        \'kwargs\',\n    ))\n_Callback.__new__.__defaults__ = (\n    None,  # args\n    None,  # kwargs\n)\n\n\nclass Callback(_Callback):\n    """"""Inter-process callback.\n\n    Attributes\n    ----------\n    function : function\n        Callback function. It needs to declare ``obj``, the object specific to\n        the target process\' module, as first parameter. Additional parameters\n        declared are passed the ``args`` and ``kwargs`` values.\n    args : tuple\n        Additional positional arguments to pass to the function.\n    kwargs : dict\n        Additional keyword arguments to pass to the function.\n    """"""\n\n    __slots__ = ()\n\n\n_Process = collections.namedtuple(\n    \'_Process\', (\n        \'instance\',\n        \'output_queues\',\n        \'output_pipes\',\n    ))\n\n\n# Enumerator for the inter-process messages.\n_MESSAGE_ERROR = 0\n_MESSAGE_STOP = 1\n_MESSAGE_QUIT = 2\n_MESSAGE_REQUEST_SIM_UPDATE = 3\n_MESSAGE_SIM_UPDATE = 4\n_MESSAGE_RUN_CALLBACKS = 5\n_MESSAGE__LAST = _MESSAGE_RUN_CALLBACKS\n\n\n_Message = collections.namedtuple(\n    \'_Message\', (\n        \'type\',\n    ))\n\n\n_ErrorMessage = collections.namedtuple(\n    \'_ErrorMessage\', (\n        \'type\',\n        \'process_id\',\n        \'process_name\',\n        \'message\',\n    ))\n\n\n_SimUpdateMessage = collections.namedtuple(\n    \'_SimUpdateMessage\', (\n        \'type\',\n        \'time\',\n    ))\n\n\n_RunCallbacksMessage = collections.namedtuple(\n    \'_RunCallbacksMessage\', (\n        \'type\',\n        \'callbacks\',\n    ))\n\n\n_MESSAGE_STRUCTS = {\n    _MESSAGE_ERROR: _ErrorMessage,\n    _MESSAGE_STOP: _Message,\n    _MESSAGE_QUIT: _Message,\n    _MESSAGE_REQUEST_SIM_UPDATE: _Message,\n    _MESSAGE_SIM_UPDATE: _SimUpdateMessage,\n    _MESSAGE_RUN_CALLBACKS: _RunCallbacksMessage,\n}\nassert len(_MESSAGE_STRUCTS) == _MESSAGE__LAST + 1\n\n\n_Time = collections.namedtuple(\n    \'_Time\', (\n        \'value\',\n        \'unit\',\n    ))\n\n\ndef run(application=None, gui=None, particle_simulation=None):\n    """"""Main entry point to get the application running.\n\n    Parameters\n    ----------\n    application: dict\n        Keyword arguments for the configuration of the application:\n\n        - logging_level : :class:`LoggingLevel`\n            Logging messages having a lower threshold than the given level are\n            ignored.\n        - profile : bool\n            ``True`` to enable a profiler to monitor the performances of the\n            application. Each process is reported separately.\n        - time_step : float\n            Amount by which all the simulation times are being incremented by\n            at each step. The lower the value, the more accurate the\n            simulations are, but the more compute-intensive they become. This\n            global time step overrides any time step set in the parameter\n            ``particle_simulation``.\n        - capture : bool\n            ``True`` to write a ``.bmp`` snapshot for each frame to the\n            destination pointed by ``capture_filename``.\n        - capture_filename : str\n            Filename of the snapshots to write. The frame number can be defined\n            through Python\'s formatting syntax. For example, the pattern\n            ``/destination/directory/{frame:04}.bmp`` outputs filenames with 4\n            digits padded with zeroes, such as ``0009.bmp``, ``0085.bmp``, and\n            so on. If ``None``, the snapshots are outputted in a temporary\n            folder.\n        - capture_increment : int\n            Capture a snapshot every n-th frame.\n    gui : dict\n        Keyword arguments for the configuration of the GUI. See the parameters\n        for the class :class:`hienoi.gui.GUI`.\n    particle_simulation : dict\n        Keyword arguments for the configuration of the particle simulation. See\n        the parameters for the class\n        :class:`hienoi.dynamics.ParticleSimulation`.\n\n    Returns\n    -------\n    int\n        A value of :attr:`Status.SUCCESS` if successful, or\n        :attr:`Status.FAILURE` otherwise.\n    """"""\n    configs = {\n        \'application\': {\n            \'logging_level\': LoggingLevel.NOTSET,\n            \'profile\': False,\n            \'time_step\': 0.02,\n            \'capture\': False,\n            \'capture_filename\': None,\n            \'capture_increment\': 1,\n        },\n        \'gui\': gui,\n        \'particle_simulation\': particle_simulation,\n    }\n    configs = {key: {} if value is None else value\n               for key, value in _iteritems(configs)}\n    configs[\'application\'].update({} if application is None else application)\n    configs[\'particle_simulation\'][\'time_step\'] = (\n        configs[\'application\'][\'time_step\'])\n    configs = _Configs(**configs)\n\n    if configs.application[\'profile\']:\n        return _run_profiler(_run, configs)\n\n    return _run(configs)\n\n\ndef _run(configs):\n    """"""Implementation for the `run()` function.""""""\n    logger = multiprocessing.log_to_stderr()\n    logger.setLevel(configs.application[\'logging_level\'])\n\n    # Messages from the main process to the child ones.\n    downwards_queue = multiprocessing.Queue()\n    # Messages from the child processes to the main one.\n    upwards_queue = multiprocessing.Queue()\n    # Messages from the GUI process to the particle simulation one.\n    gui_to_psim_pipe = multiprocessing.Pipe(duplex=False)\n    # Messages from the particle simulation process to the GUI one.\n    psim_to_gui_pipe = multiprocessing.Pipe(duplex=False)\n\n    if (configs.application[\'capture\']\n            and configs.application[\'capture_filename\'] is None):\n        directory = tempfile.mkdtemp()\n        logger.info(""Created a temporary directory for the snapshots: %s""\n                    % (directory,))\n        configs.application[\'capture_filename\'] = os.path.join(\n            directory, \'{frame:04}.bmp\')\n\n    initial_sim_states = _InitialSimulationStates(\n        particle=hienoi.dynamics.ParticleSimulation(\n            **configs.particle_simulation))\n\n    # The application is spawning child processes which comes with an overhead\n    # mostly in the form of extra copies of data states needing to be made and\n    # inter-process messaging latency, which may or may not impact the\n    # execution speed. Since Hienoi aims at being of educational value,\n    # performances implications have been disregarded here in favour of\n    # demonstrating a multiprocessing approach.\n    processes = (\n        _Process(\n            instance=_create_process(\n                _gui_process, \'gui\',\n                args=(gui_to_psim_pipe[1], upwards_queue, psim_to_gui_pipe[0],\n                      downwards_queue, initial_sim_states, configs),\n                kwargs={},\n                upwards=upwards_queue,\n                profile=configs.application[\'profile\']),\n            output_queues=(upwards_queue,),\n            output_pipes=(gui_to_psim_pipe[0],)),\n        _Process(\n            instance=_create_process(\n                _particle_simulation_process, \'particle_simulation\',\n                args=(psim_to_gui_pipe[1], gui_to_psim_pipe[0],\n                      downwards_queue, initial_sim_states, configs),\n                kwargs={},\n                upwards=upwards_queue,\n                profile=configs.application[\'profile\']),\n            output_queues=(upwards_queue,),\n            output_pipes=(psim_to_gui_pipe[0],)),\n    )\n\n    try:\n        for process in processes:\n            process.instance.start()\n\n        return_code = _main_process(logger, downwards_queue, upwards_queue,\n                                    len(processes), configs)\n    finally:\n        for process in processes:\n            while process.instance.is_alive():\n                # Any data pushed into the queues by a child process needs\n                # to be flushed before being able to join that process.\n                for q in process.output_queues:\n                    _flush_queue(q)\n\n                # Sometimes pipes also need to be flushed to unblock a process\n                # that started sending a large chunk a data to another process\n                # that has stopped in the meantime.\n                for c in process.output_pipes:\n                    _flush_pipe(c)\n\n            if process.instance.pid != None:\n                process.instance.join()\n\n    return return_code\n\n\ndef _main_process(logger, downwards, upwards, process_count, configs):\n    """"""Main process.""""""\n    try:\n        while True:\n            message = _receive_message(upwards, block=True)\n            if message.type == _MESSAGE_ERROR:\n                logger.error(""Process \'%s\' [%d]:\\n%s"" % (\n                    message.process_name, message.process_id, message.message))\n                return Status.FAILURE\n            elif message.type == _MESSAGE_QUIT:\n                break\n    finally:\n        for _ in _range(process_count):\n            _send_message(downwards, _MESSAGE_STOP)\n\n        downwards.close()\n\n    return Status.SUCCESS\n\n\ndef _gui_process(to_psim, upwards, from_psim, downwards, sims, configs):\n    """"""GUI process.""""""\n    gui = None\n    try:\n        gui = hienoi.gui.GUI(**configs.gui)\n        time_step = configs.application[\'time_step\']\n        capture = configs.application[\'capture\']\n        capture_filename = configs.application[\'capture_filename\']\n        capture_increment = configs.application[\'capture_increment\']\n\n        current_state = hienoi.renderer.SceneState(\n            time=0.0,\n            particles=sims.particle.particles.data)\n        del sims\n\n        # Because the initial simulation state is already available, the first\n        # partial state is to be assembled at the next time step.\n        partial_state = {\'time\': time_step}\n        next_state = None\n\n        request_sim_updates = True\n        frame = 0\n        render = True\n        accumulator = 0.0\n        previous_time = 0.0\n        elapsed_time = 0.0\n        time_start = _clock()\n        while True:\n            message = _receive_message(downwards)\n            if message is None:\n                pass\n            elif message.type == _MESSAGE_STOP:\n                break\n\n            on_event_data = OnEventData(callbacks=Callbacks())\n            gui.poll_events(current_state, data=on_event_data)\n            if gui.quit:\n                _send_message(upwards, _MESSAGE_QUIT)\n                break\n\n            if on_event_data.callbacks.particle_simulation:\n                _send_message(\n                    to_psim, _MESSAGE_RUN_CALLBACKS,\n                    callbacks=on_event_data.callbacks.particle_simulation)\n\n            if next_state is None:\n                if request_sim_updates:\n                    _send_message(to_psim, _MESSAGE_REQUEST_SIM_UPDATE)\n                    request_sim_updates = False\n\n                if \'particles\' not in partial_state:\n                    message = _receive_message(from_psim)\n                    if message is None:\n                        pass\n                    elif message.type == _MESSAGE_SIM_UPDATE:\n                        assert (abs(message.time - partial_state[\'time\'])\n                                < time_step * 0.1)\n                        buf = _receive_buffer(from_psim)\n                        particles = _buffer_to_array(buf)\n                        partial_state[\'particles\'] = particles.data\n\n            if _is_scene_state_complete(partial_state):\n                next_state = hienoi.renderer.SceneState(**partial_state)\n                request_sim_updates = True\n\n            accumulator += elapsed_time\n            if accumulator >= time_step and next_state is not None:\n                current_state = next_state\n                partial_state = {\'time\': current_state.time + time_step}\n                next_state = None\n                accumulator = 0.0\n                render = True\n\n            if render:\n                gui.render(current_state)\n                if capture and frame % capture_increment == 0:\n                    filename = capture_filename.format(frame=frame)\n                    gui.write_snapshot(filename)\n\n                frame += 1\n                render = False\n\n            current_time = _clock() - time_start\n            elapsed_time = current_time - previous_time\n            previous_time = current_time\n    finally:\n        to_psim.close()\n        if gui is not None:\n            gui.terminate()\n\n\ndef _particle_simulation_process(to_gui, from_gui, downwards, sims, configs):\n    """"""Particle simulation process.""""""\n    try:\n        sim = sims.particle\n        particles = DynamicArray(0, hienoi._common.PARTICLE_NANI.dtype)\n        callbacks = None\n\n        # Step the simulation without sending the initial state over to the\n        # GUI process since it already has initialized its own copy.\n        step = True\n        send = False\n        while True:\n            message = _receive_message(downwards)\n            if message is None:\n                pass\n            elif message.type == _MESSAGE_STOP:\n                break\n\n            while True:\n                message = _receive_message(from_gui)\n                if message is None:\n                    break\n                elif message.type == _MESSAGE_REQUEST_SIM_UPDATE:\n                    send = True\n                elif message.type == _MESSAGE_RUN_CALLBACKS:\n                    callbacks = message.callbacks\n\n            if step:\n                if callbacks is not None:\n                    _run_callbacks(sim, callbacks)\n                    sim.consolidate()\n                    callbacks = None\n\n                sim.step()\n                step = False\n\n            if send:\n                _send_message(to_gui, _MESSAGE_SIM_UPDATE, time=sim.time)\n\n                # Copy only the relevant rendering attributes of the simulation\n                # state into a contiguous array.\n                particles.copy_from(sim.particles.data)\n\n                _send_buffer(to_gui, _array_to_buffer(particles))\n                step = True\n                send = False\n    finally:\n        to_gui.close()\n\n\ndef _run_profiler(function, *args, **kwargs):\n    """"""Run a profiler on the specified function.""""""\n    profiler = cProfile.Profile()\n    profiler.enable()\n    result = function(*args, **kwargs)\n    profiler.disable()\n    stats = pstats.Stats(profiler).sort_stats(\'cumtime\')\n    stats.print_stats()\n    return result\n\n\ndef _create_process(target, name, args, kwargs, upwards, profile):\n    """"""Create a new process.""""""\n    process = multiprocessing.Process(\n        target=_process_wrapper,\n        name=name,\n        args=(target, upwards, profile) + args,\n        kwargs=kwargs)\n    process.daemon = False\n    return process\n\n\ndef _process_wrapper(function, upwards, profile, *args, **kwargs):\n    """"""Wrap a process with additional features.""""""\n    try:\n        if profile:\n            _run_profiler(function, *args, **kwargs)\n        else:\n            function(*args, **kwargs)\n    except Exception:\n        process = multiprocessing.current_process()\n        info = sys.exc_info()\n        exception = traceback.format_exception(\n            info[0], info[1], info[2].tb_next)\n        _send_message(upwards, _MESSAGE_ERROR,\n                      process_id=process.pid,\n                      process_name=process.name,\n                      message=\'\'.join(exception).rstrip())\n    finally:\n        upwards.close()\n\n\ndef _is_scene_state_complete(state):\n    """"""Check if a scene state dictionary has a complete definition.""""""\n    return all(field in state for field in hienoi.renderer.SceneState._fields)\n\n\ndef _run_callbacks(obj, callbacks):\n    """"""Run a sequence of inter-process callbacks.""""""\n    for callback in callbacks:\n        args = () if callback.args is None else callback.args\n        kwargs = {} if callback.kwargs is None else callback.kwargs\n        callback.function(obj, *args, **kwargs)\n\n\ndef _buffer_to_array(buf):\n    """"""Unpack a buffer object into an array.""""""\n    return DynamicArray.from_buffer(buf.data, buf.metadata.dtype)\n\n\ndef _array_to_buffer(array):\n    """"""Pack an array into a buffer object.""""""\n    return _Buffer(data=array.data,\n                   metadata=_BufferMetadata(dtype=array.dtype))\n\n\ndef _send_message(c, type, **kwargs):\n    """"""Send a message.""""""\n    message = _MESSAGE_STRUCTS[type](type=type, **kwargs)\n    if isinstance(c, multiprocessing.queues.Queue):\n        c.put(message, block=True)\n    else:\n        c.send(message)\n\n\ndef _receive_message(c, block=False):\n    """"""Receive a message.""""""\n    if isinstance(c, multiprocessing.queues.Queue):\n        try:\n            message = c.get(block=block)\n        except queue.Empty:\n            return None\n    else:\n        if not block and not c.poll():\n            return None\n\n        try:\n            message = c.recv()\n        except EOFError:\n            return None\n\n    return message\n\n\ndef _send_buffer(c, buf):\n    """"""Send a buffer object to a pipe connection.""""""\n    c.send(buf.metadata)\n    c.send_bytes(buf.data)\n\n\ndef _receive_buffer(c):\n    """"""Receive a buffer object from a pipe connection.""""""\n    metadata = c.recv()\n    data = c.recv_bytes()\n    return _Buffer(\n        data=data,\n        metadata=metadata)\n\n\ndef _flush_queue(q):\n    """"""Flush the content of a queue.""""""\n    try:\n        while True:\n            q.get(block=False)\n    except queue.Empty:\n        pass\n\n\ndef _flush_pipe(c):\n    """"""Flush the content of a pipe.""""""\n    try:\n        while c.poll():\n            c.recv_bytes()\n    except EOFError:\n        pass\n\n\ndef _pick_time_unit(value):\n    """"""Pick the most readable time unit.""""""\n    bounds = (1e-9, 1e-6, 1e-3)\n    units = \'num\'\n    if value >= 1.0:\n        out = _Time(value=value, unit=\'s\')\n    elif value <= bounds[0] * 1e-3:\n        out = _Time(value=0.0, unit=\'%ss\' % (units[0],))\n    else:\n        i = max(0, bisect.bisect(bounds, value) - 1)\n        out = _Time(value=value / bounds[i], unit=\'%ss\' % (units[i],))\n\n    return out\n'"
hienoi/dynamics.py,0,"b'""""""Physics systems evolving over time.""""""\n\nimport itertools\nimport math\nimport sys\n\nimport numpy\n\nimport hienoi._common\nimport hienoi._numeric\nfrom hienoi._common import UserData\nfrom hienoi._dynamicarray import DynamicArray\nfrom hienoi._kdtree import KDTree\nfrom hienoi._nani import Bool, Number, READ_ONLY, PickableNaniStructure\nfrom hienoi._numeric import Int32, Float32\nfrom hienoi._orderedbuffer import OrderedBuffer\nfrom hienoi._vectors import VECTOR2F\n\n\nif sys.version_info[0] == 2:\n    def _iteritems(d, **kwargs):\n        return d.iteritems(**kwargs)\n\n    _zip = itertools.izip\nelse:\n    def _iteritems(d, **kwargs):\n        return iter(d.items(**kwargs))\n\n    _zip = zip\n\n\nclass ParticleSimulation(object):\n    """"""Particle simulation.\n\n    Such a system allows to have particles moving over time based on basic laws\n    of motion.\n\n    Each particle have attributes such as position, velocity, force, and mass.\n    What the force attribute really represents is the acceleration force. When\n    running the simulation, at each time interval `t` defined by the\n    simulation\'s time step, the simulation is stepped, that is, its current\n    state is solved to advance to the next state corresponding to a later point\n    in time `t + time_step`.\n\n    The solver\'s operation consists in integrating the [acceleration] force of\n    each particle to retrieve their new velocity, and in turn integrating this\n    velocity to obtain their new position. The particles end up moving over\n    time according to the forces applied to them.\n\n    Particles can be added, removed, and can have their attributes modified at\n    any point in time through three hooks provided: ``initialize_callback``,\n    ``presolve_callback``, and ``postsolve_callback``.\n\n    Warning\n    -------\n    Any modification to the particle attributes is applied in-place, that is\n    with immediate effect. However the addition and removal of particles is\n    only really executed at a later time.\n\n    This behaviour is noticable when querying the simulation\'s state: a\n    particle just added isn\'t taken into account (it lives in a buffer), while\n    one that has just been marked as \'not alive\' is still queried.\n\n    Another way to reason about this is to think of each callback as being part\n    of a node graph. A callback is like a node which takes an upstream\n    simulation state as input and outputs a new simulation state downstream.\n    Whenever querying is required, it is being done on the set of particles\n    available in the upstream state, and the downstream state is only written\n    once the callback has finished evaluating.\n\n    The method :meth:`consolidate` is the one responsible for processing all\n    the additions and removals requested and is automatically run after\n    each callback. It can also be called manually within the callbacks but it\n    isn\'t a recommended approach since it comes with a drawbacks, see\n    :meth:`consolidate`.\n\n    Parameters\n    ----------\n    time_step : float\n        See :attr:`ParticleSimulation.time_step`.\n    initial_particle_capacity : int\n        Initial number of elements allocated for the particle array.\n    particle_bucket_buffer_capacity : int\n        New particles cannot always be directly added to the array and\n        therefore temporarily end up in a buffer until the function\n        :func:`consolidate` is run. The given bucket buffer capacity\n        represents the number of elements that a single bucket can hold.\n    particle_attributes : sequence of hienoi.Field or compatible tuple\n        Additional attributes to define for each particle.\n    initialize_callback : function\n        Callback function to initialize the simulation.\n        It takes a single argument ``sim``, an instance of this class.\n    presolve_callback : function\n        Callback function executed before solving the simulation.\n        It takes a single argument ``sim``, an instance of this class.\n    postsolve_callback : function\n        Callback function executed after solving the simulation.\n        It takes a single argument ``sim``, an instance of this class.\n\n    Attributes\n    ----------\n    time_step : float\n        Amount by which the simulation time is being incremented by at each\n        step. The lower the value, the more accurate the simulation is, but the\n        more compute-intensive it becomes.\n    time : float\n        Simulation time.\n    last_particle_id : int\n        ID of the last particle created.\n    particles : sequence of nani.Particle\n        All the particles.\n    user_data : object\n        Attribute reserved for any user data.\n    """"""\n\n    _ATTRS = (\n        (\'id\', Number(type=Int32, default=-1), READ_ONLY),\n        (\'alive\', Bool(default=True)),\n        (\'position\', hienoi._common.PARTICLE_ATTRS.position.nani),\n        (\'velocity\', VECTOR2F),\n        (\'force\', VECTOR2F),\n        (\'mass\', Number(type=Float32, default=1.0)),\n        (\'size\', hienoi._common.PARTICLE_ATTRS.size.nani),\n        (\'color\', hienoi._common.PARTICLE_ATTRS.color.nani),\n    )\n    _ATTR_ID_NUMPY_TYPE = hienoi._numeric.to_numpy(_ATTRS[0][1].type)\n\n    class Neighbours(object):\n        """"""Neighbour sequence.""""""\n\n        def __init__(self, neighbours, particles, particle_view):\n            self._neighbours = neighbours\n            self._particles = particles\n            self._particle_view = particle_view\n\n        def __len__(self):\n            return len(self._neighbours)\n\n        def __iter__(self):\n            return (\n                ParticleSimulation.Neighbour(\n                    item, self._particle_view(self._particles[item[\'index\']]))\n                for item in self._neighbours)\n\n        @property\n        def data(self):\n            return self._neighbours\n\n    class Neighbour(object):\n        """"""Neighbour object.""""""\n\n        def __init__(self, data, particle):\n            self._data = data\n            self._particle = particle\n\n        @property\n        def particle(self):\n            return self._particle\n\n        @property\n        def squared_distance(self):\n            return self._data[\'squared_distance\']\n\n        @property\n        def distance(self):\n            return math.sqrt(self._data[\'squared_distance\'])\n\n    def __init__(self,\n                 time_step=0.02,\n                 initial_particle_capacity=512,\n                 particle_bucket_buffer_capacity=256,\n                 particle_attributes=None,\n                 initialize_callback=None,\n                 presolve_callback=None,\n                 postsolve_callback=None):\n        attrs = self._ATTRS\n        if particle_attributes is not None:\n            attrs += particle_attributes\n\n        self._nani = PickableNaniStructure(attrs, \'Particle\')\n\n        self._presolve_callback = presolve_callback\n        self._postsolve_callback = postsolve_callback\n\n        self._time_step = time_step\n        self._time = 0.0\n        self._last_id = -1\n\n        # Particles are stored in a contiguous, resizable, array.\n        self._array = DynamicArray(initial_particle_capacity, self._nani.dtype)\n\n        # New particles are always added into a temporary buffer until\n        # consolidation.\n        self._buffer = OrderedBuffer(particle_bucket_buffer_capacity,\n                                     self._nani.dtype)\n\n        self._kd_tree = None\n\n        self.user_data = UserData()\n        if initialize_callback:\n            initialize_callback(self)\n            self.consolidate()\n\n    @property\n    def time_step(self):\n        return self._time_step\n\n    @property\n    def time(self):\n        return self._time\n\n    @property\n    def last_particle_id(self):\n        return self._last_id\n\n    @property\n    def particles(self):\n        return self._nani.view(self._array.data)\n\n    def add_particle(self, **kwargs):\n        """"""Add a new particle.\n\n        Any read-only attribute passed to the ``kwargs`` parameter, such as the\n        \'id\' attribute, are discarded.\n\n        Parameters\n        ----------\n        kwargs\n            Keyword arguments to override the default attribute values.\n\n        Returns\n        -------\n        nani.Particle\n            The new particle.\n        """"""\n        kwargs = kwargs.copy()\n        kwargs[\'id\'] = self._last_id + 1\n        particle = self._buffer.append(self._nani.default._replace(**kwargs))\n        self._last_id = particle[\'id\']\n        return self._nani.element_view(particle)\n\n    def add_particles(self, count):\n        """"""Add a bunch of new particles.\n\n        Parameters\n        ----------\n        count : int\n            Number of particles to add.\n\n        Returns\n        -------\n        sequence of nani.Particle\n            The new particles.\n        """"""\n        array = numpy.empty(count, dtype=self._nani.dtype)\n        array[:] = self._nani.default\n        array[\'id\'] = numpy.arange(self._last_id + 1,\n                                   self._last_id + 1 + count)\n        particles = self._buffer.extend(array)\n        self._last_id = particles[\'id\'][-1]\n        return self._nani.view(particles)\n\n    def get_particle(self, id):\n        """"""Retrieve a particle.\n\n        Parameters\n        ----------\n        id : int\n            ID of the particle to retrieve.\n\n        Returns\n        -------\n        nani.Particle\n            The particle found.\n        """"""\n        # PRECONDITION: `self._array.data` sorted by id.\n        id = self._ATTR_ID_NUMPY_TYPE(id)\n        idx = numpy.searchsorted(self._array.data[\'id\'], id)\n        if idx < len(self._array) and self._array.data[idx][\'id\'] == id:\n            return self._nani.element_view(self._array.data[idx])\n\n        raise ValueError(""No particle found with ID \'%d\'."" % (id,))\n\n    def get_neighbour_particles(self, point, count=1, radius=None, sort=False):\n        """"""Retrieve the particles neighbour to a point.""""""\n        if self._kd_tree is None:\n            self._kd_tree = KDTree(self._array.data[\'position\'])\n\n        neighbours = self._kd_tree.search(point, count, radius, sort)\n        return self.Neighbours(neighbours, self._array.data,\n                               self._nani.element_view)\n\n    def step(self):\n        """"""Advance the simulation by one step.\n\n        This is where the velocity and position for each particle are solved.\n        """"""\n        self._time += self.time_step\n\n        if self._presolve_callback:\n            self._presolve_callback(self)\n            self.consolidate()\n\n        particles = self._array.data\n        _solve(particles, self.time_step)\n        particles[\'force\'] = 0\n\n        if self._postsolve_callback:\n            self._postsolve_callback(self)\n            self.consolidate()\n\n    def consolidate(self):\n        """"""Execute the addition and removal of particles.\n\n        Warning\n        -------\n        This operation is likely to invalidate any previous reference to\n        particles or to query objects.\n\n        >>> import hienoi.dynamics\n        >>> sim = hienoi.dynamics.ParticleSimulation()\n        >>> p0 = sim.add_particle()\n        >>> sim.consolidate()\n        >>> p0 = sim.get_particle(0)\n        >>> p0.force = [1.0, 1.0]\n\n        In the example above, the particle with ID 0 needs to be retrieved\n        again after consolidation. Otherwise the new force set would have been\n        applied to an invalid particle.\n        """"""\n        # POSTCONDITION: `self._array.data` sorted by id.\n        chunks = ([self._array.data]\n                  + [chunk for chunk in self._buffer.chunks])\n        filters = [chunk[\'alive\'] for chunk in chunks]\n        counts = [numpy.count_nonzero(filter) for filter in filters]\n        new_size = sum(counts)\n\n        if (len(self._buffer) == 0\n                and new_size == len(self._array)):\n            return\n\n        self._array.resize(new_size, copy=False)\n        array = self._array.data\n\n        i = 0\n        for filter, chunk, count in _zip(filters, chunks, counts):\n            if count == len(chunk):\n                array[i:i + count] = chunk\n            else:\n                numpy.compress(filter, chunk, out=array[i:i + count])\n\n            i += count\n\n        self._buffer.clear()\n        self._kd_tree = None\n\n\ndef _solve(particles, time_step):\n    """"""Solve the particles.""""""\n    # Implemented as a simple Euler integration.\n    particles[\'velocity\'] += (particles[\'force\'] * time_step\n                              / particles[\'mass\'][:, numpy.newaxis])\n    particles[\'position\'] += particles[\'velocity\'] * time_step\n'"
hienoi/gui.py,0,"b'""""""Graphical user interface.""""""\n\nimport collections\nimport ctypes\n\nimport sdl2\n\nimport hienoi.renderer\nfrom hienoi._common import GLProfile, GraphicsAPI, ParticleDisplay, UserData\nfrom hienoi._vectors import Vector2i, Vector2f, Vector4f\n\n\nclass NavigationAction(object):\n    """"""Enumerator for the current nagivation action.\n\n    Attributes\n    ----------\n    NONE\n    MOVE\n    ZOOM\n    """"""\n\n    NONE = 0\n    MOVE = 1\n    ZOOM = 2\n\n\n_Handles = collections.namedtuple(\n    \'_Handles\', (\n        \'window\',\n        \'renderer\',\n    ))\n\n\n_GLHandles = collections.namedtuple(\n    \'_GLHandles\', (\n        \'context\',\n    ))\n\n\n_RGBMasks = collections.namedtuple(\n    \'_RGBMasks\', (\n        \'red\',\n        \'green\',\n        \'blue\',\n    ))\n\n\n_FIT_VIEW_REL_PADDING = 2.0\n\nif sdl2.SDL_BYTEORDER == sdl2.SDL_LIL_ENDIAN:\n    _RGB_MASKS = _RGBMasks(red=0x000000FF, green=0x0000FF00, blue=0x00FF0000)\nelse:\n    _RGB_MASKS = _RGBMasks(red=0x00FF0000, green=0x0000FF00, blue=0x000000FF)\n\n\nclass GUI(object):\n    """"""GUI.\n\n    Parameters\n    ----------\n    window_title : str\n        Title for the window.\n    window_position : hienoi.Vector2i\n        Initial window position.\n    window_size : hienoi.Vector2i\n        Initial window size.\n    window_flags : int\n        SDL2 window flags.\n    view_aperture_x : float\n        Initial length in world units to be shown on the X axis.\n    view_zoom_range : hienoi.Vector2f\n        Zoom value range for the view.\n    mouse_wheel_step : float\n        Coefficient value for each mouse wheel step.\n    grid_density : float\n        See :attr:`GUI.grid_density`.\n    grid_adaptive_threshold : float\n        See :attr:`GUI.grid_adaptive_threshold`.\n    show_grid : bool\n        See :attr:`GUI.show_grid`.\n    background_color : hienoi.Vector4f\n        See :attr:`GUI.background_color`.\n    grid_color : hienoi.Vector4f\n        See :attr:`GUI.grid_color`.\n    grid_origin_color : hienoi.Vector4f\n        See :attr:`GUI.grid_origin_color`.\n    particle_display : int\n        See :attr:`GUI.particle_display`.\n    point_size : int\n        See :attr:`GUI.point_size`.\n    edge_feather : float\n        See :attr:`GUI.edge_feather`.\n    stroke_width : float\n        See :attr:`GUI.stroke_width`.\n    initialize_callback : function\n        Callback function to initialize any GUI state.\n        It takes a single argument ``gui``, an instance of this class.\n    on_event_callback : function\n        Callback function ran during the event polling.\n        It takes 3 arguments: ``gui``, an instance of this class,\n        ``data``, some data to pass back and forth between the caller and this\n        callback function, and ``event``, the event fired.\n    renderer : dict\n        Keyword arguments for the configuration of the renderer. See the\n        parameters for the class :class:`hienoi.renderer.Renderer`.\n\n    Attributes\n    ----------\n    view_position : hienoi.Vector2f\n        Position of the view (camera).\n    view_zoom : float\n        Current zoom value for the view.\n    grid_density : float\n        Density of the grid.\n        A density of 10.0 means that there are around 10 grid divisions\n        displayed on the X axis. A grid division unit represents a fixed length\n        in world units, meaning that the actual grid density changes depending\n        on the view\'s zoom.\n    show_grid : bool\n        True to show the grid.\n    background_color : hienoi.Vector4f\n        Color for the background.\n    grid_color : hienoi.Vector4f\n        Color for the grid.\n    grid_origin_color : hienoi.Vector4f\n        Color for the origin axis of the grid.\n    particle_display : int\n        Display mode for the particles. Available values are enumerated in the\n        :class:`~hienoi.ParticleDisplay` class.\n    point_size : int\n        Size of the particles in pixels when the display mode is set to\n        :attr:`~hienoi.ParticleDisplay.POINT`.\n    edge_feather : float\n        Feather fall-off in pixels to apply to objects drawn with displays such\n        as :attr:`~hienoi.ParticleDisplay.CIRCLE` or\n        :attr:`~hienoi.ParticleDisplay.DISC`.\n    stroke_width : float\n        Width of the stroke in pixels to apply to objects drawn with displays\n        such as :attr:`~hienoi.ParticleDisplay.CIRCLE`.\n    quit : bool\n        ``True`` to signal to the application that it should quit.\n    has_view_changed : bool\n        ``True`` if the view state has just been changed following an event. It\n        is reset to ``False`` whenever :meth:`poll_events` is called.\n    user_data : object\n        Attribute reserved for any user data.\n    """"""\n\n    def __init__(self,\n                 window_title=\'hienoi\',\n                 window_position=Vector2i(sdl2.SDL_WINDOWPOS_CENTERED,\n                                          sdl2.SDL_WINDOWPOS_CENTERED),\n                 window_size=Vector2i(800, 600),\n                 window_flags=sdl2.SDL_WINDOW_RESIZABLE,\n                 view_aperture_x=100.0,\n                 view_zoom_range=Vector2f(1e-6, 1e+6),\n                 mouse_wheel_step=0.01,\n                 grid_density=10.0,\n                 grid_adaptive_threshold=3.0,\n                 show_grid=True,\n                 background_color=Vector4f(0.15, 0.15, 0.15, 1.0),\n                 grid_color=Vector4f(0.85, 0.85, 0.85, 0.05),\n                 grid_origin_color=Vector4f(0.85, 0.25, 0.25, 0.25),\n                 particle_display=ParticleDisplay.DISC,\n                 point_size=4,\n                 edge_feather=2.0,\n                 stroke_width=0.0,\n                 initialize_callback=None,\n                 on_event_callback=None,\n                 renderer=None):\n        renderer = {} if renderer is None else renderer\n\n        if sdl2.SDL_Init(sdl2.SDL_INIT_VIDEO) != 0:\n            raise RuntimeError(sdl2.SDL_GetError().decode())\n\n        renderer_info = hienoi.renderer.get_info()\n        if renderer_info.api == GraphicsAPI.OPENGL:\n            sdl2.SDL_GL_SetAttribute(sdl2.SDL_GL_CONTEXT_MAJOR_VERSION,\n                                     renderer_info.major_version)\n            sdl2.SDL_GL_SetAttribute(sdl2.SDL_GL_CONTEXT_MINOR_VERSION,\n                                     renderer_info.minor_version)\n            if renderer_info.profile == GLProfile.CORE:\n                sdl2.SDL_GL_SetAttribute(sdl2.SDL_GL_CONTEXT_PROFILE_MASK,\n                                         sdl2.SDL_GL_CONTEXT_PROFILE_CORE)\n\n        self._handles = _create_handles(window_title, window_position,\n                                        window_size, window_flags,\n                                        renderer_info)\n        self._renderer = hienoi.renderer.Renderer(**renderer)\n\n        self._initial_view_aperture_x = view_aperture_x\n        self._view_zoom_range = view_zoom_range\n        self._mouse_wheel_step = mouse_wheel_step\n        self._grid_adaptive_threshold = grid_adaptive_threshold\n        self._on_event_callback = on_event_callback\n        self._listen_for_navigation = False\n        self._is_view_manipulated = False\n\n        self.view_position = Vector2f(0.0, 0.0)\n        self._view_zoom = 1.0\n        self.grid_density = grid_density\n        self.show_grid = show_grid\n        self.background_color = background_color\n        self.grid_color = grid_color\n        self.grid_origin_color = grid_origin_color\n        self.particle_display = particle_display\n        self.point_size = point_size\n        self.edge_feather = edge_feather\n        self.stroke_width = stroke_width\n        self._navigation_action = NavigationAction.NONE\n        self.quit = False\n\n        self.user_data = UserData()\n        if initialize_callback:\n            initialize_callback(self)\n\n    @property\n    def view_zoom(self):\n        return self._view_zoom\n\n    @view_zoom.setter\n    def view_zoom(self, value):\n        self._view_zoom = max(self._view_zoom_range[0],\n                              min(self._view_zoom_range[1], value))\n\n    @property\n    def navigation_action(self):\n        return self._navigation_action\n\n    @property\n    def has_view_changed(self):\n        return self._has_view_changed\n\n    def poll_events(self, scene_state, data=None):\n        """"""Process each event in the queue.\n\n        Parameters\n        ----------\n        scene_state : hienoi.renderer.SceneState\n            Scene state.\n        data : object\n            Data to pass back and forth between the caller and the function set\n            for the \'on event\' callback.\n        """"""\n        self._has_view_changed = False\n\n        event = sdl2.SDL_Event()\n        while sdl2.SDL_PollEvent(ctypes.byref(event)) != 0:\n            event_type = event.type\n            if event_type == sdl2.SDL_QUIT:\n                self._on_quit_event(event.quit)\n            elif event_type == sdl2.SDL_WINDOWEVENT:\n                self._on_window_event(event.window)\n            elif event_type == sdl2.SDL_KEYDOWN:\n                self._on_key_down_event(event.key, scene_state)\n            elif event_type == sdl2.SDL_KEYUP:\n                self._on_key_up_event(event.key)\n            elif event_type == sdl2.SDL_MOUSEBUTTONDOWN:\n                self._on_mouse_button_down_event(event.button)\n            elif event_type == sdl2.SDL_MOUSEBUTTONUP:\n                self._on_mouse_button_up_event(event.button)\n            elif event_type == sdl2.SDL_MOUSEWHEEL:\n                self._on_mouse_wheel_event(event.wheel)\n            elif event_type == sdl2.SDL_MOUSEMOTION:\n                self._on_mouse_motion_event(event.motion)\n\n            if self._on_event_callback:\n                self._on_event_callback(self, data, event)\n\n            if self.quit:\n                break\n\n    def render(self, scene_state):\n        """"""Render a new frame.\n\n        Parameters\n        ----------\n        scene_state : hienoi.renderer.SceneState\n            Scene state.\n        """"""\n        renderer_state = hienoi.renderer.State(\n            window_size=self.get_window_size(),\n            view_position=self.view_position,\n            view_zoom=self._view_zoom,\n            origin=self.world_to_screen(Vector2f(0.0, 0.0)),\n            initial_view_aperture_x=self._initial_view_aperture_x,\n            view_aperture=self.get_view_aperture(),\n            grid_density=self.grid_density,\n            grid_adaptive_threshold=self._grid_adaptive_threshold,\n            background_color=self.background_color,\n            grid_color=self.grid_color,\n            grid_origin_color=self.grid_origin_color,\n            show_grid=self.show_grid,\n            particle_display=self.particle_display,\n            point_size=self.point_size,\n            edge_feather=self.edge_feather,\n            stroke_width=self.stroke_width,\n        )\n\n        self._renderer.render(renderer_state, scene_state)\n\n        if hienoi.renderer.get_info().api == GraphicsAPI.OPENGL:\n            sdl2.SDL_GL_SwapWindow(self._handles.window)\n\n    def terminate(self):\n        """"""Cleanup the GUI resources.""""""\n        self._renderer.cleanup()\n        if hienoi.renderer.get_info().api == GraphicsAPI.OPENGL:\n            sdl2.SDL_GL_DeleteContext(self._handles.renderer.context)\n\n        sdl2.SDL_DestroyWindow(self._handles.window)\n        sdl2.SDL_Quit()\n\n    def get_window_size(self):\n        """"""Retrieve the window size.\n\n        Returns\n        -------\n        hienoi.Vector2i\n            The window size.\n        """"""\n        window_size_x = ctypes.c_int()\n        window_size_y = ctypes.c_int()\n        sdl2.SDL_GetWindowSize(self._handles.window,\n                               ctypes.byref(window_size_x),\n                               ctypes.byref(window_size_y))\n        return Vector2i(window_size_x.value, window_size_y.value)\n\n    def get_view_aperture(self):\n        """"""Retrieve the view aperture.\n\n        It represents the area in world units covered by the view.\n\n        Returns\n        -------\n        hienoi.Vector2f\n            The view aperture.\n        """"""\n        window_size = self.get_window_size()\n        aperture_x = self._initial_view_aperture_x / self._view_zoom\n        return Vector2f(aperture_x, aperture_x * window_size.y / window_size.x)\n\n    def get_mouse_position(self):\n        """"""Retrieve the mouse position in screen space.\n\n        Returns\n        -------\n        hienoi.Vector2i\n            The mouse position.\n        """"""\n        position_x = ctypes.c_int()\n        position_y = ctypes.c_int()\n        sdl2.SDL_GetMouseState(ctypes.byref(position_x),\n                               ctypes.byref(position_y))\n        return Vector2i(position_x.value, position_y.value)\n\n    def get_screen_to_world_ratio(self):\n        """"""Retrieve the ratio to convert a sreen unit into a world unit.\n\n        Returns\n        -------\n        float\n            The screen to world ratio.\n        """"""\n        window_size = self.get_window_size()\n        aperture_x = self._initial_view_aperture_x / self._view_zoom\n        return aperture_x / window_size.x\n\n    def screen_to_world(self, point):\n        """"""Convert a point from screen space to world space coordinates.\n\n        Parameters\n        ----------\n        point : hienoi.Vector2i\n            Point in screen space coordinates.\n\n        Returns\n        -------\n        hienoi.Vector2f\n            The point in world space coordinates.\n        """"""\n        window_size = self.get_window_size()\n        view_aperture = self.get_view_aperture()\n        return Vector2f(\n            (self.view_position.x\n             + (point.x - window_size.x / 2.0)\n             * view_aperture.x / window_size.x),\n            (self.view_position.y\n             - (point.y - window_size.y / 2.0)\n             * view_aperture.y / window_size.y))\n\n    def world_to_screen(self, point):\n        """"""Convert a point from world space to screen space coordinates.\n\n        Parameters\n        ----------\n        point : hienoi.Vector2f\n            Point in world space coordinates.\n\n        Returns\n        -------\n        hienoi.Vector2i\n            The point in screen space coordinates.\n        """"""\n        window_size = self.get_window_size()\n        view_aperture = self.get_view_aperture()\n        return Vector2i(\n            int(round(\n                (window_size.x / view_aperture.x)\n                * (-self.view_position.x + point.x + view_aperture.x / 2.0))),\n            int(round(\n                (window_size.y / view_aperture.y)\n                * (self.view_position.y - point.y + view_aperture.y / 2.0))))\n\n    def write_snapshot(self, filename):\n        """"""Take a snapshot of the view and write it as a BMP image.\n\n        Parameters\n        ----------\n        filename : str\n            Destination filename.\n        """"""\n        pixel_size = 4\n        pixels = self._renderer.read_pixels()\n        surface = sdl2.SDL_CreateRGBSurfaceFrom(\n            pixels.data, pixels.width, pixels.height,\n            8 * pixel_size, pixels.width * pixel_size,\n            _RGB_MASKS.red, _RGB_MASKS.green, _RGB_MASKS.blue, 0)\n        sdl2.SDL_SaveBMP(surface, filename)\n        sdl2.SDL_FreeSurface(surface)\n\n    def _reset_view(self):\n        """"""Reset the view position and zoom.""""""\n        self.view_position = Vector2f(0.0, 0.0)\n        self.view_zoom = 1.0\n        self._has_view_changed = True\n\n    def _fit_view(self, scene_state):\n        """"""Fit the view to the scene.""""""\n        if len(scene_state.particles) > 1:\n            window_size = self.get_window_size()\n            initial_size = Vector2f(\n                self._initial_view_aperture_x,\n                self._initial_view_aperture_x * window_size.y / window_size.x)\n\n            lower_bounds = scene_state.lower_bounds\n            upper_bounds = scene_state.upper_bounds\n            required_size = (upper_bounds - lower_bounds).iscale(\n                _FIT_VIEW_REL_PADDING)\n            required_size = Vector2f(\n                max(required_size.x,\n                    initial_size.x * self._view_zoom_range[0]),\n                max(required_size.y,\n                    initial_size.y * self._view_zoom_range[0]))\n\n            self.view_position = (lower_bounds + upper_bounds).iscale(0.5)\n            self.view_zoom = min(initial_size.x / required_size.x,\n                                 initial_size.y / required_size.y)\n        elif len(scene_state.particles) == 1:\n            self.view_position = Vector2f(\n                *scene_state.particles[\'position\'][0])\n            self.view_zoom = 1.0\n        else:\n            self._reset_view()\n\n        self._has_view_changed = True\n\n    def _on_quit_event(self, event):\n        """"""Event \'on quit\'.""""""\n        self.quit = True\n\n    def _on_window_event(self, event):\n        """"""Event \'on window\'.""""""\n        if event.event == sdl2.SDL_WINDOWEVENT_SIZE_CHANGED:\n            self._renderer.resize(event.data1, event.data2)\n\n    def _on_key_down_event(self, event, scene_state):\n        """"""Event \'on key down\'.""""""\n        code = event.keysym.sym\n        modifier = event.keysym.mod\n        if modifier == sdl2.KMOD_NONE:\n            if code == sdl2.SDLK_SPACE:\n                self._listen_for_navigation = True\n            elif code == sdl2.SDLK_d:\n                self.particle_display = (\n                    (self.particle_display + 1) % (ParticleDisplay._LAST + 1))\n            elif code == sdl2.SDLK_f:\n                self._fit_view(scene_state)\n            elif code == sdl2.SDLK_g:\n                self.show_grid = not self.show_grid\n            elif code == sdl2.SDLK_r:\n                self._reset_view()\n\n    def _on_key_up_event(self, event):\n        """"""Event \'on key up\'.""""""\n        code = event.keysym.sym\n        if code == sdl2.SDLK_SPACE:\n            self._listen_for_navigation = False\n\n    def _on_mouse_button_down_event(self, event):\n        """"""Event \'on mouse button down\'.""""""\n        if self._listen_for_navigation:\n            if event.button == sdl2.SDL_BUTTON_LEFT:\n                self._navigation_action = NavigationAction.MOVE\n            elif event.button == sdl2.SDL_BUTTON_RIGHT:\n                self._navigation_action = NavigationAction.ZOOM\n\n    def _on_mouse_button_up_event(self, event):\n        """"""Event \'on mouse button up\'.""""""\n        if (event.button == sdl2.SDL_BUTTON_LEFT\n                or event.button == sdl2.SDL_BUTTON_RIGHT):\n            self._navigation_action = NavigationAction.NONE\n\n    def _on_mouse_wheel_event(self, event):\n        """"""Event \'on mouse wheel\'.""""""\n        scale = 1.0 + self._mouse_wheel_step * event.y\n        self.view_zoom *= scale\n        self._has_view_changed = True\n\n    def _on_mouse_motion_event(self, event):\n        """"""Event \'on mouse motion\'.""""""\n        window_size = self.get_window_size()\n        view_aperture = self.get_view_aperture()\n        if self._navigation_action == NavigationAction.MOVE:\n            self.view_position.set(\n                (self.view_position.x\n                 - event.xrel * view_aperture.x / window_size.x),\n                (self.view_position.y\n                 + event.yrel * view_aperture.y / window_size.y))\n            self._has_view_changed = True\n        elif self._navigation_action == NavigationAction.ZOOM:\n            scale = (1.0\n                     + float(event.xrel) / window_size.x\n                     - float(event.yrel) / window_size.y)\n            self.view_zoom *= scale\n            self._has_view_changed = True\n\n\ndef _create_handles(window_title, window_position, window_size, window_flags,\n                    renderer_info):\n    """"""Create the SDL2 handles.""""""\n    window_flags = sdl2.SDL_WINDOW_SHOWN | window_flags\n    if renderer_info.api == GraphicsAPI.OPENGL:\n        window_flags |= sdl2.SDL_WINDOW_OPENGL\n        window = sdl2.SDL_CreateWindow(\n            window_title.encode(),\n            window_position.x, window_position.y,\n            window_size.x, window_size.y,\n            window_flags)\n        if not window:\n            raise RuntimeError(sdl2.SDL_GetError().decode())\n\n        context = sdl2.SDL_GL_CreateContext(window)\n        if not context:\n            raise RuntimeError(sdl2.SDL_GetError().decode())\n\n        # Try to disable the vertical synchronization. It applies to the active\n        # context and thus needs to be called after `SDL_GL_CreateContext`.\n        sdl2.SDL_GL_SetSwapInterval(0)\n\n        return _Handles(\n            window=window,\n            renderer=_GLHandles(context=context))\n'"
hienoi/renderer.py,0,"b'""""""OpenGL renderer.""""""\n\nimport collections\nimport ctypes\nimport itertools\nimport math\nimport operator\nimport os\nimport sys\n\nimport numpy\nimport OpenGL\nimport OpenGL.GL as gl\n\nimport hienoi._common\nimport hienoi._numeric\nfrom hienoi._common import GraphicsAPI, GLProfile, ParticleDisplay\nfrom hienoi._vectors import Vector2f\n\n\nif sys.version_info[0] == 2:\n    def _accumulate(iterable, function=operator.add):\n        iterator = iter(iterable)\n        try:\n            total = next(iterator)\n        except StopIteration:\n            return\n\n        yield total\n        for element in iterator:\n            total = function(total, element)\n            yield total\nelse:\n    _accumulate = itertools.accumulate\n\n\nOpenGL.ERROR_CHECKING = False\nOpenGL.ERROR_ON_COPY = True\n\n\nclass VertexLayout(object):\n    """"""Enumerator for the OpenGL vertex layouts.\n\n    Attributes\n    ----------\n    INTERLEAVED\n    PACKED\n    """"""\n\n    INTERLEAVED = 0\n    PACKED = 1\n\n\n_VertexFormat = collections.namedtuple(\n    \'_VertexFormat\', (\n        \'vao\',\n        \'vbo\',\n        \'attributes\',\n        \'size\',\n        \'dtype\',\n    ))\n\n\n_VertexAttribute = collections.namedtuple(\n    \'_VertexAttribute\', (\n        \'name\',\n        \'location\',\n        \'count\',\n        \'type\',\n        \'size\',\n        \'normalized\',\n        \'divisor\',\n    ))\n\n\n_Info = collections.namedtuple(\n    \'Info\', (\n        \'api\',\n        \'major_version\',\n        \'minor_version\',\n        \'profile\',\n    ))\n\n\nclass Info(_Info):\n    """"""Renderer info.\n\n    Attributes\n    ----------\n    api : int\n        Graphics API. It is set to :attr:`GraphicsAPI.OPENGL`.\n    major_version : int\n        Major version.\n    minor_version : int\n        Minor version.\n    profile : int\n        Context profile. Available values are enumerated in the\n        :class:`GLProfile` class.\n    """"""\n\n    __slots__ = ()\n\n\n_INFO = Info(\n    api=GraphicsAPI.OPENGL,\n    major_version=3,\n    minor_version=3,\n    profile=GLProfile.CORE)\n\n_BUFFERS = (\n    {\n        \'type\': \'vao\',\n        \'names\': (\'dummy\', \'particles\', \'point_particles\'),\n    },\n    {\n        \'type\': \'vbo\',\n        \'names\': (\'particles\',),\n    },\n)\n\n_PROGRAMS = (\n    {\n        \'name\': \'grid\',\n        \'shaders\': (\n            {\n                \'type\': gl.GL_VERTEX_SHADER,\n                \'filepath\': \'shaders/grid.vert\',\n            },\n            {\n                \'type\': gl.GL_FRAGMENT_SHADER,\n                \'filepath\': \'shaders/grid.frag\',\n            },\n        ),\n    },\n    {\n        \'name\': \'particles\',\n        \'shaders\': (\n            {\n                \'type\': gl.GL_VERTEX_SHADER,\n                \'filepath\': \'shaders/particles.vert\',\n            },\n            {\n                \'type\': gl.GL_FRAGMENT_SHADER,\n                \'filepath\': \'shaders/particles.frag\',\n            },\n        ),\n    },\n    {\n        \'name\': \'point_particles\',\n        \'shaders\': (\n            {\n                \'type\': gl.GL_VERTEX_SHADER,\n                \'filepath\': \'shaders/point_particles.vert\',\n            },\n            {\n                \'type\': gl.GL_FRAGMENT_SHADER,\n                \'filepath\': \'shaders/point_particles.frag\',\n            },\n        ),\n    },\n)\n\n_UNIFORMS = (\n    {\n        \'program\': \'grid\',\n        \'names\': (\'origin\', \'unit\', \'color\', \'origin_color\'),\n    },\n    {\n        \'program\': \'particles\',\n        \'names\': (\'projection\', \'half_edge_feather\', \'half_stroke_width\',\n                  \'fill\',),\n    },\n    {\n        \'program\': \'point_particles\',\n        \'names\': (\'projection\',),\n    },\n)\n\n_VERTEX_FORMATS = (\n    {\n        \'name\': \'particle\',\n        \'vao\': \'particles\',\n        \'vbo\': \'particles\',\n        \'attributes\': (\n            {\n                \'name\': \'position\',\n                \'location\': 0,\n                \'count\': hienoi._common.PARTICLE_ATTRS.position.count,\n                \'type\': hienoi._numeric.to_gl(\n                    hienoi._common.PARTICLE_ATTRS.position.element_type),\n                \'normalized\': gl.GL_FALSE,\n                \'divisor\': 1,\n            },\n            {\n                \'name\': \'size\',\n                \'location\': 1,\n                \'count\': hienoi._common.PARTICLE_ATTRS.size.count,\n                \'type\': hienoi._numeric.to_gl(\n                    hienoi._common.PARTICLE_ATTRS.size.element_type),\n                \'normalized\': gl.GL_FALSE,\n                \'divisor\': 1,\n            },\n            {\n                \'name\': \'color\',\n                \'location\': 2,\n                \'count\': hienoi._common.PARTICLE_ATTRS.color.count,\n                \'type\': hienoi._numeric.to_gl(\n                    hienoi._common.PARTICLE_ATTRS.color.element_type),\n                \'normalized\': gl.GL_FALSE,\n                \'divisor\': 1,\n            },\n        ),\n    },\n    {\n        \'name\': \'point_particle\',\n        \'vao\': \'point_particles\',\n        \'vbo\': \'particles\',\n        \'attributes\': (\n            {\n                \'name\': \'position\',\n                \'location\': 0,\n                \'count\': hienoi._common.PARTICLE_ATTRS.position.count,\n                \'type\': hienoi._numeric.to_gl(\n                    hienoi._common.PARTICLE_ATTRS.position.element_type),\n                \'normalized\': gl.GL_FALSE,\n            },\n            {\n                \'name\': \'color\',\n                \'location\': 1,\n                \'count\': hienoi._common.PARTICLE_ATTRS.color.count,\n                \'type\': hienoi._numeric.to_gl(\n                    hienoi._common.PARTICLE_ATTRS.color.element_type),\n                \'normalized\': gl.GL_FALSE,\n            },\n        ),\n    },\n)\n\n\n_State = collections.namedtuple(\n    \'State\', (\n        \'window_size\',\n        \'view_position\',\n        \'view_zoom\',\n        \'origin\',\n        \'initial_view_aperture_x\',\n        \'view_aperture\',\n        \'grid_density\',\n        \'grid_adaptive_threshold\',\n        \'background_color\',\n        \'grid_color\',\n        \'grid_origin_color\',\n        \'show_grid\',\n        \'particle_display\',\n        \'point_size\',\n        \'edge_feather\',\n        \'stroke_width\',\n    ))\n\n\nclass State(_State):\n    """"""Renderer state.\n\n    Attributes\n    ----------\n    window_size : hienoi.Vector2i\n        Size of the window.\n    view_position : hienoi.Vector2f\n        Position of the view (camera).\n    view_zoom : float\n        Current zoom value for the view.\n    origin : hienoi.Vector2f\n        Origin in screen coordinates.\n    initial_view_aperture_x : float\n        Initial length in world units to be shown on the X axis.\n    view_aperture : hienoi.Vector2f\n        Area in world units covered by the view.\n    grid_density : float\n        Density of the grid.\n        A density of 10.0 means that there are around 10 grid divisions\n        displayed on the X axis. A grid division unit represents a fixed length\n        in world units, meaning that the actual grid density changes depending\n        on the view\'s zoom.\n    grid_adaptive_threshold : float\n        Threshold at which the grid division level is readjusted.\n        A ratio of 2.0 means that the upper bound of a division level is\n        2 times more dense that its lower bound. The division level is\n        updated when the grid density reaches either end of this range.\n    background_color : hienoi.Vector4f\n        Color for the background.\n    grid_color : hienoi.Vector4f\n        Color for the grid.\n    grid_origin_color : hienoi.Vector4f\n        Color for the origin axis of the grid.\n    show_grid : bool\n        True to show the grid.\n    particle_display : int\n        Display mode for the particles. Available values are enumerated in the\n        :class:`~hienoi.ParticleDisplay` class.\n    point_size : int\n        Size of the particles in pixels when the display mode is set to\n        :attr:`~hienoi.ParticleDisplay.POINT`.\n    edge_feather : float\n        Feather fall-off in pixels to apply to objects drawn with displays such\n        as :attr:`~hienoi.ParticleDisplay.CIRCLE` or\n        :attr:`~hienoi.ParticleDisplay.DISC`.\n    stroke_width : float\n        Width of the stroke in pixels to apply to objects drawn with displays\n        such as  :attr:`~hienoi.ParticleDisplay.CIRCLE`.\n    """"""\n\n    __slots__ = ()\n\n\n_SceneState = collections.namedtuple(\n    \'SceneState\', (\n        \'time\',\n        \'particles\',\n    ))\n\n\nclass SceneState(_SceneState):\n    """"""Scene state.\n\n    Attributes\n    ----------\n    time : float\n        Time.\n    particles : numpy.ndarray\n        Particles.\n    """"""\n\n    __slots__ = ()\n\n    @property\n    def lower_bounds(self):\n        return Vector2f(*numpy.amin(self.particles[\'position\'], axis=0))\n\n    @property\n    def upper_bounds(self):\n        return Vector2f(*numpy.amax(self.particles[\'position\'], axis=0))\n\n\n_Pixels = collections.namedtuple(\n    \'Pixels\', (\n        \'data\',\n        \'width\',\n        \'height\',\n    ))\n\n\nclass Pixels(_Pixels):\n    """"""Pixels data.\n\n    Attributes\n    ----------\n    data : str\n        Data as an unsigned byte string.\n    width : int\n        Width of the pixel rectangle.\n    height : int\n        Heght of the pixel rectangle.\n    """"""\n\n    __slots__ = ()\n\n\nclass Renderer(object):\n    """"""Renderer.\n\n    Parameters\n    ----------\n    vertex_layout : int\n        OpenGL vertex layout. Available values are enumerated in the\n        :class:`VertexLayout` class.\n    """"""\n\n    def __init__(self,\n                 vertex_layout=VertexLayout.INTERLEAVED):\n        gl.glEnable(gl.GL_BLEND)\n        gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n\n        self._bufs = _generate_buffers(_BUFFERS)\n        self._programs = _create_programs(_PROGRAMS)\n        self._uniforms = _get_uniform_locations(_UNIFORMS, self._programs)\n        self._vertex_formats = _get_vertex_formats(_VERTEX_FORMATS, self._bufs)\n\n        self._vbo_capacities = {vbo: 0 for vbo in self._bufs.vbo}\n        self._vertex_layout = vertex_layout\n\n        for vertex_format in self._vertex_formats:\n            _set_vertex_attributes(vertex_format, self._vertex_layout, 0)\n\n    def render(self, state, scene_state):\n        """"""Render a new frame.\n\n        Parameters\n        ----------\n        state : hienoi.renderer.State\n            Renderer state.\n        scene_state : hienoi.renderer.SceneState\n            Scene state.\n        """"""\n        gl.glClearColor(*state.background_color)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT)\n\n        if state.show_grid:\n            self._draw_grid(state)\n\n        projection = _get_projection_matrix(\n            state.window_size, state.view_position, state.view_zoom,\n            state.view_aperture, state.initial_view_aperture_x)\n        self._draw_particles(scene_state.particles, projection, state)\n\n    def resize(self, width, height):\n        """"""Resize the OpenGL viewport.\n\n        Parameters\n        ----------\n        width : int\n            Width.\n        height : int\n            Height.\n        """"""\n        gl.glViewport(0, 0, width, height)\n\n    def cleanup(self):\n        """"""Cleanup the OpenGL resources.""""""\n        for program in self._programs:\n            gl.glDeleteProgram(program)\n\n        gl.glDeleteBuffers(len(self._bufs.vbo), self._bufs.vbo)\n        gl.glDeleteBuffers(len(self._bufs.vao), self._bufs.vao)\n\n    def read_pixels(self):\n        """"""Read the pixels from the buffer.\n\n        Returns\n        -------\n        hienoi.renderer.Pixels\n            Pixels data.\n        """"""\n        _, _, width, height = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        data = gl.glReadPixels(0, 0,\n                               width, height,\n                               gl.GL_RGBA, gl.GL_UNSIGNED_BYTE)\n        return Pixels(data=data,\n                      width=int(width),\n                      height=int(height))\n\n    def _draw_grid(self, state):\n        """"""Draw the grid.""""""\n        unit = _get_screen_space_grid_unit(state)\n\n        # The grid drawing logic mostly happens in the fragment shader, on a\n        # billboard of the size of the screen. The billboard is generated by\n        # sending 4 vertices to the vertex shader which then sets their\n        # position. Since no vertex attributes are required, no VBOs are\n        # passed, and only a dummy (empty) VAO is being used.\n        gl.glUseProgram(self._programs.grid)\n        gl.glBindVertexArray(self._bufs.vao.dummy)\n        gl.glUniform2i(self._uniforms.grid.origin,\n                       state.origin.x, state.window_size.y - state.origin.y)\n        gl.glUniform1f(self._uniforms.grid.unit, unit)\n        gl.glUniform4f(self._uniforms.grid.color, *state.grid_color)\n        gl.glUniform4f(self._uniforms.grid.origin_color,\n                       *state.grid_origin_color)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n    def _draw_particles(self, particles, projection, state):\n        """"""Draw the particles.""""""\n        particle_count = len(particles)\n        if state.particle_display == ParticleDisplay.POINT:\n            program = self._programs.point_particles\n            vao = self._bufs.vao.point_particles\n            vbo = self._bufs.vbo.particles\n            uniforms = self._uniforms.point_particles\n            vertex_format = self._vertex_formats.point_particle\n        else:\n            program = self._programs.particles\n            vao = self._bufs.vao.particles\n            vbo = self._bufs.vbo.particles\n            uniforms = self._uniforms.particles\n            vertex_format = self._vertex_formats.particle\n\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, vbo)\n        vbo_capacity = self._vbo_capacities[vbo]\n\n        size = vertex_format.size * particle_count\n        if size > vbo_capacity:\n            vbo_capacity = _grow_capacity(size, vbo_capacity, 2.0)\n            self._reserve_vbo(vbo_capacity)\n            self._vbo_capacities[vbo] = vbo_capacity\n\n        if self._vertex_layout == VertexLayout.INTERLEAVED:\n            vertex_data = numpy.ascontiguousarray(\n                _view_array_fields(\n                    particles,\n                    *(attr.name for attr in vertex_format.attributes)),\n                dtype=vertex_format.dtype)\n            gl.glBufferSubData(gl.GL_ARRAY_BUFFER, 0, size, vertex_data)\n        elif self._vertex_layout == VertexLayout.PACKED:\n            vertex_capacity = int(vbo_capacity / vertex_format.size)\n            offset = 0\n            for attr in vertex_format.attributes:\n                vertex_data = particles[attr.name]\n                gl.glBufferSubData(gl.GL_ARRAY_BUFFER, offset,\n                                   attr.size * particle_count,\n                                   vertex_data)\n                offset += attr.size * vertex_capacity\n\n        gl.glUseProgram(program)\n        gl.glBindVertexArray(vao)\n        gl.glUniformMatrix4fv(uniforms.projection, 1, gl.GL_FALSE, projection)\n\n        if state.particle_display == ParticleDisplay.POINT:\n            gl.glPointSize(state.point_size)\n            gl.glDrawArrays(gl.GL_POINTS, 0, particle_count)\n        else:\n            # The particles could have be drawn using `GL_POINTS` and\n            # `gl_PointCoord` from the fragment shader but the point size limit\n            # imposed by the GL implementations can be rather small for our\n            # needs. Also some implementations cause clipping as soon as the\n            # centre of the point exits the rendering area, without considering\n            # its size. Instead, a billboard is generated by sending 4 vertices\n            # for each particle with their position defined in the vertex\n            # shader.\n            pixel_size = state.view_aperture.x / state.window_size.x\n            gl.glUniform1f(uniforms.half_edge_feather,\n                           state.edge_feather * 0.5 * pixel_size)\n            gl.glUniform1f(uniforms.half_stroke_width,\n                           state.stroke_width * 0.5 * pixel_size)\n            gl.glUniform1i(uniforms.fill,\n                           state.particle_display == ParticleDisplay.DISC)\n            if particle_count > 0:\n                gl.glDrawArraysInstanced(gl.GL_TRIANGLE_STRIP, 0, 4,\n                                         particle_count)\n\n    def _reserve_vbo(self, capacity):\n        """"""Increase the capacity of the OpenGL VBO buffer currently bound.""""""\n        gl.glBufferData(gl.GL_ARRAY_BUFFER, capacity, None, gl.GL_DYNAMIC_DRAW)\n        if self._vertex_layout == VertexLayout.PACKED:\n            # The vertex attribute offsets need to be recomputed whenever a VBO\n            # with a packed layout is resized.\n            for vertex_format in self._vertex_formats:\n                vertex_capacity = int(capacity / vertex_format.size)\n                _set_vertex_attributes(vertex_format, VertexLayout.PACKED,\n                                       vertex_capacity)\n\n\ndef get_info():\n    """"""Retrieve some information about the renderer.\n\n    Returns\n    -------\n    hienoi.renderer.Info\n        The renderer information.\n    """"""\n    return _INFO\n\n\ndef _generate_buffers(bufs_data):\n    """"""Generate the OpenGL buffers.""""""\n    bufs = {}\n    for buf_data in bufs_data:\n        buf_type = buf_data[\'type\']\n        buf_names = buf_data[\'names\']\n        if buf_type == \'vao\':\n            gen_function = gl.glGenVertexArrays\n            struct = collections.namedtuple(\'_Buffers_vao\', buf_names)\n        elif buf_type == \'vbo\':\n            gen_function = gl.glGenBuffers\n            struct = collections.namedtuple(\'_Buffers_vbo\', buf_names)\n\n        count = len(buf_names)\n        if count == 1:\n            bufs[buf_type] = struct(gen_function(1))\n        elif count > 1:\n            bufs[buf_type] = struct(*gen_function(count))\n        else:\n            bufs[buf_type] = struct()\n\n    struct = collections.namedtuple(\'_Buffers\', bufs.keys())\n    return struct(**bufs)\n\n\ndef _create_programs(programs_data):\n    """"""Create the OpenGL programs.""""""\n    programs = {}\n    for program_data in programs_data:\n        program = gl.glCreateProgram()\n\n        shaders = []\n        shaders_data = program_data[\'shaders\']\n        for shader_data in shaders_data:\n            shader = _create_shader_from_file(shader_data[\'filepath\'],\n                                              shader_data[\'type\'])\n            gl.glAttachShader(program, shader)\n            shaders.append(shader)\n\n        gl.glLinkProgram(program)\n        if gl.glGetProgramiv(program, gl.GL_LINK_STATUS) != gl.GL_TRUE:\n            raise RuntimeError(gl.glGetProgramInfoLog(program).decode())\n\n        for shader in shaders:\n            gl.glDeleteShader(shader)\n\n        program_name = program_data[\'name\']\n        programs[program_name] = program\n\n    struct = collections.namedtuple(\'_Programs\', programs.keys())\n    return struct(**programs)\n\n\ndef _get_uniform_locations(uniforms_data, programs):\n    """"""Retrieve the OpenGL uniform locations for the specified programs.""""""\n    uniforms = {}\n    for uniform_data in uniforms_data:\n        program_name = uniform_data[\'program\']\n        program = getattr(programs, program_name, None)\n        if program is None:\n            raise RuntimeError(""No program with the name \'%s\' was defined.""\n                               % program_name)\n\n        uniform_names = uniform_data[\'names\']\n\n        program_uniforms = {}\n        for uniform_name in uniform_names:\n            location = gl.glGetUniformLocation(program, uniform_name)\n            program_uniforms[uniform_name] = location\n\n        struct = collections.namedtuple(\'_Uniforms_%s\' % program_name,\n                                        uniform_names)\n        uniforms[program_name] = struct(**program_uniforms)\n\n    struct = collections.namedtuple(\'_Uniforms\', uniforms.keys())\n    return struct(**uniforms)\n\n\ndef _get_vertex_formats(vertex_formats_data, bufs):\n    """"""Retrieve the OpenGL vertex formats.""""""\n    def get_gl_type_size(gl_type):\n        return hienoi._numeric.get_type_size(hienoi._numeric.from_gl(gl_type))\n\n    def gl_to_numpy_type(gl_type):\n        return hienoi._numeric.to_numpy(hienoi._numeric.from_gl(gl_type))\n\n    formats = {}\n    for vertex_format_data in vertex_formats_data:\n        vertex_format_name = vertex_format_data[\'name\']\n        attrs = tuple(\n            _VertexAttribute(\n                name=attr[\'name\'],\n                location=attr[\'location\'],\n                count=attr[\'count\'],\n                type=attr[\'type\'],\n                size=get_gl_type_size(attr[\'type\']) * attr[\'count\'],\n                normalized=attr[\'normalized\'],\n                divisor=attr.get(\'divisor\', 0))\n            for attr in vertex_format_data[\'attributes\'])\n        dtype = numpy.dtype([\n            (attr[\'name\'], (gl_to_numpy_type(attr[\'type\']), attr[\'count\']))\n            for attr in vertex_format_data[\'attributes\']])\n        formats[vertex_format_name] = _VertexFormat(\n            vao=getattr(bufs.vao, vertex_format_data[\'vao\']),\n            vbo=getattr(bufs.vbo, vertex_format_data[\'vbo\']),\n            attributes=attrs,\n            size=sum(attr.size for attr in attrs),\n            dtype=dtype)\n\n    struct = collections.namedtuple(\'_VertexFormats\', formats.keys())\n    return struct(**formats)\n\n\ndef _set_vertex_attributes(vertex_format, layout, vbo_vertex_capacity):\n    """"""Set the OpenGL vertex attributes.""""""\n    gl.glBindVertexArray(vertex_format.vao)\n    gl.glBindBuffer(gl.GL_ARRAY_BUFFER, vertex_format.vbo)\n\n    if layout == VertexLayout.INTERLEAVED:\n        stride = sum(attr.size for attr in vertex_format.attributes)\n        offsets = [0] + list(_accumulate([\n            attr.size for attr in vertex_format.attributes[:-1]]))\n    elif layout == VertexLayout.PACKED:\n        stride = 0\n        offsets = [0] + list(_accumulate([\n            attr.size * vbo_vertex_capacity\n            for attr in vertex_format.attributes[:-1]]))\n\n    for i, attr in enumerate(vertex_format.attributes):\n        gl.glEnableVertexAttribArray(attr.location)\n        gl.glVertexAttribPointer(\n            attr.location, attr.count, attr.type,\n            attr.normalized, stride, ctypes.c_voidp(offsets[i]))\n        gl.glVertexAttribDivisor(attr.location, attr.divisor)\n\n\ndef _create_shader_from_file(filepath, shader_type):\n    """"""Create an OpenGL shader from a file.""""""\n    here = os.path.abspath(os.path.dirname(__file__))\n    filepath = os.path.abspath(os.path.join(here, filepath))\n    with open(filepath, \'r\') as shader_file:\n        shader = gl.glCreateShader(shader_type)\n        gl.glShaderSource(shader, shader_file.read())\n        gl.glCompileShader(shader)\n        if gl.glGetShaderiv(shader, gl.GL_COMPILE_STATUS) != gl.GL_TRUE:\n            raise RuntimeError(gl.glGetShaderInfoLog(shader).decode())\n\n        return shader\n\n    return 0\n\n\ndef _get_projection_matrix(window_size, view_position, view_zoom,\n                           view_aperture, initial_view_aperture_x):\n    """"""Retrieve the projection matrix.""""""\n    scale = 2.0 * view_zoom / initial_view_aperture_x\n    return (ctypes.c_float * 16)(\n        scale,\n        0.0,\n        0.0,\n        0.0,\n\n        0.0,\n        scale * window_size.x / window_size.y,\n        0.0,\n        0.0,\n\n        0.0,\n        0.0,\n        1.0,\n        0.0,\n\n        -2.0 * view_position.x / view_aperture.x,\n        -2.0 * view_position.y / view_aperture.y,\n        0.0,\n        1.0)\n\n\ndef _get_screen_space_grid_unit(state):\n    """"""Retrieve the unit of length of the grid in screen space.""""""\n    level = pow(state.grid_adaptive_threshold,\n                math.floor(0.5 + math.log(state.view_zoom,\n                                          state.grid_adaptive_threshold)))\n    return (state.window_size.x * state.view_zoom\n            / (level * state.grid_density))\n\n\ndef _grow_capacity(requested, current, grow_factor):\n    """"""Recommended a new capacity value for when a buffer needs to grow.""""""\n    return max(requested,\n               int(max(current * grow_factor,\n                       math.ceil(1.0 / (grow_factor - 1.0)) * 2)))\n\n\ndef _view_array_fields(array, *fields):\n    """"""View the fields data from a NumPy array.""""""\n    return array.getfield(numpy.dtype(\n        {field: array.dtype.fields[field] for field in fields}))\n'"
tests/__init__.py,0,b''
tests/run.py,0,"b'#!/usr/bin/env python\n\nimport argparse\nimport collections\nimport os\nimport sys\nimport unittest\n\n\n# Usage\'s syntax based on docopt.\n_USAGE = ""%(prog)s [<name>...]""\n_DESCRIPTION = (\n    ""Runs the tests that have their name containing either one of the \'name\' ""\n    ""arguments passed. If no \'name\' argument is passed, all the tests are run.""\n)\n\n\ndef _find_tests(path, selectors=None):\n    if selectors is None:\n        def filter(test):\n            return True\n    else:\n        def filter(test):\n            return any(selector in _get_test_full_name(test)\n                       for selector in selectors)\n\n    out = []\n    loader = unittest.TestLoader()\n    if path == \'__main__\':\n        root_test = loader.loadTestsFromModule(sys.modules[path])\n    else:\n        root_test = loader.discover(path)\n\n    stack = collections.deque((root_test,))\n    while stack:\n        obj = stack.popleft()\n        if isinstance(obj, unittest.TestSuite):\n            stack.extend(test for test in obj)\n        elif type(obj).__name__ == \'ModuleImportFailure\':\n            try:\n                # This should always throw an ImportError exception.\n                getattr(obj, _get_test_name(obj))()\n            except ImportError as e:\n                sys.exit(e.message.strip())\n        elif filter(obj):\n            out.append(obj)\n\n    return out\n\n\ndef _get_test_name(test):\n    return test._testMethodName\n\n\ndef _get_test_full_name(test):\n    return \'%s.%s.%s\' % (type(test).__module__, type(test).__name__,\n                         _get_test_name(test))\n\n\ndef run(start_path, verbosity=2):\n    parser = argparse.ArgumentParser(usage=_USAGE, description=_DESCRIPTION)\n    parser.add_argument(\'name\', nargs=\'*\',\n                        help=\'partial test names to search\')\n    args = parser.parse_args()\n    selectors = args.name if args.name else None\n    tests = _find_tests(start_path, selectors)\n    suite = unittest.TestLoader().suiteClass(tests)\n    unittest.TextTestRunner(verbosity=verbosity).run(suite)\n\n\nif __name__ == ""__main__"":\n    run(os.path.abspath(os.path.dirname(__file__)))\n'"
tests/test__dynamicarray.py,0,"b""#!/usr/bin/env python\n\nimport os\nimport sys\nimport unittest\n\nimport numpy\n\n_HERE = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, os.path.abspath(os.path.join(_HERE, os.pardir)))\n\nfrom hienoi._dynamicarray import DynamicArray\n\n\nclass DynamicArrayTest(unittest.TestCase):\n\n    def test_constructor(self):\n        a = DynamicArray(0, numpy.dtype(numpy.float32))\n        self.assertEqual(len(a), 0)\n        self.assertEqual(a.capacity, 0)\n        self.assertEqual(len(a.data), 0)\n        self.assertEqual(len(a.data.base), 0)\n        self.assertEqual(a.data.tolist(), [])\n\n        a = DynamicArray(256, numpy.dtype(numpy.float32))\n        self.assertEqual(len(a), 0)\n        self.assertEqual(a.capacity, 256)\n        self.assertEqual(len(a.data), 0)\n        self.assertEqual(len(a.data.base), 256)\n        self.assertEqual(a.data.tolist(), [])\n\n    def test_data(self):\n        a = DynamicArray(256, numpy.dtype(numpy.int8))\n        a.extend([0, 1, 4, 9])\n        self.assertEqual(a.data.tolist(), [0, 1, 4, 9])\n        self.assertEqual(len(a.data.base), 256)\n\n    def test_capacity(self):\n        a = DynamicArray(0, numpy.dtype(numpy.float32))\n        self.assertEqual(a.capacity, 0)\n        a.extend([0, 1, 4, 9])\n        self.assertGreaterEqual(a.capacity, 4)\n\n        a = DynamicArray(256, numpy.dtype(numpy.float32))\n        self.assertEqual(a.capacity, 256)\n        a.extend([1, 0, 1, 4, 9])\n        self.assertEqual(a.capacity, 256)\n\n    def test_copy_from(self):\n        a = DynamicArray(0, numpy.dtype([\n            ('a', numpy.int8),\n            ('b', numpy.float32),\n            ('c', numpy.float64),\n        ]))\n        a.extend([\n            (4, 3.932, 902.345),\n            (7, 1.016, 548.229),\n            (2, 0.542, 771.031),\n            (8, 5.429, 858.063),\n        ])\n        b = DynamicArray(0, numpy.dtype([\n            ('a', numpy.int8),\n            ('c', numpy.float64),\n        ]))\n        b.copy_from(a.data)\n        self.assertEqual(len(b), 4)\n        self.assertEqual(b.data.tolist(), [(4, 902.345), (7, 548.229), (2, 771.031), (8, 858.063),])\n\n    def test_grow(self):\n        a = DynamicArray(0, numpy.dtype(numpy.int8))\n        self.assertEqual(len(a), 0)\n        self.assertEqual(len(a.data), 0)\n\n        a.grow(4)\n        self.assertEqual(len(a), 0)\n        self.assertEqual(len(a.data), 0)\n        self.assertGreaterEqual(a.capacity, 4)\n\n        a.extend([0, 1, 4, 9])\n        self.assertEqual(len(a), 4)\n        self.assertEqual(len(a.data), 4)\n        self.assertEqual(a.data.tolist(), [0, 1, 4, 9])\n\n        a.grow(2)\n        self.assertEqual(len(a), 4)\n        self.assertEqual(len(a.data), 4)\n        self.assertGreaterEqual(a.capacity, 4)\n        self.assertEqual(a.data.tolist(), [0, 1, 4, 9])\n\n        request = a.capacity * 2\n        a.grow(request)\n        self.assertEqual(len(a), 4)\n        self.assertEqual(len(a.data), 4)\n        self.assertGreaterEqual(a.capacity, request)\n        self.assertEqual(a.data.tolist(), [0, 1, 4, 9])\n\n        request = a.capacity * 2\n        a.grow(request, copy=False)\n        self.assertEqual(len(a), 0)\n        self.assertEqual(len(a.data), 0)\n        self.assertGreaterEqual(a.capacity, request)\n        self.assertEqual(a.data.tolist(), [])\n\n    def test_resize(self):\n        a = DynamicArray(0, numpy.dtype(numpy.int8))\n        a.extend([0, 1, 4, 9])\n        self.assertEqual(len(a), 4)\n        self.assertEqual(len(a.data), 4)\n        self.assertEqual(a.data.tolist(), [0, 1, 4, 9])\n\n        a.resize(2)\n        self.assertEqual(len(a), 2)\n        self.assertEqual(len(a.data), 2)\n        self.assertEqual(a.data.tolist(), [0, 1])\n\n        request = a.capacity * 2\n        a.resize(request)\n        self.assertEqual(len(a), request)\n        self.assertEqual(len(a.data), request)\n        self.assertGreaterEqual(a.capacity, request)\n        self.assertEqual(a.data.tolist()[:2], [0, 1])\n\n    def test_append(self):\n        a = DynamicArray(0, numpy.dtype(numpy.int8))\n        self.assertEqual(len(a), 0)\n        self.assertEqual(len(a.data), 0)\n\n        data = a.append(0)\n        self.assertEqual(data, 0)\n        self.assertIsInstance(data, numpy.int8)\n        self.assertEqual(len(a), 1)\n        self.assertEqual(a.data.tolist(), [0])\n\n        data = a.append(1)\n        self.assertEqual(data, 1)\n        self.assertIsInstance(data, numpy.int8)\n        self.assertEqual(len(a), 2)\n        self.assertEqual(a.data.tolist(), [0, 1])\n\n        data = a.append(4)\n        self.assertEqual(data, 4)\n        self.assertIsInstance(data, numpy.int8)\n        self.assertEqual(len(a), 3)\n        self.assertEqual(a.data.tolist(), [0, 1, 4])\n\n        data = a.append(9)\n        self.assertEqual(data, 9)\n        self.assertIsInstance(data, numpy.int8)\n        self.assertEqual(len(a), 4)\n        self.assertEqual(a.data.tolist(), [0, 1, 4, 9])\n\n    def test_extend(self):\n        a = DynamicArray(0, numpy.dtype(numpy.int8))\n        self.assertEqual(len(a), 0)\n        self.assertEqual(len(a.data), 0)\n\n        a.extend([0, 1, 4, 9])\n        self.assertEqual(len(a), 4)\n        self.assertEqual(a.data.tolist(), [0, 1, 4, 9])\n\n        a.extend([2, 4, 6, 8])\n        self.assertEqual(len(a), 8)\n        self.assertEqual(a.data.tolist(), [0, 1, 4, 9, 2, 4, 6, 8])\n\n        a.extend(numpy.arange(4))\n        self.assertEqual(len(a), 12)\n        self.assertEqual(a.data.tolist(), [0, 1, 4, 9, 2, 4, 6, 8, 0, 1, 2, 3])\n\n    def test_clear(self):\n        a = DynamicArray(0, numpy.dtype(numpy.int8))\n        a.extend([0, 1, 4, 9])\n        self.assertEqual(len(a), 4)\n        self.assertEqual(a.data.tolist(), [0, 1, 4, 9])\n\n        a.clear()\n        self.assertEqual(len(a), 0)\n        self.assertEqual(a.data.tolist(), [])\n\n\nif __name__ == '__main__':\n    from tests.run import run\n    run('__main__')\n"""
tests/test__kdtree.py,0,"b""#!/usr/bin/env python\n\nimport os\nimport sys\nimport unittest\n\nimport numpy\n\n_HERE = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, os.path.abspath(os.path.join(_HERE, os.pardir)))\n\nfrom hienoi._kdtree import KDTree\n\n\nclass KDTreeTest(unittest.TestCase):\n\n    def test_search_1(self):\n        dtype = numpy.dtype((numpy.float32, 2))\n        a = numpy.array([\n            ( 1.1,  1.5),\n            ( 1.2, -1.6),\n            (-1.3, -1.7),\n            (-1.4,  1.8),\n            ( 0.5,  0.5),\n        ], dtype=dtype)\n\n        suite = [\n            {\n                'searches': [(((2.0, 4.0),), {'count': n, 'radius': None, 'sort': True}) for n in range(len(a) + 1)],\n                'expected_indices': [0, 4, 3, 1, 2],\n                'expected_squared_distances': [7.06, 14.5, 16.4, 32.0, 43.38],\n            },\n            {\n                'searches': [(((0.6, -0.7),), {'count': n, 'radius': None, 'sort': True}) for n in range(len(a) + 1)],\n                'expected_indices': [1, 4, 2, 0, 3],\n                'expected_squared_distances': [1.17, 1.45, 4.61, 5.09, 10.25],\n            },\n            {\n                'searches': [(((-0.2, 0.4),), {'count': len(a), 'radius': 1.0, 'sort': True})],\n                'expected_indices': [4],\n                'expected_squared_distances': [0.5],\n            },\n            {\n                'searches': [(((-0.2, 0.4),), {'count': len(a), 'radius': 2.0, 'sort': True})],\n                'expected_indices': [4, 0, 3],\n                'expected_squared_distances': [0.5, 2.9, 3.4],\n            },\n            {\n                'searches': [(((-0.2, 0.4),), {'count': len(a), 'radius': 3.0, 'sort': True})],\n                'expected_indices': [4, 0, 3, 2, 1],\n                'expected_squared_distances': [0.5, 2.9, 3.4, 5.62, 5.96],\n            },\n        ]\n\n        trees = [KDTree(a, bucket_size=size) for size in range(1, len(a) + 1)]\n        for tree in trees:\n            self._test_search_suite(tree, suite)\n\n    def test_search_2(self):\n        dtype = numpy.dtype((numpy.float32, 2))\n        a = numpy.array([\n            ( 1.1,  1.5),\n            ( 1.2,  0.5),\n            (-1.3,  0.5),\n            (-1.4,  1.8),\n            ( 0.5,  0.5),\n        ], dtype=dtype)\n\n        suite = [\n            {\n                'searches': [(((-0.2, -1.5),), {'count': n, 'radius': None, 'sort': True}) for n in range(len(a) + 1)],\n                'expected_indices': [4, 2, 1, 0, 3],\n                'expected_squared_distances': [4.49, 5.21, 5.96, 10.69, 12.33],\n            },\n            {\n                'searches': [(((1.3, -0.1),), {'count': n, 'radius': None, 'sort': True}) for n in range(len(a) + 1)],\n                'expected_indices': [1, 4, 0, 2, 3],\n                'expected_squared_distances': [0.37, 1.0, 2.6, 7.12, 10.9],\n            },\n            {\n                'searches': [(((2.1, 0.7),), {'count': len(a), 'radius': 1.0, 'sort': True})],\n                'expected_indices': [1],\n                'expected_squared_distances': [0.85],\n            },\n            {\n                'searches': [(((2.1, 0.7),), {'count': len(a), 'radius': 2.0, 'sort': True})],\n                'expected_indices': [1, 0, 4],\n                'expected_squared_distances': [0.85, 1.64, 2.6],\n            },\n            {\n                'searches': [(((2.1, 0.7),), {'count': len(a), 'radius': 3.0, 'sort': True})],\n                'expected_indices': [1, 0, 4],\n                'expected_squared_distances': [0.85, 1.64, 2.6],\n            },\n            {\n                'searches': [(((2.1, 0.7),), {'count': len(a), 'radius': 4.0, 'sort': True})],\n                'expected_indices': [1, 0, 4, 2, 3],\n                'expected_squared_distances': [0.85, 1.64, 2.6, 11.6, 13.46],\n            },\n        ]\n\n        trees = [KDTree(a, bucket_size=size) for size in range(1, len(a) + 1)]\n        for tree in trees:\n            self._test_search_suite(tree, suite)\n\n    def _test_search_suite(self, tree, suite):\n        for case in suite:\n            for search in case['searches']:\n                args, kwargs = search[0], search[1]\n                n = min(len(case['expected_indices']), kwargs['count'])\n\n                neighbours = tree.search(*args, **kwargs)\n                self.assertEqual(len(neighbours), n)\n                self.assertEqual(neighbours['index'].tolist(), case['expected_indices'][:n])\n                self.assertEqual([round(d, 3) for d in neighbours['squared_distance']], case['expected_squared_distances'][:n])\n\n\nif __name__ == '__main__':\n    from tests.run import run\n    run('__main__')\n"""
tests/test__nani.py,0,"b""#!/usr/bin/env python\n\nimport os\nimport sys\nimport unittest\n\n_HERE = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, os.path.abspath(os.path.join(_HERE, os.pardir)))\n\nimport hienoi._nani\nfrom hienoi._numeric import Float32\n\n\n_PY2 = sys.version_info[0] == 2\n\n\nclass NaniTest(unittest.TestCase):\n\n    def test_basics(self):\n        data_type = hienoi._nani.Bool(default=True)\n        self.assertIsNotNone(hienoi._nani.resolve(data_type))\n\n        data_type = hienoi._nani.Object(default=[])\n        self.assertIsNotNone(hienoi._nani.resolve(data_type))\n\n        data_type = hienoi._nani.Number(type=Float32, default=1.23)\n        self.assertIsNotNone(hienoi._nani.resolve(data_type))\n\n        if _PY2:\n            data_type = hienoi._nani.String(length=8, default='abc')\n            self.assertIsNotNone(hienoi._nani.resolve(data_type))\n        else:\n            data_type = hienoi._nani.Unicode(length=8, default='abc')\n            self.assertIsNotNone(hienoi._nani.resolve(data_type))\n\n        data_type = hienoi._nani.String(length=8, default=b'abc')\n        self.assertIsNotNone(hienoi._nani.resolve(data_type))\n\n        data_type = hienoi._nani.Unicode(length=8, default=u'abc')\n        self.assertIsNotNone(hienoi._nani.resolve(data_type))\n\n        data_type = hienoi._nani.Array(element_type=hienoi._nani.Number(), shape=1)\n        self.assertIsNotNone(hienoi._nani.resolve(data_type))\n\n        data_type = hienoi._nani.Structure(\n            fields=(\n                ('number', hienoi._nani.Number()),\n            )\n        )\n        self.assertIsNotNone(hienoi._nani.resolve(data_type))\n\n\nif __name__ == '__main__':\n    from tests.run import run\n    run('__main__')\n"""
tests/test__orderedbuffer.py,0,"b""#!/usr/bin/env python\n\nimport os\nimport sys\nimport unittest\n\nimport numpy\n\n_HERE = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, os.path.abspath(os.path.join(_HERE, os.pardir)))\n\nfrom hienoi._orderedbuffer import OrderedBuffer\n\n\nclass OrderedBufferTest(unittest.TestCase):\n\n    def test_constructor(self):\n        b = OrderedBuffer(256, numpy.dtype(numpy.float32))\n        self.assertEqual(len(b), 0)\n        self.assertEqual(b.bucket_capacity, 256)\n        self.assertEqual(b.chunks, [])\n        self.assertEqual([chunk for chunk in b.chunks], [])\n\n    def test_append(self):\n        b = OrderedBuffer(3, numpy.dtype(numpy.int8))\n\n        data = b.append(9)\n        self.assertEqual(data, 9)\n        self.assertIsInstance(data, numpy.int8)\n        self.assertEqual(len(b), 1)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9]])\n\n        data = b.append(1)\n        self.assertIsInstance(data, numpy.int8)\n        self.assertEqual(len(b), 2)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1]])\n\n        data = b.append(4)\n        self.assertIsInstance(data, numpy.int8)\n        self.assertEqual(len(b), 3)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1, 4]])\n\n        data = b.append(0)\n        self.assertIsInstance(data, numpy.int8)\n        self.assertEqual(len(b), 4)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1, 4], [0]])\n\n    def test_extend(self):\n        b = OrderedBuffer(3, numpy.dtype(numpy.int8))\n\n        # Add an empty bunch.\n        bunch = b.extend([])\n        self.assertEqual(bunch.tolist(), [])\n        self.assertEqual(len(bunch), 0)\n        self.assertIsNone(bunch.base)\n        self.assertEqual(len(b), 0)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [])\n\n        # Fill the first bucket.\n        bunch = b.extend([9, 1, 4])\n        self.assertEqual(bunch.tolist(), [9, 1, 4])\n        self.assertEqual(len(bunch), 3)\n        self.assertEqual(len(bunch.base), 3)\n        self.assertEqual(len(b), 3)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1, 4]])\n\n        # Partly fill the second bucket.\n        bunch = b.extend([0, 7])\n        self.assertEqual(bunch.tolist(), [0, 7])\n        self.assertEqual(len(bunch), 2)\n        self.assertEqual(len(bunch.base), 3)\n        self.assertEqual(len(b), 5)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1, 4], [0, 7]])\n\n        # This doesn't fit without overflowing the second bucket so it is\n        # stored as a bunch.\n        bunch = b.extend([5, 2])\n        self.assertEqual(len(bunch), 2)\n        self.assertIsNone(bunch.base)\n        self.assertEqual(len(b), 7)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1, 4], [0, 7], [5, 2]])\n\n        # Finish filling the second bucket while preserving the order.\n        bunch = b.extend([3])\n        self.assertEqual(len(bunch), 1)\n        self.assertEqual(len(bunch.base), 3)\n        self.assertEqual(len(b), 8)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1, 4], [0, 7], [5, 2], [3]])\n\n        # Partly fill a third bucket.\n        bunch = b.extend([6])\n        self.assertEqual(len(bunch), 1)\n        self.assertEqual(len(bunch.base), 3)\n        self.assertEqual(len(b), 9)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1, 4], [0, 7], [5, 2], [3], [6]])\n\n        # Add a bunch larger than the bucket capacity.\n        bunch = b.extend([1, 2, 3, 4, 5])\n        self.assertEqual(len(bunch), 5)\n        self.assertIsNone(bunch.base)\n        self.assertEqual(len(b), 14)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1, 4], [0, 7], [5, 2], [3], [6], [1, 2, 3, 4, 5]])\n\n        # Finish filling the third bucket.\n        bunch = b.extend([7, 8])\n        self.assertEqual(len(bunch), 2)\n        self.assertEqual(len(bunch.base), 3)\n        self.assertEqual(len(b), 16)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1, 4], [0, 7], [5, 2], [3], [6], [1, 2, 3, 4, 5], [7, 8]])\n\n        # Partly fill a fourth bucket.\n        bunch = b.extend([9])\n        self.assertEqual(len(bunch), 1)\n        self.assertEqual(len(bunch.base), 3)\n        self.assertEqual(len(b), 17)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1, 4], [0, 7], [5, 2], [3], [6], [1, 2, 3, 4, 5], [7, 8], [9]])\n\n        # Finish filling the fourth bucket.\n        bunch = b.extend([8, 7])\n        self.assertEqual(len(bunch), 2)\n        self.assertEqual(len(bunch.base), 3)\n        self.assertEqual(len(b), 19)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1, 4], [0, 7], [5, 2], [3], [6], [1, 2, 3, 4, 5], [7, 8], [9, 8, 7]])\n\n    def test_clear(self):\n        b = OrderedBuffer(3, numpy.dtype(numpy.int8))\n        b.extend([9, 1])\n        b.extend([1, 2, 3, 4, 5])\n        b.append(4)\n        self.assertEqual(len(b), 8)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[9, 1], [1, 2, 3, 4, 5], [4]])\n\n        b.clear()\n        self.assertEqual(len(b), 0)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [])\n\n        b.append(0)\n        b.extend([7, 8, 9])\n        b.append(1)\n        b.extend([2])\n        self.assertEqual(len(b), 6)\n        self.assertEqual([chunk.tolist() for chunk in b.chunks], [[0], [7, 8, 9], [1, 2]])\n\n\nif __name__ == '__main__':\n    from tests.run import run\n    run('__main__')\n"""
tests/test_dynamics.py,0,"b""#!/usr/bin/env python\n\nimport os\nimport sys\nimport unittest\n\n_HERE = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, os.path.abspath(os.path.join(_HERE, os.pardir)))\n\nimport hienoi.dynamics\nfrom hienoi import Vector2f\n\n\nclass ParticleSimulationTest(unittest.TestCase):\n\n    def test_constructor_1(self):\n        sim = hienoi.dynamics.ParticleSimulation()\n        self.assertEqual(sim.time, 0.0)\n        self.assertEqual(sim.last_particle_id, -1)\n        self.assertEqual(len(sim.particles), 0)\n\n    def test_constructor_2(self):\n        def initialize(sim):\n            p0 = sim.add_particle()\n            p1 = sim.add_particle()\n            p2 = sim.add_particle()\n            p1.alive = False\n\n            self.assertEqual(sim.time, 0.0)\n            self.assertEqual(sim.last_particle_id, 2)\n            self.assertEqual(len(sim.particles), 0)\n            self.assertEqual(len(list(iter(sim.particles))), 0)\n            self.assertTrue(p0.alive)\n            self.assertFalse(p1.alive)\n            self.assertTrue(p2.alive)\n\n        sim = hienoi.dynamics.ParticleSimulation(initialize_callback=initialize)\n        self.assertEqual(sim.time, 0.0)\n        self.assertEqual(sim.last_particle_id, 2)\n        self.assertEqual(len(sim.particles), 2)\n        self.assertEqual(len(list(iter(sim.particles))), 2)\n        for particle in sim.particles:\n            self.assertTrue(particle.alive)\n\n    def test_add_particle(self):\n        sim = hienoi.dynamics.ParticleSimulation(particle_bucket_buffer_capacity=2)\n\n        p0 = sim.add_particle(size=2.0)\n        self.assertEqual(len(sim.particles), 0)\n        self.assertEqual(len(list(iter(sim.particles))), 0)\n        self.assertEqual(sim.last_particle_id, 0)\n        self.assertEqual(p0.id, 0)\n        self.assertEqual(p0.size, 2.0)\n        self.assertTrue(p0.alive)\n\n        p1 = sim.add_particle(id=99)\n        self.assertEqual(len(sim.particles), 0)\n        self.assertEqual(len(list(iter(sim.particles))), 0)\n        self.assertEqual(sim.last_particle_id, 1)\n        self.assertEqual(p1.id, 1)\n        self.assertTrue(p1.alive)\n\n        p2 = sim.add_particle()\n        self.assertEqual(len(sim.particles), 0)\n        self.assertEqual(len(list(iter(sim.particles))), 0)\n        self.assertEqual(sim.last_particle_id, 2)\n        self.assertEqual(p2.id, 2)\n        self.assertTrue(p2.alive)\n\n        sim.consolidate()\n        self.assertEqual(len(sim.particles), 3)\n        self.assertEqual(len(list(iter(sim.particles))), 3)\n        self.assertEqual(sim.last_particle_id, 2)\n\n    def test_add_particles(self):\n        sim = hienoi.dynamics.ParticleSimulation(particle_bucket_buffer_capacity=3)\n\n        bunch = sim.add_particles(2)\n        self.assertEqual(len(bunch), 2)\n        self.assertEqual([particle.id for particle in bunch], [0, 1])\n        self.assertEqual(len(sim.particles), 0)\n        self.assertEqual(len(list(iter(sim.particles))), 0)\n        self.assertEqual(sim.last_particle_id, 1)\n\n        bunch = sim.add_particles(5)\n        self.assertEqual(len(bunch), 5)\n        self.assertEqual([particle.id for particle in bunch], [2, 3, 4, 5, 6])\n        self.assertEqual(len(sim.particles), 0)\n        self.assertEqual(len(list(iter(sim.particles))), 0)\n        self.assertEqual(sim.last_particle_id, 6)\n\n        sim.consolidate()\n        self.assertEqual(len(sim.particles), 7)\n        self.assertEqual(len(list(iter(sim.particles))), 7)\n        self.assertEqual(sim.last_particle_id, 6)\n        self.assertEqual([particle.id for particle in sim.particles], [0, 1, 2, 3, 4, 5, 6])\n\n    def test_kill_particle(self):\n        sim = hienoi.dynamics.ParticleSimulation()\n        sim.add_particle()\n        sim.add_particle()\n        sim.consolidate()\n\n        p0 = sim.get_particle(0)\n        p1 = sim.get_particle(1)\n\n        p2 = sim.add_particle()\n        p3 = sim.add_particle()\n        p4 = sim.add_particle()\n\n        p0.alive = False\n        p3.alive = False\n\n        self.assertFalse(p0.alive)\n        self.assertTrue(p1.alive)\n        self.assertTrue(p2.alive)\n        self.assertFalse(p3.alive)\n        self.assertEqual(len(sim.particles), 2)\n\n        sim.consolidate()\n        self.assertEqual(len(sim.particles), 3)\n        self.assertEqual([particle.id for particle in sim.particles], [1, 2, 4])\n\n    def test_get_particle(self):\n        sim = hienoi.dynamics.ParticleSimulation()\n\n        sim.add_particle()\n        sim.add_particle()\n        self.assertRaises(ValueError, sim.get_particle, 0)\n        self.assertRaises(ValueError, sim.get_particle, 1)\n\n        sim.consolidate()\n        sim.add_particle()\n        sim.add_particle()\n        self.assertEqual(sim.get_particle(0).id, 0)\n        self.assertEqual(sim.get_particle(1).id, 1)\n        self.assertRaises(ValueError, sim.get_particle, 2)\n        self.assertRaises(ValueError, sim.get_particle, 3)\n\n    def test_step(self):\n        sim = hienoi.dynamics.ParticleSimulation(time_step=0.5)\n        sim.add_particle(force=(1.0, 0.0))\n        sim.add_particle(force=(2.0, 0.0))\n        sim.consolidate()\n        p0 = sim.get_particle(0)\n        p1 = sim.get_particle(1)\n        p2 = sim.add_particle(force=(3.0, 0.0))\n\n        sim.step()\n        self.assertEqual(p0.force, (0.0, 0.0))\n        self.assertEqual(p1.force, (0.0, 0.0))\n        self.assertEqual(p2.force, (3.0, 0.0))\n        self.assertEqual(p0.velocity, (0.5, 0.0))\n        self.assertEqual(p1.velocity, (1.0, 0.0))\n        self.assertEqual(p2.velocity, (0.0, 0.0))\n        self.assertEqual(p0.position, (0.25, 0.0))\n        self.assertEqual(p1.position, (0.5, 0.0))\n        self.assertEqual(p2.position, (0.0, 0.0))\n\n        sim.step()\n        self.assertEqual(p0.force, (0.0, 0.0))\n        self.assertEqual(p1.force, (0.0, 0.0))\n        self.assertEqual(p2.force, (3.0, 0.0))\n        self.assertEqual(p0.velocity, (0.5, 0.0))\n        self.assertEqual(p1.velocity, (1.0, 0.0))\n        self.assertEqual(p2.velocity, (0.0, 0.0))\n        self.assertEqual(p0.position, (0.5, 0.0))\n        self.assertEqual(p1.position, (1.0, 0.0))\n        self.assertEqual(p2.position, (0.0, 0.0))\n\n    def test_consolidate(self):\n        sim = hienoi.dynamics.ParticleSimulation()\n\n        sim.consolidate()\n        self.assertEqual(len(sim.particles), 0)\n        self.assertEqual([particle.id for particle in sim.particles], [])\n\n        p0 = sim.add_particle()\n        p1 = sim.add_particle()\n        p2 = sim.add_particle()\n        p1.alive = False\n        sim.consolidate()\n        self.assertEqual(len(sim.particles), 2)\n        self.assertEqual([particle.id for particle in sim.particles], [0, 2])\n\n        sim.add_particle()\n        sim.consolidate()\n        self.assertEqual(len(sim.particles), 3)\n        self.assertEqual([particle.id for particle in sim.particles], [0, 2, 3])\n\n\nif __name__ == '__main__':\n    from tests.run import run\n    run('__main__')\n"""
