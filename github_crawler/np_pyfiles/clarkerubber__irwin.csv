file_path,api_count,code
Env.py,0,"b'import logging\n\nfrom pymongo import MongoClient\n\nfrom chess import uci\n\nfrom modules.fishnet.fishnet import stockfish_command\n\nfrom modules.lichess.Api import Api\n\nfrom modules.game.Game import GameDB\nfrom modules.game.AnalysedGame import AnalysedGameDB\nfrom modules.game.Player import PlayerDB\nfrom modules.game.AnalysedPosition import AnalysedPositionDB\n\nfrom modules.queue.IrwinQueue import IrwinQueueDB\nfrom modules.queue.EngineQueue import EngineQueueDB\n\nfrom modules.irwin.training.AnalysedGameActivation import AnalysedGameActivationDB\nfrom modules.irwin.training.BasicGameActivation import BasicGameActivationDB\n\nfrom modules.irwin.AnalysisReport import PlayerReportDB, GameReportDB\n\nfrom modules.irwin.Env import Env as IrwinEnv\nfrom modules.irwin.Irwin import Irwin\n\nclass Env:\n    def __init__(self, config, engine=True, newmodel: bool = False):\n        logging.debug(\'newmodel\')\n        logging.debug(newmodel)\n        self.config = config\n        self.engine = engine\n\n        if self.engine:\n            self.engine = uci.popen_engine(stockfish_command(config[\'stockfish\'][\'update\']))\n            self.engine.setoption({\'Threads\': config[\'stockfish\'][\'threads\'], \'Hash\': config[\'stockfish\'][\'memory\']})\n            self.engine.uci()\n            self.infoHandler = uci.InfoHandler()\n            self.engine.info_handlers.append(self.infoHandler)\n\n        self.api = Api(config[\'api\'][\'url\'], config[\'api\'][\'token\'])\n\n        # Set up mongodb\n        self.client = MongoClient(config[\'db\'][\'host\'])\n        self.db = self.client.irwin\n        if config[\'db\'][\'authenticate\']:\n            self.db.authenticate(\n                config[\'db\'][\'authentication\'][\'username\'],\n                config[\'db\'][\'authentication\'][\'password\'], mechanism=\'MONGODB-CR\')\n\n        # Irwin\n        self.irwinEnv = IrwinEnv(config, self.db)\n        self.irwin = Irwin(self.irwinEnv, newmodel)\n\n    def restartEngine(self):\n        if self.engine:\n            self.engine.kill()\n            self.engine = uci.popen_engine(stockfish_command(self.config[\'stockfish\'][\'update\']))\n            self.engine.setoption({\'Threads\': self.config[\'stockfish\'][\'threads\'], \'Hash\': self.config[\'stockfish\'][\'memory\']})\n            self.engine.uci()\n            self.infoHandler = uci.InfoHandler()\n            self.engine.info_handlers.append(self.infoHandler)\n\n    def __del__(self):\n        logging.warning(""Removing Env"")\n        self.engine.kill()\n        try:\n            del self.irwin\n        except TypeError:\n            pass'"
app.py,0,"b'from default_imports import *\n\nimport sys\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nfrom webapp.Env import Env\n\nfrom modules.db.DBManager import DBManager\n\nfrom flask import Flask\n\nfrom webapp.controllers.api.blueprint import buildApiBlueprint\n\n\nconfig = ConfigWrapper.new(\'conf/server_config.json\')\n\nloglevels = {\n    \'CRITICAL\': logging.CRITICAL,\n    \'ERROR\': logging.ERROR,\n    \'WARNING\': logging.WARNING,\n    \'INFO\': logging.INFO,\n    \'DEBUG\': logging.DEBUG,\n    \'NOTSET\': logging.NOTSET\n}\n\nlogging.basicConfig(format=""%(message)s"", level=loglevels[config.loglevel], stream=sys.stdout)\nlogging.getLogger(""requests.packages.urllib3"").setLevel(logging.WARNING)\nlogging.getLogger(""chess.uci"").setLevel(logging.WARNING)\nlogging.getLogger(""modules.fishnet.fishnet"").setLevel(logging.INFO)\n\n## Database\ndbManager = DBManager(config)\n\n## Modules\n\nenv = Env(config)\n\napp = Flask(__name__)\n\napiBlueprint = buildApiBlueprint(env)\n\napp.register_blueprint(apiBlueprint)\n\nif __name__ == ""__main__"":\n    app.run(host=""0.0.0.0"", threaded=True)\n'"
client.py,0,"b'from default_imports import *\n\nimport argparse\nimport sys\nimport time\nimport json\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nfrom modules.game.Game import Game, GameDB\nfrom modules.game.AnalysedPosition import AnalysedPositionDB\nfrom modules.game.AnalysedGame import AnalysedGame\nfrom modules.game.EngineTools import EngineTools\n\nfrom modules.db.DBManager import DBManager\n\nfrom modules.client.Env import Env\nfrom modules.client.Api import Api\n\n\nconf = ConfigWrapper.new(\'conf/client_config.json\')\n\nparser = argparse.ArgumentParser(description=__doc__)\n## Training\nparser.add_argument(""--token"", dest=""token"", nargs=""?"",\n                default=None, help=""token to use with webserver"")\n\nloglevels = {\n    \'CRITICAL\': logging.CRITICAL,\n    \'ERROR\': logging.ERROR,\n    \'WARNING\': logging.WARNING,\n    \'INFO\': logging.INFO,\n    \'DEBUG\': logging.DEBUG,\n    \'NOTSET\': logging.NOTSET\n}\n\nlogging.basicConfig(format=""%(message)s"", level=loglevels[conf.loglevel], stream=sys.stdout)\nlogging.getLogger(""requests.packages.urllib3"").setLevel(logging.WARNING)\nlogging.getLogger(""chess.uci"").setLevel(logging.WARNING)\nlogging.getLogger(""modules.fishnet.fishnet"").setLevel(logging.WARNING)\n\nargs = parser.parse_args()\n\nenv = Env(conf, token = args.token)\napi = Api(env)\n\ndef analyseGames(games: List[Game], playerId: str) -> Iterable[AnalysedGame]:\n    """"""\n    Iterate through list of games and return analysed games\n    """"""\n\n    count = len(games)\n    for i, game in enumerate(games):\n        logging.warning(f\'{playerId}: Analysing Game #{i+1} / {count}: {game.id}\')\n        analysedGame = env.engineTools.analyseGame(game, game.white == playerId, conf[\'stockfish nodes\'])\n        if analysedGame is not None:\n            yield analysedGame\n\nwhile True:\n    logging.info(\'getting new job\')\n    job = api.requestJob()\n\n    if job is not None:\n        logging.warning(f\'Analysing Player: {job.playerId}\')\n        gameIds = [g.id for g in job.games]\n        logging.warning(f\'Analysing Games: {gameIds}\')\n\n        analysedGames = list(analyseGames(job.games, job.playerId))\n\n        response = api.completeJob(job, analysedGames)\n\n        if response is not None:\n            try:\n                resJson = response.json()\n                if response.status_code == 200:\n                    logging.info(\'SUCCESS. Posted completed job. Message: {}\'.format(resJson.get(\'message\')))\n                else:\n                    logging.warning(\'SOFT FAILURE. Failed to post completed job. Message: {}\'.format(resJson.get(\'message\')))\n            except json.decoder.JSONDecodeError:\n                logging.warning(f\'HARD FAILURE. Failed to post job. Bad response from server.\')\n    else:\n        logging.warning(\'Job is None. Pausing\')\n        time.sleep(10)\n'"
default_imports.py,0,"b""## Typing and enforcing of types\nfrom typing import NamedTuple, TypeVar, NewType, Iterable, List, Dict, Tuple\nfrom typing import Optional as Opt\n\nfrom numpy import float16, float32, float64\nfrom numpy import float as npfloat\n\nNumber = TypeVar('Number', int, float, npfloat, float16, float32, float64)\n\n## Logging\nimport logging\n\n## Tools\nnotNone = lambda x: x is not None"""
lichess-listener.py,0,"b'""""""Stream listener for Irwin. Acts on player status updates, and analysis requests""""""\nfrom default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nimport requests\nfrom requests.exceptions import ChunkedEncodingError, ConnectionError\nfrom requests.packages.urllib3.exceptions import NewConnectionError, ProtocolError, MaxRetryError\nfrom http.client import IncompleteRead\nfrom socket import gaierror\n\nfrom webapp.Env import Env\n\nfrom modules import http\nfrom modules.lichess.Request import Request\nfrom modules.queue.EngineQueue import EngineQueue\n\nimport json\nimport argparse\nimport logging\nimport sys\nfrom datetime import datetime, timedelta\nfrom time import sleep\n\nparser = argparse.ArgumentParser(description=__doc__)\n\nparser.add_argument(""--quiet"", dest=""loglevel"",\n                    default=logging.DEBUG, action=""store_const"", const=logging.INFO,\n                    help=""reduce the number of logged messages"")\nsettings = parser.parse_args()\n\nlogging.basicConfig(format=""%(message)s"", level=settings.loglevel, stream=sys.stdout)\nlogging.getLogger(""requests.packages.urllib3"").setLevel(logging.WARNING)\nlogging.getLogger(""chess.uci"").setLevel(logging.WARNING)\nlogging.getLogger(""modules.fishnet.fishnet"").setLevel(logging.WARNING)\n\n\nconfig = ConfigWrapper.new(\'conf/server_config.json\')\n\nenv = Env(config)\n\n""""""\nPossible messages that lichess will emit\n\n{\'t\':\'request\', \'origin\': \'moderator\', \'user\': {\'id\': \'userId\', \'titled\': bool, \'engine\': bool, \'games\': int}, \'games\': [<game>]}\n""""""\n\ndef handleLine(payload: Dict):\n    request = Request.fromJson(payload)\n    playerId = request.player.id\n    if request is not None:\n        logging.info(f\'Processing request for {request.player}\')\n        # store user\n        env.gameApi.writePlayer(request.player)\n        # store games\n        env.gameApi.writeGames(request.games)\n\n        existingEngineQueue = env.queue.engineQueueById(playerId)\n\n        newEngineQueue = EngineQueue.new(\n            playerId=playerId,\n            origin=request.origin,\n            gamesAndPredictions=list(zip(request.games, env.irwin.basicGameModel.predict(playerId, request.games))))\n\n        if existingEngineQueue is not None and not existingEngineQueue.completed:\n            newEngineQueue = EngineQueue.merge(existingEngineQueue, newEngineQueue)\n\n        requiredGames = env.gameApi.gamesForAnalysis(playerId, newEngineQueue.requiredGameIds)\n        if len(requiredGames) > 0:\n            env.queue.queueEngineAnalysis(newEngineQueue)\n\n\nsession = http.get_requests_session_with_keepalive()\nwhile True:\n    try:\n        r = session.get(\n            config.api.url + \'api/stream/irwin\',\n            headers = {\n                \'User-Agent\': \'Irwin\',\n                \'Authorization\': f\'Bearer {config.api.token}\'\n            },\n            stream = True\n        )\n        for line in r.iter_lines():\n            try:\n                payload = json.loads(line.decode(""utf-8""))\n                handleLine(payload)\n            except json.decoder.JSONDecodeError:\n                logging.warning(f""Failed to decode: {line.text}"")\n    except (ChunkedEncodingError, ConnectionError, NewConnectionError, ProtocolError, MaxRetryError, IncompleteRead, gaierror):\n        sleep(5)\n        continue\n'"
tools.py,0,"b'""""""Main interface for Irwin""""""\nfrom default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nimport argparse\nimport sys\nimport logging\nimport json\n\nfrom utils.updatePlayerDatabase import updatePlayerDatabase\nfrom utils.buildAnalysedPositionTable import buildAnalysedPositionTable\nfrom utils.buildAverageReport import buildAverageReport\n\nfrom Env import Env\n\nconfig = ConfigWrapper.new(\'conf/server_config.json\')\n\nparser = argparse.ArgumentParser(description=__doc__)\n## Training\nparser.add_argument(""--trainbasic"", dest=""trainbasic"", nargs=""?"",\n                default=False, const=True, help=""train basic game model"")\nparser.add_argument(""--trainanalysed"", dest=""trainanalysed"", nargs=""?"",\n                default=False, const=True, help=""train analysed game model"")\nparser.add_argument(""--filtered"", dest=""filtered"", nargs=""?"",\n                default=False, const=True , help=""use filtered dataset for training"")\nparser.add_argument(""--newmodel"", dest=""newmodel"", nargs=""?"",\n                default=False, const=True, help=""throw out current model. build new"")\n\n## Database building\nparser.add_argument(""--buildbasictable"", dest=""buildbasictable"", nargs=""?"",\n                default=False, const=True,\n                    help=""build table of basic game activations"")\nparser.add_argument(""--buildanalysedtable"", dest=""buildanalysedtable"", nargs=""?"",\n                default=False, const=True,\n                    help=""build table of analysed game activations"")\nparser.add_argument(""--buildpositiontable"", dest=""buildpositiontable"", nargs=""?"",\n                default=False, const=True,\n                    help=""build table of analysed positions"")\nparser.add_argument(""--updatedatabase"", dest=""updatedatabase"", nargs=""?"",\n                default=False, const=True,\n                    help=""collect game analyses for players. Build database collection"")\nparser.add_argument(""--buildaveragereport"", dest=""buildaveragereport"", nargs=""?"",\n                default=False, const=True,\n                    help=""build an average report for all players in the database"")\n\n## Evaluation and testing\nparser.add_argument(""--eval"", dest=""eval"", nargs=""?"",\n                default=False, const=True,\n                    help=""evaluate the performance of neural networks"")\nparser.add_argument(""--test"", dest=""test"", nargs=""?"",\n                default=False, const=True, help=""test on a single player"")\nparser.add_argument(""--discover"", dest=""discover"", nargs=""?"",\n                default=False, const=True,\n                    help=""search for cheaters in the database that haven\'t been marked"")\n\nparser.add_argument(""--quiet"", dest=""loglevel"",\n                default=logging.DEBUG, action=""store_const"", const=logging.INFO,\n                    help=""reduce the number of logged messages"")\nargs = parser.parse_args()\n\nlogging.basicConfig(format=""%(message)s"", level=args.loglevel, stream=sys.stdout)\nlogging.getLogger(""requests.packages.urllib3"").setLevel(logging.WARNING)\nlogging.getLogger(""chess.uci"").setLevel(logging.WARNING)\nlogging.getLogger(""modules.fishnet.fishnet"").setLevel(logging.INFO)\n\nlogging.debug(args.newmodel)\nenv = Env(config, newmodel=args.newmodel)\n\nif args.updatedatabase:\n    updatePlayerDatabase()\n\n# train on a single batch\nif args.trainbasic:\n    env.irwin.training.basicModelTraining.train(\n        config[\'irwin model basic training epochs\'],\n        args.filtered)\n\nif args.buildbasictable:\n    env.irwin.training.basicModelTraining.buildTable()\n\nif args.buildanalysedtable:\n    env.irwin.training.analysedModelTraining.buildTable()\n\nif args.buildpositiontable:\n    buildAnalysedPositionTable(env)\n\nif args.trainanalysed:\n    env.irwin.training.analysedModelTraining.train(\n        config[\'irwin model analysed training epochs\'],\n        args.filtered)\n\n# test on a single user in the DB\nif args.test:\n    for userId in [\'ralph27_velasco\']:\n        player = env.playerDB.byPlayerId(userId)\n        gameStore = GameStore.new()\n        gameStore.addGames(env.gameDB.byPlayerIdAndAnalysed(userId))\n        gameStore.addAnalysedGames(env.analysedGameDB.byPlayerId(userId))\n        env.api.postReport(env.irwin.report(player, gameStore))\n        logging.debug(""posted"")\n\n# how good is the network?\nif args.eval:\n    env.irwin.evaluation.evaluate()\n\nif args.discover:\n    env.irwin.discover()\n\nif args.buildaveragereport:\n    buildAverageReport(env)'"
conf/ConfigWrapper.py,0,"b'from default_imports import *\n\nimport json\n\nclass ConfigWrapper:\n    """"""\n    Used for loading and accessing values from a json config file.\n    """"""\n    def __init__(self, d: Dict):\n        self.d = d\n\n    @staticmethod\n    def new(filename: str):\n        with open(filename) as confFile:\n            return ConfigWrapper(json.load(confFile))\n\n    def __getitem__(self, key: str):\n        """"""\n        allows for accessing like, conf[""index items like this""]\n        """"""\n        try:\n            head, tail = key.split(\' \', 1)\n            return self.__getattr__(head)[tail]\n        except ValueError:\n            return self.__getattr__(key)\n\n    def __getattr__(self, key: str):\n        """"""\n        allows for accessing like, conf.index.like.this\n        """"""\n        r = self.d.get(key)\n        if isinstance(r, dict):\n            return ConfigWrapper(r)\n        return r\n\n    def asdict(self) -> Dict:\n        return self.d\n\n    def __repr__(self):\n        return ""ConfigWrapper({})"".format(self.d)'"
utils/buildAnalysedPositionTable.py,0,"b'from chess.pgn import read_game\nfrom modules.game.AnalysedPosition import AnalysedPosition\nimport logging\n\ndef buildAnalysedPositionTable(env):\n    logging.info(""buildAnalysedPositionColl"")\n    logging.info(""Getting AnalysedGames"")\n    batch = 908\n    while True:\n        logging.info(""Processing Batch: "" + str(batch))\n        analysedGames = env.analysedGameDB.allBatch(batch)\n        batch += 1\n        if len(analysedGames) == 0:\n            logging.info(""reached end of analysedGameDB"")\n            return\n        analysedGamesLength = str(len(analysedGames))\n        for i, analysedGame in enumerate(analysedGames):\n            game = env.gameDB.byId(analysedGame.gameId)\n            white = analysedGame.userId == game.white # is the player black or white\n            try:\n                from StringIO import StringIO\n            except ImportError:\n                from io import StringIO\n\n            try:\n                playableGame = read_game(StringIO("" "".join(game.pgn)))\n            except ValueError:\n                continue\n\n            node = playableGame\n\n            index = 0\n            analysedPositions = []\n            logging.info(""walking through game - "" + game.id + "" - "" + str(i) + ""/"" + analysedGamesLength)\n            while not node.is_end():\n                nextNode = node.variation(0)\n                if white == node.board().turn: # if it is the turn of the player of interest\n                    analysedPositions.append(AnalysedPosition.fromBoardAndAnalyses(\n                        node.board(),\n                        analysedGame.analysedMoves[index].analyses))\n                    index += 1\n                node = nextNode\n            env.analysedPositionDB.writeMany(analysedPositions)\n'"
utils/buildAverageReport.py,0,"b'"""""" build and average player report and game report """"""\nimport logging\nfrom random import shuffle\nfrom modules.irwin.AnalysisReport import GameReportStore\n\ndef gameReportStoreByPlayers(env, players):\n    logging.debug(\'getting player reports against players\')\n    playerReports = [env.playerReportDB.newestByUserId(player.id) for player in players]\n    gameReports = []\n    logging.debug(\'getting game reports against player reports\')\n    [gameReports.extend(env.gameReportDB.byReportId(report.id)) for report in playerReports if report is not None]\n    return GameReportStore(gameReports)\n\ndef getAverages(gameReportStore):\n    return {\n        \'averageLossByMove\': gameReportStore.averageLossByMove(),\n        \'averageRankByMove\': gameReportStore.averageRankByMove()\n    }\n\n\ndef buildAverageReport(env):\n    logging.debug(\'getting legit players\')\n    legitPlayers = env.playerDB.byEngine(False)\n    titledPlayers = [player for player in legitPlayers if player.titled]\n\n    logging.debug(\'---calculating legit averages---\')\n    legitReportStore = gameReportStoreByPlayers(env, legitPlayers)\n    legitAvgs = getAverages(legitReportStore)\n    del legitReportStore\n    del legitPlayers\n\n    logging.debug(\'---calculating titled averages---\')\n    titledReportStore = gameReportStoreByPlayers(env, titledPlayers)\n    titledAvgs = getAverages(titledReportStore)\n    del titledReportStore\n    del titledPlayers\n\n    logging.debug(\'---calculating engine averages---\')\n    engineReportStore = gameReportStoreByPlayers(env, env.playerDB.byEngine(True))\n    engineAvgs = getAverages(engineReportStore)\n    del engineReportStore\n\n    averages = {\n        \'legit\': legitAvgs,\n        \'titled\': titledAvgs,\n        \'engine\': engineAvgs\n    }\n\n    logging.debug(averages)\n'"
utils/updatePlayerDatabase.py,0,"b'""""""Update data on players in the database""""""\nimport logging\n\nfrom modules.game.Player import Player\nfrom modules.game.Game import Game\nfrom modules.game.GameStore import GameStore\n\ndef updatePlayerDatabase(env):\n    players= env.playerDB.all()\n    length = len(players)\n    for i, p in enumerate(players):\n        logging.info(\'Getting player data for \'+p.id + \'  -  \'+str(i)+\'/\'+str(length))\n        playerData = env.api.getPlayerData(p.id)\n        if playerData is not None:\n            env.playerDB.write(Player.fromPlayerData(playerData))\n            env.gameDB.writeMany(Game.fromPlayerData(playerData))'"
webapp/DefaultResponse.py,0,"b""from flask import Response, json\n\nSuccess = Response(\n    response=json.dumps({\n        'success': True,\n        'message': 'action completed successfully'\n        }),\n    status=200,\n    mimetype='application/json')\n\nBadRequest = Response(\n    response=json.dumps({\n        'success': False,\n        'message': 'bad request'\n        }),\n    status=400,\n    mimetype='application/json')\n\nNotAuthorised = Response(\n    response=json.dumps({\n        'success': False,\n        'message': 'you are not authorised to perform that action'\n        }),\n    status=401,\n    mimetype='application/json')\n\nNotAvailable = Response(\n    response=json.dumps({\n        'success': False,\n        'message': 'resource not available'\n        }),\n    status=418,\n    mimetype='application/json')"""
webapp/Env.py,0,"b""from modules.db.DBManager import DBManager\n\nfrom modules.auth.Auth import Auth\nfrom modules.auth.Env import Env as AuthEnv\n\nfrom modules.game.Env import Env as GameEnv\nfrom modules.game.Api import Api as GameApi\n\nfrom modules.queue.Env import Env as QueueEnv\nfrom modules.queue.Queue import Queue\n\nfrom modules.irwin.Env import Env as IrwinEnv\nfrom modules.irwin.Irwin import Irwin\n\nfrom modules.lichess.Api import Api as LichessApi\n\nimport logging\n\nclass Env:\n    def __init__(self, config):\n        self.config = config\n\n        ## Database\n        self.dbManager = DBManager(self.config)\n        self.db = self.dbManager.db()\n\n        ## Envs\n        self.authEnv = AuthEnv(self.config, self.db)\n        self.gameEnv = GameEnv(self.config, self.db)\n        self.queueEnv = QueueEnv(self.config, self.db)\n        self.irwinEnv = IrwinEnv(self.config, self.db)\n\n        ## Modules\n        self.auth = Auth(self.authEnv)\n        self.gameApi = GameApi(self.gameEnv)\n        self.queue = Queue(self.queueEnv)\n        self.irwin = Irwin(self.irwinEnv)\n        self.lichessApi = LichessApi(self.config['api url'], self.config['api token'])\n"""
modules/auth/Auth.py,0,"b'from default_imports import *\n\nfrom modules.auth.Env import Env\nfrom modules.auth.User import User, UserID, Username, Password\nfrom modules.auth.Token import Token, TokenID\nfrom modules.auth.Priv import Priv\n\nfrom webapp.DefaultResponse import BadRequest\n\nfrom flask import request, abort\nfrom functools import wraps\n\nAuthable = TypeVar(\'Authable\', User, Token)\n\nAuthorised = NewType(\'Authorised\', bool)\n\nAuthID = TypeVar(\'AuthID\', UserID, TokenID)\n\nclass Auth(NamedTuple(\'Auth\', [(\'env\', Env)])):\n    def loginUser(self, username: Username, password: Password) -> Tuple[Opt[User], Authorised]:\n        """"""\n        Attempts to log in a user.\n        Returns True is successful.\n        False if the user exists and the password is incorrect.\n        None if the user does not exist.\n        """"""\n        user = self.env.userDB.byId(username)\n        if user is not None:\n            return (user, user.checkPassword(password))\n        return (None, False)\n\n    def registerUser(self, name: Username, password: Password, privs: List[Priv] = []) -> Opt[User]:\n        """"""\n        Will attempt to register a user.\n        Returns User object if successful, otherwise None.\n        """"""\n        user = User.new(name, password, privs)\n        if env.userDB.byId(user.id) is None:\n            env.userDB.write(user)\n            return user\n        return None\n\n    def authoriseTokenId(self, tokenId: TokenID, priv: Priv) -> Tuple[Opt[Token], Authorised]:\n        """"""\n        Given a tokenId, will check if the tokenId has priv.\n        """"""\n        token = self.env.tokenDB.byId(tokenId)\n        if token is not None:\n            return (token, token.hasPriv(priv))\n        return (None, False)\n\n    def authoriseUser(self, username: Username, password: Password, priv: Priv) -> Tuple[Opt[User], Authorised]:\n        """"""\n        Checks if user has priv in list of privs. \n        """"""\n        user, loggedIn = self.loginUser(username, password)\n        if user is not None:\n            return (user, loggedIn and user.hasPriv(priv))\n        return (None, False)\n\n    def authoriseRequest(self, req: Opt[Dict], priv: Priv) -> Tuple[Opt[Authable], Authorised]:\n        """"""\n        Checks if a request is verified with priv.\n        """"""\n        if req is not None:\n            # Attempt to authorise token first\n            authReq = req.get(\'auth\')\n            if authReq is not None:\n                tokenId = authReq.get(\'token\')\n                if tokenId is not None:\n                    return self.authoriseTokenId(tokenId, priv)\n\n                # Then attempt to authorise user/password\n                username = authReq.get(\'username\')\n                password = authReq.get(\'password\')\n\n                if None not in [username, password]:\n                    return self.authoriseUser(username, password, priv)\n\n        return (None, False)\n\n    def authoriseRoute(self, priv: Priv):\n        """"""\n        Wrap around a flask route and check it is authorised\n        """"""\n        def decorator(func):\n            @wraps(func)\n            def wrapper(*args, **kwargs):\n                json_obj = request.get_json(silent=True)\n                authable, authorised = self.authoriseRequest(json_obj, priv)\n                if authorised:\n                    logging.info(f\'{authable.name} has been authorised to {priv.permission}\')\n                    args_ = (authable,) + args\n                    return func(*args_, **kwargs)\n                if authable is not None:\n                    logging.warning(f\'UNAUTHORISED: {authable.name} has tried to perform an action requiring {priv.permission}\')\n                abort(BadRequest)\n            return wrapper\n        return decorator'"
modules/auth/Env.py,0,"b'from default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nfrom modules.auth.User import UserDB\nfrom modules.auth.Token import TokenDB\n\nfrom pymongo.database import Database\n\nclass Env:\n    def __init__(self, config: ConfigWrapper, db: Database):\n        self.db = db\n        self.config = config\n        self.userDB = UserDB(self.db[self.config[""auth coll user""]])\n        self.tokenDB = TokenDB(self.db[self.config[""auth coll token""]])'"
modules/auth/Priv.py,0,"b""from default_imports import *\n\nPermission = NewType('Permission', str)\n\nPriv = NamedTuple('Priv', [\n        ('permission', Permission)\n    ])\n\nRequestJob = Priv('request_job') # client can request work\nCompleteJob = Priv('complete_job') # client can post results of work\nPostJob = Priv('post_job') # lichess can post a job for analysis"""
modules/auth/Token.py,0,"b""from default_imports import *\n\nfrom modules.auth.Priv import Priv\n\nfrom pymongo.collection import Collection\n\nTokenID = NewType('TokenID', str)\n\nclass Token(NamedTuple('Token', [\n        ('id', TokenID),\n        ('name', str),\n        ('privs', List[Priv])\n    ])):\n    def hasPriv(self, priv: Priv) -> bool:\n        return priv in self.privs\n\nclass TokenBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> Token:\n        return Token(\n            id = bson['_id'],\n            name = bson['name'],\n            privs = [Priv(p) for p in bson['privs']])\n\n    @staticmethod\n    def writes(token: Token) -> Dict:\n        return {\n            '_id': token.id,\n            'name': token.name,\n            'privs': [p.permission for p in token.privs]}\n\nclass TokenDB(NamedTuple('TokenDB', [\n        ('coll', Collection)\n    ])):\n    def write(self, token: Token):\n        self.coll.update_one({'_id': token.id}, {'$set': TokenBSONHandler.writes(token)}, upsert=True)\n\n    def byId(self, _id: TokenID) -> Opt[Token]:\n        doc = self.coll.find_one({'_id': _id})\n        return None if doc is None else TokenBSONHandler.reads(doc)"""
modules/auth/User.py,0,"b'from default_imports import *\n\nfrom modules.auth.Priv import Priv\n\nfrom pymongo.collection import Collection\nimport hashlib, uuid\n\nUsername = NewType(\'Username\', str)\nUserID = NewType(\'UserID\', str)\nPassword = NewType(\'Password\', str)\nSalt = NewType(\'Salt\', str)\n\nclass User(NamedTuple(\'User\', [\n        (\'id\', UserID), \n        (\'name\', Username),\n        (\'password\', Password),\n        (\'salt\', Salt),\n        (\'privs\', List[Priv])\n    ])):\n    @staticmethod\n    def new(name: Username, password: Password, privs: List[Priv] = []):\n        """"""\n        Creates a new User object.\n        """"""\n        hashedPassword, salt = User.hashPassword(password)\n        return User(\n            id = name.lower().replace(\' \', \'\'),\n            name = name,\n            password = hashedPassword,\n            salt = salt,\n            privs = privs\n            )\n\n    @staticmethod\n    def hashPassword(password: Password, salt: Opt[Salt] = None) -> Tuple[Password, Salt]:\n        """"""\n        Given a string and a salt this function will generate a hash of the password.\n        If salt is not provided a new random salt is created.\n        """"""\n        if salt is None:\n            salt = uuid.uuid4().hex\n        hashedPassword = hashlib.sha512(password + salt).hexdigest()\n        return hashedPassword, salt\n\n    def checkPassword(self, password: Password) -> bool:\n        """"""\n        Checks if a raw password matches that hashed password of the user.\n        """"""\n        return self.hashPassword(password, self.salt) == self.password\n\nclass UserBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> User:\n        return User(\n            id = bson[\'_id\'],\n            name = bson[\'name\'],\n            password = bson[\'password\'],\n            salt = bson[\'salt\'],\n            privs = [Priv(p) for p in bson[\'privs\']])\n\n    @staticmethod\n    def writes(user: User) -> Dict:\n        return {\n            \'_id\': user.id,\n            \'name\': user.name,\n            \'password\': user.password,\n            \'salt\': user.salt,\n            \'privs\': [p.permission for p in user.privs]\n        }\n\nclass UserDB(NamedTuple(\'UserDB\', [\n        (\'coll\', Collection)\n    ])):\n    def write(self, user: User):\n        self.coll.update_one({\'_id\': user.id}, {\'$set\': UserBSONHandler.writes(user)}, upsert=True)\n\n    def byId(self, _id: UserID) -> Opt[User]:\n        doc = self.coll.find_one({\'_id\': _id})\n        return None if doc is None else UserBSONHandler.reads(doc)'"
modules/client/Api.py,0,"b'from default_imports import *\n\nimport json\nimport requests\nimport time\n\nfrom modules.game.Game import GameBSONHandler\nfrom modules.game.AnalysedGame import AnalysedGameBSONHandler, AnalysedGame\nfrom modules.client.Env import Env\nfrom modules.client.Job import Job\n\nfrom requests.models import Response\n\nclass Api(NamedTuple(\'Api\', [\n        (\'env\', Env)\n    ])):\n    def requestJob(self) -> Opt[Dict]:\n        for i in range(5):\n            try:\n                result = requests.get(f\'{self.env.url}/api/request_job\', json={\'auth\': self.env.auth})\n                return Job.fromJson(result.json())\n            except (json.decoder.JSONDecodeError, requests.ConnectionError, requests.exceptions.SSLError):\n                logging.warning(f""Error in request job. Trying again in 10 sec. Received: {result.text}"")\n                time.sleep(10)\n        return None\n\n    def completeJob(self, job: Job, analysedGames: List[AnalysedGame]) -> Opt[Response]:\n        payload = {\n            \'auth\': self.env.auth,\n            \'job\': job.toJson(),\n            \'analysedGames\': [ag.toJson() for ag in analysedGames] \n        }\n        for i in range(5):\n            try:\n                result = requests.post(f\'{self.env.url}/api/complete_job\', json=payload)\n                return result\n            except (json.decoder.JSONDecodeError, requests.ConnectionError, requests.exceptions.SSLError):\n                logging.warning(\'Error in completing job. Trying again in 10 sec\')\n                time.sleep(10)\n        return None'"
modules/client/Env.py,0,"b'from default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nfrom modules.game.EngineTools import EngineTools\n\nclass Env:\n    def __init__(self, config: ConfigWrapper, token: Opt[str] = None):\n        self.config = config\n        self.url = ""{}://{}"".format(self.config.server.protocol, self.config.server.domain)\n        self.engineTools = EngineTools.new(self.config)\n        if token is None:\n            self.auth = self.config.auth.asdict()\n        else:\n            self.auth = {\'token\': token}'"
modules/client/Job.py,0,"b""from default_imports import *\n\nfrom modules.game.Player import PlayerID\nfrom modules.game.Game import Game, GameBSONHandler\nfrom modules.game.AnalysedPosition import AnalysedPosition, AnalysedPositionBSONHandler\n\nclass Job(NamedTuple('Job', [\n        ('playerId', PlayerID),\n        ('games', List[Game]),\n        ('analysedPositions', List[AnalysedPosition])\n    ])):\n    @staticmethod\n    def fromJson(json: Dict):\n        try:\n            return JobBSONHandler.reads(json)\n        except KeyError as e:\n            logging.warning(f'Failed convert {json} to Job: {e}')\n            return None\n\n    def toJson(self):\n        return JobBSONHandler.writes(self)\n\nclass JobBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> Job:\n        return Job(\n            playerId = bson['playerId'],\n            games = [GameBSONHandler.reads(g) for g in bson['games']],\n            analysedPositions = [AnalysedPositionBSONHandler.reads(ap) for ap in bson['analysedPositions']])\n\n    @staticmethod\n    def writes(job: Job) -> Dict:\n        return {\n            'playerId': job.playerId,\n            'games': [g.toJson() for g in job.games],\n            'analysedPositions': [AnalysedPositionBSONHandler.writes(ap) for ap in job.analysedPositions]\n        }"""
modules/db/DBManager.py,0,"b""from default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nfrom pymongo import MongoClient\nfrom pymongo.database import Database\n\nclass DBManager(NamedTuple('DBManager', [\n        ('config', 'ConfigWrapper')\n    ])):\n    def client(self) -> MongoClient:\n        return MongoClient(self.config.db.host)\n\n    def db(self) -> Database:\n        client = self.client()\n        db = client[self.config['db database']]\n        if self.config['db authenticate']:\n            db.authenticate(\n                self.config.authentication.username,\n                self.config.authentication.password, mechanism='MONGODB-CR')\n        return db"""
modules/fishnet/fishnet.py,0,"b'# -*- coding: utf-8 -*-\n\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport json\nimport time\nimport contextlib\nimport sys\nimport os\nimport stat\nimport platform\nimport ctypes\n\ntry:\n    import httplib\nexcept ImportError:\n    import http.client as httplib\n\ntry:\n    import urlparse\nexcept ImportError:\n    import urllib.parse as urlparse\n\ntry:\n    import urllib.request as urllib\nexcept ImportError:\n    import urllib\n\n\ndef stockfish_command(update=True):\n    filename = stockfish_filename()\n\n    if update:\n        filename = update_stockfish(filename)\n\n    return os.path.join(""."", filename)\n\n\ndef stockfish_filename():\n    machine = platform.machine().lower()\n\n    modern, bmi2 = detect_cpu_capabilities()\n    if modern and bmi2:\n        suffix = ""-bmi2""\n    elif modern:\n        suffix = ""-modern""\n    else:\n        suffix = """"\n\n    if os.name == ""nt"":\n        return ""stockfish-windows-%s%s.exe"" % (machine, suffix)\n    elif os.name == ""os2"" or sys.platform == ""darwin"":\n        return ""stockfish-osx-%s"" % machine\n    elif os.name == ""posix"":\n        return ""stockfish-%s%s"" % (machine, suffix)\n\n\ndef update_stockfish(filename):\n    print(""Looking up %s ..."" % filename)\n\n    headers = {}\n    headers[""User-Agent""] = ""Python-Puzzle-Generator""\n\n    # Only update to newer versions\n    try:\n        headers[""If-Modified-Since""] = time.strftime(\'%a, %d %b %Y %H:%M:%S GMT\', time.gmtime(os.path.getmtime(filename)))\n    except OSError:\n        pass\n\n    # Escape GitHub API rate limiting\n    if ""GITHUB_API_TOKEN"" in os.environ:\n        headers[""Authorization""] = ""token %s"" % os.environ[""GITHUB_API_TOKEN""]\n\n    # Find latest release\n    with http(""GET"", ""https://api.github.com/repos/niklasf/Stockfish/releases/latest"", headers=headers) as response:\n        if response.status == 304:\n            print(""Local %s is newer than release"" % filename)\n            return filename\n\n        release = json.loads(response.read().decode(""utf-8""))\n\n    print(""Latest stockfish release is tagged"", release[""tag_name""])\n\n    for asset in release[""assets""]:\n        if asset[""name""] == filename:\n            print(""Found"", asset[""browser_download_url""])\n            break\n    else:\n        raise ConfigError(""No precompiled %s for your platform"" % filename)\n\n    # Download\n    def reporthook(a, b, c):\n        if sys.stderr.isatty():\n            sys.stderr.write(""\\rDownloading %s: %d/%d (%d%%)"" % (\n                                 filename, min(a * b, c), c,\n                                 round(min(a * b, c) * 100 / c)))\n            sys.stderr.flush()\n\n    urllib.urlretrieve(asset[""browser_download_url""], filename, reporthook)\n\n    sys.stderr.write(""\\n"")\n    sys.stderr.flush()\n\n    # Make executable\n    print(""chmod +x"", filename)\n    st = os.stat(filename)\n    os.chmod(filename, st.st_mode | stat.S_IEXEC)\n    return filename\n\n\n@contextlib.contextmanager\ndef make_cpuid():\n    # Loosely based on cpuid.py by Anders H\xc3\xb8st, licensed MIT:\n    # https://github.com/flababah/cpuid.py\n\n    # Prepare system information\n    is_windows = os.name == ""nt""\n    is_64bit = ctypes.sizeof(ctypes.c_void_p) == 8\n    if platform.machine().lower() not in [""amd64"", ""x86_64"", ""x86"", ""i686""]:\n        raise OSError(""Got no CPUID opcodes for %s"" % platform.machine())\n\n    # Struct for return value\n    class CPUID_struct(ctypes.Structure):\n        _fields_ = [(""eax"", ctypes.c_uint32),\n                    (""ebx"", ctypes.c_uint32),\n                    (""ecx"", ctypes.c_uint32),\n                    (""edx"", ctypes.c_uint32)]\n\n    # Select kernel32 or libc\n    if is_windows:\n        if is_64bit:\n            libc = ctypes.CDLL(""kernel32.dll"")\n        else:\n            libc = ctypes.windll.kernel32\n    else:\n        libc = ctypes.pythonapi\n\n    # Select opcodes\n    if is_64bit:\n        if is_windows:\n            # Windows x86_64\n            # Two first call registers : RCX, RDX\n            # Volatile registers       : RAX, RCX, RDX, R8-11\n            opc = [\n                0x53,                    # push   %rbx\n                0x48, 0x89, 0xd0,        # mov    %rdx,%rax\n                0x49, 0x89, 0xc8,        # mov    %rcx,%r8\n                0x31, 0xc9,              # xor    %ecx,%ecx\n                0x0f, 0xa2,              # cpuid\n                0x41, 0x89, 0x00,        # mov    %eax,(%r8)\n                0x41, 0x89, 0x58, 0x04,  # mov    %ebx,0x4(%r8)\n                0x41, 0x89, 0x48, 0x08,  # mov    %ecx,0x8(%r8)\n                0x41, 0x89, 0x50, 0x0c,  # mov    %edx,0xc(%r8)\n                0x5b,                    # pop    %rbx\n                0xc3                     # retq\n            ]\n        else:\n            # Posix x86_64\n            # Two first call registers : RDI, RSI\n            # Volatile registers       : RAX, RCX, RDX, RSI, RDI, R8-11\n            opc = [\n                0x53,                    # push   %rbx\n                0x48, 0x89, 0xf0,        # mov    %rsi,%rax\n                0x31, 0xc9,              # xor    %ecx,%ecx\n                0x0f, 0xa2,              # cpuid\n                0x89, 0x07,              # mov    %eax,(%rdi)\n                0x89, 0x5f, 0x04,        # mov    %ebx,0x4(%rdi)\n                0x89, 0x4f, 0x08,        # mov    %ecx,0x8(%rdi)\n                0x89, 0x57, 0x0c,        # mov    %edx,0xc(%rdi)\n                0x5b,                    # pop    %rbx\n                0xc3                     # retq\n            ]\n    else:\n        # CDECL 32 bit\n        # Two first call registers : Stack (%esp)\n        # Volatile registers       : EAX, ECX, EDX\n        opc = [\n            0x53,                    # push   %ebx\n            0x57,                    # push   %edi\n            0x8b, 0x7c, 0x24, 0x0c,  # mov    0xc(%esp),%edi\n            0x8b, 0x44, 0x24, 0x10,  # mov    0x10(%esp),%eax\n            0x31, 0xc9,              # xor    %ecx,%ecx\n            0x0f, 0xa2,              # cpuid\n            0x89, 0x07,              # mov    %eax,(%edi)\n            0x89, 0x5f, 0x04,        # mov    %ebx,0x4(%edi)\n            0x89, 0x4f, 0x08,        # mov    %ecx,0x8(%edi)\n            0x89, 0x57, 0x0c,        # mov    %edx,0xc(%edi)\n            0x5f,                    # pop    %edi\n            0x5b,                    # pop    %ebx\n            0xc3                     # ret\n        ]\n\n    code_size = len(opc)\n    code = (ctypes.c_ubyte * code_size)(*opc)\n\n    if is_windows:\n        # Allocate executable memory\n        addr = libc.VirtualAlloc(None, code_size, 0x1000, 0x40)\n        if not addr:\n            raise MemoryError(""Could not VirtualAlloc RWX memory"")\n    else:\n        # Allocate memory\n        libc.valloc.restype = ctypes.c_void_p\n        libc.valloc.argtypes = [ctypes.c_size_t]\n        addr = libc.valloc(code_size)\n        if not addr:\n            raise MemoryError(""Could not valloc memory"")\n\n        # Make executable\n        libc.mprotect.restype = ctypes.c_int\n        libc.mprotect.argtypes = [ctypes.c_void_p, ctypes.c_size_t, ctypes.c_int]\n        if 0 != libc.mprotect(addr, code_size, 1 | 2 | 4):\n            raise OSError(""Failed to set RWX using mprotect"")\n\n    # Copy code to allocated executable memory. No need to flush instruction\n    # cache for CPUID.\n    ctypes.memmove(addr, code, code_size)\n\n    # Create and yield callable\n    result = CPUID_struct()\n    func_type = ctypes.CFUNCTYPE(None, ctypes.POINTER(CPUID_struct), ctypes.c_uint32)\n    func_ptr = func_type(addr)\n\n    def cpuid(eax):\n        func_ptr(result, eax)\n        return result.eax, result.ebx, result.ecx, result.edx\n\n    yield cpuid\n\n    # Free\n    if is_windows:\n        libc.VirtualFree(addr, 0, 0x8000)\n    else:\n        libc.free.restype = None\n        libc.free.argtypes = [ctypes.c_void_p]\n        libc.free(addr)\n\n\ndef detect_cpu_capabilities():\n    # Detects support for popcnt and pext instructions\n    modern, bmi2 = False, False\n\n    try:\n        with make_cpuid() as cpuid:\n            for eax in [0x0, 0x80000000]:\n                highest, _, _, _ = cpuid(eax)\n                for eax in range(eax, highest + 1):\n                    a, b, c, d = cpuid(eax)\n\n                    # popcnt\n                    if eax == 1 and c & (1 << 23):\n                        modern = True\n\n                    # pext\n                    if eax == 7 and b & (1 << 8):\n                        bmi2 = True\n    except OSError:\n        pass\n\n    return modern, bmi2\n\n\nclass HttpError(Exception):\n    def __init__(self, status, reason, body):\n        self.status = status\n        self.reason = reason\n        self.body = body\n\n    def __str__(self):\n        return ""HTTP %d %s\\n\\n%s"" % (self.status, self.reason, self.body)\n\n    def __repr__(self):\n        return ""%s(%d, %r, %r)"" % (type(self).__name__, self.status,\n                                   self.reason, self.body)\n\n\nclass HttpServerError(HttpError):\n    pass\n\n\nclass HttpClientError(HttpError):\n    pass\n\n\n@contextlib.contextmanager\ndef http(method, url, body=None, headers=None):\n    url_info = urlparse.urlparse(url)\n    if url_info.scheme == ""https"":\n        con = httplib.HTTPSConnection(url_info.hostname, url_info.port or 443)\n    else:\n        con = httplib.HTTPConnection(url_info.hostname, url_info.port or 80)\n\n    con.request(method, url_info.path, body, headers)\n    response = con.getresponse()\n\n    try:\n        if 400 <= response.status < 500:\n            raise HttpClientError(response.status, response.reason,\n                                  response.read())\n        elif 500 <= response.status < 600:\n            raise HttpServerError(response.status, response.reason,\n                                  response.read())\n        else:\n            yield response\n    finally:\n        con.close()\n'"
modules/game/AnalysedGame.py,3,"b'from default_imports import *\n\nfrom math import log10, floor\nimport numpy as np\nimport json\n\nfrom modules.game.Game import Game, GameID, Emt\nfrom modules.game.Colour import Colour\nfrom modules.game.Player import PlayerID\nfrom modules.game.AnalysedMove import AnalysedMove, AnalysedMoveBSONHandler, EngineEval, Analysis, Rank, TrueRank\nfrom modules.game.AnalysedPosition import AnalysedPosition\n\nfrom pymongo.collection import Collection\n\nAnalysedGameID = NewType(\'AnalysedGameID\', str) # <GameID>/<white|black>\n\nAnalysedGameTensor = NewType(\'AnalysedGameTensor\', np.ndarray)\n\nclass AnalysedGame(NamedTuple(\'AnalysedGame\', [\n        (\'id\', AnalysedGameID),\n        (\'playerId\', PlayerID),\n        (\'gameId\', GameID),\n        (\'analysedMoves\', List[AnalysedMove])\n    ])):\n    """"""\n    An analysed game is a game that has been deeply analysed from a single\n    player\'s perspective.\n    """"""\n    @staticmethod\n    def new(gameId: GameID, colour: Colour, playerId: PlayerID, analysedMoves: List[AnalysedMove]):\n        return AnalysedGame(\n            id=AnalysedGame.makeId(gameId, colour),\n            playerId=playerId,\n            gameId=gameId,\n            analysedMoves=analysedMoves)\n\n    @staticmethod\n    def makeId(gameId: GameID, colour: Colour) -> AnalysedGameID:\n        return gameId + \'/\' + (\'white\' if colour else \'black\')\n\n    def tensor(self, length: int = 60) -> AnalysedGameTensor:\n        emtAvg = self.emtAverage()\n        wclAvg = self.wclAverage()\n        ts = [ma.tensor(emtAvg, wclAvg) for ma in self.analysedMoves]\n        ts = ts[:length]\n        ts = ts + (length-len(ts))*[AnalysedMove.nullTensor()]\n        return ts\n\n    def toJson(self):\n        return AnalysedGameBSONHandler.writes(self)\n\n    def emtAverage(self) -> Number:\n        return np.average([m.emt for m in self.analysedMoves])\n\n    def wclAverage(self) -> Number:\n        return np.average([m.winningChancesLoss() for m in self.analysedMoves])\n\n    def gameLength(self) -> int:\n        return len(self.analysedMoves)\n\n    def emts(self) -> List[Emt]:\n        return [m.emt for m in self.analysedMoves]\n\n    def emtSeconds(self) -> List[Number]:\n        return [emt/100 for emt in self.emts()]\n\n    def winningChances(self) -> List[Number]:\n        return [m.advantage() for m in self.analysedMoves]\n\n    def winningChancesPercent(self) -> List[Number]:\n        return [100*m.advantage() for m in self.analysedMoves]\n\n    def winningChancesLossPercent(self, usePV: bool = True) -> List[Number]:\n        return [100*m.winningChancesLoss(usePV=usePV) for m in self.analysedMoves]\n\n    def winningChancesLossByPV(self):\n        """""" for generating graphs """"""\n        pvs = [(\n            \'PV\'+str(i+1),\n            \'rgba(20, 20, 20, \' + str(0.6 - i*0.1) + \')\',\n            []) for i in range(5)] # one entry per PV\n        for analysedMove in self.analysedMoves:\n            losses = analysedMove.PVsWinningChancesLoss()\n            for i in range(5):\n                try:\n                    pvs[i][2].append(max(0, 100*losses[i]))\n                except IndexError:\n                    pvs[i][2].append(\'null\')\n        return pvs\n\n    def ranks(self) -> List[TrueRank]:\n        """""" for generating graphs """"""\n        return [move.trueRank() for move in self.analysedMoves]\n\n    def ambiguities(self) -> List[int]:\n        """""" for generating graphs """"""\n        return [move.ambiguity() for move in self.analysedMoves]\n\n    def length(self) -> int:\n        return len(self.analysedMoves)\n\n    def ranksJSON(self) -> str:\n        return json.dumps(self.ranks())\n\n    def binnedSeconds(self, bins: int = 10) -> Dict:\n        # JSON format for graphing\n        emts = self.emts()\n        minSec = min(emts)\n        maxSec = max(emts)\n        step = int((maxSec-minSec)/bins)\n        data = [[] for i in range(bins)]\n        labels = [[] for i in range(bins)]\n        for i, stepStart in enumerate(range(minSec, maxSec, step)):\n            data[min(bins-1, i)] = len([a for a in emts if a >= stepStart and a <= stepStart+step])\n            labels[min(bins-1, i)] = str(round_sig(stepStart/100)) + \'-\' + str(round_sig((stepStart+step)/100)) + \'s\'\n        return {\'data\': json.dumps(data), \'labels\': json.dumps(labels)}\n\n    def binnedLosses(self, bins: int = 10) -> Dict:\n        # JSON format for graphing\n        losses = self.winningChancesLossPercent()\n        data = [[] for i in range(bins+1)]\n        for i in range(0, bins, 1):\n            data[min(bins-1,i)] = len([a for a in losses if i == int(a)])\n        data[bins] = sum([int(a >= 10) for a in losses])\n        labels = [(\'-\' + str(a) + \'%\') for a in range(bins)]\n        labels.append(\'Other\')\n        return {\'data\': json.dumps(data), \'labels\': json.dumps(labels)}\n\n    def binnedPVs(self, bins: int = 6) -> Dict:\n        # JSON format for graphing\n        pvs = self.ranks()\n        data = [[] for i in range(bins)]\n        for i, p in enumerate([1, 2, 3, 4, 5, None]):\n            data[i] = len([1 for pv in pvs if pv == p])\n        labels = [\'PV 1\', \'PV 2\', \'PV 3\', \'PV 4\', \'PV 5\', \'Other\']\n        return {\'data\': json.dumps(data), \'labels\': json.dumps(labels)}\n\n    def moveRankByTime(self) -> List[Dict]:\n        return [{\'x\': time, \'y\': rank} for rank, time in zip(self.ranks(), self.emtSeconds())]\n\n    def moveRankByTimeJSON(self) -> str:\n        # json format for graphing\n        return json.dumps(self.moveRankByTime())\n\n    def lossByTime(self) -> List[Dict]:\n        return [{\'x\': time, \'y\': loss} for loss, time in zip(self.winningChancesLossPercent(), self.emtSeconds())]\n\n    def lossByTimeJSON(self) -> str:\n        # json format for graphing\n        return json.dumps(self.lossByTime())\n\n    def lossByRank(self) -> List[Dict]:\n        return [{\'x\': rank, \'y\': loss} for loss, rank in zip(self.winningChancesLossPercent(), self.ranks())]\n\n    def lossByRankJSON(self) -> str:\n        # json format for graphing\n        return json.dumps(self.lossByRank())\n\ndef round_sig(x, sig=2):\n    if x == 0:\n        return 0\n    return round(x, sig-int(floor(log10(abs(x))))-1)\n\nclass GameAnalysedGame(NamedTuple(\'GameAnalysedGame\', [\n        (\'analysedGame\', AnalysedGame),\n        (\'game\', Game)\n    ])):\n    """"""\n    Merger of Game and Analysed Game for a merged tensor\n    """"""\n    def length(self):\n        return self.analysedGame.length()\n\n    def tensor(self):\n        try:\n            gt = self.game.boardTensorsByPlayerId(self.analysedGame.playerId, safe = False)\n            at = self.analysedGame.tensor()\n            return [\n                [_1 + _2 for _1, _2 in zip(gt[0], at)],\n                gt[1]\n            ]\n        except (TypeError, AttributeError):\n            return None\n\nclass AnalysedGameBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> AnalysedGame:\n        return AnalysedGame(\n            id = bson[\'_id\'],\n            playerId = bson[\'userId\'],\n            gameId = bson[\'gameId\'],\n            analysedMoves = [AnalysedMoveBSONHandler.reads(am) for am in bson[\'analysis\']])\n\n    @staticmethod\n    def writes(analysedGame: AnalysedGame) -> Dict:\n        return {\n            \'_id\': analysedGame.id,\n            \'userId\': analysedGame.playerId,\n            \'gameId\': analysedGame.gameId,\n            \'analysis\': [AnalysedMoveBSONHandler.writes(am) for am in analysedGame.analysedMoves]\n        }\n\nclass AnalysedGameDB(NamedTuple(\'AnalysedGameDB\', [\n        (\'analysedGameColl\', Collection)\n    ])):\n    def write(self, analysedGame: AnalysedGame):\n        return self.analysedGameColl.update_one(\n            {\'_id\': analysedGame.id},\n            {\'$set\': AnalysedGameBSONHandler.writes(analysedGame)},\n            upsert=True)\n\n    def writeMany(self, analysedGames: List[AnalysedGame]):\n        return [self.write(ga) for ga in analysedGames]\n\n    def byPlayerId(self, playerId: PlayerID) -> List[AnalysedGame]:\n        return [AnalysedGameBSONHandler.reads(ga) for ga in self.analysedGameColl.find({\'userId\': playerId})]\n\n    def byPlayerIds(self, playerIds: List[PlayerID]) -> List[AnalysedGame]:\n        return [self.byPlayerId(playerId) for playerId in playerIds]\n\n    def byId(self, _id: AnalysedGameID) -> Opt[AnalysedGame]:\n        bson = self.analysedGameColl.find_one({""_id"": _id})\n        return None if bson is None else AnalysedGameBSONHandler.reads(bson)\n\n    def byIds(self, ids: List[AnalysedGameID]) -> List[AnalysedGame]:\n        return [AnalysedGameBSONHandler.reads(ga) for ga in self.analysedGameColl.find({""_id"": {""$in"": ids}})]\n\n    def allBatch(self, batch: int, batchSize: int = 500):\n        """"""\n        Gets all analysed games in a paged format\n        batch = page number\n        batchSize = size of page\n        """"""\n        return [AnalysedGameBSONHandler.reads(ga) for ga in self.analysedGameColl.find(skip=batch*batchSize, limit=batchSize)]\n\n    def byGameIdAndUserId(self, gameId: GameID, playerId: PlayerID) -> Opt[AnalysedGame]:\n        bson = self.analysedGameColl.find_one({\'gameId\': gameId, \'userId\': playerId})\n        return None if bson is None else AnalysedGameBSONHandler.reads(bson)'"
modules/game/AnalysedMove.py,1,"b""from default_imports import *\n\nfrom modules.game.EngineEval import EngineEval, EngineEvalBSONHandler\n\nfrom modules.game.Game import Emt\nfrom functools import lru_cache\nfrom math import exp\nimport numpy as np\n\n# For moves that have been analysed by stockfish\n\nUCI = NewType('UCI', str)\n\nMoveNumber = NewType('MoveNumber', int)\n\nAnalysis = NamedTuple('Analysis', [\n    ('uci', 'UCI'),\n    ('engineEval', 'EngineEval')\n])\n\nRank = NewType('Rank', int)\nTrueRank = NewType('TrueRank', Opt[Rank])\n\nclass AnalysedMove(NamedTuple('AnalysedMove', [\n        ('uci', UCI),\n        ('move', MoveNumber),\n        ('emt', Emt),\n        ('engineEval', EngineEval),\n        ('analyses', List[Analysis])\n    ])):\n    def tensor(self, timeAvg: Number, wclAvg: Number) -> List[Number]:\n        return [\n            self.rank() + 1,\n            self.ambiguity() + 1,\n            self.advantage(),\n            self.emt / (timeAvg + 1e-8), # elapsed move time / average\n            abs(self.emt - timeAvg) / (timeAvg + 1e-8), # variance from average\n            self.difToNextBest(),\n            self.difToNextWorst(),\n            self.winningChancesLoss(), # loss of advantage\n            self.winningChancesLoss() - wclAvg, # loss in comparison to average\n            self.averageWinningChancesLoss()\n        ]\n\n    @staticmethod\n    def nullTensor() -> List[int]:\n        return 10*[0]\n\n    def top(self) -> Opt[Analysis]:\n        return next(iter(self.analyses or []), None)\n\n    def difToNextBest(self) -> Number:\n        tr = self.trueRank()\n        if tr is not None and tr != 1:\n            return winningChances(self.analyses[tr-2].engineEval) - self.advantage()\n        elif tr == 1:\n            return 0\n        else:\n            return winningChances(self.analyses[-1].engineEval) - self.advantage()\n\n    def difToNextWorst(self) -> Number:\n        tr = self.trueRank()\n        if tr is not None and tr <= len(self.analyses)-1:\n            return winningChances(self.analyses[tr].engineEval) - self.advantage()\n        return 0\n\n    def PVsWinningChancesLoss(self) -> Number:\n        return [winningChances(self.top().engineEval) - winningChances(a.engineEval) for a in self.analyses]\n\n    def averageWinningChancesLoss(self) -> Number:\n        return np.average(self.PVsWinningChancesLoss())\n\n    def winningChancesLoss(self, usePV: bool = False) -> Number:\n        adv = self.advantage()\n        if usePV:\n            r = self.trueRank()\n            if r is not None:\n                adv = winningChances(self.analyses[r-1].engineEval)\n                \n        return max(0, winningChances(self.top().engineEval) - adv)\n\n    def advantage(self) -> Number:\n        return winningChances(self.engineEval)\n\n    def ambiguity(self) -> int: # 1 = only one top move, 5 = all moves good\n        return sum(int(similarChances(winningChances(self.top().engineEval), winningChances(analysis.engineEval))) for analysis in self.analyses)\n\n    def trueRank(self) -> TrueRank:\n        return next((x+1 for x, am in enumerate(self.analyses) if am.uci == self.uci), None)\n\n    def rank(self) -> Rank:\n        return min(15, next((x for x, am in enumerate(self.analyses) if am.uci == self.uci), self.projectedRank()) + 1)\n\n    def projectedRank(self) -> Number:\n        if len(self.analyses) == 1:\n            return 10\n        else: # rise over run prediction of move rank given the difference between the winning chances in the bottom two analysed moves\n            try:\n                return len(self.analyses) + int(len(self.analyses)*abs(winningChances(self.analyses[-1].engineEval) - winningChances(self.engineEval)) / abs(winningChances(self.analyses[0].engineEval) - winningChances(self.analyses[-2].engineEval)))\n            except ZeroDivisionError:\n                return 10\n\n@lru_cache(maxsize=64)\ndef winningChances(engineEval: EngineEval) -> Number:\n    if engineEval.mate is not None:\n        return 1 if engineEval.mate > 0 else 0\n    else:\n        return 1 / (1 + exp(-0.004 * engineEval.cp))\n\ndef similarChances(c1: Number, c2: Number) -> bool:\n    return abs(c1 - c2) < 0.05\n\nclass AnalysisBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> Analysis:\n        return Analysis(\n            uci = bson['uci'],\n            engineEval = EngineEvalBSONHandler.reads(bson['score'])\n        )\n\n    @staticmethod\n    def writes(analysis: Analysis) -> Dict:\n        return {\n            'uci': analysis.uci,\n            'score': EngineEvalBSONHandler.writes(analysis.engineEval)\n        }\n\n\nclass AnalysedMoveBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> AnalysedMove:\n        return AnalysedMove(\n            uci = bson['uci'],\n            move = bson['move'],\n            emt = bson['emt'],\n            engineEval = EngineEvalBSONHandler.reads(bson['score']),\n            analyses = [AnalysisBSONHandler.reads(a) for a in bson['analyses']]\n            )\n\n    @staticmethod\n    def writes(analysedMove: AnalysedMove) -> Dict:\n        return {\n            'uci': analysedMove.uci,\n            'move': analysedMove.move,\n            'emt': analysedMove.emt,\n            'score': EngineEvalBSONHandler.writes(analysedMove.engineEval),\n            'analyses': [AnalysisBSONHandler.writes(a) for a in analysedMove.analyses]\n        }\n"""
modules/game/AnalysedPosition.py,0,"b'from default_imports import *\n\nfrom modules.game.AnalysedMove import Analysis, AnalysisBSONHandler\nfrom chess import polyglot, Board\nfrom pymongo.collection import Collection\nimport pymongo\nimport logging\n\nAnalysedPositionID = NewType(\'AnalysedPositionID\', str)\n\nclass AnalysedPosition(NamedTuple(\'AnalysedPosition\', [\n        (\'id\', AnalysedPositionID),\n        (\'analyses\', List[Analysis])\n    ])):\n    """"""\n    Like an analysed move, but only with SF analysis. Does not contain any other move data.\n    This is used for accelerating stockfish analysis.\n    """"""\n    @staticmethod\n    def fromBoardAndAnalyses(board: Board, analyses: List[Analysis]):\n        return AnalysedPosition(\n            id=AnalysedPosition.idFromBoard(board),\n            analyses=analyses)\n\n    @staticmethod\n    def idFromBoard(board: Board) -> AnalysedPositionID:\n        return str(polyglot.zobrist_hash(board))\n\nclass AnalysedPositionBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> AnalysedPosition:\n        return AnalysedPosition(\n            id=bson[\'_id\'],\n            analyses=[AnalysisBSONHandler.reads(b) for b in bson[\'analyses\']])\n\n    def writes(analysedPosition: AnalysedPosition) -> Dict:\n        return {\n            \'_id\': analysedPosition.id,\n            \'analyses\': [AnalysisBSONHandler.writes(a) for a in analysedPosition.analyses]\n        }\n\nclass AnalysedPositionDB(NamedTuple(\'AnalysedPositionDB\', [\n        (\'analysedPositionColl\', Collection)\n    ])):\n    def write(self, analysedPosition: AnalysedPosition):\n        try:\n            self.analysedPositionColl.update_one(\n                {\'_id\': analysedPosition.id},\n                {\'$set\': AnalysedPositionBSONHandler.writes(analysedPosition)},\n                upsert=True)\n        except pymongo.errors.DuplicateKeyError:\n            logging.warning(""DuplicateKeyError when attempting to write position: "" + str(analysedPosition.id))\n\n    def writeMany(self, analysedPositions: List[AnalysedPosition]):\n        [self.write(analysedPosition) for analysedPosition in analysedPositions]\n\n    def byBoard(self, board: Board) -> Opt[AnalysedPosition]:\n        analysedPositionBSON = self.analysedPositionColl.find_one({\'_id\': AnalysedPosition.idFromBoard(board)})\n        return None if analysedPositionBSON is None else AnalysedPositionBSONHandler.reads(analysedPositionBSON)'"
modules/game/Api.py,0,"b'from default_imports import *\nimport logging\n\nfrom modules.game.AnalysedGame import AnalysedGameBSONHandler\n\nfrom modules.game.Env import Env\n\nfrom modules.game.Player import Player\nfrom modules.game.Player import PlayerID\nfrom modules.game.Game import Game, GameID\n\nclass Api(NamedTuple(\'Api\', [\n        (\'env\', Env)\n    ])):\n    def writeAnalysedGames(self, analysedGamesBSON: List[Dict]) -> bool:\n        try:\n            analysedGames = [AnalysedGameBSONHandler.reads(g) for g in analysedGamesBSON]\n            self.env.analysedGameDB.writeMany(analysedGames)\n            return True\n        except (KeyError, ValueError):\n            logging.warning(\'Malformed analysedGamesBSON: \' + str(analysedGamesBSON))\n        return False\n\n    def gamesForAnalysis(self, playerId: PlayerID, required: List[str] = []) -> List[Game]:\n        """"""\n        Given a playerId and an amount of games. This function will return the games within `limit`\n        that should be analysed\n        """"""\n        games = self.env.gameDB.byPlayerId(playerId)\n        analysedGames = self.env.analysedGameDB.byPlayerId(playerId)\n\n        gameIds = {g.id for g in games}\n        analysedGameIds = {g.gameId for g in analysedGames}\n\n        notAnalysedButRequiredIds = set(required) - analysedGameIds\n\n        correct_length = lambda g: len(g.pgn) >= 40 and len(g.pgn) <= 120\n        games = [g for g in games if g.id in notAnalysedButRequiredIds and correct_length(g)]\n\n        return games\n\n    def gamesByIds(self, gameIds: List[GameID]):\n        return self.env.gameDB.byIds(gameIds)\n\n    def writeGames(self, games: List[Game]):\n        """"""\n        Store games from lichess\n        """"""\n        self.env.gameDB.writeMany(games)\n\n    def writePlayer(self, player: Player):\n        """"""\n        Upsert a new player to the db\n        """"""\n        self.env.playerDB.write(player)\n'"
modules/game/Colour.py,0,"b""from default_imports import *\n\nColour = NewType('Color', bool)\nWhite = Colour(True)\nBlack = Colour(False)"""
modules/game/EngineEval.py,0,"b""from default_imports import *\n\nfrom modules.game.Colour import Colour\n\nfrom math import exp\n\nclass EngineEval(NamedTuple('EngineEval', [\n        ('cp', Opt[Number]),\n        ('mate', Opt[int])\n    ])):\n    @staticmethod\n    def fromDict(d: Dict):\n        return EngineEval(d.get('cp', None), d.get('mate', None))\n\n    def asdict(self) -> Dict:\n        return {'cp': self.cp} if self.cp is not None else {'mate': self.mate}\n\n    def inverse(self):\n        return EngineEval(-self.cp if self.cp is not None else None,\n            -self.mate if self.mate is not None else None)\n\n    def winningChances(self, colour: Colour) -> Number:\n        if self.mate is not None:\n            base = (1 if self.mate > 0 else 0)\n        else:\n            base = 1 / (1 + exp(-0.004 * self.cp))\n        return 100*(base if colour else (1-base))\n\nclass EngineEvalBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> List[EngineEval]:\n        return EngineEval.fromDict(bson)\n\n    def writes(engineEval: EngineEval) -> Dict:\n        return engineEval.asdict()"""
modules/game/EngineTools.py,0,"b'from default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nfrom modules.game.Game import Game\nfrom modules.game.Colour import Colour\nfrom modules.game.AnalysedGame import AnalysedGame\nfrom modules.game.EngineEval import EngineEval\nfrom modules.game.AnalysedPosition import AnalysedPosition, AnalysedPositionDB\nfrom modules.game.AnalysedMove import AnalysedMove, Analysis\n\nfrom modules.fishnet.fishnet import stockfish_command\n\nfrom chess.pgn import read_game\n\nfrom chess import uci\nfrom chess.uci import Engine\nfrom chess.uci import InfoHandler\n\ntry:\n    from StringIO import StringIO\nexcept ImportError:\n    from io import StringIO\n\nclass EngineTools(NamedTuple(\'EngineTools\', [\n        (\'engine\', Engine),\n        (\'infoHandler\', InfoHandler)\n    ])):\n    @staticmethod\n    def new(conf: ConfigWrapper):\n        engine = uci.popen_engine(stockfish_command(conf[\'stockfish update\']))\n        engine.setoption({\'Threads\': conf[\'stockfish threads\'], \'Hash\': conf[\'stockfish memory\']})\n        engine.uci()\n\n        infoHandler = uci.InfoHandler()\n\n        engine.info_handlers.append(infoHandler)\n\n        return EngineTools(\n            engine=engine,\n            infoHandler=infoHandler)\n\n    def analyseGame(self, game: Game, colour: Colour, nodes: int) -> Opt[AnalysedGame]:\n        gameLen = len(game.pgn)\n        if gameLen < 40 or gameLen > 120:\n            logging.warning(f\'game too long/short to analyse ({gameLen} plys)\')\n            return None\n        elif game.emts is None:\n            logging.warning(f\'game has no emts\')\n            return None\n        analysedMoves = []\n\n        try:\n            playableGame = read_game(StringIO("" "".join(game.pgn)))\n        except ValueError:\n            return None\n\n        node = playableGame\n        mainline_moves = [x for x in node.main_line()]\n        if len(game.emts) < len(mainline_moves):\n            logging.warning(f""Not enough emts. len(emts): {len(game.emts)} vs len(node.main_line()): {len(mainline_moves)}"")\n            return None\n\n        self.engine.ucinewgame()\n\n        while not node.is_end():\n            logging.info(f\'analysing position\\n{node.board()}\\n\')\n            nextNode = node.variation(0)\n            if colour == node.board().turn: ## if it is the turn of the player of interest\n                self.engine.setoption({\'multipv\': 5})\n                self.engine.position(node.board())\n                self.engine.go(nodes=nodes)\n\n                analyses = list([\n                    Analysis(\n                        pv[1][0].uci(),\n                        EngineEval(engineEval[1].cp, engineEval[1].mate)) for engineEval, pv in zip(\n                            self.infoHandler.info[\'score\'].items(),\n                            self.infoHandler.info[\'pv\'].items())])\n\n                self.engine.setoption({\'multipv\': 1})\n                self.engine.position(nextNode.board())\n                self.engine.go(nodes=nodes)\n\n                engineEval = EngineEval(\n                    self.infoHandler.info[\'score\'][1].cp,\n                    self.infoHandler.info[\'score\'][1].mate).inverse() # flipped because analysing from other player side\n\n                moveNumber = node.board().fullmove_number\n\n                analysedMoves.append(AnalysedMove(\n                    uci = node.variation(0).move.uci(),\n                    move = moveNumber,\n                    emt = game.emts[EngineTools.ply(moveNumber, colour)],\n                    engineEval = engineEval,\n                    analyses = analyses))\n\n            node = nextNode\n\n        playerId = game.white if colour else game.black\n        return AnalysedGame.new(game.id, colour, playerId, analysedMoves)\n\n    @staticmethod\n    def ply(moveNumber, colour: Colour) -> int:\n        return (2*(moveNumber-1)) + (0 if colour else 1)\n'"
modules/game/Env.py,0,"b'from default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nfrom modules.game.Game import GameDB\nfrom modules.game.AnalysedGame import AnalysedGameDB\nfrom modules.game.Player import PlayerDB\nfrom modules.game.AnalysedPosition import AnalysedPositionDB\n\nfrom pymongo.database import Database\n\nclass Env:\n    def __init__(self, config: ConfigWrapper, db: Database):\n        self.config = config\n        self.db = db\n\n        self.gameDB = GameDB(self.db[self.config[""game coll game""]])\n        self.analysedGameDB = AnalysedGameDB(self.db[self.config[""game coll analysed_game""]])\n        self.playerDB = PlayerDB(self.db[self.config[""game coll player""]])\n        self.analysedPositionDB = AnalysedPositionDB(self.db[self.config[""game coll analysed_position""]])'"
modules/game/Game.py,3,"b'from default_imports import *\n\nfrom modules.game.Colour import Colour\nfrom modules.game.Player import PlayerID\nfrom modules.game.EngineEval import EngineEval, EngineEvalBSONHandler\n\nfrom pymongo.collection import Collection\n\nfrom multiprocessing import Pool\n\nimport math\nimport chess\nfrom chess.pgn import read_game\nimport numpy as np\n\nGameID = NewType(\'GameID\', str)\nEmt = NewType(\'Emt\', int)\nAnalysis = NewType(\'Analysis\', Opt[List[EngineEval]])\n\nMoveTensor = NewType(\'MoveTensor\', List[Number])\nGameTensor = NewType(\'GameTensor\', List[MoveTensor])\n\nclass Game(NamedTuple(\'Game\', [\n        (\'id\', GameID),\n        (\'white\', PlayerID),\n        (\'black\', PlayerID),\n        (\'pgn\', List[str]),\n        (\'emts\', Opt[List[Emt]]),\n        (\'analysis\', Analysis)\n    ])):\n    @staticmethod\n    def fromDict(d: Dict):\n        return Game(\n            id=d[\'id\'],\n            white=d[\'white\'],\n            black=d[\'black\'],\n            pgn=d[\'pgn\'].split(\' \'),\n            emts=d[\'emts\'],\n            analysis=None if d.get(\'analysis\') is None else [EngineEval.fromDict(a) for a in d[\'analysis\']]\n            )\n\n    @staticmethod\n    def fromJson(json: Dict):\n        return Game.fromDict(json)\n\n    def toJson(self):\n        return {\n            \'_id\': self.id,\n            \'white\': self.white,\n            \'black\': self.black,\n            \'pgn\': self.pgn,\n            \'emts\': self.emts,\n            \'analysis\': [EngineEvalBSONHandler.writes(a) for a in self.analysis],\n            \'analysed\': len(self.analysis) > 0\n        }\n\n\n    def playable(self):\n        try:\n            from StringIO import StringIO\n        except ImportError:\n            from io import StringIO\n\n        return read_game(StringIO("" "".join(self.pgn)))\n\n    def boardTensors(self, colour):\n        # replay the game for move tensors\n        playable = self.playable()\n        node = playable.variation(0)\n\n        advancement = lambda rank: rank if colour else (7 - rank)\n\n        while not node.is_end():\n            nextNode = node.variation(0)\n\n            board = node.board()\n            move = node.move\n\n            if board.turn == colour:\n                yield (\n                    [\n                        advancement(chess.square_rank(move.to_square)),\n                        board.pseudo_legal_moves.count(),\n                        int(board.is_capture(move))\n                    ],\n                    board.piece_at(move.to_square).piece_type\n                )\n\n            node = nextNode\n\n    def boardTensorsByPlayerId(self, playerId: PlayerID, length: int = 60, safe: bool = True):\n        if safe and self.white != playerId and self.black != playerId:\n            logging.warning(f\'{playerId} is not a player in game {self.id} - ({self.white}, {self.black})\')\n            return None\n\n        colour = (self.white == playerId)\n        tensors = list(self.boardTensors(colour))\n        remaining = max(0, length-len(tensors))\n        output = [\n            [remaining*[Game.nullBoardTensor()] + [t[0] for t in tensors]][0][:length],\n            [remaining*[[0]] + [[t[1]] for t in tensors]][0][:length]\n        ]\n\n        return output\n\n    def tensor(self, playerId: PlayerID, length: int = 60, noisey: bool = False, safe: bool = True) -> Opt[GameTensor]:\n        if self.analysis == [] or (safe and self.white != playerId and self.black != playerId):\n            if noisey:\n                logging.debug(f\'playerId: ""{playerId}""\')\n                logging.debug(f\'gameId: ""{self.id}""\')\n                logging.debug(f\'white: ""{self.white}""\')\n                logging.debug(f\'black: ""{self.black}""\')\n            return None\n\n        colour = (self.white == playerId)\n\n        analysis = self.analysis[1:] if colour else self.analysis\n        analysis = list(zip(analysis[0::2],analysis[1::2])) # grouping analyses pairwise\n\n        emts = self.emtsByColour(colour, [-1 for _ in self.analysis] if self.emts is None else self.emts)\n        avgEmt = np.average(emts)\n        boardTensors = list(self.boardTensors(colour))\n        pieceTypes = [[b[1]] for b in boardTensors]\n        tensors = [Game.moveTensor(a, e, b, avgEmt, colour) for a, e, b in zip(analysis, emts, [b[0] for b in boardTensors])]\n        remaining = (max(0, length-len(tensors)))\n        tensors = [\n                #np.array([remaining*[Game.nullMoveTensor()] + tensors][0][:length]),\n                [remaining*[Game.nullMoveTensor()] + tensors][0][:length],\n                #np.array([remaining*[[0]] + pieceTypes][0][:length])\n                [remaining*[[0]] + pieceTypes][0][:length]\n            ] # pad to `length` tensors in length\n        return tensors\n\n    def emtsByColour(self, colour: Colour, emts: Opt[List[int]] = None) -> List[Emt]:\n        emts = self.emts if emts is None else emts\n        return emts[(0 if colour else 1)::2]\n\n    @staticmethod\n    def moveTensor(analysis: Analysis, emt: Emt, boardTensor: List[int], avgEmt: Number, colour: Colour) -> MoveTensor:\n        return [\n            analysis[1].winningChances(colour),\n            (analysis[0].winningChances(colour) - analysis[1].winningChances(colour)),\n            emt,\n            emt - avgEmt,\n            100*((emt - avgEmt)/(avgEmt + 1e-8)),\n        ] + boardTensor\n\n    @staticmethod\n    def nullBoardTensor():\n        return [0, 0, 0]\n\n    @staticmethod\n    def nullMoveTensor() -> MoveTensor:\n        return [0, 0, 0, 0, 0, 0, 0, 0]\n\n    @staticmethod\n    def ply(moveNumber: int, colour: Colour) -> int:\n        return (2*(moveNumber-1)) + (0 if colour else 1)\n\nclass GameBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> Game:\n        return Game(\n            id = bson[\'_id\'],\n            white = bson.get(\'white\'),\n            black = bson.get(\'black\'),\n            pgn = bson[\'pgn\'],\n            emts = bson[\'emts\'],\n            analysis = [EngineEvalBSONHandler.reads(a) for a in bson.get(\'analysis\', [])])\n\n    @staticmethod\n    def writes(game: Game) -> Dict:\n        return {\n            \'white\': game.white,\n            \'black\': game.black,\n            \'pgn\': game.pgn,\n            \'emts\': game.emts,\n            \'analysis\': [EngineEvalBSONHandler.writes(a) for a in game.analysis],\n            \'analysed\': len(game.analysis) > 0\n        }\n\nclass GameDB(NamedTuple(\'GameDB\', [\n        (\'gameColl\', Collection)\n    ])):\n    def byId(self, _id: GameID) -> Opt[Game]:\n        bson = self.gameColl.find_one({\'_id\': _id})\n        return None if bson is None else GameBSONHandler.reads(bson)\n\n    def byIds(self, ids: List[GameID]) -> List[Game]:\n        return [self.byId(gid) for gid in ids]\n        #return [GameBSONHandler.reads(g) for g in self.gameColl.find({\'_id\': {\'$in\': [i for i in ids]}})]\n\n    def byPlayerId(self, playerId: PlayerID) -> List[Game]:\n        return [GameBSONHandler.reads(g) for g in self.gameColl.find({""$or"": [{""white"": playerId}, {""black"": playerId}]})]\n\n    def byPlayerIdAndAnalysed(self, playerId: PlayerID, analysed: bool = True) -> List[Game]:\n        return [GameBSONHandler.reads(g) for g in self.gameColl.find({""analysed"": analysed, ""$or"": [{""white"": playerId}, {""black"": playerId}]})]\n\n    def write(self, game: Game):\n        self.gameColl.update_one({\'_id\': game.id}, {\'$set\': GameBSONHandler.writes(game)}, upsert=True)\n\n    def writeMany(self, games: List[Game]):\n        [self.write(g) for g in games]\n'"
modules/game/GameStore.py,1,"b""from default_imports import *\n\nfrom modules.game.Player import PlayerID\nfrom modules.game.Game import Game, GameID, GameTensor, Emt\nfrom modules.game.AnalysedGame import AnalysedGame, AnalysedGameTensor\n\nimport numpy as np\nimport math\nimport json\n\nclass GameStore(NamedTuple('GameStore', [\n        ('playerId', PlayerID),\n        ('games', List[Game]), \n        ('analysedGames', List[AnalysedGame])\n    ])):\n    @staticmethod\n    def new(playerId: PlayerID):\n        return GameStore(playerId, [], [])\n\n    def gamesWithoutAnalysis(self, excludeIds: List[GameID] = []) -> List[Game]:\n        return [game for game in self.games if not self.gameIdHasAnalysis(game.id) if (game.id not in excludeIds)]\n\n    def gameIdHasAnalysis(self, gid: GameID) -> bool:\n        return any([ga for ga in self.analysedGames if ga.gameId == gid])\n\n    def hasGameId(self, gid: GameID) -> bool:\n        return any([g for g in self.games if gid == g.id])\n\n    def gameById(self, gid: GameID) -> Opt[Game]:\n        return next(iter([g for g in self.games if gid == g.id]), None)\n\n    def addGames(self, games: List[Game]) -> None:\n        [self.games.append(g) for g in games if (not self.hasGameId(g.id) and g.emts is not None and len(g.pgn) < 120 and len(g.pgn) > 40)]\n\n    def addAnalysedGame(self, ga: AnalysedGame) -> None:\n        if not self.gameIdHasAnalysis(ga.gameId) and ga is not None and len(ga.analysedMoves) < 60 and len(ga.analysedMoves) > 20:\n            self.analysedGames.append(ga)\n\n    def addAnalysedGames(self, analysedGames: List[AnalysedGame]) -> None:\n        [self.addAnalysedGame(ga) for ga in analysedGames]\n\n    def randomGamesWithoutAnalysis(self, size: int = 10, excludeIds: List[GameID] = []) -> List[Game]:\n        gWithout = self.gamesWithoutAnalysis(excludeIds)\n        if len(gWithout) > 0:\n            return [gWithout[x] for x in np.random.choice(list(range(len(gWithout))), min(len(gWithout), size), replace=False)]\n        return []\n\n    def gameTensors(self) -> List[GameTensor]:\n        tensors = [(g.id, g.tensor(self.playerId)) for g in self.games]\n        return [t for t in tensors if t[1] is not None]\n\n    def gameTensorsWithoutAnalysis(self) -> List[GameTensor]:\n        return [(gid, t) for gid, t in self.gameTensors(self.playerId) if not self.gameIdHasAnalysis(gid)]\n\n    def analysedGameTensors(self) -> List[AnalysedGameTensor]:\n        return [(analysedGame.tensor(), analysedGame.length()) for analysedGame in self.analysedGames if len(analysedGame.analysedMoves) < 60 and len(analysedGame.analysedMoves) > 20 and analysedGame.emtAverage() < 2000]\n\n    def moveRankByTime(self):\n        output = []\n        [output.extend(ga.moveRankByTime()) for ga in self.analysedGames]\n        return output\n\n    def moveRankByTimeJSON(self):\n        return json.dumps(self.moveRankByTime())\n\n    def lossByTime(self):\n        output = []\n        [output.extend(ga.lossByTime()) for ga in self.analysedGames]\n        return output\n\n    def lossByTimeJSON(self):\n        return json.dumps(self.lossByTime())\n\n    def lossByRank(self):\n        output = []\n        [output.extend(ga.lossByRank()) for ga in self.analysedGames]\n        return output\n\n    def lossByRankJSON(self):\n        return json.dumps(self.lossByRank())"""
modules/game/Player.py,0,"b'from default_imports import *\n\nfrom datetime import datetime, timedelta\nimport pymongo\nfrom pymongo.collection import Collection\n\nfrom typing import NewType\n\nPlayerID = NewType(\'PlayerID\', str)\n\nclass Player(NamedTuple(\'Player\', [\n    (\'id\', \'PlayerID\'),\n    (\'titled\', bool),\n    (\'engine\', bool),\n    (\'gamesPlayed\', int)])):\n    @staticmethod\n    def fromJson(userData: Dict):\n        try:\n            return Player(\n                id=userData[\'id\'],\n                titled=userData[\'titled\'],\n                engine=userData[\'engine\'],\n                gamesPlayed=userData[\'games\'])\n        except (RuntimeTypeError, AttributeError):\n            logging.debug(""something\'s fucked"")\n        return None\n\nclass PlayerBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> Player:\n        return Player(\n                id = bson[\'_id\'],\n                titled = bson.get(\'titled\', False),\n                engine = bson[\'engine\'],\n                gamesPlayed = bson[\'gamesPlayed\']\n            )\n\n    def writes(player: Player) -> Dict:\n        return {\n            \'_id\': player.id,\n            \'titled\': player.titled,\n            \'engine\': player.engine,\n            \'gamesPlayed\': player.gamesPlayed,\n            \'date\': datetime.now()\n        }\n\nclass PlayerDB(NamedTuple(\'PlayerDB\', [\n        (\'playerColl\', \'Collection\')\n    ])):\n    def byId(self, playerId: PlayerID) -> Opt[Player]:\n        playerBSON = self.playerColl.find_one({\'_id\': playerId})\n        return None if playerBSON is None else PlayerBSONHandler.reads(playerBSON)\n\n    def byPlayerId(self, playerId: PlayerID) -> Opt[Player]:\n        return self.byId(playerId)\n\n    def unmarkedByUserIds(self, playerIds: List[PlayerID]) -> List[Player]:\n        return [(None if bson is None else PlayerBSONHandler.reads(bson))\n            for bson in [self.playerColl.find_one({\'_id\': playerId, \'engine\': False}) for playerId in playerIds]]\n\n    def engineSample(self, engine: bool, size: int) -> List[Player]:\n        pipeline = [\n                {""$match"": {""engine"": engine}},\n                {""$sample"": {""size"": int(size)}}\n            ]\n        return [PlayerBSONHandler.reads(p) for p in self.playerColl.aggregate(pipeline)]\n\n    def oldestNonEngine(self) -> Opt[Player]:\n        playerBSON = self.playerColl.find_one_and_update(\n            filter={\'$or\': [{\'engine\': False}, {\'engine\': None}], \'date\': {\'$lt\': datetime.now() - timedelta(days=30)}},\n            update={\'$set\': {\'date\': datetime.now()}},\n            sort=[(\'date\', pymongo.ASCENDING)])\n        return None if playerBSON is None else PlayerBSONHandler.reads(playerBSON)\n\n    def byEngine(self, engine: bool = True) -> List[Player]:\n        return [PlayerBSONHandler.reads(p) for p in self.playerColl.find({\'engine\': engine})]\n\n    def all(self) -> List[Player]:\n        return [PlayerBSONHandler.reads(p) for p in self.playerColl.find({})]\n\n    def write(self, player: Player):\n        self.playerColl.update_one({\'_id\': player.id}, {\'$set\': PlayerBSONHandler.writes(player)}, upsert=True)'"
modules/http/__init__.py,0,"b'""""""Some http/socket related utilities.\n""""""\nimport socket\nimport requests\n\nclass HTTPAdapterWithSocketOptions(requests.adapters.HTTPAdapter):\n    """"""A helper adapter to set socket options on the socket requests will use.\n    """"""\n    def __init__(self, *args, **kwargs):\n        self.socket_options = kwargs.pop(""socket_options"", None)\n        super(HTTPAdapterWithSocketOptions, self).__init__(*args, **kwargs)\n\n    def init_poolmanager(self, *args, **kwargs):\n        if self.socket_options is not None:\n            kwargs[""socket_options""] = self.socket_options\n        super(HTTPAdapterWithSocketOptions, self).init_poolmanager(*args, **kwargs)\n\n\ndef get_keepalive_adapter():\n    return HTTPAdapterWithSocketOptions(\n        socket_options=[(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)]\n    )\n\ndef get_requests_session_with_keepalive():\n    adapter = get_keepalive_adapter()\n    s = requests.session()\n    s.mount(""http://"", adapter)\n    s.mount(""https://"", adapter)\n    return s\n'"
modules/irwin/AnalysedGameModel.py,6,"b'from default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nimport numpy as np\nimport logging\nimport os\n\nfrom random import shuffle\nfrom math import ceil\n\nfrom modules.game.AnalysedGame import GameAnalysedGame\n\nfrom keras.models import load_model, Model\nfrom keras.layers import Dropout, Embedding, Reshape, Dense, LSTM, Input, concatenate, Conv1D, Flatten\nfrom keras.optimizers import Adam\n\nfrom keras.engine.training import Model\n\nfrom numpy import ndarray\n\nGamePrediction = NewType(\'GamePrediction\', int)\nMovePrediction = NewType(\'MovePrediction\', int)\n\nWeightedMovePrediction = NewType(\'WeightedMovePrediction\', int)\nWeightedGamePrediction = NewType(\'WeightedGamePrediction\', int)\n\nclass AnalysedGamePrediction(NamedTuple(\'AnalysedGamePrediction\', [\n        (\'game\', GamePrediction),\n        (\'lstmMoves\', List[MovePrediction]),\n        (\'isolatedMoves\', List[MovePrediction])\n    ])):\n    @staticmethod\n    def fromTensor(tensor: ndarray, length: int):\n        return AnalysedGamePrediction(\n            game = int(100*tensor[0][0]),\n            lstmMoves = [int(100*i) for i in tensor[1][0][:length]],\n            isolatedMoves = [int(100*i) for i in tensor[2][0][:length]])\n\n    def weightedMovePredictions(self) -> List[WeightedMovePrediction]:\n        return [int(0.5*(l + i)) for l, i in zip(self.lstmMoves, self.isolatedMoves)]\n    \n    def weightedGamePrediction(self) -> WeightedGamePrediction:\n        moveActivations = sorted(self.weightedMovePredictions(), reverse=True)\n        moveActivationsLen = len(moveActivations)\n\n        nanToZero = lambda x: 0 if np.isnan(x) else x\n\n        highest = nanToZero(np.average([i for i in moveActivations if i > 80]))\n        topX = np.average(moveActivations[:ceil(0.3*moveActivationsLen)])\n        topY = np.average(moveActivations[:ceil(0.9*moveActivationsLen)])\n\n        return int(np.average([highest, topX, topY]))\n\nclass AnalysedGameModel:\n    def __init__(self, config: ConfigWrapper, newmodel: bool = False):\n        self.config = config\n        self.model = self.createModel(newmodel)\n    \n    def createModel(self, newmodel: bool = False) -> Model:\n        if os.path.isfile(self.config[""irwin model analysed file""]) and not newmodel:\n            logging.debug(""model already exists, opening from file"")\n            m = load_model(self.config[""irwin model analysed file""])\n            m._make_predict_function()\n            return m\n        logging.debug(\'model does not exist, building from scratch\')\n        inputGame = Input(shape=(60, 13), dtype=\'float32\', name=\'game_input\')\n        pieceType = Input(shape=(60, 1), dtype=\'float32\', name=\'piece_type\')\n\n        pieceEmbed = Embedding(input_dim=7, output_dim=8)(pieceType)\n        rshape = Reshape((60,8))(pieceEmbed)\n\n        concats = concatenate(inputs=[inputGame, rshape])\n\n        # Merge embeddings\n\n        ### Conv Net Block of Siamese Network\n        conv1 = Conv1D(filters=64, kernel_size=3, activation=\'relu\')(concats)\n        dense1 = Dense(32, activation=\'relu\')(conv1)\n        conv2 = Conv1D(filters=64, kernel_size=5, activation=\'relu\')(dense1)\n        dense2 = Dense(32, activation=\'sigmoid\')(conv2)\n        conv3 = Conv1D(filters=64, kernel_size=10, activation=\'relu\')(dense2)\n        dense3 = Dense(16, activation=\'relu\')(conv3)\n        dense4 = Dense(8, activation=\'sigmoid\')(dense3)\n\n        f = Flatten()(dense4)\n        dense5 = Dense(64, activation=\'relu\')(f)\n        convNetOutput = Dense(16, activation=\'sigmoid\')(dense5)\n\n\n        ### LSTM Block of Siamese Network\n        # merge move stats with move options\n        c1 = Conv1D(filters=128, kernel_size=5, name=\'conv1\')(concats)\n\n        # analyse all the moves and come to a decision about the game\n        l1 = LSTM(128, return_sequences=True)(c1)\n        l2 = LSTM(128, return_sequences=True, activation=\'sigmoid\')(l1)\n\n        c2 = Conv1D(filters=64, kernel_size=10, name=\'conv2\')(l2)\n\n        l3 = LSTM(64, return_sequences=True)(c2)\n        l4 = LSTM(32, return_sequences=True, activation=\'sigmoid\', name=\'position_words\')(l3)\n        l5 = LSTM(32)(l4)\n        l6 = Dense(16, activation=\'sigmoid\', name=\'game_word\')(l5)\n        d4 = Dropout(0.3)(l6)\n\n        s1 = Dense(16, activation=\'sigmoid\')(l4)\n        lstmMove = Dense(1, activation=\'sigmoid\', name=\'lstm_move_output\')(s1)\n\n        # isolated consideration of move blocks\n\n        mi1 = Dense(64, activation=\'relu\')(c1)\n        mi2 = Dense(16, activation=\'relu\')(mi1)\n        isolatedMove = Dense(1, activation=\'sigmoid\', name=\'isolated_move\')(mi2)\n\n\n        mergeLSTMandConv = concatenate([d4, convNetOutput])\n        denseOut1 = Dense(16, activation=\'sigmoid\')(mergeLSTMandConv)\n        mainOutput = Dense(1, activation=\'sigmoid\', name=\'main_output\')(denseOut1)\n\n        model = Model(inputs=[inputGame, pieceType], outputs=[mainOutput, lstmMove, isolatedMove])\n\n        model.compile(optimizer=Adam(lr=0.0001),\n            loss=\'binary_crossentropy\',\n            loss_weights=[1., 0.3, 0.2],\n            metrics=[\'accuracy\'])\n        return model\n\n    def predict(self, gameAnalysedGames: List[GameAnalysedGame]) -> List[Opt[ndarray]]:\n        list_to_array = lambda l: None if l is None else [np.array([l[0]]), np.array([l[1]])]\n        arrs = ((list_to_array(ag.tensor()), ag.length()) for ag in gameAnalysedGames)\n        return [None if t is None else AnalysedGamePrediction.fromTensor(self.model.predict(t), l) for t, l in arrs]\n\n    def saveModel(self):\n        self.model.save(self.config[""irwin model analysed file""])'"
modules/irwin/AnalysisReport.py,2,"b'from collections import namedtuple\nfrom datetime import datetime\nfrom functools import reduce\nfrom math import ceil\nimport operator\nimport numpy as np\nimport random\nimport pymongo\nimport json\n\nclass PlayerReport(namedtuple(\'PlayerReport\', [\'id\', \'userId\', \'owner\', \'activation\', \'date\'])):\n    @staticmethod\n    def new(userId, owner, activation):\n        reportId = str(""%016x"" % random.getrandbits(64))\n        return PlayerReport(\n            id=reportId,\n            userId=userId,\n            owner=owner,\n            activation=activation,\n            date=datetime.now())\n\n    def reportDict(self, gameReports):\n        return {\n            \'userId\': self.userId,\n            \'owner\': self.owner,\n            \'activation\': int(self.activation),\n            \'games\': [gameReport.reportDict() for gameReport in gameReports]\n        }\n\nclass GameReportStore(namedtuple(\'GameReportStore\', [\'gameReports\'])):\n    @staticmethod\n    def new(gameReports):\n        gameReports.sort(key=lambda obj: -obj.activation)\n        return GameReportStore(gameReports)\n\n    def topGames(self, p=0.15):\n        """""" Get the top p games from all gameReports """"""\n        self.gameReports.sort(key=lambda obj: -obj.activation)\n        return [gameReport \n            for i, gameReport in enumerate(self.gameReports)\n            if (i <= p*len(self.gameReports) or gameReport.activation >= 90)]\n\n    def longestGame(self):\n        if len(self.gameReports) == 0:\n            return 0\n        return max([len(gameReport.moves) for gameReport in self.gameReports])\n\n    def losses(self, top=False):\n        gameReports = self.topGames() if top else self.gameReports\n        return [gameReport.losses() for gameReport in gameReports]\n\n    def ranks(self, subNone=None, top=False):\n        gameReports = self.topGames() if top else self.gameReports\n        return [gameReport.ranks(subNone=subNone) for gameReport in gameReports]\n\n    def averageLossByMove(self, top=False):\n        """""" Calculate the average loss by move. Used for graphing""""""\n        if self.longestGame() == 0:\n            return [] # zero case\n        return json.dumps(GameReportStore.zipAvgLOL(self.losses(top=top)))\n\n    def averageRankByMove(self, top=False):\n        """""" Calculate the the average rank by move. Used for graphing """"""\n        if self.longestGame() == 0:\n            return [] # zero case\n        return json.dumps(GameReportStore.zipAvgLOL(self.ranks(subNone=6, top=top)))\n\n    def stdBracketLossByMove(self, top=False):\n        if self.longestGame() == 0:\n            return [] # zero case\n        return json.dumps(GameReportStore.stdBracket(self.losses(top=top)))\n\n    def stdBracketRankByMove(self, top=False):\n        if self.longestGame() == 0:\n            return [] # zero case\n        return json.dumps(GameReportStore.stdBracket(self.ranks(subNone=6, top=top), lowerLimit=1))\n\n    def binnedActivations(self, top=False):\n        gameReports = self.topGames() if top else self.gameReports\n        return json.dumps([sum([int(gameReport.activation in range(i,i+10)) for gameReport in gameReports]) for i in range(0, 100, 10)][::-1])\n\n    def binnedMoveActivations(self, top=False):\n        gameReports = self.topGames() if top else self.gameReports\n        moveActivations = reduce(operator.concat, [gameReport.activations() for gameReport in gameReports])\n        return json.dumps([sum([int(moveActivation in range(i,i+10)) for moveActivation in moveActivations]) for i in range(0, 100, 10)][::-1])\n\n    def activations(self, top=False):\n        gameReports = self.topGames() if top else self.gameReports\n        activations = []\n        [activations.extend(gr.activations()) for gr in gameReports]\n        return activations\n        \n    @staticmethod\n    def zipLOL(lol):\n        """"""\n        lol: List[List[A]]\n        assumes the input isn\'t : []\n        """"""\n        longest = max([len(l) for l in lol])\n        bins = [[] for i in range(longest)]\n        for l in lol:\n            try:\n                [bins[i].append(l[i]) for i in range(longest) if l[i] is not None]\n            except IndexError:\n                continue\n        return bins\n\n    @staticmethod\n    def zipAvgLOL(lol):\n        """"""\n        lol: List[List[A]]\n        assumes the input isn\'t : []\n        """"""\n        return [np.average(b) for b in GameReportStore.zipLOL(lol)]\n\n    @staticmethod\n    def zipStdLOL(lol):\n        """"""\n        lol: List[List[A]]\n        assumes the input isn\'t : []\n        """"""\n        return [np.std(b) for b in GameReportStore.zipLOL(lol)]\n\n    @staticmethod\n    def stdBracket(lol, lowerLimit=0):\n        stds = GameReportStore.zipStdLOL(lol)\n        avgs = GameReportStore.zipAvgLOL(lol)\n        return {\n            \'top\': [avg + stds[i] for i, avg in enumerate(avgs)],\n            \'bottom\': [max(avg - stds[i], lowerLimit) for i, avg in enumerate(avgs)]\n        }\n\nclass GameReport(namedtuple(\'GameReport\', [\'id\', \'reportId\', \'gameId\', \'activation\', \'moves\'])):\n    @staticmethod\n    def new(analysedGame, gameActivation, gamePredictions, reportId, userId):\n        gameId = analysedGame.gameId\n        return GameReport(\n            id=gameId + \'/\' + reportId,\n            reportId=reportId,\n            gameId=gameId,\n            activation=gameActivation,\n            moves=[MoveReport.new(am, p) for am, p in zip(analysedGame.analysedMoves, movePredictions(gamePredictions[0]))])\n\n    def reportDict(self):\n        return {\n            \'gameId\': self.gameId,\n            \'activation\': self.activation,\n            \'moves\': [move.reportDict() for move in self.moves]\n        }\n\n    def colorIndex(self):\n        return int(self.activation/10)\n\n    def activations(self):\n        return [move.activation for move in self.moves]\n\n    def ranks(self, subNone=None):\n        return [(subNone if move.rank is None else move.rank) for move in self.moves]\n\n    def ranksJSON(self):\n        return json.dumps(self.ranks())\n\n    def losses(self):\n        losses = [move.loss for move in self.moves]\n        if losses[-1] > 50:\n            losses[-1] = 0\n        return losses\n\n    def moveNumbers(self):\n        return [i+1 for i in range(len(self.moves))]\n\n    def binnedActivations(self):\n        bins = [0 for i in range(10)]\n        for move in self.moves:\n            bins[int(move.activation/10)] += 1\n        return bins[::-1]\n\n\nclass MoveReport(namedtuple(\'MoveReport\', [\'activation\', \'rank\', \'ambiguity\', \'advantage\', \'loss\'])):\n    @staticmethod\n    def new(analysedMove, movePrediction):\n        return MoveReport(\n            activation=moveActivation(movePrediction),\n            rank=analysedMove.trueRank(),\n            ambiguity=analysedMove.ambiguity(),\n            advantage=int(100*analysedMove.advantage()),\n            loss=int(100*analysedMove.winningChancesLoss()))\n\n    def reportDict(self):\n        return {\n            \'a\': self.activation,\n            \'r\': self.rank,\n            \'m\': self.ambiguity,\n            \'o\': self.advantage,\n            \'l\': self.loss\n        }\n\ndef movePredictions(gamePredictions):\n    return list(zip(list(gamePredictions[1][0]), list(gamePredictions[2][0])))\n\ndef moveActivation(movePrediction):\n    return int(50*(movePrediction[0][0]+movePrediction[1][0]))\n\nclass PlayerReportBSONHandler:\n    @staticmethod\n    def reads(bson):\n        return PlayerReport(\n            id=bson[\'_id\'],\n            userId=bson[\'userId\'],\n            owner=bson[\'owner\'],\n            activation=bson[\'activation\'],\n            date=bson[\'date\']\n            )\n\n    @staticmethod\n    def writes(playerReport):\n        return {\n            \'_id\': playerReport.id,\n            \'userId\': playerReport.userId,\n            \'owner\': playerReport.owner,\n            \'activation\': playerReport.activation,\n            \'date\': playerReport.date\n        }\n\nclass GameReportBSONHandler:\n    @staticmethod\n    def reads(bson):\n        return GameReport(\n            id=bson[\'_id\'],\n            reportId=bson[\'reportId\'],\n            gameId=bson[\'gameId\'],\n            activation=bson[\'activation\'],\n            moves=[MoveReportBSONHandler.reads(mBson) for mBson in bson[\'moves\']])\n\n    @staticmethod\n    def writes(gameReport):\n        return {\n            \'_id\': gameReport.id,\n            \'reportId\': gameReport.reportId,\n            \'gameId\': gameReport.gameId,\n            \'activation\': gameReport.activation,\n            \'moves\': [MoveReportBSONHandler.writes(move) for move in gameReport.moves]\n        }\n\nclass MoveReportBSONHandler:\n    @staticmethod\n    def reads(bson):\n        return MoveReport(\n            activation=bson[\'a\'],\n            rank=bson[\'r\'],\n            ambiguity=bson[\'m\'],\n            advantage=bson[\'o\'],\n            loss=bson[\'l\'])\n\n    @staticmethod\n    def writes(moveReport):\n        return {\n            \'a\': moveReport.activation,\n            \'r\': moveReport.rank,\n            \'m\': moveReport.ambiguity,\n            \'o\': moveReport.advantage,\n            \'l\': moveReport.loss\n        }\n\nclass PlayerReportDB(namedtuple(\'PlayerReportDB\', [\'playerReportColl\'])):\n    def byPlayerId(self, userId):\n        return [PlayerReportBSONHandler.reads(bson)\n            for bson\n            in self.playerReportColl.find(\n                filter={\'userId\': userId},\n                sort=[(\'date\', pymongo.DESCENDING)])]\n\n    def newestByUserId(self, userId):\n        bson = self.playerReportColl.find_one(\n            filter={\'userId\': userId},\n            sort=[(\'date\', pymongo.DESCENDING)])\n        return None if bson is None else PlayerReportBSONHandler.reads(bson)\n\n    def byPlayerIds(self, userIds):\n        return [self.newestByUserId(userId) for userId in userIds]\n\n    def newest(self, amount=50):\n        return [PlayerReportBSONHandler.reads(bson) \n            for bson in self.playerReportColl.find(sort=[(\'date\', pymongo.DESCENDING)], limit=amount)]\n\n    def byId(self, reportId):\n        bson = self.playerReportColl.find_one({\'_id\': reportId})\n        return None if bson is None else PlayerReportBSONHandler.reads(bson)\n\n    def write(self, playerReport):\n        self.playerReportColl.update_one(\n            {\'_id\': playerReport.id},\n            {\'$set\': PlayerReportBSONHandler.writes(playerReport)},\n            upsert=True)\n\n    def timeSinceUpdated(self, userId):\n        report = self.newestByUserId(userId)\n        if report is None:\n            return None\n        return datetime.now() - report.date\n\nclass GameReportDB(namedtuple(\'GameReportDB\', [\'gameReportColl\'])):\n    def byId(self, id):\n        bson = self.gameReportColl.find_one({\'_id\': id})\n        return None if bson is None else GameReportBSONHandler.reads(bson)\n\n    def byReportId(self, reportId):\n        return [GameReportBSONHandler.reads(bson) for bson in self.gameReportColl.find({\'reportId\': reportId})]\n\n    def byGameId(self, gameId):\n        return [GameReportBSONHandler.reads(bson) for bson in self.gameReportColl.find({\'gameId\': gameId})]\n\n    def write(self, gameReport):\n        self.gameReportColl.update_one(\n            {\'_id\': gameReport.id},\n            {\'$set\': GameReportBSONHandler.writes(gameReport)},\n            upsert=True)\n\n    def writeMany(self, gameReports):\n        [self.write(gameReport) for gameReport in gameReports]'"
modules/irwin/BasicGameModel.py,1,"b'from default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nimport numpy as np\nimport logging\nimport os\n\nfrom random import shuffle\n\nfrom collections import namedtuple\n\nfrom modules.game.Player import PlayerID\nfrom modules.game.Game import Game\n\nfrom keras.models import load_model, Model\nfrom keras.layers import Dropout, Embedding, Reshape, Flatten, Dense, LSTM, Input, concatenate, Conv1D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import TensorBoard\n\nfrom functools import lru_cache\n\nclass BasicGameModel:\n    def __init__(self, config: ConfigWrapper, newmodel: bool = False):\n        self.config = config\n        self.model = self.createModel(newmodel)\n\n    def createModel(self, newmodel: bool = False):\n        if os.path.isfile(self.config[""irwin model basic file""]) and not newmodel:\n            logging.debug(""model already exists, opening from file"")\n            m = load_model(self.config[""irwin model basic file""])\n            m._make_predict_function()\n            return m\n        logging.debug(\'model does not exist, building from scratch\')\n\n        moveStatsInput = Input(shape=(60, 8), dtype=\'float32\', name=\'move_input\')\n        pieceType = Input(shape=(60, 1), dtype=\'float32\', name=\'piece_type\')\n\n        pieceEmbed = Embedding(input_dim=7, output_dim=8)(pieceType)\n        rshape = Reshape((60,8))(pieceEmbed)\n\n        concats = concatenate(inputs=[moveStatsInput, rshape])\n\n        ### Conv Net Block of Siamese Network\n        conv1 = Conv1D(filters=64, kernel_size=3, activation=\'relu\')(concats)\n        dense1 = Dense(32, activation=\'relu\')(conv1)\n        conv2 = Conv1D(filters=64, kernel_size=5, activation=\'relu\')(dense1)\n        dense2 = Dense(32, activation=\'sigmoid\')(conv2)\n        conv3 = Conv1D(filters=64, kernel_size=10, activation=\'relu\')(dense2)\n        dense3 = Dense(16, activation=\'relu\')(conv3)\n        dense4 = Dense(8, activation=\'sigmoid\')(dense3)\n\n        f = Flatten()(dense4)\n        dense5 = Dense(64, activation=\'relu\')(f)\n        convNetOutput = Dense(16, activation=\'sigmoid\')(dense5)\n\n        ### LSTM Block of Siamese Network\n        mv1 = Dense(32, activation=\'relu\')(concats)\n        d1 = Dropout(0.3)(mv1)\n        mv2 = Dense(16, activation=\'relu\')(d1)\n\n        c1 = Conv1D(filters=64, kernel_size=5, name=\'conv1\')(mv2)\n\n        # analyse all the moves and come to a decision about the game\n        l1 = LSTM(64, return_sequences=True)(c1)\n        l2 = LSTM(32, return_sequences=True, activation=\'relu\')(l1)\n\n        c2 = Conv1D(filters=64, kernel_size=10, name=\'conv2\')(l2)\n\n        l3 = LSTM(32, return_sequences=True)(c2)\n        l4 = LSTM(16, return_sequences=True, activation=\'relu\', recurrent_activation=\'hard_sigmoid\')(l3)\n        l5 = LSTM(16, activation=\'sigmoid\')(l4)\n\n        mergeLSTMandConv = concatenate([l5, convNetOutput])\n        denseOut1 = Dense(16, activation=\'sigmoid\')(mergeLSTMandConv)\n        mainOutput = Dense(1, activation=\'sigmoid\', name=\'main_output\')(denseOut1)\n\n        model = Model(inputs=[moveStatsInput, pieceType], outputs=mainOutput)\n\n        model.compile(optimizer=Adam(lr=0.0001),\n            loss=\'binary_crossentropy\',\n            metrics=[\'accuracy\'])\n        return model\n\n    def predict(self, playerId: PlayerID, games: List[Game]) -> Opt[int]:\n        tensors = [game.tensor(playerId) for game in games]\n        return [None if t is None else int(100*self.model.predict([np.array([t[0]]),np.array([t[1]])])[0][0]) for t in tensors]\n\n    def saveModel(self):\n        logging.debug(""saving model"")\n        self.model.save(self.config[""irwin model basic file""])'"
modules/irwin/Env.py,0,"b'from default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nfrom pymongo.database import Database\n\nfrom modules.game.Game import GameDB\nfrom modules.game.Player import PlayerDB\nfrom modules.game.AnalysedGame import AnalysedGameDB\n\nfrom modules.irwin.training.BasicGameActivation import BasicGameActivationDB\nfrom modules.irwin.training.AnalysedGameActivation import AnalysedGameActivationDB\n\nclass Env:\n    def __init__(self, config: ConfigWrapper, db: Database):\n        self.config = config\n        self.db = db\n\n        self.gameDB = GameDB(db[self.config[""game coll game""]])\n        self.playerDB = PlayerDB(db[self.config[""game coll player""]])\n        self.analysedGameDB = AnalysedGameDB(db[self.config[""game coll analysed_game""]])\n        self.analysedGameActivationDB = AnalysedGameActivationDB(db[self.config[""irwin coll analysed_game_activation""]])\n        self.basicGameActivationDB = BasicGameActivationDB(db[self.config[""irwin coll basic_game_activation""]])'"
modules/irwin/GameReport.py,0,"b""from default_imports import *\n\nfrom modules.irwin.AnalysedGameModel import AnalysedGamePrediction, WeightedGamePrediction\n\nfrom modules.irwin.MoveReport import MoveReport\n\nfrom modules.game.AnalysedGame import AnalysedGame, AnalysedGameID\nfrom modules.game.Player import PlayerID\nfrom modules.game.Game import GameID\n\nGameReportID = NewType('GameReportID', str)\n\nclass GameReport(NamedTuple('GameReport', [\n        ('id', GameReportID),\n        ('reportId', str),\n        ('gameId', AnalysedGameID),\n        ('activation', WeightedGamePrediction),\n        ('moves', List[MoveReport])\n    ])):\n    @staticmethod\n    def new(analysedGame: AnalysedGame, analysedGamePrediction: AnalysedGamePrediction, playerReportId: str):\n        gameId = analysedGame.gameId\n        return GameReport(\n            id=GameReport.makeId(gameId, playerReportId),\n            reportId=playerReportId,\n            gameId=gameId,\n            activation=analysedGamePrediction.weightedGamePrediction(),\n            moves=[MoveReport.new(am, p) for am, p in zip(analysedGame.analysedMoves, analysedGamePrediction.weightedMovePredictions())])\n\n    @staticmethod\n    def makeId(gameId: GameID, reportId: str) -> GameReportID:\n        return '{}/{}'.format(gameId, reportId)\n\n    def reportDict(self):\n        return {\n            'gameId': self.gameId,\n            'activation': self.activation,\n            'moves': [move.reportDict() for move in self.moves]\n        }"""
modules/irwin/Irwin.py,0,"b'from default_imports import *\n\nfrom modules.auth.Auth import AuthID\n\nfrom modules.game.Player import Player\nfrom modules.game.AnalysedGame import GameAnalysedGame\n\nfrom modules.irwin.PlayerReport import PlayerReport\nfrom modules.irwin.AnalysedGameModel import AnalysedGameModel\nfrom modules.irwin.BasicGameModel import BasicGameModel\n\nfrom modules.irwin.Env import Env\n\nfrom modules.irwin.training.Training import Training\nfrom modules.irwin.training.Evaluation import Evaluation\n\nclass Irwin:\n    """"""\n    Irwin(env: Env)\n\n    The main thinking and evalutaion engine of the application.\n    """"""\n    def __init__(self, env: Env, newmodel: bool = False):\n        logging.debug(\'creating irwin instance\')\n        self.env = env\n        self.basicGameModel = BasicGameModel(env.config)\n        self.analysedGameModel = AnalysedGameModel(env.config)\n        self.training = Training(env, newmodel)\n        self.evaluation = Evaluation(self, self.env.config)\n\n    def createReport(self, player: Player, gameAnalysedGames: List[GameAnalysedGame], owner: AuthID = \'test\'):\n        predictions = self.analysedGameModel.predict(gameAnalysedGames)\n        playerReport = PlayerReport.new(player, [(ag, p) for ag, p in zip(gameAnalysedGames, predictions) if p is not None], owner)\n\n        return playerReport'"
modules/irwin/MoveReport.py,0,"b""from default_imports import *\n\nfrom modules.game.AnalysedMove import AnalysedMove, TrueRank\nfrom modules.irwin.AnalysedGameModel import WeightedMovePrediction\n\nclass MoveReport(NamedTuple('MoveReport', [\n        ('activation', WeightedMovePrediction),\n        ('rank', TrueRank),\n        ('ambiguity', int),\n        ('advantage', int),\n        ('loss', int)\n    ])):\n    @staticmethod\n    def new(analysedMove: AnalysedMove, movePrediction: WeightedMovePrediction):\n        return MoveReport(\n            activation=movePrediction,\n            rank=analysedMove.trueRank(),\n            ambiguity=analysedMove.ambiguity(),\n            advantage=int(100*analysedMove.advantage()),\n            loss=int(100*analysedMove.winningChancesLoss()))\n\n    def reportDict(self):\n        return {\n            'a': self.activation,\n            'r': self.rank,\n            'm': self.ambiguity,\n            'o': self.advantage,\n            'l': self.loss\n        }"""
modules/irwin/PlayerReport.py,1,"b'from default_imports import *\n\nimport random\n\nfrom datetime import datetime\nfrom math import ceil\n\nimport numpy as np\n\nfrom modules.game.AnalysedGame import AnalysedGame\nfrom modules.game.Player import Player, PlayerID\nfrom modules.auth.Auth import AuthID\nfrom modules.irwin.AnalysedGameModel import AnalysedGamePrediction\nfrom modules.irwin.GameReport import GameReport\n\nPlayerReportID = NewType(\'PlayerReportID\', str)\n\nclass PlayerReport(NamedTuple(\'PlayerReport\', [\n        (\'id\', PlayerReportID),\n        (\'userId\', PlayerID),\n        (\'owner\', AuthID),\n        (\'activation\', int),\n        (\'gameReports\', List[GameReport]),\n        (\'date\', datetime)\n    ])):\n    @property\n    def playerId(self):\n        return self.userId\n\n    @staticmethod\n    def new(player: Player, gamesAndPredictions: Iterable[Tuple[AnalysedGame, AnalysedGamePrediction]], owner: AuthID = \'test\'):\n        reportId = PlayerReport.makeId()\n        gamesAndPredictions = [(ag, agp) for ag, agp in gamesAndPredictions if agp is not None]\n        gameReports = [GameReport.new(analysedGame, analysedGamePrediction, reportId) for analysedGame, analysedGamePrediction in gamesAndPredictions]\n        return PlayerReport(\n            id=reportId,\n            userId=player.id,\n            owner=owner,\n            activation=PlayerReport.playerPrediction(player, [agp for _, agp in gamesAndPredictions]),\n            gameReports=gameReports,\n            date=datetime.now())\n\n    @staticmethod\n    def makeId() -> PlayerReportID:\n        return str(""%016x"" % random.getrandbits(64))\n\n    @staticmethod\n    def playerPrediction(player: Player, analysedGamePredictions: List[AnalysedGamePrediction]) -> int:\n        sortedGameActivations = sorted([gp.weightedGamePrediction() for gp in analysedGamePredictions], reverse=True)\n        topGameActivations = sortedGameActivations[:ceil(0.15*len(sortedGameActivations))]\n        topGameActivationsAvg = int(np.average(topGameActivations)) if len(topGameActivations) > 0 else 0\n\n        aboveUpper = len([i for i in sortedGameActivations if i > 90])\n        aboveLower = len([i for i in sortedGameActivations if i > 80])\n\n        if aboveUpper > 2 and player.gamesPlayed < 500:\n            result = topGameActivationsAvg\n        elif aboveLower > 0:\n            result = min(92, topGameActivationsAvg)\n        else:\n            result = min(62, topGameActivationsAvg)\n        return result\n\n    def reportDict(self) -> Dict:\n        return {\n            \'userId\': self.userId,\n            \'owner\': self.owner,\n            \'activation\': int(self.activation),\n            \'games\': [gameReport.reportDict() for gameReport in self.gameReports]\n        }'"
modules/lichess/Api.py,0,"b'import requests\nimport logging\nimport time\nimport json\nfrom collections import namedtuple\n\nclass Api(namedtuple(\'Api\', [\'url\', \'token\'])):\n    def postReport(self, report):\n        reportDict = report.reportDict()\n        logging.debug(f\'Sending player report: {reportDict}\')\n        for _ in range(5):\n            try:\n                response = requests.post(\n                    self.url + \'irwin/report\',\n                    headers = {\n                        \'User-Agent\': \'Irwin\',\n                        \'Authorization\': f\'Bearer {self.token}\'\n                    },\n                    json = reportDict\n                )\n                if response.status_code == 200:\n                    logging.debug(f\'Lichess responded with: {response.text}\')\n                    return True\n                else:\n                    logging.warning(str(response.status_code) + \': Failed to post player report\')\n                    logging.warning(json.dumps(reportDict))\n                    if response.status_code == 413:\n                        return False\n                    logging.debug(\'Trying again in 60 sec\')\n                    time.sleep(60)\n            except requests.exceptions.ChunkedEncodingError:\n                logging.warning(""ChunkedEncodingError: Failed to post report."")\n                logging.debug(""Not attempting to post again"")\n                return\n            except requests.ConnectionError:\n                logging.warning(""CONNECTION ERROR: Failed to post report."")\n                logging.debug(""Trying again in 30 sec"")\n                time.sleep(30)\n            except requests.exceptions.SSLError:\n                logging.warning(""SSL ERROR: Failed to post report."")\n                logging.debug(""Trying again in 30 sec"")\n                time.sleep(30)\n            except ValueError:\n                logging.warning(""VALUE ERROR: Failed to post report."")\n                logging.debug(""Trying again in 30 sec"")\n                time.sleep(30)\n\n    def getPlayerData(self, userId):\n        for _ in range(5):\n            try:\n                response = requests.get(\n                    self.url+\'irwin/\'+userId+\'/assessment\',\n                    headers = {\n                        \'User-Agent\': \'Irwin\',\n                        \'Authorization\': f\'Bearer {self.token}\'\n                    }\n                )\n                try:\n                    return response.json()\n                except json.decoder.JSONDecodeError:\n                    logging.warning(\'Error: JSONDecodeError in getPlayerData for user: \' + str(userId))\n                    logging.warning(\'Status Code \' + str(response.status_code))\n                    logging.warning(\'Text: \' + response.text[:200])\n                    return None\n            except requests.ConnectionError:\n                logging.warning(\'CONNECTION ERROR: Failed to pull assessment data\')\n                logging.debug(\'Trying again in 30 sec\')\n                time.sleep(30)\n            except requests.exceptions.SSLError:\n                logging.warning(\'SSL ERROR: Failed to pull assessment data\')\n                logging.debug(\'Trying again in 30 sec\')\n                time.sleep(30)\n        return False\n'"
modules/lichess/Request.py,0,"b""from default_imports import *\n\nfrom modules.queue.Origin import Origin\nfrom modules.game.Player import Player\nfrom modules.game.Game import Game\n\nclass Request(NamedTuple('Request', [\n        ('origin', Origin),\n        ('player', Player),\n        ('games', List[Game])\n    ])):\n    @staticmethod\n    def fromJson(json): # Opt[Request]\n        try:\n            return Request(\n                origin = json['origin'],\n                player = Player.fromJson(json['user']),\n                games = [Game.fromJson(game) for game in json['games']]\n                )\n        except KeyError:\n            logging.debug('key error mofo')\n            return None\n"""
modules/queue/EngineQueue.py,1,"b'""""""Queue item for basic analysis by irwin""""""\nfrom default_imports import *\n\nfrom modules.auth.Auth import AuthID\nfrom modules.game.Game import Game, PlayerID, GameID\nfrom modules.queue.Origin import Origin, OriginReport, OriginModerator, OriginRandom, maxOrigin\n\nfrom datetime import datetime, timedelta\n\nimport pymongo\nfrom pymongo.collection import Collection\n\nimport numpy as np\nfrom math import ceil\n\nEngineQueueID = NewType(\'EngineQueueID\', str)\nPrecedence = NewType(\'Precedence\', int)\n\nclass EngineQueue(NamedTuple(\'EngineQueue\', [\n        (\'id\', EngineQueueID), # same as player ID\n        (\'origin\', Origin),\n        (\'requiredGameIds\', List[GameID]), # games that must be analysed\n        (\'precedence\', Precedence),\n        (\'completed\', bool),\n        (\'owner\', AuthID),\n        (\'date\', datetime)\n    ])):\n    @staticmethod\n    def new(playerId: PlayerID, origin: Origin, gamesAndPredictions: List[Tuple[Game, int]]):\n        if len(gamesAndPredictions) > 0:\n            gamesAndPredictions = sorted(gamesAndPredictions, key=lambda gap: gap[1], reverse=True)\n            required = [gap[0].id for gap in gamesAndPredictions][:10]\n            activations = [gap[1]**2 for gap in gamesAndPredictions]\n            top30avg = ceil(np.average(activations[:ceil(0.3*len(activations))]))\n        else:\n            required = []\n            top30avg = 0\n\n        # set the precedence to the top30avg\n        precedence = top30avg\n\n        # then modify it depending on where it came from\n        if origin == OriginReport:\n            precedence += 5000\n        elif origin == OriginModerator:\n            precedence = 100000\n\n        return EngineQueue(\n            id=playerId,\n            origin=origin,\n            requiredGameIds=required,\n            precedence=precedence,\n            owner=None,\n            completed=False,\n            date=datetime.now())\n\n    def complete(self):\n        return EngineQueue(\n            id=self.id,\n            origin=self.origin,\n            requiredGameIds=self.requiredGameIds,\n            precedence=self.precedence,\n            completed=True,\n            owner=self.owner,\n            date=self.date)\n\n    @staticmethod\n    def merge(engineQueueA, engineQueueB):\n        if engineQueueA.completed:\n            return engineQueueB\n        elif engineQueueB.completed:\n            return engineQueueA\n        return EngineQueue(\n            id=engineQueueA.id,\n            origin=maxOrigin(engineQueueA.origin, engineQueueB.origin),\n            requiredGameIds=list(set(engineQueueA.requiredGameIds) | set(engineQueueB.requiredGameIds)),\n            precedence=max(engineQueueA.precedence, engineQueueB.precedence),\n            completed=min(engineQueueA.completed, engineQueueB.completed),\n            owner=engineQueueA.owner if engineQueueA.owner is not None else (engineQueueB.owner if engineQueueB.owner is not None else None),\n            date=min(engineQueueA.date, engineQueueB.date)) # retain the oldest datetime so the sorting doesn\'t mess up\n\nclass EngineQueueBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> EngineQueue:\n        return EngineQueue(\n            id=bson[\'_id\'],\n            origin=bson[\'origin\'],\n            precedence=bson[\'precedence\'],\n            requiredGameIds=list(set(bson.get(\'requiredGameIds\', []))),\n            completed=bson.get(\'complete\', False),\n            owner=bson.get(\'owner\'),\n            date=bson.get(\'date\'))\n\n    @staticmethod\n    def writes(engineQueue: EngineQueue) -> Dict:\n        return {\n            \'_id\': engineQueue.id,\n            \'origin\': engineQueue.origin,\n            \'precedence\': engineQueue.precedence,\n            \'requiredGameIds\': list(set(engineQueue.requiredGameIds)),\n            \'completed\': engineQueue.completed,\n            \'owner\': engineQueue.owner,\n            \'date\': datetime.now()\n        }\n\nclass EngineQueueDB(NamedTuple(\'EngineQueueDB\', [\n        (\'engineQueueColl\', Collection)\n    ])):\n    def write(self, engineQueue: EngineQueue):\n        self.engineQueueColl.update_one(\n            {\'_id\': engineQueue.id},\n            {\'$set\': EngineQueueBSONHandler.writes(engineQueue)}, upsert=True)\n\n    def inProgress(self) -> List[EngineQueue]:\n        return [EngineQueueBSONHandler.reads(bson) for bson in self.engineQueueColl.find({\'owner\': {\'$ne\': None}, \'completed\': False})]\n\n    def byId(self, _id: EngineQueueID) -> Opt[EngineQueue]:\n        bson = self.engineQueueColl.find_one({\'_id\': _id})\n        return None if bson is None else EngineQueueBSONHandler.reads(bson)\n\n    def byPlayerId(self, playerId: str) -> Opt[EngineQueue]:\n        return self.byId(playerId)\n\n    def complete(self, engineQueue: EngineQueue):\n        """"""remove a complete job from the queue""""""\n        self.write(engineQueue.complete())\n\n    def updateComplete(self, _id: EngineQueueID, complete: bool):\n        self.engineQueueColl.update_one(\n            {\'_id\': _id},\n            {\'$set\': {\'completed\': complete, \'owner\': None}})\n\n    def removePlayerId(self, playerId: PlayerID):\n        """"""remove all jobs related to playerId""""""\n        self.engineQueueColl.remove({\'_id\': playerId})\n\n    def exists(self, playerId: PlayerID) -> bool:\n        """"""playerId has a engineQueue object against their name""""""\n        return self.engineQueueColl.find_one({\'_id\': playerId}) is not None\n\n    def owned(self, playerId: PlayerID) -> bool:\n        """"""Does any deep player queue for playerId have an owner""""""\n        bson = self.engineQueueColl.find_one({\'_id\': playerId, \'owner\': None})\n        hasOwner = False\n        if bson is not None:\n            hasOwner = bson[\'owner\'] is not None\n        return hasOwner\n\n    def oldest(self) -> Opt[EngineQueue]:\n        bson = self.engineQueueColl.find_one(\n            filter={\'date\': {\'$lt\': datetime.now() - timedelta(days=2)}},\n            sort=[(\'date\', pymongo.ASCENDING)])\n        return None if bson is None else EngineQueueBSONHandler.reads(bson)\n\n    def nextUnprocessed(self, name: AuthID) -> Opt[EngineQueue]:\n        """"""find the next job to process against owner\'s name""""""\n        incompleteBSON = self.engineQueueColl.find_one({\'owner\': name, \'completed\': {\'$ne\': True}})\n        if incompleteBSON is not None: # owner has unfinished business\n            logging.debug(f\'{name} is returning to complete {incompleteBSON}\')\n            return EngineQueueBSONHandler.reads(incompleteBSON)\n\n        engineQueueBSON = self.engineQueueColl.find_one_and_update(\n            filter={\'owner\': None, \'completed\': False},\n            update={\'$set\': {\'owner\': name}},\n            sort=[(""precedence"", pymongo.DESCENDING),\n                (""date"", pymongo.ASCENDING)])\n        return None if engineQueueBSON is None else EngineQueueBSONHandler.reads(engineQueueBSON)\n\n    def top(self, amount: int = 20) -> List[EngineQueue]:\n        """"""Return the top `amount` of players, ranked by precedence""""""\n        bsons = self.engineQueueColl.find(\n            filter={\'complete\': False},\n            sort=[(""precedence"", pymongo.DESCENDING),\n                (""date"", pymongo.ASCENDING)]).limit(amount)\n        return [EngineQueueBSONHandler.reads(b) for b in bsons]\n'"
modules/queue/Env.py,0,"b""from default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nfrom pymongo.collection import Collection\n\nfrom modules.queue.EngineQueue import EngineQueueDB\nfrom modules.queue.IrwinQueue import IrwinQueueDB\n\nclass Env:\n    def __init__(self, config: ConfigWrapper, db: Collection):\n        self.db = db\n\n        self.engineQueueDB = EngineQueueDB(db[config['queue coll engine']])\n        self.irwinQueueDB = IrwinQueueDB(db[config['queue coll irwin']])"""
modules/queue/IrwinQueue.py,0,"b'""""""Queue item for deep analysis by irwin""""""\nfrom default_imports import *\n\nfrom modules.queue.Origin import Origin\nfrom modules.game.Game import PlayerID\n\nfrom datetime import datetime\nimport pymongo\nfrom pymongo.collection import Collection\n\nIrwinQueue = NamedTuple(\'IrwinQueue\', [\n        (\'id\', PlayerID),\n        (\'origin\', Origin)\n    ])\n\nclass IrwinQueueBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> IrwinQueue:\n        return IrwinQueue(\n            id=bson[\'_id\'],\n            origin=bson[\'origin\'])\n\n    @staticmethod\n    def writes(irwinQueue: IrwinQueue) -> Dict:\n        return {\n            \'_id\': irwinQueue.id,\n            \'origin\': irwinQueue.origin,\n            \'date\': datetime.now()\n        }\n\nclass IrwinQueueDB(NamedTuple(\'IrwinQueueDB\', [\n        (\'irwinQueueColl\', Collection)\n    ])):\n    def write(self, irwinQueue: IrwinQueue):\n        self.irwinQueueColl.update_one(\n            {\'_id\': irwinQueue.id}, \n            {\'$set\': IrwinQueueBSONHandler.writes(irwinQueue)},\n            upsert=True)\n\n    def removePlayerId(self, playerId: PlayerID):\n        self.irwinQueueColl.remove({\'_id\': playerId})\n\n    def nextUnprocessed(self) -> Opt[IrwinQueue]:\n        irwinQueueBSON = self.irwinQueueColl.find_one_and_delete(\n            filter={},\n            sort=[(""date"", pymongo.ASCENDING)])\n        return None if irwinQueueBSON is None else IrwinQueueBSONHandler.reads(irwinQueueBSON)'"
modules/queue/Origin.py,0,"b""from default_imports import *\n\nOrigin = NewType('Origin', str)\nOriginReport = Origin('report')\nOriginModerator = Origin('moderator')\nOriginRandom = Origin('random')\n\ndef maxOrigin(a, b):\n    if a == OriginModerator or b == OriginModerator:\n        return OriginModerator\n\n    if a == OriginReport or b == OriginReport:\n        return OriginReport\n\n    return OriginRandom"""
modules/queue/Queue.py,0,"b""from default_imports import *\n\nfrom modules.queue.Env import Env\nfrom modules.queue.EngineQueue import EngineQueue, EngineQueueID\nfrom modules.game.Player import PlayerID\n\nfrom modules.auth.Auth import Authable\n\nclass Queue(NamedTuple('Queue', [('env', Env)])):\n    def nextEngineAnalysis(self, id: EngineQueueID) -> Opt[EngineQueue]:\n        return self.env.engineQueueDB.nextUnprocessed(id)\n\n    def completeEngineAnalysis(self, _id: EngineQueueID):\n        return self.env.engineQueueDB.updateComplete(_id, complete=True)\n\n    def nextIrwinAnalysis(self):\n        return None\n        #return self.env.irwinAnalysisQueueDB.\n\n    def queueNerualAnalysis(self, playerId: PlayerID):\n        ...\n\n    def queueEngineAnalysis(self, engineQueue: EngineQueue):\n        return self.env.engineQueueDB.write(engineQueue)\n\n    def engineQueueById(self, playerId: PlayerID):\n        return self.env.engineQueueDB.byPlayerId(playerId)"""
utils/mongodb/addDateToPlayer.py,0,"b""from pymongo import MongoClient\nfrom datetime import datetime, timedelta\n\nclient = MongoClient()\ndb = client.irwin\nplayerColl = db.player\n\nfor pBSON in playerColl.find({}):\n    if pBSON.get('date') is None:\n        playerColl.update_one({'_id': pBSON['_id']}, {'$set': {'date': datetime.now() - timedelta(days=50)}})"""
utils/mongodb/addGameAnalysedBool.py,0,"b""from pymongo import MongoClient\n\nclient = MongoClient()\ndb = client.irwin\ngameColl = db.game\n\nfor gBSON in gameColl.find({}):\n    analysed = len(gBSON.get('analysis', [])) > 0\n    gameColl.update_one({'_id': gBSON['_id']}, {'$set': {'analysed': analysed}})\n"""
modules/irwin/training/AnalysedGameActivation.py,0,"b'from default_imports import *\n\nfrom modules.game.Player import PlayerID\nfrom modules.game.AnalysedGame import AnalysedGame, AnalysedGameID\n\nfrom modules.irwin.AnalysedGameModel import AnalysedGamePrediction\n\nfrom pymongo.collection import Collection\n\nPrediction = NewType(\'Prediction\', int)\n\nclass AnalysedGameActivation(NamedTuple(\'AnalysedGameActivation\', [\n        (\'id\', AnalysedGameID),\n        (\'playerId\', PlayerID),\n        (\'engine\', bool),\n        (\'length\', int),\n        (\'prediction\', Prediction)]\n    )):\n    """"""\n    Used as a pivot coll for training.\n    """"""\n    @staticmethod\n    def fromAnalysedGameAndPrediction(analysedGame: AnalysedGame, prediction: AnalysedGamePrediction, engine: bool):\n        return AnalysedGameActivation(\n            id = analysedGame.id,\n            playerId = analysedGame.playerId,\n            engine = engine,\n            length = len(analysedGame.analysedMoves),\n            prediction = prediction.game)\n\nclass AnalysedGameActivationBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> AnalysedGameActivation:\n        return AnalysedGameActivation(\n            id = bson[\'_id\'],\n            playerId = bson[\'playerId\'],\n            engine = bson[\'engine\'],\n            length = bson[\'length\'],\n            prediction = bson[\'prediction\'])\n\n    @staticmethod\n    def writes(analysedGameActivation: AnalysedGameActivation) -> Dict:\n        return {\n            \'_id\': analysedGameActivation.id,\n            \'playerId\': analysedGameActivation.playerId,\n            \'engine\': analysedGameActivation.engine,\n            \'length\': analysedGameActivation.length,\n            \'prediction\': analysedGameActivation.prediction\n        }\n\nclass AnalysedGameActivationDB(NamedTuple(\'AnalysedGameActivationDB\', [\n        (\'confidentAnalysedGamePivotColl\', Collection)\n    ])):\n    def byPlayerId(self, playerId: PlayerID) -> List[AnalysedGameActivation]:\n        return [AnalysedGameActivationBSONHandler.reads(bson) for bson in self.confidentAnalysedGamePivotColl.find({\'userId\': playerId})]\n\n    def byEngineAndPrediction(self, engine: bool, prediction: Prediction, limit = None) -> List[AnalysedGameActivation]:\n        gtlt = \'$gte\' if engine else \'$lte\'\n        pipeline = [{\'$match\': {\'engine\': engine, \'prediction\': {gtlt: prediction}}}]\n\n        if limit is not None:\n            pipeline.append({\'$sample\': {\'size\': limit}})\n\n        return [AnalysedGameActivationBSONHandler.reads(bson) for bson in self.confidentAnalysedGamePivotColl.aggregate(pipeline)]\n\n    def write(self, analysedGameActivation: AnalysedGameActivation):\n        self.confidentAnalysedGamePivotColl.update_one({\'_id\': analysedGameActivation.id}, {\'$set\': AnalysedGameActivationBSONHandler.writes(analysedGameActivation)}, upsert=True)\n\n    def writeMany(self, analysedGameActivations: List[AnalysedGameActivation]):\n        [self.write(analysedGameActivation) for analysedGameActivation in analysedGameActivations]'"
modules/irwin/training/AnalysedModelTraining.py,7,"b'from default_imports import *\n\nfrom multiprocessing import Pool\n\nfrom modules.game.AnalysedGame import AnalysedGameTensor, GameAnalysedGame\n\nfrom modules.irwin.AnalysedGameModel import AnalysedGameModel\n\nfrom modules.irwin.Env import Env\nfrom modules.irwin.training.AnalysedGameActivation import AnalysedGameActivation\n\nimport numpy as np\n\nfrom random import shuffle\n\nBatch = NamedTuple(\'Batch\', [\n        (\'data\', np.ndarray),\n        (\'labels\', List[np.ndarray])\n    ])\n\nclass AnalysedModelTraining(NamedTuple(\'AnalysedModelTraining\', [\n        (\'env\', Env),\n        (\'analysedGameModel\', AnalysedGameModel)\n    ])):\n    def train(self, epochs: int, filtered: bool = True) -> None:\n        logging.debug(""getting dataset"")\n        batch = self.getTrainingDataset(filtered)\n\n        logging.debug(""training"")\n        logging.debug(""Batch Info: Games: {}"".format(len(batch.data[0])))\n\n        logging.debug(""Game Len: {}"".format(len(batch.data[0][0])))\n\n        self.analysedGameModel.model.fit(\n            batch.data, batch.labels,\n            epochs=epochs, batch_size=32, validation_split=0.2)\n\n        self.analysedGameModel.saveModel()\n        logging.debug(""complete"")\n\n    def getPlayerTensors(self, playerId: str):\n        analysedGames = self.env.analysedGameDB.byPlayerId(playerId)\n        games = self.env.gameDB.byIds([ag.gameId for ag in analysedGames])\n\n        return list(filter(None, [GameAnalysedGame(ag, g).tensor() for ag, g in zip(analysedGames, games) if ag.gameLength() <= 60]))\n\n    def getTensorsByEngine(self, engine: bool, limit: int):\n        players = self.env.playerDB.byEngine(engine)\n        shuffle(players)\n\n        tensors = []\n        \n        for player in players:\n            logging.info(f\'getting tensors for {player.id}\')\n\n            tensors.extend(self.getPlayerTensors(player.id))\n            l = len(tensors)\n            \n            logging.info(f\'loaded {l} / {limit} tensors\')\n\n            if l >= limit:\n                logging.info(\'reached limit\')\n                break\n        return tensors\n\n    def getTensorByCPE(self, cpe):\n        analysedGame = self.env.analysedGameDB.byId(cpe.id)\n        if analysedGame is not None and analysedGame.gameLength() <= 60:\n            game = self.env.gameDB.byId(analysedGame.gameId)\n            return GameAnalysedGame(analysedGame, game).tensor()\n        return None\n\n    def getFilteredEngineTensors(self, limit: int):\n        logging.info(f\'getting {limit} filtered tensors\')\n\n        cheatPivotEntries = self.env.analysedGameActivationDB.byEngineAndPrediction(\n            engine = True,\n            prediction = 80,\n            limit = limit)\n\n        return list(filter(None, [self.getTensorByCPE(cpe) for cpe in cheatPivotEntries]))\n\n    def getTrainingDataset(self, filtered: bool):\n        limit = self.env.config[""irwin model analysed training sample_size""]\n\n        legitTensors = self.getTensorsByEngine(\n            engine = False,\n            limit = limit)\n\n        if filtered:\n            cheatTensors = self.getFilteredEngineTensors(limit = limit)\n        else:\n            cheatTensors = self.getTensorsByEngine(\n                engine = True,\n                limit = limit)\n\n        logging.debug(\'cgts: \' + str(len(cheatTensors)))\n        logging.debug(\'lgts: \' + str(len(legitTensors)))\n\n        logging.debug(""batching tensors"")\n        return self.createBatchAndLabels(cheatTensors, legitTensors)\n\n    @staticmethod\n    def createBatchAndLabels(cheatTensors: List[AnalysedGameTensor], legitTensors: List[AnalysedGameTensor]) -> Batch:\n        """"""\n        group the dataset into batches by the length of the dataset, because numpy needs it that way\n        """"""\n        mlen = min(len(cheatTensors), len(legitTensors))\n\n        cheats = cheatTensors[:mlen]\n        legits = legitTensors[:mlen]\n\n        logging.debug(""batch size "" + str(len(cheats + legits)))\n\n        labels = [1.0]*len(cheats) + [0.0]*len(legits)\n\n        blz = list(zip(cheats+legits, labels))\n        shuffle(blz)\n\n        r =  Batch(\n            data = [\n                np.array([t[0] for t, l in blz]),\n                np.array([t[1] for t, l in blz])\n            ],\n            labels=[\n                np.array([l for t, l in blz]), \n                np.array([ [[l]]*(60-13) for t, l in blz]),\n                np.array([ [[l]]*(60-4) for t, l in blz])\n            ])\n        logging.debug(r.labels[0])\n        logging.debug(r.labels[1])\n        logging.debug(r.labels[2])\n        return r\n\n    def buildTable(self):\n        """"""Build table of activations for analysed games. used for training""""""\n        logging.warning(""Building Analysed Activation Table"")\n        logging.debug(""getting players"")\n        cheats = self.env.playerDB.byEngine(True)\n\n        lenPlayers = str(len(cheats))\n\n        logging.info(""gettings games and predicting"")\n\n        for i, p in enumerate(cheats):\n            logging.info(""predicting: "" + p.id + ""  -  "" + str(i) + \'/\' + lenPlayers)\n            analysedGames = self.env.analysedGameDB.byPlayerId(p.id)\n            games = self.env.gameDB.byIds([ag.gameId for ag in analysedGames])\n\n            predictions = self.analysedGameModel.predict([GameAnalysedGame(ag, g) for ag, g in zip(analysedGames, games)])\n\n            analysedGameActivations = [AnalysedGameActivation.fromAnalysedGameAndPrediction(\n                analysedGame = analysedGame,\n                prediction = prediction,\n                engine=p.engine) for analysedGame, prediction in zip(analysedGames, predictions) if prediction is not None]\n            self.env.analysedGameActivationDB.writeMany(analysedGameActivations)'"
modules/irwin/training/BasicGameActivation.py,0,"b'""""""Type used for pivot coll for basic game model training""""""\nfrom default_imports import *\n\nfrom modules.game.Game import GameID, PlayerID\n\nfrom pymongo.collection import Collection\n\nBasicGameActivationID = NewType(\'BasicGameActivationID\', str)\nPrediction = NewType(\'Prediction\', int)\n\nclass BasicGameActivation(NamedTuple(\'BasicGameActivation\', [\n        (\'id\', BasicGameActivationID),\n        (\'gameId\', GameID),\n        (\'playerId\', PlayerID),\n        (\'engine\', bool),\n        (\'prediction\', int)\n    ])):\n    @staticmethod\n    def fromPrediction(gameId: GameID, playerId: PlayerID, prediction: Prediction, engine: bool):\n        return BasicGameActivation(\n            id = gameId + \'/\' + playerId,\n            gameId = gameId,\n            playerId = playerId,\n            engine = engine,\n            prediction = prediction\n            )\n\n    @staticmethod\n    def makeId(gameId: GameID, playerId: PlayerID) -> BasicGameActivationID:\n        return gameId + \'/\' + playerId\n\nclass BasicGameActivationBSONHandler:\n    @staticmethod\n    def reads(bson: Dict) -> BasicGameActivation:\n        return BasicGameActivation(\n            id = bson[\'_id\'],\n            gameId = bson[\'gameId\'],\n            playerId = bson[\'userId\'],\n            engine = bson[\'engine\'],\n            prediction = bson[\'prediction\'])\n\n    @staticmethod\n    def writes(gba: BasicGameActivation) -> Dict:\n        return {\n            \'_id\': gba.id,\n            \'gameId\': gba.gameId,\n            \'userId\': gba.playerId,\n            \'engine\': gba.engine,\n            \'prediction\': gba.prediction\n        }\n\nclass BasicGameActivationDB(NamedTuple(\'BasicGameActivationDB\', [\n        (\'basicGameActivationColl\', Collection)\n    ])):\n    def byPlayerId(self, playerId: PlayerID) -> List[BasicGameActivation]:\n        return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.find({\'userId\': playerId})]\n\n    def byEngineAndPrediction(self, engine: bool, prediction: Prediction, limit: Opt[int] = None) -> List[BasicGameActivation]:\n        gtlt = \'$gte\' if engine else \'$lte\'\n        pipeline = [{\'$match\': {\'engine\': engine, \'prediction\': {gtlt: prediction}}}]\n\n        if limit is not None:\n            pipeline.append({\'$sample\': {\'size\': limit}})\n\n        return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.aggregate(pipeline)]\n\n    def write(self, gba: BasicGameActivation):\n        self.basicGameActivationColl.update_one({\'_id\': gba.id}, {\'$set\': BasicGameActivationBSONHandler.writes(gba)}, upsert=True)\n\n    def writeMany(self, gbas: List[BasicGameActivation]):\n        [self.write(gba) for gba in gbas]'"
modules/irwin/training/BasicModelTraining.py,5,"b'from default_imports import *\n\nfrom modules.game.Game import GameTensor\n\nfrom modules.irwin.BasicGameModel import BasicGameModel\n\nfrom modules.irwin.Env import Env\nfrom modules.irwin.training.BasicGameActivation import BasicGameActivation\n\nimport numpy as np\n\nfrom random import shuffle\n\nBatch = NamedTuple(\'Batch\', [\n        (\'data\', np.ndarray),\n        (\'labels\', np.ndarray)\n    ])\n\nclass BasicModelTraining(NamedTuple(\'BasicModelTraining\', [\n        (\'env\', Env),\n        (\'basicGameModel\', BasicGameModel)\n    ])):\n    def train(self, epochs: int, filtered: bool = False, newmodel: bool = False):\n        logging.debug(""getting dataset"")\n        batch = self.getTrainingDataset(filtered)\n\n        logging.debug(""training"")\n        logging.debug(""Batch Info: Games: {}"".format(len(batch.data[0])))\n\n        self.basicGameModel.model.fit(\n            batch.data, batch.labels,\n            epochs=epochs, batch_size=32, validation_split=0.2)\n\n        self.basicGameModel.saveModel()\n        logging.debug(""complete"")\n\n    def getPlayerTensors(self, playerId: str):\n        games = self.env.gameDB.byPlayerIdAndAnalysed(playerId)\n        return list(filter(None, [g.tensor(playerId) for g in games]))\n\n    def getTensorsByEngine(self, engine: bool, limit: int):\n        players = self.env.playerDB.byEngine(engine)\n        shuffle(players)\n\n        tensors = []\n\n        for player in players:\n            logging.info(f\'getting tensors for {player.id}\')\n\n            tensors.extend(self.getPlayerTensors(player.id))\n            l = len(tensors)\n\n            logging.info(f\'loaded {l} / {limit} tensors\')\n\n            if l >= limit:\n                logging.info(\'reached limit\')\n                break\n\n        return tensors\n\n    def getTensorByCPE(self, cpe):\n        game = self.env.gameDB.byId(cpe.gameId)\n        return game.tensor(cpe.playerId)\n\n\n    def getFilteredEngineTensors(self, limit: int):\n        logging.info(f\'getting {limit} filtered tensors\')\n\n        cheatPivotEntries = self.env.basicGameActivationDB.byEngineAndPrediction(\n            engine = True,\n            prediction = 70,\n            limit = limit)\n\n        return list(filter(None, [self.getTensorByCPE(cpe) for cpe in cheatPivotEntries]))\n\n    def getTrainingDataset(self, filtered: bool = False):\n        logging.debug(""Getting players from DB"")\n\n        limit = self.env.config[\'irwin model basic training sample_size\']\n\n        legitTensors = self.getTensorsByEngine(\n            engine = False,\n            limit = limit)\n\n        if filtered:\n            cheatTensors = self.getFilteredEngineTensors(limit = limit)\n        else:\n            cheatTensors = self.getTensorsByEngine(\n                engine = True,\n                limit = limit)\n\n        logging.debug(""batching tensors"")\n        return self.createBatchAndLabels(cheatTensors, legitTensors)\n\n    @staticmethod\n    def createBatchAndLabels(cheatTensors: List[GameTensor], legitTensors: List[GameTensor]) -> Batch:\n        """"""\n        group the dataset into batches by the length of the dataset, because numpy needs it that way\n        """"""\n        logging.debug(len(cheatTensors))\n        logging.debug(len(legitTensors))\n        mlen = min(len(cheatTensors), len(legitTensors))\n        logging.debug(mlen)\n\n        cheats = cheatTensors[:mlen]\n        legits = legitTensors[:mlen]\n\n        logging.debug(""batch size "" + str(len(cheats + legits)))\n\n        labels = [1]*len(cheats) + [0]*len(legits)\n\n        blz = list(zip(cheats+legits, labels))\n        shuffle(blz)\n\n        b = Batch(\n            data = [\n                np.array([t[0] for t, l in blz]),\n                np.array([t[1] for t, l in blz])\n            ],\n            labels = np.array([l for t, l in blz])\n        )\n\n        return b\n\n    def buildTable(self):\n        """"""\n        Build table of activations for basic games (analysed by lichess). used for training\n        """"""\n        logging.debug(""Building Basic Activation Table"")\n        logging.info(""getting players"")\n        cheats = self.env.playerDB.byEngine(True)\n\n        lenPlayers = str(len(cheats))\n\n        logging.info(""getting games and predicting"")\n        for i, p in enumerate(cheats):\n            logging.info(""predicting: "" + p.id + ""  -  "" + str(i) + ""/"" + lenPlayers)\n\n            games = self.env.gameDB.byPlayerIdAndAnalysed(p.id)\n            gamesAndTensors = zip(games, self.basicGameModel.predict(p.id, games))\n\n            self.env.basicGameActivationDB.writeMany([BasicGameActivation.fromPrediction(\n                gameId=g.id,\n                playerId=p.id,\n                prediction=pr,\n                engine=p.engine) for g, pr in gamesAndTensors if pr is not None])'"
modules/irwin/training/Evaluation.py,0,"b'from default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nfrom modules.game.Player import Player\nfrom modules.game.GameStore import GameStore\nfrom modules.game.AnalysedGame import GameAnalysedGame\n\nfrom modules.irwin.PlayerReport import PlayerReport\n\nclass Evaluation(NamedTuple(\'Evaluation\', [\n        (\'irwin\', \'Irwin\'),\n        (\'config\', ConfigWrapper)\n    ])):\n    def getPlayerOutcomes(self, engine: bool, batchSize: int) -> Opt[int]: # returns a generator for activations, player by player.\n        for player in self.irwin.env.playerDB.engineSample(engine, batchSize):\n            analysedGames = self.irwin.env.analysedGameDB.byPlayerId(player.id)\n            games = self.irwin.env.gameDB.byIds([ag.gameId for ag in analysedGames])\n            predictions = self.irwin.analysedGameModel.predict([GameAnalysedGame(ag, g) for ag, g in zip(analysedGames, games) if ag.gameLength() <= 60])\n            playerReport = PlayerReport.new(player, zip(analysedGames, predictions))\n            if len(playerReport.gameReports) > 0:\n                yield Evaluation.outcome(\n                    playerReport.activation,\n                    92, 64, engine)\n            else:\n                yield None\n\n    def evaluate(self):\n        outcomes = []\n        [[((outcomes.append(o) if o is not None else ...), Evaluation.performance(outcomes)) for o in self.getPlayerOutcomes(engine, self.config[\'irwin testing eval_size\'])] for engine in (True, False)]\n\n    @staticmethod\n    def performance(outcomes):\n        tp = len([a for a in outcomes if a == 1])\n        fn = len([a for a in outcomes if a == 2])\n        tn = len([a for a in outcomes if a == 3])\n        fp = len([a for a in outcomes if a == 4])\n        tr = len([a for a in outcomes if a == 5])\n        fr = len([a for a in outcomes if a == 6])\n\n        cheatsLen = max(1, tp + fn + tr)\n        legitsLen = max(1, fp + tn + fr)\n\n        logging.warning(""True positive: "" + str(tp) + "" ("" + str(int(100*tp/cheatsLen)) + ""%)"")\n        logging.warning(""False negative: "" + str(fn) + "" ("" + str(int(100*fn/cheatsLen)) + ""%)"")\n        logging.warning(""True negative: "" + str(tn) + "" ("" + str(int(100*tn/legitsLen)) + ""%)"")\n        logging.warning(""False positive: "" + str(fp) + "" ("" + str(int(100*fp/legitsLen)) + ""%)"")\n        logging.warning(""True Report: "" + str(tr) + "" ("" + str(int(100*tr/cheatsLen)) + ""%)"")\n        logging.warning(""False Report: "" + str(fr) + "" ("" + str(int(100*fr/legitsLen)) + ""%)"")\n        logging.warning(""Cheats coverage: "" + str(int(100*(tp+tr)/cheatsLen)) + ""%"")\n        logging.warning(""Legits coverage: "" + str(int(100*(tn)/legitsLen)) + ""%"")\n\n    @staticmethod\n    def outcome(a: int, tm: int, tr: int, e: bool) -> int: # activation, threshold mark, threshold report, expected value\n        logging.debug(a)\n        true_positive = 1\n        false_negative = 2\n        true_negative = 3\n        false_positive = 4\n        true_report = 5\n        false_report = 6\n\n        if a > tm and e:\n            return true_positive\n        if a > tm and not e:\n            return false_positive\n        if a > tr and e:\n            return true_report\n        if a > tr and not e:\n            return false_report\n        if a <= tr and e:\n            return false_negative\n        return true_negative'"
modules/irwin/training/Training.py,0,"b'from default_imports import *\n\nfrom conf.ConfigWrapper import ConfigWrapper\n\nfrom modules.irwin.Env import Env\n\nfrom modules.irwin.training.AnalysedModelTraining import AnalysedModelTraining\nfrom modules.irwin.training.BasicModelTraining import BasicModelTraining\nfrom modules.irwin.training.Evaluation import Evaluation\n\nfrom modules.irwin.AnalysedGameModel import AnalysedGameModel\nfrom modules.irwin.BasicGameModel import BasicGameModel\n\n\nclass Training:\n    def __init__(self, env: Env, newmodel: bool = False):\n        self.analysedModelTraining = AnalysedModelTraining(\n            env=env,\n            analysedGameModel=AnalysedGameModel(env.config, newmodel))\n\n        self.basicModelTraining = BasicModelTraining(\n            env=env,\n            basicGameModel=BasicGameModel(env.config, newmodel))\n\n        self.evaluation = Evaluation(env, env.config)'"
webapp/controllers/api/blueprint.py,0,"b""import logging\nfrom flask import Blueprint, Response, request, jsonify, json\nfrom webapp.DefaultResponse import Success, BadRequest, NotAvailable\n\nfrom modules.game.AnalysedGame import GameAnalysedGame\nfrom modules.irwin.PlayerReport import PlayerReport\nfrom modules.auth.Priv import RequestJob, CompleteJob, PostJob\nfrom modules.queue.Origin import OriginReport, OriginModerator, OriginRandom\nfrom modules.client.Job import Job\nimport traceback\n\ndef buildApiBlueprint(env):\n    apiBlueprint = Blueprint('Api', __name__, url_prefix='/api')\n\n    @apiBlueprint.route('/request_job', methods=['GET'])\n    @env.auth.authoriseRoute(RequestJob)\n    def apiRequestJob(authable):\n        engineQueue = env.queue.nextEngineAnalysis(authable.id)\n        logging.debug(f'EngineQueue for req {engineQueue}')\n        if engineQueue is not None:\n            requiredGames = env.gameApi.gamesForAnalysis(engineQueue.id, engineQueue.requiredGameIds)\n            requiredGameIds = [g.id for g in requiredGames]\n\n            logging.warning(f'Requesting {authable.name} analyses {requiredGameIds} for {engineQueue.id}')\n\n            job = Job(\n                playerId = engineQueue.id,\n                games = requiredGames,\n                analysedPositions = [])\n\n            logging.info(f'Job: {job}')\n\n            return  Response(\n                response = json.dumps(job.toJson()),\n                status = 200,\n                mimetype = 'application/json')\n        return NotAvailable\n\n    @apiBlueprint.route('/complete_job', methods=['POST'])\n    @env.auth.authoriseRoute(CompleteJob)\n    def apiCompleteJob(authable):\n        req = request.get_json(silent=True)\n        try:\n            job = Job.fromJson(req['job'])\n            insertRes = env.gameApi.writeAnalysedGames(req['analysedGames'])\n            if insertRes:\n                env.queue.completeEngineAnalysis(job.playerId)\n\n                player = env.irwin.env.playerDB.byId(job.playerId)\n                analysedGames = env.irwin.env.analysedGameDB.byPlayerId(job.playerId)\n                games = env.irwin.env.gameDB.byIds([ag.gameId for ag in analysedGames])\n                predictions = env.irwin.analysedGameModel.predict([GameAnalysedGame(ag, g) for ag, g in zip(analysedGames, games) if ag.gameLength() <= 60])\n\n                playerReport = PlayerReport.new(player, zip(analysedGames, predictions), owner = authable.name)\n                logging.warning(f'Sending player report for {playerReport.playerId}, activation {playerReport.activation}%')\n                env.lichessApi.postReport(playerReport)\n\n                return Success\n        except KeyError as e:\n            tb = traceback.format_exc()\n            logging.warning(f'Error completing job: {tb}')\n\n        return BadRequest\n\n    return apiBlueprint\n"""
