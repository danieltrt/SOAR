file_path,api_count,code
main.py,0,"b'import os  # accessing the os functions\nfrom modules import capture_video\nfrom modules import capture_images\nfrom modules import train_images\nfrom modules import recognize\nimport pyfiglet\n\n\n# input live stream from a recorder\n# INPUT_VIDEO = ""http://192.168.1.100:8080/video""\n\n# input from saved video\n# INPUT_VIDEO = ""video.avi""\n\n# input from a device attached to computer\nINPUT_VIDEO = 0  # or -1 if 0 doesn\'t work\n\n\n# creating the title bar function\ndef title_bar():\n    # os.system(\'cls\')  # for windows\n\n    # title of the program\n    title = pyfiglet.figlet_format(""Attendance using Face Recognition"")\n    print(title)\n\n\n# creating the user main menu function\ndef main_menu():\n    title_bar()\n    # print()\n    print(10*""*"", ""WELCOME"", 10*""*"")\n    print(""[1] Check Camera"")\n    print(""[2] Capture Faces"")\n    print(""[3] Train Images"")\n    print(""[4] Recognize & Attendance"")\n    print(""[5] Quit"")\n\n    while True:\n        try:\n            choice = int(input(""Enter Choice: ""))\n\n            if choice == 1:\n                check_camera(INPUT_VIDEO)\n                break\n            elif choice == 2:\n                capture_face(INPUT_VIDEO)\n                break\n            elif choice == 3:\n                train_face()\n                break\n            elif choice == 4:\n                recognize_face(INPUT_VIDEO)\n                break\n            elif choice == 5:\n                print(""Thank You =)"")\n                break\n            else:\n                print(""Invalid Choice. Enter 1-4"")\n                main_menu()\n        except ValueError:\n            print(""Invalid Choice. Enter 1-4\\n Try Again"")\n        finally:\n            # key = input(""Enter any key to return main menu"")\n            pass\n\n\n# ---------------------------------------------------------\n# calling the camera test function from check_camera.py file\ndef check_camera(input_video):\n    capture_video.start(input_video)\n    main_menu()\n\n\n# --------------------------------------------------------------\n# calling the take image function form capture_image.py file\ndef capture_face(input_video):\n    capture_images.capture(input_video)\n    main_menu()\n\n\n# -----------------------------------------------------------------\n# calling the train images from train_images.py file\ndef train_face():\n    train_images.train()\n    main_menu()\n\n\n# --------------------------------------------------------------------\n# calling the recognize_attendance from recognize.py file\ndef recognize_face(input_video):\n    recognize.mark_attendance(input_video)\n    main_menu()\n\n\n# --------------- run the main function ------------------\nif __name__ == ""__main__"":\n    main_menu()\n'"
modules/__init__.py,0,b' \n'
modules/capture_images.py,0,"b'import os\nimport csv\nimport cv2\nimport unicodedata  # to check if entered in different unicode format\n\n\n# check if student_id is a number\ndef is_number(_id):\n    try:\n        float(_id)\n        return True\n    except ValueError:\n        pass\n\n    try:\n        unicodedata.numeric(_id)\n        return True\n    except (TypeError, ValueError):\n        pass\n\n    return False\n\n\n# Capture Image function definition\ndef capture(input_video):\n    student_id = input(""Enter Your ID (numbers only): "")\n    name = input(""Enter Your Name (alphabets only): "")\n\n    # if ""student_id is a number"" and ""name consists of alphabetic chars only"" then\n    if is_number(student_id) and name.isalpha():\n        # store input video stream in cap variable\n        cap = cv2.VideoCapture(input_video)\n\n        # using haar cascade\n        haar_cascade_path = ""files"" + os.sep + ""haarcascade_frontalface_default.xml""\n        detector = cv2.CascadeClassifier(haar_cascade_path)\n\n        increment_num = 0\n\n        while True:\n            # capture frame-by-frame\n            ret, img = cap.read()\n            if ret is True:  # video is detected\n                # convert frame to grayscale\n                gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n                # detect faces using haar cascade detector\n                faces = detector.detectMultiScale(gray_frame, 1.3, 5)\n                for(x, y, w, h) in faces:\n                    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)  # ##gray\n\n                    # incrementing number\n                    increment_num += 1\n\n                    # saving the captured face in the data-set folder training_images\n                    cv2.imwrite(""training_images"" + os.sep + name + ""."" + student_id + \'.\' +\n                                str(increment_num) + "".jpg"", img[y:y+h, x:x+w])  # ##gray[y:y+h, x:x+w]\n\n                    # display the resulting frame\n                    cv2.imshow(\'Capturing Face - Attendance using Face Recognition\', img)  # ##gray\n\n                # wait for 100 milliseconds\n                if cv2.waitKey(100) & 0xFF == ord(\'q\'):\n                    break\n                # break if the sample number is more than 100\n                elif increment_num > 60:\n                    break\n            else:  # video not detected\n                break\n\n        # when everything is done\n        cap.release()\n        cv2.destroyAllWindows()\n\n        # res = ""Images Saved for ID : "" + student_id + "" Name : "" + name\n        row = [student_id, name]\n        with open(""files"" + os.sep + ""student_details.csv"", \'a+\') as csv_file:\n            writer = csv.writer(csv_file)\n            writer.writerow(row)\n        csv_file.close()\n\n    # else Invalid Input (""student_id is not a number"" or ""name doesn\'t contain only alphabetic chars"")\n    else:\n        # if student_id input is correct then\n        if is_number(student_id):\n            # ask to input correct alphabetic name\n            print(""Enter Alphabetical Name: "")\n\n        # if name input is correct then\n        if name.isalpha():\n            # ask to input correct numeric ID\n            print(""Enter Numeric ID: "")\n'"
modules/capture_video.py,0,"b""import cv2\n\n\ndef start(input_video):\n    # store input video stream capture in cap variable\n    cap = cv2.VideoCapture(input_video)\n\n    while cap.isOpened():\n        # capture frame-by-frame\n        ret, frame = cap.read()\n        if ret is True:  # video is detected\n            # convert frame to grayscale\n            # gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n            # display the resulting frame\n            cv2.imshow('Checking Video - Attendance using Face Recognition', frame)\n\n            if cv2.waitKey(1) & 0xFF == ord('q'):\n                break\n        else:  # video not detected\n            break\n\n    # when everything is done\n    cap.release()\n    cv2.destroyAllWindows()\n"""
modules/recognize.py,0,"b'import os\nimport cv2\nimport time\nimport datetime\nimport pandas as pd\n\n\ndef mark_attendance(input_video):\n    # reading trained dataset\n    recognizer = cv2.face.LBPHFaceRecognizer_create()  # cv2.createLBPHFaceRecognizer()\n    recognizer.read(""files"" + os.sep + ""trainer.yml"")\n\n    # using haar cascade\n    haar_cascade_path = ""files"" + os.sep + ""haarcascade_frontalface_default.xml""\n    face_cascade = cv2.CascadeClassifier(haar_cascade_path)\n\n    # preparing pandas dataframe\n    df = pd.read_csv(""files"" + os.sep + ""student_details.csv"")\n    col_names = [\'ID\', \'Name\', \'Date\', \'Time\']\n    attendance_df = pd.DataFrame(columns=col_names)\n\n    # store input video stream capture in cap variable\n    cam = cv2.VideoCapture(input_video)\n    font = cv2.FONT_HERSHEY_SIMPLEX\n\n    while True:\n        # capture frame-by-frame\n        ret, img = cam.read()\n        if ret is True:  # video is detected\n            # convert frame to grayscale\n            gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n            # detect faces using haar cascade detector\n            faces = face_cascade.detectMultiScale(gray_frame, 1.2, 5)\n            for(x, y, w, h) in faces:\n                cv2.rectangle(img, (x, y), (x+w, y+h), (225, 0, 0), 2)\n                _id, conf = recognizer.predict(gray_frame[y:y+h, x:x+w])\n\n                if conf < 50:\n                    current_time = time.time()\n                    date = datetime.datetime.fromtimestamp(current_time).strftime(\'%Y-%m-%d\')\n                    timestamp = datetime.datetime.fromtimestamp(current_time).strftime(\'%H:%M:%S\')\n                    student_name = df.loc[df[\'ID\'] == _id][\'Name\'].values[0]\n                    display_text = student_name  # str(_id) + ""-"" +\n                    attendance_df.loc[len(attendance_df)] = [_id, student_name, date, timestamp]\n\n                else:\n                    display_text = \'Unknown\'\n\n                if conf > 75:\n                    file_number = len(os.listdir(""unknown_images"")) + 1\n                    cv2.imwrite(""unknown_images"" + os.sep + ""Image"" + str(file_number) +\n                                "".jpg"", img[y:y+h, x:x+w])\n                cv2.putText(img, display_text, (x, y+h), font, 1, (255, 255, 255), 2)\n            attendance_df = attendance_df.drop_duplicates(subset=[\'ID\'], keep=\'first\')\n            cv2.imshow(\'Recognizing Faces - Attendance using Face Recognition\', img)\n            if cv2.waitKey(1) == ord(\'q\'):\n                break\n        else:  # video not detected\n            break\n\n    # get current time and date\n    current_time = time.time()\n    date = datetime.datetime.fromtimestamp(current_time).strftime(\'%Y-%m-%d\')\n    timestamp = datetime.datetime.fromtimestamp(current_time).strftime(\'%H:%M:%S\')\n    hour, minute, second = timestamp.split("":"")\n\n    # create a csv(comma separated value) file and append current date and time to its name\n    file_name = ""Attendance"" + os.sep + ""Attendance_"" + date + ""_"" + hour + ""-"" + minute + ""-"" + second + "".csv""\n    attendance_df.to_csv(file_name, index=False)\n\n    # when everything is done\n    cam.release()\n    cv2.destroyAllWindows()\n\n    print(""Attendance Successful!"")\n'"
modules/train_images.py,2,"b'import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\n\n\n# -------------- image labels ------------------------\n\n# returns faces and id_list\ndef get_images_and_labels(path):\n    # get the path of all the files in the folder\n    image_paths = [os.path.join(path, f) for f in os.listdir(path)]\n    # create empty face list\n    faces = []\n    # create empty ID list\n    id_list = []\n\n    # now looping through all the image paths and loading the IDs and the images\n    for image_path in image_paths:\n        # loading the image and converting it to gray scale\n        pil_image = Image.open(image_path).convert(\'L\')\n        # Now we are converting the PIL image into numpy array\n        image_np = np.array(pil_image, \'uint8\')\n        # getting the ID from the image\n        _id = int(os.path.split(image_path)[-1].split(""."")[1])\n        # extract the face from the training image sample\n        faces.append(image_np)\n        id_list.append(_id)\n    return faces, id_list\n\n\n# ----------- train images function ---------------\ndef train():\n    recognizer = cv2.face_LBPHFaceRecognizer.create()\n    # haar_cascade_path = ""files"" + os.sep + ""haarcascade_frontalface_default.xml""\n    # detector = cv2.CascadeClassifier(haar_cascade_path)\n    faces, _id = get_images_and_labels(""training_images"")\n    recognizer.train(faces, np.array(_id))\n    recognizer.save(""files"" + os.sep + ""trainer.yml"")\n    print(""Images Trained Successfully"")\n'"
