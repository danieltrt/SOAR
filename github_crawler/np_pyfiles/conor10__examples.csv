file_path,api_count,code
python/cones/volatility_cones.py,7,"b""from numpy import log, sqrt\nimport numpy as np\nimport pandas as pd\nfrom pylab import axhline, figure, legend, plot, show\n\n\ndef main():\n    prices = pd.read_csv('AAPL.csv', index_col=0, parse_dates=True)\n    prices.sort_index(inplace=True)\n\n    imp_vol = pd.read_csv('AAPL_IMP_VOL.csv', index_col=2, parse_dates=True)\n    imp_vol.sort_index(inplace=True)\n\n    prices['Adj Returns'] = \\\n        calculate_log_returns(prices['Adj Close'].values)\n    close_data = prices['Adj Returns'][-300:].values\n    imp_vol_data_30d = imp_vol['30d iv mean'][-300:].values\n    imp_vol_data_360d = imp_vol['360d iv mean'][-300:].values\n\n    days_to_expiry = [20, 60, 120, 180, 240]\n\n    lower = []\n    means = []\n    upper = []\n\n    for expiry in days_to_expiry:\n        np_lower, np_mean, np_upper = calc_sigmas(expiry, close_data)\n        lower.append(np_lower)\n        means.append(np_mean)\n        upper.append(np_upper)\n\n    historical_sigma_20d = calc_daily_sigma(20, close_data)\n    historical_sigma_240d = calc_daily_sigma(240, close_data)\n\n    limit = max(days_to_expiry)\n    x = range(0, limit)\n\n    fig = figure()\n    ax1 = fig.add_subplot(3, 1, 1)\n    plot(days_to_expiry, lower, color='red', label='Lower')\n    plot(days_to_expiry, means, color='grey', label='Average')\n    plot(days_to_expiry, upper, color='blue', label='Upper')\n    axhline(lower[0], linestyle='dashed', color='red')\n    axhline(lower[-1], linestyle='dashed', color='red')\n    axhline(upper[0], linestyle='dashed', color='blue')\n    axhline(upper[-1], linestyle='dashed', color='blue')\n    ax1.set_title('Volatility Cones')\n    legend(bbox_to_anchor=(1., 1.), loc=2)\n\n    ax2 = fig.add_subplot(3, 1, 2)\n    plot(x, historical_sigma_20d[-limit:], label='Historical')\n    plot(x, imp_vol_data_30d[-limit:], label='Implied')\n    axhline(lower[0], linestyle='dashed', color='red')\n    axhline(upper[0], linestyle='dashed', color='blue')\n    ax2.set_title('20 Day Volatilities')\n    ax2.set_xlim(ax1.get_xlim())\n    ax2.set_ylim(ax1.get_ylim())\n    legend(bbox_to_anchor=(1., 1.), loc=2)\n\n    # We only want to plot implied vol. where we have a value for historical\n    imp_vol_data_360d[np.where(np.isnan(historical_sigma_240d))] = np.nan\n\n    ax3 = fig.add_subplot(3, 1, 3)\n    plot(x, historical_sigma_240d[-limit:], label='Historical')\n    plot(x, imp_vol_data_360d[-limit:], label='Implied')\n    axhline(lower[-1], linestyle='dashed', color='red')\n    axhline(upper[-1], linestyle='dashed', color='blue')\n    ax3.set_title('240 Day Volatilities')\n    ax3.set_xlim(ax1.get_xlim())\n    ax3.set_ylim(ax1.get_ylim())\n    legend(bbox_to_anchor=(1., 1.), loc=2)\n    show()\n\n\ndef calc_sigmas(N, X, period=20):\n    start = 0\n    end = N\n\n    results = []\n\n    while end <= len(X):\n        sigma = calc_sigma(N, X[start:end])\n        results.append(sigma)\n        # print('N: {}, sigma: {}'.format(N, sigma))\n        start += period\n        end += period\n\n    sigmas = np.array(results)\n    mean = sigmas.mean()\n\n    # Uncomment the following three lines to use z scores instead of minimum\n    # and maximum sigma values\n    #\n    # z_score=2.0\n    # interval = sigmas.std() * z_score\n    # return mean - interval, mean, mean + interval\n    #\n    return sigmas.min(), mean, sigmas.max()\n\n\ndef calc_daily_sigma(lookback, data):\n    results = np.zeros(len(data))\n    start = 0\n    end = lookback\n    results[start:end] = np.nan\n    while end < len(data):\n        results[end] = calc_sigma(lookback, data[start:end])\n        start += 1\n        end += 1\n    return results\n\n\ndef calc_sigma(N, X):\n    return sqrt(sum((X)**2) / float(N - 1)) * sqrt(252.0)\n\n\ndef calculate_log_returns(pnl):\n    lagged_pnl = lag(pnl)\n    returns = log(pnl / lagged_pnl)\n\n    # All values prior to our position opening in pnl will have a\n    # value of inf. This is due to division by 0.0\n    returns[np.isinf(returns)] = 0.\n    # Additionally, any values of 0 / 0 will produce NaN\n    returns[np.isnan(returns)] = 0.\n    return returns\n\n\ndef lag(data):\n    lagged = np.roll(data, 1)\n    lagged[0] = 0.\n    return lagged\n\n\nif __name__ == '__main__':\n    main()\n"""
python/drawdown/__init__.py,0,b''
python/drawdown/dd_example.py,1,"b""import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn\n\nimport utils\n\n\nnp.random.seed(3)\n\n\ndef main():\n\n    start_price = 70.0\n    prices = utils.generate_gbm_prices(500, 70.0, 0.05, 0.3, 1.0)\n    returns = (utils.calculate_returns(prices) + 1.0).cumprod() - 1.0\n    pnl = start_price * (returns + 1.0)\n\n    max_dd, max_count, max_dd_idx, max_duration_idx, hwm_idx = \\\n        utils.calculate_max_drawdown(returns)\n\n    plt.plot(pnl)\n    plt.plot((hwm_idx, max_dd_idx),\n             (pnl[hwm_idx], pnl[max_dd_idx]), color='black')\n    plt.annotate('max dd ({0:.2f}%)'.format(max_dd * 100.0),\n                 xy=(max_dd_idx, pnl[max_dd_idx]),\n                 xycoords='data', xytext=(0, -50),\n                 textcoords='offset points',\n                 arrowprops=dict(facecolor='black', shrink=0.05))\n\n    max_duration_start_idx = max_duration_idx - max_count\n    max_duration_x1x2 = (max_duration_start_idx, max_duration_idx)\n    max_duration_y1y2 = (pnl[max_duration_start_idx],\n                         pnl[max_duration_start_idx])\n\n    plt.plot(max_duration_x1x2, max_duration_y1y2, color='black')\n    plt.annotate('max dd duration ({} days)'.format(max_count),\n                 xy=((max_duration_start_idx + max_duration_idx) / 2,\n                     pnl[max_duration_start_idx]),\n                 xycoords='data',\n                 xytext=(-100, 30), textcoords='offset points',\n                 arrowprops=dict(facecolor='black', shrink=0.05))\n\n    plt.show()\n\n\nif __name__ == '__main__':\n    main()"""
python/drawdown/utils.py,10,"b'import numpy as np\n\n\nDAYS_PER_YEAR = 252.0\n\n\ndef generate_gbm_prices(periods, start_price, mu, sigma, delta):\n    t = delta / DAYS_PER_YEAR\n    prices = np.zeros(periods)\n    epsilon_sigma_t = np.random.normal(0, 1, periods-1) * sigma * np.sqrt(t)\n    prices[0] = start_price\n    for i in range(1, len(prices)):\n        prices[i] = prices[i-1] * \\\n                    np.exp((mu - 0.5 * sigma**2) * t +\n                           epsilon_sigma_t[i-1])\n    return prices\n\n\ndef lag(data, empty_term=0.):\n    lagged = np.roll(data, 1)\n    lagged[0] = empty_term\n    return lagged\n\n\ndef calculate_returns(prices):\n    lagged_pnl = lag(prices)\n    returns = (prices - lagged_pnl) / lagged_pnl\n\n    # All values prior to our position opening in pnl will have a\n    # value of inf. This is due to division by 0.0\n    returns[np.isinf(returns)] = 0.\n    # Additionally, any values of 0 / 0 will produce NaN\n    returns[np.isnan(returns)] = 0.\n    return returns\n\n\ndef calculate_max_drawdown(returns):\n    size = len(returns)\n    highwatermark = np.zeros(size)\n    drawdown = np.zeros(size)\n    dd_duration = np.zeros(size, dtype=int)\n\n    for i in range(1, size):\n        highwatermark[i] = max(highwatermark[i-1], returns[i])\n        drawdown[i] = ((1.0 + returns[i]) / (1.0 + highwatermark[i])) - 1.0\n        if drawdown[i] == 0.:\n            dd_duration[i] = 0\n        else:\n            dd_duration[i] = dd_duration[i-1] + 1\n\n    min_dd_idx = drawdown.argmin()\n    return min(drawdown), max(dd_duration), \\\n           min_dd_idx, dd_duration.argmax(), \\\n           np.where(returns == highwatermark[min_dd_idx-1])[-1]\n'"
python/expiries/__init__.py,0,"b""__author__ = 'Conor'\n"""
python/expiries/vix.py,0,"b'import datetime as dt\n\n\ndef get_expiry_date_for_month(curr_date):\n    """"""\n    http://cfe.cboe.com/products/spec_vix.aspx\n\n    TERMINATION OF TRADING:\n\n    Trading hours for expiring VIX futures contracts end at 7:00 a.m. Chicago\n    time on the final settlement date.\n\n    FINAL SETTLEMENT DATE:\n\n    The Wednesday that is thirty days prior to the third Friday of the\n    calendar month immediately following the month in which the contract\n    expires (""Final Settlement Date""). If the third Friday of the month\n    subsequent to expiration of the applicable VIX futures contract is a\n    CBOE holiday, the Final Settlement Date for the contract shall be thirty\n    days prior to the CBOE business day immediately preceding that Friday.\n    """"""\n    # Date of third friday of the following month\n    if curr_date.month == 12:\n        third_friday_next_month = dt.date(curr_date.year + 1, 1, 15)\n    else:\n        third_friday_next_month = dt.date(curr_date.year,\n                                          curr_date.month + 1, 15)\n\n    one_day = dt.timedelta(days=1)\n    thirty_days = dt.timedelta(days=30)\n    while third_friday_next_month.weekday() != 4:\n        # Using += results in a timedelta object\n        third_friday_next_month = third_friday_next_month + one_day\n\n    # TODO: Incorporate check that it\'s a trading day, if so move the 3rd\n    # Friday back by one day before subtracting\n    return third_friday_next_month - thirty_days\n'"
python/logger/init_logger.py,0,"b""import logging.config\nimport os\nimport yaml\n\n\ndef setup(default_path='config/error_logging.yaml',\n          default_level=logging.INFO,\n          env_key='LOG_CFG'):\n\n    path = default_path\n    value = os.getenv(env_key, None)\n    if value:\n        path = value\n    if os.path.exists(path):\n        with open(path, 'rt') as f:\n            config = yaml.load(f.read())\n            logging.config.dictConfig(config)\n    else:\n        logging.basicConfig(level=default_level)\n\n"""
python/logger/main.py,0,"b'import logging\n\nimport init_logger\n\n\ndef log_an_error():\n    log = logging.getLogger(__name__)\n    log.error(""Uh oh, something\'s not right"")\n\n\nif __name__ == \'__main__\':\n    init_logger.setup()\n    logging.info(""Wow, that was simple..."")\n    log_an_error()\n'"
python/model_validation/__init__.py,0,b'\n'
python/model_validation/utils.py,1,"b'import numpy as np\n\n\ndef lag(data, empty_term=0.):\n    lagged = np.roll(data, 1)\n    lagged[0] = empty_term\n    return lagged\n\n'"
python/model_validation/volatility.py,2,"b'import numpy as np\nfrom numpy import log, sqrt\nimport pandas as pd\n\nimport utils\n\n\nANNUALISER = sqrt(252.0)\n\n\ndef annualise(data):\n    return data * ANNUALISER\n\n\ndef population_std_dev(close_prices, lookback):\n    N = float(lookback)\n\n    prices = log(close_prices / utils.lag(close_prices))\n    results = np.zeros(np.size(prices))\n    results[:] = np.NAN\n    for i in range(lookback, len(prices)):\n        bounds = range(i-(lookback-1), i+1)\n        results[i] = sqrt(\n            ((prices[bounds] - prices[bounds].sum() / N)**2).sum() / (N - 1))\n\n    return annualise(results)\n\n\ndef pandas_std_dev(close_prices, lookback):\n    prices = log(close_prices / utils.lag(close_prices))\n    return annualise(pd.rolling_std(prices, window=lookback))\n'"
python/parkinson_volatility/compare_models.py,0,"b""from matplotlib.pyplot import figure, legend, plot, show\nimport pandas as pd\nimport seaborn\n\nimport volatility as vm\n\n\ndef main():\n    data = pd.read_csv('AAPL.csv', index_col=0, parse_dates=True)\n    data.sort_index(inplace=True)\n    # There was a stock split on 9th June 2014, so we work prior to this date\n    # as we're using non-adjusted data\n    data = data[-1000:-100]\n\n    # We don't use the adjusted close in this example, as the Parkinson\n    # model uses high and low prices which are not adjusted\n    std_dev = vm.population_std_dev(data['Close'], 20)\n    parkinson_vol = vm.parkinson_std_dev(data['High'], data['Low'], 20)\n\n    fig = figure()\n    fig.add_subplot(2, 1, 1)\n    plot(data['High'], label='High')\n    plot(data['Low'], label='Low')\n    plot(data['Close'], label='Close')\n    legend()\n\n    fig.add_subplot(2, 1, 2)\n    plot(std_dev, label='Close to close')\n    plot(parkinson_vol, label='Parkinson')\n    legend()\n\n    show()\n\n\nif __name__ == '__main__':\n    main()"""
python/parkinson_volatility/utils.py,1,"b'import numpy as np\n\n\ndef lag(data, empty_term=0.):\n    lagged = np.roll(data, 1)\n    lagged[0] = empty_term\n    return lagged\n\n'"
python/parkinson_volatility/volatility.py,0,"b'from numpy import log, NAN, sqrt, size, zeros\n\nimport utils\n\nANNUALISER = sqrt(252.0)\n\n\ndef annualise(data):\n    return data * ANNUALISER\n\n\ndef population_std_dev(close_prices, lookback):\n    N = float(lookback)\n\n    prices = log(close_prices / utils.lag(close_prices))\n    results = zeros(size(prices))\n    results[:] = NAN\n    for i in range(lookback, len(prices)):\n        bounds = range(i-(lookback-1), i+1)\n        results[i] = sqrt(\n            ((prices[bounds] - prices[bounds].sum() / N)**2).sum() / (N - 1))\n\n    return annualise(results)\n\n\ndef parkinson_std_dev(high_prices, low_prices, lookback):\n    """"""\n    Requires high and low prices during trading period\n    """"""\n    N = float(lookback)\n\n    prices = log(high_prices / low_prices)**2\n    results = zeros(size(prices))\n    results[:] = NAN\n    for i in range(lookback-1, len(high_prices)):\n        bounds = range(i-(lookback-1), i+1)\n        results[i] = sqrt((1 / (4 * N * log(2))) *\n                          (prices[bounds]).sum())\n    return annualise(results)\n'"
python/pca/vix_futures.py,12,"b'import datetime as dt\nimport glob\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn\n\n\nFUTURES_MONTHS = [\'F\', \'G\', \'H\', \'J\', \'K\', \'M\', \'N\', \'Q\', \'U\', \'V\', \'X\', \'Z\']\nFUTURES_DATA_DIR = \'/path/to/data\'\n\n\ndef main():\n    futures_prices = load_futures_prices()\n\n    n_futures = [30., 60., 90., 120., 150., 180.]\n    prices = {}\n\n    start = \'01/01/2009\'\n    end = \'30/12/2014\'\n    dates = pd.date_range(start, end, normalize=True)\n\n    prices = pd.DataFrame(index=dates)\n\n    for n in n_futures:\n        result = load_vix_future(n, futures_prices, dates)\n        # You may want to add some additional validation here looking for NaNs...\n        prices[str(n)] = result\n\n    prices = prices.dropna()\n\n    prices.plot()\n    plt.title(\'Constant maturity synthetic VIX futures prices\')\n    plt.show()\n\n    returns = pd.DataFrame(index=prices.index)\n\n    for key in prices:\n        returns[key] = calculate_log_returns(prices[key])\n\n    corr = returns.corr()\n    print(corr)\n    eig_val, eig_vec = np.linalg.eig(corr)\n    prop_of_variation = eig_val / eig_val.sum()\n    print(eig_val)\n    print(eig_vec)\n    print(\'Proportion of variation explained: {}\'.format(prop_of_variation))\n\n\ndef load_futures_prices():\n    return load_vix_futures_prices(\n        FUTURES_DATA_DIR, price=\'Settle\', start_year=2005)\n\n\ndef load_vix_future(n, futures_prices, dates):\n    ratios = np.empty(len(dates))\n\n    for i in range(0, len(ratios)):\n        ratios[i] = get_vix_future_ndays(n, futures_prices, dates[i].date())\n\n    return ratios\n\n\ndef get_vix_future_ndays(n, futures_prices, curr_date):\n    """"""\n    Weighted future expiring n days from now.\n    """"""\n    # We use n-1 as we roll to the next month if our target date falls on an\n    # expiry date, we want to that months contract, not the next\n    target_date = curr_date + dt.timedelta(days=n-1)\n\n    prev_expiry_date = get_next_expiry_date(curr_date)\n    next_expiry_date = get_next_expiry_date(\n        prev_expiry_date + dt.timedelta(days=1))\n\n    while next_expiry_date < target_date:\n        prev_expiry_date = next_expiry_date\n        next_expiry_date = get_next_expiry_date(\n            prev_expiry_date + dt.timedelta(days=1))\n\n    prices = get_futures_prices(\n        futures_prices, curr_date, prev_expiry_date, 2)\n    near_date_maturity = (prev_expiry_date - curr_date).days\n\n    if prices[0] is np.NaN or prices[1] is np.NaN:\n        return np.NaN\n    else:\n        return (near_date_maturity / n) * prices[0] + \\\n               ((n - near_date_maturity) / n) * prices[1]\n\n\ndef get_futures_prices(futures_prices, curr_date, expiry_date, month_count):\n\n    def get_price_value(prices, curr_date):\n        if curr_date in prices:\n            return prices[curr_date]\n        else:\n            return np.NaN\n\n    year = expiry_date.year\n    month = expiry_date.month\n\n    prices = []\n\n    prices.append(\n        get_price_value(futures_prices[year][month - 1], curr_date))\n\n    remaining = month_count - 1\n    next_month = month\n    next_year = year\n    while remaining > 0:\n        if next_month == 12:\n            next_month = 1\n            next_year += 1\n        else:\n            next_month += 1\n\n        prices.append(\n            get_price_value(\n                futures_prices[next_year][next_month - 1], curr_date))\n\n        remaining -= 1\n\n    return prices\n\n\ndef get_next_expiry_date(curr_date):\n    expiry_date = get_expiry_date_for_month(curr_date)\n\n    # It must be less then the expiry date, as on expiry date we only have\n    # a settlement price\n    if curr_date < expiry_date:\n        return expiry_date\n    else:\n        return get_expiry_date_for_month(curr_date + dt.timedelta(days=30))\n\n\ndef get_expiry_date_for_month(curr_date):\n    """"""\n    http://cfe.cboe.com/products/spec_vix.aspx\n\n    TERMINATION OF TRADING:\n\n    Trading hours for expiring VIX futures contracts end at 7:00 a.m. Chicago\n    time on the final settlement date.\n\n    FINAL SETTLEMENT DATE:\n\n    The Wednesday that is thirty days prior to the third Friday of the\n    calendar month immediately following the month in which the contract\n    expires (""Final Settlement Date""). If the third Friday of the month\n    subsequent to expiration of the applicable VIX futures contract is a\n    CBOE holiday, the Final Settlement Date for the contract shall be thirty\n    days prior to the CBOE business day immediately preceding that Friday.\n    """"""\n    # Date of third friday of the following month\n    if curr_date.month == 12:\n        third_friday_next_month = dt.date(curr_date.year + 1, 1, 15)\n    else:\n        third_friday_next_month = dt.date(curr_date.year,\n                                          curr_date.month + 1, 15)\n\n    one_day = dt.timedelta(days=1)\n    thirty_days = dt.timedelta(days=30)\n    while third_friday_next_month.weekday() != 4:\n        # Using += results in a timedelta object\n        third_friday_next_month = third_friday_next_month + one_day\n\n    # TODO: Incorporate check that it\'s a trading day, if so move the 3rd\n    # Friday back by one day before subtracting\n    return third_friday_next_month - thirty_days\n\n\ndef load_vix_futures_prices(source_dir, price=\'Close\',\n                            start_year=2005, end_year=2099):\n    """"""\n    Dictionary of dataframe price data in format\n    CFE_[M][YY]_VX.csv where M is []\n\n    start_year and end_year parameters refer to futures we are interested in,\n    not dates we have price data for.\n\n    :return data[YYYY][M] = dataframe\n    Where YYYY is expiry year, M is expiry month in range [0, 11]\n    """"""\n\n    data = {}\n\n    files = glob.glob(os.path.join(source_dir, \'CFE_*\'))\n    for f in files:\n        filename = os.path.basename(f)\n        month = FUTURES_MONTHS.index(filename[4])\n        year = int(\'20\' + filename[5] + filename[6])\n\n        if year < start_year or year > end_year:\n            continue\n\n        try:\n            df = load_symbol_data(f, index=0, header_row=0)\n        except IndexError:\n            df = load_symbol_data(f, index=0, header_row=1)\n\n        if year not in data:\n            data[year] = 12 * [None]\n        data[year][month] = df[price]\n\n    return data\n\ndef load_symbol_data(filename, index=0, header_row=0, order_ascending=True):\n    df = pd.read_csv(filename, index_col=index, header=header_row,\n                     parse_dates=True)\n\n    if order_ascending:\n        # Ensure data is in ascending order by date\n        if df.index[0] > df.index[1]:\n            df.sort_index(inplace=True)\n    return df\n\n\ndef np_print_full(*args, **kwargs):\n    from pprint import pprint\n    opt = np.get_printoptions()\n    np.set_printoptions(threshold=\'nan\')\n    pprint(*args, **kwargs)\n    np.set_printoptions(**opt)\n\n\ndef lag(data, empty_term=0., axis=0):\n    lagged = np.roll(data, 1, axis=axis)\n    lagged[0] = empty_term\n    return lagged\n\n\ndef calculate_log_returns(prices):\n    lagged_pnl = lag(prices)\n    returns = np.log(prices / lagged_pnl)\n\n    # All values prior to our position opening in pnl will have a\n    # value of inf. This is due to division by 0.0\n    returns[np.isinf(returns)] = 0.\n    # Additionally, any values of 0 / 0 will produce NaN\n    returns[np.isnan(returns)] = 0.\n    return returns\n\n\nif __name__ == \'__main__\':\n    main()\n'"
python/prices/__init__.py,0,b''
python/prices/bm.py,9,"b'import math\n\nimport numpy as np\n\n\nDAYS_PER_YEAR = 252.0\n\n\ndef generate_bm_prices(periods, start_price, mu, sigma, delta):\n    t = delta / DAYS_PER_YEAR\n    prices = np.zeros(periods)\n    epsilon_sigma_t = np.random.normal(0, 1, periods) * sigma * np.sqrt(t)\n    prices[0] = start_price\n    for i in range(1, len(prices)):\n        prices[i] = prices[i-1] * mu * t + \\\n                    prices[i-1] * epsilon_sigma_t[i-1] + \\\n                    prices[i-1]\n    return prices\n\n\ndef generate_gbm_prices(periods, start_price, mu, sigma, delta):\n    t = delta / DAYS_PER_YEAR\n    prices = np.zeros(periods)\n    epsilon_sigma_t = np.random.normal(0, 1, periods-1) * sigma * np.sqrt(t)\n    prices[0] = start_price\n    for i in range(1, len(prices)):\n        prices[i] = prices[i-1] * \\\n                    np.exp((mu - 0.5 * sigma**2) * t +\n                           epsilon_sigma_t[i-1])\n    return prices\n\n\ndef generate_gbm_prices_vec(periods, start_price, mu, sigma, delta):\n    epsilon = np.random.normal(0, 1, periods-1)\n\n    t = np.linspace(0, periods-1, periods) / DAYS_PER_YEAR\n    t[0] = 0.0\n\n    W = np.insert(np.cumsum(epsilon), 0, 0.0) / math.sqrt(DAYS_PER_YEAR)\n    t = t * delta\n    W = W * math.sqrt(delta)\n\n    return start_price * np.exp((mu - 0.5 * sigma**2) * t + sigma * W)\n\n\n'"
python/prices/generate_charts.py,7,"b""import math\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn\n\nimport bm\n\n\ndef main():\n    periods = 200\n    start_price = 70.0\n    mu = 0.05\n    sigma = 0.3\n    delta = 1.0\n\n    compare_bm_versus_gbm(periods, start_price, mu, sigma, delta)\n    run_multiple_simulations(10000, periods, start_price, mu, sigma,\n                             delta)\n\n\ndef compare_bm_versus_gbm(periods, start_price, mu, sigma, delta):\n    np.random.seed(10)\n    gbm_prices = bm.generate_gbm_prices(periods, start_price, mu, sigma,\n                                         delta)\n    np.random.seed(10)\n    bm_prices = bm.generate_bm_prices(periods, start_price, mu, sigma,\n                                       delta)\n\n    plt.plot(gbm_prices, label='GBM')\n    plt.plot(bm_prices, label='BM')\n    plt.legend()\n    plt.show()\n\n\ndef run_multiple_simulations(simulation_count, periods, start_price, mu,\n                             sigma, delta):\n    np.random.seed(10)\n    annualised_days = 252.0\n    sigmas = []\n    mus = []\n    for i in range(0, simulation_count):\n        prices = bm.generate_gbm_prices(periods, start_price, mu, sigma,\n                                         delta)\n        returns = calculate_log_returns(prices)\n        mus.append(returns.mean() * annualised_days)\n        sigmas.append(returns.std() * math.sqrt(annualised_days))\n\n    plt.subplot(211)\n    plt.hist(mus)\n    plt.axvline(x=mu, alpha=0.5, label='mu')\n    plt.legend()\n    plt.subplot(212)\n    plt.hist(sigmas)\n    plt.axvline(x=sigma, alpha=0.5, label='sigma')\n    plt.legend()\n    plt.show()\n\n\ndef lag(data, empty_term=0.):\n    lagged = np.roll(data, 1)\n    lagged[0] = empty_term\n    return lagged\n\n\ndef calculate_log_returns(pnl):\n    lagged_pnl = lag(pnl)\n    returns = np.log(pnl / lagged_pnl)\n\n    # All values prior to our position opening in pnl will have a\n    # value of inf. This is due to division by 0.0\n    returns[np.isinf(returns)] = 0.\n    # Additionally, any values of 0 / 0 will produce NaN\n    returns[np.isnan(returns)] = 0.\n    return returns\n\n\n\nif __name__ == '__main__':\n    main()"""
python/returns/__init__.py,0,b''
python/returns/calc_returns.py,7,"b""import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn\n\n\ndef main():\n    start_cash = 1000000.\n    positions = np.loadtxt('positions.txt')\n    cash = np.loadtxt('cash.txt')\n    prices = np.loadtxt('prices.txt')\n\n    delta = (prices - lag(prices)) * positions\n\n    notional_value = (np.absolute(positions) * prices).sum(1) + cash\n    returns = delta.sum(1) / notional_value\n\n    log_returns = (np.log(1.0 + returns)).cumsum()\n    real_returns = start_cash * np.exp(log_returns)\n\n    plt.plot(real_returns)\n    plt.show()\n\n\ndef lag(data, empty_term=0.):\n    lagged = np.roll(data, 1, axis=0)\n    lagged[0] = empty_term\n    return lagged\n\n\nif __name__ == '__main__':\n    main()"""
python/services/__init__.py,0,b''
python/services/bm.py,9,"b'import math\n\nimport numpy as np\n\n\nDAYS_PER_YEAR = 252.0\n\n\ndef generate_bm_prices(periods, start_price, mu, sigma, delta):\n    t = delta / DAYS_PER_YEAR\n    prices = np.zeros(periods)\n    epsilon_sigma_t = np.random.normal(0, 1, periods) * sigma * np.sqrt(t)\n    prices[0] = start_price\n    for i in range(1, len(prices)):\n        prices[i] = prices[i-1] * mu * t + \\\n                    prices[i-1] * epsilon_sigma_t[i-1] + \\\n                    prices[i-1]\n    return prices\n\n\ndef generate_gbm_prices(periods, start_price, mu, sigma, delta):\n    t = delta / DAYS_PER_YEAR\n    prices = np.zeros(periods)\n    epsilon_sigma_t = np.random.normal(0, 1, periods-1) * sigma * np.sqrt(t)\n    prices[0] = start_price\n    for i in range(1, len(prices)):\n        prices[i] = prices[i-1] * \\\n                    np.exp((mu - 0.5 * sigma**2) * t +\n                           epsilon_sigma_t[i-1])\n    return prices\n\n\ndef generate_gbm_prices_vec(periods, start_price, mu, sigma, delta):\n    epsilon = np.random.normal(0, 1, periods-1)\n\n    t = np.linspace(0, periods-1, periods) / DAYS_PER_YEAR\n    t[0] = 0.0\n\n    W = np.insert(np.cumsum(epsilon), 0, 0.0) / math.sqrt(DAYS_PER_YEAR)\n    t = t * delta\n    W = W * math.sqrt(delta)\n\n    return start_price * np.exp((mu - 0.5 * sigma**2) * t + sigma * W)\n\n\n'"
python/services/price_service.py,0,"b'from flask import app, Flask, jsonify, request\nimport bm\n\n\napp = Flask(__name__)\n\n\n@app.route(\'/gbm\')\ndef gbm():\n    args = request.args\n\n    periods = int(args.get(\'periods\'))\n    start_price = float(args.get(\'startPrice\'))\n    mu = float(args.get(\'mu\'))\n    sigma = float(args.get(\'sigma\'))\n    delta = float(args.get(\'delta\'))\n\n    prices = bm.generate_gbm_prices(periods, start_price, mu, sigma, delta)\n    return jsonify(result=prices.tolist())\n\n\nif __name__ == ""__main__"":\n    app.run()\n'"
python/unittests/utils.py,1,"b'import numpy as np\n\n\ndef day_count(start, end):\n    delta = end - start\n    return delta.days\n\n\ndef ffill(data):\n    for i in range(1, len(data)):\n        if np.isnan(data[i]):\n            data[i] = data[i-1]\n    return data\n\n'"
python/drawdown/test/__init__.py,0,b''
python/drawdown/test/test_utils.py,3,"b'import unittest\n\nimport numpy as np\nfrom numpy.testing import utils as np_utils\n\n\nimport drawdown.utils as utils\n\n\nclass TestUtils(unittest.TestCase):\n\n    def test_lag(self):\n        np_utils.assert_array_equal(\n            np.array([0, 1, 2, 3, 4]),\n            utils.lag(np.array([1, 2, 3, 4, 5])))\n\n    def test_calculate_max_drawdown(self):\n        returns = np.array(\n            [0.1, 0.2, -0.1, -0.2, 0.1, -0.2, 0.1, 0.1, 0.1, 0.1, 0.3])\n        compound_returns = (1. + returns).cumprod() - 1.\n        max_dd, max_duration, dd_idx, duration_idx, hwm_idx = \\\n            utils.calculate_max_drawdown(compound_returns)\n        self.assertAlmostEqual(-0.3664, max_dd)\n        self.assertEqual(8, max_duration)\n        self.assertEqual(5, dd_idx)\n        self.assertEqual(9, duration_idx)\n        self.assertEqual(1, hwm_idx)'"
python/expiries/tests/__init__.py,0,"b""__author__ = 'Conor'\n"""
python/expiries/tests/test_vix.py,0,"b""import datetime as dt\nimport unittest\n\nfrom expiries import vix\n\n\nclass VixTests(unittest.TestCase):\n    def test_get_expiry_date_for_month(self):\n        self.assertEqual(\n            dt.date(2014, 12, 17),\n            vix.get_expiry_date_for_month(dt.date(2014, 12, 1)))\n        self.assertEqual(\n            dt.date(2015, 1, 21),\n            vix.get_expiry_date_for_month(dt.date(2015, 1, 1)))\n        self.assertEqual(\n            dt.date(2015, 2, 18),\n            vix.get_expiry_date_for_month(dt.date(2015, 2, 1)))\n\n\nif __name__ == '__main__':\n    unittest.main()\n"""
python/model_validation/test/__init__.py,0,b''
python/model_validation/test/test_utils.py,4,"b""import unittest\n\nimport numpy as np\nfrom numpy.testing import utils as np_utils\n\nimport model_validation.utils as utils\n\n\nclass TestUtils(unittest.TestCase):\n    def test_lag(self):\n        np_utils.assert_array_equal(\n            np.array([0, 1, 2, 3, 4]),\n            utils.lag(np.array([1, 2, 3, 4, 5])))\n\n    def test_lag_nan(self):\n        np_utils.assert_array_equal(\n            np.array([np.NAN, 1, 2, 3, 4]),\n            utils.lag(np.array([1., 2., 3., 4., 5.]), np.NAN))\n\n\nif __name__ == '__main__':\n    unittest.main()\n"""
python/model_validation/test/test_volatility.py,0,"b""import unittest\n\nimport numpy.testing as ntest\nimport pandas as pd\n\nimport model_validation.volatility as volatility\n\n\nFILENAME = 'data/AAPL_std_dev.xlsx'\n\n\nclass TestVolatility(unittest.TestCase):\n    def setUp(self):\n        self.xls_file = pd.ExcelFile(FILENAME)\n        self.data = self.xls_file.parse('AAPL Std Dev',\n                                   header=0, index_col=0, parse_cols='A:J')\n        # We want to reverse our series so the first index is the oldest\n        # entry not newest\n        self.data.sort_index(inplace=True)\n\n    def test_population_std_dev(self):\n        vol30 = volatility.population_std_dev(self.data['Adj Close'], 30)\n        ntest.assert_array_almost_equal(self.data['30 Day Vol'], vol30)\n\n        vol60 = volatility.population_std_dev(self.data['Adj Close'], 60)\n        ntest.assert_array_almost_equal(self.data['60 Day Vol'], vol60)\n\n    def test_pandas_std_dev(self):\n        vol = volatility.pandas_std_dev(self.data['Adj Close'], 30)\n        ntest.assert_array_almost_equal(self.data['30 Day Vol'], vol)\n\n        vol = volatility.pandas_std_dev(self.data['Adj Close'], 60)\n        ntest.assert_array_almost_equal(self.data['60 Day Vol'], vol)\n\nif __name__ == '__main__':\n    unittest.main()\n"""
python/prices/test/__init__.py,0,b''
python/prices/test/test_gbm.py,3,"b""import unittest\n\nimport numpy as np\nfrom numpy.testing import utils as np_utils\n\nimport prices.bm as bm\n\n\nclass GBMTests(unittest.TestCase):\n    def test_geometric_models(self):\n        np.random.seed(10)\n\n        periods = 1000\n        price = 70.0\n        mu = 0.05\n        sigma = 0.3\n        period_duration = 1.0\n\n        np.random.seed(10)\n        iterative_ret = bm.generate_gbm_prices(\n            periods, price, mu, sigma, period_duration)\n        np.random.seed(10)\n        vectorised_ret = bm.generate_gbm_prices_vec(\n            periods, price, mu, sigma, period_duration)\n\n        # Equal to 6 decimal places\n        np_utils.assert_array_almost_equal(iterative_ret, vectorised_ret)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"""
python/services/test/__init__.py,0,"b""__author__ = 'Conor'\n"""
python/services/test/test_price_service.py,0,"b""import json\nimport unittest\n\nfrom services import price_service\n\n\nclass ServicesTest(unittest.TestCase):\n    def setUp(self):\n        self.app = price_service.app.test_client()\n\n    def test_gbm(self):\n        data = {\n            'periods': 100,\n            'startPrice': 70.0,\n            'mu': 0.05,\n            'sigma': 0.30,\n            'delta': 1.0\n        }\n\n        response = self.app.get('/gbm', query_string=data)\n        self.assertEqual(200, response.status_code)\n        data = json.loads(response.get_data().decode('utf-8'))\n        self.assertEqual(100, len(data['result']))\n"""
python/unittests/test/test_utils.py,2,"b""import datetime as dt\nimport unittest\n\nimport numpy as np\nfrom numpy.testing import utils as np_utils\n\nimport utils\n\n\nclass TestUtils(unittest.TestCase):\n    def test_day_count(self):\n        start = dt.datetime(2014, 7, 10)\n        end = dt.datetime(2014, 8, 10)\n        self.assertEqual(31, utils.day_count(start, end))\n\n    def test_ffill(self):\n        data = np.array([0, np.nan, 1, np.nan, np.nan, -1, np.nan])\n        np_utils.assert_array_equal(\n            np.array([0, 0, 1, 1, 1, -1, -1]),\n            utils.ffill(data))\n\n\nif __name__ == '__main__':\n    unittest.main()\n\n"""
