file_path,api_count,code
config.py,0,"b""##\r\n# A bunch of constants for use in other files\r\n\r\n\r\n# Image dimensions to resize to\r\nCROPPED_WIDTH  = 200\r\nCROPPED_HEIGHT = 66\r\nCOLOR_CHANNELS = 3\r\n\r\nRESIZE_DIMENSIONS = (CROPPED_HEIGHT, CROPPED_WIDTH)\r\nINPUT_DIMENSIONS = RESIZE_DIMENSIONS + (COLOR_CHANNELS,)\r\n\r\n# hyperparameters to tune\r\nBATCH_SIZE = 128           # number of samples in a batch of data in an epoch\r\nSAMPLES_PER_EPOCH = 2048   # number of times the generator will yield per epoch\r\nNB_EPOCHS = 100             # number of epochs to train for\r\nKEEP_PROB = 0.25           # keep probability for hinton's dropout\r\nLEARNING_RATE = 0.0001     # learning rate for convnet\r\nALPHA = 1.0                # ELU alpha param\r\n"""
drive.py,1,"b'import argparse\r\nimport base64\r\nimport json\r\nimport cv2\r\nimport numpy as np\r\nimport socketio\r\nimport eventlet\r\nimport eventlet.wsgi\r\nimport time\r\nimport math\r\nfrom PIL import Image\r\nfrom PIL import ImageOps\r\nfrom flask import Flask, render_template\r\nfrom io import BytesIO\r\n\r\nfrom keras.models import model_from_json\r\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\r\n\r\nimport scipy\r\nfrom scipy import ndimage\r\nfrom scipy.misc import imresize\r\n\r\n\r\n# Fix error with Keras and TensorFlow\r\nimport tensorflow as tf\r\ntf.python.control_flow_ops = tf\r\n\r\n\r\n# user level imports\r\nfrom ops import *\r\nfrom config import *\r\n\r\nsio = socketio.Server()\r\napp = Flask(__name__)\r\nmodel = None\r\nprev_image_array = None\r\n\r\n@sio.on(\'telemetry\')\r\ndef telemetry(sid, data):\r\n    # The current steering angle of the car\r\n    steering_angle = data[""steering_angle""]\r\n    # The current throttle of the car\r\n    throttle = data[""throttle""]\r\n    # The current speed of the car\r\n    speed = data[""speed""]\r\n    # The current image from the center camera of the car\r\n    imgString = data[""image""]\r\n    image = Image.open(BytesIO(base64.b64decode(imgString)))\r\n    image_array = np.asarray(image)\r\n\r\n    # simulation sends rgb images to the model, cv imread takes BGR\r\n    image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\r\n\r\n    # Preprocessing for our image\r\n    image_array = preprocess_image(image_array)\r\n\r\n    # adjust dim for keras\r\n    image_array = image_array[None, :, :, :]\r\n\r\n    # import pdb; pdb.set_trace()\r\n\r\n    # the model assumes that the features are just the image arrays.\r\n    steering_angle = float(model.predict(image_array, batch_size=1))\r\n\r\n    # The driving model currently just outputs a constant throttle. Feel free to edit this.\r\n    # throttle = 0.2\r\n\r\n    throttle = max(0.1, -0.15 / 0.05 * abs(steering_angle) + 0.35)\r\n    # slow down for turns\r\n    # if abs(steering_angle) > .07:\r\n    #     throttle = .05\r\n    print(\'Angle: {0:02f}, Throttle: {1:02f}\'.format(steering_angle, throttle))\r\n    send_control(steering_angle, throttle)\r\n\r\n\r\n@sio.on(\'connect\')\r\ndef connect(sid, environ):\r\n    print(""connect "", sid)\r\n    send_control(0, 0)\r\n\r\n# TODO this should end the process after the connection has closed.\r\n@sio.on(\'disconnect\')\r\ndef disconnect():\r\n    print(\'Client disconnected\')\r\n    exit()\r\n\r\n\r\ndef send_control(steering_angle, throttle):\r\n    sio.emit(""steer"", data={\r\n    \'steering_angle\': steering_angle.__str__(),\r\n    \'throttle\': throttle.__str__()\r\n    }, skip_sid=True)\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    parser = argparse.ArgumentParser(description=\'Remote Driving\')\r\n    parser.add_argument(\'model\', type=str,\r\n    help=\'Path to model definition json. Model weights should be on the same path.\')\r\n    args = parser.parse_args()\r\n    with open(args.model, \'r\') as jfile:\r\n        model = model_from_json(jfile.read())\n\n\r\n    model.compile(""adam"", ""mse"")\r\n    weights_file = args.model.replace(\'json\', \'h5\')\r\n    model.load_weights(weights_file)\r\n\r\n    # wrap Flask application with engineio\'s middleware\r\n    app = socketio.Middleware(sio, app)\r\n\r\n    # deploy as an eventlet WSGI server\r\n    eventlet.wsgi.server(eventlet.listen((\'\', 4567)), app)\r\n'"
networks.py,0,"b'# @Author David Awad\r\n# code to create our neural network and save it as a model.\r\nimport os\r\nimport csv\r\nimport cv2\r\nimport math\r\nimport json\r\nimport pickle\r\nimport random\r\nimport collections\r\n\r\nfrom os.path import normpath, join\r\n\r\nimport scipy\r\nfrom scipy import ndimage\r\nfrom scipy.misc import imresize\r\n\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nimport pydot\r\n\r\n\r\n# keras contents\r\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\r\nfrom keras.models import model_from_json, Sequential\r\nfrom keras.utils import np_utils\r\nfrom keras.layers.advanced_activations import ELU as elu\r\nfrom keras.layers import Flatten, ZeroPadding2D, MaxPooling2D, Activation, Dropout, Convolution2D\r\nfrom keras.layers import Dense, Input, Activation, BatchNormalization, Lambda, ELU\r\nfrom keras.optimizers import Adam\r\nfrom keras.backend import ndim\r\n\r\n# from keras.utils.visualize_util import plot\r\n\r\n\r\nfrom tensorflow.python.framework.ops import convert_to_tensor\r\n\r\nimport numpy as np\r\n# Fix obscure error with Keras and TensorFlow\r\nimport tensorflow as tf\r\ntf.python.control_flow_ops = tf\r\n\r\n# user level imports\r\nfrom ops import *\r\nfrom config import *\r\n\r\n\r\n# NVIDIA MODEL\r\ndef nvidia_model():\r\n    print(\'Nvidia Model...\')\r\n    model = Sequential()\r\n    # model.add(Lambda(lambda x: x / 255. - .5, input_shape=INPUT_DIMENSIONS))\r\n#     model.add(BatchNormalization(input_shape=INPUT_DIMENSIONS, axis=1))\r\n    model.add(Convolution2D(24, 5, 5, input_shape=INPUT_DIMENSIONS, border_mode=\'valid\', init=\'he_normal\', subsample=(2, 2), name=\'conv1\'))\r\n\r\n    model.add(ELU())\r\n    model.add(Convolution2D(36, 5, 5, border_mode=\'valid\', init=\'he_normal\', subsample=(2, 2), name=\'conv2\'))\r\n\r\n    model.add(ELU())\r\n    # model.add(Dropout(KEEP_PROB))\r\n    model.add(Convolution2D(48, 5, 5, border_mode=\'valid\', init=\'he_normal\', subsample=(2, 2), name=\'conv3\'))\r\n\r\n    model.add(ELU())\r\n    # model.add(Dropout(KEEP_PROB))\r\n    model.add(Convolution2D(64, 3, 3, border_mode=\'valid\', init=\'he_normal\', subsample=(1, 1), name=\'conv4\'))\r\n\r\n    model.add(ELU())\r\n    # model.add(Dropout(KEEP_PROB))\r\n    model.add(Convolution2D(64, 3, 3, border_mode=\'valid\', init=\'he_normal\', subsample=(1, 1), name=\'conv5\'))\r\n\r\n    model.add(ELU())\r\n    model.add(Flatten())\r\n    model.add(Dense(1164, init=\'he_normal\', name=""dense_1164""))\r\n\r\n    model.add(ELU())\r\n    model.add(Dense(100, init=\'he_normal\', name=""dense_100""))\r\n\r\n    model.add(ELU())\r\n    model.add(Dense(50, init=\'he_normal\', name=""dense_50""))\r\n\r\n    model.add(ELU())\r\n    model.add(Dense(10, init=\'he_normal\', name=""dense_10""))\r\n\r\n    model.add(ELU())\r\n    model.add(Dense(1, init=\'he_normal\', name=""dense_1""))\r\n    return model\r\n\r\n\r\ndef comma_model():\r\n    print(\'Comma Model...\')\r\n    model = Sequential()\r\n    # Color conversion\r\n    model.add(BatchNormalization(input_shape=INPUT_DIMENSIONS, axis=1))\r\n    model.add(Convolution2D(3, 1, 1, border_mode=\'same\', name=\'color_conv\'))\r\n    model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=""same"", activation=\'elu\'))\r\n    model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=""same"", activation=\'elu\'))\r\n    model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=""same""))\r\n    model.add(Flatten())\r\n    model.add(Dropout(.2))\r\n    model.add(ELU())\r\n    model.add(Dense(512))\r\n    model.add(Dropout(.5))\r\n    model.add(ELU())\r\n    model.add(Dense(1))\r\n    return model\r\n\r\n\r\ndef experimental_cnn():\r\n    model = Sequential()\r\n\r\n    model.add(ZeroPadding2D((1, 1), input_shape=INPUT_DIMENSIONS))\r\n    model.add(Convolution2D(32, 3, 3, activation=\'elu\'))\r\n\r\n    model.add(ZeroPadding2D((1, 1)))\r\n    model.add(Convolution2D(32, 3, 3, activation=\'elu\'))\r\n\r\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\r\n\r\n    model.add(ZeroPadding2D((1, 1), input_shape=INPUT_DIMENSIONS))\r\n    model.add(Convolution2D(64, 3, 3, activation=\'elu\'))\r\n\r\n    model.add(ZeroPadding2D((1, 1)))\r\n    model.add(Convolution2D(64, 3, 3, activation=\'elu\'))\r\n\r\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\r\n    model.add(Dropout(0.5))\r\n\r\n    model.add(ZeroPadding2D((1, 1), input_shape=INPUT_DIMENSIONS))\r\n    model.add(Convolution2D(128, 3, 3, activation=\'elu\'))\r\n    model.add(ZeroPadding2D((1, 1)))\r\n    model.add(Convolution2D(128, 3, 3, activation=\'elu\'))\r\n\r\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\r\n\r\n    model.add(Flatten(input_shape=(3, CROPPED_WIDTH, CROPPED_HEIGHT)))\r\n    model.add(Dense(256, activation=\'elu\'))\r\n\r\n    model.add(Dropout(0.5))\r\n    model.add(Dense(64, activation=\'elu\'))\r\n\r\n    model.add(Dropout(0.5))\r\n    model.add(Dense(16, activation=\'elu\'))\r\n    model.add(Dense(1))\r\n\r\n    return model\r\n'"
ops.py,21,"b'##\r\n# Contains various utility functions used in drive and train_model\r\nimport cv2\r\nimport math\r\nimport numpy as np\r\n\r\nimport os\r\nimport csv\r\nimport cv2\r\nimport math\r\nimport json\r\nimport pickle\r\nimport random\r\nimport collections\r\n\r\nfrom os.path import normpath, join\r\n\r\nimport scipy\r\nfrom scipy import ndimage\r\nfrom scipy.misc import imresize\r\n\r\nfrom sklearn.model_selection import train_test_split\r\n\r\n# keras contents\r\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\r\nfrom keras.layers.advanced_activations import ELU as elu\r\nfrom keras.layers import Flatten, ZeroPadding2D, MaxPooling2D, Activation, Dropout, Convolution2D\r\nfrom keras.layers import Dense, Input, Activation, BatchNormalization, Lambda, ELU\r\nfrom keras.models import model_from_json, Sequential\r\nfrom keras.optimizers import Adam\r\nfrom keras.utils import np_utils\r\nfrom keras.backend import ndim\r\n\r\nfrom tensorflow.python.framework.ops import convert_to_tensor\r\n\r\nimport numpy as np\r\n# Fix obscure error with Keras and TensorFlow\r\nimport tensorflow as tf\r\ntf.python.control_flow_ops = tf\r\n\r\nfrom config import *\r\n\r\n\r\n# our image preprocessing scheme\r\ndef preprocess_image(image):\r\n    """"""\r\n    takes an image array and crops and normalizes it for training on the neural network\r\n    """"""\r\n    image_shape = image.shape\r\n\r\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n\r\n    norm_image = np.zeros(image.shape)\r\n    # normalize image colors for faster training\r\n    image = cv2.normalize(image, norm_image, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\r\n\r\n    # crop out the top 1/3 with horizon line & bottom 25px containing hood of the car\r\n    image = image[math.floor(image_shape[0] / 5):image_shape[0] - 25, 0:image_shape[1]]\r\n    # resize the image to our desired output dimensions\r\n    image = cv2.resize(image, (CROPPED_WIDTH, CROPPED_HEIGHT), interpolation=cv2.INTER_AREA)\r\n    return np.float32(image)\r\n\r\n\r\n# randomly augment brightness\r\ndef augment_brightness_camera_images(image):\r\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\r\n    bright_rand = .25 + np.random.uniform()\r\n\r\n    image[:, :, 2] = image[:, :, 2] * bright_rand\r\n    image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\r\n    return image\r\n\r\n\r\n# translate an image randomly within a certain range\r\ndef trans_image(image, angle, trans_range):\r\n    # Translation\r\n    x_shift = trans_range * np.random.uniform() - trans_range / 2\r\n    shifted_angle = angle + x_shift / trans_range * 2 * .2\r\n    y_shift = 40 * np.random.uniform() - 40 / 2\r\n\r\n    modifier = np.float32([[1, 0, x_shift], [0, 1, y_shift]])\r\n    translated_image = cv2.warpAffine(image, modifier, (CROPPED_WIDTH, CROPPED_HEIGHT))\r\n\r\n    return translated_image, shifted_angle\r\n\r\n\r\n# add random shadows to the image\r\ndef add_random_shadows(image):\r\n    top_y = CROPPED_HEIGHT * np.random.uniform()\r\n    top_x = 0\r\n    bot_x = CROPPED_WIDTH\r\n    bot_y = CROPPED_HEIGHT * np.random.uniform()\r\n    image_hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\r\n    mask = 0 * image_hls[:, :, 1]\r\n    mask_x = np.mgrid[0:image.shape[0], 0:image.shape[1]][0]\r\n    mask_y = np.mgrid[0:image.shape[0], 0:image.shape[1]][1]\r\n\r\n    mask[((mask_x - top_x) * (bot_y - top_y) - (bot_x - top_x) * (mask_y - top_y) >= 0)] = 1\r\n\r\n    if np.random.randint(2) == 1:\r\n        bright_rand = .5\r\n        cond1 = mask == 1\r\n        cond0 = mask == 0\r\n        if np.random.randint(2) == 1:\r\n            image_hls[:, :, 1][cond1] = image_hls[:, :, 1][cond1] * bright_rand\r\n        else:\r\n            image_hls[:, :, 1][cond0] = image_hls[:, :, 1][cond0] * bright_rand\r\n    image = cv2.cvtColor(image_hls, cv2.COLOR_HLS2RGB)\r\n    return image\r\n\r\n\r\ndef split_data_sets(csv_driving_data, test_size=0.2):\r\n    csv_driving_data = normpath(os.getcwd() + csv_driving_data)\r\n    with open(csv_driving_data, \'r\') as f:\r\n        reader = csv.reader(f)\r\n        driving_data = [row for row in reader][1:]\r\n\r\n        train_data, val_data = train_test_split(driving_data, test_size=test_size, random_state=1)\r\n        val_data, test_data = train_test_split(val_data, test_size=0.1, random_state=1)\r\n        return train_data, val_data, test_data\r\n\r\n\r\ndef create_valid_generator(data_points, batch_size=BATCH_SIZE):\r\n    """"""\r\n    generator for purely vavlidation data\r\n    """"""\r\n    # propagate batch_images and batch_steering\r\n    batch_images = np.zeros((batch_size, CROPPED_HEIGHT, CROPPED_WIDTH, 3))\r\n    batch_steering = np.zeros(batch_size)\r\n\r\n    while True:\r\n        batch_filled = 0\r\n        # TODO change to .shape\r\n        while batch_filled < batch_size:\r\n\r\n            # grab a random training example\r\n            row = data_points[np.random.randint(len(data_points))]\r\n\r\n            impath = row[0]  # set image path\r\n            angle = float(row[3])           # read steering angle\r\n\r\n            # read our image from the camera of choice\r\n            impath = os.path.normpath(os.getcwd() + ""/data/"" + impath).replace("" "", """")\r\n            # impath = os.path.normpath(impath).replace("" "", """")\r\n            image = cv2.imread(impath)\r\n\r\n            if image is None or angle == 0.0: continue\r\n\r\n            image = preprocess_image(image)\r\n\r\n            # fill batch of data\r\n            batch_images[batch_filled] = image\r\n            batch_steering[batch_filled] = angle\r\n            batch_filled += 1\r\n        yield batch_images, batch_steering\r\n\r\n\r\ndef create_generator(data_points, batch_size=BATCH_SIZE):\r\n    """"""\r\n    generator for training data\r\n    """"""\r\n    # propagate batch_images and batch_steering\r\n    batch_images = np.zeros((batch_size, CROPPED_HEIGHT, CROPPED_WIDTH, 3))\r\n    batch_steering = np.zeros(batch_size)\r\n\r\n    while True:\r\n        batch_filled = 0\r\n        # TODO change to .shape\r\n        while batch_filled < batch_size:\r\n\r\n            # grab a random training example\r\n            row = data_points[np.random.randint(len(data_points))]\r\n\r\n            # select a random camera image and set path to one of our 3 camera images\r\n            camera_selection = np.random.randint(3)\r\n            impath = row[camera_selection]  # set image path\r\n            angle = float(row[3])           # read steering angle\r\n\r\n            # TODO make threshold a constant\r\n            # ignore low angles\r\n            min_ang_threshold = 0.8\r\n            if abs(angle) < .1:\r\n                # for every small angle, flip a coin to see if we use it.\r\n                rand = np.random.uniform()\r\n                if rand > min_ang_threshold: continue\r\n\r\n            # center cam\r\n            if (camera_selection == 0):\r\n                shift_ang = 0.\r\n\r\n            # left cam\r\n            if (camera_selection == 1):\r\n                shift_ang = .30\r\n\r\n            # right cam\r\n            if (camera_selection == 2):\r\n                shift_ang = -.30\r\n\r\n            # read our image from the camera of choice\r\n            impath = os.path.normpath(os.getcwd() + ""/data/"" + impath).replace("" "", """")\r\n            # impath = os.path.normpath(impath).replace("" "", """")\r\n            # NOTE: cv2.imread takes images in BGR format, NOT RGB\r\n            image = cv2.imread(impath)\r\n\r\n            if image is None or angle == 0.0: continue\r\n\r\n            angle = angle + shift_ang\r\n\r\n            # do the actual image preprocessing and cropping\r\n            image = preprocess_image(image)\r\n\r\n            # translate the image randomly to better simulate road conditions\r\n            image, angle = trans_image(image, angle, 100)\r\n\r\n            # add random shadow\r\n            image = add_random_shadows(image)\r\n\r\n            # augment brightness\r\n            image = augment_brightness_camera_images(image)\r\n\r\n            # flip half the images\r\n            flip_prob = np.random.randint(2)\r\n            if flip_prob > 0:\r\n                image = cv2.flip(image, 1)\r\n                angle = -angle\r\n\r\n            # fill batch of data\r\n            batch_images[batch_filled] = image\r\n            batch_steering[batch_filled] = angle\r\n            batch_filled += 1\r\n        yield batch_images, batch_steering\r\n'"
train_model.py,1,"b""# @Author David Awad\n# code to create our neural network and save it as a model.\n# from __future__ import unicode_literals\nimport os\nimport csv\nimport cv2\nimport math\nimport json\nimport pickle\nimport random\nimport collections\n\nfrom os.path import normpath, join\n\nimport scipy\nfrom scipy import ndimage\nfrom scipy.misc import imresize\n\nfrom sklearn.model_selection import train_test_split\n\nimport pydot\n\n\n# keras contents\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\nfrom keras.models import model_from_json, Sequential\nfrom keras.utils import np_utils\nfrom keras.layers.advanced_activations import ELU as elu\nfrom keras.layers import Flatten, ZeroPadding2D, MaxPooling2D, Activation, Dropout, Convolution2D\nfrom keras.layers import Dense, Input, Activation, BatchNormalization, Lambda, ELU\nfrom keras.optimizers import Adam\nfrom keras.backend import ndim\n\n# from keras.utils.visualize_util import plot\n\n\nfrom tensorflow.python.framework.ops import convert_to_tensor\n\nimport numpy as np\n# Fix obscure error with Keras and TensorFlow\nimport tensorflow as tf\ntf.python.control_flow_ops = tf\n\n# user level imports\nfrom ops import *\nfrom config import *\nfrom networks import *\n\n# fix random seed for reproducibility\nseed = 7\nnp.random.seed(seed)\n\n\n# create testing and validation sets out of the training data\ntrain_data, val_data, test_data = split_data_sets(csv_driving_data='/data/driving_log.csv')\n\n# create our generators (training, validation, test) for keras.\n\n# training set, used for training the neural network\ntraining_set = create_generator(train_data)\n# validation set, used during training to monitor progress\nvalidation_set = create_valid_generator(val_data)\n# testing set, used only once after the training is finished\ntesting_set = create_valid_generator(test_data)\n\n# select model\nmodel = experimental_cnn()\n\n# model.summary()\nmodel.compile(loss='mse', optimizer=Adam(lr=LEARNING_RATE))\n\nmodel.fit_generator(training_set,\n                    samples_per_epoch=SAMPLES_PER_EPOCH,\n                    nb_epoch=NB_EPOCHS,\n                    nb_val_samples=128,\n                    validation_data=validation_set)\n\n# save plot of our model to memory\n# plot(model, to_file='model.png')\n\n# evaluate model on the testing set\nscore = model.evaluate_generator(testing_set, val_samples=256)\n\n# POST PROCESSING, SAVE MODEL TO DISK\nwith open('model.json', 'w') as json_file:\n    json_file.write(model.to_json())\n\n# save weights as model.h5\nmodel.save_weights('model.h5')\n\nprint('Test score:', score)\nprint('Saved model to disk successfully')\n"""
