file_path,api_count,code
detection.py,13,"b'#!/usr/local/bin/python3\n# -*- coding: utf-8 -*-\nfrom moviepy.editor import VideoFileClip\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport argparse\nimport math\nimport cv2\n\n##\n# @Author David Awad\n# Detection.py, traces and identifies lane\n# markings in an image or .mp4 video\n# usage: detection.py [-h] [-f FILE] [-v VIDEO]\n\n\ndef region_of_interest(img, vertices):\n    #defining a blank mask to start with\n    mask = np.zeros_like(img)\n\n    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n    if len(img.shape) > 2:\n        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n        ignore_mask_color = (255,) * channel_count\n    else:\n        ignore_mask_color = 255\n\n    #filling pixels inside the polygon defined by ""vertices"" with the fill color\n    cv2.fillPoly(mask, vertices, ignore_mask_color)\n    #returning the image only where mask pixels are nonzero\n    masked_image = cv2.bitwise_and(img, mask)\n    return masked_image\n\n\ndef draw_lines(img, lines, color=[255, 0, 0], thickness=8):\n    # reshape lines to a 2d matrix\n    lines = lines.reshape(lines.shape[0], lines.shape[2])\n    # create array of slopes\n    slopes = (lines[:,3] - lines[:,1]) /(lines[:,2] - lines[:,0])\n    # remove junk from lists\n    lines = lines[~np.isnan(lines) & ~np.isinf(lines)]\n    slopes = slopes[~np.isnan(slopes) & ~np.isinf(slopes)]\n    # convert lines into list of points\n    lines.shape = (lines.shape[0]//2,2)\n\n    # Right lane\n    # move all points with negative slopes into right ""lane""\n    right_slopes = slopes[slopes < 0]\n    right_lines = np.array(list(filter(lambda x: x[0] > (img.shape[1]/2), lines)))\n    max_right_x, max_right_y = right_lines.max(axis=0)\n    min_right_x, min_right_y = right_lines.min(axis=0)\n\n    # Left lane\n    # all positive  slopes go into left ""lane""\n    left_slopes = slopes[slopes > 0]\n    left_lines = np.array(list(filter(lambda x: x[0] < (img.shape[1]/2), lines)))\n    max_left_x, max_left_y = left_lines.max(axis=0)\n    min_left_x, min_left_y = left_lines.min(axis=0)\n\n    # Curve fitting approach\n    # calculate polynomial fit for the points in right lane\n    right_curve = np.poly1d(np.polyfit(right_lines[:,1], right_lines[:,0], 2))\n    left_curve  = np.poly1d(np.polyfit(left_lines[:,1], left_lines[:,0], 2))\n\n    # shared ceiling on the horizon for both lines\n    min_y = min(min_left_y, min_right_y)\n\n    # use new curve function f(y) to calculate x values\n    max_right_x = int(right_curve(img.shape[0]))\n    min_right_x = int(right_curve(min_right_y))\n\n    min_left_x = int(left_curve(img.shape[0]))\n\n    r1 = (min_right_x, min_y)\n    r2 = (max_right_x, img.shape[0])\n    print(\'Right points r1 and r2,\', r1, r2)\n    cv2.line(img, r1, r2, color, thickness)\n\n    l1 = (max_left_x, min_y)\n    l2 = (min_left_x, img.shape[0])\n    print(\'Left points l1 and l2,\', l1, l2)\n    cv2.line(img, l1, l2, color, thickness)\n\n\ndef hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n    """"""\n    `img` should be the output of a Canny transform.\n    Returns an image with hough lines drawn.\n    """"""\n    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n    draw_lines(line_img, lines)\n    return line_img\n\n# Takes in a single frame or an image and returns a marked image\ndef mark_lanes(image):\n    if image is None: raise ValueError(""no image given to mark_lanes"")\n    # grayscale the image to make finding gradients clearer\n    gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n\n    # Define a kernel size and apply Gaussian smoothing\n    kernel_size = 5\n    blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size), 0)\n\n    # Define our parameters for Canny and apply\n    low_threshold = 50\n    high_threshold = 150\n    edges_img = cv2.Canny(np.uint8(blur_gray), low_threshold, high_threshold)\n\n\n    imshape = image.shape\n    vertices = np.array([[(0, imshape[0]),\n                          (450, 320),\n                          (490, 320),\n                          (imshape[1], imshape[0]) ]],\n                          dtype=np.int32)\n\n    masked_edges = region_of_interest(edges_img, vertices )\n\n\n    # Define the Hough transform parameters\n    rho             = 2           # distance resolution in pixels of the Hough grid\n    theta           = np.pi/180   # angular resolution in radians of the Hough grid\n    threshold       = 15       # minimum number of votes (intersections in Hough grid cell)\n    min_line_length = 20       # minimum number of pixels making up a line\n    max_line_gap    = 20       # maximum gap in pixels between connectable line segments\n\n    line_image = hough_lines(masked_edges, rho, theta, threshold, min_line_length, max_line_gap)\n\n    # Draw the lines on the edge image\n    # initial_img * \xce\xb1 + img * \xce\xb2 + \xce\xbb\n    lines_edges = cv2.addWeighted(image, 0.8, line_image, 1, 0)\n    return lines_edges\n\n\ndef read_image_for_marking(img_filepath):\n    # read in the image\n    image = mpimg.imread(img_filepath)\n    print(\'Reading image :\', img_filepath, \'\\nDimensions:\', image.shape)\n\n    marked_lanes = mark_lanes(image)\n\n    # show the image to plotter and then save it to a file\n    plt.imshow(marked_lanes)\n    plt.savefig(img_filepath[:-4] + \'_output.png\')\n\n\nif __name__ == ""__main__"":\n    # set up parser\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""-f"", ""--file"", help=""filepath for image to mark"", default=\'test_images/solidWhiteRight.jpg\')\n    parser.add_argument(""-v"", ""--video"", help=""filepath for video to mark"")\n    args = parser.parse_args()\n\n    if args.video:\n        clip = VideoFileClip(args.video)\n        clip = clip.fl_image(mark_lanes)\n        clip.write_videofile(\'output_\' + args.video, audio=False)\n\n    else:\n        # if nothing passed running algorithm on image\n        read_image_for_marking(args.file)\n'"
