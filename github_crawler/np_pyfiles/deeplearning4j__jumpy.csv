file_path,api_count,code
setup.py,0,"b""from setuptools import setup\nfrom setuptools import find_packages\n\n\nsetup(name='jumpy',\n      version='0.2.3',\n      description='Numpy and nd4j interop',\n      long_description='Mapping of the numpy & nd4j array representations',\n      author='Adam Gibson',\n      author_email='adam@skymind.io',\n      classifiers=[\n        'Development Status :: 3 - Alpha',\n        'License :: OSI Approved :: Apache Software License',\n        'Programming Language :: Python :: 3',\n        'Topic :: Software Development :: Libraries',\n      ],\n      keywords='numpy jumpy java nd4j deeplearning4j',\n      url='https://github.com/deeplearning4j/jumpy',\n      license='Apache',\n      setup_requires=['Cython'],\n      install_requires=['Cython', 'pyjnius', 'numpy'],\n      extras_require={\n          'visualize': ['pydot-ng'],\n          'tests': ['pytest',\n                    'pytest-pep8',\n                    'mock'],\n      },\n      packages=find_packages())\n"""
benchmarks/benchmark.py,2,"b""import jumpy as jp\nimport numpy as np\nfrom random import randint\nimport timeit\nimport gc\n\ngc.disable()\njp.disable_gc()\n\n\nclass Benchmark(object):\n    def __init__(self, n=1000):\n        print 'Running tests with [',n,'x',n,'] dimensionality'\n        self.n = n\n        self.m = 200\n        self.np_arr = []\n        self.nd4j_arr = []\n        for counter in range(0, self.m + 1):\n            self.np_arr.append(np.linspace(1, n * n, n * n).reshape((n, n)))\n\n        for counter in range(0, self.m + 1):\n            self.nd4j_arr.append(jp.array(self.np_arr[counter]))\n\n    def run_nd4j_scalar(self):\n        self.nd4j_arr[randint(0, self.m)] += 1.0172\n\n    def run_numpy_scalar(self):\n        self.np_arr[randint(0, self.m)] += 1.0172\n\n    def run_nd4j_add(self):\n        self.nd4j_arr[randint(0, self.m)] += self.nd4j_arr[randint(0, self.m)]\n\n    def run_numpy_add(self):\n        self.np_arr[randint(0, self.m)] += self.np_arr[randint(0, self.m)]\n\n    def run_numpy_sub(self):\n        self.np_arr[randint(0, self.m)] -= self.np_arr[randint(0, self.m)]\n\n    def run_nd4j_sub(self):\n        self.nd4j_arr[randint(0, self.m)] -= self.nd4j_arr[randint(0, self.m)]\n\n    def run_nd4j_mmul(self):\n        jp.dot(self.nd4j_arr[randint(0, self.m)], self.nd4j_arr[randint(0, self.m)])\n\n    def run_numpy_mmul(self):\n        np.dot(self.np_arr[randint(0, self.m)], self.np_arr[randint(0, self.m)])\n\n    def run_benchmark(self, n_trials=1000):\n        print 'nd4j scalar ', timeit.timeit(self.run_nd4j_scalar, number=n_trials)\n        print 'numpy scalar ', timeit.timeit(self.run_numpy_scalar, number=n_trials)\n        print 'nd4j add ', timeit.timeit(self.run_nd4j_add, number=n_trials)\n        print 'numpy add ', timeit.timeit(self.run_numpy_add, number=n_trials)\n        print 'nd4j sub ', timeit.timeit(self.run_nd4j_sub, number=n_trials)\n        print 'numpy sub ', timeit.timeit(self.run_numpy_sub, number=n_trials)\n        print 'nd4j mmul ', timeit.timeit(self.run_nd4j_mmul, number=n_trials)\n        print 'numpy mmul ', timeit.timeit(self.run_numpy_mmul, number=n_trials)\n\n\nbenchmark = Benchmark()\nbenchmark.run_benchmark()\n"""
jumpy/__init__.py,0,b'from .ndarray import *\nfrom .matlib import *\nfrom .memory_manager import *\nfrom .ops import *\n'
jumpy/java_classes.py,0,"b""import jnius_config\nimport os\n\njnius_config.add_options('-Dorg.bytedeco.javacpp.nopointergc=true')\njnius_class_path = os.environ.get('JUMPY_CLASS_PATH')\nif not jnius_class_path:\n\traise Exception('Environment variable JUMPY_CLASS_PATH not set.')\nelif not os.path.exists(jnius_class_path):\n\traise Exception('File not found : ' + jnius_class_path)\njnius_config.set_classpath(jnius_class_path)\n\nfrom jnius import autoclass\n\nNd4j = autoclass('org.nd4j.linalg.factory.Nd4j')\nINDArray = autoclass('org.nd4j.linalg.api.ndarray.INDArray')\nTransforms = autoclass('org.nd4j.linalg.ops.transforms.Transforms')\nNDArrayIndex = autoclass('org.nd4j.linalg.indexing.NDArrayIndex')\nDataBuffer = autoclass('org.nd4j.linalg.api.buffer.DataBuffer')\nSystem = autoclass('java.lang.System')\nInteger = autoclass('java.lang.Integer')\nFloat = autoclass('java.lang.Float')\nDouble = autoclass('java.lang.Double')\nShape = autoclass('org.nd4j.linalg.api.shape.Shape')\nBinarySerde = autoclass('org.nd4j.serde.binary.BinarySerde')\nNativeOpsHolder = autoclass('org.nd4j.nativeblas.NativeOpsHolder')\nDoublePointer = autoclass('org.bytedeco.javacpp.DoublePointer')\nFloatPointer = autoclass('org.bytedeco.javacpp.FloatPointer')\nIntPointer = autoclass('org.bytedeco.javacpp.IntPointer')\nDataTypeUtil = autoclass('org.nd4j.linalg.api.buffer.util.DataTypeUtil')\nMemoryManager = autoclass('org.nd4j.linalg.memory.MemoryManager')\nSameDiff = autoclass('org.nd4j.autodiff.samediff.SameDiff')\n"""
jumpy/matlib.py,0,b'from .ndarray import ndarray\nfrom .java_classes import Nd4j\n\n\ndef zeros(shape):\n    return ndarray(Nd4j.zeros(*shape))\n\n\ndef ones(shape):\n    return ndarray(Nd4j.ones(*shape))\n'
jumpy/memory_manager.py,0,b'from .java_classes import Nd4j\n\nmemory_manager = Nd4j.getMemoryManager()\n\n\ndef disable_gc():\n    memory_manager.togglePeriodicGc(False)\n\n\ndef enable_gc():\n    memory_manager.togglePeriodicGc(True)\n\n\ndef set_gc_interval(interval=5000):\n    memory_manager.setAutoGcWindow(interval)'
jumpy/ndarray.py,11,"b'from .java_classes import *\nimport numpy as np\nimport ctypes\n\n\n# Java instance initializations\nnative_ops = NativeOpsHolder.getInstance().getDeviceNativeOps()\n\n\n# DATA TYPE MANAGEMENT\n\ndef set_context_dtype(dtype):\n    \'\'\'\n    Sets the dtype for nd4j\n    # Arguments\n        dtype: \'float\' or \'double\'\n    \'\'\'\n    dtype = DataTypeUtil.getDtypeFromContext(dtype)\n    DataTypeUtil.setDTypeForContext(dtype)\n\ndef get_context_dtype():\n    \'\'\'\n    Returns the nd4j dtype\n    \'\'\'\n    dtype = DataTypeUtil.getDtypeFromContext()\n    return DataTypeUtil.getDTypeForName(dtype)\n\n\ndef get_nd4j_dtype(np_dtype):\n    \'\'\'\n    Gets the equivalent nd4j data type\n    for a given numpy data type.\n    # Arguments\n        np_dtype: Numpy data type. One of\n            [\'float64\', \'float32\', \'float16\']\n    \'\'\'\n    if type(np_dtype) == type:\n        np_dtype = np_dtype.__name__\n    elif type(np_dtype) == np.dtype:\n        np_dtype = np_dtype.name\n    mapping = {\n        \'float64\' : \'double\',\n        \'float32\' : \'float\',\n        \'float16\' : \'half\'\n        }\n    nd4j_dtype = mapping.get(np_dtype)\n    if not nd4j_dtype:\n        raise Exception(\'Invalid numpy data type : \' + np_dtype)\n    return nd4j_dtype\n\ndef get_np_dtype(nd4j_dtype):\n    \'\'\'\n    Gets the equivalent numpy data type\n    for a given nd4j data type.\n    # Arguments:\n        nd4j_dtype : Nd4j data type. One of \n        [\'double\', \'float\', \'half\']\n    \'\'\'\n    mapping = {\n        \'double\' : np.float64,\n        \'float\' : np.float32,\n        \'half\' : np.float16\n    }\n    np_dtype = mapping.get(nd4j_dtype)\n    if not np_dtype:\n        raise Exception(\'Invalid nd4j data type : \' + nd4j_dtype)\n    return np_dtype\n\n\nset_context_dtype(\'double\')\n\n\n_refs = []\n\ndef _from_numpy(np_array):\n    \'\'\'\n    Convert numpy array to nd4j array\n    \'\'\'\n\n    # Convert the numpy array to nd4j context dtype\n    required_dtype = get_np_dtype(get_context_dtype())\n    if np_array.dtype != required_dtype:\n        raise Exception(""{0} is required."".format(repr(np_array.dtype)))\n\n    # Nd4j does not have 1-d vectors.\n    # So we add a dummy dimension.\n    if np_array.ndim == 1:\n        np_array = np.expand_dims(np_array, 0)\n\n    # We have to maintain references to all incoming\n    # numpy arrays. Else they will get GCed\n\n    # creates a Nd4j array from a numpy array\n    # To create an Nd4j array, we need 3 things:\n    # buffer, strides, and shape\n\n    # Get the buffer\n    # A buffer is basically an array. To get the buffer object\n    # we need a pointer to the first element and the size.\n    pointer_address, _ = np_array.__array_interface__[\'data\']\n    _refs.append(np_array)\n    pointer = native_ops.pointerForAddress(pointer_address)\n    size = np_array.size\n    mapping = {\n        np.float64 : DoublePointer,\n        np.float32 : FloatPointer,\n    }\n    pointer = mapping[required_dtype](pointer)\n    buff = Nd4j.createBuffer(pointer, size)\n    assert buff.address() == pointer_address\n    _refs.append(buff)\n    # Get the strides\n    # strides = tuple of bytes to step in each \n    # dimension when traversing an array.\n    elem_size = buff.getElementSize()\n    # Make sure word size is same in both python\n    # and java worlds\n    assert elem_size == np_array.dtype.itemsize\n    strides = np_array.strides\n    # numpy uses byte wise strides. We have to \n    # convert it to word wise strides.\n    strides = [dim / elem_size for dim in strides]\n\n    # Finally, shape:\n    shape = np_array.shape\n\n    nd4j_array = Nd4j.create(buff, shape, strides, 0)\n    assert buff.address() == nd4j_array.data().address()\n    return nd4j_array\n\n\ndef _to_numpy(nd4j_array):\n    \'\'\'\n    Convert nd4j array to numpy array\n    \'\'\'\n    buff = nd4j_array.data()\n    address = buff.pointer().address()\n    dtype = get_context_dtype()\n    mapping = {\n    \'double\': ctypes.c_double,\n    \'float\': ctypes.c_float\n    }\n    Pointer = ctypes.POINTER(mapping[dtype])\n    pointer = ctypes.cast(address, Pointer)\n    np_array = np.ctypeslib.as_array(pointer, tuple(nd4j_array.shape()))\n    return np_array\n\ndef _indarray(x):\n    if type(x) is INDArray:\n        return x\n    elif type(x) is ndarray:\n        return x.array\n    elif \'numpy\' in str(type(x)):\n        return _from_numpy(x)\n    elif type(x) in (list, tuple):\n        return _from_numpy(np.array(x))\n    elif type(x) in (int, float):\n        return Nd4j.scalar(x)\n    else:\n        raise Exception(\'Data type not understood :\' + str(type(x)))\n\ndef broadcast_like(y, x):\n    xs = x.shape()\n    ys = y.shape()\n    if xs == ys:\n        return y\n    _xs = tuple(xs)\n    _ys = tuple(ys)\n    nx = len(xs)\n    ny = len(ys)\n    if nx > ny:\n        diff = nx - ny\n        ys += [1] * diff\n        y = y.reshape(ys)\n        ny = nx\n    elif ny > nx:\n        raise Exception(\'Unable to broadcast shapes \' + str(_xs) + \'\'\n                        \' and \' + str(_ys))\n    yt = []\n    rep_y = False\n    for xd, yd in zip(xs, ys):\n        if xd == yd:\n            yt.append(1)\n        elif xd == 1:\n            raise Exception(\'Unable to broadcast shapes \' + str(_xs) + \'\'\n                            \' and \' + str(_ys))   \n        elif yd == 1:\n            yt.append(xd)\n            rep_y = True\n        else:\n            raise Exception(\'Unable to broadcast shapes \' + str(_xs) + \'\'\n                            \' and \' + str(_ys))    \n    if rep_y:\n        y = y.repmat(*yt)\n    return y\n\ndef broadcast(x, y):\n    xs = x.shape()\n    ys = y.shape()\n    if xs == ys:\n        return x, y\n    _xs = tuple(xs)\n    _ys = tuple(ys)\n    nx = len(xs)\n    ny = len(ys)\n    if nx > ny:\n        diff = nx - ny\n        ys += [1] * diff\n        y = y.reshape(ys)\n        ny = nx\n    elif ny > nx:\n        diff = ny - nx\n        xs += [1] * diff\n        x = x.reshape(xs)\n        nx = ny\n    xt = []\n    yt = []\n    rep_x = False\n    rep_y = False\n    for xd, yd in zip(xs, ys):\n        if xd == yd:\n            xt.append(1)\n            yt.append(1)\n        elif xd == 1:\n            xt.append(yd)\n            yt.append(1)\n            rep_x = True\n        elif yd == 1:\n            xt.append(1)\n            yt.append(xd)\n            rep_y = True\n        else:\n            raise Exception(\'Unable to broadcast shapes \' + str(_xs) + \'\'\n                            \' and \' + str(_ys))\n    if rep_x:\n        x = x.repmat(*xt)\n    if rep_y:\n        y = y.repmat(*yt)\n    return x, y\n\n\nclass ndarray(object):\n\n    def __init__(self, data, dtype=None):\n        # we ignore dtype for now\n        typ = type(data)\n        if typ is INDArray:\n            # Note that we don\'t make a copy here\n            self.array = data\n        elif typ is ndarray:\n            self.array = data.array.dup()\n        else:\n            if typ is not np.ndarray:\n                data = np.array(data)\n            self.array = _from_numpy(data)\n\n    def numpy(self):\n        # TODO: Too expensive. Make it cheaper.\n        np_array = _to_numpy(self.array)\n        return np_array\n\n    @property\n    def size(self):\n        return self.array.length()\n\n    @property\n    def shape(self):\n        return tuple(self.array.shape())\n\n    @shape.setter\n    def shape(self, value):\n        arr = self.reshape(value)\n        self.array = arr.array\n\n    @property\n    def ndim(self):\n        return len(self.array.shape())\n\n    @property\n    def ndim(self):\n        return len(self.array.shape())\n\n    def __getitem__(self, key):\n        if type(key) is int:\n            return ndarray(self.array.get(NDArrayIndex.point(key)))\n        if type(key) is slice:\n            start = key.start\n            stop = key.stop\n            step = key.step\n            if start is None:\n                start = 0\n            if stop is None:\n                shape = self.array.shape()\n                if shape[0] == 1:\n                    stop = shape[1]\n                else:\n                    stop = shape[0]\n            if stop - start <= 0:\n                return None\n            if step is None or step == 1:\n                return ndarray(self.array.get(NDArrayIndex.interval(start, stop)))\n            else:\n                return ndarray(self.array.get(NDArrayIndex.interval(start, step, stop)))\n        if type(key) is list:\n            raise NotImplemented(\'Sorry, this type of indexing is not supported yet.\')\n        if type(key) is tuple:\n            key = list(key)\n            shape = self.array.shape()\n            ndim = len(shape)\n            nk = len(key)\n            key += [slice(None)] * (ndim - nk)\n            args = []\n            for i, dim in enumerate(key):\n                if type(dim) is int:\n                    args.append(NDArrayIndex.point(dim))\n                elif type(dim) is slice:\n                    if dim == slice(None):\n                        args.append(NDArrayIndex.all())\n                    else:\n                        start = dim.start\n                        stop = dim.stop\n                        step = dim.step\n                        if start is None:\n                            start = 0\n                        if stop is None:\n                            stop = shape[i]\n                        if stop - start <= 0:\n                            return None\n                        if step is None or step == 1:\n                            args.append(NDArrayIndex.interval(start, stop))\n                        else:\n                            args.append(NDArrayIndex.interval(start, step, stop))\n                elif type(dim) in (list, tuple):\n                    raise NotImplemented(\'Sorry, this type of indexing is not supported yet.\')\n            return ndarray(self.array.get(*args))\n\n    def __setitem__(self, key, other):\n        other = _indarray(other)\n        view = self[key]\n        if view is None:\n            return\n        view = view.array\n        other = broadcast_like(other, view)\n        view.assign(other)\n\n    def __add__(self, other):\n        other = _indarray(other)\n        x, y = broadcast(self.array, other)\n        return ndarray(x.add(y))\n\n    def __sub__(self, other):\n        other = _indarray(other)\n        x, y = broadcast(self.array, other)\n        return ndarray(x.sub(y))\n\n    def __mul__(self, other):\n        other = _indarray(other)\n        x, y = broadcast(self.array, other)\n        return ndarray(x.mul(y))\n\n    def __div__(self, other):\n        other = _indarray(other)\n        x, y = broadcast(self.array, other)\n        return ndarray(x.div(y))\n\n    def __iadd__(self, other):\n        other = _indarray(other)\n        if self.array.shape() == other.shape():\n            self.array = self.array.addi(other)\n        else:\n            x, y = broadcast(self.array, other)\n            self.array = x.add(y)\n        return self\n\n    def __isub__(self, other):\n        other = _indarray(other)\n        if self.array.shape() == other.shape():\n            self.array = self.array.subi(other)\n        else:\n            x, y = broadcast(self.array, other)\n            self.array = x.sub(y)\n        return self\n\n    def __imul__(self, other):\n        other = _indarray(other)\n        if self.array.shape() == other.shape():\n            self.array = self.array.muli(other)\n        else:\n            x, y = broadcast(self.array, other)\n            self.array = x.mul(y)\n        return self\n\n    def __idiv__(self, other):\n        other = _indarray(other)\n        if self.array.shape() == other.shape():\n            self.array = self.array.divi(other)\n        else:\n            x, y = broadcast(self.array, other)\n            self.array = x.div(y)\n        return self\n\n    def __getattr__(self, attr):\n        import ops\n        f = getattr(ops, attr)\n        setattr(ndarray, attr, f)\n        return getattr(self, attr)\n\n    def __int__(self):\n        if self.array.length() == 1:\n            return self.array.getInt(0)\n        raise Exception(\'Applicable only for scalars\')\n\n    def __float__(self):\n        if self.array.length() == 1:\n            return self.array.getDouble(0)\n        raise Exception(\'Applicable only for scalars\')\n\n    @property\n    def T(self):\n        return self.transpose()\n\n\ndef array(*args, **kwargs):\n    return ndarray(*args, **kwargs)\n'"
tests/__init__.py,0,"b""import unittest\n\nif __name__ == '__main__':\n    unittest.main()\n"""
jumpy/ops/__init__.py,0,b'from .array_manip import *\nfrom .linalg import *\n'
jumpy/ops/array_manip.py,0,"b""from .op import op\n\n# Array manipulation routines\n# https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.array-manipulation.html\n\n\n@op\ndef reshape(arr, *args):\n    if len(args) == 1 and type(args) in (list, tuple):\n        args = tuple(args[0])\n    return arr.reshape(*args)\n\n\n@op\ndef transpose(arr):\n    return arr.transpose()\n\n\n@op\ndef ravel(arr):\n    return arr.ravel()\n\n\n@op\ndef flatten(arr):\n    return arr.ravel().dup()\n\n\n@op\ndef moveaxis(arr, source, destination):\n    assert type(source) == type(\n        destination), 'source and destination should be of same type.'\n    shape = arr.shape()\n    ndim = len(shape)\n    x = list(range(ndim))\n    if type(source) is int:\n        if source < 0:\n            source += ndim\n        if destination < 0:\n            destination += ndim\n        z = x.pop(source)\n        x.insert(destination, z)\n        return arr.permute(*x)\n    if type(source) in (list, tuple):\n        source = list(source)\n        destination = list(destination)\n        assert len(source) == len(destination)\n        for src, dst in zip(source, destination):\n            if src < 0:\n                src += ndim\n            if dst < 0:\n                dst += ndim\n            z = x.pop(src)\n            x.insert(dst, z)\n        return arr.permute(*x)\n\n\n@op\ndef permute(arr, *axis):\n    if len(axis) == 1:\n        axis = axis[0]\n    assert set(axis) in [set(list(range(len(axis)))),\n                         set(list(range(len(arr.shape()))))]\n    return arr.permute(*axis)\n\n\n@op\ndef expand_dims(arr, axis):\n    return arr.expandDims(axis)\n\n\n@op\ndef squeeze(arr, axis):\n    shape = arr.shape()\n    if type(axis) in (list, tuple):\n        shape = [shape[i] for i in range(len(shape)) if i not in axis]\n    else:\n        shape.pop(axis)\n    return arr.reshape(*shape)\n\n\n@op\ndef concatenate(arrs, axis):\n    return Nd4j.concat(axis, *arrs)\n\n\n@op\ndef hstack(arrs):\n    return Nd4j.hstack(arrs)\n\n\n@op\ndef vstack(arrs):\n    return Nd4j.vstack(arrs)\n\n\n@op\ndef stack(arrs, axis):\n    for i, arr in enumerate(arrs):\n        shape = arr.shape()\n        shape.insert(axis, 1)\n        arrs[i] = arr.reshape(*shape)\n    return Nd4j.concat(axis, *arrs)\n\n\n@op\ndef tile(arr, reps):\n    if type(reps) is int:\n        return Nd4j.tile(arr, reps)\n    else:\n        return Nd4j.tile(arr, *reps)\n\n\n@op\ndef repeat(arr, repeats, axis=None):\n    if type(repeats) is int:\n        repeats = (repeats,)\n    if axis is None:\n        return arr.repeat(-1, *repeats).reshape(-1)\n    else:\n        return arr.repeat(axis, *repeats)\n"""
jumpy/ops/linalg.py,0,"b'from .op import op\nfrom ..java_classes import *\n\n\n# Linear algebra\n# https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.linalg.html\n\n\n@op\ndef dot(arr, other):\n\treturn arr.mmul(other)\n\n\n@op\ndef tensordot(arr1, arr2, axes=2):\n\tshape1 = arr1.shape()\n\tshape2 = arr2.shape()\n\tif type(axes) is int:\n\t\taxes = [shape1[axes:], shape2[:axes]]\n\telif type(axes) in [list, tuple]:\n\t\taxes = list(axes)\n\t\tfor i in range(2):\n\t\t\tif type(axes[i]) is int:\n\t\t\t\taxes[i] = [axes[i]]\n\treturn Nd4j.tensorMmul(arr1, arr2, axes)\n'"
jumpy/ops/op.py,0,"b""from ..java_classes import *\nfrom ..ndarray import array, ndarray\n\n\n_INDArray_class = 'org.nd4j.linalg.api.ndarray.INDArray'\n\n\ndef _is_nd4j(x):\n\treturn type(x).__name__ == _INDArray_class\n\n\ndef _is_jumpy(x):\n\treturn type(x) == ndarray\n\n'''\nUse the @op decorator over a method to automatically\ntake care of nd4j<->jumpy conversions. e.g:\n\n```python\n\n@op\ndef reshape(arr, shape):\n\t# we are in nd4j space now\n\t# arr is an INDArray instance\n\t# we return a INDArray instance as well\n\treturn arr.reshape(*shape)\n\n\n# use in jumpy space:\n\nx = jp.zeros((2, 2, 3))  # x is jumpy ndarray\ny = reshape(x, (4, 3))  # y is a jumpy ndarray\n\n```\n\nNote that methods with first argument named 'arr'\nwill be automatically bound to ndarray class.\n\n'''\ndef op(f):\n\tdef wrapper(*args, **kwargs):\n\t\targs = list(args)\n\t\tfor i, arg in enumerate(args):\n\t\t\tif _is_jumpy(arg):\n\t\t\t\targs[i] = arg.array\n\t\tfor k in kwargs:\n\t\t\tv = kwargs[k]\n\t\t\tif _is_jumpy(v):\n\t\t\t\tkwargs[k] = v.array\n\t\tout = f(*args, **kwargs)\n\t\tif _is_nd4j(out):\n\t\t\treturn array(out)\n\t\telif type(out) is list:\n\t\t\tfor i, v in enumerate(out):\n\t\t\t\tif _is_nd4j(v):\n\t\t\t\t\tout[i] = array(v)\n\t\t\treturn out\n\t\telif type(out) is tuple:\n\t\t\tout = list(out)\n\t\t\tfor i, v in enumerate(out):\n\t\t\t\tif _is_nd4j(v):\n\t\t\t\t\tout[i] = array(v)\n\t\t\treturn tuple(out)\n\treturn wrapper"""
tests/jumpy/__init__.py,0,b''
tests/jumpy/array_creation.py,4,"b'import unittest\n\nimport jumpy as jp\nimport numpy as np\n\n\nimport gc\ngc.disable()\n\nclass TestArrayCreation(unittest.TestCase):\n    init()\n\n    def test_arr_creation(self):\n        x_np = np.random.random((100, 32, 16))\n        x_jp = jp.array(x_np)\n        x_np_2 = x_jp.numpy()\n        self.assertEquals(x_np.shape, x_jp.shape)\n        self.assertEquals(x_np.shape, x_np_2.shape)\n        x_np = x_np.ravel()\n        x_np_2 = x_np_2.ravel()\n        assertEquals(list(x_np), list(x_np_2))\n'"
