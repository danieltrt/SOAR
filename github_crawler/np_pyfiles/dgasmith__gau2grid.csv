file_path,api_count,code
make_source.py,0,"b""import gau2grid as gg\ngg.c_gen.generate_c_gau2grid(2, path='build_tmp')\n"""
setup.py,0,"b'import os\nimport re\nimport sys\nimport platform\nimport subprocess\nimport versioneer\n\nfrom setuptools import setup, find_packages, Extension\nfrom setuptools.command.build_ext import build_ext\nfrom distutils.version import LooseVersion\n\n\nclass CMakeExtension(Extension):\n    def __init__(self, name, sourcedir=\'\'):\n        Extension.__init__(self, name, sources=[])\n        self.sourcedir = os.path.abspath(sourcedir)\n\n\nclass CMakeBuild(build_ext):\n    def run(self):\n        try:\n            out = subprocess.check_output([\'cmake\', \'--version\'])\n        except OSError:\n            raise RuntimeError(""CMake must be installed to build the following extensions: "" + "", "".join(\n                e.name for e in self.extensions))\n\n        if platform.system() == ""Windows"":\n            cmake_version = LooseVersion(re.search(r\'version\\s*([\\d.]+)\', out.decode()).group(1))\n            if cmake_version < \'3.1.0\':\n                raise RuntimeError(""CMake >= 3.1.0 is required on Windows"")\n\n        for ext in self.extensions:\n            self.build_extension(ext)\n\n    def build_extension(self, ext):\n        global cmake_args\n        bypass_install = cmake_args.pop(\'-DBYPASS_INSTALL\')\n\n        internal_cmake_args = [\'-DPYTHON_EXECUTABLE=\' + sys.executable]\n        internal_cmake_args += [k + ""="" + v for k, v in cmake_args.items() if v]\n\n        cfg = \'Debug\' if self.debug else \'Release\'\n        build_args = [\'--config\', cfg]\n\n        if platform.system() == ""Windows"":\n            if sys.maxsize > 2**32:\n                cmake_args += [\'-A\', \'x64\']\n            build_args += [\'--\', \'/m\']\n        else:\n            internal_cmake_args += [\'-DCMAKE_BUILD_TYPE=\' + cfg]\n            build_args += [\'--\', \'-j2\']\n\n        env = os.environ.copy()\n        env[\'CXXFLAGS\'] = \'{} -DVERSION_INFO=\\\\""{}\\\\""\'.format(env.get(\'CXXFLAGS\', \'\'), self.distribution.get_version())\n        if not os.path.exists(self.build_temp):\n            os.makedirs(self.build_temp)\n        subprocess.check_call([\'cmake\', ext.sourcedir] + internal_cmake_args, cwd=self.build_temp, env=env)\n        subprocess.check_call([\'cmake\', \'--build\', \'.\'] + build_args, cwd=self.build_temp)\n        if not bypass_install:\n            subprocess.check_call([\'cmake\', \'--build\', \'.\', \'--target\', \'install\'], cwd=self.build_temp)\n\n\nif __name__ == ""__main__"":\n\n    # Valid CMake args\n    valid_args = {\n        \'-DCMAKE_BUILD_TYPE\': \'Release\',\n        \'-DENABLE_XHOST\': \'ON\',\n        \'-DMAX_AM\': \'6\',\n        \'-DCMAKE_C_FLAGS\': False,\n        \'-DCMAKE_C_COMPILER\': False,\n        \'-DCMAKE_PREFIX_PATH\': False,\n        \'-DNATIVE_PYTHON_INSTALL_WITH_LIB\': \'OFF\',\n        \'-DBYPASS_INSTALL\': False,\n    }\n    invalid_args = {\n        \'-DBUILD_SHARED_LIBS\': \'ON\',\n        \'-DENABLE_GENERIC\': \'OFF\',\n        \'-DBUILD_FPIC\': \'ON\',\n        \'-DINSTALL_PYMOD\': \'ON\',\n        \'-DNATIVE_PYTHON_INSTALL\': \'ON\'\n    }\n    cmake_args = valid_args.copy()\n    cmake_args.update(invalid_args)\n\n    # Parse out CMake args\n    setup_args = []\n    for arg in sys.argv:\n        if ""-D"" not in arg:\n            setup_args.append(arg)\n            continue\n\n        split_arg = [x.strip() for x in arg.split(\'=\')]\n        if len(split_arg) != 2:\n            raise KeyError(""CMake argument %s not understood."" % arg)\n        key, value = split_arg\n\n        if key not in cmake_args:\n            raise KeyError(""CMake argument %s not understood."" % arg)\n\n        if key in invalid_args:\n            raise KeyError(""CMake argument %s cannot be changed with Python builds."" % key)\n\n        cmake_args[key] = value\n\n    sys.argv = setup_args\n\n    # Build full cmdclass\n    cmdclass = versioneer.get_cmdclass()\n    cmdclass[""build_ext""] = CMakeBuild\n\n    setup(\n        name=\'gau2grid\',\n        version=versioneer.get_version(),\n        description=\'Fast computation of a gaussian and its derivative on a grid.\',\n        author=\'Daniel G. A. Smith\',\n        author_email=\'dgasmith@icloud.com\',\n        url=""https://github.com/dgasmith/gau2grid"",\n        license=\'BSD-3C\',\n        packages=find_packages(),\n        include_package_data=True,\n        ext_modules=[CMakeExtension(\'gau2grid.gg\')],\n        cmdclass=cmdclass,\n        install_requires=[\n            \'numpy>=1.7\',\n        ],\n        extras_require={\n            \'docs\': [\n                \'sphinx==1.2.3\',  # autodoc was broken in 1.3.1\n                \'sphinxcontrib-napoleon\',\n                \'sphinx_rtd_theme\',\n                \'numpydoc\',\n            ],\n            \'tests\': [\n                \'pytest\',\n                \'pytest-cov\',\n            ],\n        },\n        tests_require=[\n            \'pytest\',\n            \'pytest-cov\',\n        ],\n        classifiers=[\n            \'Development Status :: 4 - Beta\',\n            \'Intended Audience :: Science/Research\',\n            \'Programming Language :: Python :: 2.7\',\n            \'Programming Language :: Python :: 3\',\n        ],\n        zip_safe=False,\n    )\n'"
versioneer.py,0,"b'\n# Version: 0.18\n\n""""""The Versioneer - like a rocketeer, but for versions.\n\nThe Versioneer\n==============\n\n* like a rocketeer, but for versions!\n* https://github.com/warner/python-versioneer\n* Brian Warner\n* License: Public Domain\n* Compatible With: python2.6, 2.7, 3.2, 3.3, 3.4, 3.5, 3.6, and pypy\n* [![Latest Version]\n(https://pypip.in/version/versioneer/badge.svg?style=flat)\n](https://pypi.python.org/pypi/versioneer/)\n* [![Build Status]\n(https://travis-ci.org/warner/python-versioneer.png?branch=master)\n](https://travis-ci.org/warner/python-versioneer)\n\nThis is a tool for managing a recorded version number in distutils-based\npython projects. The goal is to remove the tedious and error-prone ""update\nthe embedded version string"" step from your release process. Making a new\nrelease should be as easy as recording a new tag in your version-control\nsystem, and maybe making new tarballs.\n\n\n## Quick Install\n\n* `pip install versioneer` to somewhere to your $PATH\n* add a `[versioneer]` section to your setup.cfg (see below)\n* run `versioneer install` in your source tree, commit the results\n\n## Version Identifiers\n\nSource trees come from a variety of places:\n\n* a version-control system checkout (mostly used by developers)\n* a nightly tarball, produced by build automation\n* a snapshot tarball, produced by a web-based VCS browser, like github\'s\n  ""tarball from tag"" feature\n* a release tarball, produced by ""setup.py sdist"", distributed through PyPI\n\nWithin each source tree, the version identifier (either a string or a number,\nthis tool is format-agnostic) can come from a variety of places:\n\n* ask the VCS tool itself, e.g. ""git describe"" (for checkouts), which knows\n  about recent ""tags"" and an absolute revision-id\n* the name of the directory into which the tarball was unpacked\n* an expanded VCS keyword ($Id$, etc)\n* a `_version.py` created by some earlier build step\n\nFor released software, the version identifier is closely related to a VCS\ntag. Some projects use tag names that include more than just the version\nstring (e.g. ""myproject-1.2"" instead of just ""1.2""), in which case the tool\nneeds to strip the tag prefix to extract the version identifier. For\nunreleased software (between tags), the version identifier should provide\nenough information to help developers recreate the same tree, while also\ngiving them an idea of roughly how old the tree is (after version 1.2, before\nversion 1.3). Many VCS systems can report a description that captures this,\nfor example `git describe --tags --dirty --always` reports things like\n""0.7-1-g574ab98-dirty"" to indicate that the checkout is one revision past the\n0.7 tag, has a unique revision id of ""574ab98"", and is ""dirty"" (it has\nuncommitted changes.\n\nThe version identifier is used for multiple purposes:\n\n* to allow the module to self-identify its version: `myproject.__version__`\n* to choose a name and prefix for a \'setup.py sdist\' tarball\n\n## Theory of Operation\n\nVersioneer works by adding a special `_version.py` file into your source\ntree, where your `__init__.py` can import it. This `_version.py` knows how to\ndynamically ask the VCS tool for version information at import time.\n\n`_version.py` also contains `$Revision$` markers, and the installation\nprocess marks `_version.py` to have this marker rewritten with a tag name\nduring the `git archive` command. As a result, generated tarballs will\ncontain enough information to get the proper version.\n\nTo allow `setup.py` to compute a version too, a `versioneer.py` is added to\nthe top level of your source tree, next to `setup.py` and the `setup.cfg`\nthat configures it. This overrides several distutils/setuptools commands to\ncompute the version when invoked, and changes `setup.py build` and `setup.py\nsdist` to replace `_version.py` with a small static file that contains just\nthe generated version data.\n\n## Installation\n\nSee [INSTALL.md](./INSTALL.md) for detailed installation instructions.\n\n## Version-String Flavors\n\nCode which uses Versioneer can learn about its version string at runtime by\nimporting `_version` from your main `__init__.py` file and running the\n`get_versions()` function. From the ""outside"" (e.g. in `setup.py`), you can\nimport the top-level `versioneer.py` and run `get_versions()`.\n\nBoth functions return a dictionary with different flavors of version\ninformation:\n\n* `[\'version\']`: A condensed version string, rendered using the selected\n  style. This is the most commonly used value for the project\'s version\n  string. The default ""pep440"" style yields strings like `0.11`,\n  `0.11+2.g1076c97`, or `0.11+2.g1076c97.dirty`. See the ""Styles"" section\n  below for alternative styles.\n\n* `[\'full-revisionid\']`: detailed revision identifier. For Git, this is the\n  full SHA1 commit id, e.g. ""1076c978a8d3cfc70f408fe5974aa6c092c949ac"".\n\n* `[\'date\']`: Date and time of the latest `HEAD` commit. For Git, it is the\n  commit date in ISO 8601 format. This will be None if the date is not\n  available.\n\n* `[\'dirty\']`: a boolean, True if the tree has uncommitted changes. Note that\n  this is only accurate if run in a VCS checkout, otherwise it is likely to\n  be False or None\n\n* `[\'error\']`: if the version string could not be computed, this will be set\n  to a string describing the problem, otherwise it will be None. It may be\n  useful to throw an exception in setup.py if this is set, to avoid e.g.\n  creating tarballs with a version string of ""unknown"".\n\nSome variants are more useful than others. Including `full-revisionid` in a\nbug report should allow developers to reconstruct the exact code being tested\n(or indicate the presence of local changes that should be shared with the\ndevelopers). `version` is suitable for display in an ""about"" box or a CLI\n`--version` output: it can be easily compared against release notes and lists\nof bugs fixed in various releases.\n\nThe installer adds the following text to your `__init__.py` to place a basic\nversion in `YOURPROJECT.__version__`:\n\n    from ._version import get_versions\n    __version__ = get_versions()[\'version\']\n    del get_versions\n\n## Styles\n\nThe setup.cfg `style=` configuration controls how the VCS information is\nrendered into a version string.\n\nThe default style, ""pep440"", produces a PEP440-compliant string, equal to the\nun-prefixed tag name for actual releases, and containing an additional ""local\nversion"" section with more detail for in-between builds. For Git, this is\nTAG[+DISTANCE.gHEX[.dirty]] , using information from `git describe --tags\n--dirty --always`. For example ""0.11+2.g1076c97.dirty"" indicates that the\ntree is like the ""1076c97"" commit but has uncommitted changes ("".dirty""), and\nthat this commit is two revisions (""+2"") beyond the ""0.11"" tag. For released\nsoftware (exactly equal to a known tag), the identifier will only contain the\nstripped tag, e.g. ""0.11"".\n\nOther styles are available. See [details.md](details.md) in the Versioneer\nsource tree for descriptions.\n\n## Debugging\n\nVersioneer tries to avoid fatal errors: if something goes wrong, it will tend\nto return a version of ""0+unknown"". To investigate the problem, run `setup.py\nversion`, which will run the version-lookup code in a verbose mode, and will\ndisplay the full contents of `get_versions()` (including the `error` string,\nwhich may help identify what went wrong).\n\n## Known Limitations\n\nSome situations are known to cause problems for Versioneer. This details the\nmost significant ones. More can be found on Github\n[issues page](https://github.com/warner/python-versioneer/issues).\n\n### Subprojects\n\nVersioneer has limited support for source trees in which `setup.py` is not in\nthe root directory (e.g. `setup.py` and `.git/` are *not* siblings). The are\ntwo common reasons why `setup.py` might not be in the root:\n\n* Source trees which contain multiple subprojects, such as\n  [Buildbot](https://github.com/buildbot/buildbot), which contains both\n  ""master"" and ""slave"" subprojects, each with their own `setup.py`,\n  `setup.cfg`, and `tox.ini`. Projects like these produce multiple PyPI\n  distributions (and upload multiple independently-installable tarballs).\n* Source trees whose main purpose is to contain a C library, but which also\n  provide bindings to Python (and perhaps other langauges) in subdirectories.\n\nVersioneer will look for `.git` in parent directories, and most operations\nshould get the right version string. However `pip` and `setuptools` have bugs\nand implementation details which frequently cause `pip install .` from a\nsubproject directory to fail to find a correct version string (so it usually\ndefaults to `0+unknown`).\n\n`pip install --editable .` should work correctly. `setup.py install` might\nwork too.\n\nPip-8.1.1 is known to have this problem, but hopefully it will get fixed in\nsome later version.\n\n[Bug #38](https://github.com/warner/python-versioneer/issues/38) is tracking\nthis issue. The discussion in\n[PR #61](https://github.com/warner/python-versioneer/pull/61) describes the\nissue from the Versioneer side in more detail.\n[pip PR#3176](https://github.com/pypa/pip/pull/3176) and\n[pip PR#3615](https://github.com/pypa/pip/pull/3615) contain work to improve\npip to let Versioneer work correctly.\n\nVersioneer-0.16 and earlier only looked for a `.git` directory next to the\n`setup.cfg`, so subprojects were completely unsupported with those releases.\n\n### Editable installs with setuptools <= 18.5\n\n`setup.py develop` and `pip install --editable .` allow you to install a\nproject into a virtualenv once, then continue editing the source code (and\ntest) without re-installing after every change.\n\n""Entry-point scripts"" (`setup(entry_points={""console_scripts"": ..})`) are a\nconvenient way to specify executable scripts that should be installed along\nwith the python package.\n\nThese both work as expected when using modern setuptools. When using\nsetuptools-18.5 or earlier, however, certain operations will cause\n`pkg_resources.DistributionNotFound` errors when running the entrypoint\nscript, which must be resolved by re-installing the package. This happens\nwhen the install happens with one version, then the egg_info data is\nregenerated while a different version is checked out. Many setup.py commands\ncause egg_info to be rebuilt (including `sdist`, `wheel`, and installing into\na different virtualenv), so this can be surprising.\n\n[Bug #83](https://github.com/warner/python-versioneer/issues/83) describes\nthis one, but upgrading to a newer version of setuptools should probably\nresolve it.\n\n### Unicode version strings\n\nWhile Versioneer works (and is continually tested) with both Python 2 and\nPython 3, it is not entirely consistent with bytes-vs-unicode distinctions.\nNewer releases probably generate unicode version strings on py2. It\'s not\nclear that this is wrong, but it may be surprising for applications when then\nwrite these strings to a network connection or include them in bytes-oriented\nAPIs like cryptographic checksums.\n\n[Bug #71](https://github.com/warner/python-versioneer/issues/71) investigates\nthis question.\n\n\n## Updating Versioneer\n\nTo upgrade your project to a new release of Versioneer, do the following:\n\n* install the new Versioneer (`pip install -U versioneer` or equivalent)\n* edit `setup.cfg`, if necessary, to include any new configuration settings\n  indicated by the release notes. See [UPGRADING](./UPGRADING.md) for details.\n* re-run `versioneer install` in your source tree, to replace\n  `SRC/_version.py`\n* commit any changed files\n\n## Future Directions\n\nThis tool is designed to make it easily extended to other version-control\nsystems: all VCS-specific components are in separate directories like\nsrc/git/ . The top-level `versioneer.py` script is assembled from these\ncomponents by running make-versioneer.py . In the future, make-versioneer.py\nwill take a VCS name as an argument, and will construct a version of\n`versioneer.py` that is specific to the given VCS. It might also take the\nconfiguration arguments that are currently provided manually during\ninstallation by editing setup.py . Alternatively, it might go the other\ndirection and include code from all supported VCS systems, reducing the\nnumber of intermediate scripts.\n\n\n## License\n\nTo make Versioneer easier to embed, all its code is dedicated to the public\ndomain. The `_version.py` that it creates is also in the public domain.\nSpecifically, both are released under the Creative Commons ""Public Domain\nDedication"" license (CC0-1.0), as described in\nhttps://creativecommons.org/publicdomain/zero/1.0/ .\n\n""""""\n\nfrom __future__ import print_function\ntry:\n    import configparser\nexcept ImportError:\n    import ConfigParser as configparser\nimport errno\nimport json\nimport os\nimport re\nimport subprocess\nimport sys\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_root():\n    """"""Get the project root directory.\n\n    We require that all commands are run from the project root, i.e. the\n    directory that contains setup.py, setup.cfg, and versioneer.py .\n    """"""\n    root = os.path.realpath(os.path.abspath(os.getcwd()))\n    setup_py = os.path.join(root, ""setup.py"")\n    versioneer_py = os.path.join(root, ""versioneer.py"")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        # allow \'python path/to/setup.py COMMAND\'\n        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))\n        setup_py = os.path.join(root, ""setup.py"")\n        versioneer_py = os.path.join(root, ""versioneer.py"")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        err = (""Versioneer was unable to run the project root directory. ""\n               ""Versioneer requires setup.py to be executed from ""\n               ""its immediate directory (like \'python setup.py COMMAND\'), ""\n               ""or in a way that lets it use sys.argv[0] to find the root ""\n               ""(like \'python path/to/setup.py COMMAND\')."")\n        raise VersioneerBadRootError(err)\n    try:\n        # Certain runtime workflows (setup.py install/develop in a setuptools\n        # tree) execute all dependencies in a single python process, so\n        # ""versioneer"" may be imported multiple times, and python\'s shared\n        # module-import table will cache the first one. So we can\'t use\n        # os.path.dirname(__file__), as that will find whichever\n        # versioneer.py was first imported, even in later projects.\n        me = os.path.realpath(os.path.abspath(__file__))\n        me_dir = os.path.normcase(os.path.splitext(me)[0])\n        vsr_dir = os.path.normcase(os.path.splitext(versioneer_py)[0])\n        if me_dir != vsr_dir:\n            print(""Warning: build in %s is using versioneer.py from %s""\n                  % (os.path.dirname(me), versioneer_py))\n    except NameError:\n        pass\n    return root\n\n\ndef get_config_from_root(root):\n    """"""Read the project setup.cfg file to determine Versioneer config.""""""\n    # This might raise EnvironmentError (if setup.cfg is missing), or\n    # configparser.NoSectionError (if it lacks a [versioneer] section), or\n    # configparser.NoOptionError (if it lacks ""VCS=""). See the docstring at\n    # the top of versioneer.py for instructions on writing your setup.cfg .\n    setup_cfg = os.path.join(root, ""setup.cfg"")\n    parser = configparser.SafeConfigParser()\n    with open(setup_cfg, ""r"") as f:\n        parser.readfp(f)\n    VCS = parser.get(""versioneer"", ""VCS"")  # mandatory\n\n    def get(parser, name):\n        if parser.has_option(""versioneer"", name):\n            return parser.get(""versioneer"", name)\n        return None\n    cfg = VersioneerConfig()\n    cfg.VCS = VCS\n    cfg.style = get(parser, ""style"") or """"\n    cfg.versionfile_source = get(parser, ""versionfile_source"")\n    cfg.versionfile_build = get(parser, ""versionfile_build"")\n    cfg.tag_prefix = get(parser, ""tag_prefix"")\n    if cfg.tag_prefix in (""\'\'"", \'""""\'):\n        cfg.tag_prefix = """"\n    cfg.parentdir_prefix = get(parser, ""parentdir_prefix"")\n    cfg.verbose = get(parser, ""verbose"")\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\n# these dictionaries contain VCS-specific tools\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %s"" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %s"" % (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %s (error)"" % dispcmd)\n            print(""stdout was %s"" % stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\nLONG_VERSION_PY[\'git\'] = \'\'\'\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.18 (https://github.com/warner/python-versioneer)\n\n""""""Git implementation of _version.py.""""""\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    """"""Get the keywords needed to look up the version information.""""""\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = ""%(DOLLAR)sFormat:%%d%(DOLLAR)s""\n    git_full = ""%(DOLLAR)sFormat:%%H%(DOLLAR)s""\n    git_date = ""%(DOLLAR)sFormat:%%ci%(DOLLAR)s""\n    keywords = {""refnames"": git_refnames, ""full"": git_full, ""date"": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_config():\n    """"""Create, populate and return the VersioneerConfig() object.""""""\n    # these strings are filled in when \'setup.py versioneer\' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = ""git""\n    cfg.style = ""%(STYLE)s""\n    cfg.tag_prefix = ""%(TAG_PREFIX)s""\n    cfg.parentdir_prefix = ""%(PARENTDIR_PREFIX)s""\n    cfg.versionfile_source = ""%(VERSIONFILE_SOURCE)s""\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %%s"" %% dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %%s"" %% (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %%s (error)"" %% dispcmd)\n            print(""stdout was %%s"" %% stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {""version"": dirname[len(parentdir_prefix):],\n                    ""full-revisionid"": None,\n                    ""dirty"": False, ""error"": None, ""date"": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %%s but none started with prefix %%s"" %%\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %%d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%%s\', no digits"" %% "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %%s"" %% "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %%s"" %% r)\n            return {""version"": r,\n                    ""full-revisionid"": keywords[""full""].strip(),\n                    ""dirty"": False, ""error"": None,\n                    ""date"": date}\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {""version"": ""0+unknown"",\n            ""full-revisionid"": keywords[""full""].strip(),\n            ""dirty"": False, ""error"": ""no suitable tags"", ""date"": None}\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n                          hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %%s not under git control"" %% root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty"",\n                                          ""--always"", ""--long"",\n                                          ""--match"", ""%%s*"" %% tag_prefix],\n                                   cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%%s\'""\n                               %% describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%%s\' doesn\'t start with prefix \'%%s\'""\n                print(fmt %% (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%%s\' doesn\'t start with prefix \'%%s\'""\n                               %% (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n                                    cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%%ci"", ""HEAD""],\n                       cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%%d.g%%s"" %% (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%%d.g%%s"" %% (pieces[""distance""],\n                                          pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%%d"" %% pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%%d"" %% pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%%d"" %% pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%%s"" %% pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%%d"" %% pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%%s"" %% pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%%d"" %% pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%%d"" %% pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%%d-g%%s"" %% (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%%d-g%%s"" %% (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {""version"": ""unknown"",\n                ""full-revisionid"": pieces.get(""long""),\n                ""dirty"": None,\n                ""error"": pieces[""error""],\n                ""date"": None}\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%%s\'"" %% style)\n\n    return {""version"": rendered, ""full-revisionid"": pieces[""long""],\n            ""dirty"": pieces[""dirty""], ""error"": None,\n            ""date"": pieces.get(""date"")}\n\n\ndef get_versions():\n    """"""Get version information or return default if unable to do so.""""""\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don\'t do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split(\'/\'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {""version"": ""0+unknown"", ""full-revisionid"": None,\n                ""dirty"": None,\n                ""error"": ""unable to find root of source tree"",\n                ""date"": None}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {""version"": ""0+unknown"", ""full-revisionid"": None,\n            ""dirty"": None,\n            ""error"": ""unable to compute version"", ""date"": None}\n\'\'\'\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %s"" % "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %s"" % r)\n            return {""version"": r,\n                    ""full-revisionid"": keywords[""full""].strip(),\n                    ""dirty"": False, ""error"": None,\n                    ""date"": date}\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {""version"": ""0+unknown"",\n            ""full-revisionid"": keywords[""full""].strip(),\n            ""dirty"": False, ""error"": ""no suitable tags"", ""date"": None}\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n                          hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %s not under git control"" % root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty"",\n                                          ""--always"", ""--long"",\n                                          ""--match"", ""%s*"" % tag_prefix],\n                                   cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%s\'""\n                               % describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                print(fmt % (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                               % (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n                                    cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""],\n                       cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef do_vcs_install(manifest_in, versionfile_source, ipy):\n    """"""Git-specific installation logic for Versioneer.\n\n    For Git, this means creating/changing .gitattributes to mark _version.py\n    for export-subst keyword substitution.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n    files = [manifest_in, versionfile_source]\n    if ipy:\n        files.append(ipy)\n    try:\n        me = __file__\n        if me.endswith("".pyc"") or me.endswith("".pyo""):\n            me = os.path.splitext(me)[0] + "".py""\n        versioneer_file = os.path.relpath(me)\n    except NameError:\n        versioneer_file = ""versioneer.py""\n    files.append(versioneer_file)\n    present = False\n    try:\n        f = open("".gitattributes"", ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(versionfile_source):\n                if ""export-subst"" in line.strip().split()[1:]:\n                    present = True\n        f.close()\n    except EnvironmentError:\n        pass\n    if not present:\n        f = open("".gitattributes"", ""a+"")\n        f.write(""%s export-subst\\n"" % versionfile_source)\n        f.close()\n        files.append("".gitattributes"")\n    run_command(GITS, [""add"", ""--""] + files)\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {""version"": dirname[len(parentdir_prefix):],\n                    ""full-revisionid"": None,\n                    ""dirty"": False, ""error"": None, ""date"": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %s but none started with prefix %s"" %\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\nSHORT_VERSION_PY = """"""\n# This file was generated by \'versioneer.py\' (0.18) from\n# revision-control system data, or from the parent directory name of an\n# unpacked source archive. Distribution tarballs contain a pre-generated copy\n# of this file.\n\nimport json\n\nversion_json = \'\'\'\n%s\n\'\'\'  # END VERSION_JSON\n\n\ndef get_versions():\n    return json.loads(version_json)\n""""""\n\n\ndef versions_from_file(filename):\n    """"""Try to determine the version from _version.py if present.""""""\n    try:\n        with open(filename) as f:\n            contents = f.read()\n    except EnvironmentError:\n        raise NotThisMethod(""unable to read _version.py"")\n    mo = re.search(r""version_json = \'\'\'\\n(.*)\'\'\'  # END VERSION_JSON"",\n                   contents, re.M | re.S)\n    if not mo:\n        mo = re.search(r""version_json = \'\'\'\\r\\n(.*)\'\'\'  # END VERSION_JSON"",\n                       contents, re.M | re.S)\n    if not mo:\n        raise NotThisMethod(""no version_json in _version.py"")\n    return json.loads(mo.group(1))\n\n\ndef write_to_version_file(filename, versions):\n    """"""Write the given version number to the given _version.py file.""""""\n    os.unlink(filename)\n    contents = json.dumps(versions, sort_keys=True,\n                          indent=1, separators=("","", "": ""))\n    with open(filename, ""w"") as f:\n        f.write(SHORT_VERSION_PY % contents)\n\n    print(""set %s to \'%s\'"" % (filename, versions[""version""]))\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%d.g%s"" % (pieces[""distance""],\n                                          pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%d"" % pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%d"" % pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%s"" % pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%s"" % pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {""version"": ""unknown"",\n                ""full-revisionid"": pieces.get(""long""),\n                ""dirty"": None,\n                ""error"": pieces[""error""],\n                ""date"": None}\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%s\'"" % style)\n\n    return {""version"": rendered, ""full-revisionid"": pieces[""long""],\n            ""dirty"": pieces[""dirty""], ""error"": None,\n            ""date"": pieces.get(""date"")}\n\n\nclass VersioneerBadRootError(Exception):\n    """"""The project root directory is unknown or missing key files.""""""\n\n\ndef get_versions(verbose=False):\n    """"""Get the project version from whatever source is available.\n\n    Returns dict with two keys: \'version\' and \'full\'.\n    """"""\n    if ""versioneer"" in sys.modules:\n        # see the discussion in cmdclass.py:get_cmdclass()\n        del sys.modules[""versioneer""]\n\n    root = get_root()\n    cfg = get_config_from_root(root)\n\n    assert cfg.VCS is not None, ""please set [versioneer]VCS= in setup.cfg""\n    handlers = HANDLERS.get(cfg.VCS)\n    assert handlers, ""unrecognized VCS \'%s\'"" % cfg.VCS\n    verbose = verbose or cfg.verbose\n    assert cfg.versionfile_source is not None, \\\n        ""please set versioneer.versionfile_source""\n    assert cfg.tag_prefix is not None, ""please set versioneer.tag_prefix""\n\n    versionfile_abs = os.path.join(root, cfg.versionfile_source)\n\n    # extract version from first of: _version.py, VCS command (e.g. \'git\n    # describe\'), parentdir. This is meant to work for developers using a\n    # source checkout, for users of a tarball created by \'setup.py sdist\',\n    # and for users of a tarball/zipball created by \'git archive\' or github\'s\n    # download-from-tag feature or the equivalent in other VCSes.\n\n    get_keywords_f = handlers.get(""get_keywords"")\n    from_keywords_f = handlers.get(""keywords"")\n    if get_keywords_f and from_keywords_f:\n        try:\n            keywords = get_keywords_f(versionfile_abs)\n            ver = from_keywords_f(keywords, cfg.tag_prefix, verbose)\n            if verbose:\n                print(""got version from expanded keyword %s"" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        ver = versions_from_file(versionfile_abs)\n        if verbose:\n            print(""got version from file %s %s"" % (versionfile_abs, ver))\n        return ver\n    except NotThisMethod:\n        pass\n\n    from_vcs_f = handlers.get(""pieces_from_vcs"")\n    if from_vcs_f:\n        try:\n            pieces = from_vcs_f(cfg.tag_prefix, root, verbose)\n            ver = render(pieces, cfg.style)\n            if verbose:\n                print(""got version from VCS %s"" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        if cfg.parentdir_prefix:\n            ver = versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n            if verbose:\n                print(""got version from parentdir %s"" % ver)\n            return ver\n    except NotThisMethod:\n        pass\n\n    if verbose:\n        print(""unable to compute version"")\n\n    return {""version"": ""0+unknown"", ""full-revisionid"": None,\n            ""dirty"": None, ""error"": ""unable to compute version"",\n            ""date"": None}\n\n\ndef get_version():\n    """"""Get the short version string for this project.""""""\n    return get_versions()[""version""]\n\n\ndef get_cmdclass():\n    """"""Get the custom setuptools/distutils subclasses used by Versioneer.""""""\n    if ""versioneer"" in sys.modules:\n        del sys.modules[""versioneer""]\n        # this fixes the ""python setup.py develop"" case (also \'install\' and\n        # \'easy_install .\'), in which subdependencies of the main project are\n        # built (using setup.py bdist_egg) in the same python process. Assume\n        # a main project A and a dependency B, which use different versions\n        # of Versioneer. A\'s setup.py imports A\'s Versioneer, leaving it in\n        # sys.modules by the time B\'s setup.py is executed, causing B to run\n        # with the wrong versioneer. Setuptools wraps the sub-dep builds in a\n        # sandbox that restores sys.modules to it\'s pre-build state, so the\n        # parent is protected against the child\'s ""import versioneer"". By\n        # removing ourselves from sys.modules here, before the child build\n        # happens, we protect the child from the parent\'s versioneer too.\n        # Also see https://github.com/warner/python-versioneer/issues/52\n\n    cmds = {}\n\n    # we add ""version"" to both distutils and setuptools\n    from distutils.core import Command\n\n    class cmd_version(Command):\n        description = ""report generated version string""\n        user_options = []\n        boolean_options = []\n\n        def initialize_options(self):\n            pass\n\n        def finalize_options(self):\n            pass\n\n        def run(self):\n            vers = get_versions(verbose=True)\n            print(""Version: %s"" % vers[""version""])\n            print("" full-revisionid: %s"" % vers.get(""full-revisionid""))\n            print("" dirty: %s"" % vers.get(""dirty""))\n            print("" date: %s"" % vers.get(""date""))\n            if vers[""error""]:\n                print("" error: %s"" % vers[""error""])\n    cmds[""version""] = cmd_version\n\n    # we override ""build_py"" in both distutils and setuptools\n    #\n    # most invocation pathways end up running build_py:\n    #  distutils/build -> build_py\n    #  distutils/install -> distutils/build ->..\n    #  setuptools/bdist_wheel -> distutils/install ->..\n    #  setuptools/bdist_egg -> distutils/install_lib -> build_py\n    #  setuptools/install -> bdist_egg ->..\n    #  setuptools/develop -> ?\n    #  pip install:\n    #   copies source tree to a tempdir before running egg_info/etc\n    #   if .git isn\'t copied too, \'git describe\' will fail\n    #   then does setup.py bdist_wheel, or sometimes setup.py install\n    #  setup.py egg_info -> ?\n\n    # we override different ""build_py"" commands for both environments\n    if ""setuptools"" in sys.modules:\n        from setuptools.command.build_py import build_py as _build_py\n    else:\n        from distutils.command.build_py import build_py as _build_py\n\n    class cmd_build_py(_build_py):\n        def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_py.run(self)\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if cfg.versionfile_build:\n                target_versionfile = os.path.join(self.build_lib,\n                                                  cfg.versionfile_build)\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n    cmds[""build_py""] = cmd_build_py\n\n    if ""cx_Freeze"" in sys.modules:  # cx_freeze enabled?\n        from cx_Freeze.dist import build_exe as _build_exe\n        # nczeczulin reports that py2exe won\'t like the pep440-style string\n        # as FILEVERSION, but it can be used for PRODUCTVERSION, e.g.\n        # setup(console=[{\n        #   ""version"": versioneer.get_version().split(""+"", 1)[0], # FILEVERSION\n        #   ""product_version"": versioneer.get_version(),\n        #   ...\n\n        class cmd_build_exe(_build_exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _build_exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, ""w"") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {""DOLLAR"": ""$"",\n                             ""STYLE"": cfg.style,\n                             ""TAG_PREFIX"": cfg.tag_prefix,\n                             ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                             ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                             })\n        cmds[""build_exe""] = cmd_build_exe\n        del cmds[""build_py""]\n\n    if \'py2exe\' in sys.modules:  # py2exe enabled?\n        try:\n            from py2exe.distutils_buildexe import py2exe as _py2exe  # py3\n        except ImportError:\n            from py2exe.build_exe import py2exe as _py2exe  # py2\n\n        class cmd_py2exe(_py2exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _py2exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, ""w"") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {""DOLLAR"": ""$"",\n                             ""STYLE"": cfg.style,\n                             ""TAG_PREFIX"": cfg.tag_prefix,\n                             ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                             ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                             })\n        cmds[""py2exe""] = cmd_py2exe\n\n    # we override different ""sdist"" commands for both environments\n    if ""setuptools"" in sys.modules:\n        from setuptools.command.sdist import sdist as _sdist\n    else:\n        from distutils.command.sdist import sdist as _sdist\n\n    class cmd_sdist(_sdist):\n        def run(self):\n            versions = get_versions()\n            self._versioneer_generated_versions = versions\n            # unless we update this, the command will keep using the old\n            # version\n            self.distribution.metadata.version = versions[""version""]\n            return _sdist.run(self)\n\n        def make_release_tree(self, base_dir, files):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            _sdist.make_release_tree(self, base_dir, files)\n            # now locate _version.py in the new base_dir directory\n            # (remembering that it may be a hardlink) and replace it with an\n            # updated value\n            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)\n            print(""UPDATING %s"" % target_versionfile)\n            write_to_version_file(target_versionfile,\n                                  self._versioneer_generated_versions)\n    cmds[""sdist""] = cmd_sdist\n\n    return cmds\n\n\nCONFIG_ERROR = """"""\nsetup.cfg is missing the necessary Versioneer configuration. You need\na section like:\n\n [versioneer]\n VCS = git\n style = pep440\n versionfile_source = src/myproject/_version.py\n versionfile_build = myproject/_version.py\n tag_prefix =\n parentdir_prefix = myproject-\n\nYou will also need to edit your setup.py to use the results:\n\n import versioneer\n setup(version=versioneer.get_version(),\n       cmdclass=versioneer.get_cmdclass(), ...)\n\nPlease read the docstring in ./versioneer.py for configuration instructions,\nedit setup.cfg, and re-run the installer or \'python versioneer.py setup\'.\n""""""\n\nSAMPLE_CONFIG = """"""\n# See the docstring in versioneer.py for instructions. Note that you must\n# re-run \'versioneer.py setup\' after changing this section, and commit the\n# resulting files.\n\n[versioneer]\n#VCS = git\n#style = pep440\n#versionfile_source =\n#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\n""""""\n\nINIT_PY_SNIPPET = """"""\nfrom ._version import get_versions\n__version__ = get_versions()[\'version\']\ndel get_versions\n""""""\n\n\ndef do_setup():\n    """"""Main VCS-independent setup function for installing Versioneer.""""""\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (EnvironmentError, configparser.NoSectionError,\n            configparser.NoOptionError) as e:\n        if isinstance(e, (EnvironmentError, configparser.NoSectionError)):\n            print(""Adding sample versioneer config to setup.cfg"",\n                  file=sys.stderr)\n            with open(os.path.join(root, ""setup.cfg""), ""a"") as f:\n                f.write(SAMPLE_CONFIG)\n        print(CONFIG_ERROR, file=sys.stderr)\n        return 1\n\n    print("" creating %s"" % cfg.versionfile_source)\n    with open(cfg.versionfile_source, ""w"") as f:\n        LONG = LONG_VERSION_PY[cfg.VCS]\n        f.write(LONG % {""DOLLAR"": ""$"",\n                        ""STYLE"": cfg.style,\n                        ""TAG_PREFIX"": cfg.tag_prefix,\n                        ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                        ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                        })\n\n    ipy = os.path.join(os.path.dirname(cfg.versionfile_source),\n                       ""__init__.py"")\n    if os.path.exists(ipy):\n        try:\n            with open(ipy, ""r"") as f:\n                old = f.read()\n        except EnvironmentError:\n            old = """"\n        if INIT_PY_SNIPPET not in old:\n            print("" appending to %s"" % ipy)\n            with open(ipy, ""a"") as f:\n                f.write(INIT_PY_SNIPPET)\n        else:\n            print("" %s unmodified"" % ipy)\n    else:\n        print("" %s doesn\'t exist, ok"" % ipy)\n        ipy = None\n\n    # Make sure both the top-level ""versioneer.py"" and versionfile_source\n    # (PKG/_version.py, used by runtime code) are in MANIFEST.in, so\n    # they\'ll be copied into source distributions. Pip won\'t be able to\n    # install the package without this.\n    manifest_in = os.path.join(root, ""MANIFEST.in"")\n    simple_includes = set()\n    try:\n        with open(manifest_in, ""r"") as f:\n            for line in f:\n                if line.startswith(""include ""):\n                    for include in line.split()[1:]:\n                        simple_includes.add(include)\n    except EnvironmentError:\n        pass\n    # That doesn\'t cover everything MANIFEST.in can do\n    # (http://docs.python.org/2/distutils/sourcedist.html#commands), so\n    # it might give some false negatives. Appending redundant \'include\'\n    # lines is safe, though.\n    if ""versioneer.py"" not in simple_includes:\n        print("" appending \'versioneer.py\' to MANIFEST.in"")\n        with open(manifest_in, ""a"") as f:\n            f.write(""include versioneer.py\\n"")\n    else:\n        print("" \'versioneer.py\' already in MANIFEST.in"")\n    if cfg.versionfile_source not in simple_includes:\n        print("" appending versionfile_source (\'%s\') to MANIFEST.in"" %\n              cfg.versionfile_source)\n        with open(manifest_in, ""a"") as f:\n            f.write(""include %s\\n"" % cfg.versionfile_source)\n    else:\n        print("" versionfile_source already in MANIFEST.in"")\n\n    # Make VCS-specific changes. For git, this means creating/changing\n    # .gitattributes to mark _version.py for export-subst keyword\n    # substitution.\n    do_vcs_install(manifest_in, cfg.versionfile_source, ipy)\n    return 0\n\n\ndef scan_setup_py():\n    """"""Validate the contents of setup.py against Versioneer\'s expectations.""""""\n    found = set()\n    setters = False\n    errors = 0\n    with open(""setup.py"", ""r"") as f:\n        for line in f.readlines():\n            if ""import versioneer"" in line:\n                found.add(""import"")\n            if ""versioneer.get_cmdclass()"" in line:\n                found.add(""cmdclass"")\n            if ""versioneer.get_version()"" in line:\n                found.add(""get_version"")\n            if ""versioneer.VCS"" in line:\n                setters = True\n            if ""versioneer.versionfile_source"" in line:\n                setters = True\n    if len(found) != 3:\n        print("""")\n        print(""Your setup.py appears to be missing some important items"")\n        print(""(but I might be wrong). Please make sure it has something"")\n        print(""roughly like the following:"")\n        print("""")\n        print("" import versioneer"")\n        print("" setup( version=versioneer.get_version(),"")\n        print(""        cmdclass=versioneer.get_cmdclass(),  ...)"")\n        print("""")\n        errors += 1\n    if setters:\n        print(""You should remove lines like \'versioneer.VCS = \' and"")\n        print(""\'versioneer.versionfile_source = \' . This configuration"")\n        print(""now lives in setup.cfg, and should be removed from setup.py"")\n        print("""")\n        errors += 1\n    return errors\n\n\nif __name__ == ""__main__"":\n    cmd = sys.argv[1]\n    if cmd == ""setup"":\n        errors = do_setup()\n        errors += scan_setup_py()\n        if errors:\n            sys.exit(1)\n'"
gau2grid/RSH.py,1,"b'""""""\nCartesian to regular solid harmonics conversion code.\n""""""\n\nimport decimal\nimport os\nimport pickle\nimport platform\n\nimport numpy as np\n\nfrom . import order\nfrom . import utility\n\n_MAX_AM = 17\n_DECIMAL_PREC = 60\n_saved_rsh_coefs = {}\n_saved_factorials = {}\n\n\ndef _factorial(n):\n    decimal.getcontext().prec = _DECIMAL_PREC\n    if n in _saved_factorials:\n        return _saved_factorials[n]\n\n    if n == 0:\n        return decimal.Decimal(""1.0"")\n    else:\n        return n * _factorial(n - 1)\n\n\nclass RSH_Memoize(object):\n    """"""\n    Simple memoize class for RSH_coefs which is quite expensive\n    """"""\n\n    def __init__(self, func):\n        self.func = func\n        self.mem = {}\n\n    def __call__(self, AM, **kwargs):\n\n        # Bypass Memoize for testing\n        if kwargs.get(""force_call"", False):\n            return self.func(AM)\n\n        if AM not in self.mem:\n            self.mem[AM] = self.func(AM)\n\n        return self.mem[AM]\n\n\n@RSH_Memoize\ndef _cart_to_RSH_coeffs_gen(l):\n    """"""\n    Generates a coefficients [ coef, x power, y power, z power ] for each component of\n    a regular solid harmonic (in terms of raw Cartesians) with angular momentum l.\n\n    See eq. 23 of ACS, F. C. Pickard, H. F. Schaefer and B. R. Brooks, JCP, 140, 184101 (2014)\n\n    Returns coeffs with order 0, +1, -1, +2, -2, ...\n    """"""\n\n    # Arbitrary precision math with 50 decimal places\n    decimal.getcontext().prec = _DECIMAL_PREC\n\n    terms = []\n    for m in range(l + 1):\n        thisterm = {}\n        p1 = ((_factorial(l - m)) / (_factorial(l + m))).sqrt() * ((_factorial(m)) / (2**l))\n        if m:\n            p1 *= decimal.Decimal(""2.0"").sqrt()\n\n        # Loop over cartesian components\n        for lz in range(l + 1):\n            for ly in range(l - lz + 1):\n\n                lx = l - ly - lz\n                xyz = lx, ly, lz\n                j = int((lx + ly - m) / 2)\n                if (lx + ly - m) % 2 == 1 or j < 0:\n                    continue\n\n                # P2\n                p2 = decimal.Decimal(0.0)\n                for i in range(int((l - m) / 2) + 1):\n                    if i >= j:\n                        p2 += (-1)**i * _factorial(2 * l - 2 * i) / (_factorial(l - i) * _factorial(i - j) *\n                                                                     _factorial(l - m - 2 * i))\n\n                # P3\n                p3 = decimal.Decimal(0.0)\n                for k in range(j + 1):\n                    if (j >= k) and (lx >= 2 * k) and (m + 2 * k >= lx):\n                        p3 += (-1)**k / (_factorial(j - k) * _factorial(k) * _factorial(lx - 2 * k) *\n                                         _factorial(m - lx + 2 * k))\n\n                p = p1 * p2 * p3\n\n                # Add in part if not already present\n                if xyz not in thisterm:\n                    thisterm[xyz] = [decimal.Decimal(0.0), decimal.Decimal(0.0)]\n\n                # Add the two components\n                if (m - lx) % 2:\n                    # imaginary\n                    sign = decimal.Decimal(-1.0)**decimal.Decimal((m - lx - 1) / 2.0)\n                    thisterm[xyz][1] += sign * p\n                else:\n                    # real\n                    sign = decimal.Decimal(-1.0)**decimal.Decimal((m - lx) / 2.0)\n                    thisterm[xyz][0] += sign * p\n\n        tmp_R = []\n        tmp_I = []\n        for k, v in thisterm.items():\n            if abs(v[0]) > 0:\n                tmp_R.append((k, v[0]))\n            if abs(v[1]) > 0:\n                tmp_I.append((k, v[1]))\n\n        if m == 0:\n            # name_R = ""R_%d%d"" % (l, m)\n            terms.append(tmp_R)\n        else:\n            # name_R = ""R_%d%dc"" % (l, m)\n            # name_I = ""R_%d%ds"" % (l, m)\n            terms.append(tmp_R)\n            terms.append(tmp_I)\n            # terms[name_R] = tmp_R\n            # terms[name_I] = tmp_I\n\n        # for k, v in terms.items():\n        #     print(k, v)\n\n    return terms\n\n\ndef cart_to_RSH_coeffs(L, order=""gaussian"", force_call=False):\n    """"""\n    Allows coefficients either to be generated or pulled from disk\n\n    Allowed orders:\n        ""gaussian"":\n            R_0, R^+_1, R^-_1, ..., R^+_l, R^-_l\n        ""CCA"":\n            R^-_(l), R^-_(l-1), ..., R_0, ..., R^+_(l-1), R^+_l\n    """"""\n\n    # Gen the coefficients (may be memoized)\n    data = _cart_to_RSH_coeffs_gen(L, force_call=force_call)\n\n    if order.lower() == ""gaussian"":\n        return data\n    elif order.lower() == ""cca"":\n        ret = []\n\n        # Add negative\n        for l in range(L):\n            ret.append(data[2 + l * 2])\n\n        # Reverse so we get (-L, 0) not (0, L)\n        ret.reverse()\n\n        # Add in zero\n        ret.append(data[0])\n\n        # Add positive\n        for l in range(L):\n            ret.append(data[1 + l * 2])\n\n        return ret\n\n    else:\n        raise KeyError(""Order \'%s\' not understood"" % order)\n\n\ndef cart_to_spherical_transform(data, L, cartesian_order, spherical_order):\n    """"""\n    Transforms a cartesian x points matrix into a spherical x points matrix.\n    """"""\n\n    cartesian_order = {x[1:]: x[0] for x in order.cartesian_order_factory(L, cartesian_order)}\n    RSH_coefs = cart_to_RSH_coeffs(L, order=spherical_order)\n\n    nspherical = len(RSH_coefs)\n    ret = np.zeros((nspherical, data.shape[1]))\n\n    idx = 0\n    for spherical in RSH_coefs:\n        for cart_index, scale in spherical:\n            ret[idx] += float(scale) * data[cartesian_order[cart_index]]\n        idx += 1\n\n    return ret\n\n\ndef transformation_c_generator(cg, L, cartesian_order, spherical_order, function_name="""", prefix=None, align=32):\n    """"""\n    Builds a conversion from cartesian to spherical coordinates in C\n    """"""\n\n    if function_name == """":\n        if prefix:\n            function_name = ""gg_%s_cart_to_spherical_L%d"" % (prefix, L)\n        else:\n            function_name = ""gg_cart_to_spherical_L%d"" % L\n\n    cartesian_order = {x[1:]: x[0] for x in order.cartesian_order_factory(L, cartesian_order)}\n    RSH_coefs = cart_to_RSH_coeffs(L, order=spherical_order)\n\n    signature = ""void %s(const unsigned long size, const double* PRAGMA_RESTRICT cart, const unsigned long ncart, double* PRAGMA_RESTRICT spherical, const unsigned long nspherical)"" % function_name\n\n    # Start function\n    cg.start_c_block(signature)\n    cg.write(""ASSUME_ALIGNED(cart, %d)"" % align)\n\n    cg.write(""// R_%d0 Transform"" % L)\n    _c_spherical_trans(cg, 0, RSH_coefs, cartesian_order)\n    cg.blankline()\n\n    for l in range(L):\n        cg.write(""// R_%d%dc Transform"" % (L, l + 1))\n        sidx = 2 * l + 1\n        _c_spherical_trans(cg, sidx, RSH_coefs, cartesian_order)\n\n        sidx = 2 * l + 2\n        cg.write(""// R_%d%ds Transform"" % (L, l + 1))\n        _c_spherical_trans(cg, sidx, RSH_coefs, cartesian_order)\n        cg.blankline()\n\n    # End function\n    cg.close_c_block()\n    return signature\n\n\ndef _c_spherical_trans(cg, sidx, RSH_coefs, cartesian_order):\n    # cg.write(""#pragma clang loop vectorize(assume_safety)"")\n    cg.start_c_block(""for (unsigned long i = 0; i < size; i++)"")\n\n    # Figure out where we are summing to\n    if sidx == 0:\n        lhs = ""spherical[i]""\n    elif sidx == 1:\n        lhs = ""spherical[nspherical + i]""\n    else:\n        lhs = ""spherical[%d * nspherical + i]"" % sidx\n\n    op = "" =""\n    for cart_index, scale in RSH_coefs[sidx]:\n\n        # Figure out car idx\n        idx = cartesian_order[cart_index]\n        if idx == 0:\n            rhs = ""cart[i]""\n        elif idx == 1:\n            rhs = ""cart[ncart + i]""\n        else:\n            rhs = ""cart[%d * ncart + i]"" % idx\n\n        # Scales\n        if scale != 1.0:\n            cg.write(""%s %s % .16f * %s"" % (lhs, op, scale, rhs))\n        else:\n            cg.write(""%s %s %s"" % (lhs, op, rhs))\n        op = ""+=""\n    cg.blankline()\n\n    cg.close_c_block()\n\n\ndef transformation_c_generator_sum(cg, L, cartesian_order, spherical_order, function_name="""", prefix=None, align=32):\n    """"""\n    Builds a conversion from cartesian to spherical coordinates in C\n    """"""\n\n    if function_name == """":\n        if prefix:\n            function_name = ""gg_%s_cart_to_spherical_sum_L%d"" % (prefix, L)\n        else:\n            function_name = ""gg_cart_to_spherical_sum_L%d"" % L\n\n    cartesian_order = {x[1:]: x[0] for x in order.cartesian_order_factory(L, cartesian_order)}\n    RSH_coefs = cart_to_RSH_coeffs(L, order=spherical_order)\n\n    signature = ""void %s(const unsigned long size, const double* vector, const double* PRAGMA_RESTRICT cart, const unsigned long ncart, double* PRAGMA_RESTRICT output, const unsigned long nspherical)"" % function_name\n\n    # Start function\n    cg.start_c_block(signature)\n    cg.write(""ASSUME_ALIGNED(cart, %d)"" % align)\n\n    cg.write(""// temps"")\n    cg.write(""double tmp"")\n\n    cg.write(""// R_%d0 Transform"" % L)\n    _c_spherical_trans_vector_sum(cg, 0, RSH_coefs, cartesian_order)\n    cg.blankline()\n\n    for l in range(L):\n        cg.write(""// R_%d%dc Transform"" % (L, l + 1))\n        sidx = 2 * l + 1\n        _c_spherical_trans_vector_sum(cg, sidx, RSH_coefs, cartesian_order)\n\n        sidx = 2 * l + 2\n        cg.write(""// R_%d%ds Transform"" % (L, l + 1))\n        _c_spherical_trans_vector_sum(cg, sidx, RSH_coefs, cartesian_order)\n        cg.blankline()\n\n    # End function\n    cg.close_c_block()\n    return signature\n\n\ndef _c_spherical_trans_vector_sum(cg, sidx, RSH_coefs, cartesian_order):\n    # cg.write(""#pragma clang loop vectorize(assume_safety)"")\n    cg.start_c_block(""for (unsigned long i = 0; i < size; i++)"")\n\n    lhs = ""tmp""\n\n    op = "" =""\n    for cart_index, scale in RSH_coefs[sidx]:\n\n        # Figure out car idx\n        idx = cartesian_order[cart_index]\n        if idx == 0:\n            rhs = ""cart[i]""\n        elif idx == 1:\n            rhs = ""cart[ncart + i]""\n        else:\n            rhs = ""cart[%d * ncart + i]"" % idx\n\n        # Scales\n        if scale != 1.0:\n            cg.write(""%s %s % .16f * %s"" % (lhs, op, scale, rhs))\n        else:\n            cg.write(""%s %s %s"" % (lhs, op, rhs))\n        op = ""+=""\n\n    cg.write(""output[i] += tmp * vector[%s]"" % sidx)\n    cg.blankline()\n\n    cg.close_c_block()\n'"
gau2grid/__init__.py,0,"b'""""""\nGau2grid base init\n""""""\n\nfrom . import RSH\nfrom . import c_generator as c_gen\nfrom . import codegen\nfrom . import order\nfrom . import python_reference as ref\n\n# Pull in code from the c wrapper\nfrom .c_wrapper import (orbital, orbital_basis, collocation, collocation_basis, c_compiled, cgg_path, ncomponents, get_cgg_shared_object)\n# Pull in tests\nfrom .extras import test\n\n# Handle versioneer\nfrom ._version import get_versions\n\nversions = get_versions()\n__version__ = versions[\'version\']\n__git_revision__ = versions[\'full-revisionid\']\ndel get_versions, versions\n'"
gau2grid/_version.py,0,"b'# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.18 (https://github.com/warner/python-versioneer)\n""""""Git implementation of _version.py.""""""\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    """"""Get the keywords needed to look up the version information.""""""\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = ""$Format:%d$""\n    git_full = ""$Format:%H$""\n    git_date = ""$Format:%ci$""\n    keywords = {""refnames"": git_refnames, ""full"": git_full, ""date"": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_config():\n    """"""Create, populate and return the VersioneerConfig() object.""""""\n    # these strings are filled in when \'setup.py versioneer\' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = ""git""\n    cfg.style = ""pep440""\n    cfg.tag_prefix = """"\n    cfg.parentdir_prefix = ""None""\n    cfg.versionfile_source = ""gau2grid/_version.py""\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen(\n                [c] + args,\n                cwd=cwd,\n                env=env,\n                stdout=subprocess.PIPE,\n                stderr=(subprocess.PIPE if hide_stderr else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %s"" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %s"" % (commands, ))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %s (error)"" % dispcmd)\n            print(""stdout was %s"" % stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\n                ""version"": dirname[len(parentdir_prefix):],\n                ""full-revisionid"": None,\n                ""dirty"": False,\n                ""error"": None,\n                ""date"": None\n            }\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %s but none started with prefix %s"" % (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %s"" % "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %s"" % r)\n            return {\n                ""version"": r,\n                ""full-revisionid"": keywords[""full""].strip(),\n                ""dirty"": False,\n                ""error"": None,\n                ""date"": date\n            }\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {\n        ""version"": ""0+unknown"",\n        ""full-revisionid"": keywords[""full""].strip(),\n        ""dirty"": False,\n        ""error"": ""no suitable tags"",\n        ""date"": None\n    }\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root, hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %s not under git control"" % root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(\n        GITS, [""describe"", ""--tags"", ""--dirty"", ""--always"", ""--long"", ""--match"",\n               ""%s*"" % tag_prefix], cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%s\'"" % describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                print(fmt % (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%s\' doesn\'t start with prefix \'%s\'"" % (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""], cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""], cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%d.g%s"" % (pieces[""distance""], pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%d"" % pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%d"" % pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%s"" % pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%s"" % pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {\n            ""version"": ""unknown"",\n            ""full-revisionid"": pieces.get(""long""),\n            ""dirty"": None,\n            ""error"": pieces[""error""],\n            ""date"": None\n        }\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%s\'"" % style)\n\n    return {\n        ""version"": rendered,\n        ""full-revisionid"": pieces[""long""],\n        ""dirty"": pieces[""dirty""],\n        ""error"": None,\n        ""date"": pieces.get(""date"")\n    }\n\n\ndef get_versions():\n    """"""Get version information or return default if unable to do so.""""""\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don\'t do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix, verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split(\'/\'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {\n            ""version"": ""0+unknown"",\n            ""full-revisionid"": None,\n            ""dirty"": None,\n            ""error"": ""unable to find root of source tree"",\n            ""date"": None\n        }\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {\n        ""version"": ""0+unknown"",\n        ""full-revisionid"": None,\n        ""dirty"": None,\n        ""error"": ""unable to compute version"",\n        ""date"": None\n    }\n'"
gau2grid/c_generator.py,0,"b'""""""\nThe C generator for gau2grid collocation functions\n""""""\n\nimport os\n\nfrom . import RSH\nfrom . import c_pragma\nfrom . import c_util_generator as c_util\nfrom . import codegen\nfrom . import order\nfrom . import utility\n\n_grad_indices = [""x"", ""y"", ""z""]\n_hess_indices = [""xx"", ""xy"", ""xz"", ""yy"", ""yz"", ""zz""]\n_der3_indices = [""xxx, xxy, xxz, xyy, xyz, xzz, yyy, yyz, yzz, zzz""]\n\ndef transformer_loops(L):\n    return [(""order == GG_SPHERICAL_CCA"", ""gg_cca_cart_to_spherical_L%d"" % L),\n            (""order == GG_SPHERICAL_GAUSSIAN"", ""gg_gaussian_cart_to_spherical_L%d"" % L),\n            (""order == GG_CARTESIAN_CCA"", ""gg_cca_cart_copy_L%d"" % L),\n            (""order == GG_CARTESIAN_MOLDEN"", ""gg_molden_cart_copy_L%d"" % L)]\n\ndef transformer_sum_loops(L):\n    return [(""order == GG_SPHERICAL_CCA"", ""gg_cca_cart_to_spherical_sum_L%d"" % L),\n            (""order == GG_SPHERICAL_GAUSSIAN"", ""gg_gaussian_cart_to_spherical_sum_L%d"" % L),\n            (""order == GG_CARTESIAN_CCA"", ""gg_cca_cart_sum_L%d"" % L),\n            (""order == GG_CARTESIAN_MOLDEN"", ""gg_molden_cart_sum_L%d"" % L)]\n\nALIGN_SIZE = 64\n\ndef generate_c_gau2grid(max_L,\n                        path=""."",\n                        inner_block=""auto"",\n                        do_cf=True):\n    """"""\n    Creates the C files for the gau2grid program.\n\n    Parameters\n    ----------\n    max_L : int\n        The maximum angular momentum compiled for.\n    path : str, optional\n        The path to write the files to.\n    do_cf : bool, option\n        Apply clang-format to the generated files or not.\n\n    Returns\n    -------\n    None\n\n    """"""\n\n    # We now always compute internally in CCA\n    cartesian_order = ""cca""\n\n    # Build the codegen objects for each file\n    gg_header = codegen.CodeGen(cgen=True)\n    gg_utility_header = codegen.CodeGen(cgen=True)\n    gg_orbital = codegen.CodeGen(cgen=True)\n    gg_phi = codegen.CodeGen(cgen=True)\n    gg_grad = codegen.CodeGen(cgen=True)\n    gg_hess = codegen.CodeGen(cgen=True)\n    gg_der3 = codegen.CodeGen(cgen=True)\n    gg_transform = codegen.CodeGen(cgen=True)\n    gg_helper = codegen.CodeGen(cgen=True)\n    gg_pragma = codegen.CodeGen(cgen=True)\n\n    # Add license to header only\n    c_util.write_license(gg_header)\n\n    # Add general header comments\n    for cgs in [gg_header, gg_utility_header, gg_orbital, gg_phi, gg_grad, gg_hess, gg_der3, gg_transform, gg_helper, gg_pragma]:\n\n        cgs.write(""/*"", endl="""")\n        cgs.write("" * This is a Gau2Grid automatically generated C file."", endl="""")\n        cgs.write("" *"", endl="""")\n        cgs.write("" * More details can found at the following repo:"", endl="""")\n        cgs.write("" *   https://github.com/dgasmith/gau2grid"", endl="""")\n        cgs.write("" */"", endl="""")\n        cgs.blankline()\n\n    # Write out the pragma header\n    c_pragma.build_pragma_header(gg_pragma)\n\n    # gg_helper.write(""#include <stdio.h>"")\n\n    # Add utility headers\n    for cgs in [gg_orbital, gg_phi, gg_grad, gg_hess, gg_der3, gg_transform, gg_helper]:\n        cgs.write(""#include <math.h>"")\n        # cgs.write(""#include <stdio.h>"")\n        cgs.write(""#if defined(__clang__) && defined(_MSC_VER)"")\n        cgs.write(""#include <malloc.h>"")\n        cgs.write(""#elif defined __clang__"")\n        cgs.write(""#include <mm_malloc.h>"")\n        cgs.write(""#elif defined _MSC_VER"")\n        cgs.write(""#include <malloc.h>"")\n        cgs.write(""#else"")\n        cgs.write(""#include <stdlib.h>"")\n        cgs.write(""#endif"")\n        cgs.blankline()\n        cgs.write(\'#include ""gau2grid.h""\')\n        cgs.write(\'#include ""gau2grid_utility.h""\')\n        cgs.write(\'#include ""gau2grid_pragma.h""\')\n        cgs.blankline()\n\n    # Header guards\n    gg_header.write(""#ifdef __cplusplus"")\n    gg_header.write(\'extern ""C"" {\', endl="""")\n    gg_header.write(""#endif"")\n    gg_header.blankline()\n    gg_header.write(""#ifndef GAU2GRID_GUARD_H"")\n    gg_header.write(""#define GAU2GRID_GUARD_H"")\n    gg_header.blankline()\n\n    gg_header.write(\'#include ""gau2grid_pragma.h""\')\n    gg_header.blankline()\n\n    gg_header.write(""// Order definitions"")\n    gg_header.write(""#define GG_SPHERICAL_CCA 300"")\n    gg_header.write(""#define GG_SPHERICAL_GAUSSIAN 301"")\n\n    gg_header.write(""#define GG_CARTESIAN_CCA 400"")\n    gg_header.write(""#define GG_CARTESIAN_MOLDEN 401"")\n\n\n    # Add any information needed\n    gg_helper.write(""// Information helpers"")\n    gg_header.write(""// Information helpers"")\n\n    # Maximum angular momentum\n    gg_helper.write(""int gg_max_L() { return %d; }"" % max_L, endl="""")\n    gg_helper.blankline()\n\n    gg_header.write(""int gg_max_L()"")\n    gg_header.blankline()\n\n\n    # Ncomponents\n    gg_helper.start_c_block(""int gg_ncomponents(const int L, const int spherical)"")\n    gg_helper.write(""if (spherical) {"", endl="""")\n    gg_helper.write(""return 2 * L + 1"")\n    gg_helper.write(""} else {"", endl="""")\n    gg_helper.write(""return (L + 2) * (L + 1) / 2"")\n    gg_helper.write(""}"", endl="""")\n    gg_helper.close_c_block()\n    gg_helper.blankline()\n\n    gg_header.write(""int gg_ncomponents(const int L, const int spherical)"")\n    gg_header.blankline()\n\n    # Build out the spherical transformer\n\n    gg_utility_header.write(""// Spherical transformers"")\n\n    for order in [""cca"", ""gaussian""]:\n        for L in range(max_L + 1):\n            sig = RSH.transformation_c_generator(gg_transform, L, cartesian_order, order, align=ALIGN_SIZE, prefix=order)\n            gg_utility_header.write(sig)\n            gg_utility_header.blankline()\n\n            sig = RSH.transformation_c_generator_sum(gg_transform, L, cartesian_order, order, align=ALIGN_SIZE, prefix=order)\n            gg_utility_header.write(sig)\n            gg_utility_header.blankline()\n\n    for order in [""cca"", ""molden""]:\n        for L in range(max_L + 1):\n            sig = c_util.cartesian_copy_c_generator(gg_transform, L, cartesian_order, order, align=ALIGN_SIZE, prefix=order)\n            gg_utility_header.write(sig)\n            gg_utility_header.blankline()\n\n            sig = c_util.cartesian_sum_c_generator(gg_transform, L, cartesian_order, order, align=ALIGN_SIZE, prefix=order)\n            gg_utility_header.write(sig)\n            gg_utility_header.blankline()\n\n    gg_utility_header.blankline()\n\n    # Fast transformers\n    gg_header.write(""// Fast transposers"")\n    trans_sig = c_util.naive_transpose(gg_transform, align=ALIGN_SIZE)\n    gg_header.write(trans_sig)\n    fast_trans_sig = c_util.fast_transpose(gg_transform, 8, align=ALIGN_SIZE)\n    gg_header.write(fast_trans_sig)\n    gg_header.blankline()\n\n    # Fast copiers\n    gg_header.write(""// Fast segment copiers"")\n    block_sig = c_util.block_copy(gg_transform, align=ALIGN_SIZE)\n    gg_header.write(block_sig)\n    gg_header.blankline()\n\n    # Summers\n    gg_utility_header.write(""// Fast matrix vector block sum"")\n    block_sig = c_util.block_matrix_vector(gg_transform, align=ALIGN_SIZE)\n    gg_utility_header.write(block_sig)\n    gg_header.blankline()\n\n    # Loop over phi, grad, hess and build blocks for each\n    gg_helper.write(""// Collocation selector functions"")\n    helper_sigs = []\n    for name, grad, cg in [(""Orbital"", 0, gg_orbital), (""Phi"", 0, gg_phi), (""Phi grad"", 1, gg_grad),\n                           (""Phi Hess"", 2, gg_hess), (""Phi Der3"", 3, gg_der3)]:\n        cg.blankline()\n        gg_utility_header.write(""// %s computers"" % name)\n        cg.blankline()\n\n        # Write out the phi builders\n        sig_store = []\n        for L in range(max_L + 1):\n            sig = shell_c_generator(\n                cg,\n                L,\n                grad=grad,\n                cartesian_order=cartesian_order,\n                inner_block=inner_block,\n                orbital=(name == ""Orbital""))\n            sig_store.append(sig)\n            cg.blankline()\n\n            # Write out the header data\n            gg_utility_header.write(sig)\n            gg_utility_header.blankline()\n\n        if name == ""Orbital"":\n            gg_header.write(""// Orbitals on a grid"")\n        elif name == ""Phi"":\n            gg_header.write(""// Collocation matrix functions"")\n\n        # Write out the convenience functions\n        func_name, conv_sig = sig_store[0].split(""("")\n        if ""deriv"" in func_name:\n            func_name = func_name.replace(""L0_"", """")\n        else:\n            func_name = func_name.replace(""_L0"", """")\n        func_name += ""(int L, ""\n        func_name += conv_sig\n        helper_sigs.append(_make_call(func_name).split(""("")[0])\n\n        gg_header.write(func_name)\n        gg_header.blankline()\n\n        gg_helper.start_c_block(func_name)\n        gg_helper.write(""// Chooses the correct function for a given L"")\n\n        # Write out if\'s to choose the right L\n        L = 0\n        gg_helper.write(""if (L == 0) {"", endl="""")\n        for sig in sig_store:\n            if L != 0:\n                gg_helper.write(""} else if (L == %d) {"" % L, endl="""")\n\n            sig = _make_call(sig)\n            gg_helper.write(""    "" + sig)\n            L += 1\n\n        # Handle exception\n        gg_helper.write(""} else {"", endl="""")\n        # gg_helper.write(\'    printf(""Requested angular momentum exceeded compiled of %d\\\\n"")\' % max_L)\n        gg_helper.write(\'    exit(0)\')\n        gg_helper.write(""}"", endl="""")\n        gg_helper.close_c_block()\n        # print(func_name)\n\n    # Finish header guard\n    gg_header.write(""#ifdef __cplusplus"")\n    gg_header.write(""}"", endl="""")\n    gg_header.write(""#endif"")\n    gg_header.write(""#endif /* GAU2GRID_GUARD_H */"")\n\n    # Write out the CG\'s to files\n    gg_header.repr(filename=os.path.join(path, ""gau2grid.h""), clang_format=do_cf)\n    gg_utility_header.repr(filename=os.path.join(path, ""gau2grid_utility.h""), clang_format=do_cf)\n    gg_orbital.repr(filename=os.path.join(path, ""gau2grid_orbital.c""), clang_format=do_cf)\n    gg_phi.repr(filename=os.path.join(path, ""gau2grid_phi.c""), clang_format=do_cf)\n    gg_grad.repr(filename=os.path.join(path, ""gau2grid_deriv1.c""), clang_format=do_cf)\n    gg_hess.repr(filename=os.path.join(path, ""gau2grid_deriv2.c""), clang_format=do_cf)\n    gg_der3.repr(filename=os.path.join(path, ""gau2grid_deriv3.c""), clang_format=do_cf)\n    gg_transform.repr(filename=os.path.join(path, ""gau2grid_transform.c""), clang_format=do_cf)\n    gg_helper.repr(filename=os.path.join(path, ""gau2grid_helper.c""), clang_format=do_cf)\n    gg_pragma.repr(filename=os.path.join(path, ""gau2grid_pragma.h""))\n\n\ndef shell_c_generator(cg, L, function_name="""", grad=0, cartesian_order=""row"", inner_block=""auto"", orbital=False):\n\n    # Grab the line start\n    cg_line_start = len(cg.data)\n    deriv_indices = utility.get_deriv_indices(grad)\n\n    if (grad != 0) and orbital:\n        raise KeyError(""Orbital builds are only available for grad=0."")\n    # Parse Keywords\n    if function_name == """":\n        if orbital:\n            function_name = ""gg_orbitals_L%d"" % L\n        elif grad == 0:\n            function_name = ""gg_collocation_L%d"" % L\n        else:\n            function_name = ""gg_collocation_L%d_deriv%d"" % (L, grad)\n\n    if grad > 3:\n        raise TypeError(""Only grad <=3 is supported"")\n\n    # Set a few parameters for custom loops\n    L_needs_out = False\n\n    # Precompute temps\n    ncart = int((L + 1) * (L + 2) / 2)\n    nspherical = L * 2 + 1\n\n    # Do we do multiple loops for each tmp or just one at a time?\n    paritioned_loops = False\n    if (grad == 1) and (L >= 7):\n        paritioned_loops = True\n    elif (grad == 2) and (L >= 3):\n        paritioned_loops = True\n    elif (grad == 3) and (L >= 2):\n        paritioned_loops = True\n\n    # Handle inner block, everything should fit into ~50% of L1\n    # L1 is roughly 64K for data so lets say 32k max or 4096 doubles\n    if inner_block == ""auto"":\n        cache_limit_doubles = 4096\n\n        # Basic temps + grad temps\n        basic_lines = 5 + grad\n\n        if paritioned_loops:\n            # If we run partitioned loops we need this many lines\n            nlines = basic_lines + ncart\n        else:\n            # If we run a single loop we need this many lines\n            nlines = basic_lines + ncart * (1 + len(deriv_indices))\n\n        # This could be bad when we hit AVX-512 (soon)\n        inner_block = 32\n\n        if nlines * inner_block > cache_limit_doubles:\n            print(\n                ""WARNING: For L=%2d and grad=%d assumed 16,384B L1 cache limit will be exceeded. This may impact performance.""\n                % (L, grad))\n\n    elif isinstance(inner_block, int):\n        pass\n    else:\n        raise ValueError(""Inner block of name %s not understood"" % str(inner_block))\n\n    # Build function signature\n    func_sig = """"\n    if orbital:\n        func_sig = ""const double* PRAGMA_RESTRICT C, const unsigned long norbitals, ""\n\n    func_sig += ""const unsigned long npoints, const double* PRAGMA_RESTRICT xyz, const unsigned long xyz_stride, const int nprim, const double* PRAGMA_RESTRICT coeffs, const double* PRAGMA_RESTRICT exponents, const double* PRAGMA_RESTRICT center, const int order, double* PRAGMA_RESTRICT phi_out""\n\n    if orbital:\n        func_sig = func_sig.replace(""phi_out"", ""orbital_out"")\n\n    # Add extra output vals for derivs\n    for deriv in deriv_indices:\n        func_sig += "", double* PRAGMA_RESTRICT phi_%s_out"" % deriv\n\n    func_sig = ""void %s(%s)"" % (function_name, func_sig)\n    cg.start_c_block(func_sig)\n    cg.blankline()\n\n    # Figure out spacing\n    cg.write(""// Sizing"")\n    cg.write(""unsigned long nblocks = npoints / %d"" % inner_block)\n    cg.write(""nblocks += (npoints %% %d) ? 1 : 0"" % inner_block)\n    cg.write(""const unsigned long ncart = %d"" % ncart)\n    cg.write(""const unsigned long nspherical = %d"" % nspherical)\n    cg.write(""unsigned long nout"")\n\n\n    cg.blankline()\n    # cg.write(""const unsigned long nout"")\n    cg.start_c_block(""if ((order == GG_SPHERICAL_CCA) || (order == GG_SPHERICAL_GAUSSIAN))"")\n    cg.write(""nout = nspherical"")\n    cg.write(""} else {"", endl="""")\n    cg.write(""nout = ncart"")\n    cg.close_c_block()\n    cg.blankline()\n\n    # Build temporaries\n    S_cache_tmps = [""xc"", ""yc"", ""zc"", ""R2"", ""S0"", ""tmp1""]\n    if grad > 0:\n        S_cache_tmps.append(""S1"")\n    if grad > 1:\n        S_cache_tmps.append(""S2"")\n    if grad > 2:\n        S_cache_tmps.append(""S3"")\n\n    block_malloc_name = ""cache_data""\n    block_malloc_sizes = [(name, inner_block) for name in S_cache_tmps]\n    S_tmps = [block_malloc_name]\n\n    # Allocate as single block on heap\n    cg.write(""// Allocate S temporaries, single block to stay on cache"")\n    _block_malloc(cg, block_malloc_name, block_malloc_sizes)\n\n    cg.blankline()\n\n    # Hold the expn1 and expn2 arrays\n    cg.write(""// Allocate exponential temporaries"")\n    exp_tmps = [""expn1""]\n    if grad > 0:\n        exp_tmps += [""expn2""]\n    for tname in exp_tmps:\n        cg.write(_malloc(tname, ""nprim""))\n    S_tmps.extend(exp_tmps)\n    cg.blankline()\n\n    # Figure out powers needed\n    power_tmps = []\n    if (L > 1) and paritioned_loops:\n        cg.write(""// Allocate power temporaries"")\n        power_tmps = [""xc_pow"", ""yc_pow"", ""zc_pow""]\n\n        for tname in power_tmps:\n            cg.write(_malloc(tname, inner_block * (L - 1)))\n            cg.write(""ASSUME_ALIGNED(%s, %d)"" % (tname, ALIGN_SIZE));\n\n        cg.blankline()\n\n    # Determine output tmps\n    inner_tmps = []\n    if L >= L_needs_out:\n        cg.write(""// Allocate output temporaries"")\n\n        inner_tmps = [""phi_tmp""]\n        if paritioned_loops is False:\n            for deriv in deriv_indices:\n                inner_tmps.append(""phi_%s_tmp"" % deriv)\n\n        # Malloc temps\n        for tname in inner_tmps:\n            cg.write(_malloc(tname, inner_block * ncart))\n            cg.write(""ASSUME_ALIGNED(%s, %d)"" % (tname, ALIGN_SIZE));\n    cg.blankline()\n\n    # Any declerations needed\n    cg.write(""// Declare doubles"")\n    cg.write(""const double center_x = center[0]"")\n    cg.write(""const double center_y = center[1]"")\n    cg.write(""const double center_z = center[2]"")\n    cg.write(""double A"")\n    if grad > 0:\n        cg.write(""double "" + "", "".join(""A%s"" % grad.upper() for grad in _grad_indices))\n    if grad > 1:\n        cg.write(""double "" + "", "".join(""A%s"" % hess.upper() for hess in _hess_indices))\n    if grad > 2:\n        cg.write(""double "" + "", "".join(""A%s"" % der3.upper() for der3 in _der3_indices))\n    cg.blankline()\n\n    cg.write(""// Build negative exponents"")\n    cg.start_c_block(""for (unsigned long i = 0; i < nprim; i++)"")\n    cg.write(""expn1[i] = -1.0 * exponents[i]"")\n    if grad > 0:\n        cg.write(""expn2[i] = -2.0 * exponents[i]"")\n    cg.close_c_block()\n    cg.blankline()\n\n    # Start outer loop\n    cg.write(""// Start outer block loop"")\n    cg.start_c_block(""for (unsigned long block = 0; block < nblocks; block++)"")\n    cg.blankline()\n\n    # Move data into inner buffers and compute R\n    cg.blankline()\n    cg.write(""// Copy data into inner temps"")\n    cg.write(""const unsigned long start = block * %d"" % inner_block)\n    cg.write(""const unsigned long remain = ((start + %d) > npoints) ? (npoints - start) : %d"" % (inner_block,\n                                                                                                 inner_block))\n    cg.blankline()\n\n    ### Build xc, yz, zc, R2, and S0\n\n    # Two different loop options\n    cg.write(""// Handle non-AM dependant temps"")\n    cg.start_c_block(""if (xyz_stride == 1)"",)\n\n    # Contigous data blocks\n    cg.write(""const double* PRAGMA_RESTRICT x = xyz + start"")\n    cg.write(""const double* PRAGMA_RESTRICT y = xyz + npoints + start"")\n    cg.write(""const double* PRAGMA_RESTRICT z = xyz + 2 * npoints + start"")\n\n    cg.write(""PRAGMA_VECTORIZE"", endl="""")\n    cg.start_c_block(""for (unsigned long i = 0; i < remain; i++)"")\n    cg.write(""xc[i] = x[i] - center_x"")\n    cg.write(""yc[i] = y[i] - center_y"")\n    cg.write(""zc[i] = z[i] - center_z"")\n\n    cg.blankline()\n    cg.write(""// Distance"")\n    cg.write(""R2[i] = xc[i] * xc[i]"")\n    cg.write(""R2[i] += yc[i] * yc[i]"")\n    cg.write(""R2[i] += zc[i] * zc[i]"")\n\n    cg.blankline()\n    cg.write(""// Zero out S tmps"")\n    cg.write(""S0[i] = 0.0"")\n    if grad > 0:\n        cg.write(""S1[i] = 0.0"")\n    if grad > 1:\n        cg.write(""S2[i] = 0.0"")\n    if grad > 2:\n        cg.write(""S3[i] = 0.0"")\n\n    cg.close_c_block()\n    cg.write(""} else {"", endl="""")\n\n    # XYZ stripped blocks\n    cg.write(""unsigned int start_shift = start * xyz_stride"")\n    cg.blankline()\n\n    cg.write(""PRAGMA_VECTORIZE"", endl="""")\n    cg.start_c_block(""for (unsigned long i = 0; i < remain; i++)"")\n    cg.write(""xc[i] = xyz[start_shift + i * xyz_stride] - center_x"")\n    cg.write(""yc[i] = xyz[start_shift + i * xyz_stride + 1] - center_y"")\n    cg.write(""zc[i] = xyz[start_shift + i * xyz_stride + 2] - center_z"")\n\n    cg.blankline()\n    cg.write(""// Distance"")\n    cg.write(""R2[i] = xc[i] * xc[i]"")\n    cg.write(""R2[i] += yc[i] * yc[i]"")\n    cg.write(""R2[i] += zc[i] * zc[i]"")\n\n    cg.blankline()\n    cg.write(""// Zero out S tmps"")\n    cg.write(""S0[i] = 0.0"")\n    if grad > 0:\n        cg.write(""S1[i] = 0.0"")\n    if grad > 1:\n        cg.write(""S2[i] = 0.0"")\n    if grad > 2:\n        cg.write(""S3[i] = 0.0"")\n\n    cg.close_c_block()\n\n    cg.close_c_block()\n    cg.blankline()\n\n    # Start inner loop\n    cg.write(""// Start exponential block loop"")\n    cg.start_c_block(""for (unsigned long n = 0; n < nprim; n++)"")\n\n    # Build R2\n    cg.write(""const double coef = coeffs[n]"")\n    cg.write(""const double alpha_n1 = expn1[n]"")\n    if grad > 0:\n        cg.write(""const double alpha_n2 = expn2[n]"")\n\n    # Build out thoese gaussian derivs\n    cg.blankline()\n    cg.write(""PRAGMA_VECTORIZE"", endl="""")\n    cg.start_c_block(""for (unsigned long i = 0; i < remain; i++)"")\n    cg.write(""const double width = alpha_n1 * R2[i]"")\n    cg.write(""const double T1 = coef * exp(width)"")\n    cg.write(""S0[i] += T1"")\n    if grad > 0:\n        cg.write(""const double T2 = alpha_n2 * T1"")\n        cg.write(""S1[i] += T2"")\n    if grad > 1:\n        cg.write(""const double T3 = alpha_n2 * T2"")\n        cg.write(""S2[i] += T3"")\n    if grad > 2:\n        cg.write(""const double T4 = alpha_n2 * T3"")\n        cg.write(""S3[i] += T4"")\n\n    cg.close_c_block()\n    cg.blankline()\n\n    # Close off\n    cg.close_c_block()\n    cg.blankline()\n\n    # Grab the inner line start\n    inner_line_start = len(cg.data)\n    inner_line_stop = inner_line_start + 1\n\n    # Combine blocks\n    if orbital:\n        cg.write(""// Combine blocks"")\n        cg.write(""PRAGMA_VECTORIZE"", endl="""")\n        cg.start_c_block(""for (unsigned long i = 0; i < remain; i++)"")\n\n        # Build out required S\n        _S_tmps(cg, L, grad, inner_block)\n\n        # Build out required power temps if needed\n        _power_tmps(cg, L, inner_block)\n\n        # Contract temps with powers\n        _c_am_full_build(cg, L, cartesian_order, grad, inner_block)\n\n        cg.blankline()\n\n        # End inner loop\n        cg.close_c_block()\n\n        # Grab the inner line stop\n        inner_line_stop = len(cg.data)\n\n        # Spherical/Cartesian copy out\n        _tmp_to_out_orbital_sum(cg, L, inner_block)\n\n    elif L == 0:\n        cg.write(""// Combine blocks"")\n        cg.write(""PRAGMA_VECTORIZE"", endl="""")\n        cg.start_c_block(""for (unsigned long i = 0; i < remain; i++)"")\n\n        # Build out required S\n        _S_tmps(cg, L, grad, inner_block)\n\n        # Nothing else to be done. Copy it back to outs\n        cg.write(""phi_out[start + i] = S0[i]"")\n\n        if grad > 0:\n            cg.blankline()\n            cg.write(""// Gradient AM=0 Component=0"")\n            cg.write(""phi_x_out[start + i] = SX"")\n            cg.write(""phi_y_out[start + i] = SY"")\n            cg.write(""phi_z_out[start + i] = SZ"")\n\n        if grad > 1:\n            cg.blankline()\n            cg.write(""// Hessian AM=0 Component=0"")\n            cg.write(""phi_xx_out[start + i] = SXX"")\n            cg.write(""phi_yy_out[start + i] = SYY"")\n            cg.write(""phi_zz_out[start + i] = SZZ"")\n            cg.write(""phi_xy_out[start + i] = SXY"")\n            cg.write(""phi_xz_out[start + i] = SXZ"")\n            cg.write(""phi_yz_out[start + i] = SYZ"")\n\n        if grad > 2:\n            cg.blankline()\n            cg.write(""// Der3 AM=0 Component=0"")\n            cg.write(""phi_xxx_out[start + i] = SXXX"")\n            cg.write(""phi_xxy_out[start + i] = SXXY"")\n            cg.write(""phi_xxz_out[start + i] = SXXZ"")\n            cg.write(""phi_xyy_out[start + i] = SXYY"")\n            cg.write(""phi_xyz_out[start + i] = SXYZ"")\n            cg.write(""phi_xzz_out[start + i] = SXZZ"")\n            cg.write(""phi_yyy_out[start + i] = SYYY"")\n            cg.write(""phi_yyz_out[start + i] = SYYZ"")\n            cg.write(""phi_yzz_out[start + i] = SYZZ"")\n            cg.write(""phi_zzz_out[start + i] = SZZZ"")\n\n        cg.close_c_block()\n\n        # Grab the inner line stop\n        inner_line_stop = len(cg.data)\n\n    elif paritioned_loops:\n\n        cg.write(""// Build powers"")\n        cg.write(""PRAGMA_VECTORIZE"", endl="""")\n        cg.start_c_block(""for (unsigned long i = 0; i < remain; i++)"")\n        _power_tmps(cg, L, inner_block, array=True)\n        cg.close_c_block()\n\n        for dind in [""A""] + deriv_indices:\n            _c_am_single_build(cg, L, cartesian_order, grad, inner_block, dind, array=True)\n\n            dind = dind.lower()\n            if dind == ""a"":\n                dind = """"\n            else:\n                dind = ""_"" + dind\n\n            # Transform\n            for num, (criterion, fnc) in enumerate(transformer_loops(L)):\n                if num == 0:\n                    cg.start_c_block(""if (%s)"" % criterion)\n                else:\n                    cg.write(""} else if (%s) {"" % criterion, endl="""")\n\n                cg.write(""%s(remain, phi_tmp, %d, (phi%s_out + start), npoints)"" % (fnc, inner_block, dind))\n\n            # Spherical CCA\n            cg.close_c_block()\n\n            cg.blankline()\n\n        # Grab the inner line stop\n        inner_line_stop = len(cg.data)\n\n    else:\n        cg.write(""// Combine blocks"")\n        cg.write(""PRAGMA_VECTORIZE"", endl="""")\n        cg.start_c_block(""for (unsigned long i = 0; i < remain; i++)"")\n\n        # Build out required S\n        _S_tmps(cg, L, grad, inner_block)\n\n        # Build out required power temps if needed\n        _power_tmps(cg, L, inner_block)\n\n        # Contract temps with powers\n        _c_am_full_build(cg, L, cartesian_order, grad, inner_block)\n\n        cg.blankline()\n\n        # End inner loop\n        cg.close_c_block()\n\n        # Grab the inner line stop\n        inner_line_stop = len(cg.data)\n\n        # Spherical/Cartesian copy out\n        _tmp_to_out_copy(cg, L, deriv_indices, inner_block)\n\n    # End outer loop\n    cg.close_c_block()\n\n    # Free up those arrays\n    cg.blankline()\n    for name, flist in [(""S"", S_tmps), (""Power"", power_tmps), (""inner"", inner_tmps)]:\n        if len(flist) == 0: continue\n\n        cg.write(""// Free %s temporaries"" % name)\n        for tname in flist:\n            cg.write(""ALIGNED_FREE(%s)"" % tname)\n        cg.blankline()\n\n    # End function\n    cg.close_c_block()\n\n    # Clean up data, there are a few things easier to post-process\n\n    # Remove any ""[0 + i]""\n    for x in range(cg_line_start, inner_line_stop):\n        cg.data[x] = cg.data[x].replace(""[0 + "", ""["")\n\n    if paritioned_loops is False:\n        # Remove any ""A = 1"" just for the inner block\n        rep_data = {}\n        pos = inner_line_start\n        while pos < inner_line_stop:\n            line = cg.data[pos]\n            #    print(line)\n\n            # If we hit a Density line its an individual angular momentum, need to reset dict\n            if (""Density"" in line) or (""// Combine"" in line):\n                rep_data = {}\n                pos += 1\n                continue\n\n            # Skip comments and blanklines\n            if (""="" not in line) or (""//"" in line) or (""double"" in line):\n                pos += 1\n                continue\n\n            # Find a single\n            if ("" = "" in line) and (""*"" not in line) and (""+"" not in line) and (\'/\' not in line):\n                key, data = line.replace("";"", """").split("" = "")\n                rep_data[key.strip()] = data.strip()\n                cg.data.pop(pos)\n                inner_line_stop -= 1\n                continue\n\n            for k, v in rep_data.items():\n                tmp = line.split(""= "")[1]\n                if k + "";"" in tmp:\n                    cg.data[pos] = line.replace(k + "";"", v + "";"")\n                elif k + "" "" in tmp:\n                    cg.data[pos] = line.replace(k + "" "", v + "" "")\n            pos += 1\n\n    # Remove any "" * 1""\n    for x in range(cg_line_start, inner_line_stop):\n        cg.data[x] = cg.data[x].replace("" * 1;"", "";"")\n        cg.data[x] = cg.data[x].replace("" * 1.0;"", "";"")\n        cg.data[x] = cg.data[x].replace(""= 1 * "", ""= "")\n        cg.data[x] = cg.data[x].replace(""= 1.0 * "", ""= "")\n\n    return func_sig\n\n\ndef _make_call(string):\n    for rep in [""double* "", ""bool "", ""int "", ""unsigned long "", ""void "", ""PRAGMA_RESTRICT ""]:\n        string = string.replace(""const "" + rep, """")\n        string = string.replace(rep, """")\n    return string\n\n\ndef _malloc(name, size, dtype=""double""):\n    # return ""%s*  %s = (%s*)malloc(%s * sizeof(%s))"" % (dtype, name, dtype, str(size), dtype)\n    return ""%s* PRAGMA_RESTRICT %s = (%s*)ALIGNED_MALLOC(%d, %s * sizeof(%s))"" % (dtype, name, dtype, ALIGN_SIZE, str(size), dtype)\n\n\ndef _block_malloc(cg, block_name, mallocs, dtype=""double""):\n    tot_size = sum(x[1] for x in mallocs)\n    cg.write(_malloc(block_name, tot_size))\n    current_shift = 0\n    for name, size in mallocs:\n        cg.write(""%s* PRAGMA_RESTRICT %s = %s + %d"" % (dtype, name, block_name, current_shift))\n        cg.write(""ASSUME_ALIGNED(%s, %d)"" % (name, ALIGN_SIZE));\n        current_shift += size\n\n\ndef _c_am_single_build(cg, L, cartesian_order, grad, shift, specific_deriv, array=True):\n    """"""\n    Builds a unrolled angular momentum function\n    """"""\n\n    specific_deriv = specific_deriv.upper()\n    cg.write(""// Combine %s blocks"" % specific_deriv)\n    cg.write(""PRAGMA_VECTORIZE"", endl="""")\n    cg.start_c_block(""for (unsigned long i = 0; i < remain; i++)"")\n\n    if specific_deriv == ""X"":\n        cg.write(""const double SX = S1[i] * xc[i]"")\n    elif specific_deriv == ""Y"":\n        cg.write(""const double SY = S1[i] * yc[i]"")\n    elif specific_deriv == ""Z"":\n        cg.write(""const double SZ = S1[i] * zc[i]"")\n    elif specific_deriv == ""XY"":\n        cg.write(""const double SX = S1[i] * xc[i]"")\n        cg.write(""const double SY = S1[i] * yc[i]"")\n        cg.write(""const double SXY = S2[i] * xc[i] * yc[i]"")\n    elif specific_deriv == ""XZ"":\n        cg.write(""const double SX = S1[i] * xc[i]"")\n        cg.write(""const double SZ = S1[i] * zc[i]"")\n        cg.write(""const double SXZ = S2[i] * xc[i] * zc[i]"")\n    elif specific_deriv == ""YZ"":\n        cg.write(""const double SY = S1[i] * yc[i]"")\n        cg.write(""const double SZ = S1[i] * zc[i]"")\n        cg.write(""const double SYZ = S2[i] * yc[i] * zc[i]"")\n    elif specific_deriv == ""XX"":\n        cg.write(""const double SX = S1[i] * xc[i]"")\n        cg.write(""const double SXX = S2[i] * xc[i] * xc[i] + S1[i]"")\n    elif specific_deriv == ""YY"":\n        cg.write(""const double SY = S1[i] * yc[i]"")\n        cg.write(""const double SYY = S2[i] * yc[i] * yc[i] + S1[i]"")\n    elif specific_deriv == ""ZZ"":\n        cg.write(""const double SZ = S1[i] * zc[i]"")\n        cg.write(""const double SZZ = S2[i] * zc[i] * zc[i] + S1[i]"")\n    elif specific_deriv == ""XYZ"":\n        cg.write(""const double SX = S1[i] * xc[i]"")\n        cg.write(""const double SY = S1[i] * yc[i]"")\n        cg.write(""const double SZ = S1[i] * zc[i]"")\n        cg.write(""const double SXY = S2[i] * xc[i] * yc[i]"")\n        cg.write(""const double SXZ = S2[i] * xc[i] * zc[i]"")\n        cg.write(""const double SYZ = S2[i] * yc[i] * zc[i]"")\n        cg.write(""const double SXYZ = S3[i] * xc[i] * yc[i] * zc[i]"")\n    elif specific_deriv == ""XXY"":\n        cg.write(""const double SX = S1[i] * xc[i]"")\n        cg.write(""const double SY = S1[i] * yc[i]"")\n        cg.write(""const double SXY = S2[i] * xc[i] * yc[i]"")\n        cg.write(""const double SXX = S2[i] * xc[i] * xc[i] + S1[i]"")\n        cg.write(""const double SXXY = S3[i] * xc[i] * xc[i] * yc[i] + S2[i] * yc[i]"")\n    elif specific_deriv == ""XXZ"":\n        cg.write(""const double SX = S1[i] * xc[i]"")\n        cg.write(""const double SZ = S1[i] * zc[i]"")\n        cg.write(""const double SXZ = S2[i] * xc[i] * zc[i]"")\n        cg.write(""const double SXX = S2[i] * xc[i] * xc[i] + S1[i]"")\n        cg.write(""const double SXXZ = S3[i] * xc[i] * xc[i] * zc[i] + S2[i] * zc[i]"")\n    elif specific_deriv == ""XYY"":\n        cg.write(""const double SX = S1[i] * xc[i]"")\n        cg.write(""const double SY = S1[i] * yc[i]"")\n        cg.write(""const double SXY = S2[i] * xc[i] * yc[i]"")\n        cg.write(""const double SYY = S2[i] * yc[i] * yc[i] + S1[i]"")\n        cg.write(""const double SXYY = S3[i] * xc[i] * yc[i] * yc[i] + S2[i] * xc[i]"")\n    elif specific_deriv == ""XZZ"":\n        cg.write(""const double SX = S1[i] * xc[i]"")\n        cg.write(""const double SZ = S1[i] * zc[i]"")\n        cg.write(""const double SXZ = S2[i] * xc[i] * zc[i]"")\n        cg.write(""const double SZZ = S2[i] * zc[i] * zc[i] + S1[i]"")\n        cg.write(""const double SXZZ = S3[i] * xc[i] * zc[i] * zc[i] + S2[i] * xc[i]"")\n    elif specific_deriv == ""YYZ"":\n        cg.write(""const double SY = S1[i] * yc[i]"")\n        cg.write(""const double SZ = S1[i] * zc[i]"")\n        cg.write(""const double SYZ = S2[i] * yc[i] * zc[i]"")\n        cg.write(""const double SYY = S2[i] * yc[i] * yc[i] + S1[i]"")\n        cg.write(""const double SYYZ = S3[i] * yc[i] * yc[i] * zc[i] + S2[i] * zc[i]"")\n    elif specific_deriv == ""YZZ"":\n        cg.write(""const double SY = S1[i] * yc[i]"")\n        cg.write(""const double SZ = S1[i] * zc[i]"")\n        cg.write(""const double SYZ = S2[i] * yc[i] * zc[i]"")\n        cg.write(""const double SZZ = S2[i] * zc[i] * zc[i] + S1[i]"")\n        cg.write(""const double SYZZ = S3[i] * yc[i] * zc[i] * zc[i] + S2[i] * yc[i]"")\n    elif specific_deriv == ""XXX"":\n        cg.write(""const double SX = S1[i] * xc[i]"")\n        cg.write(""const double SXX = S2[i] * xc[i] * xc[i] + S1[i]"")\n        cg.write(""const double SXXX = S3[i] * xc[i] * xc[i] * xc[i] + 3 * xc[i] * S2[i]"")\n    elif specific_deriv == ""YYY"":\n        cg.write(""const double SY = S1[i] * yc[i]"")\n        cg.write(""const double SYY = S2[i] * yc[i] * yc[i] + S1[i]"")\n        cg.write(""const double SYYY = S3[i] * yc[i] * yc[i] * yc[i] + 3 * yc[i] * S2[i]"")\n    elif specific_deriv == ""ZZZ"":\n        cg.write(""const double SZ = S1[i] * zc[i]"")\n        cg.write(""const double SZZ = S2[i] * zc[i] * zc[i] + S1[i]"")\n        cg.write(""const double SZZZ = S3[i] * zc[i] * zc[i] * zc[i] + 3 * zc[i] * S2[i]"")\n    elif specific_deriv == ""A"":\n        pass\n    else:\n        raise KeyError(""Specific deriv %s not understood."" % specific_deriv)\n    cg.blankline()\n\n    # Generator\n    for idx, l, m, n in order.cartesian_order_factory(L, cartesian_order):\n\n        l = l + 2\n        m = m + 2\n        n = n + 2\n        ld1 = l - 1\n        ld2 = l - 2\n        ld3 = l - 3\n        md1 = m - 1\n        md2 = m - 2\n        md3 = m - 3\n        nd1 = n - 1\n        nd2 = n - 2\n        nd3 = n - 3\n\n        # Set grads back to zero\n        x_grad, y_grad, z_grad = False, False, False\n        shift_idx = idx * shift\n\n        name = ""X"" * ld2 + ""Y"" * md2 + ""Z"" * nd2\n        if name == """":\n            name = ""0""\n\n        # Gradient\n        AX = _build_xyz_pow(""AX"", ld2, ld1, m, n, shift, array=array, rhs_only=True)\n        x_grad = AX is not None\n        AY = _build_xyz_pow(""AY"", md2, l, md1, n, shift, array=array, rhs_only=True)\n        y_grad = AY is not None\n        AZ = _build_xyz_pow(""AZ"", nd2, l, m, nd1, shift, array=array, rhs_only=True)\n        z_grad = AZ is not None\n\n        if specific_deriv == ""A"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * S0[i]"" % (shift_idx, rhs))\n\n            # Keep lines together\n            continue\n\n        # Gradients\n        if specific_deriv == ""X"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SX"" % (shift_idx, rhs))\n\n            if x_grad:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AX))\n\n        if specific_deriv == ""Y"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SY"" % (shift_idx, rhs))\n\n            if y_grad:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AY))\n\n        if specific_deriv == ""Z"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SZ"" % (shift_idx, rhs))\n\n            if z_grad:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AZ))\n\n        # Hessian\n        if specific_deriv == ""XX"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SXX"" % (shift_idx, rhs))\n\n            # Cross term, need to write it out if specific deriv\n            if x_grad:\n                rhs = _build_xyz_pow(""AX"", ld2, ld1, m, n, shift, array=array, scale=2.0, rhs_only=True)\n                cg.write(""phi_tmp[%d + i] += %s * SX"" % (shift_idx, rhs))\n\n            AXX = _build_xyz_pow(""AXX"", ld2 * (ld2 - 1), ld2, m, n, shift, array=array, rhs_only=True)\n            if AXX is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AXX))\n\n        # YY\n        if specific_deriv == ""YY"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SYY"" % (shift_idx, rhs))\n            if y_grad:\n                rhs = _build_xyz_pow(""AY"", md2, l, md1, n, shift, array=array, scale=2.0, rhs_only=True)\n                cg.write(""phi_tmp[%d + i] += %s * SY"" % (shift_idx, rhs))\n\n            AYY = _build_xyz_pow(""AYY"", md2 * (md2 - 1), l, md2, n, shift, array=array, rhs_only=True)\n            if AYY is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AYY))\n\n        # ZZ\n        if specific_deriv == ""ZZ"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SZZ"" % (shift_idx, rhs))\n            if z_grad:\n                rhs = _build_xyz_pow(""AZ"", nd2, l, m, nd1, shift, array=array, scale=2.0, rhs_only=True)\n                cg.write(""phi_tmp[%d + i] += %s * SZ"" % (shift_idx, rhs))\n\n            AZZ = _build_xyz_pow(""AZZ"", nd2 * (nd2 - 1), l, m, nd2, shift, array=array, rhs_only=True)\n            if AZZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AZZ))\n\n        # XY\n        if specific_deriv == ""XY"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SXY"" % (shift_idx, rhs))\n\n            if y_grad:\n                rhs = AY.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SX"" % (shift_idx, rhs))\n            if x_grad:\n                rhs = AX.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SY"" % (shift_idx, rhs))\n\n            AXY = _build_xyz_pow(""AXY"", ld2 * md2, ld1, md1, n, shift, array=array, rhs_only=True)\n            if AXY is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AXY))\n\n        # XZ\n        if specific_deriv == ""XZ"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SXZ"" % (shift_idx, rhs))\n            if z_grad:\n                rhs = AZ.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SX"" % (shift_idx, rhs))\n            if x_grad:\n                rhs = AX.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SZ"" % (shift_idx, rhs))\n\n            AXZ = _build_xyz_pow(""AXZ"", ld2 * nd2, ld1, m, nd1, shift, array=array, rhs_only=True)\n            if AXZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AXZ))\n\n        # YZ\n        if specific_deriv == ""YZ"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SYZ"" % (shift_idx, rhs))\n            if z_grad:\n                rhs = AZ.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SY"" % (shift_idx, rhs))\n            if y_grad:\n                rhs = AY.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SZ"" % (shift_idx, rhs))\n\n            AYZ = _build_xyz_pow(""AYZ"", md2 * nd2, l, md1, nd1, shift, array=array, rhs_only=True)\n            if AYZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AYZ))\n\n        # XYZ\n        if specific_deriv == ""XYZ"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SXYZ"" % (shift_idx, rhs))\n            if x_grad:\n                rhs = AX.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SYZ"" % (shift_idx, rhs))\n            if y_grad:\n                rhs = AY.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SXZ"" % (shift_idx, rhs))\n            if z_grad:\n                rhs = AZ.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SXY"" % (shift_idx, rhs))\n\n            AXY = _build_xyz_pow(""AXY"", ld2 * md2, ld1, md1, n, shift, array=array, rhs_only=True)\n            if AXY is not None:\n                cg.write(""phi_tmp[%d + i] += %s * SZ"" % (shift_idx, AXY))\n            AXZ = _build_xyz_pow(""AXZ"", ld2 * nd2, ld1, m, nd1, shift, array=array, rhs_only=True)\n            if AXZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * SY"" % (shift_idx, AXZ))\n            AYZ = _build_xyz_pow(""AYZ"", md2 * nd2, l, md1, nd1, shift, array=array, rhs_only=True)\n            if AYZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * SX"" % (shift_idx, AYZ))\n\n            AXYZ = _build_xyz_pow(""AXYZ"", ld2 * md2 * md2, ld1, md1, nd1, shift, array=array, rhs_only=True)\n            if AXYZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AXYZ))\n        # XXY\n        if specific_deriv == ""XXY"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SXXY"" % (shift_idx, rhs))\n            if x_grad:\n                rhs = AX.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SXY"" % (shift_idx, rhs))\n            if y_grad:\n                rhs = AY.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SXX"" % (shift_idx, rhs))\n\n            AXX = _build_xyz_pow(""AXX"", ld2 * (ld2 - 1), ld2, m, n, shift, array=array, rhs_only=True)\n            if AXX is not None:\n                cg.write(""phi_tmp[%d + i] += %s * SY"" % (shift_idx, AXX))\n            AXY = _build_xyz_pow(""AXY"", ld2 * md2, ld1, md1, n, shift, array=array, rhs_only=True)\n            if AXY is not None:\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SX"" % (shift_idx, AXY))\n\n            AXXY = _build_xyz_pow(""AXXY"", ld2 * (ld2 - 1) * md2, ld2, md1, n, shift, array=array, rhs_only=True)\n            if AXXY is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AXXY))\n        # XXZ\n        if specific_deriv == ""XXZ"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SXXZ"" % (shift_idx, rhs))\n            if x_grad:\n                rhs = AX.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SXZ"" % (shift_idx, rhs))\n            if z_grad:\n                rhs = AZ.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SXX"" % (shift_idx, rhs))\n\n            AXX = _build_xyz_pow(""AXX"", ld2 * (ld2 - 1), ld2, m, n, shift, array=array, rhs_only=True)\n            if AXX is not None:\n                cg.write(""phi_tmp[%d + i] += %s * SZ"" % (shift_idx, AXX))\n            AXZ = _build_xyz_pow(""AXZ"", ld2 * nd2, ld1, m, nd1, shift, array=array, rhs_only=True)\n            if AXZ is not None:\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SX"" % (shift_idx, AXZ))\n\n            AXXZ = _build_xyz_pow(""AXXZ"", ld2 * (ld2 - 1) * nd2, ld2, m, nd1, shift, array=array, rhs_only=True)\n            if AXXZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AXXZ))\n        # XYY\n        if specific_deriv == ""XYY"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SXYY"" % (shift_idx, rhs))\n            if y_grad:\n                rhs = AY.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SXY"" % (shift_idx, rhs))\n            if x_grad:\n                rhs = AX.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SYY"" % (shift_idx, rhs))\n\n            AYY = _build_xyz_pow(""AYY"", md2 * (md2 - 1), l, md2, n, shift, array=array, rhs_only=True)\n            if AYY is not None:\n                cg.write(""phi_tmp[%d + i] += %s * SX"" % (shift_idx, AYY))\n            AXY = _build_xyz_pow(""AXY"", ld2 * md2, ld1, md1, n, shift, array=array, rhs_only=True)\n            if AXY is not None:\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SY"" % (shift_idx, AXY))\n\n            AXYY = _build_xyz_pow(""AXYY"", md2 * (md2 - 1) * ld2, ld1, md2, n, shift, array=array, rhs_only=True)\n            if AXYY is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AXYY))\n        # XZZ\n        if specific_deriv == ""XZZ"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SXZZ"" % (shift_idx, rhs))\n            if z_grad:\n                rhs = AZ.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SXZ"" % (shift_idx, rhs))\n            if x_grad:\n                rhs = AX.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SZZ"" % (shift_idx, rhs))\n\n            AZZ = _build_xyz_pow(""AZZ"", nd2 * (nd2 - 1), l, m, nd2, shift, array=array, rhs_only=True)\n            if AZZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * SX"" % (shift_idx, AZZ))\n            AXZ = _build_xyz_pow(""AXZ"", ld2 * nd2, ld1, m, nd1, shift, array=array, rhs_only=True)\n            if AXZ is not None:\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SZ"" % (shift_idx, AXZ))\n\n            AXZZ = _build_xyz_pow(""AXZZ"", nd2 * (nd2 - 1) * ld2, ld1, m, nd2, shift, array=array, rhs_only=True)\n            if AXZZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AXZZ))\n        # YYZ\n        if specific_deriv == ""YYZ"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SYYZ"" % (shift_idx, rhs))\n            if y_grad:\n                rhs = AY.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SYZ"" % (shift_idx, rhs))\n            if z_grad:\n                rhs = AZ.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SYY"" % (shift_idx, rhs))\n\n            AYY = _build_xyz_pow(""AYY"", md2 * (md2 - 1), l, md2, n, shift, array=array, rhs_only=True)\n            if AYY is not None:\n                cg.write(""phi_tmp[%d + i] += %s * SZ"" % (shift_idx, AYY))\n            AYZ = _build_xyz_pow(""AYZ"", md2 * nd2, l, md1, nd1, shift, array=array, rhs_only=True)\n            if AYZ is not None:\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SY"" % (shift_idx, AYZ))\n\n            AYYZ = _build_xyz_pow(""AYYZ"", md2 * (md2 - 1) * nd2, l, md2, nd1, shift, array=array, rhs_only=True)\n            if AYYZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AYYZ))\n        # YZZ\n        if specific_deriv == ""YZZ"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SYZZ"" % (shift_idx, rhs))\n            if z_grad:\n                rhs = AZ.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SYZ"" % (shift_idx, rhs))\n            if y_grad:\n                rhs = AY.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += %s * SZZ"" % (shift_idx, rhs))\n\n            AZZ = _build_xyz_pow(""AZZ"", nd2 * (nd2 - 1), l, m, nd2, shift, array=array, rhs_only=True)\n            if AZZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * SY"" % (shift_idx, AZZ))\n            AYZ = _build_xyz_pow(""AYZ"", md2 * nd2, l, md1, nd1, shift, array=array, rhs_only=True)\n            if AYZ is not None:\n                cg.write(""phi_tmp[%d + i] += 2.0 * %s * SZ"" % (shift_idx, AYZ))\n\n            AYZZ = _build_xyz_pow(""AYZZ"", nd2 * (nd2 - 1) * md2, l, md1, nd2, shift, array=array, rhs_only=True)\n            if AYZZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AYZZ))\n        # XXX\n        if specific_deriv == ""XXX"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SXXX"" % (shift_idx, rhs))\n            if x_grad:\n                rhs = AX.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += 3.0 * %s * SXX"" % (shift_idx, rhs))\n\n            AXX = _build_xyz_pow(""AXX"", ld2 * (ld2 - 1), ld2, m, n, shift, array=array, rhs_only=True)\n            if AXX is not None:\n                cg.write(""phi_tmp[%d + i] += 3.0 * %s * SX"" % (shift_idx, AXX))\n\n            AXXX = _build_xyz_pow(""AXXX"", ld2 * (ld2 - 1) * (ld2 - 2), ld3, m, n, shift, array=array, rhs_only=True)\n            if AXXX is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AXXX))\n        # YYY\n        if specific_deriv == ""YYY"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SYYY"" % (shift_idx, rhs))\n            if y_grad:\n                rhs = AY.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += 3.0 * %s * SYY"" % (shift_idx, rhs))\n\n            AYY = _build_xyz_pow(""AYY"", md2 * (md2 - 1), l, md2, n, shift, array=array, rhs_only=True)\n            if AYY is not None:\n                cg.write(""phi_tmp[%d + i] += 3.0 * %s * SY"" % (shift_idx, AYY))\n\n            AYYY = _build_xyz_pow(""AYYY"", md2 * (md2 - 1) * (md2 - 2), l, md3, n, shift, array=array, rhs_only=True)\n            if AYYY is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AYYY))\n        # ZZZ\n        if specific_deriv == ""ZZZ"":\n            rhs = _build_xyz_pow(""A"", 1.0, l, m, n, shift, array=array, rhs_only=True)\n            cg.write(""phi_tmp[%d + i] = %s * SZZZ"" % (shift_idx, rhs))\n            if z_grad:\n                rhs = AZ.split("" = "")[-1]\n                cg.write(""phi_tmp[%d + i] += 3.0 * %s * SZZ"" % (shift_idx, rhs))\n\n            AZZ = _build_xyz_pow(""AZZ"", nd2 * (nd2 - 1), l, m, nd2, shift, array=array, rhs_only=True)\n            if AZZ is not None:\n                cg.write(""phi_tmp[%d + i] += 3.0 * %s * SZ"" % (shift_idx, AZZ))\n\n            AZZZ = _build_xyz_pow(""AZZZ"", nd2 * (nd2 - 1) * (nd2 - 2), l, m, nd3, shift, array=array, rhs_only=True)\n            if AZZZ is not None:\n                cg.write(""phi_tmp[%d + i] += %s * S0[i]"" % (shift_idx, AZZZ))\n\n        idx += 1\n        cg.blankline()\n\n    cg.close_c_block()\n    cg.blankline()\n\n\ndef _c_am_full_build(cg, L, cartesian_order, grad, shift):\n    """"""\n    Builds a unrolled angular momentum function\n    """"""\n\n    # Generator\n    for idx, l, m, n in order.cartesian_order_factory(L, cartesian_order):\n\n        l = l + 2\n        m = m + 2\n        n = n + 2\n        ld1 = l - 1\n        ld2 = l - 2\n        ld3 = l - 3\n        md1 = m - 1\n        md2 = m - 2\n        md3 = m - 3\n        nd1 = n - 1\n        nd2 = n - 2\n        nd3 = n - 3\n\n        # Set grads back to zero\n        x_grad, y_grad, z_grad = False, False, False\n        shift_idx = idx * shift\n\n\n        name = ""X"" * ld2 + ""Y"" * md2 + ""Z"" * nd2\n        if name == """":\n            name = ""0""\n\n        # Density\n        cg.blankline()\n        cg.write(""// Density AM=%d Component=%s"" % (L, name))\n\n        cg.write(_build_xyz_pow(""A"", 1.0, l, m, n, shift))\n        cg.write(""phi_tmp[%d + i] = S0[i] * A"" % shift_idx)\n\n        if grad == 0: continue\n        cg.blankline()\n        cg.write(""// Gradient AM=%d Component=%s"" % (L, name))\n\n        # Gradient\n        cg.write(""phi_x_tmp[%d + i] = SX * A"" % shift_idx)\n        cg.write(""phi_y_tmp[%d + i] = SY * A"" % shift_idx)\n        cg.write(""phi_z_tmp[%d + i] = SZ * A"" % shift_idx)\n\n        AX = _build_xyz_pow(""AX"", ld2, ld1, m, n, shift)\n        if AX is not None:\n            x_grad = True\n            cg.write(AX)\n            cg.write(""phi_x_tmp[%d + i] += S0[i] * AX"" % shift_idx)\n\n        AY = _build_xyz_pow(""AY"", md2, l, md1, n, shift)\n        if AY is not None:\n            y_grad = True\n            cg.write(AY)\n            cg.write(""phi_y_tmp[%d + i] += S0[i] * AY"" % shift_idx)\n\n        AZ = _build_xyz_pow(""AZ"", nd2, l, m, nd1, shift)\n        if AZ is not None:\n            z_grad = True\n            cg.write(AZ)\n            cg.write(""phi_z_tmp[%d + i] += S0[i] * AZ"" % shift_idx)\n\n        # Hessian temporaries\n        if grad == 1: continue\n\n        cg.blankline()\n        cg.write(""// Hessian AM=%d Component=%s"" % (L, name))\n\n        # S Hess\n        # We will build S Hess, grad 1, grad 2, A Hess\n\n        # XX\n        cg.write(""phi_xx_tmp[%d + i] = SXX * A"" % shift_idx)\n        if x_grad:\n            cg.write(""phi_xx_tmp[%d + i] += SX * AX"" % shift_idx)\n            cg.write(""phi_xx_tmp[%d + i] += SX * AX"" % shift_idx)\n\n        AXX = _build_xyz_pow(""AXX"", ld2 * (ld2 - 1), ld2, m, n, shift)\n        if AXX is not None:\n            rhs = AXX.split("" = "")[-1]\n            cg.write(""phi_xx_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n\n        # YY\n        cg.write(""phi_yy_tmp[%d + i] = SYY * A"" % shift_idx)\n        if y_grad:\n            cg.write(""phi_yy_tmp[%d + i] += SY * AY"" % shift_idx)\n            cg.write(""phi_yy_tmp[%d + i] += SY * AY"" % shift_idx)\n        AYY = _build_xyz_pow(""AYY"", md2 * (md2 - 1), l, md2, n, shift)\n        if AYY is not None:\n            rhs = AYY.split("" = "")[-1]\n            cg.write(""phi_yy_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n\n        # ZZ\n        cg.write(""phi_zz_tmp[%d + i] = SZZ * A"" % shift_idx)\n        if z_grad:\n            cg.write(""phi_zz_tmp[%d + i] += SZ * AZ"" % shift_idx)\n            cg.write(""phi_zz_tmp[%d + i] += SZ * AZ"" % shift_idx)\n        AZZ = _build_xyz_pow(""AZZ"", nd2 * (nd2 - 1), l, m, nd2, shift)\n        if AZZ is not None:\n            rhs = AZZ.split("" = "")[-1]\n            cg.write(""phi_zz_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n\n        # XY\n        cg.write(""phi_xy_tmp[%d + i] = SXY * A"" % shift_idx)\n\n        if y_grad:\n            cg.write(""phi_xy_tmp[%d + i] += SX * AY"" % shift_idx)\n        if x_grad:\n            cg.write(""phi_xy_tmp[%d + i] += SY * AX"" % shift_idx)\n\n        AXY = _build_xyz_pow(""AXY"", ld2 * md2, ld1, md1, n, shift)\n        if AXY is not None:\n            rhs = AXY.split("" = "")[-1]\n            cg.write(""phi_xy_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n\n        # XZ\n        cg.write(""phi_xz_tmp[%d + i] = SXZ * A"" % shift_idx)\n        if z_grad:\n            cg.write(""phi_xz_tmp[%d + i] += SX * AZ"" % shift_idx)\n        if x_grad:\n            cg.write(""phi_xz_tmp[%d + i] += SZ * AX"" % shift_idx)\n        AXZ = _build_xyz_pow(""AXZ"", ld2 * nd2, ld1, m, nd1, shift)\n        if AXZ is not None:\n            rhs = AXZ.split("" = "")[-1]\n            cg.write(""phi_xz_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n\n        # YZ\n        cg.write(""phi_yz_tmp[%d + i] = SYZ * A"" % shift_idx)\n        if z_grad:\n            cg.write(""phi_yz_tmp[%d + i] += SY * AZ"" % shift_idx)\n        if y_grad:\n            cg.write(""phi_yz_tmp[%d + i] += SZ * AY"" % shift_idx)\n        AYZ = _build_xyz_pow(""AYZ"", md2 * nd2, l, md1, nd1, shift)\n        if AYZ is not None:\n            rhs = AYZ.split("" = "")[-1]\n            cg.write(""phi_yz_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n\n        if grad == 2: continue\n\n        # XYZ\n        cg.write(""phi_xyz_tmp[%d + i] = SXYZ * A"" % shift_idx)\n        if x_grad:\n            cg.write(""phi_xyz_tmp[%d + i] += SYZ * AX"" % shift_idx)\n        if y_grad:\n            cg.write(""phi_xyz_tmp[%d + i] += SXZ * AY"" % shift_idx)\n        if z_grad:\n            cg.write(""phi_xyz_tmp[%d + i] += SXY * AZ"" % shift_idx)\n        AXY = _build_xyz_pow(""AXY"", ld2 * md2, ld1, md1, n, shift)\n        if AXY is not None:\n            rhs = AXY.split("" = "")[-1]\n            cg.write(""phi_xyz_tmp[%d + i] += %s * SZ"" % (shift_idx, rhs))\n        AXZ = _build_xyz_pow(""AXZ"", ld2 * nd2, ld1, m, nd1, shift)\n        if AXZ is not None:\n            rhs = AXZ.split("" = "")[-1]\n            cg.write(""phi_xyz_tmp[%d + i] += %s * SY"" % (shift_idx, rhs))\n        AYZ = _build_xyz_pow(""AYZ"", md2 * nd2, l, md1, nd1, shift)\n        if AYZ is not None:\n            rhs = AYZ.split("" = "")[-1]\n            cg.write(""phi_xyz_tmp[%d + i] += %s * SX"" % (shift_idx, rhs))\n        AXYZ = _build_xyz_pow(""AXYZ"", ld2 * md2 * nd2, ld1, md1, nd1, shift)\n        if AXYZ is not None:\n            rhs = AXYZ.split("" = "")[-1]\n            cg.write(""phi_xyz_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n        # XXY\n        cg.write(""phi_xxy_tmp[%d + i] = SXXY * A"" % shift_idx)\n        if x_grad:\n            cg.write(""phi_xxy_tmp[%d + i] += 2.0 * SXY * AX"" % shift_idx)\n        if y_grad:\n            cg.write(""phi_xxy_tmp[%d + i] += SXX * AY"" % shift_idx)\n        AXY = _build_xyz_pow(""AXY"", ld2 * md2, ld1, md1, n, shift)\n        if AXY is not None:\n            rhs = AXY.split("" = "")[-1]\n            cg.write(""phi_xxy_tmp[%d + i] += 2.0 * %s * SX"" % (shift_idx, rhs))\n        AXX = _build_xyz_pow(""AXX"", ld2 * (ld2 - 1), ld2, m, n, shift)\n        if AXX is not None:\n            rhs = AXX.split("" = "")[-1]\n            cg.write(""phi_xxy_tmp[%d + i] += %s * SY"" % (shift_idx, rhs))\n        AXXY = _build_xyz_pow(""AXXY"", ld2 * (ld2 - 1) * md2, ld2, md1, n, shift)\n        if AXXY is not None:\n            rhs = AXXY.split("" = "")[-1]\n            cg.write(""phi_xxy_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n        # XXZ\n        cg.write(""phi_xxz_tmp[%d + i] = SXXZ * A"" % shift_idx)\n        if x_grad:\n            cg.write(""phi_xxz_tmp[%d + i] += 2.0 * SXZ * AX"" % shift_idx)\n        if z_grad:\n            cg.write(""phi_xxz_tmp[%d + i] += SXX * AZ"" % shift_idx)\n        AXZ = _build_xyz_pow(""AXZ"", ld2 * nd2, ld1, m, nd1, shift)\n        if AXZ is not None:\n            rhs = AXZ.split("" = "")[-1]\n            cg.write(""phi_xxz_tmp[%d + i] += 2.0 * %s * SX"" % (shift_idx, rhs))\n        AXX = _build_xyz_pow(""AXX"", ld2 * (ld2 - 1), ld2, m, n, shift)\n        if AXX is not None:\n            rhs = AXX.split("" = "")[-1]\n            cg.write(""phi_xxz_tmp[%d + i] += %s * SZ"" % (shift_idx, rhs))\n        AXXZ = _build_xyz_pow(""AXXZ"", ld2 * (ld2 - 1) * nd2, ld2, m, nd1, shift)\n        if AXXZ is not None:\n            rhs = AXXZ.split("" = "")[-1]\n            cg.write(""phi_xxz_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n        # XYY\n        cg.write(""phi_xyy_tmp[%d + i] = SXYY * A"" % shift_idx)\n        if y_grad:\n            cg.write(""phi_xyy_tmp[%d + i] += 2.0 * SXY * AY"" % shift_idx)\n        if x_grad:\n            cg.write(""phi_xyy_tmp[%d + i] += SYY * AX"" % shift_idx)\n        AXY = _build_xyz_pow(""AXY"", ld2 * md2, ld1, md1, n, shift)\n        if AXY is not None:\n            rhs = AXY.split("" = "")[-1]\n            cg.write(""phi_xyy_tmp[%d + i] += 2.0 * %s * SY"" % (shift_idx, rhs))\n        AYY = _build_xyz_pow(""AYY"", md2 * (md2 - 1), l, md2, n, shift)\n        if AYY is not None:\n            rhs = AYY.split("" = "")[-1]\n            cg.write(""phi_xyy_tmp[%d + i] += %s * SX"" % (shift_idx, rhs))\n        AXYY = _build_xyz_pow(""AXYY"", md2 * (md2 - 1) * ld2, ld1, md2, n, shift)\n        if AXYY is not None:\n            rhs = AXYY.split("" = "")[-1]\n            cg.write(""phi_xyy_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n        # XZZ\n        cg.write(""phi_xzz_tmp[%d + i] = SXZZ * A"" % shift_idx)\n        if z_grad:\n            cg.write(""phi_xzz_tmp[%d + i] += 2.0 * SXZ * AZ"" % shift_idx)\n        if x_grad:\n            cg.write(""phi_xzz_tmp[%d + i] += SZZ * AX"" % shift_idx)\n        AXZ = _build_xyz_pow(""AXZ"", ld2 * nd2, ld1, m, nd1, shift)\n        if AXZ is not None:\n            rhs = AXZ.split("" = "")[-1]\n            cg.write(""phi_xzz_tmp[%d + i] += 2.0 * %s * SZ"" % (shift_idx, rhs))\n        AZZ = _build_xyz_pow(""AZZ"", nd2 * (nd2 - 1), l, m, nd2, shift)\n        if AZZ is not None:\n            rhs = AZZ.split("" = "")[-1]\n            cg.write(""phi_xzz_tmp[%d + i] += %s * SX"" % (shift_idx, rhs))\n        AXZZ = _build_xyz_pow(""AXZZ"", nd2 * (nd2 - 1) * ld2, ld1, m, nd2, shift)\n        if AXZZ is not None:\n            rhs = AXZZ.split("" = "")[-1]\n            cg.write(""phi_xzz_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n        # YYZ\n        cg.write(""phi_yyz_tmp[%d + i] = SYYZ * A"" % shift_idx)\n        if y_grad:\n            cg.write(""phi_yyz_tmp[%d + i] += 2.0 * SYZ * AY"" % shift_idx)\n        if z_grad:\n            cg.write(""phi_yyz_tmp[%d + i] += SYY * AZ"" % shift_idx)\n        AYZ = _build_xyz_pow(""AYZ"", md2 * nd2, l, md1, nd1, shift)\n        if AYZ is not None:\n            rhs = AYZ.split("" = "")[-1]\n            cg.write(""phi_yyz_tmp[%d + i] += 2.0 * %s * SY"" % (shift_idx, rhs))\n        AYY = _build_xyz_pow(""AYY"", md2 * (md2 - 1), l, md2, n, shift)\n        if AYY is not None:\n            rhs = AYY.split("" = "")[-1]\n            cg.write(""phi_yyz_tmp[%d + i] += %s * SZ"" % (shift_idx, rhs))\n        AYYZ = _build_xyz_pow(""AYYZ"", md2 * (md2 - 1) * nd2, l, md2, nd1, shift)\n        if AYYZ is not None:\n            rhs = AYYZ.split("" = "")[-1]\n            cg.write(""phi_yyz_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n        # YZZ\n        cg.write(""phi_yzz_tmp[%d + i] = SYZZ * A"" % shift_idx)\n        if z_grad:\n            cg.write(""phi_yzz_tmp[%d + i] += 2.0 * SYZ * AZ"" % shift_idx)\n        if y_grad:\n            cg.write(""phi_yzz_tmp[%d + i] += SZZ * AY"" % shift_idx)\n        AYZ = _build_xyz_pow(""AYZ"", md2 * nd2, l, md1, nd1, shift)\n        if AYZ is not None:\n            rhs = AYZ.split("" = "")[-1]\n            cg.write(""phi_yzz_tmp[%d + i] += 2.0 * %s * SZ"" % (shift_idx, rhs))\n        AZZ = _build_xyz_pow(""AZZ"", nd2 * (nd2 - 1), l, m, nd2, shift)\n        if AZZ is not None:\n            rhs = AZZ.split("" = "")[-1]\n            cg.write(""phi_yzz_tmp[%d + i] += %s * SY"" % (shift_idx, rhs))\n        AYZZ = _build_xyz_pow(""AYZZ"", nd2 * (nd2 - 1) * md2, l, md1, nd2, shift)\n        if AYZZ is not None:\n            rhs = AYZZ.split("" = "")[-1]\n            cg.write(""phi_yzz_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n        # XXX\n        cg.write(""phi_xxx_tmp[%d + i] = SXXX * A"" % shift_idx)\n        if x_grad:\n            cg.write(""phi_xxx_tmp[%d + i] += 3.0 * SXX * AX"" % shift_idx)\n        AXX = _build_xyz_pow(""AXX"", ld2 * (ld2 - 1), ld2, m, n, shift)\n        if AXX is not None:\n            rhs = AXX.split("" = "")[-1]\n            cg.write(""phi_xxx_tmp[%d + i] += 3.0 * %s * SX"" % (shift_idx, rhs))\n        AXXX = _build_xyz_pow(""AXXX"", ld2 * (ld2 - 1) * (ld2 - 2), ld3, m, n, shift)\n        if AXXX is not None:\n            rhs = AXXX.split("" = "")[-1]\n            cg.write(""phi_xxx_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n        # YYY\n        cg.write(""phi_yyy_tmp[%d + i] = SYYY * A"" % shift_idx)\n        if y_grad:\n            cg.write(""phi_yyy_tmp[%d + i] += 3.0 * SYY * AY"" % shift_idx)\n        AYY = _build_xyz_pow(""AYY"", md2 * (md2 - 1), l, md2, n, shift)\n        if AYY is not None:\n            rhs = AYY.split("" = "")[-1]\n            cg.write(""phi_yyy_tmp[%d + i] += 3.0 * %s * SY"" % (shift_idx, rhs))\n        AYYY = _build_xyz_pow(""AYYY"", md2 * (md2 - 1) * (md2 - 2), l, md3, n, shift)\n        if AYYY is not None:\n            rhs = AYYY.split("" = "")[-1]\n            cg.write(""phi_yyy_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n        # ZZZ\n        cg.write(""phi_zzz_tmp[%d + i] = SZZZ * A"" % shift_idx)\n        if z_grad:\n            cg.write(""phi_zzz_tmp[%d + i] += 3.0 * SZZ * AZ"" % shift_idx)\n        AZZ = _build_xyz_pow(""AZZ"", nd2 * (nd2 - 1), l, m, nd2, shift)\n        if AZZ is not None:\n            rhs = AZZ.split("" = "")[-1]\n            cg.write(""phi_zzz_tmp[%d + i] += 3.0 * %s * SZ"" % (shift_idx, rhs))\n        AZZZ = _build_xyz_pow(""AZZZ"", nd2 * (nd2 - 1) * (nd2 - 2), l, m, nd3, shift)\n        if AZZZ is not None:\n            rhs = AZZZ.split("" = "")[-1]\n            cg.write(""phi_zzz_tmp[%d + i] += %s * S0[i]"" % (shift_idx, rhs))\n\n        idx += 1\n        cg.blankline()\n\n\ndef _build_xyz_pow(name, pref, l, m, n, inner_loop, shift=2, array=False, scale=1.0, rhs_only=False):\n    """"""\n    Builds an individual row contraction line.\n\n    name = pref * xc_pow[n] yc_pow[m] * zc_pow[n]\n    """"""\n    l = l - shift\n    m = m - shift\n    n = n - shift\n\n    if (pref <= 0) or (l < 0) or (n < 0) or (m < 0):\n        return None\n\n    if rhs_only:\n        ret = """"\n    else:\n        ret = name + "" =""\n\n    mul = "" ""\n    if (pref * scale) != 1.0:\n        # Basically always an int\n        ret += "" %2.1f"" % (float(pref) * scale)\n        mul = "" * ""\n\n    # Handle x\n    if l == 1:\n        # If the power is one, we can just use xc\n        ret += mul + ""xc[i]""\n        mul = "" * ""\n    elif l > 1:\n        # If the power is greater than 1 we need to use (xc_pow - 2) as we start at 2\n        if array:\n            ret += mul + ""xc_pow[%d + i]"" % ((l - 2) * inner_loop)\n        else:\n            ret += mul + ""xc_pow%d"" % l\n        mul = "" * ""\n\n    # Handle y\n    if m == 1:\n        ret += mul + ""yc[i]""\n        mul = "" * ""\n    elif m > 1:\n        if array:\n            ret += mul + ""yc_pow[%d + i]"" % ((m - 2) * inner_loop)\n        else:\n            ret += mul + ""yc_pow%d"" % m\n        mul = "" * ""\n\n    # Handle z\n    if n == 1:\n        ret += mul + ""zc[i]""\n        mul = "" * ""\n    elif n > 1:\n        if array:\n            ret += mul + ""zc_pow[%d + i]"" % ((n - 2) * inner_loop)\n        else:\n            ret += mul + ""zc_pow%d"" % n\n        mul = "" * ""\n\n    if rhs_only:\n        ret = ret.strip()\n\n    if mul == "" "":\n        ret += "" 1""\n\n    return ret\n\n\ndef _S_tmps(cg, L, grad, inner_block):\n    """"""\n    Builds out the S power temporaries if needed\n    """"""\n    if grad > 0:\n        cg.write(""// Gaussian derivs (gradients)"")\n        cg.write(""const double SX = S1[i] * xc[i]"")\n        cg.write(""const double SY = S1[i] * yc[i]"")\n        cg.write(""const double SZ = S1[i] * zc[i]"")\n    if grad > 1:\n        cg.blankline()\n        cg.write(""// Gaussians derivs (Hessians)"")\n        cg.write(""const double SXY = S2[i] * xc[i] * yc[i]"")\n        cg.write(""const double SXZ = S2[i] * xc[i] * zc[i]"")\n        cg.write(""const double SYZ = S2[i] * yc[i] * zc[i]"")\n        cg.write(""const double SXX = S2[i] * xc[i] * xc[i] + S1[i]"")\n        cg.write(""const double SYY = S2[i] * yc[i] * yc[i] + S1[i]"")\n        cg.write(""const double SZZ = S2[i] * zc[i] * zc[i] + S1[i]"")\n    if grad > 2:\n        cg.blankline()\n        cg.write(""// Gaussians 3rd derivs)"")\n        cg.write(""const double SXXX = S3[i] * xc[i] * xc[i] * xc[i] + 3 * xc[i] * S2[i]"")\n        cg.write(""const double SXXY = S3[i] * xc[i] * xc[i] * yc[i] + yc[i] * S2[i]"")\n        cg.write(""const double SXXZ = S3[i] * xc[i] * xc[i] * zc[i] + zc[i] * S2[i]"")\n        cg.write(""const double SXYY = S3[i] * xc[i] * yc[i] * yc[i] + xc[i] * S2[i]"")\n        cg.write(""const double SXYZ = S3[i] * xc[i] * yc[i] * zc[i]"")\n        cg.write(""const double SXZZ = S3[i] * xc[i] * zc[i] * zc[i] + xc[i] * S2[i]"")\n        cg.write(""const double SYYY = S3[i] * yc[i] * yc[i] * yc[i] + 3 * yc[i] * S2[i]"")\n        cg.write(""const double SYYZ = S3[i] * yc[i] * yc[i] * zc[i] + zc[i] * S2[i]"")\n        cg.write(""const double SYZZ = S3[i] * yc[i] * zc[i] * zc[i] + yc[i] * S2[i]"")\n        cg.write(""const double SZZZ = S3[i] * zc[i] * zc[i] * zc[i] + 3 * zc[i] * S2[i]"")\n\n\ndef _power_tmps(cg, L, inner_block, array=False):\n    if L < 2:\n        return\n\n    # L == 2\n    # cg.write(""PRAGMA_VECTORIZE"", endl="""")\n    # cg.start_c_block(""for (unsigned long i = 0; i < remain; i++)"")\n    if array:\n        # Build out those power derivs\n        cg.blankline()\n        cg.write(""// Cartesian derivs"")\n        cg.write(""xc_pow[i] = xc[i] * xc[i]"")\n        cg.write(""yc_pow[i] = yc[i] * yc[i]"")\n        cg.write(""zc_pow[i] = zc[i] * zc[i]"")\n\n        if L == 2:\n            cg.blankline()\n\n        for l in range(1, (L - 1)):\n            cg.write(""xc_pow[%d + i] = xc_pow[%d + i] * xc[i]"" % (inner_block * l, inner_block * (l - 1)))\n            cg.write(""yc_pow[%d + i] = yc_pow[%d + i] * yc[i]"" % (inner_block * l, inner_block * (l - 1)))\n            cg.write(""zc_pow[%d + i] = zc_pow[%d + i] * zc[i]"" % (inner_block * l, inner_block * (l - 1)))\n\n    else:\n        # Build out those power derivs\n        cg.blankline()\n        cg.write(""// Cartesian derivs"")\n        cg.write(""const double xc_pow2 = xc[i] * xc[i]"")\n        cg.write(""const double yc_pow2 = yc[i] * yc[i]"")\n        cg.write(""const double zc_pow2 = zc[i] * zc[i]"")\n\n        cg.blankline()\n\n        for l in range(2, L):\n            cg.write(""const double xc_pow%d = xc_pow%d * xc[i]"" % (l + 1, l))\n            cg.write(""const double yc_pow%d = yc_pow%d * yc[i]"" % (l + 1, l))\n            cg.write(""const double zc_pow%d = zc_pow%d * zc[i]"" % (l + 1, l))\n            cg.blankline()\n\n\ndef _tmp_to_out_copy(cg, L, deriv_indices, inner_block):\n\n    # Start spherical switch\n    cg.blankline()\n    cg.write(""// Copy data back into outer temps"")\n\n    for num, (criterion, fnc) in enumerate(transformer_loops(L)):\n\n        if num == 0:\n            cg.start_c_block(""if (%s)"" % criterion)\n        else:\n            cg.write(""} else if (%s) {"" % criterion, endl="""")\n\n        cg.write(""// Phi, transform data to outer temps"")\n        cg.write(""%s(remain, phi_tmp, %d, (phi_out + start), npoints)"" % (fnc, inner_block))\n\n        for dnum, deriv in enumerate(deriv_indices):\n            # Write out pretty headers\n            if dnum == 0:\n                cg.blankline()\n                cg.write(""// Gradient, transform data to outer temps"")\n            if dnum == 3:\n                cg.blankline()\n                cg.write(""// Hessian, transform data to outer temps"")\n\n            cg.write(""%s(remain, phi_%s_tmp, %d, (phi_%s_out + start), npoints)"" % (fnc, deriv, inner_block, deriv))\n\n    cg.close_c_block()\n\n    cg.blankline()\n\n\ndef _tmp_to_out_orbital_sum(cg, L, inner_block):\n\n    # Start spherical switch\n    cg.blankline()\n    cg.write(""// Copy data back into outer temps"")\n\n    for num, (criterion, fnc) in enumerate(transformer_sum_loops(L)):\n\n        if num == 0:\n            cg.start_c_block(""if (%s)"" % criterion)\n        else:\n            cg.write(""} else if (%s) {"" % criterion, endl="""")\n\n        cg.write(""// Phi, transform data to outer temps"")\n        cg.start_c_block(""for (unsigned long i = 0; i < norbitals; i++)"")\n        cg.write(""%s(remain, (C + i * nout), phi_tmp, %d, (orbital_out + npoints * i + start), npoints)"" %\n                 (fnc, inner_block))\n        cg.close_c_block()\n\n    cg.close_c_block()\n'"
gau2grid/c_pragma.py,0,"b'""""""\nBuilds static pragma\'s for different copmilers\n""""""\n\n_pragma_data = """"""\n\n// ISOC11 does not seem to be well implemented across platforms and compilers\n// This is a collection of macros to change pragmas and function calls as needed for compat.\n\n#pragma once\n\n\n#if defined(__GG_NO_PRAGMA)\n    // Turn everything off if there are issues\n\n    #define ALIGNED_MALLOC(alignment, size)                  malloc(size)\n    #define ALIGNED_FREE(ptr)                                free(ptr)\n    #define ASSUME_ALIGNED(ptr, width)\n\n    #define PRAGMA_VECTORIZE\n    #define PRAGMA_RESTRICT\n\n#elif defined(__ICC) || defined(__INTEL_COMPILER)\n    // pragmas for Intel\n\n    #define ALIGNED_MALLOC(alignment, size)                  _mm_malloc(size, alignment)\n    #define ALIGNED_FREE(ptr)                                _mm_free(ptr)\n    #define ASSUME_ALIGNED(ptr, width)                       __assume_aligned(ptr, width)\n\n    #define PRAGMA_VECTORIZE                                 _Pragma(""vector"")\n    #define PRAGMA_RESTRICT                                  __restrict__\n\n#elif defined(__clang__) && defined(_MSC_VER)\n    // pragmas for MSVC\n\n    #define ALIGNED_MALLOC(alignment, size)                  _aligned_malloc(size, alignment)\n    #define ALIGNED_FREE(ptr)                                _aligned_free(ptr)\n    #define ASSUME_ALIGNED(ptr, width)\n\n    #define PRAGMA_VECTORIZE                                 __pragma(loop(ivdep))\n    #define PRAGMA_RESTRICT                                  __restrict\n\n#elif defined(__clang__)\n    // pragmas for Clang.\n    // Do this before GCC because clang also defines __GNUC__\n\n    #define ALIGNED_MALLOC(alignment, size)                  _mm_malloc(size, alignment)\n    #define ALIGNED_FREE(ptr)                                _mm_free(ptr)\n    #define ASSUME_ALIGNED(ptr, width)\n\n    #define PRAGMA_VECTORIZE                                 _Pragma(""clang loop vectorize(enable)"")\n    #define PRAGMA_RESTRICT                                  __restrict__\n\n#elif (defined(__GNUC__) || defined(__GNUG__)) && defined(__APPLE__)\n    // pragmas for GCC on Darwin (weird aligned alloc not found on Darwin)\n\n    #define ALIGNED_MALLOC(alignment, size)                  malloc(size)\n    #define ALIGNED_FREE(ptr)                                free(ptr)\n    #define ASSUME_ALIGNED(ptr, width)\n\n    #define PRAGMA_VECTORIZE                                 _Pragma(""GCC ivdep"")\n    #define PRAGMA_RESTRICT                                  __restrict__\n\n#elif defined(__GNUC__) || defined(__GNUG__)\n    // pragmas for GCC\n\n    #define ALIGNED_MALLOC(alignment, size)                  aligned_alloc(alignment, size)\n    #define ALIGNED_FREE(ptr)                                free(ptr)\n    #define ASSUME_ALIGNED(ptr, width)\n\n    #define PRAGMA_VECTORIZE                                 _Pragma(""GCC ivdep"")\n    #define PRAGMA_RESTRICT                                  __restrict__\n\n#elif defined(_MSC_VER)\n    // pragmas for MSVC\n\n    #define ALIGNED_MALLOC(alignment, size)                  _aligned_malloc(size, alignment)\n    #define ALIGNED_FREE(ptr)                                _aligned_free(ptr)\n    #define ASSUME_ALIGNED(ptr, width)\n\n    #define PRAGMA_VECTORIZE                                 __pragma(loop(ivdep))\n    #define PRAGMA_RESTRICT                                  __restrict\n\n\n#elif defined(__PGI)\n    // pragmas for PGI\n\n    #define ALIGNED_MALLOC(alignment, size)                  aligned_alloc(alignment, size)\n    #define ALIGNED_FREE(ptr)                                free(ptr)\n    #define ASSUME_ALIGNED(ptr, width)\n\n    #define PRAGMA_VECTORIZE                                 _Pragma(""ivdep"")\n    #define PRAGMA_RESTRICT                                  __restrict__\n\n\n#endif\n""""""\n\n\ndef build_pragma_header(cg):\n    """"""\n    Adds PRAGMA_VECTORIZE header to assist with different compilers\n    """"""\n    for line in _pragma_data.splitlines():\n        cg.write(line, endl="""")\n'"
gau2grid/c_util_generator.py,0,"b'""""""\nBuilds c utility routines\n""""""\n\nfrom . import utility\nfrom .order import cartesian_order_factory\n\ndef write_license(cg):\n\n    license_text = """"""BSD 3-Clause License\n\n    Copyright (c) 2017, Daniel Smith\n    All rights reserved.\n\n    Redistribution and use in source and binary forms, with or without\n    modification, are permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright notice, this\n      list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above copyright notice,\n      this list of conditions and the following disclaimer in the documentation\n      and/or other materials provided with the distribution.\n\n    * Neither the name of the copyright holder nor the names of its\n      contributors may be used to endorse or promote products derived from\n      this software without specific prior written permission.\n\n    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n    AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n    DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n    FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n    DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n    SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n    CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n    OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n    OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.""""""\n\n    # Write out header\n    cg.write(""/*"", endl="""")\n    for line in license_text.splitlines():\n        line = line.strip()\n        cg.write("" * "" + line, endl="""")\n\n    cg.write("" */"", endl="""")\n    cg.blankline()\n\n\n### Pybind11 binders\n\n\ndef pybind11_func(cg, name, grad, call_name, max_L):\n    """"""\n    A function that builds the PyBind11 wrappers for the different pybind11 funcs.\n    """"""\n\n    # Figure out what we need to add per deriv\n    deriv_indices = utility.get_deriv_indices(grad)\n\n    # Write out wrapper functions\n    sig = """"""void %s(int L, py::array_t<double> arr_xyz, py::array_t<double> arr_coeffs,\npy::array_t<double> arr_exponents, py::array_t<double> arr_center, bool spherical,\npy::array_t<double> arr_out"""""" % name\n\n    # Pad out deriv outputs\n    for cart in deriv_indices:\n        sig += "", py::array_t<double> arr_%s_out"" % cart\n\n    sig += "")""\n    cg.start_c_block(sig)\n    cg.blankline()\n\n    # Grab the pointers\n    cg.write(\'// Grab array pointers\')\n    cg.write(\'auto xyz = arr_xyz.unchecked<2>()\')\n    cg.write(\'auto coeffs = arr_coeffs.unchecked<1>()\')\n    cg.write(\'auto exponents = arr_exponents.unchecked<1>()\')\n    cg.write(\'auto center = arr_center.unchecked<1>()\')\n    cg.write(\'auto out = arr_out.mutable_unchecked<2>()\')\n\n    # Pad out deriv pointers\n    for cart in deriv_indices:\n        cg.write(""auto out_%s = arr_%s_out.mutable_unchecked<2>()"" % (cart, cart))\n\n    cg.blankline()\n\n    # Run through checks\n    cg.write(\'// XYZ is of size 3\')\n    cg.start_c_block(\'if (L > %d)\' % max_L)\n    cg.write(\n        \'    throw std::invalid_argument(""Exceeded compiled angular momentum of %d. Please recompile with a higher angular momentum.\\\\n"")\'\n        % max_L)\n    cg.close_c_block()\n\n    cg.write(\'// XYZ is of size 3\')\n    cg.start_c_block(\'if (arr_xyz.shape(0) != 3)\')\n    cg.write(\'    throw std::length_error(""Length of XYZ array must be (3, n).\\\\n"")\')\n    cg.close_c_block()\n    cg.blankline()\n\n    cg.write(\'// Coeff matches exponent shape\')\n    cg.start_c_block(\'if (coeffs.shape(0) != exponents.shape(0))\')\n    cg.write(\'    throw std::length_error(""Length of coefficients and exponents must match.\\\\n"")\')\n    cg.close_c_block()\n    cg.blankline()\n\n    cg.write(\'// Center is of size 3\')\n    cg.start_c_block(\'if (center.shape(0) != 3)\')\n    cg.write(\'    throw std::length_error(""Length of center vector must be 3 (X, Y, Z).\\\\n"")\')\n    cg.close_c_block()\n    cg.blankline()\n\n    cg.write(\'// Make sure output length matches\')\n    cg.write(\'unsigned long nsize\')\n    cg.start_c_block(\'if (spherical)\')\n    cg.write(\'    nsize = 2 * L + 1\')\n    cg.write(\'} else {\', endl="""")\n    cg.write(\'    nsize = ((L + 2) * (L + 1)) / 2\')\n    cg.close_c_block()\n    cg.blankline()\n\n    cg.start_c_block(\'if (out.shape(0) != nsize)\')\n    cg.write(\'    throw std::length_error(""Size of the output array does not match the angular momentum.\\\\n"")\')\n    cg.close_c_block()\n\n    for cart in deriv_indices:\n        cg.start_c_block(\'if (out_%s.shape(0) != nsize)\' % cart)\n        cg.write(\'    throw std::length_error(""Size of the output %s array does not match the angular momentum.\\\\n"")\' %\n                 cart.upper())\n        cg.close_c_block()\n    cg.blankline()\n\n    cg.write(\'// Ensure lengths match\')\n    cg.start_c_block(\'if (out.shape(1) != arr_xyz.shape(1))\')\n    cg.write(\'    throw std::length_error(""Size of the output array and XYZ array must be the same.\\\\n"")\')\n    cg.close_c_block()\n\n    # Pad out deriv length checkers\n    for cart in deriv_indices:\n        cg.start_c_block(\'if (out_%s.shape(1) != arr_xyz.shape(1))\' % cart)\n        cg.write(\'    throw std::length_error(""Size of the output %s array and XYZ array must be the same.\\\\n"")\' %\n                 cart.upper())\n        cg.close_c_block()\n    cg.blankline()\n\n    cg.write(""// Call the GG helper function"")\n    call_func = call_name + ""(L, xyz.shape(1)""\n    call_func += "", xyz.data(0, 0), xyz.data(1, 0), xyz.data(2, 0)""\n    call_func += "", coeffs.shape(0), coeffs.data(0), exponents.data(0)""\n    call_func += "", center.data(0)""\n    call_func += "", spherical""\n    call_func += "", out.mutable_data(0, 0)""\n    for cart in deriv_indices:\n        call_func += "", out_%s.mutable_data(0, 0)"" % cart\n    call_func += "")""\n\n    cg.write(call_func)\n\n    cg.close_c_block()\n\n\ndef pybind11_transpose(cg, func_name, wrapper_name):\n    """"""\n    Wraps the transpose functions in pybind11\n    """"""\n\n    sig = ""void %s(py::array_t<double> arr_input"" % wrapper_name\n    sig += "", py::array_t<double> arr_output)""\n\n    cg.start_c_block(sig)\n    cg.write(""auto input = arr_input.unchecked<2>()"")\n    cg.write(""auto output = arr_output.mutable_unchecked<2>()"")\n    cg.write(""unsigned long n = input.shape(0)"")\n    cg.write(""unsigned long m = input.shape(1)"")\n    cg.blankline()\n\n    cg.write(\'// Check shapes\')\n    cg.start_c_block(\'if (input.shape(0) != output.shape(1))\')\n    cg.write(\'    throw std::length_error(""Input tranpose shape 0 does not match output transpose shape 1.\\\\n"")\')\n    cg.close_c_block()\n    cg.blankline()\n\n    cg.start_c_block(\'if (input.shape(1) != output.shape(0))\')\n    cg.write(\'    throw std::length_error(""Input tranpose shape 1 does not match output transpose shape 0.\\\\n"")\')\n    cg.close_c_block()\n    cg.blankline()\n\n    cg.write(""%s(n, m, input.data(0, 0), output.mutable_data(0, 0))"" % func_name)\n\n    cg.close_c_block()\n\n\n### Tranposers\n\n\ndef naive_transpose(cg, align=32):\n    """"""\n    A completely naive tranpose to swap data\n    """"""\n\n    sig = ""void gg_naive_transpose(unsigned long n, unsigned long m, const double* PRAGMA_RESTRICT input, double* PRAGMA_RESTRICT output)""\n    cg.start_c_block(sig)\n\n    cg.write(""ASSUME_ALIGNED(%s, %d)"" % (""input"", align));\n    cg.start_c_block(""for (unsigned long i = 0; i < n; i++)"")\n\n    # Inner block\n    cg.start_c_block(""for (unsigned long j = 0; j < m; j++)"")\n    cg.write(""output[j * n + i] = input[i * m + j]"")\n    cg.close_c_block()\n\n    # Outer block\n    cg.close_c_block()\n\n    cg.close_c_block()\n    return sig\n\n\ndef fast_transpose(cg, inner_block, align=32):\n    """"""\n    Builds a fast transpose using an internal blocking scheme in an attempt to vectorize IO from/to DRAM\n    """"""\n\n    sig = ""void gg_fast_transpose(unsigned long n, unsigned long m, const double* PRAGMA_RESTRICT input, double* PRAGMA_RESTRICT output)""\n    cg.start_c_block(sig)\n    cg.blankline()\n\n    cg.write(""// Temps"")\n    cg.write(""#ifdef _MSC_VER"")\n    cg.write(""__declspec(align(64)) double tmp[%d]"" % (inner_block * inner_block))\n    cg.write(""#else"")\n    cg.write(""double tmp[%d] __attribute__((aligned(64)))"" % (inner_block * inner_block))\n    cg.write(""#endif"")\n    cg.write(""ASSUME_ALIGNED(%s, %d)"" % (""input"", align));\n\n    cg.write(""// Sizing"")\n    cg.write(""unsigned long nblocks = n / %d"" % inner_block)\n    cg.write(""nblocks += (n %% %d) ? 1 : 0"" % inner_block)\n\n    cg.write(""unsigned long mblocks = m / %d"" % inner_block)\n    cg.write(""mblocks += (m %% %d) ? 1 : 0"" % inner_block)\n    # cg.write(\'printf(""Blocks: %ld %ld\\\\n"", nblocks, mblocks)\')\n\n    cg.write(""// Outer blocks"")\n    cg.start_c_block(""for (unsigned long nb = 0; nb < nblocks; nb++)"")\n    cg.write(""const unsigned long nstart = nb * %d"" % inner_block)\n    cg.write(""unsigned long nremain = ((nstart + %d) > n) ? (n - nstart) : %d"" % (inner_block, inner_block))\n\n    cg.start_c_block(""for (unsigned long mb = 0; mb < mblocks; mb++)"")\n    cg.write(""const unsigned long mstart = mb * %d"" % inner_block)\n    cg.write(""unsigned long mremain = ((mstart + %d) > m) ? (m - mstart) : %d"" % (inner_block, inner_block))\n\n    # cg.start_c_block(""if ((nremain == 0) & (mremain > 0))"")\n    # cg.write(""nremain++;"")\n    # cg.close_c_block()\n\n    # cg.start_c_block(""if ((mremain == 0) & (nremain > 0))"")\n    # cg.write(""mremain++;"")\n    # cg.close_c_block()\n    # cg.write(\'printf(""(n,m)%ld %ld | %ld %ld\\\\n"", nb, mb, nremain, mremain)\')\n\n    # Pull block\n    cg.write(""// Copy data to inner block"")\n    # cg.write(\'printf(""%ld %ld | %ld\\\\n "", mstart, nstart, start)\')\n    cg.start_c_block(""for (unsigned long l = 0; l < nremain; l++)"")\n    cg.write(""const unsigned long start = (nstart + l) * m + mstart"")\n    # cg.write(""PRAGMA_VECTORIZE"", endl="""")\n    cg.start_c_block(""for (unsigned long k = 0; k < mremain; k++)"")\n\n    # cg.write(""tmp[l * %d + k] = input[start + k]"" % inner_block)\n    cg.write(""tmp[k * %d + l] = input[start + k]"" % inner_block)\n\n    # cg.write(\'printf(""(%ld %ld %lf) "", l * 2+ k, start +k, input[start + k])\')\n    # cg.write(\'printf(""%%lf "", tmp[k * %d + l])\' % inner_block)\n    cg.close_c_block()\n    cg.close_c_block()\n    # cg.write(\'printf(""\\\\n--\\\\n"")\')\n    # cg.start_c_block(""for (unsigned long k = 0; k < 4; k++)"")\n    # cg.write(\'printf(""%lf "", tmp[k])\')\n    # cg.close_c_block()\n    # cg.write(\'printf(""\\\\n--\\\\n"")\')\n\n    # Tranpose block\n    # cg.write(""// Transpose inner block"")\n    # cg.start_c_block(""for (unsigned long k = 0; k < %d; k++)"" % inner_block)\n    # cg.start_c_block(""for (unsigned long l = k; l < %d; l++)"" % inner_block)\n    # # cg.write(\'printf(""%ld %ld \\\\n"", k, l)\')\n    # cg.write(""const double itmp = tmp[l * %d + k]"" % inner_block)\n    # cg.write(""tmp[l * %d + k] = tmp[k * %d + l]"" % (inner_block, inner_block))\n    # cg.write(""tmp[k * %d + l] = itmp"" % (inner_block))\n    # cg.close_c_block()\n    # cg.close_c_block()\n    # cg.write(\'printf(""--\\\\n"")\')\n    # cg.start_c_block(""for (unsigned long k = 0; k < 4; k++)"")\n    # cg.write(\'printf(""%lf "", tmp[k])\')\n    # cg.close_c_block()\n    # cg.write(\'printf(""\\\\n--\\\\n"")\')\n\n    # Push block\n    cg.write(""// Copy data to inner block"")\n    cg.start_c_block(""for (unsigned long k = 0; k < mremain; k++)"")\n    cg.write(""const unsigned long start = (mstart + k) * n + nstart"")\n    # cg.write(""PRAGMA_VECTORIZE"", endl="""")\n    cg.start_c_block(""for (unsigned long l = 0; l < nremain; l++)"")\n    # cg.write(\'printf(""(k,l) %ld %ld | %ld\\\\n"", k, l, start+l)\')\n\n    cg.write(""output[start + l] = tmp[k * %d + l]"" % inner_block)\n    cg.close_c_block()\n    cg.close_c_block()\n    # cg.write(\'printf(""--------\\\\n"")\')\n\n    # cg.start_c_block(""for (unsigned long k = 0; k < %d; k++)"" % inner_block)\n    # cg.start_c_block(""for (unsigned long l = 0; l < %d; l++)"" % inner_block)\n    # cg.write(""tmp[k * %d + l] = 0.0"" % inner_block)\n    # cg.close_c_block()\n    # cg.close_c_block()\n\n    # Outer block\n    cg.close_c_block()\n    cg.close_c_block()\n\n    cg.close_c_block()\n\n    return sig\n\n\n### Data copiers\n\ndef cartesian_copy_c_generator(cg, L, cartesian_order_inner, cartesian_order_outer, function_name="""", prefix=None, align=32):\n    """"""\n    Builds a conversion from cartesian to spherical coordinates in C\n    """"""\n\n\n    if function_name == """":\n        if prefix:\n            function_name = ""gg_%s_cart_copy_L%d"" % (prefix, L)\n        else:\n            function_name = ""gg_cart_copy_L%d"" % L\n\n    signature = ""void %s(const unsigned long size, const double* PRAGMA_RESTRICT cart_input, const unsigned long ncart_input, double* PRAGMA_RESTRICT cart_out, const unsigned long ncart_out)"" % function_name\n\n    try:\n        cartesian_input = {x[1:]: x[0] for x in cartesian_order_factory(L, cartesian_order_inner)}\n        cartesian_output = {x[1:]: x[0] for x in cartesian_order_factory(L, cartesian_order_outer)}\n    except KeyError:\n\n        cg.start_c_block(signature)\n        cg.close_c_block()\n\n        return signature\n\n\n    cg.start_c_block(signature)\n    cg.blankline()\n    cg.write(""ASSUME_ALIGNED(%s, %d)"" % (""cart_input"", align));\n\n    cg.write(""unsigned long inp_shift"")\n    cg.write(""unsigned long out_shift"")\n\n    for label, order in cartesian_input.items():\n        cg.blankline()\n        cg.write(""// Copy %s"" % str(label))\n\n        cg.write(""inp_shift = %d * ncart_input"" % order)\n        cg.write(""out_shift = %d * ncart_out"" % cartesian_output[label])\n\n        cg.start_c_block(""for (unsigned long i = 0; i < size; i++)"")\n        cg.write(""cart_out[out_shift + i] = cart_input[inp_shift + i]"")\n        cg.close_c_block()\n\n    cg.close_c_block()\n\n    return signature\n\n\ndef cartesian_sum_c_generator(cg, L, cartesian_order_inner, cartesian_order_outer, function_name="""", prefix=None, align=32):\n    """"""\n    Builds a conversion from cartesian to spherical coordinates in C\n    """"""\n\n\n    if function_name == """":\n        if prefix:\n            function_name = ""gg_%s_cart_sum_L%d"" % (prefix, L)\n        else:\n            function_name = ""gg_cart_sum_L%d"" % L\n\n\n    signature = ""void %s(const unsigned long size, const double* PRAGMA_RESTRICT vector, const double* PRAGMA_RESTRICT cart_input, const unsigned long ncart_input, double* PRAGMA_RESTRICT cart_out, const unsigned long ncart_out)"" % function_name\n\n\n    try:\n        cartesian_input = {x[1:]: x[0] for x in cartesian_order_factory(L, cartesian_order_inner)}\n        cartesian_output = {x[1:]: x[0] for x in cartesian_order_factory(L, cartesian_order_outer)}\n    except KeyError:\n\n        cg.start_c_block(signature)\n        cg.close_c_block()\n\n        return signature\n\n\n    cg.start_c_block(signature)\n    cg.blankline()\n    cg.write(""ASSUME_ALIGNED(%s, %d)"" % (""cart_input"", align));\n\n    cg.write(""unsigned long in_shift"")\n    cg.write(""unsigned long out_shift"")\n    cg.write(""double coef"")\n\n    for label, order in cartesian_input.items():\n        cg.blankline()\n        cg.write(""// Copy %s"" % str(label))\n\n        shift = cartesian_output[label]\n        cg.write(""in_shift = %d * ncart_input"" % order)\n        cg.write(""coef = vector[%d]"" % cartesian_output[label])\n\n        cg.start_c_block(""for (unsigned long i = 0; i < size; i++)"")\n        cg.write(""cart_out[i] += coef * cart_input[in_shift + i]"")\n        cg.close_c_block()\n\n    cg.close_c_block()\n\n    return signature\n\n\n\ndef block_copy(cg, align=32):\n    """"""\n    Copies a small block of data back to a larger array.\n    """"""\n\n    sig = ""void block_copy(unsigned long n, unsigned long m, const double* PRAGMA_RESTRICT input, unsigned long is, double* PRAGMA_RESTRICT output, unsigned long os, const int trans)""\n    # nout, nremain\n\n    cg.start_c_block(sig)\n    cg.blankline()\n    cg.write(""ASSUME_ALIGNED(%s, %d)"" % (""input"", align));\n    cg.start_c_block(""for (unsigned long i = 0; i < n; i++)"")\n    cg.write(""const unsigned long out_shift = i * os"")\n    cg.write(""const unsigned long inp_shift = i * is"")\n\n    # Inner copy over block\n    cg.blankline()\n    # cg.write(""PRAGMA_VECTORIZE"", endl="""")\n    cg.start_c_block(""for (unsigned long j = 0; j < m; j++)"")\n    # cg.write(""output[is * j + i] = input[i * is + j]"")\n    cg.write(""output[out_shift + j] = input[inp_shift + j]"")\n    cg.close_c_block()\n\n    # Close i loop\n    cg.close_c_block()\n\n    # Close func\n    cg.close_c_block()\n    return sig\n\ndef block_matrix_vector(cg, align=32):\n    """"""\n    Sums a vector_i input_ij -> output_j\n    """"""\n\n    sig = ""void block_matrix_vector(unsigned long n, unsigned long m, const double* vector, const double* PRAGMA_RESTRICT input, unsigned long is, double* PRAGMA_RESTRICT output)""\n    # nout, nremain\n\n    cg.start_c_block(sig)\n    cg.blankline()\n    cg.write(""ASSUME_ALIGNED(%s, %d)"" % (""input"", align));\n    cg.start_c_block(""for (unsigned long i = 0; i < n; i++)"")\n    cg.write(""const unsigned long inp_shift = i * is"")\n    cg.write(""const double coef = vector[i]"")\n\n    # Inner copy over block\n    cg.blankline()\n    # cg.write(""PRAGMA_VECTORIZE"", endl="""")\n    cg.start_c_block(""for (unsigned long j = 0; j < m; j++)"")\n    cg.write(""output[j] += coef * input[inp_shift + j]"")\n    cg.close_c_block()\n\n    # Close i loop\n    cg.close_c_block()\n\n    # Close func\n    cg.close_c_block()\n    return sig\n'"
gau2grid/c_wrapper.py,19,"b'""""""\nA Python wrapper for the compiled GG functions.\n""""""\n\nimport ctypes\nimport ctypes.util\nimport os\n\nimport numpy as np\n\nfrom . import docs_generator\nfrom . import utility\n\n# Attempt to load the compiled C code\n__lib_found = False\n__libgg_path = None\ncgg = None\n\n# First check the local folder\ntry:\n    abs_path = os.path.dirname(os.path.abspath(__file__))\n    cgg = np.ctypeslib.load_library(""gg"", abs_path)\n    __libgg_path = os.path.join(abs_path, cgg._name)\n    __lib_found = True\nexcept OSError:\n    try:\n        cgg = np.ctypeslib.load_library(""libgg"", abs_path)\n        __libgg_path = os.path.join(abs_path, cgg._name)\n        __lib_found = True\n    except OSError:\n        cgg = None\n\n__order_enum = {\n    ""spherical"": {\n        ""cca"": 300,\n        ""gaussian"": 301,\n    },\n    ""cartesian"": {\n        ""cca"": 400,\n        ""molden"": 401,\n    }\n}\n\n\ndef _build_collocation_ctype(nout, orbital=False):\n    """"""\n    Builds the ctypes signatures for the libgg C lib\n    """"""\n    ret = [\n        # L, npoints\n        ctypes.c_int,\n        ctypes.c_ulong,\n\n        # XYZ, stride\n        np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags=(""C"", ""A"")),\n        ctypes.c_ulong,\n\n        # Gaussian, nprim, coef, exp, center\n        ctypes.c_int,\n        np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags=(""C"", ""A"")),  # coef\n        np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags=(""C"", ""A"")),  # exp\n        np.ctypeslib.ndpointer(dtype=np.double, shape=(3, ), ndim=1, flags=(""C"", ""A"")),  # center\n\n        # Spherical\n        ctypes.c_int,\n    ]\n    if orbital:\n        ret.insert(1, ctypes.c_ulong)  # norbs\n        ret.insert(1, np.ctypeslib.ndpointer(dtype=np.double, ndim=2, flags=(""C"", ""A"")))  # orbs\n\n    # Pushback output\n    for n in range(nout):\n        ret.append(np.ctypeslib.ndpointer(dtype=np.double, ndim=2, flags=(""W"", ""C"", ""A"")))\n\n    return tuple(ret)\n\n\n# Bind the C object\nif cgg is not None:\n\n    # Helpers\n    cgg.gg_ncomponents.argtypes = (ctypes.c_int, ctypes.c_int)\n    cgg.gg_ncomponents.restype = ctypes.c_int\n\n    # Transposes\n    cgg.gg_naive_transpose.restype = None\n    cgg.gg_naive_transpose.argtypes = (ctypes.c_ulong, ctypes.c_ulong, np.ctypeslib.ndpointer(),\n                                       np.ctypeslib.ndpointer())\n\n    cgg.gg_fast_transpose.restype = None\n    cgg.gg_fast_transpose.argtypes = (ctypes.c_ulong, ctypes.c_ulong, np.ctypeslib.ndpointer(),\n                                      np.ctypeslib.ndpointer())\n\n    # Collocation generators\n    cgg.gg_orbitals.restype = None\n    cgg.gg_orbitals.argtypes = _build_collocation_ctype(1, orbital=True)\n\n    cgg.gg_collocation.restype = None\n    cgg.gg_collocation.argtypes = _build_collocation_ctype(1)\n\n    cgg.gg_collocation.restype = None\n    cgg.gg_collocation_deriv1.argtypes = _build_collocation_ctype(4)\n\n    cgg.gg_collocation.restype = None\n    cgg.gg_collocation_deriv2.argtypes = _build_collocation_ctype(10)\n\n    cgg.gg_collocation.restype = None\n    cgg.gg_collocation_deriv3.argtypes = _build_collocation_ctype(20)\n\n\ndef c_compiled():\n    """"""\n    Checks if the c code has been compiled or not.\n    """"""\n    return __lib_found\n\n\ndef _validate_c_import():\n    """"""\n    Throws an error if libgg is not found.\n    """"""\n    if c_compiled() is False:\n        raise ImportError(""Compiled libgg not found. Please compile gau2grid before calling these\\n""\n                          ""  functions. Alternatively, use the NumPy-based collocation functions found at\\n""\n                          ""  gau2grid.ref.collocation or gau2grid.ref.collocation_basis. It should\\n""\n                          ""  be noted that these functions are dramatically slower (4-20x).\\n"")\n\n\ndef cgg_path():\n    """"""\n    Returns the path to the found libgg.so/dylib/dll object.\n    """"""\n    _validate_c_import()\n    return __libgg_path\n\n\ndef get_cgg_shared_object():\n    """"""\n    Returns the compiled C shared object.\n    """"""\n    _validate_c_import()\n\n    return cgg\n\n\ndef max_L():\n    """"""\n    Return the maximum compiled angular momentum.\n    """"""\n\n    return cgg.gg_max_L()\n\n\ndef ncomponents(L, spherical=True):\n    """"""\n    Computes the number of components for spherical and cartesian gaussians of a given L\n\n    Parameters\n    ----------\n    L : int\n        The angular momentum of the basis function\n    spherical : bool, optional\n        Spherical (True) or Cartesian (False) number of components\n\n    Returns\n    -------\n    int\n        The number of components in the gaussian.\n    """"""\n\n    return cgg.gg_ncomponents(L, spherical)\n\n\ndef _wrapper_checks(L, xyz, spherical, spherical_order, cartesian_order):\n    if L > cgg.gg_max_L():\n        raise ValueError(""LibGG was only compiled to AM=%d, requested AM=%d."" % (cgg.max_L(), L))\n\n    # Check XYZ\n    if xyz.shape[0] != 3:\n        raise ValueError(""XYZ array must be of shape (3, N), found %s"" % str(xyz.shape))\n\n\n# Validate the input\n    try:\n        if spherical:\n            order_name = spherical_order\n            order_enum = __order_enum[""spherical""][spherical_order]\n        else:\n            order_name = cartesian_order\n            order_enum = __order_enum[""cartesian""][cartesian_order]\n    except KeyError:\n        raise KeyError(""Order Spherical=%s:%s not understood."" % (spherical, order_name))\n\n    return order_enum\n\n\ndef collocation_basis(xyz, basis, grad=0, spherical=True, out=None, cartesian_order=""cca"", spherical_order=""cca""):\n\n    return utility.wrap_basis_collocation(collocation,\n                                          xyz,\n                                          basis,\n                                          grad,\n                                          spherical=spherical,\n                                          out=out,\n                                          cartesian_order=cartesian_order,\n                                          spherical_order=spherical_order)\n\n\n# Write common docs\ncollocation_basis.__doc__ = docs_generator.build_collocation_basis_docs(\n    ""This function uses a optimized C library as a backend."")\n\n\ndef orbital_basis(orbs, xyz, basis, spherical=True, out=None, cartesian_order=""cca"", spherical_order=""cca""):\n\n    return utility.wrap_basis_orbital(orbital,\n                                      orbs,\n                                      xyz,\n                                      basis,\n                                      spherical=spherical,\n                                      out=out,\n                                      cartesian_order=cartesian_order,\n                                      spherical_order=spherical_order)\n\n\norbital_basis.__doc__ = docs_generator.build_orbital_basis_docs(\n    ""This function uses a optimized C library as a backend."")\n\n\ndef collocation(xyz,\n                L,\n                coeffs,\n                exponents,\n                center,\n                grad=0,\n                spherical=True,\n                out=None,\n                cartesian_order=""cca"",\n                spherical_order=""cca""):\n\n    # Validates we loaded correctly\n    _validate_c_import()\n\n    order_enum = _wrapper_checks(L, xyz, spherical, spherical_order, cartesian_order)\n\n    # Check gaussian\n    coeffs = np.asarray(coeffs, dtype=np.double)\n    exponents = np.asarray(exponents, dtype=np.double)\n    center = np.asarray(center, dtype=np.double)\n    if coeffs.shape[0] != exponents.shape[0]:\n        raise ValueError(""Coefficients (N=%d) and exponents (N=%d) must have the same shape."" %\n                         (coeffs.shape[0], exponents.shape[0]))\n\n    # Find the output shape\n    npoints = xyz.shape[1]\n    if spherical:\n        nvals = utility.nspherical(L)\n    else:\n        nvals = utility.ncartesian(L)\n\n    # Build the outputs\n    out = utility.validate_coll_output(grad, (nvals, npoints), out)\n\n    # Select the correct function\n    if grad == 0:\n        cgg.gg_collocation(L, npoints, xyz.ravel(), 1, coeffs.shape[0], coeffs, exponents, center, order_enum,\n                           out[""PHI""])\n    elif grad == 1:\n        cgg.gg_collocation_deriv1(L, npoints, xyz.ravel(), 1, coeffs.shape[0], coeffs, exponents, center, order_enum,\n                                  out[""PHI""], out[""PHI_X""], out[""PHI_Y""], out[""PHI_Z""])\n    elif grad == 2:\n        cgg.gg_collocation_deriv2(L, npoints, xyz.ravel(), 1, coeffs.shape[0], coeffs, exponents, center, order_enum,\n                                  out[""PHI""], out[""PHI_X""], out[""PHI_Y""], out[""PHI_Z""], out[""PHI_XX""], out[""PHI_XY""],\n                                  out[""PHI_XZ""], out[""PHI_YY""], out[""PHI_YZ""], out[""PHI_ZZ""])\n    elif grad == 3:\n        cgg.gg_collocation_deriv3(L, npoints, xyz.ravel(), 1, coeffs.shape[0], coeffs, exponents, center, order_enum,\n                                  out[""PHI""], out[""PHI_X""], out[""PHI_Y""], out[""PHI_Z""], out[""PHI_XX""], out[""PHI_XY""],\n                                  out[""PHI_XZ""], out[""PHI_YY""], out[""PHI_YZ""], out[""PHI_ZZ""], out[""PHI_XXX""],\n                                  out[""PHI_XXY""], out[""PHI_XXZ""], out[""PHI_XYY""], out[""PHI_XYZ""], out[""PHI_XZZ""],\n                                  out[""PHI_YYY""], out[""PHI_YYZ""], out[""PHI_YZZ""], out[""PHI_ZZZ""])\n    else:\n        raise ValueError(""Only up to grad=3 is supported."")\n\n    return out\n\n\ncollocation.__doc__ = docs_generator.build_collocation_docs(""This function uses a optimized C library as a backend."")\n\n\ndef orbital(orbs,\n            xyz,\n            L,\n            coeffs,\n            exponents,\n            center,\n            spherical=True,\n            out=None,\n            cartesian_order=""cca"",\n            spherical_order=""cca""):\n\n    # Validates we loaded correctly\n    _validate_c_import()\n\n    order_enum = _wrapper_checks(L, xyz, spherical, spherical_order, cartesian_order)\n\n    # Check gaussian\n    orbs = np.asarray(orbs, dtype=np.double)\n    coeffs = np.asarray(coeffs, dtype=np.double)\n    exponents = np.asarray(exponents, dtype=np.double)\n    center = np.asarray(center, dtype=np.double)\n    if coeffs.shape[0] != exponents.shape[0]:\n        raise ValueError(""Coefficients (N=%d) and exponents (N=%d) must have the same shape."" %\n                         (coeffs.shape[0], exponents.shape[0]))\n\n    # Find the output shape\n    npoints = xyz.shape[1]\n    if spherical:\n        nvals = utility.nspherical(L)\n    else:\n        nvals = utility.ncartesian(L)\n\n    if nvals != orbs.shape[1]:\n        raise ValueError(""Orbital block, must be equal to the shell size."")\n\n    # Build the outputs\n    if out is not None:\n        out = {""PHI"": out}\n    out = utility.validate_coll_output(0, (orbs.shape[0], npoints), out)[""PHI""]\n\n    # Select the correct function\n    cgg.gg_orbitals(L, orbs, orbs.shape[0], npoints, xyz.ravel(), 1, coeffs.shape[0], coeffs, exponents, center,\n                    order_enum, out)\n\n    return out\n\n\norbital.__doc__ = docs_generator.build_orbital_docs(""This function uses a optimized C library as a backend."")\n'"
gau2grid/codegen.py,0,"b'""""""\nContains a simple codegen helper\n""""""\n\n\nclass CodeGen(object):\n    def __init__(self, indent=""    "", cgen=False):\n        self.indent_lvl = 0\n        self.indent_tab = indent\n        self.data = []\n        self.cgen = cgen\n\n    def indent(self, lvl=1):\n        """"""\n        Indents the code one or more levels\n        """"""\n\n        self.indent_lvl += lvl\n\n    def dedent(self, lvl=1):\n        """"""\n        Dedents the code one or more levels\n        """"""\n\n        self.indent_lvl -= lvl\n        if self.indent_lvl < 0:\n            last_lines = ""\\n"".join(self.data[-4:])\n            raise ValueError(""Indent level is negative! Last lines:\\n\\n%s"" % last_lines)\n\n    def write(self, line, endl=None):\n        """"""\n        Write a line with the current indent\n        """"""\n        shift = self.indent_lvl * self.indent_tab\n        if self.cgen and (endl is None) and (""//"" not in line) and (""#"" not in line):\n            endl = "";""\n        if endl is None:\n            endl = """"\n\n        self.data.append(shift + line + endl)\n\n    def blankline(self):\n        """"""\n        Inserts a blankline\n        """"""\n        self.data.append("""")\n\n    def repr(self, filename=None, combine=""\\n"", clang_format=False):\n        """"""\n        Combine the data into a single string, optionally write to file, and format.\n        """"""\n        tmp = combine.join(self.data)\n        if clang_format:\n            if self.cgen is False:\n                raise KeyError(""clang_format is only valid for c generation."")\n            try:\n                tmp = run_clang_format(tmp)\n            except (OSError, AttributeError) as e:\n                print(str(e))\n\n        if filename is not None:\n            with open(filename, ""w"") as outfile:\n                outfile.write(tmp)\n        return tmp\n\n    def start_c_block(self, line=None):\n        """"""\n        Opens a C block with open brackets and indention\n        """"""\n\n        if self.cgen is False:\n            raise KeyError(""Start c block only valid for c generation."")\n\n        if line is None:\n            self.write(""{"", endl="""")\n        else:\n            self.write(line + "" {"", endl="""")\n\n        self.indent()\n\n    def close_c_block(self):\n        """"""\n        Ends a c block with a dedent and close line\n        """"""\n        if self.cgen is False:\n            raise KeyError(""Start c block only valid for c generation."")\n\n        self.dedent()\n        self.write(""}"", endl="""")\n\n\ndef run_clang_format(text):\n    import subprocess as sp\n    import shutil\n    import os\n\n    cf_path = None\n    try:\n        cf_path = shutil.which(""clang-format"")\n    except AttributeError:\n        # Python 3.2 or less\n        for path in os.environ[""PATH""].split("":""):\n            path = os.path.join(path, ""clang-format"")\n            if os.path.exists(path):\n                cf_path = path\n                break\n\n    if cf_path is None:\n        return text\n\n    fname = ""codegen.cf.tmp""\n\n    with open(fname, ""w"") as cfile:\n        cfile.write(text)\n\n    # Run and check output code\n    retcode = sp.call([cf_path, ""-i"", fname], stdin=sp.PIPE, stdout=sp.PIPE, stderr=sp.PIPE)\n    if retcode:\n        raise OSError(""Clang-format failed, skipping."")\n\n    with open(fname, ""r"") as cfile:\n        text = cfile.read()\n\n    os.unlink(fname)\n    return text\n'"
gau2grid/docs_generator.py,0,"b'""""""\nContains several docstrings as there are several duplicate functions\n""""""\n\n__doc_header = r""""""\n\n    .. math::\n\n        \\phi_{m p} = Y_\\ell^m \\sum_i c_i e^{ -\\alpha_{i} | \\phi_{\\rm center} - p | ^2}\n\n    Where for a given angular momentum :math:`\\ell`, components :math:`m` range from :math:`+\\ell` to :math:`-\\ell`\n    for each grid point :math:`p`.\n\n""""""\n\n__basis_str = """"""\n    basis : list of dicts\n        Each dict should contain the following keys (L, coeffs, exponents, center).\n\n        L : int\n            The angular momentum of the gaussian\n        coeffs : array_like\n            The coefficients of the gaussian\n        exponents : array_like\n            The exponents of the gaussian\n        center : array_like\n            The cartesian center of the gaussian""""""\n\n__doc_notes = """"\n# __doc_notes = """"""\n#     Notes\n#     -----\n#     For cartesian output the ""row"" order is used:\n#     L_0 = .\n#     L_1 = X, Y, Z\n#     L_2 = XX, XY, XZ, YY, YZ, ZZ.\n#     ...\n\n#     For spherical harmonics a 0-based ordering is used:\n#     L_0 = R_00\n#     L_1 = R_10, R_11c, R_11s\n#     L_2 = R_20, R_21c, R_21s, R_22c, R_22s\n#     ...\n# """"""\n\n\ndef build_collocation_docs(insert=""""):\n\n    doc_header = ""    Computes the collocation matrix for a given gaussian basis of the form:""\n    doc_header += __doc_header\n\n    param_data = """"""\n\n    Parameters\n    ----------\n    xyz : array_like\n        The ``(3, N)`` cartesian points to compute the grid on\n    L : int\n        The angular momentum of the gaussian\n    coeffs : array_like\n        The coefficients of the gaussian\n    exponents : array_like\n        The exponents of the gaussian\n    center : array_like\n        The cartesian center of the gaussian\n    grad : int, optional (default: 0)\n        Can return cartesian gradient and Hessian per point if requested.\n    spherical : bool, optional (default: True)\n        Transform the resulting cartesian gaussian to spherical\n    out : dict, optional\n        A dictionary of output NumPy arrays to write the data to.\n    %s\n    Returns\n    -------\n    dict of array_like\n        Returns a dictionary containing the requested arrays (``PHI``, ``PHI_X``, ``PHI_XX``, etc).\n        Where each matrix is of shape ``(ngaussian_basis x npoints)``\n    """"""\n\n    ret = doc_header\n    if insert == """":\n        ret += ""\\n""\n    else:\n        ret += ""    "" + insert\n\n    ret += param_data % __doc_notes\n    return ret\n\n\ndef build_orbital_docs(insert=""""):\n\n    doc_header = ""    Computes a array of a given orbital on a grid for a given gaussian basis of the form:""\n    doc_header += __doc_header\n\n    param_data = """"""\n\n    Parameters\n    ----------\n    orbitals : array_like\n        The ``(norb, nval)`` section of orbitals.\n    xyz : array_like\n        The ``(3, N)`` cartesian points to compute the grid on\n    L : int\n        The angular momentum of the gaussian\n    coeffs : array_like\n        The coefficients of the gaussian\n    exponents : array_like\n        The exponents of the gaussian\n    center : array_like\n        The cartesian center of the gaussian\n    spherical : bool, optional (default: True)\n        Transform the resulting cartesian gaussian to spherical\n    out : dict, optional\n        A dictionary of output NumPy arrays to write the data to.\n    %s\n\n    Returns\n    -------\n    array_like\n        Returns a ``(norb, N)`` array of the orbitals on a grid.\n    """"""\n\n    ret = doc_header\n    if insert == """":\n        ret += ""\\n""\n    else:\n        ret += ""    "" + insert\n\n    ret += param_data % __doc_notes\n    return ret\n\n\ndef build_collocation_basis_docs(insert=""""):\n\n    doc_header = ""    Computes the collocation matrix for a given gaussian basis of the form:""\n    doc_header += __doc_header\n\n    param_data = """"""\n\n    xyz : array_like\n        The ``(3, N)`` cartesian points to compute the grid on\n    %s\n    grad : int, default=0\n        Can return cartesian gradient and Hessian per point if requested.\n    spherical : bool, default=True\n        Transform the resulting cartesian gaussian to spherical\n    out : dict, optional\n        A dictionary of output NumPy arrays to write the data to.\n    %s\n\n    Returns\n    -------\n    dict of array_like\n        Returns a dictionary containing the requested arrays (``PHI``, ``PHI_X``, ``PHI_XX``, etc).\n        Where each matrix is of shape (ngaussian_basis x npoints)\n    """"""\n\n    ret = doc_header\n    if insert == """":\n        ret += ""\\n""\n    else:\n        ret += ""    "" + insert\n\n    ret += param_data % (__basis_str, __doc_notes)\n    return ret\n\n\ndef build_orbital_basis_docs(insert=""""):\n\n    doc_header = ""    Computes a array of a given orbital on a grid for a given gaussian basis of the form:""\n    doc_header += ""    "" + __doc_header\n\n    param_data = """"""\n\n    orbital : array_line\n        A ``(norb, nao)`` orbital array aligned to the orbitals basis\n    xyz : array_like\n        The (3, N) cartesian points to compute the grid on\n    %s\n    spherical : bool, default=True\n        Transform the resulting cartesian gaussian to spherical\n    out : dict, optional\n        A dictionary of output NumPy arrays to write the data to.\n    %s\n    Returns\n    -------\n    array_like\n        Returns a ``(norb, N)`` array of the orbitals on a grid.\n    """"""\n\n    ret = doc_header\n    # if insert == """":\n    #     ret += ""\\n""\n    # else:\n    #     ret += ""    "" + insert\n\n    ret += param_data % (__basis_str, __doc_notes)\n    return ret\n'"
gau2grid/extras.py,0,"b'""""""\nAdditional functionality not directly related to gau2grid.\n""""""\n\nimport os\n\n# Testing\ndef test():\n    """"""\n    Runs a smoke test suite through pytest.\n    """"""\n\n    try:\n        import pytest\n    except ImportError:\n        raise RuntimeError(\'Testing module `pytest` is not installed. Run `conda install pytest`\')\n\n    abs_test_dir = os.path.sep.join([os.path.abspath(os.path.dirname(__file__)), ""tests""])\n    retcode = pytest.main([\'-rws\', \'-v\', \'--capture=sys\', abs_test_dir])\n    return retcode\n'"
gau2grid/order.py,0,"b'""""""\nContains the different possible cartesian and spherical ordering codes.\n""""""\n\n\ndef row_cartesian_order(L):\n    """"""Row major cartesian order for a given orbital angular momentum.\n\n    0: [""""],\n    1: [""X"", ""Y"", ""Z""],\n    2: [""XX"", ""YY"", ""ZZ"", ""XY"", ""XZ"", ""YZ""],\n    ...\n\n    Parameters\n    ----------\n    L : int\n        Angular momentum of the shell.\n\n    Yields\n    ------\n    tuple\n        A tuple describing a component of a shell. (index, lx, ly, lz)\n    """"""\n    idx = -1\n    for i in range(L + 1):\n        l = L - i\n        for j in range(i + 1):\n            m = i - j\n            n = j\n            idx += 1\n            yield (idx, l, m, n)\n\n\ndef molden_cartesian_order(L):\n    """"""Molden cartesian order for a given orbital angular momentum.\n\n    0: [""""]\n    1: [""X"", ""Y"", ""Z""]\n    2: [""XX"", ""YY"", ""ZZ"", ""XY"", ""XZ"", ""YZ""]\n    ...\n\n    Parameters\n    ----------\n    L : int\n        Angular momentum of the shell.\n\n    Yields\n    ------\n    tuple\n        A tuple describing a component of a shell. (index, lx, ly, lz)\n    """"""\n    # http://www.cmbi.ru.nl/molden/molden_format.html\n    if L == 0:\n        data = [(0, 0, 0, 0)]\n    elif L == 1:\n        data = [(0, 1, 0, 0), (1, 0, 1, 0), (2, 0, 0, 1)]\n    elif L == 2:\n        data = [(0, 2, 0, 0), (1, 0, 2, 0), (2, 0, 0, 2), (3, 1, 1, 0), (4, 1, 0, 1), (5, 0, 1, 1)]\n    elif L == 3:\n        data = [(0, 3, 0, 0), (1, 0, 3, 0), (2, 0, 0, 3), (3, 1, 2, 0), (4, 2, 1, 0), (5, 2, 0, 1), (6, 1, 0, 2),\n                (7, 0, 1, 2), (8, 0, 2, 1), (9, 1, 1, 1)]\n    elif L == 4:\n        data = [(0, 4, 0, 0), (1, 0, 4, 0), (2, 0, 0, 4), (3, 3, 1, 0), (4, 3, 0, 1), (5, 1, 3, 0), (6, 0, 3,\n                                                                                                     1), (7, 1, 0, 3),\n                (8, 0, 1, 3), (9, 2, 2, 0), (10, 2, 0, 2), (11, 0, 2, 2), (12, 2, 1, 1), (13, 1, 2, 1), (14, 1, 1, 2)]\n    else:\n        raise KeyError(""Molden ordering only goes to 4 (G)"")\n\n    for x in data:\n        yield x\n\n\ndef cartesian_order_factory(L, order=""row""):\n    """"""Creates a iterator which will yield individual components of a shell of a given angular momentum.\n\n    Parameters\n    ----------\n    L : int\n        Angular momentum of the shell.\n    order : str, optional\n        The type of order to consider. Options: [""row"", ""cca"", ""molden""]\n\n    Returns\n    -------\n    iterator\n        An iterator which will yield a single component of a orbital shell as tuple of (index, lx, ly, lz).\n\n    """"""\n    if order.lower() in [""row"", ""cca""]:\n        return row_cartesian_order(L)\n    elif order.lower() in [""molden""]:\n        return molden_cartesian_order(L)\n    # if order.lower() in [""libint""]:\n    #     return libint_cartesian_order(L)\n    else:\n        raise KeyError(""Cartesian order \'%s\' not understood"" % order)\n'"
gau2grid/python_reference.py,9,"b'""""""\nPython reference for the collocation matrix and transformation code.\n""""""\nimport numpy as np\n\nfrom . import RSH\nfrom . import docs_generator\nfrom . import order\nfrom . import utility\n\n\ndef collocation_basis(xyz, basis, grad=0, spherical=True, out=None, cartesian_order=""row"", spherical_order=""cca""):\n    return utility.wrap_basis_collocation(collocation, xyz, basis, grad, spherical, out, cartesian_order,\n                                          spherical_order)\n\n\ncollocation_basis.__doc__ = docs_generator.build_collocation_basis_docs(\n    ""This function uses a reference NumPy expression as a backed."")\n\n\ndef collocation(xyz, L, coeffs, exponents, center, grad=0, spherical=True, cartesian_order=""row"", spherical_order=""cca"", out=None):\n\n    if grad > 3:\n        raise ValueError(""Only up to 3rd derivatives of the points (grad = 3) is supported."")\n\n    # Unpack the shell data\n    nprim = len(coeffs)\n    npoints = xyz.shape[1]\n\n    # First compute the diff distance in each cartesian\n    xc = xyz[0] - center[0]\n    yc = xyz[1] - center[1]\n    zc = xyz[2] - center[2]\n    R2 = xc * xc + yc * yc + zc * zc\n\n    # Build up the derivates in each direction\n    V1 = np.zeros(npoints)\n    V2 = np.zeros(npoints)\n    V3 = np.zeros(npoints)\n    V4 = np.zeros(npoints)\n    for K in range(nprim):\n        T1 = coeffs[K] * np.exp(-exponents[K] * R2)\n        T2 = -2.0 * exponents[K] * T1\n        T3 = -2.0 * exponents[K] * T2\n        T4 = -2.0 * exponents[K] * T3\n        V1 += T1\n        V2 += T2\n        V3 += T3\n        V4 += T4\n\n    S = V1.copy()\n    SX = V2 * xc\n    SY = V2 * yc\n    SZ = V2 * zc\n    SXY = V3 * xc * yc\n    SXZ = V3 * xc * zc\n    SYZ = V3 * yc * zc\n    SXX = V3 * xc * xc + V2\n    SYY = V3 * yc * yc + V2\n    SZZ = V3 * zc * zc + V2\n    SXXX = V4 * xc * xc * xc + 3 * V3 * xc\n    SXXY = V4 * xc * xc * yc + V3 * yc\n    SXXZ = V4 * xc * xc * zc + V3 * zc\n    SXYY = V4 * xc * yc * yc + V3 * xc\n    SXYZ = V4 * xc * yc * zc\n    SXZZ = V4 * xc * zc * zc + V3 * xc\n    SYYY = V4 * yc * yc * yc + 3 * V3 * yc\n    SYYZ = V4 * yc * yc * zc + V3 * zc\n    SYZZ = V4 * yc * zc * zc + V3 * yc\n    SZZZ = V4 * zc * zc * zc + 3 * V3 * zc\n\n    # SX, SY, SZ, SXX, SXZ, SXZ, SYY, SYZ, SZZ\n\n    # Power matrix for higher angular momenta\n    xc_pow = np.zeros((L + 3, npoints))\n    yc_pow = np.zeros((L + 3, npoints))\n    zc_pow = np.zeros((L + 3, npoints))\n\n    xc_pow[0] = 0.0\n    yc_pow[0] = 0.0\n    zc_pow[0] = 0.0\n    xc_pow[1] = 0.0\n    yc_pow[1] = 0.0\n    zc_pow[1] = 0.0\n    xc_pow[2] = 1.0\n    yc_pow[2] = 1.0\n    zc_pow[2] = 1.0\n\n    for LL in range(3, L + 3):\n        xc_pow[LL] = xc_pow[LL - 1] * xc\n        yc_pow[LL] = yc_pow[LL - 1] * yc\n        zc_pow[LL] = zc_pow[LL - 1] * zc\n\n    # Allocate data\n    ncart = utility.ncartesian(L)\n    nsph = utility.nspherical(L)\n    if spherical:\n        keys = utility.get_output_keys(grad)\n        out = utility.validate_coll_output(grad, (nsph, npoints), out)\n        tmps = {k: np.zeros((ncart, npoints)) for k in keys}\n    else:\n        out = utility.validate_coll_output(grad, (ncart, npoints), out)\n        tmps = out\n\n    # Loop over grid ordering data and compute by row\n    for idx, l, m, n in order.cartesian_order_factory(L, cartesian_order):\n\n        # build a few indices\n        l = l + 2\n        m = m + 2\n        n = n + 2\n\n        ld1 = l - 1\n        ld2 = l - 2\n        ld3 = l - 3\n        md1 = m - 1\n        md2 = m - 2\n        md3 = m - 3\n        nd1 = n - 1\n        nd2 = n - 2\n        nd3 = n - 3\n\n        A = xc_pow[l] * yc_pow[m] * zc_pow[n]\n        AX = ld2 * xc_pow[ld1] * yc_pow[m] * zc_pow[n]\n        AY = md2 * xc_pow[l] * yc_pow[md1] * zc_pow[n]\n        AZ = nd2 * xc_pow[l] * yc_pow[m] * zc_pow[nd1]\n\n        tmps[""PHI""][idx] = S * A\n        if grad > 0:\n            tmps[""PHI_X""][idx] = S * AX + SX * A\n            tmps[""PHI_Y""][idx] = S * AY + SY * A\n            tmps[""PHI_Z""][idx] = S * AZ + SZ * A\n        if grad > 1:\n            AXY = ld2 * md2 * xc_pow[ld1] * yc_pow[md1] * zc_pow[n]\n            AXZ = ld2 * nd2 * xc_pow[ld1] * yc_pow[m] * zc_pow[nd1]\n            AYZ = md2 * nd2 * xc_pow[l] * yc_pow[md1] * zc_pow[nd1]\n            AXX = ld2 * (ld2 - 1) * xc_pow[ld2] * yc_pow[m] * zc_pow[n]\n            AYY = md2 * (md2 - 1) * xc_pow[l] * yc_pow[md2] * zc_pow[n]\n            AZZ = nd2 * (nd2 - 1) * xc_pow[l] * yc_pow[m] * zc_pow[nd2]\n            tmps[""PHI_XX""][idx] = SXX * A + SX * AX + SX * AX + S * AXX\n            tmps[""PHI_YY""][idx] = SYY * A + SY * AY + SY * AY + S * AYY\n            tmps[""PHI_ZZ""][idx] = SZZ * A + SZ * AZ + SZ * AZ + S * AZZ\n            tmps[""PHI_XY""][idx] = SXY * A + SX * AY + SY * AX + S * AXY\n            tmps[""PHI_XZ""][idx] = SXZ * A + SX * AZ + SZ * AX + S * AXZ\n            tmps[""PHI_YZ""][idx] = SYZ * A + SY * AZ + SZ * AY + S * AYZ\n        if grad > 2:\n            AXYZ = ld2 * md2 * nd2 * xc_pow[ld1] * yc_pow[md1] * zc_pow[nd1]\n            AXXY = ld2 * (ld2 - 1) * md2 * xc_pow[ld2] * yc_pow[md1] * zc_pow[n]\n            AXXZ = ld2 * (ld2 - 1) * nd2 * xc_pow[ld2] * yc_pow[m] * zc_pow[nd1]\n            AXYY = md2 * (md2 - 1) * ld2 * xc_pow[ld1] * yc_pow[md2] * zc_pow[n]\n            AXZZ = nd2 * (nd2 - 1) * ld2 * xc_pow[ld1] * yc_pow[m] * zc_pow[nd2]\n            AYYZ = md2 * (md2 - 1) * nd2 * xc_pow[l] * yc_pow[md2] * zc_pow[nd1]\n            AYZZ = nd2 * (nd2 - 1) * md2 * xc_pow[l] * yc_pow[md1] * zc_pow[nd2]\n            AXXX = ld2 * (ld2 - 1) * (ld2 - 2) * xc_pow[ld3] * yc_pow[m] * zc_pow[n]\n            AYYY = md2 * (md2 - 1) * (md2 - 2) * xc_pow[l] * yc_pow[md3] * zc_pow[n]\n            AZZZ = nd2 * (nd2 - 1) * (nd2 - 2) * xc_pow[l] * yc_pow[m] * zc_pow[nd3]\n            tmps[""PHI_XYZ""][idx] = SXYZ * A + AX * SYZ + AY * SXZ + AZ * SXY + AXY * SZ + AXZ * SY + AYZ * SX + AXYZ * S\n            tmps[""PHI_XXY""][idx] = SXXY * A + 2 * AX * SXY + AY * SXX + AXX * SY + 2 * AXY * SX + AXXY * S \n            tmps[""PHI_XXZ""][idx] = SXXZ * A + 2 * AX * SXZ + AZ * SXX + AXX * SZ + 2 * AXZ * SX + AXXZ * S \n            tmps[""PHI_XYY""][idx] = SXYY * A + 2 * AY * SXY + AX * SYY + AYY * SX + 2 * AXY * SY + AXYY * S \n            tmps[""PHI_XZZ""][idx] = SXZZ * A + 2 * AZ * SXZ + AX * SZZ + AZZ * SX + 2 * AXZ * SZ + AXZZ * S \n            tmps[""PHI_YYZ""][idx] = SYYZ * A + 2 * AY * SYZ + AZ * SYY + AYY * SZ + 2 * AYZ * SY + AYYZ * S \n            tmps[""PHI_YZZ""][idx] = SYZZ * A + 2 * AZ * SYZ + AY * SZZ + AZZ * SY + 2 * AYZ * SZ + AYZZ * S \n            tmps[""PHI_XXX""][idx] = SXXX * A + 3 * AX * SXX + 3 * AXX * SX + AXXX * S \n            tmps[""PHI_YYY""][idx] = SYYY * A + 3 * AY * SYY + 3 * AYY * SY + AYYY * S \n            tmps[""PHI_ZZZ""][idx] = SZZZ * A + 3 * AZ * SZZ + 3 * AZZ * SZ + AZZZ * S \n\n    # Transform results back to spherical\n    if spherical:\n        for k, v in out.items():\n            out[k][:] = RSH.cart_to_spherical_transform(tmps[k], L, cartesian_order, spherical_order)\n\n    return out\n\n\ncollocation.__doc__ = docs_generator.build_collocation_docs(\n    ""This function uses a reference NumPy expression as a backed."")\n'"
gau2grid/utility.py,3,"b'""""""\nProvides utility functions for the gau2grid program\n""""""\n\nimport numpy as np\n\n\ndef get_deriv_indices(grad):\n    """"""\n    Returns the indices of the derivatives involved in the grid derivatives\n\n    Examples\n    --------\n    >>> get_deriv_indices(1)\n    [""x"", ""y"", ""z""]\n    """"""\n    if grad == 0:\n        return []\n    elif grad == 1:\n        return [""x"", ""y"", ""z""]\n    elif grad == 2:\n        return [""x"", ""y"", ""z"", ""xx"", ""xy"", ""xz"", ""yy"", ""yz"", ""zz""]\n    elif grad == 3:\n        return [""x"", ""y"", ""z"", ""xx"", ""xy"", ""xz"", ""yy"", ""yz"", ""zz"",\n                ""xxx"", ""xxy"", ""xxz"", ""xyy"", ""xyz"", ""xzz"", ""yyy"", ""yyz"", ""yzz"", ""zzz"" ]\n    else:\n        raise ValueError(""Only grid derivatives up to grad=3 are supported."")\n\n\ndef get_output_keys(grad):\n    """"""\n    Returns the output keys required for a given derivative\n\n    Examples\n    --------\n    >>> get_output_keys(1)\n    [""PHI"", ""PHI_X"", ""PHI_Y"", ""PHI_Z""]\n    """"""\n\n    phi = [""PHI""]\n\n    if grad == 0:\n        return phi\n\n    deriv_keys = [""PHI_"" + x.upper() for x in get_deriv_indices(grad)]\n    return phi + deriv_keys\n\n\ndef validate_coll_output(grad, shape, out):\n    """"""\n    Validates the a collocation output, constructs a new\n    output array if necessary\n    """"""\n    keys_needed = get_output_keys(grad)\n    if out is None:\n        out = {k: np.zeros(shape) for k in keys_needed}\n    else:\n        if not isinstance(out, dict):\n            raise TypeError(""Output parameter must be a dictionary."")\n        missing = set(keys_needed) - set(out)\n        if len(missing):\n            raise KeyError(""Missing output keys \'%s\'"" % str(missing))\n\n        for key in keys_needed:\n            out[key] = np.asarray(out[key])\n            if out[key].shape != shape:\n                raise ValueError(\n                    ""Shape of each output array must be (ntotal, npoints). Shape of key \'%s\' is incorrect."" % key)\n    return out\n\n\ndef nspherical(L):\n    """"""\n    Computes the number of spherical functions for a given angular momentum.\n\n    Parameters\n    ----------\n    L : int\n        The input angular momentum\n\n    Returns\n    -------\n    nspherical : int\n        The number of spherical functions\n    """"""\n\n    return L * 2 + 1\n\n\ndef ncartesian(L):\n    """"""\n    Computes the number of cartesian functions for a given angular momentum.\n\n    Parameters\n    ----------\n    L : int\n        The input angular momentum\n\n    Returns\n    -------\n    ncartesian : int\n        The number of cartesian functions\n    """"""\n\n    return int((L + 1) * (L + 2) / 2)\n\n\ndef _parse_basis(basis, spherical):\n    # Check the basis\n    parsed_basis = []\n    for num, func in enumerate(basis):\n        # TODO more checks\n\n        # Either list or dict form\n        if isinstance(func, (list, tuple)):\n            if len(func) != 4:\n                raise ValueError(""Basis should have 4 components (L, coeffs, exponents, center)."")\n            parsed_basis.append(func)\n\n        elif isinstance(func, dict):\n            missing = {""am"", ""coef"", ""exp"", ""center""} - set(func)\n            if len(missing):\n                raise KeyError(""Missing function keys \'%s\'"" % str(missing))\n\n            tmp = [func[""am""], func[""coef""], func[""exp""], func[""center""]]\n            parsed_basis.append(tmp)\n        else:\n            raise TypeError(""Basis type not recognized!"")\n\n    # The total number of output parameters\n    if spherical:\n        nfunc = [nspherical(func[0]) for func in parsed_basis]\n        ntotal = sum(nfunc)\n    else:\n        nfunc = [ncartesian(func[0]) for func in parsed_basis]\n        ntotal = sum(nfunc)\n\n    return parsed_basis, nfunc, ntotal\n\n\ndef wrap_basis_collocation(coll_function, xyz, basis, grad, spherical, out, cartesian_order, spherical_order):\n    """"""\n    Wraps collocation computers to apply to entire basis sets.\n\n    Expects the basis to take the form of:\n        [L, coeffs, exponents, center]\n    """"""\n\n    # A few checkers\n    if grad > 3:\n        raise IndexError(""Can only compute up to 3rd derivatives of the grid (grad=3)."")\n\n    parsed_basis, nfunc, ntotal = _parse_basis(basis, spherical)\n    npoints = xyz.shape[1]\n\n    # Handle output\n    out = validate_coll_output(grad, (ntotal, npoints), out)\n\n    # Loop over functions in the basis set\n    start = 0\n    for n, func in enumerate(parsed_basis):\n        # Build slice\n        nvals = nfunc[n]\n        sl = slice(start, start + nvals)\n        start += nvals\n\n        # Build temporary output views\n        tmp_out = {k: v[sl] for k, v in out.items()}\n\n        coll_function(\n            xyz,\n            *func,\n            grad=grad,\n            spherical=spherical,\n            out=tmp_out,\n            cartesian_order=cartesian_order,\n            spherical_order=spherical_order)\n\n    return out\n\n\ndef wrap_basis_orbital(orbital_function, orbs, xyz, basis, spherical, out, cartesian_order, spherical_order):\n    """"""\n    Wraps orbital computers to apply to entire basis sets.\n\n    Expects the basis to take the form of:\n        [L, coeffs, exponents, center]\n    """"""\n\n    parsed_basis, nfunc, ntotal = _parse_basis(basis, spherical)\n    npoints = xyz.shape[1]\n    norbs = orbs.shape[0]\n\n    # Handle output\n    if out is not None:\n        out = {""PHI"": out}\n    out = validate_coll_output(0, (norbs, npoints), out)[""PHI""]\n\n    # Loop over functions in the basis set\n    start = 0\n    for n, func in enumerate(parsed_basis):\n        # Build slice\n        nvals = nfunc[n]\n        sl = slice(start, start + nvals)\n        start += nvals\n\n        # Build temporary output views\n        tmp_orbs = np.array(orbs[:, sl])\n\n        orbital_function(\n            tmp_orbs,\n            xyz,\n            *func,\n            spherical=spherical,\n            out=out,\n            cartesian_order=cartesian_order,\n            spherical_order=spherical_order)\n\n    return out\n'"
scripts/make_release_sources.py,0,"b'import gau2grid as gg\nfrom pathlib import Path\nimport os\nimport zipfile\nimport tempfile\nimport shutil\n\nam_list = [6, 8]\n\nfor am in am_list:\n\n    folder = f""gau2grid-am{am}-{gg.__version__}""\n    zip_filename = folder + \'.zip\'\n    zipf = zipfile.ZipFile(zip_filename, \'w\', zipfile.ZIP_DEFLATED)\n\n    path = Path(folder)\n    path.mkdir(parents=True)\n    gg.c_gen.generate_c_gau2grid(am, path=path.resolve())\n\n    for filename in path.iterdir():\n        zipf.write(filename)\n\n    shutil.rmtree(path.resolve())\n\n#    with tempfile.TemporaryDirectory() as tmp:\n#        os.chdir(tmp)\n#\n#        folder = f""gau2grid-am{am}-{gg.__version__}""\n#        zip_filename = folder + \'.zip\'\n#        zip_path = os.path.join(tmp, zip_filename)\n#        zipf = zipfile.ZipFile(zip_path, \'w\', zipfile.ZIP_DEFLATED)\n#\n#        path = Path(tmp) / folder\n#        path.mkdir(parents=True)\n#        gg.c_gen.generate_c_gau2grid(am, path=path.resolve())\n#\n#        for filename in path.iterdir():\n#            arcname = os.path.join(*str(filename).split(os.path.sep)[-2:])\n#            print(filename, arcname)\n#            zipf.write(filename, arcname=arcname)\n#        \n'"
scripts/rsh_coef_gen.py,1,"b'""""""\nBuilds a new RSH dictionary for gau2grid.\n""""""\nimport gau2grid\nimport numpy as np\nimport decimal\nimport pickle\nimport time\nnp.set_printoptions(precision=60)\n\nt = time.time()\nrsh_dict = {}\nfor AM in range(9):\n    print(""AM %d"" % AM)\n    data = gau2grid.RSH.cart_to_RSH_coeffs(AM, gen=True)\n    rsh_dict[AM] = data\nprint(time.time() - t)\n\nwith open(""rsh_coeffs.pkl"", ""wb"") as handle:\n    pickle.dump(rsh_dict, handle, protocol=2)\n\n\nwith open(""rsh_coeffs.pkl"", ""rb"") as handle:\n    data = pickle.load(handle)\n\nfor x in range(5):\n    print(data[x])\n'"
scripts/time_compare.py,10,"b'import numpy as np\nimport time\n\nnp.random.seed(0)\n\nimport gau2grid as gg\n\n### Options\n\n#npoints = int(5)\nnpoints = int(1.e5)\n\nL = 2\nnprim = 1\n\nspherical = False\nspherical = True\n\ndo_transpose = False\n#do_transpose = True\n\n### Test\n\nxyz = np.random.rand(3, npoints)\n\ngrad_inds = [""PHI_X"", ""PHI_Y"", ""PHI_Z""]\nhess_inds = [""PHI_XX"", ""PHI_XY"", ""PHI_XZ"", ""PHI_YY"", ""PHI_YZ"", ""PHI_ZZ""]\n\n\ndef compare(test, ref, grad):\n    """"""\n    Compares two results\n    """"""\n    print(""%-6s %s"" % (""PHI"", np.allclose(test[""PHI""], ref[""PHI""])))\n    if grad > 0:\n        print(\'--\')\n        for key in grad_inds:\n            print(""%-6s %s"" % (key, np.allclose(test[key], ref[key])))\n    if grad > 1:\n        print(\'--\')\n        for key in hess_inds:\n            print(""%-6s %s"" % (key, np.allclose(test[key], ref[key])))\n\n\ndef transpose_dict(inp, out):\n    return\n\n#pygg.fast_transpose(inp[k], out[k])\n\n\ndef build_out(nvals, npoints, grad):\n    """"""\n    Builds output zeros to prevent cost effecting timings\n    """"""\n    inds = [""PHI""]\n    if grad > 0:\n        inds += grad_inds\n    if grad > 1:\n        inds += hess_inds\n\n    return {k: np.zeros((nvals, npoints)) for k in inds}\n\n\nncart = int((L + 1) * (L + 2) / 2)\nnsph = L * 2 + 1\n\nnvals = ncart\nif spherical:\n    nvals = nsph\n\ncoefs = np.arange(nprim, dtype=np.double) + 1\nexps = np.arange(nprim, dtype=np.double) + 2\n#center = np.array([5, 5, 5])\ncenter = np.array([0, 0, 0], dtype=np.double)\n\n### Points\n\n# Call pyGG\ngg_out = build_out(nvals, npoints, 0)\ntran_out = build_out(npoints, nvals, 0)\nt = time.time()\nif do_transpose:\n    transpose_dict(gg_out, tran_out)\n\ngg.collocation(xyz, L, coefs, exps, center, grad=0, spherical=spherical, out=gg_out)\n#gg_out[""PHI""] = gg_out[""PHI""].copy().reshape(npoints, nvals).T\nctime = (time.time() - t)\n\n# Call NP GG\nt = time.time()\nnp_out = gg.ref.collocation(xyz, L, coefs, exps, center, grad=0, spherical=spherical, cartesian_order=""row"")\npytime = (time.time() - t)\n\n# print(c_out.shape)\n# print(np_out[""PHI""].shape)\nprint(""PHI"")\ncompare(gg_out, np_out, 0)\n#print(np_out[""PHI""])\n#print(gg_out[""PHI""])\n\nprint(""C time  %12.6f"" % ctime)\nprint(""Py time %12.6f"" % pytime)\nprint(""Ratio   %12.6f"" % (pytime / ctime))\n\n### Derivatives\n\nprint(""\\nDerivative"")\n# Call pyGG\ngg_out = build_out(nvals, npoints, 1)\ntran_out = build_out(npoints, nvals, 1)\nt = time.time()\nif do_transpose:\n    transpose_dict(gg_out, tran_out)\ngg.collocation(xyz, L, coefs, exps, center, grad=1, spherical=spherical, out=gg_out)\nctime = (time.time() - t)\n\n# Call NP GG\nt = time.time()\nnp_out = gg.ref.collocation(xyz, L, coefs, exps, center, grad=1, spherical=spherical, cartesian_order=""row"")\npytime = (time.time() - t)\n\ncompare(gg_out, np_out, 1)\n\nprint(""C time  %12.6f"" % ctime)\nprint(""Py time %12.6f"" % pytime)\nprint(""Ratio   %12.6f"" % (pytime / ctime))\n\n### Hessian\n\nprint(""\\nHessian"")\ngg_out = build_out(nvals, npoints, 2)\ntran_out = build_out(npoints, nvals, 2)\nt = time.time()\ngg.collocation(xyz, L, coefs, exps, center, grad=2, spherical=spherical, out=gg_out)\nif do_transpose:\n    transpose_dict(gg_out, tran_out)\nctime = (time.time() - t)\n\n# Call NP GG\nt = time.time()\nnp_out = gg.ref.collocation(xyz, L, coefs, exps, center, grad=2, spherical=spherical, cartesian_order=""row"")\npytime = (time.time() - t)\n#print(np_out[""PHI_X""])\n#print(np_out[""PHI_Y""])\n#print(np_out[""PHI_Z""])\n\ncompare(gg_out, np_out, 2)\n\nprint(""C time  %12.6f"" % ctime)\nprint(""Py time %12.6f"" % pytime)\nprint(""Ratio   %12.6f"" % (pytime / ctime))\n'"
devtools/scripts/conda_env.py,0,"b'import argparse\nimport json\nimport os\nimport shutil\nimport subprocess as sp\n\n# Args\nparser = argparse.ArgumentParser(description=\'Creates a conda environment from file for a given Python version.\')\nparser.add_argument(\'-n\', \'--name\', type=str, nargs=1,\n                    help=\'The name of the created Python environment\')\nparser.add_argument(\'-p\', \'--python\', type=str, nargs=1,\n                    help=\'The version of the created Python environment\')\nparser.add_argument(\'conda_file\', nargs=\'*\',\n                    help=\'The file for the created Python environment\')\n\nargs = parser.parse_args()\n\nwith open(args.conda_file[0], ""r"") as handle:\n    script = handle.read()\n\ntmp_file = ""tmp_env.yaml""\nscript = script.replace(""- python"", ""- python {}*"".format(args.python[0]))\n\nwith open(tmp_file, ""w"") as handle:\n    handle.write(script)\n\n# Figure out conda path\nif ""CONDA_EXE"" in os.environ:\n    conda_path = os.environ[""CONDA_EXE""]\nelse:\n    conda_path = shutil.which(""conda"")\n\nprint(""CONDA ENV NAME  {}"".format(args.name[0]))\nprint(""PYTHON VERSION  {}"".format(args.python[0]))\nprint(""CONDA FILE NAME {}"".format(args.conda_file[0]))\nprint(""CONDA path      {}"".format(conda_path))\n\nsp.call(""{} env create -n {} -f {}"".format(conda_path, args.name[0], tmp_file), shell=True)\nos.unlink(tmp_file)\n'"
docs/source/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\n# sys.path.insert(0, os.path.abspath(\'.\'))\n\nsys.path.insert(0, os.path.abspath(\'../..\'))\nimport gau2grid\n\n\n# -- Project information -----------------------------------------------------\n\nproject = \'gau2grid\'\ncopyright = \'2018, Daniel G. A. Smith\'\nauthor = \'Daniel G. A. Smith\'\n\n# The short X.Y version\nversion = gau2grid.__version__\n# The full version, including alpha/beta/rc tags\nrelease = gau2grid.__version__\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.autosummary\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.napoleon\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path .\nexclude_patterns = []\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'default\'\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\'t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\'localtoc.html\', \'relations.html\', \'sourcelink.html\',\n# \'searchbox.html\']``.\n#\n# html_sidebars = {}\n\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'gau2griddoc\'\n\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'gau2grid.tex\', \'gau2grid Documentation\',\n     \'Daniel G. A. Smith\', \'manual\'),\n]\n\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'gau2grid\', \'gau2grid Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'gau2grid\', \'gau2grid Documentation\',\n     author, \'gau2grid\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n\n# -- Extension configuration -------------------------------------------------\n'"
gau2grid/tests/__init__.py,0,b''
gau2grid/tests/ref_basis.py,0,"b'test_basis = {\n    ""single-1s"": [{\n        \'center\': [0., 0., 0.],\n        \'exp\': [38.36, 1.e-1],\n        \'coef\': [2.5, 1.5],\n        \'am\': 0\n    }],\n    ""single-1p"": [{\n        \'center\': [0., 0., 0.],\n        \'exp\': [38.36, 1.e-1],\n        \'coef\': [2.5, 1.5],\n        \'am\': 1\n    }],\n    ""single-1d"": [{\n        \'center\': [0., 0., 0.],\n        \'exp\': [38.36, 1.e-1],\n        \'coef\': [2.5, 1.5],\n        \'am\': 2\n    }],\n    ""single-2s"": [{\n        \'center\': [0., 0., 0.],\n        \'exp\': [38.36, 1.e-1],\n        \'coef\': [2.5, 1.5],\n        \'am\': 0\n    },\n    {\n        \'center\': [0., 0., 1.],\n        \'exp\': [40.36, 10.77, 5.24],\n        \'coef\': [0.44135347600549724, 0.6934968471367846, 0.6641842253258472],\n        \'am\': 0\n    }],\n    ""cc-pVDZ"": [{\n        \'center\': [0., 0., 0.],\n        \'exp\': [38.36, 5.77, 1.24],\n        \'coef\': [0.44135347600549724, 0.6934968471367846, 0.6641842253258472],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.2976],\n        \'coef\': [0.28716716940915],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [1.275],\n        \'coef\': [1.9312025173106264],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [6665.0, 1000.0, 228.0, 64.71, 21.06, 7.495, 2.797, 0.5215],\n        \'coef\': [\n            0.3635842998065758, 0.6749857928202053, 1.1316199409548326, 1.6530092121132332, 1.9238206437042997,\n            1.4472783162053624, 0.43916312920743356, 0.0066458036681944005\n        ],\n        \'am\':\n        0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [6665.0, 1000.0, 228.0, 64.71, 21.06, 7.495, 2.797, 0.5215],\n        \'coef\': [\n            -0.15417974831696596, -0.29378537353969814, -0.48089580383835073, -0.7614343161217384, -0.9001038922786649,\n            -0.9726113518152741, -0.3940419460353377, 0.47839442486908734\n        ],\n        \'am\':\n        0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.1596],\n        \'coef\': [0.17996363533080056],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [9.439, 2.002, 0.5456],\n        \'coef\': [1.3437371094962303, 1.0631680878797416, 0.5082318338362495],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.1517],\n        \'coef\': [0.13494974363929313],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.55],\n        \'coef\': [0.5781548361892291],\n        \'am\': 2\n    }],\n    ""cc-pVTZ"": [{\n        \'center\': [0., 0., 0.],\n        \'exp\': [234.0, 35.16, 7.989, 2.212],\n        \'coef\': [0.3109111498784228, 0.5665439094158013, 0.8686186270728533, 0.9912097091412122],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.6669],\n        \'coef\': [0.5259635285661938],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.2089],\n        \'coef\': [0.22022363267224998],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [3.044],\n        \'coef\': [5.731204405620397],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.758],\n        \'coef\': [1.0081533438537973],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [1.965],\n        \'coef\': [5.367770348245947],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [8236.0, 1235.0, 280.8, 79.27, 25.59, 8.997, 3.319, 0.3643],\n        \'coef\': [\n            0.3342267437290266, 0.623074641610101, 1.053105907175737, 1.583163134228532, 1.9450988312081643,\n            1.6429469100201448, 0.6196591260874036, -0.003066727596880071\n        ],\n        \'am\':\n        0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [8236.0, 1235.0, 280.8, 79.27, 25.59, 8.997, 3.319, 0.3643],\n        \'coef\': [\n            -0.12101010978210466, -0.2265691065646341, -0.38575328973148, -0.5967016835701715, -0.7858351261554027,\n            -0.8165330321269189, -0.5188700867627601, 0.3477346660092945\n        ],\n        \'am\':\n        0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.9059],\n        \'coef\': [0.6617901318396681],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.1285],\n        \'coef\': [0.15296336817449552],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [18.71, 4.133, 1.2],\n        \'coef\': [2.1868515589384936, 2.050312341280497, 1.4599445297103084],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.3827],\n        \'coef\': [0.42905519588435137],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.1209],\n        \'coef\': [0.10161854305479753],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.097],\n        \'coef\': [1.9354014159719681],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.318],\n        \'coef\': [0.22164447815916097],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.761],\n        \'coef\': [0.7962875534181346],\n        \'am\': 3\n    }],\n    ""cc-pVQZ"": [{\n        \'center\': [0., 0., 0.],\n        \'exp\': [528.5, 79.31, 18.05, 5.085],\n        \'coef\': [0.46145452827470973, 0.8538653991195814, 1.4030592847322472, 1.9271042712608932],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [1.609],\n        \'coef\': [1.0181860095745041],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.5363],\n        \'coef\': [0.4466485618439204],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.1833],\n        \'coef\': [0.1996558045893794],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [5.994],\n        \'coef\': [13.36860252829213],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [1.745],\n        \'coef\': [2.858803973154869],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.56],\n        \'coef\': [0.6905181870838725],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [4.299],\n        \'coef\': [21.125280546621475],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [1.223],\n        \'coef\': [2.341023406708012],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [2.68],\n        \'coef\': [13.528752018633634],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [33980.0, 5089.0, 1157.0, 326.6, 106.1, 38.11, 14.75, 6.035, 2.53],\n        \'coef\': [\n            0.1634507261062438, 0.3044212243332817, 0.5257838689933758, 0.8468983407346078, 1.255764373372071,\n            1.6186445796014381, 1.6508946063126861, 1.1035299844183581, 0.31248567483708534\n        ],\n        \'am\':\n        0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [33980.0, 5089.0, 1157.0, 326.6, 106.1, 38.11, 14.75, 6.035, 2.53],\n        \'coef\': [\n            -0.0993718990834113, -0.19012697709862444, -0.32543340763752193, -0.5336611751361328, -0.7952977918754661,\n            -1.094938007810732, -1.213813200515633, -1.1385061171713298, -0.49474883373545114\n        ],\n        \'am\':\n        0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.7355],\n        \'coef\': [0.5660399709765215],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.2905],\n        \'coef\': [0.28201336769754937],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.1111],\n        \'coef\': [0.13714994457481866],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [34.51, 7.915, 2.368],\n        \'coef\': [3.778018950380443, 4.028726502872025, 3.515465074138135],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.8132],\n        \'coef\': [1.1007452000846343],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.289],\n        \'coef\': [0.30203856019464964],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.1007],\n        \'coef\': [0.08085873190604055],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.848],\n        \'coef\': [4.821008511624612],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.649],\n        \'coef\': [0.7723918375207073],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.228],\n        \'coef\': [0.12382132254845869],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.419],\n        \'coef\': [3.235302098757608],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.485],\n        \'coef\': [0.2889837095091748],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.011],\n        \'coef\': [1.1468354346860716],\n        \'am\': 4\n    }],\n    ""cc-pV5Z"": [{\n        \'center\': [0., 0., 0.],\n        \'exp\': [1145.0, 171.7, 39.07, 11.04],\n        \'coef\': [0.7380918729709687, 1.372859543128198, 2.326160936595324, 3.5151818682868052],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [3.566],\n        \'coef\': [1.8494649122166864],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [1.24],\n        \'coef\': [0.8374836865202823],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.4473],\n        \'coef\': [0.3898156455349628],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.164],\n        \'coef\': [0.1836720098211005],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [10.153],\n        \'coef\': [25.833489349067868],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [3.627],\n        \'coef\': [7.134680544947165],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [1.296],\n        \'coef\': [1.9710440934087394],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.463],\n        \'coef\': [0.5443977563568185],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [7.666],\n        \'coef\': [58.13061026837216],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [2.647],\n        \'coef\': [9.04125781450112],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.914],\n        \'coef\': [1.4062589475390226],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [5.411],\n        \'coef\': [65.73987909846028],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [1.707],\n        \'coef\': [4.903202978939761],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [3.43],\n        \'coef\': [32.998504307791954],\n        \'am\': 4\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [96770.0, 14500.0, 3300.0, 935.8, 306.2, 111.3, 43.9, 18.4, 8.054, 3.637],\n        \'coef\': [\n            0.10338463441967911, 0.1892300196831466, 0.3281677404717669, 0.5334399987570182, 0.8197924312886748,\n            1.1700100552197732, 1.4976131976071616, 1.6087382497487723, 1.2929161931856408, 0.5834828223937455\n        ],\n        \'am\':\n        0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [96770.0, 14500.0, 3300.0, 935.8, 306.2, 111.3, 43.9, 18.4, 8.054, 3.637],\n        \'coef\': [\n            -0.06224855727073559, -0.12293161539609407, -0.21043539452889135, -0.3443764571700645, -0.5293460581611003,\n            -0.7745118083970303, -1.0206917127579689, -1.2095549022717158, -1.1588716818781568, -0.861537240258568\n        ],\n        \'am\':\n        0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.656],\n        \'coef\': [1.0404119734216268],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.6333],\n        \'coef\': [0.5059611933793523],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.2545],\n        \'coef\': [0.2553735608723581],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.1019],\n        \'coef\': [0.12854072059813548],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [101.8, 24.04, 7.571, 2.732],\n        \'coef\': [3.110402641694326, 4.0089324328419, 4.293684144259667, 3.94378697508858],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.085],\n        \'coef\': [1.578437029078211],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.4496],\n        \'coef\': [0.5247747931188329],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.1876],\n        \'coef\': [0.17598721978831988],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.07606],\n        \'coef\': [0.05693580812460792],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [3.134],\n        \'coef\': [12.150179455809385],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.233],\n        \'coef\': [2.3746239310735566],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.485],\n        \'coef\': [0.4639353857697065],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.191],\n        \'coef\': [0.09082760213324197],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [2.006],\n        \'coef\': [7.0501610717932754],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.838],\n        \'coef\': [0.9891302676875409],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.35],\n        \'coef\': [0.13870992901469756],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.753],\n        \'coef\': [5.209975662902541],\n        \'am\': 4\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.678],\n        \'coef\': [0.38222323464616065],\n        \'am\': 4\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.259],\n        \'coef\': [1.568295112996155],\n        \'am\': 5\n    }],\n    ""cc-pV6Z"": [{\n        \'center\': [0., 0., 0.],\n        \'exp\': [4785.0, 717.0, 163.2, 46.26, 15.1],\n        \'coef\': [0.5492980072847908, 1.0362929443055922, 1.772863336362713, 2.856472519883292, 4.2491827504192345],\n        \'am\':\n        0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [5.437],\n        \'coef\': [2.5376375496458214],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [2.088],\n        \'coef\': [1.2379638500436236],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.8297],\n        \'coef\': [0.6195850210340811],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.3366],\n        \'coef\': [0.31495294669481405],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.1369],\n        \'coef\': [0.16040307081791438],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.387],\n        \'coef\': [0.4350896919103909],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.984],\n        \'coef\': [1.3969599680098106],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [2.498],\n        \'coef\': [4.476417969471105],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [6.342],\n        \'coef\': [14.345737671927447],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [16.104],\n        \'coef\': [45.984057577434875],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [0.747],\n        \'coef\': [0.9879171150357771],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [1.91],\n        \'coef\': [5.107611414746906],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [4.886],\n        \'coef\': [26.428834770986224],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [12.498],\n        \'coef\': [136.73521151333463],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [1.292],\n        \'coef\': [2.6199626821636093],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [3.462],\n        \'coef\': [24.068018833219146],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [9.276],\n        \'coef\': [221.06302808154655],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [2.236],\n        \'coef\': [10.173792440803908],\n        \'am\': 4\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [6.586],\n        \'coef\': [198.4472901517673],\n        \'am\': 4\n    }, {\n        \'center\': [0., 0., 0.],\n        \'exp\': [4.159],\n        \'coef\': [76.21810687973053],\n        \'am\': 5\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [312100.0, 46740.0, 10640.0, 3013.0, 982.8, 354.8, 138.4, 57.35, 24.92, 11.23, 5.201],\n        \'coef\': [\n            0.06241238335412585, 0.11686178146677664, 0.2025229998035736, 0.331883845860829, 0.5196895195398683,\n            0.7796582369887571, 1.1099778347548088, 1.4602361505227996, 1.6798835992492982, 1.5592862930303644,\n            0.980202962125158\n        ],\n        \'am\':\n        0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [312100.0, 46740.0, 10640.0, 3013.0, 982.8, 354.8, 138.4, 57.35, 24.92, 11.23, 5.201],\n        \'coef\': [\n            -0.0444503166102155, -0.08304266636116815, -0.14418407421038154, -0.23597736741135866, -0.3712079960204282,\n            -0.558281868845687, -0.8084366684479092, -1.0904316581229672, -1.3420429117438775, -1.409678213661604,\n            -1.2319524419545422\n        ],\n        \'am\':\n        0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [2.426],\n        \'coef\': [1.3854095902124604],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.9673],\n        \'coef\': [0.6951539311220889],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.4456],\n        \'coef\': [0.38870397229333087],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.1971],\n        \'coef\': [0.21082643275823246],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.08635],\n        \'coef\': [0.11352900946035223],\n        \'am\': 0\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [295.2, 69.98, 22.64, 8.485, 3.459],\n        \'coef\': [2.6695892766995146, 3.7811810358125713, 4.791716498985131, 5.214872146241128, 5.049027906679351],\n        \'am\':\n        1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.504],\n        \'coef\': [2.3741047842980945],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.6783],\n        \'coef\': [0.8774398594810375],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.3087],\n        \'coef\': [0.32799020536049356],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.14],\n        \'coef\': [0.12206752315491183],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.06178],\n        \'coef\': [0.043903583313808656],\n        \'am\': 1\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [4.542],\n        \'coef\': [23.259047921955737],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.979],\n        \'coef\': [5.434875452050322],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.8621],\n        \'coef\': [1.2695076875632945],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.3756],\n        \'coef\': [0.29660551880241864],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.1636],\n        \'coef\': [0.0692676143021213],\n        \'am\': 2\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [2.631],\n        \'coef\': [12.978555477989921],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.255],\n        \'coef\': [2.4541597708741256],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.5988],\n        \'coef\': [0.46434254883930615],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.2857],\n        \'coef\': [0.08785216944594705],\n        \'am\': 3\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [2.652],\n        \'coef\': [16.265319726826394],\n        \'am\': 4\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.204],\n        \'coef\': [1.8542072053265692],\n        \'am\': 4\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.547],\n        \'coef\': [0.21178762138633953],\n        \'am\': 4\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [2.03],\n        \'coef\': [7.408090675707613],\n        \'am\': 5\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [0.8511],\n        \'coef\': [0.4393201118180626],\n        \'am\': 5\n    }, {\n        \'center\': [0., 0., 3.77945227],\n        \'exp\': [1.491],\n        \'coef\': [2.0008705051325117],\n        \'am\': 6\n    }]\n}\n'"
gau2grid/tests/test_c_code.py,21,"b'""""""\nCompare the generated C code against the NumPy reference code.\n""""""\n\nimport os\nimport sys\nimport time\n\nimport numpy as np\nimport pytest\n\nimport gau2grid as gg\n\nnp.set_printoptions(linewidth=120, suppress=True)\n\n# Import locals\nfrom . import ref_basis\nfrom . import test_helper as th\n\n# Tweakers\nnpoints = int(1.e3)\nnpoints2 = int(npoints / 2)\n\n# Global points\nnp.random.seed(0)\nxyzw = np.random.rand(3, npoints)\n\n# LR points\nxyzw[:, npoints2:] += 5 * np.random.rand(3, npoints2)\n\n# Make sure the C-side has been compiled\nif ""GAU2GRID_FORCE_C_TEST"" in os.environ:\n    skip_c_test = False\nelse:\n    skip_c_test = gg.c_compiled() is False\ncheck_compile = pytest.mark.skipif(skip_c_test, reason=""Could not find the C compiled SO for gau2grid"")\n\ntest_basis_keys = list(ref_basis.test_basis.keys())\n# test_basis_keys = [""single-1s"", ""single-1p"", ""single-1d""]\n\ntest_orders = [\n    (""cartesian"", ""cca""),\n    (""cartesian"", ""molden""),\n    (""spherical"", ""cca""),\n    (""spherical"", ""gaussian"")\n] # yapf: disable\n\n@check_compile\n@pytest.mark.parametrize(""basis_name"", test_basis_keys)\n@pytest.mark.parametrize(""spherical, order_name"", test_orders)\ndef test_generator_collocation(basis_name, spherical, order_name):\n#\n    kwargs = {""grad"": 2, ""spherical"": ""spherical"" == spherical}\n\n    if kwargs[""spherical""]:\n        kwargs[""spherical_order""] = order_name\n    else:\n        kwargs[""cartesian_order""] = order_name\n\n\n    basis = ref_basis.test_basis[basis_name]\n\n    max_L = max(x[""am""] for x in basis)\n    if (order_name == ""molden"") and (max_L > 4):\n        pytest.skip(""Molden only goes to L=4."")\n\n    t = time.time()\n    gen_results = gg.collocation_basis(xyzw, basis, **kwargs)\n    gg_time = time.time() - t\n\n    t = time.time()\n    ref_results = gg.ref.collocation_basis(xyzw, basis, **kwargs)\n    ref_time = time.time() - t\n\n    # Print time with py.test -s flags\n    print("""")\n    print(""%s-%s time REF: %8.4f GG: %8.4f"" % (basis_name, spherical, ref_time, gg_time))\n\n    # print(ref_results[""PHI""])\n    # print(gen_results[""PHI""])\n    th.compare_collocation_results(gen_results, ref_results)\n\n@check_compile\n@pytest.mark.parametrize(""xyz_shape"", [3, 4, 5])\ndef test_generator_collocation_transposed(xyz_shape):\n\n    cgg = gg.get_cgg_shared_object()\n\n    # Collocation data\n    npoints = 2000\n    L = 2\n    nelem = 2 * L + 1\n    order_enum = 300\n    coeffs = np.array([2., 1])\n    exponents = np.array([1., 2])\n    center = np.array([0., 0, 0])\n\n    # Generate random points\n    data = np.random.rand(xyz_shape, npoints)\n    xyz = data[:3].copy()\n    xyz_t = data.transpose().copy()\n\n    out = np.zeros((nelem, npoints))\n    out_t = np.zeros((nelem, npoints))\n\n    cgg.gg_collocation(L, npoints, xyz.ravel(), 1, coeffs.shape[0], coeffs, exponents, center, order_enum,\n                       out)\n    cgg.gg_collocation(L, npoints, xyz_t.ravel(), xyz_shape, coeffs.shape[0], coeffs, exponents, center, order_enum,\n                       out_t)\n    th.compare_collocation_results({""PHI"": out}, {""PHI"": out_t})\n\n\n@check_compile\n@pytest.mark.parametrize(""basis_name"", test_basis_keys)\n@pytest.mark.parametrize(""spherical, order_name"", test_orders)\ndef test_generator_orbital(basis_name, spherical, order_name):\n\n    kwargs = {""grad"": 0, ""spherical"": ""spherical"" == spherical}\n\n    if kwargs[""spherical""]:\n        kwargs[""spherical_order""] = order_name\n    else:\n        kwargs[""cartesian_order""] = order_name\n\n    basis = ref_basis.test_basis[basis_name]\n\n    max_L = max(x[""am""] for x in basis)\n    if (order_name == ""molden"") and (max_L > 4):\n        pytest.skip(""Molden only goes to L=4."")\n\n    t = time.time()\n    phi = gg.collocation_basis(xyzw, basis, **kwargs)[""PHI""]\n    orbs = np.random.rand(5, phi.shape[0])\n    benchmark = np.dot(orbs, phi)\n    ref_time = time.time() - t\n\n    t = time.time()\n    del kwargs[""grad""]\n    ref_results = gg.orbital_basis(orbs, xyzw, basis, **kwargs)\n    gg_time = time.time() - t\n\n    # Print time with py.test -s flags\n    print("""")\n    print(""%s-%s time REF: %8.4f GG: %8.4f"" % (basis_name, spherical, ref_time, gg_time))\n    # print(benchmark)\n    # print(ref_results)\n\n    th.compare_collocation_results({""ORBITALS"": benchmark}, {""ORBITALS"": ref_results})\n\n@check_compile\n@pytest.mark.parametrize(""xyz_shape"", [3, 4, 5])\ndef test_generator_orbital_transposed(xyz_shape):\n\n    cgg = gg.get_cgg_shared_object()\n\n    # Collocation data\n    npoints = 2000\n    L = 2\n    nelem = 2 * L + 1\n    order_enum = 300\n    coeffs = np.array([2., 1])\n    exponents = np.array([1., 2])\n    center = np.array([0., 0, 0])\n\n    C = np.random.rand(2, nelem)\n\n    # Generate random points\n    data = np.random.rand(xyz_shape, npoints)\n    xyz = data[:3].copy()\n    xyz_t = data.transpose().copy()\n\n    out = np.zeros((nelem, npoints))\n    out_t = np.zeros((nelem, npoints))\n\n    cgg.gg_orbitals(L, C, C.shape[0], npoints, xyz.ravel(), 1, coeffs.shape[0], coeffs, exponents, center, order_enum,\n                       out)\n    cgg.gg_orbitals(L, C, C.shape[0], npoints, xyz_t.ravel(), xyz_shape, coeffs.shape[0], coeffs, exponents, center, order_enum,\n                       out_t)\n    th.compare_collocation_results({""ORB"": out}, {""ORB"": out_t})\n\n\n@check_compile\n@pytest.mark.parametrize(""grad"", [0, 1, 2, 3])\ndef test_generator_derivs(grad):\n    kwargs = {""spherical_order"": ""cca"", ""cartesian_order"": ""cca"", ""spherical"": False, ""grad"": grad}\n\n    basis = ref_basis.test_basis[""cc-pVDZ""]\n\n    gen_results = gg.collocation_basis(xyzw, basis, **kwargs)\n    ref_results = gg.ref.collocation_basis(xyzw, basis, **kwargs)\n\n    th.compare_collocation_results(gen_results, ref_results)\n\n\n@check_compile\n@pytest.mark.parametrize(""grad"", [0, 1, 2, 3])\ndef test_generator_derivs_spherical(grad):\n    kwargs = {""spherical_order"": ""cca"", ""cartesian_order"": ""cca"", ""spherical"": True, ""grad"": grad}\n\n    basis = ref_basis.test_basis[""cc-pVDZ""]\n\n    gen_results = gg.collocation_basis(xyzw, basis, **kwargs)\n    ref_results = gg.ref.collocation_basis(xyzw, basis, **kwargs)\n\n    th.compare_collocation_results(gen_results, ref_results)\n\n\n@check_compile\ndef test_libgg_path():\n    assert ""gg"" in gg.cgg_path()\n\n\n@check_compile\n@pytest.mark.parametrize(""am,spherical,result"", [\n    (0, True, 1),\n    (0, False, 1),\n    (1, True, 3),\n    (1, False, 3),\n    (2, True, 5),\n    (2, False, 6),\n    (3, True, 7),\n    (3, False, 10),\n])\ndef test_ncomponents(am, spherical, result):\n    assert gg.ncomponents(am, spherical) == result\n\n\n@check_compile\n@pytest.mark.parametrize(""spherical"", [True, False])\n@pytest.mark.parametrize(""am"", [0, 1, 2, 3, 4])\ndef test_generator_orbitals_am(spherical, am):\n    kwargs = {""spherical_order"": ""cca"", ""cartesian_order"": ""cca"", ""spherical"": spherical, ""grad"": 0}\n\n    # Build a single orbital\n    coeffs = [0.44135347600549724, 0.6934968471367846, 0.6641842253258472, 0.0001]\n    exponents = [38.36, 5.77, 1.24, 1.e-2]\n    center = [0., 0., 0.]\n    L = am\n\n    ret = gg.collocation(xyzw, L, coeffs, exponents, center, **kwargs)[""PHI""]\n    orb = np.random.rand(3, ret.shape[0])\n    bench = np.dot(orb, ret)\n\n    del kwargs[""grad""]\n    ret = gg.orbital(orb, xyzw, L, coeffs, exponents, center, **kwargs)\n\n    # Compare the results\n    th.compare_collocation_results({""ORBITALS"": bench}, {""ORBITALS"": ret})\n'"
gau2grid/tests/test_c_generator.py,1,"b'""""""\nCompare the generated C code against the NumPy reference code.\n""""""\n\nimport shutil\nimport tempfile\n\nimport numpy as np\nimport pytest\n\nimport gau2grid as gg\n\nnp.set_printoptions(linewidth=120, suppress=True)\n\n# Import locals\n\n# Simply test that the code runs for now\nc_gen_tests = []\nfor AM in range(4):\n    for grad in range(3):\n        c_gen_tests.append((AM, grad))\n\n\n@pytest.mark.parametrize(""AM,grad"", c_gen_tests)\ndef test_c_collocation_codgen(AM, grad):\n    cg = gg.codegen.CodeGen(cgen=True)\n    gg.c_gen.shell_c_generator(cg, AM, grad=grad)\n\n\n@pytest.mark.parametrize(""AM"", list(range(4)))\ndef test_c_spherical_trans_codgen(AM):\n    cg = gg.codegen.CodeGen(cgen=True)\n    gg.RSH.transformation_c_generator(cg, AM, ""row"", ""gaussian"")\n\n\ndef test_library_gen():\n\n    temp_dir = tempfile.mkdtemp()\n    gg.c_gen.generate_c_gau2grid(4, path=temp_dir)\n    shutil.rmtree(temp_dir)\n\n\ndef test_pybind11_gen():\n    cg = gg.codegen.CodeGen(cgen=True)\n    gg.c_util_generator.pybind11_func(cg, ""something"", 0, ""somthingelse"", 6)\n    gg.c_util_generator.pybind11_func(cg, ""something"", 1, ""somthingelse"", 6)\n    gg.c_util_generator.pybind11_func(cg, ""something"", 2, ""somthingelse"", 6)\n    gg.c_util_generator.pybind11_transpose(cg, ""t1"", ""t2"")\n'"
gau2grid/tests/test_helper.py,3,"b'""""""\nContains several testing helper function\n""""""\n\nimport glob\nimport os\n\nimport numpy as np\n\n\ndef compare_collocation_results(test, ref):\n    if set(test) != set(ref):\n        raise KeyError(""Test and Ref results dicts do not match"")\n\n    for k in ref.keys():\n        match = np.allclose(test[k], ref[k], atol=1.e-14, rtol=1.e-10)\n        if not match:\n            tnorm = np.linalg.norm(test[k])\n            rnorm = np.linalg.norm(ref[k])\n            raise ValueError(""Test (norm=%10.9f) and Ref (norm=%10.9f) results do not match for %s"" %\n                             (tnorm, rnorm, k))\n\n\ndef find_pygau2grid():\n    """"""\n    Finds a compiled pygau2grid code and attempts to run it\n    """"""\n    base_folder = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n\n    # Can expand this later\n    found = False\n    search_paths = [""objdir""]\n    for path in search_paths:\n        folder = os.path.join(base_folder, path)\n        find = glob.glob(os.path.join(folder, ""pygau2grid"") + ""*.so"")\n        if len(find) == 1:\n            found = os.path.dirname(find[0])\n            break\n        elif len(find) > 1:\n            raise ImportError(""Found multiple pygau2grid\'s. How is that possible?"")\n\n    return found\n'"
gau2grid/tests/test_order.py,0,"b'""""""\nTests the cartesian ordering code.\n""""""\n\nimport pytest\n\nimport gau2grid as gg\n\n_benchmark_data = {\n    ""molden"": {\n        0: [""""],\n        1: [""X"", ""Y"", ""Z""],\n        2: [""XX"", ""YY"", ""ZZ"", ""XY"", ""XZ"", ""YZ""],\n        3: [""XXX"", ""YYY"", ""ZZZ"", ""XYY"", ""XXY"", ""XXZ"", ""XZZ"", ""YZZ"", ""YYZ"", ""XYZ""],\n        4: [\n            ""XXXX"", ""YYYY"", ""ZZZZ"", ""XXXY"", ""XXXZ"", ""XYYY"", ""YYYZ"", ""XZZZ"", ""YZZZ"", ""XXYY"", ""XXZZ"", ""YYZZ"", ""XXYZ"",\n            ""XYYZ"", ""XYZZ""\n        ],\n    },\n    ""row"": {\n        0: [""""],\n        1: [""X"", ""Y"", ""Z""],\n        2: [""XX"", ""XY"", ""XZ"", ""YY"", ""YZ"", ""ZZ""],\n        3: [""XXX"", ""XXY"", ""XXZ"", ""XYY"", ""XYZ"", ""XZZ"", ""YYY"", ""YYZ"", ""YZZ"", ""ZZZ""],\n        4: [\n            ""XXXX"", ""XXXY"", ""XXXZ"", ""XXYY"", ""XXYZ"", ""XXZZ"", ""XYYY"", ""XYYZ"", ""XYZZ"", ""XZZZ"", ""YYYY"", ""YYYZ"", ""YYZZ"",\n            ""YZZZ"", ""ZZZZ""\n        ],\n    },\n    ""libint"": {\n        0: [""""],\n        1: [""X"", ""Y"", ""Z""],\n        2: [""XX"", ""YY"", ""ZZ"", ""XY"", ""YZ"", ""XZ""],\n        3: [""XXX"", ""YYY"", ""ZZZ"", ""XXY"", ""XXZ"", ""XYY"", ""YYZ"", ""XZZ"", ""YZZ"", ""XYZ""],\n        4: [\n            ""XXXX"", ""YYYY"", ""ZZZZ"", ""XXXY"", ""XXXZ"", ""XYYY"", ""YYYZ"", ""XZZZ"", ""YZZZ"", ""XXYY"", ""XXZZ"", ""YYZZ"", ""XXYZ"",\n            ""XYYZ"", ""XYZZ""\n        ],\n    }\n}\n\n\n@pytest.mark.parametrize(""order"", [""molden"", ""row""])\n@pytest.mark.parametrize(""L"", [0, 1, 2, 3, 4])\ndef test_cartesian_order(order, L):\n\n    data = _benchmark_data[order][L]\n\n    order_list = []\n    for idx, l, m, n in gg.order.cartesian_order_factory(L, order=order):\n        order = ""X"" * l + ""Y"" * m + ""Z"" * n\n        assert order == data[idx]\n        order_list.append(order)\n\n    # Check all values are unique\n    assert len(order_list) == len(set(order_list))\n\n    # Check all lengths are correct\n    assert all(len(x) == L for x in order_list)\n'"
gau2grid/tests/test_rsh.py,1,"b'""""""\nCompare the generated NumPy code against the NumPy reference code.\n""""""\n\nimport platform\n\nimport numpy as np\nimport pytest\nfrom decimal import Decimal\n\nnp.set_printoptions(precision=30)\n\nimport gau2grid as gg\n\n_benchmark = {\n    0: [[((0, 0, 0), Decimal(\'1.0\'))]],\n    1: [[((0, 0, 1), Decimal(\'1.0\'))],\n        [((1, 0, 0), Decimal(\'1.00000000000000000000000000000000000000000000000000000000000\'))],\n        [((0, 1, 0), Decimal(\'1.00000000000000000000000000000000000000000000000000000000000\'))]],\n    2: [[((2, 0, 0), Decimal(\'-0.50\')), ((0, 2, 0), Decimal(\'-0.50\')), ((0, 0, 2), Decimal(\'1.00\'))], [\n         ((1, 0, 1), Decimal(\'1.73205080756887729352744634150587236694280525381038062805581\'))],\n        [((0, 1, 1), Decimal(\'1.73205080756887729352744634150587236694280525381038062805581\'))],\n        [((2, 0, 0), Decimal(\'0.866025403784438646763723170752936183471402626905190314027905\')),\n         ((0, 2, 0), Decimal(\'-0.866025403784438646763723170752936183471402626905190314027905\'))],\n        [((1, 1, 0), Decimal(\'1.73205080756887729352744634150587236694280525381038062805581\'))]],\n    3: [[((2, 0, 1), Decimal(\'-1.500\')), ((0, 2, 1), Decimal(\'-1.500\')), ((0, 0, 3), Decimal(\'1.000\'))],\n        [((3, 0, 0), Decimal(\'-0.612372435695794524549321018676472847991486870164167532108173\')),\n         ((1, 2, 0), Decimal(\'-0.612372435695794524549321018676472847991486870164167532108173\')),\n         ((1, 0, 2), Decimal(\'2.44948974278317809819728407470589139196594748065667012843269\'))],\n        [((2, 1, 0), Decimal(\'-0.612372435695794524549321018676472847991486870164167532108173\')),\n         ((0, 3, 0), Decimal(\'-0.612372435695794524549321018676472847991486870164167532108173\')),\n         ((0, 1, 2), Decimal(\'2.44948974278317809819728407470589139196594748065667012843269\'))],\n        [((2, 0, 1), Decimal(\'1.93649167310370844258963269989119980541646085264579541329378\')),\n         ((0, 2, 1), Decimal(\'-1.93649167310370844258963269989119980541646085264579541329378\'))], [\n         ((1, 1, 1), Decimal(\'3.87298334620741688517926539978239961083292170529159082658757\'))],\n        [((3, 0, 0), Decimal(\'0.790569415042094832999723386108179633429888784831304206714378\')),\n         ((1, 2, 0), Decimal(\'-2.37170824512628449899917015832453890028966635449391262014313\'))],\n        [((2, 1, 0), Decimal(\'2.37170824512628449899917015832453890028966635449391262014313\')),\n         ((0, 3, 0), Decimal(\'-0.790569415042094832999723386108179633429888784831304206714378\'))]],\n    4: [[((4, 0, 0), Decimal(\'0.37500\')), ((2, 2, 0), Decimal(\'0.7500\')), ((0, 4, 0), Decimal(\'0.37500\')),\n         ((2, 0, 2), Decimal(\'-3.0000\')), ((0, 2, 2), Decimal(\'-3.0000\')), ((0, 0, 4), Decimal(\'1.0000\'))],\n        [((3, 0, 1), Decimal(\'-2.37170824512628449899917015832453890028966635449391262014313\')),\n         ((1, 2, 1), Decimal(\'-2.37170824512628449899917015832453890028966635449391262014313\')),\n         ((1, 0, 3), Decimal(\'3.16227766016837933199889354443271853371955513932521682685750\'))],\n        [((2, 1, 1), Decimal(\'-2.37170824512628449899917015832453890028966635449391262014313\')),\n         ((0, 3, 1), Decimal(\'-2.37170824512628449899917015832453890028966635449391262014313\')),\n         ((0, 1, 3), Decimal(\'3.16227766016837933199889354443271853371955513932521682685750\'))],\n        [((4, 0, 0), Decimal(\'-0.559016994374947424102293417182819058860154589902881431067725\')),\n         ((0, 4, 0), Decimal(\'0.559016994374947424102293417182819058860154589902881431067725\')),\n         ((2, 0, 2), Decimal(\'3.35410196624968454461376050309691435316092753941728858640634\')),\n         ((0, 2, 2), Decimal(\'-3.35410196624968454461376050309691435316092753941728858640634\'))],\n        [((3, 1, 0), Decimal(\'-1.11803398874989484820458683436563811772030917980576286213545\')),\n         ((1, 3, 0), Decimal(\'-1.11803398874989484820458683436563811772030917980576286213545\')),\n         ((1, 1, 2), Decimal(\'6.70820393249936908922752100619382870632185507883457717281269\'))],\n        [((3, 0, 1), Decimal(\'2.09165006633518886994543006446296872348203842324668049952799\')),\n         ((1, 2, 1), Decimal(\'-6.27495019900556660983629019338890617044611526974004149858395\'))],\n        [((2, 1, 1), Decimal(\'6.27495019900556660983629019338890617044611526974004149858395\')),\n         ((0, 3, 1), Decimal(\'-2.09165006633518886994543006446296872348203842324668049952799\'))],\n        [((4, 0, 0), Decimal(\'0.739509972887452005320916036445202131051937653849292540359963\')),\n         ((2, 2, 0), Decimal(\'-4.43705983732471203192549621867121278631162592309575524215978\')),\n         ((0, 4, 0), Decimal(\'0.739509972887452005320916036445202131051937653849292540359963\'))],\n        [((3, 1, 0), Decimal(\'2.95803989154980802128366414578080852420775061539717016143986\')),\n         ((1, 3, 0), Decimal(\'-2.95803989154980802128366414578080852420775061539717016143986\'))]]\n} # yapf: disable\n\n\ndef _test_shell(bench, comp):\n    comp_line = sorted(comp)\n    bench_line = sorted(bench)\n    assert len(comp_line) == len(bench_line)\n\n    for cart in range(len(comp_line)):\n        comp_coeff = comp_line[cart]\n        bench_coeff = bench_line[cart]\n\n        # Make sure cartesian alignment\n        assert comp_coeff[0] == bench_coeff[0]\n\n        # Check coefficient using Decimal tech\n        assert comp_coeff[1].quantize(bench_coeff[1]) == bench_coeff[1]\n\n    return True\n\n\n@pytest.mark.parametrize(""AM"", _benchmark.keys())\ndef test_RSH(AM):\n    # print(""AM %d"" % AM)\n\n    pkl_data = gg.RSH.cart_to_RSH_coeffs(AM)\n    bench_data = _benchmark[AM]\n\n    assert len(pkl_data) == len(bench_data)\n    for sph in range(len(pkl_data)):\n\n        assert _test_shell(bench_data[sph], pkl_data[sph])\n\n\ndef test_RSH_order_p():\n    gaus = gg.RSH.cart_to_RSH_coeffs(1, order=""gaussian"")\n    cca = gg.RSH.cart_to_RSH_coeffs(1, order=""cca"")\n\n    assert _test_shell(gaus[0], cca[1])\n    assert _test_shell(gaus[1], cca[2])\n    assert _test_shell(gaus[2], cca[0])\n\n\ndef test_RSH_order_d():\n    gaus = gg.RSH.cart_to_RSH_coeffs(2, order=""gaussian"")\n    cca = gg.RSH.cart_to_RSH_coeffs(2, order=""cca"")\n\n    assert _test_shell(gaus[0], cca[2])\n    assert _test_shell(gaus[1], cca[3])\n    assert _test_shell(gaus[2], cca[1])\n    assert _test_shell(gaus[3], cca[4])\n    assert _test_shell(gaus[4], cca[0])\n'"
