file_path,api_count,code
__init__.py,0,"b'__all__ = [\n    ""nnet"",\n    ""res_net""\n    ]\n'"
res_net.py,0,"b'from pyfunt import (SpatialConvolution, SpatialBatchNormalization,\n                SpatialAveragePooling, Sequential, ReLU, Linear,\n                Reshape, LogSoftMax, Padding, Identity, ConcatTable,\n                CAddTable)\n\n\ndef residual_layer(n_channels, n_out_channels=None, stride=1):\n    n_out_channels = n_out_channels or n_channels\n    \n    convs = Sequential()\n    add = convs.add\n    add(SpatialConvolution(\n        n_channels, n_out_channels, 3, 3, stride, stride, 1, 1))\n    add(SpatialBatchNormalization(n_out_channels))\n    add(SpatialConvolution(n_out_channels, n_out_channels, 3, 3, 1, 1, 1, 1))\n    add(SpatialBatchNormalization(n_out_channels))\n\n    if stride > 1:\n        shortcut = Sequential()\n        shortcut.add(SpatialAveragePooling(2, 2, stride, stride))\n        shortcut.add(Padding(1, (n_out_channels - n_channels)/2, 3))\n    else:\n        shortcut = Identity()\n\n    res = Sequential()\n    res.add(ConcatTable().add(convs).add(shortcut)).add(CAddTable())\n    # https://github.com/szagoruyko/wide-residual-networks/blob/master/models/resnet-pre-act.lua\n\n    res.add(ReLU(True))\n\n    return res\n\n\ndef resnet(n_size, num_starting_filters, reg):\n    \'\'\'\n    Implementation of [""Deep Residual Learning for Image Recognition"",Kaiming \\\n    He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - http://arxiv.org/abs/1512.03385\n\n    Inspired by https://github.com/gcr/torch-residual-networks\n\n    This network should model a similiar behaviour of gcr\'s implementation.\n    Check https://github.com/gcr/torch-residual-networks for more infos about \\\n    the structure.\n\n    The network operates on minibatches of data that have shape (N, C, H, W)\n    consisting of N images, each with height H and width W and with C input\n    channels.\n\n    The network has, like in the reference paper (except for the final optional\n    affine layers), (6*n)+2 layers, composed as below:\n\n                                                (image_dim: 3, 32, 32; F=16)\n                                                (input_dim: N, *image_dim)\n         INPUT\n            |\n            v\n       +-------------------+\n       |conv[F, *image_dim]|                    (out_shape: N, 16, 32, 32)\n       +-------------------+\n            |\n            v\n       +-------------------------+\n       |n * res_block[F, F, 3, 3]|              (out_shape: N, 16, 32, 32)\n       +-------------------------+\n            |\n            v\n       +-------------------------+\n       |res_block[2*F, F, 3, 3]  |              (out_shape: N, 32, 16, 16)\n       +-------------------------+\n            |\n            v\n       +---------------------------------+\n       |(n-1) * res_block[2*F, 2*F, 3, 3]|      (out_shape: N, 32, 16, 16)\n       +---------------------------------+\n            |\n            v\n       +-------------------------+\n       |res_block[4*F, 2*F, 3, 3]|              (out_shape: N, 64, 8, 8)\n       +-------------------------+\n            |\n            v\n       +---------------------------------+\n       |(n-1) * res_block[4*F, 4*F, 3, 3]|      (out_shape: N, 64, 8, 8)\n       +---------------------------------+\n            |\n            v\n       +-------------+\n       |pool[1, 8, 8]|                          (out_shape: N, 64, 1, 1)\n       +-------------+\n            |\n            v\n       +- - - - - - - - -+\n       |(opt) m * affine |                      (out_shape: N, 64, 1, 1)\n       +- - - - - - - - -+\n            |\n            v\n       +-------+\n       |softmax|                                (out_shape: N, num_classes)\n       +-------+\n            |\n            v\n         OUTPUT\n\n    Every convolution layer has a pad=1 and stride=1, except for the  dimension\n    enhancning layers which has a stride of 2 to mantain the computational\n    complexity.\n    Optionally, there is the possibility of setting m affine layers immediatley\n    before the softmax layer by setting the hidden_dims parameter, which should\n    be a list of integers representing the numbe of neurons for each affine\n    layer.\n\n    Each residual block is composed as below:\n\n                  Input\n                     |\n             ,-------+-----.\n       Downsampling      3x3 convolution+dimensionality reduction\n            |               |\n            v               v\n       Zero-padding      3x3 convolution\n            |               |\n            `-----( Add )---\'\n                     |\n                  Output\n\n    After every layer, a batch normalization with momentum .1 is applied.\n\n    Weight initialization (check also layers/init.py and layers/README.md):\n    - Inizialize the weights and biases for the affine layers in the same\n     way of torch\'s default mode by calling _init_affine_wb that returns a\n     tuple (w, b).\n    - Inizialize the weights for the conv layers in the same\n     way of torch\'s default mode by calling init_conv_w.\n    - Inizialize the weights for the conv layers in the same\n     way of kaiming\'s mode by calling init_conv_w_kaiming\n     (http://arxiv.org/abs/1502.01852 and\n      http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-\\\n      initialization)\n    - Initialize batch normalization layer\'s weights like torch\'s default by\n    calling init_bn_w\n    - Initialize batch normalization layer\'s weights like cgr\'s first resblock\\\n    \'s bn (https://github.com/gcr/torch-residual-networks/blob/master/residual\\\n           -layers.lua#L57-L59) by calling init_bn_w_gcr.\n\n    num_filters=[16, 16, 32, 32, 64, 64],\n        Initialize a new network.\n\n        Inputs:\n        - input_dim: Tuple (C, H, W) giving size of input data.\n        - num_starting_filters: Number of filters for the first convolution\n        layer.\n        - n_size: nSize for the residual network like in the reference paper\n        - hidden_dims: Optional list number of units to use in the\n        fully-connected hidden layers between the fianl pool and the sofmatx\n        layer.\n        - num_classes: Number of scores to produce from the final affine layer.\n        - reg: Scalar giving L2 regularization strength\n        - dtype: numpy datatype to use for computation.\n    \'\'\'\n\n    nfs = num_starting_filters\n    model = Sequential()\n    add = model.add\n    add(SpatialConvolution(3, nfs, 3, 3, 1, 1, 1, 1))\n    add(SpatialBatchNormalization(nfs))\n    add(ReLU())\n\n    for i in xrange(1, n_size):\n        add(residual_layer(nfs))\n    add(residual_layer(nfs, 2*nfs, 2))\n\n    for i in xrange(1, n_size-1):\n        add(residual_layer(2*nfs))\n    add(residual_layer(2*nfs, 4*nfs, 2))\n\n    for i in xrange(1, n_size-1):\n        add(residual_layer(4*nfs))\n\n    add(SpatialAveragePooling(8, 8))\n    add(Reshape(nfs*4))\n    add(Linear(nfs*4, 10))\n    add(LogSoftMax())\n    return model\n'"
train.py,2,"b'# !/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport uuid\nimport numpy as np\n# import matplotlib.pyplot as plt\nfrom pydatset.cifar10 import get_CIFAR10_data\nfrom pydatset.data_augmentation import (random_flips,\n                                        random_crops)\nfrom res_net import resnet\nfrom pyfunt.solver import Solver as Solver\n\nimport inspect\nimport argparse\n\nfrom pyfunt.class_nll_criterion import ClassNLLCriterion\n\nnp.seterr(all=\'raise\')\n\nnp.random.seed(0)\n\nDATA_PATH = \'../CIFAR_DATASET_PATH\'\n\npath_set = False\nwhile not path_set:\n    try:\n        with open(DATA_PATH) as f:\n            DATASET_PATH = f.read()\n        path_set = True\n    except:\n        data_path = raw_input(\'Enter the path for the CIFAR10 dataset: \')\n        with open(DATA_PATH, ""w"") as f:\n            f.write(data_path)\n\n\nEXPERIMENT_PATH = \'../Experiments/\' + str(uuid.uuid4())[-10:]\n\n# residual network constants\nNSIZE = 3\nN_STARTING_FILTERS = 16\n\n# solver constants\nNUM_PROCESSES = 4\n\nNUM_TRAIN = 50000\nNUM_TEST = 10000\n\nWEIGHT_DEACY = 1e-4\nREGULARIZATION = 0\nLEARNING_RATE = .1\nMOMENTUM = .99\nNUM_EPOCHS = 160\nBATCH_SIZE = 64\nCHECKPOINT_EVERY = 20\n\nXH, XW = 32, 32\n\nargs = argparse.Namespace()\n\n\ndef parse_args():\n    """"""\n    Parse the options for running the Residual Network on CIFAR-10.\n    """"""\n    desc = \'Train a Residual Network on CIFAR-10.\'\n    parser = argparse.ArgumentParser(description=desc,\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    add = parser.add_argument\n    add(\'--dataset_path\',\n        metavar=\'DIRECOTRY\',\n        default=DATASET_PATH,\n        type=str,\n        help=\'directory where results will be saved\')\n    add(\'--experiment_path\',\n        metavar=\'DIRECOTRY\',\n        default=EXPERIMENT_PATH,\n        type=str,\n        help=\'directory where results will be saved\')\n    add(\'-load\', \'--load_checkpoint\',\n        metavar=\'DIRECOTRY\',\n        default=\'\',\n        type=str,\n        help=\'load checkpoint from load_checkpoint\')\n    add(\'--n_size\',\n        metavar=\'INT\',\n        default=NSIZE,\n        type=int,\n        help=\'Network will have (6*n)+2 conv layers\')\n    add(\'--n_starting_filters\',\n        metavar=\'INT\',\n        default=N_STARTING_FILTERS,\n        type=int,\n        help=\'Network will starts with those number of filters\')\n    add(\'--n_processes\', \'-np\',\n        metavar=\'INT\',\n        default=NUM_PROCESSES,\n        type=int,\n        help=\'Number of processes for each step\')\n    add(\'--n_train\',\n        metavar=\'INT\',\n        default=NUM_TRAIN,\n        type=int,\n        help=\'Number of total images to select for training\')\n    add(\'--n_test\',\n        metavar=\'INT\',\n        default=NUM_TEST,\n        type=int,\n        help=\'Number of total images to select for validation\')\n    add(\'-wd\', \'--weight_decay\',\n        metavar=\'FLOAT\',\n        default=WEIGHT_DEACY,\n        type=float,\n        help=\'Weight decay for sgd_th\')\n    add(\'-reg\', \'--network_regularization\',\n        metavar=\'FLOAT\',\n        default=REGULARIZATION,\n        type=float,\n        help=\'L2 regularization term for the network\')\n    add(\'-lr\', \'--learning_rate\',\n        metavar=\'FLOAT\',\n        default=LEARNING_RATE,\n        type=float,\n        help=\'Learning rate to use with sgd_th\')\n    add(\'-mom\', \'--momentum\',\n        metavar=\'FLOAT\',\n        default=MOMENTUM,\n        type=float,\n        help=\'Nesterov momentum use with sgd_th\')\n    add(\'--n_epochs\', \'-nep\',\n        metavar=\'INT\',\n        default=NUM_EPOCHS,\n        type=int,\n        help=\'Number of epochs for training\')\n    add(\'--batch_size\', \'-bs\',\n        metavar=\'INT\',\n        default=BATCH_SIZE,\n        type=int,\n        help=\'Number of images for each iteration\')\n    add(\'--checkpoint_every\', \'-cp\',\n        metavar=\'INT\',\n        default=CHECKPOINT_EVERY,\n        type=int,\n        help=\'Number of epochs between each checkpoint\')\n    parser.parse_args(namespace=args)\n    assert not (args.network_regularization and args.weight_decay)\n\n\ndef data_augm(batch):\n    p = 2\n    h, w = XH, XW\n\n    # batch = random_tint(batch)\n    # batch = random_contrast(batch)\n    batch = random_flips(batch)\n    # batch = random_rotate(batch, 10)\n    batch = random_crops(batch, (h, w), pad=p)\n    return batch\n\n\ndef custom_update_decay(epoch):\n    if epoch in (80, 120):\n        return 0.1\n    return 1\n\n\ndef print_infos(solver):\n    print(\'Model: \\n%s\' % solver.model)\n\n    print(\'Solver: \\n%s\' % solver)\n\n    print(\'Data Augmentation Function: \\n\')\n    print(\'\'.join([\'\\t\' + i for i in inspect.getsourcelines(data_augm)[0]]))\n    print(\'Custom Weight Decay Update Rule: \\n\')\n    print(\'\'.join([\'\\t\' + i for i in inspect.getsourcelines(custom_update_decay)[0]]))\n\n\ndef main():\n    parse_args()\n\n    data = get_CIFAR10_data(args.dataset_path,\n                            num_training=args.n_train, num_validation=0, num_test=args.n_test)\n\n    data = {\n        \'X_train\': data[\'X_train\'],\n        \'y_train\': data[\'y_train\'],\n        \'X_val\': data[\'X_test\'],\n        \'y_val\': data[\'y_test\'],\n    }\n\n    exp_path = args.experiment_path\n    nf = args.n_starting_filters\n    reg = args.network_regularization\n\n    model = resnet(n_size=args.n_size,\n                   num_starting_filters=nf,\n                   reg=reg)\n\n    wd = args.weight_decay\n    lr = args.learning_rate\n    mom = args.momentum\n\n    optim_config = {\'learning_rate\': lr, \'nesterov\': True,\n                    \'momentum\': mom, \'weight_decay\': wd}\n\n    epochs = args.n_epochs\n    bs = args.batch_size\n    num_p = args.n_processes\n    cp = args.checkpoint_every\n    criterion = ClassNLLCriterion()\n    solver = Solver(model, data, args.load_checkpoint,\n                    criterion=criterion,\n                    num_epochs=epochs, batch_size=bs,  # 20\n                    update_rule=\'sgd_th\',\n                    optim_config=optim_config,\n                    custom_update_ld=custom_update_decay,\n                    batch_augment_func=data_augm,\n                    checkpoint_every=cp,\n                    num_processes=num_p)\n\n    print_infos(solver)\n    solver.train()\n\n    solver.export_model(exp_path)\n    solver.export_histories(exp_path)\n\n    print(\'finish\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
