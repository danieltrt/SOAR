file_path,api_count,code
lane_detection.py,36,"b'import numpy as np\nimport cv2\nimport time\nfrom threading import Thread\nfrom Queue import Queue\n\n# defualt video number, if you want to process the ""fog_video.mp4"", change video_index to 1\nvideo_index = 0\n\n# the result of lane detection, we add the road to the main frame\nroad = np.zeros((720, 1280, 3))\n\n# A flag which means the process is started\nstarted = 0\n\n# Pipeline combining color and gradient thresholding\ndef thresholding_pipeline(img, s_thresh=(90, 255), sxy_thresh=(20, 100)):\n\n    img = np.copy(img)\n    # 1: Convert to HSV color space and separate the V channel\n    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n    h_channel = hls[:, :, 0]\n    l_channel = hls[:, :, 1]\n    s_channel = hls[:, :, 2]\n\n    # 2: Calculate x directional gradient\n    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0)  # Take the derivative in x\n    abs_sobelx = np.absolute(sobelx)  # Absolute x derivative to accentuate lines away from horizontal\n    scaled_sobelx = np.uint8(255 * abs_sobelx / np.max(abs_sobelx))\n    sxbinary = np.zeros_like(scaled_sobelx)\n    sxbinary[(scaled_sobelx >= sxy_thresh[0]) & (scaled_sobelx <= sxy_thresh[1])] = 1\n    grad_thresh = sxbinary\n\n    # 3: Color Threshold of s channel\n    s_binary = np.zeros_like(s_channel)\n    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n\n    # 4: Combine the two binary thresholds\n    combined_binary = np.zeros_like(grad_thresh)\n    combined_binary[(s_binary == 1) | (grad_thresh == 1)] = 1\n\n    return combined_binary\n\n# Apply perspective transformation to bird\'s eye view\ndef perspective_transform(img, src_mask, dst_mask):\n\n    img_size = (img.shape[1], img.shape[0])\n    src = np.float32(src_mask)\n    dst = np.float32(dst_mask)\n    M = cv2.getPerspectiveTransform(src, dst)\n    warped_img = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n    return warped_img\n\n\n# Implement Sliding Windows and Fit a Polynomial\ndef sliding_windows(binary_warped, nwindows=9):\n\n    histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2):, :], axis=0)\n\n    # Find the peak of the left and right halves of the histogram\n    # These will be the starting point for the left and right lines\n    midpoint = np.int(histogram.shape[0]/2)\n    leftx_base = np.argmax(histogram[:midpoint])\n    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n\n    # Set height of windows\n    window_height = np.int(binary_warped.shape[0]/nwindows)\n    # Identify the x and y positions of all nonzero pixels in the image\n    nonzero = binary_warped.nonzero()\n    nonzeroy = np.array(nonzero[0])\n    nonzerox = np.array(nonzero[1])\n    # Current positions to be updated for each window\n    leftx_current = leftx_base\n    rightx_current = rightx_base\n    # Set the width of the windows +/- margin\n    margin = 100\n    # Set minimum number of pixels found to recenter window\n    minpix = 50\n    # Create empty lists to receive left and right lane pixel indices\n    left_lane_inds = []\n    right_lane_inds = []\n\n    # Step through the windows one by one\n    for window in range(nwindows):\n        # Identify window boundaries in x and y (and right and left)\n        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n        win_y_high = binary_warped.shape[0] - window*window_height\n        win_xleft_low = leftx_current - margin\n        win_xleft_high = leftx_current + margin\n        win_xright_low = rightx_current - margin\n        win_xright_high = rightx_current + margin\n        # Identify the nonzero pixels in x and y within the window\n        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n        # Append these indices to the lists\n        left_lane_inds.append(good_left_inds)\n        right_lane_inds.append(good_right_inds)\n        # If you found > minpix pixels, recenter next window on their mean position\n        if len(good_left_inds) > minpix:\n            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n        if len(good_right_inds) > minpix:\n            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n\n    # Concatenate the arrays of indices\n    left_lane_inds = np.concatenate(left_lane_inds)\n    right_lane_inds = np.concatenate(right_lane_inds)\n\n    # Extract left and right line pixel positions\n    leftx = nonzerox[left_lane_inds]\n    lefty = nonzeroy[left_lane_inds]\n    rightx = nonzerox[right_lane_inds]\n    righty = nonzeroy[right_lane_inds]\n\n    # Fit a second order polynomial to each\n    left_fit = np.polyfit(lefty, leftx, 2)\n    right_fit = np.polyfit(righty, rightx, 2)\n\n    return left_fit, right_fit, lefty, leftx, righty, rightx\n\n\n# Warp lane line projection back to original image\ndef project_lanelines(binary_warped, orig_img, left_fit, right_fit, dst_mask, src_mask):\n\n    global road\n    global started\n    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n\n    # Create an image to draw the lines on\n    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n\n    # Recast the x and y points into usable format for cv2.fillPoly()\n    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n    pts = np.hstack((pts_left, pts_right))\n    \n    # Draw the lane onto the warped blank image\n    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n    warped_inv = perspective_transform(color_warp, dst_mask, src_mask)\n    road = warped_inv\n    started = 1\n\n# Main process functions\ndef main_pipeline(input):\n\n    # step 1 select the ROI, and we need to distort the image for fog_video\n    if video_index == 0:\n        image = input\n        top_left = [540, 460]\n        top_right = [754, 460]\n        bottom_right = [1190, 670]\n        bottom_left = [160, 670]\n    else:\n        mtx = np.array([[1.15396467e+03, 0.00000000e+00, 6.69708251e+02],[0.00000000e+00, 1.14802823e+03, 3.85661017e+02], \n                       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n        dist = np.array([[-2.41026561e-01, -5.30262184e-02, -1.15775369e-03, -1.27924043e-04, 2.66417032e-02]])\n        image = cv2.undistort(input, mtx, dist, None, mtx)\n        top_left = [240, 270]\n        top_right = [385, 270]\n        bottom_right = [685, 402]\n        bottom_left = [0, 402]\n    src_mask = np.array([[(top_left[0], top_left[1]), (top_right[0], top_right[1]),\n                          (bottom_right[0], bottom_right[1]), (bottom_left[0], bottom_left[1])]], np.int32)\n    dst_mask = np.array([[(bottom_left[0], 0), (bottom_right[0], 0),\n                          (bottom_right[0], bottom_right[1]), (bottom_left[0], bottom_left[1])]], np.int32)\n\n    # Step 2 Thresholding: color and gradient thresholds to generate a binary image\n    binary_image = thresholding_pipeline(image, s_thresh=(90, 255))\n\n    # Step 3 Perspective transform on binary image:\n    binary_warped = perspective_transform(binary_image, src_mask, dst_mask)\n\n    # Step 4 Fit Polynomial\n    left_fit, right_fit, lefty, leftx, righty, rightx = sliding_windows(binary_warped, nwindows=9)\n\n    # Step 5 Project Lines\n    project_lanelines(binary_warped, image, left_fit, right_fit, dst_mask, src_mask)\n\nif __name__ == \'__main__\':\n    \n    frames_counts = 1\n    if video_index == 0:\n        cap=cv2.VideoCapture(\'project_video.mp4\')  \n    else:\n        cap=cv2.VideoCapture(\'fog_video.mp4\') \n\n    class MyThread(Thread):\n\n        def __init__(self, q):\n            Thread.__init__(self)\n\t    self.q = q\n\n\tdef run(self):\n\t    while(1):\n\t        if (not self.q.empty()):\n         \t    image = self.q.get()\n\t\t    main_pipeline(image)\n\n    q = Queue()\n    q.queue.clear()\n    thd1 = MyThread(q)\n    thd1.setDaemon(True)\n    thd1.start()\n\n    while (True):  \n\t    start=time.time()\n            ret,frame=cap.read()\n\n            # Detect the lane every 5 frames\n\t    if frames_counts % 5 == 0:\n\t        q.put(frame)\n\n            # Add the lane image on the original frame if started\n            if started:\n                frame = cv2.addWeighted(frame, 1, road, 0.5, 0)\n            cv2.imshow(""RealTime_lane_detection"",frame)  \n            if cv2.waitKey(1)&0xFF==ord(\'q\'):  \n                break  \n            frames_counts+=1\n\t    cv2.waitKey(12)\n            finish=time.time()\n            print \'FPS:  \' + str(int(1/(finish-start)))\n\n    cap.release()  \n    cv2.destroyAllWindows() \n\n'"
