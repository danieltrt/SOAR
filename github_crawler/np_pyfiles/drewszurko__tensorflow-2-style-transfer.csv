file_path,api_count,code
main.py,0,"b'# MIT License\n#\n# Copyright (c) 2019 Drew Szurko\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom absl import app\nfrom absl import flags\nfrom tensorflow import keras\n\nimport models\nfrom utils import load_img\n\nkeras.backend.clear_session()\n\nflags.DEFINE_string(\'content_path\', \'chomper3.jpg\', \'Path to content image.\')\nflags.DEFINE_string(\'style_path\', \'art18.jpg\', \'Path to style image.\')\nflags.DEFINE_string(\'output_dir\', \'.\', \'Output directory.\')\nflags.DEFINE_integer(\'epochs\', 20, \'Epochs to train.\')\nflags.DEFINE_integer(\'steps_per_epoch\', 500, \'Steps per epoch.\')\nflags.DEFINE_float(\'tv_weight\', 1e8, \'Total variation weight.\')\nflags.DEFINE_float(\'content_weight\', 10000, \'Content weight.\')\nflags.DEFINE_float(\'style_weight\', 0.10, \'Style weight.\')\nflags.DEFINE_float(\'learning_rate\', 0.02, \'Learning rate.\')\nflags.DEFINE_float(\'beta_1\', 0.99, \'Beta 1.\')\nflags.DEFINE_float(\'beta_2\', 0.999, \'Beta 2.\')\nflags.DEFINE_float(\'epsilon\', 0.10, \'Epsilon.\')\nflags.DEFINE_float(\'max_dim\', 512, \'Max dimension to crop I/O image.\')\nflags.mark_flags_as_required([\'content_path\', \'style_path\'])\nFLAGS = flags.FLAGS\n\n\ndef main(argv):\n    del argv\n\n    content_img = load_img(FLAGS.content_path)\n    style_img = load_img(FLAGS.style_path)\n\n    mdl = models.StyleContent(content_img, style_img)\n    mdl.train()\n\n\nif __name__ == \'__main__\':\n    app.run(main)\n'"
models.py,0,"b'# MIT License\n#\n# Copyright (c) 2019 Drew Szurko\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nfrom absl import flags\nfrom tensorflow.python.keras import applications\nfrom tensorflow.python.keras import models\nfrom tqdm.autonotebook import tqdm\n\nfrom ops import get_style_content_loss\nfrom ops import calculate_gram_matrix\nfrom ops import get_vgg_layers\nfrom utils import get_terminal_width\nfrom utils import save_img\n\nFLAGS = flags.FLAGS\n\n\nclass StyleContent(models.Model):\n    STYLE_LAYERS = [\n        \'block1_conv1\', \'block2_conv1\', \'block3_conv1\', \'block4_conv1\', \'block5_conv1\'\n    ]\n    CONTENT_LAYERS = [\'block5_conv2\']\n\n    def __init__(self, content_img, style_img):\n        super(StyleContent, self).__init__()\n        self.content_img = content_img\n        self.style_img = style_img\n        self.img = tf.Variable(content_img)\n        self.vgg = get_vgg_layers(self.STYLE_LAYERS + self.CONTENT_LAYERS)\n        self.num_style_layers = len(self.STYLE_LAYERS)\n        self.vgg.trainable = False\n        self.style_targets = self(self.style_img)[\'style\']\n        self.content_targets = self(self.content_img)[\'content\']\n        self.opt = tf.optimizers.Adam(learning_rate=FLAGS.learning_rate,\n                                      beta_1=FLAGS.beta_1,\n                                      beta_2=FLAGS.beta_2,\n                                      epsilon=FLAGS.epsilon)\n\n    def call(self, inputs, **kwargs):\n        inputs = inputs * 255.0\n        preprocessed_input = applications.vgg19.preprocess_input(inputs)\n        outputs = self.vgg(preprocessed_input)\n        style_outputs, content_outputs = (outputs[:self.num_style_layers],\n                                          outputs[self.num_style_layers:])\n\n        style_outputs = [\n            calculate_gram_matrix(style_output) for style_output in style_outputs\n        ]\n        content = {\n            content_name: value\n            for content_name, value in zip(self.CONTENT_LAYERS, content_outputs)\n        }\n        style = {\n            style_name: value\n            for style_name, value in zip(self.STYLE_LAYERS, style_outputs)\n        }\n        return {\'content\': content, \'style\': style}\n\n    def train(self):\n        for n in range(FLAGS.epochs):\n            for _ in tqdm(\n                    iterable=range(FLAGS.steps_per_epoch),\n                    ncols=int(get_terminal_width() * .9),\n                    desc=tqdm.write(f\'Epoch {n + 1}/{FLAGS.epochs}\'),\n                    unit=\' steps\',\n            ):\n                self.train_step(self.img)\n            save_img(self.img.read_value(), n + 1)\n\n    @tf.function()\n    def train_step(self, img):\n        with tf.GradientTape() as tape:\n            outputs = self(img)\n            loss = get_style_content_loss(outputs, self.content_targets,\n                                          self.style_targets, self.CONTENT_LAYERS,\n                                          self.STYLE_LAYERS, img)\n\n        grad = tape.gradient(loss, img)\n        self.opt.apply_gradients([(grad, img)])\n        img.assign(tf.clip_by_value(img, 0.0, 1.0))\n\n    def compute_output_signature(self, input_signature):\n        pass\n'"
ops.py,0,"b'# MIT License\n#\n# Copyright (c) 2019 Drew Szurko\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport tensorflow as tf\nfrom absl import flags\nfrom tensorflow import linalg\nfrom tensorflow.python.keras import applications\nfrom tensorflow.python.keras import models\n\nFLAGS = flags.FLAGS\n\n\ndef get_vgg_layers(layer_names):\n    vgg = applications.VGG19(include_top=False, weights=\'imagenet\')\n    vgg.trainable = False\n    outputs = [vgg.get_layer(name).output for name in layer_names]\n    model = models.Model([vgg.input], outputs)\n    return model\n\n\ndef calculate_gram_matrix(tensor):\n    input_shape = tf.shape(tensor)\n    result = linalg.einsum(\'bijc,bijd->bcd\', tensor, tensor)\n    num_locations = tf.cast(input_shape[1] * input_shape[2], tf.float32)\n    return result / num_locations\n\n\ndef compute_loss(outputs, targets):\n    return tf.add_n([\n        tf.reduce_mean(tf.square(outputs[name] - targets[name]))\n        for name in outputs.keys()\n    ])\n\n\ndef get_high_frequencies(img):\n    x = img[:, :, 1:, :] - img[:, :, :-1, :]\n    y = img[:, 1:, :, :] - img[:, :-1, :, :]\n    return x, y\n\n\ndef variation_loss(img):\n    x, y = get_high_frequencies(img)\n    return tf.reduce_mean(tf.square(x)) + tf.reduce_mean(tf.square(y))\n\n\ndef get_style_content_loss(outputs, content_targets, style_targets, content_layers,\n                           style_layers, img):\n    content_loss = compute_loss(outputs[\'content\'], content_targets)\n    style_loss = compute_loss(outputs[\'style\'], style_targets)\n\n    content_loss *= FLAGS.content_weight / len(content_layers)\n    style_loss *= FLAGS.style_weight / len(style_layers)\n\n    total_loss = style_loss + content_loss\n    total_loss += FLAGS.tv_weight * variation_loss(img)\n\n    return total_loss\n'"
utils.py,0,"b'# MIT License\n#\n# Copyright (c) 2019 Drew Szurko\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport os\nimport shutil\n\nimport tensorflow as tf\nfrom absl import flags\nfrom tensorflow import io\n\nFLAGS = flags.FLAGS\n\n\ndef load_img(img_path):\n    img = io.read_file(img_path)\n    img = tf.image.decode_image(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n\n    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n    long_dim = max(shape)\n    scale = FLAGS.max_dim / long_dim\n\n    new_shape = tf.cast(shape * scale, tf.int32)\n\n    img = tf.image.resize(img, new_shape, antialias=True)\n    img = img[tf.newaxis, :]\n    return img\n\n\ndef save_img(image_batch, epoch):\n    file_name = f\'{epoch}.jpg\'\n    output_dir = os.path.join(FLAGS.output_dir, file_name)\n\n    for i in image_batch:\n        img = tf.image.encode_jpeg(tf.cast(i * 255, tf.uint8), format=\'rgb\')\n        tf.io.write_file(output_dir, img)\n\n\ndef get_terminal_width():\n    width = shutil.get_terminal_size(fallback=(200, 24))[0]\n    if width == 0:\n        width = 120\n    return width\n'"
