file_path,api_count,code
MlModel.py,0,"b""from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom joblib import dump, load\n\n\nclass BuildMlPipeline:\n    \n    def __init__(self):\n        pass\n        \n    def set_estimators(self, *args):\n        estimator_db = {\n            'randomForestRegressor': RandomForestRegressor(),\n            'linearRegressor': LinearRegression(),\n        }\n        self.estimators = list(map( lambda algo: estimator_db[algo],args))\n        \n    def set_scalers(self, *args):\n        scaler_db = {\n            'standardscaler':StandardScaler(),\n            'minmaxscaler':MinMaxScaler(),\n        }\n        self.scalers = list(map( lambda scaler: scaler_db[scaler],args))\n        \n    def set_samplers(self, *args):\n        sampler_db = {\n            'smote':SMOTE(),\n            'smoteenn':SMOTEENN(),\n        }\n        self.samplers = list(map( lambda sampler: sampler_db[sampler],args))\n        \n    def set_encoders(self, *args):\n        encoders_db = {\n            'ohe':OneHotEncoder(handle_unknown='ignore'),\n            'oe':OrdinalEncoder(),\n        }\n        self.encoders = list(map( lambda encoder: encoders_db[encoder],args))\n        \n    def set_hyperparameters(self, params):\n        self.hyperparameters = params\n\n    \n    def create_pipelines(self, cat_cols, cont_cols):\n        self.model_pipelines = []\n        for scaler in self.scalers:\n            pipeline_num = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n                                           ('scaling',scaler)])\n            for encoder in self.encoders:\n                pipeline_cat = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n                                               ('encoder',encoder)])\n                preprocessor = make_column_transformer((pipeline_num, cont_cols),(pipeline_cat, cat_cols))\n                \n                for estimator in self.estimators:\n                    pipeline  = make_pipeline(preprocessor, estimator)\n                    self.model_pipelines.append(pipeline)\n        \n\n    def fit(self, trainX, trainY):\n        self.gs_pipelines = []\n        for idx,pipeline in enumerate(self.model_pipelines):\n            elems = list(map(lambda x:x[0] ,pipeline.steps))\n            param_grid = {}\n\n            for elem in elems:\n                if elem.lower() in self.hyperparameters:\n                    param_grid.update(self.hyperparameters[elem])\n\n            gs = GridSearchCV(pipeline, param_grid= param_grid, n_jobs=6, cv=5)\n            gs.fit(trainX, trainY)\n            print (gs.score(testX,testY),  list(map(lambda x:x[0] , gs.best_estimator_.steps)), gs.best_params_)\n\n            dump(gs, 'model'+str(idx)+'.pipeline')\n            self.gs_pipelines.append(gs)\n\n\n    def score(self, testX, testY):\n        for idx,model in enumerate(self.gs_pipelines):\n            y_pred = model.best_estimator_.predict(testX)\n            print (model.best_estimator_)\n            print (idx,confusion_matrix(y_true=testY,y_pred=y_pred))\n"""
flask_ml_api.py,0,"b""#!flask/bin/python\nfrom flask import Flask, jsonify, request\nimport joblib\nimport pandas as pd\n\napp = Flask(__name__)\n\n@app.route('/predict/tx', methods=['GET'])\ndef create_task():\n    tx_data = request.json\n    model = joblib.load('house.model')\n    res = model.predict([[1177.698,2,7,2,2,2]])\n    return jsonify(res[0]), 201\n\nif __name__ == '__main__':\n    app.run(debug=True)\n"""
