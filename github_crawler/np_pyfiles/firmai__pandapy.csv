file_path,api_count,code
setup.py,0,"b""from setuptools import setup, Command\nimport os\nimport sys\n\nsetup(name='pandapy',\n      version='2.2',\n      description='Structured Numpy with Pandas a Click Away',\n      url='https://github.com/firmai/pandapy',\n      author='snowde',\n      author_email='d.snow@firmai.org',\n      license='MIT',\n      packages=['pandapy'],\n      install_requires=[\n          'pandas',\n          'numpy',\n          'scipy',\n          'numpy-groupies',\n          'numba',\n          'datetime',\n          'ipython'\n\n      ],\n      zip_safe=False)\n"""
pandapy/__init__.py,161,"b'import numpy as np\nimport numba as nb\nimport numpy.lib.recfunctions as rfn \nimport numpy_groupies as npg\nimport scipy.sparse as sps\nfrom scipy import stats\nimport pandas as pd\nfrom dateutil.parser import parse\nimport datetime as dt\nfrom operator import itemgetter\nfrom itertools import groupby\nfrom IPython.core.display import display, HTML\nfrom html import escape\nfrom typing import Union\n\n\n### Helper Functions\n\ndef is_date(string: str, fuzzy: bool = True) -> bool:\n    """"""\n    Identifies whether the string is a date\n\n    :param string: str, string to check for date.\n    :param fuzzy: bool, ignore unknown tokens in string if True.\n    :return bool: bool, whether the string can be interpreted as a date.\n    """"""\n    try: \n        parse(string, fuzzy=fuzzy)\n        return True\n\n    except ValueError:\n        return False\n\ndef find_dates(array: np.ndarray) -> dict:\n    """"""\n    Finds all columns with 10 characters (e.g., 2000-00-00, blatjang23)\n    and identify whether they are indeed dates using is_date(), load a\n    boolean of all the answers into a python dictioary keyed with names. \n\n    :param array: np.ndarray(struct), array that contains the newly loaded dataset.\n    :return dict_date: dict, returns a dictionary of all length 10 columns \n                       and boolean is_date answers.\n    """"""\n    dict_date = {}\n    for name in array.dtype.names:\n      if array.dtype.fields[name][0] ==""|U10"":\n        try:\n          dict_date[name] = is_date(array[name][0])\n        except:\n          dict_date[name] = False\n    return dict_date\n\n\ndef view_fields(array: np.ndarray, names: list) -> np.ndarray:\n    """"""\n    A method to obtain a view of a structured array. \n\n    :param array: np.ndarray(structured), must be a numpy structured array.\n    :param names: list, is the collection of field (or column) names to keep.\n    :return b: np.ndarray(structured), returns a view of the array `array` (not a copy).\n    """"""\n    dt = array.dtype\n    formats = [dt.fields[name][0] for name in names]\n    offsets = [dt.fields[name][1] for name in names]\n    itemsize = array.dtype.itemsize\n    newdt = np.dtype(dict(names=names,\n                          formats=formats,\n                          offsets=offsets,\n                          itemsize=itemsize))\n    b = array.view(newdt)\n    return b\n\n## Array Functions\n\ndef drop(array: np.ndarray, name_list: Union[list, str]) -> np.ndarray: \n    """"""\n    A method to drop columns (fields) from a structured array\n\n    :param array: np.ndarray(structured), must be a numpy structured array.\n    :param name_list: list or str, is the collection of field/s (or column/s) names to keep.\n    :return : np.ndarray(structured), returns a view of the array `array` (not a copy).\n    """"""\n    if (type(name_list)==str):\n      name_list = [name_list]\n\n    dt = array.dtype\n    keep_names = [name for name in dt.names if name not in name_list]\n    return view_fields(array, keep_names)\n\n#@nb.jit\ndef array_load(array: np.ndarray, newobs: np.ndarray) -> np.ndarray:\n    """"""\n    Loop to load columns of a previous array into a new empty array\n\n    :param array: np.ndarray(structured), must be a numpy structured array.\n    :param newobs: np.ndarray(structured), must be a numpy structured array.\n    :return newobs : np.ndarray(structured), returns an array with loaded columns/fields\n    """"""\n    for n in array.dtype.names:\n      newobs[n]=array[n]\n    return newobs\n\n\ndef add(array: np.ndarray, name_list: Union[list,str], value_list: Union[list,np.ndarray,str,int,float],types: str = None) -> np.ndarray:\n    \n    """"""\n    Add additional data to the structured array\n\n    :param array: np.ndarray(structured), array to which additional columns will be added.\n    :param name_list: list or str, the name of the additional column/s to be added.\n    :param value_list: list,np.ndarray,str,int,float, the value/s to be added to the column/s\n    :param type: str, you can specify the type when only adding one column; \n                      when not provided it is deduced from the data. \n    :return newobs : np.ndarray(structured), returns the full array with the newly added fields.\n    """"""   \n\n    dt = [(val, key) for (val, key) in array.dtype.descr if val!=\'\']\n    if (len(name_list)==1) or (type(name_list)==str):\n        if (types == None):\n            try:\n                types = value_list[0].dtype\n            except:\n                types = type(value_list)\n        if (type(name_list)==str):\n            name = name_list\n        else:\n            name = name_list[0]\n        dt = dt + [(name, types)]\n        newobs = np.empty(array.shape, dtype=dt)\n        array_load(array, newobs)\n        if type(value_list)==list:\n            newobs[name]=value_list[0]\n        else:\n            newobs[name]=value_list\n    else:\n        try:\n          dt = dt + [(new, val.dtype.descr[0][1]) for new, val in zip(name_list ,value_list )]\n        except:\n          if (types == None):\n              try:\n                ty = type(value_list[0])\n              except:\n                ty = type(value_list)\n          else:\n            ty = types\n\n          dt = dt + [(new, ty) for new in name_list]\n\n        newobs = np.empty(array.shape, dtype=dt)\n        newobs = array_load(array, newobs)\n\n        if type(value_list)!=list:\n          for new in name_list:\n              newobs[new]=value_list\n        else:\n            for new, val in zip(name_list ,value_list ):\n              newobs[new]=val\n    return newobs\n\n## Actually slow rather use array[col] = values, unless you want to change dtype\ndef update(array: np.ndarray, column: str, values: Union[str, np.ndarray, str, int, float],types: str = None) -> np.ndarray:\n    """"""\n    A data update alternative from array[col] = values, that should only be used when\n    you want to specify a specific datatype, otherwise the array[col] option is much faster\n\n    :param array: np.ndarray(structured), array that houses the column to be updated.\n    :param column: str, the name of the column to be added.\n    :param values: list or np.ndarray, the value/s used to update the original \'column\'\n    :return array : np.ndarray(structured), the updated array\n    """"""   \n    if types==None:\n      types= array.dtype.fields[column][0]\n    array = drop(array,column)\n    array = drop(array,column)\n    array = add(array,column,values,types)\n    return array\n\n\ndef flip(array: np.ndarray) -> np.ndarray:\n    """"""\n    Reverse the order of the data\n\n    :param array: np.ndarray(structured), structured array to flip\n    :return : np.ndarray(structured), flipped array\n    """"""  \n    return np.flip(array)\n\n\ndef rename(array: np.ndarray,original: Union[list, str], new: Union[list, str]) -> np.ndarray:\n    """"""\n    Rename the structured array.\n\n    :param array: np.ndarray(structured), array that houses the columns/fields to be renamed.\n    :param original: list or str, the original column/s to be renamed.\n    :param new: list or str, the new column/s names.\n    :return : np.ndarray(structured), the renamed structured array.\n    """"""   \n\n    if (type(original)==str):\n      original = [original]\n      new = [new]\n    mapping = {}\n    for ori, ne in zip(original, new):\n      mapping[ori] = ne\n    \n    return rfn.rename_fields(array,mapping)\n\ndef to_struct(array: np.ndarray, name_list: list) -> np.ndarray:\n    """"""\n    Convert an unstructured (homogenous) array to a structured array. The data types\n    are automatically picked up by looking at the data, using numpy\'s recfunctions.\n\n    :param array: np.ndarray, unstructured array (i.e., normal numpy array)\n    :param name_list: list or str, the names to be given to the columns to be\n                                   given to the newly created structured array.\n    :return : np.ndarray(structured), the newly converted structured array\n    """"""   \n    return rfn.unstructured_to_structured(array, names= name_list)\n  \ndef to_unstruct(array: np.ndarray) -> np.ndarray:\n    """"""\n    Convert an structured (non-homogenous) array to an unstructured array. \n\n    :param array: np.ndarray(structured), structured array (i.e., numpy array with columns/fields)\n    :return : np.ndarray, the newly converted unstructured (normal) array\n    """"""   \n    return rfn.structured_to_unstructured(array)\n\n\ndef read(path: str, delimiter="","",convert_date=True) -> np.ndarray:\n    """"""\n    Read in dataframe from csv, url or other datatypes accepted by numpy. Identify\n    which columns are dates and convert them to a date format, return structured array.  \n\n    :param path: str, the path of the file to open and process.\n    :param delimiter: str, what is the separator to use for the data.\n    :return array : np.ndarray, loaded and processed structured array.\n    """"""   \n    array = np.genfromtxt(path,delimiter=delimiter, names=True, dtype=None, encoding=None,invalid_raise = False)\n    if convert_date:\n        dict_date = find_dates(array)\n        for item in dict_date.keys():\n            try:  \n                value = array[item].astype(""M8[D]"")\n            except:\n                print(""slow date conversion in progress"")\n                value = np.array([parse(d, fuzzy=False) for d in array[item]],dtype=""M8[D]"")\n            array = drop(array, [item])\n            array = add(array, item,value,""M8[D]"")\n        return array\n    else:\n        return array\n\ndef concat_col(array1: np.ndarray, array2: np.ndarray) -> np.ndarray:\n    """"""\n    A unique method that concatenates two structured numpy arrays\n    by column and a bit of tidying up to remove void datatypes. A \n    new array is created with the new data types of the concatenating\n    array included. The concatenating arrays are loaded into the empty\n    array via a loop function array_load(). \n\n    Note, if you are concatenating a single column, always add double\n    brackets so that the name can be easily retrieved i.e. array[[col]]\n\n    :param array1: np.ndarray, the left concatenating array.\n    :param array2: np.ndarray, the right concatenating array.\n    :return newobs : np.ndarray, newly concatenated array.\n    """"""   \n    dt = [(val, key) for (val, key) in array1.dtype.descr if val!=\'\']\n    dt = dt +  [(val, key) for (val, key) in array2.dtype.descr if val!=\'\']\n\n    newobs = np.empty(array1.shape, dtype=dt)\n    try:\n        newobs = array_load(array1, newobs)\n    except:\n        print(""Put additional brackets array1[[col]] instead of array1[col] OR use add() and not concatenate"")\n\n    try:\n        newobs = array_load(array2, newobs)\n    except:\n        print(""Put additional brackets array2[[col]] instead of array1[col] OR use add() and not concatenate"")\n\n    return newobs\n\ndef concat(first: np.ndarray, second: np.ndarray, type: ""{row, columns, array, melt}"" = ""row"") -> np.ndarray:\n    """"""\n    Multiple methods of concatenation, some of them are experimental. The basic methods are \'columns\' or \'row\'. \n    The other methods do not necessarily provide unique outcomes to that of \'columns\' and \'row\'.\n\n    Note, if you are concatenating a single column, always add double\n    brackets so that the name can be easily retrieved i.e. array[[col]]\n\n    :param array1: np.ndarray, the left/top concatenating array.\n    :param array2: np.ndarray, the right/bottom concatenating array.\n    :param type: str or in, the type of concatenation \'row\', \'columns\', \'array\' or \'melt\'\n    :return concat : np.ndarray, newly concatenated array.\n    """"""\n    if type in [""row"",""r"",""rows"",0]:\n      try:\n        concat = np.concatenate([first, second])\n      except:\n        concat = np.concatenate([rfn.structured_to_unstructured(first), rfn.structured_to_unstructured(second)])\n        concat = rfn.unstructured_to_structured(concat,names=first.dtype.names)\n    elif type in [""columns"",""column"",""c"",1]:\n      concat = concat_col(first,second)\n      #concat = rfn.merge_arrays((first, second), asrecarray=False, flatten=True)  # tuples\n    elif type==""array"":\n      concat = np.c_[[first, second]]\n    elif type==""melt"": ## looks similar to columns but list instead of tuples\n      try:\n        concat = np.c_[(first, second)]\n      except:\n        concat = np.c_[(rfn.structured_to_unstructured(first), rfn.structured_to_unstructured(second))]\n        concat = rfn.unstructured_to_structured(concat,names=first.dtype.names)\n    else:\n      raise ValueError(""type has to be set to either: row, columns, array or melt"")\n    return concat\n\ndef merge(left_array: np.ndarray, right_array: np.ndarray, left_on: str, right_on: str, how: ""{inner, outer, leftouter}"" = ""inner"", left_postscript=""_left"", right_postscript=""_right"" ) -> np.ndarray:\n    """"""\n    Multiple methods of merging data on unique columns. This method is not optimised and makes use of NumPy\'s recfunctions. \n    This method achieves everything that can be done with Pandas\' merge fucntion.\n\n    :param left_array: np.ndarray, the left concatenating array.\n    :param right_array: np.ndarray, the right concatenating array.\n    :param left_on: str, the left unique column to merge on.\n    :param right_on: str, the right unique column to merge on.\n    :param how: {inner, outer, leftouter} str, \n        If \'inner\', returns the elements common to both r1 and r2.\n        If \'outer\', returns the common elements as well as the elements of\n        r1 not in r2 and the elements of not in r2.\n        If \'leftouter\', returns the common elements and the elements of r1\n        not in r2.\n    :param left_postscript: str, appended to the names of the fields of left_array that are present\n        in right_array but absent of the key.\n    :param right_postscript: str, appended to the names of the fields of right_array that are present\n        in left_array but absent of the key.\n    :return : np.ndarray, newly merged array.\n    """"""\n\n    # DATA\n    if how not in [""inner"",""outer"",""leftouter""]:\n      raise ValueError(""how has to be set to either: \'inner\',\'outer\',\'leftouter\'"")\n    if left_on != right_on:\n      if left_on in right_array.dtype.names:\n        right_array = drop(right_array,left_on)\n\n      mapping = {right_on: left_on}\n      # LOGIC\n      right_array.dtype.names = [mapping.get(word, word) for word in right_array.dtype.names]\n\n    return rfn.join_by(left_on,left_array, right_array,jointype=how, usemask=False,r1postfix=left_postscript,r2postfix=right_postscript)\n\ndef replace(array: np.ndarray, original=1.00000000e+020, replacement=np.nan) -> np.ndarray:\n    """"""\n    More to be done\n    """"""\n    return np.where(array==1.00000000e+020, np.nan, array)\n\ndef columntype(array: np.ndarray) -> tuple:\n    """"""\n    Take in an array and output columns in numeric and \n    non-numeric types. \n\n    :param array: np.ndarray, input array. \n    :return : (numeric_cols, nonnumeric_cols) a tuple of lists.\n    """"""\n    numeric_cols = []\n    nonnumeric_cols = []\n    for col in array.dtype.names:\n      if (array[col].dtype == float) or (array[col].dtype == int):\n        numeric_cols.append(col)\n      else:\n        nonnumeric_cols.append(col)\n    return numeric_cols, nonnumeric_cols\n    \n# def bifill(array):\n#   mask = np.isnan(array)\n#   idx = np.where(~mask,np.arange(mask.shape[1]),0)\n#   np.maximum.accumulate(idx,axis=1, out=idx)\n#   array[mask] = array[np.nonzero(mask)[0], idx[mask]]\n#   return array\n\n@nb.njit\ndef ffill(arr: np.ndarray) -> np.ndarray:\n    """"""\n    Function to forward fill NaN values using Numba.  \n\n    :param array: np.ndarray, input array with NaNs. \n    :return: np.ndarray, return forward filled array.\n    """"""\n    out = arr.copy()\n    for row_idx in range(out.shape[0]):\n        for col_idx in range(1, out.shape[1]):\n            if np.isnan(out[row_idx, col_idx]):\n                out[row_idx, col_idx] = out[row_idx, col_idx - 1]\n    return out\n\n# My modification to do a backward-fill\ndef bfill(arr: np.ndarray) -> np.ndarray:\n    """"""\n    Function to backward fill NaN values.  \n\n    :param array: np.ndarray, input array with NaNs. \n    :return: np.ndarray, return backward filled array.\n    """"""\n\n    mask = np.isnan(arr)\n    idx = np.where(~mask, np.arange(mask.shape[1]), mask.shape[1] - 1)\n    idx = np.minimum.accumulate(idx[:, ::-1], axis=1)[:, ::-1]\n    out = arr[np.arange(idx.shape[0])[:,None], idx]\n    return out\n\ndef fillmean(array) -> np.ndarray:\n    """"""\n    Function to backward fill NaN values with column mean.  \n\n    :param array: np.ndarray, input array with NaNs. \n    :return: np.ndarray(structured), return mean filled array.\n    """"""\n    array = np.where(np.isnan(array), np.ma.array(array, \n                  mask = np.isnan(array)).mean(axis = 0), array) \n    return array\n\ndef fillna(array: np.ndarray, type=""mean"", value=None) -> np.ndarray:\n    """"""\n    List of filling functions applied to unstructured (normal) arrays and converted\n    back to structured arrays as output.\n\n    :param array: np.ndarray, input array with NaNs. \n    :param type: {mean, value, ffill, bfill} str,\n        \'mean\' returns the column mean.\n        \'value\' returns the value parameter.\n        \'ffill\' returns a forward filled array.\n        \'bfill\' returns a backwards filled array.\n    :param value: optional, value to be used in type=\'value\'.\n    :param array: np.ndarray, input array with NaNs. \n    :return: np.ndarray, return mean filled array.\n    """"""\n    numeric_cols, nonnumeric_cols = columntype(array)\n    dtyped = array[numeric_cols].dtype\n    numeric_unstructured = rfn.structured_to_unstructured(array[numeric_cols]).T\n\n    if type==""mean"":\n      numeric_unstructured = fillmean(numeric_unstructured.T)\n\n    if type==""value"":\n      if value==None:\n        value = 0\n        print(""To replace with anything different to 0, supply value=x"")\n      \n      numeric_unstructured = np.nan_to_num(numeric_unstructured,nan= value)\n\n    if type==""ffill"":\n      numeric_unstructured = ffill(numeric_unstructured)\n\n    if type==""bfill"": ## ffi\n      numeric_unstructured = bfill(numeric_unstructured)\n\n    if type==""mean"":\n      numeric_structured = rfn.unstructured_to_structured(numeric_unstructured,dtype=dtyped)\n    else:\n      numeric_structured = rfn.unstructured_to_structured(numeric_unstructured.T,dtype=dtyped)\n\n    if len(array[nonnumeric_cols].dtype):\n      full_return = numeric_structured\n    else:\n      full_return = concat(array[nonnumeric_cols],numeric_structured,type=""columns"")\n\n    return full_return\n\n\ndef table(array: np.ndarray, length: int = None, row_values: list = None, column_values: list = None, value_name: str = None) -> None:\n    """"""\n    An HTML table to be printed of structured numpy arrays. \n\n    :param array: np.ndarray, input array to be printed. \n    :param length: int, how many rows to print\n    :param row_values: list, a list of the structured array\'s row names.\n    :param column_values: list,  a list of the structured array\'s column names.\n    :param value_name: str, the descriptor to appear on the top left of the table. \n    :return: None print\n    """"""\n\n    if not row_values:\n      row_values = range(len(array))\n    if not column_values:\n      column_values=array.dtype.names\n    if not value_name:\n      value_name=""""\n\n    fields_original = array.dtype.fields\n    \n    is_unstructured = (array.dtype.names == None)\n\n    if is_unstructured == False:\n      array = np.array(array,dtype=\'object\')\n\n    """"""Numpy array HTML representation function.""""""\n    # Fallbacks for cases where we cannot format HTML tables\n    if array.size > 10_000:\n        return f""Large numpy array {array.shape} of {array.dtype}""\n    if (array.ndim != 2) and (is_unstructured) :\n        return f""<pre>{escape(str(array))}</pre>""\n\n    # Table format\n    html = [f""<table><tr><th>{value_name}""]\n    html += (f""<th>{j}"" for j in column_values)\n\n    if length != None:\n      row_values = row_values[:length]\n\n    for i, rv in enumerate(row_values):\n        html.append(f""<tr><th>{rv}"")\n        for j, cv in enumerate(column_values):\n          if is_unstructured:\n            val = array[i,j]\n            html.append(""<td>"")\n            html.append(escape(f""{val:.2f}"" if array.dtype == float else f""{val}""))\n          else:\n            val = array[i][j]\n            html.append(""<td>"")\n            html.append(escape(f""{val:.3f}"" if fields_original[cv][0] == ""float"" else f""{val}""))\n    html.append(""</table>"")\n    display(HTML("""".join(html)))\n\n\n# preallocate empty array and assign slice\ndef shift(array: np.ndarray, steps: int, fill_value=np.nan) -> np.ndarray:\n    """"""\n    Shift an array num number of steps forward. \n\n    :param array: np.ndarray, input array to be printed. \n    :param steps: int, how steps to shift.\n    :param fill_value: optional, fill the values with anything other than NaN\n    :return result: np.ndarray, return shifted array. \n    """"""\n    result = np.empty_like(array)\n    if steps > 0:\n        result[:steps] = fill_value\n        result[steps:] = array[:-steps]\n    elif steps < 0:\n        result[steps:] = fill_value\n        result[:steps] = array[-steps:]\n    else:\n        result[:] = array\n    return result\n\ndef pivot(array: np.ndarray, row: str, column: str, value: str, display: bool = True) -> np.ndarray:\n    """"""\n    Shift an array num number of steps forward. \n\n    :param array: np.ndarray, input array to be pivoted. \n    :param index: string, column to use to make new arrays\'s index. \n    :param columns: string, column to use to make new arrays\'s columns.\n    :param values: string, column to use for populating new arrays\'s values.\n    :param display: bool, whether or not to display a printed HTML data frame. \n    :return pivot_table: np.ndarray, pivoted array. \n    """"""\n\n    rows, row_pos = np.unique(array[row], return_inverse=True)\n    cols, col_pos = np.unique(array[column], return_inverse=True)\n\n    pivot_table = np.zeros((len(rows), len(cols)), dtype=array.dtype)\n    # pivot_table[row_pos, col_pos] = array[""Adj_Close""]\n\n    pivot_table = sps.coo_matrix((array[value], (row_pos, col_pos)),\n                                shape=(len(rows), len(cols))).A\n\n    if display:\n      table(pivot_table,None, list(rows), list(cols), value)\n    \n\n    return pivot_table\n\n# grouped = group(array, [\'Ticker\',\'Month\',\'Year\'],[\'mean\', \'std\', \'min\', \'max\'], [\'Adj_Close\',\'Close\'],display=True)\n# %timeit df.groupby([\'Ticker\',\'Month\',\'Year\'])[[\'Adj_Close\',\'Close\']].agg([\'mean\', \'std\', \'min\', \'max\'])\n# %timeit groupby(array, [\'Ticker\',\'Month\',\'Year\'],[\'mean\', \'std\', \'min\', \'max\'], [\'Adj_Close\',\'Close\'], display=False)\n\n# npg.aggregate(np.unique(tsla_extended[[\'Ticker\',\'Month\',\'Year\']], return_inverse=True)[1], tsla_extended, func=\'last\', fill_value=0)\ndef group(array: np.ndarray,groupby_cols: list, compute_functions: list, calcs_cols: list,display=True, length=None) -> np.ndarray:\n    """"""\n    Group the array according to a unique mapper of multiple columns (groupby_cols) by doing various calculations (compute_functions)\n    over a select columns (calc_cols).\n\n    :param array: np.ndarray, input array to be grouped.  \n    :param groupby_cols: list, columns to be used to do the grouping.  \n    :param compute_functions: list, columns to be used to specify the different calculations. \n    :param calcs_cols: list, columns over which the computations will be done. \n    :param display: bool, whether or not to display a printed HTML data frame. \n    :param length: int, how many rows of the displayed HTML table to print. \n    :return group_array: np.ndarray, grouped array. \n    """"""\n\n    args_dict = {}\n    for a in calcs_cols:\n      for f in compute_functions:\n        args_dict[a+""_""+f] = npg.aggregate(np.unique(array[groupby_cols], return_inverse=True)[1], array[a],f)\n\n    struct_gb = rfn.unstructured_to_structured(np.c_[list(args_dict.values())].T,names=list(args_dict.keys()))\n    grouped = np.unique(array[groupby_cols], return_inverse=True)[0]\n    group_array = rfn.merge_arrays([grouped,struct_gb],flatten=True)\n    if display:\n      table(group_array,length)\n    return group_array\n\ndef pandas(array: np.ndarray) -> pd.DataFrame:\n    """"""\n    Convert structured numpy to pandas dataframe. \n\n    :param array: np.ndarray, input array to be transformed into a pandas df.  \n    :return : pd.DataFrame: pandas dataframe.\n    """"""\n\n    is_unstructured = (array.dtype.names == None)\n    if is_unstructured == True:\n      raise ValueError(""Arrays must have the same size"")\n    else:\n      return pd.DataFrame(array)\n\n#grouped_frame_two = grouped_frame.astype({name:str(grouped.dtype.fields[name][0]) for name in grouped.dtype.names})\ndef structured(pands: pd.DataFrame) -> np.ndarray:\n    """"""\n    Convert pandas dataframe to structured numpy array. \n\n    :param pands: pd.DataFrame, pandas df to be transformed into structured numpy array.   \n    :return : np.ndarray, structured array.\n    """"""\n    return pands.to_records(index=False)\n\n#tsla_new_rem = lags(tsla_new_rem, ""Adj_Close"", 5)\ndef lags(array: np.ndarray, feature: str, lags: int) -> np.ndarray:\n    """"""\n    Create a range of lags for a certain feature (column), append and\n    return the full array. \n\n    :param array: np.ndarray, array from which to calculate lagged columns.\n    :param feature: str, name of column to be lagged. \n    :param lags: int, how many lag columns to be created with steps of one.   \n    :return : np.ndarray, structured array with appended lags.\n    """"""\n    for lag in range(1, lags + 1):\n        col = \'{}_lag_{}\' .format(feature, lag)  \n        array = add(array,col, shift(array[feature],lag), float)\n    return array\n\n#corr_mat = corr(closing)\ndef corr(array: np.ndarray, display=True) -> np.ndarray:\n    """"""\n    Correlation matrix to be returned from an homogenous structured array.\n\n    :param array: np.ndarray, array from which to derive correlation matrix.\n    :param feature: str, name of column to be lagged. \n    :param lags: int, how many lag columns to be created with steps of one.   \n    :param display: bool, whether or not to display a printed HTML data frame.\n    :return : np.ndarray, correlation matrix in the format of an unstructured array.\n    """"""\n    corr_mat_price = np.corrcoef(rfn.structured_to_unstructured(array).T)\n    if display!=False:\n        table(corr_mat_price, None, array.dtype.names, column_values=array.dtype.names,value_name=""Correlation"")\n    return corr_mat_price\n\n\ndef describe(array: np.ndarray, display=True) -> np.ndarray:\n    """"""\n    Descriptive statistics to be returned from a numerical array. \n\n    :param array: np.ndarray, array from which to derive descriptive statistics. \n    :param display: bool, whether or not to display a printed HTML data frame.\n    :return : np.ndarray, descriptive statistics in the format of an unstructured array.\n    """"""\n    fill_array = np.zeros(shape=(7,len(array.dtype.names)))\n    col_keys = [""observations"", ""minimum"", ""maximum"", ""mean"", ""variance"", ""skewness"", ""kurtosis""]\n    en_dec = 0 \n    names = []\n    for en, arr in enumerate(array.dtype.names): #do not need the loop at this point, but looks prettier\n      \n      en = en - en_dec\n      try:\n        desc = stats.describe(array[arr])\n        names.append(arr)\n        \n      except:\n        fill_array = np.delete(fill_array,en,1)\n        en_dec = en_dec + 1\n        continue\n      col_values = [desc[0], desc[1][0], desc[1][1], desc[2], desc[3], desc[4], desc[5]]\n      # newrow = [1,2,3]\n      # A = numpy.vstack([A, newrow])\n      fill_array[:,en] = col_values\n    fill_array = np.round(fill_array,3)\n    if display==True:\n      table(fill_array.T, None, names,col_keys,""Describe"")\n    return fill_array\n\n### outliers\n\n### std_signal = (signal - np.mean(signal)) / np.std(signal)\n\n@nb.jit\ndef detect(signal: np.ndarray, treshold = 2.0) -> list:\n    detected = []\n    for i in range(len(signal)):\n        if np.abs(signal[i]) > treshold:\n            detected.append(i)\n    return detected\n    \n### Noise Filtering\n\n@nb.jit\ndef removal(signal: np.ndarray, repeat: int) -> np.ndarray:\n    copy_signal = np.copy(signal)\n    for j in range(repeat):\n        for i in range(3, len(signal)):\n            copy_signal[i - 1] = (copy_signal[i - 2] + copy_signal[i]) / 2\n    return copy_signal\n\n### Get the noise\n@nb.jit\ndef get(original_signal: np.ndarray, removed_signal: np.ndarray) -> np.ndarray:\n    buffer = []\n    for i in range(len(removed_signal)):\n        buffer.append(original_signal[i] - removed_signal[i])\n    return np.array(buffer)\n\n\n\n## ===================================================================================\n## ===================================================================================\n\n## ===================================================================================\n## ===================================================================================\n\ndef returns(array: np.ndarray, col: str, type: str) -> np.ndarray:\n    """"""\n    Singular column array of returns to be returned from a nominated column of the full array.\n    The returns can be returned both in log and normal format.\n\n    :param array: np.ndarray, array which houses the price column from which to calculate the returns. \n    :param col: str, the column name of the price series to be used in return calculation. \n    :param type: {\'log\', \'normal\'} str, the type of return calculation to be returned. \n    :return : np.ndarray, the return series in singular array format. \n    """"""\n    if type==""log"":\n      return np.log(array[col]/shift(array[col], 1))\n    elif type==""normal"":\n      return array[col]/shift(array[col], 1) - 1\n\ndef portfolio_value(array, col, type) -> np.ndarray:\n    """"""\n    Singular column array of portfolio values to be returned from a nominated column of the full array.\n    The portfolio value can be calculated from both a log and normal input format.\n\n    :param array: np.ndarray, array which houses the returns column from which to calculate the returns. \n    :param col: str, the column name of the returns series to be used in portfolio value calculation. \n    :param type: {\'log\', \'normal\'} str, the type of calculation to be ingested in the portfolio value calculation. \n    :return : np.ndarray, the portfolio value series in singular array format. \n    """"""\n    if type==""normal"":\n      return np.cumprod(array[col]+1) \n    if type==""log"":\n      return np.cumprod(np.exp(array[col]))\n\n\ndef cummulative_return(array, col, type) -> np.ndarray:\n    """"""\n    Singular column array of cummulative returns to be returned from a nominated column of the full array.\n    The cummulative returns can be calculated from both a log and normal input format.\n\n    :param array: np.ndarray, array which houses the returns column from which to calculate the returns. \n    :param col: str, the column name of the returns series to be used in the cummulative returns calculation. \n    :param type: {\'log\', \'normal\'} str, the type of calculation to be ingested in the cummulative returns calculation. \n    :return : np.ndarray, the cummulative returns series in singular array format. \n    """"""\n\n    if type==""normal"":\n      return np.cumprod(array[col]+1) - 1\n    if type==""log"":\n      return np.cumprod(np.exp(array[col])) - 1\n\ndef dropnarow(array, col) -> np.ndarray:\n    """"""\n    Dropping rows in a structured array where NaN values appear. \n\n    :param array: np.ndarray, which houses the array with NaN value rows.\n    :param col: str, the column to look at when identifying the NaN value rows.  \n    :return : np.ndarray, return the array without any NaN in the rows. \n    """"""\n    return array[~np.isnan(array[col])]\n\ndef subset(array, fields) -> np.ndarray:\n    """"""\n    More to be done\n    """"""\n    \n    return array.getfield(np.dtype(\n        {name: array.dtype.fields[name] for name in fields}\n    ))\n\n\n## ===================================================================================\n## ===================================================================================\n\n## ===================================================================================\n## ===================================================================================\n\n# PMA = moving_average(combined_trends[""debtP""], 3)\n# OMA = moving_average(combined_trends[""debtO""], 3)\n\ndef moving_average(a, n=5):\n    a = np.ma.masked_array(a,np.isnan(a))\n    ret = np.cumsum(a.filled(0))\n    ret[n:] = ret[n:] - ret[:-n]\n    counts = np.cumsum(~a.mask)\n    counts[n:] = counts[n:] - counts[:-n]\n    ret[~a.mask] /= counts[~a.mask]\n    ret[a.mask] = np.nan\n\n    return ret\n\ndef moving_average(array,column, period):\n    signal = array[column]\n    buffer = [np.nan] * period\n    for i in range(period,len(signal)):\n        buffer.append(signal[i-period:i].mean())\n    return buffer\n\ndef auto_regressive(array,column, p, d, q, future_count = 10):\n    """"""\n    p = the order (number of time lags)\n    d = degree of differencing\n    q = the order of the moving-average\n    """"""\n    signal = array[column]\n    buffer = np.copy(signal).tolist()\n    for i in range(future_count):\n        ma = moving_average(np.array(buffer[-p:]), q)\n        forecast = buffer[-1]\n        for n in range(0, len(ma), d):\n            forecast -= buffer[-1 - n] - ma[n]\n        buffer.append(forecast)\n    return buffer\n\n# future_count = 15\n# predicted_15 = auto_regressive(signal,15,1,2,future_count)\n# predicted_30 = auto_regressive(signal,30,1,2,future_count)\n\ndef linear_weight_moving_average(array,column, period):\n    signal = array[column]\n    buffer = [np.nan] * period\n    for i in range(period, len(signal)):\n        buffer.append(\n            (signal[i - period : i] * (np.arange(period) + 1)).sum()\n            / (np.arange(period) + 1).sum()\n        )\n    return buffer\n\ndef anchor(array,column, weight):\n    signal = array[column]\n    buffer = []\n    last = signal[0]\n    for i in signal:\n        smoothed_val = last * weight + (1 - weight) * i\n        buffer.append(smoothed_val)\n        last = smoothed_val\n    return buffer\n'"
