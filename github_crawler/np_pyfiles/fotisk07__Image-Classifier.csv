file_path,api_count,code
futils.py,0,"b'import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch import tensor\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\nimport torchvision.models as models\nfrom collections import OrderedDict\nimport json\nimport PIL\nfrom PIL import Image\nimport argparse\n\narch = {""vgg16"":25088,\n        ""densenet121"":1024,\n        ""alexnet"":9216}\n\n\ndef load_data(where  = ""./flowers"" ):\n    \'\'\'\n    Arguments : the datas\' path\n    Returns : The loaders for the train, validation and test datasets\n\n    This function receives the location of the image files, applies the necessery transformations (rotations,flips,normalizations and crops) and converts the images to tensor in order to be able to be fed into the neural network\n\n    \'\'\'\n\n    data_dir = where\n    train_dir = data_dir + \'/train\'\n    valid_dir = data_dir + \'/valid\'\n    test_dir = data_dir + \'/test\'\n\n    #Apply the required transfomations to the test dataset in order to maximize the efficiency of the learning\n    #process\n\n\n    train_transforms = transforms.Compose([transforms.RandomRotation(50),\n                                           transforms.RandomResizedCrop(224),\n                                           transforms.RandomHorizontalFlip(),\n                                           transforms.ToTensor(),\n                                           transforms.Normalize([0.485, 0.456, 0.406],\n                                                                [0.229, 0.224, 0.225])])\n\n    # Crop and Resize the data and validation images in order to be able to be fed into the network\n\n    test_transforms = transforms.Compose([transforms.Resize(256),\n                                          transforms.CenterCrop(224),\n                                          transforms.ToTensor(),\n                                          transforms.Normalize([0.485, 0.456, 0.406],\n                                                               [0.229, 0.224, 0.225])])\n\n    validation_transforms = transforms.Compose([transforms.Resize(256),\n                                                transforms.CenterCrop(224),\n                                                transforms.ToTensor(),\n                                                transforms.Normalize([0.485, 0.456, 0.406],\n                                                                     [0.229, 0.224, 0.225])])\n\n\n    # TODO: Load the datasets with ImageFolder\n    train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n    validation_data = datasets.ImageFolder(valid_dir, transform=validation_transforms)\n    test_data = datasets.ImageFolder(test_dir ,transform = test_transforms)\n\n    # TODO: Using the image datasets and the trainforms, define the dataloaders\n    # The data loaders are going to use to load the data to the NN(no shit Sherlock)\n    trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n    vloader = torch.utils.data.DataLoader(validation_data, batch_size =32,shuffle = True)\n    testloader = torch.utils.data.DataLoader(test_data, batch_size = 20, shuffle = True)\n\n\n\n    return trainloader , vloader, testloader\n\n\ndef nn_setup(structure=\'densenet121\',dropout=0.5, hidden_layer1 = 120,lr = 0.001,power=gpu):\n    \'\'\'\n    Arguments: The architecture for the network(alexnet,densenet121,vgg16), the hyperparameters for the network (hidden layer 1 nodes, dropout and learning rate) and whether to use gpu or not\n    Returns: The set up model, along with the criterion and the optimizer fo the Training\n\n    \'\'\'\n\n    if structure == \'vgg16\':\n        model = models.vgg16(pretrained=True)\n    elif structure == \'densenet121\':\n        model = models.densenet121(pretrained=True)\n    elif structure == \'alexnet\':\n        model = models.alexnet(pretrained = True)\n    else:\n        print(""Im sorry but {} is not a valid model.Did you mean vgg16,densenet121,or alexnet?"".format(structure))\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n        from collections import OrderedDict\n        classifier = nn.Sequential(OrderedDict([\n            (\'dropout\',nn.Dropout(dropout)),\n            (\'inputs\', nn.Linear(arch[\'structure\'], hidden_layer1)),\n            (\'relu1\', nn.ReLU()),\n            (\'hidden_layer1\', nn.Linear(hidden_layer1, 90)),\n            (\'relu2\',nn.ReLU()),\n            (\'hidden_layer2\',nn.Linear(90,80)),\n            (\'relu3\',nn.ReLU()),\n            (\'hidden_layer3\',nn.Linear(80,102)),\n            (\'output\', nn.LogSoftmax(dim=1))\n                          ]))\n\n\n        model.classifier = classifier\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.classifier.parameters(), lr )\n\n        if torch.cuda.is_available() and power = \'gpu\':\n            model.cuda()\n\n        return model, criterion, optimizer\n\n\ndef train_network(model, criterion, optimizer, epochs = 3, print_every=20, loader=trainloader, power=\'gpu\'):\n    \'\'\'\n    Arguments: The model, the criterion, the optimizer, the number of epochs, teh dataset, and whether to use a gpu or not\n    Returns: Nothing\n\n    This function trains the model over a certain number of epochs and displays the training,validation and accuracy every ""print_every"" step using cuda if specified. The training method is specified by the criterion and the optimizer which are NLLLoss and Adam respectively\n\n    \'\'\'\n    steps = 0\n    running_loss = 0\n\n    print(""--------------Training is starting------------- "")\n    for e in range(epochs):\n        running_loss = 0\n        for ii, (inputs, labels) in enumerate(loader):\n            steps += 1\n            if torch.cuda.is_available() and power=\'gpu\':\n                inputs, labels = inputs.to(\'cuda\'), labels.to(\'cuda\')\n\n            optimizer.zero_grad()\n\n            # Forward and backward passes\n            outputs = model.forward(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n            if steps % print_every == 0:\n                model.eval()\n                vlost = 0\n                accuracy=0\n\n\n                for ii, (inputs2,labels2) in enumerate(vloader):\n                    optimizer.zero_grad()\n                    if torch.cuda.is_available():\n                        inputs2, labels2 = inputs2.to(\'cuda:0\') , labels2.to(\'cuda:0\')\n                        model.to(\'cuda:0\')\n\n                    with torch.no_grad():\n                        outputs = model.forward(inputs2)\n                        vlost = criterion(outputs,labels2)\n                        ps = torch.exp(outputs).data\n                        equality = (labels2.data == ps.max(1)[1])\n                        accuracy += equality.type_as(torch.FloatTensor()).mean()\n\n                vlost = vlost / len(vloader)\n                accuracy = accuracy /len(vloader)\n\n\n\n                print(""Epoch: {}/{}... "".format(e+1, epochs),\n                      ""Loss: {:.4f}"".format(running_loss/print_every),\n                      ""Validation Lost {:.4f}"".format(vlost),\n                       ""Accuracy: {:.4f}"".format(accuracy))\n\n\n                running_loss = 0\n\n\n    print(""-------------- Finished training -----------------------"")\n    print(""Dear User I the ulitmate NN machine trained your model. It required"")\n    print(""----------Epochs: {}------------------------------------"".format(epochs))\n    print(""----------Steps: {}-----------------------------"".format(steps))\n    print(""That\'s a lot of steps"")\n\n\ndef save_checkpoint(path=\'checkpoint.pth\',structure =\'densenet121\', hidden_layer1=120,dropout=0.5,lr=0.001,epochs=12):\n    \'\'\'\n    Arguments: The saving path and the hyperparameters of the network\n    Returns: Nothing\n\n    This function saves the model at a specified by the user path\n\n    \'\'\'\n    model.class_to_idx = train_data.class_to_idx\n    model.cpu\n    torch.save({\'structure\' :structure,\n                \'hidden_layer1\':hidden_layer1,\n                \'dropout\':dropout,\n                \'lr\':lr,\n                \'nb_of_epochs\':epochs,\n                \'state_dict\':model.state_dict(),\n                \'class_to_idx\':model.class_to_idx},\n                path)\n\n\ndef load_checkpoint(path=\'checkpoint.pth\'):\n    \'\'\'\n    Arguments: The path of the checkpoint file\n    Returns: The Neural Netowrk with all hyperparameters, weights and biases\n\n    \'\'\'\n    checkpoint = torch.load(path)\n    structure = checkpoint[\'structure\']\n    hidden_layer1 = checkpoint[\'hidden_layer1\']\n    dropout = checkpoint[\'dropout\']\n    lr=checkpoint[\'lr\']\n\n    model,_,_ = nn_setup(structure , dropout,hidden_layer1,lr)\n\n    model.class_to_idx = checkpoint[\'class_to_idx\']\n    model.load_state_dict(checkpoint[\'state_dict\'])\n\n\ndef process_image(image_path):\n    \'\'\'\n    Arguments: The image\'s path\n    Returns: The image as a tensor\n\n    This function opens the image usign the PIL package, applies the  necessery transformations and returns the image as a tensor ready to be fed to the network\n\n    \'\'\'\n\n    for i in image_path:\n        path = str(i)\n    img = Image.open(i) # Here we open the image\n\n    make_img_good = transforms.Compose([ # Here as we did with the traini ng data we will define a set of\n        # transfomations that we will apply to the PIL image\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    tensor_image = make_img_good(img)\n\n    return tensor_image\n\n\ndef predict(image_path, model, topk=5,power=\'gpu\'):\n    \'\'\'\n    Arguments: The path to the image, the model, the number of prefictions and whether cuda will be used or not\n    Returns: The ""topk"" most probable choices that the network predicts\n\n    \'\'\'\n\n    if torch.cuda.is_available() and power=\'gpu\':\n        model.to(\'cuda:0\')\n\n    img_torch = process_image(image_path)\n    img_torch = img_torch.unsqueeze_(0)\n    img_torch = img_torch.float()\n\n    if power == \'gpu\':\n        with torch.no_grad():\n            output = model.forward(img_torch.cuda())\n    else:\n        with torch.no_grad():\n            output=model.forward(img_torch)\n\n    probability = F.softmax(output.data,dim=1)\n\n    return probability.topk(topk)\n'"
predict.py,2,"b'import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch import tensor\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\nimport torchvision.models as models\nfrom collections import OrderedDict\nimport json\nimport PIL\nfrom PIL import Image\nimport argparse\n\nimport futils\n\n#Command Line Arguments\n\nap = argparse.ArgumentParser(\n    description=\'predict-file\')\nap.add_argument(\'input_img\', default=\'paind-project/flowers/test/1/image_06752.jpg\', nargs=\'*\', action=""store"", type = str)\nap.add_argument(\'checkpoint\', default=\'/home/workspace/paind-project/checkpoint.pth\', nargs=\'*\', action=""store"",type = str)\nap.add_argument(\'--top_k\', default=5, dest=""top_k"", action=""store"", type=int)\nap.add_argument(\'--category_names\', dest=""category_names"", action=""store"", default=\'cat_to_name.json\')\nap.add_argument(\'--gpu\', default=""gpu"", action=""store"", dest=""gpu"")\n\npa = ap.parse_args()\npath_image = pa.input_img\nnumber_of_outputs = pa.top_k\npower = pa.gpu\ninput_img = pa.input_img\npath = pa.checkpoint\n\n\n\ntraining_loader, testing_loader, validation_loader = futils.load_data()\n\n\nfutils.load_checkpoint(path)\n\n\nwith open(\'cat_to_name.json\', \'r\') as json_file:\n    cat_to_name = json.load(json_file)\n\n\nprobabilities = futils.predict(path_image, model, number_of_outputs, power)\n\n\nlabels = [cat_to_name[str(index + 1)] for index in np.array(probabilities[1][0])]\nprobability = np.array(probabilities[0][0])\n\n\ni=0\nwhile i < number_of_outputs:\n    print(""{} with a probability of {}"".format(labels[i], probability[i]))\n    i += 1\n\nprint(""Here you are"")\n'"
train.py,0,"b'import matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport torch\nfrom torch import nn\nfrom torch import tensor\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\nimport torchvision.models as models\nimport argparse\n\nimport futils\n\nap = argparse.ArgumentParser(description=\'Train.py\')\n# Command Line ardguments\n\nap.add_argument(\'data_dir\', nargs=\'*\', action=""store"", default=""./flowers/"")\nap.add_argument(\'--gpu\', dest=""gpu"", action=""store"", default=""gpu"")\nap.add_argument(\'--save_dir\', dest=""save_dir"", action=""store"", default=""./checkpoint.pth"")\nap.add_argument(\'--learning_rate\', dest=""learning_rate"", action=""store"", default=0.001)\nap.add_argument(\'--dropout\', dest = ""dropout"", action = ""store"", default = 0.5)\nap.add_argument(\'--epochs\', dest=""epochs"", action=""store"", type=int, default=1)\nap.add_argument(\'--arch\', dest=""arch"", action=""store"", default=""vgg16"", type = str)\nap.add_argument(\'--hidden_units\', type=int, dest=""hidden_units"", action=""store"", default=120)\n\npa = ap.parse_args()\nwhere = pa.data_dir\npath = pa.save_dir\nlr = pa.learning_rate\nstructure = pa.arch\ndropout = pa.dropout\nhidden_layer1 = pa.hidden_units\npower = pa.gpu\nepochs = pa.epochs\n\n\ntrainloader, v_loader, testloader = futils.load_data(where)\n\n\nmodel, optimizer, criterion = futils.nn_setup(structure,dropout,hidden_layer1,lr,power)\n\n\nfutils.train_network(model, optimizer, criterion, epochs, 20, trainloader, power)\n\n\nfutils.save_checkpoint(path,structure,hidden_layer1,dropout,lr)\n\n\nprint(""All Set and Done. The Model is trained"") # Coffee timeee\n'"
