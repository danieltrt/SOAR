file_path,api_count,code
src/codegen_function.py,0,"b'from __future__ import print_function\n\nimport argparse\nimport itertools\nimport os\nimport platform\nimport re\nimport subprocess\nimport sys\nimport tempfile\n\n""""""\nGlobal constants used by NumpyEigen\n""""""\nNUMPY_ARRAY_TYPES_TO_CPP = {\n    # Dense types\n    \'dense_float\': (\'npy_float\', \'float\', \'float32\'),\n    \'dense_double\': (\'npy_double\', \'double\', \'float64\'),\n    \'dense_longdouble\': (\'npy_longdouble\', \'longdouble\', \'float128\'),\n    \'dense_byte\': (\'npy_byte\', \'byte\', \'int8\'),\n    \'dense_short\': (\'npy_short\', \'short\', \'int16\'),\n    \'dense_int\': (\'npy_int\', \'int\', \'int32\'),\n    \'dense_long\': (\'npy_long\', \'long\', \'int64\'),\n    \'dense_longlong\': (\'npy_longlong\', \'longlong\', \'int128\'),\n    \'dense_ubyte\': (\'npy_ubyte\', \'ubyte\', \'uint8\'),\n    \'dense_ushort\': (\'npy_ushort\', \'ushort\', \'uint16\'),\n    \'dense_uint\': (\'npy_int\', \'uint\', \'uint32\'),\n    \'dense_ulong\': (\'npy_ulong\', \'ulong\', \'uint64\'),\n    \'dense_ulonglong\': (\'npy_ulonglong\', \'ulonglong\', \'uint128\'),\n    \'dense_c64\': (\'npy_complex64\', \'c64\', \'complex64\'),\n    \'dense_c128\': (\'npy_complex128\', \'c128\', \'complex128\'),\n    \'dense_c256\': (\'npy_complex256\', \'c256\', \'complex256\'),\n    \'dense_bool\': (\'npy_bool\', \'bool\', \'bool\'),\n\n    # Sparse types\n    \'sparse_float\': (\'npy_float\', \'float\', \'float32\'),\n    \'sparse_double\': (\'npy_double\', \'double\', \'float64\'),\n    \'sparse_longdouble\': (\'npy_longdouble\', \'longdouble\', \'float128\'),\n    \'sparse_byte\': (\'npy_byte\', \'byte\', \'int8\'),\n    \'sparse_short\': (\'npy_short\', \'short\', \'int16\'),\n    \'sparse_int\': (\'npy_int\', \'int\', \'int32\'),\n    \'sparse_long\': (\'npy_long\', \'long\', \'int64\'),\n    \'sparse_longlong\': (\'npy_longlong\', \'longlong\', \'int128\'),\n    \'sparse_ubyte\': (\'npy_ubyte\', \'ubyte\', \'uint8\'),\n    \'sparse_ushort\': (\'npy_ushort\', \'ushort\', \'uint16\'),\n    \'sparse_uint\': (\'npy_uint\', \'uint\', \'uint32\'),\n    \'sparse_ulong\': (\'npy_ulong\', \'ulong\', \'uint64\'),\n    \'sparse_ulonglong\': (\'npy_ulonglong\', \'ulonglong\', \'uint128\'),\n    \'sparse_c64\': (\'npy_complex64\', \'c64\', \'complex64\'),\n    \'sparse_c128\': (\'npy_complex128\', \'c128\', \'complex128\'),\n    \'sparse_c256\': (\'npy_complex256\', \'c256\', \'complex256\'),\n    \'sparse_bool\': (\'npy_bool\', \'bool\', \'bool\')}\n\nNUMPY_ARRAY_TYPES = list(NUMPY_ARRAY_TYPES_TO_CPP.keys())\nNUMPY_SCALAR_TYPES = list(set([v[2] for v in NUMPY_ARRAY_TYPES_TO_CPP.values()]))\nMATCHES_TOKEN = ""npe_matches""\nARG_TOKEN = ""npe_arg""\nDEFAULT_ARG_TOKEN = ""npe_default_arg""\nBEGIN_CODE_TOKEN = ""npe_begin_code""\nEND_CODE_TOKEN = ""npe_end_code""\nFUNCTION_TOKEN = ""npe_function""\nDOC_TOKEN = ""npe_doc""\nCOMMENT_TOKEN = ""//""\nSPARSE_MATCHES_TOKEN = ""npe_sparse_like""\nDENSE_MATCHES_TOKEN = ""npe_dense_like""\n\nLOG_DEBUG = 3\nLOG_INFO = 1\nLOG_INFO_VERBOSE = 2\nLOG_ERROR = 0\n\n""""""\nGlobal Variables set at runtime\n""""""\ncpp_command = None  # Name of the command to run for the C preprocessor. Set at input.\ncpp_path = None  # Path to the executable\nverbosity_level = 1  # Integer representing the level of verbosity 0 = only log errors, 1 = normal, 2 = verbose\n\n\nclass TermColors:\n    HEADER = \'\\033[95m\'\n    OKBLUE = \'\\033[94m\'\n    OKGREEN = \'\\033[92m\'\n    WARNING = \'\\033[93m\'\n    FAIL = \'\\033[91m\'\n    ENDC = \'\\033[0m\'\n    BOLD = \'\\033[1m\'\n    UNDERLINE = \'\\033[4m\'\n\n\nclass ParseError(Exception):\n    pass\n\n\nclass SemanticError(Exception):\n    pass\n\n\ndef log(log_level, logstr, end=\'\\n\', file=sys.stdout):\n    if log_level <= verbosity_level:\n        print(logstr, end=end, file=file)\n\n\ndef tokenize_npe_line(stmt_token, line, line_number, max_iters=64, split_token=""__NPE_SPLIT_NL__""):\n    """"""\n    Tokenize an NPE statement of the forn STMT(arg1, ..., argN)\n    :param stmt_token: The name of the statement to parse.\n    :param line: The line to tokenize.\n    :param line_number: The line number in the file being parsed.\n    :param max_iters: The number of iterations of the C preprocessor to parse everything.\n                      This has the side effect of setting the max number of arguments.\n    :param split_token: The split token for the C preprocessor to use. Don\'t change this unless you have a good reason.\n    :return:\n    """"""\n\n    def run_cpp(input_str):\n        if platform.system() == \'Windows\':\n            filename = ""tmp.cc""\n            tmpf = open(filename, ""w"")\n            tmpf.write(input_str)\n            tmpf.flush()\n            tmpf.close()\n        else:\n            tmpf = tempfile.NamedTemporaryFile(mode=""w+"", suffix="".cc"")\n            tmpf.write(input_str)\n            tmpf.flush()\n            filename = tmpf.name\n\n        cmd = [filename]\n        for c in cpp_command:\n            cmd.append(c)\n\n        if platform.system() == \'Windows\':\n            cmd = [\' \'.join(cmd)]\n\n        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, executable=cpp_path)\n        cpp_output, cpp_err = p.communicate()\n\n        cpp_err = cpp_err.decode(""utf-8"")\n        cpp_err = re.sub(r\'(Microsoft \\(R\\)).+\', \'\', cpp_err)\n        cpp_err = re.sub(r\'(Copyright \\(C\\)).+\', \'\', cpp_err)\n        cpp_err = re.sub(r\'(\' + filename + \')\', \'\', cpp_err)\n        cpp_err = cpp_err.strip()\n\n        tmpf.close()\n        return cpp_output.decode(\'utf-8\'), cpp_err, filename\n\n    cpp_str = ""#define %s(arg, ...) arg %s %s(__VA_ARGS__)"" % (stmt_token, split_token, stmt_token)\n\n    cpp_input_str = cpp_str + ""\\n"" + line + ""\\n""\n\n    exited_before_max_iters = False\n\n    tokens = []\n    for i in range(max_iters):\n        output, err, filename = run_cpp(cpp_input_str)\n\n        if err:\n            raise ParseError(""Invalid code at line %d:\\nCPP Error message:\\n%s"" %\n                             (line_number, err))\n\n        output = output.split(\'\\n\')\n\n        parsed_string = """"\n        for out_line in output:\n            if str(out_line).strip().startswith(""#""):\n                continue\n            elif str(out_line).strip().startswith(""Microsoft (R)""):\n                continue\n            elif str(out_line).strip().startswith(""Copyright (C) Microsoft Corporation""):\n                continue\n            elif str(out_line).strip() == filename:\n                continue\n            else:\n                parsed_string += str(out_line) + ""\\n""\n\n        tokens = parsed_string.split(split_token)\n\n        if tokens[-1].strip().startswith(""%s()"" % stmt_token) and tokens[-1].strip() != ""%s()"" % stmt_token:\n            raise ParseError(""Extra tokens after `%s` statement on line %d"" % (stmt_token, line_number))\n        elif tokens[-1].strip() == ""%s()"" % stmt_token:\n            exited_before_max_iters = True\n            tokens.pop()\n            break\n\n        cpp_input_str = cpp_str + ""\\n"" + parsed_string\n\n    if not exited_before_max_iters:\n        raise ParseError(""Reached token parser maximum recursion depth (%d) at line %d"" % (max_iters, line_number))\n\n    if len(tokens) == 0:\n        raise RuntimeError(""This should never happen but clearly it did. ""\n                           ""File a github issue at https://github.com/fwilliams/numpyeigen"")\n\n    tokens = [s.strip() for s in tokens]\n\n    return tokens\n\n\ndef validate_identifier_name(var_name):\n    """"""\n    Returns True if var_name is a valid C++ identifier, otherwise throws a ParseError\n    :param var_name: The name of the identifier to check\n    :return: True if var_name is a valid C++ identifier\n    """"""\n    # TODO: Validate identifier name\n    return var_name\n\n\ndef is_numpy_type(type_name):\n    """"""\n    Return True if typestr refers to a NPE type corresponding to a Numpy/Eigen type\n    :param type_name: The type string to check\n    :return: True if typestr names a Numpy/Eigen type (e.g. dense_f64, sparse_i32)\n    """"""\n    return type_name.lower() in NUMPY_ARRAY_TYPES\n\n\ndef is_sparse_type(type_name):\n    """"""\n    Return True if typestr refers to a NPE type corresponding to a Numpy/Eigen sparse type\n    :param type_name: The type string to check\n    :return: True if typestr names a Numpy/Eigen sparse type (e.g. sparse_f64, sparse_i32)\n    """"""\n    return is_numpy_type(type_name) and type_name.startswith(""sparse_"")\n\n\ndef is_dense_type(type_name):\n    """"""\n    Return True if typestr refers to a NPE type corresponding to a Numpy/Eigen dense type\n    :param type_name: The type string to check\n    :return: True if typestr names a Numpy/Eigen dense type (e.g. dense_f64, dense_i32)\n    """"""\n    return is_numpy_type(type_name) and type_name.startswith(""dense_"")\n\n\ndef consume_token(line, token, line_number, case_sensitive=True):\n    """"""\n    Consume the token, token, from the input line, ignoring leading whitespace. If the line\n    does not start with token, then throw a ParseError\n    :param line: The line from which to consume the token\n    :param token: The token string to consume\n    :param line_number: The line number in the file being read used for error reporting\n    :param case_sensitive: Whether parsing is case sensitive or not\n    :return: The line with the input token stripped\n    """"""\n    check_line = line if case_sensitive else line.lower()\n    check_token = token if case_sensitive else token.lower()\n    if not check_line.startswith(check_token):\n        # TODO: Pretty error message\n        raise ParseError(""Missing \'%s\' at line %d"" % (token, line_number))\n\n    return line[len(token):]\n\n\ndef consume_eol(line, line_number):\n    """"""\n    Consumes whitespace at the end of a line\n    :param line: The line from which to consume from\n    :param line_number: The number of the line in the file being parsed, used for error reporting\n    :return: An empty string on success\n    """"""\n    if len(line.strip()) != 0:\n        # TODO: Pretty error message\n        raise ParseError(""Expected end-of-line after \')\' token on line %d. Got \'%s\'"" % (line_number, line.strip()))\n    return line.strip()\n\n\ndef consume_call_statement(token, line, line_number, throw=True):\n    """"""\n    Consume the tokens <token> and <(> from the input line ignoring whitespace\n    :param token: The name of the call token\n    :param line: The line to check\n    :param line_number: The number of the line in the file being read\n    :param throw: Whether to throw an exception or simply return False if the line does not start with ""token(""\n    :return: The line with the start tokens consumed or False if throw=False and the line did not start with ""token(""\n    """"""\n    try:\n        line = consume_token(line.strip(), token, line_number)\n        consume_token(line.strip(), \'(\', line_number)\n    except ParseError:\n        if throw:\n            raise ParseError(""Got invalid token at line %d. Expected `%s`"" % (line_number, token))\n        else:\n            return False\n    return line\n\n\nclass NpeFileReader(object):\n    def __init__(self, name):\n        self.file_name = name\n        self.file = open(name, \'r\')\n        self.line_number = 0\n        self.line = """"\n\n    def close(self):\n        return self.file.close()\n\n    def readline(self):\n        self.line_number += 1\n        return self.file.readline()\n\n    def peekline(self):\n        if self.file.closed:\n            return """"\n        pos = self.file.tell()\n        line = self.readline()\n        self.line_number -= 1\n        self.file.seek(pos)\n        return line\n\n    def __enter__(self):  # To allow using in \'with\' statements\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.close()\n\n    def __next__(self):\n        self.line = self.readline()\n        if len(self.line) == 0:\n            raise StopIteration()\n        else:\n            return self.line\n\n    def next(self):  # Python 2.7 compatibility\n        return self.__next__()\n\n    def __iter__(self):\n        return self\n\n\nclass NpeArgument(object):\n    def __init__(self, name, is_matches, types, line_number, default_value):\n        self.name = name\n        self.is_matches = is_matches\n        self.scalar_matches_only = False\n        self.dense_scalar_matches = False  # If scalar_matches_only is set, determines whether this is from dense_like\n        self.types = types\n        self.line_number = line_number\n        self.is_sparse = False\n        self.is_dense = False\n        self.default_value = default_value\n        self.group = None\n        self.matches_name = """"\n        self._is_nullable = False\n\n    @property\n    def is_numpy_type(self):\n        return self.is_sparse or self.is_dense or self.is_matches\n\n    @property\n    def is_nullable(self):\n        return self.is_matches and self.default_value is not None\n\n    def __repr__(self):\n        return str(self.__dict__)\n\n\nclass NpeArgumentGroup(object):\n    def __init__(self, types=None, arguments=None):\n        self.arguments = arguments if arguments is not None else []\n        self.types = types if types is not None else []\n        self.meta_group = None  # Other group whose scalar type must match this one\n\n        # Representative argument for this group. This is the one argument that contains scalar types\n        self.rep_arg = None\n\n        # The scalar type of an argument in this group must match the scalar type in the other group\n        self.group_matches = None\n        self.dense_matches = False\n        self.sparse_matches = False\n\n        self.id = -1  # Which is my index in the list of groups\n\n        # The NpeMetaArgumentGroup for which this argument belongs to\n        self.meta_group = None\n\n    def __repr__(self):\n        return str(self.__dict__)\n\n\nclass NpeMetaArgumentGroup(object):\n    def __init__(self, groups=None):\n        self.groups = groups if groups is not None else []\n        self.rep_group = None\n\n    def __repr__(self):\n        return str(self.__dict__)\n\n\nclass NpeFunction(object):\n    def __init__(self, file_reader):\n        self.name = """"  # The name of the function we are binding\n        self._argument_groups = []  # Set of allowed types for each group of variables\n        self._metagroups = []  # Groups of NpeArgumentGroups which must have matching dtypes\n        self._arguments = {}  # Dictionary mapping argument names to NpeArguments\n        self.source_code = """"  # The source code of the binding\n        self.preamble = """"  # The code that comes before npe_* statements\n        self._docstr = """"  # Function documentation\n\n        self._parse(file_reader)\n        self._validate()\n\n    @property\n    def arguments(self):\n        """"""\n        Iterate over the arguments and their meta data in the order they were passed in\n        :return: An iterator over (argument_name, argument_metadata)\n        """"""\n        for _, arg_meta in self._arguments.items():\n            yield arg_meta\n\n    def argument(self, argname):\n        return self._arguments[argname]\n\n    @property\n    def array_arguments(self):\n        for _, arg_meta in self._arguments.items():\n            if arg_meta.is_numpy_type:\n                yield arg_meta\n\n    @property\n    def num_arguments(self):\n        return len(self._arguments)\n\n    @property\n    def num_argument_groups(self):\n        return len(self._argument_groups)\n\n    @property\n    def has_array_arguments(self):\n        """"""\n        Returns true if any of the arguments are numpy or scipy types\n        :return: true if any of the input arguments are numpy or scipy types\n        """"""\n        has = False\n        for arg in self.arguments:\n            if is_numpy_type(arg.types[0]) or arg.is_matches:\n                has = True\n                break\n        return has\n\n    @property\n    def argument_groups(self):\n        return self._argument_groups\n\n    @property\n    def metagroups(self):\n        return self._metagroups\n\n    @property\n    def docstring(self):\n        return self._docstr\n\n    @staticmethod\n    def _parse_matches_statement(line, line_number, matches_token_=MATCHES_TOKEN):\n        """"""\n        Parse a matches(<type>) statement, returning the the type inside the parentheses\n        :param line: The current line being parsed\n        :param line_number: The number of the line in the file being parsed\n        :return: The name of the type inside the matches statement as a string\n        """"""\n\n        line = consume_token(line.strip(), matches_token_, line_number=line_number, case_sensitive=False)\n        line = consume_token(line.strip(), \'(\', line_number=line_number).strip()\n        if not line.endswith(\')\'):\n            raise ParseError(""Missing \')\' for %s() token at line %d"" % (matches_token_, line_number))\n\n        return line[:-1]\n\n    def _parse_arg_statement(self, line, line_number, is_default):\n        stmt_token = DEFAULT_ARG_TOKEN if is_default else ARG_TOKEN\n\n        tokens = tokenize_npe_line(stmt_token, line.strip(), line_number)\n\n        arg_name = tokens[0]\n        validate_identifier_name(arg_name)\n\n        arg_types = tokens[1:]\n        if len(arg_types) == 0:\n            raise ParseError(\'%s(""%s"") at line %d got no type arguments\' % (stmt_token, arg_name, line_number))\n\n        # We allow npe_default_arg(a, npe_matches(b))\n        # in which case we want to handle this as a normal matches statement and write out the default arg later\n        arg_value = arg_types.pop() if is_default else None\n        if arg_value is not None and arg_value.startswith(MATCHES_TOKEN):\n            self._parse_matches_statement(arg_value, line_number=line_number)\n            arg_types.append(arg_value)\n\n        arg = NpeArgument(name=arg_name,\n                          is_matches=False,\n                          types=arg_types,\n                          line_number=line_number,\n                          default_value=arg_value)\n\n        if len(arg_types) == 0:\n            # TODO: Pretty error message\n            raise ParseError(\'No types specified for argument %s (line %d)\' % (arg_name, line_number))\n        elif len(arg_types) > 1 or (len(arg_types) == 1 and is_numpy_type(arg_types[0])):\n            # We\'re binding a scipy dense or sparse array. Check that the types are valid.\n            for type_str in arg_types:\n                if not is_numpy_type(type_str):\n                    # TODO: Pretty error message\n                    raise ParseError(""Got invalid type, `%s` in %s() at line %d. ""\n                                     ""If multiple types are specified, they must be a valid Numpy or Scipy type. ""\n                                     ""i.e. one of %s"" % (type_str, stmt_token, line_number, NUMPY_ARRAY_TYPES))\n                arg.is_sparse = is_sparse_type(type_str)\n                arg.is_dense = is_dense_type(type_str)\n                assert arg.is_sparse != arg.is_dense\n        else:\n            assert len(arg_types) == 1  # Non NumPy/SciPy arguments can only have one type\n            sparse_or_dense_like = arg_types[0].startswith(SPARSE_MATCHES_TOKEN) or \\\n                                   arg_types[0].startswith(DENSE_MATCHES_TOKEN)\n            if arg_types[0].startswith(MATCHES_TOKEN) or sparse_or_dense_like:\n                arg.is_matches = True\n                arg.scalar_matches_only = sparse_or_dense_like\n\n                # If the type was enforcing a match on another type, then handle that case\n                matches_token = MATCHES_TOKEN\n                if arg_types[0].startswith(SPARSE_MATCHES_TOKEN):\n                    matches_token = SPARSE_MATCHES_TOKEN\n                    arg.dense_scalar_matches = False\n                    arg.is_dense = False\n                    arg.is_sparse = True\n                elif arg_types[0].startswith(DENSE_MATCHES_TOKEN):\n                    matches_token = DENSE_MATCHES_TOKEN\n                    arg.dense_scalar_matches = True\n                    arg.is_dense = True\n                    arg.is_sparse = False\n                arg.matches_name = self._parse_matches_statement(arg_types[0], line_number=line_number,\n                                                                 matches_token_=matches_token)\n            else:\n                # TODO: Check that type requested is valid? - I\'m not sure if we can really do this though.\n                pass\n\n        self._arguments[arg_name] = arg\n\n        return arg_name, arg_types, arg_value\n\n    def _parse_doc_statement(self, line, line_number, skip):\n        if not skip:\n            return\n\n        tokens = tokenize_npe_line(DOC_TOKEN, line, line_number)\n\n        if len(tokens) == 0:\n            raise ParseError(""Got %s statement at line %d but no documentation string."" % (DOC_TOKEN, line_number))\n\n        if len(tokens) > 1:\n            raise ParseError(""Got more than one documentation token at in %s statement at line %d. ""\n                             ""Did you forget quotes around the docstring?"" % (DOC_TOKEN, line_number))\n\n        self._docstr = tokens[0]\n\n        log(LOG_INFO_VERBOSE,\n            TermColors.OKGREEN + ""NumpyEigen Docstring - %s"" % self._docstr)\n\n    @staticmethod\n    def _parse_npe_function_statement(line, line_number):\n        tokens = tokenize_npe_line(FUNCTION_TOKEN, line, line_number)\n        if len(tokens) > 1:\n            raise ParseError(FUNCTION_TOKEN + "" got extra tokens, %s, at line %d. ""\n                                              ""Expected only the name of the function."" %\n                             (tokens[1, :], line_number))\n        binding_name = tokens[0]\n        validate_identifier_name(binding_name)\n\n        return binding_name\n\n    @staticmethod\n    def _parse_begin_code_statement(line, line_number):\n        line = consume_token(line.strip(), BEGIN_CODE_TOKEN, line_number=line_number, case_sensitive=False)\n        line = consume_token(line.strip(), \'(\', line_number=line_number)\n        line = consume_token(line.strip(), \')\', line_number=line_number)\n        consume_eol(line.strip(), line_number=line_number)\n\n    @staticmethod\n    def _parse_end_code_statement(line, line_number):\n        line = consume_token(line.strip(), END_CODE_TOKEN, line_number=line_number, case_sensitive=False)\n        line = consume_token(line.strip(), \'(\', line_number=line_number)\n        line = consume_token(line.strip(), \')\', line_number=line_number)\n        consume_eol(line.strip(), line_number=line_number)\n\n    def _parse(self, file_reader):\n        line = file_reader.readline()\n        if consume_call_statement(FUNCTION_TOKEN, line, line_number=file_reader.line_number, throw=False):\n            self.name = self._parse_npe_function_statement(line, line_number=file_reader.line_number)\n        else:\n            raise RuntimeError(""This should never happen but clearly it did. ""\n                               ""File a github issue at https://github.com/fwilliams/numpyeigen"")\n\n        log(LOG_INFO_VERBOSE, TermColors.OKGREEN + ""NumpyEigen Function: "" + TermColors.ENDC + self.name)\n\n        found_begin_code_statement = False\n\n        parsing_doc = False\n        doc_lines = """"\n        for line in file_reader:\n            if consume_call_statement(ARG_TOKEN, line, line_number=file_reader.line_number, throw=False):\n                var_name, var_types, _ = self._parse_arg_statement(line, line_number=file_reader.line_number,\n                                                                   is_default=False)\n                log(LOG_INFO_VERBOSE,\n                    TermColors.OKGREEN + ""NumpyEigen Arg: "" + TermColors.ENDC + var_name + "" - "" + str(var_types))\n\n                self._parse_doc_statement(doc_lines, line_number=file_reader.line_number, skip=parsing_doc)\n                parsing_doc = False\n            elif consume_call_statement(DEFAULT_ARG_TOKEN, line, line_number=file_reader.line_number, throw=False):\n                var_name, var_types, var_value = \\\n                    self._parse_arg_statement(line, line_number=file_reader.line_number, is_default=True)\n                log(LOG_INFO_VERBOSE,\n                    TermColors.OKGREEN + ""NumpyEigen Default Arg: "" + TermColors.ENDC + var_name + "" - "" +\n                    str(var_types) + "" - "" + str(var_value))\n\n                # If we were parsing a multiline npe_doc, we\'ve now reached the end so parse the whole statement\n                self._parse_doc_statement(doc_lines, line_number=file_reader.line_number, skip=parsing_doc)\n                parsing_doc = False\n\n            elif consume_call_statement(DOC_TOKEN, line, line_number=file_reader.line_number, throw=False):\n                if self._docstr != """":\n                    raise ParseError(\n                        ""Multiple `%s` statements for one function at line %d.""\n                        % (DOC_TOKEN, file_reader.line_number))\n\n                doc_lines += line\n                parsing_doc = True\n\n            elif consume_call_statement(BEGIN_CODE_TOKEN, line, line_number=file_reader.line_number, throw=False):\n                self._parse_begin_code_statement(line, line_number=file_reader.line_number)\n                found_begin_code_statement = True\n\n                # If we were parsing a multiline npe_doc, we\'ve now reached the end so parse the whole statement\n                self._parse_doc_statement(doc_lines, line_number=file_reader.line_number, skip=parsing_doc)\n                break\n\n            elif parsing_doc:\n                # If we\'re parsing a multiline doc string, accumulate the line\n                doc_lines += line\n                continue\n\n            elif len(line.strip()) == 0:\n                # Ignore newlines and whitespace\n                continue\n\n            elif line.strip().lower().startswith(COMMENT_TOKEN):\n                # Ignore commented lines\n                continue\n\n            else:\n                raise ParseError(""Unexpected tokens at line %d: %s"" % (file_reader.line_number, line))\n\n        if not found_begin_code_statement:\n            raise ParseError(""Invalid binding file. Must does not contain a %s() statement."" % BEGIN_CODE_TOKEN)\n\n        reached_end_token = False\n        for line in file_reader:\n            if consume_call_statement(END_CODE_TOKEN, line, line_number=file_reader.line_number, throw=False):\n                self._parse_end_code_statement(line, line_number=file_reader.line_number)\n                reached_end_token = True\n                break\n            elif not reached_end_token:\n                self.source_code += line\n\n        if not reached_end_token:\n            raise ParseError(""Unexpected EOF. Binding file must end with a %s() statement."" % END_CODE_TOKEN)\n\n    def _validate(self):\n        for arg in self.arguments:\n            if arg.is_numpy_type:\n                if arg.is_matches:  # Argument type is a matches constraint of some kind\n                    # Check that the matched argument exists\n                    if arg.matches_name not in self._arguments:\n                        raise SemanticError(""Argument %s is declared with npe_matches(%s) (line %d) but %s is not an ""\n                                            ""argument to the function."" %\n                                            (arg.name, arg.matches_name, arg.line_number, arg.matches_name))\n                    # Check that the matched argument is a Numpy or Scipy type\n                    matched_arg = self._arguments[arg.matches_name]\n                    if not matched_arg.is_numpy_type:\n                        raise SemanticError(""Argument %s is declared with npe_matches(%s) (line %d) but %s is not a ""\n                                            ""Numpy or Scipy argument argument."" %\n                                            (arg.name, arg.matches_name, arg.line_number, arg.matches_name))\n\n                    # Handle npe_matches, npe_sparse/dense_like constraints\n                    if not arg.scalar_matches_only:  # Hard matches another argument\n                        # Merge the two arguments into an argument group\n                        if matched_arg.group is None:\n                            grp = NpeArgumentGroup()\n                            self._argument_groups.append(grp)\n                            grp.id = len(self._argument_groups) - 1\n                            matched_arg.group = grp\n\n                        arg.group = matched_arg.group\n                    else:  # Dtype matches another argument\n                        # Put arguments into seperate groups, and enforce that the dtypes of these groups need to match\n                        if arg.group is None:\n                            grp = NpeArgumentGroup()\n                            self._argument_groups.append(grp)\n                            grp.id = len(self._argument_groups) - 1\n                            arg.group = grp\n                        if matched_arg.group is None:\n                            grp = NpeArgumentGroup()\n                            self._argument_groups.append(grp)\n                            grp.id = len(self._argument_groups) - 1\n                            matched_arg.group = grp\n\n                        # Add constraint that dtypes of both groups need to match\n                        arg.group.group_matches = matched_arg.group\n                        arg.group.dense_matches = arg.dense_scalar_matches\n                        arg.group.sparse_matches = not arg.group.dense_matches\n\n                        # The argument which has the dense_like or sparse_like is the representative of this group\n                        assert arg.group.rep_arg is None, \\\n                            ""There should never be another representative argument when assigning one.""\n                        arg.group.rep_arg = arg\n\n                else:  # Argument type is not a matches constraint\n                    # Determine if a Numpy/Scipy argument is sparse or dense and check that the user did not\n                    # mix sparse and dense types\n                    is_sparse = is_sparse_type(arg.types[0])\n                    is_dense = is_dense_type(arg.types[0])\n                    for type_name in arg.types:\n                        if is_sparse_type(type_name) != is_sparse or is_dense_type(type_name) != is_dense:\n                            raise SemanticError(\n                                ""Argument %s (line %d) is declared with a mix of sparse and dense types.""\n                                % (arg.name, arg.line_number))\n\n                    # Make a new group and put the argument into it\n                    if arg.group is None:\n                        grp = NpeArgumentGroup()\n                        self._argument_groups.append(grp)\n                        grp.id = len(self._argument_groups) - 1\n                        arg.group = grp\n                    assert arg.group is not None\n                    assert len(arg.group.types) == 0\n                    assert arg.is_dense != arg.is_sparse\n                    assert arg.group.rep_arg is None, \\\n                        ""There should never be another representative argument when assigning one.""\n                    # The argument which has the list of types is the representative of this group\n                    arg.group.rep_arg = arg\n                    arg.group.types = arg.types\n\n                # Add the argument to its group\n                arg.group.arguments.append(arg)\n\n        # Create meta groups for matching arguments\n        for grp in self._argument_groups:\n            assert grp.rep_arg is not None\n            assert grp.rep_arg.is_sparse != grp.rep_arg.is_dense\n            for arg in grp.arguments:\n                arg.is_dense = grp.rep_arg.is_dense\n                arg.is_sparse = grp.rep_arg.is_sparse\n\n            if grp.group_matches is not None:  # This group has a scalar matches constraint to another group\n                # Create a MetaGroup containing the two ArgumentGroups\n                other_grp = grp.group_matches\n\n                if other_grp.meta_group is None:\n                    other_grp.meta_group = NpeMetaArgumentGroup()\n                    other_grp.meta_group.groups.append(other_grp)\n                    self._metagroups.append(other_grp.meta_group)\n\n                other_grp.meta_group.groups.append(grp)\n                grp.meta_group = other_grp.meta_group\n            else:  # This group does not have a scalar matches constraint\n                # Create MetaGroup contining only this ArgumentGroup\n                if grp.meta_group is None:\n                    grp.meta_group = NpeMetaArgumentGroup()\n                    grp.meta_group.groups.append(grp)\n                    self._metagroups.append(grp.meta_group)\n\n            assert grp.meta_group is not None\n\n            # One group in a MetaGroup is a representative. It contains a list of types.\n            # It should be impossible for there to be more than one such group.\n            if len(grp.types) > 0:\n                assert grp.meta_group.rep_group is None, \\\n                    ""There can only be one representative group in a meta group. This should never happen!""\n                grp.meta_group.rep_group = grp\n\n        for smg in self._metagroups:\n            # scalar_matches cycle\n            if smg.rep_group is None:\n                cycle_args = "", "".join([grp.rep_arg.name for grp in smg.groups])\n                raise SemanticError(""The types for arguments %s all reference each other forming a cycle."" % cycle_args)\n\n            # Resolve types in each group\n            for grp in smg.groups:\n                if grp != smg.rep_group:\n                    assert grp.meta_group is not None\n                    assert grp.dense_matches != grp.sparse_matches\n                    if grp.dense_matches:\n                        grp.types = [t.replace(""sparse_"", ""dense_"") for t in smg.rep_group.types]\n                    elif grp.sparse_matches:\n                        grp.types = [t.replace(""dense_"", ""sparse_"") for t in smg.rep_group.types]\n\n        # Resolve types of all arguments\n        for grp in self._argument_groups:\n            assert len(grp.arguments) != 0\n\n            # Check that every argument group contains types\n            # i.e. no circular npe_matches() arguments\n            if len(grp.types) == 0:\n                cycle_args = "", "".join([arg.name for arg in grp.arguments])\n                raise SemanticError(""The types for arguments %s all reference each other forming a npe_matches cycle."" % cycle_args)\n\n            # Paranoid double check that all arguments in a group are uniquely sparse or uniquely dense\n            # We validate this condition already at parse time so this is an assert\n            dense_group = grp.arguments[0].is_dense\n            sparse_group = grp.arguments[0].is_sparse\n            for arg in grp.arguments:\n                # We validate this condition already at parse time so this is an assert\n                assert arg.is_dense == dense_group and arg.is_sparse == sparse_group, \\\n                    ""Argument group contains a mix of dense and sparse types. This should never happen!""\n                assert arg.is_dense != arg.is_sparse, ""An argument is somehow dense and sparse simultaneously. "" \\\n                                                      ""This should never happen!""\n\n        # If verbose printing is on, dump all the metadata about this function\n        if verbosity_level >= LOG_INFO_VERBOSE:\n            logstr = TermColors.OKGREEN + ""NumpyEigen Function Metadata:\\n"" + TermColors.ENDC\n            logstr += TermColors.OKGREEN + "" Arguments: "" + TermColors.ENDC + ""%s\\n"" % [a.name for a in self.arguments]\n            logstr += TermColors.OKGREEN + "" Groups:\\n"" + TermColors.ENDC\n            for idx, grp in enumerate(self._argument_groups):\n                grpargs = [a.name for a in grp.arguments]\n                logstr += ""  %d: %s\\n"" % (idx, str(grpargs))\n            logstr += TermColors.OKGREEN + "" MetaGroups:\\n"" + TermColors.ENDC\n            for metagrp in self._metagroups:\n                logstr += ""  %s\\n"" % str([g.id for g in metagrp.groups])\n            log(LOG_INFO_VERBOSE, logstr)\n\n\nclass NpeAST(object):\n    def __init__(self, file_reader):\n        self.input_file_name = file_reader.file_name\n        self.children = []\n        self._parse(file_reader)\n\n    def _parse(self, file_reader):\n\n        _preamble = """"\n        while True:\n            line = file_reader.peekline()\n            if len(line) == 0:\n                file_reader.readline()\n                break\n\n            if len(line.strip()) == 0:\n                _preamble += file_reader.readline()\n                continue\n            elif consume_call_statement(ARG_TOKEN, line, line_number=file_reader.line_number + 1, throw=False):\n                raise ParseError(""Got unexpected `%s`  at line %d"" %\n                                 (ARG_TOKEN, file_reader.line_number + 1))\n            elif consume_call_statement(DEFAULT_ARG_TOKEN, line, line_number=file_reader.line_number + 1, throw=False):\n                raise ParseError(""Got unexpected `%s`  at line %d"" %\n                                 (DEFAULT_ARG_TOKEN, file_reader.line_number + 1))\n            elif consume_call_statement(BEGIN_CODE_TOKEN, line, line_number=file_reader.line_number + 1, throw=False):\n                raise ParseError(""Got unexpected `%s`  at line %d"" %\n                                 (BEGIN_CODE_TOKEN, file_reader.line_number + 1))\n            elif consume_call_statement(END_CODE_TOKEN, line, line_number=file_reader.line_number + 1, throw=False):\n                raise ParseError(""Got unexpected `%s`  at line %d"" %\n                                 (END_CODE_TOKEN, file_reader.line_number + 1))\n            elif consume_call_statement(DOC_TOKEN, line, line_number=file_reader.line_number + 1, throw=False):\n                raise ParseError(""Got unexpected `%s`  at line %d"" %\n                                 (DOC_TOKEN, file_reader.line_number + 1))\n            elif consume_call_statement(FUNCTION_TOKEN, line, line_number=file_reader.line_number + 1, throw=False):\n                self.children.append(NpeFunction(file_reader))\n                assert len(self.children[-1].preamble) == 0\n                self.children[-1].preamble = _preamble\n                _preamble = """"\n            else:\n                _preamble += file_reader.readline()\n\n\ndef codegen_ast(ast, out_file, write_debug_prints=True):\n    PRIVATE_ID_PREFIX = ""_NPE_PY_BINDING_""\n    PRIVATE_NAMESPACE = ""npe::detail""\n    STORAGE_ORDER_ENUM = ""StorageOrder""\n    ALIGNED_ENUM = ""Alignment""\n    TYPE_ID_ENUM = ""TypeId""\n    TYPE_CHAR_ENUM = ""NumpyTypeChar""\n    STORAGE_ORDER_SUFFIXES = [\'_cm\', \'_rm\', \'_x\']\n    STORAGE_ORDER_SUFFIX_CM = STORAGE_ORDER_SUFFIXES[0]\n    STORAGE_ORDER_SUFFIX_RM = STORAGE_ORDER_SUFFIXES[1]\n    STORAGE_ORDER_SUFFIX_XM = STORAGE_ORDER_SUFFIXES[2]\n    STORAGE_ORDER_CM = ""ColMajor""\n    STORAGE_ORDER_RM = ""RowMajor""\n    STORAGE_ORDER_XM = ""NoOrder""\n    MAP_TYPE_PREFIX = ""npe_Map_""\n    MATRIX_TYPE_PREFIX = ""npe_Matrix_""\n    SCALAR_TYPE_PREFIX = ""npe_Scalar_""\n\n    def cast_arg(var):\n        if var.is_dense:\n            return ""static_cast<pybind11::array&>(%s)"" % var.name\n        elif var.is_sparse:\n            return ""static_cast<npe::sparse_array&>(%s)"" % var.name\n        else:\n            raise AssertionError(""This should never happen!"")\n\n    def type_name_var(var_name):\n        return PRIVATE_ID_PREFIX + var_name + ""_type_s""\n\n    def storage_order_var(var_name):\n        return PRIVATE_ID_PREFIX + var_name + ""_so""\n\n    def type_id_var(var_name):\n        return PRIVATE_ID_PREFIX + var_name + ""_t_id""\n\n    def storage_order_for_suffix(suffix):\n        if suffix == STORAGE_ORDER_SUFFIX_CM:\n            return PRIVATE_NAMESPACE + ""::"" + STORAGE_ORDER_ENUM + ""::"" + STORAGE_ORDER_CM\n        elif suffix == STORAGE_ORDER_SUFFIX_RM:\n            return PRIVATE_NAMESPACE + ""::"" + STORAGE_ORDER_ENUM + ""::"" + STORAGE_ORDER_RM\n        elif suffix == STORAGE_ORDER_SUFFIX_XM:\n            return PRIVATE_NAMESPACE + ""::"" + STORAGE_ORDER_ENUM + ""::"" + STORAGE_ORDER_XM\n        else:\n            assert False, ""major wtf""\n\n    def aligned_enum_for_suffix(suffix):\n        if suffix == STORAGE_ORDER_SUFFIX_CM or suffix == STORAGE_ORDER_SUFFIX_RM:\n            return PRIVATE_NAMESPACE + ""::"" + ALIGNED_ENUM + ""::"" + ""Aligned""\n        elif suffix == STORAGE_ORDER_SUFFIX_XM:\n            return PRIVATE_NAMESPACE + ""::"" + ALIGNED_ENUM + ""::"" + ""Unaligned""\n        else:\n            assert False, ""major wtf""\n\n    def type_char_for_numpy_type(np_type):\n        return PRIVATE_NAMESPACE + ""::"" + TYPE_CHAR_ENUM + ""::char_"" + NUMPY_ARRAY_TYPES_TO_CPP[np_type][1]\n\n    def write_flags_getter(arg):\n        storage_order_var_name = storage_order_var(arg.name)\n        row_major = PRIVATE_NAMESPACE + ""::RowMajor""\n        col_major = PRIVATE_NAMESPACE + ""::ColMajor""\n        no_order = PRIVATE_NAMESPACE + ""::NoOrder""\n        out_str = ""const "" + PRIVATE_NAMESPACE + ""::"" + STORAGE_ORDER_ENUM + "" "" + storage_order_var_name + "" = ""\n        out_str += ""("" + cast_arg(arg) + "".flags() & NPY_ARRAY_F_CONTIGUOUS) ? "" + col_major + "" : ""\n        out_str += ""("" + cast_arg(arg) + "".flags() & NPY_ARRAY_C_CONTIGUOUS ? "" + row_major + "" : "" + no_order + "");\\n""\n        out_file.write(out_str)\n\n    def write_type_id_getter(arg):\n        out_str = ""const int "" + type_id_var(arg.name) + "" = ""\n        type_name = type_name_var(arg.name)\n        storage_order_name = storage_order_var(arg.name)\n        is_sparse = PRIVATE_NAMESPACE + ""::is_sparse<std::remove_reference<decltype("" + \\\n                    cast_arg(arg) + "")>::type>::value""\n        out_str += PRIVATE_NAMESPACE + ""::get_type_id("" + is_sparse + "", "" + type_name + "", "" + \\\n                   storage_order_name + "");\\n""\n        out_file.write(out_str)\n\n    def write_function_switch_header(fun):\n        out_file.write(\'""%s""\' % fun.name)\n        out_file.write("", []("")\n\n        # Write the argument list\n        i = 0\n        for arg in fun.arguments:\n            prefix = ""npe::detail::maybe_none<"" if arg.is_nullable else """"\n            suffix = ""> "" if arg.is_nullable else "" ""\n\n            if arg.is_sparse:\n                out_file.write(prefix + ""npe::sparse_array"" + suffix)\n                out_file.write(arg.name)\n            elif arg.is_dense:\n                out_file.write(prefix + ""pybind11::array"" + suffix)\n                out_file.write(arg.name)\n            else:\n                # Non Numpy/Scipy arguments only have one type\n                assert len(arg.types) == 1, ""More than one type %s"" % str(arg.types)\n                var_type = arg.types[0]\n                out_file.write(var_type + "" "")\n                out_file.write(arg.name)\n            next_token = "", "" if i < fun.num_arguments - 1 else "") {\\n""\n            out_file.write(next_token)\n            i += 1\n\n        if fun.num_arguments == 0:\n            out_file.write("") {\\n"")\n\n        out_file.write(""#ifdef __NPE_REDIRECT_IO__\\n"")\n        out_file.write(\'pybind11::scoped_ostream_redirect __npe_redirect_stdout__(std::cout, \'\n                       \'pybind11::module::import(""sys"").attr(""stdout""));\\n\')\n        out_file.write(\'pybind11::scoped_ostream_redirect __npe_redirect_stderr__(std::cerr, \'\n                       \'pybind11::module::import(""sys"").attr(""stderr""));\\n\')\n        out_file.write(""#endif\\n"")\n\n        if write_debug_prints:\n            out_file.write(\'std::cout << ""Invocation of %s"" << std::endl;\\n\' % fun.name)\n\n        # Declare variables used to determine the type at runtime\n        for arg in fun.array_arguments:\n            # A character representing the dtype of the argument\n            out_file.write(""const char %s = %s::transform_typechar(%s.dtype().type());\\n"" %\n                           (type_name_var(arg.name), PRIVATE_NAMESPACE, cast_arg(arg)))\n\n            # Check that the shape of the argument has length one or 2\n            out_file.write(""ssize_t %s_shape_0 = 0;\\n"" % arg.name)\n            out_file.write(""ssize_t %s_shape_1 = 0;\\n"" % arg.name)\n            out_file.write(""if (%s.ndim() == 1) {\\n"" % cast_arg(arg))\n            out_file.write(""%s_shape_0 = %s.shape()[0];\\n"" % (arg.name, cast_arg(arg)))\n            out_file.write(""%s_shape_1 = %s.shape()[0] == 0 ? 0 : 1;\\n"" % (arg.name, cast_arg(arg)))\n            out_file.write(""} else if (%s.ndim() == 2) {\\n"" % cast_arg(arg))\n            out_file.write(""%s_shape_0 = %s.shape()[0];\\n"" % (arg.name, cast_arg(arg)))\n            out_file.write(""%s_shape_1 = %s.shape()[1];\\n"" % (arg.name, cast_arg(arg)))\n            out_file.write(""} else if (%s.ndim() > 2) {\\n"" % cast_arg(arg))\n            out_file.write(""throw std::invalid_argument(\\""Argument "" + arg.name +\n                           "" has invalid number of dimensions. Must be 1 or 2.\\"");\\n"")\n            out_file.write(""}\\n"")\n\n            # Declare variables representing the storage order and an integer ID representing the combination of\n            # scalar type (dtype) and storage order of the argument\n            write_flags_getter(arg)\n            write_type_id_getter(arg)\n\n            if write_debug_prints:\n                out_file.write(\'std::cout << ""- Argument: %s"" << std::endl;\\n\' % arg.name)\n                out_file.write(\'std::cout << ""   - shape: ("" << %s << "", "" << %s << "")"" << std::endl;\\n\' %\n                               (str(arg.name + ""_shape_0""), str(arg.name + ""_shape_1"")))\n\n                storage_order_var_name = storage_order_var(arg.name)\n                out_file.write(\'std::cout << ""   - "" << %s::storage_order_to_str(%s) << std::endl;\\n\' %\n                               (PRIVATE_NAMESPACE, storage_order_var_name))\n\n                type_name = type_name_var(arg.name)\n                out_file.write(\'std::cout << ""   - type char: "" << %s << std::endl;\\n\' % type_name)\n                out_file.write(\'std::cout << ""   - type name: "" << %s::type_to_str(%s) << std::endl;\\n\' %\n                               (PRIVATE_NAMESPACE, type_name))\n\n        if write_debug_prints:\n            out_file.write(\'std::cout << ""-------------------------------------------------------"" << std::endl;\\n\')\n\n        # Ensure the types in each group match\n        first_non_nullables = []\n\n        for grp in fun.argument_groups:\n            # At least one argument must be non-nullable, find this argument and use it as a reprensentative to\n            # compare the types of all arguments in a group to\n            first_non_nullable = None\n            for arg in grp.arguments:\n                if not arg.is_nullable:\n                    first_non_nullable = arg\n                    break\n            assert first_non_nullable is not None, ""What in the actual fuck?""\n            first_non_nullables.append(first_non_nullable)\n\n            # TODO: Pretty error message highlighting exactly which arguments mismatch\n            # Compare the type of the representative to every valid type in the group and raise an exception if there\n            # is a mismatch\n            out_str = ""if (""\n            for i in range(len(grp.types)):\n                type_name = grp.types[i]\n                out_str += type_name_var(first_non_nullable.name) + ""!= "" + \\\n                           PRIVATE_NAMESPACE + ""::transform_typechar( "" + type_char_for_numpy_type(type_name) + "")""\n                next_token = "" && "" if i < len(grp.types) - 1 else "") {\\n""\n                out_str += next_token\n            pretty_group_types = [NUMPY_ARRAY_TYPES_TO_CPP[gt][2] for gt in grp.types]\n            out_str += \'std::string err_msg = std::string(""Invalid scalar type ("") + \' \\\n                       \'%s::type_to_str(%s) + "", "" + %s::storage_order_to_str(%s) + \' \\\n                       \'std::string("") for argument \\\'%s\\\'. Expected one of %s."");\\n\' % \\\n                       (PRIVATE_NAMESPACE, type_name_var(first_non_nullable.name),\n                        PRIVATE_NAMESPACE, storage_order_var(first_non_nullable.name),\n                        first_non_nullable.name, pretty_group_types)\n            out_str += \'throw std::invalid_argument(err_msg);\\n\'\n            out_str += ""}\\n""\n            out_file.write(out_str)\n\n            # If there is only one argument to check, then don\'t generate any extra checks\n            assert len(grp.arguments) >= 1\n            if len(grp.arguments) == 1:\n                continue\n\n            # Now, check that the dtype and storage order of every argument in the group matches the type of the\n            # representative.\n            # If one of the arguments is a vector or a zero sized array, then automatically coalesce it to the right\n            # storage order\n            out_file.write(""{\\n"")\n            out_file.write(""int group_matched_type_id = %s;\\n"" % type_id_var(first_non_nullable.name))\n            out_file.write(""bool found_non_1d = ""\n                           ""(%s_shape_0 != 1 && %s_shape_1 != 1 && %s_shape_0 != 0 && %s_shape_1 != 0);\\n"" %\n                           (first_non_nullable.name, first_non_nullable.name,\n                            first_non_nullable.name, first_non_nullable.name))\n            out_file.write(\'std::string match_to_name = ""%s"";\\n\' % first_non_nullable.name)\n            out_file.write(\'%s::StorageOrder match_so = %s;\\n\' %\n                           (PRIVATE_NAMESPACE, storage_order_var(first_non_nullable.name)))\n            out_file.write(""char group_type_s = %s;\\n"" % type_name_var(first_non_nullable.name))\n\n            for arg in grp.arguments:\n                exception_str1 = \'std::string err_msg = std::string(""Invalid type ("") + \' \\\n                                 \'%s::type_to_str(%s) + "", "" + %s::storage_order_to_str(%s) + \' \\\n                                 \'std::string("") for argument \\\'%s\\\'. Expected it to match argument \\\'"") + \' \\\n                                 \'match_to_name + std::string(""\\\' which is of type ("") + \' \\\n                                 \'%s::type_to_str(group_type_s) + "", "" + %s::storage_order_to_str(match_so) + \' \\\n                                 \'std::string("")."");\\n\' \\\n                                 % (PRIVATE_NAMESPACE, type_name_var(arg.name),\n                                    PRIVATE_NAMESPACE, storage_order_var(arg.name),\n                                    arg.name, PRIVATE_NAMESPACE, PRIVATE_NAMESPACE) + \\\n                                 \'throw std::invalid_argument(err_msg);\\n\'\n                exception_str2 = \'std::string err_msg = std::string(""Invalid type ("") + \' \\\n                                 \'%s::type_to_str(%s) + "", "" + %s::storage_order_to_str(match_so) + \' \\\n                                 \'std::string("") for argument \\\'%s\\\'. Expected it to match argument \\\'"") + \' \\\n                                 \'match_to_name + std::string(""\\\' which is of type ("") + \' \\\n                                 \'%s::type_to_str(group_type_s) + "", "" +  %s::storage_order_to_str(match_so) + \' \\\n                                 \'std::string("")."");\\n\' \\\n                                 % (PRIVATE_NAMESPACE, type_name_var(arg.name),\n                                    PRIVATE_NAMESPACE, arg.name, PRIVATE_NAMESPACE, PRIVATE_NAMESPACE) + \\\n                                 \'throw std::invalid_argument(err_msg);\\n\'\n                out_str = ""if (!"" + arg.name + "".is_none) {\\n"" if arg.is_nullable else """"\n                out_str += ""if ("" + str(arg.name + ""_shape_0"") + "" != 1 && "" + \\\n                           str(arg.name + ""_shape_1"") + "" != 1 && "" + \\\n                           str(arg.name + ""_shape_0"") + "" != 0 && "" + \\\n                           str(arg.name + ""_shape_1"") + "" != 0) {\\n""\n                out_str += ""if (!found_non_1d) {\\n"" + \\\n                           ""group_matched_type_id = "" + type_id_var(arg.name) + "";\\n"" + \\\n                           ""found_non_1d = true;\\n"" + \\\n                           \'match_to_name = ""\' + arg.name + \'"";\\n\' + \\\n                           ""match_so = "" + storage_order_var(arg.name) + "";\\n"" + \\\n                           ""group_type_s = "" + type_name_var(arg.name) + "";\\n"" + \\\n                           ""\\n}\\n""\n                out_str += ""if ("" + type_id_var(arg.name) + "" != group_matched_type_id) {\\n""\n                out_str += exception_str1\n                out_str += ""}\\n""\n                out_str += ""} else if (group_type_s != %s) {\\n"" % type_name_var(arg.name)\n                out_str += exception_str2\n                out_str += ""}\\n""\n                out_str += ""}\\n"" if arg.is_nullable else """"\n                out_file.write(out_str)\n            out_file.write(""}\\n"")\n\n        # Now check that each metagroup have matching dtypes\n        for metagrp in fun.metagroups:\n            rep_arg = first_non_nullables[metagrp.rep_group.id]\n            for grp in metagrp.groups:\n                if grp == rep_arg.group:\n                    continue\n\n                arg = first_non_nullables[grp.id]\n                exception_str = \'std::string err_msg = std::string(""Invalid dtype `"") + \' \\\n                                \'%s::type_to_str(%s) + \' \'std::string(""` for argument \\\'%s\\\'. \' \\\n                                \'Expected it to match argument "") + \' \\\n                                \'""\\\'%s\\\'"" + std::string("" which has dtype `"") + \' \\\n                                \'%s::type_to_str(%s) + \' \\\n                                \'std::string(""`."");\\n\' \\\n                                % (PRIVATE_NAMESPACE, type_name_var(arg.name), arg.name, rep_arg.name,\n                                   PRIVATE_NAMESPACE, type_name_var(rep_arg.name)) + \\\n                                \'throw std::invalid_argument(err_msg);\\n\'\n\n                out_str = ""if (!"" + arg.name + "".is_none) {\\n"" if arg.is_nullable else """"\n                out_str += ""if("" + type_name_var(arg.name) + "" != "" + type_name_var(rep_arg.name) + "") {\\n""\n                out_str += exception_str\n                out_str += ""}\\n""\n                out_str += ""}\\n"" if arg.is_nullable else """"\n                out_file.write(out_str)\n\n    def write_function_switch_body(fun):\n        # At this stage in execution, we\'re guaranteed that every argument in a group has exactly the same type\n        # and that any arguments in the same metagroup have exactly the same dtype\n        expanded_type_groups = [itertools.product(group.types, STORAGE_ORDER_SUFFIXES) for group in fun.argument_groups]\n        group_combos = itertools.product(*expanded_type_groups)\n        branch_count = 0\n\n        if fun.has_array_arguments:\n            for combo in group_combos:\n                if_or_elseif = ""if "" if branch_count == 0 else "" else if ""\n                if platform.system() == ""Windows"":  # Windows has a branch limit so we don\'t use else if\n                    if_or_elseif = ""if""\n\n                out_str = if_or_elseif + ""(""\n                skip = False\n                for group_id in range(len(combo)):\n                    # Sparse types only have column (csc) and row (csr) matrix types,\n                    #  so don\'t output a branch for unaligned\n                    if is_sparse_type(combo[group_id][0]) and combo[group_id][1] == STORAGE_ORDER_SUFFIX_XM:\n                        skip = True\n                        break\n                    repr_var = fun.argument_groups[group_id].arguments[0]\n                    typename = combo[group_id][0] + combo[group_id][1]\n                    out_str += type_id_var(repr_var.name) + "" == "" + PRIVATE_NAMESPACE + ""::transform_typeid("" + \\\n                               PRIVATE_NAMESPACE + ""::"" + TYPE_ID_ENUM + ""::"" + typename + "")""\n                    next_token = "" && "" if group_id < len(combo) - 1 else "")""\n                    out_str += next_token\n\n                def dtype_from_type(type_):\n                    return type_.replace(""dense_"", """").replace(""sparse_"", """")\n\n                for metagrp in fun.metagroups:\n                    rep_dtype = dtype_from_type(combo[metagrp.groups[0].id][0])\n                    for grp in metagrp.groups:\n                        grp_dtype = dtype_from_type(combo[grp.id][0])\n                        if grp_dtype != rep_dtype:\n                            skip = True\n                            break\n                    else:\n                        continue\n                    break\n\n                if skip:\n                    continue\n\n                out_str += "" {\\n""\n                out_file.write(out_str)\n                write_switch_branch(fun, combo)\n                out_file.write(""}"")\n                branch_count += 1\n\n            throw_err = \'throw std::invalid_argument(""This should never happen but clearly it did. \' \\\n                        \'File a github issue at https://github.com/fwilliams/numpyeigen"");\\n\'\n            if platform.system() != ""Windows"":  # Windows has a branch limit so we don\'t do else if\n                out_file.write("" else {\\n"")\n                out_file.write(throw_err)\n                out_file.write(""}\\n"")\n            else:\n                out_file.write(throw_err)\n        else:\n            group_combos = list(group_combos)\n            assert len(group_combos) == 1, ""This should never happen but clearly it did. "" \\\n                                           ""File a github issue at https://github.com/fwilliams/numpyeigen""\n            for _ in group_combos:\n                out_file.write(""{\\n"")\n                out_file.write(fun.source_code + ""\\n"")\n                out_file.write(""}\\n"")\n        out_file.write(""\\n"")\n        out_file.write(""}"")\n\n    def write_switch_branch(fun, combo):\n        out_file.write(""{\\n"")\n        for group_id in range(len(combo)):\n            type_prefix = combo[group_id][0]\n            type_suffix = combo[group_id][1]\n            for arg in fun.argument_groups[group_id].arguments:\n                cpp_type = NUMPY_ARRAY_TYPES_TO_CPP[type_prefix][0]\n                storage_order_enum = storage_order_for_suffix(type_suffix)\n                aligned_enum = aligned_enum_for_suffix(type_suffix)\n\n                out_file.write(""typedef "" + cpp_type + "" Scalar_"" + arg.name + "";\\n"")\n                if is_sparse_type(combo[group_id][0]):\n                    eigen_type = ""Eigen::SparseMatrix<"" + cpp_type + "", "" + \\\n                                 storage_order_enum + "", int>""\n                    out_file.write(""typedef "" + eigen_type + "" Matrix_%s"" % arg.name + "";\\n"")\n                    out_file.write(""#if EIGEN_WORLD_VERSION == 3 && EIGEN_MAJOR_VERSION <= 2\\n"")\n                    out_file.write(""typedef Eigen::MappedSparseMatrix<"" + cpp_type + "", "" +\n                                   storage_order_enum + "", int> Map_"" + arg.name + "";\\n"")\n                    out_file.write(""#elif (EIGEN_WORLD_VERSION == 3 && ""\n                                   ""EIGEN_MAJOR_VERSION > 2) || (EIGEN_WORLD_VERSION > 3)\\n"")\n                    out_file.write(""typedef Eigen::Map<Matrix_"" + arg.name + ""> Map_"" + arg.name + "";\\n"")\n                    out_file.write(""#endif\\n"")\n\n                else:\n                    eigen_type = ""Eigen::Matrix<"" + cpp_type + "", "" + ""Eigen::Dynamic, "" + ""Eigen::Dynamic, "" + \\\n                                 storage_order_enum + "">""\n                    out_file.write(""typedef "" + eigen_type + "" Matrix_%s"" % arg.name + "";\\n"")\n                    if type_suffix == STORAGE_ORDER_SUFFIX_XM:\n                        out_file.write(""Eigen::Index "" + arg.name + ""_inner_stride = 0;\\n"")\n                        out_file.write(""Eigen::Index "" + arg.name + ""_outer_stride = 0;\\n"")\n                        out_file.write(""if ("" + arg.name + "".ndim() == 1) {\\n"")\n                        out_file.write(arg.name + ""_outer_stride = "" + arg.name + "".strides(0) / sizeof("" +\n                                       cpp_type + "");\\n"")\n                        out_file.write(""} else if ("" + arg.name + "".ndim() == 2) {\\n"")\n                        out_file.write(arg.name + ""_outer_stride = "" + arg.name + "".strides(1) / sizeof("" +\n                                       cpp_type + "");\\n"")\n                        out_file.write(arg.name + ""_inner_stride = "" + arg.name + "".strides(0) / sizeof("" +\n                                       cpp_type + "");\\n"")\n                        out_file.write(""}"")\n                        # out_file.write(\'std::cout << ""\' + arg.name + \' strides = "" << \' + arg.name +\n                        #                \'_outer_stride << "", "" << \' + arg.name + \'_inner_stride << std::endl;\')\n                        out_file.write(""typedef Eigen::Map<"" + eigen_type + "", "" +\n                                       aligned_enum + "", Eigen::Stride<Eigen::Dynamic, Eigen::Dynamic>> Map_"" +\n                                       arg.name + "";\\n"")\n                    else:\n                        out_file.write(""typedef Eigen::Map<"" + eigen_type + "", "" +\n                                       aligned_enum + ""> Map_"" + arg.name + "";\\n"")\n\n        call_str = ""return callit_"" + fun.name\n        template_str = ""<""\n        for arg in fun.arguments:\n            if arg.is_numpy_type:\n                template_str += ""Map_"" + arg.name + "", Matrix_"" + arg.name + "", Scalar_"" + arg.name + "",""\n\n        template_str = template_str[:-1] + "">(""\n\n        call_str = call_str + template_str if fun.has_array_arguments else call_str + ""(""\n\n        for arg in fun.arguments:\n            if arg.is_numpy_type:\n                stride_str = """"\n                assert arg.group is not None\n                arg_suffix = combo[arg.group.id][1]\n                if arg_suffix == STORAGE_ORDER_SUFFIX_XM:\n                    stride_str = "", Eigen::Stride<Eigen::Dynamic, Eigen::Dynamic>("" + \\\n                                 arg.name + ""_outer_stride, "" + arg.name + ""_inner_stride)""\n\n                map_str = """"\n                if arg.is_nullable:\n                    map_str = arg.name + "".is_none ? Map_"" + arg.name\n                    if arg.is_sparse:\n                        map_str += ""(0, 0, 0, nullptr, nullptr, nullptr) : ""\n                    else:\n                        map_str += ""(nullptr, 0, 0"" + stride_str + "") : ""\n\n                if not arg.is_sparse:\n                    map_str += ""Map_"" + arg.name + ""((Scalar_"" + arg.name + ""*) "" + cast_arg(arg) + "".data(), "" + \\\n                               arg.name + ""_shape_0, "" + arg.name + ""_shape_1"" + stride_str + ""),""\n                else:\n                    map_str += arg.name + "".as_eigen<Matrix_"" + arg.name + "">(),""\n\n                call_str += map_str\n\n            else:\n                call_str += arg.name + "",""\n\n        call_str = call_str[:-1] + "");\\n""\n        out_file.write(call_str)\n        # out_file.write(binding_source_code + ""\\n"")\n        out_file.write(""}\\n"")\n\n    def write_function_definition(fun):\n        template_str = ""template <""\n        for arg in fun.arguments:\n            if arg.is_numpy_type:\n                template_str += ""typename "" + MAP_TYPE_PREFIX + arg.name + "",""\n                template_str += ""typename "" + MATRIX_TYPE_PREFIX + arg.name + "",""\n                template_str += ""typename "" + SCALAR_TYPE_PREFIX + arg.name + "",""\n        template_str = template_str[:-1] + "">\\n""\n        if fun.has_array_arguments:\n            out_file.write(template_str)\n        out_file.write(""static auto callit_%s("" % fun.name)\n\n        argument_str = """"\n        for arg in fun.arguments:\n            if arg.is_numpy_type:\n                argument_str += ""%s%s %s,"" % (MAP_TYPE_PREFIX, arg.name, arg.name)\n            else:\n                argument_str += arg.types[0] + "" "" + arg.name + "",""\n        argument_str = argument_str[:-1] + "") {\\n""\n        out_file.write(argument_str)\n        out_file.write(fun.source_code)\n        out_file.write(""}\\n"")\n\n    def write_function_switch_end(fun):\n        if len(fun.docstring) > 0:\n            out_file.write("", "" + fun.docstring)\n\n        arg_list = """"\n        for arg in fun.arguments:\n            arg_list += "", pybind11::arg(\\"""" + arg.name + ""\\"")""\n\n            if arg.is_nullable:\n                arg_list += ""="" + \'pybind11::none()\'\n            elif arg.default_value is not None:\n                arg_list += ""="" + arg.default_value\n\n        out_file.write(arg_list)\n        out_file.write("");\\n"")\n\n    FOR_REAL_DEFINE = ""__NPE_FOR_REAL__""\n    out_file.write(""#define "" + FOR_REAL_DEFINE + ""\\n"")\n    out_file.write(""#include <npe.h>\\n"")\n\n    for child in ast.children:\n        out_file.write(child.preamble + ""\\n"")\n        if type(child) == NpeFunction:\n            write_function_definition(child)\n        else:\n            raise RuntimeError(""What in the actual fuck?"")\n\n    func_name = ""pybind_output_fun_"" + os.path.basename(ast.input_file_name).replace(""."", ""_"")\n    out_file.write(""void %s(pybind11::module& m) {\\n"" % func_name)\n\n    for child in ast.children:\n        out_file.write(\'m.def(\')\n        if type(child) == NpeFunction:\n            write_function_switch_header(child)\n            write_function_switch_body(child)\n            write_function_switch_end(child)\n        else:\n            raise RuntimeError(""What in the actual fuck?"")\n\n    out_file.write(""}\\n"")\n    out_file.write(""\\n"")\n\n\ndef main():\n    global cpp_command\n    global cpp_path\n    global verbosity_level\n\n    arg_parser = argparse.ArgumentParser()\n    arg_parser.add_argument(""file"", type=str)\n    arg_parser.add_argument(""cpp_cmd"", type=str)\n    arg_parser.add_argument(""-o"", ""--output"", type=str, default=""a.out"")\n    arg_parser.add_argument(""-v"", ""--verbosity-level"", type=int, default=LOG_INFO,\n                            help=""How verbose is the output. < 0 = silent, ""\n                                 ""0 = only errors, 1 = normal, 2 = verbose, > 3 = debug"")\n    arg_parser.add_argument(\'--debug-trace\', action=\'store_true\',\n                            help=\'Print traces containing type information of variables passed into bound functions\')\n    arg_parser.add_argument(\'--c-preprocessor-args\', help=\'Input String\', nargs=\'*\', type=str)\n\n    args = arg_parser.parse_args()\n\n    cpp_path = args.cpp_cmd\n\n    cpp_command = []\n    for tmp in args.c_preprocessor_args:\n        for t in tmp.split("" ""):\n            cpp_command.append(t)\n\n    verbosity_level = args.verbosity_level\n\n    try:\n        with NpeFileReader(args.file) as infile:\n            ast = NpeAST(infile)\n        with open(args.output, \'w+\') as outfile:\n            codegen_ast(ast, outfile, write_debug_prints=args.debug_trace)\n    except SemanticError as e:\n        # TODO: Pretty printer\n        log(LOG_ERROR, TermColors.FAIL + TermColors.BOLD + ""NumpyEigen Semantic Error: "" +\n            TermColors.ENDC + TermColors.ENDC + str(e), file=sys.stderr)\n        sys.exit(1)\n    except ParseError as e:\n        # TODO: Pretty printer\n        log(LOG_ERROR, TermColors.FAIL + TermColors.BOLD + ""NumpyEigen Syntax Error: "" +\n            TermColors.ENDC + TermColors.ENDC + str(e), file=sys.stderr)\n        sys.exit(1)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
src/codegen_module.py,0,"b'import argparse\nimport os\n\n\nclass TermColors:\n    HEADER = \'\\033[95m\'\n    OKBLUE = \'\\033[94m\'\n    OKGREEN = \'\\033[92m\'\n    WARNING = \'\\033[93m\'\n    FAIL = \'\\033[91m\'\n    ENDC = \'\\033[0m\'\n    BOLD = \'\\033[1m\'\n    UNDERLINE = \'\\033[4m\'\n\n\nFUNCTION_NAME_PREFIX = ""pybind_output_fun_""\n\n\ndef write_module(out_file, module_name, files):\n    out_file.write(""#include <pybind11/pybind11.h>\\n"")\n\n    func_names = [""pybind_output_fun_"" + os.path.basename(fn).replace(""."", ""_"") for fn in files]\n\n    for fn in func_names:\n        out_file.write(""void %s(pybind11::module&);\\n"" % fn)\n\n    out_file.write(""PYBIND11_MODULE(%s, m) {\\n"" % module_name)\n    out_file.write(""m.doc() = \\""TODO: Dodumentation\\"";\\n"")\n\n    for fn in func_names:\n        out_file.write(""%s(m);\\n"" % fn)\n\n    out_file.write(""#ifdef VERSION_INFO\\n"")\n    out_file.write(""m.attr(\\""__version__\\"") = VERSION_INFO;\\n"")\n    out_file.write(""m.attr(\\""__version__\\"") = \\""dev\\"";\\n"")\n    out_file.write(""#endif\\n"")\n    out_file.write(""}\\n"")\n\n\nif __name__ == ""__main__"":\n    arg_parser = argparse.ArgumentParser()\n    arg_parser.add_argument(""-o"", ""--output"", type=str, default=""a.out"")\n    arg_parser.add_argument(""-m"", ""--module-name"", type=str, required=True)\n    arg_parser.add_argument(""-f"", ""--files"", type=str, nargs=""+"", required=True)\n\n    args = arg_parser.parse_args()\n\n    print(TermColors.OKGREEN + ""NumpyEigen Module:"" + TermColors.ENDC + args.module_name)\n\n    with open(args.output, \'w+\') as outfile:\n        write_module(outfile, args.module_name, args.files)'"
tests/profiling.py,10,"b'# This file is part of libigl, a simple c++ geometry processing library.\n#\n# Copyright (C) 2017 Sebastian Koch <s.koch@tu-berlin.de> and Daniele Panozzo <daniele.panozzo@gmail.com>\n#\n# This Source Code Form is subject to the terms of the Mozilla Public License\n# v. 2.0. If a copy of the MPL was not distributed with this file, You can\n# obtain one at http://mozilla.org/MPL/2.0/.\nimport sys, os\nimport math\nimport time\nimport numpy as np\nfrom iglhelpers import *\nfrom numba import jit, autojit\nimport pyigl_proto as p\n\n\n# Add the igl library to the modules search path\nsys.path.insert(0, os.getcwd() + ""/../"")\nimport pyigl as igl\n\nfrom shared import TUTORIAL_SHARED_PATH, check_dependencies\n\ndependencies = []\ncheck_dependencies(dependencies)\n\nV = igl.eigen.MatrixXd()\nU = igl.eigen.MatrixXd()\nF = igl.eigen.MatrixXi()\nL = igl.eigen.SparseMatrixd()\n\nverbose = True\n\ndef timing(func, amount, text):\n    times = []\n    for i in range(amount):\n        t0 = time.time()\n        func()\n        t1 = time.time()\n        secs = t1 - t0\n        times.append(secs)\n\n    print(text, np.mean(times), np.std(times), np.median(times), ""sec"") if verbose else print(secs)\n\nif True:\n    #timing(lambda: igl.readOBJ(TUTORIAL_SHARED_PATH + ""cube.obj"", V, F), 100000, ""Loading 100000 small objs:"")\n\n    #timing(lambda: igl.readOBJ(TUTORIAL_SHARED_PATH + ""armadillo.obj"", V, F), 20, ""Loading 20 large objs:"")\n\n    #timing(lambda: igl.cotmatrix(V, F, L), 100, ""Calculating 100 cotmatrices:"")\n\n#    def matrices():\n#        matrix = np.random.randn(10000, 10000)\n#        matrix = p2e(matrix)\n#        matrix_2 = matrix * matrix\n\n#    timing(lambda: matrices(), 5, ""Calculating 50 matrix products:"")\n\n#    def matrices2():\n#        matrix = igl.eigen.MatrixXd(10000, 10000)\n#        matrix.setRandom()\n#        matrix_2 = matrix * matrix\n\n#    timing(lambda: matrices2(), 5, ""Calculating 50 matrix products:"")\n\n#    def matrices(matrix):\n#        matrix = p2e(matrix)\n#        matrix_2 = matrix + matrix\n#        return matrix_2\n#    matrix = np.eye(10000)\n#    matrix = matrix.astype(dtype=""float64"", order=""F"")\n#    timing(lambda: matrices(matrix), 50, ""Calculating 50 matrix products:"")\n\n#    def matrices1(matrix):\n#        #matrix = p2e(matrix)\n#        matrix_2 = matrix + matrix\n#        return matrix_2\n#    matrix = np.eye(10000)\n#    matrix = matrix.astype(dtype=""float64"", order=""F"")\n#    timing(lambda: matrices1(matrix), 50, ""Calculating 50 matrix products:"")\n\n    def matrices2(matrix):\n        #matrix = p2e(matrix)\n        matrix_2 = p.matrix_add(matrix, matrix)\n        return matrix_2\n    matrix = np.eye(1000, dtype=""float64"")\n#    matrix = matrix.astype(dtype=""float32"")#, order=""C"")\n    timing(lambda: matrices2(matrix), 50, ""Calculating 50 matrix products:"")\n\n#    def matrices2(matrix):\n#        matrix_2 = matrix + matrix\n#        return matrix_2\n\n#    matrix = igl.eigen.MatrixXd(10000, 10000)\n#    matrix.setIdentity()\n#    timing(lambda: matrices2(matrix), 50, ""Calculating 50 matrix products:"")\n\n\n\n#@autojit\n#def matrices3():\n#    matrix = np.random.randn(1000, 1000)\n#    matrix = p2e(matrix)\n#    su = 0\n#    for i in range(1000):\n#        for j in range(1000):\n#            su += matrix[i, j]\n\n#timing(lambda: matrices3(), 10, ""Combined (np/eigen) matrix access:"")\n\n\n#@autojit\n#def matrices4():\n#    matrix = igl.eigen.MatrixXd(1000, 1000)\n#    matrix.setRandom()\n#    su = 0\n#    for i in range(1000):\n#        for j in range(1000):\n#            su += matrix[i, j]\n\n#timing(lambda: matrices4(), 10, ""Eigen matrix access:"")\n\n\n#@autojit\n#def matrices5():\n#    matrix = np.random.randn(1000, 1000)\n#    su = 0\n#    for i in range(1000):\n#        for j in range(1000):\n#            su += matrix[i, j]\n\n#timing(lambda: matrices5(), 10, ""Numpy matrix access:"")\n\n##@autojit\n#def matrices6():\n#    matrix = np.random.randn(1000, 1000)\n#    su = np.sum(matrix)\n\n#timing(lambda: matrices6(), 10, ""Numpy matrix access:"")\n\n#matrix = np.random.rand(1000, 1000)\n#matrix_2 = matrix.dot(matrix)\n\n#matrix_e = p2e(matrix)\n#matrix_e2 = matrix_e * matrix_e\n\n#for i in range(1000):\n#    for j in range(1000):\n#        a = matrix[i, j]\n\n#for i in range(1000):\n#    for j in range(1000):\n#        a = matrix_e[i, j]\n\n\n\n## Alternative construction of same Laplacian\n#G = igl.eigen.SparseMatrixd()\n#K = igl.eigen.SparseMatrixd()\n\n## Gradient/Divergence\n#igl.grad(V, F, G)\n\n## Diagonal per-triangle ""mass matrix""\n#dblA = igl.eigen.MatrixXd()\n#igl.doublearea(V, F, dblA)\n\n## Place areas along diagonal #dim times\n\n#T = (dblA.replicate(3, 1) * 0.5).asDiagonal() * 1\n\n## Laplacian K built as discrete divergence of gradient or equivalently\n## discrete Dirichelet energy Hessian\n\n#temp = -G.transpose()\n#K = -G.transpose() * T * G\n\n\n## Use original normals as pseudo-colors\n#N = igl.eigen.MatrixXd()\n#igl.per_vertex_normals(V, F, N)\n#C = N.rowwiseNormalized() * 0.5 + 0.5\n'"
tests/test_1d_arrays.py,93,"b'import unittest\nimport sys\nimport os\n\nsys.path.append(os.getcwd())\nimport numpy as np\nimport numpyeigen_test as npe_test\n\n\nclass Test1dArays(unittest.TestCase):\n\n    def test_passing_1d_arrays(self):\n        a = np.ones(10)\n        expected = np.array(a)\n        expected[0] = 2.0\n        self.assertEqual(a[0], 1.0)\n        def_str, def_nparr, ret = npe_test.default_arg(a)\n        self.assertEqual(def_str, ""abcdef"")\n        self.assertEqual(def_nparr.shape, (0, 0))\n        self.assertTrue(np.array_equal(ret, expected))\n        self.assertTrue(np.array_equal(a, expected))\n\n    def test_passing_1d_arrays_1(self):\n        a = np.ones(10)\n        v = np.ones([10, 10])\n        f = np.ones([10, 10], dtype=np.int)\n\n        retv, retp = npe_test.one_d_arg(v, f, a)\n        self.assertTrue(np.array_equal(retp, a))\n        self.assertTrue(np.array_equal(retv, v))\n\n        a = np.ones([10, 10])\n        v = np.ones([10, 10])\n        f = np.ones([10, 10], dtype=np.int)\n\n        retv, retp = npe_test.one_d_arg(v, f, a)\n        self.assertTrue(np.array_equal(retp, a))\n        self.assertTrue(np.array_equal(retv, v))\n\n    def test_passing_1d_arrays_2(self):\n        v = np.ones(10)\n        f = np.ones([10, 10], dtype=np.int)\n        p = np.ones(10)\n        q = np.ones(10)\n        r = np.ones(10)\n        s = np.ones(10)\n\n        retv, retp = npe_test.one_d_arg_big(v, f, p, q, r, s)\n        self.assertTrue(np.array_equal(retp, p))\n        self.assertTrue(np.array_equal(retv, v))\n\n        with self.assertRaises(ValueError):\n            v = np.ones(10, dtype=np.float32)\n            f = np.ones([10, 10], dtype=np.int)\n            p = np.ones(10)\n            q = np.ones(10)\n            r = np.ones(10)\n            s = np.ones(10)\n            npe_test.one_d_arg_big(v, f, p, q, r, s)\n\n        with self.assertRaises(ValueError):\n            v = np.ones(10)\n            f = np.ones([10, 10], dtype=np.int)\n            p = np.ones(10, dtype=np.float32)\n            q = np.ones(10)\n            r = np.ones(10)\n            s = np.ones(10)\n            npe_test.one_d_arg_big(v, f, p, q, r, s)\n\n        with self.assertRaises(ValueError):\n            v = np.ones(10)\n            f = np.ones([10, 10], dtype=np.int)\n            p = np.ones(10)\n            q = np.ones(10, dtype=np.float32)\n            r = np.ones(10)\n            s = np.ones(10)\n            npe_test.one_d_arg_big(v, f, p, q, r, s)\n\n        with self.assertRaises(ValueError):\n            v = np.ones(10)\n            f = np.ones([10, 10], dtype=np.int)\n            p = np.ones(10)\n            q = np.ones(10)\n            r = np.ones(10, dtype=np.float32)\n            s = np.ones(10)\n            npe_test.one_d_arg_big(v, f, p, q, r, s)\n\n        with self.assertRaises(ValueError):\n            v = np.ones(10)\n            f = np.ones([10, 10], dtype=np.int)\n            p = np.ones(10)\n            q = np.ones(10)\n            r = np.ones(10)\n            s = np.ones(10, dtype=np.float32)\n            npe_test.one_d_arg_big(v, f, p, q, r, s)\n\n    def test_passing_0d_arrays(self):\n        dim = np.random.randint(5)\n        a = np.zeros([0, dim])\n        expected = np.array([0, dim])\n        ret = npe_test.default_arg2(a)\n        self.assertTrue(np.array_equal(ret, expected))\n\n    def test_passing_0d_arrays_1(self):\n        dim = np.random.randint(5)\n        # (np.zeros([0, dim]), np.zeros([dim, 0]), np.zeros([0]), np.zeros([0, 0])):\n\n        a = np.zeros([0, dim])\n        v = np.ones([10, 10])\n        f = np.ones([10, 10], dtype=np.int)\n\n        retv, retp = npe_test.one_d_arg(v, f, a)\n        self.assertEqual(retp.shape[0], a.shape[0])\n        self.assertEqual(len(a), 0)\n        self.assertTrue(np.array_equal(retv, v))\n\n        #\n        np.zeros([dim, 0])\n        v = np.ones([10, 10])\n        f = np.ones([10, 10], dtype=np.int)\n\n        retv, retp = npe_test.one_d_arg(v, f, a)\n        self.assertEqual(retp.shape[0], a.shape[0])\n        self.assertEqual(len(a), 0)\n        self.assertTrue(np.array_equal(retv, v))\n\n        #\n        a = np.zeros([0])\n        v = np.ones([10, 10])\n        f = np.ones([10, 10], dtype=np.int)\n\n        retv, retp = npe_test.one_d_arg(v, f, a)\n        self.assertEqual(retp.shape, a.reshape([0, 0]).shape)\n        self.assertEqual(len(a), 0)\n        self.assertTrue(np.array_equal(retv, v))\n\n        #\n        a = np.zeros([0, 0])\n        v = np.ones([10, 10])\n        f = np.ones([10, 10], dtype=np.int)\n\n        retv, retp = npe_test.one_d_arg(v, f, a)\n        self.assertEqual(retp.shape, a.shape)\n        self.assertEqual(len(a), 0)\n        self.assertTrue(np.array_equal(retv, v))\n\n        #\n        a = np.zeros([])\n        v = np.ones([10, 10])\n        f = np.ones([10, 10], dtype=np.int)\n\n        retv, retp = npe_test.one_d_arg(v, f, a)\n        print(a.shape, retp.shape)\n        self.assertEqual(tuple(retp.shape), (0, 0))\n        self.assertTrue(np.array_equal(retv, v))\n\n    def test_passing_0d_arrays_2(self):\n        dim = np.random.randint(5)\n        a = np.zeros([0, dim])\n\n        for arr_test in (np.zeros([0, dim])):\n            v = arr_test.copy()\n            f = np.ones([10, 10], dtype=np.int)\n            p = arr_test.copy()\n            q = arr_test.copy()\n            r = arr_test.copy()\n            s = arr_test.copy()\n\n            retv, retp = npe_test.one_d_arg_big(v, f, p, q, r, s)\n            self.assertEqual(retp.shape, a.shape)\n            self.assertEqual(len(a), 0)\n            self.assertTrue(np.array_equal(retv, v))\n\n            with self.assertRaises(ValueError):\n                v = arr_test.astype(np.float32)  # np.ones(10, dtype=np.float32)\n                f = np.ones([10, 10], dtype=np.int)\n                p = arr_test.copy()\n                q = arr_test.copy()\n                r = arr_test.copy()\n                s = arr_test.copy()\n                npe_test.one_d_arg_big(v, f, p, q, r, s)\n\n            with self.assertRaises(ValueError):\n                v = arr_test.copy()\n                f = np.ones([10, 10], dtype=np.int)\n                p = arr_test.astype(np.float32)\n                q = arr_test.copy()\n                r = arr_test.copy()\n                s = arr_test.copy()\n                npe_test.one_d_arg_big(v, f, p, q, r, s)\n\n            with self.assertRaises(ValueError):\n                v = arr_test.copy()\n                f = np.ones([10, 10], dtype=np.int)\n                p = arr_test.copy()\n                q = arr_test.astype(np.float32)\n                r = arr_test.copy()\n                s = arr_test.copy()\n                npe_test.one_d_arg_big(v, f, p, q, r, s)\n\n            with self.assertRaises(ValueError):\n                v = arr_test.copy()\n                f = np.ones([10, 10], dtype=np.int)\n                p = arr_test.copy()\n                q = arr_test.copy()\n                r = arr_test.astype(np.float32)\n                s = arr_test.copy()\n                npe_test.one_d_arg_big(v, f, p, q, r, s)\n\n            with self.assertRaises(ValueError):\n                v = arr_test.copy()\n                f = np.ones([10, 10], dtype=np.int)\n                p = arr_test.copy()\n                q = arr_test.copy()\n                r = arr_test.copy()\n                s = arr_test.astype(np.float32)\n                npe_test.one_d_arg_big(v, f, p, q, r, s)\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
tests/test_default_matches.py,28,"b'from __future__ import print_function\nimport unittest\nimport sys\nimport os\nimport scipy as sp\nimport scipy.sparse\n\nsys.path.append(os.getcwd())\nimport numpy as np\nimport numpyeigen_test as npe_test\nimport numpyeigen_helpers as npe_helpers\n\nimport platform\n\n\nclass TestDefaultMatches(unittest.TestCase):\n\n    def test_not_none_1(self):\n        a = np.eye(100)\n        b = np.zeros([100, 100])\n        c = np.zeros([100, 100])\n\n        d, e, f = npe_test.default_matches_1(a, b, c)\n\n        self.assertEqual(a[0, 0], 2.0)\n        self.assertEqual(c[0, 0], 2.0)\n\n        self.assertNotEqual(f[0, 0], 3.0)\n        self.assertNotEqual(c[0, 0], 3.0)\n        f[0, 0] = 3.0\n        self.assertEqual(f[0, 0], 3.0)\n        self.assertEqual(f[0, 0], c[0, 0])\n\n    def test_none_1(self):\n        a = np.eye(100)\n        b = np.zeros([100, 100])\n\n        d, e, f = npe_test.default_matches_1(a, b)\n\n        self.assertEqual(a[0, 0], 2.0)\n        self.assertEqual(f.shape, (0, 0))\n        self.assertEqual(f.dtype, a.dtype)\n\n    def test_not_none_2(self):\n        a = np.random.rand(25, 25).astype(np.float32)\n        b = np.random.rand(22, 21).astype(np.float32)\n        c = np.random.rand(32, 33).astype(np.float32)\n\n        d = np.eye(100, dtype=np.int32)\n        e = np.zeros([100, 100], dtype=np.int32)\n        f = np.zeros([100, 100], dtype=np.int32)\n\n        g, h, i = npe_test.default_matches_2(a, b, c, d, e, f)\n\n        self.assertEqual(d[0, 0], 2.0)\n        self.assertEqual(e[0, 0], 2.0)\n        self.assertEqual(f[0, 0], 2.0)\n\n        self.assertNotEqual(f[0, 0], 3.0)\n        self.assertNotEqual(i[0, 0], 3.0)\n        f[0, 0] = 3.0\n        self.assertEqual(i[0, 0], 3.0)\n        self.assertEqual(f[0, 0], i[0, 0])\n\n        self.assertNotEqual(e[0, 0], 3.0)\n        self.assertNotEqual(h[0, 0], 3.0)\n        e[0, 0] = 3.0\n        self.assertEqual(e[0, 0], 3.0)\n        self.assertEqual(e[0, 0], h[0, 0])\n\n        self.assertNotEqual(d[0, 0], 3.0)\n        self.assertNotEqual(g[0, 0], 3.0)\n        g[0, 0] = 3.0\n        self.assertEqual(d[0, 0], 3.0)\n        self.assertEqual(d[0, 0], g[0, 0])\n\n    def test_none_2(self):\n        if platform.system() == \'Windows\':\n            print(""Warning skipping test on windows"")\n            return\n\n        a = np.random.rand(25, 25).astype(np.float32)\n        b = np.random.rand(22, 21).astype(np.float32)\n\n        d = np.eye(100, dtype=np.int32)\n        e = np.zeros([100, 100], dtype=np.int32)\n\n        g, h, i = npe_test.default_matches_2(a, b, None, d, e, None)\n\n        self.assertEqual(d[0, 0], 2.0)\n        self.assertEqual(e[0, 0], 2.0)\n        self.assertEqual(i.shape, (0, 0))\n        self.assertEqual(i.dtype, d.dtype)\n\n        self.assertNotEqual(e[0, 0], 3.0)\n        self.assertNotEqual(h[0, 0], 3.0)\n        e[0, 0] = 3.0\n        self.assertEqual(e[0, 0], 3.0)\n        self.assertEqual(e[0, 0], h[0, 0])\n\n        self.assertNotEqual(d[0, 0], 3.0)\n        self.assertNotEqual(g[0, 0], 3.0)\n        g[0, 0] = 3.0\n        self.assertEqual(d[0, 0], 3.0)\n        self.assertEqual(d[0, 0], g[0, 0])\n\n    def test_not_none_3(self):\n        print(""NOT NONE 3"")\n        a = np.random.rand(25, 25).astype(np.float32)\n        a[a < 0.5] = 0.0\n        b = np.random.rand(22, 21).astype(np.float32)\n        b[b < 0.5] = 0.0\n        c = np.random.rand(32, 33).astype(np.float32)\n        c[c < 0.5] = 0.0\n\n        a = sp.sparse.csr_matrix(a)\n        b = sp.sparse.csr_matrix(b)\n        c = sp.sparse.csr_matrix(c)\n        d = np.eye(100, dtype=np.int32)\n        e = np.zeros([100, 100], dtype=np.int32)\n        f = np.zeros([100, 100], dtype=np.int32)\n\n        print(""ABOUT TO CALL"")\n        g, h, i = npe_test.default_matches_3(a, b, c, d, e, f)\n\n        self.assertEqual(type(g), sp.sparse.csr_matrix)\n        self.assertEqual(type(h), sp.sparse.csr_matrix)\n        self.assertEqual(type(i), sp.sparse.csr_matrix)\n\n    def test_none_3(self):\n        a = np.random.rand(25, 25).astype(np.float32)\n        a[a < 0.5] = 0.0\n        b = np.random.rand(22, 21).astype(np.float32)\n        b[b < 0.5] = 0.0\n        c = np.random.rand(32, 33).astype(np.float32)\n        c[c < 0.5] = 0.0\n\n        a = sp.sparse.csr_matrix(a)\n        b = sp.sparse.csr_matrix(b)\n        d = np.eye(100, dtype=np.int32)\n\n        sys.stdout.flush()\n        g, h, i = npe_test.default_matches_3(a, b, None, d)\n\n        self.assertEqual(type(g), np.ndarray)\n        self.assertEqual(type(h), np.ndarray)\n        self.assertEqual(type(i), np.ndarray)\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
tests/test_dense_binding.py,66,"b'from __future__ import print_function\nimport unittest\nimport sys\nimport os\nimport time\n\nsys.path.append(os.getcwd())\nimport numpy as np\nimport numpyeigen_test as npe_test\nimport numpyeigen_helpers as npe_helpers\nimport platform\nimport scipy.sparse as sp\n\n\nclass TestDenseBindings(unittest.TestCase):\n\n    def test_no_copy(self):\n        a = np.eye(100)\n        expected = np.array(a)\n        expected[0, 0] = 2.0\n        self.assertEqual(a[0, 0], 1.0)\n        ret = npe_test.mutate_matrix(a)  # Always sets A[0, 0] to 2.0\n        self.assertTrue(np.array_equal(ret, a))\n        self.assertTrue(np.array_equal(a, expected))\n\n    def test_pybind_does_a_copy_if_type_mismatch(self):\n        a = np.eye(100)\n        expected = np.array(a)\n        expected[0, 0] = 2.0\n        self.assertEqual(a[0, 0], 1.0)\n        ret = npe_helpers.mutate_copy(a)  # Always sets A[0, 0] to 2.0\n        self.assertFalse(np.array_equal(ret, a))\n        self.assertFalse(np.array_equal(a, expected))\n\n    def test_pybind_does_not_make_a_copy_if_type_mismatch(self):\n        a = np.eye(100, dtype=np.float32)\n        expected = np.array(a, dtype=np.float32)\n        expected[0, 0] = 2.0\n        self.assertEqual(a[0, 0], 1.0)\n        ret = npe_helpers.mutate_copy(a)  # Always sets A[0, 0] to 2.0\n        self.assertTrue(np.array_equal(a, expected))\n\n        a = np.eye(100, dtype=np.float64)\n        expected = np.array(a, dtype=np.float64)\n        expected[0, 0] = 2.0\n        self.assertEqual(a[0, 0], 1.0)\n        ret = npe_helpers.mutate_copy(a)  # Always sets A[0, 0] to 2.0\n        self.assertFalse(np.array_equal(a, expected))\n\n    def test_timing_for_copy_vs_no_copy(self):\n        mat_size = 10000\n        num_iters = 10\n\n        times_nocopy = []\n        a = np.eye(mat_size)\n        for i in range(num_iters):\n            start_time = time.time()\n            npe_test.mutate_matrix(a)\n            end_time = time.time()\n            times_nocopy.append(end_time-start_time)\n\n        times_nocopy_pybind = []\n        a = np.eye(mat_size, dtype=np.float32)\n        for i in range(num_iters):\n            start_time = time.time()\n            npe_helpers.mutate_copy(a)\n            end_time = time.time()\n            times_nocopy_pybind.append(end_time-start_time)\n\n        times_copy = []\n        a = np.eye(mat_size)\n        for i in range(num_iters):\n            start_time = time.time()\n            npe_helpers.mutate_copy(a)\n            end_time = time.time()\n            times_copy.append(end_time-start_time)\n\n        median_nocopy = np.median(times_nocopy)\n        median_copy = np.median(times_copy)\n        self.assertLess(median_nocopy*1e3, median_copy)\n        # print(""COPY:"")\n        # print(""  mean:"", np.mean(times_copy))\n        # print(""  std:"", np.std(times_copy))\n        # print(""  med:"", np.median(times_copy))\n        #\n        # print(""NOCOPY pybind22:"")\n        # print(""  mean:"", np.mean(times_nocopy))\n        # print(""  std:"", np.std(times_nocopy))\n        # print(""  med:"", np.median(times_nocopy))\n        #\n        # print(""NOCOPY pybind11:"")\n        # print(""  mean:"", np.mean(times_nocopy_pybind))\n        # print(""  std:"", np.std(times_nocopy_pybind))\n        # print(""  med:"", np.median(times_nocopy_pybind))\n\n    def test_return_does_not_copy(self):\n        mat_size = 10000\n        num_iters = 10\n\n        times_nocopy = []\n        a = np.eye(mat_size)\n        for i in range(num_iters):\n            start_time = time.time()\n            npe_test.mutate_matrix(a)\n            end_time = time.time()\n            times_nocopy.append(end_time-start_time)\n\n        times_copy = []\n        a = np.eye(mat_size)\n        for i in range(num_iters):\n            start_time = time.time()\n            npe_helpers.return_dense_copy(a)\n            end_time = time.time()\n            times_copy.append(end_time-start_time)\n\n        median_nocopy = np.median(times_nocopy)\n        median_copy = np.median(times_copy)\n\n        print(""COPY:"")\n        print(""  mean:"", np.mean(times_copy))\n        print(""  std:"", np.std(times_copy))\n        print(""  med:"", np.median(times_copy))\n\n        print(""NOCOPY pybind22:"")\n        print(""  mean:"", np.mean(times_nocopy))\n        print(""  std:"", np.std(times_nocopy))\n        print(""  med:"", np.median(times_nocopy))\n\n        self.assertLess(median_nocopy*1e3, median_copy)\n\n    def test_bool_array(self):\n        a = np.zeros(10, dtype=np.bool)\n        a[np.random.rand(10) > 0.5] = True\n        b = np.zeros(10, dtype=np.bool)\n        b[np.logical_not(a)] = True\n\n        c = npe_test.bool_array(a, b)\n\n        self.assertTrue(np.array_equal(c, np.ones(10, dtype=np.bool)))\n\n        a = np.zeros((10, 10), dtype=np.bool)\n        a[np.random.rand(10, 10) > 0.5] = True\n        b = np.zeros((10, 10), dtype=np.bool)\n        b[np.logical_not(a)] = True\n\n        c = npe_test.bool_array(a, b)\n\n        self.assertTrue(np.array_equal(c, np.ones((10, 10), dtype=np.bool)))\n\n    def test_long_and_int(self):\n        if sys.version_info[0] >= 3:\n            along = np.ones((10, 10), dtype=""long"")\n        aint = np.ones((10, 10), dtype=""int32"")\n        alonglong = np.ones((10, 10), dtype=""longlong"")\n\n        if sys.version_info[0] >= 3:\n            blong = np.ones((10, 10), dtype=""long"")\n        bint = np.ones((10, 10), dtype=""int32"")\n        blonglong = np.ones((10, 10), dtype=""longlong"")\n\n        is_64bits = sys.maxsize > 2 ** 32\n        if not is_64bits:\n            raise ValueError(""Numpyeigen does not work on 32 bit systems yet!"")\n\n        if platform.system() != \'Windows\':\n            npe_test.intlonglong(alonglong, bint)\n            if sys.version_info[0] >= 3:\n                npe_test.intlonglong(along, bint)\n                npe_test.intlonglong(alonglong, blong)\n                npe_test.intlonglong(along, blong)\n                npe_test.intlonglong(along, blonglong)\n                npe_test.intlonglong(aint, blong)\n            npe_test.intlonglong(aint, bint)\n            npe_test.intlonglong(alonglong, blonglong)\n            npe_test.intlonglong(aint, blonglong)\n\n            if sys.version_info[0] >= 3:\n                npe_test.intlong(along, bint)\n                npe_test.intlong(alonglong, blong)\n                npe_test.intlong(along, blong)\n                npe_test.intlong(aint, blong)\n                npe_test.intlong(along, blonglong)\n            npe_test.intlong(alonglong, bint)\n            npe_test.intlong(aint, bint)\n            npe_test.intlong(alonglong, blonglong)\n            npe_test.intlong(aint, blonglong)\n\n            with self.assertRaises(ValueError):\n                if sys.version_info[0] >= 3:\n                    npe_test.longlonglong(along, bint)\n                    npe_test.longlonglong(aint, blong)\n                npe_test.longlonglong(alonglong, bint)\n                npe_test.longlonglong(aint, bint)\n                npe_test.longlonglong(aint, blonglong)\n\n            if sys.version_info[0] >= 3:\n                npe_test.longlonglong(alonglong, blong)\n                npe_test.longlonglong(along, blong)\n                npe_test.longlonglong(along, blonglong)\n            npe_test.longlonglong(alonglong, blonglong)\n        else:\n            if sys.version_info[0] >= 3:\n                npe_test.intlonglong(along, bint)\n                npe_test.intlonglong(alonglong, blong)\n                npe_test.intlonglong(along, blong)\n                npe_test.intlonglong(along, blonglong)\n                npe_test.intlonglong(aint, blong)\n            npe_test.intlonglong(alonglong, bint)\n            npe_test.intlonglong(aint, bint)\n            npe_test.intlonglong(alonglong, blonglong)\n            npe_test.intlonglong(aint, blonglong)\n\n            with self.assertRaises(ValueError):\n                if sys.version_info[0] >= 3:\n                    npe_test.intlong(alonglong, blong)\n                    npe_test.intlong(along, blonglong)\n                npe_test.intlong(alonglong, bint)\n                npe_test.intlong(alonglong, blonglong)\n                npe_test.intlong(aint, blonglong)\n\n            if sys.version_info[0] >= 3:\n                npe_test.intlong(along, bint)\n                npe_test.intlong(along, blong)\n                npe_test.intlong(aint, blong)\n            npe_test.intlong(aint, bint)\n\n            if sys.version_info[0] >= 3:\n                npe_test.longlonglong(alonglong, blong)\n                npe_test.longlonglong(along, blonglong)\n                npe_test.longlonglong(along, bint)\n                npe_test.longlonglong(along, blong)\n                npe_test.longlonglong(aint, blong)\n            npe_test.longlonglong(alonglong, bint)\n            npe_test.longlonglong(aint, blonglong)\n            npe_test.longlonglong(aint, bint)\n            npe_test.longlonglong(alonglong, blonglong)\n\n    def test_dense_like(self):\n        a = sp.diags([np.ones(100)], [0], format=""csr"")\n        b1 = np.eye(100, dtype=np.float64)\n        b2 = np.eye(100, dtype=np.float32)\n        c1 = np.eye(100, dtype=np.float64)\n        c2 = np.eye(100, dtype=np.float32)\n\n        ret = npe_test.dense_like_1(a, b1)\n        val = (ret - b1)\n        self.assertEqual(np.linalg.norm(val), 0.0)\n\n        ret = npe_test.dense_like_2(a, b1, c1)\n        val = (ret - b1)\n        self.assertEqual(np.linalg.norm(val), 0.0)\n        val = (ret - c1)\n        self.assertEqual(np.linalg.norm(val), 0.0)\n\n        ret = npe_test.dense_like_3(a, b1, c1)\n        val = (ret - b1)\n        self.assertEqual(np.linalg.norm(val), 0.0)\n        val = (ret - c1)\n        self.assertEqual(np.linalg.norm(val), 0.0)\n\n        ret = npe_test.dense_like_4(b1, b1, c1)\n        val = (ret - b1)\n        self.assertEqual(np.linalg.norm(val), 0.0)\n        val = (ret - c1)\n        self.assertEqual(np.linalg.norm(val), 0.0)\n\n        with self.assertRaises(ValueError):\n            npe_test.dense_like_1(a, b2)\n        with self.assertRaises(ValueError):\n            npe_test.dense_like_2(a, b1, c2)\n        with self.assertRaises(ValueError):\n            npe_test.dense_like_2(a, b2, c1)\n        with self.assertRaises(ValueError):\n            npe_test.dense_like_2(a, b2, c2)\n        with self.assertRaises(ValueError):\n            npe_test.dense_like_3(a, b1, c2)\n        with self.assertRaises(ValueError):\n            npe_test.dense_like_3(a, b2, c1)\n        with self.assertRaises(ValueError):\n            npe_test.dense_like_3(a, b2, c2)\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
tests/test_docstring.py,0,"b'from __future__ import print_function\n\nimport unittest\nimport sys\nimport os\n\n\nsys.path.append(os.getcwd())\nimport numpyeigen_test as npe_test\n\n\nclass TestDocstring(unittest.TestCase):\n\n    def test_docstring(self):\n        docstr = ""This is\\n"" + \\\n                 ""a multi-line\\n"" + \\\n                 ""documentation\\n"" + \\\n                 ""string...""\n\n        self.assertTrue(docstr in npe_test.docstring.__doc__)\n\n        docstr = ""this is the docstr""\n        self.assertTrue(docstr in npe_test.string_expr_docstring.__doc__)\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
tests/test_npe_call_interface.py,32,"b'import os\nimport sys\nimport unittest\n\nsys.path.append(os.getcwd())\nimport numpy as np\nimport numpyeigen_test as npe_test\n\n\nclass TestNpeCallInterface(unittest.TestCase):\n\n    def test_default_arguments(self):\n        a = np.eye(10)\n        expected = np.array(a)\n        expected[0, 0] = 2.0\n        self.assertEqual(a[0, 0], 1.0)\n        def_str, def_nparr, ret = npe_test.default_arg(a)\n        self.assertEqual(def_str, ""abcdef"")\n        self.assertEqual(def_nparr.shape, (0, 0))\n        self.assertTrue(np.array_equal(ret, a))\n        self.assertTrue(np.array_equal(a, expected))\n\n        def_str, def_nparr, ret = npe_test.default_arg(a, doubleit=True)\n        self.assertEqual(def_str, ""abcabcdef"")\n        self.assertEqual(def_nparr.shape, (0, 0))\n        self.assertTrue(np.array_equal(ret, a))\n        self.assertTrue(np.array_equal(a, expected))\n\n    def test_passing_subset_of_arguments(self):\n        a = np.eye(100)\n        expected = np.array(a)\n        expected[0, 0] = 2.0\n        self.assertEqual(a[0, 0], 1.0)\n\n        def_str, def_nparr, ret = npe_test.default_arg(a, b=""fff"")\n        self.assertEqual(def_str, ""fffdef"")\n        self.assertEqual(def_nparr.shape, (0, 0))\n        self.assertTrue(np.array_equal(ret, a))\n        self.assertTrue(np.array_equal(a, expected))\n\n        def_str, def_nparr, ret = npe_test.default_arg(a, c=np.eye(7))\n        self.assertEqual(def_str, ""abcdef"")\n        self.assertEqual(def_nparr.shape, (7, 7))\n        self.assertTrue(np.array_equal(ret, a))\n        self.assertTrue(np.array_equal(a, expected))\n\n        def_str, def_nparr, ret = npe_test.default_arg(a, c=np.eye(7), b=""fff"")\n        self.assertEqual(def_str, ""fffdef"")\n        self.assertEqual(def_nparr.shape, (7, 7))\n        self.assertTrue(np.array_equal(ret, a))\n        self.assertTrue(np.array_equal(a, expected))\n\n        def_str, def_nparr, ret = npe_test.default_arg(a, doubleit=True, c=np.eye(7), b=""fff"")\n        self.assertEqual(def_str, ""ffffffdef"")\n        self.assertEqual(def_nparr.shape, (7, 7))\n        self.assertTrue(np.array_equal(ret, a))\n        self.assertTrue(np.array_equal(a, expected))\n\n    def test_passing_no_numpy_arguments(self):\n        ret = npe_test.no_numpy(""abc"")\n        self.assertEqual(ret, ""abc"")\n\n    def test_dtype(self):\n        a = np.zeros(10, dtype=np.float32)\n\n        b = npe_test.test_dtype(a, dtype=""float32"")\n        self.assertEqual(b.dtype, np.float32)\n\n        b = npe_test.test_dtype(a, dtype=""float64"")\n        self.assertEqual(b.dtype, np.float64)\n\n        b = npe_test.test_dtype(a, dtype=np.float32)\n        self.assertEqual(b.dtype, np.float32)\n\n        b = npe_test.test_dtype(a, dtype=np.float64)\n        self.assertEqual(b.dtype, np.float64)\n\n        threw = False\n        try:\n            npe_test.test_dtype(a, dtype=np.int32)\n        except TypeError:\n            threw = True\n        self.assertTrue(threw)\n\n        threw = False\n        try:\n            npe_test.test_dtype(a, dtype=""not_a_type"")\n        except TypeError:\n            threw = True\n        self.assertTrue(threw)\n\n    def test_multiple_functions_per_file(self):\n        a = np.random.rand(10, 10)\n        b = np.random.rand(10, 10)\n        ma1 = npe_test.matrix_add(a, b)\n        ma2 = npe_test.matrix_add2(a, b)\n        ma3 = npe_test.matrix_add3(a, b)\n        print(ma1, ma2, ma3)\n        self.assertTrue(np.array_equal(ma1, ma2))\n        self.assertTrue(np.array_equal(ma2, ma3))\n        self.assertTrue(np.array_equal(ma3, ma1))\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
tests/test_slices.py,21,"b""import os\nimport sys\nimport unittest\n\nsys.path.append(os.getcwd())\nimport numpy as np\nimport numpyeigen_test as npe_test\n\n\nclass TestSlices(unittest.TestCase):\n\n    def test_passing_slices(self):\n        def run_test(dtype1, dtype2, zero_thresh):\n            a = np.random.rand(10, 11).astype(dtype1)\n            b = np.random.rand(10, 11).astype(dtype2)\n\n            res1 = npe_test.matrix_add4(a[0:10:2], b[0:10:2])\n            res2 = a[0:10:2] + b[0:10:2]\n            self.assertLessEqual(np.linalg.norm(res1-res2), zero_thresh)\n\n            res1 = npe_test.matrix_add4(a[0:10:2], a[0:10:2])\n            res2 = a[0:10:2] + a[0:10:2]\n            self.assertLessEqual(np.linalg.norm(res1-res2), zero_thresh)\n\n            res1 = npe_test.matrix_add4(a[0:10:2, 0:9:3], b[0:10:2, 0:9:3])\n            res2 = a[0:10:2, 0:9:3] + b[0:10:2, 0:9:3]\n            self.assertLessEqual(np.linalg.norm(res1-res2), zero_thresh)\n\n            res1 = npe_test.matrix_add4(a[0:10:2, 0:9:3], a[0:10:2, 0:9:3])\n            res2 = a[0:10:2, 0:9:3] + a[0:10:2, 0:9:3]\n            self.assertLessEqual(np.linalg.norm(res1-res2), zero_thresh)\n\n        run_test(np.float32, np.float32, 0.0)\n        run_test(np.float64, np.float64, 0.0)\n        run_test(np.float32, np.float64, 1e-6)\n        run_test(np.float64, np.float32, 1e-6)\n\n    def test_mixing_slices_and_non_slices(self):\n        def run_test(dtype1, dtype2, zero_thresh):\n            a = np.random.rand(10, 11).astype(dtype1)\n            c = np.random.rand(*a[0:10:2].shape).astype(dtype2)\n            d = np.random.rand(*a[0:10:2, 0:9:3].shape).astype(dtype2)\n\n            res1 = npe_test.matrix_add4(a[0:10:2], c)\n            res2 = a[0:10:2] + c\n            self.assertLessEqual(np.linalg.norm(res1-res2), zero_thresh)\n\n            res1 = npe_test.matrix_add4(c, a[0:10:2])\n            res2 = a[0:10:2] + c\n            self.assertLessEqual(np.linalg.norm(res1-res2), zero_thresh)\n\n            res1 = npe_test.matrix_add4(a[0:10:2, 0:9:3], d)\n            res2 = a[0:10:2, 0:9:3] + d\n            self.assertLessEqual(np.linalg.norm(res1-res2), zero_thresh)\n\n            res1 = npe_test.matrix_add4(d, a[0:10:2, 0:9:3])\n            res2 = a[0:10:2, 0:9:3] + d\n            self.assertLessEqual(np.linalg.norm(res1-res2), zero_thresh)\n\n        run_test(np.float32, np.float32, 0.0)\n        run_test(np.float64, np.float64, 0.0)\n        run_test(np.float32, np.float64, 1e-6)\n        run_test(np.float64, np.float32, 1e-6)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"""
tests/test_sparse_binding.py,40,"b'import unittest\nimport sys\nimport os\nimport time\n\nsys.path.append(os.getcwd())\nimport numpy as np\nimport scipy.sparse as sp\nimport numpyeigen_helpers as npe_help\nimport numpyeigen_test as npe_test\n\n\nclass TestSparseMatrixWrapper(unittest.TestCase):\n\n    def test_sparse_matrix_wrapper(self):\n        a = sp.csr_matrix(np.eye(100))\n        b = npe_help.sparse_return(a)\n        self.assertTrue(a is b)\n\n    def test_sparse_matrix_sorting(self):\n        a = sp.random(200, 200)\n        b = a.dot(a)\n        self.assertFalse(b.has_sorted_indices)\n        c = npe_help.sparse_return(b)\n        self.assertTrue(b is c)\n\n    def test_sparse_matrix_binding(self):\n        a = sp.csr_matrix(np.eye(100))\n        b = sp.csr_matrix(np.eye(100))\n        ret = npe_test.sparse_matrix_add(a, b)\n        self.assertEqual(ret.data[0], 2)\n\n    def test_dont_blow_up_memory(self):\n        a = sp.diags([np.ones(1000000)], [0], format=""csr"")\n        b = sp.diags([np.ones(1000000)], [0], format=""csr"")\n        for i in range(10):\n            ret = npe_test.sparse_matrix_add(a, b)\n            self.assertEqual(ret.data[0], 2)\n\n    def test_pass_thru(self):\n        a = sp.csr_matrix(np.eye(100))\n        b = sp.csr_matrix(np.eye(100))\n        ret = npe_test.sparse_matrix_passthru(a, b)\n        self.assertEqual(ret.data[0], 1)\n\n    def test_no_copy(self):\n        a = sp.diags([np.ones(100)], [0], format=""csr"")\n        self.assertEqual(a.data[0], 1.0)\n        ret = npe_test.mutate_sparse_matrix(a)  # Always sets A[0, 0] to 2.0\n        self.assertEqual(ret.data[0], a.data[0])\n        self.assertEqual(a.data[0], 2.0)\n\n    def test_pybind_does_a_copy_for_sparse(self):\n        a = sp.diags([np.ones(100)], [0], format=""csr"")\n        self.assertEqual(a.data[0], 1.0)\n        ret = npe_help.sparse_mutate_copy(a)  # Always sets A[0, 0] to 2.0\n        self.assertEqual(ret, (100, 100))\n        self.assertEqual(a.data[0], 1.0)\n\n    def test_dont_clean_up_if_we_reference_members_of_scipy_matrix(self):\n        a = sp.diags([np.ones(100)], [0], format=""csr"")\n        for i in range(100):\n            b = npe_test.sparse_matrix_add(a, a)\n            bdata = b.data\n            del b\n            # check that bdata is still something reasonable\n            self.assertEqual(bdata.shape, (100,))\n            self.assertEqual(bdata[0], 2.0)\n\n    def test_timing_for_copy_vs_no_copy(self):\n        mat_size = 10000000\n        num_iters = 10\n\n        times_nocopy = []\n        a = sp.diags([np.ones(mat_size)], [0], format=""csr"")\n        for i in range(num_iters):\n            start_time = time.time()\n            npe_test.mutate_sparse_matrix(a)\n            end_time = time.time()\n            times_nocopy.append(end_time-start_time)\n\n        times_copy = []\n        for i in range(num_iters):\n            start_time = time.time()\n            npe_help.sparse_mutate_copy(a)\n            end_time = time.time()\n            times_copy.append(end_time-start_time)\n\n        median_nocopy = np.median(times_nocopy)\n        median_copy = np.median(times_copy)\n\n        print(""test_timing_for_copy_vs_no_copy"")\n        print(""COPY:"")\n        print(""  mean:"", np.mean(times_copy))\n        print(""  std:"", np.std(times_copy))\n        print(""  med:"", np.median(times_copy))\n\n        print(""NOCOPY npe:"")\n        print(""  mean:"", np.mean(times_nocopy))\n        print(""  std:"", np.std(times_nocopy))\n        print(""  med:"", np.median(times_nocopy))\n\n        self.assertLess(median_nocopy*1e-3, median_copy)\n\n    def test_return_does_not_copy(self):\n        mat_size = 10000000\n        num_iters = 10\n\n        times_nocopy = []\n        a = sp.diags([np.ones(mat_size)], [0], format=""csr"")\n        for i in range(num_iters):\n            start_time = time.time()\n            npe_test.mutate_sparse_matrix(a)\n            end_time = time.time()\n            times_nocopy.append(end_time-start_time)\n\n        times_copy = []\n        for i in range(num_iters):\n            start_time = time.time()\n            npe_help.return_sparse_copy(mat_size)\n            end_time = time.time()\n            times_copy.append(end_time-start_time)\n\n        median_nocopy = np.median(times_nocopy)\n        median_copy = np.median(times_copy)\n\n        print(""test_return_does_not_copy"")\n        print(""COPY:"")\n        print(""  mean:"", np.mean(times_copy))\n        print(""  std:"", np.std(times_copy))\n        print(""  med:"", np.median(times_copy))\n\n        print(""NOCOPY pybind22:"")\n        print(""  mean:"", np.mean(times_nocopy))\n        print(""  std:"", np.std(times_nocopy))\n        print(""  med:"", np.median(times_nocopy))\n\n        self.assertLess(median_nocopy*1e3, median_copy)\n\n    def test_sparse_like(self):\n        a = np.eye(100)\n        b1 = sp.diags([np.ones(100)], [0], format=""csr"")\n        b2 = sp.diags([np.ones(100)], [0], format=""csr"", dtype=np.float32)\n        c1 = sp.diags([np.ones(100)], [0], format=""csc"")\n        c2 = sp.diags([np.ones(100)], [0], format=""csc"", dtype=np.float32)\n\n        ret = npe_test.sparse_like_1(a, b1)\n        val = (ret - b1).todense()\n        self.assertEqual(np.linalg.norm(val), 0.0)\n\n        ret = npe_test.sparse_like_2(a, b1, c1)\n        val = (ret - b1).todense()\n        self.assertEqual(np.linalg.norm(val), 0.0)\n        val = (ret - c1).todense()\n        self.assertEqual(np.linalg.norm(val), 0.0)\n\n        ret = npe_test.sparse_like_3(a, b1, c1)\n        val = (ret - b1).todense()\n        self.assertEqual(np.linalg.norm(val), 0.0)\n        val = (ret - c1).todense()\n        self.assertEqual(np.linalg.norm(val), 0.0)\n\n        ret = npe_test.sparse_like_4(b1, b1, c1)\n        val = (ret - b1).todense()\n        self.assertEqual(np.linalg.norm(val), 0.0)\n        val = (ret - c1).todense()\n        self.assertEqual(np.linalg.norm(val), 0.0)\n\n        with self.assertRaises(ValueError):\n            npe_test.sparse_like_1(a, b2)\n        with self.assertRaises(ValueError):\n            npe_test.sparse_like_2(a, b1, c2)\n        with self.assertRaises(ValueError):\n            npe_test.sparse_like_2(a, b2, c1)\n        with self.assertRaises(ValueError):\n            npe_test.sparse_like_2(a, b2, c2)\n        with self.assertRaises(ValueError):\n            npe_test.sparse_like_3(a, b1, c2)\n        with self.assertRaises(ValueError):\n            npe_test.sparse_like_3(a, b2, c1)\n        with self.assertRaises(ValueError):\n            npe_test.sparse_like_3(a, b2, c2)\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
