file_path,api_count,code
competitive/__init__.py,0,b''
environment/__init__.py,0,b''
miscellaneous/__init__.py,0,b''
miscellaneous/maze_print.py,0,"b""import random\n\nU_SYMBOL = '_'\nS_SYMBOL = ' '\nV_SYMBOL = '|'\nB_SYMBOL = '\\n'\n\n\ndef generate_random_maze(rows, columns):\n    dist = [0] * 3 + [1] * 1\n    return [[random.choice(dist) for i in range(columns)] for j in range(rows)]\n\n\ndef stringify_list_2d(list_2d):\n    s = ''\n    for row in list_2d:\n        for column in row:\n            s += str(column) + S_SYMBOL\n        s += B_SYMBOL\n    return s\n\n\ndef stringify_maze(maze):\n    s = ''\n    for i in range(len(maze)):\n        if i == 0:\n            s += S_SYMBOL\n            for j in range(len(maze[i])):\n                s += U_SYMBOL + S_SYMBOL\n            s += B_SYMBOL\n        s += V_SYMBOL\n        for j in range(len(maze[i])):\n            if i == len(maze) - 1 or maze[i][j] != maze[i + 1][j]:\n                s += U_SYMBOL\n            else:\n                s += S_SYMBOL\n            if j == len(maze[i]) - 1 or maze[i][j] != maze[i][j + 1]:\n                s += V_SYMBOL\n            else:\n                s += S_SYMBOL\n        s += B_SYMBOL\n    return s\n\n\ndef print_maze(maze):\n    print(stringify_maze(maze))\n\n\ndef print_list_2d(list_2d):\n    print(stringify_list_2d(list_2d))\n\n\nif __name__ == '__main__':\n    rows = 20\n    columns = 30\n    maze = generate_random_maze(rows, columns)\n    print_list_2d(maze)\n    print_maze(maze)\n"""
miscellaneous/wolframExample.py,0,"b'""""""\nAuthor: Sergio Garcia Prado\n        www.garciparedes.me\n""""""\n\nimport wolframalpha\n\nclient = wolframalpha.Client("""")\n\noperation = input(""Indique la operacion: "")\n\nres = client.query(operation)\nprint(next(res.results).text)\n'"
numerical/__init__.py,0,b''
text/__init__.py,0,b''
utils/json.py,0,"b'#!/usr/bin/env python3\n\n__author__ = ""Sergio Garcia Prado""\n__license__ = ""MPL-2.0""\n__version__ = ""1.0.0""\n__maintainer__ = ""Sergio Garcia Prado""\n__email__ = ""sergio@garciparedes.me""\n\nimport json\n\n\ndef dict_to_json(dict_data):\n    return json.dumps(dict_data, indent=2, sort_keys=True)\n'"
visualization/__init__.py,0,b''
web/__init__.py,0,b''
competitive/other/__init__.py,0,b''
competitive/other/backup_discs.py,0,"b""from itertools import combinations\nfrom typing import List, Tuple, Generator\n\n\ndef packs(elements: List[float], bin_size: float) -> Generator[List[float], None, None]:\n    elements = sorted(elements)\n    for s in reversed(range(1, len(elements) + 1)):\n        for group in combinations(elements, s):\n            if bin_size < sum(group):\n                break\n            yield group\n\n\ndef improves_result(best: List[float], new: List[float]) -> bool:\n    if len(best) < len(new):\n        return True\n    if len(best) == len(new) and sum(best) < sum(new):\n        return True\n    return False\n\n\ndef planificar(elements: List[float], bins: int, bin_size: float) -> List[Tuple[float]]:\n    result = list()\n\n    while elements and len(result) < bins:\n        best_group = tuple()\n        for group in packs(elements, bin_size):\n            if not improves_result(best_group, group):\n                continue\n            best_group = group\n\n            if sum(best_group) == bin_size:\n                break\n\n        result.append(best_group)\n        for v in best_group:\n            elements.remove(v)\n\n    return result\n\n\ndef main():\n    result = planificar([10, 15, 20, 5], 2, 25)\n    print(result)\n\n    mark = sum(len(group) for group in result)\n    print(mark)\n\n\nif __name__ == '__main__':\n    main()\n"""
competitive/other/maze_solver.py,0,"b""from itertools import chain\nfrom typing import Tuple, Sequence, List, Set\n\nPath = Sequence[Tuple[int, int]]\n\n\ndef maze_solver(edges: Set[Tuple[int, int]], start_node: int, end_node: int, path: Path = tuple()) -> Path:\n    if end_node in chain(*path):\n        return path\n\n    best_path = None\n    for current_edge in set(edge for edge in edges if start_node in edge):\n\n        current_start = current_edge[0] if current_edge[1] == start_node else current_edge[1]\n        current_nodes = set(chain(*path))\n        current_edges = set(edge for edge in edges if not current_nodes.intersection(edge))\n        current_path = (*path, current_edge)\n\n        new_path = maze_solver(current_edges, current_start, end_node, current_path)\n\n        if new_path is None:\n            continue\n        if end_node not in chain(*new_path):\n            continue\n        if best_path is not None and not len(new_path) < len(best_path):\n            continue\n\n        best_path = new_path\n\n    return best_path\n\n\ndef main() -> None:\n    graph = {\n        (0, 1),\n        (1, 2),\n        (2, 3),\n        (1, 3),\n    }\n\n    solution = maze_solver(graph, 3, 0)\n    print(solution)\n\n\nif __name__ == '__main__':\n    main()\n"""
competitive/t3chfest/__init__.py,0,b''
environment/containerizing/__init__.py,0,b''
environment/logging/__init__.py,0,b''
environment/logging/dynamic_handler.py,0,"b'import os\nimport logging\n\nfrom typing import List\nfrom io import StringIO\n\nlogger = logging.getLogger(__name__)\n\n\nclass DynamicHandler(logging.StreamHandler):\n    def __init__(self):\n        super().__init__(stream=StringIO())\n        self.level = logging.INFO\n        self.formatter = logging.Formatter(\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\')\n\n    def activate(self, target: logging.Logger = logging.getLogger()) -> None:\n        target.setLevel(logging.DEBUG)  # ""Necessary"" condition.\n        target.addHandler(self)\n\n    def deactivate(self, target: logging.Logger = logging.getLogger()) -> None:\n        target.removeHandler(self)\n        self.flush()\n\n    @property\n    def rows(self) -> List[str]:\n        stream = self.stream\n        stream.seek(os.SEEK_SET)\n        results = stream.readlines()\n        stream.seek(os.SEEK_END)\n        results = [row.strip() for row in results]\n        return results\n\n\ndef function():\n    logger.info(\'Starting info message...\')\n    logger.debug(\'Starting debug message...\')\n    # loggable business logic...\n    logger.info(\'Completed info message.\')\n    logger.debug(\'Completed debug message.\')\n\n\ndef main():\n    handler = DynamicHandler()\n\n    logger.info(\'A info message.\')\n    logger.debug(\'A debug message.\')\n\n    handler.activate()\n    function()\n    handler.deactivate()\n\n    logger.info(\'Another info message.\')\n    logger.debug(\'Another debug message.\')\n\n    print(f\'Handler results:\\n{handler.rows}\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
environment/scripting/torrent_crawler.py,0,"b'#!/usr/bin/env python3\n\nimport urllib.request as req\nimport re\nimport os\nfrom pathlib import Path\n\n\ndef main():\n    url = input().strip()\n    path = Path(input().strip())\n    opener = req.build_opener()\n    opener.addheaders = [(\'User-agent\', \'Mozilla/5.0\')]\n    req.install_opener(opener)\n    page = req.urlopen(url).read().decode(\'utf-8\')\n    links = re.findall(r\'""([^""]+\\.torrent)""\', page)\n    for i, url in enumerate(links):\n        file_name = ""torrent_"" + str(i) + "".torrent""\n        req.urlretrieve(url, path / file_name)\n        print(url)\n\nif __name__ == \'__main__\':\n    main()\n'"
iot/pybluez/initial-example.py,0,"b'\'\'\'\n    URL: https://github.com/karulis/pybluez/blob/master/examples/simple/inquiry.py\n\'\'\'\n\n# simple inquiry example\nimport bluetooth\n\nnearby_devices = bluetooth.discover_devices(lookup_names=True)\nprint(""found %d devices"" % len(nearby_devices))\n\nfor addr, name in nearby_devices:\n    print(""  %s - %s"" % (addr, name))'"
miscellaneous/hello_worlds/3dplot.py,0,"b""'''\n\nAuthor: Gabriel\n        http://stackoverflow.com/users/1391441/gabriel\n\n        Chinmay Kanchi\n        http://stackoverflow.com/users/148765/chinmay-kanchi\n\nExample from stackoverflow of matplotlib\n        http://stackoverflow.com/a/1986020/3921457\n\n'''\n\nfrom matplotlib import pyplot\nimport pylab\nfrom mpl_toolkits.mplot3d import Axes3D\nimport random\n\n\nfig = pylab.figure()\nax = Axes3D(fig)\n\nsequence_containing_x_vals = list(range(0,100))\nsequence_containing_y_vals = list(range(0,100))\nsequence_containing_z_vals = list(range(0,100))\n\nrandom.shuffle(sequence_containing_x_vals)\nrandom.shuffle(sequence_containing_y_vals)\nrandom.shuffle(sequence_containing_z_vals)\n\n#ax.scatter(sequence_containing_x_vals, sequence_containing_y_vals, sequence_containing_z_vals)\n\nax.scatter(2,3,3,'z', 100,'y')\nax.scatter(2,5,3,'z', 100, 'r')\nax.scatter(100,100,100,'z', 100, 'r')\n\npyplot.show()\n"""
miscellaneous/hello_worlds/__init__.py,0,b''
miscellaneous/hello_worlds/bucles.py,0,"b'a = 5\nwhile a > 0:\n    print(""Hola"")\n    a -= 1\n'"
miscellaneous/hello_worlds/bucles1.py,0,"b'\xef\xbb\xbfr = [1,2,3,4,5,6]\n\nfor i in r:\n\tprint(i)\n\nl = r[1 : 4]\nfor i in l:\n\tprint(i)'"
miscellaneous/hello_worlds/control.py,0,"b'\xef\xbb\xbfa = int (raw_input( ))\n\n#Escribe ""Es un n\xc3\xbamero""\nprint ""Es un numero""\n\nif a >= 5 :\n\tprint ""Mayor""\n\tprint ""o igual que 5""\nelse:\n\tprint ""Menor que 5""'"
miscellaneous/hello_worlds/control1.py,0,"b'mes = int (raw_input())\n\nif mes == 1:\n\tprint(""enero"")\n\nelif mes ==2:\n\tprint(""febrero"")\n\nelif mes == 3:\n\tprint(""marzo"")\nelse:\n\tprint(""otro mes"")'"
miscellaneous/hello_worlds/edad.py,0,"b'edad = 0\n\nwhile edad < 18:\n    edad += 1\n    print(""Felicidades, tienes "", str(edad))\n'"
miscellaneous/hello_worlds/entrada.py,0,"b'from pip._vendor.distlib.compat import raw_input\n\na = raw_input();\nprint(a)\nprint(type(a))\ntry:\n    a = int(a)\n    print(type(a))\n    print(a)\nexcept:\n    print(""No era el numero"")\n'"
miscellaneous/hello_worlds/euclides.py,0,"b'""""""\nAuthor: Sergio Garcia Prado\n        www.garciparedes.me\n\nExample of Euclides Algorithm.\n""""""\n\nfrom pip._vendor.distlib.compat import raw_input\n\n\ndef euclides(m, n):\n    while (m > 0):\n        t = m\n        m = n % m\n        n = t\n    return n\n\n\ndef main():\n    print(""GCD Euclides Algorithm."")\n\n    numA = raw_input(""Number A: "")\n    numB = raw_input(""Number B: "")\n\n    print(""GCD of %s and %s is  %s"" % (numA, numB, euclides(3, 6)))\n\n\nif __name__ == ""__main__"":\n    main()\n'"
miscellaneous/hello_worlds/fibonacci.py,0,"b'""""""\nAuthor: Sergio Garcia Prado\n        www.garciparedes.me\n\nFibonacci example implemented recursive and Iterative mind.\n""""""\n\nimport time\n\nfrom pip._vendor.distlib.compat import raw_input\n\n""""""                            Funtions                            """"""\n\n""""""\nRecursive Version\n""""""\n\n\ndef recursiveFib(n):\n    if (n < 2):\n        return n\n    else:\n        return (recursiveFib(n - 1) + recursiveFib(n - 2))\n\n\n""""""\nIterative Version\n""""""\n\n\ndef iterativeFib(n):\n    i = 1\n    j = 0\n    for k in range(n):\n        j = i + j\n        i = j - i\n    return j\n\n\n""""""                            MAIN                            """"""\n\nprint(""""""Fibonacci Example"""""")\n\nnumber = int(raw_input(""Insert Integer Number: ""))\nprint(\'\')\nprint(""""""Iterative Version"""""")\nstart = time.time()\nprint(iterativeFib(number))\nprint(""it took"", time.time() - start, ""seconds."")\n\nprint(\'\')\n\nprint(""""""Recursive Version"""""")\nstart = time.time()\nprint(recursiveFib(number))\nprint(""it took"", time.time() - start, ""seconds."")\n'"
miscellaneous/hello_worlds/funcion.py,0,"b'\xef\xbb\xbfdef f(p, *otros):\n    """"""Esta funci\xc3\xb3n imprime en pantalla\n    el primer valor, el los siguientes en forma de Tupla\n    y la tupla separada.""""""\n\n    print(""Numero"")\n    print(p)\n\n    print(""Tupla junta"")\n    print(otros)\n\n    print(""Tupla separada"")\n    for i in otros:\n        print(i)\n\n\nf(8)\nf(8, 1)\nf(8, 1, 2)\nf(8, 1, 2, 3)\n\n\ndef sumar(x, y):\n    # Suma dos n\xc3\xbameros y los devuelve como una funci\xc3\xb3n\n    return x + y\n\n\nsuma = sumar(3, 4)\nprint(suma)\n'"
miscellaneous/hello_worlds/matrixExample.py,0,"b'""""""\nAuthor: Sergio Garcia Prado\n        www.garciparedes.me\n""""""\n\nfrom random import randint\n\ndimension = 30\n\nmatrix = [[0 for x in range(dimension)] for x in range(dimension)]\n\nfor i in range(len(matrix)):\n    linea = """"\n    for j in range(len(matrix[i])):\n        matrix[i][j] = randint(0, 1)\n        linea += str(matrix[i][j])\n    print(linea)\n'"
miscellaneous/hello_worlds/prueba.py,0,"b'\xef\xbb\xbf###Programa que imprima los 25 primeros numeros naturales\nprint(""Me llamo Sergio Garc\xc3\xada"")\nn = 1\nwhile n <= 25: \n    print(n)\n    n += 1'"
miscellaneous/hello_worlds/sesion_1_1.py,0,"b'mat = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nvalor = mat[0][1]\nlinea = mat[0]\nprint(valor)\nprint(linea)\n'"
numerical/arrow/__init__.py,0,b''
numerical/arrow/hello_world.py,0,"b""import logging\n\nimport pandas as pd\nfrom pathlib import Path\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nCSV_FILE_PATH = Path(__file__).parents[1] / 'data.csv'\nPARQUET_FILE_PATH = Path(__file__).parents[1] / 'data.parquet'\n\n\ndef main():\n    logger.info(f'Starting...')\n\n    file_path = Path(CSV_FILE_PATH)\n    df = pd.DataFrame({'a': [1, 2, 3, 4, 5], 'b': [6, 7, 8, 9, 10]})\n    df.to_parquet(file_path)\n\n    df = pd.read_parquet(file_path)\n    logger.info(df)\n\n    logger.info(f'Finished!')\n\n\nif __name__ == '__main__':\n    main()\n"""
numerical/arrow/modin_read.py,0,"b""import logging\n\nimport modin.pandas as pd\nfrom ..utils import (\n    PARQUET_FILE_PATH,\n)\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\ndef main():\n    logger.info(f'Starting...')\n\n    logger.info(f'Parquet Stored Size: {PARQUET_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB')\n\n    df = pd.read_parquet(PARQUET_FILE_PATH)\n    logger.info(f'In memory Size: {df.memory_usage(deep=True).sum() / 1024 ** 3:.3f} GB')\n\n    logger.info(f'Finished!')\n\n\nif __name__ == '__main__':\n    main()\n"""
numerical/arrow/pandas_read.py,0,"b""import logging\n\nimport pandas as pd\nfrom pathlib import Path\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nPARQUET_FILE_PATH = Path(__file__).parents[1] / 'data.parquet'\n\n\ndef main():\n    logger.info(f'Starting...')\n\n    logger.info(f'Parquet Stored Size: {PARQUET_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB')\n\n    df = pd.read_parquet(PARQUET_FILE_PATH)\n    logger.info(f'In memory Size: {df.memory_usage(deep=True).sum() / 1024 ** 3:.3f} GB')\n\n    logger.info(f'Finished!')\n\n\nif __name__ == '__main__':\n    main()\n"""
numerical/data_science/__init__.py,0,b''
numerical/data_science/cumlist.py,0,"b""import pandas as pd\n\n\ndef main():\n    base = pd.DataFrame({\n        'value': ['hola', 'adios', 'lalala', 'hasta luego'],\n        'flag': [False, True, True, True],\n        'label': ['A', 'A', 'B', 'B']\n    })\n    base['value'] = base['value'].apply(lambda value: [value])\n    base['index'] = base.index\n\n    transformed = base.groupby('label').apply(lambda df: df['value'][df['flag']].cumsum()).reset_index()\n\n    result = base.drop(columns={'value'}).merge(\n        transformed.drop(columns={'label'}),\n        left_on='index',\n        right_on='level_1',\n        how='left',\n    )\n    result = result.drop(columns={'index', 'level_1'})\n    result['value'] = result['value'].apply(lambda value: value if isinstance(value, list) else [])\n    print(result)\n\n\nif __name__ == '__main__':\n    main()\n"""
numerical/data_science/logic_function_tree_learning.py,0,"b""from numerical.data_science.res import DataSets as ds\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\n\n\ndef learn_function(a, b, c, d, e):\n    return bool(not (a and b) or not (c and d)) != bool(e)\n\n\nif __name__ == '__main__':\n    np_data = ds.generate_from_logic_method(learn_function).data\n    clf = tree.DecisionTreeClassifier()\n\n    X_train, X_test, y_train, y_test = train_test_split(np_data[:,:-1],np_data[:,-1], test_size=0.33,\n                                                        random_state=42)\n    clf = DecisionTreeClassifier()\n    clf = clf.fit(X_train, y_train)\n"""
numerical/data_science/weka_relative_error.py,0,"b'#!/usr/bin/env python3\n\nimport sys\nimport pandas as pd\n\n\nif __name__ == ""__main__"":\n    file_name = sys.argv[1]\n    error_ratio_list = [float(i) for i in sys.argv[2:]]\n    file_error = pd.read_csv(file_name)\n\n    for error_ratio in error_ratio_list:\n        error_count = (file_error[\'error\'].abs() / file_error[\'actual\']<= error_ratio).sum()\n        print(\'Max Rel. Error: \' + str(error_ratio) + \'\\t-> Error Ratio:\\t\'  + str(1 - error_count / float(file_error.shape[0])))\n'"
numerical/math/interpreter.py,0,b'#!/usr/bin/env python3\n\nimport numpy as np\nimport math\nfrom matplotlib import pyplot as plt\nfrom sympy import *\n\n# Code Here\n'
numerical/math/template.py,0,"b""#!/usr/bin/env python3\n\nimport numpy as np\nimport math\nfrom matplotlib import pyplot as plt\nfrom sympy import *\n\n\ndef main() -> None:\n\n    # Code Here\n\n    pass\n\nif __name__ == '__main__':\n    main()\n"""
numerical/modin/__init__.py,0,b''
numerical/modin/hello_world.py,1,"b""import modin.pandas as pd\nimport numpy as np\n\n\ndef main():\n    frame_data = np.random.randint(0, 100, size=(2 ** 10, 2 ** 8))\n    df = pd.DataFrame(frame_data)\n    print(df.mean())\n\n\nif __name__ == '__main__':\n    main()\n"""
numerical/modin/multi_file_dataset.py,0,"b'from datetime import datetime\nfrom pathlib import Path\n\nimport modin.pandas as pd\n\n\ndef main():\n    directory_path = Path(\'data/\')\n    pattern = \'*.csv\'\n\n    start = datetime.now()\n\n    df = pd.concat(\n        (file_to_dataframe(file_path) for file_path in directory_path.glob(pattern)),\n        sort=False,\n        copy=False,\n    )\n\n    end = datetime.now()\n\n    print(f\'Units mean: ""{df[""KWMENG_C""].mean()}""\')\n    print(f\'Elapsed ""{end - start}"" seconds\')\n\n\ndef file_to_dataframe(file_path: Path) -> pd.DataFrame:\n    print(f\'Reading ""{file_path}""...\')\n    return pd.read_csv(file_path, sep=\'|\', decimal=\',\', encoding=\'latin-1\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/tensorflow/__init__.py,0,b''
numerical/tensorflow/hello_world.py,0,"b'import tensorflow as tf\n\n\ndef main():\n    node1 = tf.constant(3.0, tf.float32)\n    node2 = tf.constant(4.0)  # also tf.float32 implicitly\n    print(node1, node2)\n\n    sess = tf.Session()\n    print(sess.run([node1, node2]))\n\n    node3 = tf.add(node1, node2)\n    print(""node3: "", node3)\n    print(""sess.run(node3): "", sess.run(node3))\n\n    a = tf.placeholder(tf.float32)\n    b = tf.placeholder(tf.float32)\n    adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n    print(sess.run(adder_node, {a: 3, b: 4.5}))\n    print(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))\n\n    add_and_triple = adder_node * 3.\n    print(sess.run(add_and_triple, {a: 3, b: 4.5}))\n\n    W = tf.Variable([.3], tf.float32)\n    b = tf.Variable([-.3], tf.float32)\n    x = tf.placeholder(tf.float32)\n    linear_model = W * x + b\n\n    init = tf.global_variables_initializer()\n    sess.run(init)\n\n    print(sess.run(linear_model, {x: [1, 2, 3, 4]}))\n\n    y = tf.placeholder(tf.float32)\n    squared_deltas = tf.square(linear_model - y)\n    loss = tf.reduce_sum(squared_deltas)\n    print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n\n    fixW = tf.assign(W, [-1.])\n    fixb = tf.assign(b, [1.])\n    sess.run([fixW, fixb])\n    print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/tensorflow/naive_pagerank.py,0,"b'import tensorflow as tf\n\n\ndef main():\n    a_raw = [\n        [0.0, 0.0, 1.0, 1.0],\n        [1.0, 0.0, 0.0, 0.0],\n        [1.0, 1.0, 0.0, 1.0],\n        [1.0, 1.0, 0.0, 0.0]\n    ]\n\n    v_raw = [\n        [0.25],\n        [0.25],\n        [0.25],\n        [0.25]\n    ]\n    steps = 7\n\n    a = tf.Variable(a_raw, tf.float32)\n    v = tf.Variable(v_raw, tf.float32)\n\n    transition = tf.div(a, tf.reduce_sum(a, 0))\n    page_rank = tf.matmul(transition, v)\n\n    run_iteration = tf.assign(v, page_rank)\n\n    init = tf.global_variables_initializer()\n    with tf.Session() as sess:\n        sess.run(init)\n\n        for step in range(steps):\n            print(""Iteration: "" + str(step))\n            print(sess.run(run_iteration))\n\n        tf.summary.FileWriter(\'logs/.\', sess.graph)\n        pass\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/tensorflow/pagerank.py,0,"b""import tensorflow as tf\n\n\ndef main():\n    a_raw = [\n        [0.0, 0.0, 1.0, 1.0],\n        [1.0, 0.0, 0.0, 0.0],\n        [1.0, 1.0, 0.0, 1.0],\n        [1.0, 1.0, 0.0, 0.0]\n    ]\n    beta = 0.85\n    steps = 7\n\n    a = tf.Variable(a_raw, tf.float32)\n    n = int(a.get_shape()[0])\n\n    v = tf.Variable(tf.fill([n, 1], 1 / n), tf.float32)\n\n    o_degree = tf.reduce_sum(a, 0)\n\n    condition = tf.not_equal(o_degree, 0)\n\n    transition = tf.transpose(\n        tf.where(condition,\n                 tf.transpose(beta * tf.div(a, o_degree) + (1 - beta) / n),\n                 tf.fill([n, n], 1 / n)))\n\n    page_rank = tf.matmul(transition, v)\n\n    run_iteration = tf.assign(v, page_rank)\n\n    init = tf.global_variables_initializer()\n    with tf.Session() as sess:\n        sess.run(init)\n        print(sess.run(transition))\n\n        for step in range(steps):\n            sess.run(run_iteration)\n\n        print(sess.run(v))\n\n        tf.summary.FileWriter('logs/.', sess.graph)\n        pass\n\n\nif __name__ == '__main__':\n    main()\n"""
numerical/tensorflow/pagerank_wiki_vote.py,2,"b'import tensorflow as tf\nimport numpy as np\nfrom numerical.data_science.res import DataSets\n\n\ndef ranked(x):\n    # x will be a numpy array with the contents of the placeholder below\n    return np.argsort(x, axis=0)\n\n\ndef main():\n    steps = 20\n\n    data_set = DataSets.get_wiki_vote()\n    data_set -= 1\n    n_raw = data_set.max(axis=0).max() + 1\n\n    beta = tf.constant(0.85, tf.float32, name=""Beta"")\n    n = tf.constant(n_raw, tf.float32, name=""NodeCounts"")\n\n    a = tf.Variable(tf.transpose(\n        tf.scatter_nd(data_set.values.tolist(), data_set.shape[0] * [1.0],\n                      [n_raw, n_raw])), tf.float64, name=""AdjacencyMatrix"")\n\n    v = tf.Variable(tf.fill([n_raw, 1], tf.pow(n, -1)), name=""PageRankVector"")\n\n    o_degree = tf.reduce_sum(a, 0)\n\n    condition = tf.not_equal(o_degree, 0)\n\n    transition = tf.transpose(\n        tf.where(condition,\n                 tf.transpose(beta * tf.div(a, o_degree) + (1 - beta) / n),\n                 tf.fill([n_raw, n_raw], tf.pow(n, -1))))\n\n    page_rank = tf.matmul(transition, v, a_is_sparse=True)\n\n    run_iteration = tf.assign(v, page_rank)\n\n    ranks = tf.transpose(tf.py_func(ranked, [-v], tf.int64))[0]\n    init = tf.global_variables_initializer()\n    with tf.Session() as sess:\n        sess.run(init)\n\n        for step in range(steps):\n            sess.run(run_iteration)\n\n        print(sess.run(v))\n        print(sess.run(ranks))\n        np.savetxt(\'logs/test.csv\', sess.run(ranks), fmt=\'%i\')\n        tf.summary.FileWriter(\'logs/.\', sess.graph)\n        pass\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/tensorflow/sparse_from_file.py,0,"b""import tensorflow as tf\n\nfrom numerical.data_science.res import DataSets\n\n\ndef main():\n    data_set = DataSets.get_followers() - 1\n    n = data_set.max(axis=0).max() + 1\n\n    init = tf.global_variables_initializer()\n    with tf.Session() as sess:\n        sess.run(init)\n        print(sess.run(\n            tf.scatter_nd(data_set.values.tolist(), data_set.shape[0] * [1.0],\n                          [n, n])))\n\n\nif __name__ == '__main__':\n    main()\n"""
numerical/utils/__init__.py,0,"b'from .constants import (\n    PARQUET_FILE_PATH,\n    HDF_FILE_PATH,\n    COLUMNAR_HDF_FILE_PATH,\n    ARROW_FILE_PATH,\n    CSV_FILE_PATH,\n    SQLITE_FILE_PATH,\n    DIRECTORY_PATH,\n    TMP_PATH,\n    CHUNK_SIZE,\n)\n'"
numerical/utils/constants.py,0,"b""from pathlib import Path\n\nDIRECTORY_PATH = Path(__file__).parents[1]\n\nCSV_FILE_PATH = DIRECTORY_PATH / 'data.csv'\nPARQUET_FILE_PATH = DIRECTORY_PATH / 'data.parquet'\nARROW_FILE_PATH = DIRECTORY_PATH / 'data.arrow'\nSQLITE_FILE_PATH = DIRECTORY_PATH / 'data.sqlite'\nHDF_FILE_PATH = DIRECTORY_PATH / 'data.hdf5'\nCOLUMNAR_HDF_FILE_PATH = DIRECTORY_PATH / 'data-columnar.hdf5'\n\nTMP_PATH = DIRECTORY_PATH / 'tmp'\n\nCHUNK_SIZE = 100_000\nTABLE_NAME = 'data'\n"""
numerical/utils/csv_to_hdf.py,0,"b'import logging\nimport pandas as pd\n\nfrom numerical.utils.constants import (\n    CSV_FILE_PATH,\n    HDF_FILE_PATH,\n    CHUNK_SIZE,\n    TABLE_NAME,\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef csv_to_hdf():\n    logger.info(f\'Starting...\')\n\n    logger.info(f\'CSV Stored Size: {CSV_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB\')\n\n    if HDF_FILE_PATH.exists():\n        HDF_FILE_PATH.unlink()\n\n    stream = pd.read_csv(\n        CSV_FILE_PATH,\n        chunksize=CHUNK_SIZE,\n        low_memory=False,\n        sep=\',\',\n        encoding=\'latin-1\',\n    )\n    for i, chunk in enumerate(stream, 1):\n        print(f\'{i}-th iteration\\tInserting ""{len(chunk)}"" rows on ""{TABLE_NAME}""...\')\n        chunk.to_hdf(HDF_FILE_PATH, TABLE_NAME)\n\n    logger.info(f\'HDF Stored Size: {HDF_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB\')\n\n    logger.info(f\'Finished!\')\n\n\ndef main():\n    logging.basicConfig(level=logging.INFO)\n\n    csv_to_hdf()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/utils/csv_to_parquet.py,0,"b'"""""" From: \'https://stackoverflow.com/a/45618618/3921457\' """"""\nimport logging\n\nimport pandas as pd\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\nfrom numerical.utils.constants import (\n    CSV_FILE_PATH,\n    PARQUET_FILE_PATH,\n    CHUNK_SIZE,\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef csv_to_parquet():\n    logger.info(f\'Starting...\')\n\n    stream = pd.read_csv(\n        CSV_FILE_PATH,\n        chunksize=CHUNK_SIZE,\n        low_memory=False,\n        sep=\',\',\n        encoding=\'latin-1\',\n    )\n\n    logger.info(f\'CSV Stored Size: {CSV_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB\')\n\n    chunk = next(stream)\n    logger.debug(f\'Processing 1-th chunk...\')\n    parquet_schema = pa.Table.from_pandas(chunk).schema\n    parquet_writer = pq.ParquetWriter(PARQUET_FILE_PATH, parquet_schema, compression=\'snappy\')\n\n    for i, chunk in enumerate(stream, 2):\n        logger.debug(f\'Processing {i}-th chunk...\')\n        table = pa.Table.from_pandas(chunk, parquet_schema)\n        parquet_writer.write_table(table)\n\n    parquet_writer.close()\n\n    logger.info(f\'Parquet Stored Size: {PARQUET_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB\')\n\n    logger.info(f\'Finished!\')\n\n\ndef main():\n    logging.basicConfig(level=logging.INFO)\n\n    csv_to_parquet()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/utils/csv_to_sqlite.py,0,"b'import logging\nimport sqlite3\nimport pandas as pd\n\nfrom numerical.utils.constants import (\n    CSV_FILE_PATH,\n    SQLITE_FILE_PATH,\n    CHUNK_SIZE,\n    TABLE_NAME\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef csv_to_sqlite():\n    logger.info(f\'Starting...\')\n\n    logger.info(f\'CSV Stored Size: {CSV_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB\')\n\n    connection = sqlite3.connect(SQLITE_FILE_PATH)\n\n    logger.info(f\'Dropping ""{TABLE_NAME}"" table...\')\n    connection.execute(f\'DROP TABLE IF EXISTS {TABLE_NAME};\')\n\n    stream = pd.read_csv(\n        CSV_FILE_PATH,\n        chunksize=CHUNK_SIZE,\n        low_memory=False,\n        sep=\',\',\n        encoding=\'latin-1\',\n    )\n    for i, chunk in enumerate(stream, 1):\n        logger.info(f\'{i}-th iteration\\tInserting ""{len(chunk)}"" rows on ""{TABLE_NAME}""...\')\n        chunk.to_sql(TABLE_NAME, connection, if_exists=\'append\', chunksize=10_000)\n\n\n    logger.info(f\'SQLITE Stored Size: {SQLITE_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB\')\n\n    logger.info(f\'Finished!\')\n\n\ndef main():\n    logging.basicConfig(level=logging.INFO)\n    csv_to_sqlite()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/vaex/__init__.py,0,b''
numerical/vaex/csv_to_arrow.py,0,"b""import logging\n\nimport vaex\n\nfrom numerical.utils.constants import (\n    CSV_FILE_PATH,\n    ARROW_FILE_PATH,\n    HDF_FILE_PATH,\n)\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\ndef main():\n    logger.info(f'Starting...')\n\n    logger.info(f'CSV Stored Size: {CSV_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB')\n\n    df = vaex.open(str(CSV_FILE_PATH), convert=str(HDF_FILE_PATH))\n    logger.info(f'HDF5 Stored Size: {HDF_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB')\n\n    df.export(str(ARROW_FILE_PATH))\n    logger.info(f'ARROW Stored Size: {ARROW_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB')\n\n    logger.info(f'Finished!')\n\n\nif __name__ == '__main__':\n    main()\n"""
numerical/vaex/csv_to_columnar_hdf.py,0,"b'from shutil import rmtree\n\nimport pandas as pd\n\nimport vaex\n\nfrom numerical.utils import (\n    CSV_FILE_PATH,\n    CHUNK_SIZE,\n    COLUMNAR_HDF_FILE_PATH,\n    TMP_PATH,\n)\n\n\ndef main():\n    print(f\'HDF5 Stored Size: {CSV_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB\')\n\n    stream = pd.read_csv(\n        CSV_FILE_PATH,\n        chunksize=CHUNK_SIZE,\n        low_memory=False,\n        sep=\',\',\n        encoding=\'latin-1\',\n    )\n    TMP_PATH.mkdir(parents=True, exist_ok=True)\n    for i, chunk in enumerate(stream):\n        print(f\'Processing {i + 1}-th chunk containing ""{len(chunk)}"" rows of data...\')\n        df_chunk = vaex.from_pandas(chunk, copy_index=False)\n        export_path = TMP_PATH / f\'part_{i}.hdf5\'\n        df_chunk.export_hdf5(str(export_path))\n\n    df = vaex.open(str(TMP_PATH / \'part*\'))\n\n    df.export_hdf5(str(COLUMNAR_HDF_FILE_PATH))\n    print(f\'HDF5 Stored Size: {COLUMNAR_HDF_FILE_PATH.stat().st_size / 1024 ** 3:.3f} GB\')\n\n    rmtree(TMP_PATH)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
operations_research/ortools/introduction.py,0,"b""from ortools.linear_solver.pywraplp import Solver\n\n\ndef main():\n    # Create the linear solver with the GLOP backend.\n    solver = Solver('simple_lp_program', Solver.GLOP_LINEAR_PROGRAMMING)\n\n    # Create the variables x and y.\n    x = solver.NumVar(0, 1, 'x')\n    y = solver.NumVar(0, 2, 'y')\n\n    print('Number of variables =', solver.NumVariables())\n\n    # Create a linear constraint, 0 <= x + y <= 2.\n    ct = solver.Constraint(0, 2, 'ct')\n    ct.SetCoefficient(x, 1)\n    ct.SetCoefficient(y, 1)\n\n    print('Number of constraints =', solver.NumConstraints())\n\n    # Create the objective function, 3 * x + y.\n    objective = solver.Objective()\n    objective.SetCoefficient(x, 3)\n    objective.SetCoefficient(y, 1)\n    objective.SetMaximization()\n\n    solver.Solve()\n\n    print('Solution:')\n    print('Objective value =', objective.Value())\n    print('x =', x.solution_value())\n    print('y =', y.solution_value())\n\n\nif __name__ == '__main__':\n    main()\n"""
operations_research/ortools/pickup_and_delivery.py,0,"b'""""""Simple Pickup Delivery Problem (PDP).""""""\n\nfrom ortools.constraint_solver import (\n    routing_enums_pb2,\n    pywrapcp,\n)\n\n\ndef create_data_model():\n    """"""Stores the data for the problem.""""""\n    data = dict()\n    data[\'distance_matrix\'] = [\n        [0, 548, 776, 696, 582, 274, 502, 194, 308, 194, 536, 502, 388, 354, 468, 776, 662],\n        [548, 0, 684, 308, 194, 502, 730, 354, 696, 742, 1084, 594, 480, 674, 1016, 868, 1210],\n        [776, 684, 0, 992, 878, 502, 274, 810, 468, 742, 400, 1278, 1164, 1130, 788, 1552, 754],\n        [696, 308, 992, 0, 114, 650, 878, 502, 844, 890, 1232, 514, 628, 822, 1164, 560, 1358],\n        [582, 194, 878, 114, 0, 536, 764, 388, 730, 776, 1118, 400, 514, 708, 1050, 674, 1244],\n        [274, 502, 502, 650, 536, 0, 228, 308, 194, 240, 582, 776, 662, 628, 514, 1050, 708],\n        [502, 730, 274, 878, 764, 228, 0, 536, 194, 468, 354, 1004, 890, 856, 514, 1278, 480],\n        [194, 354, 810, 502, 388, 308, 536, 0, 342, 388, 730, 468, 354, 320, 662, 742, 856],\n        [308, 696, 468, 844, 730, 194, 194, 342, 0, 274, 388, 810, 696, 662, 320, 1084, 514],\n        [194, 742, 742, 890, 776, 240, 468, 388, 274, 0, 342, 536, 422, 388, 274, 810, 468],\n        [536, 1084, 400, 1232, 1118, 582, 354, 730, 388, 342, 0, 878, 764, 730, 388, 1152, 354],\n        [502, 594, 1278, 514, 400, 776, 1004, 468, 810, 536, 878, 0, 114, 308, 650, 274, 844],\n        [388, 480, 1164, 628, 514, 662, 890, 354, 696, 422, 764, 114, 0, 194, 536, 388, 730],\n        [354, 674, 1130, 822, 708, 628, 856, 320, 662, 388, 730, 308, 194, 0, 342, 422, 536],\n        [468, 1016, 788, 1164, 1050, 514, 514, 662, 320, 274, 388, 650, 536, 342, 0, 764, 194],\n        [776, 868, 1552, 560, 674, 1050, 1278, 742, 1084, 810, 1152, 274, 388, 422, 764, 0, 798],\n        [662, 1210, 754, 1358, 1244, 708, 480, 856, 514, 468, 354, 844, 730, 536, 194, 798, 0],\n    ]\n    data[\'pickups_deliveries\'] = [\n        [1, 6],\n        [2, 10],\n        [4, 3],\n        [5, 9],\n        [7, 8],\n        [15, 11],\n        [13, 12],\n        [16, 14],\n    ]\n    data[\'num_vehicles\'] = 4\n    data[\'depot\'] = 0\n    return data\n\n\ndef print_solution(data, manager, routing, assignment):\n    """"""Prints assignment on console.""""""\n    total_distance = 0\n    for vehicle_id in range(data[\'num_vehicles\']):\n        index = routing.Start(vehicle_id)\n        plan_output = \'Route for vehicle {}:\\n\'.format(vehicle_id)\n        route_distance = 0\n        while not routing.IsEnd(index):\n            plan_output += \' {} -> \'.format(manager.IndexToNode(index))\n            previous_index = index\n            index = assignment.Value(routing.NextVar(index))\n            route_distance += routing.GetArcCostForVehicle(\n                previous_index, index, vehicle_id)\n        plan_output += \'{}\\n\'.format(manager.IndexToNode(index))\n        plan_output += \'Distance of the route: {}m\\n\'.format(route_distance)\n        print(plan_output)\n        total_distance += route_distance\n    print(\'Total Distance of all routes: {}m\'.format(total_distance))\n\n\ndef main():\n    """"""Entry point of the program.""""""\n    # Instantiate the data problem.\n    data = create_data_model()\n\n    # Create the routing index manager.\n    manager = pywrapcp.RoutingIndexManager(len(data[\'distance_matrix\']), data[\'num_vehicles\'], data[\'depot\'])\n\n    # Create Routing Model.\n    routing = pywrapcp.RoutingModel(manager)\n\n    # Define cost of each arc.\n    def distance_callback(from_index, to_index):\n        """"""Returns the manhattan distance between the two nodes.""""""\n        # Convert from routing variable Index to distance matrix NodeIndex.\n        from_node = manager.IndexToNode(from_index)\n        to_node = manager.IndexToNode(to_index)\n        return data[\'distance_matrix\'][from_node][to_node]\n\n    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n\n    # Add Distance constraint.\n    dimension_name = \'Distance\'\n    routing.AddDimension(\n        transit_callback_index,\n        0,  # no slack\n        3000,  # vehicle maximum travel distance\n        True,  # start cumul to zero\n        dimension_name,\n    )\n    distance_dimension = routing.GetDimensionOrDie(dimension_name)\n    distance_dimension.SetGlobalSpanCostCoefficient(100)\n\n    solver = routing.solver()\n    # Define Transportation Requests.\n    for request in data[\'pickups_deliveries\']:\n        pickup_index = manager.NodeToIndex(request[0])\n        delivery_index = manager.NodeToIndex(request[1])\n        routing.AddPickupAndDelivery(pickup_index, delivery_index)\n        solver.Add(routing.VehicleVar(pickup_index) == routing.VehicleVar(delivery_index))\n        solver.Add(distance_dimension.CumulVar(pickup_index) <= distance_dimension.CumulVar(delivery_index))\n\n    # Setting first solution heuristic.\n    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n    search_parameters.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.PARALLEL_CHEAPEST_INSERTION\n\n    # Solve the problem.\n    assignment = routing.SolveWithParameters(search_parameters)\n\n    # Print solution on console.\n    if assignment:\n        print_solution(data, manager, routing, assignment)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
operations_research/pulp/getting_started.py,0,"b'from pulp import (\n    LpVariable,\n    LpProblem,\n    LpMinimize,\n    LpStatus,\n)\n\n\ndef main():\n    x = LpVariable(""x"", 0, 3)\n    y = LpVariable(""y"", 0, 1)\n\n    problem = LpProblem(""myProblem"", LpMinimize)\n    problem += x + y <= 2\n    problem += -4 * x + y\n\n    status = problem.solve()\n\n    print(f\'Status: {LpStatus[status]}\')\n    for var in problem.variables():\n        print(f\'{var.name} = {var.value()}\')\n    print(f\'objective = {problem.objective.value()}\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
text/regex/__init__.py,0,b''
text/regex/regex_distance.py,0,"b'# This code is based on ""https://gist.github.com/wil3/1671fbde4c698565040a"" gist.\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\ndef regex_dist(regex: str, target: str):\n    logger.info(f\'Computing distance between ""{regex}"" and ""{target}""...\')\n\n    def regex_dist_aux(r_i, t_i):\n        if r_i == -1 and t_i == -1:\n            return 0\n        if r_i == -1:\n            return t_i + 1\n        if t_i == -1:\n            i, counter = r_i, 0\n            while i >= 0:\n                char = regex[i]\n                if char in (\'?\', \'*\', \'+\'):\n                    i -= 2\n                else:\n                    i -= 1\n                if char not in (\'?\', \'*\'):\n                    counter += 1\n            return counter\n\n        if memo[r_i][t_i] is not None:\n            return memo[r_i][t_i]\n\n        # Regex special cases\n        if regex[r_i] == \'.\':\n            memo[r_i][t_i] = regex_dist_aux(r_i - 1, t_i - 1)\n            return memo[r_i][t_i]\n\n        if regex[r_i] == \'+\' or regex[r_i] == \'*\' or regex[r_i] == \'?\':\n            if regex[r_i - 1] == target[t_i]:\n                if regex[r_i] == \'?\':\n                    memo[r_i][t_i] = regex_dist_aux(r_i - 2, t_i - 1)\n                else:\n                    memo[r_i][t_i] = min(regex_dist_aux(r_i - 2, t_i - 1), regex_dist_aux(r_i, t_i - 1))\n            else:\n                additional_cost = 1 if (regex[r_i] == \'+\') else 0\n                memo[r_i][t_i] = min(regex_dist_aux(r_i - 2, t_i - 1) + 1,\n                                     regex_dist_aux(r_i, t_i - 1) + 1,\n                                     regex_dist_aux(r_i - 2, t_i) + additional_cost)\n            return memo[r_i][t_i]\n\n        # Other characters\n        if regex[r_i] == target[t_i]:\n            memo[r_i][t_i] = regex_dist_aux(r_i - 1, t_i - 1)\n        else:\n            memo[r_i][t_i] = min(regex_dist_aux(r_i - 1, t_i - 1) + 1,\n                                 regex_dist_aux(r_i, t_i - 1) + 1,\n                                 regex_dist_aux(r_i - 1, t_i) + 1)\n        return memo[r_i][t_i]\n\n    memo = [[None] * (len(target) + 1) for _ in range(len(regex) + 1)]\n    distance = regex_dist_aux(len(regex) - 1, len(target) - 1)\n    logger.info(f\'The distance between ""{regex}"" and ""{target}"" is ""{distance}""...\')\n    return distance\n\n\ndef main():\n    # Some examples\n    assert regex_dist(""OrchestraaaQA+a"", ""CarthorseQAAAA"") == 10\n    assert regex_dist(""A+b"", ""AAb"") == 0\n    assert regex_dist(""A+b"", ""AAAAAb"") == 0\n    assert regex_dist(""A+b"", ""AAAAAb03b"") == 3\n    assert regex_dist(""A..b"", ""AAAAAb03b"") == 5\n    assert regex_dist(""q+"", ""A"") == 1\n    assert regex_dist(""q+a?a+"", ""A"") == 2\n    assert regex_dist(""q+a?a+A+"", ""A"") == 2\n    assert regex_dist(""q+a?a+A+."", ""A"") == 3\n    assert regex_dist(""q+A"", ""AAAAAb03b"") == 8\n\n\nif __name__ == \'__main__\':\n    main()\n'"
text/regex/string_matching.py,0,"b'# !/usr/bin/env python\n\n# This code is based on ""https://gist.github.com/wil3/1671fbde4c698565040a"" gist.\n\nimport string\nimport re\nimport random\nimport operator as op\nfrom math import ceil, floor\nfrom pathlib import Path\nfrom typing import List, Tuple\n\nimport numpy\nfrom random import (\n    random,\n    choice,\n    randint,\n    seed,\n)\nfrom deap import algorithms\nfrom deap import base\nfrom deap import creator\nfrom deap import tools\n\nVALID_CHARS = list(string.printable)\nMAX_LENGTH = 100\n\nMATE_RATIO = 0.6\nMUTATION_RATIO = 0.9\nPOPULATION_SIZE = 50\nMAX_GENERATIONS = 10e6\nPATTERN = re.compile(r\'\\w{8}\')\n\n\ndef get_random_char() -> chr:\n    return choice(VALID_CHARS)\n\n\ndef gen_word(minimum: int, maximum: int) -> List[chr]:\n    length = randint(minimum, maximum)\n    return [get_random_char() for _ in range(length)]\n\n\ndef evaluate(individual: List[chr]) -> Tuple[float]:\n    if not re.fullmatch(PATTERN, \'\'.join(individual)):\n        return float(\'inf\'),\n    return len(individual),\n\n\ndef mutate(individual: List[chr]) -> Tuple[List[chr]]:\n    r = random()\n    c = get_random_char()\n    pos = randint(0, len(individual) - 1)\n    if r < 1 / 3:\n        individual.append(c)\n    elif 1 / 3 <= r < 2 / 3:\n        individual.pop(pos)\n    else:\n        individual[pos] = c\n    return individual,\n\n\ndef mate(ind1: List[chr], ind2: List[chr]) -> Tuple[List[chr], ...]:\n    for i in range(min(len(ind1), len(ind2))):\n        if random() < MATE_RATIO:\n            ind1[i], ind2[i] = ind2[i], ind1[i]\n    return ind1, ind2\n\n\ndef build() -> base.Toolbox:\n    creator.create(""FitnessMin"", base.Fitness, weights=(-1.0,))\n    creator.create(""Individual"", list, fitness=creator.FitnessMin)\n\n    toolbox = base.Toolbox()\n    # Attribute generator\n    toolbox.register(""attr_item"", get_random_char)\n    toolbox.register(""attr_len"", randint, 0, MAX_LENGTH)\n\n    toolbox.register(""word"", gen_word, 1, MAX_LENGTH)\n    # Structure initializers\n    # toolbox.register(""individual"", init_individual)\n    # toolbox.register(""individual"",tools.initRepeat, creator.Individual,\n    #                 toolbox.attr_item, toolbox.attr_len)\n    toolbox.register(""individual"", tools.initIterate, creator.Individual, toolbox.word)\n    toolbox.register(""population"", tools.initRepeat, list, toolbox.individual)\n    # Operator registering\n    toolbox.register(""evaluate"", evaluate)\n    toolbox.register(""mate"", mate)\n    toolbox.register(""mutate"", mutate)\n    toolbox.register(""select"", tools.selBest)\n\n    return toolbox\n\n\ndef execute(toolbox: base.Toolbox, cases: int = 100) -> List[str]:\n    population = toolbox.population(n=POPULATION_SIZE)\n    hall_of_fame = tools.ParetoFront()\n\n    stats = tools.Statistics(lambda i: i.fitness.values)\n    stats.register(""avg"", numpy.mean, axis=0)\n    stats.register(""std"", numpy.std, axis=0)\n    stats.register(""min"", numpy.min, axis=0)\n    stats.register(""max"", numpy.max, axis=0)\n\n    logbook = tools.Logbook()\n    logbook.header = ""gen"", ""evals"", ""std"", ""min"", ""avg"", ""max"", ""best""\n\n    # Evaluate every individuals\n    for individual in population:\n        individual.fitness.values = toolbox.evaluate(individual)\n\n    hall_of_fame.update(population)\n    record = stats.compile(population)\n    logbook.record(gen=0, evals=len(population), **record)\n    print(logbook.stream)\n\n    generated_cases = list\n    last_fitness = float(\'inf\')\n    current_fitness = None\n    generation_count = 1\n    while generation_count <= MAX_GENERATIONS and (last_fitness != current_fitness or current_fitness == float(\'inf\')):\n        last_fitness = current_fitness\n\n        # Select the next generation individuals\n        offspring = toolbox.select(population, floor(POPULATION_SIZE * 0.9))\n\n        # Clone the selected individuals\n        offspring = list(toolbox.map(toolbox.clone, offspring))\n\n        # Add new individuals from the population\n        offspring += toolbox.population(n=POPULATION_SIZE - len(offspring))\n\n        # Apply crossover and mutation on the offspring\n        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n            if not random() < MATE_RATIO:\n                continue\n            toolbox.mate(child1, child2)\n            del child1.fitness.values\n            del child2.fitness.values\n\n        for mutant in offspring:\n            if not random() < MUTATION_RATIO:\n                continue\n            toolbox.mutate(mutant)\n            del mutant.fitness.values\n\n        # Evaluate the individuals with an invalid fitness\n        invalid_ind = [individual for individual in offspring if not individual.fitness.valid]\n        for individual in offspring:\n            individual.fitness.values = toolbox.evaluate(individual)\n\n        generated_cases = tools.selBest(population, k=cases)\n        current_fitness = sum(toolbox.map(op.itemgetter(0), toolbox.map(toolbox.evaluate, generated_cases)))\n        best = choice(generated_cases)\n        word = """".join(best)\n\n        # Select the next generation population\n        population = toolbox.select(population + offspring, POPULATION_SIZE)\n        record = stats.compile(population)\n        logbook.record(gen=generation_count, evals=len(invalid_ind), best=word, **record)\n        print(logbook.stream)\n\n        generation_count += 1\n\n    return [\'\'.join(case) for case in generated_cases]\n\n\ndef main() -> None:\n    seed(56)\n\n    toolbox = build()\n    generated_cases = execute(toolbox, 100)\n    print(generated_cases)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
utils/collections/cycled_set.py,0,"b'from collections.abc import MutableSet\n\n\nclass CycledSet(MutableSet):\n    def __init__(self, iterable=()):\n        self.data = set(iterable)\n\n    def __contains__(self, value):\n        return value in self.data\n\n    def __iter__(self):\n        while True:\n            if any(self.data):\n                yield from self._iter_data()\n            else:\n                yield None\n\n    def _iter_data(self):\n        copied_data = set(self.data)\n        for element in copied_data:\n            if element not in self.data:\n                continue\n            yield element\n\n    def __len__(self):\n        return len(self.data)\n\n    def __repr__(self):\n        return repr(self.data)\n\n    def add(self, item):\n        self.data.add(item)\n\n    def discard(self, item):\n        self.data.discard(item)\n'"
utils/collections/labeled_tree.py,0,"b'class LabeledTree(object):\n    def __init__(self, data):\n        self.data = data\n        self.children = {}\n\n    def add_child(self, label, obj):\n        self.children[label] = obj\n\n    def __str__(self):\n        return self.str()\n\n    def str(self, deep=1):\n\n        str_out = str(self.data)\n\n        for key, value in self.children.items():\n\n            try:\n                value = value.str(deep + 1)\n            except AttributeError:\n                value = value\n\n            str_out += ""\\n"" + deep * ""\\t"" + str(key) + "" --> "" + str(value)\n        return str_out\n'"
utils/collections/oscar_dict.py,0,"b""from collections import UserDict\n\n\nclass OscarDict(UserDict):\n\n    def __getitem__(self, key):\n        value = self.data[key]\n        if callable(value):\n            value = value()\n            self.data[key] = value\n        return value\n\n\ndef main():\n    base = {'a': 3, 'b': lambda: 'Oscar'}\n    fancy = OscarDict(base)\n\n    print(fancy['a'])\n    print(fancy['b'])\n\n    fancy['c'] = lambda: 'Sergio'\n\n    print(fancy['c'])\n\n\nif __name__ == '__main__':\n    main()\n"""
utils/collections/tree.py,0,"b'class Tree(object):\n    def __init__(self, data):\n        self.data = data\n        self.children = []\n\n    def add_child(self, obj):\n        self.children.append(obj)\n\n    def __str__(self):\n        return self.str()\n\n    def str(self, deep=1):\n\n        str_out = str(self.data)\n\n        for child in self.children:\n\n            try:\n                value = child.str(deep + 1)\n            except AttributeError:\n                value = child\n\n            str_out += ""\\n"" + deep * ""\\t"" + "" --> "" + str(value)\n        return str_out\n'"
visualization/bokeh/__init__.py,0,b''
visualization/bokeh/grouped_bar_plot_example_01.py,0,"b'#!/usr/bin/env python3\n\n\n# EXAMPLE FROM: https://bokeh.pydata.org/en/latest/docs/user_guide/categorical.html#nested-categories\n\nfrom bokeh.io import show\nfrom bokeh.models import ColumnDataSource, FactorRange\nfrom bokeh.plotting import figure\nfrom bokeh.transform import factor_cmap\nfrom bokeh.palettes import Spectral6\n\ndef main() -> None:\n    fruits = [\'Apples\', \'Pears\', \'Nectarines\', \'Plums\', \'Grapes\', \'Strawberries\']\n    years = [\'2015\', \'2016\', \'2017\']\n\n    data = {\'fruits\' : fruits,\n            \'2015\'   : [2, 1, 4, 3, 2, 4],\n            \'2016\'   : [5, 3, 3, 2, 4, 6],\n            \'2017\'   : [3, 2, 4, 4, 5, 3]}\n\n    # this creates [ (""Apples"", ""2015""), (""Apples"", ""2016""), (""Apples"", ""2017""), (""Pears"", ""2015), ... ]\n    x = [ (fruit, year) for fruit in fruits for year in years ]\n\n    counts = sum(zip(data[\'2015\'], data[\'2016\'], data[\'2017\']), tuple()) # like an hstack\n\n    source = ColumnDataSource(data=dict(x=x, counts=counts))\n\n    p = figure(x_range=FactorRange(*x))\n\n    p.vbar(x=\'x\', top=\'counts\', width=0.9, source=source, line_color=""white"",\n           # use the palette to colormap based on the the x[1:2] values\n           fill_color=factor_cmap(\'x\', palette=Spectral6, factors=years, start=1, end=2))\n\n    p.y_range.start = 0\n    p.x_range.range_padding = 0.1\n    p.xaxis.major_label_orientation = 1\n    p.xgrid.grid_line_color = None\n\n    show(p)\n\nif __name__ == \'__main__\':\n    main()\n'"
visualization/bokeh/stacked_plot_example_01.py,0,"b""#!/usr/bin/env python3\n\n\n# EXAMPLE FROM: https://stackoverflow.com/a/43936905/3921457\n\nimport pandas as pd\nfrom bokeh.models import ColumnDataSource\nfrom bokeh.plotting import show, output_notebook, figure as bf\n\n\n\ndef main() -> None:\n    df = pd.DataFrame({'S': [34,23, 12, 9],\n                       'P':[65, 44, 81,23]})\n\n    df_comb = df.join(df.divide(df.sum(axis=1), axis=0), rsuffix='_w').join(df.divide(df.sum(axis=1) * 2, axis=0), rsuffix='_w_labelheights')\n    df_comb['P_w_labelheights'] += df_comb['S_w']\n    df_comb\n\n    f = bf()\n    source = ColumnDataSource(df_comb)\n\n    s = f.vbar(x='index', bottom=0, top='S_w', width=0.5, source=source)\n    p = f.vbar(x='index', bottom='S_w', top=1, width=0.5, source=source, color='orange')\n\n    s_label = f.text(x='index', y='S_w_labelheights', source=source, text='S')\n    p_label = f.text(x='index', y='P_w_labelheights', source=source, text='P')\n\n    show(f)\n\n\nif __name__ == '__main__':\n    main()\n"""
visualization/bokeh/stacked_plot_example_02.py,0,"b'#!/usr/bin/env python3\n\n\n# EXAMPLE FROM: https://bokeh.pydata.org/en/latest/docs/user_guide/categorical.html#stacked\n\nfrom bokeh.core.properties import value\nfrom bokeh.io import show\nfrom bokeh.plotting import figure\n\n\ndef main() -> None:\n\n    fruits = [\'Apples\', \'Pears\', \'Nectarines\', \'Plums\', \'Grapes\', \'Strawberries\']\n    years = [""2015"", ""2016"", ""2017""]\n    colors = [""#c9d9d3"", ""#718dbf"", ""#e84d60""]\n\n    data = {\'fruits\' : fruits,\n            \'2015\'   : [2, 1, 4, 3, 2, 4],\n            \'2016\'   : [5, 3, 4, 2, 4, 6],\n            \'2017\'   : [3, 2, 4, 4, 5, 3]}\n\n    p = figure(x_range=fruits, plot_height=250, title=""Fruit Counts by Year"",\n               toolbar_location=None, tools="""")\n\n    p.vbar_stack(years, x=\'fruits\', width=0.9, color=colors, source=data,\n                 legend=[value(x) for x in years])\n\n    p.y_range.start = 0\n    p.x_range.range_padding = 0.1\n    p.xgrid.grid_line_color = None\n    p.axis.minor_tick_line_color = None\n    p.outline_line_color = None\n    p.legend.location = ""top_left""\n    p.legend.orientation = ""horizontal""\n\n    show(p)\n\nif __name__ == \'__main__\':\n    main()\n'"
visualization/bokeh/time_series_plot_example.py,0,"b'#!/usr/bin/env python3\n\n\n# EXAMPLE FROM: https://stackoverflow.com/a/45984782/3921457\n\n\nimport pandas as pd\n\nfrom bokeh.models import ColumnDataSource\nfrom bokeh.plotting import figure, show\n\n\ndef main() -> None:\n    dic = {\n        \'2017-08-11\': {\'Yes\': 157, \'Not sure\': 2, \'No\': 1},\n        \'2017-08-22\': {\'Yes\': 142, \'Not sure\': 12},\n        \'2017-08-01\': {\'Yes\': 112, \'Others\': 10, \'Not sure\': 4, \'No\': 9},\n        \'2017-08-17\': {\'Yes\': 117, \'No\': 12, \'Not sure\': 11, \'Others\': 2},\n        \'2017-08-25\': {\'Yes\': 61, \'Not sure\': 9},\n        \'2017-08-23\': {\'Yes\': 268, \'Not sure\': 20, \'No\': 1},\n        \'2017-07-10\': {\'Yes\': 123, \'Not sure\': 4, \'No\': 1},\n        \'2017-08-10\': {\'Yes\': 343, \'Not sure\': 20},\n        \'2017-07-13\': {\'Yes\': 116, \'Others\': 1, \'Not sure\': 14, \'No\': 2},\n        \'2017-07-14\': {\'Yes\': 255, \'Not sure\': 22, \'No\': 6},\n        \'2017-08-07\': {\'Yes\': 73, \'Others\': 3, \'Not sure\': 4, \'No\': 5},\n        \'2017-08-04\': {\'Not sure\': 11, \'Others\': 8, \'Yes\': 178, \'No\': 10},\n        \'2017-08-16\': {\'Not sure\': 10, \'Yes\': 219},\n        \'2017-07-18\': {\'Yes\': 1, \'No\': 1},\n        \'2017-08-15\': {\'Yes\': 301, \'Others\': 4, \'Not sure\': 37, \'No\': 31},\n        \'2017-08-08\': {\'Yes\': 38, \'No\': 2, \'Others\': 1},\n        \'2017-08-09\': {\'Yes\': 120, \'Not sure\': 3},\n        \'2017-08-28\': {\'Yes\': 206, \'Others\': 2, \'Not sure\': 18, \'No\': 24},\n        \'2017-08-14\': {\'Yes\': 46, \'No\': 3, \'Not sure\': 5, \'Others\': 7}\n    }\n\n    df = pd.DataFrame.from_dict(dic, orient=""index"")\n    df = df.fillna(0)\n    df.index = pd.to_datetime(df.index)\n    df.index.name = \'Date\'\n    df.sort_index(inplace=True)\n\n    df[\'Total\'] = df.Yes + df[\'Not sure\'] + df.No + df.Others\n    df[\'Precision\'] = round(df.Yes/df.Total, 2)\n    df\n    source = ColumnDataSource(df)\n\n    p = figure(x_axis_type=""datetime"", plot_width=800, plot_height=350)\n    p.line(\'Date\', \'Precision\', source=source)\n\n    show(p)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
web/django/__init__.py,0,b''
competitive/t3chfest/2017/__init__.py,0,b''
competitive/t3chfest/2017/task-1.py,0,"b'# you can write to stdout for debugging purposes, e.g.\n# print ""this is a debug message""\ndef solution(N):\n    b = bin(N).split(\'0b\')[1]\n    l = len(b)\n    i = l / 2\n    while (i > 0):\n        j = 1\n        while (b[0:i] == b[i * j:i * (j + 1)]):\n            j += 1\n            if (l == i * j):\n                return i\n            elif (l > i * j and l < i * (j + 1) and b[:l % i] == b[-(l % i):]):\n                return i\n        i -= 1\n    return -1\n\n\nprint(solution(3))\nprint(solution(7))\nprint(solution(15))\nprint(solution(955))\nprint(solution(954))\nprint(solution(102))\nprint(solution(1000000000))\n'"
competitive/t3chfest/2017/task-2.py,0,"b'# you can write to stdout for debugging purposes, e.g.\n# print ""this is a debug message""\nimport re\n\n\ndef solution(N, S, T):\n    ships = []\n    list_S = re.findall(\'([0-9]+)([A-Z]) ([0-9]+)([A-Z])\', S)\n    list_T = re.findall(\'([0-9]+)([A-Z])\', T)\n\n    for s_tuple in list_S:\n        tiles = (abs(int(s_tuple[2]) - int(s_tuple[0])) + 1) * (abs(ord(s_tuple[3]) - ord(s_tuple[1])) + 1)\n        max_disp = max(abs(int(s_tuple[2]) - int(s_tuple[0])) + 1, (abs(ord(s_tuple[3]) - ord(s_tuple[1])) + 1))\n        ships.append([s_tuple, tiles, tiles, max_disp])\n\n    for h_tuple in list_T:\n        for ship in ships:\n            if (check_hit(ship, h_tuple)):\n                ship[1] -= 1\n                break\n    sunked = 0\n    hits = 0\n    for ship in ships:\n        if (ship[1] == 0):\n            sunked += 1\n        elif (ship[1] < ship[2]):\n            hits += 1\n    return str(sunked) + "","" + str(hits)\n\n\ndef check_hit(ship, hit):\n    return max(abs(int(ship[0][0]) - int(hit[0])) + abs(int(ship[0][2]) - int(hit[0])),\n               abs(ord(ship[0][1]) - ord(hit[1])) + abs(ord(ship[0][3]) - ord(hit[1]))) < ship[3]\n\n\nprint(solution(12, \'1B 4D\', \'1A\'))\n\nprint(solution(4, \'1B 2C,2D 4D\', \'2B 2D 3D 4D 4A\'))\nprint(solution(12, \'1A 2A,12A 12A\', \'12A\'))\nprint(solution(3, \'1A 1B,2C 2C\', \'1B\'))\n'"
competitive/t3chfest/2017/task-3.py,0,"b'# you can write to stdout for debugging purposes, e.g.\n# print ""this is a debug message""\n\ndef solution(T):\n    c = find_capital(T)\n    Graph = list(enumerate(T));\n    Distances = [0] * (len(T) - 1)\n\n    deep = 0\n    Graph.pop(c)\n    Queue = [c]\n    while (len(Queue) != 0):\n\n        if (Queue[0] != -1):\n            Queue.append(-1)\n\n        for road in list(Graph):\n            if (Queue[0] == road[1]):\n                Distances[deep] += 1\n                Queue.append(road[0])\n                Graph.remove(road)\n\n        if (Queue.pop(0) == -1):\n            deep += 1\n    return Distances\n\n\ndef find_capital(T):\n    for deep, j in enumerate(T):\n        if (deep == j):\n            return deep\n\n\nprint(solution([9, 1, 4, 9, 0, 4, 8, 9, 0, 1]))\n'"
competitive/t3chfest/2017/task-4.py,0,"b""# you can write to stdout for debugging purposes, e.g.\n# print 'this is a debug message'\n\ndef solution(A, B):\n    resultList, remainderList = [str(A // B)], [A % B]\n    A %= B\n    stop = False\n    while A != 0 and not stop:\n        quotient, A = divmod(A * 10, B)\n        resultList.append(str(quotient))\n        if A in remainderList:\n            resultList.insert(remainderList.index(A) + 1, '(')\n            resultList.append(')')\n            stop = True\n        else:\n            remainderList.append(A)\n    if (len(resultList) == 1):\n        return resultList[0]\n    else:\n        resultList.insert(1, '.')\n        return ''.join(resultList)\n\n\nprint(solution(12, 3))\nprint(solution(1, 2))\nprint(solution(5, 4))\nprint(solution(1, 3))\nprint(solution(3, 28))\n"""
competitive/t3chfest/2017/task-5.py,0,"b'# you can write to stdout for debugging purposes, e.g.\n# print ""this is a debug message""\n\ndef solution(A, D):\n    # write your code in Python 2.7\n    season = 0\n    M = [False for col in range(len(A))]\n    iterator = A[0:min(D, len(A))]\n    while (season < len(A) + 1):\n        for i, a in enumerate(iterator):\n            if (a >= 0 and a <= season):\n                M[i] = True\n                iterator.extend(A[(len(iterator)):min(i + D + 1, len(A))])\n        j = D\n        while (j > 0):\n            if (M[-j]):\n                return season\n            j -= 1\n        season += 1\n    return -1\n\n\nprint(solution([1, -1, 0, 2, 3, 5], 3))\nprint(solution([3, 2, 1], 1))\nprint(solution([1, 2, 3, 4, -1, -1, -1], 3))\n'"
competitive/t3chfest/2017/task-6.py,0,"b'# you can write to stdout for debugging purposes, e.g.\n# print ""this is a debug message""\nimport time\n\n\ndef solution(A):\n    # write your code in Python 2.7\n    result = 0\n    data = dict()\n    for a in A:\n        if not a in data:\n            d = 2 ** a\n            if a % 2 == 1:\n                d *= -1\n            data[(a)] = d\n        result += data[a]\n    return result\n\n\ntime1 = time.time()\n(solution([1000000, 999999, 999998, 999998, 7]))\ntime2 = time.time()\nprint(\'took %0.3f ms\' % ((time2 - time1) * 1000.0))\n\ntime1 = time.time()\n(solution([1000000, 1000000, 1000000, 7]))\ntime2 = time.time()\nprint(\'took %0.3f ms\' % ((time2 - time1) * 1000.0))\n'"
competitive/t3chfest/2018/__init__.py,0,b''
competitive/t3chfest/2018/task_1.py,0,"b""#!/usr/bin/env python3\n\ndef check_vector(A):\n    parity = A[0] % 2\n    for i in range(1, len(A)):\n        if A[i] % 2 != parity:\n            return False\n    return True\n\ndef equal_vector(A):\n    for i in range(len(A) - 1):\n        if A[i] != A[i + 1]:\n            return False\n    return True\n\n\ndef solution(A):\n    if len(A) == 0:\n        return 0\n    elif check_vector(A):\n        count = 0\n        matched = equal_vector(A)\n        while not matched:\n            count += 1\n            mean = (sum(A) / len(A))\n            for i in range(len(A)):\n                if A[i] - mean < 0:\n                    A[i] += 1\n                else:\n                    A[i] -= 1\n            matched = equal_vector(A)\n        return count\n    else:\n         return -1\n\nif __name__ == '__main__':\n    print(solution([200, -200, 10, 2]))\n"""
competitive/t3chfest/2018/task_2.py,0,"b'#!/usr/bin/env python3\n\ndef swap(S, T):\n    for i in range(len(T) - 1):\n        if (S[i] == T[i + 1] and S[i + 1] == T[i] and\n            S[i] != T[i] and S[i + 1] != T[i + 1]):\n            if S[i + 2:] == T[i + 2:]:\n                return ""SWAP "" + S[i] + "" "" + S[i + 1]\n            else:\n                return ""IMPOSSIBLE""\n\n\ndef insertion(A, B, action):\n    for i in range(len(B)):\n        if i == len(A) or A[i] != B[i]:\n            if A[i:] == B[i+1:]:\n                return action + "" "" + B[i]\n            else:\n                return ""IMPOSSIBLE""\n\n\ndef solution(S, T):\n    diff = len(S) - len(T)\n    if diff == 1:\n        return insertion(T, S, ""DELETE"")\n    elif diff == - 1:\n        return insertion(S, T, ""INSERT"")\n    elif diff == 0:\n        if S == T:\n            return ""NOTHING""\n        else:\n            return swap(S, T)\n    else:\n        return ""IMPOSSIBLE""\n\n\nif __name__ == \'__main__\':\n    print(solution(""inces"",""nicse""))\n'"
competitive/t3chfest/2018/task_3.py,0,"b""#!/usr/bin/env python3\n\n\ndef solution(K, A):\n    c = 0\n    for i in range(len(A)):\n        for j in range(i, len(A)):\n            if A[i] + A[j] == K:\n                if i != j:\n                    c += 2\n                else:\n                    c += 1\n    return c\n\n\nif __name__ == '__main__':\n    print(solution(6, [1, 8, -3, 0, 1, 3, -2, 4, 5]))\n"""
competitive/t3chfest/2018/task_4.py,0,"b""#!/usr/bin/env python3\n\ndef solution(A):\n    sorted_A = sorted(A)\n    c = 0\n    i = 0\n    while i < len(A):\n        if A[i] != sorted_A[i]:\n            j = i + 1\n            while j < len(A) and A[j] != sorted_A[i]:\n                j += 1\n            i = j\n        c += 1\n        i += 1\n    return c\n\n\n\nif __name__ == '__main__':\n    print(solution([1, 5, 4, 9, 8, 7, 12, 13, 14]))\n    print(solution([4, 3, 2, 6, 1]))\n    print(solution([2, 1, 3]))\n"""
competitive/t3chfest/2018/task_5.py,0,"b""#!/usr/bin/env python3\n\ndef solution(A):\n    c = 0\n    i = 0\n    while i < len(A) - 1:\n        if A[i] > A[i + 1]:\n\n            j = i - 1\n            while j >= 0 and A[j] > A[i + 1] and not A[j] > A[j + 1]:\n                j -= 1\n            l = i - j\n\n            j = i + 1\n            while j < len(A) and A[j] < A[i] and j - (i + 1) < l:\n                j += 1\n            r =  j - (i + 1)\n\n            if r < l:\n                i += r\n                c += r\n            else:\n                c+=l\n\n        i += 1\n    return c\n\n\n\nif __name__ == '__main__':\n    print(solution([1,2,3,4,5,6,7,5,6,7,8,10,10,10,10,10,10,10,10,10,10,9,1, 11,2]))\n"""
competitive/t3chfest/2018/task_6.py,0,"b""#!/usr/bin/env python3\n\nbit = lambda x: x % 2\ncarry = lambda x: 1 if x < 0 else -1 if x > 1 else 0\n\ndef solution(A):\n    R = []\n    if len(A) > 0:\n        R.append(bit(A[0]))\n        c = carry(A[0])\n        for i in range(1, len(A)):\n            n = A[i] + A[i - 1] + c\n            R.append(bit(n))\n            c = carry(n)\n        n = A[-1] + c\n        R.append(bit(n))\n        while len(R) > 0 and R[-1] == 0:\n            R.pop()\n    return R\n\n\nif __name__ == '__main__':\n    print(solution([0]))\n"""
environment/concurrency/asyncio/hello_world.py,0,"b""import asyncio\n\n\nasync def main():\n    print('Hello ...')\n    await asyncio.sleep(1)\n    print('... World!')\n\n\nif __name__ == '__main__':\n    asyncio.run(main())\n"""
environment/containerizing/docker/__init__.py,0,b''
environment/containerizing/docker/hello_docker_container.py,1,"b'from datetime import datetime\n\nimport docker\n\n\ndef main():\n    start = datetime.now()\n\n    client = docker.from_env()\n\n    apt_dependencies = \' \'.join([\n        \'vim\',\n    ])\n\n    pip_dependencies = \' \'.join([\n        \'numpy\',\n        \'pandas\',\n    ])\n\n    code = \';\'.join([\n        \'import numpy as np\',\n        \'size = 100\',\n        \'random_numbers = np.random.uniform(size=size)\',\n        \'print(random_numbers)\'\n    ])\n\n    container = client.containers.run(""python"", \'tail -f /dev/null\', detach=True)\n    result = container.exec_run(f""apt-get update"")\n    print(result.output.decode())\n\n    result = container.exec_run(f""apt-get install -y {apt_dependencies}"")\n    print(result.output.decode())\n\n    result = container.exec_run(f""pip install {pip_dependencies}"")\n    print(result.output.decode())\n\n    result = container.exec_run(f""python -c \'{code}\'"")\n    print(result.output.decode())\n\n    container.stop()\n    end = datetime.now()\n\n    print(f\'Elapsed Time: {end - start}\')\n\nif __name__ == \'__main__\':\n    main()\n'"
environment/containerizing/docker/hello_docker_image.py,1,"b'from io import StringIO, BytesIO\nfrom datetime import datetime\n\nimport docker\n\n\ndef main():\n\n    client = docker.from_env()\n\n    apt_dependencies = \' \'.join([\n        \'vim\',\n    ])\n\n    pip_dependencies = \' \'.join([\n        \'numpy\',\n    ])\n\n    code = \';\'.join([\n        \'import numpy as np\',\n        \'size = 100\',\n        \'random_numbers = np.random.uniform(size=size)\',\n        \'print(random_numbers)\'\n    ])\n\n    version = \'latest\'\n    tag = \'hello-docker-py\'\n\n    output = BytesIO(\'\\n\'.join([\n        f\'FROM python:{version}\',\n        f\'RUN apt-get update && apt-get install -y {apt_dependencies}\',\n        f\'RUN pip install {pip_dependencies}\',\n    ]).encode())\n    client.images.build(fileobj=output, tag=tag)\n\n    start = datetime.now()\n\n    container = client.containers.run(tag, \'tail -f /dev/null\', detach=True)\n\n    result = container.exec_run(f""python -c \'{code}\'"")\n    print(result.output.decode())\n\n    result = container.exec_run(f""python -c \'{code}\'"")\n    print(result.output.decode())\n\n    end = datetime.now()\n\n    print(f\'Elapsed Time: {end - start}\')\n    container.stop()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
environment/scripting/argparse/echo.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nimport argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""text"", help=""echo the string you use here"")\nargs = parser.parse_args()\n\nprint(args.text)\n'"
environment/scripting/argparse/integer_operation.py,0,"b""#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport argparse\n\nparser = argparse.ArgumentParser(description='Apply operations over numbers')\n\nparser.add_argument('number', type=int, help='number to operate')\nparser.add_argument('--other', type=int, help='other to operate')\nparser.add_argument('-s', '--square', help='display a square of a given number', action='store_true')\nparser.add_argument('-c', '--cube', help='display a cube of a given number', action='store_true')\nparser.add_argument('--sum', help='apply sum', action='store_true')\n\nargs = parser.parse_args()\n\nnumber = args.number\n\nif args.square:\n    number **= 2\n\nif args.cube:\n    number **= 3\n\nif args.other:\n    other = args.other\n    if args.sum:\n        number += other\n\nprint(number)\n"""
environment/scripting/argparse/integers.py,0,"b""#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport argparse\n\nparser = argparse.ArgumentParser(description='Process some integers.')\n\nparser.add_argument('integers', metavar='N', type=int, nargs='+', help='an integer for the accumulator')\nparser.add_argument('--sum', dest='accumulate', action='store_const', const=sum, default=max, help='sum the integers (default: find the max)')\n\nargs = parser.parse_args()\nprint(args.accumulate(args.integers))\n"""
environment/scripting/fire/calculator.py,0,"b'import fire\n\n\nclass Calculator(object):\n    """"""A simple calculator class.""""""\n\n    def double(self, number):\n        return 2 * number\n\n\nif __name__ == \'__main__\':\n    fire.Fire(Calculator)\n'"
numerical/data_science/models/__init__.py,0,b''
numerical/data_science/res/__init__.py,0,b'from .data_sets import (\n    DataSets\n)\n'
numerical/data_science/res/data_sets.py,0,"b'import pandas as pd\nfrom .logic_data_set import LogicDataSet\n\n\nclass DataSets:\n    @staticmethod\n    def _get_path():\n        return ""./res""\n\n    @staticmethod\n    def get_weber_nominal():\n        outLook = pd.Series([""Sunny"", ""Overcast"", ""Rain""], dtype=""category"")\n        temp = pd.Series([""Hot"", ""Mild"", ""Cold""], dtype=""category"")\n        humidity = pd.Series([""High"", ""Normal""], dtype=""category"")\n        wind = pd.Series([""Weak"", ""Strong""], dtype=""category"")\n        playTennis = pd.Series([""Yes"", ""No""], dtype=""category"")\n\n        columns = pd.Index([""Outlook"", ""Temperature"", ""Humidity"", ""Wind"", ""PlayTennis""])\n\n        data = [\n            [outLook[0], temp[0], humidity[0], wind[0], playTennis[1]],\n            [outLook[0], temp[0], humidity[0], wind[1], playTennis[1]],\n            [outLook[1], temp[0], humidity[0], wind[0], playTennis[0]],\n            [outLook[2], temp[1], humidity[0], wind[0], playTennis[0]],\n            [outLook[2], temp[2], humidity[1], wind[0], playTennis[0]],\n            [outLook[2], temp[2], humidity[1], wind[1], playTennis[1]],\n            [outLook[1], temp[2], humidity[1], wind[1], playTennis[0]],\n            [outLook[0], temp[1], humidity[0], wind[0], playTennis[1]],\n            [outLook[0], temp[2], humidity[1], wind[0], playTennis[0]],\n            [outLook[2], temp[1], humidity[1], wind[0], playTennis[0]],\n            [outLook[0], temp[1], humidity[1], wind[1], playTennis[0]],\n            [outLook[1], temp[1], humidity[0], wind[1], playTennis[0]],\n            [outLook[1], temp[0], humidity[1], wind[0], playTennis[0]],\n            [outLook[2], temp[1], humidity[0], wind[1], playTennis[1]],\n        ]\n\n        return pd.DataFrame(data, columns=columns, dtype=""category"")\n\n    @staticmethod\n    def get_weather():\n        types = {\n            \'outlook\': \'category\',\n            \'temperature\': \'int32\', \'humidity\': \'int32\',\n            \'windy\': \'category\', \'play\': \'category\',\n        }\n\n        return pd.read_csv(DataSets._get_path() + \'/weather.csv\', dtype=types)\n\n    @staticmethod\n    def get_weather_semi_nominal():\n        types = {\n            \'N\xc2\xba\': \'int32\', \'Outlook\': \'category\',\n            \'Temperature\': \'int32\', \'Humidity\': \'category\',\n            \'Wind\': \'category\', \'PlayTennis\': \'category\',\n        }\n\n        return pd.read_csv(DataSets._get_path() + \'/weather_semi_nominal.csv\', dtype=types)\n\n    @staticmethod\n    def get_car_eval():\n        return pd.read_csv(DataSets._get_path() + \'/careval.csv\')\n\n    @staticmethod\n    def get_credit():\n        return pd.read_csv(DataSets._get_path() + \'/credit.csv\')\n\n    @staticmethod\n    def get_presion():\n        pd_class = pd.Series([""-"", ""+""], dtype=""category"")\n\n        columns = pd.Index([""Presion"", ""Clase""])\n\n        data = [\n            40, pd_class[0],\n            48, pd_class[0],\n            60, pd_class[0],\n            72, pd_class[0],\n            80, pd_class[0],\n            90, pd_class[0],\n        ]\n\n        return pd.DataFrame(data, columns=columns)\n\n    @staticmethod\n    def generate_from_logic_method(logic_m):\n        return LogicDataSet(logic_m)\n\n    @staticmethod\n    def get_wiki_vote():\n        return pd.read_csv(DataSets._get_path() + \'/wiki-Vote.csv\')\n\n    @staticmethod\n    def get_followers():\n        return pd.read_csv(DataSets._get_path() + \'/followers.csv\')\n\n    @staticmethod\n    def get_users():\n        return pd.read_csv(DataSets._get_path() + \'/users.csv\')\n\n    @staticmethod\n    def get_thoraric_surgery():\n        types = {\n            \'DGN\': \'category\', \'PRE4\': \'float64\', \'PRE5\': \'float64\', \'PRE6\': \'category\', \'PRE7\': \'category\',\n            \'PRE8\': \'category\', \'PRE9\': \'category\', \'PRE10\': \'category\', \'PRE11\': \'category\', \'PRE14\': \'category\',\n            \'PRE17\': \'category\', \'PRE19\': \'category\', \'PRE25\': \'category\', \'PRE30\': \'category\', \'PRE32\': \'category\',\n            \'AGE\': \'int32\', \'Risk1Yr\': \'category\'\n        }\n\n        return pd.read_csv(DataSets._get_path() + \'/ThoraricSurgery.csv\', dtype=types)\n'"
numerical/data_science/res/logic_data_set.py,3,"b""import numpy as np\nimport pandas as pd\nimport string as st\nfrom inspect import signature\n\n\nclass LogicDataSet():\n    def __init__(self, logic_function):\n        self.logic_function = logic_function\n        self.num_vars = len(signature(self.logic_function).parameters)\n        self._data = None\n        pass\n\n    @property\n    def data(self):\n        if self._data is None:\n            self.generate_data()\n        return self._data\n\n    @property\n    def data_as_pandas(self):\n        return pd.DataFrame(self.data, columns=list(st.ascii_uppercase)[:self.num_vars] + ['Result'])\n\n    @staticmethod\n    def _array_logic_function(input_data, logic_f):\n        input_data[-1] = logic_f(*input_data[:-1])\n        return input_data\n\n    def __str__(self):\n        return str(self.data)\n\n    def generate_data(self):\n        self._data = np.zeros([2 ** self.num_vars, self.num_vars + 1], dtype=bool)\n        for i in range(self.num_vars):\n            self._data[:, i] = np.tile([0] * 2 ** i + [1] * 2 ** i, [2 ** (self.num_vars - i - 1)])\n        self._data = np.apply_along_axis(LogicDataSet._array_logic_function, 1, self._data, self.logic_function)\n\n\ndef l(a, b, c, d, e):\n    return bool(not (a and b) or not (c and d)) != bool(e)\n\n\nif __name__ == '__main__':\n    pd_l = LogicDataSet(l).data_as_pandas\n    # pd_l.to_csv('logic_function.csv', index=False)\n    print(pd_l)\n"""
numerical/math/algebra/matrix-det-eigen.py,9,"b'#!/usr/bin/env python3\n\nimport numpy as np\n\ndef main():\n\n    a = np.matrix([[1, 0], [- 5, 7]])\n    det_a = np.linalg.det(a)\n    eigvals_a = np.linalg.eigvals(a)\n\n    print(""Matriz A:"")\n    print(a)\n    print(""Determinante de A:"")\n    print(det_a)\n    print(""Valores Propios de A:"")\n    print(eigvals_a)\n    b = np.matrix([[3, 1], [2, np.sqrt(np.pi)]])\n    det_b = np.linalg.det(b)\n    eigvals_b = np.linalg.eigvals(b)\n\n    print(""Matriz A:"")\n    print(b)\n    print(""Determinante de B:"")\n    print(det_b)\n    print(""Valores Propios de B:"")\n    print(eigvals_b)\n\n    c = np.matrix([[- 2, 0, 1], [3, 2, 4], [- 1, - 1, 0]])\n    det_c = np.linalg.det(c)\n    eigvals_c = np.linalg.eigvals(c)\n\n    print(""Matriz C:"")\n    print(c)\n    print(""Determinante de C:"")\n    print(det_c)\n    print(""Valores Propios de C:"")\n    print(eigvals_c)\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/math/combinatorics/k_elections_with_reemplacement_with_order.py,0,"b'#!/usr/bin/env python3\n\nimport scipy as sp\nimport numpy as np\nimport math\nfrom matplotlib import pyplot as plt\n\n\ncombs = lambda n, k: n ** k\n\n\ndef main():\n    n = 4\n    k = 3\n    print(""n ="", n, ""k ="", k,\n          ""k elections with replacement ="", combs(n, k))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/math/combinatorics/k_elections_without_reemplacement_with_order.py,0,"b'#!/usr/bin/env python3\n\nimport scipy as sp\nimport numpy as np\nimport math\n\nfrom matplotlib import pyplot as plt\n\nfrom functools import reduce\n\n\ncombs = lambda n, k: reduce(lambda a, b: a * b, range(n-k+1, n+1))\n\n\ndef main():\n    n = 4\n    k = 3\n    print(""n ="", n, ""k ="", k,\n          ""k elections without replacement ="", combs(n, k))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/math/combinatorics/k_elections_without_reemplacement_without_order.py,2,"b'#!/usr/bin/env python3\n\nimport scipy.special as sp_special\nimport numpy as np\nimport math\n\nfrom matplotlib import pyplot as plt\n\nfrom functools import reduce\n\n\ncombs = lambda n, n_i: sp_special.factorial(n) / np.prod(sp_special.factorial(n_i))\n\n\ndef main():\n    n = 5\n    n_i = np.array([2, 2, 1])\n    print(""n ="", n, ""n_i ="", n_i,\n          ""k elections without replacement ="", combs(n, n_i))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/math/combinatorics/k_elections_without_reemplacement_without_order_fixed_groups.py,0,"b'#!/usr/bin/env python3\n\nimport scipy.special as sp_special\nimport numpy as np\nimport math\n\nfrom matplotlib import pyplot as plt\n\nfrom functools import reduce\n\n\ncombs = lambda n, k: sp_special.comb(n, k, exact=True)\n\n\ndef main():\n    n = 4\n    k = 3\n    print(""n ="", n, ""k ="", k,\n          ""k elections without replacement ="", combs(n, k))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/math/integration/double-integral-exercise-19.py,6,"b'#!/usr/bin/env python3\n\nimport numpy as np\nfrom scipy import integrate\nimport cmath\n\n\ndef integrate_function(f, a1, a2, b1, b2):\n    return integrate.dblquad(f, a1, a2, b1, b2)[0]\n\n\ndef main():\n\n    e_19_1 = integrate_function(lambda y, x: x * y ** 2, -1, 1,\n                                lambda x: -x, lambda x: x)\n\n    print(""E19.1:\\t"" + str(e_19_1))\n\n    e_19_2 = integrate_function(lambda y, x: x ** 2 + y ** 2, 0, 1,\n                                lambda x: x ** 3, lambda x: x ** 2)\n    print(""E19.2:\\t"" + str(e_19_2))\n\n    e_19_3 = integrate_function(lambda y, x: (x * y - y ** 2) ** (1 / 2), 0, 1,\n                                lambda x: 0, lambda x: x)\n    print(""E19.3:\\t"" + str(e_19_3))\n\n    e_19_4 = integrate_function(lambda x, y: 12 - 3 * x - 4 * y, 0, 1,\n                                lambda b: b ** 2, lambda b: 3 - 2 * b)\n    print(""E19.4:\\t"" + str(e_19_4))\n\n    e_19_5 = integrate_function(lambda y, x: x ** 2 + y ** 2, - np.sqrt(2), 1,\n                                lambda b1: b1 ** 2, lambda b2: 2)\n    print(""E19.5:\\t"" + str(e_19_5))\n\n    e_19_6 = integrate_function(lambda y, x: y ** 2, -2, 6,\n                                lambda b1: np.abs(b1),\n                                lambda b2: np.divide(b2, 2) + 3)\n    print(""E19.6:\\t"" + str(e_19_6))\n\n    e_19_7 = integrate_function(lambda y, x: 2 *\n                                cmath.sqrt(1 - x ** 2).real + 1,\n                                - np.arccos(0.5), np.arccos(0.5),\n                                lambda b1: 1 - cmath.sqrt(1 - b1 ** 2).real,\n                                lambda b2: cmath.sqrt(1 - b2 ** 2).real)\n    print(""E19.7:\\t"" + str(e_19_7))\n\n    e24_1 = integrate_function(lambda y, x: 1, 0, 1,\n                               lambda b1: 0, lambda b2: b2 ** 2)\n    print(""E24.1:\\t"" + str(e24_1))\n\n    e24_3 = integrate_function(lambda y, x: y * np.sin(x), 0, np.pi / 2,\n                               lambda b1: 0, lambda b2: np.cos(b2))\n    print(""E24.3:\\t"" + str(e24_3))\n\n    e27_1 = integrate_function(lambda y, x: x * y, 0, 1,\n                               lambda b1: b1, lambda b2: 1)\n    print(""E27.1:\\t"" + str(e27_1))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/math/numeric_methods/polinomial_evaluation.py,3,"b""#!/usr/bin/env python3\n\nimport numpy as np\n\ndef truncate_digits(value, digits=None):\n    if digits is not None:\n        sign = value < 0\n        value = abs(value) % 10 ** digits\n        shift = 0\n        while digits > shift and value > 1:\n            shift += 1\n            value = value / 10\n        value = np.round(value, decimals=digits) * 10 ** shift\n        if sign == True:\n            value *= - 1\n    return value\n\n\ndef direct_eval(polinomial, x_0, digits=None):\n    r = 0.0\n    cached = np.ones(polinomial.shape[0])\n    for i in range(1, polinomial.shape[0]):\n        cached[i] = truncate_digits(cached[i - 1] * x_0, digits=digits)\n    for i in range(polinomial.shape[0]):\n        r = truncate_digits(r + truncate_digits(cached[i] * polinomial[i],\n                            digits=digits), digits=digits)\n    return r\n\n\ndef nested_eval(polinomial, x_0, digits=None):\n    r = 0.0\n    for i in reversed(range(1, polinomial.shape[0])):\n        r = truncate_digits(x_0 * truncate_digits(r + polinomial[i],\n                digits=digits), digits=digits)\n    return truncate_digits(r + truncate_digits(polinomial[0], digits=digits),\n                           digits=digits)\n\n\ndef main():\n\n    p_x = np.array([- 0.149, 3, - 6, 1])\n    x_0 = 4.71\n    print(direct_eval(p_x, x_0, 3))\n    print(nested_eval(p_x, x_0, 3))\n\nif __name__ == '__main__':\n    main()\n"""
numerical/math/stats/stats_template.py,0,"b""#!/usr/bin/env python3\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom scipy import stats\n\n\ndef main():\n\n    # Code Here\n\n    pass\n\nif __name__ == '__main__':\n    main()\n"""
web/django/django_first_app/__init__.py,0,b''
web/django/django_first_app/manage.py,0,"b'#!/usr/bin/env python3\nimport os\nimport sys\n\nif __name__ == ""__main__"":\n    os.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""django_first_app.settings"")\n\n    from web.django import execute_from_command_line\n\n    execute_from_command_line(sys.argv)\n'"
web/django/graphene/__init__.py,0,b''
environment/scripting/fabric/hello_world/fabfile.py,0,"b'from fabric import task\n\n\n@task\ndef hello(c):\n    c.run(f\'echo ""Hello World!""\')\n'"
numerical/data_science/models/trees/__init__.py,0,b''
numerical/data_science/models/trees/gain_ranking_continous.py,5,"b'import numpy as np\nimport pandas as pd\nfrom numerical.data_science.res import DataSets\nfrom numerical.data_science import GainRanking\n\n\nclass GainRankingContinous(GainRanking):\n    """"""\n    Class GainRankingContinous\n    """"""\n\n    def __init__(self, data_input, class_name, debug=False):\n        GainRanking.__init__(self, data_input, class_name, debug)\n\n    def gain(self, subdata, h_S):\n        result = pd.Series(index=subdata.columns)\n        for column in subdata.columns:\n            if subdata[column].dtype.name != \'category\':\n                if (subdata[column].dtype == np.int or\n                            subdata[column].dtype == np.int16 or\n                            subdata[column].dtype == np.int32 or\n                            subdata[column].dtype == np.int64 or\n                            subdata[column].dtype == np.int128):\n                    subdata.ix[:, column] = self.discretize(subdata[column])\n                else:\n                    raise NotImplementedError\n\n            a = self.sub_entropy(subdata[column])\n            counts = subdata[column].value_counts()\n            p = (counts / counts.sum())\n            result[column] = (h_S - (p * a).sum())\n        return result, subdata\n\n    def discretize(self, subdata):\n        new_data = pd.concat([subdata, self.data[self.class_name]], axis=1).sort_values(by=subdata.name)\n        temp = new_data[self.class_name].iloc[0]\n        i = 0\n        cuts = []\n        for current in new_data[self.class_name]:\n            if temp != current:\n                cuts.append((new_data[subdata.name].iloc[i] + new_data[subdata.name].iloc[i - 1]) / 2)\n                temp = current\n            i += 1\n        alt = pd.DataFrame()\n        for cut in cuts:\n            alt = pd.concat([alt, subdata.apply(\n                GainRankingContinous.discretize_split, 1, args=(cut,)).astype(\'category\').rename(cut)], axis=1)\n        return alt[self.gain(alt, self.h_S)[0].idxmax()]\n\n    @staticmethod\n    def discretize_split(value, point):\n        if value < point:\n            return \' < \' + str(point)\n        else:\n            return \'>= \' + str(point)\n\n\nif __name__ == \'__main__\':\n    data_pd_2 = DataSets.get_weather_semi_nominal().ix[:, 1:]\n\n    print(GainRankingContinous(data_pd_2, data_pd_2.columns[-1]))\n'"
numerical/data_science/models/trees/gainranking.py,1,"b'import numpy as np\nimport pandas as pd\nfrom numerical.data_science.res import DataSets\n\n\nclass GainRanking:\n    """"""\n    Class GainRanking\n    """"""\n\n    def __init__(self, data_input, class_name, debug=False):\n        self.data = data_input\n        self.class_name = class_name\n        self.debug = debug\n        self.h_S = self.entropy(self.data)\n        self._gain_list = None\n\n    @property\n    def gain_list(self):\n        if self._gain_list is None:\n            columns = self.data.columns[self.data.columns != self.class_name]\n            self._gain_list, self.data.ix[:, columns] = self.gain(self.data.ix[:, columns], self.h_S)\n        return self._gain_list\n\n    @property\n    def gain_winner(self):\n        return self.gain_list.idxmax(), self.data[self.gain_list.idxmax()]\n\n    def gain(self, subdata, h_S):\n        result = pd.Series(index=subdata.columns)\n        for column in subdata.columns:\n            a = self.sub_entropy(subdata[column])\n            counts = subdata[column].value_counts()\n            p = (counts / counts.sum())\n            result[column] = (h_S - (p * a).sum())\n        return result, subdata\n\n    def entropy(self, subdata):\n        counts = subdata[self.class_name].value_counts()\n        p = (counts / counts.sum())\n        return (p * np.log2(1 / p)).sum()\n\n    def sub_entropy(self, subdata):\n        result = pd.Series(index=subdata.unique())\n        cross = pd.concat([subdata, self.data[self.class_name]], axis=1)\n        for cat in subdata.unique():\n            result[cat] = self.entropy(cross[subdata == cat])\n        return result\n\n    def __str__(self):\n        return str(self.gain_list)\n\n\nif __name__ == \'__main__\':\n    data_pd = DataSets.get_weber_nominal()\n    print(GainRanking(data_pd, data_pd.columns[-1]))\n'"
numerical/data_science/models/trees/id3.py,0,"b'from numerical.data_science.res import DataSets\nfrom numerical.data_science import GainRanking\nfrom utils.collections.labeled_tree import LabeledTree\n\n\nclass ID3:\n    def __init__(self, training_set, class_name, ranking=GainRanking):\n        self.class_name = class_name\n        self.ranking = ranking\n        self.tree = self.generate_tree(training_set)\n\n    def generate_tree(self, data_pd):\n        win, categories = self.ranking(data_pd, self.class_name).gain_winner\n        tree = LabeledTree(win)\n        for v1 in categories:\n            d = data_pd.ix[data_pd[win] == v1, data_pd.columns != win]\n\n            if len(d[self.class_name].unique()) == 1:\n                tree.add_child(v1, d[self.class_name].unique()[0])\n\n            elif d.shape[1] == 1:\n                tree.add_child(v1, "" "".join(d[self.class_name].unique()))\n\n            elif d.shape[0] == 0:\n                tree.add_child(v1, None)\n\n            else:\n                tree.add_child(v1, self.generate_tree(d))\n\n        return tree\n\n    def __str__(self):\n        return str(self.tree)\n\n\nif __name__ == \'__main__\':\n    data_pd = DataSets.get_weber_nominal()\n    id3_tennis = ID3(data_pd, data_pd.columns[-1])\n    print(id3_tennis)\n\n    \'\'\'\n    pd_careval = DataSets.get_car_eval()\n    id3_careval = ID3(pd_careval, pd_careval.columns[-1])\n    print(id3_careval)\n    \'\'\'\n\n    pd_credit = DataSets.get_credit().ix[:, 1:]\n    id3_credit = ID3(pd_credit, pd_credit.columns[0])\n    print(id3_credit)\n'"
numerical/data_science/models/trees/j48.py,0,"b""from numerical.data_science.res import DataSets\nfrom numerical.data_science import GainRankingContinous\nfrom numerical.data_science import ID3\n\n\nclass J48(ID3):\n    def __init__(self, training_set, class_name):\n        ID3.__init__(self, training_set, class_name, ranking=GainRankingContinous)\n\n\nif __name__ == '__main__':\n    data_pd_2 = DataSets.get_weather()\n    j48_tennis = J48(data_pd_2, data_pd_2.columns[-1])\n    print(j48_tennis)\n\n"""
numerical/data_science/res/main/DiscretizeThoraricSurgery.py,0,"b""from numerical.data_science.res import DataSets\n\n\ndef discretize_AGE(value):\n    if value <= 62:\n        return 'AGE_1'\n    elif 62 < value <= 65:\n        return 'AGE_3'\n    elif 65 < value <= 70:\n        return 'AGE_2'\n    else:\n        return 'AGE_4'\n\ndef discretize_PRE4(value):\n    if value <= 2.66:\n        return 'PRE4_1'\n    elif 2.66 < value <= 2.88:\n        return 'PRE4_2'\n    else:\n        return 'PRE4_3'\n\n\ndef discretize_PRE5(value):\n    if value <= 2.05:\n        return 'PRE5_1'\n    else:\n        return 'PRE5_2'\n\n\n\nif __name__ == '__main__':\n    pd_data = DataSets.get_thoraric_surgery()\n\n    pd_data['PRE4'] = pd_data['PRE4'].apply(discretize_PRE4,1).astype('category')\n    pd_data['PRE5'] = pd_data['PRE5'].apply(discretize_PRE5,1).astype('category')\n    pd_data['AGE'] = pd_data['AGE'].apply(discretize_AGE,1).astype('category')\n\n    print(pd_data)\n    pd_data.to_csv('ThoraricSurgery_discrete.csv', index=False)\n"""
numerical/data_science/res/main/__init__.py,0,b''
numerical/data_science/res/main/distance_functions.py,2,"b""import math\nimport numpy as np\n\n\ndef euclidean_distance(a, b):\n    return math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n\n\ndef weighted_euclidean_distance(a, b, w=[0.2, 0.8]):\n    return math.sqrt(w[0] * (a[0] - b[0]) ** 2 + w[1] * (a[1] - b[1]) ** 2)\n\n\ndef manhattan_distance(a, b):\n    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n\n\ndef hamming_distance(a, b):\n    return int(a[0] != b[0]) + int(a[1] != b[1])\n\n\ndef distance_to_set(instance, set, function):\n    result = list()\n    for item in set:\n        result.append(function(instance, item))\n    return result\n\n\ndef normalize(x):\n    return (x - x.min(axis=0)) / (x.max(axis=0) - x.min(axis=0))\n\n\nif __name__ == '__main__':\n    estrellas = [\n        [1, 1],\n        [1, 4],\n        [3, 1],\n        [5, 3]\n    ]\n\n    circulos = [\n        [2, 1],\n        [5, 2],\n        [6, 1]\n    ]\n\n    instancia = [3, 3]\n\n    x = np.array(estrellas + circulos)\n    y = np.array(instancia)\n\n    x_normed = normalize(x)\n    y_normed = (y - x.min(axis=0)) / (x.max(axis=0) - x.min(axis=0))\n\n    # print(x_normed)\n\n    # print(estrellas)\n    # print(circulos)\n    # print(instancia)\n    print(distance_to_set(y_normed, x_normed, euclidean_distance))\n    print(distance_to_set(y_normed, x_normed, weighted_euclidean_distance))\n    print(distance_to_set(instancia, estrellas + circulos, manhattan_distance))\n    print(distance_to_set(instancia, estrellas + circulos, hamming_distance))\n"""
numerical/math/stats/distributions/chi-square-inverse-mean.py,1,"b""#!/usr/bin/env python3\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom scipy import stats\n\ndef main():\n\n    plt.plot(np.linspace(0.5,1,200),stats.norm.ppf(np.linspace(0.5,1,200)))\n    plt.grid(True)\n    plt.xlabel('alpha')\n    plt.ylabel('Z_alpha')\n    plt.show()\n\nif __name__ == '__main__':\n    main()\n"""
numerical/math/stats/distributions/lognorm_percentiles.py,2,"b""#!/usr/bin/env python3\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef main():\n    '''\n        X -> LogNormal(nu, sigma)\n        P(X<40) = 0.4\n        P(X<50) = 0.55\n    '''\n\n    perc1 = 0.4\n    p1 = 40\n\n    perc2 = 0.55\n    p2 = 50\n\n    z_04  = norm.ppf(perc1)\n    z_055 = norm.ppf(perc2)\n\n    sigma = (np.log(p1)-np.log(p2))/(z_04 - z_055)\n    nu = (z_055 * sigma + np.log(40))\n\n    print('nu = ' + str(nu))\n    print('sigma = ' + str(sigma))\n\nif __name__ == '__main__':\n    main()\n"""
numerical/math/stats/distributions/normal-percentage.py,0,"b""#!/usr/bin/env python3\n\nimport numpy as np\nfrom sympy import *\nfrom mpmath import gamma, e\n\ndef main():\n\n    a = 0\n    b = oo\n\n    x = Symbol('x')\n    k = 2 #Symbol('k')\n\n    f = (x ** (k / 2 - 1) * e ** (-x / 2)) / (2 ** (k / 2) * gamma(k / 2))\n    g = 1 / x\n\n    print(sympify(integrate( g * f, (x, a,b))))\n\nif __name__ == '__main__':\n    main()\n"""
numerical/math/stats/distributions/probability-exercise-generator.py,6,"b""#!/usr/bin/env python3\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom scipy import stats\n\ndef main():\n\n    t1 = np.array(['1.1','1.2','1.3','1.4','1.5',\n                   '1.6', '1.7', '1.8', '1.9', '1.10',\n                   '1.11', '1.12', '1.13', '1.15', '1.16',\n                   '1.17', '1.18', '1.19', '1.20'])\n\n    t2 = np.array(['1.14', '1.21', '1.22', '1.23', '1.24',\n                   '1.25', '1.26', '1.27', '1.28', '1.29',\n                   '1.31', '1.32'])\n\n    t3 = np.array(['2.1','2.2','2.3','2.4','2.6',\n                   '2.7','2.8','2.9ab','2.13','2.18',\n                   '2.19','2.21','2.22','2.23','2.24',\n                   '2.25','2.35'])\n\n    t4 = np.array(['2.5','2.9c','2.15','2.16','2.17','lavadoras',\n                   '2.26','2.27','2.28','2.29', '2.31', '2.33'\n                   '2.37','2.38','2.39'])\n\n    exercises = pd.DataFrame([t1,t2,t3,t4]).T\n    # print(exercises)\n\n    t_rand = np.random.randint(0, exercises.shape[1])\n    print(t_rand)\n    e_rand = np.random.randint(0, exercises.count()[t_rand])\n\n    print(exercises.iloc[e_rand, t_rand])\n\n\nif __name__ == '__main__':\n    main()\n"""
numerical/math/stats/transformations/normal-power2-transformation.py,7,"b""#!/usr/bin/env python3\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef main():\n\n    bins = 100\n\n    elems_per_bin = 10 ** 5\n\n    x = np.random.normal(0,1, bins * elems_per_bin)\n    y = np.power(x,2)\n\n    f_x = np.histogram(x, bins)[0] / (elems_per_bin*(np.max(x)-np.min(x)))\n    f_y = np.histogram(y, bins)[0]/ (elems_per_bin*(np.max(y)-np.min(y)))\n\n    plt.plot(np.linspace(np.min(x),np.max(x),bins),f_x)\n    plt.plot(np.linspace(np.min(y),np.max(y),bins),f_y)\n\n    plt.gca().set_ylim([0,1])\n    plt.yticks(np.arange(0,1,0.1))\n    plt.grid(True)\n\n    plt.show()\n\nif __name__ == '__main__':\n    main()\n"""
numerical/math/stats/transformations/uniform-cos-transformation.py,7,"b""#!/usr/bin/env python3\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef main():\n\n    bins = 100\n\n    elems_per_bin = 10 ** 5\n\n    x = np.random.uniform(0,2*np.pi, bins * elems_per_bin)\n    y = np.cos(x)\n\n    f_x = np.histogram(x, bins)[0] / (elems_per_bin*(np.max(x)-np.min(x)))\n    f_y = np.histogram(y, bins)[0]/ (elems_per_bin*(np.max(y)-np.min(y)))\n\n    plt.plot(np.linspace(np.min(x),np.max(x),bins),f_x)\n    plt.plot(np.linspace(np.min(y),np.max(y),bins),f_y)\n\n    plt.gca().set_ylim([0,1])\n    plt.yticks(np.arange(0,1,0.1))\n    plt.grid(True)\n\n    plt.show()\n\nif __name__ == '__main__':\n    main()\n"""
web/django/django_first_app/django_first_app/__init__.py,0,b''
web/django/django_first_app/django_first_app/settings.py,0,"b'""""""\nDjango settings for django_first_app project.\n\nGenerated by \'django-admin startproject\' using Django 1.9.6.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/1.9/topics/settings/\n\nFor the full list of settings and their values, see\nhttps://docs.djangoproject.com/en/1.9/ref/settings/\n""""""\n\nimport os\n\n# Build paths inside the project like this: os.path.join(BASE_DIR, ...)\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n\n\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/1.9/howto/deployment/checklist/\n\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = \'6jf-1s7m*9a#@kcc7&&!d(10=c9kp&$d)o)=4qtj@*ch04a_#z\'\n\n# SECURITY WARNING: don\'t run with debug turned on in production!\nDEBUG = True\n\nALLOWED_HOSTS = []\n\n\n# Application definition\n\nINSTALLED_APPS = [\n    \'polls.apps.PollsConfig\',\n    \'django.contrib.admin\',\n    \'django.contrib.auth\',\n    \'django.contrib.contenttypes\',\n    \'django.contrib.sessions\',\n    \'django.contrib.messages\',\n    \'django.contrib.staticfiles\',\n]\n\nMIDDLEWARE_CLASSES = [\n    \'django.middleware.security.SecurityMiddleware\',\n    \'django.contrib.sessions.middleware.SessionMiddleware\',\n    \'django.middleware.common.CommonMiddleware\',\n    \'django.middleware.csrf.CsrfViewMiddleware\',\n    \'django.contrib.auth.middleware.AuthenticationMiddleware\',\n    \'django.contrib.auth.middleware.SessionAuthenticationMiddleware\',\n    \'django.contrib.messages.middleware.MessageMiddleware\',\n    \'django.middleware.clickjacking.XFrameOptionsMiddleware\',\n]\n\nROOT_URLCONF = \'django_first_app.urls\'\n\nTEMPLATES = [\n    {\n        \'BACKEND\': \'django.template.backends.django.DjangoTemplates\',\n        \'DIRS\': [],\n        \'APP_DIRS\': True,\n        \'OPTIONS\': {\n            \'context_processors\': [\n                \'django.template.context_processors.debug\',\n                \'django.template.context_processors.request\',\n                \'django.contrib.auth.context_processors.auth\',\n                \'django.contrib.messages.context_processors.messages\',\n            ],\n        },\n    },\n]\n\nWSGI_APPLICATION = \'django_first_app.wsgi.application\'\n\n\n# Database\n# https://docs.djangoproject.com/en/1.9/ref/settings/#databases\n\nDATABASES = {\n    \'default\': {\n        \'ENGINE\': \'django.db.backends.sqlite3\',\n        \'NAME\': os.path.join(BASE_DIR, \'db.sqlite3\'),\n    }\n}\n\n\n# Password validation\n# https://docs.djangoproject.com/en/1.9/ref/settings/#auth-password-validators\n\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.UserAttributeSimilarityValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.MinimumLengthValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.CommonPasswordValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.NumericPasswordValidator\',\n    },\n]\n\n\n# Internationalization\n# https://docs.djangoproject.com/en/1.9/topics/i18n/\n\nLANGUAGE_CODE = \'en-us\'\n\nTIME_ZONE = \'UTC\'\n\nUSE_I18N = True\n\nUSE_L10N = True\n\nUSE_TZ = True\n\n\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/1.9/howto/static-files/\n\nSTATIC_URL = \'/static/\'\n'"
web/django/django_first_app/django_first_app/urls.py,0,"b'""""""django_first_app URL Configuration\n\nThe `urlpatterns` list routes URLs to views. For more information please see:\n    https://docs.djangoproject.com/en/1.9/topics/http/urls/\nExamples:\nFunction views\n    1. Add an import:  from my_app import views\n    2. Add a URL to urlpatterns:  url(r\'^$\', views.home, name=\'home\')\nClass-based views\n    1. Add an import:  from other_app.views import Home\n    2. Add a URL to urlpatterns:  url(r\'^$\', Home.as_view(), name=\'home\')\nIncluding another URLconf\n    1. Import the include() function: from django.conf.urls import url, include\n    2. Add a URL to urlpatterns:  url(r\'^blog/\', include(\'blog.urls\'))\n""""""\nfrom web.django import include, url\nfrom web.django import admin\n\nurlpatterns = [\n    url(r\'^polls/\', include(\'polls.urls\')),\n    url(r\'^admin/\', admin.site.urls),\n]\n'"
web/django/django_first_app/django_first_app/wsgi.py,0,"b'""""""\nWSGI config for django_first_app project.\n\nIt exposes the WSGI callable as a module-level variable named ``application``.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/1.9/howto/deployment/wsgi/\n""""""\n\nimport os\n\nfrom web.django import get_wsgi_application\n\nos.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""django_first_app.settings"")\n\napplication = get_wsgi_application()\n'"
web/django/django_first_app/polls/__init__.py,0,b''
web/django/django_first_app/polls/admin.py,0,"b""# Register your models here.\n\nfrom web.django import admin\n\nfrom .models import Question, Choice\n\n\nclass ChoiceInline(admin.TabularInline):\n    model = Choice\n    extra = 3\n\n\nclass QuestionAdmin(admin.ModelAdmin):\n    fieldsets = [\n        (None, {'fields': ['question_text']}),\n        ('Date information', {'fields': ['pub_date'], 'classes': ['collapse']}),\n    ]\n    inlines = [ChoiceInline]\n    list_display = ('question_text', 'pub_date', 'was_published_recently')\n    list_filter = ['pub_date']\n    search_fields = ['question_text']\n\n\nadmin.site.register(Question, QuestionAdmin)\n"""
web/django/django_first_app/polls/apps.py,0,"b""from web.django import AppConfig\n\n\nclass PollsConfig(AppConfig):\n    name = 'polls'\n"""
web/django/django_first_app/polls/models.py,0,"b""import datetime\n\nfrom web.django import models\nfrom web.django import timezone\n\n\n# Create your models here.\n\n\nclass Question(models.Model):\n    question_text = models.CharField(max_length=200)\n    pub_date = models.DateTimeField('date published')\n\n    def __str__(self):\n        return self.question_text\n\n    def was_published_recently(self):\n        now = timezone.now()\n        return now - datetime.timedelta(days=1) <= self.pub_date <= now\n\n    was_published_recently.admin_order_field = 'pub_date'\n    was_published_recently.boolean = True\n    was_published_recently.short_description = 'Published recently?'\n\n\nclass Choice(models.Model):\n    question = models.ForeignKey(Question, on_delete=models.CASCADE)\n    choice_text = models.CharField(max_length=200)\n    votes = models.IntegerField(default=0)\n\n    def __str__(self):\n        return self.choice_text\n"""
web/django/django_first_app/polls/tests.py,0,"b'import datetime\n\nfrom web.django import timezone\nfrom web.django import TestCase\nfrom web.django import reverse\n\nfrom .models import Question\n\n\nclass QuestionMethodTests(TestCase):\n    def test_was_published_recently_with_future_question(self):\n        """"""\n        was_published_recently() should return False for questions whose\n        pub_date is in the future.\n        """"""\n        time = timezone.now() + datetime.timedelta(days=30)\n        future_question = Question(pub_date=time)\n        self.assertIs(future_question.was_published_recently(), False)\n\n    def test_was_published_recently_with_old_question(self):\n        """"""\n        was_published_recently() should return False for questions whose\n        pub_date is older than 1 day.\n        """"""\n        time = timezone.now() - datetime.timedelta(days=30)\n        old_question = Question(pub_date=time)\n        self.assertIs(old_question.was_published_recently(), False)\n\n    def test_was_published_recently_with_recent_question(self):\n        """"""\n        was_published_recently() should return True for questions whose\n        pub_date is within the last day.\n        """"""\n        time = timezone.now() - datetime.timedelta(hours=1)\n        recent_question = Question(pub_date=time)\n        self.assertIs(recent_question.was_published_recently(), True)\n\n\ndef create_question(question_text, days):\n    """"""\n    Creates a question with the given `question_text` and published the\n    given number of `days` offset to now (negative for questions published\n    in the past, positive for questions that have yet to be published).\n    """"""\n    time = timezone.now() + datetime.timedelta(days=days)\n    return Question.objects.create(question_text=question_text, pub_date=time)\n\n\nclass QuestionViewTests(TestCase):\n    def test_index_view_with_no_questions(self):\n        """"""\n        If no questions exist, an appropriate message should be displayed.\n        """"""\n        response = self.client.get(reverse(\'polls:index\'))\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, ""No polls are available."")\n        self.assertQuerysetEqual(response.context[\'latest_question_list\'], [])\n\n    def test_index_view_with_a_past_question(self):\n        """"""\n        Questions with a pub_date in the past should be displayed on the\n        index page.\n        """"""\n        create_question(question_text=""Past question."", days=-30)\n        response = self.client.get(reverse(\'polls:index\'))\n        self.assertQuerysetEqual(\n            response.context[\'latest_question_list\'],\n            [\'<Question: Past question.>\']\n        )\n\n    def test_index_view_with_a_future_question(self):\n        """"""\n        Questions with a pub_date in the future should not be displayed on\n        the index page.\n        """"""\n        create_question(question_text=""Future question."", days=30)\n        response = self.client.get(reverse(\'polls:index\'))\n        self.assertContains(response, ""No polls are available."")\n        self.assertQuerysetEqual(response.context[\'latest_question_list\'], [])\n\n    def test_index_view_with_future_question_and_past_question(self):\n        """"""\n        Even if both past and future questions exist, only past questions\n        should be displayed.\n        """"""\n        create_question(question_text=""Past question."", days=-30)\n        create_question(question_text=""Future question."", days=30)\n        response = self.client.get(reverse(\'polls:index\'))\n        self.assertQuerysetEqual(\n            response.context[\'latest_question_list\'],\n            [\'<Question: Past question.>\']\n        )\n\n    def test_index_view_with_two_past_questions(self):\n        """"""\n        The questions index page may display multiple questions.\n        """"""\n        create_question(question_text=""Past question 1."", days=-30)\n        create_question(question_text=""Past question 2."", days=-5)\n        response = self.client.get(reverse(\'polls:index\'))\n        self.assertQuerysetEqual(\n            response.context[\'latest_question_list\'],\n            [\'<Question: Past question 2.>\', \'<Question: Past question 1.>\']\n        )\n\n\nclass QuestionIndexDetailTests(TestCase):\n    def test_detail_view_with_a_future_question(self):\n        """"""\n        The detail view of a question with a pub_date in the future should\n        return a 404 not found.\n        """"""\n        future_question = create_question(question_text=\'Future question.\', days=5)\n        url = reverse(\'polls:detail\', args=(future_question.id,))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 404)\n\n    def test_detail_view_with_a_past_question(self):\n        """"""\n        The detail view of a question with a pub_date in the past should\n        display the question\'s text.\n        """"""\n        past_question = create_question(question_text=\'Past Question.\', days=-5)\n        url = reverse(\'polls:detail\', args=(past_question.id,))\n        response = self.client.get(url)\n        self.assertContains(response, past_question.question_text)\n'"
web/django/django_first_app/polls/urls.py,0,"b""from web.django import url\n\nfrom . import views\n\napp_name = 'polls'\nurlpatterns = [\n    url(r'^$', views.IndexView.as_view(), name='index'),\n    url(r'^(?P<pk>[0-9]+)/$', views.DetailView.as_view(), name='detail'),\n    url(r'^(?P<pk>[0-9]+)/results/$', views.ResultsView.as_view(), name='results'),\n    url(r'^(?P<question_id>[0-9]+)/vote/$', views.vote, name='vote'),\n]\n"""
web/django/django_first_app/polls/views.py,0,"b'from web.django import get_object_or_404, render\nfrom web.django import HttpResponseRedirect\nfrom web.django import reverse\nfrom web.django import generic\nfrom web.django import timezone\n\nfrom .models import Choice, Question\n\n\n# Create your views here.\n\nclass IndexView(generic.ListView):\n    template_name = \'polls/index.html\'\n    context_object_name = \'latest_question_list\'\n\n    def get_queryset(self):\n        """"""\n        Return the last five published questions (not including those set to be\n        published in the future).\n        """"""\n        return Question.objects.filter(\n            pub_date__lte=timezone.now()\n        ).order_by(\'-pub_date\')[:5]\n\n\nclass DetailView(generic.DetailView):\n    model = Question\n    template_name = \'polls/detail.html\'\n\n    def get_queryset(self):\n        """"""\n        Excludes any questions that aren\'t published yet.\n        """"""\n        return Question.objects.filter(pub_date__lte=timezone.now())\n\n\nclass ResultsView(generic.DetailView):\n    model = Question\n    template_name = \'polls/results.html\'\n\n\ndef vote(request, question_id):\n    question = get_object_or_404(Question, pk=question_id)\n    try:\n        selected_choice = question.choice_set.get(pk=request.POST[\'choice\'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the question voting form.\n        return render(request, \'polls/detail.html\', {\n            \'question\': question,\n            \'error_message\': ""You didn\'t select a choice."",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse(\'polls:results\', args=(question.id,)))\n'"
web/django/graphene/graphene-django-tutorial/__init__.py,0,b''
web/django/graphene/graphene-django-tutorial/manage.py,0,"b'#!/usr/bin/env python3\nimport os\nimport sys\n\nif __name__ == ""__main__"":\n    os.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""cookbook.settings"")\n\n    from web.django import execute_from_command_line\n\n    execute_from_command_line(sys.argv)\n'"
web/django/graphene/graphene-quickstart/__init__.py,0,b''
web/django/graphene/graphene-quickstart/lesson-01.py,0,"b'#!/usr/bin/env python3\n\n""""""\nURL: http://docs.graphene-python.org/en/latest/quickstart/\n""""""\n\nimport graphene\nimport utils.json as uj\n\n\nclass Query(graphene.ObjectType):\n    hello = graphene.String()\n\n    def resolve_hello(self, args, context, info):\n        return \'World\'\n\n\nschema = graphene.Schema(query=Query)\n\nresult = schema.execute(\'{ hello }\')\n\nprint(uj.dict_to_json(result.data))\n'"
web/django/graphene/graphene-quickstart/lesson-02-enums.py,0,"b'#!/usr/bin/env python3\n\n""""""\nURL: http://docs.graphene-python.org/en/latest/types/enums/\n""""""\n\nimport graphene\n\n\nclass Episode(graphene.Enum):\n    NEWHOPE = 4\n    EMPIRE = 5\n    JEDI = 6\n\n    @property\n    def description(self):\n        if self == Episode.NEWHOPE:\n            return \'New Hope Episode\'\n        return \'Other episode\'\n'"
web/django/graphene/graphene-quickstart/lesson-03-scalars.py,0,"b'#!/usr/bin/env python3\n\n""""""\nURL: http://docs.graphene-python.org/en/latest/types/scalars/\n""""""\n\nimport datetime\n\nimport graphene\nfrom graphene.types import Scalar\nfrom graphql.language import ast\n\n\nclass DateTime(Scalar):\n    """"""DateTime Scalar Description""""""\n\n    @staticmethod\n    def serialize(dt):\n        return dt.isoformat()\n\n    @staticmethod\n    def parse_literal(node):\n        if isinstance(node, ast.StringValue):\n            return datetime.datetime.strptime(\n                node.value, ""%Y-%m-%dT%H:%M:%S.%f"")\n\n    @staticmethod\n    def parse_value(value):\n        return datetime.datetime.strptime(value, ""%Y-%m-%dT%H:%M:%S.%f"")\n\n\nclass Person(graphene.ObjectType):\n    name = graphene.String()\n'"
web/django/graphene/graphene-quickstart/lesson-04-interfaces.py,0,"b'#!/usr/bin/env python3\n\n""""""\nURL: http://docs.graphene-python.org/en/latest/types/interfaces/\n""""""\n\nimport graphene\n\n\nclass Character(graphene.Interface):\n    name = graphene.String()\n\n\n# Human is a Character implementation\nclass Human(graphene.ObjectType):\n    class Meta:\n        interfaces = (Character,)\n\n    born_in = graphene.String()\n\n\n# Droid is a Character implementation\nclass Droid(graphene.ObjectType):\n    class Meta:\n        interfaces = (Character,)\n\n    function = graphene.String()\n'"
web/django/graphene/graphene-quickstart/lesson-05-abstract-types.py,0,"b'#!/usr/bin/env python3\n\n""""""\nURL: http://docs.graphene-python.org/en/latest/types/abstracttypes/\n""""""\n\nimport graphene\n\n\nclass UserFields(graphene.AbstractType):\n    name = graphene.String()\n\n\nclass User(graphene.ObjectType, UserFields):\n    pass\n\n\nclass UserInput(graphene.InputObjectType, UserFields):\n    pass\n'"
web/django/graphene/graphene-quickstart/lesson-06-object-types.py,0,"b'#!/usr/bin/env python3\n\n""""""\nURL: http://docs.graphene-python.org/en/latest/types/objecttypes/\n""""""\n\nimport graphene\n\n\nclass Person(graphene.ObjectType):\n    first_name = graphene.String()\n    last_name = graphene.String()\n    full_name = graphene.String()\n\n    def resolve_full_name(self, args, context, info):\n        return \'{} {}\'.format(self.first_name, self.last_name)\n'"
web/django/graphene/graphene-quickstart/lesson-07-schema.py,0,"b'#!/usr/bin/env python3\n\n""""""\nURL: http://docs.graphene-python.org/en/latest/types/schema/\n""""""\n\nimport graphene\n\n\nclass Person(graphene.ObjectType):\n    last_name = graphene.String()\n    other_name = graphene.String(name=\'_other_Name\')\n'"
web/django/graphene/graphene-quickstart/lesson-08-mutations.py,0,"b'#!/usr/bin/env python3\n\n""""""\nURL: http://docs.graphene-python.org/en/latest/types/mutations/\n""""""\n\nimport graphene\nimport utils.json as uj\n\n\nclass Person(graphene.ObjectType):\n    name = graphene.String()\n    age = graphene.Int()\n\n\nclass PersonInput(graphene.InputObjectType):\n    name = graphene.String()\n    age = graphene.Int()\n\n\nclass CreatePerson(graphene.Mutation):\n    class Input:\n        person_data = graphene.Argument(PersonInput)\n\n    ok = graphene.Boolean()\n    person = graphene.Field(lambda: Person)\n\n    def mutate(self, args, context, info):\n        p_data = args.get(\'person_data\')\n\n        name = p_data.get(\'name\')\n        age = p_data.get(\'age\')\n\n        person = Person(name=name, age=age)\n        ok = True\n        return CreatePerson(person=person, ok=ok)\n\n\nclass LatLngInput(graphene.InputObjectType):\n    lat = graphene.Float()\n    lng = graphene.Float()\n\n\n# A location has a latlng associated to it\nclass LocationInput(graphene.InputObjectType):\n    name = graphene.String()\n    latlng = graphene.InputField(LatLngInput)\n\n\nclass MyMutations(graphene.ObjectType):\n    create_person = CreatePerson.Field()\n\n\nschema = graphene.Schema(mutation=MyMutations)\n\nquery_string = \'mutation myFirstMutation {\' \\\n               \'   createPerson(personData: {name:""Peter"", age: 24}) {\' \\\n               \'       person {\' \\\n               \'           name,\' \\\n               \'           age\' \\\n               \'       }\' \\\n               \'       ok\' \\\n               \'   }\' \\\n               \'}\'\n\nresult = schema.execute(query_string)\n\nprint(uj.dict_to_json(result.data))\n'"
web/django/graphene/graphene-quickstart/lesson-09-context.py,0,"b'#!/usr/bin/env python3\n\n""""""\nURL: http://docs.graphene-python.org/en/latest/execution/#context\n""""""\n\nimport graphene\nimport utils.json as uj\n\n\nclass Query(graphene.ObjectType):\n    name = graphene.String()\n\n    def resolve_name(self, args, context, info):\n        return context.get(\'name\')\n\n\nschema = graphene.Schema(Query)\nresult = schema.execute(\'{ name }\', context_value={\'name\': \'Syrus\'})\n\nprint(uj.dict_to_json(result.data))\n'"
web/django/graphene/graphene-quickstart/lesson-10-middleware.py,0,"b'#!/usr/bin/env python3\n\n""""""\nURL: http://docs.graphene-python.org/en/latest/execution/middleware/\n""""""\n\nimport graphene\nimport utils.json as uj\n\n\nclass AuthorizationMiddleware(object):\n    def resolve(self, next, root, args, context, info):\n        if info.field_name == \'user\':\n            return None\n        return next(root, args, context, info)\n\n\nclass Query(graphene.ObjectType):\n    name = graphene.String()\n\n    def resolve_name(self, args, context, info):\n        return context.get(\'name\')\n\n\nschema = graphene.Schema(Query)\nresult = schema.execute(\'{ name }\', context_value={\'name\': \'Syrus\'}, middleware=[AuthorizationMiddleware()])\n\nprint(uj.dict_to_json(result.data))\n'"
numerical/math/algebra/matrix_decomposition/qr/givens_rotations.py,18,"b'#!/usr/bin/env python3\n\nfrom typing import Tuple\n\nimport numpy as np\n\n\ndef rotator(A: np.ndarray, i: int, j: int, k: int) -> np.ndarray:\n    G = np.eye(A.shape[0])\n    r = np.sqrt(A[i, k] ** 2 + A[j, k] ** 2)\n    if A[j, k] != 0:\n        G[i, i] = A[i, k] / r\n        G[i, j] = A[j, k] / r\n        G[j, i] = - A[j, k] / r\n        G[j, j] = A[i, k] / r\n    return G\n\n\ndef qr_givens(A: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n    Q = np.eye(A.shape[0])\n    for j in range(A.shape[1]):\n        G = np.eye(A.shape[0])\n        for i in reversed(range(j, A.shape[1])):\n            G = rotator(G @ A, i, i + 1, j) @ G\n        Q = Q @ np.transpose(G)\n        A = G @ A\n    return (Q, A)\n\n\ndef main() -> None:\n\n    A = np.array([[1,-1,1],\n                [1,1,1],\n                [1,1,-1],\n                [1,1,1]])\n\n    b = np.array([1, 1, -1, 0])\n\n    [Q, R] = qr_givens(A)\n    c = (np.transpose(Q) @ b).flatten()\n    x = np.linalg.solve(R[0:R.shape[1], :], c[0:R.shape[1]])\n\n    print(""A ="", np.round(A, decimals=2),  \'\\n\', sep=\'\\n\')\n    print(""Q ="", np.round(Q, decimals=2),  \'\\n\', sep=\'\\n\')\n    print(""R ="", np.round(R, decimals=2),  \'\\n\', sep=\'\\n\')\n    print(""Q @ R ="", np.round(Q @ R, decimals=2), \'\\n\', sep=\'\\n\')\n    print(""b ="", np.round(b, decimals=2), \'\\n\', sep=\'\\n\')\n    print(""c ="", np.round(c, decimals=2), \'\\n\', sep=\'\\n\')\n    print(""x ="", np.round(x, decimals=2), \'\\n\', sep=\'\\n\')\n\nif __name__ == \'__main__\':\n    main()\n'"
numerical/math/algebra/matrix_decomposition/qr/householder_reflections.py,18,"b'#!/usr/bin/env python3\n\nfrom typing import Tuple\n\nimport numpy as np\n\n\ndef reflector(A: np.ndarray, i: int) -> np.ndarray:\n    x = np.take(A, [i], 1)\n    y =  np.concatenate([x[:i], [[np.sqrt(np.sum(np.power(x[i:],2)))]],\n                        np.zeros([A.shape[0] - i - 1, 1])])\n    u = (x - y)\n    return np.eye(A.shape[0]) - (2 / np.squeeze(u.T @ u)) * (u @ u.T)\n\n\ndef qr_householder(A: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n    Q = np.eye(A.shape[0])\n    for i in range(A.shape[1]):\n        R = reflector(A, i)\n        Q = Q @ R\n        A = R @ A\n    return (Q, A)\n\n\ndef main() -> None:\n\n    A = np.array([[1,-1,1],\n                [1,1,1],\n                [1,1,-1],\n                [1,1,1]])\n\n    b = np.array([1, 1, -1, 0])\n\n    [Q, R] = qr_householder(A)\n    c = (np.transpose(Q) @ b).flatten()\n    x = np.linalg.solve(R[0:R.shape[1], :], c[0:R.shape[1]])\n\n    print(""A ="", np.round(A, decimals=2),  \'\\n\', sep=\'\\n\')\n    print(""Q ="", np.round(Q, decimals=2),  \'\\n\', sep=\'\\n\')\n    print(""R ="", np.round(R, decimals=2),  \'\\n\', sep=\'\\n\')\n    print(""Q @ R ="", np.round(Q @ R, decimals=2), \'\\n\', sep=\'\\n\')\n    print(""b ="", np.round(b, decimals=2), \'\\n\', sep=\'\\n\')\n    print(""c ="", np.round(c, decimals=2), \'\\n\', sep=\'\\n\')\n    print(""x ="", np.round(x, decimals=2), \'\\n\', sep=\'\\n\')\n\nif __name__ == \'__main__\':\n    main()\n'"
web/django/django_first_app/polls/migrations/0001_initial.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.9.6 on 2017-01-31 17:51\nfrom __future__ import unicode_literals\n\nfrom web.django import migrations, models\nfrom web import django\n\n\nclass Migration(migrations.Migration):\n\n    initial = True\n\n    dependencies = [\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='Choice',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('choice_text', models.CharField(max_length=200)),\n                ('votes', models.IntegerField(default=0)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='Question',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('question_text', models.CharField(max_length=200)),\n                ('pub_date', models.DateTimeField(verbose_name='date published')),\n            ],\n        ),\n        migrations.AddField(\n            model_name='choice',\n            name='question',\n            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='polls.Question'),\n        ),\n    ]\n"""
web/django/django_first_app/polls/migrations/__init__.py,0,b''
web/django/graphene/graphene-django-tutorial/cookbook/__init__.py,0,b''
web/django/graphene/graphene-django-tutorial/cookbook/schema.py,0,"b'import graphene\n\nfrom .ingredients import schema as i_schema\n\n\nclass Query(i_schema.Query, graphene.ObjectType):\n    # This class will inherit from multiple Queries\n    # as we begin to add more apps to our project\n    pass\n\n\nschema = graphene.Schema(query=Query)\n'"
web/django/graphene/graphene-django-tutorial/cookbook/settings.py,0,"b'""""""\nDjango settings for cookbook project.\n\nGenerated by \'django-admin startproject\' using Django 1.9.6.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/1.9/topics/settings/\n\nFor the full list of settings and their values, see\nhttps://docs.djangoproject.com/en/1.9/ref/settings/\n""""""\n\nimport os\n\n# Build paths inside the project like this: os.path.join(BASE_DIR, ...)\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n\n\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/1.9/howto/deployment/checklist/\n\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = \'$@-69dolh++9@k^5ka79)fje!aoj6ra%)la7w^#m3u^9zd#tl3\'\n\n# SECURITY WARNING: don\'t run with debug turned on in production!\nDEBUG = True\n\nALLOWED_HOSTS = []\n\n\n# Application definition\n\nINSTALLED_APPS = [\n    \'django.contrib.admin\',\n    \'django.contrib.auth\',\n    \'django.contrib.contenttypes\',\n    \'django.contrib.sessions\',\n    \'django.contrib.messages\',\n    \'django.contrib.staticfiles\',\n    \'graphene_django\',\n    \'cookbook.ingredients\',\n]\n\nGRAPHENE = {\n    \'SCHEMA\': \'cookbook.schema.schema\'\n}\n\nMIDDLEWARE_CLASSES = [\n    \'django.middleware.security.SecurityMiddleware\',\n    \'django.contrib.sessions.middleware.SessionMiddleware\',\n    \'django.middleware.common.CommonMiddleware\',\n    \'django.middleware.csrf.CsrfViewMiddleware\',\n    \'django.contrib.auth.middleware.AuthenticationMiddleware\',\n    \'django.contrib.auth.middleware.SessionAuthenticationMiddleware\',\n    \'django.contrib.messages.middleware.MessageMiddleware\',\n    \'django.middleware.clickjacking.XFrameOptionsMiddleware\',\n]\n\nROOT_URLCONF = \'cookbook.urls\'\n\nTEMPLATES = [\n    {\n        \'BACKEND\': \'django.template.backends.django.DjangoTemplates\',\n        \'DIRS\': [],\n        \'APP_DIRS\': True,\n        \'OPTIONS\': {\n            \'context_processors\': [\n                \'django.template.context_processors.debug\',\n                \'django.template.context_processors.request\',\n                \'django.contrib.auth.context_processors.auth\',\n                \'django.contrib.messages.context_processors.messages\',\n            ],\n        },\n    },\n]\n\nWSGI_APPLICATION = \'cookbook.wsgi.application\'\n\n\n# Database\n# https://docs.djangoproject.com/en/1.9/ref/settings/#databases\n\nDATABASES = {\n    \'default\': {\n        \'ENGINE\': \'django.db.backends.sqlite3\',\n        \'NAME\': os.path.join(BASE_DIR, \'db.sqlite3\'),\n    }\n}\n\n\n# Password validation\n# https://docs.djangoproject.com/en/1.9/ref/settings/#auth-password-validators\n\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.UserAttributeSimilarityValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.MinimumLengthValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.CommonPasswordValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.NumericPasswordValidator\',\n    },\n]\n\n\n# Internationalization\n# https://docs.djangoproject.com/en/1.9/topics/i18n/\n\nLANGUAGE_CODE = \'en-us\'\n\nTIME_ZONE = \'UTC\'\n\nUSE_I18N = True\n\nUSE_L10N = True\n\nUSE_TZ = True\n\n\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/1.9/howto/static-files/\n\nSTATIC_URL = \'/static/\'\n'"
web/django/graphene/graphene-django-tutorial/cookbook/urls.py,0,"b'""""""cookbook URL Configuration\n\nThe `urlpatterns` list routes URLs to views. For more information please see:\n    https://docs.djangoproject.com/en/1.9/topics/http/urls/\nExamples:\nFunction views\n    1. Add an import:  from my_app import views\n    2. Add a URL to urlpatterns:  url(r\'^$\', views.home, name=\'home\')\nClass-based views\n    1. Add an import:  from other_app.views import Home\n    2. Add a URL to urlpatterns:  url(r\'^$\', Home.as_view(), name=\'home\')\nIncluding another URLconf\n    1. Import the include() function: from django.conf.urls import url, include\n    2. Add a URL to urlpatterns:  url(r\'^blog/\', include(\'blog.urls\'))\n""""""\nfrom web.django import url\nfrom web.django import admin\n\nfrom graphene_django.views import GraphQLView\n\nurlpatterns = [\n    url(r\'^admin/\', admin.site.urls),\n    url(r\'^graphql\', GraphQLView.as_view(graphiql=True)),\n]\n'"
web/django/graphene/graphene-django-tutorial/cookbook/wsgi.py,0,"b'""""""\nWSGI config for cookbook project.\n\nIt exposes the WSGI callable as a module-level variable named ``application``.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/1.9/howto/deployment/wsgi/\n""""""\n\nimport os\n\nfrom web.django import get_wsgi_application\n\nos.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""cookbook.settings"")\n\napplication = get_wsgi_application()\n'"
web/django/graphene/graphene-django-tutorial/cookbook/ingredients/__init__.py,0,b''
web/django/graphene/graphene-django-tutorial/cookbook/ingredients/admin.py,0,b'# Register your models here.\n'
web/django/graphene/graphene-django-tutorial/cookbook/ingredients/apps.py,0,"b""from __future__ import unicode_literals\n\nfrom web.django import AppConfig\n\n\nclass IngredientsConfig(AppConfig):\n    name = 'cookbook.ingredients'\n"""
web/django/graphene/graphene-django-tutorial/cookbook/ingredients/models.py,0,"b""from __future__ import unicode_literals\n\nfrom web.django import models\n\n\n# Create your models here.\n\n\nclass Category(models.Model):\n    name = models.CharField(max_length=100)\n\n    def __str__(self):\n        return self.name\n\n\nclass Ingredient(models.Model):\n    name = models.CharField(max_length=100)\n    notes = models.TextField()\n    category = models.ForeignKey(Category, related_name='ingredients')\n\n    def __str__(self):\n        return self.name\n"""
web/django/graphene/graphene-django-tutorial/cookbook/ingredients/schema.py,0,"b""from graphene import relay, ObjectType, AbstractType\nfrom graphene_django import DjangoObjectType\nfrom graphene_django.filter import DjangoFilterConnectionField\n\nfrom .models import Category, Ingredient\n\n\n# Graphene will automatically map the Category model's fields onto the CategoryNode.\n# This is configured in the CategoryNode's Meta class (as you can see below)\nclass CategoryNode(DjangoObjectType):\n    class Meta:\n        model = Category\n        filter_fields = ['name', 'ingredients']\n        interfaces = (relay.Node, )\n\n\nclass IngredientNode(DjangoObjectType):\n    class Meta:\n        model = Ingredient\n        # Allow for some more advanced filtering here\n        filter_fields = {\n            'name': ['exact', 'icontains', 'istartswith'],\n            'notes': ['exact', 'icontains'],\n            'category': ['exact'],\n            'category__name': ['exact'],\n        }\n        interfaces = (relay.Node, )\n\n\nclass Query(AbstractType):\n    category = relay.Node.Field(CategoryNode)\n    all_categories = DjangoFilterConnectionField(CategoryNode)\n\n    ingredient = relay.Node.Field(IngredientNode)\n    all_ingredients = DjangoFilterConnectionField(IngredientNode)"""
web/django/graphene/graphene-django-tutorial/cookbook/ingredients/tests.py,0,b'# Create your tests here.\n'
web/django/graphene/graphene-django-tutorial/cookbook/ingredients/views.py,0,b'# Create your views here.\n'
web/django/graphene/graphene-django-tutorial/cookbook/ingredients/migrations/0001_initial.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.9.6 on 2017-02-01 10:36\nfrom __future__ import unicode_literals\n\nfrom web.django import migrations, models\nfrom web import django\n\n\nclass Migration(migrations.Migration):\n\n    initial = True\n\n    dependencies = [\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='Category',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('name', models.CharField(max_length=100)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='Ingredient',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('name', models.CharField(max_length=100)),\n                ('notes', models.TextField()),\n                ('category', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='ingredients', to='ingredients.Category')),\n            ],\n        ),\n    ]\n"""
web/django/graphene/graphene-django-tutorial/cookbook/ingredients/migrations/__init__.py,0,b''
